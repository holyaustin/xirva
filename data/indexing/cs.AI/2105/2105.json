[{"id": "2105.00002", "submitter": "Jakob Mokander", "authors": "Jakob Mokander and Luciano Floridi", "title": "Ethics-Based Auditing to Develop Trustworthy AI", "comments": "Minds & Machines (2021)", "journal-ref": null, "doi": "10.1007/s11023-021-09557-8", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A series of recent developments points towards auditing as a promising\nmechanism to bridge the gap between principles and practice in AI ethics.\nBuilding on ongoing discussions concerning ethics-based auditing, we offer\nthree contributions. First, we argue that ethics-based auditing can improve the\nquality of decision making, increase user satisfaction, unlock growth\npotential, enable law-making, and relieve human suffering. Second, we highlight\ncurrent best practices to support the design and implementation of ethics-based\nauditing: To be feasible and effective, ethics-based auditing should take the\nform of a continuous and constructive process, approach ethical alignment from\na system perspective, and be aligned with public policies and incentives for\nethically desirable behaviour. Third, we identify and discuss the constraints\nassociated with ethics-based auditing. Only by understanding and accounting for\nthese constraints can ethics-based auditing facilitate ethical alignment of AI,\nwhile enabling society to reap the full economic and social benefits of\nautomation.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 11:39:40 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Mokander", "Jakob", ""], ["Floridi", "Luciano", ""]]}, {"id": "2105.00059", "submitter": "Alexandr Sboev", "authors": "Alexander Sboev, Sanna Sboeva, Ivan Moloshnikov, Artem Gryaznov, Roman\n  Rybka, Alexander Naumov, Anton Selivanov, Gleb Rylkov, Viacheslav Ilyin", "title": "An analysis of full-size Russian complexly NER labelled corpus of\n  Internet user reviews on the drugs based on deep learning and language neural\n  nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present the full-size Russian complexly NER-labeled corpus of Internet\nuser reviews, along with an evaluation of accuracy levels reached on this\ncorpus by a set of advanced deep learning neural networks to extract the\npharmacologically meaningful entities from Russian texts. The corpus annotation\nincludes mentions of the following entities: Medication (33005 mentions),\nAdverse Drug Reaction (1778), Disease (17403), and Note (4490). Two of them -\nMedication and Disease - comprise a set of attributes. A part of the corpus has\nthe coreference annotation with 1560 coreference chains in 300 documents.\nSpecial multi-label model based on a language model and the set of features is\ndeveloped, appropriate for presented corpus labeling. The influence of the\nchoice of different modifications of the models: word vector representations,\ntypes of language models pre-trained for Russian, text normalization styles,\nand other preliminary processing are analyzed. The sufficient size of our\ncorpus allows to study the effects of particularities of corpus labeling and\nbalancing entities in the corpus. As a result, the state of the art for the\npharmacological entity extraction problem for Russian is established on a\nfull-size labeled corpus. In case of the adverse drug reaction (ADR)\nrecognition, it is 61.1 by the F1-exact metric that, as our analysis shows, is\non par with the accuracy level for other language corpora with similar\ncharacteristics and the ADR representativnes. The evaluated baseline precision\nof coreference relation extraction on the corpus is 71, that is higher the\nresults reached on other Russian corpora.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 19:46:24 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Sboev", "Alexander", ""], ["Sboeva", "Sanna", ""], ["Moloshnikov", "Ivan", ""], ["Gryaznov", "Artem", ""], ["Rybka", "Roman", ""], ["Naumov", "Alexander", ""], ["Selivanov", "Anton", ""], ["Rylkov", "Gleb", ""], ["Ilyin", "Viacheslav", ""]]}, {"id": "2105.00060", "submitter": "Cynthia Rudin", "authors": "Michael Anis Mihdi Afnan, Cynthia Rudin, Vincent Conitzer, Julian\n  Savulescu, Abhishek Mishra, Yanhe Liu, Masoud Afnan", "title": "Ethical Implementation of Artificial Intelligence to Select Embryos in\n  In Vitro Fertilization", "comments": null, "journal-ref": "AIES 2021", "doi": "10.1145/3461702.3462589", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  AI has the potential to revolutionize many areas of healthcare. Radiology,\ndermatology, and ophthalmology are some of the areas most likely to be impacted\nin the near future, and they have received significant attention from the\nbroader research community. But AI techniques are now also starting to be used\nin in vitro fertilization (IVF), in particular for selecting which embryos to\ntransfer to the woman. The contribution of AI to IVF is potentially\nsignificant, but must be done carefully and transparently, as the ethical\nissues are significant, in part because this field involves creating new\npeople. We first give a brief introduction to IVF and review the use of AI for\nembryo selection. We discuss concerns with the interpretation of the reported\nresults from scientific and practical perspectives. We then consider the\nbroader ethical issues involved. We discuss in detail the problems that result\nfrom the use of black-box methods in this context and advocate strongly for the\nuse of interpretable models. Importantly, there have been no published trials\nof clinical effectiveness, a problem in both the AI and IVF communities, and we\ntherefore argue that clinical implementation at this point would be premature.\nFinally, we discuss ways for the broader AI community to become involved to\nensure scientifically sound and ethically responsible development of AI in IVF.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 19:46:31 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Afnan", "Michael Anis Mihdi", ""], ["Rudin", "Cynthia", ""], ["Conitzer", "Vincent", ""], ["Savulescu", "Julian", ""], ["Mishra", "Abhishek", ""], ["Liu", "Yanhe", ""], ["Afnan", "Masoud", ""]]}, {"id": "2105.00063", "submitter": "Dejan Stepec", "authors": "Tomaz Martincic and Dejan Stepec and Joao Pita Costa and Kristijan\n  Cagran and Athanasios Chaldeakis", "title": "Vessel and Port Efficiency Metrics through Validated AIS data", "comments": "OCEANS 2020", "journal-ref": null, "doi": "10.1109/IEEECONF38699.2020.9389112", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Automatic Identification System (AIS) data represents a rich source of\ninformation about maritime traffic and offers a great potential for data\nanalytics and predictive modeling solutions, which can help optimizing logistic\nchains and to reduce environmental impacts. In this work, we address the main\nlimitations of the validity of AIS navigational data fields, by proposing a\nmachine learning-based data-driven methodology to detect and (to the possible\nextent) also correct erroneous data. Additionally, we propose a metric that can\nbe used by vessel operators and ports to express numerically their business and\nenvironmental efficiency through time and spatial dimensions, enabled with the\nobtained validated AIS data. We also demonstrate Port Area Vessel Movements\n(PARES) tool, which demonstrates the proposed solutions.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 19:51:51 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Martincic", "Tomaz", ""], ["Stepec", "Dejan", ""], ["Costa", "Joao Pita", ""], ["Cagran", "Kristijan", ""], ["Chaldeakis", "Athanasios", ""]]}, {"id": "2105.00113", "submitter": "Yisroel Mirsky Dr.", "authors": "Yisroel Mirsky", "title": "IPatch: A Remote Adversarial Patch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Applications such as autonomous vehicles and medical screening use deep\nlearning models to localize and identify hundreds of objects in a single frame.\nIn the past, it has been shown how an attacker can fool these models by placing\nan adversarial patch within a scene. However, these patches must be placed in\nthe target location and do not explicitly alter the semantics elsewhere in the\nimage.\n  In this paper, we introduce a new type of adversarial patch which alters a\nmodel's perception of an image's semantics. These patches can be placed\nanywhere within an image to change the classification or semantics of locations\nfar from the patch. We call this new class of adversarial examples `remote\nadversarial patches' (RAP).\n  We implement our own RAP called IPatch and perform an in-depth analysis on\nimage segmentation RAP attacks using five state-of-the-art architectures with\neight different encoders on the CamVid street view dataset. Moreover, we\ndemonstrate that the attack can be extended to object recognition models with\npreliminary results on the popular YOLOv3 model. We found that the patch can\nchange the classification of a remote target region with a success rate of up\nto 93% on average.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 22:34:32 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 15:21:53 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Mirsky", "Yisroel", ""]]}, {"id": "2105.00134", "submitter": "Arseny Tolmachev", "authors": "Arseny Tolmachev, Akira Sakai, Masaru Todoriki, Koji Maruhashi", "title": "Bermuda Triangles: GNNs Fail to Detect Simple Topological Structures", "comments": "ICLR 2021 GTRL Poster Presentation:\n  https://openreview.net/forum?id=Vz_Nl9MSQnu", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most graph neural network architectures work by message-passing node vector\nembeddings over the adjacency matrix, and it is assumed that they capture graph\ntopology by doing that. We design two synthetic tasks, focusing purely on\ntopological problems -- triangle detection and clique distance -- on which\ngraph neural networks perform surprisingly badly, failing to detect those\n\"bermuda\" triangles. Datasets and their generation scripts are publicly\navailable on github.com/FujitsuLaboratories/bermudatriangles and\ndataset.labs.fujitsu.com.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 00:47:37 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Tolmachev", "Arseny", ""], ["Sakai", "Akira", ""], ["Todoriki", "Masaru", ""], ["Maruhashi", "Koji", ""]]}, {"id": "2105.00157", "submitter": "Tanner Bohn", "authors": "Charles X. Ling, Tanner Bohn", "title": "A Deep Learning Framework for Lifelong Machine Learning", "comments": "27 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans can learn a variety of concepts and skills incrementally over the\ncourse of their lives while exhibiting many desirable properties, such as\ncontinual learning without forgetting, forward transfer and backward transfer\nof knowledge, and learning a new concept or task with only a few examples.\nSeveral lines of machine learning research, such as lifelong machine learning,\nfew-shot learning, and transfer learning attempt to capture these properties.\nHowever, most previous approaches can only demonstrate subsets of these\nproperties, often by different complex mechanisms. In this work, we propose a\nsimple yet powerful unified deep learning framework that supports almost all of\nthese properties and approaches through one central mechanism. Experiments on\ntoy examples support our claims. We also draw connections between many\npeculiarities of human learning (such as memory loss and \"rain man\") and our\nframework.\n  As academics, we often lack resources required to build and train, deep\nneural networks with billions of parameters on hundreds of TPUs. Thus, while\nour framework is still conceptual, and our experiment results are surely not\nSOTA, we hope that this unified lifelong learning framework inspires new work\ntowards large-scale experiments and understanding human learning in general.\n  This paper is summarized in two short YouTube videos:\nhttps://youtu.be/gCuUyGETbTU (part 1) and https://youtu.be/XsaGI01b-1o (part\n2).\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 03:43:25 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ling", "Charles X.", ""], ["Bohn", "Tanner", ""]]}, {"id": "2105.00162", "submitter": "Chrisantha Fernando Dr", "authors": "Chrisantha Fernando, S. M. Ali Eslami, Jean-Baptiste Alayrac, Piotr\n  Mirowski, Dylan Banarse, Simon Osindero", "title": "Generative Art Using Neural Visual Grammars and Dual Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whilst there are perhaps only a few scientific methods, there seem to be\nalmost as many artistic methods as there are artists. Artistic processes appear\nto inhabit the highest order of open-endedness. To begin to understand some of\nthe processes of art making it is helpful to try to automate them even\npartially. In this paper, a novel algorithm for producing generative art is\ndescribed which allows a user to input a text string, and which in a creative\nresponse to this string, outputs an image which interprets that string. It does\nso by evolving images using a hierarchical neural Lindenmeyer system, and\nevaluating these images along the way using an image text dual encoder trained\non billions of images and their associated text from the internet. In doing so\nwe have access to and control over an instance of an artistic process, allowing\nanalysis of which aspects of the artistic process become the task of the\nalgorithm, and which elements remain the responsibility of the artist.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 04:21:52 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 01:34:46 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Fernando", "Chrisantha", ""], ["Eslami", "S. M. Ali", ""], ["Alayrac", "Jean-Baptiste", ""], ["Mirowski", "Piotr", ""], ["Banarse", "Dylan", ""], ["Osindero", "Simon", ""]]}, {"id": "2105.00173", "submitter": "Daniel Szelogowski", "authors": "Daniel Szelogowski", "title": "Emotion Recognition of the Singing Voice: Toward a Real-Time Analysis\n  Tool for Singers", "comments": "26 pages, 10 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.CY cs.LG cs.NE eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Current computational-emotion research has focused on applying acoustic\nproperties to analyze how emotions are perceived mathematically or used in\nnatural language processing machine learning models. While recent interest has\nfocused on analyzing emotions from the spoken voice, little experimentation has\nbeen performed to discover how emotions are recognized in the singing voice --\nboth in noiseless and noisy data (i.e., data that is either inaccurate,\ndifficult to interpret, has corrupted/distorted/nonsense information like\nactual noise sounds in this case, or has a low ratio of usable/unusable\ninformation). Not only does this ignore the challenges of training machine\nlearning models on more subjective data and testing them with much noisier\ndata, but there is also a clear disconnect in progress between advancing the\ndevelopment of convolutional neural networks and the goal of emotionally\ncognizant artificial intelligence. By training a new model to include this type\nof information with a rich comprehension of psycho-acoustic properties, not\nonly can models be trained to recognize information within extremely noisy\ndata, but advancement can be made toward more complex biofeedback applications\n-- including creating a model which could recognize emotions given any human\ninformation (language, breath, voice, body, posture) and be used in any\nperformance medium (music, speech, acting) or psychological assistance for\npatients with disorders such as BPD, alexithymia, autism, among others. This\npaper seeks to reflect and expand upon the findings of related research and\npresent a stepping-stone toward this end goal.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 05:47:15 GMT"}, {"version": "v2", "created": "Sun, 4 Jul 2021 07:34:14 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Szelogowski", "Daniel", ""]]}, {"id": "2105.00200", "submitter": "Nicoletta Fornara Mrs", "authors": "Nicoletta Fornara, Soheil Roshankish, Marco Colombetti", "title": "A Framework for Automatic Monitoring of Norms that regulate Time\n  Constrained Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of proposing a model of norms and a\nframework for automatically computing their violation or fulfilment. The\nproposed T-NORM model can be used to express abstract norms able to regulate\nclasses of actions that should or should not be performed in a temporal\ninterval. We show how the model can be used to formalize obligations and\nprohibitions and for inhibiting them by introducing permissions and exemptions.\nThe basic building blocks for norm specification consists of rules with\nsuitably nested components. The activation condition, the regulated actions,\nand the temporal constrains of norms are specified using the W3C Web Ontology\nLanguage (OWL 2). Thanks to this choice, it is possible to use OWL reasoning\nfor computing the effects that the logical implication between actions has on\nnorms fulfilment or violation. The operational semantics of the T-NORM model is\nspecified by providing an unambiguous procedure for translating every norm and\nevery exception into production rules.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 09:29:32 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Fornara", "Nicoletta", ""], ["Roshankish", "Soheil", ""], ["Colombetti", "Marco", ""]]}, {"id": "2105.00202", "submitter": "Stavros Ntalampiras", "authors": "Michelangelo Acconcjaioco and Stavros Ntalampiras", "title": "One-shot learning for acoustic identification of bird species in\n  non-stationary environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work introduces the one-shot learning paradigm in the computational\nbioacoustics domain. Even though, most of the related literature assumes\navailability of data characterizing the entire class dictionary of the problem\nat hand, that is rarely true as a habitat's species composition is only known\nup to a certain extent. Thus, the problem needs to be addressed by\nmethodologies able to cope with non-stationarity. To this end, we propose a\nframework able to detect changes in the class dictionary and incorporate new\nclasses on the fly. We design an one-shot learning architecture composed of a\nSiamese Neural Network operating in the logMel spectrogram space. We\nextensively examine the proposed approach on two datasets of various bird\nspecies using suitable figures of merit. Interestingly, such a learning scheme\nexhibits state of the art performance, while taking into account extreme\nnon-stationarity cases.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 09:43:20 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Acconcjaioco", "Michelangelo", ""], ["Ntalampiras", "Stavros", ""]]}, {"id": "2105.00239", "submitter": "Guokai Tang", "authors": "Saurabh Jain, Guokai Tang, Lim Sze Chi", "title": "MRCBert: A Machine Reading ComprehensionApproach for Unsupervised\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When making an online purchase, it becomes important for the customer to read\nthe product reviews carefully and make a decision based on that. However,\nreviews can be lengthy, may contain repeated, or sometimes irrelevant\ninformation that does not help in decision making. In this paper, we introduce\nMRCBert, a novel unsupervised method to generate summaries from product\nreviews. We leverage Machine Reading Comprehension, i.e. MRC, approach to\nextract relevant opinions and generate both rating-wise and aspect-wise\nsummaries from reviews. Through MRCBert we show that we can obtain reasonable\nperformance using existing models and transfer learning, which can be useful\nfor learning under limited or low resource scenarios. We demonstrated our\nresults on reviews of a product from the Electronics category in the Amazon\nReviews dataset. Our approach is unsupervised as it does not require any\ndomain-specific dataset, such as the product review dataset, for training or\nfine-tuning. Instead, we have used SQuAD v1.1 dataset only to fine-tune BERT\nfor the MRC task. Since MRCBert does not require a task-specific dataset, it\ncan be easily adapted and used in other domains.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 12:57:08 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Jain", "Saurabh", ""], ["Tang", "Guokai", ""], ["Chi", "Lim Sze", ""]]}, {"id": "2105.00249", "submitter": "Wei Guo", "authors": "Wei Guo, Benedetta Tondi and Mauro Barni", "title": "A Master Key Backdoor for Universal Impersonation Attack against\n  DNN-based Face Verification", "comments": null, "journal-ref": "pattern recognition letters 2021", "doi": "10.1016/j.patrec.2021.01.009", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new attack against face verification systems based on Deep\nNeural Networks (DNN). The attack relies on the introduction into the network\nof a hidden backdoor, whose activation at test time induces a verification\nerror allowing the attacker to impersonate any user. The new attack, named\nMaster Key backdoor attack, operates by interfering with the training phase, so\nto instruct the DNN to always output a positive verification answer when the\nface of the attacker is presented at its input. With respect to existing\nattacks, the new backdoor attack offers much more flexibility, since the\nattacker does not need to know the identity of the victim beforehand. In this\nway, he can deploy a Universal Impersonation attack in an open-set framework,\nallowing him to impersonate any enrolled users, even those that were not yet\nenrolled in the system when the attack was conceived. We present a practical\nimplementation of the attack targeting a Siamese-DNN face verification system,\nand show its effectiveness when the system is trained on VGGFace2 dataset and\ntested on LFW and YTF datasets. According to our experiments, the Master Key\nbackdoor attack provides a high attack success rate even when the ratio of\npoisoned training data is as small as 0.01, thus raising a new alarm regarding\nthe use of DNN-based face verification systems in security-critical\napplications.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 13:51:33 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Guo", "Wei", ""], ["Tondi", "Benedetta", ""], ["Barni", "Mauro", ""]]}, {"id": "2105.00266", "submitter": "Nicolas Boull\\'e", "authors": "Nicolas Boull\\'e, Christopher J. Earls, Alex Townsend", "title": "Data-driven discovery of physical laws with human-understandable deep\n  learning", "comments": "52 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an opportunity for deep learning to revolutionize science and\ntechnology by revealing its findings in a human interpretable manner. We\ndevelop a novel data-driven approach for creating a human-machine partnership\nto accelerate scientific discovery. By collecting physical system responses,\nunder carefully selected excitations, we train rational neural networks to\nlearn Green's functions of hidden partial differential equation. These\nsolutions reveal human-understandable properties and features, such as linear\nconservation laws, and symmetries, along with shock and singularity locations,\nboundary effects, and dominant modes. We illustrate this technique on several\nexamples and capture a range of physics, including advection-diffusion, viscous\nshocks, and Stokes flow in a lid-driven cavity.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 14:40:16 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Boull\u00e9", "Nicolas", ""], ["Earls", "Christopher J.", ""], ["Townsend", "Alex", ""]]}, {"id": "2105.00274", "submitter": "Patrick Koopmann", "authors": "Patrick Koopmann", "title": "Signature-Based Abduction with Fresh Individuals and Complex Concepts\n  for Description Logics (Extended Version)", "comments": "Extended version of a paper accepted at IJCAI-2021, 20 pages, 3\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a knowledge base and an observation as a set of facts, ABox abduction\naims at computing a hypothesis that, when added to the knowledge base, is\nsufficient to entail the observation. In signature-based ABox abduction, the\nhypothesis is further required to use only names from a given set. This form of\nabduction has applications such as diagnosis, KB repair, or explaining missing\nentailments. It is possible that hypotheses for a given observation only exist\nif we admit the use of fresh individuals and/or complex concepts built from the\ngiven signature, something most approaches for ABox abduction so far do not\nsupport or only support with restrictions. In this paper, we investigate the\ncomputational complexity of this form of abduction -- allowing either fresh\nindividuals, complex concepts, or both -- for various description logics, and\ngive size bounds on the hypotheses if they exist.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 14:55:46 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Koopmann", "Patrick", ""]]}, {"id": "2105.00290", "submitter": "Yunhao Ge", "authors": "Yunhao Ge, Yao Xiao, Zhi Xu, Meng Zheng, Srikrishna Karanam, Terrence\n  Chen, Laurent Itti, Ziyan Wu", "title": "A Peek Into the Reasoning of Neural Networks: Interpreting with\n  Structural Visual Concepts", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite substantial progress in applying neural networks (NN) to a wide\nvariety of areas, they still largely suffer from a lack of transparency and\ninterpretability. While recent developments in explainable artificial\nintelligence attempt to bridge this gap (e.g., by visualizing the correlation\nbetween input pixels and final outputs), these approaches are limited to\nexplaining low-level relationships, and crucially, do not provide insights on\nerror correction. In this work, we propose a framework (VRX) to interpret\nclassification NNs with intuitive structural visual concepts. Given a trained\nclassification model, the proposed VRX extracts relevant class-specific visual\nconcepts and organizes them using structural concept graphs (SCG) based on\npairwise concept relationships. By means of knowledge distillation, we show VRX\ncan take a step towards mimicking the reasoning process of NNs and provide\nlogical, concept-level explanations for final model decisions. With extensive\nexperiments, we empirically show VRX can meaningfully answer \"why\" and \"why\nnot\" questions about the prediction, providing easy-to-understand insights\nabout the reasoning process. We also show that these insights can potentially\nprovide guidance on improving NN's performance.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 15:47:42 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ge", "Yunhao", ""], ["Xiao", "Yao", ""], ["Xu", "Zhi", ""], ["Zheng", "Meng", ""], ["Karanam", "Srikrishna", ""], ["Chen", "Terrence", ""], ["Itti", "Laurent", ""], ["Wu", "Ziyan", ""]]}, {"id": "2105.00324", "submitter": "Fangfang Xia", "authors": "Zixuan Zhao, Nathan Wycoff, Neil Getty, Rick Stevens, Fangfang Xia", "title": "Neko: a Library for Exploring Neuromorphic Learning Rules", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of neuromorphic computing is in a period of active exploration.\nWhile many tools have been developed to simulate neuronal dynamics or convert\ndeep networks to spiking models, general software libraries for learning rules\nremain underexplored. This is partly due to the diverse, challenging nature of\nefforts to design new learning rules, which range from encoding methods to\ngradient approximations, from population approaches that mimic the Bayesian\nbrain to constrained learning algorithms deployed on memristor crossbars. To\naddress this gap, we present Neko, a modular, extensible library with a focus\non aiding the design of new learning algorithms. We demonstrate the utility of\nNeko in three exemplar cases: online local learning, probabilistic learning,\nand analog on-device learning. Our results show that Neko can replicate the\nstate-of-the-art algorithms and, in one case, lead to significant\noutperformance in accuracy and speed. Further, it offers tools including\ngradient comparison that can help develop new algorithmic variants. Neko is an\nopen source Python library that supports PyTorch and TensorFlow backends.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 18:50:32 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Zhao", "Zixuan", ""], ["Wycoff", "Nathan", ""], ["Getty", "Neil", ""], ["Stevens", "Rick", ""], ["Xia", "Fangfang", ""]]}, {"id": "2105.00336", "submitter": "M Tanveer PhD", "authors": "M. Tanveer and T. Rajani and R. Rastogi and Y.H. Shao", "title": "Comprehensive Review On Twin Support Vector Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Twin support vector machine (TSVM) and twin support vector regression (TSVR)\nare newly emerging efficient machine learning techniques which offer promising\nsolutions for classification and regression challenges respectively. TSVM is\nbased upon the idea to identify two nonparallel hyperplanes which classify the\ndata points to their respective classes. It requires to solve two small sized\nquadratic programming problems (QPPs) in lieu of solving single large size QPP\nin support vector machine (SVM) while TSVR is formulated on the lines of TSVM\nand requires to solve two SVM kind problems. Although there has been good\nresearch progress on these techniques; there is limited literature on the\ncomparison of different variants of TSVR. Thus, this review presents a rigorous\nanalysis of recent research in TSVM and TSVR simultaneously mentioning their\nlimitations and advantages. To begin with we first introduce the basic theory\nof TSVM and then focus on the various improvements and applications of TSVM,\nand then we introduce TSVR and its various enhancements. Finally, we suggest\nfuture research and development prospects.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 19:48:45 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Tanveer", "M.", ""], ["Rajani", "T.", ""], ["Rastogi", "R.", ""], ["Shao", "Y. H.", ""]]}, {"id": "2105.00339", "submitter": "Saeed Khorram", "authors": "Saeed Khorram, Xiao Fu, Mohamad H. Danesh, Zhongang Qi, Li Fuxin", "title": "Stochastic Block-ADMM for Training Deep Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose Stochastic Block-ADMM as an approach to train deep\nneural networks in batch and online settings. Our method works by splitting\nneural networks into an arbitrary number of blocks and utilizes auxiliary\nvariables to connect these blocks while optimizing with stochastic gradient\ndescent. This allows training deep networks with non-differentiable constraints\nwhere conventional backpropagation is not applicable. An application of this is\nsupervised feature disentangling, where our proposed DeepFacto inserts a\nnon-negative matrix factorization (NMF) layer into the network. Since\nbackpropagation only needs to be performed within each block, our approach\nalleviates vanishing gradients and provides potentials for parallelization. We\nprove the convergence of our proposed method and justify its capabilities\nthrough experiments in supervised and weakly-supervised settings.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 19:56:13 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Khorram", "Saeed", ""], ["Fu", "Xiao", ""], ["Danesh", "Mohamad H.", ""], ["Qi", "Zhongang", ""], ["Fuxin", "Li", ""]]}, {"id": "2105.00354", "submitter": "Zhilin Lu", "authors": "Zhilin Lu, Xudong Zhang, Hongyi He, Jintao Wang and Jian Song", "title": "Binarized Aggregated Network with Quantization: Flexible Deep Learning\n  Deployment for CSI Feedback in Massive MIMO System", "comments": "28 pages, 15 figures, 5 tables, This work has been submitted to the\n  IEEE for possible publication. Copyright may be transferred without notice.\n  arXiv admin note: text overlap with arXiv:2101.06618", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive multiple-input multiple-output (MIMO) is one of the key techniques to\nachieve better spectrum and energy efficiency in 5G system. The channel state\ninformation (CSI) needs to be fed back from the user equipment to the base\nstation in frequency division duplexing (FDD) mode. However, the overhead of\nthe direct feedback is unacceptable due to the large antenna array in massive\nMIMO system. Recently, deep learning is widely adopted to the compressed CSI\nfeedback task and proved to be effective. In this paper, a novel network named\naggregated channel reconstruction network (ACRNet) is designed to boost the\nfeedback performance with network aggregation and parametric rectified linear\nunit (PReLU) activation. The practical deployment of the feedback network in\nthe communication system is also considered. Specifically, the elastic feedback\nscheme is proposed to flexibly adapt the network to meet different resource\nlimitations. Besides, the network binarization technique is combined with the\nfeature quantization for lightweight and practical deployment. Experiments show\nthat the proposed ACRNet outperforms loads of previous state-of-the-art\nnetworks, providing a neat feedback solution with high performance, low cost\nand impressive flexibility.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 22:50:25 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Lu", "Zhilin", ""], ["Zhang", "Xudong", ""], ["He", "Hongyi", ""], ["Wang", "Jintao", ""], ["Song", "Jian", ""]]}, {"id": "2105.00373", "submitter": "Sharad Chitlangia", "authors": "Sharad Chitlangia, Zuxin Liu, Akhil Agnihotri, Ding Zhao", "title": "Improving Perception via Sensor Placement: Designing Multi-LiDAR Systems\n  for Autonomous Vehicles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have witnessed an increasing interest in improving the\nperception performance of LiDARs on autonomous vehicles. While most of the\nexisting works focus on developing novel model architectures to process point\ncloud data, we study the problem from an optimal sensing perspective. To this\nend, together with a fast evaluation function based on ray tracing within the\nperception region of a LiDAR configuration, we propose an easy-to-compute\ninformation-theoretic surrogate cost metric based on Probabilistic Occupancy\nGrids (POG) to optimize LiDAR placement for maximal sensing. We show a\ncorrelation between our surrogate function and common object detection\nperformance metrics. We demonstrate the efficacy of our approach by verifying\nour results in a robust and reproducible data collection and extraction\nframework based on the CARLA simulator. Our results confirm that sensor\nplacement is an important factor in 3D point cloud-based object detection and\ncould lead to a variation of performance by 10% ~ 20% on the state-of-the-art\nperception algorithms. We believe that this is one of the first studies to use\nLiDAR placement to improve the performance of perception.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 01:52:18 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Chitlangia", "Sharad", ""], ["Liu", "Zuxin", ""], ["Agnihotri", "Akhil", ""], ["Zhao", "Ding", ""]]}, {"id": "2105.00375", "submitter": "Harish Panneer Selvam", "authors": "Harish Panneer Selvam, Yan Li, Pengyue Wang, William F. Northrop,\n  Shashi Shekhar", "title": "Vehicle Emissions Prediction with Physics-Aware AI Models: Preliminary\n  Results", "comments": "Accepted by Association for Advancement of Artificial Intelligence\n  (AAAI) Fall Symposium Series 2020: Physics-Guided AI to Accelerate Scientific\n  Discovery (https://sites.google.com/vt.edu/pgai-aaai-20)", "journal-ref": "PGAI-AAAI-20(2020)", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Given an on-board diagnostics (OBD) dataset and a physics-based emissions\nprediction model, this paper aims to develop an accurate and\ncomputational-efficient AI (Artificial Intelligence) method that predicts\nvehicle emissions. The problem is of societal importance because vehicular\nemissions lead to climate change and impact human health. This problem is\nchallenging because the OBD data does not contain enough parameters needed by\nhigh-order physics models. Conversely, related work has shown that low-order\nphysics models have poor predictive accuracy when using available OBD data.\nThis paper uses a divergent window co-occurrence pattern detection method to\ndevelop a spatiotemporal variability-aware AI model for predicting emission\nvalues from the OBD datasets. We conducted a case study using real-world OBD\ndata from a local public transportation agency. Results show that the proposed\nAI method has approximately 65% improved predictive accuracy than a non-AI\nlow-order physics model and is approximately 35% more accurate than a baseline\nmodel.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 01:52:59 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Selvam", "Harish Panneer", ""], ["Li", "Yan", ""], ["Wang", "Pengyue", ""], ["Northrop", "William F.", ""], ["Shekhar", "Shashi", ""]]}, {"id": "2105.00377", "submitter": "Shuai Peng", "authors": "Shuai Peng, Ke Yuan, Liangcai Gao, Zhi Tang", "title": "MathBERT: A Pre-Trained Model for Mathematical Formula Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale pre-trained models like BERT, have obtained a great success in\nvarious Natural Language Processing (NLP) tasks, while it is still a challenge\nto adapt them to the math-related tasks. Current pre-trained models neglect the\nstructural features and the semantic correspondence between formula and its\ncontext. To address these issues, we propose a novel pre-trained model, namely\n\\textbf{MathBERT}, which is jointly trained with mathematical formulas and\ntheir corresponding contexts. In addition, in order to further capture the\nsemantic-level structural features of formulas, a new pre-training task is\ndesigned to predict the masked formula substructures extracted from the\nOperator Tree (OPT), which is the semantic structural representation of\nformulas. We conduct various experiments on three downstream tasks to evaluate\nthe performance of MathBERT, including mathematical information retrieval,\nformula topic classification and formula headline generation. Experimental\nresults demonstrate that MathBERT significantly outperforms existing methods on\nall those three tasks. Moreover, we qualitatively show that this pre-trained\nmodel effectively captures the semantic-level structural information of\nformulas. To the best of our knowledge, MathBERT is the first pre-trained model\nfor mathematical formula understanding.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 02:10:31 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Peng", "Shuai", ""], ["Yuan", "Ke", ""], ["Gao", "Liangcai", ""], ["Tang", "Zhi", ""]]}, {"id": "2105.00381", "submitter": "Yunxiang Li", "authors": "Yunxiang Li, Guodong Zeng, Yifan Zhang, Jun Wang, Qianni Zhang, Qun\n  Jin, Lingling Sun, Qisi Lian, Neng Xia, Ruizi Peng, Kai Tang, Yaqi Wang,\n  Shuai Wang", "title": "Anatomy-Guided Parallel Bottleneck Transformer Network for Automated\n  Evaluation of Root Canal Therapy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Objective: Accurate evaluation of the root canal filling result in X-ray\nimage is a significant step for the root canal therapy, which is based on the\nrelative position between the apical area boundary of tooth root and the top of\nfilled gutta-percha in root canal as well as the shape of the tooth root and so\non to classify the result as correct-filling, under-filling or over-filling.\nMethods: We propose a novel anatomy-guided Transformer diagnosis network. For\nobtaining accurate anatomy-guided features, a polynomial curve fitting\nsegmentation is proposed to segment the fuzzy boundary. And a Parallel\nBottleneck Transformer network (PBT-Net) is introduced as the classification\nnetwork for the final evaluation. Results, and conclusion: Our numerical\nexperiments show that our anatomy-guided PBT-Net improves the accuracy from\n40\\% to 85\\% relative to the baseline classification network. Comparing with\nthe SOTA segmentation network indicates that the ASD is significantly reduced\nby 30.3\\% through our fitting segmentation. Significance: Polynomial curve\nfitting segmentation has a great segmentation effect for extremely fuzzy\nboundaries. The prior knowledge guided classification network is suitable for\nthe evaluation of root canal therapy greatly. And the new proposed Parallel\nBottleneck Transformer for realizing self-attention is general in design,\nfacilitating a broad use in most backbone networks.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 02:38:31 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Li", "Yunxiang", ""], ["Zeng", "Guodong", ""], ["Zhang", "Yifan", ""], ["Wang", "Jun", ""], ["Zhang", "Qianni", ""], ["Jin", "Qun", ""], ["Sun", "Lingling", ""], ["Lian", "Qisi", ""], ["Xia", "Neng", ""], ["Peng", "Ruizi", ""], ["Tang", "Kai", ""], ["Wang", "Yaqi", ""], ["Wang", "Shuai", ""]]}, {"id": "2105.00385", "submitter": "Zachary Pardos", "authors": "Anirudhan Badrinath, Frederic Wang, Zachary Pardos", "title": "pyBKT: An Accessible Python Library of Bayesian Knowledge Tracing Models", "comments": "Accepted to the 2021 Conference on Educational Data Mining (EDM '21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian Knowledge Tracing, a model used for cognitive mastery estimation,\nhas been a hallmark of adaptive learning research and an integral component of\ndeployed intelligent tutoring systems (ITS). In this paper, we provide a brief\nhistory of knowledge tracing model research and introduce pyBKT, an accessible\nand computationally efficient library of model extensions from the literature.\nThe library provides data generation, fitting, prediction, and cross-validation\nroutines, as well as a simple to use data helper interface to ingest typical\ntutor log dataset formats. We evaluate the runtime with various dataset sizes\nand compare to past implementations. Additionally, we conduct sanity checks of\nthe model using experiments with simulated data to evaluate the accuracy of its\nEM parameter learning and use real-world data to validate its predictions,\ncomparing pyBKT's supported model variants with results from the papers in\nwhich they were originally introduced. The library is open source and open\nlicense for the purpose of making knowledge tracing more accessible to\ncommunities of research and practice and to facilitate progress in the field\nthrough easier replication of past approaches.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 03:08:53 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 04:20:30 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Badrinath", "Anirudhan", ""], ["Wang", "Frederic", ""], ["Pardos", "Zachary", ""]]}, {"id": "2105.00388", "submitter": "Wen Zhang", "authors": "Wen Zhang, Chi-Man Wong, Ganqiang Ye, Bo Wen, Wei Zhang, Huajun Chen", "title": "Billion-scale Pre-trained E-commerce Product Knowledge Graph Model", "comments": "Paper accepted by ICDE2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, knowledge graphs have been widely applied to organize data\nin a uniform way and enhance many tasks that require knowledge, for example,\nonline shopping which has greatly facilitated people's life. As a backbone for\nonline shopping platforms, we built a billion-scale e-commerce product\nknowledge graph for various item knowledge services such as item\nrecommendation. However, such knowledge services usually include tedious data\nselection and model design for knowledge infusion, which might bring\ninappropriate results. Thus, to avoid this problem, we propose a Pre-trained\nKnowledge Graph Model (PKGM) for our billion-scale e-commerce product knowledge\ngraph, providing item knowledge services in a uniform way for embedding-based\nmodels without accessing triple data in the knowledge graph. Notably, PKGM\ncould also complete knowledge graphs during servicing, thereby overcoming the\ncommon incompleteness issue in knowledge graphs. We test PKGM in three\nknowledge-related tasks including item classification, same item\nidentification, and recommendation. Experimental results show PKGM successfully\nimproves the performance of each task.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 04:28:22 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Zhang", "Wen", ""], ["Wong", "Chi-Man", ""], ["Ye", "Ganqiang", ""], ["Wen", "Bo", ""], ["Zhang", "Wei", ""], ["Chen", "Huajun", ""]]}, {"id": "2105.00395", "submitter": "Yusuke Koda", "authors": "Yusuke Koda and Jihong Park and Mehdi Bennis and Praneeth Vepakomma\n  and Ramesh Raskar", "title": "AirMixML: Over-the-Air Data Mixup for Inherently Privacy-Preserving Edge\n  Machine Learning", "comments": "6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless channels can be inherently privacy-preserving by distorting the\nreceived signals due to channel noise, and superpositioning multiple signals\nover-the-air. By harnessing these natural distortions and superpositions by\nwireless channels, we propose a novel privacy-preserving machine learning (ML)\nframework at the network edge, coined over-the-air mixup ML (AirMixML). In\nAirMixML, multiple workers transmit analog-modulated signals of their private\ndata samples to an edge server who trains an ML model using the received\nnoisy-and superpositioned samples. AirMixML coincides with model training using\nmixup data augmentation achieving comparable accuracy to that with raw data\nsamples. From a privacy perspective, AirMixML is a differentially private (DP)\nmechanism limiting the disclosure of each worker's private sample information\nat the server, while the worker's transmit power determines the privacy\ndisclosure level. To this end, we develop a fractional channel-inversion power\ncontrol (PC) method, {\\alpha}-Dirichlet mixup PC (DirMix({\\alpha})-PC), wherein\nfor a given global power scaling factor after channel inversion, each worker's\nlocal power contribution to the superpositioned signal is controlled by the\nDirichlet dispersion ratio {\\alpha}. Mathematically, we derive a closed-form\nexpression clarifying the relationship between the local and global PC factors\nto guarantee a target DP level. By simulations, we provide DirMix({\\alpha})-PC\ndesign guidelines to improve accuracy, privacy, and energy-efficiency. Finally,\nAirMixML with DirMix({\\alpha})-PC is shown to achieve reasonable accuracy\ncompared to a privacy-violating baseline with neither superposition nor PC.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 05:45:43 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Koda", "Yusuke", ""], ["Park", "Jihong", ""], ["Bennis", "Mehdi", ""], ["Vepakomma", "Praneeth", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2105.00398", "submitter": "Fan Zhu", "authors": "Xin Xu, Yu Dong, Fan Zhu", "title": "A LiDAR Assisted Control Module with High Precision in Parking Scenarios\n  for Autonomous Driving Vehicle", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Autonomous driving has been quite promising in recent years. The public has\nseen Robotaxi delivered by Waymo, Baidu, Cruise, and so on. While autonomous\ndriving vehicles certainly have a bright future, we have to admit that it is\nstill a long way to go for products such as Robotaxi. On the other hand, in\nless complex scenarios autonomous driving may have the potentiality to reliably\noutperform humans. For example, humans are good at interactive tasks (while\nautonomous driving systems usually do not), but we are often incompetent for\ntasks with strict precision demands. In this paper, we introduce a real-world,\nindustrial scenario of which human drivers are not capable. The task required\nthe ego vehicle to keep a stationary lateral distance (i.e. 3? <= 5\ncentimeters) with respect to a reference. To address this challenge, we\nredesigned the control module from Baidu Apollo open-source autonomous driving\nsystem. A precise (3? <= 2 centimeters) Error Feedback System was first built\nto partly replace the localization module. Then we investigated the control\nmodule thoroughly and added a real-time calibration algorithm to gain extra\nprecision. We also built a simulation to fine-tune the control parameters.\nAfter all those works, the results are encouraging, showing that an end-to-end\nlateral precision with 3? <= 5 centimeters has been achieved. Further, we show\nthat the results not only outperformed original Apollo modules but also beat\nspecially trained and highly experienced human test drivers.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 06:13:32 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Xu", "Xin", ""], ["Dong", "Yu", ""], ["Zhu", "Fan", ""]]}, {"id": "2105.00403", "submitter": "Koji Inoue", "authors": "Tatsuya Kawahara, Koji Inoue, Divesh Lala", "title": "Intelligent Conversational Android ERICA Applied to Attentive Listening\n  and Job Interview", "comments": "7 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Following the success of spoken dialogue systems (SDS) in smartphone\nassistants and smart speakers, a number of communicative robots are developed\nand commercialized. Compared with the conventional SDSs designed as a\nhuman-machine interface, interaction with robots is expected to be in a closer\nmanner to talking to a human because of the anthropomorphism and physical\npresence. The goal or task of dialogue may not be information retrieval, but\nthe conversation itself. In order to realize human-level \"long and deep\"\nconversation, we have developed an intelligent conversational android ERICA. We\nset up several social interaction tasks for ERICA, including attentive\nlistening, job interview, and speed dating. To allow for spontaneous,\nincremental multiple utterances, a robust turn-taking model is implemented\nbased on TRP (transition-relevance place) prediction, and a variety of\nbackchannels are generated based on time frame-wise prediction instead of\nIPU-based prediction. We have realized an open-domain attentive listening\nsystem with partial repeats and elaborating questions on focus words as well as\nassessment responses. It has been evaluated with 40 senior people, engaged in\nconversation of 5-7 minutes without a conversation breakdown. It was also\ncompared against the WOZ setting. We have also realized a job interview system\nwith a set of base questions followed by dynamic generation of elaborating\nquestions. It has also been evaluated with student subjects, showing promising\nresults.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 06:37:23 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Kawahara", "Tatsuya", ""], ["Inoue", "Koji", ""], ["Lala", "Divesh", ""]]}, {"id": "2105.00412", "submitter": "Chenxi Sun", "authors": "Chenxi Sun and Shenda Hong and Moxian Song and Yanxiu Zhou and Yongyue\n  Sun and Derun Cai and Hongyan Li", "title": "TE-ESN: Time Encoding Echo State Network for Prediction Based on\n  Irregularly Sampled Time Series Data", "comments": "7 pages, 4 figures, accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prediction based on Irregularly Sampled Time Series (ISTS) is of wide concern\nin the real-world applications. For more accurate prediction, the methods had\nbetter grasp more data characteristics. Different from ordinary time series,\nISTS is characterised with irregular time intervals of intra-series and\ndifferent sampling rates of inter-series. However, existing methods have\nsuboptimal predictions due to artificially introducing new dependencies in a\ntime series and biasedly learning relations among time series when modeling\nthese two characteristics. In this work, we propose a novel Time Encoding (TE)\nmechanism. TE can embed the time information as time vectors in the complex\ndomain. It has the the properties of absolute distance and relative distance\nunder different sampling rates, which helps to represent both two\nirregularities of ISTS. Meanwhile, we create a new model structure named Time\nEncoding Echo State Network (TE-ESN). It is the first ESNs-based model that can\nprocess ISTS data. Besides, TE-ESN can incorporate long short-term memories and\nseries fusion to grasp horizontal and vertical relations. Experiments on one\nchaos system and three real-world datasets show that TE-ESN performs better\nthan all baselines and has better reservoir property.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 08:00:46 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Sun", "Chenxi", ""], ["Hong", "Shenda", ""], ["Song", "Moxian", ""], ["Zhou", "Yanxiu", ""], ["Sun", "Yongyue", ""], ["Cai", "Derun", ""], ["Li", "Hongyan", ""]]}, {"id": "2105.00421", "submitter": "Yeyun Zou", "authors": "Yeyun Zou, Qiyu Xie", "title": "A survey on VQA_Datasets and Approaches", "comments": "10 pages", "journal-ref": null, "doi": "10.1109/ITCA52113.2020.00069", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual question answering (VQA) is a task that combines both the techniques\nof computer vision and natural language processing. It requires models to\nanswer a text-based question according to the information contained in a\nvisual. In recent years, the research field of VQA has been expanded. Research\nthat focuses on the VQA, examining the reasoning ability and VQA on scientific\ndiagrams, has also been explored more. Meanwhile, more multimodal feature\nfusion mechanisms have been proposed. This paper will review and analyze\nexisting datasets, metrics, and models proposed for the VQA task.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 08:50:30 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Zou", "Yeyun", ""], ["Xie", "Qiyu", ""]]}, {"id": "2105.00451", "submitter": "Luca Capezzuto", "authors": "Luca Capezzuto, Danesh Tarapore, Sarvapali D. Ramchurn", "title": "Multi-Agent Routing and Scheduling Through Coalition Formation", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In task allocation for real-time domains, such as disaster response, a\nlimited number of agents is deployed across a large area to carry out numerous\ntasks, each with its prerequisites, profit, time window and workload. To\nmaximize profits while minimizing time penalties, agents need to cooperate by\nforming, disbanding and reforming coalitions. In this paper, we name this\nproblem Multi-Agent Routing and Scheduling through Coalition formation (MARSC)\nand show that it generalizes the important Team Orienteering Problem with Time\nWindows. We propose a binary integer program and an anytime and scalable\nheuristic to solve it. Using public London Fire Brigade records, we create a\ndataset with 347588 tasks and a test framework that simulates the mobilization\nof firefighters. In problems with up to 150 agents and 3000 tasks, our\nheuristic finds solutions up to 3.25 times better than the Earliest Deadline\nFirst approach commonly used in real-time systems. Our results constitute the\nfirst large-scale benchmark for the MARSC problem.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 11:53:44 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Capezzuto", "Luca", ""], ["Tarapore", "Danesh", ""], ["Ramchurn", "Sarvapali D.", ""]]}, {"id": "2105.00467", "submitter": "Abdul Quamar", "authors": "Venkata Vamsikrishna Meduri, Abdul Quamar, Chuan Lei, Vasilis\n  Efthymiou, Fatma Ozcan", "title": "BI-REC: Guided Data Analysis for Conversational Business Intelligence", "comments": "16 pages, 16 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational interfaces to Business Intelligence (BI) applications enable\ndata analysis using a natural language dialog in small incremental steps. To\ntruly unleash the power of conversational BI to democratize access to data, a\nsystem needs to provide effective and continuous support for data analysis. In\nthis paper, we propose BI-REC, a conversational recommendation system for BI\napplications to help users accomplish their data analysis tasks.\n  We define the space of data analysis in terms of BI patterns, augmented with\nrich semantic information extracted from the OLAP cube definition, and use\ngraph embeddings learned using GraphSAGE to create a compact representation of\nthe analysis state. We propose a two-step approach to explore the search space\nfor useful BI pattern recommendations. In the first step, we train a\nmulti-class classifier using prior query logs to predict the next high-level\nactions in terms of a BI operation (e.g., {\\em Drill-Down} or {\\em Roll-up})\nand a measure that the user is interested in. In the second step, the\nhigh-level actions are further refined into actual BI pattern recommendations\nusing collaborative filtering. This two-step approach allows us to not only\ndivide and conquer the huge search space, but also requires less training data.\nOur experimental evaluation shows that BI-REC achieves an accuracy of 83% for\nBI pattern recommendations and up to 2X speedup in latency of prediction\ncompared to a state-of-the-art baseline. Our user study further shows that\nBI-REC provides recommendations with a precision@3 of 91.90% across several\ndifferent analysis tasks.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 13:19:38 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Meduri", "Venkata Vamsikrishna", ""], ["Quamar", "Abdul", ""], ["Lei", "Chuan", ""], ["Efthymiou", "Vasilis", ""], ["Ozcan", "Fatma", ""]]}, {"id": "2105.00470", "submitter": "Wenxiao Wang", "authors": "Tianyu Hua, Wenxiao Wang, Zihui Xue, Yue Wang, Sucheng Ren, Hang Zhao", "title": "On Feature Decorrelation in Self-Supervised Learning", "comments": "The first two authors contribute equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In self-supervised representation learning, a common idea behind most of the\nstate-of-the-art approaches is to enforce the robustness of the representations\nto predefined augmentations. A potential issue of this idea is the existence of\ncompletely collapsed solutions (i.e., constant features), which are typically\navoided implicitly by carefully chosen implementation details. In this work, we\nstudy a relatively concise framework containing the most common components from\nrecent approaches. We verify the existence of complete collapse and discover\nanother reachable collapse pattern that is usually overlooked, namely\ndimensional collapse. We connect dimensional collapse with strong correlations\nbetween axes and consider such connection as a strong motivation for feature\ndecorrelation (i.e., standardizing the covariance matrix). The capability of\ncorrelation as an unsupervised metric and the gains from feature decorrelation\nare verified empirically to highlight the importance and the potential of this\ninsight.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 13:28:18 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Hua", "Tianyu", ""], ["Wang", "Wenxiao", ""], ["Xue", "Zihui", ""], ["Wang", "Yue", ""], ["Ren", "Sucheng", ""], ["Zhao", "Hang", ""]]}, {"id": "2105.00499", "submitter": "Mahdi Rezaei", "authors": "Saeed Tafazzol, Erfan Fathi, Mahdi Rezaei, Ehsan Asali", "title": "Curious Exploration and Return-based Memory Restoration for Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reward engineering and designing an incentive reward function are non-trivial\ntasks to train agents in complex environments. Furthermore, an inaccurate\nreward function may lead to a biased behaviour which is far from an efficient\nand optimised behaviour. In this paper, we focus on training a single agent to\nscore goals with binary success/failure reward function in Half Field Offense\ndomain. As the major advantage of this research, the agent has no presumption\nabout the environment which means it only follows the original formulation of\nreinforcement learning agents. The main challenge of using such a reward\nfunction is the high sparsity of positive reward signals. To address this\nproblem, we use a simple prediction-based exploration strategy (called Curious\nExploration) along with a Return-based Memory Restoration (RMR) technique which\ntends to remember more valuable memories. The proposed method can be utilized\nto train agents in environments with fairly complex state and action spaces.\nOur experimental results show that many recent solutions including our baseline\nmethod fail to learn and perform in complex soccer domain. However, the\nproposed method can converge easily to the nearly optimal behaviour. The video\npresenting the performance of our trained agent is available at\nhttp://bit.ly/HFO_Binary_Reward.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 16:01:34 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Tafazzol", "Saeed", ""], ["Fathi", "Erfan", ""], ["Rezaei", "Mahdi", ""], ["Asali", "Ehsan", ""]]}, {"id": "2105.00505", "submitter": "Sixie Yu", "authors": "Sixie Yu, David Kempe, Yevgeniy Vorobeychik", "title": "Altruism Design in Networked Public Goods Games", "comments": "To appear in IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many collective decision-making settings feature a strategic tension between\nagents acting out of individual self-interest and promoting a common good.\nThese include wearing face masks during a pandemic, voting, and vaccination.\nNetworked public goods games capture this tension, with networks encoding\nstrategic interdependence among agents. Conventional models of public goods\ngames posit solely individual self-interest as a motivation, even though\naltruistic motivations have long been known to play a significant role in\nagents' decisions. We introduce a novel extension of public goods games to\naccount for altruistic motivations by adding a term in the utility function\nthat incorporates the perceived benefits an agent obtains from the welfare of\nothers, mediated by an altruism graph. Most importantly, we view altruism not\nas immutable, but rather as a lever for promoting the common good. Our central\nalgorithmic question then revolves around the computational complexity of\nmodifying the altruism network to achieve desired public goods game investment\nprofiles. We first show that the problem can be solved using linear programming\nwhen a principal can fractionally modify the altruism network. While the\nproblem becomes in general intractable if the principal's actions are\nall-or-nothing, we exhibit several tractable special cases.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 16:35:47 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Yu", "Sixie", ""], ["Kempe", "David", ""], ["Vorobeychik", "Yevgeniy", ""]]}, {"id": "2105.00522", "submitter": "Zhiwei Liu", "authors": "Zhiwei Liu, Ziwei Fan, Yu Wang, Philip S. Yu", "title": "Augmenting Sequential Recommendation with Pseudo-Prior Items via\n  Reversely Pre-training Transformer", "comments": "Accepted by SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3463036", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sequential Recommendation characterizes the evolving patterns by modeling\nitem sequences chronologically. The essential target of it is to capture the\nitem transition correlations. The recent developments of transformer inspire\nthe community to design effective sequence encoders, \\textit{e.g.,} SASRec and\nBERT4Rec. However, we observe that these transformer-based models suffer from\nthe cold-start issue, \\textit{i.e.,} performing poorly for short sequences.\nTherefore, we propose to augment short sequences while still preserving\noriginal sequential correlations. We introduce a new framework for\n\\textbf{A}ugmenting \\textbf{S}equential \\textbf{Re}commendation with\n\\textbf{P}seudo-prior items~(ASReP). We firstly pre-train a transformer with\nsequences in a reverse direction to predict prior items. Then, we use this\ntransformer to generate fabricated historical items at the beginning of short\nsequences. Finally, we fine-tune the transformer using these augmented\nsequences from the time order to predict the next item. Experiments on two\nreal-world datasets verify the effectiveness of ASReP. The code is available on\n\\url{https://github.com/DyGRec/ASReP}.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 18:06:23 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Liu", "Zhiwei", ""], ["Fan", "Ziwei", ""], ["Wang", "Yu", ""], ["Yu", "Philip S.", ""]]}, {"id": "2105.00525", "submitter": "Anagha Kulkarni", "authors": "Anagha Kulkarni, Siddharth Srivastava and Subbarao Kambhampati", "title": "Planning for Proactive Assistance in Environments with Partial\n  Observability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper addresses the problem of synthesizing the behavior of an AI agent\nthat provides proactive task assistance to a human in settings like factory\nfloors where they may coexist in a common environment. Unlike in the case of\nrequested assistance, the human may not be expecting proactive assistance and\nhence it is crucial for the agent to ensure that the human is aware of how the\nassistance affects her task. This becomes harder when there is a possibility\nthat the human may neither have full knowledge of the AI agent's capabilities\nnor have full observability of its activities. Therefore, our \\textit{proactive\nassistant} is guided by the following three principles: \\textbf{(1)} its\nactivity decreases the human's cost towards her goal; \\textbf{(2)} the human is\nable to recognize the potential reduction in her cost; \\textbf{(3)} its\nactivity optimizes the human's overall cost (time/resources) of achieving her\ngoal. Through empirical evaluation and user studies, we demonstrate the\nusefulness of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 18:12:06 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Kulkarni", "Anagha", ""], ["Srivastava", "Siddharth", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2105.00544", "submitter": "Fuad Yimer Mr.", "authors": "Fuad Yimer Yesuf and M. Prathap", "title": "CARL-DTN: Context Adaptive Reinforcement Learning based Routing\n  Algorithm in Delay Tolerant Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The term Delay/Disruption-Tolerant Networks (DTN) invented to describe and\ncover all types of long-delay, disconnected, intermittently connected networks,\nwhere mobility and outages or scheduled contacts may be experienced. This\nenvironment is characterized by frequent network partitioning, intermittent\nconnectivity, large or variable delay, asymmetric data rate, and low\ntransmission reliability. There have been routing protocols developed in DTN.\nHowever, those routing algorithms are design based upon specific assumptions.\nThe assumption makes existing algorithms suitable for specific environment\nscenarios. Different routing algorithm uses different relay node selection\ncriteria to select the replication node. Too Frequently forwarding messages can\nresult in excessive packet loss and large buffer and network overhead. On the\nother hand, less frequent transmission leads to a lower delivery ratio. In DTN\nthere is a trade-off off between delivery ratio and overhead. In this study, we\nproposed context-adaptive reinforcement learning based routing(CARL-DTN)\nprotocol to determine optimal replicas of the message based on the real-time\ndensity. Our routing protocol jointly uses a real-time physical context,\nsocial-tie strength, and real-time message context using fuzzy logic in the\nrouting decision. Multi-hop forwarding probability is also considered for the\nrelay node selection by employing Q-Learning algorithm to estimate the\nencounter probability between nodes and to learn about nodes available in the\nneighbor by discounting reward. The performance of the proposed protocol is\nevaluated based on various simulation scenarios. The result shows that the\nproposed protocol has better performance in terms of message delivery ratio and\noverhead.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 20:08:17 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Yesuf", "Fuad Yimer", ""], ["Prathap", "M.", ""]]}, {"id": "2105.00557", "submitter": "Hao Sun", "authors": "Chengping Rao, Hao Sun, Yang Liu", "title": "Hard Encoding of Physics for Learning Spatiotemporal Dynamics", "comments": null, "journal-ref": "ICLR 2021 SimDL Workshop", "doi": null, "report-no": null, "categories": "cs.LG cs.AI physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling nonlinear spatiotemporal dynamical systems has primarily relied on\npartial differential equations (PDEs). However, the explicit formulation of\nPDEs for many underexplored processes, such as climate systems, biochemical\nreaction and epidemiology, remains uncertain or partially unknown, where very\nlimited measurement data is yet available. To tackle this challenge, we propose\na novel deep learning architecture that forcibly encodes known physics\nknowledge to facilitate learning in a data-driven manner. The coercive encoding\nmechanism of physics, which is fundamentally different from the penalty-based\nphysics-informed learning, ensures the network to rigorously obey given\nphysics. Instead of using nonlinear activation functions, we propose a novel\nelementwise product operation to achieve the nonlinearity of the model.\nNumerical experiment demonstrates that the resulting physics-encoded learning\nparadigm possesses remarkable robustness against data noise/scarcity and\ngeneralizability compared with some state-of-the-art models for data-driven\nmodeling.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 21:40:39 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Rao", "Chengping", ""], ["Sun", "Hao", ""], ["Liu", "Yang", ""]]}, {"id": "2105.00558", "submitter": "Loc Trinh", "authors": "Loc Trinh, Yan Liu", "title": "An Examination of Fairness of AI Models for Deepfake Detection", "comments": "To appear in the 30th International Joint Conference on Artificial\n  Intelligence (IJCAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have demonstrated that deep learning models can discriminate\nbased on protected classes like race and gender. In this work, we evaluate bias\npresent in deepfake datasets and detection models across protected subgroups.\nUsing facial datasets balanced by race and gender, we examine three popular\ndeepfake detectors and find large disparities in predictive performances across\nraces, with up to 10.7% difference in error rate between subgroups. A closer\nlook reveals that the widely used FaceForensics++ dataset is overwhelmingly\ncomposed of Caucasian subjects, with the majority being female Caucasians. Our\ninvestigation of the racial distribution of deepfakes reveals that the methods\nused to create deepfakes as positive training signals tend to produce\n\"irregular\" faces - when a person's face is swapped onto another person of a\ndifferent race or gender. This causes detectors to learn spurious correlations\nbetween the foreground faces and fakeness. Moreover, when detectors are trained\nwith the Blended Image (BI) dataset from Face X-Rays, we find that those\ndetectors develop systematic discrimination towards certain racial subgroups,\nprimarily female Asians.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 21:55:04 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Trinh", "Loc", ""], ["Liu", "Yan", ""]]}, {"id": "2105.00580", "submitter": "Siddharth Karamcheti", "authors": "Siddharth Karamcheti, Albert J. Zhai, Dylan P. Losey, Dorsa Sadigh", "title": "Learning Visually Guided Latent Actions for Assistive Teleoperation", "comments": "Accepted at Learning for Dynamics and Control (L4DC) 2021. 12 pages,\n  4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.HC cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is challenging for humans -- particularly those living with physical\ndisabilities -- to control high-dimensional, dexterous robots. Prior work\nexplores learning embedding functions that map a human's low-dimensional inputs\n(e.g., via a joystick) to complex, high-dimensional robot actions for assistive\nteleoperation; however, a central problem is that there are many more\nhigh-dimensional actions than available low-dimensional inputs. To extract the\ncorrect action and maximally assist their human controller, robots must reason\nover their context: for example, pressing a joystick down when interacting with\na coffee cup indicates a different action than when interacting with knife. In\nthis work, we develop assistive robots that condition their latent embeddings\non visual inputs. We explore a spectrum of visual encoders and show that\nincorporating object detectors pretrained on small amounts of cheap,\neasy-to-collect structured data enables i) accurately and robustly recognizing\nthe current context and ii) generalizing control embeddings to new objects and\ntasks. In user studies with a high-dimensional physical robot arm, participants\nleverage this approach to perform new tasks with unseen objects. Our results\nindicate that structured visual representations improve few-shot performance\nand are subjectively preferred by users.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 23:58:28 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Karamcheti", "Siddharth", ""], ["Zhai", "Albert J.", ""], ["Losey", "Dylan P.", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2105.00602", "submitter": "Shuo Wang", "authors": "Shuo Wang, Surya Nepal, Kristen Moore, Marthie Grobler, Carsten\n  Rudolph, Alsharif Abuadbba", "title": "OCTOPUS: Overcoming Performance andPrivatization Bottlenecks in\n  Distributed Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The diversity and quantity of the data warehousing, gathering data from\ndistributed devices such as mobile phones, can enhance machine learning\nalgorithms' success and robustness. Federated learning enables distributed\nparticipants to collaboratively learn a commonly-shared model while holding\ndata locally. However, it is also faced with expensive communication and\nlimitations due to the heterogeneity of distributed data sources and lack of\naccess to global data. In this paper, we investigate a practical distributed\nlearning scenario where multiple downstream tasks (e.g., classifiers) could be\nlearned from dynamically-updated and non-iid distributed data sources,\nefficiently and providing local privatization. We introduce a new distributed\nlearning scheme to address communication overhead via latent compression,\nleveraging global data while providing local privatization of local data\nwithout additional cost due to encryption or perturbation. This scheme divides\nthe learning into (1) informative feature encoding, extracting and transmitting\nthe latent space compressed representation features of local data at each node\nto address communication overhead; (2) downstream tasks centralized at the\nserver using the encoded codes gathered from each node to address computing and\nstorage overhead. Besides, a disentanglement strategy is applied to address the\nprivatization of sensitive components of local data. Extensive experiments are\nconducted on image and speech datasets. The results demonstrate that downstream\ntasks on the compact latent representations can achieve comparable accuracy to\ncentralized learning with the privatization of local data.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 02:24:53 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Wang", "Shuo", ""], ["Nepal", "Surya", ""], ["Moore", "Kristen", ""], ["Grobler", "Marthie", ""], ["Rudolph", "Carsten", ""], ["Abuadbba", "Alsharif", ""]]}, {"id": "2105.00607", "submitter": "Seewoo Lee", "authors": "Seewoo Lee, Youngduck Choi, Juneyoung Park, Byungsoo Kim and Jinwoo\n  Shin", "title": "Consistency and Monotonicity Regularization for Neural Knowledge Tracing", "comments": "11 pages including reference (1 page) and appendix (4 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge Tracing (KT), tracking a human's knowledge acquisition, is a\ncentral component in online learning and AI in Education. In this paper, we\npresent a simple, yet effective strategy to improve the generalization ability\nof KT models: we propose three types of novel data augmentation, coined\nreplacement, insertion, and deletion, along with corresponding regularization\nlosses that impose certain consistency or monotonicity biases on the model's\npredictions for the original and augmented sequence. Extensive experiments on\nvarious KT benchmarks show that our regularization scheme consistently improves\nthe model performances, under 3 widely-used neural networks and 4 public\nbenchmarks, e.g., it yields 6.3% improvement in AUC under the DKT model and the\nASSISTmentsChall dataset.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 02:36:29 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Lee", "Seewoo", ""], ["Choi", "Youngduck", ""], ["Park", "Juneyoung", ""], ["Kim", "Byungsoo", ""], ["Shin", "Jinwoo", ""]]}, {"id": "2105.00642", "submitter": "Benjamin Hilprecht", "authors": "Benjamin Hilprecht and Carsten Binnig", "title": "One Model to Rule them All: Towards Zero-Shot Learning for Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present our vision of so called zero-shot learning for\ndatabases which is a new learning approach for database components. Zero-shot\nlearning for databases is inspired by recent advances in transfer learning of\nmodels such as GPT-3 and can support a new database out-of-the box without the\nneed to train a new model. As a first concrete contribution in this paper, we\nshow the feasibility of zero-shot learning for the task of physical cost\nestimation and present very promising initial results. Moreover, as a second\ncontribution we discuss the core challenges related to zero-shot learning for\ndatabases and present a roadmap to extend zero-shot learning towards many other\ntasks beyond cost estimation or even beyond classical database systems and\nworkloads.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 06:18:47 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Hilprecht", "Benjamin", ""], ["Binnig", "Carsten", ""]]}, {"id": "2105.00644", "submitter": "Saurav Manchanda", "authors": "Saurav Manchanda and Da Zheng and George Karypis", "title": "Schema-Aware Deep Graph Convolutional Networks for Heterogeneous Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph convolutional network (GCN) based approaches have achieved significant\nprogress for solving complex, graph-structured problems. GCNs incorporate the\ngraph structure information and the node (or edge) features through message\npassing and computes 'deep' node representations. Despite significant progress\nin the field, designing GCN architectures for heterogeneous graphs still\nremains an open challenge. Due to the schema of a heterogeneous graph, useful\ninformation may reside multiple hops away. A key question is how to perform\nmessage passing to incorporate information of neighbors multiple hops away\nwhile avoiding the well-known over-smoothing problem in GCNs. To address this\nquestion, we propose our GCN framework 'Deep Heterogeneous Graph Convolutional\nNetwork (DHGCN)', which takes advantage of the schema of a heterogeneous graph\nand uses a hierarchical approach to effectively utilize information many hops\naway. It first computes representations of the target nodes based on their\n'schema-derived ego-network' (SEN). It then links the nodes of the same type\nwith various pre-defined metapaths and performs message passing along these\nlinks to compute final node representations. Our design choices naturally\ncapture the way a heterogeneous graph is generated from the schema. The\nexperimental results on real and synthetic datasets corroborate the design\nchoice and illustrate the performance gains relative to competing alternatives.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 06:24:27 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Manchanda", "Saurav", ""], ["Zheng", "Da", ""], ["Karypis", "George", ""]]}, {"id": "2105.00648", "submitter": "Yoo Yongmin", "authors": "Yongmin Yoo, Tak-Sung Heo, Yeongjoon Park, Kyungsun Kim", "title": "A novel hybrid methodology of measuring sentence similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of measuring sentence similarity is an essential issue in the\nnatural language processing (NLP) area. It is necessary to measure the\nsimilarity between sentences accurately. There are many approaches to measuring\nsentence similarity. Deep learning methodology shows a state-of-the-art\nperformance in many natural language processing fields and is used a lot in\nsentence similarity measurement methods. However, in the natural language\nprocessing field, considering the structure of the sentence or the word\nstructure that makes up the sentence is also important. In this study, we\npropose a methodology combined with both deep learning methodology and a method\nconsidering lexical relationships. Our evaluation metric is the Pearson\ncorrelation coefficient and Spearman correlation coefficient. As a result, the\nproposed method outperforms the current approaches on a KorSTS standard\nbenchmark Korean dataset. Moreover, it performs a maximum of 65% increase than\nonly using deep learning methodology. Experiments show that our proposed method\ngenerally results in better performance than those with only a deep learning\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 06:50:54 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 06:31:04 GMT"}, {"version": "v3", "created": "Mon, 14 Jun 2021 07:56:38 GMT"}, {"version": "v4", "created": "Tue, 15 Jun 2021 23:25:44 GMT"}, {"version": "v5", "created": "Mon, 21 Jun 2021 02:27:56 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Yoo", "Yongmin", ""], ["Heo", "Tak-Sung", ""], ["Park", "Yeongjoon", ""], ["Kim", "Kyungsun", ""]]}, {"id": "2105.00663", "submitter": "Dimitri Justeau Allaire", "authors": "Dimitri Justeau-Allaire, Philippe Birnbaum, Xavier Lorca", "title": "Bounds of MIN_NCC and MAX_NCC and filtering scheme for graph domain\n  variables", "comments": "short note, 3 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Graph domain variables and constraints are an extension of constraint\nprogramming introduced by Dooms et al. This approach had been further\ninvestigated by Fages in its PhD thesis. On the other hand, Beldiceanu et al.\npresented a generic filtering scheme for global constraints based on graph\nproperties. This scheme strongly relies on the computation of graph properties'\nbounds and can be used in the context of graph domain variables and constraints\nwith a few adjustments. Bounds of MIN_NCC and MAX_NCC had been defined for the\ngraph-based representation of global constraint for the path_with_loops graph\nclass. In this note, we generalize those bounds for graph domain variables and\nfor any graph class. We also provide a filtering scheme for any graph class and\narbitrary bounds.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 07:35:15 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Justeau-Allaire", "Dimitri", ""], ["Birnbaum", "Philippe", ""], ["Lorca", "Xavier", ""]]}, {"id": "2105.00667", "submitter": "Boris Ruf", "authors": "Boris Ruf, Marcin Detyniecki", "title": "Explaining how your AI system is fair", "comments": "Accepted at the ACM CHI 2021 Workshop on Operationalizing\n  Human-Centered Perspectives in Explainable AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To implement fair machine learning in a sustainable way, choosing the right\nfairness objective is key. Since fairness is a concept of justice which comes\nin various, sometimes conflicting definitions, this is not a trivial task\nthough. The most appropriate fairness definition for an artificial intelligence\n(AI) system is a matter of ethical standards and legal requirements, and the\nright choice depends on the particular use case and its context. In this\nposition paper, we propose to use a decision tree as means to explain and\njustify the implemented kind of fairness to the end users. Such a structure\nwould first of all support AI practitioners in mapping ethical principles to\nfairness definitions for a concrete application and therefore make the\nselection a straightforward and transparent process. However, this approach\nwould also help document the reasoning behind the decision making. Due to the\ngeneral complexity of the topic of fairness in AI, we argue that specifying\n\"fairness\" for a given use case is the best way forward to maintain confidence\nin AI systems. In this case, this could be achieved by sharing the reasons and\nprinciples expressed during the decision making process with the broader\naudience.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 07:52:56 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ruf", "Boris", ""], ["Detyniecki", "Marcin", ""]]}, {"id": "2105.00674", "submitter": "Heiko Paulheim", "authors": "Michael Matthias Voit and Heiko Paulheim", "title": "Bias in Knowledge Graphs -- an Empirical Study with Movie Recommendation\n  and Different Language Editions of DBpedia", "comments": "Accepted for publication at 3rd Conference on Language, Data and\n  Knowledge (LDK 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Public knowledge graphs such as DBpedia and Wikidata have been recognized as\ninteresting sources of background knowledge to build content-based recommender\nsystems. They can be used to add information about the items to be recommended\nand links between those. While quite a few approaches for exploiting knowledge\ngraphs have been proposed, most of them aim at optimizing the recommendation\nstrategy while using a fixed knowledge graph. In this paper, we take a\ndifferent approach, i.e., we fix the recommendation strategy and observe\nchanges when using different underlying knowledge graphs. Particularly, we use\ndifferent language editions of DBpedia. We show that the usage of different\nknowledge graphs does not only lead to differently biased recommender systems,\nbut also to recommender systems that differ in performance for particular\nfields of recommendations.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 08:07:30 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Voit", "Michael Matthias", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2105.00691", "submitter": "Dominik Dellermann", "authors": "Dominik Dellermann, Philipp Ebel, Matthias Soellner, Jan Marco\n  Leimeister", "title": "Hybrid Intelligence", "comments": null, "journal-ref": null, "doi": "10.1007/s12599-019-00595-2", "report-no": null, "categories": "cs.AI cs.HC cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Research has a long history of discussing what is superior in predicting\ncertain outcomes: statistical methods or the human brain. This debate has\nrepeatedly been sparked off by the remarkable technological advances in the\nfield of artificial intelligence (AI), such as solving tasks like object and\nspeech recognition, achieving significant improvements in accuracy through\ndeep-learning algorithms (Goodfellow et al. 2016), or combining various methods\nof computational intelligence, such as fuzzy logic, genetic algorithms, and\ncase-based reasoning (Medsker 2012). One of the implicit promises that underlie\nthese advancements is that machines will 1 day be capable of performing complex\ntasks or may even supersede humans in performing these tasks. This triggers new\nheated debates of when machines will ultimately replace humans (McAfee and\nBrynjolfsson 2017). While previous research has proved that AI performs well in\nsome clearly defined tasks such as playing chess, playing Go or identifying\nobjects on images, it is doubted that the development of an artificial general\nintelligence (AGI) which is able to solve multiple tasks at the same time can\nbe achieved in the near future (e.g., Russell and Norvig 2016). Moreover, the\nuse of AI to solve complex business problems in organizational contexts occurs\nscarcely, and applications for AI that solve complex problems remain mainly in\nlaboratory settings instead of being implemented in practice. Since the road to\nAGI is still a long one, we argue that the most likely paradigm for the\ndivision of labor between humans and machines in the next decades is Hybrid\nIntelligence. This concept aims at using the complementary strengths of human\nintelligence and AI, so that they can perform better than each of the two could\nseparately (e.g., Kamar 2016).\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 08:56:09 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Dellermann", "Dominik", ""], ["Ebel", "Philipp", ""], ["Soellner", "Matthias", ""], ["Leimeister", "Jan Marco", ""]]}, {"id": "2105.00694", "submitter": "Emir Zunic", "authors": "Emir Zunic, Kemal Korjenic, Sead Delalic, Zlatko Subara", "title": "Comparison Analysis of Facebook's Prophet, Amazon's DeepAR+ and CNN-QR\n  Algorithms for Successful Real-World Sales Forecasting", "comments": null, "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 13, No 2, April 2021", "doi": "10.5121/ijcsit.2021.13205", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  By successfully solving the problem of forecasting, the processes in the work\nof various companies are optimized and savings are achieved. In this process,\nthe analysis of time series data is of particular importance. Since the\ncreation of Facebook's Prophet, and Amazon's DeepAR+ and CNN-QR forecasting\nmodels, algorithms have attracted a great deal of attention. The paper presents\nthe application and comparison of the above algorithms for sales forecasting in\ndistribution companies. A detailed comparison of the performance of algorithms\nover real data with different lengths of sales history was made. The results\nshow that Prophet gives better results for items with a longer history and\nfrequent sales, while Amazon's algorithms show superiority for items without a\nlong history and items that are rarely sold.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 09:01:24 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Zunic", "Emir", ""], ["Korjenic", "Kemal", ""], ["Delalic", "Sead", ""], ["Subara", "Zlatko", ""]]}, {"id": "2105.00696", "submitter": "Feng Xia", "authors": "Feng Xia, Ke Sun, Shuo Yu, Abdul Aziz, Liangtian Wan, Shirui Pan, Huan\n  Liu", "title": "Graph Learning: A Survey", "comments": "19 pages, 6 figures", "journal-ref": "IEEE Transactions on Artificial Intelligence (2021)", "doi": "10.1109/TAI.2021.3076021", "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graphs are widely used as a popular representation of the network structure\nof connected data. Graph data can be found in a broad spectrum of application\ndomains such as social systems, ecosystems, biological networks, knowledge\ngraphs, and information systems. With the continuous penetration of artificial\nintelligence technologies, graph learning (i.e., machine learning on graphs) is\ngaining attention from both researchers and practitioners. Graph learning\nproves effective for many tasks, such as classification, link prediction, and\nmatching. Generally, graph learning methods extract relevant features of graphs\nby taking advantage of machine learning algorithms. In this survey, we present\na comprehensive overview on the state-of-the-art of graph learning. Special\nattention is paid to four categories of existing graph learning methods,\nincluding graph signal processing, matrix factorization, random walk, and deep\nlearning. Major models and algorithms under these categories are reviewed\nrespectively. We examine graph learning applications in areas such as text,\nimages, science, knowledge graphs, and combinatorial optimization. In addition,\nwe discuss several promising research directions in this field.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 09:06:01 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Xia", "Feng", ""], ["Sun", "Ke", ""], ["Yu", "Shuo", ""], ["Aziz", "Abdul", ""], ["Wan", "Liangtian", ""], ["Pan", "Shirui", ""], ["Liu", "Huan", ""]]}, {"id": "2105.00762", "submitter": "Kwanyoung Park", "authors": "Kwanyoung Park, Hyunseok Oh, Youngki Lee", "title": "VECA : A Toolkit for Building Virtual Environments to Train and Test\n  Human-like Agents", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Building human-like agent, which aims to learn and think like human\nintelligence, has long been an important research topic in AI. To train and\ntest human-like agents, we need an environment that imposes the agent to rich\nmultimodal perception and allows comprehensive interactions for the agent,\nwhile also easily extensible to develop custom tasks. However, existing\napproaches do not support comprehensive interaction with the environment or\nlack variety in modalities. Also, most of the approaches are difficult or even\nimpossible to implement custom tasks. In this paper, we propose a novel\nVR-based toolkit, VECA, which enables building fruitful virtual environments to\ntrain and test human-like agents. In particular, VECA provides a humanoid agent\nand an environment manager, enabling the agent to receive rich human-like\nperception and perform comprehensive interactions. To motivate VECA, we also\nprovide 24 interactive tasks, which represent (but are not limited to) four\nessential aspects in early human development: joint-level locomotion and\ncontrol, understanding contexts of objects, multimodal learning, and\nmulti-agent learning. To show the usefulness of VECA on training and testing\nhuman-like learning agents, we conduct experiments on VECA and show that users\ncan build challenging tasks for engaging human-like algorithms, and the\nfeatures supported by VECA are critical on training human-like agents.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 11:42:27 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Park", "Kwanyoung", ""], ["Oh", "Hyunseok", ""], ["Lee", "Youngki", ""]]}, {"id": "2105.00771", "submitter": "Ioannis Mandralis", "authors": "Ioannis Mandralis, Pascal Weber, Guido Novati, Petros Koumoutsakos", "title": "Learning swimming escape patterns for larval fish under energy\n  constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Swimming organisms can escape their predators by creating and harnessing\nunsteady flow fields through their body motions. Stochastic optimization and\nflow simulations have identified escape patterns that are consistent with those\nobserved in natural larval swimmers. However, these patterns have been limited\nby the specification of a particular cost function and depend on a prescribed\nfunctional form of the body motion. Here, we deploy reinforcement learning to\ndiscover swimmer escape patterns for larval fish under energy constraints. The\nidentified patterns include the C-start mechanism, in addition to more\nenergetically efficient escapes. We find that maximizing distance with limited\nenergy requires swimming via short bursts of accelerating motion interlinked\nwith phases of gliding. The present, data efficient, reinforcement learning\nalgorithm results in an array of patterns that reveal practical flow\noptimization principles for efficient swimming and the methodology can be\ntransferred to the control of aquatic robotic devices operating under energy\nconstraints.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 11:58:37 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 09:17:48 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Mandralis", "Ioannis", ""], ["Weber", "Pascal", ""], ["Novati", "Guido", ""], ["Koumoutsakos", "Petros", ""]]}, {"id": "2105.00774", "submitter": "Diego Antognini", "authors": "Diego Antognini and Boi Faltings", "title": "Fast Multi-Step Critiquing for VAE-based Recommender Systems", "comments": "Accepted at RecSys 2021. 19 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that providing personalized explanations alongside\nrecommendations increases trust and perceived quality. Furthermore, it gives\nusers an opportunity to refine the recommendations by critiquing parts of the\nexplanations. On one hand, current recommender systems model the\nrecommendation, explanation, and critiquing objectives jointly, but this\ncreates an inherent trade-off between their respective performance. On the\nother hand, although recent latent linear critiquing approaches are built upon\nan existing recommender system, they suffer from computational inefficiency at\ninference due to the objective optimized at each conversation's turn. We\naddress these deficiencies with M&Ms-VAE, a novel variational autoencoder for\nrecommendation and explanation that is based on multimodal modeling\nassumptions. We train the model under a weak supervision scheme to simulate\nboth fully and partially observed variables. Then, we leverage the\ngeneralization ability of a trained M&Ms-VAE model to embed the user preference\nand the critique separately. Our work's most important innovation is our\ncritiquing module, which is built upon and trained in a self-supervised manner\nwith a simple ranking objective. Experiments on four real-world datasets\ndemonstrate that among state-of-the-art models, our system is the first to\ndominate or match the performance in terms of recommendation, explanation, and\nmulti-step critiquing. Moreover, M&Ms-VAE processes the critiques up to 25.6x\nfaster than the best baselines. Finally, we show that our model infers coherent\njoint and cross generation, even under weak supervision, thanks to our\nmultimodal-based modeling and training scheme.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 12:26:09 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 18:22:16 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Antognini", "Diego", ""], ["Faltings", "Boi", ""]]}, {"id": "2105.00777", "submitter": "Hengyi Li", "authors": "Yoshiyuki Fujikawa, Hengyi Li, Xuebin Yue, Aravinda C V, Amar Prabhu\n  G, Lin Meng", "title": "Recognition of Oracle Bone Inscriptions by using Two Deep Learning\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Oracle bone inscriptions (OBIs) contain some of the oldest characters in the\nworld and were used in China about 3000 years ago. As an ancient form of\nliterature, OBIs store a lot of information that can help us understand the\nworld history, character evaluations, and more. However, as OBIs were found\nonly discovered about 120 years ago, few studies have described them, and the\naging process has made the inscriptions less legible. Hence, automatic\ncharacter detection and recognition has become an important issue. This paper\naims to design a online OBI recognition system for helping preservation and\norganization the cultural heritage. We evaluated two deep learning models for\nOBI recognition, and have designed an API that can be accessed online for OBI\nrecognition. In the first stage, you only look once (YOLO) is applied for\ndetecting and recognizing OBIs. However, not all of the OBIs can be detected\ncorrectly by YOLO, so we next utilize MobileNet to recognize the undetected\nOBIs by manually cropping the undetected OBI in the image. MobileNet is used\nfor this second stage of recognition as our evaluation of ten state-of-the-art\nmodels showed that it is the best network for OBI recognition due to its\nsuperior performance in terms of accuracy, loss and time consumption. We\ninstalled our system on an application programming interface (API) and opened\nit for OBI detection and recognition.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 12:31:57 GMT"}, {"version": "v2", "created": "Tue, 4 May 2021 05:23:14 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Fujikawa", "Yoshiyuki", ""], ["Li", "Hengyi", ""], ["Yue", "Xuebin", ""], ["C", "Aravinda", "V"], ["G", "Amar Prabhu", ""], ["Meng", "Lin", ""]]}, {"id": "2105.00783", "submitter": "Gabriel Mittag", "authors": "Gabriel Mittags, Sebastian M\\\"oller", "title": "Full-Reference Speech Quality Estimation with Attentional Siamese Neural\n  Networks", "comments": "Late upload, presented at ICASSP 2020", "journal-ref": null, "doi": "10.1109/ICASSP40776.2020.9053951", "report-no": null, "categories": "eess.AS cs.AI cs.LG cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a full-reference speech quality prediction model\nwith a deep learning approach. The model determines a feature representation of\nthe reference and the degraded signal through a siamese recurrent convolutional\nnetwork that shares the weights for both signals as input. The resulting\nfeatures are then used to align the signals with an attention mechanism and are\nfinally combined to estimate the overall speech quality. The proposed network\narchitecture represents a simple solution for the time-alignment problem that\noccurs for speech signals transmitted through Voice-Over-IP networks and shows\nhow the clean reference signal can be incorporated into speech quality models\nthat are based on end-to-end trained neural networks.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 12:38:25 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Mittags", "Gabriel", ""], ["M\u00f6ller", "Sebastian", ""]]}, {"id": "2105.00822", "submitter": "Xiaocong Chen", "authors": "Xiaocong Chen, Lina Yao, Xianzhi Wang, Aixin Sun, Wenjie Zhang and\n  Quan Z. Sheng", "title": "Generative Adversarial Reward Learning for Generalized Behavior Tendency\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in reinforcement learning have inspired increasing interest\nin learning user modeling adaptively through dynamic interactions, e.g., in\nreinforcement learning based recommender systems. Reward function is crucial\nfor most of reinforcement learning applications as it can provide the guideline\nabout the optimization. However, current reinforcement-learning-based methods\nrely on manually-defined reward functions, which cannot adapt to dynamic and\nnoisy environments. Besides, they generally use task-specific reward functions\nthat sacrifice generalization ability. We propose a generative inverse\nreinforcement learning for user behavioral preference modelling, to address the\nabove issues. Instead of using predefined reward functions, our model can\nautomatically learn the rewards from user's actions based on discriminative\nactor-critic network and Wasserstein GAN. Our model provides a general way of\ncharacterizing and explaining underlying behavioral tendencies, and our\nexperiments show our method outperforms state-of-the-art methods in a variety\nof scenarios, namely traffic signal control, online recommender systems, and\nscanpath prediction.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 13:14:25 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 13:01:28 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Chen", "Xiaocong", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Sun", "Aixin", ""], ["Zhang", "Wenjie", ""], ["Sheng", "Quan Z.", ""]]}, {"id": "2105.00823", "submitter": "Guy Marshall", "authors": "Guy Marshall and Mokanarangan Thayaparan and Philip Osborne and Andre\n  Freitas", "title": "Switching Contexts: Transportability Measures for NLP", "comments": "10 pages, 4 figures. To appear in IWCS 2021 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper explores the topic of transportability, as a sub-area of\ngeneralisability. By proposing the utilisation of metrics based on\nwell-established statistics, we are able to estimate the change in performance\nof NLP models in new contexts. Defining a new measure for transportability may\nallow for better estimation of NLP system performance in new domains, and is\ncrucial when assessing the performance of NLP systems in new tasks and domains.\nThrough several instances of increasing complexity, we demonstrate how\nlightweight domain similarity measures can be used as estimators for the\ntransportability in NLP applications. The proposed transportability measures\nare evaluated in the context of Named Entity Recognition and Natural Language\nInference tasks.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 13:15:24 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Marshall", "Guy", ""], ["Thayaparan", "Mokanarangan", ""], ["Osborne", "Philip", ""], ["Freitas", "Andre", ""]]}, {"id": "2105.00825", "submitter": "Yu Li", "authors": "Yu Li, Shirley Anugrah Hayati, Weiyan Shi and Zhou Yu", "title": "DEUX: An Attribute-Guided Framework for Sociable Recommendation Dialog\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is important for sociable recommendation dialog systems to perform as both\non-task content and social content to engage users and gain their favor. In\naddition to understand the user preferences and provide a satisfying\nrecommendation, such systems must be able to generate coherent and natural\nsocial conversations to the user. Traditional dialog state tracking cannot be\napplied to such systems because it does not track the attributes in the social\ncontent. To address this challenge, we propose DEUX, a novel attribute-guided\nframework to create better user experiences while accomplishing a movie\nrecommendation task. DEUX has a module that keeps track of the movie attributes\n(e.g., favorite genres, actors,etc.) in both user utterances and system\nresponses. This allows the system to introduce new movie attributes in its\nsocial content. Then, DEUX has multiple values for the same attribute type\nwhich suits the recommendation task since a user may like multiple genres, for\ninstance. Experiments suggest that DEUX outperforms all the baselines on being\nmore consistent, fitting the user preferences better, and providing a more\nengaging chat experience. Our approach can be used for any similar problems of\nsociable task-oriented dialog system.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 12:12:26 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Li", "Yu", ""], ["Hayati", "Shirley Anugrah", ""], ["Shi", "Weiyan", ""], ["Yu", "Zhou", ""]]}, {"id": "2105.00827", "submitter": "Katikapalli Subramanyam Kalyan", "authors": "Katikapalli Subramanyam Kalyan, Ajit Rajasekharan, Sivanesan Sangeetha", "title": "AMMU -- A Survey of Transformer-based Biomedical Pretrained Language\n  Models", "comments": "Preprint under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based pretrained language models (PLMs) have started a new era in\nmodern natural language processing (NLP). These models combine the power of\ntransformers, transfer learning, and self-supervised learning (SSL). Following\nthe success of these models in the general domain, the biomedical research\ncommunity has developed various in-domain PLMs starting from BioBERT to the\nlatest BioMegatron and CoderBERT models. We strongly believe there is a need\nfor a survey paper that can provide a comprehensive survey of various\ntransformer-based biomedical pretrained language models (BPLMs). In this\nsurvey, we start with a brief overview of foundational concepts like\nself-supervised learning, embedding layer and transformer encoder layers. We\ndiscuss core concepts of transformer-based PLMs like pretraining methods,\npretraining tasks, fine-tuning methods, and various embedding types specific to\nbiomedical domain. We introduce a taxonomy for transformer-based BPLMs and then\ndiscuss all the models. We discuss various challenges and present possible\nsolutions. We conclude by highlighting some of the open issues which will drive\nthe research community to further improve transformer-based BPLMs.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 18:09:51 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Kalyan", "Katikapalli Subramanyam", ""], ["Rajasekharan", "Ajit", ""], ["Sangeetha", "Sivanesan", ""]]}, {"id": "2105.00830", "submitter": "Vignav Ramesh", "authors": "Vignav Ramesh, Anton Kolonin", "title": "Natural Language Generation Using Link Grammar for General\n  Conversational Intelligence", "comments": "17 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many current artificial general intelligence (AGI) and natural language\nprocessing (NLP) architectures do not possess general conversational\nintelligence--that is, they either do not deal with language or are unable to\nconvey knowledge in a form similar to the human language without manual,\nlabor-intensive methods such as template-based customization. In this paper, we\npropose a new technique to automatically generate grammatically valid sentences\nusing the Link Grammar database. This natural language generation method far\noutperforms current state-of-the-art baselines and may serve as the final\ncomponent in a proto-AGI question answering pipeline that understandably\nhandles natural language material.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 06:16:07 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ramesh", "Vignav", ""], ["Kolonin", "Anton", ""]]}, {"id": "2105.00839", "submitter": "Ben Wise", "authors": "Ben Wise", "title": "Elo Ratings for Large Tournaments of Software Agents in Asymmetric Games", "comments": "75 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Elo rating system has been used world wide for individual sports and team\nsports, as exemplified by the European Go Federation (EGF), International Chess\nFederation (FIDE), International Federation of Association Football (FIFA), and\nmany others. To evaluate the performance of artificial intelligence agents, it\nis natural to evaluate them on the same Elo scale as humans, such as the rating\nof 5185 attributed to AlphaGo Zero.\n  There are several fundamental differences between humans and AI that suggest\nmodifications to the system, which in turn require revisiting Elo's fundamental\nrationale. AI is typically trained on many more games than humans play, and we\nhave little a-priori information on newly created AI agents. Further, AI is\nbeing extended into games which are asymmetric between the players, and which\ncould even have large complex boards with different setup in every game, such\nas commercial paper strategy games. We present a revised rating system, and\nguidelines for tournaments, to reflect these differences.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 21:49:20 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Wise", "Ben", ""]]}, {"id": "2105.00843", "submitter": "Leila Ismail Prof.", "authors": "Huned Materwala and Leila Ismail", "title": "Performance and Energy-Aware Bi-objective Tasks Scheduling for Cloud\n  Data Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cloud computing enables remote execution of users tasks. The pervasive\nadoption of cloud computing in smart cities services and applications requires\ntimely execution of tasks adhering to Quality of Services (QoS).\n  However, the increasing use of computing servers exacerbates the issues of\nhigh energy consumption, operating costs, and environmental pollution.\nMaximizing the performance and minimizing the energy in a cloud data center is\nchallenging. In this paper, we propose a performance and energy optimization\nbi-objective algorithm to tradeoff the contradicting performance and energy\nobjectives. An evolutionary algorithm-based multi-objective optimization is for\nthe first time proposed using system performance counters. The performance of\nthe proposed model is evaluated using a realistic cloud dataset in a cloud\ncomputing environment. Our experimental results achieve higher performance and\nlower energy consumption compared to a state of the art algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 25 Apr 2021 08:55:57 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Materwala", "Huned", ""], ["Ismail", "Leila", ""]]}, {"id": "2105.00875", "submitter": "Masoud Fetanat", "authors": "Masoud Fetanat, Michael Stevens, Christopher Hayward and Nigel H.\n  Lovell", "title": "A Sensorless Control System for an Implantable Heart Pump using a\n  Real-time Deep Convolutional Neural Network", "comments": null, "journal-ref": "IEEE Transactions on Biomedical Engineering, 2021", "doi": "10.1109/TBME.2021.3061405", "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Left ventricular assist devices (LVADs) are mechanical pumps, which can be\nused to support heart failure (HF) patients as bridge to transplant and\ndestination therapy. To automatically adjust the LVAD speed, a physiological\ncontrol system needs to be designed to respond to variations of patient\nhemodynamics across a variety of clinical scenarios. These control systems\nrequire pressure feedback signals from the cardiovascular system. However,\nthere are no suitable long-term implantable sensors available. In this study, a\nnovel real-time deep convolutional neural network (CNN) for estimation of\npreload based on the LVAD flow was proposed. A new sensorless adaptive\nphysiological control system for an LVAD pump was developed using the full\ndynamic form of model free adaptive control (FFDL-MFAC) and the proposed\npreload estimator to maintain the patient conditions in safe physiological\nranges. The CNN model for preload estimation was trained and evaluated through\n10-fold cross validation on 100 different patient conditions and the proposed\nsensorless control system was assessed on a new testing set of 30 different\npatient conditions across six different patient scenarios. The proposed preload\nestimator was extremely accurate with a correlation coefficient of 0.97, root\nmean squared error of 0.84 mmHg, reproducibility coefficient of 1.56 mmHg,\ncoefficient of variation of 14.44 %, and bias of 0.29 mmHg for the testing\ndataset. The results also indicate that the proposed sensorless physiological\ncontroller works similarly to the preload-based physiological control system\nfor LVAD using measured preload to prevent ventricular suction and pulmonary\ncongestion. This study shows that the LVADs can respond appropriately to\nchanging patient states and physiological demands without the need for\nadditional pressure or flow measurements.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 05:12:09 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Fetanat", "Masoud", ""], ["Stevens", "Michael", ""], ["Hayward", "Christopher", ""], ["Lovell", "Nigel H.", ""]]}, {"id": "2105.00884", "submitter": "Giulia Milan", "authors": "Giulia Milan, Luca Vassio, Idilio Drago, Marco Mellia", "title": "RL-IoT: Reinforcement Learning to Interact with IoT Devices", "comments": "9 pages, 11 figures, submitted to IEEE COINS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our life is getting filled by Internet of Things (IoT) devices. These devices\noften rely on closed or poorly documented protocols, with unknown formats and\nsemantics. Learning how to interact with such devices in an autonomous manner\nis the key for interoperability and automatic verification of their\ncapabilities. In this paper, we propose RL-IoT, a system that explores how to\nautomatically interact with possibly unknown IoT devices. We leverage\nreinforcement learning (RL) to recover the semantics of protocol messages and\nto take control of the device to reach a given goal, while minimizing the\nnumber of interactions. We assume to know only a database of possible IoT\nprotocol messages, whose semantics are however unknown. RL-IoT exchanges\nmessages with the target IoT device, learning those commands that are useful to\nreach the given goal. Our results show that RL-IoT is able to solve both simple\nand complex tasks. With properly tuned parameters, RL-IoT learns how to perform\nactions with the target device, a Yeelight smart bulb in our case study,\ncompleting non-trivial patterns with as few as 400 interactions. RL-IoT paves\nthe road for automatic interactions with poorly documented IoT protocols, thus\nenabling interoperable systems.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 14:09:03 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 10:48:44 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Milan", "Giulia", ""], ["Vassio", "Luca", ""], ["Drago", "Idilio", ""], ["Mellia", "Marco", ""]]}, {"id": "2105.00930", "submitter": "Arnab Karmakar", "authors": "Arnab Karmakar and Deepak Mishra", "title": "Pose Invariant Person Re-Identification using Robust Pose-transformation\n  GAN", "comments": "Undergraduate thesis at Indian Institute of Space Science and\n  Technology, Under review in IEEE Systems, Man and Cybernetics (SMCA)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The objective of person re-identification (re-ID) is to retrieve a person's\nimages from an image gallery, given a single instance of the person of\ninterest. Despite several advancements, learning discriminative\nidentity-sensitive and viewpoint invariant features for robust Person\nRe-identification is a major challenge owing to the large pose variation of\nhumans. This paper proposes a re-ID pipeline that utilizes the image generation\ncapability of Generative Adversarial Networks combined with pose clustering and\nfeature fusion to achieve pose invariant feature learning. The objective is to\nmodel a given person under different viewpoints and large pose changes and\nextract the most discriminative features from all the appearances. The pose\ntransformational GAN (pt-GAN) module is trained to generate a person's image in\nany given pose. In order to identify the most significant poses for\ndiscriminative feature extraction, a Pose Clustering module is proposed. The\ngiven instance of the person is modelled in varying poses and these features\nare effectively combined through the Feature Fusion Network. The final re-ID\nmodel consisting of these 3 sub-blocks, alleviates the pose dependence in\nperson re-ID. Also, The proposed model is robust to occlusion, scale, rotation\nand illumination, providing a framework for viewpoint invariant feature\nlearning. The proposed method outperforms the state-of-the-art GAN based models\nin 4 benchmark datasets. It also surpasses the state-of-the-art models that\nreport higher re-ID accuracy in terms of improvement over baseline.\n", "versions": [{"version": "v1", "created": "Sun, 11 Apr 2021 15:47:03 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 10:01:51 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Karmakar", "Arnab", ""], ["Mishra", "Deepak", ""]]}, {"id": "2105.00931", "submitter": "Unnat Jain", "authors": "Unnat Jain, Iou-Jen Liu, Svetlana Lazebnik, Aniruddha Kembhavi, Luca\n  Weihs, Alexander Schwing", "title": "GridToPix: Training Embodied Agents with Minimal Supervision", "comments": "Project page: https://unnat.github.io/gridtopix/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While deep reinforcement learning (RL) promises freedom from hand-labeled\ndata, great successes, especially for Embodied AI, require significant work to\ncreate supervision via carefully shaped rewards. Indeed, without shaped\nrewards, i.e., with only terminal rewards, present-day Embodied AI results\ndegrade significantly across Embodied AI problems from single-agent\nHabitat-based PointGoal Navigation (SPL drops from 55 to 0) and two-agent\nAI2-THOR-based Furniture Moving (success drops from 58% to 1%) to three-agent\nGoogle Football-based 3 vs. 1 with Keeper (game score drops from 0.6 to 0.1).\nAs training from shaped rewards doesn't scale to more realistic tasks, the\ncommunity needs to improve the success of training with terminal rewards. For\nthis we propose GridToPix: 1) train agents with terminal rewards in gridworlds\nthat generically mirror Embodied AI environments, i.e., they are independent of\nthe task; 2) distill the learned policy into agents that reside in complex\nvisual worlds. Despite learning from only terminal rewards with identical\nmodels and RL algorithms, GridToPix significantly improves results across\ntasks: from PointGoal Navigation (SPL improves from 0 to 64) and Furniture\nMoving (success improves from 1% to 25%) to football gameplay (game score\nimproves from 0.1 to 0.6). GridToPix even helps to improve the results of\nshaped reward training.\n", "versions": [{"version": "v1", "created": "Wed, 14 Apr 2021 17:59:57 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Jain", "Unnat", ""], ["Liu", "Iou-Jen", ""], ["Lazebnik", "Svetlana", ""], ["Kembhavi", "Aniruddha", ""], ["Weihs", "Luca", ""], ["Schwing", "Alexander", ""]]}, {"id": "2105.00933", "submitter": "Saranga Mahanta", "authors": "Saranga Kingkor Mahanta, Abdullah Faiz Ur Rahman Khilji, Partha Pakray", "title": "Deep Neural Network for Musical Instrument Recognition using MFCCs", "comments": "Was suggested to upload on a later date", "journal-ref": "Computacion y Sistemas, Vol 25, No 2 (2021): 25(2) 2021", "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The task of efficient automatic music classification is of vital importance\nand forms the basis for various advanced applications of AI in the musical\ndomain. Musical instrument recognition is the task of instrument identification\nby virtue of its audio. This audio, also termed as the sound vibrations are\nleveraged by the model to match with the instrument classes. In this paper, we\nuse an artificial neural network (ANN) model that was trained to perform\nclassification on twenty different classes of musical instruments. Here we use\nuse only the mel-frequency cepstral coefficients (MFCCs) of the audio data. Our\nproposed model trains on the full London philharmonic orchestra dataset which\ncontains twenty classes of instruments belonging to the four families viz.\nwoodwinds, brass, percussion, and strings. Based on experimental results our\nmodel achieves state-of-the-art accuracy on the same.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 15:10:34 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 13:32:28 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Mahanta", "Saranga Kingkor", ""], ["Khilji", "Abdullah Faiz Ur Rahman", ""], ["Pakray", "Partha", ""]]}, {"id": "2105.00944", "submitter": "Antonio Bruto da Costa", "authors": "Priyanka Sinha, Pabitra Mitra, Antonio Anastasio Bruto da Costa,\n  Nikolaos Kekatos", "title": "Explaining Outcomes of Multi-Party Dialogues using Causal Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-party dialogues are common in enterprise social media on technical as\nwell as non-technical topics. The outcome of a conversation may be positive or\nnegative. It is important to analyze why a dialogue ends with a particular\nsentiment from the point of view of conflict analysis as well as future\ncollaboration design. We propose an explainable time series mining algorithm\nfor such analysis. A dialogue is represented as an attributed time series of\noccurrences of keywords, EMPATH categories, and inferred sentiments at various\npoints in its progress. A special decision tree, with decision metrics that\ntake into account temporal relationships between dialogue events, is used for\npredicting the cause of the outcome sentiment. Interpretable rules mined from\nthe classifier are used to explain the prediction. Experimental results are\npresented for the enterprise social media posts in a large company.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 15:18:53 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Sinha", "Priyanka", ""], ["Mitra", "Pabitra", ""], ["da Costa", "Antonio Anastasio Bruto", ""], ["Kekatos", "Nikolaos", ""]]}, {"id": "2105.01015", "submitter": "Thomas Elsken", "authors": "Julia Guerrero-Viu, Sven Hauns, Sergio Izquierdo, Guilherme Miotto,\n  Simon Schrodi, Andre Biedenkapp, Thomas Elsken, Difan Deng, Marius Lindauer,\n  Frank Hutter", "title": "Bag of Baselines for Multi-objective Joint Neural Architecture Search\n  and Hyperparameter Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural architecture search (NAS) and hyperparameter optimization (HPO) make\ndeep learning accessible to non-experts by automatically finding the\narchitecture of the deep neural network to use and tuning the hyperparameters\nof the used training pipeline. While both NAS and HPO have been studied\nextensively in recent years, NAS methods typically assume fixed hyperparameters\nand vice versa - there exists little work on joint NAS + HPO. Furthermore, NAS\nhas recently often been framed as a multi-objective optimization problem, in\norder to take, e.g., resource requirements into account. In this paper, we\npropose a set of methods that extend current approaches to jointly optimize\nneural architectures and hyperparameters with respect to multiple objectives.\nWe hope that these methods will serve as simple baselines for future research\non multi-objective joint NAS + HPO. To facilitate this, all our code is\navailable at https://github.com/automl/multi-obj-baselines.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 17:04:56 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Guerrero-Viu", "Julia", ""], ["Hauns", "Sven", ""], ["Izquierdo", "Sergio", ""], ["Miotto", "Guilherme", ""], ["Schrodi", "Simon", ""], ["Biedenkapp", "Andre", ""], ["Elsken", "Thomas", ""], ["Deng", "Difan", ""], ["Lindauer", "Marius", ""], ["Hutter", "Frank", ""]]}, {"id": "2105.01029", "submitter": "Mikhail Khodak", "authors": "Mikhail Khodak and Neil Tenenholtz and Lester Mackey and Nicol\\`o Fusi", "title": "Initialization and Regularization of Factorized Neural Layers", "comments": "ICLR 2021 Camera-Ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CL cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Factorized layers--operations parameterized by products of two or more\nmatrices--occur in a variety of deep learning contexts, including compressed\nmodel training, certain types of knowledge distillation, and multi-head\nself-attention architectures. We study how to initialize and regularize deep\nnets containing such layers, examining two simple, understudied schemes,\nspectral initialization and Frobenius decay, for improving their performance.\nThe guiding insight is to design optimization routines for these networks that\nare as close as possible to that of their well-tuned, non-decomposed\ncounterparts; we back this intuition with an analysis of how the initialization\nand regularization schemes impact training with gradient descent, drawing on\nmodern attempts to understand the interplay of weight-decay and\nbatch-normalization. Empirically, we highlight the benefits of spectral\ninitialization and Frobenius decay across a variety of settings. In model\ncompression, we show that they enable low-rank methods to significantly\noutperform both unstructured sparsity and tensor methods on the task of\ntraining low-memory residual networks; analogs of the schemes also improve the\nperformance of tensor decomposition techniques. For knowledge distillation,\nFrobenius decay enables a simple, overcomplete baseline that yields a compact\nmodel from over-parameterized training without requiring retraining with or\npruning a teacher network. Finally, we show how both schemes applied to\nmulti-head attention lead to improved performance on both translation and\nunsupervised pre-training.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 17:28:07 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Khodak", "Mikhail", ""], ["Tenenholtz", "Neil", ""], ["Mackey", "Lester", ""], ["Fusi", "Nicol\u00f2", ""]]}, {"id": "2105.01036", "submitter": "Anand Rao", "authors": "Shaz Hoda, Amitoj Singh, Anand Rao, Remzi Ural, Nicholas Hodson", "title": "Consumer Demand Modeling During COVID-19 Pandemic", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current pandemic has introduced substantial uncertainty to traditional\nmethods for demand planning. These uncertainties stem from the disease\nprogression, government interventions, economy and consumer behavior. While\nmost of the emerging literature on the pandemic has focused on disease\nprogression, a few have focused on consequent regulations and their impact on\nindividual behavior. The contributions of this paper include a quantitative\nbehavior model of fear of COVID-19, impact of government interventions on\nconsumer behavior, and impact of consumer behavior on consumer choice and hence\ndemand for goods. It brings together multiple models for disease progression,\nconsumer behavior and demand estimation-thus bridging the gap between disease\nprogression and consumer demand. We use panel regression to understand the\ndrivers of demand during the pandemic and Bayesian inference to simplify the\nregulation landscape that can help build scenarios for resilient demand\nplanning. We illustrate this resilient demand planning model using a specific\nexample of gas retailing. We find that demand is sensitive to fear of COVID-19:\nas the number of COVID-19 cases increase over the previous week, the demand for\ngas decreases -- though this dissipates over time. Further, government\nregulations restrict access to different services, thereby reducing mobility,\nwhich in itself reduces demand.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 17:36:06 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Hoda", "Shaz", ""], ["Singh", "Amitoj", ""], ["Rao", "Anand", ""], ["Ural", "Remzi", ""], ["Hodson", "Nicholas", ""]]}, {"id": "2105.01060", "submitter": "Chuang Gan", "authors": "Yilun Du, Chuang Gan, Phillip Isola", "title": "Curious Representation Learning for Embodied Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Self-supervised representation learning has achieved remarkable success in\nrecent years. By subverting the need for supervised labels, such approaches are\nable to utilize the numerous unlabeled images that exist on the Internet and in\nphotographic datasets. Yet to build truly intelligent agents, we must construct\nrepresentation learning algorithms that can learn not only from datasets but\nalso learn from environments. An agent in a natural environment will not\ntypically be fed curated data. Instead, it must explore its environment to\nacquire the data it will learn from. We propose a framework, curious\nrepresentation learning (CRL), which jointly learns a reinforcement learning\npolicy and a visual representation model. The policy is trained to maximize the\nerror of the representation learner, and in doing so is incentivized to explore\nits environment. At the same time, the learned representation becomes stronger\nand stronger as the policy feeds it ever harder data to learn from. Our learned\nrepresentations enable promising transfer to downstream navigation tasks,\nperforming better than or comparably to ImageNet pretraining without using any\nsupervision at all. In addition, despite being trained in simulation, our\nlearned representations can obtain interpretable results on real images.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 17:59:20 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Du", "Yilun", ""], ["Gan", "Chuang", ""], ["Isola", "Phillip", ""]]}, {"id": "2105.01099", "submitter": "Zhiwei Qin", "authors": "Zhiwei Qin, Hongtu Zhu, and Jieping Ye", "title": "Reinforcement Learning for Ridesharing: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we present a comprehensive, in-depth survey of the literature\non reinforcement learning approaches to ridesharing problems. Papers on the\ntopics of rideshare matching, vehicle repositioning, ride-pooling, and dynamic\npricing are covered. Popular data sets and open simulation environments are\nalso introduced. Subsequently, we discuss a number of challenges and\nopportunities for reinforcement learning research on this important domain.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 18:09:58 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Qin", "Zhiwei", ""], ["Zhu", "Hongtu", ""], ["Ye", "Jieping", ""]]}, {"id": "2105.01115", "submitter": "Jakub Kowalski", "authors": "Rados{\\l}aw Miernik, Jakub Kowalski", "title": "Evolving Evaluation Functions for Collectible Card Game AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we presented a study regarding two important aspects of\nevolving feature-based game evaluation functions: the choice of genome\nrepresentation and the choice of opponent used to test the model. We compared\nthree representations. One simpler and more limited, based on a vector of\nweights that are used in a linear combination of predefined game features. And\ntwo more complex, based on binary and n-ary trees. On top of this test, we also\ninvestigated the influence of fitness defined as a simulation-based function\nthat: plays against a fixed weak opponent, plays against a fixed strong\nopponent, and plays against the best individual from the previous population.\nFor a testbed, we have chosen a recently popular domain of digital collectible\ncard games. We encoded our experiments in a programming game, Legends of Code\nand Magic, used in Strategy Card Game AI Competition. However, as the problems\nstated are of general nature we are convinced that our observations are\napplicable in the other domains as well.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 18:39:06 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Miernik", "Rados\u0142aw", ""], ["Kowalski", "Jakub", ""]]}, {"id": "2105.01129", "submitter": "Gaurav Sahu", "authors": "Gaurav Sahu, Robin Cohen, Olga Vechtomova", "title": "Towards A Multi-agent System for Online Hate Speech Detection", "comments": "Accepted to the 2nd International Workshop on Autonomous Agents for\n  Social Good (AASG), AAMAS, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper envisions a multi-agent system for detecting the presence of hate\nspeech in online social media platforms such as Twitter and Facebook. We\nintroduce a novel framework employing deep learning techniques to coordinate\nthe channels of textual and im-age processing. Our experimental results aim to\ndemonstrate the effectiveness of our methods for classifying online content,\ntraining the proposed neural network model to effectively detect hateful\ninstances in the input. We conclude with a discussion of how our system may be\nof use to provide recommendations to users who are managing online social\nnetworks, showcasing the immense potential of intelligent multi-agent systems\ntowards delivering social good.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 19:06:42 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Sahu", "Gaurav", ""], ["Cohen", "Robin", ""], ["Vechtomova", "Olga", ""]]}, {"id": "2105.01152", "submitter": "Andre Ribeiro", "authors": "Andre F. Ribeiro, Frank Neffke and Ricardo Hausmann", "title": "What can the millions of random treatments in nonexperimental data\n  reveal about causes?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a new method to estimate causal effects from nonexperimental data.\nEach pair of sample units is first associated with a stochastic 'treatment' -\ndifferences in factors between units - and an effect - a resultant outcome\ndifference. It is then proposed that all such pairs can be combined to provide\nmore accurate estimates of causal effects in observational data, provided a\nstatistical model connecting combinatorial properties of treatments to the\naccuracy and unbiasedness of their effects. The article introduces one such\nmodel and a Bayesian approach to combine the $O(n^2)$ pairwise observations\ntypically available in nonexperimnetal data. This also leads to an\ninterpretation of nonexperimental datasets as incomplete, or noisy, versions of\nideal factorial experimental designs.\n  This approach to causal effect estimation has several advantages: (1) it\nexpands the number of observations, converting thousands of individuals into\nmillions of observational treatments; (2) starting with treatments closest to\nthe experimental ideal, it identifies noncausal variables that can be ignored\nin the future, making estimation easier in each subsequent iteration while\ndeparting minimally from experiment-like conditions; (3) it recovers individual\ncausal effects in heterogeneous populations. We evaluate the method in\nsimulations and the National Supported Work (NSW) program, an intensively\nstudied program whose effects are known from randomized field experiments. We\ndemonstrate that the proposed approach recovers causal effects in common NSW\nsamples, as well as in arbitrary subpopulations and an order-of-magnitude\nlarger supersample with the entire national program data, outperforming\nStatistical, Econometrics and Machine Learning estimators in all cases...\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 20:13:34 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Ribeiro", "Andre F.", ""], ["Neffke", "Frank", ""], ["Hausmann", "Ricardo", ""]]}, {"id": "2105.01159", "submitter": "Farnaz H Foomani", "authors": "Farnaz H. Foomani, D. M. Anisuzzaman, Jeffrey Niezgoda, Jonathan\n  Niezgoda, William Guns, Sandeep Gopalakrishnan, Zeyun Yu", "title": "Synthesizing time-series wound prognosis factors from electronic medical\n  records using generative adversarial networks", "comments": "20 pages, 5 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Wound prognostic models not only provide an estimate of wound healing time to\nmotivate patients to follow up their treatments but also can help clinicians to\ndecide whether to use a standard care or adjuvant therapies and to assist them\nwith designing clinical trials. However, collecting prognosis factors from\nElectronic Medical Records (EMR) of patients is challenging due to privacy,\nsensitivity, and confidentiality. In this study, we developed time series\nmedical generative adversarial networks (GANs) to generate synthetic wound\nprognosis factors using very limited information collected during routine care\nin a specialized wound care facility. The generated prognosis variables are\nused in developing a predictive model for chronic wound healing trajectory. Our\nnovel medical GAN can produce both continuous and categorical features from\nEMR. Moreover, we applied temporal information to our model by considering data\ncollected from the weekly follow-ups of patients. Conditional training\nstrategies were utilized to enhance training and generate classified data in\nterms of healing or non-healing. The ability of the proposed model to generate\nrealistic EMR data was evaluated by TSTR (test on the synthetic, train on the\nreal), discriminative accuracy, and visualization. We utilized samples\ngenerated by our proposed GAN in training a prognosis model to demonstrate its\nreal-life application. Using the generated samples in training predictive\nmodels improved the classification accuracy by 6.66-10.01% compared to the\nprevious EMR-GAN. Additionally, the suggested prognosis classifier has achieved\nthe area under the curve (AUC) of 0.975, 0.968, and 0.849 when training the\nnetwork using data from the first three visits, first two visits, and first\nvisit, respectively. These results indicate a significant improvement in wound\nhealing prediction compared to the previous prognosis models.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 20:26:48 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Foomani", "Farnaz H.", ""], ["Anisuzzaman", "D. M.", ""], ["Niezgoda", "Jeffrey", ""], ["Niezgoda", "Jonathan", ""], ["Guns", "William", ""], ["Gopalakrishnan", "Sandeep", ""], ["Yu", "Zeyun", ""]]}, {"id": "2105.01195", "submitter": "Md Abdullah Al Alamin", "authors": "Md Abdullah Al Alamin, Gias Uddin", "title": "Quality Assurance Challenges for Machine Learning Software Applications\n  During Software Development Life Cycle Phases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past decades, the revolutionary advances of Machine Learning (ML) have\nshown a rapid adoption of ML models into software systems of diverse types.\nSuch Machine Learning Software Applications (MLSAs) are gaining importance in\nour daily lives. As such, the Quality Assurance (QA) of MLSAs is of paramount\nimportance. Several research efforts are dedicated to determining the specific\nchallenges we can face while adopting ML models into software systems. However,\nwe are aware of no research that offered a holistic view of the distribution of\nthose ML quality assurance challenges across the various phases of software\ndevelopment life cycles (SDLC). This paper conducts an in-depth literature\nreview of a large volume of research papers that focused on the quality\nassurance of ML models. We developed a taxonomy of MLSA quality assurance\nissues by mapping the various ML adoption challenges across different phases of\nSDLC. We provide recommendations and research opportunities to improve SDLC\npractices based on the taxonomy. This mapping can help prioritize quality\nassurance efforts of MLSAs where the adoption of ML models can be considered\ncrucial.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 22:29:23 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 18:29:10 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Alamin", "Md Abdullah Al", ""], ["Uddin", "Gias", ""]]}, {"id": "2105.01196", "submitter": "Patryk Orzechowski", "authors": "Pawe{\\l} Renc, Patryk Orzechowski, Aleksander Byrski, Jaros{\\l}aw\n  W\\k{a}s, and Jason H. Moore", "title": "EBIC.JL -- an Efficient Implementation of Evolutionary Biclustering\n  Algorithm in Julia", "comments": "9 pages, 11 figures", "journal-ref": null, "doi": "10.1145/3449726.3463197", "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.NE q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Biclustering is a data mining technique which searches for local patterns in\nnumeric tabular data with main application in bioinformatics. This technique\nhas shown promise in multiple areas, including development of biomarkers for\ncancer, disease subtype identification, or gene-drug interactions among others.\nIn this paper we introduce EBIC.JL - an implementation of one of the most\naccurate biclustering algorithms in Julia, a modern highly parallelizable\nprogramming language for data science. We show that the new version maintains\ncomparable accuracy to its predecessor EBIC while converging faster for the\nmajority of the problems. We hope that this open source software in a\nhigh-level programming language will foster research in this promising field of\nbioinformatics and expedite development of new biclustering methods for big\ndata.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 22:30:38 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Renc", "Pawe\u0142", ""], ["Orzechowski", "Patryk", ""], ["Byrski", "Aleksander", ""], ["W\u0105s", "Jaros\u0142aw", ""], ["Moore", "Jason H.", ""]]}, {"id": "2105.01220", "submitter": "Zahra Zahedi", "authors": "Zahra Zahedi, Mudit Verma, Sarath Sreedharan, Subbarao Kambhampati", "title": "Trust-Aware Planning: Modeling Trust Evolution in Longitudinal\n  Human-Robot Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Trust between team members is an essential requirement for any successful\ncooperation. Thus, engendering and maintaining the fellow team members' trust\nbecomes a central responsibility for any member trying to not only successfully\nparticipate in the task but to ensure the team achieves its goals. The problem\nof trust management is particularly challenging in mixed human-robot teams\nwhere the human and the robot may have different models about the task at hand\nand thus may have different expectations regarding the current course of action\nand forcing the robot to focus on the costly explicable behavior. We propose a\ncomputational model for capturing and modulating trust in such longitudinal\nhuman-robot interaction, where the human adopts a supervisory role. In our\nmodel, the robot integrates human's trust and their expectations from the robot\ninto its planning process to build and maintain trust over the interaction\nhorizon. By establishing the required level of trust, the robot can focus on\nmaximizing the team goal by eschewing explicit explanatory or explicable\nbehavior without worrying about the human supervisor monitoring and intervening\nto stop behaviors they may not necessarily understand. We model this reasoning\nabout trust levels as a meta reasoning process over individual planning tasks.\nWe additionally validate our model through a human subject experiment.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 23:38:34 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Zahedi", "Zahra", ""], ["Verma", "Mudit", ""], ["Sreedharan", "Sarath", ""], ["Kambhampati", "Subbarao", ""]]}, {"id": "2105.01225", "submitter": "Murat Cubuktepe", "authors": "Murat Cubuktepe, Franti\\v{s}ek Blahoudek, and Ufuk Topcu", "title": "Polynomial-Time Algorithms for Multi-Agent Minimal-Capacity Planning", "comments": "Submitted to TCNS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of minimizing the resource capacity of autonomous agents\ncooperating to achieve a shared task. More specifically, we consider high-level\nplanning for a team of homogeneous agents that operate under resource\nconstraints in stochastic environments and share a common goal: given a set of\ntarget locations, ensure that each location will be visited infinitely often by\nsome agent almost surely. We formalize the dynamics of agents by consumption\nMarkov decision processes. In a consumption Markov decision process, the agent\nhas a resource of limited capacity. Each action of the agent may consume some\namount of the resource. To avoid exhaustion, the agent can replenish its\nresource to full capacity in designated reload states. The resource capacity\nrestricts the capabilities of the agent. The objective is to assign target\nlocations to agents, and each agent is only responsible for visiting the\nassigned subset of target locations repeatedly. Moreover, the assignment must\nensure that the agents can carry out their tasks with minimal resource\ncapacity. We reduce the problem of finding target assignments for a team of\nagents with the lowest possible capacity to an equivalent graph-theoretical\nproblem. We develop an algorithm that solves this graph problem in time that is\n\\emph{polynomial} in the number of agents, target locations, and size of the\nconsumption Markov decision process. We demonstrate the applicability and\nscalability of the algorithm in a scenario where hundreds of unmanned\nunderwater vehicles monitor hundreds of locations in environments with\nstochastic ocean currents.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 00:30:02 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Cubuktepe", "Murat", ""], ["Blahoudek", "Franti\u0161ek", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2105.01227", "submitter": "Zi-Jian Ni", "authors": "Zi-jian Ni, Wei Liu", "title": "Causal factors discovering from Chinese construction accident cases", "comments": "21 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In China, construction accidents have killed more people than any other\nindustry since 2012. The factors which led to the accident have complex\ninteraction. Real data about accidents is the key to reveal the mechanism among\nthese factors. But the data from the questionnaire and interview has inherent\ndefects. Many behaviors that impact safety are illegal. In China, most of the\ncases are from accident investigation reports. Finding out the cause of the\naccident and liability affirmation are the core of incident investigation\nreports. So the truth of some answers from the respondents is doubtful. With a\nseries of NLP technologies, in this paper, causal factors of construction\naccidents are extracted and organized from Chinese incident case texts.\nFinally, three kinds of neglected causal factors are discovered after data\nanalysis.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 00:36:17 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Ni", "Zi-jian", ""], ["Liu", "Wei", ""]]}, {"id": "2105.01269", "submitter": "Ishita Padhiar", "authors": "Ishita Padhiar, Oshani Seneviratne, Shruthi Chari, Daniel Gruen,\n  Deborah L. McGuinness", "title": "Semantic Modeling for Food Recommendation Explanations", "comments": "7 pages, 4 figures, 1 table, 3 listings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increased use of AI methods to provide recommendations in the\nhealth, specifically in the food dietary recommendation space, there is also an\nincreased need for explainability of those recommendations. Such explanations\nwould benefit users of recommendation systems by empowering them with\njustifications for following the system's suggestions. We present the Food\nExplanation Ontology (FEO) that provides a formalism for modeling explanations\nto users for food-related recommendations. FEO models food recommendations,\nusing concepts from the explanation domain to create responses to user\nquestions about food recommendations they receive from AI systems such as\npersonalized knowledge base question answering systems. FEO uses a modular,\nextensible structure that lends itself to a variety of explanations while still\npreserving important semantic details to accurately represent explanations of\nfood recommendations. In order to evaluate this system, we used a set of\ncompetency questions derived from explanation types present in literature that\nare relevant to food recommendations. Our motivation with the use of FEO is to\nempower users to make decisions about their health, fully equipped with an\nunderstanding of the AI recommender systems as they relate to user questions,\nby providing reasoning behind their recommendations in the form of\nexplanations.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 03:25:36 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Padhiar", "Ishita", ""], ["Seneviratne", "Oshani", ""], ["Chari", "Shruthi", ""], ["Gruen", "Daniel", ""], ["McGuinness", "Deborah L.", ""]]}, {"id": "2105.01275", "submitter": "Yunxiang Zhao", "authors": "Yunsheng Pang, Yunxiang Zhao, Dongsheng Li", "title": "Graph Pooling via Coarsened Graph Infomax", "comments": null, "journal-ref": null, "doi": "10.1145/3404835.3463074", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph pooling that summaries the information in a large graph into a compact\nform is essential in hierarchical graph representation learning. Existing graph\npooling methods either suffer from high computational complexity or cannot\ncapture the global dependencies between graphs before and after pooling. To\naddress the problems of existing graph pooling methods, we propose Coarsened\nGraph Infomax Pooling (CGIPool) that maximizes the mutual information between\nthe input and the coarsened graph of each pooling layer to preserve graph-level\ndependencies. To achieve mutual information neural maximization, we apply\ncontrastive learning and propose a self-attention-based algorithm for learning\npositive and negative samples. Extensive experimental results on seven datasets\nillustrate the superiority of CGIPool comparing to the state-of-the-art\nmethods.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 03:50:21 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 14:08:24 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Pang", "Yunsheng", ""], ["Zhao", "Yunxiang", ""], ["Li", "Dongsheng", ""]]}, {"id": "2105.01276", "submitter": "Weijia Zhang", "authors": "Weijia Zhang", "title": "Non-I.I.D. Multi-Instance Learning for Predicting Instance and Bag\n  Labels using Variational Auto-Encoder", "comments": "To appear in Proceedings of the 30th International Joint Conference\n  on Artificial Intelligence (IJCAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-instance learning is a type of weakly supervised learning. It deals\nwith tasks where the data is a set of bags and each bag is a set of instances.\nOnly the bag labels are observed whereas the labels for the instances are\nunknown. An important advantage of multi-instance learning is that by\nrepresenting objects as a bag of instances, it is able to preserve the inherent\ndependencies among parts of the objects. Unfortunately, most existing\nalgorithms assume all instances to be \\textit{identically and independently\ndistributed}, which violates real-world scenarios since the instances within a\nbag are rarely independent. In this work, we propose the Multi-Instance\nVariational Auto-Encoder (MIVAE) algorithm which explicitly models the\ndependencies among the instances for predicting both bag labels and instance\nlabels. Experimental results on several multi-instance benchmarks and\nend-to-end medical imaging datasets demonstrate that MIVAE performs better than\nstate-of-the-art algorithms for both instance label and bag label prediction\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 03:50:33 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Zhang", "Weijia", ""]]}, {"id": "2105.01279", "submitter": "Yan Song", "authors": "Yan Song, Tong Zhang, Yonggang Wang, Kai-Fu Lee", "title": "ZEN 2.0: Continue Training and Adaption for N-gram Enhanced Text\n  Encoders", "comments": "13 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained text encoders have drawn sustaining attention in natural language\nprocessing (NLP) and shown their capability in obtaining promising results in\ndifferent tasks. Recent studies illustrated that external self-supervised\nsignals (or knowledge extracted by unsupervised learning, such as n-grams) are\nbeneficial to provide useful semantic evidence for understanding languages such\nas Chinese, so as to improve the performance on various downstream tasks\naccordingly. To further enhance the encoders, in this paper, we propose to\npre-train n-gram-enhanced encoders with a large volume of data and advanced\ntechniques for training. Moreover, we try to extend the encoder to different\nlanguages as well as different domains, where it is confirmed that the same\narchitecture is applicable to these varying circumstances and new\nstate-of-the-art performance is observed from a long list of NLP tasks across\nlanguages and domains.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 04:08:58 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Song", "Yan", ""], ["Zhang", "Tong", ""], ["Wang", "Yonggang", ""], ["Lee", "Kai-Fu", ""]]}, {"id": "2105.01280", "submitter": "Feng Shi", "authors": "Feng Shi, Ahren Yiqiao Jin, Song-Chun Zhu", "title": "VersaGNN: a Versatile accelerator for Graph neural networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\textit{Graph Neural Network} (GNN) is a promising approach for analyzing\ngraph-structured data that tactfully captures their dependency information via\nnode-level message passing. It has achieved state-of-the-art performances in\nmany tasks, such as node classification, graph matching, clustering, and graph\ngeneration. As GNNs operate on non-Euclidean data, their irregular data access\npatterns cause considerable computational costs and overhead on conventional\narchitectures, such as GPU and CPU. Our analysis shows that GNN adopts a hybrid\ncomputing model. The \\textit{Aggregation} (or \\textit{Message Passing}) phase\nperforms vector additions where vectors are fetched with irregular strides. The\n\\textit{Transformation} (or \\textit{Node Embedding}) phase can be either dense\nor sparse-dense matrix multiplication. In this work, We propose\n\\textit{VersaGNN}, an ultra-efficient, systolic-array-based versatile hardware\naccelerator that unifies dense and sparse matrix multiplication. By applying\nthis single optimized systolic array to both aggregation and transformation\nphases, we have significantly reduced chip sizes and energy consumption. We\nthen divide the computing engine into blocked systolic arrays to support the\n\\textit{Strassen}'s algorithm for dense matrix multiplication, dramatically\nscaling down the number of multiplications and enabling high-throughput\ncomputation of GNNs. To balance the workload of sparse-dense matrix\nmultiplication, we also introduced a greedy algorithm to combine sparse\nsub-matrices of compressed format into condensed ones to reduce computational\ncycles. Compared with current state-of-the-art GNN software frameworks,\n\\textit{VersaGNN} achieves on average 3712$\\times$ speedup with 1301.25$\\times$\nenergy reduction on CPU, and 35.4$\\times$ speedup with 17.66$\\times$ energy\nreduction on GPU.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 04:10:48 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Shi", "Feng", ""], ["Jin", "Ahren Yiqiao", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2105.01305", "submitter": "Heiko Paulheim", "authors": "Petar Ristoski, Stefano Faralli, Simone Paolo Ponzetto and Heiko\n  Paulheim", "title": "Large-scale Taxonomy Induction Using Entity and Word Embeddings", "comments": "Published at IEEE/WIC/ACM International Conference on Web\n  Intelligence 2017 (WI'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Taxonomies are an important ingredient of knowledge organization, and serve\nas a backbone for more sophisticated knowledge representations in intelligent\nsystems, such as formal ontologies. However, building taxonomies manually is a\ncostly endeavor, and hence, automatic methods for taxonomy induction are a good\nalternative to build large-scale taxonomies. In this paper, we propose TIEmb,\nan approach for automatic unsupervised class subsumption axiom extraction from\nknowledge bases using entity and text embeddings. We apply the approach on the\nWebIsA database, a database of subsumption relations extracted from the large\nportion of the World Wide Web, to extract class hierarchies in the Person and\nPlace domain.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 05:53:12 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Ristoski", "Petar", ""], ["Faralli", "Stefano", ""], ["Ponzetto", "Simone Paolo", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2105.01346", "submitter": "Hachem Kadri", "authors": "Paolo Milanesi (QARMA), Hachem Kadri (LIS, QARMA, AMU SCI), St\\'ephane\n  Ayache (QARMA), Thierry Arti\\`eres (QARMA)", "title": "Implicit Regularization in Deep Tensor Factorization", "comments": null, "journal-ref": "International Joint Conference on Neural Networks (IJCNN), Jul\n  2021, Online, China", "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attempts of studying implicit regularization associated to gradient descent\n(GD) have identified matrix completion as a suitable test-bed. Late findings\nsuggest that this phenomenon cannot be phrased as a minimization-norm problem,\nimplying that a paradigm shift is required and that dynamics has to be taken\ninto account. In the present work we address the more general setup of tensor\ncompletion by leveraging two popularized tensor factorization, namely Tucker\nand TensorTrain (TT). We track relevant quantities such as tensor nuclear norm,\neffective rank, generalized singular values and we introduce deep Tucker and TT\nunconstrained factorization to deal with the completion task. Experiments on\nboth synthetic and real data show that gradient descent promotes solution with\nlow-rank, and validate the conjecture saying that the phenomenon has to be\naddressed from a dynamical perspective.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 07:48:40 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Milanesi", "Paolo", "", "QARMA"], ["Kadri", "Hachem", "", "LIS, QARMA, AMU SCI"], ["Ayache", "St\u00e9phane", "", "QARMA"], ["Arti\u00e8res", "Thierry", "", "QARMA"]]}, {"id": "2105.01401", "submitter": "Pierre-Alain Mo\\\"ellic", "authors": "Rapha\\\"el Joud, Pierre-Alain Moellic, R\\'emi Bernhard, Jean-Baptiste\n  Rigaud", "title": "A Review of Confidentiality Threats Against Embedded Neural Network\n  Models", "comments": "Accepted at 7th IEEE World Forum on Internet of Things (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utilization of Machine Learning (ML) algorithms, especially Deep Neural\nNetwork (DNN) models, becomes a widely accepted standard in many domains more\nparticularly IoT-based systems. DNN models reach impressive performances in\nseveral sensitive fields such as medical diagnosis, smart transport or security\nthreat detection, and represent a valuable piece of Intellectual Property. Over\nthe last few years, a major trend is the large-scale deployment of models in a\nwide variety of devices. However, this migration to embedded systems is slowed\ndown because of the broad spectrum of attacks threatening the integrity,\nconfidentiality and availability of embedded models. In this review, we cover\nthe landscape of attacks targeting the confidentiality of embedded DNN models\nthat may have a major impact on critical IoT systems, with a particular focus\non model extraction and data leakage. We highlight the fact that Side-Channel\nAnalysis (SCA) is a relatively unexplored bias by which model's confidentiality\ncan be compromised. Input data, architecture or parameters of a model can be\nextracted from power or electromagnetic observations, testifying a real need\nfrom a security point of view.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 10:27:20 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Joud", "Rapha\u00ebl", ""], ["Moellic", "Pierre-Alain", ""], ["Bernhard", "R\u00e9mi", ""], ["Rigaud", "Jean-Baptiste", ""]]}, {"id": "2105.01403", "submitter": "Pierre-Alain Mo\\\"ellic", "authors": "Mathieu Dumont, Pierre-Alain Moellic, Raphael Viera, Jean-Max\n  Dutertre, R\\'emi Bernhard", "title": "An Overview of Laser Injection against Embedded Neural Network Models", "comments": "Accepted at 7th IEEE World Forum on Internet of Things (2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For many IoT domains, Machine Learning and more particularly Deep Learning\nbrings very efficient solutions to handle complex data and perform challenging\nand mostly critical tasks. However, the deployment of models in a large variety\nof devices faces several obstacles related to trust and security. The latest is\nparticularly critical since the demonstrations of severe flaws impacting the\nintegrity, confidentiality and accessibility of neural network models. However,\nthe attack surface of such embedded systems cannot be reduced to abstract flaws\nbut must encompass the physical threats related to the implementation of these\nmodels within hardware platforms (e.g., 32-bit microcontrollers). Among\nphysical attacks, Fault Injection Analysis (FIA) are known to be very powerful\nwith a large spectrum of attack vectors. Most importantly, highly focused FIA\ntechniques such as laser beam injection enable very accurate evaluation of the\nvulnerabilities as well as the robustness of embedded systems. Here, we propose\nto discuss how laser injection with state-of-the-art equipment, combined with\ntheoretical evidences from Adversarial Machine Learning, highlights worrying\nthreats against the integrity of deep learning inference and claims that join\nefforts from the theoretical AI and Physical Security communities are a urgent\nneed.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 10:32:30 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Dumont", "Mathieu", ""], ["Moellic", "Pierre-Alain", ""], ["Viera", "Raphael", ""], ["Dutertre", "Jean-Max", ""], ["Bernhard", "R\u00e9mi", ""]]}, {"id": "2105.01419", "submitter": "Tianyu Liu", "authors": "Hang Yu, Tianyu Liu, Jie Lu and Guangquan Zhang", "title": "Automatic Learning to Detect Concept Drift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Many methods have been proposed to detect concept drift, i.e., the change in\nthe distribution of streaming data, due to concept drift causes a decrease in\nthe prediction accuracy of algorithms. However, the most of current detection\nmethods are based on the assessment of the degree of change in the data\ndistribution, cannot identify the type of concept drift. In this paper, we\npropose Active Drift Detection with Meta learning (Meta-ADD), a novel framework\nthat learns to classify concept drift by tracking the changed pattern of error\nrates. Specifically, in the training phase, we extract meta-features based on\nthe error rates of various concept drift, after which a meta-detector is\ndeveloped via a prototypical neural network by representing various concept\ndrift classes as corresponding prototypes. In the detection phase, the learned\nmeta-detector is fine-tuned to adapt to the corresponding data stream via\nstream-based active learning. Hence, Meta-ADD uses machine learning to learn to\ndetect concept drifts and identify their types automatically, which can\ndirectly support drift understand. The experiment results verify the\neffectiveness of Meta-ADD.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 11:10:39 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Yu", "Hang", ""], ["Liu", "Tianyu", ""], ["Lu", "Jie", ""], ["Zhang", "Guangquan", ""]]}, {"id": "2105.01425", "submitter": "Pascal Lenzner", "authors": "Simon Krogmann, Pascal Lenzner, Louise Molitor, Alexander Skopalik", "title": "Two-Stage Facility Location Games with Strategic Clients and Facilities", "comments": "To appear at the 30th International Joint Conference on Artificial\n  Intelligence (IJCAI-21), full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider non-cooperative facility location games where both facilities and\nclients act strategically and heavily influence each other. This contrasts\nestablished game-theoretic facility location models with non-strategic clients\nthat simply select the closest opened facility. In our model, every facility\nlocation has a set of attracted clients and each client has a set of shopping\nlocations and a weight that corresponds to her spending capacity. Facility\nagents selfishly select a location for opening their facility to maximize the\nattracted total spending capacity, whereas clients strategically decide how to\ndistribute their spending capacity among the opened facilities in their\nshopping range. We focus on a natural client behavior similar to classical load\nbalancing: our selfish clients aim for a distribution that minimizes their\nmaximum waiting times for getting serviced, where a facility's waiting time\ncorresponds to its total attracted client weight.\n  We show that subgame perfect equilibria exist and give almost tight constant\nbounds on the Price of Anarchy and the Price of Stability, which even hold for\na broader class of games with arbitrary client behavior. Since facilities and\nclients influence each other, it is crucial for the facilities to anticipate\nthe selfish clients' behavior when selecting their location. For this, we\nprovide an efficient algorithm that also implies an efficient check for\nequilibrium. Finally, we show that computing a socially optimal facility\nplacement is NP-hard and that this result holds for all feasible client weight\ndistributions.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 11:27:09 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Krogmann", "Simon", ""], ["Lenzner", "Pascal", ""], ["Molitor", "Louise", ""], ["Skopalik", "Alexander", ""]]}, {"id": "2105.01434", "submitter": "Michele Loi Dr.", "authors": "Michele Loi and Matthias Spielkamp", "title": "Towards Accountability in the Use of Artificial Intelligence for Public\n  Administrations", "comments": "10 pages, 4 figures, 2 tables", "journal-ref": null, "doi": "10.1145/3461702.3462631", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We argue that the phenomena of distributed responsibility, induced\nacceptance, and acceptance through ignorance constitute instances of imperfect\ndelegation when tasks are delegated to computationally-driven systems.\nImperfect delegation challenges human accountability. We hold that both direct\npublic accountability via public transparency and indirect public\naccountability via transparency to auditors in public organizations can be both\ninstrumentally ethically valuable and required as a matter of deontology from\nthe principle of democratic self-government. We analyze the regulatory content\nof 16 guideline documents about the use of AI in the public sector, by mapping\ntheir requirements to those of our philosophical account of accountability, and\nconclude that while some guidelines refer to processes that amount to auditing,\nit seems that the debate would benefit from more clarity about the nature of\nthe entitlement of auditors and the goals of auditing, also in order to develop\nethically meaningful standards with respect to which different forms of\nauditing can be evaluated and compared.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 11:50:04 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Loi", "Michele", ""], ["Spielkamp", "Matthias", ""]]}, {"id": "2105.01454", "submitter": "Stefanie Rinderle-Ma", "authors": "Florian Stertz and Juergen Mangler and Stefanie Rinderle-Ma", "title": "The Role of Time and Data: Online Conformance Checking in the\n  Manufacturing Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Process mining has matured as analysis instrument for process-oriented data\nin recent years. Manufacturing is a challenging domain that craves for\nprocess-oriented technologies to address digitalization challenges. We found\nthat process mining creates high expectations, but its implementation and usage\nby manufacturing experts such as process supervisors and shopfloor workers\nremain unclear to a certain extent. Reason (1) is that even though\nmanufacturing allows for well-structured processes, the actual workflow is\nrarely captured in a process model. Even if a model is available, a software\nfor orchestrating and logging the execution is often missing. Reason (2) refers\nto the work reality in manufacturing: a process instance is started by a\nshopfloor worker who then turns to work on other things. Hence continuous\nmonitoring of the process instances does not happen, i.e., process monitoring\nis merely a secondary task, and the shopfloor worker can only react to\nproblems/errors that have already occurred. (1) and (2) motivate the goals of\nthis study that is driven by Technical Action Research (TAR). Based on the\nexperimental artifact TIDATE -- a lightweight process execution and mining\nframework -- it is studied how the correct execution of process instances can\nbe ensured and how a data set suitable for process mining can be generated at\nrun time in a real-world setting. Secondly, it is investigated whether and how\nprocess mining supports domain experts during process monitoring as a secondary\ntask. The findings emphasize the importance of online conformance checking in\nmanufacturing and show how appropriate data sets can be identified and\ngenerated.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 12:23:35 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Stertz", "Florian", ""], ["Mangler", "Juergen", ""], ["Rinderle-Ma", "Stefanie", ""]]}, {"id": "2105.01517", "submitter": "Yanbei Chen", "authors": "Yanbei Chen, Thomas Hummel, A. Sophia Koepke, Zeynep Akata", "title": "Where and When: Space-Time Attention for Audio-Visual Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explaining the decision of a multi-modal decision-maker requires to determine\nthe evidence from both modalities. Recent advances in XAI provide explanations\nfor models trained on still images. However, when it comes to modeling multiple\nsensory modalities in a dynamic world, it remains underexplored how to\ndemystify the mysterious dynamics of a complex multi-modal model. In this work,\nwe take a crucial step forward and explore learnable explanations for\naudio-visual recognition. Specifically, we propose a novel space-time attention\nnetwork that uncovers the synergistic dynamics of audio and visual data over\nboth space and time. Our model is capable of predicting the audio-visual video\nevents, while justifying its decision by localizing where the relevant visual\ncues appear, and when the predicted sounds occur in videos. We benchmark our\nmodel on three audio-visual video event datasets, comparing extensively to\nmultiple recent multi-modal representation learners and intrinsic explanation\nmodels. Experimental results demonstrate the clear superior performance of our\nmodel over the existing methods on audio-visual video event recognition.\nMoreover, we conduct an in-depth study to analyze the explainability of our\nmodel based on robustness analysis via perturbation tests and pointing games\nusing human annotations.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 14:16:55 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Chen", "Yanbei", ""], ["Hummel", "Thomas", ""], ["Koepke", "A. Sophia", ""], ["Akata", "Zeynep", ""]]}, {"id": "2105.01531", "submitter": "Javier Nistal", "authors": "Javier Nistal, Cyran Aouameur, Stefan Lattner, and Ga\\\"el Richard", "title": "VQCPC-GAN: Variable-length Adversarial Audio Synthesis using\n  Vector-Quantized Contrastive Predictive Coding", "comments": "5 pages, 1 figure, 1 table; under review for WASPAA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Influenced by the field of Computer Vision, Generative Adversarial Networks\n(GANs) are often adopted for the audio domain using fixed-size two-dimensional\nspectrogram representations as the \"image data\". However, in the (musical)\naudio domain, it is often desired to generate output of variable duration. This\npaper presents VQCPC-GAN, an adversarial framework for synthesizing\nvariable-length audio by exploiting Vector-Quantized Contrastive Predictive\nCoding (VQCPC). A sequence of VQCPC tokens extracted from real audio data\nserves as conditional input to a GAN architecture, providing step-wise\ntime-dependent features of the generated content. The input noise z\n(characteristic in adversarial architectures) remains fixed over time, ensuring\ntemporal consistency of global features. We evaluate the proposed model by\ncomparing a diverse set of metrics against various strong baselines. Results\nshow that, even though the baselines score best, VQCPC-GAN achieves comparable\nperformance even when generating variable-length audio. Numerous sound examples\nare provided in the accompanying website, and we release the code for\nreproducibility.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 14:35:51 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Nistal", "Javier", ""], ["Aouameur", "Cyran", ""], ["Lattner", "Stefan", ""], ["Richard", "Ga\u00ebl", ""]]}, {"id": "2105.01564", "submitter": "Haggai Roitman", "authors": "Yotam Eshel, Or Levi, Haggai Roitman, Alexander Nus", "title": "PreSizE: Predicting Size in E-Commerce using Transformers", "comments": "Accepted for publication in SIGIR'2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in the e-commerce fashion industry have led to an exploration\nof novel ways to enhance buyer experience via improved personalization.\nPredicting a proper size for an item to recommend is an important\npersonalization challenge, and is being studied in this work. Earlier works in\nthis field either focused on modeling explicit buyer fitment feedback or\nmodeling of only a single aspect of the problem (e.g., specific category,\nbrand, etc.). More recent works proposed richer models, either content-based or\nsequence-based, better accounting for content-based aspects of the problem or\nbetter modeling the buyer's online journey. However, both these approaches fail\nin certain scenarios: either when encountering unseen items (sequence-based\nmodels) or when encountering new users (content-based models).\n  To address the aforementioned gaps, we propose PreSizE - a novel deep\nlearning framework which utilizes Transformers for accurate size prediction.\nPreSizE models the effect of both content-based attributes, such as brand and\ncategory, and the buyer's purchase history on her size preferences. Using an\nextensive set of experiments on a large-scale e-commerce dataset, we\ndemonstrate that PreSizE is capable of achieving superior prediction\nperformance compared to previous state-of-the-art baselines. By encoding item\nattributes, PreSizE better handles cold-start cases with unseen items, and\ncases where buyers have little past purchase data. As a proof of concept, we\ndemonstrate that size predictions made by PreSizE can be effectively integrated\ninto an existing production recommender system yielding very effective features\nand significantly improving recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 15:23:59 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Eshel", "Yotam", ""], ["Levi", "Or", ""], ["Roitman", "Haggai", ""], ["Nus", "Alexander", ""]]}, {"id": "2105.01585", "submitter": "Qingcheng Xiao", "authors": "Qingcheng Xiao, Size Zheng, Bingzhe Wu, Pengcheng Xu, Xuehai Qian, Yun\n  Liang", "title": "HASCO: Towards Agile HArdware and Software CO-design for Tensor\n  Computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor computations overwhelm traditional general-purpose computing devices\ndue to the large amounts of data and operations of the computations. They call\nfor a holistic solution composed of both hardware acceleration and software\nmapping. Hardware/software (HW/SW) co-design optimizes the hardware and\nsoftware in concert and produces high-quality solutions. There are two main\nchallenges in the co-design flow. First, multiple methods exist to partition\ntensor computation and have different impacts on performance and energy\nefficiency. Besides, the hardware part must be implemented by the intrinsic\nfunctions of spatial accelerators. It is hard for programmers to identify and\nanalyze the partitioning methods manually. Second, the overall design space\ncomposed of HW/SW partitioning, hardware optimization, and software\noptimization is huge. The design space needs to be efficiently explored.\n  To this end, we propose an agile co-design approach HASCO that provides an\nefficient HW/SW solution to dense tensor computation. We use tensor syntax\ntrees as the unified IR, based on which we develop a two-step approach to\nidentify partitioning methods. For each method, HASCO explores the hardware and\nsoftware design spaces. We propose different algorithms for the explorations,\nas they have distinct objectives and evaluation costs. Concretely, we develop a\nmulti-objective Bayesian optimization algorithm to explore hardware\noptimization. For software optimization, we use heuristic and Q-learning\nalgorithms. Experiments demonstrate that HASCO achieves a 1.25X to 1.44X\nlatency reduction through HW/SW co-design compared with developing the hardware\nand software separately.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 15:48:27 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Xiao", "Qingcheng", ""], ["Zheng", "Size", ""], ["Wu", "Bingzhe", ""], ["Xu", "Pengcheng", ""], ["Qian", "Xuehai", ""], ["Liang", "Yun", ""]]}, {"id": "2105.01601", "submitter": "Ilya Tolstikhin", "authors": "Ilya Tolstikhin and Neil Houlsby and Alexander Kolesnikov and Lucas\n  Beyer and Xiaohua Zhai and Thomas Unterthiner and Jessica Yung and Andreas\n  Steiner and Daniel Keysers and Jakob Uszkoreit and Mario Lucic and Alexey\n  Dosovitskiy", "title": "MLP-Mixer: An all-MLP Architecture for Vision", "comments": "v2: Fixed parameter counts in Table 1. v3: Added results on JFT-3B in\n  Figure 2(right); Added Section 3.4 on the input permutations. v4: Updated the\n  x label in Figure 2(right)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) are the go-to model for computer vision.\nRecently, attention-based networks, such as the Vision Transformer, have also\nbecome popular. In this paper we show that while convolutions and attention are\nboth sufficient for good performance, neither of them are necessary. We present\nMLP-Mixer, an architecture based exclusively on multi-layer perceptrons (MLPs).\nMLP-Mixer contains two types of layers: one with MLPs applied independently to\nimage patches (i.e. \"mixing\" the per-location features), and one with MLPs\napplied across patches (i.e. \"mixing\" spatial information). When trained on\nlarge datasets, or with modern regularization schemes, MLP-Mixer attains\ncompetitive scores on image classification benchmarks, with pre-training and\ninference cost comparable to state-of-the-art models. We hope that these\nresults spark further research beyond the realms of well established CNNs and\nTransformers.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 16:17:21 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 12:48:26 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 09:50:52 GMT"}, {"version": "v4", "created": "Fri, 11 Jun 2021 09:36:50 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Tolstikhin", "Ilya", ""], ["Houlsby", "Neil", ""], ["Kolesnikov", "Alexander", ""], ["Beyer", "Lucas", ""], ["Zhai", "Xiaohua", ""], ["Unterthiner", "Thomas", ""], ["Yung", "Jessica", ""], ["Steiner", "Andreas", ""], ["Keysers", "Daniel", ""], ["Uszkoreit", "Jakob", ""], ["Lucic", "Mario", ""], ["Dosovitskiy", "Alexey", ""]]}, {"id": "2105.01603", "submitter": "Lifang He", "authors": "Sicong Che, Hao Peng, Lichao Sun, Yong Chen, Lifang He", "title": "Federated Multi-View Learning for Private Medical Data Integration and\n  Analysis", "comments": "22 pages, 6 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with the rapid expansion of information technology and digitalization\nof health data, there is an increasing concern on maintaining data privacy\nwhile garnering the benefits in medical field. Two critical challenges are\nidentified: Firstly, medical data is naturally distributed across multiple\nlocal sites, making it difficult to collectively train machine learning models\nwithout data leakage. Secondly, in medical applications, data are often\ncollected from different sources and views, resulting in heterogeneity and\ncomplexity that requires reconciliation. This paper aims to provide a generic\nFederated Multi-View Learning (FedMV) framework for multi-view data leakage\nprevention, which is based on different types of local data availability and\nenables to accommodate two types of problems: Vertical Federated Multi-View\nLearning (V-FedMV) and Horizontal Federated Multi-View Learning (H-FedMV). We\nexperimented with real-world keyboard data collected from BiAffect study. The\nresults demonstrated that the proposed FedMV approach can make full use of\nmulti-view data in a privacy-preserving way, and both V-FedMV and H-FedMV\nmethods perform better than their single-view and pairwise counterparts.\nBesides, the proposed model can be easily adapted to deal with multi-view\nsequential data in a federated environment, which has been modeled and\nexperimentally studied. To the best of our knowledge, this framework is the\nfirst to consider both vertical and horizontal diversification in the\nmulti-view setting, as well as their sequential federated learning.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 16:23:25 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Che", "Sicong", ""], ["Peng", "Hao", ""], ["Sun", "Lichao", ""], ["Chen", "Yong", ""], ["He", "Lifang", ""]]}, {"id": "2105.01620", "submitter": "Lixin Zou", "authors": "Lixin Zou, Long Xia, Linfang Hou, Xiangyu Zhao, and Dawei Yin", "title": "Data-Efficient Reinforcement Learning for Malaria Control", "comments": "7 pages, 4 figures, IJCAI 2021 Accepted Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sequential decision-making under cost-sensitive tasks is prohibitively\ndaunting, especially for the problem that has a significant impact on people's\ndaily lives, such as malaria control, treatment recommendation. The main\nchallenge faced by policymakers is to learn a policy from scratch by\ninteracting with a complex environment in a few trials. This work introduces a\npractical, data-efficient policy learning method, named Variance-Bonus Monte\nCarlo Tree Search~(VB-MCTS), which can copy with very little data and\nfacilitate learning from scratch in only a few trials. Specifically, the\nsolution is a model-based reinforcement learning method. To avoid model bias,\nwe apply Gaussian Process~(GP) regression to estimate the transitions\nexplicitly. With the GP world model, we propose a variance-bonus reward to\nmeasure the uncertainty about the world. Adding the reward to the planning with\nMCTS can result in more efficient and effective exploration. Furthermore, the\nderived polynomial sample complexity indicates that VB-MCTS is sample\nefficient. Finally, outstanding performance on a competitive world-level RL\ncompetition and extensive experimental results verify its advantage over the\nstate-of-the-art on the challenging malaria control task.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 16:54:16 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 04:19:07 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Zou", "Lixin", ""], ["Xia", "Long", ""], ["Hou", "Linfang", ""], ["Zhao", "Xiangyu", ""], ["Yin", "Dawei", ""]]}, {"id": "2105.01648", "submitter": "Robert Tjarko Lange", "authors": "Marc Aurel Vischer, Robert Tjarko Lange, Henning Sprekeler", "title": "On Lottery Tickets and Minimal Task Representations in Deep\n  Reinforcement Learning", "comments": "15 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The lottery ticket hypothesis questions the role of overparameterization in\nsupervised deep learning. But how is the performance of winning lottery tickets\naffected by the distributional shift inherent to reinforcement learning\nproblems? In this work, we address this question by comparing sparse agents who\nhave to address the non-stationarity of the exploration-exploitation problem\nwith supervised agents trained to imitate an expert. We show that feed-forward\nnetworks trained via reinforcement learning and imitation learning can be\npruned to the same level of sparsity, suggesting that the distributional shift\nhas a limited impact on the size of winning tickets. Using a set of carefully\ndesigned baseline conditions, we find that the majority of the lottery ticket\neffect in both learning paradigms can be attributed to the identified mask\nrather than the weight initialization. The input layer mask selectively prunes\nentire input dimensions that turn out to be irrelevant for the task at hand. At\na moderate level of sparsity the mask identified by iterative magnitude pruning\nyields minimal task-relevant representations, i.e., an interpretable inductive\nbias. Finally, we propose a simple initialization rescaling which promotes the\nrobust identification of sparse task representations in low-dimensional control\ntasks.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 17:47:39 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 04:24:37 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Vischer", "Marc Aurel", ""], ["Lange", "Robert Tjarko", ""], ["Sprekeler", "Henning", ""]]}, {"id": "2105.01652", "submitter": "Sai Saketh Rambhatla", "authors": "Sai Saketh Rambhatla and Rama Chellappa and Abhinav Shrivastava", "title": "The Pursuit of Knowledge: Discovering and Localizing Novel Categories\n  using Dual Memory", "comments": "Minor changes to table comments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle object category discovery, which is the problem of discovering and\nlocalizing novel objects in a large unlabeled dataset. While existing methods\nshow results on datasets with less cluttered scenes and fewer object instances\nper image, we present our results on the challenging COCO dataset. Moreover, we\nargue that, rather than discovering new categories from scratch, discovery\nalgorithms can benefit from identifying what is already known and focusing\ntheir attention on the unknown. We propose a method to use prior knowledge\nabout certain object categories to discover new categories by leveraging two\nmemory modules, namely Working and Semantic memory. We show the performance of\nour detector on the COCO minival dataset to demonstrate its in-the-wild\ncapabilities.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 17:55:59 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 01:23:56 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Rambhatla", "Sai Saketh", ""], ["Chellappa", "Rama", ""], ["Shrivastava", "Abhinav", ""]]}, {"id": "2105.01688", "submitter": "Anusua Trivedi", "authors": "Anusua Trivedi, Mohit Jain, Nikhil Kumar Gupta, Markus Hinsche,\n  Prashant Singh, Markus Matiaschek, Tristan Behrens, Mirco Militeri, Cameron\n  Birge, Shivangi Kaushik, Archisman Mohapatra, Rita Chatterjee, Rahul Dodhia,\n  Juan Lavista Ferres", "title": "Height Estimation of Children under Five Years using Depth Images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Malnutrition is a global health crisis and is the leading cause of death\namong children under five. Detecting malnutrition requires anthropometric\nmeasurements of weight, height, and middle-upper arm circumference. However,\nmeasuring them accurately is a challenge, especially in the global south, due\nto limited resources. In this work, we propose a CNN-based approach to estimate\nthe height of standing children under five years from depth images collected\nusing a smart-phone. According to the SMART Methodology Manual [5], the\nacceptable accuracy for height is less than 1.4 cm. On training our deep\nlearning model on 87131 depth images, our model achieved an average mean\nabsolute error of 1.64% on 57064 test images. For 70.3% test images, we\nestimated height accurately within the acceptable 1.4 cm range. Thus, our\nproposed solution can accurately detect stunting (low height-for-age) in\nstanding children below five years of age.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 18:15:57 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Trivedi", "Anusua", ""], ["Jain", "Mohit", ""], ["Gupta", "Nikhil Kumar", ""], ["Hinsche", "Markus", ""], ["Singh", "Prashant", ""], ["Matiaschek", "Markus", ""], ["Behrens", "Tristan", ""], ["Militeri", "Mirco", ""], ["Birge", "Cameron", ""], ["Kaushik", "Shivangi", ""], ["Mohapatra", "Archisman", ""], ["Chatterjee", "Rita", ""], ["Dodhia", "Rahul", ""], ["Ferres", "Juan Lavista", ""]]}, {"id": "2105.01736", "submitter": "Fei Wang", "authors": "Fei Wang, Kexuan Sun, Muhao Chen, Jay Pujara, Pedro Szekely", "title": "Retrieving Complex Tables with Multi-Granular Graph Representation\n  Learning", "comments": "Accepted by SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462909", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The task of natural language table retrieval (NLTR) seeks to retrieve\nsemantically relevant tables based on natural language queries. Existing\nlearning systems for this task often treat tables as plain text based on the\nassumption that tables are structured as dataframes. However, tables can have\ncomplex layouts which indicate diverse dependencies between subtable\nstructures, such as nested headers. As a result, queries may refer to different\nspans of relevant content that is distributed across these structures.\nMoreover, such systems fail to generalize to novel scenarios beyond those seen\nin the training set. Prior methods are still distant from a generalizable\nsolution to the NLTR problem, as they fall short in handling complex table\nlayouts or queries over multiple granularities. To address these issues, we\npropose Graph-based Table Retrieval (GTR), a generalizable NLTR framework with\nmulti-granular graph representation learning. In our framework, a table is\nfirst converted into a tabular graph, with cell nodes, row nodes and column\nnodes to capture content at different granularities. Then the tabular graph is\ninput to a Graph Transformer model that can capture both table cell content and\nthe layout structures. To enhance the robustness and generalizability of the\nmodel, we further incorporate a self-supervised pre-training task based on\ngraph-context matching. Experimental results on two benchmarks show that our\nmethod leads to significant improvements over the current state-of-the-art\nsystems. Further experiments demonstrate promising performance of our method on\ncross-dataset generalization, and enhanced capability of handling complex\ntables and fulfilling diverse query intents. Code and data are available at\nhttps://github.com/FeiWang96/GTR.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 20:19:03 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Wang", "Fei", ""], ["Sun", "Kexuan", ""], ["Chen", "Muhao", ""], ["Pujara", "Jay", ""], ["Szekely", "Pedro", ""]]}, {"id": "2105.01774", "submitter": "Lily Xu", "authors": "Elizabeth Bondi, Lily Xu, Diana Acosta-Navas, and Jackson A. Killian", "title": "Envisioning Communities: A Participatory Approach Towards AI for Social\n  Good", "comments": "Bondi and Xu Equal contribution. 12 pages, 5 figures. Accepted at the\n  Fourth AAAI/ACM Conference on Artificial Intelligence, Ethics, and Society\n  (AIES-21)", "journal-ref": null, "doi": "10.1145/3461702.3462612", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in artificial intelligence (AI) for social good presupposes some\ndefinition of social good, but potential definitions have been seldom suggested\nand never agreed upon. The normative question of what AI for social good\nresearch should be \"for\" is not thoughtfully elaborated, or is frequently\naddressed with a utilitarian outlook that prioritizes the needs of the majority\nover those who have been historically marginalized, brushing aside realities of\ninjustice and inequity. We argue that AI for social good ought to be assessed\nby the communities that the AI system will impact, using as a guide the\ncapabilities approach, a framework to measure the ability of different policies\nto improve human welfare equity. Furthermore, we lay out how AI research has\nthe potential to catalyze social progress by expanding and equalizing\ncapabilities. We show how the capabilities approach aligns with a participatory\napproach for the design and implementation of AI for social good research in a\nframework we introduce called PACT, in which community members affected should\nbe brought in as partners and their input prioritized throughout the project.\nWe conclude by providing an incomplete set of guiding questions for carrying\nout such participatory AI research in a way that elicits and respects a\ncommunity's own definition of social good.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 21:40:04 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 15:21:10 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Bondi", "Elizabeth", ""], ["Xu", "Lily", ""], ["Acosta-Navas", "Diana", ""], ["Killian", "Jackson A.", ""]]}, {"id": "2105.01798", "submitter": "Emna Baccour", "authors": "Emna Baccour, Naram Mhaisen, Alaa Awad Abdellatif, Aiman Erbad, Amr\n  Mohamed, Mounir Hamdi, Mohsen Guizani", "title": "Pervasive AI for IoT Applications: Resource-efficient Distributed\n  Artificial Intelligence", "comments": "Survey paper submitted to IEEE COMSAT", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial intelligence (AI) has witnessed a substantial breakthrough in a\nvariety of Internet of Things (IoT) applications and services, spanning from\nrecommendation systems to robotics control and military surveillance. This is\ndriven by the easier access to sensory data and the enormous scale of\npervasive/ubiquitous devices that generate zettabytes (ZB) of real-time data\nstreams. Designing accurate models using such data streams, to predict future\ninsights and revolutionize the decision-taking process, inaugurates pervasive\nsystems as a worthy paradigm for a better quality-of-life. The confluence of\npervasive computing and artificial intelligence, Pervasive AI, expanded the\nrole of ubiquitous IoT systems from mainly data collection to executing\ndistributed computations with a promising alternative to centralized learning,\npresenting various challenges. In this context, a wise cooperation and resource\nscheduling should be envisaged among IoT devices (e.g., smartphones, smart\nvehicles) and infrastructure (e.g. edge nodes, and base stations) to avoid\ncommunication and computation overheads and ensure maximum performance. In this\npaper, we conduct a comprehensive survey of the recent techniques developed to\novercome these resource challenges in pervasive AI systems. Specifically, we\nfirst present an overview of the pervasive computing, its architecture, and its\nintersection with artificial intelligence. We then review the background,\napplications and performance metrics of AI, particularly Deep Learning (DL) and\nonline learning, running in a ubiquitous system. Next, we provide a deep\nliterature review of communication-efficient techniques, from both algorithmic\nand system perspectives, of distributed inference, training and online learning\ntasks across the combination of IoT devices, edge devices and cloud servers.\nFinally, we discuss our future vision and research challenges.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 23:42:06 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Baccour", "Emna", ""], ["Mhaisen", "Naram", ""], ["Abdellatif", "Alaa Awad", ""], ["Erbad", "Aiman", ""], ["Mohamed", "Amr", ""], ["Hamdi", "Mounir", ""], ["Guizani", "Mohsen", ""]]}, {"id": "2105.01799", "submitter": "Aly El Gamal", "authors": "Shakti N. Wadekar, Benjamin J. Schwartz, Shyam S. Kannan, Manuel Mar,\n  Rohan Kumar Manna, Vishnu Chellapandi, Daniel J. Gonzalez, Aly El Gamal", "title": "Towards End-to-End Deep Learning for Autonomous Racing: On Data\n  Collection and a Unified Architecture for Steering and Throttle Prediction", "comments": "6 pages, 10 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Networks (DNNs) which are trained end-to-end have been\nsuccessfully applied to solve complex problems that we have not been able to\nsolve in past decades. Autonomous driving is one of the most complex problems\nwhich is yet to be completely solved and autonomous racing adds more complexity\nand exciting challenges to this problem. Towards the challenge of applying\nend-to-end learning to autonomous racing, this paper shows results on two\naspects: (1) Analyzing the relationship between the driving data used for\ntraining and the maximum speed at which the DNN can be successfully applied for\npredicting steering angle, (2) Neural network architecture and training\nmethodology for learning steering and throttle without any feedback or\nrecurrent connections.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 23:44:11 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Wadekar", "Shakti N.", ""], ["Schwartz", "Benjamin J.", ""], ["Kannan", "Shyam S.", ""], ["Mar", "Manuel", ""], ["Manna", "Rohan Kumar", ""], ["Chellapandi", "Vishnu", ""], ["Gonzalez", "Daniel J.", ""], ["Gamal", "Aly El", ""]]}, {"id": "2105.01820", "submitter": "Qi Dai", "authors": "Qi Dai, Di Shen, Jinhong Wang, Suzhou Huang and Dimitar Filev", "title": "Calibration of Human Driving Behavior and Preference Using Naturalistic\n  Traffic Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Understanding human driving behaviors quantitatively is critical even in the\nera when connected and autonomous vehicles and smart infrastructure are\nbecoming ever more prevalent. This is particularly so as that mixed traffic\nsettings, where autonomous vehicles and human driven vehicles co-exist, are\nexpected to persist for quite some time. Towards this end it is necessary that\nwe have a comprehensive modeling framework for decision-making within which\nhuman driving preferences can be inferred statistically from observed driving\nbehaviors in realistic and naturalistic traffic settings. Leveraging a recently\nproposed computational framework for smart vehicles in a smart world using\nmulti-agent based simulation and optimization, we first recapitulate how the\nforward problem of driving decision-making is modeled as a state space model.\nWe then show how the model can be inverted to estimate driver preferences from\nnaturalistic traffic data using the standard Kalman filter technique. We\nexplicitly illustrate our approach using the vehicle trajectory data from\nSugiyama experiment that was originally meant to demonstrate how stop-and-go\nshockwave can arise spontaneously without bottlenecks. Not only the estimated\nstate filter can fit the observed data well for each individual vehicle, the\ninferred utility functions can also re-produce quantitatively similar pattern\nof the observed collective behaviors. One distinct advantage of our approach is\nthe drastically reduced computational burden. This is possible because our\nforward model treats driving decision process, which is intrinsically dynamic\nwith multi-agent interactions, as a sequence of independent static optimization\nproblems contingent on the state with a finite look ahead anticipation.\nConsequently we can practically sidestep solving an interacting dynamic\ninversion problem that would have been much more computationally demanding.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 01:20:03 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Dai", "Qi", ""], ["Shen", "Di", ""], ["Wang", "Jinhong", ""], ["Huang", "Suzhou", ""], ["Filev", "Dimitar", ""]]}, {"id": "2105.01846", "submitter": "Xianbiao Qi", "authors": "Yelin He and Xianbiao Qi and Jiaquan Ye and Peng Gao and Yihao Chen\n  and Bingcong Li and Xin Tang and Rong Xiao", "title": "PingAn-VCGroup's Solution for ICDAR 2021 Competition on Scientific Table\n  Image Recognition to Latex", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our solution for the ICDAR 2021 Competition on Scientific\nTable Image Recognition to LaTeX. This competition has two sub-tasks: Table\nStructure Reconstruction (TSR) and Table Content Reconstruction (TCR). We treat\nboth sub-tasks as two individual image-to-sequence recognition problems. We\nleverage our previously proposed algorithm MASTER \\cite{lu2019master}, which is\noriginally proposed for scene text recognition. We optimize the MASTER model\nfrom several perspectives: network structure, optimizer, normalization method,\npre-trained model, resolution of input image, data augmentation, and model\nensemble. Our method achieves 0.7444 Exact Match and 0.8765 Exact Match @95\\%\non the TSR task, and obtains 0.5586 Exact Match and 0.7386 Exact Match 95\\% on\nthe TCR task.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 03:15:48 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["He", "Yelin", ""], ["Qi", "Xianbiao", ""], ["Ye", "Jiaquan", ""], ["Gao", "Peng", ""], ["Chen", "Yihao", ""], ["Li", "Bingcong", ""], ["Tang", "Xin", ""], ["Xiao", "Rong", ""]]}, {"id": "2105.01848", "submitter": "Xianbiao Qi", "authors": "Jiaquan Ye and Xianbiao Qi and Yelin He and Yihao Chen and Dengyi Gu\n  and Peng Gao and Rong Xiao", "title": "PingAn-VCGroup's Solution for ICDAR 2021 Competition on Scientific\n  Literature Parsing Task B: Table Recognition to HTML", "comments": "8 Pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our solution for ICDAR 2021 competition on scientific\nliterature parsing taskB: table recognition to HTML. In our method, we divide\nthe table content recognition task into foursub-tasks: table structure\nrecognition, text line detection, text line recognition, and box assignment.Our\ntable structure recognition algorithm is customized based on MASTER [1], a\nrobust image textrecognition algorithm. PSENet [2] is used to detect each text\nline in the table image. For text linerecognition, our model is also built on\nMASTER. Finally, in the box assignment phase, we associatedthe text boxes\ndetected by PSENet with the structure item reconstructed by table structure\nprediction,and fill the recognized content of the text line into the\ncorresponding item. Our proposed methodachieves a 96.84% TEDS score on 9,115\nvalidation samples in the development phase, and a 96.32%TEDS score on 9,064\nsamples in the final evaluation phase.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 03:20:26 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Ye", "Jiaquan", ""], ["Qi", "Xianbiao", ""], ["He", "Yelin", ""], ["Chen", "Yihao", ""], ["Gu", "Dengyi", ""], ["Gao", "Peng", ""], ["Xiao", "Rong", ""]]}, {"id": "2105.01875", "submitter": "Se Jung Kwon", "authors": "Dongsoo Lee, Se Jung Kwon, Byeongwook Kim, Jeongin Yun, Baeseong Park,\n  Yongkweon Jeon", "title": "Modulating Regularization Frequency for Efficient Compression-Aware\n  Model Training", "comments": "arXiv admin note: text overlap with arXiv:1905.10145", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While model compression is increasingly important because of large neural\nnetwork size, compression-aware training is challenging as it needs\nsophisticated model modifications and longer training time.In this paper, we\nintroduce regularization frequency (i.e., how often compression is performed\nduring training) as a new regularization technique for a practical and\nefficient compression-aware training method. For various regularization\ntechniques, such as weight decay and dropout, optimizing the regularization\nstrength is crucial to improve generalization in Deep Neural Networks (DNNs).\nWhile model compression also demands the right amount of regularization, the\nregularization strength incurred by model compression has been controlled only\nby compression ratio. Throughout various experiments, we show that\nregularization frequency critically affects the regularization strength of\nmodel compression. Combining regularization frequency and compression ratio,\nthe amount of weight updates by model compression per mini-batch can be\noptimized to achieve the best model accuracy. Modulating regularization\nfrequency is implemented by occasional model compression while conventional\ncompression-aware training is usually performed for every mini-batch.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 05:44:15 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Lee", "Dongsoo", ""], ["Kwon", "Se Jung", ""], ["Kim", "Byeongwook", ""], ["Yun", "Jeongin", ""], ["Park", "Baeseong", ""], ["Jeon", "Yongkweon", ""]]}, {"id": "2105.01876", "submitter": "Chaoqi Yang", "authors": "Chaoqi Yang, Cao Xiao, Lucas Glass, Jimeng Sun", "title": "Change Matters: Medication Change Prediction with Recurrent Residual\n  Networks", "comments": "Accepted in IJCAI'21, this is the long version with appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning is revolutionizing predictive healthcare, including\nrecommending medications to patients with complex health conditions. Existing\napproaches focus on predicting all medications for the current visit, which\noften overlaps with medications from previous visits. A more clinically\nrelevant task is to identify medication changes.\n  In this paper, we propose a new recurrent residual network, named MICRON, for\nmedication change prediction. MICRON takes the changes in patient health\nrecords as input and learns to update a hidden medication vector and the\nmedication set recurrently with a reconstruction design. The medication vector\nis like the memory cell that encodes longitudinal information of medications.\nUnlike traditional methods that require the entire patient history for\nprediction, MICRON has a residual-based inference that allows for sequential\nupdating based only on new patient features (e.g., new diagnoses in the recent\nvisit) more efficiently.\n  We evaluated MICRON on real inpatient and outpatient datasets. MICRON\nachieves 3.5% and 7.8% relative improvements over the best baseline in F1\nscore, respectively. MICRON also requires fewer parameters, which significantly\nreduces the training time to 38.3s per epoch with 1.5x speed-up.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 05:51:30 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Yang", "Chaoqi", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas", ""], ["Sun", "Jimeng", ""]]}, {"id": "2105.01882", "submitter": "Gautam Tata", "authors": "Gautam Tata, Sarah-Jeanne Royer, Olivier Poirion and Jay Lowe", "title": "DeepPlastic: A Novel Approach to Detecting Epipelagic Bound Plastic\n  Using Deep Visual Models", "comments": "8 Pages, 6 Figures, 2 Tables - Added Paragraph for Code Availability\n  - Submitted preprint to Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The quantification of positively buoyant marine plastic debris is critical to\nunderstanding how concentrations of trash from across the world's ocean and\nidentifying high concentration garbage hotspots in dire need of trash removal.\nCurrently, the most common monitoring method to quantify floating plastic\nrequires the use of a manta trawl. Techniques requiring manta trawls (or\nsimilar surface collection devices) utilize physical removal of marine plastic\ndebris as the first step and then analyze collected samples as a second step.\nThe need for physical removal before analysis incurs high costs and requires\nintensive labor preventing scalable deployment of a real-time marine plastic\nmonitoring service across the entirety of Earth's ocean bodies. Without better\nmonitoring and sampling methods, the total impact of plastic pollution on the\nenvironment as a whole, and details of impact within specific oceanic regions,\nwill remain unknown. This study presents a highly scalable workflow that\nutilizes images captured within the epipelagic layer of the ocean as an input.\nIt produces real-time quantification of marine plastic debris for accurate\nquantification and physical removal. The workflow includes creating and\npreprocessing a domain-specific dataset, building an object detection model\nutilizing a deep neural network, and evaluating the model's performance.\nYOLOv5-S was the best performing model, which operates at a Mean Average\nPrecision (mAP) of 0.851 and an F1-Score of 0.89 while maintaining\nnear-real-time speed.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 06:04:26 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 21:54:01 GMT"}, {"version": "v3", "created": "Sat, 24 Jul 2021 06:50:10 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Tata", "Gautam", ""], ["Royer", "Sarah-Jeanne", ""], ["Poirion", "Olivier", ""], ["Lowe", "Jay", ""]]}, {"id": "2105.01883", "submitter": "Xiaohan Ding", "authors": "Xiaohan Ding, Xiangyu Zhang, Jungong Han, Guiguang Ding", "title": "RepMLP: Re-parameterizing Convolutions into Fully-connected Layers for\n  Image Recognition", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose RepMLP, a multi-layer-perceptron-style neural network building\nblock for image recognition, which is composed of a series of fully-connected\n(FC) layers. Compared to convolutional layers, FC layers are more efficient,\nbetter at modeling the long-range dependencies and positional patterns, but\nworse at capturing the local structures, hence usually less favored for image\nrecognition. We propose a structural re-parameterization technique that adds\nlocal prior into an FC to make it powerful for image recognition. Specifically,\nwe construct convolutional layers inside a RepMLP during training and merge\nthem into the FC for inference. On CIFAR, a simple pure-MLP model shows\nperformance very close to CNN. By inserting RepMLP in traditional CNN, we\nimprove ResNets by 1.8% accuracy on ImageNet, 2.9% for face recognition, and\n2.3% mIoU on Cityscapes with lower FLOPs. Our intriguing findings highlight\nthat combining the global representational capacity and positional perception\nof FC with the local prior of convolution can improve the performance of neural\nnetwork with faster speed on both the tasks with translation invariance (e.g.,\nsemantic segmentation) and those with aligned images and positional patterns\n(e.g., face recognition). The code and models are available at\nhttps://github.com/DingXiaoH/RepMLP.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 06:17:40 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Ding", "Xiaohan", ""], ["Zhang", "Xiangyu", ""], ["Han", "Jungong", ""], ["Ding", "Guiguang", ""]]}, {"id": "2105.01893", "submitter": "Zhenxin Yang", "authors": "Zhengxin Yang", "title": "Full-Sentence Models Perform Better in Simultaneous Translation Using\n  the Information Enhanced Decoding Strategy", "comments": "8 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simultaneous translation, which starts translating each sentence after\nreceiving only a few words in source sentence, has a vital role in many\nscenarios. Although the previous prefix-to-prefix framework is considered\nsuitable for simultaneous translation and achieves good performance, it still\nhas two inevitable drawbacks: the high computational resource costs caused by\nthe need to train a separate model for each latency $k$ and the insufficient\nability to encode information because each target token can only attend to a\nspecific source prefix. We propose a novel framework that adopts a simple but\neffective decoding strategy which is designed for full-sentence models. Within\nthis framework, training a single full-sentence model can achieve arbitrary\ngiven latency and save computational resources. Besides, with the competence of\nthe full-sentence model to encode the whole sentence, our decoding strategy can\nenhance the information maintained in the decoded states in real time.\nExperimental results show that our method achieves better translation quality\nthan baselines on 4 directions: Zh$\\rightarrow$En, En$\\rightarrow$Ro and\nEn$\\leftrightarrow$De.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 07:03:41 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Yang", "Zhengxin", ""]]}, {"id": "2105.01904", "submitter": "Yaron Shoham", "authors": "Yaron Shoham, Gal Elidan", "title": "Solving Sokoban with forward-backward reinforcement learning", "comments": "To be published in SoCS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite seminal advances in reinforcement learning in recent years, many\ndomains where the rewards are sparse, e.g. given only at task completion,\nremain quite challenging. In such cases, it can be beneficial to tackle the\ntask both from its beginning and end, and make the two ends meet. Existing\napproaches that do so, however, are not effective in the common scenario where\nthe strategy needed near the end goal is very different from the one that is\neffective earlier on.\n  In this work we propose a novel RL approach for such settings. In short, we\nfirst train a backward-looking agent with a simple relaxed goal, and then\naugment the state representation of the forward-looking agent with\nstraightforward hint features. This allows the learned forward agent to\nleverage information from backward plans, without mimicking their policy.\n  We demonstrate the efficacy of our approach on the challenging game of\nSokoban, where we substantially surpass learned solvers that generalize across\nlevels, and are competitive with SOTA performance of the best highly-crafted\nsystems. Impressively, we achieve these results while learning from a small\nnumber of practice levels and using simple RL techniques.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 07:37:57 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 15:15:35 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Shoham", "Yaron", ""], ["Elidan", "Gal", ""]]}, {"id": "2105.01925", "submitter": "Simon Razniewski", "authors": "Simon Razniewski", "title": "Commonsense Knowledge Base Construction in the Age of Big Data", "comments": "Manuscript for the cancelled BTW 2021 demo track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compiling commonsense knowledge is traditionally an AI topic approached by\nmanual labor. Recent advances in web data processing have enabled automated\napproaches. In this demonstration we will showcase three systems for automated\ncommonsense knowledge base construction, highlighting each time one aspect of\nspecific interest to the data management community. (i) We use Quasimodo to\nillustrate knowledge extraction systems engineering, (ii) Dice to illustrate\nthe role that schema constraints play in cleaning fuzzy commonsense knowledge,\nand (iii) Ascent to illustrate the relevance of conceptual modelling. The demos\nare available online at https://quasimodo.r2.enst.fr,\nhttps://dice.mpi-inf.mpg.de and ascent.mpi-inf.mpg.de.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 08:27:36 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Razniewski", "Simon", ""]]}, {"id": "2105.01929", "submitter": "Jo\\v{z}e Ro\\v{z}anec", "authors": "Jo\\v{z}e M. Ro\\v{z}anec, Patrik Zajec, Klemen Kenda, Inna Novalija,\n  Bla\\v{z} Fortuna, Dunja Mladeni\\'c", "title": "XAI-KG: knowledge graph to support XAI and decision-making in\n  manufacturing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing adoption of artificial intelligence requires accurate\nforecasts and means to understand the reasoning of artificial intelligence\nmodels behind such a forecast. Explainable Artificial Intelligence (XAI) aims\nto provide cues for why a model issued a certain prediction. Such cues are of\nutmost importance to decision-making since they provide insights on the\nfeatures that influenced most certain forecasts and let the user decide if the\nforecast can be trusted. Though many techniques were developed to explain\nblack-box models, little research was done on assessing the quality of those\nexplanations and their influence on decision-making. We propose an ontology and\nknowledge graph to support collecting feedback regarding forecasts, forecast\nexplanations, recommended decision-making options, and user actions. This way,\nwe provide means to improve forecasting models, explanations, and\nrecommendations of decision-making options. We tailor the knowledge graph for\nthe domain of demand forecasting and validate it on real-world data.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 08:42:07 GMT"}, {"version": "v2", "created": "Thu, 6 May 2021 03:41:32 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Ro\u017eanec", "Jo\u017ee M.", ""], ["Zajec", "Patrik", ""], ["Kenda", "Klemen", ""], ["Novalija", "Inna", ""], ["Fortuna", "Bla\u017e", ""], ["Mladeni\u0107", "Dunja", ""]]}, {"id": "2105.01974", "submitter": "Marco Valentino", "authors": "Marco Valentino, Ian Pratt-Hartmann, Andr\\'e Freitas", "title": "Do Natural Language Explanations Represent Valid Logical Arguments?\n  Verifying Entailment in Explainable NLI Gold Standards", "comments": "To appear in IWCS 2021 proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emerging line of research in Explainable NLP is the creation of datasets\nenriched with human-annotated explanations and rationales, used to build and\nevaluate models with step-wise inference and explanation generation\ncapabilities. While human-annotated explanations are used as ground-truth for\nthe inference, there is a lack of systematic assessment of their consistency\nand rigour. In an attempt to provide a critical quality assessment of\nExplanation Gold Standards (XGSs) for NLI, we propose a systematic annotation\nmethodology, named Explanation Entailment Verification (EEV), to quantify the\nlogical validity of human-annotated explanations. The application of EEV on\nthree mainstream datasets reveals the surprising conclusion that a majority of\nthe explanations, while appearing coherent on the surface, represent logically\ninvalid arguments, ranging from being incomplete to containing clearly\nidentifiable logical errors. This conclusion confirms that the inferential\nproperties of explanations are still poorly formalised and understood, and that\nadditional work on this line of research is necessary to improve the way\nExplanation Gold Standards are constructed.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 10:59:26 GMT"}, {"version": "v2", "created": "Sat, 15 May 2021 10:11:43 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Valentino", "Marco", ""], ["Pratt-Hartmann", "Ian", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "2105.01978", "submitter": "Huma Samin", "authors": "Huma Samin (1), Luis H. Garcia Paucar (1), Nelly Bencomo (1), Cesar M.\n  Carranza Hurtado (2), Erik M. Fredericks (3) ((1) SEA, Aston University,\n  Birmingham, UK, (2) Universidad Pontificia Cat\\'olica del Per\\'u, Lima,\n  Per\\'u, (3) Grand Valley State University, Michigan, USA)", "title": "RDMSim: An Exemplar for Evaluation and Comparison of Decision-Making\n  Techniques for Self-Adaptation", "comments": "Accepted at the 16th International Symposium on Software Engineering\n  for Adaptive and Self-Managing Systems (SEAMS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision-making for self-adaptation approaches need to address different\nchallenges, including the quantification of the uncertainty of events that\ncannot be foreseen in advance and their effects, and dealing with conflicting\nobjectives that inherently involve multi-objective decision making (e.g.,\navoiding costs vs. providing reliable service). To enable researchers to\nevaluate and compare decision-making techniques for self-adaptation, we present\nthe RDMSim exemplar. RDMSim enables researchers to evaluate and compare\ntechniques for decision-making under environmental uncertainty that support\nself-adaptation. The focus of the exemplar is on the domain problem related to\nRemote Data Mirroring, which gives opportunity to face the challenges described\nabove. RDMSim provides probe and effector components for easy integration with\nexternal adaptation managers, which are associated with decision-making\ntechniques and based on the MAPE-K loop. Specifically, the paper presents (i)\nRDMSim, a simulator for real-world experimentation, (ii) a set of realistic\nsimulation scenarios that can be used for experimentation and comparison\npurposes, (iii) data for the sake of comparison.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 11:03:16 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Samin", "Huma", ""], ["Paucar", "Luis H. Garcia", ""], ["Bencomo", "Nelly", ""], ["Hurtado", "Cesar M. Carranza", ""], ["Fredericks", "Erik M.", ""]]}, {"id": "2105.01984", "submitter": "Silverio Mart\\'inez-Fern\\'andez", "authors": "Silverio Mart\\'inez-Fern\\'andez, Justus Bogner, Xavier Franch, Marc\n  Oriol, Julien Siebert, Adam Trendowicz, Anna Maria Vollmer, Stefan Wagner", "title": "Software Engineering for AI-Based Systems: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AI-based systems are software systems with functionalities enabled by at\nleast one AI component (e.g., for image- and speech-recognition, and autonomous\ndriving). AI-based systems are becoming pervasive in society due to advances in\nAI. However, there is limited synthesized knowledge on Software Engineering\n(SE) approaches for building, operating, and maintaining AI-based systems. To\ncollect and analyze state-of-the-art knowledge about SE for AI-based systems,\nwe conducted a systematic mapping study. We considered 248 studies published\nbetween January 2010 and March 2020. SE for AI-based systems is an emerging\nresearch area, where more than 2/3 of the studies have been published since\n2018. The most studied properties of AI-based systems are dependability and\nsafety. We identified multiple SE approaches for AI-based systems, which we\nclassified according to the SWEBOK areas. Studies related to software testing\nand software quality are very prevalent, while areas like software maintenance\nseem neglected. Data-related issues are the most recurrent challenges. Our\nresults are valuable for: researchers, to quickly understand the state of the\nart and learn which topics need more research; practitioners, to learn about\nthe approaches and challenges that SE entails for AI-based systems; and,\neducators, to bridge the gap among SE and AI in their curricula.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 11:22:08 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Mart\u00ednez-Fern\u00e1ndez", "Silverio", ""], ["Bogner", "Justus", ""], ["Franch", "Xavier", ""], ["Oriol", "Marc", ""], ["Siebert", "Julien", ""], ["Trendowicz", "Adam", ""], ["Vollmer", "Anna Maria", ""], ["Wagner", "Stefan", ""]]}, {"id": "2105.01992", "submitter": "Yu Li", "authors": "Yu Li, Josh Arnold, Feifan Yan, Weiyan Shi and Zhou Yu", "title": "LEGOEval: An Open-Source Toolkit for Dialogue System Evaluation via\n  Crowdsourcing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present LEGOEval, an open-source toolkit that enables researchers to\neasily evaluate dialogue systems in a few lines of code using the online\ncrowdsource platform, Amazon Mechanical Turk. Compared to existing toolkits,\nLEGOEval features a flexible task design by providing a Python API that maps to\ncommonly used React.js interface components. Researchers can personalize their\nevaluation procedures easily with our built-in pages as if playing with LEGO\nblocks. Thus, LEGOEval provides a fast, consistent method for reproducing human\nevaluation results. Besides the flexible task design, LEGOEval also offers an\neasy API to review collected data.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 11:38:14 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Li", "Yu", ""], ["Arnold", "Josh", ""], ["Yan", "Feifan", ""], ["Shi", "Weiyan", ""], ["Yu", "Zhou", ""]]}, {"id": "2105.02001", "submitter": "Robert Alexander Marsden", "authors": "Robert A. Marsden, Alexander Bartler, Mario D\\\"obler, Bin Yang", "title": "Contrastive Learning and Self-Training for Unsupervised Domain\n  Adaptation in Semantic Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep convolutional neural networks have considerably improved\nstate-of-the-art results for semantic segmentation. Nevertheless, even modern\narchitectures lack the ability to generalize well to a test dataset that\noriginates from a different domain. To avoid the costly annotation of training\ndata for unseen domains, unsupervised domain adaptation (UDA) attempts to\nprovide efficient knowledge transfer from a labeled source domain to an\nunlabeled target domain. Previous work has mainly focused on minimizing the\ndiscrepancy between the two domains by using adversarial training or\nself-training. While adversarial training may fail to align the correct\nsemantic categories as it minimizes the discrepancy between the global\ndistributions, self-training raises the question of how to provide reliable\npseudo-labels. To align the correct semantic categories across domains, we\npropose a contrastive learning approach that adapts category-wise centroids\nacross domains. Furthermore, we extend our method with self-training, where we\nuse a memory-efficient temporal ensemble to generate consistent and reliable\npseudo-labels. Although both contrastive learning and self-training (CLST)\nthrough temporal ensembling enable knowledge transfer between two domains, it\nis their combination that leads to a symbiotic structure. We validate our\napproach on two domain adaptation benchmarks: GTA5 $\\rightarrow$ Cityscapes and\nSYNTHIA $\\rightarrow$ Cityscapes. Our method achieves better or comparable\nresults than the state-of-the-art. We will make the code publicly available.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 11:55:53 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Marsden", "Robert A.", ""], ["Bartler", "Alexander", ""], ["D\u00f6bler", "Mario", ""], ["Yang", "Bin", ""]]}, {"id": "2105.02019", "submitter": "Blesson Varghese", "authors": "Hyunho Ahn and Munkyu Lee and Cheol-Ho Hong and Blesson Varghese", "title": "ScissionLite: Accelerating Distributed Deep Neural Networks Using\n  Transfer Layer", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Industrial Internet of Things (IIoT) applications can benefit from leveraging\nedge computing. For example, applications underpinned by deep neural networks\n(DNN) models can be sliced and distributed across the IIoT device and the edge\nof the network for improving the overall performance of inference and for\nenhancing privacy of the input data, such as industrial product images.\nHowever, low network performance between IIoT devices and the edge is often a\nbottleneck. In this study, we develop ScissionLite, a holistic framework for\naccelerating distributed DNN inference using the Transfer Layer (TL). The TL is\na traffic-aware layer inserted between the optimal slicing point of a DNN model\nslice in order to decrease the outbound network traffic without a significant\naccuracy drop. For the TL, we implement a new lightweight down/upsampling\nnetwork for performance-limited IIoT devices. In ScissionLite, we develop\nScissionTL, the Preprocessor, and the Offloader for end-to-end activities for\ndeploying DNN slices with the TL. They decide the optimal slicing point of the\nDNN, prepare pre-trained DNN slices including the TL, and execute the DNN\nslices on an IIoT device and the edge. Employing the TL for the sliced DNN\nmodels has a negligible overhead. ScissionLite improves the inference latency\nby up to 16 and 2.8 times when compared to execution on the local device and an\nexisting state-of-the-art model slicing approach respectively.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 12:38:58 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Ahn", "Hyunho", ""], ["Lee", "Munkyu", ""], ["Hong", "Cheol-Ho", ""], ["Varghese", "Blesson", ""]]}, {"id": "2105.02027", "submitter": "Daniel Weber", "authors": "Daniel Weber and Clemens G\\\"uhmann", "title": "Non-Autoregressive vs Autoregressive Neural Networks for System\n  Identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of neural networks to non-linear dynamic system\nidentification tasks has a long history, which consists mostly of\nautoregressive approaches. Autoregression, the usage of the model outputs of\nprevious time steps, is a method of transferring a system state between time\nsteps, which is not necessary for modeling dynamic systems with modern neural\nnetwork structures, such as gated recurrent units (GRUs) and Temporal\nConvolutional Networks (TCNs). We compare the accuracy and execution\nperformance of autoregressive and non-autoregressive implementations of a GRU\nand TCN on the simulation task of three publicly available system\nidentification benchmarks. Our results show, that the non-autoregressive neural\nnetworks are significantly faster and at least as accurate as their\nautoregressive counterparts. Comparisons with other state-of-the-art black-box\nsystem identification methods show, that our implementation of the\nnon-autoregressive GRU is the best performing neural network-based system\nidentification method, and in the benchmarks without extrapolation, the best\nperforming black-box method.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 12:52:06 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Weber", "Daniel", ""], ["G\u00fchmann", "Clemens", ""]]}, {"id": "2105.02045", "submitter": "Zihao Wang", "authors": "Wang Zihao, Demarcy Thomas, Vandersteen Clair, Gnansia Dan, Raffaelli\n  Charles, Guevara Nicolas, Delingette Herv\\'e", "title": "Bayesian Logistic Shape Model Inference: application to cochlea image\n  segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating shape information is essential for the delineation of many\norgans and anatomical structures in medical images. While previous work has\nmainly focused on parametric spatial transformations applied on reference\ntemplate shapes, in this paper, we address the Bayesian inference of parametric\nshape models for segmenting medical images with the objective to provide\ninterpretable results. The proposed framework defines a likelihood appearance\nprobability and a prior label probability based on a generic shape function\nthrough a logistic function. A reference length parameter defined in the\nsigmoid controls the trade-off between shape and appearance information. The\ninference of shape parameters is performed within an Expectation-Maximisation\napproach where a Gauss-Newton optimization stage allows to provide an\napproximation of the posterior probability of shape parameters. This framework\nis applied to the segmentation of cochlea structures from clinical CT images\nconstrained by a 10 parameter shape model. It is evaluated on three different\ndatasets, one of which includes more than 200 patient images. The results show\nperformances comparable to supervised methods and better than previously\nproposed unsupervised ones. It also enables an analysis of parameter\ndistributions and the quantification of segmentation uncertainty including the\neffect of the shape model.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 13:21:42 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Zihao", "Wang", ""], ["Thomas", "Demarcy", ""], ["Clair", "Vandersteen", ""], ["Dan", "Gnansia", ""], ["Charles", "Raffaelli", ""], ["Nicolas", "Guevara", ""], ["Herv\u00e9", "Delingette", ""]]}, {"id": "2105.02055", "submitter": "Sneha Das", "authors": "Sneha Das and Nicole Nadine L{\\o}nfeldt and Anne Katrine Pagsberg and\n  Line H. Clemmensen", "title": "Towards Interpretable and Transferable Speech Emotion Recognition:\n  Latent Representation Based Analysis of Features, Methods and Corpora", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, speech emotion recognition (SER) has been used in wide\nranging applications, from healthcare to the commercial sector. In addition to\nsignal processing approaches, methods for SER now also use deep learning\ntechniques. However, generalizing over languages, corpora and recording\nconditions is still an open challenge in the field. Furthermore, due to the\nblack-box nature of deep learning algorithms, a newer challenge is the lack of\ninterpretation and transparency in the models and the decision making process.\nThis is critical when the SER systems are deployed in applications that\ninfluence human lives. In this work we address this gap by providing an\nin-depth analysis of the decision making process of the proposed SER system.\nTowards that end, we present low-complexity SER based on undercomplete- and\ndenoising- autoencoders that achieve an average classification accuracy of over\n55\\% for four-class emotion classification. Following this, we investigate the\nclustering of emotions in the latent space to understand the influence of the\ncorpora on the model behavior and to obtain a physical interpretation of the\nlatent embedding. Lastly, we explore the role of each input feature towards the\nperformance of the SER.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 13:47:39 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Das", "Sneha", ""], ["L\u00f8nfeldt", "Nicole Nadine", ""], ["Pagsberg", "Anne Katrine", ""], ["Clemmensen", "Line H.", ""]]}, {"id": "2105.02099", "submitter": "Franti\\v{s}ek Blahoudek", "authors": "Franti\\v{s}ek Blahoudek, Petr Novotn\\'y, Melkior Ornik, Pranay\n  Thangeda and Ufuk Topcu", "title": "Efficient Strategy Synthesis for MDPs with Resource Constraints", "comments": "16 pages, 9 figures, submited to IEEE Transactions on Automatic\n  Control, extended version of arXiv:2005.07227", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We consider qualitative strategy synthesis for the formalism called\nconsumption Markov decision processes. This formalism can model dynamics of an\nagents that operates under resource constraints in a stochastic environment.\nThe presented algorithms work in time polynomial with respect to the\nrepresentation of the model and they synthesize strategies ensuring that a\ngiven set of goal states will be reached (once or infinitely many times) with\nprobability 1 without resource exhaustion. In particular, when the amount of\nresource becomes too low to safely continue in the mission, the strategy\nchanges course of the agent towards one of a designated set of reload states\nwhere the agent replenishes the resource to full capacity; with sufficient\namount of resource, the agent attempts to fulfill the mission again.\n  We also present two heuristics that attempt to reduce expected time that the\nagent needs to fulfill the given mission, a parameter important in practical\nplanning. The presented algorithms were implemented and numerical examples\ndemonstrate (i) the effectiveness (in terms of computation time) of the\nplanning approach based on consumption Markov decision processes and (ii) the\npositive impact of the two heuristics on planning in a realistic example.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 14:59:30 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Blahoudek", "Franti\u0161ek", ""], ["Novotn\u00fd", "Petr", ""], ["Ornik", "Melkior", ""], ["Thangeda", "Pranay", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2105.02103", "submitter": "Evgeny Smirnov", "authors": "Evgeny Smirnov, Nikita Garaev, Vasiliy Galyuk", "title": "Prototype Memory for Large-scale Face Representation Learning", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Face representation learning using datasets with massive number of identities\nrequires appropriate training methods. Softmax-based approach, currently the\nstate-of-the-art in face recognition, in its usual \"full softmax\" form is not\nsuitable for datasets with millions of persons. Several methods, based on the\n\"sampled softmax\" approach, were proposed to remove this limitation. These\nmethods, however, have a set of disadvantages. One of them is a problem of\n\"prototype obsolescence\": classifier weights (prototypes) of the rarely sampled\nclasses, receive too scarce gradients and become outdated and detached from the\ncurrent encoder state, resulting in an incorrect training signals. This problem\nis especially serious in ultra-large-scale datasets. In this paper, we propose\na novel face representation learning model called Prototype Memory, which\nalleviates this problem and allows training on a dataset of any size. Prototype\nMemory consists of the limited-size memory module for storing recent class\nprototypes and employs a set of algorithms to update it in appropriate way. New\nclass prototypes are generated on the fly using exemplar embeddings in the\ncurrent mini-batch. These prototypes are enqueued to the memory and used in a\nrole of classifier weights for usual softmax classification-based training. To\nprevent obsolescence and keep the memory in close connection with encoder,\nprototypes are regularly refreshed, and oldest ones are dequeued and disposed.\nPrototype Memory is computationally efficient and independent of dataset size.\nIt can be used with various loss functions, hard example mining algorithms and\nencoder architectures. We prove the effectiveness of the proposed model by\nextensive experiments on popular face recognition benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 15:08:34 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Smirnov", "Evgeny", ""], ["Garaev", "Nikita", ""], ["Galyuk", "Vasiliy", ""]]}, {"id": "2105.02104", "submitter": "Lynton Ardizzone", "authors": "Lynton Ardizzone, Jakob Kruse, Carsten L\\\"uth, Niels Bracher, Carsten\n  Rother, Ullrich K\\\"othe", "title": "Conditional Invertible Neural Networks for Diverse Image-to-Image\n  Translation", "comments": "arXiv admin note: text overlap with arXiv:1907.02392", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new architecture called a conditional invertible neural\nnetwork (cINN), and use it to address the task of diverse image-to-image\ntranslation for natural images. This is not easily possible with existing INN\nmodels due to some fundamental limitations. The cINN combines the purely\ngenerative INN model with an unconstrained feed-forward network, which\nefficiently preprocesses the conditioning image into maximally informative\nfeatures. All parameters of a cINN are jointly optimized with a stable, maximum\nlikelihood-based training procedure. Even though INN-based models have received\nfar less attention in the literature than GANs, they have been shown to have\nsome remarkable properties absent in GANs, e.g. apparent immunity to mode\ncollapse. We find that our cINNs leverage these properties for image-to-image\ntranslation, demonstrated on day to night translation and image colorization.\nFurthermore, we take advantage of our bidirectional cINN architecture to\nexplore and manipulate emergent properties of the latent space, such as\nchanging the image style in an intuitive way.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 15:10:37 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Ardizzone", "Lynton", ""], ["Kruse", "Jakob", ""], ["L\u00fcth", "Carsten", ""], ["Bracher", "Niels", ""], ["Rother", "Carsten", ""], ["K\u00f6the", "Ullrich", ""]]}, {"id": "2105.02172", "submitter": "Robert R. Tucci", "authors": "Robert R. Tucci", "title": "Goodness of Causal Fit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a Goodness of Causal Fit (GCF) measure which depends on Pearl \"do\"\ninterventions. This is different from a measure of Goodness of Fit (GF), which\ndoes not use interventions. Given a DAG set ${\\cal G}$, to find a good $G\\in\n{\\cal G}$, we propose plotting $GCF(G)$ versus $GF(G)$ for all $G\\in {\\cal G}$,\nand finding a graph $G\\in {\\cal G}$ with a large amount of both types of\ngoodness.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 16:37:07 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Tucci", "Robert R.", ""]]}, {"id": "2105.02198", "submitter": "Tyler Millhouse", "authors": "Tyler Millhouse, Melanie Moses, Melanie Mitchell", "title": "Foundations of Intelligence in Natural and Artificial Systems: A\n  Workshop Report", "comments": "30 pages, 0 figures, workshop report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In March of 2021, the Santa Fe Institute hosted a workshop as part of its\nFoundations of Intelligence in Natural and Artificial Systems project. This\nproject seeks to advance the field of artificial intelligence by promoting\ninterdisciplinary research on the nature of intelligence. During the workshop,\nspeakers from diverse disciplines gathered to develop a taxonomy of\nintelligence, articulating their own understanding of intelligence and how\ntheir research has furthered that understanding. In this report, we summarize\nthe insights offered by each speaker and identify the themes that emerged\nduring the talks and subsequent discussions.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 17:11:58 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Millhouse", "Tyler", ""], ["Moses", "Melanie", ""], ["Mitchell", "Melanie", ""]]}, {"id": "2105.02209", "submitter": "Amirsaeed Yazdani", "authors": "Amirsaeed Yazdani, Tiantong Guo, Vishal Monga", "title": "Physically Inspired Dense Fusion Networks for Relighting", "comments": "Rank second in NTIRE 2021 One-to-one depth guided image relighting\n  challenge, accepted by CVPRW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image relighting has emerged as a problem of significant research interest\ninspired by augmented reality applications. Physics-based traditional methods,\nas well as black box deep learning models, have been developed. The existing\ndeep networks have exploited training to achieve a new state of the art;\nhowever, they may perform poorly when training is limited or does not represent\nproblem phenomenology, such as the addition or removal of dense shadows. We\npropose a model which enriches neural networks with physical insight. More\nprecisely, our method generates the relighted image with new illumination\nsettings via two different strategies and subsequently fuses them using a\nweight map (w). In the first strategy, our model predicts the material\nreflectance parameters (albedo) and illumination/geometry parameters of the\nscene (shading) for the relit image (we refer to this strategy as intrinsic\nimage decomposition (IID)). The second strategy is solely based on the black\nbox approach, where the model optimizes its weights based on the ground-truth\nimages and the loss terms in the training stage and generates the relit output\ndirectly (we refer to this strategy as direct). While our proposed method\napplies to both one-to-one and any-to-any relighting problems, for each case we\nintroduce problem-specific components that enrich the model performance: 1) For\none-to-one relighting we incorporate normal vectors of the surfaces in the\nscene to adjust gloss and shadows accordingly in the image. 2) For any-to-any\nrelighting, we propose an additional multiscale block to the architecture to\nenhance feature extraction. Experimental results on the VIDIT 2020 and the\nVIDIT 2021 dataset (used in the NTIRE 2021 relighting challenge) reveals that\nour proposal can outperform many state-of-the-art methods in terms of\nwell-known fidelity metrics and perceptual loss.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 17:33:45 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Yazdani", "Amirsaeed", ""], ["Guo", "Tiantong", ""], ["Monga", "Vishal", ""]]}, {"id": "2105.02264", "submitter": "Luca Buoncompagni", "authors": "Luca Buoncompagni, Syed Yusha Kareem and Fulvio Mastrogiovanni", "title": "Human Activity Recognition Models in Ontology Networks", "comments": "The paper has been accepted for publication in the IEEE Transactions\n  on Cybernetics journal on April 2021 and with DOI 10.1109/TCYB.2021.3073539.\n  It is an extension of arXiv:1707.03988v1 and it is related to the\n  arXiv:1809.08208v1 article. It contains 20 pages, 6 figures, 4 tables and 2\n  Appendices", "journal-ref": "IEEE Transactions on Cybernetics, 2021", "doi": "10.1109/TCYB.2021.3073539", "report-no": null, "categories": "cs.AI cs.LO cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present Arianna+, a framework to design networks of ontologies for\nrepresenting knowledge enabling smart homes to perform human activity\nrecognition online. In the network, nodes are ontologies allowing for various\ndata contextualisation, while edges are general-purpose computational\nprocedures elaborating data. Arianna+ provides a flexible interface between the\ninputs and outputs of procedures and statements, which are atomic\nrepresentations of ontological knowledge. Arianna+ schedules procedures on the\nbasis of events by employing logic-based reasoning, i.e., by checking the\nclassification of certain statements in the ontologies. Each procedure involves\ninput and output statements that are differently contextualised in the\nontologies based on specific prior knowledge. Arianna+ allows to design\nnetworks that encode data within multiple contexts and, as a reference\nscenario, we present a modular network based on a spatial context shared among\nall activities and a temporal context specialised for each activity to be\nrecognised. In the paper, we argue that a network of small ontologies is more\nintelligible and has a reduced computational load than a single ontology\nencoding the same knowledge. Arianna+ integrates in the same architecture\nheterogeneous data processing techniques, which may be better suited to\ndifferent contexts. Thus, we do not propose a new algorithmic approach to\nactivity recognition, instead, we focus on the architectural aspects for\naccommodating logic-based and data-driven activity models in a context-oriented\nway. Also, we discuss how to leverage data contextualisation and reasoning for\nactivity recognition, and to support an iterative development process driven by\ndomain experts.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 18:23:56 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Buoncompagni", "Luca", ""], ["Kareem", "Syed Yusha", ""], ["Mastrogiovanni", "Fulvio", ""]]}, {"id": "2105.02282", "submitter": "Zihao Wang", "authors": "Zihao Wang, Herv\\'e Delingette", "title": "Attention for Image Registration (AiR): an unsupervised Transformer\n  approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image registration as an important basis in signal processing task often\nencounter the problem of stability and efficiency. Non-learning registration\napproaches rely on the optimization of the similarity metrics between the fix\nand moving images. Yet, those approaches are usually costly in both time and\nspace complexity. The problem can be worse when the size of the image is large\nor the deformations between the images are severe. Recently, deep learning, or\nprecisely saying, the convolutional neural network (CNN) based image\nregistration methods have been widely investigated in the research community\nand show promising effectiveness to overcome the weakness of non-learning based\nmethods. To explore the advanced learning approaches in image registration\nproblem for solving practical issues, we present in this paper a method of\nintroducing attention mechanism in deformable image registration problem. The\nproposed approach is based on learning the deformation field with a Transformer\nframework (AiR) that does not rely on the CNN but can be efficiently trained on\nGPGPU devices also. In a more vivid interpretation: we treat the image\nregistration problem as the same as a language translation task and introducing\na Transformer to tackle the problem. Our method learns an unsupervised\ngenerated deformation map and is tested on two benchmark datasets. The source\ncode of the AiR will be released at Gitlab.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 18:49:32 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Wang", "Zihao", ""], ["Delingette", "Herv\u00e9", ""]]}, {"id": "2105.02283", "submitter": "Carmine Dodaro", "authors": "Carmine Dodaro, Giuseppe Galat\\`a, Muhammad Kamran Khan, Marco\n  Maratea, Ivan Porro", "title": "Operating Room (Re)Scheduling with Bed Management via ASP", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Operating Room Scheduling (ORS) problem is the task of assigning patients\nto operating rooms, taking into account different specialties, lengths and\npriority scores of each planned surgery, operating room session durations, and\nthe availability of beds for the entire length of stay both in the Intensive\nCare Unit and in the wards. A proper solution to the ORS problem is of primary\nimportance for the healthcare service quality and the satisfaction of patients\nin hospital environments. In this paper we first present a solution to the\nproblem based on Answer Set Programming (ASP). The solution is tested on\nbenchmarks with realistic sizes and parameters, on three scenarios for the\ntarget length on 5-day scheduling, common in small-medium sized hospitals, and\nresults show that ASP is a suitable solving methodology for the ORS problem in\nsuch setting. Then, we also performed a scalability analysis on the schedule\nlength up to 15 days, which still shows the suitability of our solution also on\nlonger plan horizons. Moreover, we also present an ASP solution for the\nrescheduling problem, i.e. when the off-line schedule cannot be completed for\nsome reason. Finally, we introduce a web framework for managing ORS problems\nvia ASP that allows a user to insert the main parameters of the problem, solve\na specific instance, and show results graphically in real-time. Under\nconsideration in Theory and Practice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 18:51:22 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Dodaro", "Carmine", ""], ["Galat\u00e0", "Giuseppe", ""], ["Khan", "Muhammad Kamran", ""], ["Maratea", "Marco", ""], ["Porro", "Ivan", ""]]}, {"id": "2105.02331", "submitter": "Wei Guo", "authors": "Wei Guo, Marc Brittain, Peng Wei", "title": "Safety Enhancement for Deep Reinforcement Learning in Autonomous\n  Separation Assurance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The separation assurance task will be extremely challenging for air traffic\ncontrollers in a complex and high density airspace environment. Deep\nreinforcement learning (DRL) was used to develop an autonomous separation\nassurance framework in our previous work where the learned model advised speed\nmaneuvers. In order to improve the safety of this model in unseen environments\nwith uncertainties, in this work we propose a safety module for DRL in\nautonomous separation assurance applications. The proposed module directly\naddresses both model uncertainty and state uncertainty to improve safety. Our\nsafety module consists of two sub-modules: (1) the state safety sub-module is\nbased on the execution-time data augmentation method to introduce state\ndisturbances in the model input state; (2) the model safety sub-module is a\nMonte-Carlo dropout extension that learns the posterior distribution of the DRL\nmodel policy. We demonstrate the effectiveness of the two sub-modules in an\nopen-source air traffic simulator with challenging environment settings.\nThrough extensive numerical experiments, our results show that the proposed\nsub-safety modules help the DRL agent significantly improve its safety\nperformance in an autonomous separation assurance task.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 21:20:40 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 19:42:45 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Guo", "Wei", ""], ["Brittain", "Marc", ""], ["Wei", "Peng", ""]]}, {"id": "2105.02357", "submitter": "Samanta Knapi\\v{c}", "authors": "Samanta Knapi\\v{c}, Avleen Malhi, Rohit Saluja, Kary Fr\\\"amling", "title": "Explainable Artificial Intelligence for Human Decision-Support System in\n  Medical Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the present paper we present the potential of Explainable Artificial\nIntelligence methods for decision-support in medical image analysis scenarios.\nWith three types of explainable methods applied to the same medical image data\nset our aim was to improve the comprehensibility of the decisions provided by\nthe Convolutional Neural Network (CNN). The visual explanations were provided\non in-vivo gastral images obtained from a Video capsule endoscopy (VCE), with\nthe goal of increasing the health professionals' trust in the black box\npredictions. We implemented two post-hoc interpretable machine learning methods\nLIME and SHAP and the alternative explanation approach CIU, centered on the\nContextual Value and Utility (CIU). The produced explanations were evaluated\nusing human evaluation. We conducted three user studies based on the\nexplanations provided by LIME, SHAP and CIU. Users from different non-medical\nbackgrounds carried out a series of tests in the web-based survey setting and\nstated their experience and understanding of the given explanations. Three user\ngroups (n=20, 20, 20) with three distinct forms of explanations were\nquantitatively analyzed. We have found that, as hypothesized, the CIU\nexplainable method performed better than both LIME and SHAP methods in terms of\nincreasing support for human decision-making as well as being more transparent\nand thus understandable to users. Additionally, CIU outperformed LIME and SHAP\nby generating explanations more rapidly. Our findings suggest that there are\nnotable differences in human decision-making between various explanation\nsupport settings. In line with that, we present three potential explainable\nmethods that can with future improvements in implementation be generalized on\ndifferent medical data sets and can provide great decision-support for medical\nexperts.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 22:29:28 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Knapi\u010d", "Samanta", ""], ["Malhi", "Avleen", ""], ["Saluja", "Rohit", ""], ["Fr\u00e4mling", "Kary", ""]]}, {"id": "2105.02365", "submitter": "William Chen", "authors": "William Chen, Kensal Ramos, Kalyan Naidu Mullaguri", "title": "Genetic Algorithms For Extractive Summarization", "comments": "4 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Most current work in NLP utilizes deep learning, which requires a lot of\ntraining data and computational power. This paper investigates the strengths of\nGenetic Algorithms (GAs) for extractive summarization, as we hypothesized that\nGAs could construct more efficient solutions for the summarization task due to\ntheir relative customizability relative to deep learning models. This is done\nby building a vocabulary set, the words of which are represented as an array of\nweights, and optimizing those set of weights with the GA. These weights can be\nused to build an overall weighting of a sentence, which can then be passed to\nsome threshold for extraction. Our results showed that the GA was able to learn\na weight representation that could filter out excessive vocabulary and thus\ndictate sentence importance based on common English words.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 23:14:41 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Chen", "William", ""], ["Ramos", "Kensal", ""], ["Mullaguri", "Kalyan Naidu", ""]]}, {"id": "2105.02368", "submitter": "Hao Sun", "authors": "Fangzheng Sun, Yang Liu, Hao Sun", "title": "Physics-informed Spline Learning for Nonlinear Dynamics Discovery", "comments": null, "journal-ref": "The 30th International Joint Conference on Artificial Intelligence\n  (IJCAI-2021)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI nlin.CD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamical systems are typically governed by a set of linear/nonlinear\ndifferential equations. Distilling the analytical form of these equations from\nvery limited data remains intractable in many disciplines such as physics,\nbiology, climate science, engineering and social science. To address this\nfundamental challenge, we propose a novel Physics-informed Spline Learning\n(PiSL) framework to discover parsimonious governing equations for nonlinear\ndynamics, based on sparsely sampled noisy data. The key concept is to (1)\nleverage splines to interpolate locally the dynamics, perform analytical\ndifferentiation and build the library of candidate terms, (2) employ sparse\nrepresentation of the governing equations, and (3) use the physics residual in\nturn to inform the spline learning. The synergy between splines and discovered\nunderlying physics leads to the robust capacity of dealing with high-level data\nscarcity and noise. A hybrid sparsity-promoting alternating direction\noptimization strategy is developed for systematically pruning the sparse\ncoefficients that form the structure and explicit expression of the governing\nequations. The efficacy and superiority of the proposed method have been\ndemonstrated by multiple well-known nonlinear dynamical systems, in comparison\nwith two state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 23:32:43 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 00:41:11 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Sun", "Fangzheng", ""], ["Liu", "Yang", ""], ["Sun", "Hao", ""]]}, {"id": "2105.02375", "submitter": "Qing Qu", "authors": "Zhihui Zhu, Tianyu Ding, Jinxin Zhou, Xiao Li, Chong You, Jeremias\n  Sulam, and Qing Qu", "title": "A Geometric Analysis of Neural Collapse with Unconstrained Features", "comments": "42 pages, 8 figures, 1 table; the first two authors contributed to\n  this work equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first global optimization landscape analysis of\n$Neural\\;Collapse$ -- an intriguing empirical phenomenon that arises in the\nlast-layer classifiers and features of neural networks during the terminal\nphase of training. As recently reported by Papyan et al., this phenomenon\nimplies that ($i$) the class means and the last-layer classifiers all collapse\nto the vertices of a Simplex Equiangular Tight Frame (ETF) up to scaling, and\n($ii$) cross-example within-class variability of last-layer activations\ncollapses to zero. We study the problem based on a simplified\n$unconstrained\\;feature\\;model$, which isolates the topmost layers from the\nclassifier of the neural network. In this context, we show that the classical\ncross-entropy loss with weight decay has a benign global landscape, in the\nsense that the only global minimizers are the Simplex ETFs while all other\ncritical points are strict saddles whose Hessian exhibit negative curvature\ndirections. In contrast to existing landscape analysis for deep neural networks\nwhich is often disconnected from practice, our analysis of the simplified model\nnot only does it explain what kind of features are learned in the last layer,\nbut it also shows why they can be efficiently optimized in the simplified\nsettings, matching the empirical observations in practical deep network\narchitectures. These findings could have profound implications for\noptimization, generalization, and robustness of broad interests. For example,\nour experiments demonstrate that one may set the feature dimension equal to the\nnumber of classes and fix the last-layer classifier to be a Simplex ETF for\nnetwork training, which reduces memory cost by over $20\\%$ on ResNet18 without\nsacrificing the generalization performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 00:00:50 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Zhu", "Zhihui", ""], ["Ding", "Tianyu", ""], ["Zhou", "Jinxin", ""], ["Li", "Xiao", ""], ["You", "Chong", ""], ["Sulam", "Jeremias", ""], ["Qu", "Qing", ""]]}, {"id": "2105.02388", "submitter": "Noah Ziems", "authors": "Noah Ziems, Shaoen Wu", "title": "Security Vulnerability Detection Using Deep Learning Natural Language\n  Processing", "comments": "IEEE INFOCOM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Detecting security vulnerabilities in software before they are exploited has\nbeen a challenging problem for decades. Traditional code analysis methods have\nbeen proposed, but are often ineffective and inefficient. In this work, we\nmodel software vulnerability detection as a natural language processing (NLP)\nproblem with source code treated as texts, and address the automated software\nvenerability detection with recent advanced deep learning NLP models assisted\nby transfer learning on written English. For training and testing, we have\npreprocessed the NIST NVD/SARD databases and built a dataset of over 100,000\nfiles in $C$ programming language with 123 types of vulnerabilities. The\nextensive experiments generate the best performance of over 93\\% accuracy in\ndetecting security vulnerabilities.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 01:28:21 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Ziems", "Noah", ""], ["Wu", "Shaoen", ""]]}, {"id": "2105.02410", "submitter": "Tong Wang", "authors": "Tong Wang, Jingyi Yang, Yunyi Li, Boxiang Wang", "title": "Partially Interpretable Estimators (PIE): Black-Box-Refined\n  Interpretable Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Partially Interpretable Estimators (PIE) which attribute a\nprediction to individual features via an interpretable model, while a\n(possibly) small part of the PIE prediction is attributed to the interaction of\nfeatures via a black-box model, with the goal to boost the predictive\nperformance while maintaining interpretability. As such, the interpretable\nmodel captures the main contributions of features, and the black-box model\nattempts to complement the interpretable piece by capturing the \"nuances\" of\nfeature interactions as a refinement. We design an iterative training algorithm\nto jointly train the two types of models. Experimental results show that PIE is\nhighly competitive to black-box models while outperforming interpretable\nbaselines. In addition, the understandability of PIE is comparable to simple\nlinear models as validated via a human evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 03:06:34 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Wang", "Tong", ""], ["Yang", "Jingyi", ""], ["Li", "Yunyi", ""], ["Wang", "Boxiang", ""]]}, {"id": "2105.02418", "submitter": "Ziniu Wu", "authors": "Ziniu Wu, Peilun Yang, Pei Yu, Rong Zhu, Yuxing Han, Yaliang Li, Defu\n  Lian, Kai Zeng, Jingren Zhou", "title": "A Unified Transferable Model for ML-Enhanced DBMS", "comments": "7 pages, 2 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, the database management system (DBMS) community has witnessed the\npower of machine learning (ML) solutions for DBMS tasks. Despite their\npromising performance, these existing solutions can hardly be considered\nsatisfactory. First, these ML-based methods in DBMS are not effective enough\nbecause they are optimized on each specific task, and cannot explore or\nunderstand the intrinsic connections between tasks. Second, the training\nprocess has serious limitations that hinder their practicality, because they\nneed to retrain the entire model from scratch for a new DB. Moreover, for each\nretraining, they require an excessive amount of training data, which is very\nexpensive to acquire and unavailable for a new DB. We propose to explore the\ntransferabilities of the ML methods both across tasks and across DBs to tackle\nthese fundamental drawbacks.\n  In this paper, we propose a unified model MTMLF that uses a multi-task\ntraining procedure to capture the transferable knowledge across tasks and a\npretrain finetune procedure to distill the transferable meta knowledge across\nDBs. We believe this paradigm is more suitable for cloud DB service, and has\nthe potential to revolutionize the way how ML is used in DBMS. Furthermore, to\ndemonstrate the predicting power and viability of MTMLF, we provide a concrete\nand very promising case study on query optimization tasks. Last but not least,\nwe discuss several concrete research opportunities along this line of work.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 03:31:32 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Wu", "Ziniu", ""], ["Yang", "Peilun", ""], ["Yu", "Pei", ""], ["Zhu", "Rong", ""], ["Han", "Yuxing", ""], ["Li", "Yaliang", ""], ["Lian", "Defu", ""], ["Zeng", "Kai", ""], ["Zhou", "Jingren", ""]]}, {"id": "2105.02501", "submitter": "Fan Bai", "authors": "Fan Bai, Jiaxiang Wu, Pengcheng Shen, Shaoxin Li and Shuigeng Zhou", "title": "Federated Face Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Face recognition has been extensively studied in computer vision and\nartificial intelligence communities in recent years. An important issue of face\nrecognition is data privacy, which receives more and more public concerns. As a\ncommon privacy-preserving technique, Federated Learning is proposed to train a\nmodel cooperatively without sharing data between parties. However, as far as we\nknow, it has not been successfully applied in face recognition. This paper\nproposes a framework named FedFace to innovate federated learning for face\nrecognition. Specifically, FedFace relies on two major innovative algorithms,\nPartially Federated Momentum (PFM) and Federated Validation (FV). PFM locally\napplies an estimated equivalent global momentum to approximating the\ncentralized momentum-SGD efficiently. FV repeatedly searches for better\nfederated aggregating weightings via testing the aggregated models on some\nprivate validation datasets, which can improve the model's generalization\nability. The ablation study and extensive experiments validate the\neffectiveness of the FedFace method and show that it is comparable to or even\nbetter than the centralized baseline in performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 08:07:25 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Bai", "Fan", ""], ["Wu", "Jiaxiang", ""], ["Shen", "Pengcheng", ""], ["Li", "Shaoxin", ""], ["Zhou", "Shuigeng", ""]]}, {"id": "2105.02509", "submitter": "Dengfeng Ke", "authors": "Dengfeng Ke, Jinsong Zhang, Yanlu Xie, Yanyan Xu, Binghuai Lin", "title": "Speech Enhancement using Separable Polling Attention and Global Layer\n  Normalization followed with PReLU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Single channel speech enhancement is a challenging task in speech community.\nRecently, various neural networks based methods have been applied to speech\nenhancement. Among these models, PHASEN and T-GSA achieve state-of-the-art\nperformances on the publicly opened VoiceBank+DEMAND corpus. Both of the models\nreach the COVL score of 3.62. PHASEN achieves the highest CSIG score of 4.21\nwhile T-GSA gets the highest PESQ score of 3.06. However, both of these two\nmodels are very large. The contradiction between the model performance and the\nmodel size is hard to reconcile. In this paper, we introduce three kinds of\ntechniques to shrink the PHASEN model and improve the performance. Firstly,\nseperable polling attention is proposed to replace the frequency transformation\nblocks in PHASEN. Secondly, global layer normalization followed with PReLU is\nused to replace batch normalization followed with ReLU. Finally, BLSTM in\nPHASEN is replaced with Conv2d operation and the phase stream is simplified.\nWith all these modifications, the size of the PHASEN model is shrunk from 33M\nparameters to 5M parameters, while the performance on VoiceBank+DEMAND is\nimproved to the CSIG score of 4.30, the PESQ score of 3.07 and the COVL score\nof 3.73.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 08:18:02 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Ke", "Dengfeng", ""], ["Zhang", "Jinsong", ""], ["Xie", "Yanlu", ""], ["Xu", "Yanyan", ""], ["Lin", "Binghuai", ""]]}, {"id": "2105.02540", "submitter": "David Berend", "authors": "David Berend", "title": "Distribution Awareness for AI System Testing", "comments": "2 pages, 1 figure, pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As Deep Learning (DL) is continuously adopted in many safety critical\napplications, its quality and reliability start to raise concerns. Similar to\nthe traditional software development process, testing the DL software to\nuncover its defects at an early stage is an effective way to reduce risks after\ndeployment. Although recent progress has been made in designing novel testing\ntechniques for DL software, the distribution of generated test data is not\ntaken into consideration. It is therefore hard to judge whether the identified\nerrors are indeed meaningful errors to the DL application. Therefore, we\npropose a new OOD-guided testing technique which aims to generate new unseen\ntest cases relevant to the underlying DL system task. Our results show that\nthis technique is able to filter up to 55.44% of error test case on CIFAR-10\nand is 10.05% more effective in enhancing robustness.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 09:24:06 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Berend", "David", ""]]}, {"id": "2105.02544", "submitter": "Junwei Bao Doctor", "authors": "Jing Zhao, Junwei Bao, Yifan Wang, Youzheng Wu, Xiaodong He, Bowen\n  Zhou", "title": "SGG: Learning to Select, Guide, and Generate for Keyphrase Generation", "comments": "10 pages, 4 figures, accepted by NAACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Keyphrases, that concisely summarize the high-level topics discussed in a\ndocument, can be categorized into present keyphrase which explicitly appears in\nthe source text, and absent keyphrase which does not match any contiguous\nsubsequence but is highly semantically related to the source. Most existing\nkeyphrase generation approaches synchronously generate present and absent\nkeyphrases without explicitly distinguishing these two categories. In this\npaper, a Select-Guide-Generate (SGG) approach is proposed to deal with present\nand absent keyphrase generation separately with different mechanisms.\nSpecifically, SGG is a hierarchical neural network which consists of a\npointing-based selector at low layer concentrated on present keyphrase\ngeneration, a selection-guided generator at high layer dedicated to absent\nkeyphrase generation, and a guider in the middle to transfer information from\nselector to generator. Experimental results on four keyphrase generation\nbenchmarks demonstrate the effectiveness of our model, which significantly\noutperforms the strong baselines for both present and absent keyphrases\ngeneration. Furthermore, we extend SGG to a title generation task which\nindicates its extensibility in natural language generation tasks.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 09:43:33 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Zhao", "Jing", ""], ["Bao", "Junwei", ""], ["Wang", "Yifan", ""], ["Wu", "Youzheng", ""], ["He", "Xiaodong", ""], ["Zhou", "Bowen", ""]]}, {"id": "2105.02551", "submitter": "Jary Pomponi", "authors": "Jary Pomponi, Simone Scardapane, and Aurelio Uncini", "title": "Structured Ensembles: an Approach to Reduce the Memory Footprint of\n  Ensemble Methods", "comments": "Preprint submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a novel ensembling technique for deep neural\nnetworks, which is able to drastically reduce the required memory compared to\nalternative approaches. In particular, we propose to extract multiple\nsub-networks from a single, untrained neural network by solving an end-to-end\noptimization task combining differentiable scaling over the original\narchitecture, with multiple regularization terms favouring the diversity of the\nensemble. Since our proposal aims to detect and extract sub-structures, we call\nit Structured Ensemble. On a large experimental evaluation, we show that our\nmethod can achieve higher or comparable accuracy to competing methods while\nrequiring significantly less storage. In addition, we evaluate our ensembles in\nterms of predictive calibration and uncertainty, showing they compare\nfavourably with the state-of-the-art. Finally, we draw a link with the\ncontinual learning literature, and we propose a modification of our framework\nto handle continuous streams of tasks with a sub-linear memory cost. We compare\nwith a number of alternative strategies to mitigate catastrophic forgetting,\nhighlighting advantages in terms of average accuracy and memory.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 09:56:01 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Pomponi", "Jary", ""], ["Scardapane", "Simone", ""], ["Uncini", "Aurelio", ""]]}, {"id": "2105.02572", "submitter": "Byeongjoon Noh", "authors": "Byeongjoon Noh and Hwasoo Yeo", "title": "A novel method of predictive collision risk area estimation for\n  proactive pedestrian accident prevention system in urban surveillance\n  infrastructure", "comments": "26 pages, 17 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Road traffic accidents, especially vehicle pedestrian collisions in\ncrosswalk, globally pose a severe threat to human lives and have become a\nleading cause of premature deaths. In order to protect such vulnerable road\nusers from collisions, it is necessary to recognize possible conflict in\nadvance and warn to road users, not post facto. A breakthrough for proactively\npreventing pedestrian collisions is to recognize pedestrian's potential risks\nbased on vision sensors such as CCTVs. In this study, we propose a predictive\ncollision risk area estimation system at unsignalized crosswalks. The proposed\nsystem applied trajectories of vehicles and pedestrians from video footage\nafter preprocessing, and then predicted their trajectories by using deep LSTM\nnetworks. With use of predicted trajectories, this system can infer collision\nrisk areas statistically, further severity of levels is divided as danger,\nwarning, and relative safe. In order to validate the feasibility and\napplicability of the proposed system, we applied it and assess the severity of\npotential risks in two unsignalized spots in Osan city, Korea.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 10:29:44 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Noh", "Byeongjoon", ""], ["Yeo", "Hwasoo", ""]]}, {"id": "2105.02575", "submitter": "Lukas Harsch", "authors": "Lukas Harsch, Stefan Riedelbauch", "title": "Direct Prediction of Steady-State Flow Fields in Meshed Domain with\n  Graph Networks", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a model to directly predict the steady-state flow field for a\ngiven geometry setup. The setup is an Eulerian representation of the fluid flow\nas a meshed domain. We introduce a graph network architecture to process the\nmesh-space simulation as a graph. The benefit of our model is a strong\nunderstanding of the global physical system, while being able to explore the\nlocal structure. This is essential to perform direct prediction and is thus\nsuperior to other existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 10:35:54 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Harsch", "Lukas", ""], ["Riedelbauch", "Stefan", ""]]}, {"id": "2105.02585", "submitter": "Chao Yang", "authors": "Bi-Ying Yan and Chao Yang and Feng Chen and Kohei Takeda and Changjun\n  Wang", "title": "FDNet: A Deep Learning Approach with Two Parallel Cross Encoding\n  Pathways for Precipitation Nowcasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the goal of predicting the future rainfall intensity in a local region\nover a relatively short period time, precipitation nowcasting has been a\nlong-time scientific challenge with great social and economic impact. The radar\necho extrapolation approaches for precipitation nowcasting take radar echo\nimages as input, aiming to generate future radar echo images by learning from\nthe historical images. To effectively handle complex and high non-stationary\nevolution of radar echoes, we propose to decompose the movement into optical\nflow field motion and morphologic deformation. Following this idea, we\nintroduce Flow-Deformation Network (FDNet), a neural network that models flow\nand deformation in two parallel cross pathways. The flow encoder captures the\noptical flow field motion between consecutive images and the deformation\nencoder distinguishes the change of shape from the translational motion of\nradar echoes. We evaluate the proposed network architecture on two real-world\nradar echo datasets. Our model achieves state-of-the-art prediction results\ncompared with recent approaches. To the best of our knowledge, this is the\nfirst network architecture with flow and deformation separation to model the\nevolution of radar echoes for precipitation nowcasting. We believe that the\ngeneral idea of this work could not only inspire much more effective approaches\nbut also be applied to other similar spatiotemporal prediction tasks\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 11:18:24 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Yan", "Bi-Ying", ""], ["Yang", "Chao", ""], ["Chen", "Feng", ""], ["Takeda", "Kohei", ""], ["Wang", "Changjun", ""]]}, {"id": "2105.02590", "submitter": "Samson Tan", "authors": "Samson Tan, Shafiq Joty, Kathy Baxter, Araz Taeihagh, Gregory A.\n  Bennett, Min-Yen Kan", "title": "Reliability Testing for Natural Language Processing Systems", "comments": "Accepted to ACL-IJCNLP 2021 (main conference). Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CY cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Questions of fairness, robustness, and transparency are paramount to address\nbefore deploying NLP systems. Central to these concerns is the question of\nreliability: Can NLP systems reliably treat different demographics fairly and\nfunction correctly in diverse and noisy environments? To address this, we argue\nfor the need for reliability testing and contextualize it among existing work\non improving accountability. We show how adversarial attacks can be reframed\nfor this goal, via a framework for developing reliability tests. We argue that\nreliability testing -- with an emphasis on interdisciplinary collaboration --\nwill enable rigorous and targeted testing, and aid in the enactment and\nenforcement of industry standards.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 11:24:58 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 04:17:44 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 03:55:40 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Tan", "Samson", ""], ["Joty", "Shafiq", ""], ["Baxter", "Kathy", ""], ["Taeihagh", "Araz", ""], ["Bennett", "Gregory A.", ""], ["Kan", "Min-Yen", ""]]}, {"id": "2105.02605", "submitter": "Junhan Yang", "authors": "Junhan Yang, Zheng Liu, Shitao Xiao, Chaozhuo Li, Guangzhong Sun, and\n  Xing Xie", "title": "GraphFormers: GNN-nested Language Models for Linked Text Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Linked text representation is critical for many intelligent web applications,\nsuch as online advertisement and recommender systems. Recent breakthroughs on\npretrained language models and graph neural networks facilitate the development\nof corresponding techniques. However, the existing works mainly rely on\ncascaded model structures: the texts are independently encoded by language\nmodels at first, and the textual embeddings are further aggregated by graph\nneural networks. We argue that the neighbourhood information is insufficiently\nutilized within the above process, which restricts the representation quality.\nIn this work, we propose GraphFormers, where graph neural networks are nested\nalongside each transformer layer of the language models. On top of the above\narchitecture, the linked texts will iteratively extract neighbourhood\ninformation for the enhancement of their own semantics. Such an iterative\nworkflow gives rise to more effective utilization of neighbourhood information,\nwhich contributes to the representation quality. We further introduce an\nadaptation called unidirectional GraphFormers, which is much more efficient and\ncomparably effective; and we leverage a pretraining strategy called the\nneighbourhood-aware masked language modeling to enhance the training effect. We\nperform extensive experiment studies with three large-scale linked text\ndatasets, whose results verify the effectiveness of our proposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 12:20:41 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Yang", "Junhan", ""], ["Liu", "Zheng", ""], ["Xiao", "Shitao", ""], ["Li", "Chaozhuo", ""], ["Sun", "Guangzhong", ""], ["Xie", "Xing", ""]]}, {"id": "2105.02626", "submitter": "Xingjian Zhen", "authors": "Varun Nagaraj Rao, Xingjian Zhen, Karen Hovsepian, Mingwei Shen", "title": "A First Look: Towards Explainable TextVQA Models via Visual and Textual\n  Explanations", "comments": "This paper is done when Xingjian was an intern in Amazon PARS group,\n  summer 2020. This paper is accepted by NAACL-MAI-Workshop, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable deep learning models are advantageous in many situations. Prior\nwork mostly provide unimodal explanations through post-hoc approaches not part\nof the original system design. Explanation mechanisms also ignore useful\ntextual information present in images. In this paper, we propose MTXNet, an\nend-to-end trainable multimodal architecture to generate multimodal\nexplanations, which focuses on the text in the image. We curate a novel dataset\nTextVQA-X, containing ground truth visual and multi-reference textual\nexplanations that can be leveraged during both training and evaluation. We then\nquantitatively show that training with multimodal explanations complements\nmodel performance and surpasses unimodal baselines by up to 7% in CIDEr scores\nand 2% in IoU. More importantly, we demonstrate that the multimodal\nexplanations are consistent with human interpretations, help justify the\nmodels' decision, and provide useful insights to help diagnose an incorrect\nprediction. Finally, we describe a real-world e-commerce application for using\nthe generated multimodal explanations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 00:36:17 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Rao", "Varun Nagaraj", ""], ["Zhen", "Xingjian", ""], ["Hovsepian", "Karen", ""], ["Shen", "Mingwei", ""]]}, {"id": "2105.02653", "submitter": "Yanzhe Bekkemoen", "authors": "Yanzhe Bekkemoen, Helge Langseth", "title": "Correcting Classification: A Bayesian Framework Using Explanation\n  Feedback to Improve Classification Abilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural networks (NNs) have shown high predictive performance, however, with\nshortcomings. Firstly, the reasons behind the classifications are not fully\nunderstood. Several explanation methods have been developed, but they do not\nprovide mechanisms for users to interact with the explanations. Explanations\nare social, meaning they are a transfer of knowledge through interactions.\nNonetheless, current explanation methods contribute only to one-way\ncommunication. Secondly, NNs tend to be overconfident, providing unreasonable\nuncertainty estimates on out-of-distribution observations. We overcome these\ndifficulties by training a Bayesian convolutional neural network (CNN) that\nuses explanation feedback. After training, the model presents explanations of\ntraining sample classifications to an annotator. Based on the provided\ninformation, the annotator can accept or reject the explanations by providing\nfeedback. Our proposed method utilizes this feedback for fine-tuning to correct\nthe model such that the explanations and classifications improve. We use\nexisting CNN architectures to demonstrate the method's effectiveness on one toy\ndataset (decoy MNIST) and two real-world datasets (Dogs vs. Cats and ISIC skin\ncancer). The experiments indicate that few annotated explanations and\nfine-tuning epochs are needed to improve the model and predictive performance,\nmaking the model more trustworthy and understandable.\n", "versions": [{"version": "v1", "created": "Thu, 29 Apr 2021 13:59:21 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 15:37:31 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Bekkemoen", "Yanzhe", ""], ["Langseth", "Helge", ""]]}, {"id": "2105.02658", "submitter": "Tatsuya Sakai", "authors": "Tatsuya Sakai and Takayuki Nagai", "title": "Explainable Autonomous Robots: A Survey and Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced communication protocols are critical to enable the coexistence of\nautonomous robots with humans. Thus, the development of explanatory\ncapabilities is an urgent first step toward autonomous robots. This survey\nprovides an overview of the various types of \"explainability\" discussed in\nmachine learning research. Then, we discuss the definition of \"explainability\"\nin the context of autonomous robots (i.e., explainable autonomous robots) by\nexploring the question \"what is an explanation?\" We further conduct a research\nsurvey based on this definition and present some relevant topics for future\nresearch.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 13:38:02 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Sakai", "Tatsuya", ""], ["Nagai", "Takayuki", ""]]}, {"id": "2105.02670", "submitter": "Tatsuya Sakai", "authors": "Tatsuya Sakai, Kazuki Miyazawa, Takato Horii and Takayuki Nagai", "title": "A Framework of Explanation Generation toward Reliable Autonomous Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To realize autonomous collaborative robots, it is important to increase the\ntrust that users have in them. Toward this goal, this paper proposes an\nalgorithm which endows an autonomous agent with the ability to explain the\ntransition from the current state to the target state in a Markov decision\nprocess (MDP). According to cognitive science, to generate an explanation that\nis acceptable to humans, it is important to present the minimum information\nnecessary to sufficiently understand an event. To meet this requirement, this\nstudy proposes a framework for identifying important elements in the\ndecision-making process using a prediction model for the world and generating\nexplanations based on these elements. To verify the ability of the proposed\nmethod to generate explanations, we conducted an experiment using a grid\nenvironment. It was inferred from the result of a simulation experiment that\nthe explanation generated using the proposed method was composed of the minimum\nelements important for understanding the transition from the current state to\nthe target state. Furthermore, subject experiments showed that the generated\nexplanation was a good summary of the process of state transition, and that a\nhigh evaluation was obtained for the explanation of the reason for an action.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 13:50:37 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Sakai", "Tatsuya", ""], ["Miyazawa", "Kazuki", ""], ["Horii", "Takato", ""], ["Nagai", "Takayuki", ""]]}, {"id": "2105.02685", "submitter": "Pierre Colombo", "authors": "Pierre Colombo and Chloe Clavel and Pablo Piantanida", "title": "A Novel Estimator of Mutual Information for Learning to Disentangle\n  Textual Representations", "comments": null, "journal-ref": "ACL 2021", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Learning disentangled representations of textual data is essential for many\nnatural language tasks such as fair classification, style transfer and sentence\ngeneration, among others. The existent dominant approaches in the context of\ntext data {either rely} on training an adversary (discriminator) that aims at\nmaking attribute values difficult to be inferred from the latent code {or rely\non minimising variational bounds of the mutual information between latent code\nand the value attribute}. {However, the available methods suffer of the\nimpossibility to provide a fine-grained control of the degree (or force) of\ndisentanglement.} {In contrast to} {adversarial methods}, which are remarkably\nsimple, although the adversary seems to be performing perfectly well during the\ntraining phase, after it is completed a fair amount of information about the\nundesired attribute still remains. This paper introduces a novel variational\nupper bound to the mutual information between an attribute and the latent code\nof an encoder. Our bound aims at controlling the approximation error via the\nRenyi's divergence, leading to both better disentangled representations and in\nparticular, a precise control of the desirable degree of disentanglement {than\nstate-of-the-art methods proposed for textual data}. Furthermore, it does not\nsuffer from the degeneracy of other losses in multi-class scenarios. We show\nthe superiority of this method on fair classification and on textual style\ntransfer tasks. Additionally, we provide new insights illustrating various\ntrade-offs in style transfer when attempting to learn disentangled\nrepresentations and quality of the generated sentence.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 14:05:06 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Colombo", "Pierre", ""], ["Clavel", "Chloe", ""], ["Piantanida", "Pablo", ""]]}, {"id": "2105.02693", "submitter": "Hongbo Zhang Dr.", "authors": "Jia-Xing Zhong, Hongbo Zhang", "title": "Uncertainty-aware INVASE: Enhanced Breast Cancer Diagnosis Feature\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present an uncertainty-aware INVASE to quantify predictive\nconfidence of healthcare problem. By introducing learnable Gaussian\ndistributions, we lever-age their variances to measure the degree of\nuncertainty. Based on the vanilla INVASE, two additional modules are proposed,\ni.e., an uncertainty quantification module in the predictor, and a reward\nshaping module in the selector. We conduct extensive experiments on UCI-WDBC\ndataset. Notably, our method eliminates almost all predictive bias with only\nabout 20% queries, while the uncertainty-agnostic counterpart requires nearly\n100% queries. The open-source implementation with a detailed tutorial is\navailable at\nhttps://github.com/jx-zhong-for-academic-purpose/Uncertainty-aware-INVASE/blob/main/tutorialinvase%2B.ipynb.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 21:30:33 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Zhong", "Jia-Xing", ""], ["Zhang", "Hongbo", ""]]}, {"id": "2105.02704", "submitter": "Roman Yampolskiy", "authors": "Roman V. Yampolskiy", "title": "AI Risk Skepticism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we survey skepticism regarding AI risk and show parallels with\nother types of scientific skepticism. We start by classifying different types\nof AI Risk skepticism and analyze their root causes. We conclude by suggesting\nsome intervention approaches, which may be successful in reducing AI risk\nskepticism, at least amongst artificial intelligence researchers.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 23:29:36 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 16:10:25 GMT"}, {"version": "v3", "created": "Sat, 17 Jul 2021 21:51:45 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Yampolskiy", "Roman V.", ""]]}, {"id": "2105.02714", "submitter": "Dvir Ginzburg", "authors": "Dvir Ginzburg and Dan Raviv", "title": "Deep Weighted Consensus: Dense correspondence confidence maps for 3D\n  shape registration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new paradigm for rigid alignment between point clouds based on\nlearnable weighted consensus which is robust to noise as well as the full\nspectrum of the rotation group.\n  Current models, learnable or axiomatic, work well for constrained\norientations and limited noise levels, usually by an end-to-end learner or an\niterative scheme. However, real-world tasks require us to deal with large\nrotations as well as outliers and all known models fail to deliver.\n  Here we present a different direction. We claim that we can align point\nclouds out of sampled matched points according to confidence level derived from\na dense, soft alignment map. The pipeline is differentiable, and converges\nunder large rotations in the full spectrum of SO(3), even with high noise\nlevels. We compared the network to recently presented methods such as DCP,\nPointNetLK, RPM-Net, PRnet, and axiomatic methods such as ICP and Go-ICP. We\nreport here a fundamental boost in performance.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 14:27:59 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Ginzburg", "Dvir", ""], ["Raviv", "Dan", ""]]}, {"id": "2105.02738", "submitter": "Marija Slavkovik", "authors": "Marija Slavkovik, Clemens Stachl, Caroline Pitman, Jonathan Askonas", "title": "Digital Voodoo Dolls", "comments": "Accepted for publication at Artificial Intelligence, Ethics and\n  Society (AIES-2021)", "journal-ref": null, "doi": "10.1145/3461702.3462626", "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An institution, be it a body of government, commercial enterprise, or a\nservice, cannot interact directly with a person. Instead, a model is created to\nrepresent us. We argue the existence of a new high-fidelity type of person\nmodel which we call a digital voodoo doll. We conceptualize it and compare its\nfeatures with existing models of persons. Digital voodoo dolls are\ndistinguished by existing completely beyond the influence and control of the\nperson they represent. We discuss the ethical issues that such a lack of\naccountability creates and argue how these concerns can be mitigated.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 14:56:54 GMT"}, {"version": "v2", "created": "Fri, 7 May 2021 16:29:06 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Slavkovik", "Marija", ""], ["Stachl", "Clemens", ""], ["Pitman", "Caroline", ""], ["Askonas", "Jonathan", ""]]}, {"id": "2105.02741", "submitter": "Zhiyuan Wu", "authors": "Zizhen Zhang, Zhiyuan Wu, Jiahai Wang", "title": "Meta-Learning-based Deep Reinforcement Learning for Multiobjective\n  Optimization Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning (DRL) has recently shown its success in tackling\ncomplex combinatorial optimization problems. When these problems are extended\nto multiobjective ones, it becomes difficult for the existing DRL approaches to\nflexibly and efficiently deal with multiple subproblems determined by weight\ndecomposition of objectives. This paper proposes a concise meta-learning-based\nDRL approach. It first trains a meta-model by meta-learning. The meta-model is\nfine-tuned with a few update steps to derive submodels for the corresponding\nsubproblems. The Pareto front is built accordingly. The computational\nexperiments on multiobjective traveling salesman problems demonstrate the\nsuperiority of our method over most of learning-based and iteration-based\napproaches.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 15:09:35 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Zhang", "Zizhen", ""], ["Wu", "Zhiyuan", ""], ["Wang", "Jiahai", ""]]}, {"id": "2105.02751", "submitter": "Nikolaos Aletras", "authors": "Dimitrios Tsarapatsanis, Nikolaos Aletras", "title": "On the Ethical Limits of Natural Language Processing on Legal Text", "comments": "Accepted at ACL Findings 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Natural language processing (NLP) methods for analyzing legal text offer\nlegal scholars and practitioners a range of tools allowing to empirically\nanalyze law on a large scale. However, researchers seem to struggle when it\ncomes to identifying ethical limits to using NLP systems for acquiring genuine\ninsights both about the law and the systems' predictive capacity. In this paper\nwe set out a number of ways in which to think systematically about such issues.\nWe place emphasis on three crucial normative parameters which have, to the best\nof our knowledge, been underestimated by current debates: (a) the importance of\nacademic freedom, (b) the existence of a wide diversity of legal and ethical\nnorms domestically but even more so internationally and (c) the threat of\nmoralism in research related to computational law. For each of these three\nparameters we provide specific recommendations for the legal NLP community. Our\ndiscussion is structured around the study of a real-life scenario that has\nprompted recent debate in the legal NLP research community.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 15:22:24 GMT"}, {"version": "v2", "created": "Sat, 8 May 2021 10:05:17 GMT"}, {"version": "v3", "created": "Tue, 25 May 2021 09:21:15 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Tsarapatsanis", "Dimitrios", ""], ["Aletras", "Nikolaos", ""]]}, {"id": "2105.02761", "submitter": "Petar Veli\\v{c}kovi\\'c", "authors": "Petar Veli\\v{c}kovi\\'c, Charles Blundell", "title": "Neural Algorithmic Reasoning", "comments": "Accepted as an Opinion paper in Patterns. 7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms have been fundamental to recent global technological advances and,\nin particular, they have been the cornerstone of technical advances in one\nfield rapidly being applied to another. We argue that algorithms possess\nfundamentally different qualities to deep learning methods, and this strongly\nsuggests that, were deep learning methods better able to mimic algorithms,\ngeneralisation of the sort seen with algorithms would become possible with deep\nlearning -- something far out of the reach of current machine learning methods.\nFurthermore, by representing elements in a continuous space of learnt\nalgorithms, neural networks are able to adapt known algorithms more closely to\nreal-world problems, potentially finding more efficient and pragmatic solutions\nthan those proposed by human computer scientists.\n  Here we present neural algorithmic reasoning -- the art of building neural\nnetworks that are able to execute algorithmic computation -- and provide our\nopinion on its transformative potential for running classical algorithms on\ninputs previously considered inaccessible to them.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 15:33:57 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Veli\u010dkovi\u0107", "Petar", ""], ["Blundell", "Charles", ""]]}, {"id": "2105.02810", "submitter": "Bryar Hassan Dr.", "authors": "Bryar A. Hassan, TarikA. Rashid, Seyedali Mirjalili", "title": "Performance evaluation results of evolutionary clustering algorithm star\n  for clustering heterogeneous datasets", "comments": null, "journal-ref": null, "doi": "10.1016/j.dib.2021.107044", "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This article presents the data used to evaluate the performance of\nevolutionary clustering algorithm star (ECA*) compared to five traditional and\nmodern clustering algorithms. Two experimental methods are employed to examine\nthe performance of ECA* against genetic algorithm for clustering++\n(GENCLUST++), learning vector quantisation (LVQ) , expectation maximisation\n(EM) , K-means++ (KM++) and K-means (KM). These algorithms are applied to 32\nheterogenous and multi-featured datasets to determine which one performs well\non the three tests. For one, ther paper examines the efficiency of ECA* in\ncontradiction of its corresponding algorithms using clustering evaluation\nmeasures. These validation criteria are objective function and cluster quality\nmeasures. For another, it suggests a performance rating framework to measurethe\nthe performance sensitivity of these algorithms on varos dataset features\n(cluster dimensionality, number of clusters, cluster overlap, cluster shape and\ncluster structure). The contributions of these experiments are two-folds: (i)\nECA* exceeds its counterpart aloriths in ability to find out the right cluster\nnumber; (ii) ECA* is less sensitive towards dataset features compared to its\ncompetitive techniques. Nonetheless, the results of the experiments performed\ndemonstrate some limitations in the ECA*: (i) ECA* is not fully applied based\non the premise that no prior knowledge exists; (ii) Adapting and utilising ECA*\non several real applications has not been achieved yet.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 08:17:19 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Hassan", "Bryar A.", ""], ["Rashid", "TarikA.", ""], ["Mirjalili", "Seyedali", ""]]}, {"id": "2105.02825", "submitter": "Leon Sixt", "authors": "Martin Schuessler, Philipp Wei{\\ss}, Leon Sixt", "title": "Two4Two: Evaluating Interpretable Machine Learning - A Synthetic Dataset\n  For Controlled Experiments", "comments": "6 pages, 3 figures, presented at the ICLR 2021 RAI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A growing number of approaches exist to generate explanations for image\nclassification. However, few of these approaches are subjected to human-subject\nevaluations, partly because it is challenging to design controlled experiments\nwith natural image datasets, as they leave essential factors out of the\nresearcher's control. With our approach, researchers can describe their desired\ndataset with only a few parameters. Based on these, our library generates\nsynthetic image data of two 3D abstract animals. The resulting data is suitable\nfor algorithmic as well as human-subject evaluations. Our user study results\ndemonstrate that our method can create biases predictive enough for a\nclassifier and subtle enough to be noticeable only to every second participant\ninspecting the data visually. Our approach significantly lowers the barrier for\nconducting human subject evaluations, thereby facilitating more rigorous\ninvestigations into interpretable machine learning. For our library and\ndatasets see, https://github.com/mschuessler/two4two/\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:14:39 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Schuessler", "Martin", ""], ["Wei\u00df", "Philipp", ""], ["Sixt", "Leon", ""]]}, {"id": "2105.02851", "submitter": "Colin Shea-Blymyer", "authors": "Colin Shea-Blymyer and Houssam Abbas", "title": "Algorithmic Ethics: Formalization and Verification of Autonomous Vehicle\n  Obligations", "comments": "To be published in ACT Transactions on Cyber-Physical Systems Special\n  Issue on Artificial Intelligence and Cyber-Physical Systems. arXiv admin\n  note: text overlap with arXiv:2009.00738", "journal-ref": null, "doi": "10.1145/3460975", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We develop a formal framework for automatic reasoning about the obligations\nof autonomous cyber-physical systems, including their social and ethical\nobligations. Obligations, permissions and prohibitions are distinct from a\nsystem's mission, and are a necessary part of specifying advanced, adaptive\nAI-equipped systems. They need a dedicated deontic logic of obligations to\nformalize them. Most existing deontic logics lack corresponding algorithms and\nsystem models that permit automatic verification. We demonstrate how a\nparticular deontic logic, Dominance Act Utilitarianism (DAU), is a suitable\nstarting point for formalizing the obligations of autonomous systems like\nself-driving cars. We demonstrate its usefulness by formalizing a subset of\nResponsibility-Sensitive Safety (RSS) in DAU; RSS is an industrial proposal for\nhow self-driving cars should and should not behave in traffic. We show that\ncertain logical consequences of RSS are undesirable, indicating a need to\nfurther refine the proposal. We also demonstrate how obligations can change\nover time, which is necessary for long-term autonomy. We then demonstrate a\nmodel-checking algorithm for DAU formulas on weighted transition systems, and\nillustrate it by model-checking obligations of a self-driving car controller\nfrom the literature.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:41:06 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Shea-Blymyer", "Colin", ""], ["Abbas", "Houssam", ""]]}, {"id": "2105.02873", "submitter": "Bj\\\"orn H Eriksson Mr.", "authors": "Bj\\\"orn H Eriksson", "title": "Contextual Bandits with Sparse Data in Web setting", "comments": "4 pages, 3 tables, review paper, scoping study", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper is a scoping study to identify current methods used in handling\nsparse data with contextual bandits in web settings. The area is highly current\nand state of the art methods are identified. The years 2017-2020 are\ninvestigated, and 19 method articles are identified, and two review articles.\nFive categories of methods are described, making it easy to choose how to\naddress sparse data using contextual bandits with a method available for\nmodification in the specific setting of concern. In addition, each method has\nmultiple techniques to choose from for future evaluation. The problem areas are\nalso mentioned that each article covers. An overall updated understanding of\nsparse data problems using contextual bandits in web settings is given. The\nidentified methods are policy evaluation (off-line and on-line) ,\nhybrid-method, model representation (clusters and deep neural networks),\ndimensionality reduction, and simulation.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 17:58:13 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Eriksson", "Bj\u00f6rn H", ""]]}, {"id": "2105.02936", "submitter": "Edward Raff", "authors": "Edward Raff", "title": "Exact Acceleration of K-Means++ and K-Means$\\|$", "comments": "to appear in the 30th International Joint Conference on Artificial\n  Intelligence (IJCAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K-Means++ and its distributed variant K-Means$\\|$ have become de facto tools\nfor selecting the initial seeds of K-means. While alternatives have been\ndeveloped, the effectiveness, ease of implementation, and theoretical grounding\nof the K-means++ and $\\|$ methods have made them difficult to \"best\" from a\nholistic perspective. By considering the limited opportunities within seed\nselection to perform pruning, we develop specialized triangle inequality\npruning strategies and a dynamic priority queue to show the first acceleration\nof K-Means++ and K-Means$\\|$ that is faster in run-time while being\nalgorithmicly equivalent. For both algorithms we are able to reduce distance\ncomputations by over $500\\times$. For K-means++ this results in up to a\n17$\\times$ speedup in run-time and a $551\\times$ speedup for K-means$\\|$. We\nachieve this with simple, but carefully chosen, modifications to known\ntechniques which makes it easy to integrate our approach into existing\nimplementations of these algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 20:22:55 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Raff", "Edward", ""]]}, {"id": "2105.02963", "submitter": "Praveen Ravirathinam", "authors": "Rahul Ghosh, Praveen Ravirathinam, Xiaowei Jia, Chenxi Lin, Zhenong\n  Jin, Vipin Kumar", "title": "Attention-augmented Spatio-Temporal Segmentation for Land Cover Mapping", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The availability of massive earth observing satellite data provide huge\nopportunities for land use and land cover mapping. However, such mapping effort\nis challenging due to the existence of various land cover classes, noisy data,\nand the lack of proper labels. Also, each land cover class typically has its\nown unique temporal pattern and can be identified only during certain periods.\nIn this article, we introduce a novel architecture that incorporates the UNet\nstructure with Bidirectional LSTM and Attention mechanism to jointly exploit\nthe spatial and temporal nature of satellite data and to better identify the\nunique temporal patterns of each land cover. We evaluate this method for\nmapping crops in multiple regions over the world. We compare our method with\nother state-of-the-art methods both quantitatively and qualitatively on two\nreal-world datasets which involve multiple land cover classes. We also\nvisualise the attention weights to study its effectiveness in mitigating noise\nand identifying discriminative time period.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 05:39:42 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Ghosh", "Rahul", ""], ["Ravirathinam", "Praveen", ""], ["Jia", "Xiaowei", ""], ["Lin", "Chenxi", ""], ["Jin", "Zhenong", ""], ["Kumar", "Vipin", ""]]}, {"id": "2105.02965", "submitter": "Maarten Bieshaar", "authors": "Felix M\\\"oller, Diego Botache, Denis Huseljic, Florian Heidecker,\n  Maarten Bieshaar and Bernhard Sick", "title": "Out-of-distribution Detection and Generation using Soft Brownian Offset\n  Sampling and Autoencoders", "comments": "10 pages, 7 figures, accepted for publication at CVPR 2021 Workshop\n  Safe Artificial Intelligence for Automated Driving (SAIAD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks often suffer from overconfidence which can be partly\nremedied by improved out-of-distribution detection. For this purpose, we\npropose a novel approach that allows for the generation of out-of-distribution\ndatasets based on a given in-distribution dataset. This new dataset can then be\nused to improve out-of-distribution detection for the given dataset and machine\nlearning task at hand. The samples in this dataset are with respect to the\nfeature space close to the in-distribution dataset and therefore realistic and\nplausible. Hence, this dataset can also be used to safeguard neural networks,\ni.e., to validate the generalization performance. Our approach first generates\nsuitable representations of an in-distribution dataset using an autoencoder and\nthen transforms them using our novel proposed Soft Brownian Offset method.\nAfter transformation, the decoder part of the autoencoder allows for the\ngeneration of these implicit out-of-distribution samples. This newly generated\ndataset then allows for mixing with other datasets and thus improved training\nof an out-of-distribution classifier, increasing its performance.\nExperimentally, we show that our approach is promising for time series using\nsynthetic data. Using our new method, we also show in a quantitative case study\nthat we can improve the out-of-distribution detection for the MNIST dataset.\nFinally, we provide another case study on the synthetic generation of\nout-of-distribution trajectories, which can be used to validate trajectory\nprediction algorithms for automated driving.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 06:59:24 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["M\u00f6ller", "Felix", ""], ["Botache", "Diego", ""], ["Huseljic", "Denis", ""], ["Heidecker", "Florian", ""], ["Bieshaar", "Maarten", ""], ["Sick", "Bernhard", ""]]}, {"id": "2105.02968", "submitter": "Jonas Kohler", "authors": "Adrian Hoffmann, Claudio Fanconi, Rahul Rade, Jonas Kohler", "title": "This Looks Like That... Does it? Shortcomings of Latent Space Prototype\n  Interpretability in Deep Networks", "comments": null, "journal-ref": "ICML 2021 Workshop on Theoretic Foundation, Criticism, and\n  Application Trend of Explainable AI", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks that yield human interpretable decisions by\narchitectural design have lately become an increasingly popular alternative to\npost hoc interpretation of traditional black-box models. Among these networks,\nthe arguably most widespread approach is so-called prototype learning, where\nsimilarities to learned latent prototypes serve as the basis of classifying an\nunseen data point. In this work, we point to an important shortcoming of such\napproaches. Namely, there is a semantic gap between similarity in latent space\nand similarity in input space, which can corrupt interpretability. We design\ntwo experiments that exemplify this issue on the so-called ProtoPNet.\nSpecifically, we find that this network's interpretability mechanism can be led\nastray by intentionally crafted or even JPEG compression artefacts, which can\nproduce incomprehensible decisions. We argue that practitioners ought to have\nthis shortcoming in mind when deploying prototype-based models in practice.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 12:28:34 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 08:48:08 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 10:16:34 GMT"}, {"version": "v4", "created": "Wed, 23 Jun 2021 12:28:10 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Hoffmann", "Adrian", ""], ["Fanconi", "Claudio", ""], ["Rade", "Rahul", ""], ["Kohler", "Jonas", ""]]}, {"id": "2105.02993", "submitter": "Sam Earle", "authors": "Sam Earle, Maria Edwards, Ahmed Khalifa, Philip Bontrager and Julian\n  Togelius", "title": "Learning Controllable Content Generators", "comments": "8 pages, 11 figures, submitted to CoG '21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has recently been shown that reinforcement learning can be used to train\ngenerators capable of producing high-quality game levels, with quality defined\nin terms of some user-specified heuristic. To ensure that these generators'\noutput is sufficiently diverse (that is, not amounting to the reproduction of a\nsingle optimal level configuration), the generation process is constrained such\nthat the initial seed results in some variance in the generator's output.\nHowever, this results in a loss of control over the generated content for the\nhuman user. We propose to train generators capable of producing controllably\ndiverse output, by making them \"goal-aware.\" To this end, we add conditional\ninputs representing how close a generator is to some heuristic, and also modify\nthe reward mechanism to incorporate that value. Testing on multiple domains, we\nshow that the resulting level generators are capable of exploring the space of\npossible levels in a targeted, controllable manner, producing levels of\ncomparable quality as their goal-unaware counterparts, that are diverse along\ndesigner-specified dimensions.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 22:15:51 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Earle", "Sam", ""], ["Edwards", "Maria", ""], ["Khalifa", "Ahmed", ""], ["Bontrager", "Philip", ""], ["Togelius", "Julian", ""]]}, {"id": "2105.03041", "submitter": "Taisei Hashimoto", "authors": "Taisei Hashimoto and Yoshimasa Tsuruoka", "title": "Utilizing Skipped Frames in Action Repeats via Pseudo-Actions", "comments": "Deep Reinforcement Learning Workshop, NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many deep reinforcement learning settings, when an agent takes an action,\nit repeats the same action a predefined number of times without observing the\nstates until the next action-decision point. This technique of action\nrepetition has several merits in training the agent, but the data between\naction-decision points (i.e., intermediate frames) are, in effect, discarded.\nSince the amount of training data is inversely proportional to the interval of\naction repeats, they can have a negative impact on the sample efficiency of\ntraining. In this paper, we propose a simple but effective approach to\nalleviate to this problem by introducing the concept of pseudo-actions. The key\nidea of our method is making the transition between action-decision points\nusable as training data by considering pseudo-actions. Pseudo-actions for\ncontinuous control tasks are obtained as the average of the action sequence\nstraddling an action-decision point. For discrete control tasks, pseudo-actions\nare computed from learned action embeddings. This method can be combined with\nany model-free reinforcement learning algorithm that involves the learning of\nQ-functions. We demonstrate the effectiveness of our approach on both\ncontinuous and discrete control tasks in OpenAI Gym.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 02:43:44 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Hashimoto", "Taisei", ""], ["Tsuruoka", "Yoshimasa", ""]]}, {"id": "2105.03045", "submitter": "MohammadMahdi Behzadi", "authors": "Mohammad Mahdi Behzadi, Horea T. Ilies", "title": "GANTL: Towards Practical and Real-Time Topology Optimization with\n  Conditional GANs and Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many machine learning methods have been recently developed to circumvent the\nhigh computational cost of the gradient-based topology optimization. These\nmethods typically require extensive and costly datasets for training, have a\ndifficult time generalizing to unseen boundary and loading conditions and to\nnew domains, and do not take into consideration topological constraints of the\npredictions, which produces predictions with inconsistent topologies. We\npresent a deep learning method based on generative adversarial networks for\ngenerative design exploration. The proposed method combines the generative\npower of conditional GANs with the knowledge transfer capabilities of transfer\nlearning methods to predict optimal topologies for unseen boundary conditions.\nWe also show that the knowledge transfer capabilities embedded in the design of\nthe proposed algorithm significantly reduces the size of the training dataset\ncompared to the traditional deep learning neural or adversarial networks.\nMoreover, we formulate a topological loss function based on the bottleneck\ndistance obtained from the persistent diagram of the structures and demonstrate\na significant improvement in the topological connectivity of the predicted\nstructures. We use numerous examples to explore the efficiency and accuracy of\nthe proposed approach for both seen and unseen boundary conditions in 2D.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 03:13:32 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Behzadi", "Mohammad Mahdi", ""], ["Ilies", "Horea T.", ""]]}, {"id": "2105.03047", "submitter": "Zichao Meng", "authors": "Zichao Meng, Ye Guo, Wenjun Tang, Hongbin Sun, Wenqi Huang", "title": "A Multivariate Density Forecast Approach for Online Power System\n  Security Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A multivariate density forecast model based on deep learning is designed in\nthis paper to forecast the joint cumulative distribution functions (JCDFs) of\nmultiple security margins in power systems. Differing from existing\nmultivariate density forecast models, the proposed method requires no a priori\nhypotheses on the distribution of forecasting targets. In addition, based on\nthe universal approximation capability of neural networks, the value domain of\nthe proposed approach has been proven to include all continuous JCDFs. The\nforecasted JCDF is further employed to calculate the deterministic security\nassessment index evaluating the security level of future power system\noperations. Numerical tests verify the superiority of the proposed method over\ncurrent multivariate density forecast models. The deterministic security\nassessment index is demonstrated to be more informative for operators than\nsecurity margins as well.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 03:30:05 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Meng", "Zichao", ""], ["Guo", "Ye", ""], ["Tang", "Wenjun", ""], ["Sun", "Hongbin", ""], ["Huang", "Wenqi", ""]]}, {"id": "2105.03050", "submitter": "Xingxing Zou", "authors": "Xingxing Zou, Waikeung Wong", "title": "fAshIon after fashion: A Report of AI in Fashion", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this independent report fAshIon after fashion, we examine the development\nof fAshIon (artificial intelligence (AI) in fashion) and explore its\npotentiality to become a major disruptor of the fashion industry in the near\nfuture. To do this, we investigate AI technologies used in the fashion industry\nthrough several lenses. We summarise fAshIon studies conducted over the past\ndecade and categorise them into seven groups: Overview, Evaluation, Basic Tech,\nSelling, Styling, Design, and Buying. The datasets mentioned in fAshIon\nresearch have been consolidated on one GitHub page for ease of use. We analyse\nthe authors' backgrounds and the geographic regions treated in these studies to\ndetermine the landscape of fAshIon research. The results of our analysis are\npresented with an aim to provide researchers with a holistic view of research\nin fAshIon. As part of our primary research, we also review a wide range of\ncases of applied fAshIon in the fashion industry and analyse their impact on\nthe industry, markets and individuals. We also identify the challenges\npresented by fAshIon and suggest that these may form the basis for future\nresearch. We finally exhibit that many potential opportunities exist for the\nuse of AI in fashion which can transform the fashion industry embedded with AI\ntechnologies and boost profits.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 03:38:37 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Zou", "Xingxing", ""], ["Wong", "Waikeung", ""]]}, {"id": "2105.03052", "submitter": "Tao Zhang", "authors": "Tao Zhang and Quanyan Zhu", "title": "Informational Design of Dynamic Multi-Agent System", "comments": "arXiv admin note: substantial text overlap with arXiv:2102.07152", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers a novel information design problem and studies how the\ncraft of payoff-relevant environmental signals solely can influence the\nbehaviors of intelligent agents. The agents' strategic interactions are\ncaptured by a Markov game, in which each agent first selects one external\nsignal from multiple signal sources as additional payoff-relevant information\nand then takes an action. There is a rational information designer (principal)\nwho possesses one signal source and aims to influence the equilibrium behaviors\nof the agents by designing the information structure of her signals sent to the\nagents. We propose a direct information design approach that incentivizes each\nagent to select the signal sent by the principal, such that the design process\navoids the predictions of the agents' strategic selection behaviors. We then\nintroduce the design protocol given a goal of the designer which we refer to as\nobedient implementability (OIL) and characterize the OIL in a class of obedient\nsequential Markov perfect equilibria (O-SMPE). A design regime is proposed\nbased on an approach which we refer to as the fixed-point alignment that\nincentivizes the agents to choose the signal sent by the principal, guarantees\nthat the agents' policy profile of taking actions is the policy component of an\nO-SMPE and the principal's goal is achieved. We then formulate the principal's\noptimal goal selection problem in terms of information design and characterize\nthe optimization problem by minimizing the fixed-point misalignments. The\nproposed approach can be applied to elicit desired behaviors of multi-agent\nsystems in competing as well as cooperating settings and be extended to\nheterogeneous stochastic games in the complete- and the incomplete-information\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 03:46:14 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 01:08:34 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Zhang", "Tao", ""], ["Zhu", "Quanyan", ""]]}, {"id": "2105.03061", "submitter": "Dongmyung Shin", "authors": "Dongmyung Shin, Younghoon Kim, Chungseok Oh, Hongjun An, Juhyung Park,\n  Jiye Kim, and Jongho Lee", "title": "DeepRF: Deep Reinforcement Learning Designed RadioFrequency Waveform in\n  MRI", "comments": "35 pages, 5 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.LG eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A carefully engineered radiofrequency (RF) pulse plays a key role in a number\nof systems such as mobile phone, radar, and magnetic resonance imaging (MRI).\nThe design of an RF waveform, however, is often posed as an inverse problem\nthat has no general solution. As a result, various design methods each with a\nspecific purpose have been developed based on the intuition of human experts.\nIn this work, we propose an artificial intelligence-powered RF pulse design\nframework, DeepRF, which utilizes the self-learning characteristics of deep\nreinforcement learning (DRL) to generate a novel RF beyond human intuition.\nAdditionally, the method can design various types of RF pulses via customized\nreward functions. The algorithm of DeepRF consists of two modules: the RF\ngeneration module, which utilizes DRL to explore new RF pulses, and the RF\nrefinement module, which optimizes the seed RF pulses from the generation\nmodule via gradient ascent. The effectiveness of DeepRF is demonstrated using\nfour exemplary RF pulses, slice-selective excitation pulse, slice-selective\ninversion pulse, B1-insensitive volume inversion pulse, and B1-insensitive\nselective inversion pulse, that are commonly used in MRI. The results show that\nthe DeepRF-designed pulses successfully satisfy the design criteria while\nimproving specific absorption rates when compared to those of the conventional\nRF pulses. Further analyses suggest that the DeepRF-designed pulses utilize new\nmechanisms of magnetization manipulation that are difficult to be explained by\nconventional theory, suggesting the potentials of DeepRF in discovering unseen\ndesign dimensions beyond human intuition. This work may lay the foundation for\nan emerging field of AI-driven RF waveform design.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 04:22:27 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Shin", "Dongmyung", ""], ["Kim", "Younghoon", ""], ["Oh", "Chungseok", ""], ["An", "Hongjun", ""], ["Park", "Juhyung", ""], ["Kim", "Jiye", ""], ["Lee", "Jongho", ""]]}, {"id": "2105.03075", "submitter": "Steven Y. Feng", "authors": "Steven Y. Feng, Varun Gangal, Jason Wei, Sarath Chandar, Soroush\n  Vosoughi, Teruko Mitamura, Eduard Hovy", "title": "A Survey of Data Augmentation Approaches for NLP", "comments": "Accepted to ACL 2021 Findings. GitHub repo with paper list at\n  https://github.com/styfeng/DataAug4NLP", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation has recently seen increased interest in NLP due to more\nwork in low-resource domains, new tasks, and the popularity of large-scale\nneural networks that require large amounts of training data. Despite this\nrecent upsurge, this area is still relatively underexplored, perhaps due to the\nchallenges posed by the discrete nature of language data. In this paper, we\npresent a comprehensive and unifying survey of data augmentation for NLP by\nsummarizing the literature in a structured manner. We first introduce and\nmotivate data augmentation for NLP, and then discuss major methodologically\nrepresentative approaches. Next, we highlight techniques that are used for\npopular NLP applications and tasks. We conclude by outlining current challenges\nand directions for future research. Overall, our paper aims to clarify the\nlandscape of existing literature in data augmentation for NLP and motivate\nadditional work in this area. We also present a GitHub repository with a paper\nlist that will be continuously updated at\nhttps://github.com/styfeng/DataAug4NLP\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 06:03:45 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 23:39:31 GMT"}, {"version": "v3", "created": "Sat, 29 May 2021 21:57:45 GMT"}, {"version": "v4", "created": "Fri, 2 Jul 2021 20:34:55 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Feng", "Steven Y.", ""], ["Gangal", "Varun", ""], ["Wei", "Jason", ""], ["Chandar", "Sarath", ""], ["Vosoughi", "Soroush", ""], ["Mitamura", "Teruko", ""], ["Hovy", "Eduard", ""]]}, {"id": "2105.03090", "submitter": "Benjamin Doerr", "authors": "Henry Bambury, Antoine Bultel, Benjamin Doerr", "title": "An Extended Jump Function Benchmark for the Analysis of Randomized\n  Search Heuristics", "comments": "Extended version of a paper appearing in the proceedings of GECCO\n  2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Jump functions are the most studied non-unimodal benchmark in the theory of\nrandomized search heuristics, in particular, evolutionary algorithms (EAs).\nThey have significantly improved our understanding of how EAs escape from local\noptima. However, their particular structure -- to leave the local optimum one\ncan only jump directly to the global optimum -- raises the question of how\nrepresentative such results are.\n  For this reason, we propose an extended class $\\textsc{Jump}_{k,\\delta}$ of\njump functions that contain a valley of low fitness of width $\\delta$ starting\nat distance $k$ from the global optimum. We prove that several previous results\nextend to this more general class: for all $k = o(n^{1/3})$ and $\\delta < k$,\nthe optimal mutation rate for the $(1+1)$~EA is $\\frac{\\delta}{n}$, and the\nfast $(1+1)$~EA runs faster than the classical $(1+1)$~EA by a factor\nsuper-exponential in $\\delta$. However, we also observe that some known results\ndo not generalize: the randomized local search algorithm with stagnation\ndetection, which is faster than the fast $(1+1)$~EA by a factor polynomial in\n$k$ on $\\textsc{Jump}_k$, is slower by a factor polynomial in $n$ on some\n$\\textsc{Jump}_{k,\\delta}$ instances.\n  Computationally, the new class allows experiments with wider fitness valleys,\nespecially when they lie further away from the global optimum.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 07:21:10 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Bambury", "Henry", ""], ["Bultel", "Antoine", ""], ["Doerr", "Benjamin", ""]]}, {"id": "2105.03092", "submitter": "Marcus Kalander", "authors": "Keli Zhang, Marcus Kalander, Min Zhou, Xi Zhang and Junjian Ye", "title": "An Influence-based Approach for Root Cause Alarm Discovery in Telecom\n  Networks", "comments": null, "journal-ref": "International Workshop on Artificial Intelligence for IT\n  Operations (AIOPS) 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alarm root cause analysis is a significant component in the day-to-day\ntelecommunication network maintenance, and it is critical for efficient and\naccurate fault localization and failure recovery. In practice, accurate and\nself-adjustable alarm root cause analysis is a great challenge due to network\ncomplexity and vast amounts of alarms. A popular approach for failure root\ncause identification is to construct a graph with approximate edges, commonly\nbased on either event co-occurrences or conditional independence tests.\nHowever, considerable expert knowledge is typically required for edge pruning.\nWe propose a novel data-driven framework for root cause alarm localization,\ncombining both causal inference and network embedding techniques. In this\nframework, we design a hybrid causal graph learning method (HPCI), which\ncombines Hawkes Process with Conditional Independence tests, as well as propose\na novel Causal Propagation-Based Embedding algorithm (CPBE) to infer edge\nweights. We subsequently discover root cause alarms in a real-time data stream\nby applying an influence maximization algorithm on the weighted graph. We\nevaluate our method on artificial data and real-world telecom data, showing a\nsignificant improvement over the best baselines.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 07:41:46 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Zhang", "Keli", ""], ["Kalander", "Marcus", ""], ["Zhou", "Min", ""], ["Zhang", "Xi", ""], ["Ye", "Junjian", ""]]}, {"id": "2105.03123", "submitter": "Kostas Karpouzis", "authors": "Kostas Karpouzis and George Tsatiris", "title": "AI in (and for) Games", "comments": "Submitted to G. Tsihrintzis, M. Virvou, L. Tsoukalas,. A. Esposito,\n  L. Jain (Eds.), \"Artificial Intelligence and Assistive Technologies\",\n  Springer, 2021. arXiv admin note: text overlap with arXiv:2101.11333", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This chapter outlines the relation between artificial intelligence (AI) /\nmachine learning (ML) algorithms and digital games. This relation is two-fold:\non one hand, AI/ML researchers can generate large, in-the-wild datasets of\nhuman affective activity, player behaviour (i.e. actions within the game\nworld), commercial behaviour, interaction with graphical user interface\nelements or messaging with other players, while games can utilise intelligent\nalgorithms to automate testing of game levels, generate content, develop\nintelligent and responsive non-player characters (NPCs) or predict and respond\nplayer behaviour across a wide variety of player cultures. In this work, we\ndiscuss some of the most common and widely accepted uses of AI/ML in games and\nhow intelligent systems can benefit from those, elaborating on estimating\nplayer experience based on expressivity and performance, and on generating\nproper and interesting content for a language learning game.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 08:57:07 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Karpouzis", "Kostas", ""], ["Tsatiris", "George", ""]]}, {"id": "2105.03142", "submitter": "Frank Po Wen Lo", "authors": "Frank Po Wen Lo, Modou L Jobarteh, Yingnan Sun, Jianing Qiu, Shuo\n  Jiang, Gary Frost, Benny Lo", "title": "An Intelligent Passive Food Intake Assessment System with Egocentric\n  Cameras", "comments": "11 pages, 14 figures, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malnutrition is a major public health concern in low-and-middle-income\ncountries (LMICs). Understanding food and nutrient intake across communities,\nhouseholds and individuals is critical to the development of health policies\nand interventions. To ease the procedure in conducting large-scale dietary\nassessments, we propose to implement an intelligent passive food intake\nassessment system via egocentric cameras particular for households in Ghana and\nUganda. Algorithms are first designed to remove redundant images for minimising\nthe storage memory. At run time, deep learning-based semantic segmentation is\napplied to recognise multi-food types and newly-designed handcrafted features\nare extracted for further consumed food weight monitoring. Comprehensive\nexperiments are conducted to validate our methods on an in-the-wild dataset\ncaptured under the settings which simulate the unique LMIC conditions with\nparticipants of Ghanaian and Kenyan origin eating common Ghanaian/Kenyan\ndishes. To demonstrate the efficacy, experienced dietitians are involved in\nthis research to perform the visual portion size estimation, and their\npredictions are compared to our proposed method. The promising results have\nshown that our method is able to reliably monitor food intake and give feedback\non users' eating behaviour which provides guidance for dietitians in regular\ndietary assessment.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 09:47:51 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Lo", "Frank Po Wen", ""], ["Jobarteh", "Modou L", ""], ["Sun", "Yingnan", ""], ["Qiu", "Jianing", ""], ["Jiang", "Shuo", ""], ["Frost", "Gary", ""], ["Lo", "Benny", ""]]}, {"id": "2105.03143", "submitter": "Mohamed Seghir Hadj Ameur", "authors": "Mohamed Seghir Hadj Ameur, Hassina Aliane", "title": "AraCOVID19-MFH: Arabic COVID-19 Multi-label Fake News and Hate Speech\n  Detection Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Along with the COVID-19 pandemic, an \"infodemic\" of false and misleading\ninformation has emerged and has complicated the COVID-19 response efforts.\nSocial networking sites such as Facebook and Twitter have contributed largely\nto the spread of rumors, conspiracy theories, hate, xenophobia, racism, and\nprejudice. To combat the spread of fake news, researchers around the world have\nand are still making considerable efforts to build and share COVID-19 related\nresearch articles, models, and datasets. This paper releases \"AraCOVID19-MFH\" a\nmanually annotated multi-label Arabic COVID-19 fake news and hate speech\ndetection dataset. Our dataset contains 10,828 Arabic tweets annotated with 10\ndifferent labels. The labels have been designed to consider some aspects\nrelevant to the fact-checking task, such as the tweet's check worthiness,\npositivity/negativity, and factuality. To confirm our annotated dataset's\npractical utility, we used it to train and evaluate several classification\nmodels and reported the obtained results. Though the dataset is mainly designed\nfor fake news detection, it can also be used for hate speech detection,\nopinion/news classification, dialect identification, and many other tasks.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 09:52:44 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Ameur", "Mohamed Seghir Hadj", ""], ["Aliane", "Hassina", ""]]}, {"id": "2105.03148", "submitter": "Pingli Ma", "authors": "Chen Li, Pingli Ma, Md Mamunur Rahaman, Yudong Yao, Jiawei Zhang,\n  Shuojia Zou, Xin Zhao, Marcin Grzegorzek", "title": "A State-of-the-art Survey of Object Detection Techniques in\n  Microorganism Image Analysis: from Traditional Image Processing and Classical\n  Machine Learning to Current Deep Convolutional Neural Networks and Potential\n  Visual Transformers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Microorganisms play a vital role in human life. Therefore, microorganism\ndetection is of great significance to human beings. However, the traditional\nmanual microscopic detection methods have the disadvantages of long detection\ncycle, low detection accuracy in large orders, and great difficulty in\ndetecting uncommon microorganisms. Therefore, it is meaningful to apply\ncomputer image analysis technology to the field of microorganism detection.\nComputer image analysis can realize high-precision and high-efficiency\ndetection of microorganisms. In this review, first,we analyse the existing\nmicroorganism detection methods in chronological order, from traditional image\nprocessing and traditional machine learning to deep learning methods. Then, we\nanalyze and summarize these existing methods and introduce some potential\nmethods, including visual transformers. In the end, the future development\ndirection and challenges of microorganism detection are discussed. In general,\nwe have summarized 137 related technical papers from 1985 to the present. This\nreview will help researchers have a more comprehensive understanding of the\ndevelopment process, research status, and future trends in the field of\nmicroorganism detection and provide a reference for researchers in other\nfields.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 10:18:17 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Li", "Chen", ""], ["Ma", "Pingli", ""], ["Rahaman", "Md Mamunur", ""], ["Yao", "Yudong", ""], ["Zhang", "Jiawei", ""], ["Zou", "Shuojia", ""], ["Zhao", "Xin", ""], ["Grzegorzek", "Marcin", ""]]}, {"id": "2105.03170", "submitter": "Weibo Hu", "authors": "Chuan Chen, Weibo Hu, Ziyue Xu, Zibin Zheng", "title": "FedGL: Federated Graph Learning Framework with Global Self-Supervision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph data are ubiquitous in the real world. Graph learning (GL) tries to\nmine and analyze graph data so that valuable information can be discovered.\nExisting GL methods are designed for centralized scenarios. However, in\npractical scenarios, graph data are usually distributed in different\norganizations, i.e., the curse of isolated data islands. To address this\nproblem, we incorporate federated learning into GL and propose a general\nFederated Graph Learning framework FedGL, which is capable of obtaining a\nhigh-quality global graph model while protecting data privacy by discovering\nthe global self-supervision information during the federated training.\nConcretely, we propose to upload the prediction results and node embeddings to\nthe server for discovering the global pseudo label and global pseudo graph,\nwhich are distributed to each client to enrich the training labels and\ncomplement the graph structure respectively, thereby improving the quality of\neach local model. Moreover, the global self-supervision enables the information\nof each client to flow and share in a privacy-preserving manner, thus\nalleviating the heterogeneity and utilizing the complementarity of graph data\namong different clients. Finally, experimental results show that FedGL\nsignificantly outperforms baselines on four widely used graph datasets.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 11:27:23 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Chen", "Chuan", ""], ["Hu", "Weibo", ""], ["Xu", "Ziyue", ""], ["Zheng", "Zibin", ""]]}, {"id": "2105.03178", "submitter": "Gongxu Luo", "authors": "Gongxu Luo, Jianxin Li, Hao Peng, Carl Yang, Lichao Sun, Philip S. Yu,\n  Lifang He", "title": "Graph Entropy Guided Node Embedding Dimension Selection for Graph Neural\n  Networks", "comments": "Accept by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph representation learning has achieved great success in many areas,\nincluding e-commerce, chemistry, biology, etc. However, the fundamental problem\nof choosing the appropriate dimension of node embedding for a given graph still\nremains unsolved. The commonly used strategies for Node Embedding Dimension\nSelection (NEDS) based on grid search or empirical knowledge suffer from heavy\ncomputation and poor model performance. In this paper, we revisit NEDS from the\nperspective of minimum entropy principle. Subsequently, we propose a novel\nMinimum Graph Entropy (MinGE) algorithm for NEDS with graph data. To be\nspecific, MinGE considers both feature entropy and structure entropy on graphs,\nwhich are carefully designed according to the characteristics of the rich\ninformation in them. The feature entropy, which assumes the embeddings of\nadjacent nodes to be more similar, connects node features and link topology on\ngraphs. The structure entropy takes the normalized degree as basic unit to\nfurther measure the higher-order structure of graphs. Based on them, we design\nMinGE to directly calculate the ideal node embedding dimension for any graph.\nFinally, comprehensive experiments with popular Graph Neural Networks (GNNs) on\nbenchmark datasets demonstrate the effectiveness and generalizability of our\nproposed MinGE.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 11:40:29 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 12:29:48 GMT"}, {"version": "v3", "created": "Mon, 17 May 2021 06:50:03 GMT"}, {"version": "v4", "created": "Mon, 24 May 2021 06:30:01 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Luo", "Gongxu", ""], ["Li", "Jianxin", ""], ["Peng", "Hao", ""], ["Yang", "Carl", ""], ["Sun", "Lichao", ""], ["Yu", "Philip S.", ""], ["He", "Lifang", ""]]}, {"id": "2105.03192", "submitter": "Gauthier Chassang", "authors": "Gauthier Chassang (INSERM,PFGS), Mogens Thomsen (INSERM), Pierre\n  Rumeau, Florence S\\`edes (IRIT), Alejandra Delfin (INSERM)", "title": "An interdisciplinary conceptual study of Artificial Intelligence (AI)\n  for helping benefit-risk assessment practices: Towards a comprehensive\n  qualification matrix of AI programs and devices (pre-print 2020)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a comprehensive analysis of existing concepts coming from\ndifferent disciplines tackling the notion of intelligence, namely psychology\nand engineering, and from disciplines aiming to regulate AI innovations, namely\nAI ethics and law. The aim is to identify shared notions or discrepancies to\nconsider for qualifying AI systems. Relevant concepts are integrated into a\nmatrix intended to help defining more precisely when and how computing tools\n(programs or devices) may be qualified as AI while highlighting critical\nfeatures to serve a specific technical, ethical and legal assessment of\nchallenges in AI development. Some adaptations of existing notions of AI\ncharacteristics are proposed. The matrix is a risk-based conceptual model\ndesigned to allow an empirical, flexible and scalable qualification of AI\ntechnologies in the perspective of benefit-risk assessment practices,\ntechnological monitoring and regulatory compliance: it offers a structured\nreflection tool for stakeholders in AI development that are engaged in\nresponsible research and innovation.Pre-print version (achieved on May 2020)\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 12:01:31 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Chassang", "Gauthier", "", "INSERM,PFGS"], ["Thomsen", "Mogens", "", "INSERM"], ["Rumeau", "Pierre", "", "IRIT"], ["S\u00e8des", "Florence", "", "IRIT"], ["Delfin", "Alejandra", "", "INSERM"]]}, {"id": "2105.03193", "submitter": "Duong Le Hoang", "authors": "Duong H. Le, Binh-Son Hua", "title": "Network Pruning That Matters: A Case Study on Retraining Variants", "comments": "Accepted at ICLR 2021 (Poster)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Network pruning is an effective method to reduce the computational expense of\nover-parameterized neural networks for deployment on low-resource systems.\nRecent state-of-the-art techniques for retraining pruned networks such as\nweight rewinding and learning rate rewinding have been shown to outperform the\ntraditional fine-tuning technique in recovering the lost accuracy (Renda et\nal., 2020), but so far it is unclear what accounts for such performance. In\nthis work, we conduct extensive experiments to verify and analyze the uncanny\neffectiveness of learning rate rewinding. We find that the reason behind the\nsuccess of learning rate rewinding is the usage of a large learning rate.\nSimilar phenomenon can be observed in other learning rate schedules that\ninvolve large learning rates, e.g., the 1-cycle learning rate schedule (Smith\net al., 2019). By leveraging the right learning rate schedule in retraining, we\ndemonstrate a counter-intuitive phenomenon in that randomly pruned networks\ncould even achieve better performance than methodically pruned networks\n(fine-tuned with the conventional approach). Our results emphasize the\ncruciality of the learning rate schedule in pruned network retraining - a\ndetail often overlooked by practitioners during the implementation of network\npruning. One-sentence Summary: We study the effective of different retraining\nmechanisms while doing pruning\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 12:03:24 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Le", "Duong H.", ""], ["Hua", "Binh-Son", ""]]}, {"id": "2105.03216", "submitter": "Carlos Gershenson", "authors": "Carlos Gershenson", "title": "Emergence in artificial life", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.gen-ph cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concepts similar to emergence have been used since antiquity, but we lack an\nagreed definition of emergence. Still, emergence has been identified as one of\nthe features of complex systems. Most would agree on the statement \"life is\ncomplex\". Thus, understanding emergence and complexity should benefit the study\nof living systems. It can be said that life emerges from the interactions of\ncomplex molecules. But how useful is this to understand living systems?\nArtificial life (ALife) has been developed in recent decades to study life\nusing a synthetic approach: build it to understand it. ALife systems are not so\ncomplex, be them soft (simulations), hard (robots), or wet (protocells). Then,\nwe can aim at first understanding emergence in ALife, for then using this\nknowledge in biology. I argue that to understand emergence and life, it becomes\nuseful to use information as a framework. In a general sense, emergence can be\ndefined as information that is not present at one scale but is present at\nanother scale. This perspective avoids problems of studying emergence from a\nmaterialistic framework, and can be useful to study self-organization and\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 16:40:52 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Gershenson", "Carlos", ""]]}, {"id": "2105.03237", "submitter": "Arnab Kumar Mondal", "authors": "Arnab Kumar Mondal, Vineet Jain and Kaleem Siddiqi", "title": "Mini-batch graphs for robust image classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep learning models for classification tasks in computer vision are\ntrained using mini-batches. In the present article, we take advantage of the\nrelationships between samples in a mini-batch, using graph neural networks to\naggregate information from similar images. This helps mitigate the adverse\neffects of alterations to the input images on classification performance.\nDiverse experiments on image-based object and scene classification show that\nthis approach not only improves a classifier's performance but also increases\nits robustness to image perturbations and adversarial attacks. Further, we also\nshow that mini-batch graph neural networks can help to alleviate the problem of\nmode collapse in Generative Adversarial Networks.\n", "versions": [{"version": "v1", "created": "Thu, 22 Apr 2021 03:43:32 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Mondal", "Arnab Kumar", ""], ["Jain", "Vineet", ""], ["Siddiqi", "Kaleem", ""]]}, {"id": "2105.03265", "submitter": "Ozan \\c{C}atal", "authors": "Ozan \\c{C}atal, Wouter Jansen, Tim Verbelen, Bart Dhoedt and Jan\n  Steckel", "title": "LatentSLAM: unsupervised multi-sensor representation learning for\n  localization and mapping", "comments": "Accepted for publication at IEEE ICRA2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biologically inspired algorithms for simultaneous localization and mapping\n(SLAM) such as RatSLAM have been shown to yield effective and robust robot\nnavigation in both indoor and outdoor environments. One drawback however is the\nsensitivity to perceptual aliasing due to the template matching of\nlow-dimensional sensory templates. In this paper, we propose an unsupervised\nrepresentation learning method that yields low-dimensional latent state\ndescriptors that can be used for RatSLAM. Our method is sensor agnostic and can\nbe applied to any sensor modality, as we illustrate for camera images, radar\nrange-doppler maps and lidar scans. We also show how combining multiple sensors\ncan increase the robustness, by reducing the number of false matches. We\nevaluate on a dataset captured with a mobile robot navigating in a\nwarehouse-like environment, moving through different aisles with similar\nappearance, making it hard for the SLAM algorithms to disambiguate locations.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 13:44:32 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["\u00c7atal", "Ozan", ""], ["Jansen", "Wouter", ""], ["Verbelen", "Tim", ""], ["Dhoedt", "Bart", ""], ["Steckel", "Jan", ""]]}, {"id": "2105.03273", "submitter": "Daniel Karapetyan Dr", "authors": "Daniel Karapetyan and Gregory Gutin", "title": "Solving the Workflow Satisfiability Problem using General Purpose\n  Solvers", "comments": "Associated data: http://doi.org/10.17639/nott.7116", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The workflow satisfiability problem (WSP) is a well-studied problem in access\ncontrol seeking allocation of authorised users to every step of the workflow,\nsubject to workflow specification constraints. It was noticed that the number\n$k$ of steps is typically small compared to the number of users in the\nreal-world instances of WSP; therefore $k$ is considered as the parameter in\nWSP parametrised complexity research. While WSP in general was shown to be\nW[1]-hard, WSP restricted to a special case of user-independent (UI)\nconstraints is fixed-parameter tractable (FPT). However, restriction to the UI\nconstraints might be impractical.\n  To efficiently handle non-UI constraints, we introduce the notion of\nbranching factor of a constraint. As long as the branching factors of the\nconstraints are relatively small and the number of non-UI constraints is\nreasonable, WSP can be solved in FPT time.\n  Extending the results from Karapetyan et al. (2019), we demonstrate that\ngeneral-purpose solvers are capable of achieving FPT-like performance on WSP\nwith arbitrary constraints when used with appropriate formulations. This\nenables one to tackle most of practical WSP instances. While important on its\nown, we hope that this result will also motivate researchers to look for\nFPT-aware formulations of other FPT problems.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 13:59:30 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Karapetyan", "Daniel", ""], ["Gutin", "Gregory", ""]]}, {"id": "2105.03278", "submitter": "Jie Huang", "authors": "Jie Huang", "title": "A Multi-Size Neural Network with Attention Mechanism for Answer\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Semantic matching is of central significance to the answer selection task\nwhich aims to select correct answers for a given question from a candidate\nanswer pool. A useful method is to employ neural networks with attention to\ngenerate sentences representations in a way that information from pair\nsentences can mutually influence the computation of representations. In this\nwork, an effective architecture,multi-size neural network with attention\nmechanism (AM-MSNN),is introduced into the answer selection task. This\narchitecture captures more levels of language granularities in parallel,\nbecause of the various sizes of filters comparing with single-layer CNN and\nmulti-layer CNNs. Meanwhile it extends the sentence representations by\nattention mechanism, thus containing more information for different types of\nquestions. The empirical study on three various benchmark tasks of answer\nselection demonstrates the efficacy of the proposed model in all the benchmarks\nand its superiority over competitors. The experimental results show that (1)\nmulti-size neural network (MSNN) is a more useful method to capture abstract\nfeatures on different levels of granularities than single/multi-layer CNNs; (2)\nthe attention mechanism (AM) is a better strategy to derive more informative\nrepresentations; (3) AM-MSNN is a better architecture for the answer selection\ntask for the moment.\n", "versions": [{"version": "v1", "created": "Sat, 24 Apr 2021 02:13:26 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Huang", "Jie", ""]]}, {"id": "2105.03310", "submitter": "Yuan Pu", "authors": "Yuan Pu, Shaochen Wang, Xin Yao, Bin Li", "title": "Context-Based Soft Actor Critic for Environments with Non-stationary\n  Dynamics", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The performance of deep reinforcement learning methods prone to degenerate\nwhen applied to environments with non-stationary dynamics. In this paper, we\nutilize the latent context recurrent encoders motivated by recent Meta-RL\nmaterials, and propose the Latent Context-based Soft Actor Critic (LC-SAC)\nmethod to address aforementioned issues. By minimizing the contrastive\nprediction loss function, the learned context variables capture the information\nof the environment dynamics and the recent behavior of the agent. Then combined\nwith the soft policy iteration paradigm, the LC-SAC method alternates between\nsoft policy evaluation and soft policy improvement until it converges to the\noptimal policy. Experimental results show that the performance of LC-SAC is\nsignificantly better than the SAC algorithm on the MetaWorld ML1 tasks whose\ndynamics changes drasticly among different episodes, and is comparable to SAC\non the continuous control benchmark task MuJoCo whose dynamics changes slowly\nor doesn't change between different episodes. In addition, we also conduct\nrelevant experiments to determine the impact of different hyperparameter\nsettings on the performance of the LC-SAC algorithm and give the reasonable\nsuggestions of hyperparameter setting.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 15:00:59 GMT"}, {"version": "v2", "created": "Mon, 10 May 2021 09:25:53 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Pu", "Yuan", ""], ["Wang", "Shaochen", ""], ["Yao", "Xin", ""], ["Li", "Bin", ""]]}, {"id": "2105.03354", "submitter": "Dominik Dellermann", "authors": "Dominik Dellermann, Adrian Calma, Nikolaus Lipusch, Thorsten Weber,\n  Sascha Weigel, and Philipp Ebel", "title": "The future of human-AI collaboration: a taxonomy of design knowledge for\n  hybrid intelligence systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent technological advances, especially in the field of machine learning,\nprovide astonishing progress on the road towards artificial general\nintelligence. However, tasks in current real-world business applications cannot\nyet be solved by machines alone. We, therefore, identify the need for\ndeveloping socio-technological ensembles of humans and machines. Such systems\npossess the ability to accomplish complex goals by combining human and\nartificial intelligence to collectively achieve superior results and\ncontinuously improve by learning from each other. Thus, the need for structured\ndesign knowledge for those systems arises. Following a taxonomy development\nmethod, this article provides three main contributions: First, we present a\nstructured overview of interdisciplinary research on the role of humans in the\nmachine learning pipeline. Second, we envision hybrid intelligence systems and\nconceptualize the relevant dimensions for system design for the first time.\nFinally, we offer useful guidance for system developers during the\nimplementation of such applications.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 16:10:44 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Dellermann", "Dominik", ""], ["Calma", "Adrian", ""], ["Lipusch", "Nikolaus", ""], ["Weber", "Thorsten", ""], ["Weigel", "Sascha", ""], ["Ebel", "Philipp", ""]]}, {"id": "2105.03356", "submitter": "Dominik Dellermann", "authors": "Dominik Dellermann, Nikolaus Lipusch, Philipp Ebel, and Jan Marco\n  Leimeister", "title": "Design principles for a hybrid intelligence decision support system for\n  business model validation", "comments": null, "journal-ref": null, "doi": "10.1007/s12525-018-0309-2", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  One of the most critical tasks for startups is to validate their business\nmodel. Therefore, entrepreneurs try to collect information such as feedback\nfrom other actors to assess the validity of their assumptions and make\ndecisions. However, previous work on decisional guidance for business model\nvalidation provides no solution for the highly uncertain and complex context of\nearlystage startups. The purpose of this paper is, thus, to develop design\nprinciples for a Hybrid Intelligence decision support system (HI-DSS) that\ncombines the complementary capabilities of human and machine intelligence. We\nfollow a design science research approach to design a prototype artifact and a\nset of design principles. Our study provides prescriptive knowledge for HI-DSS\nand contributes to previous work on decision support for business models, the\napplications of complementary strengths of humans and machines for making\ndecisions, and support systems for extremely uncertain decision-making\nproblems.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 16:13:36 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Dellermann", "Dominik", ""], ["Lipusch", "Nikolaus", ""], ["Ebel", "Philipp", ""], ["Leimeister", "Jan Marco", ""]]}, {"id": "2105.03360", "submitter": "Dominik Dellermann", "authors": "Dominik Dellermann, Nikolaus Lipusch, Philipp Ebel, Karl Michael Popp,\n  and Jan Marco Leimeister", "title": "Finding the unicorn: Predicting early stage startup success through a\n  hybrid intelligence method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial intelligence is an emerging topic and will soon be able to perform\ndecisions better than humans. In more complex and creative contexts such as\ninnovation, however, the question remains whether machines are superior to\nhumans. Machines fail in two kinds of situations: processing and interpreting\nsoft information (information that cannot be quantified) and making predictions\nin unknowable risk situations of extreme uncertainty. In such situations, the\nmachine does not have representative information for a certain outcome.\nThereby, humans are still the gold standard for assessing soft signals and make\nuse of intuition. To predict the success of startups, we, thus, combine the\ncomplementary capabilities of humans and machines in a Hybrid Intelligence\nmethod. To reach our aim, we follow a design science research approach to\ndevelop a Hybrid Intelligence method that combines the strength of both machine\nand collective intelligence to demonstrate its utility for predictions under\nextreme uncertainty.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 16:16:36 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Dellermann", "Dominik", ""], ["Lipusch", "Nikolaus", ""], ["Ebel", "Philipp", ""], ["Popp", "Karl Michael", ""], ["Leimeister", "Jan Marco", ""]]}, {"id": "2105.03363", "submitter": "Weinan Zhang", "authors": "Weinan Zhang, Xihuai Wang, Jian Shen, Ming Zhou", "title": "Model-based Multi-agent Policy Optimization with Adaptive Opponent-wise\n  Rollouts", "comments": "Paper accepted at IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates the model-based methods in multi-agent reinforcement\nlearning (MARL). We specify the dynamics sample complexity and the opponent\nsample complexity in MARL, and conduct a theoretic analysis of return\ndiscrepancy upper bound. To reduce the upper bound with the intention of low\nsample complexity during the whole learning process, we propose a novel\ndecentralized model-based MARL method, named Adaptive Opponent-wise Rollout\nPolicy Optimization (AORPO). In AORPO, each agent builds its multi-agent\nenvironment model, consisting of a dynamics model and multiple opponent models,\nand trains its policy with the adaptive opponent-wise rollout. We further prove\nthe theoretic convergence of AORPO under reasonable assumptions. Empirical\nexperiments on competitive and cooperative tasks demonstrate that AORPO can\nachieve improved sample efficiency with comparable asymptotic performance over\nthe compared MARL methods.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 16:20:22 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 14:48:20 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zhang", "Weinan", ""], ["Wang", "Xihuai", ""], ["Shen", "Jian", ""], ["Zhou", "Ming", ""]]}, {"id": "2105.03365", "submitter": "Dominik Dellermann", "authors": "Dominik Dellermann", "title": "Accelerating Entrepreneurial Decision-Making Through Hybrid Intelligence", "comments": null, "journal-ref": null, "doi": "10.17170/kobra-202004301196", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accelerating Entrepreneurial Decision-Making Through Hybrid Intelligence\nDESIGN PARADIGMS AND PRINCIPLES FOR DECISIONAL GUIDANCE IN ENTREPRENEURSHIP\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 16:24:47 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Dellermann", "Dominik", ""]]}, {"id": "2105.03371", "submitter": "Haoyu Ren", "authors": "Haoyu Ren, Darko Anicic, Thomas Runkler", "title": "The Synergy of Complex Event Processing and Tiny Machine Learning in\n  Industrial IoT", "comments": "Accepted by The 15th ACM International Conference on Distributed and\n  Event-based Systems (DEBS) 2021", "journal-ref": null, "doi": "10.1145/3465480.3466928", "report-no": null, "categories": "cs.DC cs.AI cs.DB cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Focusing on comprehensive networking, big data, and artificial intelligence,\nthe Industrial Internet-of-Things (IIoT) facilitates efficiency and robustness\nin factory operations. Various sensors and field devices play a central role,\nas they generate a vast amount of real-time data that can provide insights into\nmanufacturing. The synergy of complex event processing (CEP) and machine\nlearning (ML) has been developed actively in the last years in IIoT to identify\npatterns in heterogeneous data streams and fuse raw data into tangible facts.\nIn a traditional compute-centric paradigm, the raw field data are continuously\nsent to the cloud and processed centrally. As IIoT devices become increasingly\npervasive and ubiquitous, concerns are raised since transmitting such amount of\ndata is energy-intensive, vulnerable to be intercepted, and subjected to high\nlatency. The data-centric paradigm can essentially solve these problems by\nempowering IIoT to perform decentralized on-device ML and CEP, keeping data\nprimarily on edge devices and minimizing communications. However, this is no\nmean feat because most IIoT edge devices are designed to be computationally\nconstrained with low power consumption. This paper proposes a framework that\nexploits ML and CEP's synergy at the edge in distributed sensor networks. By\nleveraging tiny ML and micro CEP, we shift the computation from the cloud to\nthe power-constrained IIoT devices and allow users to adapt the on-device ML\nmodel and the CEP reasoning logic flexibly on the fly without requiring to\nreupload the whole program. Lastly, we evaluate the proposed solution and show\nits effectiveness and feasibility using an industrial use case of machine\nsafety monitoring.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 14:58:48 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Ren", "Haoyu", ""], ["Anicic", "Darko", ""], ["Runkler", "Thomas", ""]]}, {"id": "2105.03388", "submitter": "Stanislav Sobolevsky", "authors": "Stanislav Sobolevsky", "title": "Hierarchical Graph Neural Networks", "comments": "12 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.CO physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the recent years, Graph Neural Networks have become increasingly popular\nin network analytic and beyond. With that, their architecture noticeable\ndiverges from the classical multi-layered hierarchical organization of the\ntraditional neural networks. At the same time, many conventional approaches in\nnetwork science efficiently utilize the hierarchical approaches to account for\nthe hierarchical organization of the networks, and recent works emphasize their\ncritical importance. This paper aims to connect the dots between the\ntraditional Neural Network and the Graph Neural Network architectures as well\nas the network science approaches, harnessing the power of the hierarchical\nnetwork organization. A Hierarchical Graph Neural Network architecture is\nproposed, supplementing the original input network layer with the hierarchy of\nauxiliary network layers and organizing the computational scheme updating the\nnode features through both - horizontal network connections within each layer\nas well as the vertical connection between the layers. It enables simultaneous\nlearning of the individual node features along with the aggregated network\nfeatures at variable resolution and uses them to improve the convergence and\nstability of the individual node feature learning. The proposed Hierarchical\nGraph Neural network architecture is successfully evaluated on the network\nembedding and modeling as well as network classification, node labeling, and\ncommunity tasks and demonstrates increased efficiency in those.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 16:47:18 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 14:35:38 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Sobolevsky", "Stanislav", ""]]}, {"id": "2105.03414", "submitter": "Niranj Jyothish", "authors": "Ajay Krishnan, Niranj Jyothish, Xun Jia", "title": "Using reinforcement learning to design an AI assistantfor a satisfying\n  co-op experience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this project, we designed an intelligent assistant player for the\nsingle-player game Space Invaders with the aim to provide a satisfying co-op\nexperience. The agent behaviour was designed using reinforcement learning\ntechniques and evaluated based on several criteria. We validate the hypothesis\nthat an AI-driven computer player can provide a satisfying co-op experience.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 17:44:02 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Krishnan", "Ajay", ""], ["Jyothish", "Niranj", ""], ["Jia", "Xun", ""]]}, {"id": "2105.03417", "submitter": "Mokanarangan Thayaparan", "authors": "Mokanarangan Thayaparan, Marco Valentino, Deborah Ferreira, Julia\n  Rozanova, Andr\\'e Freitas", "title": "$\\partial$-Explainer: Abductive Natural Language Inference via\n  Differentiable Convex Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constrained optimization solvers with Integer Linear programming (ILP) have\nbeen the cornerstone for explainable natural language inference during its\ninception. ILP based approaches provide a way to encode explicit and\ncontrollable assumptions casting natural language inference as an abductive\nreasoning problem, where the solver constructs a plausible explanation for a\ngiven hypothesis. While constrained based solvers provide explanations, they\nare often limited by the use of explicit constraints and cannot be integrated\nas part of broader deep neural architectures. In contrast, state-of-the-art\ntransformer-based models can learn from data and implicitly encode complex\nconstraints. However, these models are intrinsically black boxes. This paper\npresents a novel framework named $\\partial$-Explainer (Diff-Explainer) that\ncombines the best of both worlds by casting the constrained optimization as\npart of a deep neural network via differentiable convex optimization and\nfine-tuning pre-trained transformers for downstream explainable NLP tasks. To\ndemonstrate the efficacy of the framework, we transform the constraints\npresented by TupleILP and integrate them with sentence embedding transformers\nfor the task of explainable science QA. Our experiments show up to $\\approx\n10\\%$ improvement over non-differentiable solver while still providing\nexplanations for supporting its inference.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 17:49:19 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Thayaparan", "Mokanarangan", ""], ["Valentino", "Marco", ""], ["Ferreira", "Deborah", ""], ["Rozanova", "Julia", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "2105.03491", "submitter": "Gregor Bachmann", "authors": "Gregor Bachmann, Seyed-Mohsen Moosavi-Dezfooli, Thomas Hofmann", "title": "Uniform Convergence, Adversarial Spheres and a Simple Remedy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous work has cast doubt on the general framework of uniform convergence\nand its ability to explain generalization in neural networks. By considering a\nspecific dataset, it was observed that a neural network completely\nmisclassifies a projection of the training data (adversarial set), rendering\nany existing generalization bound based on uniform convergence vacuous. We\nprovide an extensive theoretical investigation of the previously studied data\nsetting through the lens of infinitely-wide models. We prove that the Neural\nTangent Kernel (NTK) also suffers from the same phenomenon and we uncover its\norigin. We highlight the important role of the output bias and show\ntheoretically as well as empirically how a sensible choice completely mitigates\nthe problem. We identify sharp phase transitions in the accuracy on the\nadversarial set and study its dependency on the training sample size. As a\nresult, we are able to characterize critical sample sizes beyond which the\neffect disappears. Moreover, we study decompositions of a neural network into a\nclean and noisy part by considering its canonical decomposition into its\ndifferent eigenfunctions and show empirically that for too small bias the\nadversarial phenomenon still persists.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 20:23:01 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Bachmann", "Gregor", ""], ["Moosavi-Dezfooli", "Seyed-Mohsen", ""], ["Hofmann", "Thomas", ""]]}, {"id": "2105.03540", "submitter": "Tianyu Liu", "authors": "Lingyu Zhang and Tianyu Liu and Yunhai Wang", "title": "An Intelligent Model for Solving Manpower Scheduling Problems", "comments": "none", "journal-ref": "BDAI 2021", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The manpower scheduling problem is a critical research field in the resource\nmanagement area. Based on the existing studies on scheduling problem solutions,\nthis paper transforms the manpower scheduling problem into a combinational\noptimization problem under multi-constraint conditions from a new perspective.\nIt also uses logical paradigms to build a mathematical model for problem\nsolution and an improved multi-dimensional evolution algorithm for solving the\nmodel. Moreover, the constraints discussed in this paper basically cover all\nthe requirements of human resource coordination in modern society and are\nsupported by our experiment results. In the discussion part, we compare our\nmodel with other heuristic algorithms or linear programming methods and prove\nthat the model proposed in this paper makes a 25.7% increase in efficiency and\na 17% increase in accuracy at most. In addition, to the numerical solution of\nthe manpower scheduling problem, this paper also studies the algorithm for\nscheduling task list generation and the method of displaying scheduling\nresults. As a result, we not only provide various modifications for the basic\nalgorithm to solve different condition problems but also propose a new\nalgorithm that increases at least 28.91% in time efficiency by comparing with\ndifferent baseline models.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 23:51:12 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Zhang", "Lingyu", ""], ["Liu", "Tianyu", ""], ["Wang", "Yunhai", ""]]}, {"id": "2105.03546", "submitter": "Austin Nguyen", "authors": "Austin Anhkhoi Nguyen", "title": "Scalable, Decentralized Multi-Agent Reinforcement Learning Methods\n  Inspired by Stigmergy and Ant Colonies", "comments": "50 pages, 40 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bolstering multi-agent learning algorithms to tackle complex coordination and\ncontrol tasks has been a long-standing challenge of on-going research. Numerous\nmethods have been proposed to help reduce the effects of non-stationarity and\nunscalability. In this work, we investigate a novel approach to decentralized\nmulti-agent learning and planning that attempts to address these two\nchallenges. In particular, this method is inspired by the cohesion,\ncoordination, and behavior of ant colonies. As a result, these algorithms are\ndesigned to be naturally scalable to systems with numerous agents. While no\noptimality is guaranteed, the method is intended to work well in practice and\nscale better in efficacy with the number of agents present than others. The\napproach combines single-agent RL and an ant-colony-inspired decentralized,\nstigmergic algorithm for multi-agent path planning and environment\nmodification. Specifically, we apply this algorithm in a setting where agents\nmust navigate to a goal location, learning to push rectangular boxes into holes\nto yield new traversable pathways. It is shown that while the approach yields\npromising success in this particular environment, it may not be as easily\ngeneralized to others. The algorithm designed is notably scalable to numerous\nagents but is limited in its performance due to its relatively simplistic,\nrule-based approach. Furthermore, the composability of RL-trained policies is\ncalled into question, where, while policies are successful in their training\nenvironments, applying trained policies to a larger-scale, multi-agent\nframework results in unpredictable behavior.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 01:04:51 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Nguyen", "Austin Anhkhoi", ""]]}, {"id": "2105.03567", "submitter": "Weibin Li", "authors": "Weibin Li, Qiwei Zhong, Qingyang Zhao, Hongchun Zhang, Xiaonan Meng", "title": "Multimodal and Contrastive Learning for Click Fraud Detection", "comments": "Accepted to DeMal@WWW 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advertising click fraud detection plays one of the vital roles in current\nE-commerce websites as advertising is an essential component of its business\nmodel. It aims at, given a set of corresponding features, e.g., demographic\ninformation of users and statistical features of clicks, predicting whether a\nclick is fraudulent or not in the community. Recent efforts attempted to\nincorporate attributed behavior sequence and heterogeneous network for\nextracting complex features of users and achieved significant effects on click\nfraud detection. In this paper, we propose a Multimodal and Contrastive\nlearning network for Click Fraud detection (MCCF). Specifically, motivated by\nthe observations on differences of demographic information, behavior sequences\nand media relationship between fraudsters and genuine users on E-commerce\nplatform, MCCF jointly utilizes wide and deep features, behavior sequence and\nheterogeneous network to distill click representations. Moreover, these three\nmodules are integrated by contrastive learning and collaboratively contribute\nto the final predictions. With the real-world datasets containing 2.54 million\nclicks on Alibaba platform, we investigate the effectiveness of MCCF. The\nexperimental results show that the proposed approach is able to improve AUC by\n7.2% and F1-score by 15.6%, compared with the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 03:03:11 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Li", "Weibin", ""], ["Zhong", "Qiwei", ""], ["Zhao", "Qingyang", ""], ["Zhang", "Hongchun", ""], ["Meng", "Xiaonan", ""]]}, {"id": "2105.03588", "submitter": "Zhuofa Chen", "authors": "Yousif Khaireddin, Zhuofa Chen", "title": "Facial Emotion Recognition: State of the Art Performance on FER2013", "comments": "9 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Facial emotion recognition (FER) is significant for human-computer\ninteraction such as clinical practice and behavioral description. Accurate and\nrobust FER by computer models remains challenging due to the heterogeneity of\nhuman faces and variations in images such as different facial pose and\nlighting. Among all techniques for FER, deep learning models, especially\nConvolutional Neural Networks (CNNs) have shown great potential due to their\npowerful automatic feature extraction and computational efficiency. In this\nwork, we achieve the highest single-network classification accuracy on the\nFER2013 dataset. We adopt the VGGNet architecture, rigorously fine-tune its\nhyperparameters, and experiment with various optimization methods. To our best\nknowledge, our model achieves state-of-the-art single-network accuracy of 73.28\n% on FER2013 without using extra training data.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 04:20:53 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Khaireddin", "Yousif", ""], ["Chen", "Zhuofa", ""]]}, {"id": "2105.03591", "submitter": "Pengyuan Zhou", "authors": "Pengyuan Zhou, Pei Fang, Pan Hui", "title": "Loss Tolerant Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated learning has attracted attention in recent years for\ncollaboratively training data on distributed devices with privacy-preservation.\nThe limited network capacity of mobile and IoT devices has been seen as one of\nthe major challenges for cross-device federated learning. Recent solutions have\nbeen focusing on threshold-based client selection schemes to guarantee the\ncommunication efficiency. However, we find this approach can cause biased\nclient selection and results in deteriorated performance. Moreover, we find\nthat the challenge of network limit may be overstated in some cases and the\npacket loss is not always harmful. In this paper, we explore the loss tolerant\nfederated learning (LT-FL) in terms of aggregation, fairness, and\npersonalization. We use ThrowRightAway (TRA) to accelerate the data uploading\nfor low-bandwidth-devices by intentionally ignoring some packet losses. The\nresults suggest that, with proper integration, TRA and other algorithms can\ntogether guarantee the personalization and fairness performance in the face of\npacket loss below a certain fraction (10%-30%).\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 04:44:47 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhou", "Pengyuan", ""], ["Fang", "Pei", ""], ["Hui", "Pan", ""]]}, {"id": "2105.03640", "submitter": "Emanuele La Malfa", "authors": "Emanuele La Malfa, Agnieszka Zbrzezny, Rhiannon Michelmore, Nicola\n  Paoletti and Marta Kwiatkowska", "title": "On Guaranteed Optimal Robust Explanations for NLP Models", "comments": "13 pages (8+5 Appendix). Accepted as long-paper at IJCAI 2021", "journal-ref": "IJCAI 2021", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build on abduction-based explanations for ma-chine learning and develop a\nmethod for computing local explanations for neural network models in natural\nlanguage processing (NLP). Our explanations comprise a subset of the words of\nthe in-put text that satisfies two key features: optimality w.r.t. a\nuser-defined cost function, such as the length of explanation, and robustness,\nin that they ensure prediction invariance for any bounded perturbation in the\nembedding space of the left out words. We present two solution algorithms,\nrespectively based on implicit hitting sets and maximum universal subsets,\nintroducing a number of algorithmic improvements to speed up convergence of\nhard instances. We show how our method can be con-figured with different\nperturbation sets in the em-bedded space and used to detect bias in predictions\nby enforcing include/exclude constraints on biased terms, as well as to enhance\nexisting heuristic-based NLP explanation frameworks such as Anchors. We\nevaluate our framework on three widely used sentiment analysis tasks and texts\nof up to100words from SST, Twitter and IMDB datasets,demonstrating the\neffectiveness of the derived explanations.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 08:44:48 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 08:41:57 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["La Malfa", "Emanuele", ""], ["Zbrzezny", "Agnieszka", ""], ["Michelmore", "Rhiannon", ""], ["Paoletti", "Nicola", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "2105.03641", "submitter": "Zhixian Yang", "authors": "Zhixian Yang, Xiaojun Wan", "title": "Neural Text Generation with Part-of-Speech Guided Softmax", "comments": "Main text: 8 pages, 2 figures, 8 tables. Supplementary Information: 2\n  pages, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural text generation models are likely to suffer from the low-diversity\nproblem. Various decoding strategies and training-based methods have been\nproposed to promote diversity only by exploiting contextual features, but\nrarely do they consider incorporating syntactic structure clues. In this work,\nwe propose using linguistic annotation, i.e., part-of-speech (POS), to guide\nthe text generation. In detail, we introduce POS Guided Softmax (POSG-Softmax)\nto explicitly model two posterior probabilities: (i) next-POS, and (ii)\nnext-token from the vocabulary of the target POS. A POS guided sampling\nstrategy is further proposed to address the low-diversity problem by enriching\nthe diversity of POS. Extensive experiments and human evaluations demonstrate\nthat, compared with existing state-of-the-art methods, our proposed methods can\ngenerate more diverse text while maintaining comparable quality.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 08:53:16 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Yang", "Zhixian", ""], ["Wan", "Xiaojun", ""]]}, {"id": "2105.03654", "submitter": "Xinyu Wang", "authors": "Xinyu Wang, Yong Jiang, Nguyen Bach, Tao Wang, Zhongqiang Huang, Fei\n  Huang, Kewei Tu", "title": "Improving Named Entity Recognition by External Context Retrieving and\n  Cooperative Learning", "comments": "Accepted to ACL 2021, 12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent advances in Named Entity Recognition (NER) show that document-level\ncontexts can significantly improve model performance. In many application\nscenarios, however, such contexts are not available. In this paper, we propose\nto find external contexts of a sentence by retrieving and selecting a set of\nsemantically relevant texts through a search engine, with the original sentence\nas the query. We find empirically that the contextual representations computed\non the retrieval-based input view, constructed through the concatenation of a\nsentence and its external contexts, can achieve significantly improved\nperformance compared to the original input view based only on the sentence.\nFurthermore, we can improve the model performance of both input views by\nCooperative Learning, a training method that encourages the two input views to\nproduce similar contextual representations or output label distributions.\nExperiments show that our approach can achieve new state-of-the-art performance\non 8 NER data sets across 5 domains.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 09:45:21 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 02:08:10 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Wang", "Xinyu", ""], ["Jiang", "Yong", ""], ["Bach", "Nguyen", ""], ["Wang", "Tao", ""], ["Huang", "Zhongqiang", ""], ["Huang", "Fei", ""], ["Tu", "Kewei", ""]]}, {"id": "2105.03680", "submitter": "Maciej Swiechowski PhD", "authors": "Maciej \\'Swiechowski", "title": "A Crossover That Matches Diverse Parents Together in Evolutionary\n  Algorithms", "comments": "Accepted to GECCO 2021", "journal-ref": null, "doi": "10.1145/3449726.3459431", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Crossover and mutation are the two main operators that lead to new solutions\nin evolutionary approaches. In this article, a new method of performing the\ncrossover phase is presented. The problem of choice is evolutionary decision\ntree construction. The method aims at finding such individuals that together\ncomplement each other. Hence we say that they are diversely specialized. We\npropose the way of calculating the so-called complementary fitness. In several\nempirical experiments, we evaluate the efficacy of the method proposed in four\nvariants and compare it to a fitness-rank-based approach. One variant emerges\nclearly as the best approach, whereas the remaining ones are below the\nbaseline.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 11:43:26 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["\u015awiechowski", "Maciej", ""]]}, {"id": "2105.03701", "submitter": "Evgeny Krivosheev", "authors": "Evgeny Krivosheev, Mattia Atzeni, Katsiaryna Mirylenka, Paolo Scotton,\n  Christoph Miksovic, Anton Zorin", "title": "Business Entity Matching with Siamese Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Data integration has been studied extensively for decades and approached from\ndifferent angles. However, this domain still remains largely rule-driven and\nlacks universal automation. Recent developments in machine learning and in\nparticular deep learning have opened the way to more general and efficient\nsolutions to data-integration tasks. In this paper, we demonstrate an approach\nthat allows modeling and integrating entities by leveraging their relations and\ncontextual information. This is achieved by combining siamese and graph neural\nnetworks to effectively propagate information between connected entities and\nsupport high scalability. We evaluated our approach on the task of integrating\ndata about business entities, demonstrating that it outperforms both\ntraditional rule-based systems and other deep learning approaches.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 13:47:52 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Krivosheev", "Evgeny", ""], ["Atzeni", "Mattia", ""], ["Mirylenka", "Katsiaryna", ""], ["Scotton", "Paolo", ""], ["Miksovic", "Christoph", ""], ["Zorin", "Anton", ""]]}, {"id": "2105.03726", "submitter": "Kathrin Grosse", "authors": "Lukas Bieringer, Kathrin Grosse, Michael Backes, Katharina Krombholz", "title": "Mental Models of Adversarial Machine Learning", "comments": "19 pages, 8 figures, under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although machine learning (ML) is widely used in practice, little is known\nabout practitioners' actual understanding of potential security challenges. In\nthis work, we close this substantial gap in the literature and contribute a\nqualitative study focusing on developers' mental models of the ML pipeline and\npotentially vulnerable components. Studying mental models has helped in other\nsecurity fields to discover root causes or improve risk communication. Our\nstudy reveals four characteristic ranges in mental models of industrial\npractitioners. The first range concerns the intertwined relationship of\nadversarial machine learning (AML) and classical security. The second range\ndescribes structural and functional components. The third range expresses\nindividual variations of mental models, which are neither explained by the\napplication nor by the educational background of the corresponding subjects.\nThe fourth range corresponds to the varying levels of technical depth, which\nare however not determined by our subjects' level of knowledge. Our\ncharacteristic ranges have implications for the integration of AML into\ncorporate workflows, security enhancing tools for practitioners, and creating\nappropriate regulatory frameworks for AML.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 16:05:07 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Bieringer", "Lukas", ""], ["Grosse", "Kathrin", ""], ["Backes", "Michael", ""], ["Krombholz", "Katharina", ""]]}, {"id": "2105.03733", "submitter": "Lingwei Peng", "authors": "Lingwei Peng, Hui Qian, Zhebang Shen, Chao Zhang, Fei Li", "title": "Generative Actor-Critic: An Off-policy Algorithm Using the Push-forward\n  Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-free deep reinforcement learning has achieved great success in many\ndomains, such as video games, recommendation systems and robotic control tasks.\nIn continuous control tasks, widely used policies with Gaussian distributions\nresults in ineffective exploration of environments and limited performance of\nalgorithms in many cases. In this paper, we propose a density-free off-policy\nalgorithm, Generative Actor-Critic(GAC), using the push-forward model to\nincrease the expressiveness of policies, which also includes an entropy-like\ntechnique, MMD-entropy regularizer, to balance the exploration and\nexploitation. Additionnally, we devise an adaptive mechanism to automatically\nscale this regularizer, which further improves the stability and robustness of\nGAC. The experiment results show that push-forward policies possess desirable\nfeatures, such as multi-modality, which can improve the efficiency of\nexploration and asymptotic performance of algorithms obviously.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 16:29:20 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 15:29:17 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Peng", "Lingwei", ""], ["Qian", "Hui", ""], ["Shen", "Zhebang", ""], ["Zhang", "Chao", ""], ["Li", "Fei", ""]]}, {"id": "2105.03736", "submitter": "Sourjya Roy", "authors": "Sourjya Roy, Mustafa Ali and Anand Raghunathan", "title": "PIM-DRAM: Accelerating Machine Learning Workloads using Processing in\n  Commodity DRAM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Neural Networks (DNNs) have transformed the field of machine learning\nand are widely deployed in many applications involving image, video, speech and\nnatural language processing. The increasing compute demands of DNNs have been\nwidely addressed through Graphics Processing Units (GPUs) and specialized\naccelerators. However, as model sizes grow, these von Neumann architectures\nrequire very high memory bandwidth to keep the processing elements utilized as\na majority of the data resides in the main memory. Processing in memory has\nbeen proposed as a promising solution for the memory wall bottleneck for ML\nworkloads. In this work, we propose a new DRAM-based processing-in-memory (PIM)\nmultiplication primitive coupled with intra-bank accumulation to accelerate\nmatrix vector operations in ML workloads. The proposed multiplication primitive\nadds < 1% area overhead and does not require any change in the DRAM\nperipherals. Therefore, the proposed multiplication can be easily adopted in\ncommodity DRAM chips. Subsequently, we design a DRAM-based PIM architecture,\ndata mapping scheme and dataflow for executing DNNs within DRAM. System\nevaluations performed on networks like AlexNet, VGG16 and ResNet18 show that\nthe proposed architecture, mapping, and data flow can provide up to 23x speedup\nover an NVIDIA Titan Xp GPU. Furthermore, it achieves upto 6.5x speedup over an\nideal von Neumann architecture with infinite computational throughput,\nhighlighting the need to overcome the memory bottleneck in future generations\nof DNN hardware.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 16:39:24 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 19:47:44 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Roy", "Sourjya", ""], ["Ali", "Mustafa", ""], ["Raghunathan", "Anand", ""]]}, {"id": "2105.03752", "submitter": "Bicheng Yan", "authors": "Bicheng Yan, Dylan Robert Harp, Bailian Chen, Rajesh J. Pawar", "title": "Improving Deep Learning Performance for Predicting Large-Scale\n  Porous-Media Flow through Feature Coarsening", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.AI cs.LG physics.comp-ph", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Physics-based simulation for fluid flow in porous media is a computational\ntechnology to predict the temporal-spatial evolution of state variables (e.g.\npressure) in porous media, and usually requires high computational expense due\nto its nonlinearity and the scale of the study domain. This letter describes a\ndeep learning (DL) workflow to predict the pressure evolution as fluid flows in\nlarge-scale 3D heterogeneous porous media. In particular, we apply feature\ncoarsening technique to extract the most representative information and perform\nthe training and prediction of DL at the coarse scale, and further recover the\nresolution at the fine scale by 2D piecewise cubic interpolation. We validate\nthe DL approach that is trained from physics-based simulation data to predict\npressure field in a field-scale 3D geologic CO_2 storage reservoir. We evaluate\nthe impact of feature coarsening on DL performance, and observe that the\nfeature coarsening can not only decrease training time by >74% and reduce\nmemory consumption by >75%, but also maintains temporal error <1.5%. Besides,\nthe DL workflow provides predictive efficiency with ~1400 times speedup\ncompared to physics-based simulation.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 17:58:46 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Yan", "Bicheng", ""], ["Harp", "Dylan Robert", ""], ["Chen", "Bailian", ""], ["Pawar", "Rajesh J.", ""]]}, {"id": "2105.03793", "submitter": "Yunwen Lei", "authors": "Yunwen Lei, Zhenhuan Yang, Tianbao Yang, Yiming Ying", "title": "Stability and Generalization of Stochastic Gradient Methods for Minimax\n  Problems", "comments": "To appear in ICML 2021 as Long Presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many machine learning problems can be formulated as minimax problems such as\nGenerative Adversarial Networks (GANs), AUC maximization and robust estimation,\nto mention but a few. A substantial amount of studies are devoted to studying\nthe convergence behavior of their stochastic gradient-type algorithms. In\ncontrast, there is relatively little work on their generalization, i.e., how\nthe learning models built from training examples would behave on test examples.\nIn this paper, we provide a comprehensive generalization analysis of stochastic\ngradient methods for minimax problems under both convex-concave and\nnonconvex-nonconcave cases through the lens of algorithmic stability. We\nestablish a quantitative connection between stability and several\ngeneralization measures both in expectation and with high probability. For the\nconvex-concave setting, our stability analysis shows that stochastic gradient\ndescent ascent attains optimal generalization bounds for both smooth and\nnonsmooth minimax problems. We also establish generalization bounds for both\nweakly-convex-weakly-concave and gradient-dominated problems.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 22:38:00 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 19:32:31 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Lei", "Yunwen", ""], ["Yang", "Zhenhuan", ""], ["Yang", "Tianbao", ""], ["Ying", "Yiming", ""]]}, {"id": "2105.03797", "submitter": "Bin Wang", "authors": "Kaitai Zhang, Bin Wang, Wei Wang, Fahad Sohrab, Moncef Gabbouj and\n  C.-C. Jay Kuo", "title": "AnomalyHop: An SSL-based Image Anomaly Localization Method", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An image anomaly localization method based on the successive subspace\nlearning (SSL) framework, called AnomalyHop, is proposed in this work.\nAnomalyHop consists of three modules: 1) feature extraction via successive\nsubspace learning (SSL), 2) normality feature distributions modeling via\nGaussian models, and 3) anomaly map generation and fusion. Comparing with\nstate-of-the-art image anomaly localization methods based on deep neural\nnetworks (DNNs), AnomalyHop is mathematically transparent, easy to train, and\nfast in its inference speed. Besides, its area under the ROC curve (ROC-AUC)\nperformance on the MVTec AD dataset is 95.9%, which is among the best of\nseveral benchmarking methods. Our codes are publicly available at Github.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 23:17:27 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhang", "Kaitai", ""], ["Wang", "Bin", ""], ["Wang", "Wei", ""], ["Sohrab", "Fahad", ""], ["Gabbouj", "Moncef", ""], ["Kuo", "C. -C. Jay", ""]]}, {"id": "2105.03799", "submitter": "Dr.Vijay Bhaskar Semwal", "authors": "Vijay Bhaskar Semwal, Neha Gaud and G.C.Nandi", "title": "Human Gait State Prediction Using Cellular Automata and Classification\n  Using ELM", "comments": "Machine Intelligence and Signal Analysis conference. Published in\n  book Advances in Intelligent Systems and Computing, vol 748. Springer,\n  Singapore. arXiv admin note: substantial text overlap with arXiv:1710.06548", "journal-ref": null, "doi": "10.1007/978-981-13-0923-6", "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research article, we have reported periodic cellular automata rules\nfor different gait state prediction and classification of the gait data using\nextreme machine Leaning (ELM). This research is the first attempt to use\ncellular automaton to understand the complexity of bipedal walk. Due to\nnonlinearity, varying configurations throughout the gait cycle and the passive\njoint located at the unilateral foot-ground contact in bipedal walk resulting\nvariation of dynamic descriptions and control laws from phase to phase for\nhuman gait is making difficult to predict the bipedal walk states. We have\ndesigned the cellular automata rules which will predict the next gait state of\nbipedal steps based on the previous two neighbour states. We have designed\ncellular automata rules for normal walk. The state prediction will help to\ncorrectly design the bipedal walk. The normal walk depends on next two states\nand has total 8 states. We have considered the current and previous states to\npredict next state. So we have formulated 16 rules using cellular automata, 8\nrules for each leg. The priority order maintained using the fact that if right\nleg in swing phase then left leg will be in stance phase. To validate the model\nwe have classified the gait Data using ELM [1] and achieved accuracy 60%. We\nhave explored the trajectories and compares with another gait trajectories.\nFinally we have presented the error analysis for different joints.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 23:47:32 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Semwal", "Vijay Bhaskar", ""], ["Gaud", "Neha", ""], ["Nandi", "G. C.", ""]]}, {"id": "2105.03804", "submitter": "Farzaneh Rajabi", "authors": "Austin Park, Farzaneh Rajabi, Ross Weber", "title": "Slash or burn: Power line and vegetation classification for wildfire\n  prevention", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Electric utilities are struggling to manage increasing wildfire risk in a\nhotter and drier climate. Utility transmission and distribution lines regularly\nignite destructive fires when they make contact with surrounding vegetation.\nTrimming vegetation to maintain the separation from utility assets is as\ncritical to safety as it is difficult. Each utility has tens of thousands of\nlinear miles to manage, poor knowledge of where those assets are located, and\nno way to prioritize trimming. Feature-enhanced convolutional neural networks\n(CNNs) have proven effective in this problem space. Histograms of oriented\ngradients (HOG) and Hough transforms are used to increase the salience of the\nlinear structures like power lines and poles. Data is frequently taken from\ndrone or satellite footage, but Google Street View offers an even more scalable\nand lower cost solution. This paper uses $1,320$ images scraped from Street\nView, transfer learning on popular CNNs, and feature engineering to place\nimages in one of three classes: (1) no utility systems, (2) utility systems\nwith no overgrown vegetation, or (3) utility systems with overgrown vegetation.\nThe CNN output thus yields a prioritized vegetation management system and\ncreates a geotagged map of utility assets as a byproduct. Test set accuracy\nwith reached $80.15\\%$ using VGG11 with a trained first layer and classifier,\nand a model ensemble correctly classified $88.88\\%$ of images with risky\nvegetation overgrowth.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 00:34:37 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Park", "Austin", ""], ["Rajabi", "Farzaneh", ""], ["Weber", "Ross", ""]]}, {"id": "2105.03811", "submitter": "Farzaneh Rajabi", "authors": "Farzaneh Rajabi, Jack Siyuan He", "title": "Click-Through Rate Prediction Using Graph Neural Networks and Online\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommendation systems have been extensively studied by many literature in\nthe past and are ubiquitous in online advertisement, shopping\nindustry/e-commerce, query suggestions in search engines, and friend\nrecommendation in social networks. Moreover,\nrestaurant/music/product/movie/news/app recommendations are only a few of the\napplications of a recommender system. A small percent improvement on the CTR\nprediction accuracy has been mentioned to add millions of dollars of revenue to\nthe advertisement industry. Click-Through-Rate (CTR) prediction is a special\nversion of recommender system in which the goal is predicting whether or not a\nuser is going to click on a recommended item. A content-based recommendation\napproach takes into account the past history of the user's behavior, i.e. the\nrecommended products and the users reaction to them. So, a personalized model\nthat recommends the right item to the right user at the right time is the key\nto building such a model. On the other hand, the so-called collaborative\nfiltering approach incorporates the click history of the users who are very\nsimilar to a particular user, thereby helping the recommender to come up with a\nmore confident prediction for that particular user by leveraging the wider\nknowledge of users who share their taste in a connected network of users. In\nthis project, we are interested in building a CTR predictor using Graph Neural\nNetworks complemented by an online learning algorithm that models such dynamic\ninteractions. By framing the problem as a binary classification task, we have\nevaluated this system both on the offline models (GNN, Deep Factorization\nMachines) with test-AUC of 0.7417 and on the online learning model with\ntest-AUC of 0.7585 using a sub-sampled version of Criteo public dataset\nconsisting of 10,000 data points.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 01:35:49 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Rajabi", "Farzaneh", ""], ["He", "Jack Siyuan", ""]]}, {"id": "2105.03821", "submitter": "Yuheng Lu", "authors": "Yuheng Lu, Jinpeng Chen, ChuXiong Sun, Jie Hu", "title": "Graph Inference Representation: Learning Graph Positional Embeddings\n  with Anchor Path Encoding", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning node representations that incorporate information from graph\nstructure benefits wide range of tasks on graph. The majority of existing graph\nneural networks (GNNs) have limited power in capturing position information for\na given node. The idea of positioning nodes with selected anchors has been\nexploited, yet mainly relying on explicit labeling of distance information.\nHere we propose Graph Inference Representation (GIR), an anchor based GNN model\nencoding path information related to pre-selected anchors for each node.\nAbilities to get position-aware embeddings are theoretically and experimentally\ninvestigated on GIR and its core variants. Further, the complementarity between\nGIRs and typical GNNs is demonstrated. We show that GIRs get outperformed\nresults in position-aware scenarios, and performances on typical GNNs could be\nimproved by fusing GIR embeddings.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 03:25:58 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 14:53:25 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lu", "Yuheng", ""], ["Chen", "Jinpeng", ""], ["Sun", "ChuXiong", ""], ["Hu", "Jie", ""]]}, {"id": "2105.03831", "submitter": "Guangyan Zhou", "authors": "Guangyan Zhou, Wei Xu", "title": "Super Solutions of the Model RB", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The concept of super solution is a special type of generalized solutions with\ncertain degree of robustness and stability. In this paper we consider the\n$(1,1)$-super solutions of the model RB. Using the first moment method, we\nestablish a \"threshold\" such that as the constraint density crosses this value,\nthe expected number of $(1,1)$-super solutions goes from $0$ to infinity.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 04:17:34 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhou", "Guangyan", ""], ["Xu", "Wei", ""]]}, {"id": "2105.03844", "submitter": "Sihang Chen", "authors": "Sihang Chen, Weiqi Luo and Chao Yu", "title": "Reinforcement Learning with Expert Trajectory For Quantitative Trading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-fin.TR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, quantitative investment methods combined with artificial\nintelligence have attracted more and more attention from investors and\nresearchers. Existing related methods based on the supervised learning are not\nvery suitable for learning problems with long-term goals and delayed rewards in\nreal futures trading. In this paper, therefore, we model the price prediction\nproblem as a Markov decision process (MDP), and optimize it by reinforcement\nlearning with expert trajectory. In the proposed method, we employ more than\n100 short-term alpha factors instead of price, volume and several technical\nfactors in used existing methods to describe the states of MDP. Furthermore,\nunlike DQN (deep Q-learning) and BC (behavior cloning) in related methods, we\nintroduce expert experience in training stage, and consider both the\nexpert-environment interaction and the agent-environment interaction to design\nthe temporal difference error so that the agents are more adaptable for\ninevitable noise in financial data. Experimental results evaluated on share\nprice index futures in China, including IF (CSI 300) and IC (CSI 500), show\nthat the advantages of the proposed method compared with three typical\ntechnical analysis and two deep leaning based methods.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 05:49:21 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Chen", "Sihang", ""], ["Luo", "Weiqi", ""], ["Yu", "Chao", ""]]}, {"id": "2105.03876", "submitter": "Saeed Bakhshi Germi", "authors": "Saeed Bakhshi Germi and Esa Rahtu and Heikki Huttunen", "title": "Selective Probabilistic Classifier Based on Hypothesis Testing", "comments": "Accepted in EUVIP 2021 conference. Comments: Copyright statement\n  added to first page in new version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a simple yet effective method to deal with the\nviolation of the Closed-World Assumption for a classifier. Previous works tend\nto apply a threshold either on the classification scores or the loss function\nto reject the inputs that violate the assumption. However, these methods cannot\nachieve the low False Positive Ratio (FPR) required in safety applications. The\nproposed method is a rejection option based on hypothesis testing with\nprobabilistic networks. With probabilistic networks, it is possible to estimate\nthe distribution of outcomes instead of a single output. By utilizing Z-test\nover the mean and standard deviation for each class, the proposed method can\nestimate the statistical significance of the network certainty and reject\nuncertain outputs. The proposed method was experimented on with different\nconfigurations of the COCO and CIFAR datasets. The performance of the proposed\nmethod is compared with the Softmax Response, which is a known top-performing\nmethod. It is shown that the proposed method can achieve a broader range of\noperation and cover a lower FPR than the alternative.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 08:55:56 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 20:41:58 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Germi", "Saeed Bakhshi", ""], ["Rahtu", "Esa", ""], ["Huttunen", "Heikki", ""]]}, {"id": "2105.03923", "submitter": "Shihong Deng", "authors": "Changnan Xiao, Haosen Shi, Jiajun Fan, Shihong Deng", "title": "CASA: A Bridge Between Gradient of Policy Improvement and Policy\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel design of model-free reinforcement learning,\nCASA, Critic AS an Actor. CASA follows the actor-critic framework that\nestimates state-value, state-action-value and policy simultaneously. We prove\nthat CASA integrates a consistent path for the policy evaluation and the policy\nimprovement, which completely eliminates the gradient conflict between the\npolicy improvement and the policy evaluation. The policy evaluation is\nequivalent to a compensational policy improvement, which alleviates the\nfunction approximation error, and is also equivalent to an entropy-regularized\npolicy improvement, which prevents the policy from being trapped into a\nsuboptimal solution. Building on this design, an expectation-correct Doubly\nRobust Trace is introduced to learn state-value and state-action-value, and the\nconvergence is guaranteed. Our experiments show that the design achieves\nState-Of-The-Art on Arcade Learning Environment.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 12:45:13 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 12:50:54 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 16:28:16 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Xiao", "Changnan", ""], ["Shi", "Haosen", ""], ["Fan", "Jiajun", ""], ["Deng", "Shihong", ""]]}, {"id": "2105.03943", "submitter": "Rishi Hazra", "authors": "Rishi Hazra and Sonu Dixit", "title": "gComm: An environment for investigating generalization in Grounded\n  Language Acquisition", "comments": "Accepted in NAACL 2021 workshop: Visually Grounded Interaction and\n  Language (ViGIL). arXiv admin note: substantial text overlap with\n  arXiv:2012.05011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  gComm is a step towards developing a robust platform to foster research in\ngrounded language acquisition in a more challenging and realistic setting. It\ncomprises a 2-d grid environment with a set of agents (a stationary speaker and\na mobile listener connected via a communication channel) exposed to a\ncontinuous array of tasks in a partially observable setting. The key to solving\nthese tasks lies in agents developing linguistic abilities and utilizing them\nfor efficiently exploring the environment. The speaker and listener have access\nto information provided in different modalities, i.e. the speaker's input is a\nnatural language instruction that contains the target and task specifications\nand the listener's input is its grid-view. Each must rely on the other to\ncomplete the assigned task, however, the only way they can achieve the same, is\nto develop and use some form of communication. gComm provides several tools for\nstudying different forms of communication and assessing their generalization.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 13:44:55 GMT"}, {"version": "v2", "created": "Sun, 16 May 2021 01:20:15 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hazra", "Rishi", ""], ["Dixit", "Sonu", ""]]}, {"id": "2105.03953", "submitter": "Zihan Liu", "authors": "Zihan Liu, Genta Indra Winata, Pascale Fung", "title": "Continual Mixed-Language Pre-Training for Extremely Low-Resource Neural\n  Machine Translation", "comments": "Accepted in Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data scarcity in low-resource languages has become a bottleneck to\nbuilding robust neural machine translation systems. Fine-tuning a multilingual\npre-trained model (e.g., mBART (Liu et al., 2020)) on the translation task is a\ngood approach for low-resource languages; however, its performance will be\ngreatly limited when there are unseen languages in the translation pairs. In\nthis paper, we present a continual pre-training (CPT) framework on mBART to\neffectively adapt it to unseen languages. We first construct noisy\nmixed-language text from the monolingual corpus of the target language in the\ntranslation pair to cover both the source and target languages, and then, we\ncontinue pre-training mBART to reconstruct the original monolingual text.\nResults show that our method can consistently improve the fine-tuning\nperformance upon the mBART baseline, as well as other strong baselines, across\nall tested low-resource translation pairs containing unseen languages.\nFurthermore, our approach also boosts the performance on translation pairs\nwhere both languages are seen in the original mBART's pre-training. The code is\navailable at https://github.com/zliucr/cpt-nmt.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 14:49:07 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Fung", "Pascale", ""]]}, {"id": "2105.03962", "submitter": "Arun Verma", "authors": "Arun Verma, Manjesh K. Hanawal", "title": "Stochastic Multi-Armed Bandits with Control Variates", "comments": "26 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper studies a new variant of the stochastic multi-armed bandits\nproblem, where the learner has access to auxiliary information about the arms.\nThe auxiliary information is correlated with the arm rewards, which we treat as\ncontrol variates. In many applications, the arm rewards are a function of some\nexogenous values, whose mean value is known a priori from historical data and\nhence can be used as control variates. We use the control variates to obtain\nmean estimates with smaller variance and tighter confidence bounds. We then\ndevelop an algorithm named UCB-CV that uses improved estimates. We characterize\nthe regret bounds in terms of the correlation between the rewards and control\nvariates. The experiments on synthetic data validate the performance guarantees\nof our proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 15:40:09 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Verma", "Arun", ""], ["Hanawal", "Manjesh K.", ""]]}, {"id": "2105.03986", "submitter": "Sarit Kraus", "authors": "Aviram Aviv, Yaniv Oshrat, Samuel A. Assefa, Tobi Mustapha, Daniel\n  Borrajo, Manuela Veloso, Sarit Kraus", "title": "Advising Agent for Service-Providing Live-Chat Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Call centers, in which human operators attend clients using textual chat, are\nvery common in modern e-commerce. Training enough skilled operators who are\nable to provide good service is a challenge. We suggest an algorithm and a\nmethod to train and implement an assisting agent that provides on-line advice\nto operators while they attend clients. The agent is domain-independent and can\nbe introduced to new domains without major efforts in design, training and\norganizing structured knowledge of the professional discipline. We demonstrate\nthe applicability of the system in an experiment that realizes its full\nlife-cycle on a specific domain and analyze its capabilities.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 18:10:54 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 13:46:48 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Aviv", "Aviram", ""], ["Oshrat", "Yaniv", ""], ["Assefa", "Samuel A.", ""], ["Mustapha", "Tobi", ""], ["Borrajo", "Daniel", ""], ["Veloso", "Manuela", ""], ["Kraus", "Sarit", ""]]}, {"id": "2105.04021", "submitter": "Bhaskar Mitra", "authors": "Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos and Jimmy\n  Lin", "title": "MS MARCO: Benchmarking Ranking Models in the Large-Data Regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation efforts such as TREC, CLEF, NTCIR and FIRE, alongside public\nleaderboard such as MS MARCO, are intended to encourage research and track our\nprogress, addressing big questions in our field. However, the goal is not\nsimply to identify which run is \"best\", achieving the top score. The goal is to\nmove the field forward by developing new robust techniques, that work in many\ndifferent settings, and are adopted in research and practice. This paper uses\nthe MS MARCO and TREC Deep Learning Track as our case study, comparing it to\nthe case of TREC ad hoc ranking in the 1990s. We show how the design of the\nevaluation effort can encourage or discourage certain outcomes, and raising\nquestions about internal and external validity of results. We provide some\nanalysis of certain pitfalls, and a statement of best practices for avoiding\nsuch pitfalls. We summarize the progress of the effort so far, and describe our\ndesired end state of \"robust usefulness\", along with steps that might be\nrequired to get us there.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 20:57:36 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Craswell", "Nick", ""], ["Mitra", "Bhaskar", ""], ["Yilmaz", "Emine", ""], ["Campos", "Daniel", ""], ["Lin", "Jimmy", ""]]}, {"id": "2105.04027", "submitter": "Panayiotis Danassis", "authors": "Panayiotis Danassis, Florian Wiedemair, Boi Faltings", "title": "Improving Multi-agent Coordination by Learning to Estimate Contention", "comments": "Accepted to the 30th International Joint Conference on Artificial\n  Intelligence (IJCAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-agent learning algorithm, ALMA-Learning, for efficient and\nfair allocations in large-scale systems. We circumvent the traditional pitfalls\nof multi-agent learning (e.g., the moving target problem, the curse of\ndimensionality, or the need for mutually consistent actions) by relying on the\nALMA heuristic as a coordination mechanism for each stage game. ALMA-Learning\nis decentralized, observes only own action/reward pairs, requires no\ninter-agent communication, and achieves near-optimal (<5% loss) and fair\ncoordination in a variety of synthetic scenarios and a real-world meeting\nscheduling problem. The lightweight nature and fast learning constitute\nALMA-Learning ideal for on-device deployment.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 21:30:48 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 17:53:24 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Danassis", "Panayiotis", ""], ["Wiedemair", "Florian", ""], ["Faltings", "Boi", ""]]}, {"id": "2105.04045", "submitter": "Yingbo Li", "authors": "Yingbo Li, Yucong Duan, Zakaria Maama, Haoyang Che, Anamaria-Beatrice\n  Spulber, Stelios Fuentes", "title": "Swarm Differential Privacy for Purpose Driven\n  Data-Information-Knowledge-Wisdom Architecture", "comments": null, "journal-ref": "Mobile Information Systems. Volume 2021, Article ID 6671628. 28\n  Jun 2021", "doi": "10.1155/2021/6671628", "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Privacy protection has recently been in the spotlight of attention to both\nacademia and industry. Society protects individual data privacy through complex\nlegal frameworks. The increasing number of applications of data science and\nartificial intelligence has resulted in a higher demand for the ubiquitous\napplication of the data. The privacy protection of the broad\nData-Information-Knowledge-Wisdom (DIKW) landscape, the next generation of\ninformation organization, has taken a secondary role. In this paper, we will\nexplore DIKW architecture through the applications of the popular swarm\nintelligence and differential privacy. As differential privacy proved to be an\neffective data privacy approach, we will look at it from a DIKW domain\nperspective. Swarm Intelligence can effectively optimize and reduce the number\nof items in DIKW used in differential privacy, thus accelerating both the\neffectiveness and the efficiency of differential privacy for crossing multiple\nmodals of conceptual DIKW. The proposed approach is demonstrated through the\napplication of personalized data that is based on the open-sourse IRIS dataset.\nThis experiment demonstrates the efficiency of Swarm Intelligence in reducing\ncomputing complexity.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 23:09:07 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 07:27:40 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 18:50:20 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Li", "Yingbo", ""], ["Duan", "Yucong", ""], ["Maama", "Zakaria", ""], ["Che", "Haoyang", ""], ["Spulber", "Anamaria-Beatrice", ""], ["Fuentes", "Stelios", ""]]}, {"id": "2105.04066", "submitter": "Bin Zhao", "authors": "Bin Zhao, Haopeng Li, Xiaoqiang Lu, Xuelong Li", "title": "Reconstructive Sequence-Graph Network for Video Summarization", "comments": "Accepted by IEEE TPAMI 2021", "journal-ref": null, "doi": "10.1109/TPAMI.2021.3072117", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting the inner-shot and inter-shot dependencies is essential for\nkey-shot based video summarization. Current approaches mainly devote to\nmodeling the video as a frame sequence by recurrent neural networks. However,\none potential limitation of the sequence models is that they focus on capturing\nlocal neighborhood dependencies while the high-order dependencies in long\ndistance are not fully exploited. In general, the frames in each shot record a\ncertain activity and vary smoothly over time, but the multi-hop relationships\noccur frequently among shots. In this case, both the local and global\ndependencies are important for understanding the video content. Motivated by\nthis point, we propose a Reconstructive Sequence-Graph Network (RSGN) to encode\nthe frames and shots as sequence and graph hierarchically, where the\nframe-level dependencies are encoded by Long Short-Term Memory (LSTM), and the\nshot-level dependencies are captured by the Graph Convolutional Network (GCN).\nThen, the videos are summarized by exploiting both the local and global\ndependencies among shots. Besides, a reconstructor is developed to reward the\nsummary generator, so that the generator can be optimized in an unsupervised\nmanner, which can avert the lack of annotated data in video summarization.\nFurthermore, under the guidance of reconstruction loss, the predicted summary\ncan better preserve the main video content and shot-level dependencies.\nPractically, the experimental results on three popular datasets i.e., SumMe,\nTVsum and VTW) have demonstrated the superiority of our proposed approach to\nthe summarization task.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 01:47:55 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhao", "Bin", ""], ["Li", "Haopeng", ""], ["Lu", "Xiaoqiang", ""], ["Li", "Xuelong", ""]]}, {"id": "2105.04067", "submitter": "Yixin Su", "authors": "Yixin Su and Rui Zhang and Sarah Erfani and Junhao Gan", "title": "Neural Graph Matching based Collaborative Filtering", "comments": "10 pages, 6 figures, 4 tables, SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462833", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User and item attributes are essential side-information; their interactions\n(i.e., their co-occurrence in the sample data) can significantly enhance\nprediction accuracy in various recommender systems. We identify two different\ntypes of attribute interactions, inner interactions and cross interactions:\ninner interactions are those between only user attributes or those between only\nitem attributes; cross interactions are those between user attributes and item\nattributes. Existing models do not distinguish these two types of attribute\ninteractions, which may not be the most effective way to exploit the\ninformation carried by the interactions. To address this drawback, we propose a\nneural Graph Matching based Collaborative Filtering model (GMCF), which\neffectively captures the two types of attribute interactions through modeling\nand aggregating attribute interactions in a graph matching structure for\nrecommendation. In our model, the two essential recommendation procedures,\ncharacteristic learning and preference matching, are explicitly conducted\nthrough graph learning (based on inner interactions) and node matching (based\non cross interactions), respectively. Experimental results show that our model\noutperforms state-of-the-art models. Further studies verify the effectiveness\nof GMCF in improving the accuracy of recommendation.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 01:51:46 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 01:53:56 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Su", "Yixin", ""], ["Zhang", "Rui", ""], ["Erfani", "Sarah", ""], ["Gan", "Junhao", ""]]}, {"id": "2105.04088", "submitter": "Zan Wang", "authors": "Hanqing Wang, Zan Wang, Wei Liang, Lap-Fai Yu", "title": "PEARL: Parallelized Expert-Assisted Reinforcement Learning for Scene\n  Rearrangement Planning", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scene Rearrangement Planning (SRP) is an interior task proposed recently. The\nprevious work defines the action space of this task with handcrafted\ncoarse-grained actions that are inflexible to be used for transforming scene\narrangement and intractable to be deployed in practice. Additionally, this new\ntask lacks realistic indoor scene rearrangement data to feed popular\ndata-hungry learning approaches and meet the needs of quantitative evaluation.\nTo address these problems, we propose a fine-grained action definition for SRP\nand introduce a large-scale scene rearrangement dataset. We also propose a\nnovel learning paradigm to efficiently train an agent through self-playing,\nwithout any prior knowledge. The agent trained via our paradigm achieves\nsuperior performance on the introduced dataset compared to the baseline agents.\nWe provide a detailed analysis of the design of our approach in our\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 03:27:16 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Wang", "Hanqing", ""], ["Wang", "Zan", ""], ["Liang", "Wei", ""], ["Yu", "Lap-Fai", ""]]}, {"id": "2105.04098", "submitter": "Chun Yuan Yuan", "authors": "Chunyuan Yuan, Wanhui Qian, Qianwen Ma, Wei Zhou, Songlin Hu", "title": "SRLF: A Stance-aware Reinforcement Learning Framework for Content-based\n  Rumor Detection on Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The rapid development of social media changes the lifestyle of people and\nsimultaneously provides an ideal place for publishing and disseminating rumors,\nwhich severely exacerbates social panic and triggers a crisis of social trust.\nEarly content-based methods focused on finding clues from the text and user\nprofiles for rumor detection. Recent studies combine the stances of users'\ncomments with news content to capture the difference between true and false\nrumors. Although the user's stance is effective for rumor detection, the manual\nlabeling process is time-consuming and labor-intensive, which limits the\napplication of utilizing it to facilitate rumor detection.\n  In this paper, we first finetune a pre-trained BERT model on a small labeled\ndataset and leverage this model to annotate weak stance labels for users'\ncomment data to overcome the problem mentioned above. Then, we propose a novel\nStance-aware Reinforcement Learning Framework (SRLF) to select high-quality\nlabeled stance data for model training and rumor detection. Both the stance\nselection and rumor detection tasks are optimized simultaneously to promote\nboth tasks mutually. We conduct experiments on two commonly used real-world\ndatasets. The experimental results demonstrate that our framework outperforms\nthe state-of-the-art models significantly, which confirms the effectiveness of\nthe proposed framework.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 03:58:34 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Yuan", "Chunyuan", ""], ["Qian", "Wanhui", ""], ["Ma", "Qianwen", ""], ["Zhou", "Wei", ""], ["Hu", "Songlin", ""]]}, {"id": "2105.04120", "submitter": "Pranshu Malviya", "authors": "Yash Pratyush Sinha, Pranshu Malviya, Rupaj Kumar Nayak", "title": "Fast constraint satisfaction problem and learning-based algorithm for\n  solving Minesweeper", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minesweeper is a popular spatial-based decision-making game that works with\nincomplete information. As an exemplary NP-complete problem, it is a major area\nof research employing various artificial intelligence paradigms. The present\nwork models this game as Constraint Satisfaction Problem (CSP) and Markov\nDecision Process (MDP). We propose a new method named as dependents from the\nindependent set using deterministic solution search (DSScsp) for the faster\nenumeration of all solutions of a CSP based Minesweeper game and improve the\nresults by introducing heuristics. Using MDP, we implement machine learning\nmethods on these heuristics. We train the classification model on sparse data\nwith results from CSP formulation. We also propose a new rewarding method for\napplying a modified deep Q-learning for better accuracy and versatile learning\nin the Minesweeper game. The overall results have been analyzed for different\nkinds of Minesweeper games and their accuracies have been recorded. Results\nfrom these experiments show that the proposed method of MDP based\nclassification model and deep Q-learning overall is the best methods in terms\nof accuracy for games with given mine densities.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 05:27:15 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Sinha", "Yash Pratyush", ""], ["Malviya", "Pranshu", ""], ["Nayak", "Rupaj Kumar", ""]]}, {"id": "2105.04126", "submitter": "Yiming Cui", "authors": "Yiming Cui, Ting Liu, Wanxiang Che, Zhigang Chen, Shijin Wang", "title": "ExpMRC: Explainability Evaluation for Machine Reading Comprehension", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Achieving human-level performance on some of Machine Reading Comprehension\n(MRC) datasets is no longer challenging with the help of powerful Pre-trained\nLanguage Models (PLMs). However, it is necessary to provide both answer\nprediction and its explanation to further improve the MRC system's reliability,\nespecially for real-life applications. In this paper, we propose a new\nbenchmark called ExpMRC for evaluating the explainability of the MRC systems.\nExpMRC contains four subsets, including SQuAD, CMRC 2018, RACE$^+$, and C$^3$\nwith additional annotations of the answer's evidence. The MRC systems are\nrequired to give not only the correct answer but also its explanation. We use\nstate-of-the-art pre-trained language models to build baseline systems and\nadopt various unsupervised approaches to extract evidence without a\nhuman-annotated training set. The experimental results show that these models\nare still far from human performance, suggesting that the ExpMRC is\nchallenging. Resources will be available through\nhttps://github.com/ymcui/expmrc\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 06:00:20 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Cui", "Yiming", ""], ["Liu", "Ting", ""], ["Che", "Wanxiang", ""], ["Chen", "Zhigang", ""], ["Wang", "Shijin", ""]]}, {"id": "2105.04129", "submitter": "Andrew Jacobsen", "authors": "Andrew Jacobsen, Alan Chan", "title": "Parameter-free Gradient Temporal Difference Learning", "comments": "30 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning lies at the intersection of several challenges. Many\napplications of interest involve extremely large state spaces, requiring\nfunction approximation to enable tractable computation. In addition, the\nlearner has only a single stream of experience with which to evaluate a large\nnumber of possible courses of action, necessitating algorithms which can learn\noff-policy. However, the combination of off-policy learning with function\napproximation leads to divergence of temporal difference methods. Recent work\ninto gradient-based temporal difference methods has promised a path to\nstability, but at the cost of expensive hyperparameter tuning. In parallel,\nprogress in online learning has provided parameter-free methods that achieve\nminimax optimal guarantees up to logarithmic terms, but their application in\nreinforcement learning has yet to be explored. In this work, we combine these\ntwo lines of attack, deriving parameter-free, gradient-based temporal\ndifference algorithms. Our algorithms run in linear time and achieve\nhigh-probability convergence guarantees matching those of GTD2 up to $\\log$\nfactors. Our experiments demonstrate that our methods maintain high prediction\nperformance relative to fully-tuned baselines, with no tuning whatsoever.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 06:07:05 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Jacobsen", "Andrew", ""], ["Chan", "Alan", ""]]}, {"id": "2105.04154", "submitter": "Luca Schmidtke", "authors": "Luca Schmidtke, Athanasios Vlontzos, Simon Ellershaw, Anna Lukens,\n  Tomoki Arichi, Bernhard Kainz", "title": "Unsupervised Human Pose Estimation through Transforming Shape Templates", "comments": "CVPR 2021 (poster). Project page: https://infantmotion.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human pose estimation is a major computer vision problem with applications\nranging from augmented reality and video capture to surveillance and movement\ntracking. In the medical context, the latter may be an important biomarker for\nneurological impairments in infants. Whilst many methods exist, their\napplication has been limited by the need for well annotated large datasets and\nthe inability to generalize to humans of different shapes and body\ncompositions, e.g. children and infants. In this paper we present a novel\nmethod for learning pose estimators for human adults and infants in an\nunsupervised fashion. We approach this as a learnable template matching problem\nfacilitated by deep feature extractors. Human-interpretable landmarks are\nestimated by transforming a template consisting of predefined body parts that\nare characterized by 2D Gaussian distributions. Enforcing a connectivity prior\nguides our model to meaningful human shape representations. We demonstrate the\neffectiveness of our approach on two different datasets including adults and\ninfants.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 07:15:56 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Schmidtke", "Luca", ""], ["Vlontzos", "Athanasios", ""], ["Ellershaw", "Simon", ""], ["Lukens", "Anna", ""], ["Arichi", "Tomoki", ""], ["Kainz", "Bernhard", ""]]}, {"id": "2105.04158", "submitter": "Alessandro Antonucci", "authors": "Rafael Caba\\~nas and Alessandro Antonucci", "title": "CREPO: An Open Repository to Benchmark Credal Network Algorithms", "comments": "Isipta 2021 (Version with Supplementary Material)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Credal networks are a popular class of imprecise probabilistic graphical\nmodels obtained as a Bayesian network generalization based on, so-called\ncredal, sets of probability mass functions. A Java library called CREMA has\nbeen recently released to model, process and query credal networks. Despite the\nNP-hardness of the (exact) task, a number of algorithms is available to\napproximate credal network inferences. In this paper we present CREPO, an open\nrepository of synthetic credal networks, provided together with the exact\nresults of inference tasks on these models. A Python tool is also delivered to\nload these data and interact with CREMA, thus making extremely easy to evaluate\nand compare existing and novel inference algorithms. To demonstrate such\nbenchmarking scheme, we propose an approximate heuristic to be used inside\nvariable elimination schemes to keep a bound on the maximum number of vertices\ngenerated during the combination step. A CREPO-based validation against\napproximate procedures based on linearization and exact techniques performed in\nCREMA is finally discussed.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 07:31:59 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Caba\u00f1as", "Rafael", ""], ["Antonucci", "Alessandro", ""]]}, {"id": "2105.04165", "submitter": "Pan Lu", "authors": "Pan Lu, Ran Gong, Shibiao Jiang, Liang Qiu, Siyuan Huang, Xiaodan\n  Liang, Song-Chun Zhu", "title": "Inter-GPS: Interpretable Geometry Problem Solving with Formal Language\n  and Symbolic Reasoning", "comments": "Accepted to ACL 2021, 13 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Geometry problem solving has attracted much attention in the NLP community\nrecently. The task is challenging as it requires abstract problem understanding\nand symbolic reasoning with axiomatic knowledge. However, current datasets are\neither small in scale or not publicly available. Thus, we construct a new\nlarge-scale benchmark, Geometry3K, consisting of 3,002 geometry problems with\ndense annotation in formal language. We further propose a novel geometry\nsolving approach with formal language and symbolic reasoning, called\nInterpretable Geometry Problem Solver (Inter-GPS). Inter-GPS first parses the\nproblem text and diagram into formal language automatically via rule-based text\nparsing and neural object detecting, respectively. Unlike implicit learning in\nexisting methods, Inter-GPS incorporates theorem knowledge as conditional rules\nand performs symbolic reasoning step by step. Also, a theorem predictor is\ndesigned to infer the theorem application sequence fed to the symbolic solver\nfor the more efficient and reasonable searching path. Extensive experiments on\nthe Geometry3K and GEOS datasets demonstrate that Inter-GPS achieves\nsignificant improvements over existing methods. The project with code and data\nis available at https://lupantech.github.io/inter-gps.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 07:46:55 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 19:28:02 GMT"}, {"version": "v3", "created": "Tue, 20 Jul 2021 23:22:27 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Lu", "Pan", ""], ["Gong", "Ran", ""], ["Jiang", "Shibiao", ""], ["Qiu", "Liang", ""], ["Huang", "Siyuan", ""], ["Liang", "Xiaodan", ""], ["Zhu", "Song-Chun", ""]]}, {"id": "2105.04246", "submitter": "Marios Fournarakis", "authors": "Marios Fournarakis, Markus Nagel", "title": "In-Hindsight Quantization Range Estimation for Quantized Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Quantization techniques applied to the inference of deep neural networks have\nenabled fast and efficient execution on resource-constraint devices. The\nsuccess of quantization during inference has motivated the academic community\nto explore fully quantized training, i.e. quantizing back-propagation as well.\nHowever, effective gradient quantization is still an open problem. Gradients\nare unbounded and their distribution changes significantly during training,\nwhich leads to the need for dynamic quantization. As we show, dynamic\nquantization can lead to significant memory overhead and additional data\ntraffic slowing down training. We propose a simple alternative to dynamic\nquantization, in-hindsight range estimation, that uses the quantization ranges\nestimated on previous iterations to quantize the present. Our approach enables\nfast static quantization of gradients and activations while requiring only\nminimal hardware support from the neural network accelerator to keep track of\noutput statistics in an online fashion. It is intended as a drop-in replacement\nfor estimating quantization ranges and can be used in conjunction with other\nadvances in quantized training. We compare our method to existing methods for\nrange estimation from the quantized training literature and demonstrate its\neffectiveness with a range of architectures, including MobileNetV2, on image\nclassification benchmarks (Tiny ImageNet & ImageNet).\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 10:25:28 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Fournarakis", "Marios", ""], ["Nagel", "Markus", ""]]}, {"id": "2105.04250", "submitter": "Dominik Drexler", "authors": "Dominik Drexler and Jendrik Seipp and Hector Geffner", "title": "Expressing and Exploiting the Common Subgoal Structure of Classical\n  Planning Domains Using Sketches: Extended Version", "comments": "This work will appear in the Proceedings of the 18th International\n  Conference on Principles of Knowledge Representation and Reasoning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Width-based planning methods deal with conjunctive goals by decomposing\nproblems into subproblems of low width. Algorithms like SIW thus fail when the\ngoal is not easily serializable in this way or when some of the subproblems\nhave a high width. In this work, we address these limitations by using a simple\nbut powerful language for expressing finer problem decompositions introduced\nrecently by Bonet and Geffner, called policy sketches. A policy sketch over a\nset of Boolean and numerical features is a set of sketch rules that express how\nthe values of these features are supposed to change. Like general policies,\npolicy sketches are domain general, but unlike policies, the changes captured\nby sketch rules do not need to be achieved in a single step. We show that many\nplanning domains that cannot be solved by SIW are provably solvable in low\npolynomial time with the SIW_R algorithm, the version of SIW that employs\nuser-provided policy sketches. Policy sketches are thus shown to be a powerful\nlanguage for expressing domain-specific knowledge in a simple and compact way\nand a convenient alternative to languages such as HTNs or temporal logics.\nFurthermore, they make it easy to express general problem decompositions and\nprove key properties of them like their width and complexity.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 10:36:18 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 09:57:29 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Drexler", "Dominik", ""], ["Seipp", "Jendrik", ""], ["Geffner", "Hector", ""]]}, {"id": "2105.04261", "submitter": "Pablo Lanillos", "authors": "Pablo Lanillos, Marcel van Gerven", "title": "Neuroscience-inspired perception-action in robotics: applying active\n  inference for state estimation, control and self-perception", "comments": "Accepted at ICLR 2021 Brain2AI workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike robots, humans learn, adapt and perceive their bodies by interacting\nwith the world. Discovering how the brain represents the body and generates\nactions is of major importance for robotics and artificial intelligence. Here\nwe discuss how neuroscience findings open up opportunities to improve current\nestimation and control algorithms in robotics. In particular, how active\ninference, a mathematical formulation of how the brain resists a natural\ntendency to disorder, provides a unified recipe to potentially solve some of\nthe major challenges in robotics, such as adaptation, robustness, flexibility,\ngeneralization and safe interaction. This paper summarizes some experiments and\nlessons learned from developing such a computational model on real embodied\nplatforms, i.e., humanoid and industrial robots. Finally, we showcase the\nlimitations and challenges that we are still facing to give robots human-like\nperception\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 10:59:38 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Lanillos", "Pablo", ""], ["van Gerven", "Marcel", ""]]}, {"id": "2105.04289", "submitter": "Andrei Margeloiu", "authors": "Andrei Margeloiu, Matthew Ashman, Umang Bhatt, Yanzhi Chen, Mateja\n  Jamnik, Adrian Weller", "title": "Do Concept Bottleneck Models Learn as Intended?", "comments": "Accepted at ICLR 2021 Workshop on Responsible AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concept bottleneck models map from raw inputs to concepts, and then from\nconcepts to targets. Such models aim to incorporate pre-specified, high-level\nconcepts into the learning procedure, and have been motivated to meet three\ndesiderata: interpretability, predictability, and intervenability. However, we\nfind that concept bottleneck models struggle to meet these goals. Using post\nhoc interpretability methods, we demonstrate that concepts do not correspond to\nanything semantically meaningful in input space, thus calling into question the\nusefulness of concept bottleneck models in their current form.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 12:00:52 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Margeloiu", "Andrei", ""], ["Ashman", "Matthew", ""], ["Bhatt", "Umang", ""], ["Chen", "Yanzhi", ""], ["Jamnik", "Mateja", ""], ["Weller", "Adrian", ""]]}, {"id": "2105.04293", "submitter": "Giovanni Mauro", "authors": "Paolo Cintia, Giovanni Mauro, Luca Pappalardo, Paolo Ferragina", "title": "An interactive dashboard for searching and comparing soccer performance\n  scores", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The performance of soccer players is one of most discussed aspects by many\nactors in the soccer industry: from supporters to journalists, from coaches to\ntalent scouts. Unfortunately, the dashboards available online provide no\neffective way to compare the evolution of the performance of players or to find\nplayers behaving similarly on the field. This paper describes the design of a\nweb dashboard that interacts via APIs with a performance evaluation algorithm\nand provides graphical tools that allow the user to perform many tasks, such as\nto search or compare players by age, role or trend of growth in their\nperformance, find similar players based on their pitching behavior, change the\nalgorithm's parameters to obtain customized performance scores. We also\ndescribe an example of how a talent scout can interact with the dashboard to\nfind young, promising talents.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 16:50:26 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 13:39:02 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Cintia", "Paolo", ""], ["Mauro", "Giovanni", ""], ["Pappalardo", "Luca", ""], ["Ferragina", "Paolo", ""]]}, {"id": "2105.04342", "submitter": "Michael Green", "authors": "Michael Cerny Green, Victoria Yen, Sam Earle, Dipika Rajesh, Maria\n  Edwards, L. B. Soros", "title": "Exploring open-ended gameplay features with Micro RollerCoaster Tycoon", "comments": "8 pages, 10 figures, submitted to Foundations of Digital Games\n  Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces MicroRCT, a novel open source simulator inspired by the\ntheme park sandbox game RollerCoaster Tycoon. The goal in MicroRCT is to place\nrides and shops in an amusement park to maximize profit earned from park\nguests. Thus, the challenges for game AI include both selecting high-earning\nattractions and placing them in locations that are convenient to guests. In\nthis paper, the MAP-Elites algorithm is used to generate a diversity of park\nlayouts, exploring two theoretical questions about evolutionary algorithms and\ngame design: 1) Is there a benefit to starting from a minimal starting point\nfor evolution and complexifying incrementally? and 2) What are the effects of\nresource limitations on creativity and optimization? Results indicate that\nbuilding from scratch with no costs results in the widest diversity of\nhigh-performing designs.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 13:19:17 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Green", "Michael Cerny", ""], ["Yen", "Victoria", ""], ["Earle", "Sam", ""], ["Rajesh", "Dipika", ""], ["Edwards", "Maria", ""], ["Soros", "L. B.", ""]]}, {"id": "2105.04387", "submitter": "Jinjie Ni", "authors": "Jinjie Ni, Tom Young, Vlad Pandelea, Fuzhao Xue, Vinay Adiga, Erik\n  Cambria", "title": "Recent Advances in Deep Learning Based Dialogue Systems: A Systematic\n  Survey", "comments": "76 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dialogue systems are a popular Natural Language Processing (NLP) task as it\nis promising in real-life applications. It is also a complicated task since\nmany NLP tasks deserving study are involved. As a result, a multitude of novel\nworks on this task are carried out, and most of them are deep learning-based\ndue to the outstanding performance. In this survey, we mainly focus on the deep\nlearning-based dialogue systems. We comprehensively review state-of-the-art\nresearch outcomes in dialogue systems and analyze them from two angles: model\ntype and system type. Specifically, from the angle of model type, we discuss\nthe principles, characteristics, and applications of different models that are\nwidely used in dialogue systems. This will help researchers acquaint these\nmodels and see how they are applied in state-of-the-art frameworks, which is\nrather helpful when designing a new dialogue system. From the angle of system\ntype, we discuss task-oriented and open-domain dialogue systems as two streams\nof research, providing insight into the hot topics related. Furthermore, we\ncomprehensively review the evaluation methods and datasets for dialogue systems\nto pave the way for future research. Finally, some possible research trends are\nidentified based on the recent research outcomes. To the best of our knowledge,\nthis survey is the most comprehensive and up-to-date one at present in the area\nof dialogue systems and dialogue-related tasks, extensively covering the\npopular frameworks, topics, and datasets.\n  Keywords: Dialogue Systems, Chatbots, Conversational AI, Task-oriented, Open\nDomain, Chit-chat, Question Answering, Artificial Intelligence, Natural\nLanguage Processing, Information Retrieval, Deep Learning, Neural Networks,\nCNN, RNN, Hierarchical Recurrent Encoder-Decoder, Memory Networks, Attention,\nTransformer, Pointer Net, CopyNet, Reinforcement Learning, GANs, Knowledge\nGraph, Survey, Review\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 14:07:49 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 13:45:12 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 04:23:43 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 06:12:48 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Ni", "Jinjie", ""], ["Young", "Tom", ""], ["Pandelea", "Vlad", ""], ["Xue", "Fuzhao", ""], ["Adiga", "Vinay", ""], ["Cambria", "Erik", ""]]}, {"id": "2105.04396", "submitter": "Jiazhi Song", "authors": "Jiazhi Song, Inna Sharf", "title": "Stability Constrained Mobile Manipulation Planning on Rough Terrain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a framework that allows online\ndynamic-stability-constrained optimal trajectory planning of a mobile\nmanipulator robot working on rough terrain. First, the kinematics model of a\nmobile manipulator robot, and the Zero Moment Point (ZMP) stability measure are\npresented as theoretical background. Then, a sampling-based quasi-static\nplanning algorithm modified for stability guarantee and traction optimization\nin continuous dynamic motion is presented along with a mathematical proof. The\nrobot's quasi-static path is then used as an initial guess to warm-start a\nnonlinear optimal control solver which may otherwise have difficulties finding\na solution to the stability-constrained formulation efficiently. The\nperformance and computational efficiency of the framework are demonstrated\nthrough an application to a simulated timber harvesting mobile manipulator\nmachine working on varying terrain. The results demonstrate feasibility of\nonline trajectory planning on varying terrain while satisfying the dynamic\nstability constraint.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 14:21:59 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Song", "Jiazhi", ""], ["Sharf", "Inna", ""]]}, {"id": "2105.04404", "submitter": "Theo Lacombe", "authors": "Th\\'eo Lacombe (DATASHAPE), Yuichi Ike, Mathieu Carriere, Fr\\'ed\\'eric\n  Chazal, Marc Glisse, Yuhei Umeda", "title": "Topological Uncertainty: Monitoring trained neural networks through\n  persistence of activation graphs", "comments": null, "journal-ref": "2021 International Joint Conference on Artificial Intelligence,\n  Aug 2021, Montr{\\'e}al, Canada", "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural networks are capable of reaching astonishing performances on\na wide variety of contexts, properly training networks on complicated tasks\nrequires expertise and can be expensive from a computational perspective. In\nindustrial applications, data coming from an open-world setting might widely\ndiffer from the benchmark datasets on which a network was trained. Being able\nto monitor the presence of such variations without retraining the network is of\ncrucial importance. In this article, we develop a method to monitor trained\nneural networks based on the topological properties of their activation graphs.\nTo each new observation, we assign a Topological Uncertainty, a score that aims\nto assess the reliability of the predictions by investigating the whole network\ninstead of its final layer only, as typically done by practitioners. Our\napproach entirely works at a post-training level and does not require any\nassumption on the network architecture, optimization scheme, nor the use of\ndata augmentation or auxiliary datasets; and can be faithfully applied on a\nlarge range of network architectures and data types. We showcase experimentally\nthe potential of Topological Uncertainty in the context of trained network\nselection, Out-Of-Distribution detection, and shift-detection, both on\nsynthetic and real datasets of images and graphs.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 14:16:03 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Lacombe", "Th\u00e9o", "", "DATASHAPE"], ["Ike", "Yuichi", ""], ["Carriere", "Mathieu", ""], ["Chazal", "Fr\u00e9d\u00e9ric", ""], ["Glisse", "Marc", ""], ["Umeda", "Yuhei", ""]]}, {"id": "2105.04405", "submitter": "Mohammad Ali Alomrani", "authors": "Mohammad Ali Alomrani", "title": "A Critical Review of Information Bottleneck Theory and its Applications\n  to Deep Learning", "comments": "Experimental error in section 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the past decade, deep neural networks have seen unparalleled improvements\nthat continue to impact every aspect of today's society. With the development\nof high performance GPUs and the availability of vast amounts of data, learning\ncapabilities of ML systems have skyrocketed, going from classifying digits in a\npicture to beating world-champions in games with super-human performance.\nHowever, even as ML models continue to achieve new frontiers, their practical\nsuccess has been hindered by the lack of a deep theoretical understanding of\ntheir inner workings. Fortunately, a known information-theoretic method called\nthe information bottleneck theory has emerged as a promising approach to better\nunderstand the learning dynamics of neural networks. In principle, IB theory\nmodels learning as a trade-off between the compression of the data and the\nretainment of information. The goal of this survey is to provide a\ncomprehensive review of IB theory covering it's information theoretic roots and\nthe recently proposed applications to understand deep learning models.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 14:16:38 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 11:50:14 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Alomrani", "Mohammad Ali", ""]]}, {"id": "2105.04408", "submitter": "Hongmei He Ph.D", "authors": "Hongmei He, John Gray, Angelo Cangelosi, Qinggang Meng, T.Martin\n  McGinnity, J\\\"orn Mehnen", "title": "The Challenges and Opportunities of Human-Centered AI for Trustworthy\n  Robots and Autonomous Systems", "comments": "15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The trustworthiness of Robots and Autonomous Systems (RAS) has gained a\nprominent position on many research agendas towards fully autonomous systems.\nThis research systematically explores, for the first time, the key facets of\nhuman-centered AI (HAI) for trustworthy RAS. In this article, five key\nproperties of a trustworthy RAS initially have been identified. RAS must be (i)\nsafe in any uncertain and dynamic surrounding environments; (ii) secure, thus\nprotecting itself from any cyber-threats; (iii) healthy with fault tolerance;\n(iv) trusted and easy to use to allow effective human-machine interaction\n(HMI), and (v) compliant with the law and ethical expectations. Then, the\nchallenges in implementing trustworthy autonomous system are analytically\nreviewed, in respects of the five key properties, and the roles of AI\ntechnologies have been explored to ensure the trustiness of RAS with respects\nto safety, security, health and HMI, while reflecting the requirements of\nethics in the design of RAS. While applications of RAS have mainly focused on\nperformance and productivity, the risks posed by advanced AI in RAS have not\nreceived sufficient scientific attention. Hence, a new acceptance model of RAS\nis provided, as a framework for requirements to human-centered AI and for\nimplementing trustworthy RAS by design. This approach promotes human-level\nintelligence to augment human's capacity. while focusing on contributions to\nhumanity.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 13:57:28 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["He", "Hongmei", ""], ["Gray", "John", ""], ["Cangelosi", "Angelo", ""], ["Meng", "Qinggang", ""], ["McGinnity", "T. Martin", ""], ["Mehnen", "J\u00f6rn", ""]]}, {"id": "2105.04414", "submitter": "Arash Shaban-Nejad", "authors": "Khalid Alghatani, Nariman Ammar, Abdelmounaam Rezgui, Arash\n  Shaban-Nejad", "title": "Predicting Intensive Care Unit Length of Stay and Mortality Using\n  Patient Vital Signs: Machine Learning Model Development and Validation", "comments": "23 Pages, 11 Figures, 13 Tables", "journal-ref": "JMIR Med Inform 2021;9(5):e21347", "doi": "10.2196/21347", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Patient monitoring is vital in all stages of care. We here report the\ndevelopment and validation of ICU length of stay and mortality prediction\nmodels. The models will be used in an intelligent ICU patient monitoring module\nof an Intelligent Remote Patient Monitoring (IRPM) framework that monitors the\nhealth status of patients, and generates timely alerts, maneuver guidance, or\nreports when adverse medical conditions are predicted. We utilized the publicly\navailable Medical Information Mart for Intensive Care (MIMIC) database to\nextract ICU stay data for adult patients to build two prediction models: one\nfor mortality prediction and another for ICU length of stay. For the mortality\nmodel, we applied six commonly used machine learning (ML) binary classification\nalgorithms for predicting the discharge status (survived or not). For the\nlength of stay model, we applied the same six ML algorithms for binary\nclassification using the median patient population ICU stay of 2.64 days. For\nthe regression-based classification, we used two ML algorithms for predicting\nthe number of days. We built two variations of each prediction model: one using\n12 baseline demographic and vital sign features, and the other based on our\nproposed quantiles approach, in which we use 21 extra features engineered from\nthe baseline vital sign features, including their modified means, standard\ndeviations, and quantile percentages. We could perform predictive modeling with\nminimal features while maintaining reasonable performance using the quantiles\napproach. The best accuracy achieved in the mortality model was approximately\n89% using the random forest algorithm. The highest accuracy achieved in the\nlength of stay model, based on the population median ICU stay (2.64 days), was\napproximately 65% using the random forest algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 18:45:26 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Alghatani", "Khalid", ""], ["Ammar", "Nariman", ""], ["Rezgui", "Abdelmounaam", ""], ["Shaban-Nejad", "Arash", ""]]}, {"id": "2105.04447", "submitter": "Bing Li", "authors": "Bing Li, Cheng Zheng, Silvio Giancola, Bernard Ghanem", "title": "SCTN: Sparse Convolution-Transformer Network for Scene Flow Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel scene flow estimation approach to capture and infer 3D\nmotions from point clouds. Estimating 3D motions for point clouds is\nchallenging, since a point cloud is unordered and its density is significantly\nnon-uniform. Such unstructured data poses difficulties in matching\ncorresponding points between point clouds, leading to inaccurate flow\nestimation. We propose a novel architecture named Sparse\nConvolution-Transformer Network (SCTN) that equips the sparse convolution with\nthe transformer. Specifically, by leveraging the sparse convolution, SCTN\ntransfers irregular point cloud into locally consistent flow features for\nestimating continuous and consistent motions within an object/local object\npart. We further propose to explicitly learn point relations using a point\ntransformer module, different from exiting methods. We show that the learned\nrelation-based contextual information is rich and helpful for matching\ncorresponding points, benefiting scene flow estimation. In addition, a novel\nloss function is proposed to adaptively encourage flow consistency according to\nfeature similarity. Extensive experiments demonstrate that our proposed\napproach achieves a new state of the art in scene flow estimation. Our approach\nachieves an error of 0.038 and 0.037 (EPE3D) on FlyingThings3D and KITTI Scene\nFlow respectively, which significantly outperforms previous methods by large\nmargins.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 15:16:14 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 23:42:06 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Li", "Bing", ""], ["Zheng", "Cheng", ""], ["Giancola", "Silvio", ""], ["Ghanem", "Bernard", ""]]}, {"id": "2105.04472", "submitter": "Anne Collin", "authors": "Anne Collin, Artur Bilka, Scott Pendleton, Radboud Duintjer Tebbens", "title": "Safety of the Intended Driving Behavior Using Rulebooks", "comments": null, "journal-ref": "2020 IEEE Intelligent Vehicles Symposium (IV)", "doi": "10.1109/IV47402.2020.9304588", "report-no": null, "categories": "cs.RO cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Autonomous Vehicles (AVs) are complex systems that drive in uncertain\nenvironments and potentially navigate unforeseeable situations. Safety of these\nsystems requires not only an absence of malfunctions but also high performance\nof functions in many different scenarios. The ISO/PAS 21448 [1] guidance\nrecommends a process to ensure the Safety of the Intended Functionality (SOTIF)\nfor road vehicles. This process starts with a functional specification that\nfully describes the intended functionality and further includes the\nverification and validation that the AV meets this specification. For the path\nplanning function, defining the correct sequence of control actions for each\nvehicle in all potential driving situations is intractable. In this paper, the\nauthors provide a link between the Rulebooks framework, presented by [2], and\nthe SOTIF process. We establish that Rulebooks provide a functional description\nof the path planning task in an AV and discuss the potential usage of the\nmethod for verification and validation.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 16:11:15 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Collin", "Anne", ""], ["Bilka", "Artur", ""], ["Pendleton", "Scott", ""], ["Tebbens", "Radboud Duintjer", ""]]}, {"id": "2105.04475", "submitter": "Liang Ding", "authors": "Lei Zhou, Liang Ding, Kevin Duh, Shinji Watanabe, Ryohei Sasano,\n  Koichi Takeda", "title": "Self-Guided Curriculum Learning for Neural Machine Translation", "comments": "Work in progress", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In the field of machine learning, the well-trained model is assumed to be\nable to recover the training labels, i.e. the synthetic labels predicted by the\nmodel should be as close to the ground-truth labels as possible. Inspired by\nthis, we propose a self-guided curriculum strategy to encourage the learning of\nneural machine translation (NMT) models to follow the above recovery criterion,\nwhere we cast the recovery degree of each training example as its learning\ndifficulty. Specifically, we adopt the sentence level BLEU score as the proxy\nof recovery degree. Different from existing curricula relying on linguistic\nprior knowledge or third-party language models, our chosen learning difficulty\nis more suitable to measure the degree of knowledge mastery of the NMT models.\nExperiments on translation benchmarks, including WMT14\nEnglish$\\Rightarrow$German and WMT17 Chinese$\\Rightarrow$English, demonstrate\nthat our approach can consistently improve translation performance against\nstrong baseline Transformer.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 16:12:14 GMT"}, {"version": "v2", "created": "Sat, 15 May 2021 10:20:12 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Zhou", "Lei", ""], ["Ding", "Liang", ""], ["Duh", "Kevin", ""], ["Watanabe", "Shinji", ""], ["Sasano", "Ryohei", ""], ["Takeda", "Koichi", ""]]}, {"id": "2105.04484", "submitter": "Angel Daruna", "authors": "Angel Daruna, Lakshmi Nair, Weiyu Liu, Sonia Chernova", "title": "Towards Robust One-shot Task Execution using Knowledge Graph Embeddings", "comments": "7 pages, 3 figures. Accepted for publication at IEEE ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Requiring multiple demonstrations of a task plan presents a burden to\nend-users of robots. However, robustly executing tasks plans from a single\nend-user demonstration is an ongoing challenge in robotics. We address the\nproblem of one-shot task execution, in which a robot must generalize a single\ndemonstration or prototypical example of a task plan to a new execution\nenvironment. Our approach integrates task plans with domain knowledge to infer\ntask plan constituents for new execution environments. Our experimental\nevaluations show that our knowledge representation makes more relevant\ngeneralizations that result in significantly higher success rates over tested\nbaselines. We validated the approach on a physical platform, which resulted in\nthe successful generalization of initial task plans to 38 of 50 execution\nenvironments with errors resulting from autonomous robot operation included.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 16:21:53 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Daruna", "Angel", ""], ["Nair", "Lakshmi", ""], ["Liu", "Weiyu", ""], ["Chernova", "Sonia", ""]]}, {"id": "2105.04493", "submitter": "Wei Jin", "authors": "Wei Jin, Xiaorui Liu, Yao Ma, Tyler Derr, Charu Aggarwal, Jiliang Tang", "title": "Graph Feature Gating Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph neural networks (GNNs) have received tremendous attention due to their\npower in learning effective representations for graphs. Most GNNs follow a\nmessage-passing scheme where the node representations are updated by\naggregating and transforming the information from the neighborhood. Meanwhile,\nthey adopt the same strategy in aggregating the information from different\nfeature dimensions. However, suggested by social dimension theory and spectral\nembedding, there are potential benefits to treat the dimensions differently\nduring the aggregation process. In this work, we investigate to enable\nheterogeneous contributions of feature dimensions in GNNs. In particular, we\npropose a general graph feature gating network (GFGN) based on the graph signal\ndenoising problem and then correspondingly introduce three graph filters under\nGFGN to allow different levels of contributions from feature dimensions.\nExtensive experiments on various real-world datasets demonstrate the\neffectiveness and robustness of the proposed frameworks.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 16:33:58 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Jin", "Wei", ""], ["Liu", "Xiaorui", ""], ["Ma", "Yao", ""], ["Derr", "Tyler", ""], ["Aggarwal", "Charu", ""], ["Tang", "Jiliang", ""]]}, {"id": "2105.04505", "submitter": "Maximilian Idahl", "authors": "Maximilian Idahl, Lijun Lyu, Ujwal Gadiraju, Avishek Anand", "title": "Towards Benchmarking the Utility of Explanations for Model Debugging", "comments": "Short paper, to appear at TrustNLP @ NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-hoc explanation methods are an important class of approaches that help\nunderstand the rationale underlying a trained model's decision. But how useful\nare they for an end-user towards accomplishing a given task? In this vision\npaper, we argue the need for a benchmark to facilitate evaluations of the\nutility of post-hoc explanation methods. As a first step to this end, we\nenumerate desirable properties that such a benchmark should possess for the\ntask of debugging text classifiers. Additionally, we highlight that such a\nbenchmark facilitates not only assessing the effectiveness of explanations but\nalso their efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 16:57:33 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Idahl", "Maximilian", ""], ["Lyu", "Lijun", ""], ["Gadiraju", "Ujwal", ""], ["Anand", "Avishek", ""]]}, {"id": "2105.04534", "submitter": "Yan Zhou", "authors": "Yan Zhou, Murat Kantarcioglu, Chris Clifton", "title": "Improving Fairness of AI Systems with Lossless De-biasing", "comments": "8 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In today's society, AI systems are increasingly used to make critical\ndecisions such as credit scoring and patient triage. However, great convenience\nbrought by AI systems comes with troubling prevalence of bias against\nunderrepresented groups. Mitigating bias in AI systems to increase overall\nfairness has emerged as an important challenge. Existing studies on mitigating\nbias in AI systems focus on eliminating sensitive demographic information\nembedded in data. Given the temporal and contextual complexity of\nconceptualizing fairness, lossy treatment of demographic information may\ncontribute to an unnecessary trade-off between accuracy and fairness,\nespecially when demographic attributes and class labels are correlated. In this\npaper, we present an information-lossless de-biasing technique that targets the\nscarcity of data in the disadvantaged group. Unlike the existing work, we\ndemonstrate, both theoretically and empirically, that oversampling\nunderrepresented groups can not only mitigate algorithmic bias in AI systems\nthat consistently predict a favorable outcome for a certain group, but improve\noverall accuracy by mitigating class imbalance within data that leads to a bias\ntowards the majority class. We demonstrate the effectiveness of our technique\non real datasets using a variety of fairness metrics.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 17:38:38 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhou", "Yan", ""], ["Kantarcioglu", "Murat", ""], ["Clifton", "Chris", ""]]}, {"id": "2105.04554", "submitter": "Jan N. Fuhg", "authors": "Jan Niklas Fuhg, Michele Marino, Nikolaos Bouklas", "title": "Local approximate Gaussian process regression for data-driven\n  constitutive laws: Development and comparison with neural networks", "comments": "22 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Hierarchical computational methods for multiscale mechanics such as the\nFE$^2$ and FE-FFT methods are generally accompanied by high computational\ncosts. Data-driven approaches are able to speed the process up significantly by\nenabling to incorporate the effective micromechanical response in macroscale\nsimulations without the need of performing additional computations at each\nGauss point explicitly. Traditionally artificial neural networks (ANNs) have\nbeen the surrogate modeling technique of choice in the solid mechanics\ncommunity. However they suffer from severe drawbacks due to their parametric\nnature and suboptimal training and inference properties for the investigated\ndatasets in a three dimensional setting. These problems can be avoided using\nlocal approximate Gaussian process regression (laGPR). This method can allow\nthe prediction of stress outputs at particular strain space locations by\ntraining local regression models based on Gaussian processes, using only a\nsubset of the data for each local model, offering better and more reliable\naccuracy than ANNs. A modified Newton-Raphson approach is proposed to\naccommodate for the local nature of the laGPR approximation when solving the\nglobal structural problem in a FE setting. Hence, the presented work offers a\ncomplete and general framework enabling multiscale calculations combining a\ndata-driven constitutive prediction using laGPR, and macroscopic calculations\nusing an FE scheme that we test for finite-strain three-dimensional\nhyperelastic problems.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 14:49:28 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Fuhg", "Jan Niklas", ""], ["Marino", "Michele", ""], ["Bouklas", "Nikolaos", ""]]}, {"id": "2105.04555", "submitter": "Jaehoon Koo", "authors": "Jaehoon Koo, Prasanna Balaprakash, Michael Kruse, Xingfu Wu, Paul\n  Hovland, Mary Hall", "title": "Customized Monte Carlo Tree Search for LLVM/Polly's Composable Loop\n  Optimization Transformations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.AI cs.DC cs.LG cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Polly is the LLVM project's polyhedral loop nest optimizer. Recently,\nuser-directed loop transformation pragmas were proposed based on LLVM/Clang and\nPolly. The search space exposed by the transformation pragmas is a tree,\nwherein each node represents a specific combination of loop transformations\nthat can be applied to the code resulting from the parent node's loop\ntransformations. We have developed a search algorithm based on Monte Carlo tree\nsearch (MCTS) to find the best combination of loop transformations. Our\nalgorithm consists of two phases: exploring loop transformations at different\ndepths of the tree to identify promising regions in the tree search space and\nexploiting those regions by performing a local search. Moreover, a restart\nmechanism is used to avoid the MCTS getting trapped in a local solution. The\nbest and worst solutions are transferred from the previous phases of the\nrestarts to leverage the search history. We compare our approach with random,\ngreedy, and breadth-first search methods on PolyBench kernels and ECP proxy\napplications. Experimental results show that our MCTS algorithm finds pragma\ncombinations with a speedup of 2.3x over Polly's heuristic optimizations on\naverage.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 21:57:39 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Koo", "Jaehoon", ""], ["Balaprakash", "Prasanna", ""], ["Kruse", "Michael", ""], ["Wu", "Xingfu", ""], ["Hovland", "Paul", ""], ["Hall", "Mary", ""]]}, {"id": "2105.04556", "submitter": "Shreshth Tuli", "authors": "Shreshth Tuli, Rajas Bansal, Rohan Paul and Mausam", "title": "TANGO: Commonsense Generalization in Predicting Tool Interactions for\n  Mobile Manipulators", "comments": "10 pages, 10 figures. Accepted in IJCAI 2021. The first two authors\n  contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Robots assisting us in factories or homes must learn to make use of objects\nas tools to perform tasks, e.g., a tray for carrying objects. We consider the\nproblem of learning commonsense knowledge of when a tool may be useful and how\nits use may be composed with other tools to accomplish a high-level task\ninstructed by a human. We introduce a novel neural model, termed TANGO, for\npredicting task-specific tool interactions, trained using demonstrations from\nhuman teachers instructing a virtual robot. TANGO encodes the world state,\ncomprising objects and symbolic relationships between them, using a graph\nneural network. The model learns to attend over the scene using knowledge of\nthe goal and the action history, finally decoding the symbolic action to\nexecute. Crucially, we address generalization to unseen environments where some\nknown tools are missing, but alternative unseen tools are present. We show that\nby augmenting the representation of the environment with pre-trained embeddings\nderived from a knowledge-base, the model can generalize effectively to novel\nenvironments. Experimental results show a 60.5-78.9% absolute improvement over\nthe baseline in predicting successful symbolic plans in unseen settings for a\nsimulated mobile manipulator.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 18:11:57 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 12:47:32 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Tuli", "Shreshth", ""], ["Bansal", "Rajas", ""], ["Paul", "Rohan", ""], ["Mausam", "", ""]]}, {"id": "2105.04595", "submitter": "Md Solimul Chowdhury", "authors": "Md Solimul Chowdhury, Martin M\\\"uller, Jia You", "title": "A Deep Dive into Conflict Generating Decisions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Boolean Satisfiability (SAT) is a well-known NP-complete problem. Despite\nthis theoretical hardness, SAT solvers based on Conflict Driven Clause Learning\n(CDCL) can solve large SAT instances from many important domains. CDCL learns\nclauses from conflicts, a technique that allows a solver to prune its search\nspace. The selection heuristics in CDCL prioritize variables that are involved\nin recent conflicts. While only a fraction of decisions generate any conflicts,\nmany generate multiple conflicts.\n  In this paper, we study conflict-generating decisions in CDCL in detail. We\ninvestigate the impact of single conflict (sc) decisions, which generate only\none conflict, and multi-conflict (mc) decisions which generate two or more. We\nempirically characterize these two types of decisions based on the quality of\nthe learned clauses produced by each type of decision. We also show an\nimportant connection between consecutive clauses learned within the same mc\ndecision, where one learned clause triggers the learning of the next one\nforming a chain of clauses. This leads to the consideration of similarity\nbetween conflicts, for which we formulate the notion of conflictsproximity as a\nsimilarity measure. We show that conflicts in mc decisions are more closely\nrelated than consecutive conflicts generated from sc decisions. Finally, we\ndevelop Common Reason Variable Reduction (CRVR) as a new decision strategy that\nreduces the selection priority of some variables from the learned clauses of mc\ndecisions. Our empirical evaluation of CRVR implemented in three leading\nsolvers demonstrates performance gains in benchmarks from the main track of SAT\nCompetition-2020.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 18:17:52 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Chowdhury", "Md Solimul", ""], ["M\u00fcller", "Martin", ""], ["You", "Jia", ""]]}, {"id": "2105.04607", "submitter": "Shadi Endrawis", "authors": "Shadi Endrawis, Gal Leibovich, Guy Jacob, Gal Novik and Aviv Tamar", "title": "Efficient Self-Supervised Data Collection for Offline Robot Learning", "comments": "Accepted in ICRA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A practical approach to robot reinforcement learning is to first collect a\nlarge batch of real or simulated robot interaction data, using some data\ncollection policy, and then learn from this data to perform various tasks,\nusing offline learning algorithms. Previous work focused on manually designing\nthe data collection policy, and on tasks where suitable policies can easily be\ndesigned, such as random picking policies for collecting data about object\ngrasping. For more complex tasks, however, it may be difficult to find a data\ncollection policy that explores the environment effectively, and produces data\nthat is diverse enough for the downstream task. In this work, we propose that\ndata collection policies should actively explore the environment to collect\ndiverse data. In particular, we develop a simple-yet-effective goal-conditioned\nreinforcement-learning method that actively focuses data collection on novel\nobservations, thereby collecting a diverse data-set. We evaluate our method on\nsimulated robot manipulation tasks with visual inputs and show that the\nimproved diversity of active data collection leads to significant improvements\nin the downstream learning tasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 18:42:58 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Endrawis", "Shadi", ""], ["Leibovich", "Gal", ""], ["Jacob", "Guy", ""], ["Novik", "Gal", ""], ["Tamar", "Aviv", ""]]}, {"id": "2105.04614", "submitter": "Alex James Dr", "authors": "A. P. James, L. O. Chua", "title": "Analog Neural Computing with Super-resolution Memristor Crossbars", "comments": "13 pages", "journal-ref": "IEEE Transactions on Circuits and Systems 1: Regular Papers, 2021\n  (Special Issue for 50th Birthday of Memristor)", "doi": "10.1109/TCSI.2021.3079980", "report-no": null, "categories": "cs.ET cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Memristor crossbar arrays are used in a wide range of in-memory and\nneuromorphic computing applications. However, memristor devices suffer from\nnon-idealities that result in the variability of conductive states, making\nprogramming them to a desired analog conductance value extremely difficult as\nthe device ages. In theory, memristors can be a nonlinear programmable analog\nresistor with memory properties that can take infinite resistive states. In\npractice, such memristors are hard to make, and in a crossbar, it is confined\nto a limited set of stable conductance values. The number of conductance levels\navailable for a node in the crossbar is defined as the crossbar's resolution.\nThis paper presents a technique to improve the resolution by building a\nsuper-resolution memristor crossbar with nodes having multiple memristors to\ngenerate r-simplicial sequence of unique conductance values. The wider the\nrange and number of conductance values, the higher the crossbar's resolution.\nThis is particularly useful in building analog neural network (ANN) layers,\nwhich are proven to be one of the go-to approaches for forming a neural network\nlayer in implementing neuromorphic computations.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 18:52:44 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["James", "A. P.", ""], ["Chua", "L. O.", ""]]}, {"id": "2105.04615", "submitter": "Mohit Kumar", "authors": "Mohit Kumar", "title": "Differentially Private Transfer Learning with Conditionally Deep\n  Autoencoders", "comments": "arXiv admin note: substantial text overlap with arXiv:2104.07060", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper considers the problem of differentially private semi-supervised\ntransfer learning. The notion of membership-mapping is developed using measure\ntheory basis to learn data representation via a fuzzy membership function. An\nalternative conception of deep autoencoder, referred to as Conditionally Deep\nMembership-Mapping Autoencoder (CDMMA) (that consists of a nested compositions\nof membership-mappings), is considered. Under practice-oriented settings, an\nanalytical solution for the learning of CDMFA can be derived by means of\nvariational optimization. The paper proposes a transfer learning approach that\ncombines CDMMA with a tailored noise adding mechanism to achieve a given level\nof privacy-loss bound with the minimum perturbation of the data. Numerous\nexperiments were carried out using MNIST, USPS, Office, and Caltech256 datasets\nto verify the competitive robust performance of the proposed methodology.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 18:52:44 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 05:02:54 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Kumar", "Mohit", ""]]}, {"id": "2105.04619", "submitter": "Stephan R Richter", "authors": "Stephan R. Richter and Hassan Abu AlHaija and Vladlen Koltun", "title": "Enhancing Photorealism Enhancement", "comments": "Code and data available at\n  https://github.com/intel-isl/PhotorealismEnhancement Video available at\n  https://youtu.be/P1IcaBn3ej0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to enhancing the realism of synthetic images. The\nimages are enhanced by a convolutional network that leverages intermediate\nrepresentations produced by conventional rendering pipelines. The network is\ntrained via a novel adversarial objective, which provides strong supervision at\nmultiple perceptual levels. We analyze scene layout distributions in commonly\nused datasets and find that they differ in important ways. We hypothesize that\nthis is one of the causes of strong artifacts that can be observed in the\nresults of many prior methods. To address this we propose a new strategy for\nsampling image patches during training. We also introduce multiple\narchitectural improvements in the deep network modules used for photorealism\nenhancement. We confirm the benefits of our contributions in controlled\nexperiments and report substantial gains in stability and realism in comparison\nto recent image-to-image translation methods and a variety of other baselines.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 19:00:49 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Richter", "Stephan R.", ""], ["AlHaija", "Hassan Abu", ""], ["Koltun", "Vladlen", ""]]}, {"id": "2105.04620", "submitter": "Steven Schockaert", "authors": "Steven Schockaert, Yazm\\'in Ib\\'a\\~nez-Garc\\'ia, V\\'ictor\n  Guti\\'errez-Basulto", "title": "A Description Logic for Analogical Reasoning", "comments": "Accepted for IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ontologies formalise how the concepts from a given domain are interrelated.\nDespite their clear potential as a backbone for explainable AI, existing\nontologies tend to be highly incomplete, which acts as a significant barrier to\ntheir more widespread adoption. To mitigate this issue, we present a mechanism\nto infer plausible missing knowledge, which relies on reasoning by analogy. To\nthe best of our knowledge, this is the first paper that studies analogical\nreasoning within the setting of description logic ontologies. After showing\nthat the standard formalisation of analogical proportion has important\nlimitations in this setting, we introduce an alternative semantics based on\nbijective mappings between sets of features. We then analyse the properties of\nanalogies under the proposed semantics, and show among others how it enables\ntwo plausible inference patterns: rule translation and rule extrapolation.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 19:06:07 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Schockaert", "Steven", ""], ["Ib\u00e1\u00f1ez-Garc\u00eda", "Yazm\u00edn", ""], ["Guti\u00e9rrez-Basulto", "V\u00edctor", ""]]}, {"id": "2105.04623", "submitter": "Feng Nan", "authors": "Feng Nan, Cicero Nogueira dos Santos, Henghui Zhu, Patrick Ng,\n  Kathleen McKeown, Ramesh Nallapati, Dejiao Zhang, Zhiguo Wang, Andrew O.\n  Arnold, Bing Xiang", "title": "Improving Factual Consistency of Abstractive Summarization via Question\n  Answering", "comments": "ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A commonly observed problem with the state-of-the art abstractive\nsummarization models is that the generated summaries can be factually\ninconsistent with the input documents. The fact that automatic summarization\nmay produce plausible-sounding yet inaccurate summaries is a major concern that\nlimits its wide application. In this paper we present an approach to address\nfactual consistency in summarization. We first propose an efficient automatic\nevaluation metric to measure factual consistency; next, we propose a novel\nlearning algorithm that maximizes the proposed metric during model training.\nThrough extensive experiments, we confirm that our method is effective in\nimproving factual consistency and even overall quality of the summaries, as\njudged by both automatic metrics and human evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 19:07:21 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Nan", "Feng", ""], ["Santos", "Cicero Nogueira dos", ""], ["Zhu", "Henghui", ""], ["Ng", "Patrick", ""], ["McKeown", "Kathleen", ""], ["Nallapati", "Ramesh", ""], ["Zhang", "Dejiao", ""], ["Wang", "Zhiguo", ""], ["Arnold", "Andrew O.", ""], ["Xiang", "Bing", ""]]}, {"id": "2105.04646", "submitter": "Chengchun Shi", "authors": "Chengchun Shi and Runzhe Wan and Victor Chernozhukov and Rui Song", "title": "Deeply-Debiased Off-Policy Interval Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy evaluation learns a target policy's value with a historical\ndataset generated by a different behavior policy. In addition to a point\nestimate, many applications would benefit significantly from having a\nconfidence interval (CI) that quantifies the uncertainty of the point estimate.\nIn this paper, we propose a novel deeply-debiasing procedure to construct an\nefficient, robust, and flexible CI on a target policy's value. Our method is\njustified by theoretical results and numerical experiments. A Python\nimplementation of the proposed procedure is available at\nhttps://github.com/RunzheStat/D2OPE.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 20:00:08 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 20:14:34 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Shi", "Chengchun", ""], ["Wan", "Runzhe", ""], ["Chernozhukov", "Victor", ""], ["Song", "Rui", ""]]}, {"id": "2105.04650", "submitter": "Zilong Wang", "authors": "Zilong Wang, Mingjie Zhan, Houxing Ren, Zhaohui Hou, Yuwei Wu, Xingyan\n  Zhang, Ding Liang", "title": "GroupLink: An End-to-end Multitask Method for Word Grouping and Relation\n  Extraction in Form Understanding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Forms are a common type of document in real life and carry rich information\nthrough textual contents and the organizational structure. To realize automatic\nprocessing of forms, word grouping and relation extraction are two fundamental\nand crucial steps after preliminary processing of optical character reader\n(OCR). Word grouping is to aggregate words that belong to the same semantic\nentity, and relation extraction is to predict the links between semantic\nentities. Existing works treat them as two individual tasks, but these two\ntasks are correlated and can reinforce each other. The grouping process will\nrefine the integrated representation of the corresponding entity, and the\nlinking process will give feedback to the grouping performance. For this\npurpose, we acquire multimodal features from both textual data and layout\ninformation and build an end-to-end model through multitask training to combine\nword grouping and relation extraction to enhance performance on each task. We\nvalidate our proposed method on a real-world, fully-annotated, noisy-scanned\nbenchmark, FUNSD, and extensive experiments demonstrate the effectiveness of\nour method.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 20:15:06 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Wang", "Zilong", ""], ["Zhan", "Mingjie", ""], ["Ren", "Houxing", ""], ["Hou", "Zhaohui", ""], ["Wu", "Yuwei", ""], ["Zhang", "Xingyan", ""], ["Liang", "Ding", ""]]}, {"id": "2105.04662", "submitter": "Kayla Boggess", "authors": "Shenghui Chen, Kayla Boggess, David Parker, and Lu Feng", "title": "Multi-Objective Controller Synthesis with Uncertain Human Preferences", "comments": "23 pages, 9 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-objective controller synthesis concerns the problem of computing an\noptimal controller subject to multiple (possibly conflicting) objective\nproperties. The relative importance of objectives is often specified by human\ndecision-makers. However, there is inherent uncertainty in human preferences\n(e.g., due to different preference elicitation methods). In this paper, we\nformalize the notion of uncertain human preferences and present a novel\napproach that accounts for uncertain human preferences in the multi-objective\ncontroller synthesis for Markov decision processes (MDPs). Our approach is\nbased on mixed-integer linear programming (MILP) and synthesizes a sound,\noptimally permissive multi-strategy with respect to a multi-objective property\nand an uncertain set of human preferences. Experimental results on a range of\nlarge case studies show that our MILP-based approach is feasible and scalable\nto synthesize sound, optimally permissive multi-strategies with varying MDP\nmodel sizes and uncertainty levels of human preferences. Evaluation via an\nonline user study also demonstrates the quality and benefits of synthesized\n(multi-)strategies.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 20:41:05 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Chen", "Shenghui", ""], ["Boggess", "Kayla", ""], ["Parker", "David", ""], ["Feng", "Lu", ""]]}, {"id": "2105.04666", "submitter": "David Kohan Marzag\\~ao", "authors": "David Kohan Marzag\\~ao, Luciana Basualdo Bonatto, Tiago Madeira,\n  Marcelo Matheus Gauy, Peter McBurney", "title": "The Influence of Memory in Multi-Agent Consensus", "comments": "Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Multi-agent consensus problems can often be seen as a sequence of autonomous\nand independent local choices between a finite set of decision options, with\neach local choice undertaken simultaneously, and with a shared goal of\nachieving a global consensus state. Being able to estimate probabilities for\nthe different outcomes and to predict how long it takes for a consensus to be\nformed, if ever, are core issues for such protocols.\n  Little attention has been given to protocols in which agents can remember\npast or outdated states. In this paper, we propose a framework to study what we\ncall \\emph{memory consensus protocol}. We show that the employment of memory\nallows such processes to always converge, as well as, in some scenarios, such\nas cycles, converge faster. We provide a theoretical analysis of the\nprobability of each option eventually winning such processes based on the\ninitial opinions expressed by agents. Further, we perform experiments to\ninvestigate network topologies in which agents benefit from memory on the\nexpected time needed for consensus.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 20:59:35 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Marzag\u00e3o", "David Kohan", ""], ["Bonatto", "Luciana Basualdo", ""], ["Madeira", "Tiago", ""], ["Gauy", "Marcelo Matheus", ""], ["McBurney", "Peter", ""]]}, {"id": "2105.04692", "submitter": "Pavel Naumov", "authors": "Lia Bozzone and Pavel Naumov", "title": "Budget-Constrained Coalition Strategies with Discounting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discounting future costs and rewards is a common practice in accounting, game\ntheory, and machine learning. In spite of this, existing logics for reasoning\nabout strategies with cost and resource constraints do not account for\ndiscounting. The paper proposes a sound and complete logical system for\nreasoning about budget-constrained strategic abilities that incorporates\ndiscounting into its semantics.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 22:21:43 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Bozzone", "Lia", ""], ["Naumov", "Pavel", ""]]}, {"id": "2105.04699", "submitter": "Girish Joshi", "authors": "Girish Joshi, Girish Chowdhary", "title": "Adaptive Policy Transfer in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient and robust policy transfer remains a key challenge for\nreinforcement learning to become viable for real-wold robotics. Policy transfer\nthrough warm initialization, imitation, or interacting over a large set of\nagents with randomized instances, have been commonly applied to solve a variety\nof Reinforcement Learning tasks. However, this seems far from how skill\ntransfer happens in the biological world: Humans and animals are able to\nquickly adapt the learned behaviors between similar tasks and learn new skills\nwhen presented with new situations. Here we seek to answer the question: Will\nlearning to combine adaptation and exploration lead to a more efficient\ntransfer of policies between domains? We introduce a principled mechanism that\ncan \"Adapt-to-Learn\", that is adapt the source policy to learn to solve a\ntarget task with significant transition differences and uncertainties. We show\nthat the presented method learns to seamlessly combine learning from adaptation\nand exploration and leads to a robust policy transfer algorithm with\nsignificantly reduced sample complexity in transferring skills between related\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 22:42:03 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Joshi", "Girish", ""], ["Chowdhary", "Girish", ""]]}, {"id": "2105.04707", "submitter": "Amita Misra", "authors": "Amita Misra, Zhe Liu and Jalal Mahmud", "title": "Accountable Error Characterization", "comments": "Proceedings of the First Workshop on Trustworthy Natural Language\n  Processing, TrustNLP@NAACL-HLT 2021, June 10, 2021, Association for\n  Computational Linguistics, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Customers of machine learning systems demand accountability from the\ncompanies employing these algorithms for various prediction tasks.\nAccountability requires understanding of system limit and condition of\nerroneous predictions, as customers are often interested in understanding the\nincorrect predictions, and model developers are absorbed in finding methods\nthat can be used to get incremental improvements to an existing system.\nTherefore, we propose an accountable error characterization method, AEC, to\nunderstand when and where errors occur within the existing black-box models.\nAEC, as constructed with human-understandable linguistic features, allows the\nmodel developers to automatically identify the main sources of errors for a\ngiven classification system. It can also be used to sample for the set of most\ninformative input points for a next round of training. We perform error\ndetection for a sentiment analysis task using AEC as a case study. Our results\non the sample sentiment task show that AEC is able to characterize erroneous\npredictions into human understandable categories and also achieves promising\nresults on selecting erroneous samples when compared with the uncertainty-based\nsampling.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 23:40:01 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Misra", "Amita", ""], ["Liu", "Zhe", ""], ["Mahmud", "Jalal", ""]]}, {"id": "2105.04708", "submitter": "Bimal Bhattarai", "authors": "Bimal Bhattarai, Ole-Christoffer Granmo, Lei Jiao", "title": "Word-level Human Interpretable Scoring Mechanism for Novel Text\n  Detection Using Tsetlin Machines", "comments": "18 pages, 11 figures, 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in novelty detection focuses mainly on document-level\nclassification, employing deep neural networks (DNN). However, the black-box\nnature of DNNs makes it difficult to extract an exact explanation of why a\ndocument is considered novel. In addition, dealing with novelty at the\nword-level is crucial to provide a more fine-grained analysis than what is\navailable at the document level. In this work, we propose a Tsetlin machine\n(TM)-based architecture for scoring individual words according to their\ncontribution to novelty. Our approach encodes a description of the novel\ndocuments using the linguistic patterns captured by TM clauses. We then adopt\nthis description to measure how much a word contributes to making documents\nnovel. Our experimental results demonstrate how our approach breaks down\nnovelty into interpretable phrases, successfully measuring novelty.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 23:41:14 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Bhattarai", "Bimal", ""], ["Granmo", "Ole-Christoffer", ""], ["Jiao", "Lei", ""]]}, {"id": "2105.04709", "submitter": "Roger Dannenberg", "authors": "Shuqi Dai, Xichu Ma, Ye Wang, Roger B. Dannenberg", "title": "Personalized Popular Music Generation Using Imitation and Structure", "comments": "26 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many practices have been presented in music generation recently. While\nstylistic music generation using deep learning techniques has became the main\nstream, these models still struggle to generate music with high musicality,\ndifferent levels of music structure, and controllability. In addition, more\napplication scenarios such as music therapy require imitating more specific\nmusical styles from a few given music examples, rather than capturing the\noverall genre style of a large data corpus. To address requirements that\nchallenge current deep learning methods, we propose a statistical machine\nlearning model that is able to capture and imitate the structure, melody,\nchord, and bass style from a given example seed song. An evaluation using 10\npop songs shows that our new representations and methods are able to create\nhigh-quality stylistic music that is similar to a given input song. We also\ndiscuss potential uses of our approach in music evaluation and music therapy.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 23:43:00 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Dai", "Shuqi", ""], ["Ma", "Xichu", ""], ["Wang", "Ye", ""], ["Dannenberg", "Roger B.", ""]]}, {"id": "2105.04719", "submitter": "Pengwei Wang", "authors": "Pengwei Wang, Xin Ye, Xiaohuan Zhou, Jinghui Xie, Hao Wang", "title": "Speech2Slot: An End-to-End Knowledge-based Slot Filling from Speech", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contrast to conventional pipeline Spoken Language Understanding (SLU)\nwhich consists of automatic speech recognition (ASR) and natural language\nunderstanding (NLU), end-to-end SLU infers the semantic meaning directly from\nspeech and overcomes the error propagation caused by ASR. End-to-end slot\nfilling (SF) from speech is an essential component of end-to-end SLU, and is\nusually regarded as a sequence-to-sequence generation problem, heavily relied\non the performance of language model of ASR. However, it is hard to generate a\ncorrect slot when the slot is out-of-vovabulary (OOV) in training data,\nespecially when a slot is an anti-linguistic entity without grammatical rule.\nInspired by object detection in computer vision that is to detect the object\nfrom an image, we consider SF as the task of slot detection from speech. In\nthis paper, we formulate the SF task as a matching task and propose an\nend-to-end knowledge-based SF model, named Speech-to-Slot (Speech2Slot), to\nleverage knowledge to detect the boundary of a slot from the speech. We also\nrelease a large-scale dataset of Chinese speech for slot filling, containing\nmore than 830,000 samples. The experiments show that our approach is markedly\nsuperior to the conventional pipeline SLU approach, and outperforms the\nstate-of-the-art end-to-end SF approach with 12.51% accuracy improvement.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 13:31:27 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Wang", "Pengwei", ""], ["Ye", "Xin", ""], ["Zhou", "Xiaohuan", ""], ["Xie", "Jinghui", ""], ["Wang", "Hao", ""]]}, {"id": "2105.04758", "submitter": "Fanfei Chen", "authors": "Fanfei Chen, Paul Szenher, Yewei Huang, Jinkun Wang, Tixiao Shan, Shi\n  Bai, Brendan Englot", "title": "Zero-Shot Reinforcement Learning on Graphs for Autonomous Exploration\n  Under Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of autonomous exploration under localization\nuncertainty for a mobile robot with 3D range sensing. We present a framework\nfor self-learning a high-performance exploration policy in a single simulation\nenvironment, and transferring it to other environments, which may be physical\nor virtual. Recent work in transfer learning achieves encouraging performance\nby domain adaptation and domain randomization to expose an agent to scenarios\nthat fill the inherent gaps in sim2sim and sim2real approaches. However, it is\ninefficient to train an agent in environments with randomized conditions to\nlearn the important features of its current state. An agent can use domain\nknowledge provided by human experts to learn efficiently. We propose a novel\napproach that uses graph neural networks in conjunction with deep reinforcement\nlearning, enabling decision-making over graphs containing relevant exploration\ninformation provided by human experts to predict a robot's optimal sensing\naction in belief space. The policy, which is trained only in a single\nsimulation environment, offers a real-time, scalable, and transferable\ndecision-making strategy, resulting in zero-shot transfer to other simulation\nenvironments and even real-world environments.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 02:42:17 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Chen", "Fanfei", ""], ["Szenher", "Paul", ""], ["Huang", "Yewei", ""], ["Wang", "Jinkun", ""], ["Shan", "Tixiao", ""], ["Bai", "Shi", ""], ["Englot", "Brendan", ""]]}, {"id": "2105.04774", "submitter": "Xuhui Ren", "authors": "Xuhui Ren, Hongzhi Yin, Tong Chen, Hao Wang, Zi Huang, Kai Zheng", "title": "Learning to Ask Appropriate Questions in Conversational Recommendation", "comments": "to be published in SIGIR'2021", "journal-ref": null, "doi": "10.1145/3404835.3462839", "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conversational recommender systems (CRSs) have revolutionized the\nconventional recommendation paradigm by embracing dialogue agents to\ndynamically capture the fine-grained user preference. In a typical\nconversational recommendation scenario, a CRS firstly generates questions to\nlet the user clarify her/his demands and then makes suitable recommendations.\nHence, the ability to generate suitable clarifying questions is the key to\ntimely tracing users' dynamic preferences and achieving successful\nrecommendations. However, existing CRSs fall short in asking high-quality\nquestions because: (1) system-generated responses heavily depends on the\nperformance of the dialogue policy agent, which has to be trained with huge\nconversation corpus to cover all circumstances; and (2) current CRSs cannot\nfully utilize the learned latent user profiles for generating appropriate and\npersonalized responses.\n  To mitigate these issues, we propose the Knowledge-Based Question Generation\nSystem (KBQG), a novel framework for conversational recommendation. Distinct\nfrom previous conversational recommender systems, KBQG models a user's\npreference in a finer granularity by identifying the most relevant relations\nfrom a structured knowledge graph (KG). Conditioned on the varied importance of\ndifferent relations, the generated clarifying questions could perform better in\nimpelling users to provide more details on their preferences. Finially,\naccurate recommendations can be generated in fewer conversational turns.\nFurthermore, the proposed KBQG outperforms all baselines in our experiments on\ntwo real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 03:58:10 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Ren", "Xuhui", ""], ["Yin", "Hongzhi", ""], ["Chen", "Tong", ""], ["Wang", "Hao", ""], ["Huang", "Zi", ""], ["Zheng", "Kai", ""]]}, {"id": "2105.04776", "submitter": "Xiaobin Liu", "authors": "Xiaobin Liu, Shiliang Zhang", "title": "Graph Consistency Based Mean-Teaching for Unsupervised Domain Adaptive\n  Person Re-Identification", "comments": "IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent works show that mean-teaching is an effective framework for\nunsupervised domain adaptive person re-identification. However, existing\nmethods perform contrastive learning on selected samples between teacher and\nstudent networks, which is sensitive to noises in pseudo labels and neglects\nthe relationship among most samples. Moreover, these methods are not effective\nin cooperation of different teacher networks. To handle these issues, this\npaper proposes a Graph Consistency based Mean-Teaching (GCMT) method with\nconstructing the Graph Consistency Constraint (GCC) between teacher and student\nnetworks. Specifically, given unlabeled training images, we apply teacher\nnetworks to extract corresponding features and further construct a teacher\ngraph for each teacher network to describe the similarity relationships among\ntraining images. To boost the representation learning, different teacher graphs\nare fused to provide the supervise signal for optimizing student networks. GCMT\nfuses similarity relationships predicted by different teacher networks as\nsupervision and effectively optimizes student networks with more sample\nrelationships involved. Experiments on three datasets, i.e., Market-1501,\nDukeMTMCreID, and MSMT17, show that proposed GCMT outperforms state-of-the-art\nmethods by clear margin. Specially, GCMT even outperforms the previous method\nthat uses a deeper backbone. Experimental results also show that GCMT can\neffectively boost the performance with multiple teacher and student networks.\nOur code is available at https://github.com/liu-xb/GCMT .\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 04:09:49 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 05:57:52 GMT"}, {"version": "v3", "created": "Fri, 14 May 2021 13:28:39 GMT"}, {"version": "v4", "created": "Wed, 19 May 2021 02:11:13 GMT"}, {"version": "v5", "created": "Mon, 31 May 2021 01:02:48 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Liu", "Xiaobin", ""], ["Zhang", "Shiliang", ""]]}, {"id": "2105.04785", "submitter": "Yongchun Zhu", "authors": "Yongchun Zhu, Kaikai Ge, Fuzhen Zhuang, Ruobing Xie, Dongbo Xi, Xu\n  Zhang, Leyu Lin and Qing He", "title": "Transfer-Meta Framework for Cross-domain Recommendation to Cold-Start\n  Users", "comments": "5 pages, accepted by SIGIR2021", "journal-ref": null, "doi": "10.1145/3404835.3463010", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cold-start problems are enormous challenges in practical recommender systems.\nOne promising solution for this problem is cross-domain recommendation (CDR)\nwhich leverages rich information from an auxiliary (source) domain to improve\nthe performance of recommender system in the target domain. In these CDR\napproaches, the family of Embedding and Mapping methods for CDR (EMCDR) is very\neffective, which explicitly learn a mapping function from source embeddings to\ntarget embeddings with overlapping users. However, these approaches suffer from\none serious problem: the mapping function is only learned on limited\noverlapping users, and the function would be biased to the limited overlapping\nusers, which leads to unsatisfying generalization ability and degrades the\nperformance on cold-start users in the target domain. With the advantage of\nmeta learning which has good generalization ability to novel tasks, we propose\na transfer-meta framework for CDR (TMCDR) which has a transfer stage and a meta\nstage. In the transfer (pre-training) stage, a source model and a target model\nare trained on source and target domains, respectively. In the meta stage, a\ntask-oriented meta network is learned to implicitly transform the user\nembedding in the source domain to the target feature space. In addition, the\nTMCDR is a general framework that can be applied upon various base models,\ne.g., MF, BPR, CML. By utilizing data from Amazon and Douban, we conduct\nextensive experiments on 6 cross-domain tasks to demonstrate the superior\nperformance and compatibility of TMCDR.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 05:15:53 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Zhu", "Yongchun", ""], ["Ge", "Kaikai", ""], ["Zhuang", "Fuzhen", ""], ["Xie", "Ruobing", ""], ["Xi", "Dongbo", ""], ["Zhang", "Xu", ""], ["Lin", "Leyu", ""], ["He", "Qing", ""]]}, {"id": "2105.04801", "submitter": "Sahil Sidheekh", "authors": "Sahil Sidheekh, Aroof Aimen, Narayanan C. Krishnan", "title": "On Characterizing GAN Convergence Through Proximal Duality Gap", "comments": null, "journal-ref": null, "doi": null, "report-no": "2640-3498", "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the accomplishments of Generative Adversarial Networks (GANs) in\nmodeling data distributions, training them remains a challenging task. A\ncontributing factor to this difficulty is the non-intuitive nature of the GAN\nloss curves, which necessitates a subjective evaluation of the generated output\nto infer training progress. Recently, motivated by game theory, duality gap has\nbeen proposed as a domain agnostic measure to monitor GAN training. However, it\nis restricted to the setting when the GAN converges to a Nash equilibrium. But\nGANs need not always converge to a Nash equilibrium to model the data\ndistribution. In this work, we extend the notion of duality gap to proximal\nduality gap that is applicable to the general context of training GANs where\nNash equilibria may not exist. We show theoretically that the proximal duality\ngap is capable of monitoring the convergence of GANs to a wider spectrum of\nequilibria that subsumes Nash equilibria. We also theoretically establish the\nrelationship between the proximal duality gap and the divergence between the\nreal and generated data distributions for different GAN formulations. Our\nresults provide new insights into the nature of GAN convergence. Finally, we\nvalidate experimentally the usefulness of proximal duality gap for monitoring\nand influencing GAN training.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 06:27:27 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 08:56:03 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Sidheekh", "Sahil", ""], ["Aimen", "Aroof", ""], ["Krishnan", "Narayanan C.", ""]]}, {"id": "2105.04823", "submitter": "Songyang Zhang", "authors": "Songyang Zhang, Jiale Zhou, Xuming He", "title": "Learning Implicit Temporal Alignment for Few-shot Video Classification", "comments": "Accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Few-shot video classification aims to learn new video categories with only a\nfew labeled examples, alleviating the burden of costly annotation in real-world\napplications. However, it is particularly challenging to learn a\nclass-invariant spatial-temporal representation in such a setting. To address\nthis, we propose a novel matching-based few-shot learning strategy for video\nsequences in this work. Our main idea is to introduce an implicit temporal\nalignment for a video pair, capable of estimating the similarity between them\nin an accurate and robust manner. Moreover, we design an effective context\nencoding module to incorporate spatial and feature channel context, resulting\nin better modeling of intra-class variations. To train our model, we develop a\nmulti-task loss for learning video matching, leading to video features with\nbetter generalization. Extensive experimental results on two challenging\nbenchmarks, show that our method outperforms the prior arts with a sizable\nmargin on SomethingSomething-V2 and competitive results on Kinetics.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 07:18:57 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Zhang", "Songyang", ""], ["Zhou", "Jiale", ""], ["He", "Xuming", ""]]}, {"id": "2105.04848", "submitter": "Fouad Trad", "authors": "Salah El Falou, Fouad Trad", "title": "Forecast Analysis of the COVID-19 Incidence in Lebanon: Prediction of\n  Future Epidemiological Trends to Plan More Effective Control Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ever since the COVID-19 pandemic started, all the governments have been\ntrying to limit its effects on their citizens and countries. This pandemic was\nharsh on different levels for almost all populations worldwide and this is what\ndrove researchers and scientists to get involved and work on several kinds of\nsimulations to get a better insight into this virus and be able to stop it the\nearliest possible. In this study, we simulate the spread of COVID-19 in Lebanon\nusing an Agent-Based Model where people are modeled as agents that have\nspecific characteristics and behaviors determined from statistical\ndistributions using Monte Carlo Algorithm. These agents can go into the world,\ninteract with each other, and thus, infect each other. This is how the virus\nspreads. During the simulation, we can introduce different Non-Pharmaceutical\nInterventions - or more commonly NPIs - that aim to limit the spread of the\nvirus (wearing a mask, closing locations, etc). Our Simulator was first\nvalidated on concepts (e.g. Flattening the Curve and Second Wave scenario), and\nthen it was applied on the case of Lebanon. We studied the effect of opening\nschools and universities on the pandemic situation in the country since the\nLebanese Ministry of Education is planning to do so progressively, starting\nfrom 21 April 2021. Based on the results we obtained, we conclude that it would\nbe better to delay the school openings while the vaccination campaign is still\nslow in the country.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 08:07:03 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 11:56:46 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Falou", "Salah El", ""], ["Trad", "Fouad", ""]]}, {"id": "2105.04885", "submitter": "Michail Chatzianastasis", "authors": "Michail Chatzianastasis, George Dasoulas, Georgios Siolas, Michalis\n  Vazirgiannis", "title": "Operation Embeddings for Neural Architecture Search", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural Architecture Search (NAS) has recently gained increased attention, as\na class of approaches that automatically searches in an input space of network\narchitectures. A crucial part of the NAS pipeline is the encoding of the\narchitecture that consists of the applied computational blocks, namely the\noperations and the links between them. Most of the existing approaches either\nfail to capture the structural properties of the architectures or use a\nhand-engineered vector to encode the operator information. In this paper, we\npropose the replacement of fixed operator encoding with learnable\nrepresentations in the optimization process. This approach, which effectively\ncaptures the relations of different operations, leads to smoother and more\naccurate representations of the architectures and consequently to improved\nperformance of the end task. Our extensive evaluation in ENAS benchmark\ndemonstrates the effectiveness of the proposed operation embeddings to the\ngeneration of highly accurate models, achieving state-of-the-art performance.\nFinally, our method produces top-performing architectures that share similar\noperation and graph patterns, highlighting a strong correlation between\narchitecture's structural properties and performance.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 09:17:10 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Chatzianastasis", "Michail", ""], ["Dasoulas", "George", ""], ["Siolas", "Georgios", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "2105.04906", "submitter": "Adrien Bardes", "authors": "Adrien Bardes and Jean Ponce and Yann LeCun", "title": "VICReg: Variance-Invariance-Covariance Regularization for\n  Self-Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent self-supervised methods for image representation learning are based on\nmaximizing the agreement between embedding vectors from different views of the\nsame image. A trivial solution is obtained when the encoder outputs constant\nvectors. This collapse problem is often avoided through implicit biases in the\nlearning architecture, that often lack a clear justification or interpretation.\nIn this paper, we introduce VICReg (Variance-Invariance-Covariance\nRegularization), a method that explicitly avoids the collapse problem with a\nsimple regularization term on the variance of the embeddings along each\ndimension individually. VICReg combines the variance term with a decorrelation\nmechanism based on redundancy reduction and covariance regularization, and\nachieves results on par with the state of the art on several downstream tasks.\nIn addition, we show that incorporating our new variance term into other\nmethods helps stabilize the training and leads to performance improvements.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 09:53:21 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Bardes", "Adrien", ""], ["Ponce", "Jean", ""], ["LeCun", "Yann", ""]]}, {"id": "2105.04916", "submitter": "Yanqi Chen", "authors": "Yanqi Chen, Zhaofei Yu, Wei Fang, Tiejun Huang and Yonghong Tian", "title": "Pruning of Deep Spiking Neural Networks through Gradient Rewiring", "comments": "9 pages, 7 figures, 4 tables. To appear in the 30th International\n  Joint Conference on Artificial Intelligence (IJCAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs) have been attached great importance due to\ntheir biological plausibility and high energy-efficiency on neuromorphic chips.\nAs these chips are usually resource-constrained, the compression of SNNs is\nthus crucial along the road of practical use of SNNs. Most existing methods\ndirectly apply pruning approaches in artificial neural networks (ANNs) to SNNs,\nwhich ignore the difference between ANNs and SNNs, thus limiting the\nperformance of the pruned SNNs. Besides, these methods are only suitable for\nshallow SNNs. In this paper, inspired by synaptogenesis and synapse elimination\nin the neural system, we propose gradient rewiring (Grad R), a joint learning\nalgorithm of connectivity and weight for SNNs, that enables us to seamlessly\noptimize network structure without retraining. Our key innovation is to\nredefine the gradient to a new synaptic parameter, allowing better exploration\nof network structures by taking full advantage of the competition between\npruning and regrowth of connections. The experimental results show that the\nproposed method achieves minimal loss of SNNs' performance on MNIST and\nCIFAR-10 dataset so far. Moreover, it reaches a $\\sim$3.5% accuracy loss under\nunprecedented 0.73% connectivity, which reveals remarkable structure refining\ncapability in SNNs. Our work suggests that there exists extremely high\nredundancy in deep SNNs. Our codes are available at\nhttps://github.com/Yanqi-Chen/Gradient-Rewiring.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 10:05:53 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 02:35:21 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 08:38:17 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Chen", "Yanqi", ""], ["Yu", "Zhaofei", ""], ["Fang", "Wei", ""], ["Huang", "Tiejun", ""], ["Tian", "Yonghong", ""]]}, {"id": "2105.04934", "submitter": "Guanqiang Gao", "authors": "Guanqiang Gao, Bin Xin, Yi Mei, Shuxin Ding, and Juan Li", "title": "A Hybrid Decomposition-based Multi-objective Evolutionary Algorithm for\n  the Multi-Point Dynamic Aggregation Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An emerging optimisation problem from the real-world applications, named the\nmulti-point dynamic aggregation (MPDA) problem, has become one of the active\nresearch topics of the multi-robot system. This paper focuses on a\nmulti-objective MPDA problem which is to design an execution plan of the robots\nto minimise the number of robots and the maximal completion time of all the\ntasks. The strongly-coupled relationships among robots and tasks, the\nredundancy of the MPDA encoding, and the variable-size decision space of the\nMO-MPDA problem posed extra challenges for addressing the problem effectively.\nTo address the above issues, we develop a hybrid decomposition-based\nmulti-objective evolutionary algorithm (HDMOEA) using $ \\varepsilon\n$-constraint method. It selects the maximal completion time of all tasks as the\nmain objective, and converted the other objective into constraints. HDMOEA\ndecomposes a MO-MPDA problem into a series of scalar constrained optimization\nsubproblems by assigning each subproblem with an upper bound robot number. All\nthe subproblems are optimized simultaneously with the transferring knowledge\nfrom other subproblems. Besides, we develop a hybrid population initialisation\nmechanism to enhance the quality of initial solutions, and a reproduction\nmechanism to transmit effective information and tackle the encoding redundancy.\nExperimental results show that the proposed HDMOEA method significantly\noutperforms the state-of-the-art methods in terms of several most-used metrics.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 10:53:16 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Gao", "Guanqiang", ""], ["Xin", "Bin", ""], ["Mei", "Yi", ""], ["Ding", "Shuxin", ""], ["Li", "Juan", ""]]}, {"id": "2105.05005", "submitter": "Jaeyoung Kim", "authors": "Jaeyoung Kim, Han Lu, Anshuman Tripathi, Qian Zhang and Hasim Sak", "title": "Reducing Streaming ASR Model Delay with Self Alignment", "comments": "submitted to INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Reducing prediction delay for streaming end-to-end ASR models with minimal\nperformance regression is a challenging problem. Constrained alignment is a\nwell-known existing approach that penalizes predicted word boundaries using\nexternal low-latency acoustic models. On the contrary, recently proposed\nFastEmit is a sequence-level delay regularization scheme encouraging vocabulary\ntokens over blanks without any reference alignments. Although all these schemes\nare successful in reducing delay, ASR word error rate (WER) often severely\ndegrades after applying these delay constraining schemes. In this paper, we\npropose a novel delay constraining method, named self alignment. Self alignment\ndoes not require external alignment models. Instead, it utilizes Viterbi\nforced-alignments from the trained model to find the lower latency alignment\ndirection. From LibriSpeech evaluation, self alignment outperformed existing\nschemes: 25% and 56% less delay compared to FastEmit and constrained alignment\nat the similar word error rate. For Voice Search evaluation,12% and 25% delay\nreductions were achieved compared to FastEmit and constrained alignment with\nmore than 2% WER improvements.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 18:00:11 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Kim", "Jaeyoung", ""], ["Lu", "Han", ""], ["Tripathi", "Anshuman", ""], ["Zhang", "Qian", ""], ["Sak", "Hasim", ""]]}, {"id": "2105.05012", "submitter": "Chang-Shing Lee", "authors": "Chang-Shing Lee, Mei-Hui Wang, Zong-Han Ciou, Rin-Pin Chang, Chun-Hao\n  Tsai, Shen-Chien Chen, Tzong-Xiang Huang, Eri Sato-Shimokawara, and Toru\n  Yamaguchi", "title": "Robotic Assistant Agent for Student and Machine Co-Learning on AI-FML\n  Practice with AIoT Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, the Robotic Assistant Agent for student and machine\nco-learning on AI-FML practice with AIoT application is presented. The\nstructure of AI-FML contains three parts, including fuzzy logic, neural\nnetwork, and evolutionary computation. Besides, the Robotic Assistant Agent\n(RAA) can assist students and machines in co-learning English and AI-FML\npractice based on the robot Kebbi Air and AIoT-FML learning tool. Since Sept.\n2019, we have introduced an Intelligent Speaking English Assistant (ISEA) App\nand AI-FML platform to English and computer science learning classes at two\nelementary schools in Taiwan. We use the collected English-learning data to\ntrain a predictive regression model based on students' monthly examination\nscores. In Jan. 2021, we further combined the developed AI-FML platform with a\nnovel AIoT-FML learning tool to enhance students' interests in learning English\nand AI-FML with basic hands-on practice. The proposed RAA is responsible for\nreasoning students' learning performance and showing the results on the\nAIoT-FML learning tool after communicating with the AI-FML platform. The\nexperimental results and the collection of students' feedback show that this\nkind of learning model is popular with elementary-school and high-school\nstudents, and the learning performance of elementary-school students is\nimproved.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 13:19:06 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Lee", "Chang-Shing", ""], ["Wang", "Mei-Hui", ""], ["Ciou", "Zong-Han", ""], ["Chang", "Rin-Pin", ""], ["Tsai", "Chun-Hao", ""], ["Chen", "Shen-Chien", ""], ["Huang", "Tzong-Xiang", ""], ["Sato-Shimokawara", "Eri", ""], ["Yamaguchi", "Toru", ""]]}, {"id": "2105.05029", "submitter": "Jing Li", "authors": "Tiangang Li", "title": "Adversarial examples attack based on random warm restart mechanism and\n  improved Nesterov momentum", "comments": "9 pages, 7 figures, 5 tables, CCS 2021 Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The deep learning algorithm has achieved great success in the field of\ncomputer vision, but some studies have pointed out that the deep learning model\nis vulnerable to attacks adversarial examples and makes false decisions. This\nchallenges the further development of deep learning, and urges researchers to\npay more attention to the relationship between adversarial examples attacks and\ndeep learning security. This work focuses on adversarial examples, optimizes\nthe generation of adversarial examples from the view of adversarial robustness,\ntakes the perturbations added in adversarial examples as the optimization\nparameter. We propose RWR-NM-PGD attack algorithm based on random warm restart\nmechanism and improved Nesterov momentum from the view of gradient\noptimization. The algorithm introduces improved Nesterov momentum, using its\ncharacteristics of accelerating convergence and improving gradient update\ndirection in optimization algorithm to accelerate the generation of adversarial\nexamples. In addition, the random warm restart mechanism is used for\noptimization, and the projected gradient descent algorithm is used to limit the\nrange of the generated perturbations in each warm restart, which can obtain\nbetter attack effect. Experiments on two public datasets show that the\nalgorithm proposed in this work can improve the success rate of attacking deep\nlearning models without extra time cost. Compared with the benchmark attack\nmethod, the algorithm proposed in this work can achieve better attack success\nrate for both normal training model and defense model. Our method has average\nattack success rate of 46.3077%, which is 27.19% higher than I-FGSM and 9.27%\nhigher than PGD. The attack results in 13 defense models show that the attack\nalgorithm proposed in this work is superior to the benchmark algorithm in\nattack universality and transferability.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 07:24:25 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Li", "Tiangang", ""]]}, {"id": "2105.05069", "submitter": "Rishi Hazra", "authors": "Rishi Hazra, Sonu Dixit, Sayambhu Sen", "title": "Zero-Shot Generalization using Intrinsically Motivated Compositional\n  Emergent Protocols", "comments": "Accepted in NAACL 2021 workshop: Visually Grounded Interaction and\n  Language (ViGIL). arXiv admin note: substantial text overlap with\n  arXiv:2012.05011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human language has been described as a system that makes \\textit{use of\nfinite means to express an unlimited array of thoughts}. Of particular interest\nis the aspect of compositionality, whereby, the meaning of a compound language\nexpression can be deduced from the meaning of its constituent parts. If\nartificial agents can develop compositional communication protocols akin to\nhuman language, they can be made to seamlessly generalize to unseen\ncombinations. Studies have recognized the role of curiosity in enabling\nlinguistic development in children. In this paper, we seek to use this\nintrinsic feedback in inducing a systematic and unambiguous protolanguage. We\ndemonstrate how compositionality can enable agents to not only interact with\nunseen objects but also transfer skills from one task to another in a zero-shot\nsetting: \\textit{Can an agent, trained to `pull' and `push twice', `pull\ntwice'?}.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 14:20:26 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Hazra", "Rishi", ""], ["Dixit", "Sonu", ""], ["Sen", "Sayambhu", ""]]}, {"id": "2105.05080", "submitter": "Federica Filippini", "authors": "Federica Filippini, Danilo Ardagna, Marco Lattuada, Edoardo Amaldi,\n  Michele Ciavotta, Maciek Riedl, Katarzyna Materka, Pawe{\\l} Skrzypek,\n  Fabrizio Magugliani, Marco Cicala", "title": "ANDREAS: Artificial intelligence traiNing scheDuler foR accElerAted\n  resource clusterS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial Intelligence (AI) and Deep Learning (DL) algorithms are currently\napplied to a wide range of products and solutions. DL training jobs are highly\nresource demanding and they experience great benefits when exploiting AI\naccelerators (e.g., GPUs). However, the effective management of GPU-powered\nclusters comes with great challenges. Among these, efficient scheduling and\nresource allocation solutions are crucial to maximize performance and minimize\nData Centers operational costs. In this paper we propose ANDREAS, an advanced\nscheduling solution that tackles these problems jointly, aiming at optimizing\nDL training runtime workloads and their energy consumption in accelerated\nclusters. Experiments based on simulation demostrate that we can achieve a cost\nreduction between 30 and 62% on average with respect to first-principle methods\nwhile the validation on a real cluster shows a worst case deviation below 13%\nbetween actual and predicted costs, proving the effectiveness of ANDREAS\nsolution in practical scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 14:36:19 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Filippini", "Federica", ""], ["Ardagna", "Danilo", ""], ["Lattuada", "Marco", ""], ["Amaldi", "Edoardo", ""], ["Ciavotta", "Michele", ""], ["Riedl", "Maciek", ""], ["Materka", "Katarzyna", ""], ["Skrzypek", "Pawe\u0142", ""], ["Magugliani", "Fabrizio", ""], ["Cicala", "Marco", ""]]}, {"id": "2105.05112", "submitter": "Rida  Miraj", "authors": "Rida Miraj, Masaki Aono", "title": "Integrating extracted information from bert and multiple embedding\n  methods with the deep neural network for humour detection", "comments": null, "journal-ref": null, "doi": "10.5121/ijnlc.2021.10202", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Humour detection from sentences has been an interesting and challenging task\nin the last few years. In attempts to highlight humour detection, most research\nwas conducted using traditional approaches of embedding, e.g., Word2Vec or\nGlove. Recently BERT sentence embedding has also been used for this task. In\nthis paper, we propose a framework for humour detection in short texts taken\nfrom news headlines. Our proposed framework (IBEN) attempts to extract\ninformation from written text via the use of different layers of BERT. After\nseveral trials, weights were assigned to different layers of the BERT model.\nThe extracted information was then sent to a Bi-GRU neural network as an\nembedding matrix. We utilized the properties of some external embedding models.\nA multi-kernel convolution in our neural network was also employed to extract\nhigher-level sentence representations. This framework performed very well on\nthe task of humour detection.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 15:09:19 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Miraj", "Rida", ""], ["Aono", "Masaki", ""]]}, {"id": "2105.05135", "submitter": "Rida  Miraj", "authors": "Rida Miraj, Masaki Aono", "title": "kdehumor at semeval-2020 task 7: a neural network model for detecting\n  funniness in dataset humicroedit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes our contribution to SemEval-2020 Task 7: Assessing Humor\nin Edited News Headlines. Here we present a method based on a deep neural\nnetwork. In recent years, quite some attention has been devoted to humor\nproduction and perception. Our team KdeHumor employs recurrent neural network\nmodels including Bi-Directional LSTMs (BiLSTMs). Moreover, we utilize the\nstate-of-the-art pre-trained sentence embedding techniques. We analyze the\nperformance of our method and demonstrate the contribution of each component of\nour architecture.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 15:44:03 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Miraj", "Rida", ""], ["Aono", "Masaki", ""]]}, {"id": "2105.05145", "submitter": "Boyuan Chen", "authors": "Boyuan Chen, Yuhang Hu, Robert Kwiatkowski, Shuran Song, Hod Lipson", "title": "Visual Perspective Taking for Opponent Behavior Modeling", "comments": "ICRA 2021. Website: http://www.cs.columbia.edu/~bchen/vpttob/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to engage in complex social interaction, humans learn at a young age\nto infer what others see and cannot see from a different point-of-view, and\nlearn to predict others' plans and behaviors. These abilities have been mostly\nlacking in robots, sometimes making them appear awkward and socially inept.\nHere we propose an end-to-end long-term visual prediction framework for robots\nto begin to acquire both these critical cognitive skills, known as Visual\nPerspective Taking (VPT) and Theory of Behavior (TOB). We demonstrate our\napproach in the context of visual hide-and-seek - a game that represents a\ncognitive milestone in human development. Unlike traditional visual predictive\nmodel that generates new frames from immediate past frames, our agent can\ndirectly predict to multiple future timestamps (25s), extrapolating by 175%\nbeyond the training horizon. We suggest that visual behavior modeling and\nperspective taking skills will play a critical role in the ability of physical\nrobots to fully integrate into real-world multi-agent activities. Our website\nis at http://www.cs.columbia.edu/~bchen/vpttob/.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 16:02:32 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Chen", "Boyuan", ""], ["Hu", "Yuhang", ""], ["Kwiatkowski", "Robert", ""], ["Song", "Shuran", ""], ["Lipson", "Hod", ""]]}, {"id": "2105.05165", "submitter": "Rameswar Panda", "authors": "Rameswar Panda, Chun-Fu Chen, Quanfu Fan, Ximeng Sun, Kate Saenko,\n  Aude Oliva, Rogerio Feris", "title": "AdaMML: Adaptive Multi-Modal Learning for Efficient Video Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-modal learning, which focuses on utilizing various modalities to\nimprove the performance of a model, is widely used in video recognition. While\ntraditional multi-modal learning offers excellent recognition results, its\ncomputational expense limits its impact for many real-world applications. In\nthis paper, we propose an adaptive multi-modal learning framework, called\nAdaMML, that selects on-the-fly the optimal modalities for each segment\nconditioned on the input for efficient video recognition. Specifically, given a\nvideo segment, a multi-modal policy network is used to decide what modalities\nshould be used for processing by the recognition model, with the goal of\nimproving both accuracy and efficiency. We efficiently train the policy network\njointly with the recognition model using standard back-propagation. Extensive\nexperiments on four challenging diverse datasets demonstrate that our proposed\nadaptive approach yields 35%-55% reduction in computation when compared to the\ntraditional baseline that simply uses all the modalities irrespective of the\ninput, while also achieving consistent improvements in accuracy over the\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 16:19:07 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 17:49:10 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Panda", "Rameswar", ""], ["Chen", "Chun-Fu", ""], ["Fan", "Quanfu", ""], ["Sun", "Ximeng", ""], ["Saenko", "Kate", ""], ["Oliva", "Aude", ""], ["Feris", "Rogerio", ""]]}, {"id": "2105.05197", "submitter": "Batuhan Hangun", "authors": "Onder Eyecioglu, Batuhan Hangun, Korhan Kayisli, Mehmet Yesilbudak", "title": "Performance Comparison of Different Machine Learning Algorithms on the\n  Prediction of Wind Turbine Power Generation", "comments": "2019 8th International Conference on Renewable Energy Research and\n  Applications (ICRERA)", "journal-ref": null, "doi": "10.1109/ICRERA47325.2019.8996541", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Over the past decade, wind energy has gained more attention in the world.\nHowever, owing to its indirectness and volatility properties, wind power\npenetration has increased the difficulty and complexity in dispatching and\nplanning of electric power systems. Therefore, it is needed to make the\nhigh-precision wind power prediction in order to balance the electrical power.\nFor this purpose, in this study, the prediction performance of linear\nregression, k-nearest neighbor regression and decision tree regression\nalgorithms is compared in detail. k-nearest neighbor regression algorithm\nprovides lower coefficient of determination values, while decision tree\nregression algorithm produces lower mean absolute error values. In addition,\nthe meteorological parameters of wind speed, wind direction, barometric\npressure and air temperature are evaluated in terms of their importance on the\nwind power parameter. The biggest importance factor is achieved by wind speed\nparameter. In consequence, many useful assessments are made for wind power\npredictions.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 17:02:24 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Eyecioglu", "Onder", ""], ["Hangun", "Batuhan", ""], ["Kayisli", "Korhan", ""], ["Yesilbudak", "Mehmet", ""]]}, {"id": "2105.05222", "submitter": "Kayo Yin", "authors": "Kayo Yin, Amit Moryossef, Julie Hochgesang, Yoav Goldberg, Malihe\n  Alikhani", "title": "Including Signed Languages in Natural Language Processing", "comments": "ACL 2021 Best Theme Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Signed languages are the primary means of communication for many deaf and\nhard of hearing individuals. Since signed languages exhibit all the fundamental\nlinguistic properties of natural language, we believe that tools and theories\nof Natural Language Processing (NLP) are crucial towards its modeling. However,\nexisting research in Sign Language Processing (SLP) seldom attempt to explore\nand leverage the linguistic organization of signed languages. This position\npaper calls on the NLP community to include signed languages as a research area\nwith high social and scientific impact. We first discuss the linguistic\nproperties of signed languages to consider during their modeling. Then, we\nreview the limitations of current SLP models and identify the open challenges\nto extend NLP to signed languages. Finally, we urge (1) the adoption of an\nefficient tokenization method; (2) the development of linguistically-informed\nmodels; (3) the collection of real-world signed language data; (4) the\ninclusion of local signed language communities as an active and leading voice\nin the direction of research.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 17:37:55 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 19:12:46 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Yin", "Kayo", ""], ["Moryossef", "Amit", ""], ["Hochgesang", "Julie", ""], ["Goldberg", "Yoav", ""], ["Alikhani", "Malihe", ""]]}, {"id": "2105.05227", "submitter": "Yu Guo", "authors": "Yu Guo", "title": "Doing Natural Language Processing in A Natural Way: An NLP toolkit based\n  on object-oriented knowledge base and multi-level grammar base", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce an NLP toolkit based on object-oriented knowledge base and\nmulti-level grammar base. This toolkit focuses on semantic parsing, it also has\nabilities to discover new knowledge and grammar automatically, new discovered\nknowledge and grammar will be identified by human, and will be used to update\nthe knowledge base and grammar base. This process can be iterated many times to\nimprove the toolkit continuously.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 17:43:06 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 03:15:26 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Guo", "Yu", ""]]}, {"id": "2105.05233", "submitter": "Prafulla Dhariwal", "authors": "Prafulla Dhariwal, Alex Nichol", "title": "Diffusion Models Beat GANs on Image Synthesis", "comments": "Added compute requirements, ImageNet 256$\\times$256 upsampling FID\n  and samples, DDIM guided sampler, fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that diffusion models can achieve image sample quality superior to\nthe current state-of-the-art generative models. We achieve this on\nunconditional image synthesis by finding a better architecture through a series\nof ablations. For conditional image synthesis, we further improve sample\nquality with classifier guidance: a simple, compute-efficient method for\ntrading off diversity for fidelity using gradients from a classifier. We\nachieve an FID of 2.97 on ImageNet 128$\\times$128, 4.59 on ImageNet\n256$\\times$256, and 7.72 on ImageNet 512$\\times$512, and we match BigGAN-deep\neven with as few as 25 forward passes per sample, all while maintaining better\ncoverage of the distribution. Finally, we find that classifier guidance\ncombines well with upsampling diffusion models, further improving FID to 3.94\non ImageNet 256$\\times$256 and 3.85 on ImageNet 512$\\times$512. We release our\ncode at https://github.com/openai/guided-diffusion\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 17:50:24 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 17:57:59 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 17:57:08 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 17:49:49 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Dhariwal", "Prafulla", ""], ["Nichol", "Alex", ""]]}, {"id": "2105.05246", "submitter": "Florin Gogianu", "authors": "Florin Gogianu and Tudor Berariu, Mihaela Rosca, Claudia Clopath,\n  Lucian Busoniu, Razvan Pascanu", "title": "Spectral Normalisation for Deep Reinforcement Learning: an Optimisation\n  Perspective", "comments": "Accepted at ICML2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most of the recent deep reinforcement learning advances take an RL-centric\nperspective and focus on refinements of the training objective. We diverge from\nthis view and show we can recover the performance of these developments not by\nchanging the objective, but by regularising the value-function estimator.\nConstraining the Lipschitz constant of a single layer using spectral\nnormalisation is sufficient to elevate the performance of a Categorical-DQN\nagent to that of a more elaborated \\rainbow{} agent on the challenging Atari\ndomain. We conduct ablation studies to disentangle the various effects\nnormalisation has on the learning dynamics and show that is sufficient to\nmodulate the parameter updates to recover most of the performance of spectral\nnormalisation. These findings hint towards the need to also focus on the neural\ncomponent and its learning dynamics to tackle the peculiarities of Deep\nReinforcement Learning.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 17:59:46 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Gogianu", "Florin", ""], ["Berariu", "Tudor", ""], ["Rosca", "Mihaela", ""], ["Clopath", "Claudia", ""], ["Busoniu", "Lucian", ""], ["Pascanu", "Razvan", ""]]}, {"id": "2105.05296", "submitter": "Ori Sztyglic", "authors": "Ori Sztyglic and Vadim Indelman", "title": "Online POMDP Planning via Simplification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider online planning in partially observable domains.\nSolving the corresponding POMDP problem is a very challenging task,\nparticularly in an online setting. Our key contribution is a novel algorithmic\napproach, Simplified Information Theoretic Belief Space Planning (SITH-BSP),\nwhich aims to speed-up POMDP planning considering belief-dependent rewards,\nwithout compromising on the solution's accuracy. We do so by mathematically\nrelating the simplified elements of the problem to the corresponding\ncounterparts of the original problem. Specifically, we focus on belief\nsimplification and use it to formulate bounds on the corresponding original\nbelief-dependent rewards. These bounds in turn are used to perform branch\npruning over the belief tree, in the process of calculating the optimal policy.\nWe further introduce the notion of adaptive simplification, while re-using\ncalculations between different simplification levels and exploit it to prune,\nat each level in the belief tree, all branches but one. Therefore, our approach\nis guaranteed to find the optimal solution of the original problem but with\nsubstantial speedup. As a second key contribution, we derive novel analytical\nbounds for differential entropy, considering a sampling-based belief\nrepresentation, which we believe are of interest on their own. We validate our\napproach in simulation using these bounds and where simplification corresponds\nto reducing the number of samples, exhibiting a significant computational\nspeedup while yielding the optimal solution.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 18:46:08 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Sztyglic", "Ori", ""], ["Indelman", "Vadim", ""]]}, {"id": "2105.05306", "submitter": "Mla{\\dj}an Jovanovi\\'c Dr", "authors": "Mladjan Jovanovic, Aleksandar Jevremovic, Milica Pejovic-Milovancevic", "title": "Intelligent interactive technologies for mental health and well-being", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mental healthcare has seen numerous benefits from interactive technologies\nand artificial intelligence. Various interventions have successfully used\nintelligent technologies to automate the assessment and evaluation of\npsychological treatments and mental well-being and functioning. These\ntechnologies include different types of robots, video games, and conversational\nagents. The paper critically analyzes existing solutions with the outlooks for\ntheir future. In particular, we: i)give an overview of the technology for\nmental health, ii) critically analyze the technology against the proposed\ncriteria, and iii) provide the design outlooks for these technologies.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 19:04:21 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Jovanovic", "Mladjan", ""], ["Jevremovic", "Aleksandar", ""], ["Pejovic-Milovancevic", "Milica", ""]]}, {"id": "2105.05320", "submitter": "Yiming Wang", "authors": "Yiming Wang, Dongxia Chang, Zhiqian Fu, and Yao Zhao", "title": "Seeing All From a Few: Nodes Selection Using Graph Pooling for Graph\n  Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, there has been considerable research interest in graph clustering\naimed at data partition using the graph information. However, one limitation of\nthe most of graph-based methods is that they assume the graph structure to\noperate is fixed and reliable. And there are inevitably some edges in the graph\nthat are not conducive to graph clustering, which we call spurious edges. This\npaper is the first attempt to employ graph pooling technique for node\nclustering and we propose a novel dual graph embedding network (DGEN), which is\ndesigned as a two-step graph encoder connected by a graph pooling layer to\nlearn the graph embedding. In our model, it is assumed that if a node and its\nnearest neighboring node are close to the same clustering center, this node is\nan informative node and this edge can be considered as a cluster-friendly edge.\nBased on this assumption, the neighbor cluster pooling (NCPool) is devised to\nselect the most informative subset of nodes and the corresponding edges based\non the distance of nodes and their nearest neighbors to the cluster centers.\nThis can effectively alleviate the impact of the spurious edges on the\nclustering. Finally, to obtain the clustering assignment of all nodes, a\nclassifier is trained using the clustering results of the selected nodes.\nExperiments on five benchmark graph datasets demonstrate the superiority of the\nproposed method over state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Apr 2021 06:51:51 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 02:51:53 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Wang", "Yiming", ""], ["Chang", "Dongxia", ""], ["Fu", "Zhiqian", ""], ["Zhao", "Yao", ""]]}, {"id": "2105.05330", "submitter": "Md Kamruzzaman Sarker", "authors": "Md Kamruzzaman Sarker, Lu Zhou, Aaron Eberhart, Pascal Hitzler", "title": "Neuro-Symbolic Artificial Intelligence: Current Trends", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neuro-Symbolic Artificial Intelligence -- the combination of symbolic methods\nwith methods that are based on artificial neural networks -- has a\nlong-standing history. In this article, we provide a structured overview of\ncurrent trends, by means of categorizing recent publications from key\nconferences. The article is meant to serve as a convenient starting point for\nresearch on the general topic.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 20:11:57 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 05:08:12 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Sarker", "Md Kamruzzaman", ""], ["Zhou", "Lu", ""], ["Eberhart", "Aaron", ""], ["Hitzler", "Pascal", ""]]}, {"id": "2105.05347", "submitter": "Tom Schaul", "authors": "Tom Schaul, Georg Ostrovski, Iurii Kemaev, Diana Borsa", "title": "Return-based Scaling: Yet Another Normalisation Trick for Deep RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scaling issues are mundane yet irritating for practitioners of reinforcement\nlearning. Error scales vary across domains, tasks, and stages of learning;\nsometimes by many orders of magnitude. This can be detrimental to learning\nspeed and stability, create interference between learning tasks, and\nnecessitate substantial tuning. We revisit this topic for agents based on\ntemporal-difference learning, sketch out some desiderata and investigate\nscenarios where simple fixes fall short. The mechanism we propose requires\nneither tuning, clipping, nor adaptation. We validate its effectiveness and\nrobustness on the suite of Atari games. Our scaling method turns out to be\nparticularly helpful at mitigating interference, when training a shared neural\nnetwork on multiple targets that differ in reward scale or discounting.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 21:31:02 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Schaul", "Tom", ""], ["Ostrovski", "Georg", ""], ["Kemaev", "Iurii", ""], ["Borsa", "Diana", ""]]}, {"id": "2105.05381", "submitter": "Shahbaz Rezaei", "authors": "Shahbaz Rezaei, Zubair Shafiq, Xin Liu", "title": "Accuracy-Privacy Trade-off in Deep Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep ensemble learning has been shown to improve accuracy by training\nmultiple neural networks and fusing their outputs. Ensemble learning has also\nbeen used to defend against membership inference attacks that undermine\nprivacy. In this paper, we empirically demonstrate a trade-off between these\ntwo goals, namely accuracy and privacy (in terms of membership inference\nattacks), in deep ensembles. Using a wide range of datasets and model\narchitectures, we show that the effectiveness of membership inference attacks\nalso increases when ensembling improves accuracy. To better understand this\ntrade-off, we study the impact of various factors such as prediction confidence\nand agreement between models that constitute the ensemble. Finally, we evaluate\ndefenses against membership inference attacks based on regularization and\ndifferential privacy. We show that while these defenses can mitigate the\neffectiveness of the membership inference attack, they simultaneously degrade\nensemble accuracy. The source code is available at\nhttps://github.com/shrezaei/MI-on-EL.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 00:58:04 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 16:48:18 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Rezaei", "Shahbaz", ""], ["Shafiq", "Zubair", ""], ["Liu", "Xin", ""]]}, {"id": "2105.05382", "submitter": "Arna Ghosh", "authors": "Luke Y. Prince, Ellen Boven, Roy Henha Eyono, Arna Ghosh, Joe\n  Pemberton, Franz Scherr, Claudia Clopath, Rui Ponte Costa, Wolfgang Maass,\n  Blake A. Richards, Cristina Savin, Katharina Anna Wilmes", "title": "CCN GAC Workshop: Issues with learning in biological recurrent neural\n  networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This perspective piece came about through the Generative Adversarial\nCollaboration (GAC) series of workshops organized by the Computational\nCognitive Neuroscience (CCN) conference in 2020. We brought together a number\nof experts from the field of theoretical neuroscience to debate emerging issues\nin our understanding of how learning is implemented in biological recurrent\nneural networks. Here, we will give a brief review of the common assumptions\nabout biological learning and the corresponding findings from experimental\nneuroscience and contrast them with the efficiency of gradient-based learning\nin recurrent neural networks commonly used in artificial intelligence. We will\nthen outline the key issues discussed in the workshop: synaptic plasticity,\nneural circuits, theory-experiment divide, and objective functions. Finally, we\nconclude with recommendations for both theoretical and experimental\nneuroscientists when designing new studies that could help to bring clarity to\nthese issues.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 00:59:40 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Prince", "Luke Y.", ""], ["Boven", "Ellen", ""], ["Eyono", "Roy Henha", ""], ["Ghosh", "Arna", ""], ["Pemberton", "Joe", ""], ["Scherr", "Franz", ""], ["Clopath", "Claudia", ""], ["Costa", "Rui Ponte", ""], ["Maass", "Wolfgang", ""], ["Richards", "Blake A.", ""], ["Savin", "Cristina", ""], ["Wilmes", "Katharina Anna", ""]]}, {"id": "2105.05395", "submitter": "Abhishek Ray", "authors": "Marios Papamichalis, Abhishek Ray, Ilias Bilionis, Karthik Kannan,\n  Rajiv Krishnamurthy", "title": "Bayesian Model Averaging for Data Driven Decision Making when Causality\n  is Partially Known", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Probabilistic machine learning models are often insufficient to help with\ndecisions on interventions because those models find correlations - not causal\nrelationships. If observational data is only available and experimentation are\ninfeasible, the correct approach to study the impact of an intervention is to\ninvoke Pearl's causality framework. Even that framework assumes that the\nunderlying causal graph is known, which is seldom the case in practice. When\nthe causal structure is not known, one may use out-of-the-box algorithms to\nfind causal dependencies from observational data. However, there exists no\nmethod that also accounts for the decision-maker's prior knowledge when\ndeveloping the causal structure either. The objective of this paper is to\ndevelop rational approaches for making decisions from observational data in the\npresence of causal graph uncertainty and prior knowledge from the\ndecision-maker. We use ensemble methods like Bayesian Model Averaging (BMA) to\ninfer set of causal graphs that can represent the data generation process. We\nprovide decisions by computing the expected value and risk of potential\ninterventions explicitly. We demonstrate our approach by applying them in\ndifferent example contexts.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 01:55:45 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Papamichalis", "Marios", ""], ["Ray", "Abhishek", ""], ["Bilionis", "Ilias", ""], ["Kannan", "Karthik", ""], ["Krishnamurthy", "Rajiv", ""]]}, {"id": "2105.05418", "submitter": "Aman Madaan", "authors": "Aman Madaan, Dheeraj Rajagopal, Niket Tandon, Yiming Yang, Eduard Hovy", "title": "Could you give me a hint? Generating inference graphs for defeasible\n  reasoning", "comments": "Findings of the Association for Computational Linguistics: ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Defeasible reasoning is the mode of reasoning where conclusions can be\noverturned by taking into account new evidence. A commonly used method in\ncognitive science and logic literature is to handcraft argumentation supporting\ninference graphs. While humans find inference graphs very useful for reasoning,\nconstructing them at scale is difficult. In this paper, we automatically\ngenerate such inference graphs through transfer learning from another NLP task\nthat shares the kind of reasoning that inference graphs support. Through\nautomated metrics and human evaluation, we find that our method generates\nmeaningful graphs for the defeasible inference task. Human accuracy on this\ntask improves by 20% by consulting the generated graphs. Our findings open up\nexciting new research avenues for cases where machine reasoning can help human\nreasoning. (A dataset of 230,000 influence graphs for each defeasible query is\nlocated at: https://tinyurl.com/defeasiblegraphs.)\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 04:04:10 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 03:46:46 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Madaan", "Aman", ""], ["Rajagopal", "Dheeraj", ""], ["Tandon", "Niket", ""], ["Yang", "Yiming", ""], ["Hovy", "Eduard", ""]]}, {"id": "2105.05424", "submitter": "Wei Xu", "authors": "Wei Xu, Marvin J. Dainoff, Liezhong Ge, Zaifeng Gao", "title": "Transitioning to human interaction with AI systems: New challenges and\n  opportunities for HCI professionals to enable human-centered AI", "comments": "72 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While AI has benefited humans, it may also harm humans if not appropriately\ndeveloped. The focus of HCI work is transiting from conventional human\ninteraction with non-AI computing systems to interaction with AI systems. We\nconducted a high-level literature review and a holistic analysis of current\nwork in developing AI systems from an HCI perspective. Our review and analysis\nhighlight the new changes introduced by AI technology and the new challenges\nthat HCI professionals face when applying the human-centered AI (HCAI) approach\nin the development of AI systems. We also identified seven main issues in human\ninteraction with AI systems, which HCI professionals did not encounter when\ndeveloping non-AI computing systems. To further enable the implementation of\nthe HCAI approach, we identified new HCI opportunities tied to specific\nHCAI-driven design goals to guide HCI professionals in addressing these new\nissues. Finally, our assessment of current HCI methods shows the limitations of\nthese methods in support of developing AI systems. We propose alternative\nmethods that can help overcome these limitations and effectively help HCI\nprofessionals apply the HCAI approach to the development of AI systems. We also\noffer strategic recommendations for HCI professionals to effectively influence\nthe development of AI systems with the HCAI approach, eventually developing\nHCAI systems.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 04:30:45 GMT"}, {"version": "v2", "created": "Sat, 24 Jul 2021 00:28:44 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Xu", "Wei", ""], ["Dainoff", "Marvin J.", ""], ["Ge", "Liezhong", ""], ["Gao", "Zaifeng", ""]]}, {"id": "2105.05473", "submitter": "Chenyang Xi", "authors": "Chenyang Xi, Bo Tang, Jiajun Shen, Xinfu Liu, Feiyu Xiong, Xueying Li", "title": "Interpretable performance analysis towards offline reinforcement\n  learning: A dataset perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline reinforcement learning (RL) has increasingly become the focus of the\nartificial intelligent research due to its wide real-world applications where\nthe collection of data may be difficult, time-consuming, or costly. In this\npaper, we first propose a two-fold taxonomy for existing offline RL algorithms\nfrom the perspective of exploration and exploitation tendency. Secondly, we\nderive the explicit expression of the upper bound of extrapolation error and\nexplore the correlation between the performance of different types of\nalgorithms and the distribution of actions under states. Specifically, we relax\nthe strict assumption on the sufficiently large amount of state-action tuples.\nAccordingly, we provably explain why batch constrained Q-learning (BCQ)\nperforms better than other existing techniques. Thirdly, after identifying the\nweakness of BCQ on dataset of low mean episode returns, we propose a modified\nvariant based on top return selection mechanism, which is proved to be able to\ngain state-of-the-art performance on various datasets. Lastly, we create a\nbenchmark platform on the Atari domain, entitled RL easy go (RLEG), at an\nestimated cost of more than 0.3 million dollars. We make it open-source for\nfair and comprehensive competitions between offline RL algorithms with complete\ndatasets and checkpoints being provided.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 07:17:06 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Xi", "Chenyang", ""], ["Tang", "Bo", ""], ["Shen", "Jiajun", ""], ["Liu", "Xinfu", ""], ["Xiong", "Feiyu", ""], ["Li", "Xueying", ""]]}, {"id": "2105.05498", "submitter": "Gyubok Lee", "authors": "Gyubok Lee, Seongjun Yang, Edward Choi", "title": "Improving Lexically Constrained Neural Machine Translation with\n  Source-Conditioned Masked Span Prediction", "comments": "To appear in ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate terminology translation is crucial for ensuring the practicality and\nreliability of neural machine translation (NMT) systems. To address this,\nlexically constrained NMT explores various methods to ensure pre-specified\nwords and phrases appear in the translation output. However, in many cases,\nthose methods are studied on general domain corpora, where the terms are mostly\nuni- and bi-grams (>98%). In this paper, we instead tackle a more challenging\nsetup consisting of domain-specific corpora with much longer n-gram and highly\nspecialized terms. Inspired by the recent success of masked span prediction\nmodels, we propose a simple and effective training strategy that achieves\nconsistent improvements on both terminology and sentence-level translation for\nthree domain-specific corpora in two language pairs.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 08:11:33 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 10:59:03 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Lee", "Gyubok", ""], ["Yang", "Seongjun", ""], ["Choi", "Edward", ""]]}, {"id": "2105.05559", "submitter": "Hans Weytjens", "authors": "Hans Weytjens and Jochen De Weerdt", "title": "Learning Uncertainty with Artificial Neural Networks for Improved\n  Remaining Time Prediction of Business Processes", "comments": "Accepted for the main conference at the Business Process Management\n  Conferences 2021, 6-10 September 2021, Rome, Italy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial neural networks will always make a prediction, even when\ncompletely uncertain and regardless of the consequences. This obliviousness of\nuncertainty is a major obstacle towards their adoption in practice. Techniques\nexist, however, to estimate the two major types of uncertainty: model\nuncertainty and observation noise in the data. Bayesian neural networks are\ntheoretically well-founded models that can learn the model uncertainty of their\npredictions. Minor modifications to these models and their loss functions allow\nlearning the observation noise for individual samples as well. This paper is\nthe first to apply these techniques to predictive process monitoring. We found\nthat they contribute towards more accurate predictions and work quickly.\nHowever, their main benefit resides with the uncertainty estimates themselves\nthat allow the separation of higher-quality from lower-quality predictions and\nthe building of confidence intervals. This leads to many interesting\napplications, enables an earlier adoption of prediction systems with smaller\ndatasets and fosters a better cooperation with humans.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 10:18:57 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Weytjens", "Hans", ""], ["De Weerdt", "Jochen", ""]]}, {"id": "2105.05563", "submitter": "Yanbo Xue", "authors": "Yuan Cheng and Yanbo Xue", "title": "Looking at CTR Prediction Again: Is Attention All You Need?", "comments": "9 pages, 2 figures, 4 tables, SIGIR'21", "journal-ref": null, "doi": "10.1145/3404835.3462936", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction is a critical problem in web search,\nrecommendation systems and online advertisement displaying. Learning good\nfeature interactions is essential to reflect user's preferences to items. Many\nCTR prediction models based on deep learning have been proposed, but\nresearchers usually only pay attention to whether state-of-the-art performance\nis achieved, and ignore whether the entire framework is reasonable. In this\nwork, we use the discrete choice model in economics to redefine the CTR\nprediction problem, and propose a general neural network framework built on\nself-attention mechanism. It is found that most existing CTR prediction models\nalign with our proposed general framework. We also examine the expressive power\nand model complexity of our proposed framework, along with potential extensions\nto some existing models. And finally we demonstrate and verify our insights\nthrough some experimental results on public datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 10:27:14 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Cheng", "Yuan", ""], ["Xue", "Yanbo", ""]]}, {"id": "2105.05571", "submitter": "Chen Shani", "authors": "Chen Shani, Alexander Libov, Sofia Tolmach, Liane Lewin-Eytan, Yoelle\n  Maarek, Dafna Shahaf", "title": "\"Alexa, what do you do for fun?\" Characterizing playful requests with\n  virtual assistants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual assistants such as Amazon's Alexa, Apple's Siri, Google Home, and\nMicrosoft's Cortana, are becoming ubiquitous in our daily lives and\nsuccessfully help users in various daily tasks, such as making phone calls or\nplaying music. Yet, they still struggle with playful utterances, which are not\nmeant to be interpreted literally. Examples include jokes or absurd requests or\nquestions such as, \"Are you afraid of the dark?\", \"Who let the dogs out?\", or\n\"Order a zillion gummy bears\". Today, virtual assistants often return\nirrelevant answers to such utterances, except for hard-coded ones addressed by\ncanned replies.\n  To address the challenge of automatically detecting playful utterances, we\nfirst characterize the different types of playful human-virtual assistant\ninteraction. We introduce a taxonomy of playful requests rooted in theories of\nhumor and refined by analyzing real-world traffic from Alexa. We then focus on\none node, personification, where users refer to the virtual assistant as a\nperson (\"What do you do for fun?\"). Our conjecture is that understanding such\nutterances will improve user experience with virtual assistants. We conducted a\nWizard-of-Oz user study and showed that endowing virtual assistant s with the\nability to identify humorous opportunities indeed has the potential to increase\nuser satisfaction. We hope this work will contribute to the understanding of\nthe landscape of the problem and inspire novel ideas and techniques towards the\nvision of giving virtual assistants a sense of humor.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 10:48:00 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Shani", "Chen", ""], ["Libov", "Alexander", ""], ["Tolmach", "Sofia", ""], ["Lewin-Eytan", "Liane", ""], ["Maarek", "Yoelle", ""], ["Shahaf", "Dafna", ""]]}, {"id": "2105.05589", "submitter": "Saba Gholizadeh Ansari", "authors": "Saba Gholizadeh Ansari, I. S. W. B. Prasetya, Mehdi Dastani, Frank\n  Dignum, Gabriele Keller", "title": "An Appraisal Transition System for Event-driven Emotions in Agent-based\n  Player Experience Testing", "comments": "This is a preprint of an article with the same title, accepted in 9th\n  International Workshop on Engineering Multi-Agent Systems (EMAS 2021) which\n  was held as a part of 20th International Conference on Autonomous Agents and\n  Multiagent Systems (AAMAS 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Player experience (PX) evaluation has become a field of interest in the game\nindustry. Several manual PX techniques have been introduced to assist\ndevelopers to understand and evaluate the experience of players in computer\ngames. However, automated testing of player experience still needs to be\naddressed. An automated player experience testing framework would allow\ndesigners to evaluate the PX requirements in the early development stages\nwithout the necessity of participating human players. In this paper, we propose\nan automated player experience testing approach by suggesting a formal model of\nevent-based emotions. In particular, we discuss an event-based transition\nsystem to formalize relevant emotions using Ortony, Clore, & Collins (OCC)\ntheory of emotions. A working prototype of the model is integrated on top of\nAplib, a tactical agent programming library, to create intelligent PX test\nagents, capable of appraising emotions in a 3D game case study. The results are\ngraphically shown e.g. as heat maps. Emotion visualization of the test agent\nwould ultimately help game designers in creating content that evokes a certain\nexperience in players.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 11:09:35 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Ansari", "Saba Gholizadeh", ""], ["Prasetya", "I. S. W. B.", ""], ["Dastani", "Mehdi", ""], ["Dignum", "Frank", ""], ["Keller", "Gabriele", ""]]}, {"id": "2105.05596", "submitter": "Ziheng Zhang", "authors": "Zhiyuan Qi, Ziheng Zhang, Jiaoyan Chen, Xi Chen, Yuejia Xiang, Ningyu\n  Zhang, Yefeng Zheng", "title": "Unsupervised Knowledge Graph Alignment by Probabilistic Reasoning and\n  Semantic Embedding", "comments": "Accepted by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge Graph (KG) alignment is to discover the mappings (i.e., equivalent\nentities, relations, and others) between two KGs. The existing methods can be\ndivided into the embedding-based models, and the conventional reasoning and\nlexical matching based systems. The former compute the similarity of entities\nvia their cross-KG embeddings, but they usually rely on an ideal supervised\nlearning setting for good performance and lack appropriate reasoning to avoid\nlogically wrong mappings; while the latter address the reasoning issue but are\npoor at utilizing the KG graph structures and the entity contexts. In this\nstudy, we aim at combining the above two solutions and thus propose an\niterative framework named PRASE which is based on probabilistic reasoning and\nsemantic embedding. It learns the KG embeddings via entity mappings from a\nprobabilistic reasoning system named PARIS, and feeds the resultant entity\nmappings and embeddings back into PARIS for augmentation. The PRASE framework\nis compatible with different embedding-based models, and our experiments on\nmultiple datasets have demonstrated its state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 11:27:46 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 02:25:23 GMT"}, {"version": "v3", "created": "Fri, 11 Jun 2021 07:51:22 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Qi", "Zhiyuan", ""], ["Zhang", "Ziheng", ""], ["Chen", "Jiaoyan", ""], ["Chen", "Xi", ""], ["Xiang", "Yuejia", ""], ["Zhang", "Ningyu", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2105.05621", "submitter": "Ashutosh Modi", "authors": "Pradip Swarnakar and Ashutosh Modi", "title": "NLP for Climate Policy: Creating a Knowledge Platform for Holistic and\n  Effective Climate Action", "comments": "12 Pages (8 + 4 pages for references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Climate change is a burning issue of our time, with the Sustainable\nDevelopment Goal (SDG) 13 of the United Nations demanding global climate\naction. Realizing the urgency, in 2015 in Paris, world leaders signed an\nagreement committing to taking voluntary action to reduce carbon emissions.\nHowever, the scale, magnitude, and climate action processes vary globally,\nespecially between developed and developing countries. Therefore, from\nparliament to social media, the debates and discussions on climate change\ngather data from wide-ranging sources essential to the policy design and\nimplementation. The downside is that we do not currently have the mechanisms to\npool the worldwide dispersed knowledge emerging from the structured and\nunstructured data sources.\n  The paper thematically discusses how NLP techniques could be employed in\nclimate policy research and contribute to society's good at large. In\nparticular, we exemplify symbiosis of NLP and Climate Policy Research via four\nmethodologies. The first one deals with the major topics related to climate\npolicy using automated content analysis. We investigate the opinions\n(sentiments) of major actors' narratives towards climate policy in the second\nmethodology. The third technique explores the climate actors' beliefs towards\npro or anti-climate orientation. Finally, we discuss developing a Climate\nKnowledge Graph.\n  The present theme paper further argues that creating a knowledge platform\nwould help in the formulation of a holistic climate policy and effective\nclimate action. Such a knowledge platform would integrate the policy actors'\nvaried opinions from different social sectors like government, business, civil\nsociety, and the scientific community. The research outcome will add value to\neffective climate action because policymakers can make informed decisions by\nlooking at the diverse public opinion on a comprehensive platform.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 12:30:02 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Swarnakar", "Pradip", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2105.05633", "submitter": "Robin Strudel", "authors": "Robin Strudel, Ricardo Garcia, Ivan Laptev, Cordelia Schmid", "title": "Segmenter: Transformer for Semantic Segmentation", "comments": "Code available at https://github.com/rstrudel/segmenter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Image segmentation is often ambiguous at the level of individual image\npatches and requires contextual information to reach label consensus. In this\npaper we introduce Segmenter, a transformer model for semantic segmentation. In\ncontrast to convolution based approaches, our approach allows to model global\ncontext already at the first layer and throughout the network. We build on the\nrecent Vision Transformer (ViT) and extend it to semantic segmentation. To do\nso, we rely on the output embeddings corresponding to image patches and obtain\nclass labels from these embeddings with a point-wise linear decoder or a mask\ntransformer decoder. We leverage models pre-trained for image classification\nand show that we can fine-tune them on moderate sized datasets available for\nsemantic segmentation. The linear decoder allows to obtain excellent results\nalready, but the performance can be further improved by a mask transformer\ngenerating class masks. We conduct an extensive ablation study to show the\nimpact of the different parameters, in particular the performance is better for\nlarge models and small patch sizes. Segmenter attains excellent results for\nsemantic segmentation. It outperforms the state of the art on the challenging\nADE20K dataset and performs on-par on Pascal Context and Cityscapes.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 13:01:44 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Strudel", "Robin", ""], ["Garcia", "Ricardo", ""], ["Laptev", "Ivan", ""], ["Schmid", "Cordelia", ""]]}, {"id": "2105.05714", "submitter": "Matthew Hutson", "authors": "Matthew Hutson", "title": "Representation in Dynamical Systems", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI nlin.CD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The brain is often called a computer and likened to a Turing machine, in part\nbecause the mind can manipulate discrete symbols such as numbers. But the brain\nis a dynamical system, more like a Watt governor than a Turing machine. Can a\ndynamical system be said to operate using \"representations\"? This paper argues\nthat it can, although not in the way a digital computer does. Instead, it uses\nphenomena best described using mathematic concepts such as chaotic attractors\nto stand in for aspects of the world.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 15:03:03 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Hutson", "Matthew", ""]]}, {"id": "2105.05716", "submitter": "Adrian Remonda", "authors": "Adrian Remonda, Eduardo Veas, Granit Luzhnica", "title": "Acting upon Imagination: when to trust imagined trajectories in model\n  based reinforcement learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Model based reinforcement learning (MBRL) uses an imperfect model of the\nworld to imagine trajectories of future states and plan the best actions to\nmaximize a reward function. These trajectories are imperfect and MBRL attempts\nto overcome this by relying on model predictive control (MPC) to continuously\nre-imagine trajectories from scratch. Such re-generation of imagined\ntrajectories carries the major computational cost and increasing complexity in\ntasks with longer receding horizon. This paper aims to investigate how far in\nthe future the imagined trajectories can be relied upon while still maintaining\nacceptable reward. Firstly, an error analysis is presented for systematic\nskipping recalculations for varying number of consecutive steps.% in several\nchallenging benchmark control tasks. Secondly, we propose two methods offering\nwhen to trust and act upon imagined trajectories, looking at recent errors with\nrespect to expectations, or comparing the confidence in an action imagined\nagainst its execution. Thirdly, we evaluate the effects of acting upon\nimagination while training the model of the world. Results show that acting\nupon imagination can reduce calculations by at least 20% and up to 80%,\ndepending on the environment, while retaining acceptable reward.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 15:04:07 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 10:26:30 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Remonda", "Adrian", ""], ["Veas", "Eduardo", ""], ["Luzhnica", "Granit", ""]]}, {"id": "2105.05717", "submitter": "Lunchen Xie", "authors": "Lunchen Xie, Jiaqi Liu, Songtao Lu, Tsung-hui Chang, Qingjiang Shi", "title": "An Efficient Learning Framework For Federated XGBoost Using Secret\n  Sharing And Distributed Optimization", "comments": "24 pages, Special issue of ACM Transactions on Intelligent Systems\n  and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  XGBoost is one of the most widely used machine learning models in the\nindustry due to its superior learning accuracy and efficiency. Targeting at\ndata isolation issues in the big data problems, it is crucial to deploy a\nsecure and efficient federated XGBoost (FedXGB) model. Existing FedXGB models\neither have data leakage issues or are only applicable to the two-party setting\nwith heavy communication and computation overheads. In this paper, a lossless\nmulti-party federated XGB learning framework is proposed with a security\nguarantee, which reshapes the XGBoost's split criterion calculation process\nunder a secret sharing setting and solves the leaf weight calculation problem\nby leveraging distributed optimization. Remarkably, a thorough analysis of\nmodel security is provided as well, and multiple numerical results showcase the\nsuperiority of the proposed FedXGB compared with the state-of-the-art models on\nbenchmark datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 15:04:18 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Xie", "Lunchen", ""], ["Liu", "Jiaqi", ""], ["Lu", "Songtao", ""], ["Chang", "Tsung-hui", ""], ["Shi", "Qingjiang", ""]]}, {"id": "2105.05744", "submitter": "Sandipan Basu Mr", "authors": "Sandipan Basu, Aravind Gaddala, Pooja Chetan, Garima Tiwari, Narayana\n  Darapaneni, Sadwik Parvathaneni, Anwesh Reddy Paduri", "title": "Building a Question and Answer System for News Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This project attempts to build a Question- Answering system in the News\nDomain, where Passages will be News articles, and anyone can ask a Question\nagainst it. We have built a span-based model using an Attention mechanism,\nwhere the model predicts the answer to a question as to the position of the\nstart and end tokens in a paragraph. For training our model, we have used the\nStanford Question and Answer (SQuAD 2.0) dataset[1]. To do well on SQuAD 2.0,\nsystems must not only answer questions when possible but also determine when no\nanswer is supported by the paragraph and abstain from answering. Our model\narchitecture comprises three layers- Embedding Layer, RNN Layer, and the\nAttention Layer. For the Embedding layer, we used GloVe and the Universal\nSentence Encoder. For the RNN Layer, we built variations of the RNN Layer\nincluding bi-LSTM and Stacked LSTM and we built an Attention Layer using a\nContext to Question Attention and also improvised on the innovative\nBidirectional Attention Layer. Our best performing model which uses GloVe\nEmbedding combined with Bi-LSTM and Context to Question Attention achieved an\nF1 Score and EM of 33.095 and 33.094 respectively. We also leveraged transfer\nlearning and built a Transformer based model using BERT. The BERT-based model\nachieved an F1 Score and EM of 57.513 and 49.769 respectively. We concluded\nthat the BERT model is superior in all aspects of answering various types of\nquestions.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 15:56:21 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Basu", "Sandipan", ""], ["Gaddala", "Aravind", ""], ["Chetan", "Pooja", ""], ["Tiwari", "Garima", ""], ["Darapaneni", "Narayana", ""], ["Parvathaneni", "Sadwik", ""], ["Paduri", "Anwesh Reddy", ""]]}, {"id": "2105.05757", "submitter": "Thomas Goerttler", "authors": "Thomas Goerttler and Klaus Obermayer", "title": "Exploring the Similarity of Representations in Model-Agnostic\n  Meta-Learning", "comments": "Learning to Learn workshop at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In past years model-agnostic meta-learning (MAML) has been one of the most\npromising approaches in meta-learning. It can be applied to different kinds of\nproblems, e.g., reinforcement learning, but also shows good results on few-shot\nlearning tasks. Besides their tremendous success in these tasks, it has still\nnot been fully revealed yet, why it works so well. Recent work proposes that\nMAML rather reuses features than rapidly learns. In this paper, we want to\ninspire a deeper understanding of this question by analyzing MAML's\nrepresentation. We apply representation similarity analysis (RSA), a\nwell-established method in neuroscience, to the few-shot learning instantiation\nof MAML. Although some part of our analysis supports their general results that\nfeature reuse is predominant, we also reveal arguments against their\nconclusion. The similarity-increase of layers closer to the input layers arises\nfrom the learning task itself and not from the model. In addition, the\nrepresentations after inner gradient steps make a broader change to the\nrepresentation than the changes during meta-training.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 16:20:40 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Goerttler", "Thomas", ""], ["Obermayer", "Klaus", ""]]}, {"id": "2105.05789", "submitter": "Andrey Zhitnikov", "authors": "Andrey Zhitnikov, Vadim Indelman", "title": "Probabilistic Loss and its Online Characterization for Simplified\n  Decision Making Under Uncertainty", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is a long-standing objective to ease the computation burden incurred by\nthe decision making process. Identification of this mechanism's sensitivity to\nsimplification has tremendous ramifications. Yet, algorithms for decision\nmaking under uncertainty usually lean on approximations or heuristics without\nquantifying their effect. Therefore, challenging scenarios could severely\nimpair the performance of such methods. In this paper, we extend the decision\nmaking mechanism to the whole by removing standard approximations and\nconsidering all previously suppressed stochastic sources of variability. On top\nof this extension, our key contribution is a novel framework to simplify\ndecision making while assessing and controlling online the simplification's\nimpact. Furthermore, we present novel stochastic bounds on the return and\ncharacterize online the effect of simplification using this framework on a\nparticular simplification technique - reducing the number of samples in belief\nrepresentation for planning. Finally, we verify the advantages of our approach\nthrough extensive simulations.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 17:02:01 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Zhitnikov", "Andrey", ""], ["Indelman", "Vadim", ""]]}, {"id": "2105.05790", "submitter": "Caleb Belth", "authors": "Caleb Belth, Sarah Payne, Deniz Beser, Jordan Kodner, Charles Yang", "title": "The Greedy and Recursive Search for Morphological Productivity", "comments": "CogSci 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As children acquire the knowledge of their language's morphology, they\ninvariably discover the productive processes that can generalize to new words.\nMorphological learning is made challenging by the fact that even fully\nproductive rules have exceptions, as in the well-known case of English past\ntense verbs, which features the -ed rule against the irregular verbs. The\nTolerance Principle is a recent proposal that provides a precise threshold of\nexceptions that a productive rule can withstand. Its empirical application so\nfar, however, requires the researcher to fully specify rules defined over a set\nof words. We propose a greedy search model that automatically hypothesizes\nrules and evaluates their productivity over a vocabulary. When the search for\nbroader productivity fails, the model recursively subdivides the vocabulary and\ncontinues the search for productivity over narrower rules. Trained on\npsychologically realistic data from child-directed input, our model displays\ndevelopmental patterns observed in child morphology acquisition, including the\nnotoriously complex case of German noun pluralization. It also produces\nresponses to nonce words that, despite receiving only a fraction of the\ntraining data, are more similar to those of human subjects than current neural\nnetwork models' responses are.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 17:02:32 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Belth", "Caleb", ""], ["Payne", "Sarah", ""], ["Beser", "Deniz", ""], ["Kodner", "Jordan", ""], ["Yang", "Charles", ""]]}, {"id": "2105.05873", "submitter": "Roberto Bigazzi", "authors": "Roberto Bigazzi, Federico Landi, Marcella Cornia, Silvia Cascianelli,\n  Lorenzo Baraldi and Rita Cucchiara", "title": "Out of the Box: Embodied Navigation in the Real World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.RO", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The research field of Embodied AI has witnessed substantial progress in\nvisual navigation and exploration thanks to powerful simulating platforms and\nthe availability of 3D data of indoor and photorealistic environments. These\ntwo factors have opened the doors to a new generation of intelligent agents\ncapable of achieving nearly perfect PointGoal Navigation. However, such\narchitectures are commonly trained with millions, if not billions, of frames\nand tested in simulation. Together with great enthusiasm, these results yield a\nquestion: how many researchers will effectively benefit from these advances? In\nthis work, we detail how to transfer the knowledge acquired in simulation into\nthe real world. To that end, we describe the architectural discrepancies that\ndamage the Sim2Real adaptation ability of models trained on the Habitat\nsimulator and propose a novel solution tailored towards the deployment in\nreal-world scenarios. We then deploy our models on a LoCoBot, a Low-Cost Robot\nequipped with a single Intel RealSense camera. Different from previous work,\nour testing scene is unavailable to the agent in simulation. The environment is\nalso inaccessible to the agent beforehand, so it cannot count on scene-specific\nsemantic priors. In this way, we reproduce a setting in which a research group\n(potentially from other fields) needs to employ the agent visual navigation\ncapabilities as-a-Service. Our experiments indicate that it is possible to\nachieve satisfying results when deploying the obtained model in the real world.\nOur code and models are available at https://github.com/aimagelab/LoCoNav.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 18:00:14 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Bigazzi", "Roberto", ""], ["Landi", "Federico", ""], ["Cornia", "Marcella", ""], ["Cascianelli", "Silvia", ""], ["Baraldi", "Lorenzo", ""], ["Cucchiara", "Rita", ""]]}, {"id": "2105.05883", "submitter": "Yann Fraboni", "authors": "Yann Fraboni, Richard Vidal, Laetitia Kameni, Marco Lorenzi", "title": "Clustered Sampling: Low-Variance and Improved Representativity for\n  Clients Selection in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the problem of optimizing communications between server\nand clients in federated learning (FL). Current sampling approaches in FL are\neither biased, or non optimal in terms of server-clients communications and\ntraining stability. To overcome this issue, we introduce \\textit{clustered\nsampling} for clients selection. We prove that clustered sampling leads to\nbetter clients representatitivity and to reduced variance of the clients\nstochastic aggregation weights in FL. Compatibly with our theory, we provide\ntwo different clustering approaches enabling clients aggregation based on 1)\nsample size, and 2) models similarity. Through a series of experiments in\nnon-iid and unbalanced scenarios, we demonstrate that model aggregation through\nclustered sampling consistently leads to better training convergence and\nvariability when compared to standard sampling approaches. Our approach does\nnot require any additional operation on the clients side, and can be seamlessly\nintegrated in standard FL implementations. Finally, clustered sampling is\ncompatible with existing methods and technologies for privacy enhancement, and\nfor communication reduction through model compression.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 18:19:20 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 12:50:59 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Fraboni", "Yann", ""], ["Vidal", "Richard", ""], ["Kameni", "Laetitia", ""], ["Lorenzi", "Marco", ""]]}, {"id": "2105.05885", "submitter": "Divya Koyyalagunta", "authors": "Divya Koyyalagunta, Anna Sun, Rachel Lea Draelos, Cynthia Rudin", "title": "Playing Codenames with Language Graphs and Word Embeddings", "comments": "Divya Koyyalagunta and Anna Sun contributed equally to this work.\n  This is an arXiv version of the paper that has been accepted for publication\n  in the Journal of Artificial Intelligence Research (JAIR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although board games and video games have been studied for decades in\nartificial intelligence research, challenging word games remain relatively\nunexplored. Word games are not as constrained as games like chess or poker.\nInstead, word game strategy is defined by the players' understanding of the way\nwords relate to each other. The word game Codenames provides a unique\nopportunity to investigate common sense understanding of relationships between\nwords, an important open challenge. We propose an algorithm that can generate\nCodenames clues from the language graph BabelNet or from any of several\nembedding methods - word2vec, GloVe, fastText or BERT. We introduce a new\nscoring function that measures the quality of clues, and we propose a weighting\nterm called DETECT that incorporates dictionary-based word representations and\ndocument frequency to improve clue selection. We develop BabelNet-Word\nSelection Framework (BabelNet-WSF) to improve BabelNet clue quality and\novercome the computational barriers that previously prevented leveraging\nlanguage graphs for Codenames. Extensive experiments with human evaluators\ndemonstrate that our proposed innovations yield state-of-the-art performance,\nwith up to 102.8% improvement in precision@2 in some cases. Overall, this work\nadvances the formal study of word games and approaches for common sense\nlanguage understanding.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 18:23:03 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Koyyalagunta", "Divya", ""], ["Sun", "Anna", ""], ["Draelos", "Rachel Lea", ""], ["Rudin", "Cynthia", ""]]}, {"id": "2105.05911", "submitter": "Christopher Morris", "authors": "Christopher Morris, Matthias Fey, Nils M. Kriege", "title": "The Power of the Weisfeiler-Leman Algorithm for Machine Learning with\n  Graphs", "comments": "Accepted at IJCAI 2021 (survey track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, algorithms and neural architectures based on the\nWeisfeiler-Leman algorithm, a well-known heuristic for the graph isomorphism\nproblem, emerged as a powerful tool for (supervised) machine learning with\ngraphs and relational data. Here, we give a comprehensive overview of the\nalgorithm's use in a machine learning setting. We discuss the theoretical\nbackground, show how to use it for supervised graph- and node classification,\ndiscuss recent extensions, and its connection to neural architectures.\nMoreover, we give an overview of current applications and future directions to\nstimulate research.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 19:05:18 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 05:04:15 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Morris", "Christopher", ""], ["Fey", "Matthias", ""], ["Kriege", "Nils M.", ""]]}, {"id": "2105.05916", "submitter": "Huan Wang", "authors": "Huan Wang, Can Qin, Yue Bai, Yun Fu", "title": "Dynamical Isometry: The Missing Ingredient for Neural Network Pruning", "comments": "8 pages, 2 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recent works [40, 24] observed an interesting phenomenon in neural\nnetwork pruning: A larger finetuning learning rate can improve the final\nperformance significantly. Unfortunately, the reason behind it remains elusive\nup to date. This paper is meant to explain it through the lens of dynamical\nisometry [42]. Specifically, we examine neural network pruning from an unusual\nperspective: pruning as initialization for finetuning, and ask whether the\ninherited weights serve as a good initialization for the finetuning? The\ninsights from dynamical isometry suggest a negative answer. Despite its\ncritical role, this issue has not been well-recognized by the community so far.\nIn this paper, we will show the understanding of this problem is very important\n-- on top of explaining the aforementioned mystery about the larger finetuning\nrate, it also unveils the mystery about the value of pruning [5, 30]. Besides a\nclearer theoretical understanding of pruning, resolving the problem can also\nbring us considerable performance benefits in practice.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 19:20:09 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Wang", "Huan", ""], ["Qin", "Can", ""], ["Bai", "Yue", ""], ["Fu", "Yun", ""]]}, {"id": "2105.05932", "submitter": "Marcus Carpenter", "authors": "Marcus Carpenter, Chunbo Luo, Xiao-Si Wang", "title": "The effects of regularisation on RNN models for time series forecasting:\n  Covid-19 as an example", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Many research papers that propose models to predict the course of the\nCOVID-19 pandemic either use handcrafted statistical models or large neural\nnetworks. Even though large neural networks are more powerful than simpler\nstatistical models, they are especially hard to train on small datasets. This\npaper not only presents a model with grater flexibility than the other proposed\nneural networks, but also presents a model that is effective on smaller\ndatasets. To improve performance on small data, six regularisation methods were\ntested. The results show that the GRU combined with 20% Dropout achieved the\nlowest RMSE scores. The main finding was that models with less access to data\nrelied more on the regulariser. Applying Dropout to a GRU model trained on only\n28 days of data reduced the RMSE by 23%.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 10:50:57 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Carpenter", "Marcus", ""], ["Luo", "Chunbo", ""], ["Wang", "Xiao-Si", ""]]}, {"id": "2105.05977", "submitter": "Alex Kuznetsov", "authors": "Alex Kuznetsov, Hector Urdiales", "title": "Spelling Correction with Denoising Transformer", "comments": "9 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel method of performing spelling correction on short input\nstrings, such as search queries or individual words. At its core lies a\nprocedure for generating artificial typos which closely follow the error\npatterns manifested by humans. This procedure is used to train the production\nspelling correction model based on a transformer architecture. This model is\ncurrently served in the HubSpot product search. We show that our approach to\ntypo generation is superior to the widespread practice of adding noise, which\nignores human patterns. We also demonstrate how our approach may be extended to\nresource-scarce settings and train spelling correction models for Arabic,\nGreek, Russian, and Setswana languages, without using any labeled data.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 21:35:18 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Kuznetsov", "Alex", ""], ["Urdiales", "Hector", ""]]}, {"id": "2105.05983", "submitter": "Lucas Tsutsui Da Silva", "authors": "Lucas Tsutsui da Silva, Vinicius M. A. Souza, Gustavo E. A. P. A.\n  Batista", "title": "An Open-Source Tool for Classification Models in Resource-Constrained\n  Hardware", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications that need to sense, measure, and gather real-time information\nfrom the environment frequently face three main restrictions: power\nconsumption, cost, and lack of infrastructure. Most of the challenges imposed\nby these limitations can be better addressed by embedding Machine Learning (ML)\nclassifiers in the hardware that senses the environment, creating smart sensors\nable to interpret the low-level data stream. However, for this approach to be\ncost-effective, we need highly efficient classifiers suitable to execute in\nunresourceful hardware, such as low-power microcontrollers. In this paper, we\npresent an open-source tool named EmbML - Embedded Machine Learning that\nimplements a pipeline to develop classifiers for resource-constrained hardware.\nWe describe its implementation details and provide a comprehensive analysis of\nits classifiers considering accuracy, classification time, and memory usage.\nMoreover, we compare the performance of its classifiers with classifiers\nproduced by related tools to demonstrate that our tool provides a diverse set\nof classification algorithms that are both compact and accurate. Finally, we\nvalidate EmbML classifiers in a practical application of a smart sensor and\ntrap for disease vector mosquitoes.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 21:51:02 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["da Silva", "Lucas Tsutsui", ""], ["Souza", "Vinicius M. A.", ""], ["Batista", "Gustavo E. A. P. A.", ""]]}, {"id": "2105.05996", "submitter": "Tharindu Ranasinghe Mr", "authors": "Tharindu Ranasinghe, Marcos Zampieri", "title": "Multilingual Offensive Language Identification for Low-resource\n  Languages", "comments": "Accepted to ACM Transactions on Asian and Low-Resource Language\n  Information Processing (TALLIP). This is an extended version of a paper\n  accepted to EMNLP. arXiv admin note: substantial text overlap with\n  arXiv:2010.05324", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Offensive content is pervasive in social media and a reason for concern to\ncompanies and government organizations. Several studies have been recently\npublished investigating methods to detect the various forms of such content\n(e.g. hate speech, cyberbullying, and cyberaggression). The clear majority of\nthese studies deal with English partially because most annotated datasets\navailable contain English data. In this paper, we take advantage of available\nEnglish datasets by applying cross-lingual contextual word embeddings and\ntransfer learning to make predictions in low-resource languages. We project\npredictions on comparable data in Arabic, Bengali, Danish, Greek, Hindi,\nSpanish, and Turkish. We report results of 0.8415 F1 macro for Bengali in\nTRAC-2 shared task, 0.8532 F1 macro for Danish and 0.8701 F1 macro for Greek in\nOffensEval 2020, 0.8568 F1 macro for Hindi in HASOC 2019 shared task and 0.7513\nF1 macro for Spanish in in SemEval-2019 Task 5 (HatEval) showing that our\napproach compares favourably to the best systems submitted to recent shared\ntasks on these three languages. Additionally, we report competitive performance\non Arabic, and Turkish using the training and development sets of OffensEval\n2020 shared task. The results for all languages confirm the robustness of\ncross-lingual contextual embeddings and transfer learning for this task.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 22:50:16 GMT"}, {"version": "v2", "created": "Sat, 15 May 2021 15:39:26 GMT"}, {"version": "v3", "created": "Thu, 20 May 2021 11:20:49 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Ranasinghe", "Tharindu", ""], ["Zampieri", "Marcos", ""]]}, {"id": "2105.06001", "submitter": "Niku Gorji", "authors": "Niku Gorji, Sasha Rubin", "title": "Sufficient reasons for classifier decisions in the presence of\n  constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has unveiled a theory for reasoning about the decisions made by\nbinary classifiers: a classifier describes a Boolean function, and the reasons\nbehind an instance being classified as positive are the prime-implicants of the\nfunction that are satisfied by the instance. One drawback of these works is\nthat they do not explicitly treat scenarios where the underlying data is known\nto be constrained, e.g., certain combinations of features may not exist, may\nnot be observable, or may be required to be disregarded. We propose a more\ngeneral theory, also based on prime-implicants, tailored to taking constraints\ninto account. The main idea is to view classifiers in the presence of\nconstraints as describing partial Boolean functions, i.e., that are undefined\non instances that do not satisfy the constraints. We prove that this simple\nidea results in reasons that are no less (and sometimes more) succinct. That\nis, not taking constraints into account (e.g., ignored, or taken as negative\ninstances) results in reasons that are subsumed by reasons that do take\nconstraints into account. We illustrate this improved parsimony on synthetic\nclassifiers and classifiers learned from real data.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 23:36:12 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Gorji", "Niku", ""], ["Rubin", "Sasha", ""]]}, {"id": "2105.06020", "submitter": "Ruiqi Zhong", "authors": "Ruiqi Zhong, Dhruba Ghosh, Dan Klein, Jacob Steinhardt", "title": "Are Larger Pretrained Language Models Uniformly Better? Comparing\n  Performance at the Instance Level", "comments": "ACL 2021 Findings. Code and data:\n  https://github.com/ruiqi-zhong/acl2021-instance-level", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Larger language models have higher accuracy on average, but are they better\non every single instance (datapoint)? Some work suggests larger models have\nhigher out-of-distribution robustness, while other work suggests they have\nlower accuracy on rare subgroups. To understand these differences, we\ninvestigate these models at the level of individual instances. However, one\nmajor challenge is that individual predictions are highly sensitive to noise in\nthe randomness in training. We develop statistically rigorous methods to\naddress this, and after accounting for pretraining and finetuning noise, we\nfind that our BERT-Large is worse than BERT-Mini on at least 1-4% of instances\nacross MNLI, SST-2, and QQP, compared to the overall accuracy improvement of\n2-10%. We also find that finetuning noise increases with model size and that\ninstance-level accuracy has momentum: improvement from BERT-Mini to BERT-Medium\ncorrelates with improvement from BERT-Medium to BERT-Large. Our findings\nsuggest that instance-level predictions provide a rich source of information;\nwe therefore, recommend that researchers supplement model weights with model\npredictions.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 01:10:51 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Zhong", "Ruiqi", ""], ["Ghosh", "Dhruba", ""], ["Klein", "Dan", ""], ["Steinhardt", "Jacob", ""]]}, {"id": "2105.06029", "submitter": "Ming Yin", "authors": "Ming Yin, Yu-Xiang Wang", "title": "Optimal Uniform OPE and Model-based Offline Reinforcement Learning in\n  Time-Homogeneous, Reward-Free and Task-Agnostic Settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the statistical limits of uniform convergence for offline\npolicy evaluation (OPE) problems with model-based methods (for episodic MDP)\nand provides a unified framework towards optimal learning for several\nwell-motivated offline tasks. Uniform OPE\n$\\sup_\\Pi|Q^\\pi-\\hat{Q}^\\pi|<\\epsilon$ is a stronger measure than the\npoint-wise OPE and ensures offline learning when $\\Pi$ contains all policies\n(the global class). In this paper, we establish an $\\Omega(H^2\nS/d_m\\epsilon^2)$ lower bound (over model-based family) for the global uniform\nOPE and our main result establishes an upper bound of\n$\\tilde{O}(H^2/d_m\\epsilon^2)$ for the \\emph{local} uniform convergence that\napplies to all \\emph{near-empirically optimal} policies for the MDPs with\n\\emph{stationary} transition. Here $d_m$ is the minimal marginal state-action\nprobability. Critically, the highlight in achieving the optimal rate\n$\\tilde{O}(H^2/d_m\\epsilon^2)$ is our design of \\emph{singleton absorbing MDP},\nwhich is a new sharp analysis tool that works with the model-based approach. We\ngeneralize such a model-based framework to the new settings: offline\ntask-agnostic and the offline reward-free with optimal complexity\n$\\tilde{O}(H^2\\log(K)/d_m\\epsilon^2)$ ($K$ is the number of tasks) and\n$\\tilde{O}(H^2S/d_m\\epsilon^2)$ respectively. These results provide a unified\nsolution for simultaneously solving different offline RL problems.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 01:36:34 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 04:32:16 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 07:01:53 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Yin", "Ming", ""], ["Wang", "Yu-Xiang", ""]]}, {"id": "2105.06047", "submitter": "Rahul Duggal", "authors": "Rahul Duggal, Hao Zhou, Shuo Yang, Yuanjun Xiong, Wei Xia, Zhuowen Tu,\n  Stefano Soatto", "title": "Compatibility-aware Heterogeneous Visual Search", "comments": "Accepted at CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of visual search under resource constraints. Existing\nsystems use the same embedding model to compute representations (embeddings)\nfor the query and gallery images. Such systems inherently face a hard\naccuracy-efficiency trade-off: the embedding model needs to be large enough to\nensure high accuracy, yet small enough to enable query-embedding computation on\nresource-constrained platforms. This trade-off could be mitigated if gallery\nembeddings are generated from a large model and query embeddings are extracted\nusing a compact model. The key to building such a system is to ensure\nrepresentation compatibility between the query and gallery models. In this\npaper, we address two forms of compatibility: One enforced by modifying the\nparameters of each model that computes the embeddings. The other by modifying\nthe architectures that compute the embeddings, leading to compatibility-aware\nneural architecture search (CMP-NAS). We test CMP-NAS on challenging retrieval\ntasks for fashion images (DeepFashion2), and face images (IJB-C). Compared to\nordinary (homogeneous) visual search using the largest embedding model\n(paragon), CMP-NAS achieves 80-fold and 23-fold cost reduction while\nmaintaining accuracy within 0.3% and 1.6% of the paragon on DeepFashion2 and\nIJB-C respectively.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 02:30:50 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Duggal", "Rahul", ""], ["Zhou", "Hao", ""], ["Yang", "Shuo", ""], ["Xiong", "Yuanjun", ""], ["Xia", "Wei", ""], ["Tu", "Zhuowen", ""], ["Soatto", "Stefano", ""]]}, {"id": "2105.06071", "submitter": "Dongdong Li", "authors": "Dongdong Li, Zhaochun Ren, Pengjie Ren, Zhumin Chen, Miao Fan, Jun Ma,\n  Maarten de Rijke", "title": "Semi-Supervised Variational Reasoning for Medical Dialogue Generation", "comments": "Accepted by Sigir2021", "journal-ref": null, "doi": "10.1145/3404835.3462921", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Medical dialogue generation aims to provide automatic and accurate responses\nto assist physicians to obtain diagnosis and treatment suggestions in an\nefficient manner. In medical dialogues two key characteristics are relevant for\nresponse generation: patient states (such as symptoms, medication) and\nphysician actions (such as diagnosis, treatments). In medical scenarios\nlarge-scale human annotations are usually not available, due to the high costs\nand privacy requirements. Hence, current approaches to medical dialogue\ngeneration typically do not explicitly account for patient states and physician\nactions, and focus on implicit representation instead. We propose an end-to-end\nvariational reasoning approach to medical dialogue generation. To be able to\ndeal with a limited amount of labeled data, we introduce both patient state and\nphysician action as latent variables with categorical priors for explicit\npatient state tracking and physician policy learning, respectively. We propose\na variational Bayesian generative approach to approximate posterior\ndistributions over patient states and physician actions. We use an efficient\nstochastic gradient variational Bayes estimator to optimize the derived\nevidence lower bound, where a 2-stage collapsed inference method is proposed to\nreduce the bias during model training. A physician policy network composed of\nan action-classifier and two reasoning detectors is proposed for augmented\nreasoning ability. We conduct experiments on three datasets collected from\nmedical platforms. Our experimental results show that the proposed method\noutperforms state-of-the-art baselines in terms of objective and subjective\nevaluation metrics. Our experiments also indicate that our proposed\nsemi-supervised reasoning method achieves a comparable performance as\nstate-of-the-art fully supervised learning baselines for physician policy\nlearning.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 04:14:35 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Li", "Dongdong", ""], ["Ren", "Zhaochun", ""], ["Ren", "Pengjie", ""], ["Chen", "Zhumin", ""], ["Fan", "Miao", ""], ["Ma", "Jun", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2105.06091", "submitter": "Ankit Sonthalia", "authors": "Weng Fei Low, Ankit Sonthalia, Zhi Gao, Andr\\'e van Schaik, Bharath\n  Ramesh", "title": "Superevents: Towards Native Semantic Segmentation for Event-based\n  Cameras", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most successful computer vision models transform low-level features, such as\nGabor filter responses, into richer representations of intermediate or\nmid-level complexity for downstream visual tasks. These mid-level\nrepresentations have not been explored for event cameras, although it is\nespecially relevant to the visually sparse and often disjoint spatial\ninformation in the event stream. By making use of locally consistent\nintermediate representations, termed as superevents, numerous visual tasks\nranging from semantic segmentation, visual tracking, depth estimation shall\nbenefit. In essence, superevents are perceptually consistent local units that\ndelineate parts of an object in a scene. Inspired by recent deep learning\narchitectures, we present a novel method that employs lifetime augmentation for\nobtaining an event stream representation that is fed to a fully convolutional\nnetwork to extract superevents. Our qualitative and quantitative experimental\nresults on several sequences of a benchmark dataset highlights the significant\npotential for event-based downstream applications.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 05:49:41 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Low", "Weng Fei", ""], ["Sonthalia", "Ankit", ""], ["Gao", "Zhi", ""], ["van Schaik", "Andr\u00e9", ""], ["Ramesh", "Bharath", ""]]}, {"id": "2105.06109", "submitter": "Kishor Datta Gupta", "authors": "Kishor Datta Gupta and Dipankar Dasgupta", "title": "Negative Selection Algorithm Research and Applications in the last\n  decade: A Review", "comments": "Dataset and code: https://github.com/kishordgupta/OCC_DATASET and\n  https://github.com/kishordgupta/pyod", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Negative selection Algorithm (NSA) is one of the important methods in the\nfield of Immunological Computation (or Artificial Immune Systems). Over the\nyears, some progress was made which turns this algorithm (NSA) into an\nefficient approach to solve problems in different domain. This review takes\ninto account these signs of progress during the last decade and categorizes\nthose based on different characteristics and performances. Our study shows that\nNSA's evolution can be labeled in four ways highlighting the most notable NSA\nvariations and their limitations in different application domains. We also\npresent alternative approaches to NSA for comparison and analysis. It is\nevident that NSA performs better for nonlinear representation than most of the\nother methods, and it can outperform neural-based models in computation time.\nWe summarize NSA's development and highlight challenges in NSA research in\ncomparison with other similar models.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 06:58:03 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Gupta", "Kishor Datta", ""], ["Dasgupta", "Dipankar", ""]]}, {"id": "2105.06129", "submitter": "Aaditya Singh", "authors": "Aaditya Singh, Shreeshail Hingane, Xinyu Gong, Zhangyang Wang", "title": "SAFIN: Arbitrary Style Transfer With Self-Attentive Factorized Instance\n  Normalization", "comments": "Accepted at ICME 2021, 5 Pages + 1 Page (references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artistic style transfer aims to transfer the style characteristics of one\nimage onto another image while retaining its content. Existing approaches\ncommonly leverage various normalization techniques, although these face\nlimitations in adequately transferring diverse textures to different spatial\nlocations. Self-Attention-based approaches have tackled this issue with partial\nsuccess but suffer from unwanted artifacts. Motivated by these observations,\nthis paper aims to combine the best of both worlds: self-attention and\nnormalization. That yields a new plug-and-play module that we name\nSelf-Attentive Factorized Instance Normalization (SAFIN). SAFIN is essentially\na spatially adaptive normalization module whose parameters are inferred through\nattention on the content and style image. We demonstrate that plugging SAFIN\ninto the base network of another state-of-the-art method results in enhanced\nstylization. We also develop a novel base network composed of Wavelet Transform\nfor multi-scale style transfer, which when combined with SAFIN, produces\nvisually appealing results with lesser unwanted textures.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 08:01:01 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 05:44:54 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Singh", "Aaditya", ""], ["Hingane", "Shreeshail", ""], ["Gong", "Xinyu", ""], ["Wang", "Zhangyang", ""]]}, {"id": "2105.06136", "submitter": "Hui Wang", "authors": "Hui Wang and Mike Preuss and Aske Plaat", "title": "Adaptive Warm-Start MCTS in AlphaZero-like Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  AlphaZero has achieved impressive performance in deep reinforcement learning\nby utilizing an architecture that combines search and training of a neural\nnetwork in self-play. Many researchers are looking for ways to reproduce and\nimprove results for other games/tasks. However, the architecture is designed to\nlearn from scratch, tabula rasa, accepting a cold-start problem in self-play.\nRecently, a warm-start enhancement method for Monte Carlo Tree Search was\nproposed to improve the self-play starting phase. It employs a fixed parameter\n$I^\\prime$ to control the warm-start length. Improved performance was reported\nin small board games. In this paper we present results with an adaptive switch\nmethod. Experiments show that our approach works better than the fixed\n$I^\\prime$, especially for \"deep,\" tactical, games (Othello and Connect Four).\nWe conjecture that the adaptive value for $I^\\prime$ is also influenced by the\nsize of the game, and that on average $I^\\prime$ will increase with game size.\nWe conclude that AlphaZero-like deep reinforcement learning benefits from\nadaptive rollout based warm-start, as Rapid Action Value Estimate did for\nrollout-based reinforcement learning 15 years ago.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 08:24:51 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Wang", "Hui", ""], ["Preuss", "Mike", ""], ["Plaat", "Aske", ""]]}, {"id": "2105.06160", "submitter": "Fang Tao Li", "authors": "Fangtao Li, Ting Bai, Chenyu Cao, Zihe Liu, Chenghao Yan, Bin Wu", "title": "Relation-aware Hierarchical Attention Framework for Video Question\n  Answering", "comments": "9 pages, This paper is accepted by ICMR 2021", "journal-ref": null, "doi": "10.1145/3460426.3463635", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video Question Answering (VideoQA) is a challenging video understanding task\nsince it requires a deep understanding of both question and video. Previous\nstudies mainly focus on extracting sophisticated visual and language\nembeddings, fusing them by delicate hand-crafted networks. However, the\nrelevance of different frames, objects, and modalities to the question are\nvaried along with the time, which is ignored in most of existing methods.\nLacking understanding of the the dynamic relationships and interactions among\nobjects brings a great challenge to VideoQA task. To address this problem, we\npropose a novel Relation-aware Hierarchical Attention (RHA) framework to learn\nboth the static and dynamic relations of the objects in videos. In particular,\nvideos and questions are embedded by pre-trained models firstly to obtain the\nvisual and textual features. Then a graph-based relation encoder is utilized to\nextract the static relationship between visual objects. To capture the dynamic\nchanges of multimodal objects in different video frames, we consider the\ntemporal, spatial, and semantic relations, and fuse the multimodal features by\nhierarchical attention mechanism to predict the answer. We conduct extensive\nexperiments on a large scale VideoQA dataset, and the experimental results\ndemonstrate that our RHA outperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 09:35:42 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 02:34:56 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Li", "Fangtao", ""], ["Bai", "Ting", ""], ["Cao", "Chenyu", ""], ["Liu", "Zihe", ""], ["Yan", "Chenghao", ""], ["Wu", "Bin", ""]]}, {"id": "2105.06188", "submitter": "Xiaofei Li", "authors": "Xiaofei Li, Zhong Dong", "title": "SizeNet: Object Recognition via Object Real Size-based Convolutional\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the conclusion that humans choose the visual cortex regions\ncorresponding to the real size of an object to analyze its features when\nidentifying objects in the real world, this paper presents a framework,\nSizeNet, which is based on both the real sizes and features of objects to solve\nobject recognition problems. SizeNet was used for object recognition\nexperiments on the homemade Rsize dataset, and was compared with the\nstate-of-the-art methods AlexNet, VGG-16, Inception V3, Resnet-18, and\nDenseNet-121. The results showed that SizeNet provides much higher accuracy\nrates for object recognition than the other algorithms. SizeNet can solve the\ntwo problems of correctly recognizing objects with highly similar features but\nreal sizes that are obviously different from each other, and correctly\ndistinguishing a target object from interference objects whose real sizes are\nobviously different from the target object. This is because SizeNet recognizes\nobjects based not only on their features, but also on their real size. The real\nsize of an object can help exclude the interference object's categories whose\nreal size ranges do not match the real size of the object, which greatly\nreduces the object's categories' number in the label set used for the\ndownstream object recognition based on object features. SizeNet is of great\nsignificance for studying the interpretable computer vision. Our code and\ndataset will thus be made public.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 11:03:24 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 02:32:13 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Li", "Xiaofei", ""], ["Dong", "Zhong", ""]]}, {"id": "2105.06194", "submitter": "Vincenzo Ciancia", "authors": "Nick Bezhanishvili and Vincenzo Ciancia and David Gabelaia and\n  Gianluca Grilletti and Diego Latella and Mieke Massink", "title": "Geometric Model Checking of Continuous Space", "comments": "26 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.CV cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological Spatial Model Checking is a recent paradigm that combines Model\nChecking with the topological interpretation of Modal Logic. The Spatial Logic\nof Closure Spaces, SLCS, extends Modal Logic with reachability connectives\nthat, in turn, can be used for expressing interesting spatial properties, such\nas \"being near to\" or \"being surrounded by\". SLCS constitutes the kernel of a\nsolid logical framework for reasoning about discrete space, such as graphs and\ndigital images, interpreted as quasi discrete closure spaces. In particular,\nthe spatial model checker VoxLogicA, that uses an extended version of SLCS, has\nbeen used successfully in the domain of medical imaging. However, SLCS is not\nrestricted to discrete space. Following a recently developed geometric\nsemantics of Modal Logic, we show that it is possible to assign an\ninterpretation to SLCS in continuous space, admitting a model checking\nprocedure, by resorting to models based on polyhedra. In medical imaging such\nrepresentations of space are increasingly relevant, due to recent developments\nof 3D scanning and visualisation techniques that exploit mesh processing. We\ndemonstrate feasibility of our approach via a new tool, PolyLogicA, aimed at\nefficient verification of SLCS formulas on polyhedra, while inheriting some\nwell-established optimization techniques already adopted in VoxLogicA. Finally,\nwe cater for a geometric definition of bisimilarity, proving that it\ncharacterises logical equivalence.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 11:25:25 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Bezhanishvili", "Nick", ""], ["Ciancia", "Vincenzo", ""], ["Gabelaia", "David", ""], ["Grilletti", "Gianluca", ""], ["Latella", "Diego", ""], ["Massink", "Mieke", ""]]}, {"id": "2105.06209", "submitter": "Yingzhe He", "authors": "Yingzhe He, Guozhu Meng, Kai Chen, Jinwen He, Xingbo Hu", "title": "DeepObliviate: A Powerful Charm for Erasing Data Residual Memory in Deep\n  Neural Networks", "comments": "16 pages, 10 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine unlearning has great significance in guaranteeing model security and\nprotecting user privacy. Additionally, many legal provisions clearly stipulate\nthat users have the right to demand model providers to delete their own data\nfrom training set, that is, the right to be forgotten. The naive way of\nunlearning data is to retrain the model without it from scratch, which becomes\nextremely time and resource consuming at the modern scale of deep neural\nnetworks. Other unlearning approaches by refactoring model or training data\nstruggle to gain a balance between overhead and model usability.\n  In this paper, we propose an approach, dubbed as DeepObliviate, to implement\nmachine unlearning efficiently, without modifying the normal training mode. Our\napproach improves the original training process by storing intermediate models\non the hard disk. Given a data point to unlearn, we first quantify its temporal\nresidual memory left in stored models. The influenced models will be retrained\nand we decide when to terminate the retraining based on the trend of residual\nmemory on-the-fly. Last, we stitch an unlearned model by combining the\nretrained models and uninfluenced models. We extensively evaluate our approach\non five datasets and deep learning models. Compared to the method of retraining\nfrom scratch, our approach can achieve 99.0%, 95.0%, 91.9%, 96.7%, 74.1%\naccuracy rates and 66.7$\\times$, 75.0$\\times$, 33.3$\\times$, 29.4$\\times$,\n13.7$\\times$ speedups on the MNIST, SVHN, CIFAR-10, Purchase, and ImageNet\ndatasets, respectively. Compared to the state-of-the-art unlearning approach,\nwe improve 5.8% accuracy, 32.5$\\times$ prediction speedup, and reach a\ncomparable retrain speedup under identical settings on average on these\ndatasets. Additionally, DeepObliviate can also pass the backdoor-based\nunlearning verification.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 12:02:04 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["He", "Yingzhe", ""], ["Meng", "Guozhu", ""], ["Chen", "Kai", ""], ["He", "Jinwen", ""], ["Hu", "Xingbo", ""]]}, {"id": "2105.06228", "submitter": "Zhiwei Xu", "authors": "Zhiwei Xu, Yunpeng Bai, Dapeng Li, Bin Zhang, Guoliang Fan", "title": "SIDE: I Infer the State I Want to Learn", "comments": "8 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As one of the solutions to the Dec-POMDP problem, the value decomposition\nmethod has achieved good results recently. However, most value decomposition\nmethods require the global state during training, but this is not feasible in\nsome scenarios where the global state cannot be obtained. Therefore, we propose\na novel value decomposition framework, named State Inference for value\nDEcomposition (SIDE), which eliminates the need to know the true state by\nsimultaneously seeking solutions to the two problems of optimal control and\nstate inference. SIDE can be extended to any value decomposition method, as\nwell as other types of multi-agent algorithms in the case of Dec-POMDP. Based\non the performance results of different algorithms in Starcraft II\nmicromanagement tasks, we verified that SIDE can construct the current state\nthat contributes to the reinforcement learning process based on past local\nobservations.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 12:26:02 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Xu", "Zhiwei", ""], ["Bai", "Yunpeng", ""], ["Li", "Dapeng", ""], ["Zhang", "Bin", ""], ["Fan", "Guoliang", ""]]}, {"id": "2105.06232", "submitter": "Yan Xu", "authors": "Yan Xu, Etsuko Ishii, Zihan Liu, Genta Indra Winata, Dan Su, Andrea\n  Madotto, Pascale Fung", "title": "Retrieval-Free Knowledge-Grounded Dialogue Response Generation with\n  Adapters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  To diversify and enrich generated dialogue responses, knowledge-grounded\ndialogue has been investigated in recent years. Despite the success of the\nexisting methods, they mainly follow the paradigm of retrieving the relevant\nsentences over a large corpus and augment the dialogues with explicit extra\ninformation, which is time- and resource-consuming. In this paper, we propose\nKnowExpert, an end-to-end framework to bypass the retrieval process by\ninjecting prior knowledge into the pre-trained language models with lightweight\nadapters. To the best of our knowledge, this is the first attempt to tackle\nthis task relying solely on a generation-based approach. Experimental results\nshow that KnowExpert performs comparably with the retrieval-based baselines,\ndemonstrating the potential of our proposed direction.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 12:33:23 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Xu", "Yan", ""], ["Ishii", "Etsuko", ""], ["Liu", "Zihan", ""], ["Winata", "Genta Indra", ""], ["Su", "Dan", ""], ["Madotto", "Andrea", ""], ["Fung", "Pascale", ""]]}, {"id": "2105.06251", "submitter": "Eike Stadtl\\\"ander", "authors": "Eike Stadtl\\\"ander, Tam\\'as Horv\\'ath, Stefan Wrobel", "title": "Learning Weakly Convex Sets in Metric Spaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the notion of weak convexity in metric spaces, a generalization\nof ordinary convexity commonly used in machine learning. It is shown that\nweakly convex sets can be characterized by a closure operator and have a unique\ndecomposition into a set of pairwise disjoint connected blocks. We give two\ngeneric efficient algorithms, an extensional and an intensional one for\nlearning weakly convex concepts and study their formal properties. Our\nexperimental results concerning vertex classification clearly demonstrate the\nexcellent predictive performance of the extensional algorithm. Two non-trivial\napplications of the intensional algorithm to polynomial PAC-learnability are\npresented. The first one deals with learning $k$-convex Boolean functions,\nwhich are already known to be efficiently PAC-learnable. It is shown how to\nderive this positive result in a fairly easy way by the generic intensional\nalgorithm. The second one is concerned with the Euclidean space equipped with\nthe Manhattan distance. For this metric space, weakly convex sets are a union\nof pairwise disjoint axis-aligned hyperrectangles. We show that a weakly convex\nset that is consistent with a set of examples and contains a minimum number of\nhyperrectangles can be found in polynomial time. In contrast, this problem is\nknown to be NP-complete if the hyperrectangles may be overlapping.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 23:00:02 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Stadtl\u00e4nder", "Eike", ""], ["Horv\u00e1th", "Tam\u00e1s", ""], ["Wrobel", "Stefan", ""]]}, {"id": "2105.06253", "submitter": "Khin Chit", "authors": "Khin Me Me Chit, Laet Laet Lin", "title": "Exploring CTC Based End-to-End Techniques for Myanmar Speech Recognition", "comments": "This is a preprint of the chapter: Chit K.M.M., Lin L.L., Exploring\n  CTC Based End-To-End Techniques for Myanmar Speech Recognition, published in\n  Advances in Intelligent Systems and Computing, vol 1324, edited by Vasant P.,\n  Zelinka I., Weber GW., 2021, Springer, Cham reproduced with permission of\n  Springer. The final authenticated version is available at\n  https://doi.org/10.1007/978-3-030-68154-8_87", "journal-ref": "Advances in Intelligent Systems and Computing, vol 1324. Springer,\n  Cham (2021)", "doi": "10.1007/978-3-030-68154-8_87", "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explore a Connectionist Temporal Classification (CTC) based\nend-to-end Automatic Speech Recognition (ASR) model for the Myanmar language. A\nseries of experiments is presented on the topology of the model in which the\nconvolutional layers are added and dropped, different depths of bidirectional\nlong short-term memory (BLSTM) layers are used and different label encoding\nmethods are investigated. The experiments are carried out in low-resource\nscenarios using our recorded Myanmar speech corpus of nearly 26 hours. The best\nmodel achieves character error rate (CER) of 4.72% and syllable error rate\n(SER) of 12.38% on the test set.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 12:58:51 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 05:29:56 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Chit", "Khin Me Me", ""], ["Lin", "Laet Laet", ""]]}, {"id": "2105.06255", "submitter": "Anupam Khan", "authors": "Anupam Khan, Soumya K. Ghosh", "title": "Machine Assistance for Credit Card Approval? Random Wheel can Recommend\n  and Explain", "comments": "14 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Approval of credit card application is one of the censorious business\ndecision the bankers are usually taking regularly. The growing number of new\ncard applications and the enormous outstanding amount of credit card bills\nduring the recent pandemic make this even more challenging nowadays. Some of\nthe previous studies suggest the usage of machine intelligence for automating\nthe approval process to mitigate this challenge. However, the effectiveness of\nsuch automation may depend on the richness of the training dataset and model\nefficiency. We have recently developed a novel classifier named random wheel\nwhich provides a more interpretable output. In this work, we have used an\nenhanced version of random wheel to facilitate a trustworthy recommendation for\ncredit card approval process. It not only produces more accurate and precise\nrecommendation but also provides an interpretable confidence measure. Besides,\nit explains the machine recommendation for each credit card application as\nwell. The availability of recommendation confidence and explanation could bring\nmore trust in the machine provided intelligence which in turn can enhance the\nefficiency of the credit card approval process.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 08:41:42 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Khan", "Anupam", ""], ["Ghosh", "Soumya K.", ""]]}, {"id": "2105.06266", "submitter": "Yuhao Zhou", "authors": "Yuhao Zhou, Xihua Li, Yunbo Cao, Xuemin Zhao, Qing Ye and Jiancheng Lv", "title": "LANA: Towards Personalized Deep Knowledge Tracing Through\n  Distinguishable Interactive Sequences", "comments": "EDM2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In educational applications, Knowledge Tracing (KT), the problem of\naccurately predicting students' responses to future questions by summarizing\ntheir knowledge states, has been widely studied for decades as it is considered\na fundamental task towards adaptive online learning. Among all the proposed KT\nmethods, Deep Knowledge Tracing (DKT) and its variants are by far the most\neffective ones due to the high flexibility of the neural network. However, DKT\noften ignores the inherent differences between students (e.g. memory skills,\nreasoning skills, ...), averaging the performances of all students, leading to\nthe lack of personalization, and therefore was considered insufficient for\nadaptive learning. To alleviate this problem, in this paper, we proposed\nLeveled Attentive KNowledge TrAcing (LANA), which firstly uses a novel\nstudent-related features extractor (SRFE) to distill students' unique inherent\nproperties from their respective interactive sequences. Secondly, the pivot\nmodule was utilized to dynamically reconstruct the decoder of the neural\nnetwork on attention of the extracted features, successfully distinguishing the\nperformance between students over time. Moreover, inspired by Item Response\nTheory (IRT), the interpretable Rasch model was used to cluster students by\ntheir ability levels, and thereby utilizing leveled learning to assign\ndifferent encoders to different groups of students. With pivot module\nreconstructed the decoder for individual students and leveled learning\nspecialized encoders for groups, personalized DKT was achieved. Extensive\nexperiments conducted on two real-world large-scale datasets demonstrated that\nour proposed LANA improves the AUC score by at least 1.00% (i.e. EdNet 1.46%\nand RAIEd2020 1.00%), substantially surpassing the other State-Of-The-Art KT\nmethods.\n", "versions": [{"version": "v1", "created": "Wed, 21 Apr 2021 02:57:42 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Zhou", "Yuhao", ""], ["Li", "Xihua", ""], ["Cao", "Yunbo", ""], ["Zhao", "Xuemin", ""], ["Ye", "Qing", ""], ["Lv", "Jiancheng", ""]]}, {"id": "2105.06268", "submitter": "Michael Cohen", "authors": "Michael K. Cohen, Badri Vellambi, Marcus Hutter", "title": "Intelligence and Unambitiousness Using Algorithmic Information Theory", "comments": "13 pages, 6 figures, 5-page appendix. arXiv admin note: text overlap\n  with arXiv:1905.12186", "journal-ref": "Journal of Selected Areas in Information Theory 2 (2021)", "doi": "10.1109/JSAIT.2021.3073844", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Algorithmic Information Theory has inspired intractable constructions of\ngeneral intelligence (AGI), and undiscovered tractable approximations are\nlikely feasible. Reinforcement Learning (RL), the dominant paradigm by which an\nagent might learn to solve arbitrary solvable problems, gives an agent a\ndangerous incentive: to gain arbitrary \"power\" in order to intervene in the\nprovision of their own reward. We review the arguments that generally\nintelligent algorithmic-information-theoretic reinforcement learners such as\nHutter's (2005) AIXI would seek arbitrary power, including over us. Then, using\nan information-theoretic exploration schedule, and a setup inspired by causal\ninfluence theory, we present a variant of AIXI which learns to not seek\narbitrary power; we call it \"unambitious\". We show that our agent learns to\naccrue reward at least as well as a human mentor, while relying on that mentor\nwith diminishing probability. And given a formal assumption that we probe\nempirically, we show that eventually, the agent's world-model incorporates the\nfollowing true fact: intervening in the \"outside world\" will have no effect on\nreward acquisition; hence, it has no incentive to shape the outside world.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 13:10:28 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Cohen", "Michael K.", ""], ["Vellambi", "Badri", ""], ["Hutter", "Marcus", ""]]}, {"id": "2105.06300", "submitter": "Xiaoyu Zhang", "authors": "Xiaoyu Zhang, Chao Chen, Yi Xie, Xiaofeng Chen, Jun Zhang, Yang Xiang", "title": "Privacy Inference Attacks and Defenses in Cloud-based Deep Neural\n  Network: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Neural Network (DNN), one of the most powerful machine learning\nalgorithms, is increasingly leveraged to overcome the bottleneck of effectively\nexploring and analyzing massive data to boost advanced scientific development.\nIt is not a surprise that cloud computing providers offer the cloud-based DNN\nas an out-of-the-box service. Though there are some benefits from the\ncloud-based DNN, the interaction mechanism among two or multiple entities in\nthe cloud inevitably induces new privacy risks. This survey presents the most\nrecent findings of privacy attacks and defenses appeared in cloud-based neural\nnetwork services. We systematically and thoroughly review privacy attacks and\ndefenses in the pipeline of cloud-based DNN service, i.e., data manipulation,\ntraining, and prediction. In particular, a new theory, called cloud-based ML\nprivacy game, is extracted from the recently published literature to provide a\ndeep understanding of state-of-the-art research. Finally, the challenges and\nfuture work are presented to help researchers to continue to push forward the\ncompetitions between privacy attackers and defenders.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 13:45:28 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Zhang", "Xiaoyu", ""], ["Chen", "Chao", ""], ["Xie", "Yi", ""], ["Chen", "Xiaofeng", ""], ["Zhang", "Jun", ""], ["Xiang", "Yang", ""]]}, {"id": "2105.06314", "submitter": "Ismini Psychoula", "authors": "Ismini Psychoula, Andreas Gutmann, Pradip Mainali, S. H. Lee, Paul\n  Dunphy, Fabien A. P. Petitcolas", "title": "Explainable Machine Learning for Fraud Detection", "comments": "To be published in IEEE Computer Special Issue on Explainable AI and\n  Machine Learning, 12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The application of machine learning to support the processing of large\ndatasets holds promise in many industries, including financial services.\nHowever, practical issues for the full adoption of machine learning remain with\nthe focus being on understanding and being able to explain the decisions and\npredictions made by complex models. In this paper, we explore explainability\nmethods in the domain of real-time fraud detection by investigating the\nselection of appropriate background datasets and runtime trade-offs on both\nsupervised and unsupervised models.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 14:12:02 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Psychoula", "Ismini", ""], ["Gutmann", "Andreas", ""], ["Mainali", "Pradip", ""], ["Lee", "S. H.", ""], ["Dunphy", "Paul", ""], ["Petitcolas", "Fabien A. P.", ""]]}, {"id": "2105.06339", "submitter": "Shoujin Wang", "authors": "Shoujin Wang, Liang Hu, Yan Wang, Xiangnan He, Quan Z. Sheng, Mehmet\n  A. Orgun, Longbing Cao, Francesco Ricci, Philip S. Yu", "title": "Graph Learning based Recommender Systems: A Review", "comments": "Accepted by IJCAI 2021 Survey Track, copyright is owned to IJCAI. The\n  first systematic survey on graph learning based recommender systems. arXiv\n  admin note: text overlap with arXiv:2004.11718", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have witnessed the fast development of the emerging topic of\nGraph Learning based Recommender Systems (GLRS). GLRS employ advanced graph\nlearning approaches to model users' preferences and intentions as well as\nitems' characteristics for recommendations. Differently from other RS\napproaches, including content-based filtering and collaborative filtering, GLRS\nare built on graphs where the important objects, e.g., users, items, and\nattributes, are either explicitly or implicitly connected. With the rapid\ndevelopment of graph learning techniques, exploring and exploiting homogeneous\nor heterogeneous relations in graphs are a promising direction for building\nmore effective RS. In this paper, we provide a systematic review of GLRS, by\ndiscussing how they extract important knowledge from graph-based\nrepresentations to improve the accuracy, reliability and explainability of the\nrecommendations. First, we characterize and formalize GLRS, and then summarize\nand categorize the key challenges and main progress in this novel research\narea. Finally, we share some new research directions in this vibrant area.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 14:50:45 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Wang", "Shoujin", ""], ["Hu", "Liang", ""], ["Wang", "Yan", ""], ["He", "Xiangnan", ""], ["Sheng", "Quan Z.", ""], ["Orgun", "Mehmet A.", ""], ["Cao", "Longbing", ""], ["Ricci", "Francesco", ""], ["Yu", "Philip S.", ""]]}, {"id": "2105.06350", "submitter": "Menghui Zhu", "authors": "Menghui Zhu, Minghuan Liu, Jian Shen, Zhicheng Zhang, Sheng Chen,\n  Weinan Zhang, Deheng Ye, Yong Yu, Qiang Fu, Wei Yang", "title": "MapGo: Model-Assisted Policy Optimization for Goal-Oriented Tasks", "comments": "Paper accepted at IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Goal-oriented Reinforcement learning, relabeling the raw goals in past\nexperience to provide agents with hindsight ability is a major solution to the\nreward sparsity problem. In this paper, to enhance the diversity of relabeled\ngoals, we develop FGI (Foresight Goal Inference), a new relabeling strategy\nthat relabels the goals by looking into the future with a learned dynamics\nmodel. Besides, to improve sample efficiency, we propose to use the dynamics\nmodel to generate simulated trajectories for policy training. By integrating\nthese two improvements, we introduce the MapGo framework (Model-Assisted Policy\nOptimization for Goal-oriented tasks). In our experiments, we first show the\neffectiveness of the FGI strategy compared with the hindsight one, and then\nshow that the MapGo framework achieves higher sample efficiency when compared\nto model-free baselines on a set of complicated tasks.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 15:07:23 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Zhu", "Menghui", ""], ["Liu", "Minghuan", ""], ["Shen", "Jian", ""], ["Zhang", "Zhicheng", ""], ["Chen", "Sheng", ""], ["Zhang", "Weinan", ""], ["Ye", "Deheng", ""], ["Yu", "Yong", ""], ["Fu", "Qiang", ""], ["Yang", "Wei", ""]]}, {"id": "2105.06381", "submitter": "Yongxin Liu", "authors": "Yongxin Liu, Jian Wang, Jianqiang Li, Shuteng Niu, Houbing Song", "title": "Class-Incremental Learning for Wireless Device Identification in IoT", "comments": "Accepted for publication by IEEE Internet of Things Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep Learning (DL) has been utilized pervasively in the Internet of Things\n(IoT). One typical application of DL in IoT is device identification from\nwireless signals, namely Non-cryptographic Device Identification (NDI).\nHowever, learning components in NDI systems have to evolve to adapt to\noperational variations, such a paradigm is termed as Incremental Learning (IL).\nVarious IL algorithms have been proposed and many of them require dedicated\nspace to store the increasing amount of historical data, and therefore, they\nare not suitable for IoT or mobile applications. However, conventional IL\nschemes can not provide satisfying performance when historical data are not\navailable. In this paper, we address the IL problem in NDI from a new\nperspective, firstly, we provide a new metric to measure the degree of\ntopological maturity of DNN models from the degree of conflict of\nclass-specific fingerprints. We discover that an important cause for\nperformance degradation in IL enabled NDI is owing to the conflict of devices'\nfingerprints. Second, we also show that the conventional IL schemes can lead to\nlow topological maturity of DNN models in NDI systems. Thirdly, we propose a\nnew Channel Separation Enabled Incremental Learning (CSIL) scheme without using\nhistorical data, in which our strategy can automatically separate devices'\nfingerprints in different learning stages and avoid potential conflict.\nFinally, We evaluated the effectiveness of the proposed framework using real\ndata from ADS-B (Automatic Dependent Surveillance-Broadcast), an application of\nIoT in aviation. The proposed framework has the potential to be applied to\naccurate identification of IoT devices in a variety of IoT applications and\nservices. Data and code available at IEEE Dataport (DOI: 10.21227/1bxc-ke87)\nand \\url{https://github.com/pcwhy/CSIL}}\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 09:11:07 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Liu", "Yongxin", ""], ["Wang", "Jian", ""], ["Li", "Jianqiang", ""], ["Niu", "Shuteng", ""], ["Song", "Houbing", ""]]}, {"id": "2105.06407", "submitter": "Robin Kips", "authors": "Robin Kips, Ruowei Jiang, Sileye Ba, Edmund Phung, Parham Aarabi,\n  Pietro Gori, Matthieu Perrot, Isabelle Bloch", "title": "Deep Graphics Encoder for Real-Time Video Makeup Synthesis from Example", "comments": "CVPR 2021 Workshop AI for Content Creation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  While makeup virtual-try-on is now widespread, parametrizing a computer\ngraphics rendering engine for synthesizing images of a given cosmetics product\nremains a challenging task. In this paper, we introduce an inverse computer\ngraphics method for automatic makeup synthesis from a reference image, by\nlearning a model that maps an example portrait image with makeup to the space\nof rendering parameters. This method can be used by artists to automatically\ncreate realistic virtual cosmetics image samples, or by consumers, to virtually\ntry-on a makeup extracted from their favorite reference image.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 08:28:32 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Kips", "Robin", ""], ["Jiang", "Ruowei", ""], ["Ba", "Sileye", ""], ["Phung", "Edmund", ""], ["Aarabi", "Parham", ""], ["Gori", "Pietro", ""], ["Perrot", "Matthieu", ""], ["Bloch", "Isabelle", ""]]}, {"id": "2105.06421", "submitter": "Mahdi Pourmirzaei", "authors": "Mahdi Pourmirzaei, Farzaneh Esmaili, Gholam Ali Montazer", "title": "Using Self-Supervised Co-Training to Improve Facial Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, at first, the impact of ImageNet pre-training on Facial\nExpression Recognition (FER) was tested under different augmentation levels. It\ncould be seen from the results that training from scratch could reach better\nperformance compared to ImageNet fine-tuning at stronger augmentation levels.\nAfter that, a framework was proposed for standard Supervised Learning (SL),\ncalled Hybrid Learning (HL) which used Self-Supervised co-training with SL in\nMulti-Task Learning (MTL) manner. Leveraging Self-Supervised Learning (SSL)\ncould gain additional information from input data like spatial information from\nfaces which helped the main SL task. It is been investigated how this method\ncould be used for FER problems with self-supervised pre-tasks such as Jigsaw\npuzzling and in-painting. The supervised head (SH) was helped by these two\nmethods to lower the error rate under different augmentations and low data\nregime in the same training settings. The state-of-the-art was reached on\nAffectNet via two completely different HL methods, without utilizing additional\ndatasets. Moreover, HL's effect was shown on two different facial-related\nproblem, head poses estimation and gender recognition, which concluded to\nreduce in error rate by up to 9% and 1% respectively. Also, we saw that the HL\nmethods prevented the model from reaching overfitting.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 16:56:36 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Pourmirzaei", "Mahdi", ""], ["Esmaili", "Farzaneh", ""], ["Montazer", "Gholam Ali", ""]]}, {"id": "2105.06423", "submitter": "Wenqi Shao", "authors": "Wenqi Shao, Hang Yu, Zhaoyang Zhang, Hang Xu, Zhenguo Li, Ping Luo", "title": "BWCP: Probabilistic Learning-to-Prune Channels for ConvNets via Batch\n  Whitening", "comments": "19 pages, 7 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a probabilistic channel pruning method to accelerate\nConvolutional Neural Networks (CNNs). Previous pruning methods often zero out\nunimportant channels in training in a deterministic manner, which reduces CNN's\nlearning capacity and results in suboptimal performance. To address this\nproblem, we develop a probability-based pruning algorithm, called batch\nwhitening channel pruning (BWCP), which can stochastically discard unimportant\nchannels by modeling the probability of a channel being activated. BWCP has\nseveral merits. (1) It simultaneously trains and prunes CNNs from scratch in a\nprobabilistic way, exploring larger network space than deterministic methods.\n(2) BWCP is empowered by the proposed batch whitening tool, which is able to\nempirically and theoretically increase the activation probability of useful\nchannels while keeping unimportant channels unchanged without adding any extra\nparameters and computational cost in inference. (3) Extensive experiments on\nCIFAR-10, CIFAR-100, and ImageNet with various network architectures show that\nBWCP outperforms its counterparts by achieving better accuracy given limited\ncomputational budgets. For example, ResNet50 pruned by BWCP has only 0.70\\%\nTop-1 accuracy drop on ImageNet, while reducing 43.1\\% FLOPs of the plain\nResNet50.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 17:00:05 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Shao", "Wenqi", ""], ["Yu", "Hang", ""], ["Zhang", "Zhaoyang", ""], ["Xu", "Hang", ""], ["Li", "Zhenguo", ""], ["Luo", "Ping", ""]]}, {"id": "2105.06441", "submitter": "Mona Zehni", "authors": "Safa Messaoud, Ismini Lourentzou, Assma Boughoula, Mona Zehni, Zhizhen\n  Zhao, Chengxiang Zhai, Alexander G. Schwing", "title": "DeepQAMVS: Query-Aware Hierarchical Pointer Networks for Multi-Video\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent growth of web video sharing platforms has increased the demand for\nsystems that can efficiently browse, retrieve and summarize video content.\nQuery-aware multi-video summarization is a promising technique that caters to\nthis demand. In this work, we introduce a novel Query-Aware Hierarchical\nPointer Network for Multi-Video Summarization, termed DeepQAMVS, that jointly\noptimizes multiple criteria: (1) conciseness, (2) representativeness of\nimportant query-relevant events and (3) chronological soundness. We design a\nhierarchical attention model that factorizes over three distributions, each\ncollecting evidence from a different modality, followed by a pointer network\nthat selects frames to include in the summary. DeepQAMVS is trained with\nreinforcement learning, incorporating rewards that capture representativeness,\ndiversity, query-adaptability and temporal coherence. We achieve\nstate-of-the-art results on the MVS1K dataset, with inference time scaling\nlinearly with the number of input video frames.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 17:33:26 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Messaoud", "Safa", ""], ["Lourentzou", "Ismini", ""], ["Boughoula", "Assma", ""], ["Zehni", "Mona", ""], ["Zhao", "Zhizhen", ""], ["Zhai", "Chengxiang", ""], ["Schwing", "Alexander G.", ""]]}, {"id": "2105.06453", "submitter": "Chen Sun", "authors": "Alexander Pashevich and Cordelia Schmid and Chen Sun", "title": "Episodic Transformer for Vision-and-Language Navigation", "comments": "Code available at https://github.com/alexpashevich/E.T.; 19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interaction and navigation defined by natural language instructions in\ndynamic environments pose significant challenges for neural agents. This paper\nfocuses on addressing two challenges: handling long sequence of subtasks, and\nunderstanding complex human instructions. We propose Episodic Transformer\n(E.T.), a multimodal transformer that encodes language inputs and the full\nepisode history of visual observations and actions. To improve training, we\nleverage synthetic instructions as an intermediate representation that\ndecouples understanding the visual appearance of an environment from the\nvariations of natural language instructions. We demonstrate that encoding the\nhistory with a transformer is critical to solve compositional tasks, and that\npretraining and joint training with synthetic instructions further improve the\nperformance. Our approach sets a new state of the art on the challenging ALFRED\nbenchmark, achieving 38.4% and 8.5% task success rates on seen and unseen test\nsplits.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 17:51:46 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Pashevich", "Alexander", ""], ["Schmid", "Cordelia", ""], ["Sun", "Chen", ""]]}, {"id": "2105.06461", "submitter": "Zhongzheng Ren", "authors": "Zhongzheng Ren, Ishan Misra, Alexander G. Schwing, and Rohit Girdhar", "title": "3D Spatial Recognition without Spatially Labeled 3D", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce WyPR, a Weakly-supervised framework for Point cloud Recognition,\nrequiring only scene-level class tags as supervision. WyPR jointly addresses\nthree core 3D recognition tasks: point-level semantic segmentation, 3D proposal\ngeneration, and 3D object detection, coupling their predictions through self\nand cross-task consistency losses. We show that in conjunction with standard\nmultiple-instance learning objectives, WyPR can detect and segment objects in\npoint cloud data without access to any spatial labels at training time. We\ndemonstrate its efficacy using the ScanNet and S3DIS datasets, outperforming\nprior state of the art on weakly-supervised segmentation by more than 6% mIoU.\nIn addition, we set up the first benchmark for weakly-supervised 3D object\ndetection on both datasets, where WyPR outperforms standard approaches and\nestablishes strong baselines for future work.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 17:58:07 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Ren", "Zhongzheng", ""], ["Misra", "Ishan", ""], ["Schwing", "Alexander G.", ""], ["Girdhar", "Rohit", ""]]}, {"id": "2105.06479", "submitter": "Eliu Huerta", "authors": "E. A. Huerta and Zhizhen Zhao", "title": "Advances in Machine and Deep Learning for Modeling and Real-time\n  Detection of Multi-Messenger Sources", "comments": "30 pages, 11 figures. Invited chapter to be published in \"Handbook of\n  Gravitational Wave Astronomy\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.HE cs.AI cs.LG gr-qc", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We live in momentous times. The science community is empowered with an\narsenal of cosmic messengers to study the Universe in unprecedented detail.\nGravitational waves, electromagnetic waves, neutrinos and cosmic rays cover a\nwide range of wavelengths and time scales. Combining and processing these\ndatasets that vary in volume, speed and dimensionality requires new modes of\ninstrument coordination, funding and international collaboration with a\nspecialized human and technological infrastructure. In tandem with the advent\nof large-scale scientific facilities, the last decade has experienced an\nunprecedented transformation in computing and signal processing algorithms. The\ncombination of graphics processing units, deep learning, and the availability\nof open source, high-quality datasets, have powered the rise of artificial\nintelligence. This digital revolution now powers a multi-billion dollar\nindustry, with far-reaching implications in technology and society. In this\nchapter we describe pioneering efforts to adapt artificial intelligence\nalgorithms to address computational grand challenges in Multi-Messenger\nAstrophysics. We review the rapid evolution of these disruptive algorithms,\nfrom the first class of algorithms introduced in early 2017, to the\nsophisticated algorithms that now incorporate domain expertise in their\narchitectural design and optimization schemes. We discuss the importance of\nscientific visualization and extreme-scale computing in reducing\ntime-to-insight and obtaining new knowledge from the interplay between models\nand data.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 18:00:02 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Huerta", "E. A.", ""], ["Zhao", "Zhizhen", ""]]}, {"id": "2105.06496", "submitter": "Matt Groh", "authors": "Matthew Groh, Ziv Epstein, Chaz Firestone, Rosalind Picard", "title": "Comparing Human and Machine Deepfake Detection with Affective and\n  Holistic Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The recent emergence of deepfake videos leads to an important societal\nquestion: how can we know if a video that we watch is real or fake? In three\nonline studies with 15,016 participants, we present authentic videos and\ndeepfakes and ask participants to identify which is which. We compare the\nperformance of ordinary participants against the leading computer vision\ndeepfake detection model and find them similarly accurate while making\ndifferent kinds of mistakes. Together, participants with access to the model's\nprediction are more accurate than either alone, but inaccurate model\npredictions often decrease participants' accuracy. We embed randomized\nexperiments and find: incidental anger decreases participants' performance and\nobstructing holistic visual processing of faces also hinders participants'\nperformance while mostly not affecting the model's. These results suggest that\nconsidering emotional influences and harnessing specialized, holistic visual\nprocessing of ordinary people could be promising defenses against\nmachine-manipulated media.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 18:22:16 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Groh", "Matthew", ""], ["Epstein", "Ziv", ""], ["Firestone", "Chaz", ""], ["Picard", "Rosalind", ""]]}, {"id": "2105.06511", "submitter": "Kaushik Roy", "authors": "Nathan Dolbir, Triyasha Dastidar, and Kaushik Roy", "title": "NLP is Not enough -- Contextualization of User Input in Chatbots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  AI chatbots have made vast strides in technology improvement in recent years\nand are already operational in many industries. Advanced Natural Language\nProcessing techniques, based on deep networks, efficiently process user\nrequests to carry out their functions. As chatbots gain traction, their\napplicability in healthcare is an attractive proposition due to the reduced\neconomic and people costs of an overburdened system. However, healthcare bots\nrequire safe and medically accurate information capture, which deep networks\naren't yet capable of due to user text and speech variations. Knowledge in\nsymbolic structures is more suited for accurate reasoning but cannot handle\nnatural language processing directly. Thus, in this paper, we study the effects\nof combining knowledge and neural representations on chatbot safety, accuracy,\nand understanding.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 18:57:32 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Dolbir", "Nathan", ""], ["Dastidar", "Triyasha", ""], ["Roy", "Kaushik", ""]]}, {"id": "2105.06517", "submitter": "Arash MohammadHasani", "authors": "Arash Mohammadhasani, Hamed Mehrivash, Alan Lynch, Zhan Shu", "title": "Reinforcement Learning Based Safe Decision Making for Highway Autonomous\n  Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we develop a safe decision-making method for self-driving cars\nin a multi-lane, single-agent setting. The proposed approach utilizes deep\nreinforcement learning (RL) to achieve a high-level policy for safe tactical\ndecision-making. We address two major challenges that arise solely in\nautonomous navigation. First, the proposed algorithm ensures that collisions\nnever happen, and therefore accelerate the learning process. Second, the\nproposed algorithm takes into account the unobservable states in the\nenvironment. These states appear mainly due to the unpredictable behavior of\nother agents, such as cars, and pedestrians, and make the Markov Decision\nProcess (MDP) problematic when dealing with autonomous navigation. Simulations\nfrom a well-known self-driving car simulator demonstrate the applicability of\nthe proposed method\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 19:17:30 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Mohammadhasani", "Arash", ""], ["Mehrivash", "Hamed", ""], ["Lynch", "Alan", ""], ["Shu", "Zhan", ""]]}, {"id": "2105.06543", "submitter": "Wei Xie", "authors": "Hua Zheng, Wei Xie, Ilya O. Ryzhov, Dongming Xie", "title": "Policy Optimization in Bayesian Network Hybrid Models of\n  Biomanufacturing Processes", "comments": "32 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biopharmaceutical manufacturing is a rapidly growing industry with impact in\nvirtually all branches of medicine. Biomanufacturing processes require close\nmonitoring and control, in the presence of complex bioprocess dynamics with\nmany interdependent factors, as well as extremely limited data due to the high\ncost and long duration of experiments. We develop a novel model-based\nreinforcement learning framework that can achieve human-level control in\nlow-data environments. The model uses a probabilistic knowledge graph to\ncapture causal interdependencies between factors in the underlying stochastic\ndecision process, leveraging information from existing kinetic models from\ndifferent unit operations while incorporating real-world experimental data. We\nthen present a computationally efficient, provably convergent stochastic\ngradient method for policy optimization. Validation is conducted on a realistic\napplication with a multi-dimensional, continuous state variable.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 20:39:02 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Zheng", "Hua", ""], ["Xie", "Wei", ""], ["Ryzhov", "Ilya O.", ""], ["Xie", "Dongming", ""]]}, {"id": "2105.06548", "submitter": "Angela Fan", "authors": "Sainbayar Sukhbaatar, Da Ju, Spencer Poff, Stephen Roller, Arthur\n  Szlam, Jason Weston, Angela Fan", "title": "Not All Memories are Created Equal: Learning to Forget by Expiring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanisms have shown promising results in sequence modeling tasks\nthat require long-term memory. Recent work investigated mechanisms to reduce\nthe computational cost of preserving and storing memories. However, not all\ncontent in the past is equally important to remember. We propose Expire-Span, a\nmethod that learns to retain the most important information and expire the\nirrelevant information. This forgetting of memories enables Transformers to\nscale to attend over tens of thousands of previous timesteps efficiently, as\nnot all states from previous timesteps are preserved. We demonstrate that\nExpire-Span can help models identify and retain critical information and show\nit can achieve strong performance on reinforcement learning tasks specifically\ndesigned to challenge this functionality. Next, we show that Expire-Span can\nscale to memories that are tens of thousands in size, setting a new state of\nthe art on incredibly long context tasks such as character-level language\nmodeling and a frame-by-frame moving objects task. Finally, we analyze the\nefficiency of Expire-Span compared to existing approaches and demonstrate that\nit trains faster and uses less memory.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 20:50:13 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 15:37:24 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Sukhbaatar", "Sainbayar", ""], ["Ju", "Da", ""], ["Poff", "Spencer", ""], ["Roller", "Stephen", ""], ["Szlam", "Arthur", ""], ["Weston", "Jason", ""], ["Fan", "Angela", ""]]}, {"id": "2105.06551", "submitter": "Nathan Lambert", "authors": "Sarah Dean, Thomas Krendl Gilbert, Nathan Lambert and Tom Zick", "title": "Axes for Sociotechnical Inquiry in AI Research", "comments": "9 pages, 1 figure", "journal-ref": null, "doi": "10.1109/TTS.2021.3074097", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of artificial intelligence (AI) technologies has far exceeded\nthe investigation of their relationship with society. Sociotechnical inquiry is\nneeded to mitigate the harms of new technologies whose potential impacts remain\npoorly understood. To date, subfields of AI research develop primarily\nindividual views on their relationship with sociotechnics, while tools for\nexternal investigation, comparison, and cross-pollination are lacking. In this\npaper, we propose four directions for inquiry into new and evolving areas of\ntechnological development: value--what progress and direction does a field\npromote, optimization--how the defined system within a problem formulation\nrelates to broader dynamics, consensus--how agreement is achieved and who is\nincluded in building it, and failure--what methods are pursued when the problem\nspecification is found wanting. The paper provides a lexicon for sociotechnical\ninquiry and illustrates it through the example of consumer drone technology.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 16:49:04 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Dean", "Sarah", ""], ["Gilbert", "Thomas Krendl", ""], ["Lambert", "Nathan", ""], ["Zick", "Tom", ""]]}, {"id": "2105.06564", "submitter": "Yingbo Li", "authors": "Yingbo Li, Yucong Duan, Anamaria-Beatrice Spulber, Haoyang Che,\n  Zakaria Maamar, Zhao Li, Chen Yang, Yu lei", "title": "Physical Artificial Intelligence: The Concept Expansion of\n  Next-Generation Artificial Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence has been a growth catalyst to our society and is\ncosidered across all idustries as a fundamental technology. However, its\ndevelopment has been limited to the signal processing domain that relies on the\ngenerated and collected data from other sensors. In recent research, concepts\nof Digital Artificial Intelligence and Physicial Artifical Intelligence have\nemerged and this can be considered a big step in the theoretical development of\nArtifical Intelligence. In this paper we explore the concept of Physicial\nArtifical Intelligence and propose two subdomains: Integrated Physicial\nArtifical Intelligence and Distributed Physicial Artifical Intelligence. The\npaper will also examine the trend and governance of Physicial Artifical\nIntelligence.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 21:46:46 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 00:38:03 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Li", "Yingbo", ""], ["Duan", "Yucong", ""], ["Spulber", "Anamaria-Beatrice", ""], ["Che", "Haoyang", ""], ["Maamar", "Zakaria", ""], ["Li", "Zhao", ""], ["Yang", "Chen", ""], ["lei", "Yu", ""]]}, {"id": "2105.06570", "submitter": "Ricardo Oscar Rodr\\'iguez", "authors": "Ricardo Rodriguez and Olim Tuyt and Lluis Godo and Francesc Esteva", "title": "Simplified Kripke semantics for K45-like Godel modal logics and its\n  axiomatic extensions", "comments": "arXiv admin note: text overlap with arXiv:1611.04444", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we provide simplified semantics for the logic K45(G), i.e. the\nmany-valued Godel counterpart of the classical modal logic K45. More precisely,\nwe characterize K45(G) as the set of valid formulae of the class of\npossibilistic Godel Kripke Frames <W,\\pi> where W is a non-empty set of worlds\nand \\pi: W \\to [0, 1] is a possibility distribution on W.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 22:20:44 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Rodriguez", "Ricardo", ""], ["Tuyt", "Olim", ""], ["Godo", "Lluis", ""], ["Esteva", "Francesc", ""]]}, {"id": "2105.06593", "submitter": "Woodrow Wang", "authors": "Woodrow Z. Wang, Mark Beliaev, Erdem B{\\i}y{\\i}k, Daniel A. Lazar,\n  Ramtin Pedarsani, Dorsa Sadigh", "title": "Emergent Prosociality in Multi-Agent Games Through Gifting", "comments": "9 pages, 6 figures, IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordination is often critical to forming prosocial behaviors -- behaviors\nthat increase the overall sum of rewards received by all agents in a\nmulti-agent game. However, state of the art reinforcement learning algorithms\noften suffer from converging to socially less desirable equilibria when\nmultiple equilibria exist. Previous works address this challenge with explicit\nreward shaping, which requires the strong assumption that agents can be forced\nto be prosocial. We propose using a less restrictive peer-rewarding mechanism,\ngifting, that guides the agents toward more socially desirable equilibria while\nallowing agents to remain selfish and decentralized. Gifting allows each agent\nto give some of their reward to other agents. We employ a theoretical framework\nthat captures the benefit of gifting in converging to the prosocial equilibrium\nby characterizing the equilibria's basins of attraction in a dynamical system.\nWith gifting, we demonstrate increased convergence of high risk, general-sum\ncoordination games to the prosocial equilibrium both via numerical analysis and\nexperiments.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 23:28:30 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Wang", "Woodrow Z.", ""], ["Beliaev", "Mark", ""], ["B\u0131y\u0131k", "Erdem", ""], ["Lazar", "Daniel A.", ""], ["Pedarsani", "Ramtin", ""], ["Sadigh", "Dorsa", ""]]}, {"id": "2105.06597", "submitter": "Yizhe Zhang", "authors": "Yizhe Zhang, Siqi Sun, Xiang Gao, Yuwei Fang, Chris Brockett, Michel\n  Galley, Jianfeng Gao, Bill Dolan", "title": "Joint Retrieval and Generation Training for Grounded Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in large-scale pre-training such as GPT-3 allow seemingly\nhigh quality text to be generated from a given prompt. However, such generation\nsystems often suffer from problems of hallucinated facts, and are not\ninherently designed to incorporate useful external information. Grounded\ngeneration models appear to offer remedies, but their training typically relies\non rarely-available parallel data where corresponding information-relevant\ndocuments are provided for context. We propose a framework that alleviates this\ndata constraint by jointly training a grounded generator and document retriever\non the language model signal. The model learns to reward retrieval of the\ndocuments with the highest utility in generation, and attentively combines them\nusing a Mixture-of-Experts (MoE) ensemble to generate follow-on text. We\ndemonstrate that both generator and retriever can take advantage of this joint\ntraining and work synergistically to produce more informative and relevant text\nin both prose and dialogue generation.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 00:11:38 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 02:24:28 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Zhang", "Yizhe", ""], ["Sun", "Siqi", ""], ["Gao", "Xiang", ""], ["Fang", "Yuwei", ""], ["Brockett", "Chris", ""], ["Galley", "Michel", ""], ["Gao", "Jianfeng", ""], ["Dolan", "Bill", ""]]}, {"id": "2105.06604", "submitter": "Zachary Pardos", "authors": "Weijie Jiang, Zachary A. Pardos", "title": "Towards Equity and Algorithmic Fairness in Student Grade Prediction", "comments": "Accepted to the 2021 AAAI/ACM Conference on AI, Ethics, and Society\n  (AIES '21)", "journal-ref": null, "doi": "10.1145/3461702.3462623", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Equity of educational outcome and fairness of AI with respect to race have\nbeen topics of increasing importance in education. In this work, we address\nboth with empirical evaluations of grade prediction in higher education, an\nimportant task to improve curriculum design, plan interventions for academic\nsupport, and offer course guidance to students. With fairness as the aim, we\ntrial several strategies for both label and instance balancing to attempt to\nminimize differences in algorithm performance with respect to race. We find\nthat an adversarial learning approach, combined with grade label balancing,\nachieved by far the fairest results. With equity of educational outcome as the\naim, we trial strategies for boosting predictive performance on historically\nunderserved groups and find success in sampling those groups in inverse\nproportion to their historic outcomes. With AI-infused technology supports\nincreasingly prevalent on campuses, our methodologies fill a need for\nframeworks to consider performance trade-offs with respect to sensitive student\nattributes and allow institutions to instrument their AI resources in ways that\nare attentive to equity and fairness.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 01:12:01 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Jiang", "Weijie", ""], ["Pardos", "Zachary A.", ""]]}, {"id": "2105.06622", "submitter": "Han Chen", "authors": "Han Chen and Peng Lu", "title": "Identification and Avoidance of Static and Dynamic Obstacles on Point\n  Cloud for UAVs Navigation", "comments": "8 pages for IROS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Avoiding hybrid obstacles in unknown scenarios with an efficient flight\nstrategy is a key challenge for unmanned aerial vehicle applications. In this\npaper, we introduce a technique to distinguish dynamic obstacles from static\nones with only point cloud input. Then, a computationally efficient obstacle\navoidance motion planning approach is proposed and it is in line with an\nimproved relative velocity method. The approach is able to avoid both static\nobstacles and dynamic ones in the same framework. For static and dynamic\nobstacles, the collision check and motion constraints are different, and they\nare integrated into one framework efficiently. In addition, we present several\ntechniques to improve the algorithm performance and deal with the time gap\nbetween different submodules. The proposed approach is implemented to run\nonboard in real-time and validated extensively in simulation and hardware\ntests. Our average single step calculating time is less than 20 ms.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 02:44:18 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Chen", "Han", ""], ["Lu", "Peng", ""]]}, {"id": "2105.06635", "submitter": "Yusheng Xiang", "authors": "Yusheng Xiang, Kailun Liu, Tianqing Su, Jun Li, Shirui Ouyang, Samuel\n  S. Mao, Marcus Geimer", "title": "An Extension of BIM Using AI: a Multi Working-Machines Pathfinding\n  Solution", "comments": "17 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi working-machines pathfinding solution enables more mobile machines\nsimultaneously to work inside of a working site so that the productivity can be\nexpected to increase evolutionary. To date, the potential cooperation conflicts\namong construction machinery limit the amount of construction machinery\ninvestment in a concrete working site. To solve the cooperation problem, civil\nengineers optimize the working site from a logistic perspective while computer\nscientists improve pathfinding algorithms' performance on the given benchmark\nmaps. In the practical implementation of a construction site, it is sensible to\nsolve the problem with a hybrid solution; therefore, in our study, we proposed\nan algorithm based on a cutting-edge multi-pathfinding algorithm to enable the\nmassive number of machines cooperation and offer the advice to modify the\nunreasonable part of the working site in the meantime. Using the logistic\ninformation from BIM, such as unloading and loading point, we added a\npathfinding solution for multi machines to improve the whole construction\nfleet's productivity. In the previous study, the experiments were limited to no\nmore than ten participants, and the computational time to gather the solution\nwas not given; thus, we publish our pseudo-code, our tested map, and benchmark\nour results. Our algorithm's most extensive feature is that it can quickly\nreplan the path to overcome the emergency on a construction site.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 04:13:00 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Xiang", "Yusheng", ""], ["Liu", "Kailun", ""], ["Su", "Tianqing", ""], ["Li", "Jun", ""], ["Ouyang", "Shirui", ""], ["Mao", "Samuel S.", ""], ["Geimer", "Marcus", ""]]}, {"id": "2105.06649", "submitter": "Cangning Fan", "authors": "Cangning Fan, Fangyi Zhang, Peng Liu, Xiuyu Sun, Hao Li, Ting Xiao,\n  Wei Zhao, Xianglong Tang", "title": "Importance Weighted Adversarial Discriminative Transfer for Anomaly\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous transfer methods for anomaly detection generally assume the\navailability of labeled data in source or target domains. However, such an\nassumption is not valid in most real applications where large-scale labeled\ndata are too expensive. Therefore, this paper proposes an importance weighted\nadversarial autoencoder-based method to transfer anomaly detection knowledge in\nan unsupervised manner, particularly for a rarely studied scenario where a\ntarget domain has no labeled normal/abnormal data while only normal data from a\nrelated source domain exist. Specifically, the method learns to align the\ndistributions of normal data in both source and target domains, but leave the\ndistribution of abnormal data in the target domain unchanged. In this way, an\nobvious gap can be produced between the distributions of normal and abnormal\ndata in the target domain, therefore enabling the anomaly detection in the\ndomain. Extensive experiments on multiple synthetic datasets and the UCSD\nbenchmark demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 05:21:17 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 07:23:54 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 07:00:19 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Fan", "Cangning", ""], ["Zhang", "Fangyi", ""], ["Liu", "Peng", ""], ["Sun", "Xiuyu", ""], ["Li", "Hao", ""], ["Xiao", "Ting", ""], ["Zhao", "Wei", ""], ["Tang", "Xianglong", ""]]}, {"id": "2105.06660", "submitter": "Kei Akuzawa", "authors": "Kei Akuzawa, Yusuke Iwasawa, Yutaka Matsuo", "title": "Estimating Disentangled Belief about Hidden State and Hidden Task for\n  Meta-RL", "comments": "accepted to L4DC2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is considerable interest in designing meta-reinforcement learning\n(meta-RL) algorithms, which enable autonomous agents to adapt new tasks from\nsmall amount of experience. In meta-RL, the specification (such as reward\nfunction) of current task is hidden from the agent. In addition, states are\nhidden within each task owing to sensor noise or limitations in realistic\nenvironments. Therefore, the meta-RL agent faces the challenge of specifying\nboth the hidden task and states based on small amount of experience. To address\nthis, we propose estimating disentangled belief about task and states,\nleveraging an inductive bias that the task and states can be regarded as global\nand local features of each task. Specifically, we train a hierarchical\nstate-space model (HSSM) parameterized by deep neural networks as an\nenvironment model, whose global and local latent variables correspond to task\nand states, respectively. Because the HSSM does not allow analytical\ncomputation of posterior distribution, i.e., belief, we employ amortized\ninference to approximate it. After the belief is obtained, we can augment\nobservations of a model-free policy with the belief to efficiently train the\npolicy. Moreover, because task and state information are factorized and\ninterpretable, the downstream policy training is facilitated compared with the\nprior methods that did not consider the hierarchical nature. Empirical\nvalidations on a GridWorld environment confirm that the HSSM can separate the\nhidden task and states information. Then, we compare the meta-RL agent with the\nHSSM to prior meta-RL methods in MuJoCo environments, and confirm that our\nagent requires less training data and reaches higher final performance.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 06:11:36 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Akuzawa", "Kei", ""], ["Iwasawa", "Yusuke", ""], ["Matsuo", "Yutaka", ""]]}, {"id": "2105.06677", "submitter": "Sebastian Palacio", "authors": "Sebastian Palacio, Adriano Lucieri, Mohsin Munir, J\\\"orn Hees, Sheraz\n  Ahmed, Andreas Dengel", "title": "XAI Handbook: Towards a Unified Framework for Explainable AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The field of explainable AI (XAI) has quickly become a thriving and prolific\ncommunity. However, a silent, recurrent and acknowledged issue in this area is\nthe lack of consensus regarding its terminology. In particular, each new\ncontribution seems to rely on its own (and often intuitive) version of terms\nlike \"explanation\" and \"interpretation\". Such disarray encumbers the\nconsolidation of advances in the field towards the fulfillment of scientific\nand regulatory demands e.g., when comparing methods or establishing their\ncompliance with respect to biases and fairness constraints. We propose a\ntheoretical framework that not only provides concrete definitions for these\nterms, but it also outlines all steps necessary to produce explanations and\ninterpretations. The framework also allows for existing contributions to be\nre-contextualized such that their scope can be measured, thus making them\ncomparable to other methods. We show that this framework is compliant with\ndesiderata on explanations, on interpretability and on evaluation metrics. We\npresent a use-case showing how the framework can be used to compare LIME, SHAP\nand MDNet, establishing their advantages and shortcomings. Finally, we discuss\nrelevant trends in XAI as well as recommendations for future work, all from the\nstandpoint of our framework.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 07:28:21 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Palacio", "Sebastian", ""], ["Lucieri", "Adriano", ""], ["Munir", "Mohsin", ""], ["Hees", "J\u00f6rn", ""], ["Ahmed", "Sheraz", ""], ["Dengel", "Andreas", ""]]}, {"id": "2105.06696", "submitter": "Qi Kuang", "authors": "Fan Zhou, Zhoufan Zhu, Qi Kuang, Liwen Zhang", "title": "Non-decreasing Quantile Function Network with Efficient Exploration for\n  Distributional Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although distributional reinforcement learning (DRL) has been widely examined\nin the past few years, there are two open questions people are still trying to\naddress. One is how to ensure the validity of the learned quantile function,\nthe other is how to efficiently utilize the distribution information. This\npaper attempts to provide some new perspectives to encourage the future\nin-depth studies in these two fields. We first propose a non-decreasing\nquantile function network (NDQFN) to guarantee the monotonicity of the obtained\nquantile estimates and then design a general exploration framework called\ndistributional prediction error (DPE) for DRL which utilizes the entire\ndistribution of the quantile function. In this paper, we not only discuss the\ntheoretical necessity of our method but also show the performance gain it\nachieves in practice by comparing with some competitors on Atari 2600 Games\nespecially in some hard-explored games.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 08:12:51 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Zhou", "Fan", ""], ["Zhu", "Zhoufan", ""], ["Kuang", "Qi", ""], ["Zhang", "Liwen", ""]]}, {"id": "2105.06706", "submitter": "Paola Ardon Miss", "authors": "Paola Ard\\'on, \\`Eric Pairet, Katrin S. Lohan, Subramanian\n  Ramamoorthy, Ronald P. A. Petrick", "title": "Building Affordance Relations for Robotic Agents - A Review", "comments": "Accepted for IJCAI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Affordances describe the possibilities for an agent to perform actions with\nan object. While the significance of the affordance concept has been previously\nstudied from varied perspectives, such as psychology and cognitive science,\nthese approaches are not always sufficient to enable direct transfer, in the\nsense of implementations, to artificial intelligence (AI)-based systems and\nrobotics. However, many efforts have been made to pragmatically employ the\nconcept of affordances, as it represents great potential for AI agents to\neffectively bridge perception to action. In this survey, we review and find\ncommon ground amongst different strategies that use the concept of affordances\nwithin robotic tasks, and build on these methods to provide guidance for\nincluding affordances as a mechanism to improve autonomy. To this end, we\noutline common design choices for building representations of affordance\nrelations, and their implications on the generalisation capabilities of an\nagent when facing previously unseen scenarios. Finally, we identify and discuss\na range of interesting research directions involving affordances that have the\npotential to improve the capabilities of an AI agent.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 08:35:18 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Ard\u00f3n", "Paola", ""], ["Pairet", "\u00c8ric", ""], ["Lohan", "Katrin S.", ""], ["Ramamoorthy", "Subramanian", ""], ["Petrick", "Ronald P. A.", ""]]}, {"id": "2105.06717", "submitter": "Farhad Moghimifar", "authors": "Farhad Moghimifar, Lizhen Qu, Yue Zhuo, Gholamreza Haffari, Mahsa\n  Baktashmotlagh", "title": "Neural-Symbolic Commonsense Reasoner with Relation Predictors", "comments": "ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense reasoning aims to incorporate sets of commonsense facts,\nretrieved from Commonsense Knowledge Graphs (CKG), to draw conclusion about\nordinary situations. The dynamic nature of commonsense knowledge postulates\nmodels capable of performing multi-hop reasoning over new situations. This\nfeature also results in having large-scale sparse Knowledge Graphs, where such\nreasoning process is needed to predict relations between new events. However,\nexisting approaches in this area are limited by considering CKGs as a limited\nset of facts, thus rendering them unfit for reasoning over new unseen\nsituations and events. In this paper, we present a neural-symbolic reasoner,\nwhich is capable of reasoning over large-scale dynamic CKGs. The logic rules\nfor reasoning over CKGs are learned during training by our model. In addition\nto providing interpretable explanation, the learned logic rules help to\ngeneralise prediction to newly introduced events. Experimental results on the\ntask of link prediction on CKGs prove the effectiveness of our model by\noutperforming the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 08:54:25 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Moghimifar", "Farhad", ""], ["Qu", "Lizhen", ""], ["Zhuo", "Yue", ""], ["Haffari", "Gholamreza", ""], ["Baktashmotlagh", "Mahsa", ""]]}, {"id": "2105.06742", "submitter": "Nathaniel Bastian PhD", "authors": "David A. Bierbrauer and Alexander Chang and Will Kritzer and Nathaniel\n  D. Bastian", "title": "Anomaly Detection in Cybersecurity: Unsupervised, Graph-Based and\n  Supervised Learning Methods in Adversarial Environments", "comments": "6 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning for anomaly detection has become a widely researched field\nin cybersecurity. Inherent to today's operating environment is the practice of\nadversarial machine learning, which attempts to circumvent machine learning\nmodels. In this work, we examine the feasibility of unsupervised learning and\ngraph-based methods for anomaly detection in the network intrusion detection\nsystem setting, as well as leverage an ensemble approach to supervised learning\nof the anomaly detection problem. We incorporate a realistic adversarial\ntraining mechanism when training our supervised models to enable strong\nclassification performance in adversarial environments. Our results indicate\nthat the unsupervised and graph-based methods were outperformed in detecting\nanomalies (malicious activity) by the supervised stacking ensemble method with\ntwo levels. This model consists of three different classifiers in the first\nlevel, followed by either a Naive Bayes or Decision Tree classifier for the\nsecond level. We see that our model maintains an F1-score above 0.97 for\nmalicious samples across all tested level two classifiers. Notably, Naive Bayes\nis the fastest level two classifier averaging 1.12 seconds while Decision Tree\nmaintains the highest AUC score of 0.98.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 10:05:10 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Bierbrauer", "David A.", ""], ["Chang", "Alexander", ""], ["Kritzer", "Will", ""], ["Bastian", "Nathaniel D.", ""]]}, {"id": "2105.06746", "submitter": "Christian Venner{\\o}d", "authors": "Adrian Kj{\\ae}rran and Christian Bakke Venner{\\o}d and Erling Stray\n  Bugge", "title": "Facial Age Estimation using Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is a part of a student project in Machine Learning at the\nNorwegian University of Science and Technology. In this paper, a deep\nconvolutional neural network with five convolutional layers and three\nfully-connected layers is presented to estimate the ages of individuals based\non images. The model is in its entirety trained from scratch, where a\ncombination of three different datasets is used as training data. These\ndatasets are the APPA dataset, UTK dataset, and the IMDB dataset. The images\nwere preprocessed using a proprietary face-recognition software. Our model is\nevaluated on both a held-out test set, and on the Adience benchmark. On the\ntest set, our model achieves a categorical accuracy of 52%. On the Adience\nbenchmark, our model proves inferior compared with other leading models, with\nan exact accuray of 30%, and an one-off accuracy of 46%. Furthermore, a script\nwas created, allowing users to estimate their age directly using their web\ncamera. The script, alongside all other code, is located in our GitHub\nrepository: AgeNet.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 10:09:47 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Kj\u00e6rran", "Adrian", ""], ["Venner\u00f8d", "Christian Bakke", ""], ["Bugge", "Erling Stray", ""]]}, {"id": "2105.06750", "submitter": "Seonghyeon Lee", "authors": "Seonghyeon Lee, Dongha Lee and Hwanjo Yu", "title": "Out-of-Manifold Regularization in Contextual Embedding Space for Text\n  Classification", "comments": "ACL2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent studies on neural networks with pre-trained weights (i.e., BERT) have\nmainly focused on a low-dimensional subspace, where the embedding vectors\ncomputed from input words (or their contexts) are located. In this work, we\npropose a new approach to finding and regularizing the remainder of the space,\nreferred to as out-of-manifold, which cannot be accessed through the words.\nSpecifically, we synthesize the out-of-manifold embeddings based on two\nembeddings obtained from actually-observed words, to utilize them for\nfine-tuning the network. A discriminator is trained to detect whether an input\nembedding is located inside the manifold or not, and simultaneously, a\ngenerator is optimized to produce new embeddings that can be easily identified\nas out-of-manifold by the discriminator. These two modules successfully\ncollaborate in a unified and end-to-end manner for regularizing the\nout-of-manifold. Our extensive evaluation on various text classification\nbenchmarks demonstrates the effectiveness of our approach, as well as its good\ncompatibility with existing data augmentation techniques which aim to enhance\nthe manifold.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 10:17:59 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Lee", "Seonghyeon", ""], ["Lee", "Dongha", ""], ["Yu", "Hwanjo", ""]]}, {"id": "2105.06756", "submitter": "Christian Venner{\\o}d", "authors": "Christian Bakke Venner{\\o}d and Adrian Kj{\\ae}rran and Erling Stray\n  Bugge", "title": "Long Short-term Memory RNN", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper is based on a machine learning project at the Norwegian University\nof Science and Technology, fall 2020. The project was initiated with a\nliterature review on the latest developments within time-series forecasting\nmethods in the scientific community over the past five years. The paper\nsummarizes the essential aspects of this research. Furthermore, in this paper,\nwe introduce an LSTM cell's architecture, and explain how different components\ngo together to alter the cell's memory and predict the output. Also, the paper\nprovides the necessary formulas and foundations to calculate a forward\niteration through an LSTM. Then, the paper refers to some practical\napplications and research that emphasize the strength and weaknesses of LSTMs,\nshown within the time-series domain and the natural language processing (NLP)\ndomain. Finally, alternative statistical methods for time series predictions\nare highlighted, where the paper outline ARIMA and exponential smoothing.\nNevertheless, as LSTMs can be viewed as a complex architecture, the paper\nassumes that the reader has some knowledge of essential machine learning\naspects, such as the multi-layer perceptron, activation functions, overfitting,\nbackpropagation, bias, over- and underfitting, and more.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 10:34:14 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Venner\u00f8d", "Christian Bakke", ""], ["Kj\u00e6rran", "Adrian", ""], ["Bugge", "Erling Stray", ""]]}, {"id": "2105.06758", "submitter": "Cor Steging", "authors": "Cor Steging, Silja Renooij, Bart Verheij", "title": "Discovering the Rationale of Decisions: Experiments on Aligning Learning\n  and Reasoning", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In AI and law, systems that are designed for decision support should be\nexplainable when pursuing justice. In order for these systems to be fair and\nresponsible, they should make correct decisions and make them using a sound and\ntransparent rationale. In this paper, we introduce a knowledge-driven method\nfor model-agnostic rationale evaluation using dedicated test cases, similar to\nunit-testing in professional software development. We apply this new method in\na set of machine learning experiments aimed at extracting known knowledge\nstructures from artificial datasets from fictional and non-fictional legal\nsettings. We show that our method allows us to analyze the rationale of\nblack-box machine learning systems by assessing which rationale elements are\nlearned or not. Furthermore, we show that the rationale can be adjusted using\ntailor-made training data based on the results of the rationale evaluation.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 10:37:03 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Steging", "Cor", ""], ["Renooij", "Silja", ""], ["Verheij", "Bart", ""]]}, {"id": "2105.06762", "submitter": "Yulong Chen", "authors": "Yulong Chen, Yang Liu, Liang Chen and Yue Zhang", "title": "DialogSum: A Real-Life Scenario Dialogue Summarization Dataset", "comments": "ACL findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Proposal of large-scale datasets has facilitated research on deep neural\nmodels for news summarization. Deep learning can also be potentially useful for\nspoken dialogue summarization, which can benefit a range of real-life scenarios\nincluding customer service management and medication tracking. To this end, we\npropose DialogSum, a large-scale labeled dialogue summarization dataset. We\nconduct empirical analysis on DialogSum using state-of-the-art neural\nsummarizers. Experimental results show unique challenges in dialogue\nsummarization, such as spoken terms, special discourse structures, coreferences\nand ellipsis, pragmatics and social common sense, which require specific\nrepresentation learning technologies to better deal with.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 11:12:40 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 08:32:00 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 03:46:14 GMT"}, {"version": "v4", "created": "Wed, 16 Jun 2021 06:34:42 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Chen", "Yulong", ""], ["Liu", "Yang", ""], ["Chen", "Liang", ""], ["Zhang", "Yue", ""]]}, {"id": "2105.06782", "submitter": "Alexey Ignatiev", "authors": "Alexey Ignatiev and Joao Marques-Silva", "title": "SAT-Based Rigorous Explanations for Decision Lists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision lists (DLs) find a wide range of uses for classification problems in\nMachine Learning (ML), being implemented in a number of ML frameworks. DLs are\noften perceived as interpretable. However, building on recent results for\ndecision trees (DTs), we argue that interpretability is an elusive goal for\nsome DLs. As a result, for some uses of DLs, it will be important to compute\n(rigorous) explanations. Unfortunately, and in clear contrast with the case of\nDTs, this paper shows that computing explanations for DLs is computationally\nhard. Motivated by this result, the paper proposes propositional encodings for\ncomputing abductive explanations (AXps) and contrastive explanations (CXps) of\nDLs. Furthermore, the paper investigates the practical efficiency of a\nMARCO-like approach for enumerating explanations. The experimental results\ndemonstrate that, for DLs used in practical settings, the use of SAT oracles\noffers a very efficient solution, and that complete enumeration of explanations\nis most often feasible.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 12:06:12 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Ignatiev", "Alexey", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "2105.06784", "submitter": "Alessandro Ronca", "authors": "Alessandro Ronca and Giuseppe De Giacomo", "title": "Efficient PAC Reinforcement Learning in Regular Decision Processes", "comments": "Extended version of a paper accepted for publication at IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently regular decision processes have been proposed as a well-behaved form\nof non-Markov decision process. Regular decision processes are characterised by\na transition function and a reward function that depend on the whole history,\nthough regularly (as in regular languages). In practice both the transition and\nthe reward functions can be seen as finite transducers. We study reinforcement\nlearning in regular decision processes. Our main contribution is to show that a\nnear-optimal policy can be PAC-learned in polynomial time in a set of\nparameters that describe the underlying decision process. We argue that the\nidentified set of parameters is minimal and it reasonably captures the\ndifficulty of a regular decision process.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 12:08:46 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 10:25:08 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Ronca", "Alessandro", ""], ["De Giacomo", "Giuseppe", ""]]}, {"id": "2105.06807", "submitter": "Ruoxi Chen", "authors": "Jinyin Chen, Ruoxi Chen, Haibin Zheng, Zhaoyan Ming, Wenrong Jiang and\n  Chen Cui", "title": "Salient Feature Extractor for Adversarial Defense on Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed unprecedented success achieved by deep learning\nmodels in the field of computer vision. However, their vulnerability towards\ncarefully crafted adversarial examples has also attracted the increasing\nattention of researchers. Motivated by the observation that adversarial\nexamples are due to the non-robust feature learned from the original dataset by\nmodels, we propose the concepts of salient feature(SF) and trivial feature(TF).\nThe former represents the class-related feature, while the latter is usually\nadopted to mislead the model. We extract these two features with coupled\ngenerative adversarial network model and put forward a novel detection and\ndefense method named salient feature extractor (SFE) to defend against\nadversarial attacks. Concretely, detection is realized by separating and\ncomparing the difference between SF and TF of the input. At the same time,\ncorrect labels are obtained by re-identifying SF to reach the purpose of\ndefense. Extensive experiments are carried out on MNIST, CIFAR-10, and ImageNet\ndatasets where SFE shows state-of-the-art results in effectiveness and\nefficiency compared with baselines. Furthermore, we provide an interpretable\nunderstanding of the defense and detection process.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 12:56:06 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Chen", "Jinyin", ""], ["Chen", "Ruoxi", ""], ["Zheng", "Haibin", ""], ["Ming", "Zhaoyan", ""], ["Jiang", "Wenrong", ""], ["Cui", "Chen", ""]]}, {"id": "2105.06827", "submitter": "Mohsen Asgari", "authors": "Mohsen Asgari, Hossein Khasteh", "title": "Application of Three Different Machine Learning Methods on Strategy\n  Creation for Profitable Trades on Cryptocurrency Markets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.TR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  AI and data driven solutions have been applied to different fields with\noutperforming and promising results. In this research work we apply k-Nearest\nNeighbours, eXtreme Gradient Boosting and Random Forest classifiers to\ndirection detection problem of three cryptocurrency markets. Our input data\nincludes price data and technical indicators. We use these classifiers to\ndesign a strategy to trade in those markets. Our test results on unseen data\nshows a great potential for this approach in helping investors with an expert\nsystem to exploit the market and gain profit. Our highest gain for an unseen 66\nday span is 860 dollars per 1800 dollars investment. We also discuss\nlimitations of these approaches and their potential impact to Efficient Market\nHypothesis.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 13:42:46 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Asgari", "Mohsen", ""], ["Khasteh", "Hossein", ""]]}, {"id": "2105.06850", "submitter": "Shunbo Zhang", "authors": "Shunbo Zhang, Shun Zhang, Feifei Gao, Jianpeng Ma, Octavia A. Dobre", "title": "Deep Learning Based RIS Channel Extrapolation with Element-grouping", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reconfigurable intelligent surface (RIS) is considered as a revolutionary\ntechnology for future wireless communication networks. In this letter, we\nconsider the acquisition of the cascaded channels, which is a challenging task\ndue to the massive number of passive RIS elements. To reduce the pilot\noverhead, we adopt the element-grouping strategy, where each element in one\ngroup shares the same reflection coefficient and is assumed to have the same\nchannel condition. We analyze the channel interference caused by the\nelement-grouping strategy and further design two deep learning based networks.\nThe first one aims to refine the partial channels by eliminating the\ninterference, while the second one tries to extrapolate the full channels from\nthe refined partial channels. We cascade the two networks and jointly train\nthem. Simulation results show that the proposed scheme provides significant\ngain compared to the conventional element-grouping method without interference\nelimination.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 14:24:54 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Zhang", "Shunbo", ""], ["Zhang", "Shun", ""], ["Gao", "Feifei", ""], ["Ma", "Jianpeng", ""], ["Dobre", "Octavia A.", ""]]}, {"id": "2105.06903", "submitter": "Weipeng Huang", "authors": "Weipeng Huang, Tin Lok James Ng, Nishma Laitonjam, Neil J. Hurley", "title": "Posterior Regularisation on Bayesian Hierarchical Mixture Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study a recent inferential framework, named posterior regularisation, on\nthe Bayesian hierarchical mixture clustering (BHMC) model. This framework\nfacilitates a simple way to impose extra constraints on a Bayesian model to\novercome some weakness of the original model. It narrows the search space of\nthe parameters of the Bayesian model through a formalism that imposes certain\nconstraints on the features of the found solutions. In this paper, in order to\nenhance the separation of clusters, we apply posterior regularisation to impose\nmax-margin constraints on the nodes at every level of the hierarchy. This paper\nshows how the framework integrates with BHMC and achieves the expected\nimprovements over the original Bayesian model.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 15:41:15 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 17:03:57 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Huang", "Weipeng", ""], ["Ng", "Tin Lok James", ""], ["Laitonjam", "Nishma", ""], ["Hurley", "Neil J.", ""]]}, {"id": "2105.06912", "submitter": "Chien-Sheng Wu", "authors": "Chien-Sheng Wu, Andrea Madotto, Wenhao Liu, Pascale Fung, Caiming\n  Xiong", "title": "QAConv: Question Answering on Informative Conversations", "comments": "Data and code are available at https://github.com/salesforce/QAConv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces QAConv, a new question answering (QA) dataset that uses\nconversations as a knowledge source. We focus on informative conversations\nincluding business emails, panel discussions, and work channels. Unlike\nopen-domain and task-oriented dialogues, these conversations are usually long,\ncomplex, asynchronous, and involve strong domain knowledge. In total, we\ncollect 34,204 QA pairs, including span-based, free-form, and unanswerable\nquestions, from 10,259 selected conversations with both human-written and\nmachine-generated questions. We segment long conversations into chunks, and use\na question generator and dialogue summarizer as auxiliary tools to collect\nmulti-hop questions. The dataset has two testing scenarios, chunk mode and full\nmode, depending on whether the grounded chunk is provided or retrieved from a\nlarge conversational pool. Experimental results show that state-of-the-art QA\nsystems trained on existing QA datasets have limited zero-shot ability and tend\nto predict our questions as unanswerable. Fine-tuning such systems on our\ncorpus can achieve significant improvement up to 23.6% and 13.6% in both chunk\nmode and full mode, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 15:53:05 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Wu", "Chien-Sheng", ""], ["Madotto", "Andrea", ""], ["Liu", "Wenhao", ""], ["Fung", "Pascale", ""], ["Xiong", "Caiming", ""]]}, {"id": "2105.06923", "submitter": "Wei Lu", "authors": "John Moon, Wei D. Lu (University of Michigan)", "title": "Hierarchical Architectures in Reservoir Computing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reservoir computing (RC) offers efficient temporal data processing with a low\ntraining cost by separating recurrent neural networks into a fixed network with\nrecurrent connections and a trainable linear network. The quality of the fixed\nnetwork, called reservoir, is the most important factor that determines the\nperformance of the RC system. In this paper, we investigate the influence of\nthe hierarchical reservoir structure on the properties of the reservoir and the\nperformance of the RC system. Analogous to deep neural networks, stacking\nsub-reservoirs in series is an efficient way to enhance the nonlinearity of\ndata transformation to high-dimensional space and expand the diversity of\ntemporal information captured by the reservoir. These deep reservoir systems\noffer better performance when compared to simply increasing the size of the\nreservoir or the number of sub-reservoirs. Low frequency components are mainly\ncaptured by the sub-reservoirs in later stage of the deep reservoir structure,\nsimilar to observations that more abstract information can be extracted by\nlayers in the late stage of deep neural networks. When the total size of the\nreservoir is fixed, tradeoff between the number of sub-reservoirs and the size\nof each sub-reservoir needs to be carefully considered, due to the degraded\nability of individual sub-reservoirs at small sizes. Improved performance of\nthe deep reservoir structure alleviates the difficulty of implementing the RC\nsystem on hardware systems.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 16:11:35 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Moon", "John", "", "University of Michigan"], ["Lu", "Wei D.", "", "University of Michigan"]]}, {"id": "2105.06929", "submitter": "Zeinab S. Jalali", "authors": "Zeinab S. Jalali, Krishnaram Kenthapadi, and Sucheta Soundarajan", "title": "On Measuring the Diversity of Organizational Networks", "comments": "12 pages, 3 figures, accepted in CompleNet 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The interaction patterns of employees in social and professional networks\nplay an important role in the success of employees and organizations as a\nwhole. However, in many fields there is a severe under-representation of\nminority groups; moreover, minority individuals may be segregated from the rest\nof the network or isolated from one another. While the problem of increasing\nthe representation of minority groups in various fields has been well-studied,\ndiver- sification in terms of numbers alone may not be sufficient: social\nrelationships should also be considered. In this work, we consider the problem\nof assigning a set of employment candidates to positions in a social network so\nthat diversity and overall fitness are maximized, and propose Fair Employee\nAssignment (FairEA), a novel algorithm for finding such a matching. The output\nfrom FairEA can be used as a benchmark by organizations wishing to evaluate\ntheir hiring and assignment practices. On real and synthetic networks, we\ndemonstrate that FairEA does well at finding high-fitness, high-diversity\nmatchings.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 16:20:44 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Jalali", "Zeinab S.", ""], ["Kenthapadi", "Krishnaram", ""], ["Soundarajan", "Sucheta", ""]]}, {"id": "2105.06948", "submitter": "Mark Ho", "authors": "Mark K. Ho, David Abel, Carlos G. Correa, Michael L. Littman, Jonathan\n  D. Cohen, Thomas L. Griffiths", "title": "Control of mental representations in human planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most striking features of human cognition is the capacity to plan.\nTwo aspects of human planning stand out: its efficiency, even in complex\nenvironments, and its flexibility, even in changing environments. Efficiency is\nespecially impressive because directly computing an optimal plan is\nintractable, even for modestly complex tasks, and yet people successfully solve\nmyriad everyday problems despite limited cognitive resources. Standard accounts\nin psychology, economics, and artificial intelligence have suggested this is\nbecause people have a mental representation of a task and then use heuristics\nto plan in that representation. However, this approach generally assumes that\nmental representations are fixed. Here, we propose that mental representations\ncan be controlled and that this provides opportunities to adaptively simplify\nproblems so they can be more easily reasoned about -- a process we refer to as\nconstrual. We construct a formal model of this process and, in a series of\nlarge, pre-registered behavioral experiments, show both that construal is\nsubject to online cognitive control and that people form value-guided\nconstruals that optimally balance the complexity of a representation and its\nutility for planning and acting. These results demonstrate how strategically\nperceiving and conceiving problems facilitates the effective use of limited\ncognitive resources.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 16:39:31 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Ho", "Mark K.", ""], ["Abel", "David", ""], ["Correa", "Carlos G.", ""], ["Littman", "Michael L.", ""], ["Cohen", "Jonathan D.", ""], ["Griffiths", "Thomas L.", ""]]}, {"id": "2105.06950", "submitter": "Yun-Wei Chu", "authors": "Chi-Yang Hsu, Yun-Wei Chu, Ting-Hao 'Kenneth' Huang, Lun-Wei Ku", "title": "Plot and Rework: Modeling Storylines for Visual Storytelling", "comments": "9 pages, ACL-IJCNLP 2021 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Writing a coherent and engaging story is not easy. Creative writers use their\nknowledge and worldview to put disjointed elements together to form a coherent\nstoryline, and work and rework iteratively toward perfection. Automated visual\nstorytelling (VIST) models, however, make poor use of external knowledge and\niterative generation when attempting to create stories. This paper introduces\nPR-VIST, a framework that represents the input image sequence as a story graph\nin which it finds the best path to form a storyline. PR-VIST then takes this\npath and learns to generate the final story via an iterative training process.\nThis framework produces stories that are superior in terms of diversity,\ncoherence, and humanness, per both automatic and human evaluations. An ablation\nstudy shows that both plotting and reworking contribute to the model's\nsuperiority.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 16:41:29 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 19:13:55 GMT"}, {"version": "v3", "created": "Wed, 7 Jul 2021 14:59:28 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Hsu", "Chi-Yang", ""], ["Chu", "Yun-Wei", ""], ["Huang", "Ting-Hao 'Kenneth'", ""], ["Ku", "Lun-Wei", ""]]}, {"id": "2105.06977", "submitter": "Kayo Yin", "authors": "Kayo Yin, Patrick Fernandes, Danish Pruthi, Aditi Chaudhary, Andr\\'e\n  F. T. Martins, Graham Neubig", "title": "Do Context-Aware Translation Models Pay the Right Attention?", "comments": "Accepted to ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Context-aware machine translation models are designed to leverage contextual\ninformation, but often fail to do so. As a result, they inaccurately\ndisambiguate pronouns and polysemous words that require context for resolution.\nIn this paper, we ask several questions: What contexts do human translators use\nto resolve ambiguous words? Are models paying large amounts of attention to the\nsame context? What if we explicitly train them to do so? To answer these\nquestions, we introduce SCAT (Supporting Context for Ambiguous Translations), a\nnew English-French dataset comprising supporting context words for 14K\ntranslations that professional translators found useful for pronoun\ndisambiguation. Using SCAT, we perform an in-depth analysis of the context used\nto disambiguate, examining positional and lexical characteristics of the\nsupporting words. Furthermore, we measure the degree of alignment between the\nmodel's attention scores and the supporting context from SCAT, and apply a\nguided attention strategy to encourage agreement between the two.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 17:32:24 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 16:26:23 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Yin", "Kayo", ""], ["Fernandes", "Patrick", ""], ["Pruthi", "Danish", ""], ["Chaudhary", "Aditi", ""], ["Martins", "Andr\u00e9 F. T.", ""], ["Neubig", "Graham", ""]]}, {"id": "2105.06987", "submitter": "Andrey Malinin Dr.", "authors": "Max Ryabinin, Andrey Malinin, Mark Gales", "title": "Scaling Ensemble Distribution Distillation to Many Classes with Proxy\n  Targets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensembles of machine learning models yield improved system performance as\nwell as robust and interpretable uncertainty estimates; however, their\ninference costs may often be prohibitively high. \\emph{Ensemble Distribution\nDistillation} is an approach that allows a single model to efficiently capture\nboth the predictive performance and uncertainty estimates of an ensemble. For\nclassification, this is achieved by training a Dirichlet distribution over the\nensemble members' output distributions via the maximum likelihood criterion.\nAlthough theoretically principled, this criterion exhibits poor convergence\nwhen applied to large-scale tasks where the number of classes is very high. In\nour work, we analyze this effect and show that the Dirichlet log-likelihood\ncriterion classes with low probability induce larger gradients than\nhigh-probability classes. This forces the model to focus on the distribution of\nthe ensemble tail-class probabilities. We propose a new training objective that\nminimizes the reverse KL-divergence to a \\emph{Proxy-Dirichlet} target derived\nfrom the ensemble. This loss resolves the gradient issues of Ensemble\nDistribution Distillation, as we demonstrate both theoretically and empirically\non the ImageNet and WMT17 En-De datasets containing 1000 and 40,000 classes,\nrespectively.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 17:50:14 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Ryabinin", "Max", ""], ["Malinin", "Andrey", ""], ["Gales", "Mark", ""]]}, {"id": "2105.07026", "submitter": "Amin Asadi", "authors": "Amin Asadi, Sarah Nurre Pinkley", "title": "A Monotone Approximate Dynamic Programming Approach for the Stochastic\n  Scheduling, Allocation, and Inventory Replenishment Problem: Applications to\n  Drone and Electric Vehicle Battery Swap Stations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.LG math.PR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There is a growing interest in using electric vehicles (EVs) and drones for\nmany applications. However, battery-oriented issues, including range anxiety\nand battery degradation, impede adoption. Battery swap stations are one\nalternative to reduce these concerns that allow the swap of depleted for full\nbatteries in minutes. We consider the problem of deriving actions at a battery\nswap station when explicitly considering the uncertain arrival of swap demand,\nbattery degradation, and replacement. We model the operations at a battery swap\nstation using a finite horizon Markov Decision Process model for the stochastic\nscheduling, allocation, and inventory replenishment problem (SAIRP), which\ndetermines when and how many batteries are charged, discharged, and replaced\nover time. We present theoretical proofs for the monotonicity of the value\nfunction and monotone structure of an optimal policy for special SAIRP cases.\nDue to the curses of dimensionality, we develop a new monotone approximate\ndynamic programming (ADP) method, which intelligently initializes a value\nfunction approximation using regression. In computational tests, we demonstrate\nthe superior performance of the new regression-based monotone ADP method as\ncompared to exact methods and other monotone ADP methods. Further, with the\ntests, we deduce policy insights for drone swap stations.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 18:39:32 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Asadi", "Amin", ""], ["Pinkley", "Sarah Nurre", ""]]}, {"id": "2105.07065", "submitter": "Nicholas Ichien", "authors": "Nicholas Ichien, Qing Liu, Shuhao Fu, Keith J. Holyoak, Alan Yuille,\n  Hongjing Lu", "title": "Visual analogy: Deep learning versus compositional models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Is analogical reasoning a task that must be learned to solve from scratch by\napplying deep learning models to massive numbers of reasoning problems? Or are\nanalogies solved by computing similarities between structured representations\nof analogs? We address this question by comparing human performance on visual\nanalogies created using images of familiar three-dimensional objects (cars and\ntheir subregions) with the performance of alternative computational models.\nHuman reasoners achieved above-chance accuracy for all problem types, but made\nmore errors in several conditions (e.g., when relevant subregions were\noccluded). We compared human performance to that of two recent deep learning\nmodels (Siamese Network and Relation Network) directly trained to solve these\nanalogy problems, as well as to that of a compositional model that assesses\nrelational similarity between part-based representations. The compositional\nmodel based on part representations, but not the deep learning models,\ngenerated qualitative performance similar to that of human reasoners.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 20:56:02 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Ichien", "Nicholas", ""], ["Liu", "Qing", ""], ["Fu", "Shuhao", ""], ["Holyoak", "Keith J.", ""], ["Yuille", "Alan", ""], ["Lu", "Hongjing", ""]]}, {"id": "2105.07066", "submitter": "Hongda Wu", "authors": "Hongda Wu, Ping Wang", "title": "Node Selection Toward Faster Convergence for Federated Learning on\n  Non-IID Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated Learning (FL) is a distributed learning paradigm that enables a\nlarge number of resource-limited nodes to collaboratively train a model without\ndata sharing. The non-independent-and-identically-distributed (non-i.i.d.) data\nsamples invoke discrepancy between global and local objectives, making the FL\nmodel slow to converge. In this paper, we proposed Optimal Aggregation\nalgorithm for better aggregation, which finds out the optimal subset of local\nupdates of participating nodes in each global round, by identifying and\nexcluding the adverse local updates via checking the relationship between the\nlocal gradient and the global gradient. Then, we proposed a Probabilistic Node\nSelection framework (FedPNS) to dynamically change the probability for each\nnode to be selected based on the output of Optimal Aggregation. FedPNS can\npreferentially select nodes that propel faster model convergence. The\nunbiasedness of the proposed FedPNS design is illustrated and the convergence\nrate improvement of FedPNS over the commonly adopted Federated Averaging\n(FedAvg) algorithm is analyzed theoretically. Experimental results demonstrate\nthe effectiveness of FedPNS in accelerating the FL convergence rate, as\ncompared to FedAvg with random node selection.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 20:56:09 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Wu", "Hongda", ""], ["Wang", "Ping", ""]]}, {"id": "2105.07078", "submitter": "Siyue Wang", "authors": "Siyue Wang, Xiao Wang, Pin-Yu Chen, Pu Zhao and Xue Lin", "title": "High-Robustness, Low-Transferability Fingerprinting of Neural Networks", "comments": "ICLR 2021 Workshop on Security and Safety in Machine Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes Characteristic Examples for effectively fingerprinting\ndeep neural networks, featuring high-robustness to the base model against model\npruning as well as low-transferability to unassociated models. This is the\nfirst work taking both robustness and transferability into consideration for\ngenerating realistic fingerprints, whereas current methods lack practical\nassumptions and may incur large false positive rates. To achieve better\ntrade-off between robustness and transferability, we propose three kinds of\ncharacteristic examples: vanilla C-examples, RC-examples, and LTRC-example, to\nderive fingerprints from the original base model. To fairly characterize the\ntrade-off between robustness and transferability, we propose Uniqueness Score,\na comprehensive metric that measures the difference between robustness and\ntransferability, which also serves as an indicator to the false alarm problem.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 21:48:23 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Wang", "Siyue", ""], ["Wang", "Xiao", ""], ["Chen", "Pin-Yu", ""], ["Zhao", "Pu", ""], ["Lin", "Xue", ""]]}, {"id": "2105.07082", "submitter": "Zehao Dong", "authors": "Zehao Dong, Heming Zhang, Yixin Chen, Fuhai Li", "title": "Interpretable Drug Synergy Prediction with Graph Neural Networks for\n  Human-AI Collaboration in Healthcare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate molecular mechanisms of resistant or sensitive response of\ncancer drug combination therapies in an inductive and interpretable manner.\nThough deep learning algorithms are widely used in the drug synergy prediction\nproblem, it is still an open problem to formulate the prediction model with\nbiological meaning to investigate the mysterious mechanisms of synergy (MoS)\nfor the human-AI collaboration in healthcare systems. To address the\nchallenges, we propose a deep graph neural network, IDSP (Interpretable Deep\nSignaling Pathways), to incorporate the gene-gene as well as gene-drug\nregulatory relationships in synergic drug combination predictions. IDSP\nautomatically learns weights of edges based on the gene and drug node\nrelations, i.e., signaling interactions, by a multi-layer perceptron (MLP) and\naggregates information in an inductive manner. The proposed architecture\ngenerates interpretable drug synergy prediction by detecting important\nsignaling interactions, and can be implemented when the underlying molecular\nmechanism encounters unseen genes or signaling pathways. We test IDWSP on\nsignaling networks formulated by genes from 46 core cancer signaling pathways\nand drug combinations from NCI ALMANAC drug combination screening data. The\nexperimental results demonstrated that 1) IDSP can learn from the underlying\nmolecular mechanism to make prediction without additional drug chemical\ninformation while achieving highly comparable performance with current\nstate-of-art methods; 2) IDSP show superior generality and flexibility to\nimplement the synergy prediction task on both transductive tasks and inductive\ntasks. 3) IDSP can generate interpretable results by detecting different\nsalient signaling patterns (i.e. MoS) for different cell lines.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 22:20:29 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Dong", "Zehao", ""], ["Zhang", "Heming", ""], ["Chen", "Yixin", ""], ["Li", "Fuhai", ""]]}, {"id": "2105.07091", "submitter": "Sydney Katz", "authors": "Sydney M. Katz, Anthony L. Corso, Christopher A. Strong, Mykel J.\n  Kochenderfer", "title": "Verification of Image-based Neural Network Controllers Using Generative\n  Models", "comments": "10 pages, 12 figures, presented at the 2021 AIAA Digital Avionics\n  Systems Conference (DASC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are often used to process information from image-based\nsensors to produce control actions. While they are effective for this task, the\ncomplex nature of neural networks makes their output difficult to verify and\npredict, limiting their use in safety-critical systems. For this reason, recent\nwork has focused on combining techniques in formal methods and reachability\nanalysis to obtain guarantees on the closed-loop performance of neural network\ncontrollers. However, these techniques do not scale to the high-dimensional and\ncomplicated input space of image-based neural network controllers. In this\nwork, we propose a method to address these challenges by training a generative\nadversarial network (GAN) to map states to plausible input images. By\nconcatenating the generator network with the control network, we obtain a\nnetwork with a low-dimensional input space. This insight allows us to use\nexisting closed-loop verification tools to obtain formal guarantees on the\nperformance of image-based controllers. We apply our approach to provide safety\nguarantees for an image-based neural network controller for an autonomous\naircraft taxi problem. We guarantee that the controller will keep the aircraft\non the runway and guide the aircraft towards the center of the runway. The\nguarantees we provide are with respect to the set of input images modeled by\nour generator network, so we provide a recall metric to evaluate how well the\ngenerator captures the space of plausible images.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 23:18:05 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Katz", "Sydney M.", ""], ["Corso", "Anthony L.", ""], ["Strong", "Christopher A.", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "2105.07107", "submitter": "Sushil Thapa", "authors": "Sunil Thulasidasan, Sushil Thapa, Sayera Dhaubhadel, Gopinath\n  Chennupati, Tanmoy Bhattacharya, Jeff Bilmes", "title": "An Effective Baseline for Robustness to Distributional Shift", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Refraining from confidently predicting when faced with categories of inputs\ndifferent from those seen during training is an important requirement for the\nsafe deployment of deep learning systems. While simple to state, this has been\na particularly challenging problem in deep learning, where models often end up\nmaking overconfident predictions in such situations. In this work we present a\nsimple, but highly effective approach to deal with out-of-distribution\ndetection that uses the principle of abstention: when encountering a sample\nfrom an unseen class, the desired behavior is to abstain from predicting. Our\napproach uses a network with an extra abstention class and is trained on a\ndataset that is augmented with an uncurated set that consists of a large number\nof out-of-distribution (OoD) samples that are assigned the label of the\nabstention class; the model is then trained to learn an effective discriminator\nbetween in and out-of-distribution samples. We compare this relatively simple\napproach against a wide variety of more complex methods that have been proposed\nboth for out-of-distribution detection as well as uncertainty modeling in deep\nlearning, and empirically demonstrate its effectiveness on a wide variety of of\nbenchmarks and deep architectures for image recognition and text\nclassification, often outperforming existing approaches by significant margins.\nGiven the simplicity and effectiveness of this method, we propose that this\napproach be used as a new additional baseline for future work in this domain.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 00:46:11 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Thulasidasan", "Sunil", ""], ["Thapa", "Sushil", ""], ["Dhaubhadel", "Sayera", ""], ["Chennupati", "Gopinath", ""], ["Bhattacharya", "Tanmoy", ""], ["Bilmes", "Jeff", ""]]}, {"id": "2105.07111", "submitter": "Zahra Dasht Bozorgi", "authors": "Zahra Dasht Bozorgi, Irene Teinemaa, Marlon Dumas, Marcello La Rosa", "title": "Prescriptive Process Monitoring for Cost-Aware Cycle Time Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reducing cycle time is a recurrent concern in the field of business process\nmanagement. Depending on the process, various interventions may be triggered to\nreduce the cycle time of a case, for example, using a faster shipping service\nin an order-to-delivery process or giving a phone call to a customer to obtain\nmissing information rather than waiting passively. Each of these interventions\ncomes with a cost. This paper tackles the problem of determining if and when to\ntrigger a time-reducing intervention in a way that maximizes the total net\ngain. The paper proposes a prescriptive process monitoring method that uses\northogonal random forest models to estimate the causal effect of triggering a\ntime-reducing intervention for each ongoing case of a process. Based on this\ncausal effect estimate, the method triggers interventions according to a\nuser-defined policy. The method is evaluated on two real-life logs.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 01:19:04 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Bozorgi", "Zahra Dasht", ""], ["Teinemaa", "Irene", ""], ["Dumas", "Marlon", ""], ["La Rosa", "Marcello", ""]]}, {"id": "2105.07131", "submitter": "Reza Sameni", "authors": "Amir-Hossein Kiamarzi, Pezhman Torabi, Reza Sameni", "title": "Hardware Synthesis of State-Space Equations; Application to FPGA\n  Implementation of Shallow and Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, shallow and deep Neural Networks (NNs) have vast applications\nincluding biomedical engineering, image processing, computer vision, and speech\nrecognition. Many researchers have developed hardware accelerators including\nfield-programmable gate arrays (FPGAs) for implementing high-performance and\nenergy efficient NNs. Apparently, the hardware architecture design process is\nspecific and time-consuming for each NN. Therefore, a systematic way to design,\nimplement and optimize NNs is highly demanded. The paper presents a systematic\napproach to implement state-space models in register transfer level (RTL), with\nspecial interest for NN implementation. The proposed design flow is based on\nthe iterative nature of state-space models and the analogy between state-space\nformulations and finite-state machines. The method can be used in\nlinear/nonlinear and time-varying/time-invariant systems. It can also be used\nto implement either intrinsically iterative systems (widely used in various\ndomains such as signal processing, numerical analysis, computer arithmetic, and\ncontrol engineering), or systems that could be rewritten in equivalent\niterative forms. The implementation of recurrent NNs such as long short-term\nmemory (LSTM) NNs, which have intrinsic state-space forms, are another major\napplications for this framework. As a case study, it is shown that state-space\nsystems can be used for the systematic implementation and optimization of NNs\n(as nonlinear and time-varying dynamic systems). An RTL code generating\nsoftware is also provided online, which simplifies the automatic generation of\nNNs of arbitrary size.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 04:00:28 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kiamarzi", "Amir-Hossein", ""], ["Torabi", "Pezhman", ""], ["Sameni", "Reza", ""]]}, {"id": "2105.07135", "submitter": "Anant Baijal", "authors": "Anant Baijal, Vivek Agarwal and Danny Hyun", "title": "Analyzing Images for Music Recommendation", "comments": "IEEE International Conference on Consumer Electronics (IEEE ICCE\n  2021)", "journal-ref": null, "doi": "10.1109/ICCE50685.2021.9427619", "report-no": null, "categories": "cs.MM cs.AI cs.SD eess.AS eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiencing images with suitable music can greatly enrich the overall user\nexperience. The proposed image analysis method treats an artwork image\ndifferently from a photograph image. Automatic image classification is\nperformed using deep-learning based models. An illustrative analysis showcasing\nthe ability of our deep-models to inherently learn and utilize perceptually\nrelevant features when classifying artworks is also presented. The Mean Opinion\nScore (MOS) obtained from subjective assessments of the respective image and\nrecommended music pairs supports the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 04:14:47 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Baijal", "Anant", ""], ["Agarwal", "Vivek", ""], ["Hyun", "Danny", ""]]}, {"id": "2105.07168", "submitter": "Masayoshi Mase", "authors": "Masayoshi Mase, Art B. Owen, Benjamin B. Seiler", "title": "Cohort Shapley value for algorithmic fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI econ.EM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cohort Shapley value is a model-free method of variable importance grounded\nin game theory that does not use any unobserved and potentially impossible\nfeature combinations. We use it to evaluate algorithmic fairness, using the\nwell known COMPAS recidivism data as our example. This approach allows one to\nidentify for each individual in a data set the extent to which they were\nadversely or beneficially affected by their value of a protected attribute such\nas their race. The method can do this even if race was not one of the original\npredictors and even if it does not have access to a proprietary algorithm that\nhas made the predictions. The grounding in game theory lets us define aggregate\nvariable importance for a data set consistently with its per subject\ndefinitions. We can investigate variable importance for multiple quantities of\ninterest in the fairness literature including false positive predictions.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 08:02:18 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Mase", "Masayoshi", ""], ["Owen", "Art B.", ""], ["Seiler", "Benjamin B.", ""]]}, {"id": "2105.07174", "submitter": "Saikat Dutta", "authors": "Saikat Dutta, Sourya Dipta Das, Nisarg A. Shah, Anil Kumar Tiwari", "title": "Stacked Deep Multi-Scale Hierarchical Network for Fast Bokeh Effect\n  Rendering from a Single Image", "comments": "Accepted to MAI workshop, CVPR 2021. Code and models:\n  https://github.com/saikatdutta/Stacked_DMSHN_bokeh", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Bokeh Effect is one of the most desirable effects in photography for\nrendering artistic and aesthetic photos. Usually, it requires a DSLR camera\nwith different aperture and shutter settings and certain photography skills to\ngenerate this effect. In smartphones, computational methods and additional\nsensors are used to overcome the physical lens and sensor limitations to\nachieve such effect. Most of the existing methods utilized additional sensor's\ndata or pretrained network for fine depth estimation of the scene and sometimes\nuse portrait segmentation pretrained network module to segment salient objects\nin the image. Because of these reasons, networks have many parameters, become\nruntime intensive and unable to run in mid-range devices. In this paper, we\nused an end-to-end Deep Multi-Scale Hierarchical Network (DMSHN) model for\ndirect Bokeh effect rendering of images captured from the monocular camera. To\nfurther improve the perceptual quality of such effect, a stacked model\nconsisting of two DMSHN modules is also proposed. Our model does not rely on\nany pretrained network module for Monocular Depth Estimation or Saliency\nDetection, thus significantly reducing the size of model and run time. Stacked\nDMSHN achieves state-of-the-art results on a large scale EBB! dataset with\naround 6x less runtime compared to the current state-of-the-art model in\nprocessing HD quality images.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 08:45:20 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Dutta", "Saikat", ""], ["Das", "Sourya Dipta", ""], ["Shah", "Nisarg A.", ""], ["Tiwari", "Anil Kumar", ""]]}, {"id": "2105.07189", "submitter": "Peter Kokol PhD", "authors": "Helena Bla\\v{z}un Vo\\v{s}ner, Peter Kokol, Jernej Zavr\\v{s}nik, Danica\n  \\v{Z}eleznik", "title": "Content Analysis Application in Nursing: A Synthetic Knowledge Synthesis\n  Meta-Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Theoretical issues: With the explosive growth in the research literature\nproduction, the need for new approaches to structure knowledge emerged. Method:\nSynthetic content analysis was used in our meta-study. Results and discussion:\nOur meta-study showed that content analysis is frequently used in nursing\nresearch in a very wide spectrum of applications. The trend of its use is\npositive and it is used globally in a variety of research settings. The\nsynthetic content analysis used in our study showed to be a very helpful tool\nin performing knowledge synthesis, replacing many of the routine activities of\nconventional synthesis with automated activities this making such studies more\neconomically viable and easier to perform.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 09:48:46 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Vo\u0161ner", "Helena Bla\u017eun", ""], ["Kokol", "Peter", ""], ["Zavr\u0161nik", "Jernej", ""], ["\u017deleznik", "Danica", ""]]}, {"id": "2105.07190", "submitter": "Gesina Schwalbe", "authors": "Gesina Schwalbe, Bettina Finzel", "title": "XAI Method Properties: A (Meta-)study", "comments": "37 pages, 2 figures, submitted to Data Mining and Knowledge Discovery", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the meantime, a wide variety of terminologies, motivations, approaches and\nevaluation criteria have been developed within the scope of research on\nexplainable artificial intelligence (XAI). Many taxonomies can be found in the\nliterature, each with a different focus, but also showing many points of\noverlap. In this paper, we summarize the most cited and current taxonomies in a\nmeta-analysis in order to highlight the essential aspects of the\nstate-of-the-art in XAI. We also present and add terminologies as well as\nconcepts from a large number of survey articles on the topic. Last but not\nleast, we illustrate concepts from the higher-level taxonomy with more than 50\nexample methods, which we categorize accordingly, thus providing a wide-ranging\noverview of aspects of XAI and paving the way for use case-appropriate as well\nas context-specific subsequent research.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 09:52:00 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Schwalbe", "Gesina", ""], ["Finzel", "Bettina", ""]]}, {"id": "2105.07224", "submitter": "Mohammad Arif Ul Alam", "authors": "Vaishali Mahipal, Mohammad Arif Ul Alam", "title": "Heterogeneous Causal Effect of Polysubstance Usage on Drug Overdose", "comments": "Submitted to EMBS BHI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a system to estimate heterogeneous concurrent drug\nusage effects on overdose estimation, that consists of efficient co-variate\nselection, sub-group selection, generation of and heterogeneous causal effect\nestimation. Although, there has been several association studies have been\nproposed in the state-of-art methods, heterogeneous causal effects have never\nbeen studied in concurrent drug usage and drug overdose problem. We apply our\nframework to answer a critical question, \"can concurrent usage of\nbenzodiazepines and opioids has heterogeneous causal effects on opioid overdose\nepidemic?\" Using Truven MarketScan claim data collected from 2001 to 2013 have\nshown significant promise of our proposed framework's efficacy. Our efficient\ncausal inference model estimated that the causal effect is higher (19%) than\nthe regression studies (15%) to estimate the risks associated with the\nconcurrent usage of opioid and benzodiazepines on opioid overdose.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 13:52:20 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Mahipal", "Vaishali", ""], ["Alam", "Mohammad Arif Ul", ""]]}, {"id": "2105.07239", "submitter": "Zhizhong Huang", "authors": "Zhizhong Huang, Shouzhen Chen, Junping Zhang, Hongming Shan", "title": "AgeFlow: Conditional Age Progression and Regression with Normalizing\n  Flows", "comments": "IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Age progression and regression aim to synthesize photorealistic appearance of\na given face image with aging and rejuvenation effects, respectively. Existing\ngenerative adversarial networks (GANs) based methods suffer from the following\nthree major issues: 1) unstable training introducing strong ghost artifacts in\nthe generated faces, 2) unpaired training leading to unexpected changes in\nfacial attributes such as genders and races, and 3) non-bijective age mappings\nincreasing the uncertainty in the face transformation. To overcome these\nissues, this paper proposes a novel framework, termed AgeFlow, to integrate the\nadvantages of both flow-based models and GANs. The proposed AgeFlow contains\nthree parts: an encoder that maps a given face to a latent space through an\ninvertible neural network, a novel invertible conditional translation module\n(ICTM) that translates the source latent vector to target one, and a decoder\nthat reconstructs the generated face from the target latent vector using the\nsame encoder network; all parts are invertible achieving bijective age\nmappings. The novelties of ICTM are two-fold. First, we propose an\nattribute-aware knowledge distillation to learn the manipulation direction of\nage progression while keeping other unrelated attributes unchanged, alleviating\nunexpected changes in facial attributes. Second, we propose to use GANs in the\nlatent space to ensure the learned latent vector indistinguishable from the\nreal ones, which is much easier than traditional use of GANs in the image\ndomain. Experimental results demonstrate superior performance over existing\nGANs-based methods on two benchmarked datasets. The source code is available at\nhttps://github.com/Hzzone/AgeFlow.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 15:02:07 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Huang", "Zhizhong", ""], ["Chen", "Shouzhen", ""], ["Zhang", "Junping", ""], ["Shan", "Hongming", ""]]}, {"id": "2105.07245", "submitter": "Zifan Chen", "authors": "ZiFan Chen, Xin Qin, Chao Yang, Li Zhang", "title": "Composite Localization for Human Pose Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The existing human pose estimation methods are confronted with inaccurate\nlong-distance regression or high computational cost due to the complex learning\nobjectives. This work proposes a novel deep learning framework for human pose\nestimation called composite localization to divide the complex learning\nobjective into two simpler ones: a sparse heatmap to find the keypoint's\napproximate location and two short-distance offsetmaps to obtain its final\nprecise coordinates. To realize the framework, we construct two types of\ncomposite localization networks: CLNet-ResNet and CLNet-Hourglass. We evaluate\nthe networks on three benchmark datasets, including the Leeds Sports Pose\ndataset, the MPII Human Pose dataset, and the COCO keypoints detection dataset.\nThe experimental results show that our CLNet-ResNet50 outperforms\nSimpleBaseline by 1.14% with about 1/2 GFLOPs. Our CLNet-Hourglass outperforms\nthe original stacked-hourglass by 4.45% on COCO.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 15:22:27 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Chen", "ZiFan", ""], ["Qin", "Xin", ""], ["Yang", "Chao", ""], ["Zhang", "Li", ""]]}, {"id": "2105.07253", "submitter": "Zhenghai Xue", "authors": "Zhenghai Xue, Xu-Hui Liu, Jing-Cheng Pang, Shengyi Jiang, Feng Xu,\n  Yang Yu", "title": "Regret Minimization Experience Replay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In reinforcement learning, experience replay stores past samples for further\nreuse. Prioritized sampling is a promising technique to better utilize these\nsamples. Previous criteria of prioritization include TD error, recentness and\ncorrective feedback, which are mostly heuristically designed. In this work, we\nstart from the regret minimization objective, and obtain an optimal\nprioritization strategy for Bellman update that can directly maximize the\nreturn of the policy. The theory suggests that data with higher hindsight TD\nerror, better on-policiness and more accurate Q value should be assigned with\nhigher weights during sampling. Thus most previous criteria only consider this\nstrategy partially. We not only provide theoretical justifications for previous\ncriteria, but also propose two new methods to compute the prioritization\nweight, namely ReMERN and ReMERT. ReMERN learns an error network, while ReMERT\nexploits the temporal ordering of states. Both methods outperform previous\nprioritized sampling algorithms in challenging RL benchmarks, including MuJoCo,\nAtari and Meta-World.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 16:08:45 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 01:34:37 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Xue", "Zhenghai", ""], ["Liu", "Xu-Hui", ""], ["Pang", "Jing-Cheng", ""], ["Jiang", "Shengyi", ""], ["Xu", "Feng", ""], ["Yu", "Yang", ""]]}, {"id": "2105.07263", "submitter": "Nicholas Andrews", "authors": "Aleem Khan, Elizabeth Fleming, Noah Schofield, Marcus Bishop, Nicholas\n  Andrews", "title": "A Deep Metric Learning Approach to Account Linking", "comments": "13 pages; to be published in NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of linking social media accounts that belong to the same\nauthor in an automated fashion on the basis of the content and metadata of\ntheir corresponding document streams. We focus on learning an embedding that\nmaps variable-sized samples of user activity -- ranging from single posts to\nentire months of activity -- to a vector space, where samples by the same\nauthor map to nearby points. The approach does not require human-annotated data\nfor training purposes, which allows us to leverage large amounts of social\nmedia content. The proposed model outperforms several competitive baselines\nunder a novel evaluation framework modeled after established recognition\nbenchmarks in other domains. Our method achieves high linking accuracy, even\nwith small samples from accounts not seen at training time, a prerequisite for\npractical applications of the proposed linking framework.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 17:06:31 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Khan", "Aleem", ""], ["Fleming", "Elizabeth", ""], ["Schofield", "Noah", ""], ["Bishop", "Marcus", ""], ["Andrews", "Nicholas", ""]]}, {"id": "2105.07270", "submitter": "Marcel Wever", "authors": "Marie-Luis Merten, Marcel Wever, Michaela Geierhos, Doris Tophinke,\n  Eyke H\\\"ullermeier", "title": "Annotation Uncertainty in the Context of Grammatical Change", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper elaborates on the notion of uncertainty in the context of\nannotation in large text corpora, specifically focusing on (but not limited to)\nhistorical languages. Such uncertainty might be due to inherent properties of\nthe language, for example, linguistic ambiguity and overlapping categories of\nlinguistic description, but could also be caused by lacking annotation\nexpertise. By examining annotation uncertainty in more detail, we identify the\nsources and deepen our understanding of the nature and different types of\nuncertainty encountered in daily annotation practice. Moreover, some practical\nimplications of our theoretical findings are also discussed. Last but not\nleast, this article can be seen as an attempt to reconcile the perspectives of\nthe main scientific disciplines involved in corpus projects, linguistics and\ncomputer science, to develop a unified view and to highlight the potential\nsynergies between these disciplines.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 17:45:29 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 06:56:43 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Merten", "Marie-Luis", ""], ["Wever", "Marcel", ""], ["Geierhos", "Michaela", ""], ["Tophinke", "Doris", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "2105.07284", "submitter": "Joseph Monaco", "authors": "Joseph D. Monaco, Kanaka Rajan, Grace M. Hwang", "title": "A brain basis of dynamical intelligence for AI and computational\n  neuroscience", "comments": "Perspective article: 24 pages, 3 figures, 1 display box", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The deep neural nets of modern artificial intelligence (AI) have not achieved\ndefining features of biological intelligence, including abstraction, causal\nlearning, and energy-efficiency. While scaling to larger models has delivered\nperformance improvements for current applications, more brain-like capacities\nmay demand new theories, models, and methods for designing artificial learning\nsystems. Here, we argue that this opportunity to reassess insights from the\nbrain should stimulate cooperation between AI research and theory-driven\ncomputational neuroscience (CN). To motivate a brain basis of neural\ncomputation, we present a dynamical view of intelligence from which we\nelaborate concepts of sparsity in network structure, temporal dynamics, and\ninteractive learning. In particular, we suggest that temporal dynamics, as\nexpressed through neural synchrony, nested oscillations, and flexible\nsequences, provide a rich computational layer for reading and updating\nhierarchical models distributed in long-term memory networks. Moreover,\nembracing agent-centered paradigms in AI and CN will accelerate our\nunderstanding of the complex dynamics and behaviors that build useful world\nmodels. A convergence of AI/CN theories and objectives will reveal dynamical\nprinciples of intelligence for brains and engineered learning systems. This\narticle was inspired by our symposium on dynamical neuroscience and machine\nlearning at the 6th Annual US/NIH BRAIN Initiative Investigators Meeting.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 19:49:32 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 13:29:51 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Monaco", "Joseph D.", ""], ["Rajan", "Kanaka", ""], ["Hwang", "Grace M.", ""]]}, {"id": "2105.07299", "submitter": "Eyvind Niklasson", "authors": "Alexander Mordvintsev, Eyvind Niklasson, Ettore Randazzo", "title": "Texture Generation with Neural Cellular Automata", "comments": "AI for Content Creation Workshop, CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.GR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Neural Cellular Automata (NCA) have shown a remarkable ability to learn the\nrequired rules to \"grow\" images, classify morphologies, segment images, as well\nas to do general computation such as path-finding. We believe the inductive\nprior they introduce lends itself to the generation of textures. Textures in\nthe natural world are often generated by variants of locally interacting\nreaction-diffusion systems. Human-made textures are likewise often generated in\na local manner (textile weaving, for instance) or using rules with local\ndependencies (regular grids or geometric patterns). We demonstrate learning a\ntexture generator from a single template image, with the generation method\nbeing embarrassingly parallel, exhibiting quick convergence and high fidelity\nof output, and requiring only some minimal assumptions around the underlying\nstate manifold. Furthermore, we investigate properties of the learned models\nthat are both useful and interesting, such as non-stationary dynamics and an\ninherent robustness to damage. Finally, we make qualitative claims that the\nbehaviour exhibited by the NCA model is a learned, distributed, local algorithm\nto generate a texture, setting our method apart from existing work on texture\ngeneration. We discuss the advantages of such a paradigm.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 22:05:46 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Mordvintsev", "Alexander", ""], ["Niklasson", "Eyvind", ""], ["Randazzo", "Ettore", ""]]}, {"id": "2105.07308", "submitter": "Alexander Ororbia", "authors": "Alexander Ororbia, M. A. Kelly", "title": "Towards a Predictive Processing Implementation of the Common Model of\n  Cognition", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present a cognitive architecture that is built from\npowerful yet simple neural models. Specifically, we describe an implementation\nof the common model of cognition grounded in neural generative coding and\nholographic associative memory. The proposed system creates the groundwork for\ndeveloping agents that learn continually from diverse tasks as well as model\nhuman performance at larger scales than what is possible with existant\ncognitive architectures.\n", "versions": [{"version": "v1", "created": "Sat, 15 May 2021 22:55:23 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 21:14:26 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Ororbia", "Alexander", ""], ["Kelly", "M. A.", ""]]}, {"id": "2105.07334", "submitter": "Kenneth Co", "authors": "Kenneth T. Co, Luis Mu\\~noz-Gonz\\'alez, Leslie Kanthan, Emil C. Lupu", "title": "Real-time Detection of Practical Universal Adversarial Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Universal Adversarial Perturbations (UAPs) are a prominent class of\nadversarial examples that exploit the systemic vulnerabilities and enable\nphysically realizable and robust attacks against Deep Neural Networks (DNNs).\nUAPs generalize across many different inputs; this leads to realistic and\neffective attacks that can be applied at scale. In this paper we propose\nHyperNeuron, an efficient and scalable algorithm that allows for the real-time\ndetection of UAPs by identifying suspicious neuron hyper-activations. Our\nresults show the effectiveness of HyperNeuron on multiple tasks (image\nclassification, object detection), against a wide variety of universal attacks,\nand in realistic scenarios, like perceptual ad-blocking and adversarial\npatches. HyperNeuron is able to simultaneously detect both adversarial mask and\npatch UAPs with comparable or better performance than existing UAP defenses\nwhilst introducing a significantly reduced latency of only 0.86 milliseconds\nper image. This suggests that many realistic and practical universal attacks\ncan be reliably mitigated in real-time, which shows promise for the robust\ndeployment of machine learning systems.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 03:01:29 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 23:33:20 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Co", "Kenneth T.", ""], ["Mu\u00f1oz-Gonz\u00e1lez", "Luis", ""], ["Kanthan", "Leslie", ""], ["Lupu", "Emil C.", ""]]}, {"id": "2105.07342", "submitter": "Lirong Wu", "authors": "Lirong Wu, Haitao Lin, Zhangyang Gao, Cheng Tan, Stan.Z.Li", "title": "Self-supervised on Graphs: Contrastive, Generative,or Predictive", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning on graphs has recently achieved remarkable success on a variety\nof tasks while such success relies heavily on the massive and carefully labeled\ndata. However, precise annotations are generally very expensive and\ntime-consuming. To address this problem, self-supervised learning (SSL) is\nemerging as a new paradigm for extracting informative knowledge through\nwell-designed pretext tasks without relying on manual labels. In this survey,\nwe extend the concept of SSL, which first emerged in the fields of computer\nvision and natural language processing, to present a timely and comprehensive\nreview of the existing SSL techniques for graph data. Specifically, we divide\nexisting graph SSL methods into three categories: contrastive, generative, and\npredictive. More importantly, unlike many other surveys that only provide a\nhigh-level description of published research, we present an additional\nmathematical summary of the existing works in a unified framework. Furthermore,\nto facilitate methodological development and empirical comparisons, we also\nsummarize the commonly used datasets, evaluation metrics, downstream tasks, and\nopen-source implementations of various algorithms. Finally, we discuss the\ntechnical challenges and potential future directions for improving graph\nself-supervised learning.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 03:30:03 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 14:03:20 GMT"}, {"version": "v3", "created": "Mon, 21 Jun 2021 08:49:48 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Wu", "Lirong", ""], ["Lin", "Haitao", ""], ["Gao", "Zhangyang", ""], ["Tan", "Cheng", ""], ["Li", "Stan. Z.", ""]]}, {"id": "2105.07346", "submitter": "Ziyu Ye", "authors": "Ziyu Ye, Yuxin Chen and Haitao Zheng", "title": "Understanding the Effect of Bias in Deep Anomaly Detection", "comments": "Accepted at IJCAI '21. Codes available on\n  github.com/ZIYU-DEEP/Understanding-Bias-in-Deep-Anomaly-Detection-PyTorch", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anomaly detection presents a unique challenge in machine learning, due to the\nscarcity of labeled anomaly data. Recent work attempts to mitigate such\nproblems by augmenting training of deep anomaly detection models with\nadditional labeled anomaly samples. However, the labeled data often does not\nalign with the target distribution and introduces harmful bias to the trained\nmodel. In this paper, we aim to understand the effect of a biased anomaly set\non anomaly detection. Concretely, we view anomaly detection as a supervised\nlearning task where the objective is to optimize the recall at a given false\npositive rate. We formally study the relative scoring bias of an anomaly\ndetector, defined as the difference in performance with respect to a baseline\nanomaly detector. We establish the first finite sample rates for estimating the\nrelative scoring bias for deep anomaly detection, and empirically validate our\ntheoretical results on both synthetic and real-world datasets. We also provide\nan extensive empirical study on how a biased training anomaly set affects the\nanomaly score function and therefore the detection performance on different\nanomaly classes. Our study demonstrates scenarios in which the biased anomaly\nset can be useful or problematic, and provides a solid benchmark for future\nresearch.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 03:55:02 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Ye", "Ziyu", ""], ["Chen", "Yuxin", ""], ["Zheng", "Haitao", ""]]}, {"id": "2105.07348", "submitter": "Dandan Zhang", "authors": "Dandan Zhang, Yu Zheng, Qiang Li, Lei Wei, Dongsheng Zhang, Zhengyou\n  Zhang", "title": "Explainable Hierarchical Imitation Learning for Robotic Drink Pouring", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accurately pour drinks into various containers is an essential skill for\nservice robots. However, drink pouring is a dynamic process and difficult to\nmodel. Traditional deep imitation learning techniques for implementing\nautonomous robotic pouring have an inherent black-box effect and require a\nlarge amount of demonstration data for model training. To address these issues,\nan Explainable Hierarchical Imitation Learning (EHIL) method is proposed in\nthis paper such that a robot can learn high-level general knowledge and execute\nlow-level actions across multiple drink pouring scenarios. Moreover, with EHIL,\na logical graph can be constructed for task execution, through which the\ndecision-making process for action generation can be made explainable to users\nand the causes of failure can be traced out. Based on the logical graph, the\nframework is manipulable to achieve different targets while the adaptability to\nunseen scenarios can be achieved in an explainable manner. A series of\nexperiments have been conducted to verify the effectiveness of the proposed\nmethod. Results indicate that EHIL outperforms the traditional behavior cloning\nmethod in terms of success rate, adaptability, manipulability and\nexplainability.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 04:30:53 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Zhang", "Dandan", ""], ["Zheng", "Yu", ""], ["Li", "Qiang", ""], ["Wei", "Lei", ""], ["Zhang", "Dongsheng", ""], ["Zhang", "Zhengyou", ""]]}, {"id": "2105.07351", "submitter": "Xianyuan Zhan", "authors": "Xianyuan Zhan, Xiangyu Zhu, Haoran Xu", "title": "Model-Based Offline Planning with Trajectory Pruning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline reinforcement learning (RL) enables learning policies using\npre-collected datasets without environment interaction, which provides a\npromising direction to make RL useable in real-world systems. Although recent\noffline RL studies have achieved much progress, existing methods still face\nmany practical challenges in real-world system control tasks, such as\ncomputational restriction during agent training and the requirement of extra\ncontrol flexibility. Model-based planning framework provides an attractive\nsolution for such tasks. However, most model-based planning algorithms are not\ndesigned for offline settings. Simply combining the ingredients of offline RL\nwith existing methods either provides over-restrictive planning or leads to\ninferior performance. We propose a new light-weighted model-based offline\nplanning framework, namely MOPP, which tackles the dilemma between the\nrestrictions of offline learning and high-performance planning. MOPP encourages\nmore aggressive trajectory rollout guided by the behavior policy learned from\ndata, and prunes out problematic trajectories to avoid potential\nout-of-distribution samples. Experimental results show that MOPP provides\ncompetitive performance compared with existing model-based offline planning and\nRL approaches, and allows easy adaptation to varying objectives and extra\nconstraints.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 05:00:54 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Zhan", "Xianyuan", ""], ["Zhu", "Xiangyu", ""], ["Xu", "Haoran", ""]]}, {"id": "2105.07354", "submitter": "Catarina Moreira", "authors": "Catarina Moreira and Jose Acacio de Barros", "title": "Order Effects in Bayesian Updates", "comments": null, "journal-ref": "In Proceedings of the 43rd Annual Meeting of the Cognitive Science\n  Society, 2021", "doi": null, "report-no": null, "categories": "cs.AI math.PR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Order effects occur when judgments about a hypothesis's probability given a\nsequence of information do not equal the probability of the same hypothesis\nwhen the information is reversed. Different experiments have been performed in\nthe literature that supports evidence of order effects.\n  We proposed a Bayesian update model for order effects where each question can\nbe thought of as a mini-experiment where the respondents reflect on their\nbeliefs. We showed that order effects appear, and they have a simple cognitive\nexplanation: the respondent's prior belief that two questions are correlated.\n  The proposed Bayesian model allows us to make several predictions: (1) we\nfound certain conditions on the priors that limit the existence of order\neffects; (2) we show that, for our model, the QQ equality is not necessarily\nsatisfied (due to symmetry assumptions); and (3) the proposed Bayesian model\nhas the advantage of possessing fewer parameters than its quantum counterpart.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 05:24:04 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Moreira", "Catarina", ""], ["de Barros", "Jose Acacio", ""]]}, {"id": "2105.07377", "submitter": "Lei Chen", "authors": "Lei Chen, Le Wu, Kun Zhang, Richang Hong, Meng Wang", "title": "Set2setRank: Collaborative Set to Set Ranking for Implicit Feedback\n  based Recommendation", "comments": "The paper is accepted by SIGIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As users often express their preferences with binary behavior data~(implicit\nfeedback), such as clicking items or buying products, implicit feedback based\nCollaborative Filtering~(CF) models predict the top ranked items a user might\nlike by leveraging implicit user-item interaction data. For each user, the\nimplicit feedback is divided into two sets: an observed item set with limited\nobserved behaviors, and a large unobserved item set that is mixed with negative\nitem behaviors and unknown behaviors. Given any user preference prediction\nmodel, researchers either designed ranking based optimization goals or relied\non negative item mining techniques for better optimization. Despite the\nperformance gain of these implicit feedback based models, the recommendation\nresults are still far from satisfactory due to the sparsity of the observed\nitem set for each user. To this end, in this paper, we explore the unique\ncharacteristics of the implicit feedback and propose Set2setRank framework for\nrecommendation. The optimization criteria of Set2setRank are two folds: First,\nwe design an item to an item set comparison that encourages each observed item\nfrom the sampled observed set is ranked higher than any unobserved item from\nthe sampled unobserved set. Second, we model set level comparison that\nencourages a margin between the distance summarized from the observed item set\nand the most \"hard\" unobserved item from the sampled negative set. Further, an\nadaptive sampling technique is designed to implement these two goals. We have\nto note that our proposed framework is model-agnostic and can be easily applied\nto most recommendation prediction approaches, and is time efficient in\npractice. Finally, extensive experiments on three real-world datasets\ndemonstrate the superiority of our proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 08:06:22 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 08:00:02 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Chen", "Lei", ""], ["Wu", "Le", ""], ["Zhang", "Kun", ""], ["Hong", "Richang", ""], ["Wang", "Meng", ""]]}, {"id": "2105.07382", "submitter": "Tianxiang Zhan", "authors": "Tianxiang Zhan, Yuanpeng He, Hanwen Li, Fuyuan Xiao", "title": "Uncertainty Measurement of Basic Probability Assignment Integrity Based\n  on Approximate Entropy in Evidence Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evidence theory is that the extension of probability can better deal with\nunknowns and inaccurate information. Uncertainty measurement plays a vital role\nin both evidence theory and probability theory. Approximate Entropy (ApEn) is\nproposed by Pincus to describe the irregularities of complex systems. The more\nirregular the time series, the greater the approximate entropy. The ApEn of the\nnetwork represents the ability of a network to generate new nodes, or the\npossibility of undiscovered nodes. Through the association of network\ncharacteristics and basic probability assignment (BPA) , a measure of the\nuncertainty of BPA regarding completeness can be obtained. The main\ncontribution of paper is to define the integrity of the basic probability\nassignment then the approximate entropy of the BPA is proposed to measure the\nuncertainty of the integrity of the BPA. The proposed method is based on the\nlogical network structure to calculate the uncertainty of BPA in evidence\ntheory. The uncertainty based on the proposed method represents the uncertainty\nof integrity of BPA and contributes to the identification of the credibility of\nBPA.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 08:41:38 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 01:01:59 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Zhan", "Tianxiang", ""], ["He", "Yuanpeng", ""], ["Li", "Hanwen", ""], ["Xiao", "Fuyuan", ""]]}, {"id": "2105.07405", "submitter": "Feng Huang", "authors": "Feng Huang, Ming Cao, and Long Wang", "title": "Optimal control of robust team stochastic games", "comments": "under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.GT cs.MA cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stochastic dynamic environments, team stochastic games have emerged as a\nversatile paradigm for studying sequential decision-making problems of fully\ncooperative multi-agent systems. However, the optimality of the derived\npolicies is usually sensitive to the model parameters, which are typically\nunknown and required to be estimated from noisy data in practice. To mitigate\nthe sensitivity of the optimal policy to these uncertain parameters, in this\npaper, we propose a model of \"robust\" team stochastic games, where players\nutilize a robust optimization approach to make decisions. This model extends\nteam stochastic games to the scenario of incomplete information and meanwhile\nprovides an alternative solution concept of robust team optimality. To seek\nsuch a solution, we develop a learning algorithm in the form of a Gauss-Seidel\nmodified policy iteration and prove its convergence. This algorithm, compared\nwith robust dynamic programming, not only possesses a faster convergence rate,\nbut also allows for using approximation calculations to alleviate the curse of\ndimensionality. Moreover, some numerical simulations are presented to\ndemonstrate the effectiveness of the algorithm by generalizing the game model\nof social dilemmas to sequential robust scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 10:42:09 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Huang", "Feng", ""], ["Cao", "Ming", ""], ["Wang", "Long", ""]]}, {"id": "2105.07420", "submitter": "Martin Zaefferer", "authors": "Thomas Bartz-Beielstein, Marcel Dr\\\"oscher, Alpar G\\\"ur, Alexander\n  Hinterleitner, Olaf Mersmann, Dessislava Peeva, Lennard Reese, Nicolas\n  Rehbach, Frederik Rehbach, Amrita Sen, Aleksandr Subbotin, Martin Zaefferer", "title": "Resource Planning for Hospitals Under Special Consideration of the\n  COVID-19 Pandemic: Optimization and Sensitivity Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crises like the COVID-19 pandemic pose a serious challenge to health-care\ninstitutions. They need to plan the resources required for handling the\nincreased load, for instance, hospital beds and ventilators. To support the\nresource planning of local health authorities from the Cologne region,\nBaBSim.Hospital, a tool for capacity planning based on discrete event\nsimulation, was created. The predictive quality of the simulation is determined\nby 29 parameters. Reasonable default values of these parameters were obtained\nin detailed discussions with medical professionals. We aim to investigate and\noptimize these parameters to improve BaBSim.Hospital. First approaches with\n\"out-of-the-box\" optimization algorithms failed. Implementing a surrogate-based\noptimization approach generated useful results in a reasonable time. To\nunderstand the behavior of the algorithm and to get valuable insights into the\nfitness landscape, an in-depth sensitivity analysis was performed. The\nsensitivity analysis is crucial for the optimization process because it allows\nfocusing the optimization on the most important parameters. We illustrate how\nthis reduces the problem dimension without compromising the resulting accuracy.\nThe presented approach is applicable to many other real-world problems, e.g.,\nthe development of new elevator systems to cover the last mile or simulation of\nstudent flow in academic study periods.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 12:38:35 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Bartz-Beielstein", "Thomas", ""], ["Dr\u00f6scher", "Marcel", ""], ["G\u00fcr", "Alpar", ""], ["Hinterleitner", "Alexander", ""], ["Mersmann", "Olaf", ""], ["Peeva", "Dessislava", ""], ["Reese", "Lennard", ""], ["Rehbach", "Nicolas", ""], ["Rehbach", "Frederik", ""], ["Sen", "Amrita", ""], ["Subbotin", "Aleksandr", ""], ["Zaefferer", "Martin", ""]]}, {"id": "2105.07426", "submitter": "Romi Banerjee", "authors": "Tejas Gaikwad, Romi Banerjee", "title": "Curiosity-driven Intuitive Physics Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Biological infants are naturally curious and try to comprehend their physical\nsurroundings by interacting, in myriad multisensory ways, with different\nobjects - primarily macroscopic solid objects - around them. Through their\nvarious interactions, they build hypotheses and predictions, and eventually\nlearn, infer and understand the nature of the physical characteristics and\nbehavior of these objects. Inspired thus, we propose a model for\ncuriosity-driven learning and inference for real-world AI agents. This model is\nbased on the arousal of curiosity, deriving from observations along\ndiscontinuities in the fundamental macroscopic solid-body physics parameters,\ni.e., shape constancy, spatial-temporal continuity, and object permanence. We\nuse the term body-budget to represent the perceived fundamental properties of\nsolid objects. The model aims to support the emulation of learning from scratch\nfollowed by substantiation through experience, irrespective of domain, in\nreal-world AI agents.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 12:58:05 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Gaikwad", "Tejas", ""], ["Banerjee", "Romi", ""]]}, {"id": "2105.07443", "submitter": "Qin Yang", "authors": "Qin Yang and Ramviyas Parasuraman", "title": "How Can Robots Trust Each Other? A Relative Needs Entropy Based Trust\n  Assessment Models", "comments": "This paper already submitted to the SMC 2021 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperation in multi-agent and multi-robot systems can help agents build\nvarious formations, shapes, and patterns presenting corresponding functions and\npurposes adapting to different situations. Relationship between agents such as\ntheir spatial proximity and functional similarities could play a crucial role\nin cooperation between agents. Trust level between agents is an essential\nfactor in evaluating their relationships' reliability and stability, much as\npeople do. This paper proposes a new model called Relative Needs Entropy (RNE)\nto assess trust between robotic agents. RNE measures the distance of needs\ndistribution between individual agents or groups of agents. To exemplify its\nutility, we implement and demonstrate our trust model through experiments\nsimulating a heterogeneous multi-robot grouping task in a persistent urban\nsearch and rescue mission consisting of tasks at two levels of difficulty. The\nresults suggest that RNE trust-Based grouping of robots can achieve better\nperformance and adaptability for diverse task execution compared to the\nstate-of-the-art energy-based or distance-based grouping models.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 14:33:11 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Yang", "Qin", ""], ["Parasuraman", "Ramviyas", ""]]}, {"id": "2105.07463", "submitter": "Mohammed Daoudi", "authors": "Naima Otberdout, Claudio Ferrari, Mohamed Daoudi, Stefano Berretti,\n  Alberto Del Bimbo", "title": "3D to 4D Facial Expressions Generation Guided by Landmarks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While deep learning-based 3D face generation has made a progress recently,\nthe problem of dynamic 3D (4D) facial expression synthesis is less\ninvestigated. In this paper, we propose a novel solution to the following\nquestion: given one input 3D neutral face, can we generate dynamic 3D (4D)\nfacial expressions from it? To tackle this problem, we first propose a mesh\nencoder-decoder architecture (Expr-ED) that exploits a set of 3D landmarks to\ngenerate an expressive 3D face from its neutral counterpart. Then, we extend it\nto 4D by modeling the temporal dynamics of facial expressions using a\nmanifold-valued GAN capable of generating a sequence of 3D landmarks from an\nexpression label (Motion3DGAN). The generated landmarks are fed into the mesh\nencoder-decoder, ultimately producing a sequence of 3D expressive faces. By\ndecoupling the two steps, we separately address the non-linearity induced by\nthe mesh deformation and motion dynamics. The experimental results on the CoMA\ndataset show that our mesh encoder-decoder guided by landmarks brings a\nsignificant improvement with respect to other landmark-based 3D fitting\napproaches, and that we can generate high quality dynamic facial expressions.\nThis framework further enables the 3D expression intensity to be continuously\nadapted from low to high intensity. Finally, we show our framework can be\napplied to other tasks, such as 2D-3D facial expression transfer.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 15:52:29 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Otberdout", "Naima", ""], ["Ferrari", "Claudio", ""], ["Daoudi", "Mohamed", ""], ["Berretti", "Stefano", ""], ["Del Bimbo", "Alberto", ""]]}, {"id": "2105.07464", "submitter": "Ning Ding", "authors": "Ning Ding, Guangwei Xu, Yulin Chen, Xiaobin Wang, Xu Han, Pengjun Xie,\n  Hai-Tao Zheng, Zhiyuan Liu", "title": "Few-NERD: A Few-Shot Named Entity Recognition Dataset", "comments": "Accepted by ACL-IJCNLP 2021 (long paper), update", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, considerable literature has grown up around the theme of few-shot\nnamed entity recognition (NER), but little published benchmark data\nspecifically focused on the practical and challenging task. Current approaches\ncollect existing supervised NER datasets and re-organize them to the few-shot\nsetting for empirical study. These strategies conventionally aim to recognize\ncoarse-grained entity types with few examples, while in practice, most unseen\nentity types are fine-grained. In this paper, we present Few-NERD, a\nlarge-scale human-annotated few-shot NER dataset with a hierarchy of 8\ncoarse-grained and 66 fine-grained entity types. Few-NERD consists of 188,238\nsentences from Wikipedia, 4,601,160 words are included and each is annotated as\ncontext or a part of a two-level entity type. To the best of our knowledge,\nthis is the first few-shot NER dataset and the largest human-crafted NER\ndataset. We construct benchmark tasks with different emphases to\ncomprehensively assess the generalization capability of models. Extensive\nempirical results and analysis show that Few-NERD is challenging and the\nproblem requires further research. We make Few-NERD public at\nhttps://ningding97.github.io/fewnerd/.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 15:53:17 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 08:50:14 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 06:56:03 GMT"}, {"version": "v4", "created": "Wed, 2 Jun 2021 07:23:06 GMT"}, {"version": "v5", "created": "Sun, 20 Jun 2021 14:55:18 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Ding", "Ning", ""], ["Xu", "Guangwei", ""], ["Chen", "Yulin", ""], ["Wang", "Xiaobin", ""], ["Han", "Xu", ""], ["Xie", "Pengjun", ""], ["Zheng", "Hai-Tao", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "2105.07469", "submitter": "Amirhossein Kardoost", "authors": "Amirhossein Kardoost and Margret Keuper", "title": "Uncertainty in Minimum Cost Multicuts for Image and Motion Segmentation", "comments": "Accepted in the 37th Conference on Uncertainty in Artificial\n  Intelligence (UAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The minimum cost lifted multicut approach has proven practically good\nperformance in a wide range of applications such as image decomposition, mesh\nsegmentation, multiple object tracking, and motion segmentation. It addresses\nsuch problems in a graph-based model, where real-valued costs are assigned to\nthe edges between entities such that the minimum cut decomposes the graph into\nan optimal number of segments. Driven by a probabilistic formulation of minimum\ncost multicuts, we provide a measure for the uncertainties of the decisions\nmade during the optimization. We argue that access to such uncertainties is\ncrucial for many practical applications and conduct an evaluation by means of\nsparsifications on three different, widely used datasets in the context of\nimage decomposition (BSDS-500) and motion segmentation (DAVIS2016 and FBMS59)\nin terms of variation of information (VI) and Rand index (RI).\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 16:22:38 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kardoost", "Amirhossein", ""], ["Keuper", "Margret", ""]]}, {"id": "2105.07508", "submitter": "Scott Cheng-Hsin Yang", "authors": "Scott Cheng-Hsin Yang, Tomas Folke, and Patrick Shafto", "title": "Abstraction, Validation, and Generalization for Explainable Artificial\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural network architectures are achieving superhuman performance on an\nexpanding range of tasks. To effectively and safely deploy these systems, their\ndecision-making must be understandable to a wide range of stakeholders. Methods\nto explain AI have been proposed to answer this challenge, but a lack of theory\nimpedes the development of systematic abstractions which are necessary for\ncumulative knowledge gains. We propose Bayesian Teaching as a framework for\nunifying explainable AI (XAI) by integrating machine learning and human\nlearning. Bayesian Teaching formalizes explanation as a communication act of an\nexplainer to shift the beliefs of an explainee. This formalization decomposes\nany XAI method into four components: (1) the inference to be explained, (2) the\nexplanatory medium, (3) the explainee model, and (4) the explainer model. The\nabstraction afforded by Bayesian Teaching to decompose any XAI method\nelucidates the invariances among them. The decomposition of XAI systems enables\nmodular validation, as each of the first three components listed can be tested\nsemi-independently. This decomposition also promotes generalization through\nrecombination of components from different XAI systems, which facilitates the\ngeneration of novel variants. These new variants need not be evaluated one by\none provided that each component has been validated, leading to an exponential\ndecrease in development time. Finally, by making the goal of explanation\nexplicit, Bayesian Teaching helps developers to assess how suitable an XAI\nsystem is for its intended real-world use case. Thus, Bayesian Teaching\nprovides a theoretical framework that encourages systematic, scientific\ninvestigation of XAI.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 20:40:23 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Yang", "Scott Cheng-Hsin", ""], ["Folke", "Tomas", ""], ["Shafto", "Patrick", ""]]}, {"id": "2105.07510", "submitter": "Benjamin Townsend", "authors": "Benjamin Townsend, Eamon Ito-Fisher, Lily Zhang and Madison May", "title": "Doc2Dict: Information Extraction as Text Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Typically, information extraction (IE) requires a pipeline approach: first, a\nsequence labeling model is trained on manually annotated documents to extract\nrelevant spans; then, when a new document arrives, a model predicts spans which\nare then post-processed and standardized to convert the information into a\ndatabase entry. We replace this labor-intensive workflow with a transformer\nlanguage model trained on existing database records to directly generate\nstructured JSON. Our solution removes the workload associated with producing\ntoken-level annotations and takes advantage of a data source which is generally\nquite plentiful (e.g. database records). As long documents are common in\ninformation extraction tasks, we use gradient checkpointing and chunked\nencoding to apply our method to sequences of up to 32,000 tokens on a single\nGPU. Our Doc2Dict approach is competitive with more complex, hand-engineered\npipelines and offers a simple but effective baseline for document-level\ninformation extraction. We release our Doc2Dict model and code to reproduce our\nexperiments and facilitate future work.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 20:46:29 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Townsend", "Benjamin", ""], ["Ito-Fisher", "Eamon", ""], ["Zhang", "Lily", ""], ["May", "Madison", ""]]}, {"id": "2105.07513", "submitter": "Ferdinando Fioretto", "authors": "Ferdinando Fioretto, Cuong Tran, Pascal Van Hentenryck", "title": "Decision Making with Differential Privacy under a Fairness Lens", "comments": "This paper is an extended version of the homonymous one, accepted at\n  IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agencies, such as the U.S. Census Bureau, release data sets and statistics\nabout groups of individuals that are used as input to a number of critical\ndecision processes. To conform to privacy and confidentiality requirements,\nthese agencies are often required to release privacy-preserving versions of the\ndata. This paper studies the release of differentially private data sets and\nanalyzes their impact on some critical resource allocation tasks under a\nfairness perspective. {The paper shows that, when the decisions take as input\ndifferentially private data}, the noise added to achieve privacy\ndisproportionately impacts some groups over others. The paper analyzes the\nreasons for these disproportionate impacts and proposes guidelines to mitigate\nthese effects. The proposed approaches are evaluated on critical decision\nproblems that use differentially private census data.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 21:04:19 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Fioretto", "Ferdinando", ""], ["Tran", "Cuong", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "2105.07519", "submitter": "Xiang Deng", "authors": "Xiang Deng and Zhongfei Zhang", "title": "Graph-Free Knowledge Distillation for Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge distillation (KD) transfers knowledge from a teacher network to a\nstudent by enforcing the student to mimic the outputs of the pretrained teacher\non training data. However, data samples are not always accessible in many cases\ndue to large data sizes, privacy, or confidentiality. Many efforts have been\nmade on addressing this problem for convolutional neural networks (CNNs) whose\ninputs lie in a grid domain within a continuous space such as images and\nvideos, but largely overlook graph neural networks (GNNs) that handle non-grid\ndata with different topology structures within a discrete space. The inherent\ndifferences between their inputs make these CNN-based approaches not applicable\nto GNNs. In this paper, we propose to our best knowledge the first dedicated\napproach to distilling knowledge from a GNN without graph data. The proposed\ngraph-free KD (GFKD) learns graph topology structures for knowledge transfer by\nmodeling them with multinomial distribution. We then introduce a gradient\nestimator to optimize this framework. Essentially, the gradients w.r.t. graph\nstructures are obtained by only using GNN forward-propagation without\nback-propagation, which means that GFKD is compatible with modern GNN libraries\nsuch as DGL and Geometric. Moreover, we provide the strategies for handling\ndifferent types of prior knowledge in the graph data or the GNNs. Extensive\nexperiments demonstrate that GFKD achieves the state-of-the-art performance for\ndistilling knowledge from GNNs without training data.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 21:38:24 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Deng", "Xiang", ""], ["Zhang", "Zhongfei", ""]]}, {"id": "2105.07526", "submitter": "Yuping Fan", "authors": "Yuping Fan and Zhiling Lan", "title": "DRAS-CQSim: A Reinforcement Learning based Framework for HPC Cluster\n  Scheduling", "comments": null, "journal-ref": "Software Impacts 2021", "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For decades, system administrators have been striving to design and tune\ncluster scheduling policies to improve the performance of high performance\ncomputing (HPC) systems. However, the increasingly complex HPC systems combined\nwith highly diverse workloads make such manual process challenging,\ntime-consuming, and error-prone. We present a reinforcement learning based HPC\nscheduling framework named DRAS-CQSim to automatically learn optimal scheduling\npolicy. DRAS-CQSim encapsulates simulation environments, agents, hyperparameter\ntuning options, and different reinforcement learning algorithms, which allows\nthe system administrators to quickly obtain customized scheduling policies.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 21:56:31 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Fan", "Yuping", ""], ["Lan", "Zhiling", ""]]}, {"id": "2105.07533", "submitter": "Richard Jiang", "authors": "Richard Jiang, Paul Chazot, Danny Crookes, Ahmed Bouridane and M Emre\n  Celebi", "title": "Private Facial Diagnosis as an Edge Service for Parkinson's DBS\n  Treatment Valuation", "comments": "Under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Facial phenotyping has recently been successfully exploited for medical\ndiagnosis as a novel way to diagnose a range of diseases, where facial\nbiometrics has been revealed to have rich links to underlying genetic or\nmedical causes. In this paper, taking Parkinson's Diseases (PD) as a case\nstudy, we proposed an Artificial-Intelligence-of-Things (AIoT) edge-oriented\nprivacy-preserving facial diagnosis framework to analyze the treatment of Deep\nBrain Stimulation (DBS) on PD patients. In the proposed framework, a new\nedge-based information theoretically secure framework is proposed to implement\nprivate deep facial diagnosis as a service over a privacy-preserving\nAIoT-oriented multi-party communication scheme, where partial homomorphic\nencryption (PHE) is leveraged to enable privacy-preserving deep facial\ndiagnosis directly on encrypted facial patterns. In our experiments with a\ncollected facial dataset from PD patients, for the first time, we demonstrated\nthat facial patterns could be used to valuate the improvement of PD patients\nundergoing DBS treatment. We further implemented a privacy-preserving deep\nfacial diagnosis framework that can achieve the same accuracy as the\nnon-encrypted one, showing the potential of our privacy-preserving facial\ndiagnosis as an trustworthy edge service for grading the severity of PD in\npatients.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 22:24:37 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Jiang", "Richard", ""], ["Chazot", "Paul", ""], ["Crookes", "Danny", ""], ["Bouridane", "Ahmed", ""], ["Celebi", "M Emre", ""]]}, {"id": "2105.07540", "submitter": "Yun Liu", "authors": "Sahar Kazemzadeh, Jin Yu, Shahar Jamshy, Rory Pilgrim, Zaid Nabulsi,\n  Christina Chen, Neeral Beladia, Charles Lau, Scott Mayer McKinney, Thad\n  Hughes, Atilla Kiraly, Sreenivasa Raju Kalidindi, Monde Muyoyeta, Jameson\n  Malemela, Ting Shih, Greg S. Corrado, Lily Peng, Katherine Chou, Po-Hsuan\n  Cameron Chen, Yun Liu, Krish Eswaran, Daniel Tse, Shravya Shetty, Shruthi\n  Prabhakara", "title": "Deep learning for detecting pulmonary tuberculosis via chest\n  radiography: an international study across 10 countries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.IV cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuberculosis (TB) is a top-10 cause of death worldwide. Though the WHO\nrecommends chest radiographs (CXRs) for TB screening, the limited availability\nof CXR interpretation is a barrier. We trained a deep learning system (DLS) to\ndetect active pulmonary TB using CXRs from 9 countries across Africa, Asia, and\nEurope, and utilized large-scale CXR pretraining, attention pooling, and noisy\nstudent semi-supervised learning. Evaluation was on (1) a combined test set\nspanning China, India, US, and Zambia, and (2) an independent mining population\nin South Africa. Given WHO targets of 90% sensitivity and 70% specificity, the\nDLS's operating point was prespecified to favor sensitivity over specificity.\nOn the combined test set, the DLS's ROC curve was above all 9 India-based\nradiologists, with an AUC of 0.90 (95%CI 0.87-0.92). The DLS's sensitivity\n(88%) was higher than the India-based radiologists (75% mean sensitivity),\np<0.001 for superiority; and its specificity (79%) was non-inferior to the\nradiologists (84% mean specificity), p=0.004. Similar trends were observed\nwithin HIV positive and sputum smear positive sub-groups, and in the South\nAfrica test set. We found that 5 US-based radiologists (where TB isn't endemic)\nwere more sensitive and less specific than the India-based radiologists (where\nTB is endemic). The DLS also remained non-inferior to the US-based\nradiologists. In simulations, using the DLS as a prioritization tool for\nconfirmatory testing reduced the cost per positive case detected by 40-80%\ncompared to using confirmatory testing alone. To conclude, our DLS generalized\nto 5 countries, and merits prospective evaluation to assist cost-effective\nscreening efforts in radiologist-limited settings. Operating point flexibility\nmay permit customization of the DLS to account for site-specific factors such\nas TB prevalence, demographics, clinical resources, and customary practice\npatterns.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 22:56:06 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kazemzadeh", "Sahar", ""], ["Yu", "Jin", ""], ["Jamshy", "Shahar", ""], ["Pilgrim", "Rory", ""], ["Nabulsi", "Zaid", ""], ["Chen", "Christina", ""], ["Beladia", "Neeral", ""], ["Lau", "Charles", ""], ["McKinney", "Scott Mayer", ""], ["Hughes", "Thad", ""], ["Kiraly", "Atilla", ""], ["Kalidindi", "Sreenivasa Raju", ""], ["Muyoyeta", "Monde", ""], ["Malemela", "Jameson", ""], ["Shih", "Ting", ""], ["Corrado", "Greg S.", ""], ["Peng", "Lily", ""], ["Chou", "Katherine", ""], ["Chen", "Po-Hsuan Cameron", ""], ["Liu", "Yun", ""], ["Eswaran", "Krish", ""], ["Tse", "Daniel", ""], ["Shetty", "Shravya", ""], ["Prabhakara", "Shruthi", ""]]}, {"id": "2105.07542", "submitter": "Chang Lu", "authors": "Chang Lu, Chandan K. Reddy, Prithwish Chakraborty, Samantha Kleinberg,\n  Yue Ning", "title": "Collaborative Graph Learning with Auxiliary Text for Temporal Event\n  Prediction in Healthcare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and explainable health event predictions are becoming crucial for\nhealthcare providers to develop care plans for patients. The availability of\nelectronic health records (EHR) has enabled machine learning advances in\nproviding these predictions. However, many deep learning based methods are not\nsatisfactory in solving several key challenges: 1) effectively utilizing\ndisease domain knowledge; 2) collaboratively learning representations of\npatients and diseases; and 3) incorporating unstructured text. To address these\nissues, we propose a collaborative graph learning model to explore\npatient-disease interactions and medical domain knowledge. Our solution is able\nto capture structural features of both patients and diseases. The proposed\nmodel also utilizes unstructured text data by employing an attention regulation\nstrategy and then integrates attentive text features into a sequential learning\nprocess. We conduct extensive experiments on two important healthcare problems\nto show the competitive prediction performance of the proposed method compared\nwith various state-of-the-art models. We also confirm the effectiveness of\nlearned representations and model interpretability by a set of ablation and\ncase studies.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 23:11:11 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Lu", "Chang", ""], ["Reddy", "Chandan K.", ""], ["Chakraborty", "Prithwish", ""], ["Kleinberg", "Samantha", ""], ["Ning", "Yue", ""]]}, {"id": "2105.07579", "submitter": "Paulo Santos", "authors": "Hyghor Miranda Cortes, Paulo Eduardo Santos, Joao Inacio da Silva\n  Filho", "title": "Monitoring electrical systems data-network equipment by means of Fuzzy\n  and Paraconsistent Annotated Logic", "comments": "38 pages; 14 figures; Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The constant increase in the amount and complexity of information obtained\nfrom IT data networkelements, for its correct monitoring and management, is a\nreality. The same happens to data net-works in electrical systems that provide\neffective supervision and control of substations and hydro-electric plants.\nContributing to this fact is the growing number of installations and new\nenvironmentsmonitored by such data networks and the constant evolution of the\ntechnologies involved. This sit-uation potentially leads to incomplete and/or\ncontradictory data, issues that must be addressed inorder to maintain a good\nlevel of monitoring and, consequently, management of these systems. Inthis\npaper, a prototype of an expert system is developed to monitor the status of\nequipment of datanetworks in electrical systems, which deals with\ninconsistencies without trivialising the inferences.This is accomplished in the\ncontext of the remote control of hydroelectric plants and substationsby a\nRegional Operation Centre (ROC). The expert system is developed with algorithms\ndefinedupon a combination of Fuzzy logic and Paraconsistent Annotated Logic\nwith Annotation of TwoValues (PAL2v) in order to analyse uncertain signals and\ngenerate the operating conditions (faulty,normal, unstable or inconsistent /\nindeterminate) of the equipment that are identified as importantfor the remote\ncontrol of hydroelectric plants and substations. A prototype of this expert\nsystemwas installed on a virtualised server with CLP500 software (from the\nEFACEC manufacturer) thatwas applied to investigate scenarios consisting of a\nRegional (Brazilian) Operation Centre, with aGeneric Substation and a Generic\nHydroelectric Plant, representing a remote control environment.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 02:33:45 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 01:08:17 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Cortes", "Hyghor Miranda", ""], ["Santos", "Paulo Eduardo", ""], ["Filho", "Joao Inacio da Silva", ""]]}, {"id": "2105.07593", "submitter": "Peter Karkus", "authors": "Peter Karkus, Shaojun Cai, David Hsu", "title": "Differentiable SLAM-net: Learning Particle SLAM for Visual Navigation", "comments": "CVPR 2021, extended results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Simultaneous localization and mapping (SLAM) remains challenging for a number\nof downstream applications, such as visual robot navigation, because of rapid\nturns, featureless walls, and poor camera quality. We introduce the\nDifferentiable SLAM Network (SLAM-net) along with a navigation architecture to\nenable planar robot navigation in previously unseen indoor environments.\nSLAM-net encodes a particle filter based SLAM algorithm in a differentiable\ncomputation graph, and learns task-oriented neural network components by\nbackpropagating through the SLAM algorithm. Because it can optimize all model\ncomponents jointly for the end-objective, SLAM-net learns to be robust in\nchallenging conditions. We run experiments in the Habitat platform with\ndifferent real-world RGB and RGB-D datasets. SLAM-net significantly outperforms\nthe widely adapted ORB-SLAM in noisy conditions. Our navigation architecture\nwith SLAM-net improves the state-of-the-art for the Habitat Challenge 2020\nPointNav task by a large margin (37% to 64% success). Project website:\nhttp://sites.google.com/view/slamnet\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 03:54:34 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 14:12:02 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Karkus", "Peter", ""], ["Cai", "Shaojun", ""], ["Hsu", "David", ""]]}, {"id": "2105.07603", "submitter": "Weiming Zhuang", "authors": "Weiming Zhuang, Xin Gan, Yonggang Wen, Shuai Zhang", "title": "EasyFL: A Low-code Federated Learning Platform For Dummies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Academia and industry have developed several platforms to support the popular\nprivacy-preserving distributed learning method -- Federated Learning (FL).\nHowever, these platforms are complex to use and require a deep understanding of\nFL, which imposes high barriers to entry for beginners, limits the productivity\nof researchers, and compromises deployment efficiency. In this paper, we\npropose the first low-code FL platform, EasyFL, to enable users with various\nlevels of expertise to experiment and prototype FL applications with little\ncoding. We achieve this goal while ensuring great flexibility and extensibility\nfor customization by unifying simple API design, modular design, and granular\ntraining flow abstraction. With only a few lines of code, EasyFL empowers them\nwith many out-of-the-box functionalities to accelerate experimentation and\ndeployment. These practical functionalities are heterogeneity simulation,\ncomprehensive tracking, distributed training optimization, and seamless\ndeployment. They are proposed based on challenges identified in the proposed FL\nlife cycle. Compared with other platforms, EasyFL not only requires just three\nlines of code (at least 10x lesser) to build a vanilla FL application but also\nincurs lower training overhead. Besides, our evaluations demonstrate that\nEasyFL expedites distributed training by 1.5x. It also improves the efficiency\nof deployment. We believe that EasyFL will increase the productivity of\nresearchers and democratize FL to wider audiences.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 04:15:55 GMT"}, {"version": "v2", "created": "Sat, 3 Jul 2021 13:18:23 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhuang", "Weiming", ""], ["Gan", "Xin", ""], ["Wen", "Yonggang", ""], ["Zhang", "Shuai", ""]]}, {"id": "2105.07606", "submitter": "Weiming Zhuang", "authors": "Weiming Zhuang, Xin Gan, Yonggang Wen, Xuesen Zhang, Shuai Zhang,\n  Shuai Yi", "title": "Towards Unsupervised Domain Adaptation for Deep Face Recognition under\n  Privacy Constraints via Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation has been widely adopted to generalize models\nfor unlabeled data in a target domain, given labeled data in a source domain,\nwhose data distributions differ from the target domain. However, existing works\nare inapplicable to face recognition under privacy constraints because they\nrequire sharing sensitive face images between two domains. To address this\nproblem, we propose a novel unsupervised federated face recognition approach\n(FedFR). FedFR improves the performance in the target domain by iteratively\naggregating knowledge from the source domain through federated learning. It\nprotects data privacy by transferring models instead of raw data between\ndomains. Besides, we propose a new domain constraint loss (DCL) to regularize\nsource domain training. DCL suppresses the data volume dominance of the source\ndomain. We also enhance a hierarchical clustering algorithm to predict pseudo\nlabels for the unlabeled target domain accurately. To this end, FedFR forms an\nend-to-end training pipeline: (1) pre-train in the source domain; (2) predict\npseudo labels by clustering in the target domain; (3) conduct\ndomain-constrained federated learning across two domains. Extensive experiments\nand analysis on two newly constructed benchmarks demonstrate the effectiveness\nof FedFR. It outperforms the baseline and classic methods in the target domain\nby over 4% on the more realistic benchmark. We believe that FedFR will shed\nlight on applying federated learning to more computer vision tasks under\nprivacy constraints.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 04:24:25 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Zhuang", "Weiming", ""], ["Gan", "Xin", ""], ["Wen", "Yonggang", ""], ["Zhang", "Xuesen", ""], ["Zhang", "Shuai", ""], ["Yi", "Shuai", ""]]}, {"id": "2105.07624", "submitter": "Fengbin Zhu", "authors": "Fengbin Zhu, Wenqiang Lei, Youcheng Huang, Chao Wang, Shuo Zhang,\n  Jiancheng Lv, Fuli Feng and Tat-Seng Chua", "title": "TAT-QA: A Question Answering Benchmark on a Hybrid of Tabular and\n  Textual Content in Finance", "comments": "Accepted by ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Hybrid data combining both tabular and textual content (e.g., financial\nreports) are quite pervasive in the real world. However, Question Answering\n(QA) over such hybrid data is largely neglected in existing research. In this\nwork, we extract samples from real financial reports to build a new large-scale\nQA dataset containing both Tabular And Textual data, named TAT-QA, where\nnumerical reasoning is usually required to infer the answer, such as addition,\nsubtraction, multiplication, division, counting, comparison/sorting, and the\ncompositions. We further propose a novel QA model termed TAGOP, which is\ncapable of reasoning over both tables and text. It adopts sequence tagging to\nextract relevant cells from the table along with relevant spans from the text\nto infer their semantics, and then applies symbolic reasoning over them with a\nset of aggregation operators to arrive at the final answer. TAGOPachieves 58.0%\ninF1, which is an 11.1% absolute increase over the previous best baseline\nmodel, according to our experiments on TAT-QA. But this result still lags far\nbehind performance of expert human, i.e.90.8% in F1. It is demonstrated that\nour TAT-QA is very challenging and can serve as a benchmark for training and\ntesting powerful QA models that address hybrid form data.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 06:12:06 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 05:38:50 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Zhu", "Fengbin", ""], ["Lei", "Wenqiang", ""], ["Huang", "Youcheng", ""], ["Wang", "Chao", ""], ["Zhang", "Shuo", ""], ["Lv", "Jiancheng", ""], ["Feng", "Fuli", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2105.07630", "submitter": "Andr\\'e Artelt", "authors": "Andr\\'e Artelt and Barbara Hammer", "title": "Convex optimization for actionable \\& plausible counterfactual\n  explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transparency is an essential requirement of machine learning based decision\nmaking systems that are deployed in real world. Often, transparency of a given\nsystem is achieved by providing explanations of the behavior and predictions of\nthe given system. Counterfactual explanations are a prominent instance of\nparticular intuitive explanations of decision making systems. While a lot of\ndifferent methods for computing counterfactual explanations exist, only very\nfew work (apart from work from the causality domain) considers feature\ndependencies as well as plausibility which might limit the set of possible\ncounterfactual explanations.\n  In this work we enhance our previous work on convex modeling for computing\ncounterfactual explanations by a mechanism for ensuring actionability and\nplausibility of the resulting counterfactual explanations.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 06:33:58 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Artelt", "Andr\u00e9", ""], ["Hammer", "Barbara", ""]]}, {"id": "2105.07634", "submitter": "Sunil Kumar Maurya", "authors": "Sunil Kumar Maurya, Xin Liu and Tsuyoshi Murata", "title": "Improving Graph Neural Networks with Simple Architecture Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph Neural Networks have emerged as a useful tool to learn on the data by\napplying additional constraints based on the graph structure. These graphs are\noften created with assumed intrinsic relations between the entities. In recent\nyears, there have been tremendous improvements in the architecture design,\npushing the performance up in various prediction tasks. In general, these\nneural architectures combine layer depth and node feature aggregation steps.\nThis makes it challenging to analyze the importance of features at various hops\nand the expressiveness of the neural network layers. As different graph\ndatasets show varying levels of homophily and heterophily in features and class\nlabel distribution, it becomes essential to understand which features are\nimportant for the prediction tasks without any prior information. In this work,\nwe decouple the node feature aggregation step and depth of graph neural network\nand introduce several key design strategies for graph neural networks. More\nspecifically, we propose to use softmax as a regularizer and \"Soft-Selector\" of\nfeatures aggregated from neighbors at different hop distances; and\n\"Hop-Normalization\" over GNN layers. Combining these techniques, we present a\nsimple and shallow model, Feature Selection Graph Neural Network (FSGNN), and\nshow empirically that the proposed model outperforms other state of the art GNN\nmodels and achieves up to 64% improvements in accuracy on node classification\ntasks. Moreover, analyzing the learned soft-selection parameters of the model\nprovides a simple way to study the importance of features in the prediction\ntasks. Finally, we demonstrate with experiments that the model is scalable for\nlarge graphs with millions of nodes and billions of edges.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 06:46:01 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Maurya", "Sunil Kumar", ""], ["Liu", "Xin", ""], ["Murata", "Tsuyoshi", ""]]}, {"id": "2105.07636", "submitter": "Sauptik Dhar", "authors": "Sauptik Dhar, Bernardo Gonzalez Torres", "title": "DOC3-Deep One Class Classification using Contradictions", "comments": "Deep Learning, Anomaly Detection, Visual Inspection, Learning from\n  Contradictions, Outlier Exposure, 18 pages, 14 tables, 6 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper introduces the notion of learning from contradictions (a.k.a\nUniversum learning) for deep one class classification problems. We formalize\nthis notion for the widely adopted one class large-margin loss, and propose the\nDeep One Class Classification using Contradictions (DOC3) algorithm. We show\nthat learning from contradictions incurs lower generalization error by\ncomparing the Empirical Radamacher Complexity (ERC) of DOC3 against its\ntraditional inductive learning counterpart. Our empirical results demonstrate\nthe efficacy of DOC3 algorithm achieving > 30% for CIFAR-10 and >50% for MV-Tec\nAD data sets in test AUCs compared to its inductive learning counterpart and in\nmany cases improving the state-of-the-art in anomaly detection.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 06:48:25 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Dhar", "Sauptik", ""], ["Torres", "Bernardo Gonzalez", ""]]}, {"id": "2105.07648", "submitter": "Jieting Luo", "authors": "Jieting Luo, Beishui Liao, John-Jules Meyer", "title": "A Formal Framework for Reasoning about Agents' Independence in\n  Self-organizing Multi-agent Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-organization is a process where a stable pattern is formed by the\ncooperative behavior between parts of an initially disordered system without\nexternal control or influence. It has been introduced to multi-agent systems as\nan internal control process or mechanism to solve difficult problems\nspontaneously. However, because a self-organizing multi-agent system has\nautonomous agents and local interactions between them, it is difficult to\npredict the behavior of the system from the behavior of the local agents we\ndesign. This paper proposes a logic-based framework of self-organizing\nmulti-agent systems, where agents interact with each other by following their\nprescribed local rules. The dependence relation between coalitions of agents\nregarding their contributions to the global behavior of the system is reasoned\nabout from the structural and semantic perspectives. We show that the\ncomputational complexity of verifying such a self-organizing multi-agent system\nis in exponential time. We then combine our framework with graph theory to\ndecompose a system into different coalitions located in different layers, which\nallows us to verify agents' full contributions more efficiently. The resulting\ninformation about agents' full contributions allows us to understand the\ncomplex link between local agent behavior and system level behavior in a\nself-organizing multi-agent system. Finally, we show how we can use our\nframework to model a constraint satisfaction problem.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 07:32:43 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 11:50:42 GMT"}, {"version": "v3", "created": "Wed, 26 May 2021 06:20:35 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Luo", "Jieting", ""], ["Liao", "Beishui", ""], ["Meyer", "John-Jules", ""]]}, {"id": "2105.07653", "submitter": "Roza Goscien", "authors": "R\\'o\\.za Go\\'scie\\'n", "title": "Traffic-Aware Service Relocation in Cloud-Oriented Elastic Optical\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we study problem of efficient service relocation (i.e.,\nchanging assigned data center for a selected client node) in elastic optical\nnetworks (EONs) in order to increase network performance (measured by the\nvolume of accepted traffic). To this end, we first propose novel traffic model\nfor cloud ready transport networks. The model takes into account four flow\ntypes (i.e., city-to-city, city-to-data center, data center-to-data center and\ndata center-to-data center) while the flow characteristics are based on real\neconomical and geographical parameters of the cities related to network nodes.\nThen, we propose dedicated flow allocation algorithm that can be supported by\nthe service relocation process. We also introduce 21 different relocation\npolicies, which use three types of data for decision making - network\ntopological characteristics, rejection history and traffic prediction.\nEventually, we perform extensive numerical experiments in order to: (i) tune\nproposed optimization approaches and (ii) evaluate and compare their efficiency\nand select the best one. The results of the investigation prove high efficiency\nof the proposed policies. The propoerly designed relocation policy allowed to\nallocate up to 3% more traffic (compared to the allocation without that\npolicy). The results also reveal that the most efficient relocation policy\nbases its decisions on two types of data simultaneously - the rejection history\nand traffic prediction.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 08:00:55 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Go\u015bcie\u0144", "R\u00f3\u017ca", ""]]}, {"id": "2105.07654", "submitter": "Jiwei Li", "authors": "Leilei Gan, Yuxian Meng, Kun Kuang, Xiaofei Sun, Chun Fan, Fei Wu and\n  Jiwei Li", "title": "Dependency Parsing as MRC-based Span-Span Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Higher-order methods for dependency parsing can partially but not fully\naddresses the issue that edges in dependency tree should be constructed at the\ntext span/subtree level rather than word level. % This shortcoming can cause an\nincorrect span covered the corresponding tree rooted at a certain word though\nthe word is correctly linked to its head. In this paper, we propose a new\nmethod for dependency parsing to address this issue. The proposed method\nconstructs dependency trees by directly modeling span-span (in other words,\nsubtree-subtree) relations. It consists of two modules: the {\\it text span\nproposal module} which proposes candidate text spans, each of which represents\na subtree in the dependency tree denoted by (root, start, end); and the {\\it\nspan linking module}, which constructs links between proposed spans. We use the\nmachine reading comprehension (MRC) framework as the backbone to formalize the\nspan linking module in an MRC setup, where one span is used as a query to\nextract the text span/subtree it should be linked to. The proposed method comes\nwith the following merits: (1) it addresses the fundamental problem that edges\nin a dependency tree should be constructed between subtrees; (2) the MRC\nframework allows the method to retrieve missing spans in the span proposal\nstage, which leads to higher recall for eligible spans. Extensive experiments\non the PTB, CTB and Universal Dependencies (UD) benchmarks demonstrate the\neffectiveness of the proposed method. We are able to achieve new SOTA\nperformances on PTB and UD benchmarks, and competitive performances to previous\nSOTA models on the CTB dataset. Code is available at\nhttps://github.com/ShannonAI/mrc-for-dependency-parsing.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 08:03:48 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Gan", "Leilei", ""], ["Meng", "Yuxian", ""], ["Kuang", "Kun", ""], ["Sun", "Xiaofei", ""], ["Fan", "Chun", ""], ["Wu", "Fei", ""], ["Li", "Jiwei", ""]]}, {"id": "2105.07674", "submitter": "Andrea Cossu", "authors": "Andrea Cossu, Davide Bacciu, Antonio Carta, Claudio Gallicchio,\n  Vincenzo Lomonaco", "title": "Continual Learning with Echo State Networks", "comments": "Accepted as oral at ESANN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual Learning (CL) refers to a learning setup where data is non\nstationary and the model has to learn without forgetting existing knowledge.\nThe study of CL for sequential patterns revolves around trained recurrent\nnetworks. In this work, instead, we introduce CL in the context of Echo State\nNetworks (ESNs), where the recurrent component is kept fixed. We provide the\nfirst evaluation of catastrophic forgetting in ESNs and we highlight the\nbenefits in using CL strategies which are not applicable to trained recurrent\nmodels. Our results confirm the ESN as a promising model for CL and open to its\nuse in streaming scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 08:49:01 GMT"}, {"version": "v2", "created": "Mon, 28 Jun 2021 12:26:42 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Cossu", "Andrea", ""], ["Bacciu", "Davide", ""], ["Carta", "Antonio", ""], ["Gallicchio", "Claudio", ""], ["Lomonaco", "Vincenzo", ""]]}, {"id": "2105.07688", "submitter": "Yuejia Xiang", "authors": "Yuejia Xiang, Ziheng Zhang, Jiaoyan Chen, Xi Chen, Zhenxi Lin, Yefeng\n  Zheng", "title": "OntoEA: Ontology-guided Entity Alignment via Joint Knowledge Graph\n  Embedding", "comments": "Accepted by Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Semantic embedding has been widely investigated for aligning knowledge graph\n(KG) entities. Current methods have explored and utilized the graph structure,\nthe entity names and attributes, but ignore the ontology (or ontological\nschema) which contains critical meta information such as classes and their\nmembership relationships with entities. In this paper, we propose an\nontology-guided entity alignment method named OntoEA, where both KGs and their\nontologies are jointly embedded, and the class hierarchy and the class\ndisjointness are utilized to avoid false mappings. Extensive experiments on\nseven public and industrial benchmarks have demonstrated the state-of-the-art\nperformance of OntoEA and the effectiveness of the ontologies.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 09:18:56 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 08:45:26 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Xiang", "Yuejia", ""], ["Zhang", "Ziheng", ""], ["Chen", "Jiaoyan", ""], ["Chen", "Xi", ""], ["Lin", "Zhenxi", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2105.07691", "submitter": "Anubhav Singh", "authors": "Anubhav Singh, Nir Lipovetzky, Miquel Ramirez, Javier Segovia-Aguas", "title": "Approximate Novelty Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Width-based search algorithms seek plans by prioritizing states according to\na suitably defined measure of novelty, that maps states into a set of novelty\ncategories. Space and time complexity to evaluate state novelty is known to be\nexponential on the cardinality of the set. We present novel methods to obtain\npolynomial approximations of novelty and width-based search. First, we\napproximate novelty computation via random sampling and Bloom filters, reducing\nthe runtime and memory footprint. Second, we approximate the best-first search\nusing an adaptive policy that decides whether to forgo the expansion of nodes\nin the open list. These two techniques are integrated into existing width-based\nalgorithms, resulting in new planners that perform significantly better than\nother state-of-the-art planners over benchmarks from the International Planning\nCompetitions.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 09:21:48 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Singh", "Anubhav", ""], ["Lipovetzky", "Nir", ""], ["Ramirez", "Miquel", ""], ["Segovia-Aguas", "Javier", ""]]}, {"id": "2105.07706", "submitter": "Xu Ma", "authors": "Xu Ma, Pengjie Wang, Hui Zhao, Shaoguo Liu, Chuhan Zhao, Wei Lin,\n  Kuang-Chih Lee, Jian Xu, Bo Zheng", "title": "Towards a Better Tradeoff between Effectiveness and Efficiency in\n  Pre-Ranking: A Learnable Feature Selection based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world search, recommendation, and advertising systems, the\nmulti-stage ranking architecture is commonly adopted. Such architecture usually\nconsists of matching, pre-ranking, ranking, and re-ranking stages. In the\npre-ranking stage, vector-product based models with representation-focused\narchitecture are commonly adopted to account for system efficiency. However, it\nbrings a significant loss to the effectiveness of the system. In this paper, a\nnovel pre-ranking approach is proposed which supports complicated models with\ninteraction-focused architecture. It achieves a better tradeoff between\neffectiveness and efficiency by utilizing the proposed learnable Feature\nSelection method based on feature Complexity and variational Dropout (FSCD).\nEvaluations in a real-world e-commerce sponsored search system for a search\nengine demonstrate that utilizing the proposed pre-ranking, the effectiveness\nof the system is significantly improved. Moreover, compared to the systems with\nconventional pre-ranking models, an identical amount of computational resource\nis consumed.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 09:48:15 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Ma", "Xu", ""], ["Wang", "Pengjie", ""], ["Zhao", "Hui", ""], ["Liu", "Shaoguo", ""], ["Zhao", "Chuhan", ""], ["Lin", "Wei", ""], ["Lee", "Kuang-Chih", ""], ["Xu", "Jian", ""], ["Zheng", "Bo", ""]]}, {"id": "2105.07752", "submitter": "Bencheng Yan", "authors": "Feng Li, Bencheng Yan, Qingqing Long, Pengjie Wang, Wei Lin, Jian Xu\n  and Bo Zheng", "title": "Explicit Semantic Cross Feature Learning via Pre-trained Graph Neural\n  Networks for CTR Prediction", "comments": "SIGIR 2021, 5 pages; The first two authors contributed equally to\n  this work; Pengjie Wang gave a lot of guidance in this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross features play an important role in click-through rate (CTR) prediction.\nMost of the existing methods adopt a DNN-based model to capture the cross\nfeatures in an implicit manner. These implicit methods may lead to a\nsub-optimized performance due to the limitation in explicit semantic modeling.\nAlthough traditional statistical explicit semantic cross features can address\nthe problem in these implicit methods, it still suffers from some challenges,\nincluding lack of generalization and expensive memory cost. Few works focus on\ntackling these challenges. In this paper, we take the first step in learning\nthe explicit semantic cross features and propose Pre-trained Cross Feature\nlearning Graph Neural Networks (PCF-GNN), a GNN based pre-trained model aiming\nat generating cross features in an explicit fashion. Extensive experiments are\nconducted on both public and industrial datasets, where PCF-GNN shows\ncompetence in both performance and memory-efficiency in various tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 11:56:04 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Li", "Feng", ""], ["Yan", "Bencheng", ""], ["Long", "Qingqing", ""], ["Wang", "Pengjie", ""], ["Lin", "Wei", ""], ["Xu", "Jian", ""], ["Zheng", "Bo", ""]]}, {"id": "2105.07758", "submitter": "Wang-Zhou Dai", "authors": "Wang-Zhou Dai, Liam Hallett, Stephen H. Muggleton, Geoff S. Baldwin", "title": "Automated Biodesign Engineering by Abductive Meta-Interpretive Learning", "comments": "Accepted by SSS-21 (AAAI Spring Symposium Series 2021), Artificial\n  Intelligence for Synthetic Biology (AI4Synbio) track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The application of Artificial Intelligence (AI) to synthetic biology will\nprovide the foundation for the creation of a high throughput automated platform\nfor genetic design, in which a learning machine is used to iteratively optimise\nthe system through a design-build-test-learn (DBTL) cycle. However, mainstream\nmachine learning techniques represented by deep learning lacks the capability\nto represent relational knowledge and requires prodigious amounts of annotated\ntraining data. These drawbacks strongly restrict AI's role in synthetic biology\nin which experimentation is inherently resource and time intensive. In this\nwork, we propose an automated biodesign engineering framework empowered by\nAbductive Meta-Interpretive Learning ($Meta_{Abd}$), a novel machine learning\napproach that combines symbolic and sub-symbolic machine learning, to further\nenhance the DBTL cycle by enabling the learning machine to 1) exploit domain\nknowledge and learn human-interpretable models that are expressed by formal\nlanguages such as first-order logic; 2) simultaneously optimise the structure\nand parameters of the models to make accurate numerical predictions; 3) reduce\nthe cost of experiments and effort on data annotation by actively generating\nhypotheses and examples. To verify the effectiveness of $Meta_{Abd}$, we have\nmodelled a synthetic dataset for the production of proteins from a three gene\noperon in a microbial host, which represents a common synthetic biology\nproblem.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 12:10:26 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Dai", "Wang-Zhou", ""], ["Hallett", "Liam", ""], ["Muggleton", "Stephen H.", ""], ["Baldwin", "Geoff S.", ""]]}, {"id": "2105.07776", "submitter": "Julien Girard-Satabin", "authors": "Julien Girard-Satabin (LIST, TAU), Aymeric Varasse (LIST), Marc\n  Schoenauer (TAU), Guillaume Charpiat (TAU), Zakaria Chihani (LIST)", "title": "DISCO Verification: Division of Input Space into COnvex polytopes for\n  neural network verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The impressive results of modern neural networks partly come from their non\nlinear behaviour. Unfortunately, this property makes it very difficult to apply\nformal verification tools, even if we restrict ourselves to networks with a\npiecewise linear structure. However, such networks yields subregions that are\nlinear and thus simpler to analyse independently. In this paper, we propose a\nmethod to simplify the verification problem by operating a partitionning into\nmultiple linear subproblems. To evaluate the feasibility of such an approach,\nwe perform an empirical analysis of neural networks to estimate the number of\nlinear regions, and compare them to the bounds currently known. We also present\nthe impact of a technique aiming at reducing the number of linear regions\nduring training.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 12:40:51 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Girard-Satabin", "Julien", "", "LIST, TAU"], ["Varasse", "Aymeric", "", "LIST"], ["Schoenauer", "Marc", "", "TAU"], ["Charpiat", "Guillaume", "", "TAU"], ["Chihani", "Zakaria", "", "LIST"]]}, {"id": "2105.07804", "submitter": "Juliana Ferreira J", "authors": "Juliana Jansen Ferreira and Mateus Monteiro", "title": "Designer-User Communication for XAI: An epistemological approach to\n  discuss XAI design", "comments": "ACM CHI Workshop on Operationalizing Human-Centered Perspectives in\n  Explainable AI at CHI 2021. 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence is becoming part of any technology we use nowadays.\nIf the AI informs people's decisions, the explanation about AI's outcomes,\nresults, and behavior becomes a necessary capability. However, the discussion\nof XAI features with various stakeholders is not a trivial task. Most of the\navailable frameworks and methods for XAI focus on data scientists and ML\ndevelopers as users. Our research is about XAI for end-users of AI systems. We\nargue that we need to discuss XAI early in the AI-system design process and\nwith all stakeholders. In this work, we aimed at investigating how to\noperationalize the discussion about XAI scenarios and opportunities among\ndesigners and developers of AI and its end-users. We took the Signifying\nMessage as our conceptual tool to structure and discuss XAI scenarios. We\nexperiment with its use for the discussion of a healthcare AI-System.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 13:18:57 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Ferreira", "Juliana Jansen", ""], ["Monteiro", "Mateus", ""]]}, {"id": "2105.07826", "submitter": "Jamal Al Qundus", "authors": "Malik Yousef, Jamal Al Qundus, Silvio Peikert, and Adrian Paschke", "title": "TopicsRanksDC: Distance-based Topic Ranking applied on Two-Class Data", "comments": "10 pages, 5 figures", "journal-ref": "International Conference on Database and Expert Systems\n  Applications DEXA 2020: Database and Expert Systems Applications pp 11-21", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a novel approach named TopicsRanksDC for topics\nranking based on the distance between two clusters that are generated by each\ntopic. We assume that our data consists of text documents that are associated\nwith two-classes. Our approach ranks each topic contained in these text\ndocuments by its significance for separating the two-classes. Firstly, the\nalgorithm detects topics using Latent Dirichlet Allocation (LDA). The words\ndefining each topic are represented as two clusters, where each one is\nassociated with one of the classes. We compute four distance metrics, Single\nLinkage, Complete Linkage, Average Linkage and distance between the centroid.\nWe compare the results of LDA topics and random topics. The results show that\nthe rank for LDA topics is much higher than random topics. The results of\nTopicsRanksDC tool are promising for future work to enable search engines to\nsuggest related topics.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 13:34:45 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Yousef", "Malik", ""], ["Qundus", "Jamal Al", ""], ["Peikert", "Silvio", ""], ["Paschke", "Adrian", ""]]}, {"id": "2105.07831", "submitter": "Hangcheng Dong", "authors": "Hangcheng Dong, Bingguo Liu, Fengdong Chen, Dong Ye and Guodong Liu", "title": "How to Explain Neural Networks: A perspective of data space division", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Interpretability of intelligent algorithms represented by deep learning has\nbeen yet an open problem. We discuss the shortcomings of the existing\nexplainable method based on the two attributes of explanation, which are called\ncompleteness and explicitness. Furthermore, we point out that a model that\ncompletely relies on feed-forward mapping is extremely easy to cause\ninexplicability because it is hard to quantify the relationship between this\nmapping and the final model. Based on the perspective of the data space\ndivision, the principle of complete local interpretable model-agnostic\nexplanations (CLIMEP) is proposed in this paper. To study the classification\nproblems, we further discussed the equivalence of the CLIMEP and the decision\nboundary. As a matter of fact, it is also difficult to implementation of\nCLIMEP. To tackle the challenge, motivated by the fact that a fully-connected\nneural network (FCNN) with piece-wise linear activation functions (PWLs) can\npartition the input space into several linear regions, we extend this result to\narbitrary FCNNs by the strategy of linearizing the activation functions.\nApplying this technique to solving classification problems, it is the first\ntime that the complete decision boundary of FCNNs has been able to be obtained.\nFinally, we propose the DecisionNet (DNet), which divides the input space by\nthe hyper-planes of the decision boundary. Hence, each linear interval of the\nDNet merely contains samples of the same label. Experiments show that the\nsurprising model compression efficiency of the DNet with an arbitrary\ncontrolled precision.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 13:43:37 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Dong", "Hangcheng", ""], ["Liu", "Bingguo", ""], ["Chen", "Fengdong", ""], ["Ye", "Dong", ""], ["Liu", "Guodong", ""]]}, {"id": "2105.07850", "submitter": "Manex Agirrezabal", "authors": "Manex Agirrezabal", "title": "The Flipped Classroom model for teaching Conditional Random Fields in an\n  NLP course", "comments": "Accepted to the 5th Workshop on Teaching NLP at NAACL-HLT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this article, we show and discuss our experience in applying the flipped\nclassroom method for teaching Conditional Random Fields in a Natural Language\nProcessing course. We present the activities that we developed together with\ntheir relationship to a cognitive complexity model (Bloom's taxonomy). After\nthis, we provide our own reflections and expectations of the model itself.\nBased on the evaluation got from students, it seems that students learn about\nthe topic and also that the method is rewarding for some students.\nAdditionally, we discuss some shortcomings and we propose possible solutions to\nthem. We conclude the paper with some possible future work.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 11:21:03 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Agirrezabal", "Manex", ""]]}, {"id": "2105.07852", "submitter": "Bryce Goodman", "authors": "Bryce Goodman", "title": "Hard Choices and Hard Limits for Artificial Intelligence", "comments": null, "journal-ref": null, "doi": "10.1145/3461702.3462539", "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Artificial intelligence (AI) is supposed to help us make better choices. Some\nof these choices are small, like what route to take to work, or what music to\nlisten to. Others are big, like what treatment to administer for a disease or\nhow long to sentence someone for a crime. If AI can assist with these big\ndecisions, we might think it can also help with hard choices, cases where\nalternatives are neither better, worse nor equal but on a par. The aim of this\npaper, however, is to show that this view is mistaken: the fact of parity shows\nthat there are hard limits on AI in decision making and choices that AI cannot,\nand should not, resolve.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 22:56:04 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Goodman", "Bryce", ""]]}, {"id": "2105.07855", "submitter": "A Mallikarjuna Reddy dr", "authors": "Swarajya lakshmi v papineni, A.Mallikarjuna Reddy, Sudeepti\n  yarlagadda, Snigdha Yarlagadda, Haritha Akkinen", "title": "An Extensive Analytical Approach on Human Resources using Random Forest\n  Algorithm", "comments": null, "journal-ref": null, "doi": "10.14445/22315381/IJETT-V69I5P217", "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The current job survey shows that most software employees are planning to\nchange their job role due to high pay for recent jobs such as data scientists,\nbusiness analysts and artificial intelligence fields. The survey also indicated\nthat work life imbalances, low pay, uneven shifts and many other factors also\nmake employees think about changing their work life. In this paper, for an\nefficient organisation of the company in terms of human resources, the proposed\nsystem designed a model with the help of a random forest algorithm by\nconsidering different employee parameters. This helps the HR department retain\nthe employee by identifying gaps and helping the organisation to run smoothly\nwith a good employee retention ratio. This combination of HR and data science\ncan help the productivity, collaboration and well-being of employees of the\norganisation. It also helps to develop strategies that have an impact on the\nperformance of employees in terms of external and social factors.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 07:35:23 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["papineni", "Swarajya lakshmi v", ""], ["Reddy", "A. Mallikarjuna", ""], ["yarlagadda", "Sudeepti", ""], ["Yarlagadda", "Snigdha", ""], ["Akkinen", "Haritha", ""]]}, {"id": "2105.07876", "submitter": "Reda Mastouri", "authors": "Reda Mastouri Et Al., Joseph Gilkey", "title": "The challenges and realities of retailing in a COVID-19 world:\n  Identifying trending and Vital During Crisis keywords during Covid-19 using\n  Machine Learning (Austria as a case study)", "comments": "easychair, ENSIAS Rabat, Morocco. Saint Peter's University, NJ- USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  From global pandemics to geopolitical turmoil, leaders in logistics, product\nallocation, procurement and operations are facing increasing difficulty with\nsafeguarding their organizations against supply chain vulnerabilities. It is\nrecommended to opt for forecasting against trending based benchmark because\nauditing a future forecast puts more focus on seasonality. The forecasting\nmodels provide with end-to-end, real time oversight of the entire supply chain,\nwhile utilizing predictive analytics and artificial intelligence to identify\npotential disruptions before they occur. By combining internal and external\ndata points, coming up with an AI-enabled modelling engine can greatly reduce\nrisk by helping retail companies proactively respond to supply and demand\nvariability. This research paper puts focus on creating an ingenious way to\ntackle the impact of COVID19 on Supply chain, product allocation, trending and\nseasonality.\n  Key words: Supply chain, covid-19, forecasting, coronavirus, manufacturing,\nseasonality, trending, retail.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 18:31:45 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Al.", "Reda Mastouri Et", ""], ["Gilkey", "Joseph", ""]]}, {"id": "2105.07877", "submitter": "Vyacheslav Yukalov", "authors": "V.I. Yukalov", "title": "Quantum Uncertainty in Decision Theory", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An approach is presented treating decision theory as a probabilistic theory\nbased on quantum techniques. Accurate definitions are given and thorough\nanalysis is accomplished for the quantum probabilities describing the choice\nbetween separate alternatives, sequential alternatives characterizing\nconditional quantum probabilities, and behavioral quantum probabilities taking\ninto account rational-irrational duality of decision making. The comparison\nbetween quantum and classical probabilities is explained. The analysis\ndemonstrates that quantum probabilities serve as an essentially more powerful\ntool of characterizing various decision-making situations including the\ninfluence of psychological behavioral effects.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 16:58:38 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Yukalov", "V. I.", ""]]}, {"id": "2105.07878", "submitter": "Gargi Joshi Miss", "authors": "Gargi Joshi, Rahee Walambe, Ketan Kotecha", "title": "A Review on Explainability in Multimodal Deep Neural Nets", "comments": "24 pages 6 figures", "journal-ref": "in IEEE Access, vol. 9, pp. 59800-59821, 2021", "doi": "10.1109/ACCESS.2021.3070212.", "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Artificial Intelligence techniques powered by deep neural nets have achieved\nmuch success in several application domains, most significantly and notably in\nthe Computer Vision applications and Natural Language Processing tasks.\nSurpassing human-level performance propelled the research in the applications\nwhere different modalities amongst language, vision, sensory, text play an\nimportant role in accurate predictions and identification. Several multimodal\nfusion methods employing deep learning models are proposed in the literature.\nDespite their outstanding performance, the complex, opaque and black-box nature\nof the deep neural nets limits their social acceptance and usability. This has\ngiven rise to the quest for model interpretability and explainability, more so\nin the complex tasks involving multimodal AI methods. This paper extensively\nreviews the present literature to present a comprehensive survey and commentary\non the explainability in multimodal deep neural nets, especially for the vision\nand language tasks. Several topics on multimodal AI and its applications for\ngeneric domains have been covered in this paper, including the significance,\ndatasets, fundamental building blocks of the methods and techniques,\nchallenges, applications, and future trends in this domain\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 14:17:49 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 11:53:33 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Joshi", "Gargi", ""], ["Walambe", "Rahee", ""], ["Kotecha", "Ketan", ""]]}, {"id": "2105.07879", "submitter": "Reza Vaezi", "authors": "Hadi Esmaeilzadeh and Reza Vaezi", "title": "Conscious AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in artificial intelligence (AI) have achieved human-scale\nspeed and accuracy for classification tasks. In turn, these capabilities have\nmade AI a viable replacement for many human activities that at their core\ninvolve classification, such as basic mechanical and analytical tasks in\nlow-level service jobs. Current systems do not need to be conscious to\nrecognize patterns and classify them. However, for AI to progress to more\ncomplicated tasks requiring intuition and empathy, it must develop capabilities\nsuch as metathinking, creativity, and empathy akin to human self-awareness or\nconsciousness. We contend that such a paradigm shift is possible only through a\nfundamental shift in the state of artificial intelligence toward consciousness,\na shift similar to what took place for humans through the process of natural\nselection and evolution. As such, this paper aims to theoretically explore the\nrequirements for the emergence of consciousness in AI. It also provides a\nprincipled understanding of how conscious AI can be detected and how it might\nbe manifested in contrast to the dominant paradigm that seeks to ultimately\ncreate machines that are linguistically indistinguishable from humans.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 15:53:44 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Esmaeilzadeh", "Hadi", ""], ["Vaezi", "Reza", ""]]}, {"id": "2105.07882", "submitter": "Max Hahn-Klimroth", "authors": "AminCoja-Oghlan, Max Hahn-Klimroth, Philipp Loick, Manuel Penschuck", "title": "Efficient and accurate group testing via Belief Propagation: an\n  empirical study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DM cs.IT math.IT stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The group testing problem asks for efficient pooling schemes and algorithms\nthat allow to screen moderately large numbers of samples for rare infections.\nThe goal is to accurately identify the infected samples while conducting the\nleast possible number of tests. Exploring the use of techniques centred around\nthe Belief Propagation message passing algorithm, we suggest a new test design\nthat significantly increases the accuracy of the results. The new design comes\nwith Belief Propagation as an efficient inference algorithm. Aiming for results\non practical rather than asymptotic problem sizes, we conduct an experimental\nstudy.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 10:52:46 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["AminCoja-Oghlan", "", ""], ["Hahn-Klimroth", "Max", ""], ["Loick", "Philipp", ""], ["Penschuck", "Manuel", ""]]}, {"id": "2105.07889", "submitter": "Jiayi Chen", "authors": "Jiayi Chen, Aidong Zhang", "title": "Simultaneous Meta-Learning with Diverse Task Spaces", "comments": "Submitted to CIKM 2021. The original title and abstract has been\n  changed due to the double-blind policy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of how to learn a model-agnostic\nmeta-learner that simultaneously learning from different feature spaces. The\nreason that most of model-agnostic meta-learner methods cannot handle multiple\ntask spaces is due to less common knowledge for the task instances. The\nreduction of shared knowledge is because different tasks with different\nexample-level manifolds cannot entirely share the same model architecture.\nActually, various tasks only share partial meta-parameters. For example, for\ntwo multi-feature tasks whose example-level manifolds contain a same subspace\nbut their remaining subspaces are not the same, one can imagine that the common\nknowledge can be the feature extractor for that common subspace, but other\nsubspaces' feature extractors cannot be used between the two tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 14:22:58 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 18:45:33 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Chen", "Jiayi", ""], ["Zhang", "Aidong", ""]]}, {"id": "2105.07898", "submitter": "Ruben Rodriguez Torrado", "authors": "Ruben Rodriguez-Torrado, Pablo Ruiz, Luis Cueto-Felgueroso, Michael\n  Cerny Green, Tyler Friesen, Sebastien Matringe and Julian Togelius", "title": "Physics-informed attention-based neural network for solving non-linear\n  partial differential equations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Physics-Informed Neural Networks (PINNs) have enabled significant\nimprovements in modelling physical processes described by partial differential\nequations (PDEs). PINNs are based on simple architectures, and learn the\nbehavior of complex physical systems by optimizing the network parameters to\nminimize the residual of the underlying PDE. Current network architectures\nshare some of the limitations of classical numerical discretization schemes\nwhen applied to non-linear differential equations in continuum mechanics. A\nparadigmatic example is the solution of hyperbolic conservation laws that\ndevelop highly localized nonlinear shock waves. Learning solutions of PDEs with\ndominant hyperbolic character is a challenge for current PINN approaches, which\nrely, like most grid-based numerical schemes, on adding artificial dissipation.\nHere, we address the fundamental question of which network architectures are\nbest suited to learn the complex behavior of non-linear PDEs. We focus on\nnetwork architecture rather than on residual regularization. Our new\nmethodology, called Physics-Informed Attention-based Neural Networks, (PIANNs),\nis a combination of recurrent neural networks and attention mechanisms. The\nattention mechanism adapts the behavior of the deep neural network to the\nnon-linear features of the solution, and break the current limitations of\nPINNs. We find that PIANNs effectively capture the shock front in a hyperbolic\nmodel problem, and are capable of providing high-quality solutions inside and\nbeyond the training set.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 14:29:08 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Rodriguez-Torrado", "Ruben", ""], ["Ruiz", "Pablo", ""], ["Cueto-Felgueroso", "Luis", ""], ["Green", "Michael Cerny", ""], ["Friesen", "Tyler", ""], ["Matringe", "Sebastien", ""], ["Togelius", "Julian", ""]]}, {"id": "2105.07933", "submitter": "Sarah Perrin", "authors": "Sarah Perrin, Mathieu Lauri\\`ere, Julien P\\'erolat, Matthieu Geist,\n  Romuald \\'Elie, Olivier Pietquin", "title": "Mean Field Games Flock! The Reinforcement Learning Way", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a method enabling a large number of agents to learn how to flock,\nwhich is a natural behavior observed in large populations of animals. This\nproblem has drawn a lot of interest but requires many structural assumptions\nand is tractable only in small dimensions. We phrase this problem as a Mean\nField Game (MFG), where each individual chooses its acceleration depending on\nthe population behavior. Combining Deep Reinforcement Learning (RL) and\nNormalizing Flows (NF), we obtain a tractable solution requiring only very weak\nassumptions. Our algorithm finds a Nash Equilibrium and the agents adapt their\nvelocity to match the neighboring flock's average one. We use Fictitious Play\nand alternate: (1) computing an approximate best response with Deep RL, and (2)\nestimating the next population distribution with NF. We show numerically that\nour algorithm learn multi-group or high-dimensional flocking with obstacles.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 15:17:36 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Perrin", "Sarah", ""], ["Lauri\u00e8re", "Mathieu", ""], ["P\u00e9rolat", "Julien", ""], ["Geist", "Matthieu", ""], ["\u00c9lie", "Romuald", ""], ["Pietquin", "Olivier", ""]]}, {"id": "2105.07944", "submitter": "Yunfei Chu", "authors": "Lu Wang, Xiaofu Chang, Shuang Li, Yunfei Chu, Hui Li, Wei Zhang,\n  Xiaofeng He, Le Song, Jingren Zhou, Hongxia Yang", "title": "TCL: Transformer-based Dynamic Graph Modelling via Contrastive Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamic graph modeling has recently attracted much attention due to its\nextensive applications in many real-world scenarios, such as recommendation\nsystems, financial transactions, and social networks. Although many works have\nbeen proposed for dynamic graph modeling in recent years, effective and\nscalable models are yet to be developed. In this paper, we propose a novel\ngraph neural network approach, called TCL, which deals with the\ndynamically-evolving graph in a continuous-time fashion and enables effective\ndynamic node representation learning that captures both the temporal and\ntopology information. Technically, our model contains three novel aspects.\nFirst, we generalize the vanilla Transformer to temporal graph learning\nscenarios and design a graph-topology-aware transformer. Secondly, on top of\nthe proposed graph transformer, we introduce a two-stream encoder that\nseparately extracts representations from temporal neighborhoods associated with\nthe two interaction nodes and then utilizes a co-attentional transformer to\nmodel inter-dependencies at a semantic level. Lastly, we are inspired by the\nrecently developed contrastive learning and propose to optimize our model by\nmaximizing mutual information (MI) between the predictive representations of\ntwo future interaction nodes. Benefiting from this, our dynamic representations\ncan preserve high-level (or global) semantics about interactions and thus is\nrobust to noisy interactions. To the best of our knowledge, this is the first\nattempt to apply contrastive learning to representation learning on dynamic\ngraphs. We evaluate our model on four benchmark datasets for interaction\nprediction and experiment results demonstrate the superiority of our model.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 15:33:25 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Wang", "Lu", ""], ["Chang", "Xiaofu", ""], ["Li", "Shuang", ""], ["Chu", "Yunfei", ""], ["Li", "Hui", ""], ["Zhang", "Wei", ""], ["He", "Xiaofeng", ""], ["Song", "Le", ""], ["Zhou", "Jingren", ""], ["Yang", "Hongxia", ""]]}, {"id": "2105.07952", "submitter": "Yuanpeng He", "authors": "Yuanpeng He", "title": "MMGET: A Markov model for generalized evidence theory", "comments": "20 pages,24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real life, lots of information merges from time to time. To appropriately\ndescribe the actual situations, lots of theories have been proposed. Among\nthem, Dempster-Shafer evidence theory is a very useful tool in managing\nuncertain information. To better adapt to complex situations of open world, a\ngeneralized evidence theory is designed. However, everything occurs in sequence\nand owns some underlying relationships with each other. In order to further\nembody the details of information and better conforms to situations of real\nworld, a Markov model is introduced into the generalized evidence theory which\nhelps extract complete information volume from evidence provided. Besides, some\nnumerical examples is offered to verify the correctness and rationality of the\nproposed method.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 12:41:57 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["He", "Yuanpeng", ""]]}, {"id": "2105.07957", "submitter": "Daniel Tanneberg", "authors": "Daniel Tanneberg, Elmar Rueckert, Jan Peters", "title": "Evolutionary Training and Abstraction Yields Algorithmic Generalization\n  of Neural Computers", "comments": "Nature Machine Intelligence", "journal-ref": "Nature Machine Intelligence, Vol. 2, December 2020, 753-763", "doi": "10.1038/s42256-020-00255-1", "report-no": null, "categories": "cs.NE cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key feature of intelligent behaviour is the ability to learn abstract\nstrategies that scale and transfer to unfamiliar problems. An abstract strategy\nsolves every sample from a problem class, no matter its representation or\ncomplexity -- like algorithms in computer science. Neural networks are powerful\nmodels for processing sensory data, discovering hidden patterns, and learning\ncomplex functions, but they struggle to learn such iterative, sequential or\nhierarchical algorithmic strategies. Extending neural networks with external\nmemories has increased their capacities in learning such strategies, but they\nare still prone to data variations, struggle to learn scalable and transferable\nsolutions, and require massive training data. We present the Neural Harvard\nComputer (NHC), a memory-augmented network based architecture, that employs\nabstraction by decoupling algorithmic operations from data manipulations,\nrealized by splitting the information flow and separated modules. This\nabstraction mechanism and evolutionary training enable the learning of robust\nand scalable algorithmic solutions. On a diverse set of 11 algorithms with\nvarying complexities, we show that the NHC reliably learns algorithmic\nsolutions with strong generalization and abstraction: perfect generalization\nand scaling to arbitrary task configurations and complexities far beyond seen\nduring training, and being independent of the data representation and the task\ndomain.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 15:37:32 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Tanneberg", "Daniel", ""], ["Rueckert", "Elmar", ""], ["Peters", "Jan", ""]]}, {"id": "2105.07960", "submitter": "Martin Zaefferer", "authors": "J\\\"org Stork, Martin Zaefferer, Nils Eisler, Patrick Tichelmann,\n  Thomas Bartz-Beielstein, A. E. Eiben", "title": "Behavior-based Neuroevolutionary Training in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": "10.1145/3449726.3463171", "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In addition to their undisputed success in solving classical optimization\nproblems, neuroevolutionary and population-based algorithms have become an\nalternative to standard reinforcement learning methods. However, evolutionary\nmethods often lack the sample efficiency of standard value-based methods that\nleverage gathered state and value experience. If reinforcement learning for\nreal-world problems with significant resource cost is considered, sample\nefficiency is essential. The enhancement of evolutionary algorithms with\nexperience exploiting methods is thus desired and promises valuable insights.\nThis work presents a hybrid algorithm that combines topology-changing\nneuroevolutionary optimization with value-based reinforcement learning. We\nillustrate how the behavior of policies can be used to create distance and loss\nfunctions, which benefit from stored experiences and calculated state values.\nThey allow us to model behavior and perform a directed search in the behavior\nspace by gradient-free evolutionary algorithms and surrogate-based\noptimization. For this purpose, we consolidate different methods to generate\nand optimize agent policies, creating a diverse population. We exemplify the\nperformance of our algorithm on standard benchmarks and a purpose-built\nreal-world problem. Our results indicate that combining methods can enhance the\nsample efficiency and learning speed for evolutionary approaches.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 15:40:42 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Stork", "J\u00f6rg", ""], ["Zaefferer", "Martin", ""], ["Eisler", "Nils", ""], ["Tichelmann", "Patrick", ""], ["Bartz-Beielstein", "Thomas", ""], ["Eiben", "A. E.", ""]]}, {"id": "2105.07965", "submitter": "Arpita Biswas", "authors": "Arpita Biswas, Gaurav Aggarwal, Pradeep Varakantham, Milind Tambe", "title": "Learn to Intervene: An Adaptive Learning Policy for Restless Bandits in\n  Application to Preventive Healthcare", "comments": "To appear in the 30th International Joint Conference on Artificial\n  Intelligence (IJCAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In many public health settings, it is important for patients to adhere to\nhealth programs, such as taking medications and periodic health checks.\nUnfortunately, beneficiaries may gradually disengage from such programs, which\nis detrimental to their health. A concrete example of gradual disengagement has\nbeen observed by an organization that carries out a free automated call-based\nprogram for spreading preventive care information among pregnant women. Many\nwomen stop picking up calls after being enrolled for a few months. To avoid\nsuch disengagements, it is important to provide timely interventions. Such\ninterventions are often expensive and can be provided to only a small fraction\nof the beneficiaries. We model this scenario as a restless multi-armed bandit\n(RMAB) problem, where each beneficiary is assumed to transition from one state\nto another depending on the intervention. Moreover, since the transition\nprobabilities are unknown a priori, we propose a Whittle index based Q-Learning\nmechanism and show that it converges to the optimal solution. Our method\nimproves over existing learning-based methods for RMABs on multiple benchmarks\nfrom literature and also on the maternal healthcare dataset.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 15:44:55 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 22:37:04 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Biswas", "Arpita", ""], ["Aggarwal", "Gaurav", ""], ["Varakantham", "Pradeep", ""], ["Tambe", "Milind", ""]]}, {"id": "2105.07985", "submitter": "Franziska Boenisch", "authors": "Franziska Boenisch, Philip Sperl, Konstantin B\\\"ottinger", "title": "Gradient Masking and the Underestimated Robustness Threats of\n  Differential Privacy in Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An important problem in deep learning is the privacy and security of neural\nnetworks (NNs). Both aspects have long been considered separately. To date, it\nis still poorly understood how privacy enhancing training affects the\nrobustness of NNs. This paper experimentally evaluates the impact of training\nwith Differential Privacy (DP), a standard method for privacy preservation, on\nmodel vulnerability against a broad range of adversarial attacks. The results\nsuggest that private models are less robust than their non-private\ncounterparts, and that adversarial examples transfer better among DP models\nthan between non-private and private ones. Furthermore, detailed analyses of DP\nand non-DP models suggest significant differences between their gradients.\nAdditionally, this work is the first to observe that an unfavorable choice of\nparameters in DP training can lead to gradient masking, and, thereby, results\nin a wrong sense of security.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 16:10:54 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Boenisch", "Franziska", ""], ["Sperl", "Philip", ""], ["B\u00f6ttinger", "Konstantin", ""]]}, {"id": "2105.07996", "submitter": "Fatema Hasan", "authors": "Fatema Hasan, Kevin S. Xu, James R. Foulds, Shimei Pan", "title": "Learning User Embeddings from Temporal Social Media Data: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-generated data on social media contain rich information about who we\nare, what we like and how we make decisions. In this paper, we survey\nrepresentative work on learning a concise latent user representation (a.k.a.\nuser embedding) that can capture the main characteristics of a social media\nuser. The learned user embeddings can later be used to support different\ndownstream user analysis tasks such as personality modeling, suicidal risk\nassessment and purchase decision prediction. The temporal nature of\nuser-generated data on social media has largely been overlooked in much of the\nexisting user embedding literature. In this survey, we focus on research that\nbridges the gap by incorporating temporal/sequential information in user\nrepresentation learning. We categorize relevant papers along several key\ndimensions, identify limitations in the current work and suggest future\nresearch directions.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 16:22:43 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Hasan", "Fatema", ""], ["Xu", "Kevin S.", ""], ["Foulds", "James R.", ""], ["Pan", "Shimei", ""]]}, {"id": "2105.07998", "submitter": "Swagat Kumar", "authors": "Swagat Kumar", "title": "Controlling an Inverted Pendulum with Policy Gradient Methods-A Tutorial", "comments": "8 pages, 3 figures, 2 tables etc", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper provides the details of implementing two important policy gradient\nmethods to solve the inverted pendulum problem. These are namely the Deep\nDeterministic Policy Gradient (DDPG) and the Proximal Policy Optimization (PPO)\nalgorithm. The problem is solved by using an actor-critic model where an\nactor-network is used to learn the policy function and a critic network is to\nevaluate the actor-network by learning to estimate the Q function. Apart from\nbriefly explaining the mathematics behind these two algorithms, the details of\npython implementation are provided which helps in demystifying the underlying\ncomplexity of the algorithm. In the process, the readers will be introduced to\nOpenAI/Gym, Tensorflow 2.x and Keras utilities used for implementing the above\nconcepts.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 16:30:54 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Kumar", "Swagat", ""]]}, {"id": "2105.08021", "submitter": "Qingyun Wang", "authors": "Qingyun Wang, Semih Yavuz, Victoria Lin, Heng Ji, Nazneen Rajani", "title": "Stage-wise Fine-tuning for Graph-to-Text Generation", "comments": "10 pages, Accepted by Proceedings of ACL-IJCNLP 2021 Student Research\n  Workshop, Code and Resources at\n  https://github.com/EagleW/Stage-wise-Fine-tuning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-to-text generation has benefited from pre-trained language models\n(PLMs) in achieving better performance than structured graph encoders. However,\nthey fail to fully utilize the structure information of the input graph. In\nthis paper, we aim to further improve the performance of the pre-trained\nlanguage model by proposing a structured graph-to-text model with a two-step\nfine-tuning mechanism which first fine-tunes the model on Wikipedia before\nadapting to the graph-to-text generation. In addition to using the traditional\ntoken and position embeddings to encode the knowledge graph (KG), we propose a\nnovel tree-level embedding method to capture the inter-dependency structures of\nthe input graph. This new approach has significantly improved the performance\nof all text generation metrics for the English WebNLG 2017 dataset.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 17:15:29 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 22:47:33 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Qingyun", ""], ["Yavuz", "Semih", ""], ["Lin", "Victoria", ""], ["Ji", "Heng", ""], ["Rajani", "Nazneen", ""]]}, {"id": "2105.08086", "submitter": "Elizabeth Bennewitz", "authors": "Elizabeth R. Bennewitz, Florian Hopfmueller, Bohdan Kulchytskyy, Juan\n  Carrasquilla and Pooya Ronagh", "title": "Neural Error Mitigation of Near-Term Quantum Simulations", "comments": "18 pages, 4 main figures, 6 supplementary figures, 1 supplementary\n  table", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the promising applications of early quantum computers is the\nsimulation of quantum systems. Variational methods for near-term quantum\ncomputers, such as the variational quantum eigensolver (VQE), are a promising\napproach to finding ground states of quantum systems relevant in physics,\nchemistry, and materials science. These approaches, however, are constrained by\nthe effects of noise as well as the limited quantum resources of near-term\nquantum hardware, motivating the need for quantum error mitigation techniques\nto reduce the effects of noise. Here we introduce $\\textit{neural error\nmitigation}$, a novel method that uses neural networks to improve estimates of\nground states and ground-state observables obtained using VQE on near-term\nquantum computers. To demonstrate our method's versatility, we apply neural\nerror mitigation to finding the ground states of H$_2$ and LiH molecular\nHamiltonians, as well as the lattice Schwinger model. Our results show that\nneural error mitigation improves the numerical and experimental VQE computation\nto yield low-energy errors, low infidelities, and accurate estimations of\nmore-complex observables like order parameters and entanglement entropy,\nwithout requiring additional quantum resources. Additionally, neural error\nmitigation is agnostic to both the quantum hardware and the particular noise\nchannel, making it a versatile tool for quantum simulation. Applying quantum\nmany-body machine learning techniques to error mitigation, our method is a\npromising strategy for extending the reach of near-term quantum computers to\nsolve complex quantum simulation problems.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 18:00:57 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Bennewitz", "Elizabeth R.", ""], ["Hopfmueller", "Florian", ""], ["Kulchytskyy", "Bohdan", ""], ["Carrasquilla", "Juan", ""], ["Ronagh", "Pooya", ""]]}, {"id": "2105.08089", "submitter": "David Hafner", "authors": "Vladlen Koltun and David Hafner", "title": "A Measure of Research Taste", "comments": "Results can be explored at https://cap-measure.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers are often evaluated by citation-based metrics. Such metrics can\ninform hiring, promotion, and funding decisions. Concerns have been expressed\nthat popular citation-based metrics incentivize researchers to maximize the\nproduction of publications. Such incentives may not be optimal for scientific\nprogress. Here we present a citation-based measure that rewards both\nproductivity and taste: the researcher's ability to focus on impactful\ncontributions. The presented measure, CAP, balances the impact of publications\nand their quantity, thus incentivizing researchers to consider whether a\npublication is a useful addition to the literature. CAP is simple,\ninterpretable, and parameter-free. We analyze the characteristics of CAP for\nhighly-cited researchers in biology, computer science, economics, and physics,\nusing a corpus of millions of publications and hundreds of millions of\ncitations with yearly temporal granularity. CAP produces qualitatively\nplausible outcomes and has a number of advantages over prior metrics. Results\ncan be explored at https://cap-measure.org/\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 18:01:47 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Koltun", "Vladlen", ""], ["Hafner", "David", ""]]}, {"id": "2105.08127", "submitter": "Luke Melas-Kyriazi", "authors": "Luke Melas-Kyriazi and Christian Rupprecht and Iro Laina and Andrea\n  Vedaldi", "title": "Finding an Unsupervised Image Segmenter in Each of Your Deep Generative\n  Models", "comments": "Project page and GitHub link:\n  https://lukemelas.github.io/unsupervised-image-segmentation &\n  https://github.com/lukemelas/unsupervised-image-segmentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research has shown that numerous human-interpretable directions exist\nin the latent space of GANs. In this paper, we develop an automatic procedure\nfor finding directions that lead to foreground-background image separation, and\nwe use these directions to train an image segmentation model without human\nsupervision. Our method is generator-agnostic, producing strong segmentation\nresults with a wide range of different GAN architectures. Furthermore, by\nleveraging GANs pretrained on large datasets such as ImageNet, we are able to\nsegment images from a range of domains without further training or finetuning.\nEvaluating our method on image segmentation benchmarks, we compare favorably to\nprior work while using neither human supervision nor access to the training\ndata. Broadly, our results demonstrate that automatically extracting\nforeground-background structure from pretrained deep generative models can\nserve as a remarkably effective substitute for human supervision.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 19:34:24 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Melas-Kyriazi", "Luke", ""], ["Rupprecht", "Christian", ""], ["Laina", "Iro", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "2105.08128", "submitter": "Luke Melas-Kyriazi", "authors": "Luke Melas-Kyriazi and Arjun K. Manrai", "title": "PixMatch: Unsupervised Domain Adaptation via Pixelwise Consistency\n  Training", "comments": "CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unsupervised domain adaptation is a promising technique for semantic\nsegmentation and other computer vision tasks for which large-scale data\nannotation is costly and time-consuming. In semantic segmentation, it is\nattractive to train models on annotated images from a simulated (source) domain\nand deploy them on real (target) domains. In this work, we present a novel\nframework for unsupervised domain adaptation based on the notion of\ntarget-domain consistency training. Intuitively, our work is based on the idea\nthat in order to perform well on the target domain, a model's output should be\nconsistent with respect to small perturbations of inputs in the target domain.\nSpecifically, we introduce a new loss term to enforce pixelwise consistency\nbetween the model's predictions on a target image and a perturbed version of\nthe same image. In comparison to popular adversarial adaptation methods, our\napproach is simpler, easier to implement, and more memory-efficient during\ntraining. Experiments and extensive ablation studies demonstrate that our\nsimple approach achieves remarkably strong results on two challenging\nsynthetic-to-real benchmarks, GTA5-to-Cityscapes and SYNTHIA-to-Cityscapes.\n  Code is available at: https://github.com/lukemelas/pixmatch\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 19:36:28 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Melas-Kyriazi", "Luke", ""], ["Manrai", "Arjun K.", ""]]}, {"id": "2105.08141", "submitter": "Srijan Das", "authors": "Srijan Das, Rui Dai, Di Yang, Francois Bremond", "title": "VPN++: Rethinking Video-Pose embeddings for understanding Activities of\n  Daily Living", "comments": "submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many attempts have been made towards combining RGB and 3D poses for the\nrecognition of Activities of Daily Living (ADL). ADL may look very similar and\noften necessitate to model fine-grained details to distinguish them. Because\nthe recent 3D ConvNets are too rigid to capture the subtle visual patterns\nacross an action, this research direction is dominated by methods combining RGB\nand 3D Poses. But the cost of computing 3D poses from RGB stream is high in the\nabsence of appropriate sensors. This limits the usage of aforementioned\napproaches in real-world applications requiring low latency. Then, how to best\ntake advantage of 3D Poses for recognizing ADL? To this end, we propose an\nextension of a pose driven attention mechanism: Video-Pose Network (VPN),\nexploring two distinct directions. One is to transfer the Pose knowledge into\nRGB through a feature-level distillation and the other towards mimicking pose\ndriven attention through an attention-level distillation. Finally, these two\napproaches are integrated into a single model, we call VPN++. We show that\nVPN++ is not only effective but also provides a high speed up and high\nresilience to noisy Poses. VPN++, with or without 3D Poses, outperforms the\nrepresentative baselines on 4 public datasets. Code is available at\nhttps://github.com/srijandas07/vpnplusplus.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 20:19:47 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Das", "Srijan", ""], ["Dai", "Rui", ""], ["Yang", "Di", ""], ["Bremond", "Francois", ""]]}, {"id": "2105.08150", "submitter": "Luke Eglington", "authors": "Philip I. Pavlik Jr, Luke G. Eglington", "title": "Modeling the EdNet Dataset with Logistic Regression", "comments": "5 pages, AAAI Workshop on AI in Education (Imagining Post-COVID\n  Education with AI)", "journal-ref": "AAAI 2021 Workshop on AI in Education", "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many of these challenges are won by neural network models created by\nfull-time artificial intelligence scientists. Due to this origin, they have a\nblack-box character that makes their use and application less clear to learning\nscientists. We describe our experience with competition from the perspective of\neducational data mining, a field founded in the learning sciences and connected\nwith roots in psychology and statistics. We describe our efforts from the\nperspectives of learning scientists and the challenges to our methods, some\nreal and some imagined. We also discuss some basic results in the Kaggle system\nand our thoughts on how those results may have been improved. Finally, we\ndescribe how learner model predictions are used to make pedagogical decisions\nfor students. Their practical use entails a) model predictions and b) a\ndecision rule (based on the predictions). We point out how increased model\naccuracy can be of limited practical utility, especially when paired with\nsimple decision rules and argue instead for the need to further investigate\noptimal decision rules.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 20:30:36 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Pavlik", "Philip I.", "Jr"], ["Eglington", "Luke G.", ""]]}, {"id": "2105.08158", "submitter": "Tao Li", "authors": "Tao Li, Guanze Peng, Quanyan Zhu and Tamer Basar", "title": "The Confluence of Networks, Games and Learning", "comments": "The manuscript has been submitted to IEEE control system magazine\n  under review, as part of the special issue \"Distributed Nash Equilibrium\n  Seeking over Networks\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have witnessed significant advances in technologies and services\nin modern network applications, including smart grid management, wireless\ncommunication, cybersecurity as well as multi-agent autonomous systems.\nConsidering the heterogeneous nature of networked entities, emerging network\napplications call for game-theoretic models and learning-based approaches in\norder to create distributed network intelligence that responds to uncertainties\nand disruptions in a dynamic or an adversarial environment. This paper\narticulates the confluence of networks, games and learning, which establishes a\ntheoretical underpinning for understanding multi-agent decision-making over\nnetworks. We provide an selective overview of game-theoretic learning\nalgorithms within the framework of stochastic approximation theory, and\nassociated applications in some representative contexts of modern network\nsystems, such as the next generation wireless communication networks, the smart\ngrid and distributed machine learning. In addition to existing research works\non game-theoretic learning over networks, we highlight several new angles and\nresearch endeavors on learning in games that are related to recent developments\nin artificial intelligence. Some of the new angles extrapolate from our own\nresearch interests. The overall objective of the paper is to provide the reader\na clear picture of the strengths and challenges of adopting game-theoretic\nlearning methods within the context of network systems, and further to identify\nfruitful future research directions on both theoretical and applied studies.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 20:54:07 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Li", "Tao", ""], ["Peng", "Guanze", ""], ["Zhu", "Quanyan", ""], ["Basar", "Tamer", ""]]}, {"id": "2105.08179", "submitter": "Yuening Li", "authors": "Yuening Li, Zhengzhang Chen, Daochen Zha, Mengnan Du, Denghui Zhang,\n  Haifeng Chen, Xia Hu", "title": "Learning Disentangled Representations for Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Time-series representation learning is a fundamental task for time-series\nanalysis. While significant progress has been made to achieve accurate\nrepresentations for downstream applications, the learned representations often\nlack interpretability and do not expose semantic meanings. Different from\nprevious efforts on the entangled feature space, we aim to extract the\nsemantic-rich temporal correlations in the latent interpretable factorized\nrepresentation of the data. Motivated by the success of disentangled\nrepresentation learning in computer vision, we study the possibility of\nlearning semantic-rich time-series representations, which remains unexplored\ndue to three main challenges: 1) sequential data structure introduces complex\ntemporal correlations and makes the latent representations hard to interpret,\n2) sequential models suffer from KL vanishing problem, and 3) interpretable\nsemantic concepts for time-series often rely on multiple factors instead of\nindividuals. To bridge the gap, we propose Disentangle Time Series (DTS), a\nnovel disentanglement enhancement framework for sequential data. Specifically,\nto generate hierarchical semantic concepts as the interpretable and\ndisentangled representation of time-series, DTS introduces multi-level\ndisentanglement strategies by covering both individual latent factors and group\nsemantic segments. We further theoretically show how to alleviate the KL\nvanishing problem: DTS introduces a mutual information maximization term, while\npreserving a heavier penalty on the total correlation and the dimension-wise KL\nto keep the disentanglement property. Experimental results on various\nreal-world benchmark datasets demonstrate that the representations learned by\nDTS achieve superior performance in downstream applications, with high\ninterpretability of semantic concepts.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 22:02:24 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 06:59:38 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Li", "Yuening", ""], ["Chen", "Zhengzhang", ""], ["Zha", "Daochen", ""], ["Du", "Mengnan", ""], ["Zhang", "Denghui", ""], ["Chen", "Haifeng", ""], ["Hu", "Xia", ""]]}, {"id": "2105.08180", "submitter": "Hao Yan", "authors": "Hao Yan, Nurretin Dorukhan Sergin, William A. Brenneman, Stephen\n  Joseph Lange, Shan Ba", "title": "Deep Multistage Multi-Task Learning for Quality Prediction of Multistage\n  Manufacturing Systems", "comments": "Accepted by Journal of Quality Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In multistage manufacturing systems, modeling multiple quality indices based\non the process sensing variables is important. However, the classic modeling\ntechnique predicts each quality variable one at a time, which fails to consider\nthe correlation within or between stages. We propose a deep multistage\nmulti-task learning framework to jointly predict all output sensing variables\nin a unified end-to-end learning framework according to the sequential system\narchitecture in the MMS. Our numerical studies and real case study have shown\nthat the new model has a superior performance compared to many benchmark\nmethods as well as great interpretability through developed variable selection\ntechniques.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 22:09:36 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Yan", "Hao", ""], ["Sergin", "Nurretin Dorukhan", ""], ["Brenneman", "William A.", ""], ["Lange", "Stephen Joseph", ""], ["Ba", "Shan", ""]]}, {"id": "2105.08195", "submitter": "Samuel Daulton", "authors": "Samuel Daulton, Maximilian Balandat, Eytan Bakshy", "title": "Parallel Bayesian Optimization of Multiple Noisy Objectives with\n  Expected Hypervolume Improvement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimizing multiple competing black-box objectives is a challenging problem\nin many fields, including science, engineering, and machine learning.\nMulti-objective Bayesian optimization is a powerful approach for identifying\nthe optimal trade-offs between the objectives with very few function\nevaluations. However, existing methods tend to perform poorly when observations\nare corrupted by noise, as they do not take into account uncertainty in the\ntrue Pareto frontier over the previously evaluated designs. We propose a novel\nacquisition function, NEHVI, that overcomes this important practical limitation\nby applying a Bayesian treatment to the popular expected hypervolume\nimprovement criterion to integrate over this uncertainty in the Pareto\nfrontier. We further argue that, even in the noiseless setting, the problem of\ngenerating multiple candidates in parallel reduces that of handling uncertainty\nin the Pareto frontier. Through this lens, we derive a natural parallel variant\nof NEHVI that can efficiently generate large batches of candidates. We provide\na theoretical convergence guarantee for optimizing a Monte Carlo estimator of\nNEHVI using exact sample-path gradients. Empirically, we show that NEHVI\nachieves state-of-the-art performance in noisy and large-batch environments.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 23:31:42 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Daulton", "Samuel", ""], ["Balandat", "Maximilian", ""], ["Bakshy", "Eytan", ""]]}, {"id": "2105.08205", "submitter": "Sidi Lu", "authors": "Sidi Lu, Xin Yuan, Aggelos K Katsaggelos, Weisong Shi", "title": "Reinforcement Learning for Adaptive Video Compressive Sensing", "comments": "12 pages, 11 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply reinforcement learning to video compressive sensing to adapt the\ncompression ratio. Specifically, video snapshot compressive imaging (SCI),\nwhich captures high-speed video using a low-speed camera is considered in this\nwork, in which multiple (B) video frames can be reconstructed from a snapshot\nmeasurement. One research gap in previous studies is how to adapt B in the\nvideo SCI system for different scenes. In this paper, we fill this gap\nutilizing reinforcement learning (RL). An RL model, as well as various\nconvolutional neural networks for reconstruction, are learned to achieve\nadaptive sensing of video SCI systems. Furthermore, the performance of an\nobject detection network using directly the video SCI measurements without\nreconstruction is also used to perform RL-based adaptive video compressive\nsensing. Our proposed adaptive SCI method can thus be implemented in low cost\nand real time. Our work takes the technology one step further towards real\napplications of video SCI.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 00:01:27 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Lu", "Sidi", ""], ["Yuan", "Xin", ""], ["Katsaggelos", "Aggelos K", ""], ["Shi", "Weisong", ""]]}, {"id": "2105.08244", "submitter": "DiJia Su", "authors": "Andy Su, Difei Su, John M.Mulvey, H.Vincent Poor", "title": "PoBRL: Optimizing Multi-Document Summarization by Blending Reinforcement\n  Learning Policies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel reinforcement learning based framework PoBRL for solving\nmulti-document summarization. PoBRL jointly optimizes over the following three\nobjectives necessary for a high-quality summary: importance, relevance, and\nlength. Our strategy decouples this multi-objective optimization into different\nsubproblems that can be solved individually by reinforcement learning.\nUtilizing PoBRL, we then blend each learned policies together to produce a\nsummary that is a concise and complete representation of the original input.\nOur empirical analysis shows state-of-the-art performance on several\nmulti-document datasets. Human evaluation also shows that our method produces\nhigh-quality output.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 02:55:42 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Su", "Andy", ""], ["Su", "Difei", ""], ["Mulvey", "John M.", ""], ["Poor", "H. Vincent", ""]]}, {"id": "2105.08276", "submitter": "Junbin Xiao", "authors": "Junbin Xiao, Xindi Shang, Angela Yao and Tat-Seng Chua", "title": "NExT-QA:Next Phase of Question-Answering to Explaining Temporal Actions", "comments": "To appear at CVPR2021.(Receive one 'Strong Accept'. Review comments:\n  The benchmark will be beneficial for an important video understanding\n  problem. The analysis is comprehensive and provides meaningful insights.)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We introduce NExT-QA, a rigorously designed video question answering\n(VideoQA) benchmark to advance video understanding from describing to\nexplaining the temporal actions. Based on the dataset, we set up multi-choice\nand open-ended QA tasks targeting causal action reasoning, temporal action\nreasoning, and common scene comprehension. Through extensive analysis of\nbaselines and established VideoQA techniques, we find that top-performing\nmethods excel at shallow scene descriptions but are weak in causal and temporal\naction reasoning. Furthermore, the models that are effective on multi-choice\nQA, when adapted to open-ended QA, still struggle in generalizing the answers.\nThis raises doubt on the ability of these models to reason and highlights\npossibilities for improvement. With detailed results for different question\ntypes and heuristic observations for future works, we hope NExT-QA will guide\nthe next generation of VQA research to go beyond superficial scene description\ntowards a deeper understanding of videos. (The dataset and related resources\nare available at https://github.com/doc-doc/NExT-QA.git)\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 04:56:46 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 09:37:24 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Xiao", "Junbin", ""], ["Shang", "Xindi", ""], ["Yao", "Angela", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2105.08279", "submitter": "Chang Liu", "authors": "Chang Liu, Guanjie Zheng, Zhenhui Li", "title": "Learning to Route via Theory-Guided Residual Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The heavy traffic and related issues have always been concerns for modern\ncities. With the help of deep learning and reinforcement learning, people have\nproposed various policies to solve these traffic-related problems, such as\nsmart traffic signal control systems and taxi dispatching systems. People\nusually validate these policies in a city simulator, since directly applying\nthem in the real city introduces real cost. However, these policies validated\nin the city simulator may fail in the real city if the simulator is\nsignificantly different from the real world. To tackle this problem, we need to\nbuild a real-like traffic simulation system. Therefore, in this paper, we\npropose to learn the human routing model, which is one of the most essential\npart in the traffic simulator. This problem has two major challenges. First,\nhuman routing decisions are determined by multiple factors, besides the common\ntime and distance factor. Second, current historical routes data usually covers\njust a small portion of vehicles, due to privacy and device availability\nissues. To address these problems, we propose a theory-guided residual network\nmodel, where the theoretical part can emphasize the general principles for\nhuman routing decisions (e.g., fastest route), and the residual part can\ncapture drivable condition preferences (e.g., local road or highway). Since the\ntheoretical part is composed of traditional shortest path algorithms that do\nnot need data to train, our residual network can learn human routing models\nfrom limited data. We have conducted extensive experiments on multiple\nreal-world datasets to show the superior performance of our model, especially\nwith small data. Besides, we have also illustrated why our model is better at\nrecovering real routes through case studies.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 05:07:34 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 09:08:57 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Liu", "Chang", ""], ["Zheng", "Guanjie", ""], ["Li", "Zhenhui", ""]]}, {"id": "2105.08304", "submitter": "Jesus Cerquides", "authors": "Jesus Cerquides", "title": "Parametrization invariant interpretation of priors and posteriors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.AI cs.LG stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we leverage on probability over Riemannian manifolds to rethink\nthe interpretation of priors and posteriors in Bayesian inference. The main\nmindshift is to move away from the idea that \"a prior distribution establishes\na probability distribution over the parameters of our model\" to the idea that\n\"a prior distribution establishes a probability distribution over probability\ndistributions\". To do that we assume that our probabilistic model is a\nRiemannian manifold with the Fisher metric. Under this mindset, any\ndistribution over probability distributions should be \"intrinsic\", that is,\ninvariant to the specific parametrization which is selected for the manifold.\nWe exemplify our ideas through a simple analysis of distributions over the\nmanifold of Bernoulli distributions. One of the major shortcomings of maximum a\nposteriori estimates is that they depend on the parametrization. Based on the\nunderstanding developed here, we can define the maximum a posteriori estimate\nwhich is independent of the parametrization.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 06:45:05 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 20:11:27 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Cerquides", "Jesus", ""]]}, {"id": "2105.08306", "submitter": "Kiran Koshy Thekumparampil", "authors": "Kiran Koshy Thekumparampil, Prateek Jain, Praneeth Netrapalli, Sewoong\n  Oh", "title": "Sample Efficient Linear Meta-Learning by Alternating Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning synthesizes and leverages the knowledge from a given set of\ntasks to rapidly learn new tasks using very little data. Meta-learning of\nlinear regression tasks, where the regressors lie in a low-dimensional\nsubspace, is an extensively-studied fundamental problem in this domain.\nHowever, existing results either guarantee highly suboptimal estimation errors,\nor require $\\Omega(d)$ samples per task (where $d$ is the data dimensionality)\nthus providing little gain over separately learning each task. In this work, we\nstudy a simple alternating minimization method (MLLAM), which alternately\nlearns the low-dimensional subspace and the regressors. We show that, for a\nconstant subspace dimension MLLAM obtains nearly-optimal estimation error,\ndespite requiring only $\\Omega(\\log d)$ samples per task. However, the number\nof samples required per task grows logarithmically with the number of tasks. To\nremedy this in the low-noise regime, we propose a novel task subset selection\nscheme that ensures the same strong statistical guarantee as MLLAM, even with\nbounded number of samples per task for arbitrarily large number of tasks.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 06:46:48 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Thekumparampil", "Kiran Koshy", ""], ["Jain", "Prateek", ""], ["Netrapalli", "Praneeth", ""], ["Oh", "Sewoong", ""]]}, {"id": "2105.08313", "submitter": "Junhao Hua", "authors": "Junhao Hua, Ling Yan, Huan Xu, Cheng Yang", "title": "Markdowns in E-Commerce Fresh Retail: A Counterfactual Prediction and\n  Multi-Period Optimization Approach", "comments": "10 pages, 7 figures, accepted to KDD'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, by leveraging abundant observational transaction data, we\npropose a novel data-driven and interpretable pricing approach for markdowns,\nconsisting of counterfactual prediction and multi-period price optimization.\nFirstly, we build a semi-parametric structural model to learn individual price\nelasticity and predict counterfactual demand. This semi-parametric model takes\nadvantage of both the predictability of nonparametric machine learning model\nand the interpretability of economic model. Secondly, we propose a multi-period\ndynamic pricing algorithm to maximize the overall profit of a perishable\nproduct over its finite selling horizon. Different with the traditional\napproaches that use the deterministic demand, we model the uncertainty of\ncounterfactual demand since it inevitably has randomness in the prediction\nprocess. Based on the stochastic model, we derive a sequential pricing strategy\nby Markov decision process, and design a two-stage algorithm to solve it. The\nproposed algorithm is very efficient. It reduces the time complexity from\nexponential to polynomial. Experimental results show the advantages of our\npricing algorithm, and the proposed framework has been successfully deployed to\nthe well-known e-commerce fresh retail scenario - Freshippo.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 07:01:37 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 11:48:10 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Hua", "Junhao", ""], ["Yan", "Ling", ""], ["Xu", "Huan", ""], ["Yang", "Cheng", ""]]}, {"id": "2105.08318", "submitter": "Hao Ding", "authors": "Hao Ding, Yifei Ma, Anoop Deoras, Yuyang Wang, Hao Wang", "title": "Zero-Shot Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance of recommender systems (RS) relies heavily on the amount of\ntraining data available. This poses a chicken-and-egg problem for early-stage\nproducts, whose amount of data, in turn, relies on the performance of their RS.\nOn the other hand, zero-shot learning promises some degree of generalization\nfrom an old dataset to an entirely new dataset. In this paper, we explore the\npossibility of zero-shot learning in RS. We develop an algorithm, dubbed\nZEro-Shot Recommenders (ZESRec), that is trained on an old dataset and\ngeneralize to a new one where there are neither overlapping users nor\noverlapping items, a setting that contrasts typical cross-domain RS that has\neither overlapping users or items. Different from categorical item indices,\ni.e., item ID, in previous methods, ZESRec uses items' natural-language\ndescriptions (or description embeddings) as their continuous indices, and\ntherefore naturally generalize to any unseen items. In terms of users, ZESRec\nbuilds upon recent advances on sequential RS to represent users using their\ninteractions with items, thereby generalizing to unseen users as well. We study\ntwo pairs of real-world RS datasets and demonstrate that ZESRec can\nsuccessfully enable recommendations in such a zero-shot setting, opening up new\nopportunities for resolving the chicken-and-egg problem for data-scarce\nstartups or early-stage products.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 07:17:37 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Ding", "Hao", ""], ["Ma", "Yifei", ""], ["Deoras", "Anoop", ""], ["Wang", "Yuyang", ""], ["Wang", "Hao", ""]]}, {"id": "2105.08326", "submitter": "Maurice Funk", "authors": "Maurice Funk, Jean Christoph Jung, Carsten Lutz", "title": "Actively Learning Concepts and Conjunctive Queries under ELr-Ontologies", "comments": "7+18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the problem to learn a concept or a query in the presence of an\nontology formulated in the description logic ELr, in Angluin's framework of\nactive learning that allows the learning algorithm to interactively query an\noracle (such as a domain expert). We show that the following can be learned in\npolynomial time: (1) EL-concepts, (2) symmetry-free ELI-concepts, and (3)\nconjunctive queries (CQs) that are chordal, symmetry-free, and of bounded\narity. In all cases, the learner can pose to the oracle membership queries\nbased on ABoxes and equivalence queries that ask whether a given concept/query\nfrom the considered class is equivalent to the target. The restriction to\nbounded arity in (3) can be removed when we admit unrestricted CQs in\nequivalence queries. We also show that EL-concepts are not polynomial query\nlearnable in the presence of ELI-ontologies.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 07:45:37 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 11:36:06 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Funk", "Maurice", ""], ["Jung", "Jean Christoph", ""], ["Lutz", "Carsten", ""]]}, {"id": "2105.08398", "submitter": "Oliver Niggemann", "authors": "Kaja Balzereit and Oliver Niggemann", "title": "Reconfiguring Hybrid Systems Using SAT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reconfiguration aims at recovering a system from a fault by automatically\nadapting the system configuration, such that the system goal can be reached\nagain. Classical approaches typically use a set of pre-defined faults for which\ncorresponding recovery actions are defined manually. This is not possible for\nmodern hybrid systems which are characterized by frequent changes. Instead,\nAI-based approaches are needed which leverage on a model of the non-faulty\nsystem and which search for a set of reconfiguration operations which will\nestablish a valid behavior again.\n  This work presents a novel algorithm which solves three main challenges: (i)\nOnly a model of the non-faulty system is needed, i.e. the faulty behavior does\nnot need to be modeled. (ii) It discretizes and reduces the search space which\noriginally is too large -- mainly due to the high number of continuous system\nvariables and control signals. (iii) It uses a SAT solver for propositional\nlogic for two purposes: First, it defines the binary concept of validity.\nSecond, it implements the search itself -- sacrificing the optimal solution for\na quick identification of an arbitrary solution. It is shown that the approach\nis able to reconfigure faults on simulated process engineering systems.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 09:50:47 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Balzereit", "Kaja", ""], ["Niggemann", "Oliver", ""]]}, {"id": "2105.08440", "submitter": "Shuxin Li", "authors": "Shuxin Li, Youzhi Zhang, Xinrun Wang, Wanqi Xue, Bo An", "title": "CFR-MIX: Solving Imperfect Information Extensive-Form Games with\n  Combinatorial Action Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world scenarios, a team of agents coordinate with each other to\ncompete against an opponent. The challenge of solving this type of game is that\nthe team's joint action space grows exponentially with the number of agents,\nwhich results in the inefficiency of the existing algorithms, e.g.,\nCounterfactual Regret Minimization (CFR). To address this problem, we propose a\nnew framework of CFR: CFR-MIX. Firstly, we propose a new strategy\nrepresentation that represents a joint action strategy using individual\nstrategies of all agents and a consistency relationship to maintain the\ncooperation between agents. To compute the equilibrium with individual\nstrategies under the CFR framework, we transform the consistency relationship\nbetween strategies to the consistency relationship between the cumulative\nregret values. Furthermore, we propose a novel decomposition method over\ncumulative regret values to guarantee the consistency relationship between the\ncumulative regret values. Finally, we introduce our new algorithm CFR-MIX which\nemploys a mixing layer to estimate cumulative regret values of joint actions as\na non-linear combination of cumulative regret values of individual actions.\nExperimental results show that CFR-MIX outperforms existing algorithms on\nvarious games significantly.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 11:19:37 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Li", "Shuxin", ""], ["Zhang", "Youzhi", ""], ["Wang", "Xinrun", ""], ["Xue", "Wanqi", ""], ["An", "Bo", ""]]}, {"id": "2105.08450", "submitter": "Yuval Shahar", "authors": "Yuval Shahar and Matan Lion", "title": "Implementation and Evaluation of a Multivariate Abstraction-Based,\n  Interval-Based Dynamic Time-Warping Method as a Similarity Measure for\n  Longitudinal Medical Records", "comments": "34 pages; 5 figures; 6 tables including three in the Appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.SC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We extended dynamic time warping (DTW) into interval-based dynamic time\nwarping (iDTW), including (A) interval-based representation (iRep): [1]\nabstracting raw, time-stamped data into interval-based abstractions, [2]\ncomparison-period scoping, [3] partitioning abstract intervals into a given\ntemporal granularity; (B) interval-based matching (iMatch): matching\npartitioned, abstract-concepts records, using a modified DTW. Using domain\nknowledge, we abstracted the raw data of medical records, for up to three\nconcepts out of four or five relevant concepts, into two interval types: State\nabstractions (e.g. LOW, HIGH) and Gradient abstractions (e.g. INCREASING,\nDECREASING). We created all uni-dimensional (State or Gradient) or\nmulti-dimensional (State and Gradient) abstraction combinations. Tasks:\nClassifying 161 oncology patients records as autologous or allogenic\nbone-marrow transplantation; classifying 125 hepatitis patients records as B or\nC hepatitis; predicting micro- or macro-albuminuria in the next year for 151\nType 2 diabetes patients. We used a k-Nearest-Neighbors majority, k=1 to\nSQRT(N), N = set size. 50,328 10-fold cross-validation experiments were\nperformed: 23,400 (Oncology), 19,800 (Hepatitis), 7,128 (Diabetes). Measures:\nArea Under the Curve (AUC), optimal Youden's Index. Paired t-tests compared\nresult vectors for equivalent configurations other than a tested variable, to\ndetermine a significant mean accuracy difference (P<0.05). Mean classification\nand prediction using abstractions was significantly better than using only raw\ntime-stamped data. In each domain, at least one abstraction combination led to\na significantly better performance than using raw data. Increasing feature\nnumber, and using multi-dimensional abstractions, enhanced performance. Unlike\nwhen using raw data, optimal performance was often reached with k=5, using\nabstractions.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 11:41:42 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Shahar", "Yuval", ""], ["Lion", "Matan", ""]]}, {"id": "2105.08475", "submitter": "Anton Korinek", "authors": "Katya Klinova and Anton Korinek", "title": "AI and Shared Prosperity", "comments": null, "journal-ref": "Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and\n  Society (AIES '21)", "doi": "10.1145/3461702.3462619", "report-no": null, "categories": "cs.AI cs.CY econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future advances in AI that automate away human labor may have stark\nimplications for labor markets and inequality. This paper proposes a framework\nto analyze the effects of specific types of AI systems on the labor market,\nbased on how much labor demand they will create versus displace, while taking\ninto account that productivity gains also make society wealthier and thereby\ncontribute to additional labor demand. This analysis enables ethically-minded\ncompanies creating or deploying AI systems as well as researchers and\npolicymakers to take into account the effects of their actions on labor markets\nand inequality, and therefore to steer progress in AI in a direction that\nadvances shared prosperity and an inclusive economic future for all of\nhumanity.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 12:37:18 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Klinova", "Katya", ""], ["Korinek", "Anton", ""]]}, {"id": "2105.08476", "submitter": "Quan Wang", "authors": "Quan Wang, Haifeng Wang, Yajuan Lyu, Yong Zhu", "title": "Link Prediction on N-ary Relational Facts: A Graph-based Approach", "comments": "Accepted to Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Link prediction on knowledge graphs (KGs) is a key research topic. Previous\nwork mainly focused on binary relations, paying less attention to higher-arity\nrelations although they are ubiquitous in real-world KGs. This paper considers\nlink prediction upon n-ary relational facts and proposes a graph-based approach\nto this task. The key to our approach is to represent the n-ary structure of a\nfact as a small heterogeneous graph, and model this graph with edge-biased\nfully-connected attention. The fully-connected attention captures universal\ninter-vertex interactions, while with edge-aware attentive biases to\nparticularly encode the graph structure and its heterogeneity. In this fashion,\nour approach fully models global and local dependencies in each n-ary fact, and\nhence can more effectively capture associations therein. Extensive evaluation\nverifies the effectiveness and superiority of our approach. It performs\nsubstantially and consistently better than current state-of-the-art across a\nvariety of n-ary relational benchmarks. Our code is publicly available.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 12:40:35 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Wang", "Quan", ""], ["Wang", "Haifeng", ""], ["Lyu", "Yajuan", ""], ["Zhu", "Yong", ""]]}, {"id": "2105.08484", "submitter": "Miguel Gonz\\'alez-Duque", "authors": "Miguel Gonz\\'alez-Duque, Rasmus Berg Palm and Sebastian Risi", "title": "Fast Game Content Adaptation Through Bayesian-based Player Modelling", "comments": "Accepted at CoG2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In games, as well as many user-facing systems, adapting content to users'\npreferences and experience is an important challenge. This paper explores a\nnovel method to realize this goal in the context of dynamic difficulty\nadjustment (DDA). Here the aim is to constantly adapt the content of a game to\nthe skill level of the player, keeping them engaged by avoiding states that are\neither too difficult or too easy. Current systems for DDA rely on expensive\ndata mining, or on hand-crafted rules designed for particular domains, and\nusually adapts to keep players in the flow, leaving no room for the designer to\npresent content that is purposefully easy or difficult. This paper presents\nFast Bayesian Content Adaption (FBCA), a system for DDA that is agnostic to the\ndomain and that can target particular difficulties. We deploy this framework in\ntwo different domains: the puzzle game Sudoku, and a simple Roguelike game. By\nmodifying the acquisition function's optimization, we are reliably able to\npresent a content with a bespoke difficulty for players with different skill\nlevels in less than five iterations for Sudoku and fifteen iterations for the\nsimple Roguelike. Our method significantly outperforms simpler DDA heuristics\nwith the added benefit of maintaining a model of the user. These results point\ntowards a promising alternative for content adaption in a variety of different\ndomains.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 12:56:44 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 22:25:53 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Gonz\u00e1lez-Duque", "Miguel", ""], ["Palm", "Rasmus Berg", ""], ["Risi", "Sebastian", ""]]}, {"id": "2105.08489", "submitter": "Dongbo Xi", "authors": "Dongbo Xi, Zhen Chen, Peng Yan, Yinger Zhang, Yongchun Zhu, Fuzhen\n  Zhuang, Yu Chen", "title": "Modeling the Sequential Dependence among Audience Multi-step Conversions\n  with Multi-task Learning in Targeted Display Advertising", "comments": "accepted by KDD21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In most real-world large-scale online applications (e.g., e-commerce or\nfinance), customer acquisition is usually a multi-step conversion process of\naudiences. For example, an impression->click->purchase process is usually\nperformed of audiences for e-commerce platforms. However, it is more difficult\nto acquire customers in financial advertising (e.g., credit card advertising)\nthan in traditional advertising. On the one hand, the audience multi-step\nconversion path is longer. On the other hand, the positive feedback is sparser\n(class imbalance) step by step, and it is difficult to obtain the final\npositive feedback due to the delayed feedback of activation. Multi-task\nlearning is a typical solution in this direction. While considerable multi-task\nefforts have been made in this direction, a long-standing challenge is how to\nexplicitly model the long-path sequential dependence among audience multi-step\nconversions for improving the end-to-end conversion. In this paper, we propose\nan Adaptive Information Transfer Multi-task (AITM) framework, which models the\nsequential dependence among audience multi-step conversions via the Adaptive\nInformation Transfer (AIT) module. The AIT module can adaptively learn what and\nhow much information to transfer for different conversion stages. Besides, by\ncombining the Behavioral Expectation Calibrator in the loss function, the AITM\nframework can yield more accurate end-to-end conversion identification. The\nproposed framework is deployed in Meituan app, which utilizes it to real-timely\nshow a banner to the audience with a high end-to-end conversion rate for\nMeituan Co-Branded Credit Cards. Offline experimental results on both\nindustrial and public real-world datasets clearly demonstrate that the proposed\nframework achieves significantly better performance compared with\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 13:07:12 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 02:46:16 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Xi", "Dongbo", ""], ["Chen", "Zhen", ""], ["Yan", "Peng", ""], ["Zhang", "Yinger", ""], ["Zhu", "Yongchun", ""], ["Zhuang", "Fuzhen", ""], ["Chen", "Yu", ""]]}, {"id": "2105.08541", "submitter": "Theresa Eimer", "authors": "Theresa Eimer, Andr\\'e Biedenkapp, Maximilian Reimer, Steven\n  Adriaensen, Frank Hutter, Marius Lindauer", "title": "DACBench: A Benchmark Library for Dynamic Algorithm Configuration", "comments": "Accepted at IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Algorithm Configuration (DAC) aims to dynamically control a target\nalgorithm's hyperparameters in order to improve its performance. Several\ntheoretical and empirical results have demonstrated the benefits of dynamically\ncontrolling hyperparameters in domains like evolutionary computation, AI\nPlanning or deep learning. Replicating these results, as well as studying new\nmethods for DAC, however, is difficult since existing benchmarks are often\nspecialized and incompatible with the same interfaces. To facilitate\nbenchmarking and thus research on DAC, we propose DACBench, a benchmark library\nthat seeks to collect and standardize existing DAC benchmarks from different AI\ndomains, as well as provide a template for new ones. For the design of\nDACBench, we focused on important desiderata, such as (i) flexibility, (ii)\nreproducibility, (iii) extensibility and (iv) automatic documentation and\nvisualization. To show the potential, broad applicability and challenges of\nDAC, we explore how a set of six initial benchmarks compare in several\ndimensions of difficulty.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 14:16:51 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Eimer", "Theresa", ""], ["Biedenkapp", "Andr\u00e9", ""], ["Reimer", "Maximilian", ""], ["Adriaensen", "Steven", ""], ["Hutter", "Frank", ""], ["Lindauer", "Marius", ""]]}, {"id": "2105.08584", "submitter": "Gongfan Fang", "authors": "Gongfan Fang, Jie Song, Xinchao Wang, Chengchao Shen, Xingen Wang,\n  Mingli Song", "title": "Contrastive Model Inversion for Data-Free Knowledge Distillation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model inversion, whose goal is to recover training data from a pre-trained\nmodel, has been recently proved feasible. However, existing inversion methods\nusually suffer from the mode collapse problem, where the synthesized instances\nare highly similar to each other and thus show limited effectiveness for\ndownstream tasks, such as knowledge distillation. In this paper, we propose\nContrastive Model Inversion~(CMI), where the data diversity is explicitly\nmodeled as an optimizable objective, to alleviate the mode collapse issue. Our\nmain observation is that, under the constraint of the same amount of data,\nhigher data diversity usually indicates stronger instance discrimination. To\nthis end, we introduce in CMI a contrastive learning objective that encourages\nthe synthesizing instances to be distinguishable from the already synthesized\nones in previous batches. Experiments of pre-trained models on CIFAR-10,\nCIFAR-100, and Tiny-ImageNet demonstrate that CMI not only generates more\nvisually plausible instances than the state of the arts, but also achieves\nsignificantly superior performance when the generated data are used for\nknowledge distillation. Code is available at\n\\url{https://github.com/zju-vipa/DataFree}.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 15:13:00 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Fang", "Gongfan", ""], ["Song", "Jie", ""], ["Wang", "Xinchao", ""], ["Shen", "Chengchao", ""], ["Wang", "Xingen", ""], ["Song", "Mingli", ""]]}, {"id": "2105.08587", "submitter": "Leila Karimi", "authors": "Leila Karimi, Mai Abdelhakim, James Joshi", "title": "Adaptive ABAC Policy Learning: A Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapid advances in computing systems, there is an increasing demand for\nmore effective and efficient access control (AC) approaches. Recently,\nAttribute Based Access Control (ABAC) approaches have been shown to be\npromising in fulfilling the AC needs of such emerging complex computing\nenvironments. An ABAC model grants access to a requester based on attributes of\nentities in a system and an authorization policy; however, its generality and\nflexibility come with a higher cost. Further, increasing complexities of\norganizational systems and the need for federated accesses to their resources\nmake the task of AC enforcement and management much more challenging. In this\npaper, we propose an adaptive ABAC policy learning approach to automate the\nauthorization management task. We model ABAC policy learning as a reinforcement\nlearning problem. In particular, we propose a contextual bandit system, in\nwhich an authorization engine adapts an ABAC model through a feedback control\nloop; it relies on interacting with users/administrators of the system to\nreceive their feedback that assists the model in making authorization\ndecisions. We propose four methods for initializing the learning model and a\nplanning approach based on attribute value hierarchy to accelerate the learning\nprocess. We focus on developing an adaptive ABAC policy learning model for a\nhome IoT environment as a running example. We evaluate our proposed approach\nover real and synthetic data. We consider both complete and sparse datasets in\nour evaluations. Our experimental results show that the proposed approach\nachieves performance that is comparable to ones based on supervised learning in\nmany scenarios and even outperforms them in several situations.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 15:18:02 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Karimi", "Leila", ""], ["Abdelhakim", "Mai", ""], ["Joshi", "James", ""]]}, {"id": "2105.08601", "submitter": "Lifeng Zhou", "authors": "Lifeng Zhou, Vishnu D. Sharma, Qingbiao Li, Amanda Prorok, Alejandro\n  Ribeiro, Vijay Kumar", "title": "Graph Neural Networks for Decentralized Multi-Robot Submodular Action\n  Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a learning-based approach for decentralized\nsubmodular maximization. We focus on applications where robots are required to\njointly select actions, e.g., motion primitives, to maximize team submodular\nobjectives with local communications only. Such applications are essential for\nlarge-scale multi-robot coordination such as multi-robot motion planning for\narea coverage, environment exploration, and target tracking. But the current\ndecentralized submodular maximization algorithms either require assumptions on\nthe inter-robot communication or lose some suboptimal guarantees. In this work,\nwe propose a general-purpose learning architecture towards submodular\nmaximization at scale, with decentralized communications. Particularly, our\nlearning architecture leverages a graph neural network (GNN) to capture local\ninteractions of the robots and learns decentralized decision-making for the\nrobots. We train the learning model by imitating an expert solution and\nimplement the resulting model for decentralized action selection involving\nlocal observations and communications only. We demonstrate the performance of\nour GNN-based learning approach in a scenario of active target coverage with\nlarge networks of robots. The simulation results show our approach nearly\nmatches the coverage performance of the expert algorithm, and yet runs several\norders faster with more than 30 robots. The results also exhibit our approach's\ngeneralization capability in previously unseen scenarios, e.g., larger\nenvironments and larger networks of robots.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 15:32:07 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Zhou", "Lifeng", ""], ["Sharma", "Vishnu D.", ""], ["Li", "Qingbiao", ""], ["Prorok", "Amanda", ""], ["Ribeiro", "Alejandro", ""], ["Kumar", "Vijay", ""]]}, {"id": "2105.08621", "submitter": "Megha Khosla", "authors": "Thorben Funke, Megha Khosla, Avishek Anand", "title": "Zorro: Valid, Sparse, and Stable Explanations in Graph Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the ever-increasing popularity and applications of graph neural\nnetworks, several proposals have been made to interpret and understand the\ndecisions of a GNN model. Explanations for a GNN model differ in principle from\nother input settings. It is important to attribute the decision to input\nfeatures and other related instances connected by the graph structure. We find\nthat the previous explanation generation approaches that maximize the mutual\ninformation between the label distribution produced by the GNN model and the\nexplanation to be restrictive. Specifically, existing approaches do not enforce\nexplanations to be predictive, sparse, or robust to input perturbations.\n  In this paper, we lay down some of the fundamental principles that an\nexplanation method for GNNs should follow and introduce a metric fidelity as a\nmeasure of the explanation's effectiveness. We propose a novel approach Zorro\nbased on the principles from rate-distortion theory that uses a simple\ncombinatorial procedure to optimize for fidelity. Extensive experiments on real\nand synthetic datasets reveal that Zorro produces sparser, stable, and more\nfaithful explanations than existing GNN explanation approaches.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 15:53:09 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Funke", "Thorben", ""], ["Khosla", "Megha", ""], ["Anand", "Avishek", ""]]}, {"id": "2105.08625", "submitter": "Xiangzhe Kong", "authors": "Xiangzhe Kong, Jialiang Huang, Ziquan Tung, Jian Guan and Minlie Huang", "title": "Stylized Story Generation with Style-Guided Planning", "comments": "9 pages, 3 figures. Will be included in Findings of ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current storytelling systems focus more ongenerating stories with coherent\nplots regard-less of the narration style, which is impor-tant for controllable\ntext generation. There-fore, we propose a new task, stylized story gen-eration,\nnamely generating stories with speci-fied style given a leading context. To\ntacklethe problem, we propose a novel generationmodel that first plans the\nstylized keywordsand then generates the whole story with theguidance of the\nkeywords. Besides, we pro-pose two automatic metrics to evaluate theconsistency\nbetween the generated story andthe specified style. Experiments\ndemonstratesthat our model can controllably generateemo-tion-driven\norevent-driven stories based onthe ROCStories dataset (Mostafazadeh et\nal.,2016). Our study presents insights for stylizedstory generation in further\nresearch.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 15:55:38 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 15:54:05 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Kong", "Xiangzhe", ""], ["Huang", "Jialiang", ""], ["Tung", "Ziquan", ""], ["Guan", "Jian", ""], ["Huang", "Minlie", ""]]}, {"id": "2105.08643", "submitter": "Zekai Chen", "authors": "Zekai Chen, Maiwang Shi, Xiao Zhang, Haochao Ying", "title": "ASM2TV: An Adaptive Semi-Supervised Multi-Task Multi-View Learning\n  Framework", "comments": "7 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world scenarios, such as human activity recognition (HAR) in IoT,\ncan be formalized as a multi-task multi-view learning problem. Each specific\ntask consists of multiple shared feature views collected from multiple sources,\neither homogeneous or heterogeneous. Common among recent approaches is to\nemploy a typical hard/soft sharing strategy at the initial phase separately for\neach view across tasks to uncover common knowledge, underlying the assumption\nthat all views are conditionally independent. On the one hand, multiple views\nacross tasks possibly relate to each other under practical situations. On the\nother hand, supervised methods might be insufficient when labeled data is\nscarce. To tackle these challenges, we introduce a novel framework ASM2TV for\nsemi-supervised multi-task multi-view learning. We present a new perspective\nnamed gating control policy, a learnable task-view-interacted sharing policy\nthat adaptively selects the most desirable candidate shared block for any view\nacross any task, which uncovers more fine-grained task-view-interacted\nrelatedness and improves inference efficiency. Significantly, our proposed\ngathering consistency adaption procedure takes full advantage of large amounts\nof unlabeled fragmented time-series, making it a general framework that\naccommodates a wide range of applications. Experiments on two diverse\nreal-world HAR benchmark datasets collected from various subjects and sources\ndemonstrate our framework's superiority over other state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 16:15:32 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Chen", "Zekai", ""], ["Shi", "Maiwang", ""], ["Zhang", "Xiao", ""], ["Ying", "Haochao", ""]]}, {"id": "2105.08645", "submitter": "Long Phan", "authors": "Long Phan, Hieu Tran, Daniel Le, Hieu Nguyen, James Anibal, Alec\n  Peltekian, and Yanfang Ye", "title": "CoTexT: Multi-task Learning with Code-Text Transformer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present CoTexT, a pre-trained, transformer-based encoder-decoder model\nthat learns the representative context between natural language (NL) and\nprogramming language (PL). Using self-supervision, CoTexT is pre-trained on\nlarge programming language corpora to learn a general understanding of language\nand code. CoTexT supports downstream NL-PL tasks such as code\nsummarizing/documentation, code generation, defect detection, and code\ndebugging. We train CoTexT on different combinations of available PL corpus\nincluding both \"bimodal\" and \"unimodal\" data. Here, bimodal data is the\ncombination of text and corresponding code snippets, whereas unimodal data is\nmerely code snippets. We first evaluate CoTexT with multi-task learning: we\nperform Code Summarization on 6 different programming languages and Code\nRefinement on both small and medium size featured in the CodeXGLUE dataset. We\nfurther conduct extensive experiments to investigate CoTexT on other tasks\nwithin the CodeXGlue dataset, including Code Generation and Defect Detection.\nWe consistently achieve SOTA results in these tasks, demonstrating the\nversatility of our models.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 16:22:05 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 05:42:26 GMT"}, {"version": "v3", "created": "Sat, 12 Jun 2021 08:41:01 GMT"}, {"version": "v4", "created": "Mon, 21 Jun 2021 11:34:45 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Phan", "Long", ""], ["Tran", "Hieu", ""], ["Le", "Daniel", ""], ["Nguyen", "Hieu", ""], ["Anibal", "James", ""], ["Peltekian", "Alec", ""], ["Ye", "Yanfang", ""]]}, {"id": "2105.08647", "submitter": "Javier Lorenzo D\\'iaz", "authors": "J. Lorenzo, I. Parra and M. A. Sotelo", "title": "IntFormer: Predicting pedestrian intention with the aid of the\n  Transformer architecture", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Understanding pedestrian crossing behavior is an essential goal in\nintelligent vehicle development, leading to an improvement in their security\nand traffic flow. In this paper, we developed a method called IntFormer. It is\nbased on transformer architecture and a novel convolutional video\nclassification model called RubiksNet. Following the evaluation procedure in a\nrecent benchmark, we show that our model reaches state-of-the-art results with\ngood performance ($\\approx 40$ seq. per second) and size ($8\\times $smaller\nthan the best performing model), making it suitable for real-time usage. We\nalso explore each of the input features, finding that ego-vehicle speed is the\nmost important variable, possibly due to the similarity in crossing cases in\nPIE dataset.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 16:23:15 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Lorenzo", "J.", ""], ["Parra", "I.", ""], ["Sotelo", "M. A.", ""]]}, {"id": "2105.08649", "submitter": "Zekai Chen", "authors": "Zekai Chen, Fangtian Zhong, Zhumin Chen, Xiao Zhang, Robert Pless,\n  Xiuzhen Cheng", "title": "DCAP: Deep Cross Attentional Product Network for User Response\n  Prediction", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User response prediction, which aims to predict the probability that a user\nwill provide a predefined positive response in a given context such as clicking\non an ad or purchasing an item, is crucial to many industrial applications such\nas online advertising, recommender systems, and search ranking. However, due to\nthe high dimensionality and super sparsity of the data collected in these\ntasks, handcrafting cross features is inevitably time expensive. Prior studies\nin predicting user response leveraged the feature interactions by enhancing\nfeature vectors with products of features to model second-order or high-order\ncross features, either explicitly or implicitly. Nevertheless, these existing\nmethods can be hindered by not learning sufficient cross features due to model\narchitecture limitations or modeling all high-order feature interactions with\nequal weights. This work aims to fill this gap by proposing a novel\narchitecture Deep Cross Attentional Product Network (DCAP), which keeps cross\nnetwork's benefits in modeling high-order feature interactions explicitly at\nthe vector-wise level. Beyond that, it can differentiate the importance of\ndifferent cross features in each network layer inspired by the multi-head\nattention mechanism and Product Neural Network (PNN), allowing practitioners to\nperform a more in-depth analysis of user behaviors. Additionally, our proposed\nmodel can be easily implemented and train in parallel. We conduct comprehensive\nexperiments on three real-world datasets. The results have robustly\ndemonstrated that our proposed model DCAP achieves superior prediction\nperformance compared with the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 16:27:20 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Chen", "Zekai", ""], ["Zhong", "Fangtian", ""], ["Chen", "Zhumin", ""], ["Zhang", "Xiao", ""], ["Pless", "Robert", ""], ["Cheng", "Xiuzhen", ""]]}, {"id": "2105.08655", "submitter": "Abhiraj Tiwari", "authors": "Sahil Khose, Abhiraj Tiwari, Ankita Ghosh", "title": "Semi-Supervised Classification and Segmentation on High Resolution\n  Aerial Images", "comments": "5 pages, 2 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FloodNet is a high-resolution image dataset acquired by a small UAV platform,\nDJI Mavic Pro quadcopters, after Hurricane Harvey. The dataset presents a\nunique challenge of advancing the damage assessment process for post-disaster\nscenarios using unlabeled and limited labeled dataset. We propose a solution to\naddress their classification and semantic segmentation challenge. We approach\nthis problem by generating pseudo labels for both classification and\nsegmentation during training and slowly incrementing the amount by which the\npseudo label loss affects the final loss. Using this semi-supervised method of\ntraining helped us improve our baseline supervised loss by a huge margin for\nclassification, allowing the model to generalize and perform better on the\nvalidation and test splits of the dataset. In this paper, we compare and\ncontrast the various methods and models for image classification and semantic\nsegmentation on the FloodNet dataset.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 09:30:03 GMT"}, {"version": "v2", "created": "Thu, 24 Jun 2021 17:45:20 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Khose", "Sahil", ""], ["Tiwari", "Abhiraj", ""], ["Ghosh", "Ankita", ""]]}, {"id": "2105.08666", "submitter": "Jing-Cheng Pang", "authors": "Jing-Cheng Pang, Tian Xu, Sheng-Yi Jiang, Yu-Ren Liu, Yang Yu", "title": "Sparsity Prior Regularized Q-learning for Sparse Action Tasks", "comments": "Reinforcement learning; Sparse action task", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many decision-making tasks, some specific actions are limited in their\nfrequency or total amounts, such as \"fire\" in the gunfight game and \"buy/sell\"\nin the stock trading. We name such actions as \"sparse action\". Sparse action\noften plays a crucial role in achieving good performance. However, their\nQ-values, estimated by \\emph{classical Bellman update}, usually suffer from a\nlarge estimation error due to the sparsity of their samples. The \\emph{greedy}\npolicy could be greatly misled by the biased Q-function and takes sparse action\naggressively, which leads to a huge sub-optimality. This paper constructs a\nreference distribution that assigns a low probability to sparse action and\nproposes a regularized objective with an explicit constraint to the reference\ndistribution. Furthermore, we derive a regularized Bellman operator and a\nregularized optimal policy that can slow down the propagation of error and\nguide the agent to take sparse action more carefully. The experiment results\ndemonstrate that our method achieves state-of-the-art performance on typical\nsparse action tasks.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 16:50:42 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 02:15:07 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Pang", "Jing-Cheng", ""], ["Xu", "Tian", ""], ["Jiang", "Sheng-Yi", ""], ["Liu", "Yu-Ren", ""], ["Yu", "Yang", ""]]}, {"id": "2105.08683", "submitter": "Luca Costabello", "authors": "Sumit Pai, Luca Costabello", "title": "Learning Embeddings from Knowledge Graphs With Numeric Edge Attributes", "comments": "IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Numeric values associated to edges of a knowledge graph have been used to\nrepresent uncertainty, edge importance, and even out-of-band knowledge in a\ngrowing number of scenarios, ranging from genetic data to social networks.\nNevertheless, traditional knowledge graph embedding models are not designed to\ncapture such information, to the detriment of predictive power. We propose a\nnovel method that injects numeric edge attributes into the scoring layer of a\ntraditional knowledge graph embedding architecture. Experiments with publicly\navailable numeric-enriched knowledge graphs show that our method outperforms\ntraditional numeric-unaware baselines as well as the recent UKGE model.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:15:01 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Pai", "Sumit", ""], ["Costabello", "Luca", ""]]}, {"id": "2105.08692", "submitter": "Bo Liu", "authors": "Bo Liu, Qiang Liu, Peter Stone, Animesh Garg, Yuke Zhu and Animashree\n  Anandkumar", "title": "Coach-Player Multi-Agent Reinforcement Learning for Dynamic Team\n  Composition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In real-world multi-agent systems, agents with different capabilities may\njoin or leave without altering the team's overarching goals. Coordinating teams\nwith such dynamic composition is challenging: the optimal team strategy varies\nwith the composition. We propose COPA, a coach-player framework to tackle this\nproblem. We assume the coach has a global view of the environment and\ncoordinates the players, who only have partial views, by distributing\nindividual strategies. Specifically, we 1) adopt the attention mechanism for\nboth the coach and the players; 2) propose a variational objective to\nregularize learning; and 3) design an adaptive communication method to let the\ncoach decide when to communicate with the players. We validate our methods on a\nresource collection task, a rescue game, and the StarCraft micromanagement\ntasks. We demonstrate zero-shot generalization to new team compositions. Our\nmethod achieves comparable or better performance than the setting where all\nplayers have a full view of the environment. Moreover, we see that the\nperformance remains high even when the coach communicates as little as 13% of\nthe time using the adaptive communication strategy.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:27:37 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 16:03:59 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Liu", "Bo", ""], ["Liu", "Qiang", ""], ["Stone", "Peter", ""], ["Garg", "Animesh", ""], ["Zhu", "Yuke", ""], ["Anandkumar", "Animashree", ""]]}, {"id": "2105.08710", "submitter": "Anirudh Goyal", "authors": "Kanika Madan, Nan Rosemary Ke, Anirudh Goyal, Bernhard Sch\\\"olkopf,\n  Yoshua Bengio", "title": "Fast and Slow Learning of Recurrent Independent Mechanisms", "comments": "Accepted at ICLR'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decomposing knowledge into interchangeable pieces promises a generalization\nadvantage when there are changes in distribution. A learning agent interacting\nwith its environment is likely to be faced with situations requiring novel\ncombinations of existing pieces of knowledge. We hypothesize that such a\ndecomposition of knowledge is particularly relevant for being able to\ngeneralize in a systematic manner to out-of-distribution changes. To study\nthese ideas, we propose a particular training framework in which we assume that\nthe pieces of knowledge an agent needs and its reward function are stationary\nand can be re-used across tasks. An attention mechanism dynamically selects\nwhich modules can be adapted to the current task, and the parameters of the\nselected modules are allowed to change quickly as the learner is confronted\nwith variations in what it experiences, while the parameters of the attention\nmechanisms act as stable, slowly changing, meta-parameters. We focus on pieces\nof knowledge captured by an ensemble of modules sparsely communicating with\neach other via a bottleneck of attention. We find that meta-learning the\nmodular aspects of the proposed system greatly helps in achieving faster\nadaptation in a reinforcement learning setup involving navigation in a\npartially observed grid world with image-level input. We also find that\nreversing the role of parameters and meta-parameters does not work nearly as\nwell, suggesting a particular role for fast adaptation of the dynamically\nselected modules.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:50:32 GMT"}, {"version": "v2", "created": "Wed, 19 May 2021 03:10:30 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Madan", "Kanika", ""], ["Ke", "Nan Rosemary", ""], ["Goyal", "Anirudh", ""], ["Sch\u00f6lkopf", "Bernhard", ""], ["Bengio", "Yoshua", ""]]}, {"id": "2105.08715", "submitter": "Mohammed Daoudi", "authors": "Baptiste Chopin, Naima Otberdout, Mohamed Daoudi, Angela Bartolo", "title": "Human Motion Prediction Using Manifold-Aware Wasserstein GAN", "comments": "IEEE International Conference on Automatic Face and Gesture\n  Recognition 2021 Jodhpur, India December 15 - 18, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human motion prediction aims to forecast future human poses given a prior\npose sequence. The discontinuity of the predicted motion and the performance\ndeterioration in long-term horizons are still the main challenges encountered\nin current literature. In this work, we tackle these issues by using a compact\nmanifold-valued representation of human motion. Specifically, we model the\ntemporal evolution of the 3D human poses as trajectory, what allows us to map\nhuman motions to single points on a sphere manifold. To learn these\nnon-Euclidean representations, we build a manifold-aware Wasserstein generative\nadversarial model that captures the temporal and spatial dependencies of human\nmotion through different losses. Extensive experiments show that our approach\noutperforms the state-of-the-art on CMU MoCap and Human 3.6M datasets. Our\nqualitative results show the smoothness of the predicted motions.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:56:10 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 21:16:53 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Chopin", "Baptiste", ""], ["Otberdout", "Naima", ""], ["Daoudi", "Mohamed", ""], ["Bartolo", "Angela", ""]]}, {"id": "2105.08741", "submitter": "Dominik Dold", "authors": "Josep Soler Garrido, Dominik Dold, Johannes Frank", "title": "Machine learning on knowledge graphs for context-aware security\n  monitoring", "comments": "Accepted for publication at IEEE-CSR 2021. Data is available on\n  https://github.com/dodo47/cyberML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine learning techniques are gaining attention in the context of intrusion\ndetection due to the increasing amounts of data generated by monitoring tools,\nas well as the sophistication displayed by attackers in hiding their activity.\nHowever, existing methods often exhibit important limitations in terms of the\nquantity and relevance of the generated alerts. Recently, knowledge graphs are\nfinding application in the cybersecurity domain, showing the potential to\nalleviate some of these drawbacks thanks to their ability to seamlessly\nintegrate data from multiple domains using human-understandable vocabularies.\nWe discuss the application of machine learning on knowledge graphs for\nintrusion detection and experimentally evaluate a link-prediction method for\nscoring anomalous activity in industrial systems. After initial unsupervised\ntraining, the proposed method is shown to produce intuitively well-calibrated\nand interpretable alerts in a diverse range of scenarios, hinting at the\npotential benefits of relational machine learning on knowledge graphs for\nintrusion detection purposes.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 18:00:19 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Garrido", "Josep Soler", ""], ["Dold", "Dominik", ""], ["Frank", "Johannes", ""]]}, {"id": "2105.08781", "submitter": "Yuanpeng He", "authors": "Yuanpeng He", "title": "Fortified quantum mass function utilizing ordinal pictorial check based\n  on time interval analysis and expertise", "comments": "33 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information management has enter a completely new era, quantum era. However,\nthere exists a lack of sufficient theory to extract truly useful quantum\ninformation and transfer it to a form which is intuitive and straightforward\nfor decision making. Therefore, based on the quantum model of mass function, a\nfortified dual check system is proposed to ensure the judgment generated\nretains enough high accuracy. Moreover, considering the situations in real\nlife, everything takes place in an observable time interval, then the concept\nof time interval is introduced into the frame of the check system. The proposed\nmodel is very helpful in disposing uncertain quantum information in this paper.\nAnd some applications are provided to verify the rationality and correctness of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 05:30:16 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["He", "Yuanpeng", ""]]}, {"id": "2105.08791", "submitter": "Xiaocheng Tang", "authors": "Xiaocheng Tang, Fan Zhang, Zhiwei Qin, Yansheng Wang, Dingyuan Shi,\n  Bingchen Song, Yongxin Tong, Hongtu Zhu, Jieping Ye", "title": "Value Function is All You Need: A Unified Learning Framework for Ride\n  Hailing Platforms", "comments": "KDD 2021; Ride-hailing marketplace open simulation platform:\n  https://outreach.didichuxing.com/Simulation/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Large ride-hailing platforms, such as DiDi, Uber and Lyft, connect tens of\nthousands of vehicles in a city to millions of ride demands throughout the day,\nproviding great promises for improving transportation efficiency through the\ntasks of order dispatching and vehicle repositioning. Existing studies,\nhowever, usually consider the two tasks in simplified settings that hardly\naddress the complex interactions between the two, the real-time fluctuations\nbetween supply and demand, and the necessary coordinations due to the\nlarge-scale nature of the problem. In this paper we propose a unified\nvalue-based dynamic learning framework (V1D3) for tackling both tasks. At the\ncenter of the framework is a globally shared value function that is updated\ncontinuously using online experiences generated from real-time platform\ntransactions. To improve the sample-efficiency and the robustness, we further\npropose a novel periodic ensemble method combining the fast online learning\nwith a large-scale offline training scheme that leverages the abundant\nhistorical driver trajectory data. This allows the proposed framework to adapt\nquickly to the highly dynamic environment, to generalize robustly to recurrent\npatterns and to drive implicit coordinations among the population of managed\nvehicles. Extensive experiments based on real-world datasets show considerably\nimprovements over other recently proposed methods on both tasks. Particularly,\nV1D3 outperforms the first prize winners of both dispatching and repositioning\ntracks in the KDD Cup 2020 RL competition, achieving state-of-the-art results\non improving both total driver income and user experience related metrics.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 19:22:24 GMT"}, {"version": "v2", "created": "Thu, 20 May 2021 01:04:34 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 08:08:31 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Tang", "Xiaocheng", ""], ["Zhang", "Fan", ""], ["Qin", "Zhiwei", ""], ["Wang", "Yansheng", ""], ["Shi", "Dingyuan", ""], ["Song", "Bingchen", ""], ["Tong", "Yongxin", ""], ["Zhu", "Hongtu", ""], ["Ye", "Jieping", ""]]}, {"id": "2105.08820", "submitter": "Udit Gupta", "authors": "Udit Gupta, Samuel Hsia, Jeff Zhang, Mark Wilkening, Javin Pombra,\n  Hsien-Hsin S. Lee, Gu-Yeon Wei, Carole-Jean Wu, David Brooks", "title": "RecPipe: Co-designing Models and Hardware to Jointly Optimize\n  Recommendation Quality and Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning recommendation systems must provide high quality, personalized\ncontent under strict tail-latency targets and high system loads. This paper\npresents RecPipe, a system to jointly optimize recommendation quality and\ninference performance. Central to RecPipe is decomposing recommendation models\ninto multi-stage pipelines to maintain quality while reducing compute\ncomplexity and exposing distinct parallelism opportunities. RecPipe implements\nan inference scheduler to map multi-stage recommendation engines onto\ncommodity, heterogeneous platforms (e.g., CPUs, GPUs).While the hardware-aware\nscheduling improves ranking efficiency, the commodity platforms suffer from\nmany limitations requiring specialized hardware. Thus, we design RecPipeAccel\n(RPAccel), a custom accelerator that jointly optimizes quality, tail-latency,\nand system throughput. RPAc-cel is designed specifically to exploit the\ndistinct design space opened via RecPipe. In particular, RPAccel processes\nqueries in sub-batches to pipeline recommendation stages, implements dual\nstatic and dynamic embedding caches, a set of top-k filtering units, and a\nreconfigurable systolic array. Com-pared to prior-art and at iso-quality, we\ndemonstrate that RPAccel improves latency and throughput by 3x and 6x.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 20:44:04 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 17:41:29 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Gupta", "Udit", ""], ["Hsia", "Samuel", ""], ["Zhang", "Jeff", ""], ["Wilkening", "Mark", ""], ["Pombra", "Javin", ""], ["Lee", "Hsien-Hsin S.", ""], ["Wei", "Gu-Yeon", ""], ["Wu", "Carole-Jean", ""], ["Brooks", "David", ""]]}, {"id": "2105.08832", "submitter": "Pedro Cisneros-Velarde", "authors": "Pedro Cisneros-Velarde, Francesco Bullo", "title": "A Contraction Theory Approach to Optimization Algorithms from\n  Acceleration Flows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much recent interest has focused on the design of optimization algorithms\nfrom the discretization of an associated optimization flow, i.e., a system of\ndifferential equations (ODEs) whose trajectories solve an associated\noptimization problem. Such a design approach poses an important problem: how to\nfind a principled methodology to design and discretize appropriate ODEs. This\npaper aims to provide a solution to this problem through the use of contraction\ntheory. We first introduce general mathematical results that explain how\ncontraction theory guarantees the stability of the implicit and explicit Euler\nintegration methods. Then, we propose a novel system of ODEs, namely the\nAccelerated-Contracting-Nesterov flow, and use contraction theory to establish\nit is an optimization flow with exponential convergence rate, from which the\nlinear convergence rate of its associated optimization algorithm is immediately\nestablished. Remarkably, a simple explicit Euler discretization of this flow\ncorresponds to the Nesterov acceleration method. Finally, we present how our\napproach leads to performance guarantees in the design of optimization\nalgorithms for time-varying optimization problems.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 21:11:37 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Cisneros-Velarde", "Pedro", ""], ["Bullo", "Francesco", ""]]}, {"id": "2105.08847", "submitter": "Michael Madaio", "authors": "Michael Madaio, Su Lin Blodgett, Elijah Mayfield, Ezekiel\n  Dixon-Rom\\'an", "title": "Confronting Structural Inequities in AI for Education", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Educational technologies, and the systems of schooling in which they are\ndeployed, enact particular ideologies about what is important to know and how\nlearners should learn. As artificial intelligence technologies -- in education\nand beyond -- have led to inequitable outcomes for marginalized communities,\nvarious approaches have been developed to evaluate and mitigate AI systems'\ndisparate impact. However, we argue in this paper that the dominant paradigm of\nevaluating fairness on the basis of performance disparities in AI models is\ninadequate for confronting the structural inequities that educational AI\nsystems (re)produce. We draw on a lens of structural injustice informed by\ncritical theory and Black feminist scholarship to critically interrogate\nseveral widely-studied and widely-adopted categories of educational AI systems\nand demonstrate how educational AI technologies are bound up in and reproduce\nhistorical legacies of structural injustice and inequity, regardless of the\nparity of their models' performance. We close with alternative visions for a\nmore equitable future for educational AI research.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 22:13:35 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Madaio", "Michael", ""], ["Blodgett", "Su Lin", ""], ["Mayfield", "Elijah", ""], ["Dixon-Rom\u00e1n", "Ezekiel", ""]]}, {"id": "2105.08867", "submitter": "Xiwei Xu", "authors": "Liming Zhu, Xiwei Xu, Qinghua Lu, Guido Governatori, Jon Whittle", "title": "AI and Ethics -- Operationalising Responsible AI", "comments": null, "journal-ref": "Humanity Driven AI: Productivity, Wellbeing, Sustainability and\n  Partnership, 2021", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In the last few years, AI continues demonstrating its positive impact on\nsociety while sometimes with ethically questionable consequences. Building and\nmaintaining public trust in AI has been identified as the key to successful and\nsustainable innovation. This chapter discusses the challenges related to\noperationalizing ethical AI principles and presents an integrated view that\ncovers high-level ethical AI principles, the general notion of\ntrust/trustworthiness, and product/process support in the context of\nresponsible AI, which helps improve both trust and trustworthiness of AI for a\nwider set of stakeholders.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 00:55:40 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Zhu", "Liming", ""], ["Xu", "Xiwei", ""], ["Lu", "Qinghua", ""], ["Governatori", "Guido", ""], ["Whittle", "Jon", ""]]}, {"id": "2105.08877", "submitter": "Erick Delage", "authors": "Abderrahim Fathan and Erick Delage", "title": "Deep Reinforcement Learning for Optimal Stopping with Application in\n  Financial Engineering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal stopping is the problem of deciding the right time at which to take a\nparticular action in a stochastic system, in order to maximize an expected\nreward. It has many applications in areas such as finance, healthcare, and\nstatistics. In this paper, we employ deep Reinforcement Learning (RL) to learn\noptimal stopping policies in two financial engineering applications: namely\noption pricing, and optimal option exercise. We present for the first time a\ncomprehensive empirical evaluation of the quality of optimal stopping policies\nidentified by three state of the art deep RL algorithms: double deep Q-learning\n(DDQN), categorical distributional RL (C51), and Implicit Quantile Networks\n(IQN). In the case of option pricing, our findings indicate that in a\ntheoretical Black-Schole environment, IQN successfully identifies nearly\noptimal prices. On the other hand, it is slightly outperformed by C51 when\nconfronted to real stock data movements in a put option exercise problem that\ninvolves assets from the S&P500 index. More importantly, the C51 algorithm is\nable to identify an optimal stopping policy that achieves 8% more out-of-sample\nreturns than the best of four natural benchmark policies. We conclude with a\ndiscussion of our findings which should pave the way for relevant future\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 01:52:04 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Fathan", "Abderrahim", ""], ["Delage", "Erick", ""]]}, {"id": "2105.08907", "submitter": "Chrisogonas Odhiambo Mr.", "authors": "Chrisogonas Odhiambo (1 and 3), Pamela Wright (2 and 3), Cindy Corbett\n  (2 and 3), Homayoun Valafar (1 and 3) ((1) Computer Science and Engineering\n  Department, (2) College of Nursing, (3) University of South Carolina)", "title": "MedSensor: Medication Adherence Monitoring Using Neural Networks on\n  Smartwatch Accelerometer Sensor Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Poor medication adherence presents serious economic and health problems\nincluding compromised treatment effectiveness, medical complications, and loss\nof billions of dollars in wasted medicine or procedures. Though various\ninterventions have been proposed to address this problem, there is an urgent\nneed to leverage light, smart, and minimally obtrusive technology such as\nsmartwatches to develop user tools to improve medication use and adherence. In\nthis study, we conducted several experiments on medication-taking activities,\ndeveloped a smartwatch android application to collect the accelerometer hand\ngesture data from the smartwatch, and conveyed the data collected to a central\ncloud database. We developed neural networks, then trained the networks on the\nsensor data to recognize medication and non-medication gestures. With the\nproposed machine learning algorithm approach, this study was able to achieve\naverage accuracy scores of 97% on the protocol-guided gesture data, and 95% on\nnatural gesture data.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 03:42:30 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Odhiambo", "Chrisogonas", "", "1 and 3"], ["Wright", "Pamela", "", "2 and 3"], ["Corbett", "Cindy", "", "2 and 3"], ["Valafar", "Homayoun", "", "1 and 3"]]}, {"id": "2105.08923", "submitter": "Wei Xie", "authors": "Hua Zheng, Jiahao Zhu, Wei Xie, Judy Zhong", "title": "Reinforcement Learning Assisted Oxygen Therapy for COVID-19 Patients\n  Under Intensive Care", "comments": "23 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Patients with severe Coronavirus disease 19 (COVID-19) typically require\nsupplemental oxygen as an essential treatment. We developed a machine learning\nalgorithm, based on a deep Reinforcement Learning (RL), for continuous\nmanagement of oxygen flow rate for critical ill patients under intensive care,\nwhich can identify the optimal personalized oxygen flow rate with strong\npotentials to reduce mortality rate relative to the current clinical practice.\nBasically, we modeled the oxygen flow trajectory of COVID-19 patients and their\nhealth outcomes as a Markov decision process. Based on individual patient\ncharacteristics and health status, a reinforcement learning based oxygen\ncontrol policy is learned and real-time recommends the oxygen flow rate to\nreduce the mortality rate. We assessed the performance of proposed methods\nthrough cross validation by using a retrospective cohort of 1,372 critically\nill patients with COVID-19 from New York University Langone Health ambulatory\ncare with electronic health records from April 2020 to January 2021. The mean\nmortality rate under the RL algorithm is lower than standard of care by 2.57%\n(95% CI: 2.08- 3.06) reduction (P<0.001) from 7.94% under the standard of care\nto 5.37 % under our algorithm and the averaged recommended oxygen flow rate is\n1.28 L/min (95% CI: 1.14-1.42) lower than the rate actually delivered to\npatients. Thus, the RL algorithm could potentially lead to better intensive\ncare treatment that can reduce mortality rate, while saving the oxygen scarce\nresources. It can reduce the oxygen shortage issue and improve public health\nduring the COVID-19 pandemic.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 04:49:48 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zheng", "Hua", ""], ["Zhu", "Jiahao", ""], ["Xie", "Wei", ""], ["Zhong", "Judy", ""]]}, {"id": "2105.08928", "submitter": "Minghuan Tan", "authors": "Minghuan Tan and Lei Wang and Lingxiao Jiang and Jing Jiang", "title": "Investigating Math Word Problems using Pretrained Multilingual Language\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we revisit math word problems~(MWPs) from the cross-lingual\nand multilingual perspective. We construct our MWP solvers over pretrained\nmultilingual language models using sequence-to-sequence model with copy\nmechanism. We compare how the MWP solvers perform in cross-lingual and\nmultilingual scenarios. To facilitate the comparison of cross-lingual\nperformance, we first adapt the large-scale English dataset MathQA as a\ncounterpart of the Chinese dataset Math23K. Then we extend several English\ndatasets to bilingual datasets through machine translation plus human\nannotation. Our experiments show that the MWP solvers may not be transferred to\na different language even if the target expressions have the same operator set\nand constants. But for both cross-lingual and multilingual cases, it can be\nbetter generalized if problem types exist on both source language and target\nlanguage.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 05:17:10 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Tan", "Minghuan", ""], ["Wang", "Lei", ""], ["Jiang", "Lingxiao", ""], ["Jiang", "Jing", ""]]}, {"id": "2105.08959", "submitter": "Cheng-Yu Tsai", "authors": "Cheng Yu Tsai and Mu-Chun Su", "title": "VSGM -- Enhance robot task understanding ability through visual semantic\n  graph", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, developing AI for robotics has raised much attention. The\ninteraction of vision and language of robots is particularly difficult. We\nconsider that giving robots an understanding of visual semantics and language\nsemantics will improve inference ability. In this paper, we propose a novel\nmethod-VSGM (Visual Semantic Graph Memory), which uses the semantic graph to\nobtain better visual image features, improve the robot's visual understanding\nability. By providing prior knowledge of the robot and detecting the objects in\nthe image, it predicts the correlation between the attributes of the object and\nthe objects and converts them into a graph-based representation; and mapping\nthe object in the image to be a top-down egocentric map. Finally, the important\nobject features of the current task are extracted by Graph Neural Networks. The\nmethod proposed in this paper is verified in the ALFRED (Action Learning From\nRealistic Environments and Directives) dataset. In this dataset, the robot\nneeds to perform daily indoor household tasks following the required language\ninstructions. After the model is added to the VSGM, the task success rate can\nbe improved by 6~10%.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 07:22:31 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 09:36:36 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Tsai", "Cheng Yu", ""], ["Su", "Mu-Chun", ""]]}, {"id": "2105.08961", "submitter": "Jacob Russin", "authors": "Jacob Russin, Roland Fernandez, Hamid Palangi, Eric Rosen, Nebojsa\n  Jojic, Paul Smolensky, Jianfeng Gao", "title": "Compositional Processing Emerges in Neural Networks Solving Math\n  Problems", "comments": "7 pages, 2 figures, Accepted to CogSci 2021 for poster presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A longstanding question in cognitive science concerns the learning mechanisms\nunderlying compositionality in human cognition. Humans can infer the structured\nrelationships (e.g., grammatical rules) implicit in their sensory observations\n(e.g., auditory speech), and use this knowledge to guide the composition of\nsimpler meanings into complex wholes. Recent progress in artificial neural\nnetworks has shown that when large models are trained on enough linguistic\ndata, grammatical structure emerges in their representations. We extend this\nwork to the domain of mathematical reasoning, where it is possible to formulate\nprecise hypotheses about how meanings (e.g., the quantities corresponding to\nnumerals) should be composed according to structured rules (e.g., order of\noperations). Our work shows that neural networks are not only able to infer\nsomething about the structured relationships implicit in their training data,\nbut can also deploy this knowledge to guide the composition of individual\nmeanings into composite wholes.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 07:24:42 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Russin", "Jacob", ""], ["Fernandez", "Roland", ""], ["Palangi", "Hamid", ""], ["Rosen", "Eric", ""], ["Jojic", "Nebojsa", ""], ["Smolensky", "Paul", ""], ["Gao", "Jianfeng", ""]]}, {"id": "2105.08966", "submitter": "Fabio Sigrist", "authors": "Fabio Sigrist", "title": "Latent Gaussian Model Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.CO stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Gaussian models and boosting are widely used techniques in statistics\nand machine learning. Tree-boosting shows excellent predictive accuracy on many\ndata sets, but potential drawbacks are that it assumes conditional independence\nof samples, produces discontinuous predictions for, e.g., spatial data, and it\ncan have difficulty with high-cardinality categorical variables. Latent\nGaussian models, such as Gaussian process and grouped random effects models,\nare flexible prior models that allow for making probabilistic predictions.\nHowever, existing latent Gaussian models usually assume either a zero or a\nlinear prior mean function which can be an unrealistic assumption. This article\nintroduces a novel approach that combines boosting and latent Gaussian models\nin order to remedy the above-mentioned drawbacks and to leverage the advantages\nof both techniques. We obtain increased predictive accuracy compared to\nexisting approaches in both simulated and real-world data experiments.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 07:36:30 GMT"}, {"version": "v2", "created": "Fri, 21 May 2021 13:42:12 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Sigrist", "Fabio", ""]]}, {"id": "2105.08969", "submitter": "Wei Shao Dr", "authors": "Wei Shao, Arian Prabowo, Sichen Zhao, Piotr Koniusz, Flora D. Salim", "title": "Predicting Flight Delay with Spatio-Temporal Trajectory Convolutional\n  Network and Airport Situational Awareness Map", "comments": "single column", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To model and forecast flight delays accurately, it is crucial to harness\nvarious vehicle trajectory and contextual sensor data on airport tarmac areas.\nThese heterogeneous sensor data, if modelled correctly, can be used to generate\na situational awareness map. Existing techniques apply traditional supervised\nlearning methods onto historical data, contextual features and route\ninformation among different airports to predict flight delay are inaccurate and\nonly predict arrival delay but not departure delay, which is essential to\nairlines. In this paper, we propose a vision-based solution to achieve a high\nforecasting accuracy, applicable to the airport. Our solution leverages a\nsnapshot of the airport situational awareness map, which contains various\ntrajectories of aircraft and contextual features such as weather and airline\nschedules. We propose an end-to-end deep learning architecture, TrajCNN, which\ncaptures both the spatial and temporal information from the situational\nawareness map. Additionally, we reveal that the situational awareness map of\nthe airport has a vital impact on estimating flight departure delay. Our\nproposed framework obtained a good result (around 18 minutes error) for\npredicting flight departure delay at Los Angeles International Airport.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 07:38:57 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Shao", "Wei", ""], ["Prabowo", "Arian", ""], ["Zhao", "Sichen", ""], ["Koniusz", "Piotr", ""], ["Salim", "Flora D.", ""]]}, {"id": "2105.09008", "submitter": "Shyh Yaw Jou", "authors": "Shi-Yao Zhou and Chung-Yen Su", "title": "A Novel lightweight Convolutional Neural Network, ExquisiteNetV2", "comments": "7 pages, 8 figures, 27 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper of ExquisiteNetV1, the ability of classification of\nExquisiteNetV1 is worse than DenseNet. In this article, we propose a faster and\nbetter model ExquisiteNetV2. We conduct many experiments to evaluate its\nperformance. We test ExquisiteNetV2, ExquisiteNetV1 and other 9 well-known\nmodels on 15 credible datasets under the same condition. According to the\nexperimental results, ExquisiteNetV2 gets the highest classification accuracy\nover half of the datasets. Important of all, ExquisiteNetV2 has fewest amounts\nof parameters. Besides, in most instances, ExquisiteNetV2 has fastest computing\nspeed.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 09:21:30 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 00:48:49 GMT"}, {"version": "v3", "created": "Tue, 29 Jun 2021 14:13:33 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Zhou", "Shi-Yao", ""], ["Su", "Chung-Yen", ""]]}, {"id": "2105.09022", "submitter": "Weiyi Zhang", "authors": "Weiyi Zhang, Shuning Zhao, Le Liu, Jianmin Li, Xingliang Cheng, Thomas\n  Fang Zheng, Xiaolin Hu", "title": "Attack on practical speaker verification system using universal\n  adversarial perturbations", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": "10.1109/ICASSP39728.2021.9413467", "report-no": null, "categories": "cs.SD cs.AI eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In authentication scenarios, applications of practical speaker verification\nsystems usually require a person to read a dynamic authentication text.\nPrevious studies played an audio adversarial example as a digital signal to\nperform physical attacks, which would be easily rejected by audio replay\ndetection modules. This work shows that by playing our crafted adversarial\nperturbation as a separate source when the adversary is speaking, the practical\nspeaker verification system will misjudge the adversary as a target speaker. A\ntwo-step algorithm is proposed to optimize the universal adversarial\nperturbation to be text-independent and has little effect on the authentication\ntext recognition. We also estimated room impulse response (RIR) in the\nalgorithm which allowed the perturbation to be effective after being played\nover the air. In the physical experiment, we achieved targeted attacks with\nsuccess rate of 100%, while the word error rate (WER) on speech recognition was\nonly increased by 3.55%. And recorded audios could pass replay detection for\nthe live person speaking.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 09:43:34 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zhang", "Weiyi", ""], ["Zhao", "Shuning", ""], ["Liu", "Le", ""], ["Li", "Jianmin", ""], ["Cheng", "Xingliang", ""], ["Zheng", "Thomas Fang", ""], ["Hu", "Xiaolin", ""]]}, {"id": "2105.09046", "submitter": "Vaishali Ingale", "authors": "Vaishali Ingale, Anush Mohan, Divit Adlakha, Krishan Kumar and Mohit\n  Gupta", "title": "Music Generation using Three-layered LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper explores the idea of utilising Long Short-Term Memory neural\nnetworks (LSTMNN) for the generation of musical sequences in ABC notation. The\nproposed approach takes ABC notations from the Nottingham dataset and encodes\nit to be fed as input for the neural networks. The primary objective is to\ninput the neural networks with an arbitrary note, let the network process and\naugment a sequence based on the note until a good piece of music is produced.\nMultiple calibrations have been done to amend the parameters of the network for\noptimal generation. The output is assessed on the basis of rhythm, harmony, and\ngrammar accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 10:27:58 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 16:09:44 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 08:15:19 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Ingale", "Vaishali", ""], ["Mohan", "Anush", ""], ["Adlakha", "Divit", ""], ["Kumar", "Krishan", ""], ["Gupta", "Mohit", ""]]}, {"id": "2105.09059", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta ((1) and (2)), Alexandrine Royer ((1) and (3)), Connor\n  Wright ((1) and (4)), Falaah Arif Khan (1), Victoria Heath (1), Erick\n  Galinkin ((1) and (5)), Ryan Khurana (1), Marianna Bergamaschi Ganapini ((1)\n  and (6)), Muriam Fancy ((1), (7), and (8)), Masa Sweidan ((1) and (9)), Mo\n  Akif (1), and Renjie Butalid (1) ((1) Montreal AI Ethics Institute, (2)\n  Microsoft, (3) University of Oxford, (4) University of Exeter, (5) Rapid7,\n  (6) Union College, (7) University of Toronto, (8) University of Ottawa, (9)\n  McGill University)", "title": "The State of AI Ethics Report (January 2021)", "comments": "188 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The 3rd edition of the Montreal AI Ethics Institute's The State of AI Ethics\ncaptures the most relevant developments in AI Ethics since October 2020. It\naims to help anyone, from machine learning experts to human rights activists\nand policymakers, quickly digest and understand the field's ever-changing\ndevelopments. Through research and article summaries, as well as expert\ncommentary, this report distills the research and reporting surrounding various\ndomains related to the ethics of AI, including: algorithmic injustice,\ndiscrimination, ethical AI, labor impacts, misinformation, privacy, risk and\nsecurity, social media, and more.\n  In addition, The State of AI Ethics includes exclusive content written by\nworld-class AI Ethics experts from universities, research institutes,\nconsulting firms, and governments. Unique to this report is \"The Abuse and\nMisogynoir Playbook,\" written by Dr. Katlyn Tuner (Research Scientist, Space\nEnabled Research Group, MIT), Dr. Danielle Wood (Assistant Professor, Program\nin Media Arts and Sciences; Assistant Professor, Aeronautics and Astronautics;\nLead, Space Enabled Research Group, MIT) and Dr. Catherine D'Ignazio (Assistant\nProfessor, Urban Science and Planning; Director, Data + Feminism Lab, MIT). The\npiece (and accompanying infographic), is a deep-dive into the historical and\nsystematic silencing, erasure, and revision of Black women's contributions to\nknowledge and scholarship in the United Stations, and globally. Exposing and\ncountering this Playbook has become increasingly important following the firing\nof AI Ethics expert Dr. Timnit Gebru (and several of her supporters) at Google.\n  This report should be used not only as a point of reference and insight on\nthe latest thinking in the field of AI Ethics, but should also be used as a\ntool for introspection as we aim to foster a more nuanced conversation\nregarding the impacts of AI on the world.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 10:59:17 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Gupta", "Abhishek", ""], ["Royer", "Alexandrine", ""], ["Wright", "Connor", ""], ["Khan", "Falaah Arif", ""], ["Heath", "Victoria", ""], ["Galinkin", "Erick", ""], ["Khurana", "Ryan", ""], ["Ganapini", "Marianna Bergamaschi", ""], ["Fancy", "Muriam", ""], ["Sweidan", "Masa", ""], ["Akif", "Mo", ""], ["Butalid", "Renjie", ""]]}, {"id": "2105.09060", "submitter": "Abhishek Gupta", "authors": "Abhishek Gupta ((1) and (2)), Alexandrine Royer ((1) and (3)), Connor\n  Wright ((1) and (4)), Victoria Heath (1), Muriam Fancy ((1) and (5)),\n  Marianna Bergamaschi Ganapini ((1) and (6)), Shannon Egan ((1) and (7)), Masa\n  Sweidan ((1) and (8)), Mo Akif (1), and Renjie Butalid (1) ((1) Montreal AI\n  Ethics Institute, (2) Microsoft, (3) University of Oxford, (4) University of\n  Exeter, (5) University of Toronto, (6) Union College, (7) University of\n  British Columbia, (8) McGill University)", "title": "The State of AI Ethics Report (Volume 4)", "comments": "190 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The 4th edition of the Montreal AI Ethics Institute's The State of AI Ethics\ncaptures the most relevant developments in the field of AI Ethics since January\n2021. This report aims to help anyone, from machine learning experts to human\nrights activists and policymakers, quickly digest and understand the\never-changing developments in the field. Through research and article\nsummaries, as well as expert commentary, this report distills the research and\nreporting surrounding various domains related to the ethics of AI, with a\nparticular focus on four key themes: Ethical AI, Fairness & Justice, Humans &\nTech, and Privacy.\n  In addition, The State of AI Ethics includes exclusive content written by\nworld-class AI Ethics experts from universities, research institutes,\nconsulting firms, and governments. Opening the report is a long-form piece by\nEdward Higgs (Professor of History, University of Essex) titled \"AI and the\nFace: A Historian's View.\" In it, Higgs examines the unscientific history of\nfacial analysis and how AI might be repeating some of those mistakes at scale.\nThe report also features chapter introductions by Alexa Hagerty\n(Anthropologist, University of Cambridge), Marianna Ganapini (Faculty Director,\nMontreal AI Ethics Institute), Deborah G. Johnson (Emeritus Professor,\nEngineering and Society, University of Virginia), and Soraj Hongladarom\n(Professor of Philosophy and Director, Center for Science, Technology and\nSociety, Chulalongkorn University in Bangkok).\n  This report should be used not only as a point of reference and insight on\nthe latest thinking in the field of AI Ethics, but should also be used as a\ntool for introspection as we aim to foster a more nuanced conversation\nregarding the impacts of AI on the world.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 11:02:13 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Gupta", "Abhishek", ""], ["Royer", "Alexandrine", ""], ["Wright", "Connor", ""], ["Heath", "Victoria", ""], ["Fancy", "Muriam", ""], ["Ganapini", "Marianna Bergamaschi", ""], ["Egan", "Shannon", ""], ["Sweidan", "Masa", ""], ["Akif", "Mo", ""], ["Butalid", "Renjie", ""]]}, {"id": "2105.09090", "submitter": "Yiming Sun", "authors": "Yiming Sun, Feng Chen, Zhiyu Chen, Mingjie Wang, Ruonan Li", "title": "Local Aggressive Adversarial Attacks on 3D Point Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are found to be prone to adversarial examples which\ncould deliberately fool the model to make mistakes. Recently, a few of works\nexpand this task from 2D image to 3D point cloud by using global point cloud\noptimization. However, the perturbations of global point are not effective for\nmisleading the victim model. First, not all points are important in\noptimization toward misleading. Abundant points account considerable distortion\nbudget but contribute trivially to attack. Second, the multi-label optimization\nis suboptimal for adversarial attack, since it consumes extra energy in finding\nmulti-label victim model collapse and causes instance transformation to be\ndissimilar to any particular instance. Third, the independent adversarial and\nperceptibility losses, caring misclassification and dissimilarity separately,\ntreat the updating of each point equally without a focus. Therefore, once\nperceptibility loss approaches its budget threshold, all points would be stock\nin the surface of hypersphere and attack would be locked in local optimality.\nTherefore, we propose a local aggressive adversarial attacks (L3A) to solve\nabove issues. Technically, we select a bunch of salient points, the high-score\nsubset of point cloud according to gradient, to perturb. Then a flow of\naggressive optimization strategies are developed to reinforce the unperceptive\ngeneration of adversarial examples toward misleading victim models. Extensive\nexperiments on PointNet, PointNet++ and DGCNN demonstrate the state-of-the-art\nperformance of our method against existing adversarial attack methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 12:22:56 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Sun", "Yiming", ""], ["Chen", "Feng", ""], ["Chen", "Zhiyu", ""], ["Wang", "Mingjie", ""], ["Li", "Ruonan", ""]]}, {"id": "2105.09095", "submitter": "J\\\"org Martin", "authors": "J\\\"org Martin and Clemens Elster", "title": "Errors-in-Variables for deep learning: rethinking aleatoric uncertainty", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a Bayesian treatment for deep regression using an\nErrors-in-Variables model which accounts for the uncertainty associated with\nthe input to the employed neural network. It is shown how the treatment can be\ncombined with already existing approaches for uncertainty quantification that\nare based on variational inference. Our approach yields a decomposition of the\npredictive uncertainty into an aleatoric and epistemic part that is more\ncomplete and, in many cases, more consistent from a statistical perspective. We\nillustrate and discuss the approach along various toy and real world examples.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 12:37:02 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 08:51:07 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Martin", "J\u00f6rg", ""], ["Elster", "Clemens", ""]]}, {"id": "2105.09108", "submitter": "Benjie Wang", "authors": "Benjie Wang, Clare Lyle, Marta Kwiatkowska", "title": "Provable Guarantees on the Robustness of Decision Rules to Causal\n  Interventions", "comments": "21 pages (8+13 Appendix). To be published in IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness of decision rules to shifts in the data-generating process is\ncrucial to the successful deployment of decision-making systems. Such shifts\ncan be viewed as interventions on a causal graph, which capture (possibly\nhypothetical) changes in the data-generating process, whether due to natural\nreasons or by the action of an adversary. We consider causal Bayesian networks\nand formally define the interventional robustness problem, a novel model-based\nnotion of robustness for decision functions that measures worst-case\nperformance with respect to a set of interventions that denote changes to\nparameters and/or causal influences. By relying on a tractable representation\nof Bayesian networks as arithmetic circuits, we provide efficient algorithms\nfor computing guaranteed upper and lower bounds on the interventional\nrobustness probabilities. Experimental results demonstrate that the methods\nyield useful and interpretable bounds for a range of practical networks, paving\nthe way towards provably causally robust decision-making systems.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 13:09:47 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Wang", "Benjie", ""], ["Lyle", "Clare", ""], ["Kwiatkowska", "Marta", ""]]}, {"id": "2105.09114", "submitter": "Bimal Bhattarai", "authors": "Bimal Bhattarai, Ole-Christoffer Granmo, Lei Jiao", "title": "Explainable Tsetlin Machine framework for fake news detection with\n  credibility score assessment", "comments": "11 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of fake news, i.e., news intentionally spread for\nmisinformation, poses a threat to individuals and society. Despite various\nfact-checking websites such as PolitiFact, robust detection techniques are\nrequired to deal with the increase in fake news. Several deep learning models\nshow promising results for fake news classification, however, their black-box\nnature makes it difficult to explain their classification decisions and\nquality-assure the models. We here address this problem by proposing a novel\ninterpretable fake news detection framework based on the recently introduced\nTsetlin Machine (TM). In brief, we utilize the conjunctive clauses of the TM to\ncapture lexical and semantic properties of both true and fake news text.\nFurther, we use the clause ensembles to calculate the credibility of fake news.\nFor evaluation, we conduct experiments on two publicly available datasets,\nPolitiFact and GossipCop, and demonstrate that the TM framework significantly\noutperforms previously published baselines by at least $5\\%$ in terms of\naccuracy, with the added benefit of an interpretable logic-based\nrepresentation. Further, our approach provides higher F1-score than BERT and\nXLNet, however, we obtain slightly lower accuracy. We finally present a case\nstudy on our model's explainability, demonstrating how it decomposes into\nmeaningful words and their negations.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 13:18:02 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Bhattarai", "Bimal", ""], ["Granmo", "Ole-Christoffer", ""], ["Jiao", "Lei", ""]]}, {"id": "2105.09124", "submitter": "Juzheng Miao", "authors": "Guang-Quan Zhou, Juzheng Miao, Xin Yang, Rui Li, En-Ze Huo, Wenlong\n  Shi, Yuhao Huang, Jikuan Qian, Chaoyu Chen, Dong Ni", "title": "Learn Fine-grained Adaptive Loss for Multiple Anatomical Landmark\n  Detection in Medical Images", "comments": "12 pages, 10 figures, accepted by IEEE Journal of Biomedical and\n  Health Informatics", "journal-ref": null, "doi": "10.1109/JBHI.2021.3080703", "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic and accurate detection of anatomical landmarks is an essential\noperation in medical image analysis with a multitude of applications. Recent\ndeep learning methods have improved results by directly encoding the appearance\nof the captured anatomy with the likelihood maps (i.e., heatmaps). However,\nmost current solutions overlook another essence of heatmap regression, the\nobjective metric for regressing target heatmaps and rely on hand-crafted\nheuristics to set the target precision, thus being usually cumbersome and\ntask-specific. In this paper, we propose a novel learning-to-learn framework\nfor landmark detection to optimize the neural network and the target precision\nsimultaneously. The pivot of this work is to leverage the reinforcement\nlearning (RL) framework to search objective metrics for regressing multiple\nheatmaps dynamically during the training process, thus avoiding setting\nproblem-specific target precision. We also introduce an early-stop strategy for\nactive termination of the RL agent's interaction that adapts the optimal\nprecision for separate targets considering exploration-exploitation tradeoffs.\nThis approach shows better stability in training and improved localization\naccuracy in inference. Extensive experimental results on two different\napplications of landmark localization: 1) our in-house prenatal ultrasound (US)\ndataset and 2) the publicly available dataset of cephalometric X-Ray landmark\ndetection, demonstrate the effectiveness of our proposed method. Our proposed\nframework is general and shows the potential to improve the efficiency of\nanatomical landmark detection.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 13:39:18 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zhou", "Guang-Quan", ""], ["Miao", "Juzheng", ""], ["Yang", "Xin", ""], ["Li", "Rui", ""], ["Huo", "En-Ze", ""], ["Shi", "Wenlong", ""], ["Huang", "Yuhao", ""], ["Qian", "Jikuan", ""], ["Chen", "Chaoyu", ""], ["Ni", "Dong", ""]]}, {"id": "2105.09221", "submitter": "Priyanka Golia", "authors": "Priyanka Golia, Subhajit Roy, and Kuldeep S. Meel", "title": "Program Synthesis as Dependency Quantified Formula Modulo Theory", "comments": "12 page excluding reference. To be published in 30th International\n  Joint Conference on Artificial Intelligence (IJCAI-21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a specification $\\varphi(X,Y)$ over inputs $X$ and output $Y$, defined\nover a background theory $\\mathbb{T}$, the problem of program synthesis is to\ndesign a program $f$ such that $Y=f(X)$ satisfies the specification $\\varphi$.\nOver the past decade, syntax-guided synthesis (SyGuS) has emerged as a dominant\napproach for program synthesis where in addition to the specification\n$\\varphi$, the end-user also specifies a grammar $L$ to aid the underlying\nsynthesis engine. This paper investigates the feasibility of synthesis\ntechniques without grammar, a sub-class defined as $\\mathbb{T}$-constrained\nsynthesis.\n  We show that $\\mathbb{T}$-constrained synthesis can be reduced to\nDQF($\\mathbb{T}$), i.e., to the problem of finding a witness of a Dependency\nQuantified Formula Modulo Theory. When the underlying theory is the theory of\nbitvectors, the corresponding DQF(BV) problem can be further reduced to\nDependency Quantified Boolean Formulas (DQBF). We rely on the progress in DQBF\nsolving to design DQBF-based synthesizers that outperform the domain-specific\nprogram synthesis techniques, thereby positioning DQBF as a core representation\nlanguage for program synthesis. Our empirical analysis shows that\n$\\mathbb{T}$-constrained synthesis can achieve significantly better performance\nthan syntax-guided approaches. Furthermore, the general-purpose DQBF solvers\nperform on par with domain-specific synthesis techniques.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 16:05:20 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Golia", "Priyanka", ""], ["Roy", "Subhajit", ""], ["Meel", "Kuldeep S.", ""]]}, {"id": "2105.09222", "submitter": "Siddharth Mehrotra", "authors": "Siddharth Mehrotra, Catholijn M. Jonker, Myrthe L. Tielman", "title": "More Similar Values, More Trust? -- the Effect of Value Similarity on\n  Trust in Human-Agent Interaction", "comments": "4th AAAI/ACM Conference on AI, Ethics, and Society", "journal-ref": "S Mehrotra, C. M. Jonker, and M. L. Tielman. More Similar Values,\n  More Trust? - the Effect of Value Similarity on Trust in Human-Agent\n  Interaction in Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and\n  Society (AIES 21)", "doi": "10.1145/3461702.3462576", "report-no": null, "categories": "cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  As AI systems are increasingly involved in decision making, it also becomes\nimportant that they elicit appropriate levels of trust from their users. To\nachieve this, it is first important to understand which factors influence trust\nin AI. We identify that a research gap exists regarding the role of personal\nvalues in trust in AI. Therefore, this paper studies how human and agent Value\nSimilarity (VS) influences a human's trust in that agent. To explore this, 89\nparticipants teamed up with five different agents, which were designed with\nvarying levels of value similarity to that of the participants. In a\nwithin-subjects, scenario-based experiment, agents gave suggestions on what to\ndo when entering the building to save a hostage. We analyzed the agent's scores\non subjective value similarity, trust and qualitative data from open-ended\nquestions. Our results show that agents rated as having more similar values\nalso scored higher on trust, indicating a positive effect between the two. With\nthis result, we add to the existing understanding of human-agent trust by\nproviding insight into the role of value-similarity.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 16:06:46 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Mehrotra", "Siddharth", ""], ["Jonker", "Catholijn M.", ""], ["Tielman", "Myrthe L.", ""]]}, {"id": "2105.09235", "submitter": "Giovanni Bonetta", "authors": "Giovanni Bonetta, Rossella Cancelliere, Ding Liu, Paul Vozila", "title": "Retrieval-Augmented Transformer-XL for Close-Domain Dialog Generation", "comments": "The International FLAIRS Conference Proceedings volume 34 issue 1", "journal-ref": null, "doi": "10.32473/flairs.v34i1.128369", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformer-based models have demonstrated excellent capabilities of\ncapturing patterns and structures in natural language generation and achieved\nstate-of-the-art results in many tasks. In this paper we present a\ntransformer-based model for multi-turn dialog response generation. Our solution\nis based on a hybrid approach which augments a transformer-based generative\nmodel with a novel retrieval mechanism, which leverages the memorized\ninformation in the training data via k-Nearest Neighbor search. Our system is\nevaluated on two datasets made by customer/assistant dialogs: the Taskmaster-1,\nreleased by Google and holding high quality, goal-oriented conversational data\nand a proprietary dataset collected from a real customer service call center.\nBoth achieve better BLEU scores over strong baselines.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 16:34:33 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Bonetta", "Giovanni", ""], ["Cancelliere", "Rossella", ""], ["Liu", "Ding", ""], ["Vozila", "Paul", ""]]}, {"id": "2105.09266", "submitter": "Giorgio Franceschelli", "authors": "Giorgio Franceschelli and Mirco Musolesi", "title": "Copyright in Generative Deep Learning", "comments": "12 pages. Second version contains updates after entry into force of\n  EU's directive on copyright in the Digital Single Market, and corrections of\n  typos. Third version contains a new section about GitHub Copilot and its\n  copyright implications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine-generated artworks are now part of the contemporary art scene: they\nare attracting significant investments and they are presented in exhibitions\ntogether with those created by human artists. These artworks are mainly based\non generative deep learning techniques, which have seen a formidable\ndevelopment and remarkable refinement in the very recent years. Given the\ninherent characteristics of these techniques, a series of novel legal problems\narise.\n  In this article, we consider a set of key questions in the area of generative\ndeep learning for the arts, including the following: is it possible to use\ncopyrighted works as training set for generative models? How do we legally\nstore their copies in order to perform the training process? Who (if someone)\nwill own the copyright on the generated data? We try to answer these questions\nconsidering the law in force in both the United States of America and the\nEuropean Union, and potential future alternatives. Finally, we also formulate a\nset of practical guidelines for artists and developers working on deep learning\ngenerated art.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 17:22:47 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 18:00:01 GMT"}, {"version": "v3", "created": "Wed, 21 Jul 2021 18:00:03 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Franceschelli", "Giorgio", ""], ["Musolesi", "Mirco", ""]]}, {"id": "2105.09268", "submitter": "Maanak Gupta", "authors": "Jeffrey C Kimmell, Mahmoud Abdelsalam, Maanak Gupta", "title": "Analyzing Machine Learning Approaches for Online Malware Detection in\n  Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The variety of services and functionality offered by various cloud service\nproviders (CSP) have exploded lately. Utilizing such services has created\nnumerous opportunities for enterprises infrastructure to become cloud-based\nand, in turn, assisted the enterprises to easily and flexibly offer services to\ntheir customers. The practice of renting out access to servers to clients for\ncomputing and storage purposes is known as Infrastructure as a Service (IaaS).\nThe popularity of IaaS has led to serious and critical concerns with respect to\nthe cyber security and privacy. In particular, malware is often leveraged by\nmalicious entities against cloud services to compromise sensitive data or to\nobstruct their functionality. In response to this growing menace, malware\ndetection for cloud environments has become a widely researched topic with\nnumerous methods being proposed and deployed. In this paper, we present online\nmalware detection based on process level performance metrics, and analyze the\neffectiveness of different baseline machine learning models including, Support\nVector Classifier (SVC), Random Forest Classifier (RFC), KNearest Neighbor\n(KNN), Gradient Boosted Classifier (GBC), Gaussian Naive Bayes (GNB) and\nConvolutional Neural Networks (CNN). Our analysis conclude that neural network\nmodels can most accurately detect the impact malware have on the process level\nfeatures of virtual machines in the cloud, and therefore are best suited to\ndetect them. Our models were trained, validated, and tested by using a dataset\nof 40,680 malicious and benign samples. The dataset was complied by running\ndifferent families of malware (collected from VirusTotal) in a live cloud\nenvironment and collecting the process level features.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 17:28:12 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Kimmell", "Jeffrey C", ""], ["Abdelsalam", "Mahmoud", ""], ["Gupta", "Maanak", ""]]}, {"id": "2105.09295", "submitter": "Virginie Do", "authors": "Virginie Do, Jamal Atif, J\\'er\\^ome Lang and Nicolas Usunier", "title": "Online Selection of Diverse Committees", "comments": "IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Citizens' assemblies need to represent subpopulations according to their\nproportions in the general population. These large committees are often\nconstructed in an online fashion by contacting people, asking for the\ndemographic features of the volunteers, and deciding to include them or not.\nThis raises a trade-off between the number of people contacted (and the\nincurring cost) and the representativeness of the committee. We study three\nmethods, theoretically and experimentally: a greedy algorithm that includes\nvolunteers as long as proportionality is not violated; a non-adaptive method\nthat includes a volunteer with a probability depending only on their features,\nassuming that the joint feature distribution in the volunteer pool is known;\nand a reinforcement learning based approach when this distribution is not known\na priori but learnt online.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 17:55:29 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Do", "Virginie", ""], ["Atif", "Jamal", ""], ["Lang", "J\u00e9r\u00f4me", ""], ["Usunier", "Nicolas", ""]]}, {"id": "2105.09297", "submitter": "Rongyu Cao Dr.", "authors": "Rongyu Cao and Yixuan Cao and Ganbin Zhou and Ping Luo", "title": "Extracting Variable-Depth Logical Document Hierarchy from Long\n  Documents: Method, Evaluation, and Application", "comments": "23 pages, 10 figures, Journal of computer science and technology", "journal-ref": "Journal of computer science and technology, 2021", "doi": "10.1007/s11390-021-1076-7", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of extracting variable-depth \"logical\ndocument hierarchy\" from long documents, namely organizing the recognized\n\"physical document objects\" into hierarchical structures. The discovery of\nlogical document hierarchy is the vital step to support many downstream\napplications. However, long documents, containing hundreds or even thousands of\npages and variable-depth hierarchy, challenge the existing methods. To address\nthese challenges, we develop a framework, namely Hierarchy Extraction from Long\nDocument (HELD), where we \"sequentially\" insert each physical object at the\nproper on of the current tree. Determining whether each possible position is\nproper or not can be formulated as a binary classification problem. To further\nimprove its effectiveness and efficiency, we study the design variants in HELD,\nincluding traversal orders of the insertion positions, heading extraction\nexplicitly or implicitly, tolerance to insertion errors in predecessor steps,\nand so on. The empirical experiments based on thousands of long documents from\nChinese, English financial market and English scientific publication show that\nthe HELD model with the \"root-to-leaf\" traversal order and explicit heading\nextraction is the best choice to achieve the tradeoff between effectiveness and\nefficiency with the accuracy of 0.9726, 0.7291 and 0.9578 in Chinese financial,\nEnglish financial and arXiv datasets, respectively. Finally, we show that\nlogical document hierarchy can be employed to significantly improve the\nperformance of the downstream passage retrieval task. In summary, we conduct a\nsystematic study on this task in terms of methods, evaluations, and\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 06:26:22 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Cao", "Rongyu", ""], ["Cao", "Yixuan", ""], ["Zhou", "Ganbin", ""], ["Luo", "Ping", ""]]}, {"id": "2105.09371", "submitter": "Haresh Karnan", "authors": "Haresh Karnan, Garrett Warnell, Xuesu Xiao, Peter Stone", "title": "VOILA: Visual-Observation-Only Imitation Learning for Autonomous\n  Navigation", "comments": "Under Submission to IROS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While imitation learning for vision based autonomous mobile robot navigation\nhas recently received a great deal of attention in the research community,\nexisting approaches typically require state action demonstrations that were\ngathered using the deployment platform. However, what if one cannot easily\noutfit their platform to record these demonstration signals or worse yet the\ndemonstrator does not have access to the platform at all? Is imitation learning\nfor vision based autonomous navigation even possible in such scenarios? In this\nwork, we hypothesize that the answer is yes and that recent ideas from the\nImitation from Observation (IfO) literature can be brought to bear such that a\nrobot can learn to navigate using only ego centric video collected by a\ndemonstrator, even in the presence of viewpoint mismatch. To this end, we\nintroduce a new algorithm, Visual Observation only Imitation Learning for\nAutonomous navigation (VOILA), that can successfully learn navigation policies\nfrom a single video demonstration collected from a physically different agent.\nWe evaluate VOILA in the photorealistic AirSim simulator and show that VOILA\nnot only successfully imitates the expert, but that it also learns navigation\npolicies that can generalize to novel environments. Further, we demonstrate the\neffectiveness of VOILA in a real world setting by showing that it allows a\nwheeled Jackal robot to successfully imitate a human walking in an environment\nusing a video recorded using a mobile phone camera.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 19:25:23 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Karnan", "Haresh", ""], ["Warnell", "Garrett", ""], ["Xiao", "Xuesu", ""], ["Stone", "Peter", ""]]}, {"id": "2105.09383", "submitter": "Hadi Hosseini", "authors": "Hadi Hosseini and Andrew Searns", "title": "Guaranteeing Maximin Shares: Some Agents Left Behind", "comments": "Full version of a paper accepted to IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI econ.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The maximin share (MMS) guarantee is a desirable fairness notion for\nallocating indivisible goods. While MMS allocations do not always exist,\nseveral approximation techniques have been developed to ensure that all agents\nreceive a fraction of their maximin share. We focus on an alternative\napproximation notion, based on the population of agents, that seeks to\nguarantee MMS for a fraction of agents. We show that no optimal approximation\nalgorithm can satisfy more than a constant number of agents, and discuss the\nexistence and computation of MMS for all but one agent and its relation to\napproximate MMS guarantees. We then prove the existence of allocations that\nguarantee MMS for $\\frac{2}{3}$ of agents, and devise a polynomial time\nalgorithm that achieves this bound for up to nine agents. A key implication of\nour result is the existence of allocations that guarantee\n$\\text{MMS}^{\\lceil{3n/2}\\rceil}$, i.e., the value that agents receive by\npartitioning the goods into $\\lceil{\\frac{3}{2}n}\\rceil$ bundles, improving the\nbest known guarantee of $\\text{MMS}^{2n-2}$. Finally, we provide empirical\nexperiments using synthetic data.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 20:17:42 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hosseini", "Hadi", ""], ["Searns", "Andrew", ""]]}, {"id": "2105.09386", "submitter": "Debmalya Mandal", "authors": "Hadi Hosseini, Debmalya Mandal, Nisarg Shah, and Kevin Shi", "title": "Surprisingly Popular Voting Recovers Rankings, Surprisingly!", "comments": "Forthcoming at IJCAI-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The wisdom of the crowd has long become the de facto approach for eliciting\ninformation from individuals or experts in order to predict the ground truth.\nHowever, classical democratic approaches for aggregating individual\n\\emph{votes} only work when the opinion of the majority of the crowd is\nrelatively accurate. A clever recent approach, \\emph{surprisingly popular\nvoting}, elicits additional information from the individuals, namely their\n\\emph{prediction} of other individuals' votes, and provably recovers the ground\ntruth even when experts are in minority. This approach works well when the goal\nis to pick the correct option from a small list, but when the goal is to\nrecover a true ranking of the alternatives, a direct application of the\napproach requires eliciting too much information. We explore practical\ntechniques for extending the surprisingly popular algorithm to ranked voting by\npartial votes and predictions and designing robust aggregation rules. We\nexperimentally demonstrate that even a little prediction information helps\nsurprisingly popular voting outperform classical approaches.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 20:31:23 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hosseini", "Hadi", ""], ["Mandal", "Debmalya", ""], ["Shah", "Nisarg", ""], ["Shi", "Kevin", ""]]}, {"id": "2105.09392", "submitter": "Gengchen Mai", "authors": "Gengchen Mai, Krzysztof Janowicz, Rui Zhu, Ling Cai, and Ni Lao", "title": "Geographic Question Answering: Challenges, Uniqueness, Classification,\n  and Future Directions", "comments": "20 pages, 3 figure, Full paper accepted to AGILE 2021", "journal-ref": "AGILE 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As an important part of Artificial Intelligence (AI), Question Answering (QA)\naims at generating answers to questions phrased in natural language. While\nthere has been substantial progress in open-domain question answering, QA\nsystems are still struggling to answer questions which involve geographic\nentities or concepts and that require spatial operations. In this paper, we\ndiscuss the problem of geographic question answering (GeoQA). We first\ninvestigate the reasons why geographic questions are difficult to answer by\nanalyzing challenges of geographic questions. We discuss the uniqueness of\ngeographic questions compared to general QA. Then we review existing work on\nGeoQA and classify them by the types of questions they can address. Based on\nthis survey, we provide a generic classification framework for geographic\nquestions. Finally, we conclude our work by pointing out unique future research\ndirections for GeoQA.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 20:47:36 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Mai", "Gengchen", ""], ["Janowicz", "Krzysztof", ""], ["Zhu", "Rui", ""], ["Cai", "Ling", ""], ["Lao", "Ni", ""]]}, {"id": "2105.09407", "submitter": "Jakub Marecek", "authors": "Allahkaram Shafiei and Vyacheslav Kungurtsev and Jakub Marecek", "title": "Trilevel and Multilevel Optimization using Monotone Operator Theory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider rather a general class of multi-level optimization problems,\nwhere a convex objective function is to be minimized, subject to constraints to\noptima of a nested convex optimization problem. As a special case, we consider\na trilevel optimization problem, where the objective of the two lower layers\nconsists of a sum of a smooth and a non-smooth term. Based on fixed-point\ntheory and related arguments, we present a natural first-order algorithm and\nanalyze its convergence and rates of convergence in several regimes of\nparameters.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 21:31:18 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Shafiei", "Allahkaram", ""], ["Kungurtsev", "Vyacheslav", ""], ["Marecek", "Jakub", ""]]}, {"id": "2105.09413", "submitter": "Mateus de Oliveira Oliveira", "authors": "Emmanuel Arrighi, Henning Fernau, Daniel Lokshtanov, Mateus de\n  Oliveira Oliveira, Petra Wolf", "title": "Diversity in Kemeny Rank Aggregation: A Parameterized Approach", "comments": "Accepted to the 30th International Joint Conference on Artificial\n  Intelligence (IJCAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In its most traditional setting, the main concern of optimization theory is\nthe search for optimal solutions for instances of a given computational\nproblem. A recent trend of research in artificial intelligence, called solution\ndiversity, has focused on the development of notions of optimality that may be\nmore appropriate in settings where subjectivity is essential. The idea is that\ninstead of aiming at the development of algorithms that output a single optimal\nsolution, the goal is to investigate algorithms that output a small set of\nsufficiently good solutions that are sufficiently diverse from one another. In\nthis way, the user has the opportunity to choose the solution that is most\nappropriate to the context at hand. It also displays the richness of the\nsolution space.\n  When combined with techniques from parameterized complexity theory, the\nparadigm of diversity of solutions offers a powerful algorithmic framework to\naddress problems of practical relevance. In this work, we investigate the\nimpact of this combination in the field of Kemeny Rank Aggregation, a\nwell-studied class of problems lying in the intersection of order theory and\nsocial choice theory and also in the field of order theory itself. In\nparticular, we show that the Kemeny Rank Aggregation problem is fixed-parameter\ntractable with respect to natural parameters providing natural formalizations\nof the notions of diversity and of the notion of a sufficiently good solution.\nOur main results work both when considering the traditional setting of\naggregation over linearly ordered votes, and in the more general setting where\nvotes are partially ordered.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 21:50:03 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Arrighi", "Emmanuel", ""], ["Fernau", "Henning", ""], ["Lokshtanov", "Daniel", ""], ["Oliveira", "Mateus de Oliveira", ""], ["Wolf", "Petra", ""]]}, {"id": "2105.09418", "submitter": "Mayukh Bagchi", "authors": "Fausto Giunchiglia, Simone Bocca, Mattia Fumagalli, Mayukh Bagchi and\n  Alessio Zamboni", "title": "iTelos- Building reusable knowledge graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  It is a fact that, when developing a new application, it is virtually\nimpossible to reuse, as-is, existing datasets. This difficulty is the cause of\nadditional costs, with the further drawback that the resulting application will\nagain be hardly reusable. It is a negative loop which consistently reinforces\nitself and for which there seems to be no way out. iTelos is a general purpose\nmethodology designed to break this loop. Its main goal is to generate reusable\nKnowledge Graphs (KGs), built reusing, as much as possible, already existing\ndata. The key assumption is that the design of a KG should be done middle-out\nmeaning by this that the design should take into consideration, in all phases\nof the development: (i) the purpose to be served, that we formalize as a set of\ncompetency queries, (ii) a set of pre-existing datasets, possibly extracted\nfrom existing KGs, and (iii) a set of pre-existing reference schemas, whose\ngoal is to facilitate sharability. We call these reference schemas,\nteleologies, as distinct from ontologies, meaning by this that, while having a\nsimilar purpose, they are designed to be easily adapted, thus becoming a key\nenabler of itelos.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 22:07:46 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Giunchiglia", "Fausto", ""], ["Bocca", "Simone", ""], ["Fumagalli", "Mattia", ""], ["Bagchi", "Mayukh", ""], ["Zamboni", "Alessio", ""]]}, {"id": "2105.09422", "submitter": "Mayukh Bagchi", "authors": "Fausto Giunchiglia and Mayukh Bagchi", "title": "Classifying concepts via visual properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We assume that substances in the world are represented by two types of\nconcepts, namely substance concepts and classification concepts, the former\ninstrumental to (visual) perception, the latter to (language based)\nclassification. Based on this distinction, we introduce a general methodology\nfor building lexico-semantic hierarchies of substance concepts, where nodes are\nannotated with the media, e.g.,videos or photos, from which substance concepts\nare extracted, and are associated with the corresponding classification\nconcepts. The methodology is based on Ranganathan's original faceted approach,\ncontextualized to the problem of classifying substance concepts. The key\nnovelty is that the hierarchy is built exploiting the visual properties of\nsubstance concepts, while the linguistically defined properties of\nclassification concepts are only used to describe substance concepts. The\nvalidity of the approach is exemplified by providing some highlights of an\nongoing project whose goal is to build a large scale multimedia multilingual\nconcept hierarchy.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 22:24:30 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Giunchiglia", "Fausto", ""], ["Bagchi", "Mayukh", ""]]}, {"id": "2105.09428", "submitter": "Chuhong Lahlou", "authors": "Chuhong Lahlou, Ancil Crayton, Caroline Trier, Evan Willett", "title": "Explainable Health Risk Predictor with Transformer-based Medicare Claim\n  Encoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2019, The Centers for Medicare and Medicaid Services (CMS) launched an\nArtificial Intelligence (AI) Health Outcomes Challenge seeking solutions to\npredict risk in value-based care for incorporation into CMS Innovation Center\npayment and service delivery models. Recently, modern language models have\nplayed key roles in a number of health related tasks. This paper presents, to\nthe best of our knowledge, the first application of these models to patient\nreadmission prediction. To facilitate this, we create a dataset of 1.2 million\nmedical history samples derived from the Limited Dataset (LDS) issued by CMS.\nMoreover, we propose a comprehensive modeling solution centered on a deep\nlearning framework for this data. To demonstrate the framework, we train an\nattention-based Transformer to learn Medicare semantics in support of\nperforming downstream prediction tasks thereby achieving 0.91 AUC and 0.91\nrecall on readmission classification. We also introduce a novel data\npre-processing pipeline and discuss pertinent deployment considerations\nsurrounding model explainability and bias.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 22:39:15 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Lahlou", "Chuhong", ""], ["Crayton", "Ancil", ""], ["Trier", "Caroline", ""], ["Willett", "Evan", ""]]}, {"id": "2105.09432", "submitter": "Mayukh Bagchi", "authors": "Fausto Giunchiglia, Alessio Zamboni, Mayukh Bagchi and Simone Bocca", "title": "Stratified Data Integration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel approach to the problem of semantic heterogeneity where\ndata are organized into a set of stratified and independent representation\nlayers, namely: conceptual(where a set of unique alinguistic identifiers are\nconnected inside a graph codifying their meaning), language(where sets of\nsynonyms, possibly from multiple languages, annotate concepts), knowledge(in\nthe form of a graph where nodes are entity types and links are properties), and\ndata(in the form of a graph of entities populating the previous knowledge\ngraph). This allows us to state the problem of semantic heterogeneity as a\nproblem of Representation Diversity where the different types of heterogeneity,\nviz. Conceptual, Language, Knowledge, and Data, are uniformly dealt within each\nsingle layer, independently from the others. In this paper we describe the\nproposed stratified representation of data and the process by which data are\nfirst transformed into the target representation, then suitably integrated and\nthen, finally, presented to the user in her preferred format. The proposed\nframework has been evaluated in various pilot case studies and in a number of\nindustrial data integration problems.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 23:14:41 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Giunchiglia", "Fausto", ""], ["Zamboni", "Alessio", ""], ["Bagchi", "Mayukh", ""], ["Bocca", "Simone", ""]]}, {"id": "2105.09452", "submitter": "Lucas N. Alegre", "authors": "Lucas N. Alegre, Ana L. C. Bazzan, Bruno C. da Silva", "title": "Minimum-Delay Adaptation in Non-Stationary Reinforcement Learning via\n  Online High-Confidence Change-Point Detection", "comments": "Published at Proc. of the 20th International Conference on Autonomous\n  Agents and Multiagent Systems (AAMAS 2021)", "journal-ref": "Proceedings of the 20th International Conference on Autonomous\n  Agents and Multiagent Systems. 2021. 97-105", "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-stationary environments are challenging for reinforcement learning\nalgorithms. If the state transition and/or reward functions change based on\nlatent factors, the agent is effectively tasked with optimizing a behavior that\nmaximizes performance over a possibly infinite random sequence of Markov\nDecision Processes (MDPs), each of which drawn from some unknown distribution.\nWe call each such MDP a context. Most related works make strong assumptions\nsuch as knowledge about the distribution over contexts, the existence of\npre-training phases, or a priori knowledge about the number, sequence, or\nboundaries between contexts. We introduce an algorithm that efficiently learns\npolicies in non-stationary environments. It analyzes a possibly infinite stream\nof data and computes, in real-time, high-confidence change-point detection\nstatistics that reflect whether novel, specialized policies need to be created\nand deployed to tackle novel contexts, or whether previously-optimized ones\nmight be reused. We show that (i) this algorithm minimizes the delay until\nunforeseen changes to a context are detected, thereby allowing for rapid\nresponses; and (ii) it bounds the rate of false alarm, which is important in\norder to minimize regret. Our method constructs a mixture model composed of a\n(possibly infinite) ensemble of probabilistic dynamics predictors that model\nthe different modes of the distribution over underlying latent MDPs. We\nevaluate our algorithm on high-dimensional continuous reinforcement learning\nproblems and show that it outperforms state-of-the-art (model-free and\nmodel-based) RL algorithms, as well as state-of-the-art meta-learning methods\nspecially designed to deal with non-stationarity.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 01:57:52 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Alegre", "Lucas N.", ""], ["Bazzan", "Ana L. C.", ""], ["da Silva", "Bruno C.", ""]]}, {"id": "2105.09458", "submitter": "Ningyu Zhang", "authors": "Dongfang Lou, Zhilin Liao, Shumin Deng, Ningyu Zhang, Huajun Chen", "title": "MLBiNet: A Cross-Sentence Collective Event Detection Network", "comments": "Accepted by ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of collectively detecting multiple events,\nparticularly in cross-sentence settings. The key to dealing with the problem is\nto encode semantic information and model event inter-dependency at a\ndocument-level. In this paper, we reformulate it as a Seq2Seq task and propose\na Multi-Layer Bidirectional Network (MLBiNet) to capture the document-level\nassociation of events and semantic information simultaneously. Specifically, a\nbidirectional decoder is firstly devised to model event inter-dependency within\na sentence when decoding the event tag vector sequence. Secondly, an\ninformation aggregation module is employed to aggregate sentence-level semantic\nand event tag information. Finally, we stack multiple bidirectional decoders\nand feed cross-sentence information, forming a multi-layer bidirectional\ntagging architecture to iteratively propagate information across sentences. We\nshow that our approach provides significant improvement in performance compared\nto the current state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 02:29:03 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 10:16:22 GMT"}, {"version": "v3", "created": "Tue, 1 Jun 2021 04:40:06 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Lou", "Dongfang", ""], ["Liao", "Zhilin", ""], ["Deng", "Shumin", ""], ["Zhang", "Ningyu", ""], ["Chen", "Huajun", ""]]}, {"id": "2105.09459", "submitter": "Md Mohaimenuzzaman", "authors": "Md Mohaimenuzzaman, SM Monzurur Rahman, Musaed Alhussein, Ghulam\n  Muhammad and Khondaker Abdullah Al Mamun", "title": "Enhancing safety in water transport system based on Internet of Things\n  for developing countries", "comments": null, "journal-ref": "International Journal of Distributed Sensor Networks (2016),\n  12(2), 2834616", "doi": "10.1155/2016/2834616", "report-no": null, "categories": "cs.NI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Accidents in inland waterways in developing countries are a regular\nphenomenon throughout the year causing deaths, injuries, monetary loss, and a\nsignificant amount of missing people. In consequence, a lot of families are\nlosing their dear ones leading to much misery. The above context demands an\nintelligent, safe, and reliable water transport system for the developing\ncountries. The concept of Intelligent Transport System (ITS) can be applied to\ndevelop such system; however, there are issues with ITS and Internet of Things\n(IoT) unlocks a new way of developing it. This paper proposes a model to\ntransform the water transport system into an intelligent system based on IoT.\nIPv6 based machine-to-machine (M2M) protocol, 3G telecommunication technology,\nand IEEE 802.15.4 network standard play a significant role in this proposed IoT\nbased system.\n", "versions": [{"version": "v1", "created": "Fri, 5 Mar 2021 06:09:11 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Mohaimenuzzaman", "Md", ""], ["Rahman", "SM Monzurur", ""], ["Alhussein", "Musaed", ""], ["Muhammad", "Ghulam", ""], ["Mamun", "Khondaker Abdullah Al", ""]]}, {"id": "2105.09464", "submitter": "Yongxiang Gu", "authors": "Yongxiang Gu, Xiaolin Qin, Yuncong Peng, Lu Li", "title": "Content-Augmented Feature Pyramid Network with Light Linear Spatial\n  Transformers for Object Detection", "comments": "13 pages,7 figures,6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As one of the prevalent components, Feature Pyramid Network (FPN) is widely\nused in the current object detection models to improve the performance of\nmulti-scale detection. However, its interaction is still in a local and lossy\nmanner, thus limiting the representation power. In this paper, to simulate a\nglobal view of human vision in object detection and address the inherent\ndefects of interaction mode in FPN, we construct a novel architecture termed\nContent-Augmented Feature Pyramid Network (CA-FPN). Unlike the vanilla FPN,\nwhich fuses features within a local receptive field, CA-FPN can adaptively\naggregate similar features from a global view. It is equipped with a global\ncontent extraction module and light linear spatial transformers. The former\nallows to extract multi-scale context information and the latter can deeply\ncombine the global content extraction module with the vanilla FPN using the\nlinearized attention function, which is designed to reduce model complexity.\nFurthermore, CA-FPN can be readily plugged into existing FPN-based models.\nExtensive experiments on the challenging COCO and PASCAL VOC object detection\ndatasets demonstrated that our CA-FPN significantly outperforms competitive\nFPN-based detectors without bells and whistles. When plugging CA-FPN into\nCascade R-CNN framework built upon a standard ResNet-50 backbone, our method\ncan achieve 44.8 AP on COCO mini-val. Its performance surpasses the previous\nstate-of-the-art by 1.5 AP, demonstrating the potentiality of application.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 02:31:31 GMT"}, {"version": "v2", "created": "Sat, 17 Jul 2021 09:12:24 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Gu", "Yongxiang", ""], ["Qin", "Xiaolin", ""], ["Peng", "Yuncong", ""], ["Li", "Lu", ""]]}, {"id": "2105.09484", "submitter": "Hoang D. Nguyen", "authors": "Minh-Duc Hoang, Linh Le, Anh-Tuan Nguyen, Trang Le and Hoang D. Nguyen", "title": "Federated Artificial Intelligence for Unified Credit Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid adoption of Internet technologies, digital footprints have\nbecome ubiquitous and versatile to revolutionise the financial industry in\ndigital transformation. This paper takes initiatives to investigate a new\nparadigm of the unified credit assessment with the use of federated artificial\nintelligence. We conceptualised digital human representation which consists of\nsocial, contextual, financial and technological dimensions to assess the\ncommercial creditworthiness and social reputation of both banked and unbanked\nindividuals. A federated artificial intelligence platform is proposed with a\ncomprehensive set of system design for efficient and effective credit scoring.\nThe study considerably contributes to the cumulative development of financial\nintelligence and social computing. It also provides a number of implications\nfor academic bodies, practitioners, and developers of financial technologies.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 03:05:42 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hoang", "Minh-Duc", ""], ["Le", "Linh", ""], ["Nguyen", "Anh-Tuan", ""], ["Le", "Trang", ""], ["Nguyen", "Hoang D.", ""]]}, {"id": "2105.09489", "submitter": "Hoang D. Nguyen", "authors": "Ethan Lim Ding Feng, Zhi-Wei Neo, Aaron William De Silva, Kellie Sim,\n  Hong-Ray Tan, Thi-Thanh Nguyen, Karen Wei Ling Koh, Wenru Wang and Hoang D.\n  Nguyen", "title": "Social Behaviour Understanding using Deep Neural Networks: Development\n  of Social Intelligence Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development in artificial intelligence, social computing has\nevolved beyond social informatics toward the birth of social intelligence\nsystems. This paper, therefore, takes initiatives to propose a social behaviour\nunderstanding framework with the use of deep neural networks for social and\nbehavioural analysis. The integration of information fusion, person and object\ndetection, social signal understanding, behaviour understanding, and context\nunderstanding plays a harmonious role to elicit social behaviours. Three\nsystems, including depression detection, activity recognition and cognitive\nimpairment screening, are developed to evidently demonstrate the importance of\nsocial intelligence. The study considerably contributes to the cumulative\ndevelopment of social computing and health informatics. It also provides a\nnumber of implications for academic bodies, healthcare practitioners, and\ndevelopers of socially intelligent agents.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 03:19:55 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Feng", "Ethan Lim Ding", ""], ["Neo", "Zhi-Wei", ""], ["De Silva", "Aaron William", ""], ["Sim", "Kellie", ""], ["Tan", "Hong-Ray", ""], ["Nguyen", "Thi-Thanh", ""], ["Koh", "Karen Wei Ling", ""], ["Wang", "Wenru", ""], ["Nguyen", "Hoang D.", ""]]}, {"id": "2105.09490", "submitter": "Harry Nguyen", "authors": "Thuy-Trinh Nguyen, Kellie Sim, Anthony To Yiu Kuen, Ronald R.\n  O'donnell, Suan Tee Lim, Wenru Wang and Hoang D. Nguyen", "title": "Designing AI-based Conversational Agent for Diabetes Care in a\n  Multilingual Context", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational agents (CAs) represent an emerging research field in health\ninformation systems, where there are great potentials in empowering patients\nwith timely information and natural language interfaces. Nevertheless, there\nhave been limited attempts in establishing prescriptive knowledge on designing\nCAs in the healthcare domain in general, and diabetes care specifically. In\nthis paper, we conducted a Design Science Research project and proposed three\ndesign principles for designing health-related CAs that embark on artificial\nintelligence (AI) to address the limitations of existing solutions. Further, we\ninstantiated the proposed design and developed AMANDA - an AI-based\nmultilingual CA in diabetes care with state-of-the-art technologies for\nnatural-sounding localised accent. We employed mean opinion scores and system\nusability scale to evaluate AMANDA's speech quality and usability,\nrespectively. This paper provides practitioners with a blueprint for designing\nCAs in diabetes care with concrete design guidelines that can be extended into\nother healthcare domains.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 03:20:24 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Nguyen", "Thuy-Trinh", ""], ["Sim", "Kellie", ""], ["Kuen", "Anthony To Yiu", ""], ["O'donnell", "Ronald R.", ""], ["Lim", "Suan Tee", ""], ["Wang", "Wenru", ""], ["Nguyen", "Hoang D.", ""]]}, {"id": "2105.09509", "submitter": "Shirong Shen", "authors": "Shirong Shen and Tongtong Wu and Guilin Qi and Yuan-Fang Li and\n  Gholamreza Haffari and Sheng Bi", "title": "Adaptive Knowledge-Enhanced Bayesian Meta-Learning for Few-shot Event\n  Detection", "comments": "Accepted by ACL2021 Findings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Event detection (ED) aims at detecting event trigger words in sentences and\nclassifying them into specific event types. In real-world applications, ED\ntypically does not have sufficient labelled data, thus can be formulated as a\nfew-shot learning problem. To tackle the issue of low sample diversity in\nfew-shot ED, we propose a novel knowledge-based few-shot event detection method\nwhich uses a definition-based encoder to introduce external event knowledge as\nthe knowledge prior of event types. Furthermore, as external knowledge\ntypically provides limited and imperfect coverage of event types, we introduce\nan adaptive knowledge-enhanced Bayesian meta-learning method to dynamically\nadjust the knowledge prior of event types. Experiments show our method\nconsistently and substantially outperforms a number of baselines by at least 15\nabsolute F1 points under the same few-shot settings.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 04:26:26 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 14:17:57 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Shen", "Shirong", ""], ["Wu", "Tongtong", ""], ["Qi", "Guilin", ""], ["Li", "Yuan-Fang", ""], ["Haffari", "Gholamreza", ""], ["Bi", "Sheng", ""]]}, {"id": "2105.09540", "submitter": "Xiaolin Chen", "authors": "Xiaolin Chen, Shuai Zhou, Kai Yang, Hao Fan, Zejin Feng, Zhong Chen,\n  Hu Wang, Yongji Wang", "title": "Fed-EINI: An Efficient and Interpretable Inference Framework for\n  Decision Tree Ensembles in Federated Learning", "comments": "10 pages, 5 figures, accepted by International Workshop on Federated\n  Learning for User Privacy and Data Confidentiality in Conjunction with ICML\n  2021(FL-ICML'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing concerns about data privacy and security drive an emerging\nfield of studying privacy-preserving machine learning from isolated data\nsources, i.e., federated learning. A class of federated learning, vertical\nfederated learning, where different parties hold different features for common\nusers, has a great potential of driving a more variety of business cooperation\namong enterprises in many fields. In machine learning, decision tree ensembles\nsuch as gradient boosting decision tree (GBDT) and random forest are widely\napplied powerful models with high interpretability and modeling efficiency.\nHowever, the interpretability is compromised in state-of-the-art vertical\nfederated learning frameworks such as SecureBoost with anonymous features to\navoid possible data breaches. To address this issue in the inference process,\nin this paper, we propose Fed-EINI to protect data privacy and allow the\ndisclosure of feature meaning by concealing decision paths with a\ncommunication-efficient secure computation method for inference outputs. The\nadvantages of Fed-EINI will be demonstrated through both theoretical analysis\nand extensive numerical results.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 06:40:05 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2021 08:09:39 GMT"}, {"version": "v3", "created": "Fri, 16 Jul 2021 08:07:13 GMT"}, {"version": "v4", "created": "Mon, 19 Jul 2021 13:17:56 GMT"}, {"version": "v5", "created": "Tue, 20 Jul 2021 14:25:09 GMT"}, {"version": "v6", "created": "Mon, 26 Jul 2021 13:10:19 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Chen", "Xiaolin", ""], ["Zhou", "Shuai", ""], ["Yang", "Kai", ""], ["Fan", "Hao", ""], ["Feng", "Zejin", ""], ["Chen", "Zhong", ""], ["Wang", "Hu", ""], ["Wang", "Yongji", ""]]}, {"id": "2105.09560", "submitter": "Hanyang Liu", "authors": "Guanjie Zheng, Hanyang Liu, Kai Xu, Zhenhui Li", "title": "Objective-aware Traffic Simulation via Inverse Reinforcement Learning", "comments": "Accepted for publication by IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Traffic simulators act as an essential component in the operating and\nplanning of transportation systems. Conventional traffic simulators usually\nemploy a calibrated physical car-following model to describe vehicles'\nbehaviors and their interactions with traffic environment. However, there is no\nuniversal physical model that can accurately predict the pattern of vehicle's\nbehaviors in different situations. A fixed physical model tends to be less\neffective in a complicated environment given the non-stationary nature of\ntraffic dynamics. In this paper, we formulate traffic simulation as an inverse\nreinforcement learning problem, and propose a parameter sharing adversarial\ninverse reinforcement learning model for dynamics-robust simulation learning.\nOur proposed model is able to imitate a vehicle's trajectories in the real\nworld while simultaneously recovering the reward function that reveals the\nvehicle's true objective which is invariant to different dynamics. Extensive\nexperiments on synthetic and real-world datasets show the superior performance\nof our approach compared to state-of-the-art methods and its robustness to\nvariant dynamics of traffic.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 07:26:34 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Zheng", "Guanjie", ""], ["Liu", "Hanyang", ""], ["Xu", "Kai", ""], ["Li", "Zhenhui", ""]]}, {"id": "2105.09567", "submitter": "Lianwei Wu", "authors": "Lianwei Wu, Yuan Rao, Yuqian Lan, Ling Sun and Zhaoyin Qi", "title": "Unified Dual-view Cognitive Model for Interpretable Claim Verification", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent studies constructing direct interactions between the claim and each\nsingle user response (a comment or a relevant article) to capture evidence have\nshown remarkable success in interpretable claim verification. Owing to\ndifferent single responses convey different cognition of individual users\n(i.e., audiences), the captured evidence belongs to the perspective of\nindividual cognition. However, individuals' cognition of social things is not\nalways able to truly reflect the objective. There may be one-sided or biased\nsemantics in their opinions on a claim. The captured evidence correspondingly\ncontains some unobjective and biased evidence fragments, deteriorating task\nperformance. In this paper, we propose a Dual-view model based on the views of\nCollective and Individual Cognition (CICD) for interpretable claim\nverification. From the view of the collective cognition, we not only capture\nthe word-level semantics based on individual users, but also focus on\nsentence-level semantics (i.e., the overall responses) among all users and\nadjust the proportion between them to generate global evidence. From the view\nof individual cognition, we select the top-$k$ articles with high degree of\ndifference and interact with the claim to explore the local key evidence\nfragments. To weaken the bias of individual cognition-view evidence, we devise\ninconsistent loss to suppress the divergence between global and local evidence\nfor strengthening the consistent shared evidence between the both. Experiments\non three benchmark datasets confirm that CICD achieves state-of-the-art\nperformance.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 07:44:03 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Wu", "Lianwei", ""], ["Rao", "Yuan", ""], ["Lan", "Yuqian", ""], ["Sun", "Ling", ""], ["Qi", "Zhaoyin", ""]]}, {"id": "2105.09574", "submitter": "Dawid Wisniewski", "authors": "Dawid Wi\\'sniewski and J\\k{e}drzej Potoniec and Agnieszka\n  {\\L}awrynowicz", "title": "BigCQ: A large-scale synthetic dataset of competency question patterns\n  formalized into SPARQL-OWL query templates", "comments": "16 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Competency Questions (CQs) are used in many ontology engineering\nmethodologies to collect requirements and track the completeness and\ncorrectness of an ontology being constructed. Although they are frequently\nsuggested by ontology engineering methodologies, the publicly available\ndatasets of CQs and their formalizations in ontology query languages are very\nscarce. Since first efforts to automate processes utilizing CQs are being made,\nit is of high importance to provide large and diverse datasets to fuel these\nsolutions. In this paper, we present BigCQ, the biggest dataset of CQ templates\nwith their formalizations into SPARQL-OWL query templates. BigCQ is created\nautomatically from a dataset of frequently used axiom shapes. These pairs of CQ\ntemplates and query templates can be then materialized as actual CQs and\nSPARQL-OWL queries if filled with resource labels and IRIs from a given\nontology. We describe the dataset in detail, provide a description of the\nprocess leading to the creation of the dataset and analyze how well the dataset\ncovers real-world examples. We also publish the dataset as well as scripts\ntransforming axiom shapes into pairs of CQ patterns and SPARQL-OWL templates,\nto make engineers able to adapt the process to their particular needs.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 07:59:59 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Wi\u015bniewski", "Dawid", ""], ["Potoniec", "J\u0119drzej", ""], ["\u0141awrynowicz", "Agnieszka", ""]]}, {"id": "2105.09596", "submitter": "Wei Xiang", "authors": "Li Wang, Wei Xiang, Ruhui Xue, Kaida Zou, Laili Zhu", "title": "AGSFCOS: Based on attention mechanism and Scale-Equalizing pyramid\n  network of object detection", "comments": "9 pages,9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, the anchor-free object detection model has shown great potential\nfor accuracy and speed to exceed anchor-based object detection. Therefore, two\nissues are mainly studied in this article: (1) How to let the backbone network\nin the anchor-free object detection model learn feature extraction? (2) How to\nmake better use of the feature pyramid network? In order to solve the above\nproblems, Experiments show that our model has a certain improvement in accuracy\ncompared with the current popular detection models on the COCO dataset, the\ndesigned attention mechanism module can capture contextual information well,\nimprove detection accuracy, and use sepc network to help balance abstract and\ndetailed information, and reduce the problem of semantic gap in the feature\npyramid network. Whether it is anchor-based network model YOLOv3, Faster RCNN,\nor anchor-free network model Foveabox, FSAF, FCOS. Our optimal model can get\n39.5% COCO AP under the background of ResNet50.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 08:41:02 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Wang", "Li", ""], ["Xiang", "Wei", ""], ["Xue", "Ruhui", ""], ["Zou", "Kaida", ""], ["Zhu", "Laili", ""]]}, {"id": "2105.09605", "submitter": "Yu Wang", "authors": "Yu Wang, Xin Xin, Zaiqiao Meng, Xiangnan He, Joemon Jose, Fuli Feng", "title": "Probabilistic and Variational Recommendation Denoising", "comments": "13 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning from implicit feedback is one of the most common cases in the\napplication of recommender systems. Generally speaking, interacted examples are\nconsidered as positive while negative examples are sampled from uninteracted\nones. However, noisy examples are prevalent in real-world implicit feedback. A\nnoisy positive example could be interacted but it actually leads to negative\nuser preference. A noisy negative example which is uninteracted because of\nunawareness of the user could also denote potential positive user preference.\nConventional training methods overlook these noisy examples, leading to\nsub-optimal recommendation. In this work, we propose probabilistic and\nvariational recommendation denoising for implicit feedback. Through an\nempirical study, we find that different models make relatively similar\npredictions on clean examples which denote the real user preference, while the\npredictions on noisy examples vary much more across different models. Motivated\nby this observation, we propose denoising with probabilistic inference (DPI)\nwhich aims to minimize the KL-divergence between the real user preference\ndistributions parameterized by two recommendation models while maximize the\nlikelihood of data observation. We then show that DPI recovers the evidence\nlower bound of an variational auto-encoder when the real user preference is\nconsidered as the latent variables. This leads to our second learning framework\ndenoising with variational autoencoder (DVAE). We employ the proposed DPI and\nDVAE on four state-of-the-art recommendation models and conduct experiments on\nthree datasets. Experimental results demonstrate that DPI and DVAE\nsignificantly improve recommendation performance compared with normal training\nand other denoising methods. Codes will be open-sourced.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 08:59:44 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Wang", "Yu", ""], ["Xin", "Xin", ""], ["Meng", "Zaiqiao", ""], ["He", "Xiangnan", ""], ["Jose", "Joemon", ""], ["Feng", "Fuli", ""]]}, {"id": "2105.09618", "submitter": "Noa Malem-Shinitski", "authors": "Noa Malem-Shinitski, Cesar Ojeda and Manfred Opper", "title": "Nonlinear Hawkes Process with Gaussian Process Self Effects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditionally, Hawkes processes are used to model time--continuous point\nprocesses with history dependence. Here we propose an extended model where the\nself--effects are of both excitatory and inhibitory type and follow a Gaussian\nProcess. Whereas previous work either relies on a less flexible\nparameterization of the model, or requires a large amount of data, our\nformulation allows for both a flexible model and learning when data are scarce.\nWe continue the line of work of Bayesian inference for Hawkes processes, and\nour approach dispenses with the necessity of estimating a branching structure\nfor the posterior, as we perform inference on an aggregated sum of Gaussian\nProcesses. Efficient approximate Bayesian inference is achieved via data\naugmentation, and we describe a mean--field variational inference approach to\nlearn the model parameters. To demonstrate the flexibility of the model we\napply our methodology on data from three different domains and compare it to\npreviously reported results.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 09:20:35 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Malem-Shinitski", "Noa", ""], ["Ojeda", "Cesar", ""], ["Opper", "Manfred", ""]]}, {"id": "2105.09637", "submitter": "Sam Devlin", "authors": "Sam Devlin, Raluca Georgescu, Ida Momennejad, Jaroslaw Rzepecki,\n  Evelyn Zuniga, Gavin Costello, Guy Leroy, Ali Shaw and Katja Hofmann", "title": "Navigation Turing Test (NTT): Learning to Evaluate Human-Like Navigation", "comments": "All data collected throughout this study, plus the code to reproduce\n  our analysis and ANTT are available at https://github.com/microsoft/NTT", "journal-ref": "Proceedings of the 38th International Conference on Machine\n  Learning (ICML), 139:2644-2653, 2021", "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A key challenge on the path to developing agents that learn complex\nhuman-like behavior is the need to quickly and accurately quantify\nhuman-likeness. While human assessments of such behavior can be highly\naccurate, speed and scalability are limited. We address these limitations\nthrough a novel automated Navigation Turing Test (ANTT) that learns to predict\nhuman judgments of human-likeness. We demonstrate the effectiveness of our\nautomated NTT on a navigation task in a complex 3D environment. We investigate\nsix classification models to shed light on the types of architectures best\nsuited to this task, and validate them against data collected through a human\nNTT. Our best models achieve high accuracy when distinguishing true human and\nagent behavior. At the same time, we show that predicting finer-grained human\nassessment of agents' progress towards human-like behavior remains unsolved.\nOur work takes an important step towards agents that more effectively learn\ncomplex human-like behavior.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 10:14:23 GMT"}, {"version": "v2", "created": "Wed, 28 Jul 2021 12:49:43 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Devlin", "Sam", ""], ["Georgescu", "Raluca", ""], ["Momennejad", "Ida", ""], ["Rzepecki", "Jaroslaw", ""], ["Zuniga", "Evelyn", ""], ["Costello", "Gavin", ""], ["Leroy", "Guy", ""], ["Shaw", "Ali", ""], ["Hofmann", "Katja", ""]]}, {"id": "2105.09647", "submitter": "Chie Hieida", "authors": "Chie Hieida and Takayuki Nagai", "title": "Survey and Perspective on Social Emotions in Robotics", "comments": "This is a preprint of an article submitted for consideration in\n  Advances Robotics, copyright Taylor \\& Francis and Robotics Society of Japan;\n  Advances Robotics is available online at http://www.tandfonline.com/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This study reviews research on social emotions in robotics. In robotics,\nemotions are pursued for a long duration, such as recognition, expression, and\ncomputational modeling of the basic mechanism behind them. Research has been\npromoted according to well-known psychological findings, such as category and\ndimension theories. Many studies have been based on these basic theories,\naddressing only basic emotions. However, social emotions, also called\nhigher-level emotions, have been studied in psychology. We believe that these\nhigher-level emotions are worth pursuing in robotics for next-generation\nsocial-aware robots. In this review paper, while summarizing the findings of\nsocial emotions in psychology and neuroscience, studies on social emotions in\nrobotics at present are surveyed. Thereafter, research directions towards\nimplementation of social emotions in robots are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 10:25:37 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hieida", "Chie", ""], ["Nagai", "Takayuki", ""]]}, {"id": "2105.09685", "submitter": "Jaydeep Borkar", "authors": "Jaydeep Borkar, Pin-Yu Chen", "title": "Simple Transparent Adversarial Examples", "comments": "14 pages, 9 figures, Published at ICLR 2021 Workshop on Security and\n  Safety in Machine Learning Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a rise in the use of Machine Learning as a Service (MLaaS)\nVision APIs as they offer multiple services including pre-built models and\nalgorithms, which otherwise take a huge amount of resources if built from\nscratch. As these APIs get deployed for high-stakes applications, it's very\nimportant that they are robust to different manipulations. Recent works have\nonly focused on typical adversarial attacks when evaluating the robustness of\nvision APIs. We propose two new aspects of adversarial image generation methods\nand evaluate them on the robustness of Google Cloud Vision API's optical\ncharacter recognition service and object detection APIs deployed in real-world\nsettings such as sightengine.com, picpurify.com, Google Cloud Vision API, and\nMicrosoft Azure's Computer Vision API. Specifically, we go beyond the\nconventional small-noise adversarial attacks and introduce secret embedding and\ntransparent adversarial examples as a simpler way to evaluate robustness. These\nmethods are so straightforward that even non-specialists can craft such\nattacks. As a result, they pose a serious threat where APIs are used for\nhigh-stakes applications. Our transparent adversarial examples successfully\nevade state-of-the art object detections APIs such as Azure Cloud Vision\n(attack success rate 52%) and Google Cloud Vision (attack success rate 36%).\n90% of the images have a secret embedded text that successfully fools the\nvision of time-limited humans but is detected by Google Cloud Vision API's\noptical character recognition. Complementing to current research, our results\nprovide simple but unconventional methods on robustness evaluation.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 11:54:26 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Borkar", "Jaydeep", ""], ["Chen", "Pin-Yu", ""]]}, {"id": "2105.09719", "submitter": "Maxence Mah\\'e", "authors": "Maxence Mahe, Pierre Belamri, Jesus Bujalance Martin", "title": "Towards a Sample Efficient Reinforcement Learning Pipeline for Vision\n  Based Robotics", "comments": "10 Pages, 15 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Deep Reinforcement learning holds the guarantee of empowering self-ruling\nrobots to master enormous collections of conduct abilities with negligible\nhuman mediation. The improvements brought by this technique enables robots to\nperform difficult tasks such as grabbing or reaching targets. Nevertheless, the\ntraining process is still time consuming and tedious especially when learning\npolicies only with RGB camera information. This way of learning is capital to\ntransfer the task from simulation to the real world since the only external\nsource of information for the robot in real life is video. In this paper, we\nstudy how to limit the time taken for training a robotic arm with 6 Degrees Of\nFreedom (DOF) to reach a ball from scratch by assembling a pipeline as\nefficient as possible. The pipeline is divided into two parts: the first one is\nto capture the relevant information from the RGB video with a Computer Vision\nalgorithm. The second one studies how to train faster a Deep Reinforcement\nLearning algorithm in order to make the robotic arm reach the target in front\nof him. Follow this link to find videos and plots in higher resolution:\n\\url{https://drive.google.com/drive/folders/1_lRlDSoPzd_GTcVrxNip10o_lm-_DPdn?usp=sharing}\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 13:13:01 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Mahe", "Maxence", ""], ["Belamri", "Pierre", ""], ["Martin", "Jesus Bujalance", ""]]}, {"id": "2105.09740", "submitter": "Siyuan Liu", "authors": "Orcun Yalcin, Xiuyi Fan, Siyuan Liu", "title": "Evaluating the Correctness of Explainable AI Algorithms for\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable AI has attracted much research attention in recent years with\nfeature attribution algorithms, which compute \"feature importance\" in\npredictions, becoming increasingly popular. However, there is little analysis\nof the validity of these algorithms as there is no \"ground truth\" in the\nexisting datasets to validate their correctness. In this work, we develop a\nmethod to quantitatively evaluate the correctness of XAI algorithms by creating\ndatasets with known explanation ground truth. To this end, we focus on the\nbinary classification problems. String datasets are constructed using formal\nlanguage derived from a grammar. A string is positive if and only if a certain\nproperty is fulfilled. Symbols serving as explanation ground truth in a\npositive string are part of an explanation if and only if they contributes to\nfulfilling the property. Two popular feature attribution explainers, Local\nInterpretable Model-agnostic Explanations (LIME) and SHapley Additive\nexPlanations (SHAP), are used in our experiments.We show that: (1)\nclassification accuracy is positively correlated with explanation accuracy; (2)\nSHAP provides more accurate explanations than LIME; (3) explanation accuracy is\nnegatively correlated with dataset complexity.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 13:36:41 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Yalcin", "Orcun", ""], ["Fan", "Xiuyi", ""], ["Liu", "Siyuan", ""]]}, {"id": "2105.09825", "submitter": "Alessandro Lenci", "authors": "Alessandro Lenci and Magnus Sahlgren and Patrick Jeuniaux and Amaru\n  Cuba Gyllensten and Martina Miliani", "title": "A comprehensive comparative evaluation and analysis of Distributional\n  Semantic Models", "comments": "Submitted to Language Resources and Evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distributional semantics has deeply changed in the last decades. First,\npredict models stole the thunder from traditional count ones, and more recently\nboth of them were replaced in many NLP applications by contextualized vectors\nproduced by Transformer neural language models. Although an extensive body of\nresearch has been devoted to Distributional Semantic Model (DSM) evaluation, we\nstill lack a thorough comparison with respect to tested models, semantic tasks,\nand benchmark datasets. Moreover, previous work has mostly focused on\ntask-driven evaluation, instead of exploring the differences between the way\nmodels represent the lexical semantic space. In this paper, we perform a\ncomprehensive evaluation of type distributional vectors, either produced by\nstatic DSMs or obtained by averaging the contextualized vectors generated by\nBERT. First of all, we investigate the performance of embeddings in several\nsemantic tasks, carrying out an in-depth statistical analysis to identify the\nmajor factors influencing the behavior of DSMs. The results show that i.) the\nalleged superiority of predict based models is more apparent than real, and\nsurely not ubiquitous and ii.) static DSMs surpass contextualized\nrepresentations in most out-of-context semantic tasks and datasets.\nFurthermore, we borrow from cognitive neuroscience the methodology of\nRepresentational Similarity Analysis (RSA) to inspect the semantic spaces\ngenerated by distributional models. RSA reveals important differences related\nto the frequency and part-of-speech of lexical items.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 15:18:06 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Lenci", "Alessandro", ""], ["Sahlgren", "Magnus", ""], ["Jeuniaux", "Patrick", ""], ["Gyllensten", "Amaru Cuba", ""], ["Miliani", "Martina", ""]]}, {"id": "2105.09829", "submitter": "Yongfeng Zhang", "authors": "Yunqi Li, Hanxiong Chen, Shuyuan Xu, Yingqiang Ge, Yongfeng Zhang", "title": "Personalized Counterfactual Fairness in Recommendation", "comments": "10 pages. Accepted to ACM SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462966", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are gaining increasing and critical impacts on human and\nsociety since a growing number of users use them for information seeking and\ndecision making. Therefore, it is crucial to address the potential unfairness\nproblems in recommendations. Just like users have personalized preferences on\nitems, users' demands for fairness are also personalized in many scenarios.\nTherefore, it is important to provide personalized fair recommendations for\nusers to satisfy their personalized fairness demands. Besides, previous works\non fair recommendation mainly focus on association-based fairness. However, it\nis important to advance from associative fairness notions to causal fairness\nnotions for assessing fairness more properly in recommender systems. Based on\nthe above considerations, this paper focuses on achieving personalized\ncounterfactual fairness for users in recommender systems. To this end, we\nintroduce a framework for achieving counterfactually fair recommendations\nthrough adversary learning by generating feature-independent user embeddings\nfor recommendation. The framework allows recommender systems to achieve\npersonalized fairness for users while also covering non-personalized\nsituations. Experiments on two real-world datasets with shallow and deep\nrecommendation algorithms show that our method can generate fairer\nrecommendations for users with a desirable recommendation performance.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 15:24:34 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 15:52:26 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Li", "Yunqi", ""], ["Chen", "Hanxiong", ""], ["Xu", "Shuyuan", ""], ["Ge", "Yingqiang", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "2105.09880", "submitter": "William McNally", "authors": "William McNally, Pascale Walters, Kanav Vats, Alexander Wong, John\n  McPhee", "title": "DeepDarts: Modeling Keypoints as Objects for Automatic Scorekeeping in\n  Darts using a Single Camera", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing multi-camera solutions for automatic scorekeeping in steel-tip darts\nare very expensive and thus inaccessible to most players. Motivated to develop\na more accessible low-cost solution, we present a new approach to keypoint\ndetection and apply it to predict dart scores from a single image taken from\nany camera angle. This problem involves detecting multiple keypoints that may\nbe of the same class and positioned in close proximity to one another. The\nwidely adopted framework for regressing keypoints using heatmaps is not\nwell-suited for this task. To address this issue, we instead propose to model\nkeypoints as objects. We develop a deep convolutional neural network around\nthis idea and use it to predict dart locations and dartboard calibration points\nwithin an overall pipeline for automatic dart scoring, which we call DeepDarts.\nAdditionally, we propose several task-specific data augmentation strategies to\nimprove the generalization of our method. As a proof of concept, two datasets\ncomprising 16k images originating from two different dartboard setups were\nmanually collected and annotated to evaluate the system. In the primary dataset\ncontaining 15k images captured from a face-on view of the dartboard using a\nsmartphone, DeepDarts predicted the total score correctly in 94.7% of the test\nimages. In a second more challenging dataset containing limited training data\n(830 images) and various camera angles, we utilize transfer learning and\nextensive data augmentation to achieve a test accuracy of 84.0%. Because\nDeepDarts relies only on single images, it has the potential to be deployed on\nedge devices, giving anyone with a smartphone access to an automatic dart\nscoring system for steel-tip darts. The code and datasets are available.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 16:25:57 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["McNally", "William", ""], ["Walters", "Pascale", ""], ["Vats", "Kanav", ""], ["Wong", "Alexander", ""], ["McPhee", "John", ""]]}, {"id": "2105.09903", "submitter": "Abhinav Valada", "authors": "Manav Madan, Peter Jakob, Tobias Schmid-Schirling, Abhinav Valada", "title": "Multi-Perspective Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view classification is inspired by the behavior of humans, especially\nwhen fine-grained features or in our case rarely occurring anomalies are to be\ndetected. Current contributions point to the problem of how high-dimensional\ndata can be fused. In this work, we build upon the deep support vector data\ndescription algorithm and address multi-perspective anomaly detection using\nthree different fusion techniques i.e. early fusion, late fusion, and late\nfusion with multiple decoders. We employ different augmentation techniques with\na denoising process to deal with scarce one-class data, which further improves\nthe performance (ROC AUC = 80\\%). Furthermore, we introduce the dices dataset\nthat consists of over 2000 grayscale images of falling dices from multiple\nperspectives, with 5\\% of the images containing rare anomalies (e.g. drill\nholes, sawing, or scratches). We evaluate our approach on the new dices dataset\nusing images from two different perspectives and also benchmark on the standard\nMNIST dataset. Extensive experiments demonstrate that our proposed approach\nexceeds the state-of-the-art on both the MNIST and dices datasets. To the best\nof our knowledge, this is the first work that focuses on addressing\nmulti-perspective anomaly detection in images by jointly using different\nperspectives together with one single objective function for anomaly detection.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 17:07:36 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Madan", "Manav", ""], ["Jakob", "Peter", ""], ["Schmid-Schirling", "Tobias", ""], ["Valada", "Abhinav", ""]]}, {"id": "2105.09909", "submitter": "Dipayan Das", "authors": "Dipayan Das, Saumik Bhattacharya, Umapada Pal, and Sukalpa Chanda", "title": "PLSM: A Parallelized Liquid State Machine for Unintentional Action\n  Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Reservoir Computing (RC) offers a viable option to deploy AI algorithms on\nlow-end embedded system platforms. Liquid State Machine (LSM) is a bio-inspired\nRC model that mimics the cortical microcircuits and uses spiking neural\nnetworks (SNN) that can be directly realized on neuromorphic hardware. In this\npaper, we present a novel Parallelized LSM (PLSM) architecture that\nincorporates spatio-temporal read-out layer and semantic constraints on model\noutput. To the best of our knowledge, such a formulation has been done for the\nfirst time in literature, and it offers a computationally lighter alternative\nto traditional deep-learning models. Additionally, we also present a\ncomprehensive algorithm for the implementation of parallelizable SNNs and LSMs\nthat are GPU-compatible. We implement the PLSM model to classify\nunintentional/accidental video clips, using the Oops dataset. From the\nexperimental results on detecting unintentional action in video, it can be\nobserved that our proposed model outperforms a self-supervised model and a\nfully supervised traditional deep learning model. All the implemented codes can\nbe found at our repository\nhttps://github.com/anonymoussentience2020/Parallelized_LSM_for_Unintentional_Action_Recognition.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 08:10:35 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Das", "Dipayan", ""], ["Bhattacharya", "Saumik", ""], ["Pal", "Umapada", ""], ["Chanda", "Sukalpa", ""]]}, {"id": "2105.09914", "submitter": "Bo-Hsiang (Andy) Tseng", "authors": "Bo-Hsiang Tseng, Shruti Bhargava, Jiarui Lu, Joel Ruben Antony Moniz,\n  Dhivya Piraviperumal, Lin Li, Hong Yu", "title": "CREAD: Combined Resolution of Ellipses and Anaphora in Dialogues", "comments": "Accepted as a long paper in the main conference by NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Anaphora and ellipses are two common phenomena in dialogues. Without\nresolving referring expressions and information omission, dialogue systems may\nfail to generate consistent and coherent responses. Traditionally, anaphora is\nresolved by coreference resolution and ellipses by query rewrite. In this work,\nwe propose a novel joint learning framework of modeling coreference resolution\nand query rewriting for complex, multi-turn dialogue understanding. Given an\nongoing dialogue between a user and a dialogue assistant, for the user query,\nour joint learning model first predicts coreference links between the query and\nthe dialogue context, and then generates a self-contained rewritten user query.\nTo evaluate our model, we annotate a dialogue based coreference resolution\ndataset, MuDoCo, with rewritten queries. Results show that the performance of\nquery rewrite can be substantially boosted (+2.3% F1) with the aid of\ncoreference modeling. Furthermore, our joint model outperforms the\nstate-of-the-art coreference resolution model (+2% F1) on this dataset.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 17:17:26 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Tseng", "Bo-Hsiang", ""], ["Bhargava", "Shruti", ""], ["Lu", "Jiarui", ""], ["Moniz", "Joel Ruben Antony", ""], ["Piraviperumal", "Dhivya", ""], ["Li", "Lin", ""], ["Yu", "Hong", ""]]}, {"id": "2105.09934", "submitter": "John Tsotsos", "authors": "John K. Tsotsos and Jun Luo", "title": "Probing the Effect of Selection Bias on NN Generalization with a Thought\n  Experiment", "comments": "24 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Learned networks in the domain of visual recognition and cognition impress in\npart because even though they are trained with datasets many orders of\nmagnitude smaller than the full population of possible images, they exhibit\nsufficient generalization to be applicable to new and previously unseen data.\nAlthough many have examined issues regarding generalization from several\nperspectives, we wondered If a network is trained with a biased dataset that\nmisses particular samples corresponding to some defining domain attribute, can\nit generalize to the full domain from which that training dataset was\nextracted? It is certainly true that in vision, no current training set fully\ncaptures all visual information and this may lead to Selection Bias. Here, we\ntry a novel approach in the tradition of the Thought Experiment. We run this\nthought experiment on a real domain of visual objects that we can fully\ncharacterize and look at specific gaps in training data and their impact on\nperformance requirements. Our thought experiment points to three conclusions:\nfirst, that generalization behavior is dependent on how sufficiently the\nparticular dimensions of the domain are represented during training; second,\nthat the utility of any generalization is completely dependent on the\nacceptable system error; and third, that specific visual features of objects,\nsuch as pose orientations out of the imaging plane or colours, may not be\nrecoverable if not represented sufficiently in a training set. Any currently\nobserved generalization in modern deep learning networks may be more the result\nof coincidental alignments and whose utility needs to be confirmed with respect\nto a system's performance specification. Our Thought Experiment Probe approach,\ncoupled with the resulting Bias Breakdown can be very informative towards\nunderstanding the impact of biases.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 17:54:48 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Tsotsos", "John K.", ""], ["Luo", "Jun", ""]]}, {"id": "2105.09937", "submitter": "Mehdi Moradi", "authors": "Nkechinyere N. Agu, Joy T. Wu, Hanqing Chao, Ismini Lourentzou, Arjun\n  Sharma, Mehdi Moradi, Pingkun Yan, James Hendler", "title": "AnaXNet: Anatomy Aware Multi-label Finding Classification in Chest X-ray", "comments": "Accepted to MICCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Radiologists usually observe anatomical regions of chest X-ray images as well\nas the overall image before making a decision. However, most existing deep\nlearning models only look at the entire X-ray image for classification, failing\nto utilize important anatomical information. In this paper, we propose a novel\nmulti-label chest X-ray classification model that accurately classifies the\nimage finding and also localizes the findings to their correct anatomical\nregions. Specifically, our model consists of two modules, the detection module\nand the anatomical dependency module. The latter utilizes graph convolutional\nnetworks, which enable our model to learn not only the label dependency but\nalso the relationship between the anatomical regions in the chest X-ray. We\nfurther utilize a method to efficiently create an adjacency matrix for the\nanatomical regions using the correlation of the label across the different\nregions. Detailed experiments and analysis of our results show the\neffectiveness of our method when compared to the current state-of-the-art\nmulti-label chest X-ray image classification methods while also providing\naccurate location information.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 17:58:02 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Agu", "Nkechinyere N.", ""], ["Wu", "Joy T.", ""], ["Chao", "Hanqing", ""], ["Lourentzou", "Ismini", ""], ["Sharma", "Arjun", ""], ["Moradi", "Mehdi", ""], ["Yan", "Pingkun", ""], ["Hendler", "James", ""]]}, {"id": "2105.09975", "submitter": "Sara Mousavi", "authors": "Sara Mousavi, Zhenning Yang, Kelley Cross, Dawnie Steadman, Audris\n  Mockus", "title": "Pseudo Pixel-level Labeling for Images with Evolving Content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Annotating images for semantic segmentation requires intense manual labor and\nis a time-consuming and expensive task especially for domains with a scarcity\nof experts, such as Forensic Anthropology. We leverage the evolving nature of\nimages depicting the decay process in human decomposition data to design a\nsimple yet effective pseudo-pixel-level label generation technique to reduce\nthe amount of effort for manual annotation of such images. We first identify\nsequences of images with a minimum variation that are most suitable to share\nthe same or similar annotation using an unsupervised approach. Given one\nuser-annotated image in each sequence, we propagate the annotation to the\nremaining images in the sequence by merging it with annotations produced by a\nstate-of-the-art CAM-based pseudo label generation technique. To evaluate the\nquality of our pseudo-pixel-level labels, we train two semantic segmentation\nmodels with VGG and ResNet backbones on images labeled using our pseudo\nlabeling method and those of a state-of-the-art method. The results indicate\nthat using our pseudo-labels instead of those generated using the\nstate-of-the-art method in the training process improves the mean-IoU and the\nfrequency-weighted-IoU of the VGG and ResNet-based semantic segmentation models\nby 3.36%, 2.58%, 10.39%, and 12.91% respectively.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 18:14:19 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Mousavi", "Sara", ""], ["Yang", "Zhenning", ""], ["Cross", "Kelley", ""], ["Steadman", "Dawnie", ""], ["Mockus", "Audris", ""]]}, {"id": "2105.09976", "submitter": "Gaia Belardinelli", "authors": "Gaia Belardinelli and Rasmus K. Rendsvig", "title": "Epistemic Planning with Attention as a Bounded Resource", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.MA econ.TH math.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Where information grows abundant, attention becomes a scarce resource. As a\nresult, agents must plan wisely how to allocate their attention in order to\nachieve epistemic efficiency. Here, we present a framework for multi-agent\nepistemic planning with attention, based on Dynamic Epistemic Logic (DEL, a\npowerful formalism for epistemic planning). We identify the framework as a\nfragment of standard DEL, and consider its plan existence problem. While in the\ngeneral case undecidable, we show that when attention is required for learning,\nall instances of the problem are decidable.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 18:14:41 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Belardinelli", "Gaia", ""], ["Rendsvig", "Rasmus K.", ""]]}, {"id": "2105.09983", "submitter": "Malek Mouhoub", "authors": "Wael Korani, Malek Mouhoub and Samira Sadaoui", "title": "Optimizing Neural Network Weights using Nature-Inspired Algorithms", "comments": "15 pages, 5 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This study aims to optimize Deep Feedforward Neural Networks (DFNNs) training\nusing nature-inspired optimization algorithms, such as PSO, MTO, and its\nvariant called MTOCL. We show how these algorithms efficiently update the\nweights of DFNNs when learning from data. We evaluate the performance of DFNN\nfused with optimization algorithms using three Wisconsin breast cancer\ndatasets, Original, Diagnostic, and Prognosis, under different experimental\nscenarios. The empirical analysis demonstrates that MTOCL is the most\nperforming in most scenarios across the three datasets. Also, MTOCL is\ncomparable to past weight optimization algorithms for the original dataset, and\nsuperior for the other datasets, especially for the challenging Prognostic\ndataset.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 18:32:29 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Korani", "Wael", ""], ["Mouhoub", "Malek", ""], ["Sadaoui", "Samira", ""]]}, {"id": "2105.10005", "submitter": "C.-H. Huck Yang", "authors": "C.-H. Huck Yang, Mohit Chhabra, Y.-C. Liu, Quan Kong, Tomoaki\n  Yoshinaga, Tomokazu Murakami", "title": "Robust Unsupervised Multi-Object Tracking in Noisy Environments", "comments": "Accepted to IEEE ICIP 2021", "journal-ref": "2021 IEEE International Conference on Image Processing (ICIP)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.MM cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Physical processes, camera movement, and unpredictable environmental\nconditions like the presence of dust can induce noise and artifacts in video\nfeeds. We observe that popular unsupervised MOT methods are dependent on\nnoise-free inputs. We show that the addition of a small amount of artificial\nrandom noise causes a sharp degradation in model performance on benchmark\nmetrics. We resolve this problem by introducing a robust unsupervised\nmulti-object tracking (MOT) model: AttU-Net. The proposed single-head attention\nmodel helps limit the negative impact of noise by learning visual\nrepresentations at different segment scales. AttU-Net shows better unsupervised\nMOT tracking performance over variational inference-based state-of-the-art\nbaselines. We evaluate our method in the MNIST-MOT and the Atari game video\nbenchmark. We also provide two extended video datasets: ``Kuzushiji-MNIST MOT''\nwhich consists of moving Japanese characters and ``Fashion-MNIST MOT'' to\nvalidate the effectiveness of the MOT models.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 19:38:03 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 14:29:32 GMT"}, {"version": "v3", "created": "Wed, 2 Jun 2021 01:36:22 GMT"}, {"version": "v4", "created": "Tue, 15 Jun 2021 06:52:21 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Yang", "C. -H. Huck", ""], ["Chhabra", "Mohit", ""], ["Liu", "Y. -C.", ""], ["Kong", "Quan", ""], ["Yoshinaga", "Tomoaki", ""], ["Murakami", "Tomokazu", ""]]}, {"id": "2105.10014", "submitter": "Florence Carton", "authors": "Florence Carton, David Filliat, Jaonary Rabarisoa and Quoc Cuong Pham", "title": "Evaluating Robustness over High Level Driving Instruction for Autonomous\n  Driving", "comments": "Accepted to IV21, 32nd IEEE Intelligent Vehicles Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, we have witnessed increasingly high performance in the field\nof autonomous end-to-end driving. In particular, more and more research is\nbeing done on driving in urban environments, where the car has to follow high\nlevel commands to navigate. However, few evaluations are made on the ability of\nthese agents to react in an unexpected situation. Specifically, no evaluations\nare conducted on the robustness of driving agents in the event of a bad\nhigh-level command. We propose here an evaluation method, namely a benchmark\nthat allows to assess the robustness of an agent, and to appreciate its\nunderstanding of the environment through its ability to keep a safe behavior,\nregardless of the instruction.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 20:10:14 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Carton", "Florence", ""], ["Filliat", "David", ""], ["Rabarisoa", "Jaonary", ""], ["Pham", "Quoc Cuong", ""]]}, {"id": "2105.10026", "submitter": "Adyasha Maharana", "authors": "Adyasha Maharana, Darryl Hannan, Mohit Bansal", "title": "Improving Generation and Evaluation of Visual Stories via Semantic\n  Consistency", "comments": "NAACL 2021 (16 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Story visualization is an under-explored task that falls at the intersection\nof many important research directions in both computer vision and natural\nlanguage processing. In this task, given a series of natural language captions\nwhich compose a story, an agent must generate a sequence of images that\ncorrespond to the captions. Prior work has introduced recurrent generative\nmodels which outperform text-to-image synthesis models on this task. However,\nthere is room for improvement of generated images in terms of visual quality,\ncoherence and relevance. We present a number of improvements to prior modeling\napproaches, including (1) the addition of a dual learning framework that\nutilizes video captioning to reinforce the semantic alignment between the story\nand generated images, (2) a copy-transform mechanism for\nsequentially-consistent story visualization, and (3) MART-based transformers to\nmodel complex interactions between frames. We present ablation studies to\ndemonstrate the effect of each of these techniques on the generative power of\nthe model for both individual images as well as the entire narrative.\nFurthermore, due to the complexity and generative nature of the task, standard\nevaluation metrics do not accurately reflect performance. Therefore, we also\nprovide an exploration of evaluation metrics for the model, focused on aspects\nof the generated frames such as the presence/quality of generated characters,\nthe relevance to captions, and the diversity of the generated images. We also\npresent correlation experiments of our proposed automated metrics with human\nevaluations. Code and data available at:\nhttps://github.com/adymaharana/StoryViz\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 20:42:42 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Maharana", "Adyasha", ""], ["Hannan", "Darryl", ""], ["Bansal", "Mohit", ""]]}, {"id": "2105.10037", "submitter": "Dripta S. Raychaudhuri", "authors": "Dripta S. Raychaudhuri, Sujoy Paul, Jeroen van Baar, Amit K.\n  Roy-Chowdhury", "title": "Cross-domain Imitation from Observations", "comments": "Accepted at ICML 2021 as a long presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imitation learning seeks to circumvent the difficulty in designing proper\nreward functions for training agents by utilizing expert behavior. With\nenvironments modeled as Markov Decision Processes (MDP), most of the existing\nimitation algorithms are contingent on the availability of expert\ndemonstrations in the same MDP as the one in which a new imitation policy is to\nbe learned. In this paper, we study the problem of how to imitate tasks when\nthere exist discrepancies between the expert and agent MDP. These discrepancies\nacross domains could include differing dynamics, viewpoint, or morphology; we\npresent a novel framework to learn correspondences across such domains.\nImportantly, in contrast to prior works, we use unpaired and unaligned\ntrajectories containing only states in the expert domain, to learn this\ncorrespondence. We utilize a cycle-consistency constraint on both the state\nspace and a domain agnostic latent space to do this. In addition, we enforce\nconsistency on the temporal position of states via a normalized position\nestimator function, to align the trajectories across the two domains. Once this\ncorrespondence is found, we can directly transfer the demonstrations on one\ndomain to the other and use it for imitation. Experiments across a wide variety\nof challenging domains demonstrate the efficacy of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 21:08:25 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Raychaudhuri", "Dripta S.", ""], ["Paul", "Sujoy", ""], ["van Baar", "Jeroen", ""], ["Roy-Chowdhury", "Amit K.", ""]]}, {"id": "2105.10041", "submitter": "Haihua Chen", "authors": "Haihua Chen, Ngan Tran, Anand Sagar Thumati, Jay Bhuyan, Junhua Ding", "title": "Data Curation and Quality Assurance for Machine Learning-based Cyber\n  Intrusion Detection", "comments": "23 pages, 4 figures, 3 tables, under review at the ACM Journal of\n  Data and Information Quality", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intrusion detection is an essential task in the cyber threat environment.\nMachine learning and deep learning techniques have been applied for intrusion\ndetection. However, most of the existing research focuses on the model work but\nignores the fact that poor data quality has a direct impact on the performance\nof a machine learning system. More attention should be paid to the data work\nwhen building a machine learning-based intrusion detection system. This article\nfirst summarizes existing machine learning-based intrusion detection systems\nand the datasets used for building these systems. Then the data preparation\nworkflow and quality requirements for intrusion detection are discussed. To\nfigure out how data and models affect machine learning performance, we\nconducted experiments on 11 HIDS datasets using seven machine learning models\nand three deep learning models. The experimental results show that BERT and GPT\nwere the best algorithms for HIDS on all of the datasets. However, the\nperformance on different datasets varies, indicating the differences between\nthe data quality of these datasets. We then evaluate the data quality of the 11\ndatasets based on quality dimensions proposed in this paper to determine the\nbest characteristics that a HIDS dataset should possess in order to yield the\nbest possible result. This research initiates a data quality perspective for\nresearchers and practitioners to improve the performance of machine\nlearning-based intrusion detection.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 21:31:46 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Chen", "Haihua", ""], ["Tran", "Ngan", ""], ["Thumati", "Anand Sagar", ""], ["Bhuyan", "Jay", ""], ["Ding", "Junhua", ""]]}, {"id": "2105.10053", "submitter": "James Cheney", "authors": "Sidahmed Benabderrahmane, Ghita Berrada, James Cheney, and Petko\n  Valtchev", "title": "A Rule Mining-Based Advanced Persistent Threats Detection System", "comments": "To appear, IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced persistent threats (APT) are stealthy cyber-attacks that are aimed\nat stealing valuable information from target organizations and tend to extend\nin time. Blocking all APTs is impossible, security experts caution, hence the\nimportance of research on early detection and damage limitation. Whole-system\nprovenance-tracking and provenance trace mining are considered promising as\nthey can help find causal relationships between activities and flag suspicious\nevent sequences as they occur. We introduce an unsupervised method that\nexploits OS-independent features reflecting process activity to detect\nrealistic APT-like attacks from provenance traces. Anomalous processes are\nranked using both frequent and rare event associations learned from traces.\nResults are then presented as implications which, since interpretable, help\nleverage causality in explaining the detected anomalies. When evaluated on\nTransparent Computing program datasets (DARPA), our method outperformed\ncompeting approaches.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 22:13:13 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Benabderrahmane", "Sidahmed", ""], ["Berrada", "Ghita", ""], ["Cheney", "James", ""], ["Valtchev", "Petko", ""]]}, {"id": "2105.10058", "submitter": "Kanvaly Fadiga", "authors": "Kanvaly Fadiga, Etienne Houz\\'e, Ada Diaconescu and Jean-Louis\n  Dessalles", "title": "To do or not to do: finding causal relations in smart homes", "comments": "10 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research in Cognitive Science suggests that humans understand and represent\nknowledge of the world through causal relationships. In addition to\nobservations, they can rely on experimenting and counterfactual reasoning --\ni.e. referring to an alternative course of events -- to identify causal\nrelations and explain atypical situations. Different instances of control\nsystems, such as smart homes, would benefit from having a similar causal model,\nas it would help the user understand the logic of the system and better react\nwhen needed. However, while data-driven methods achieve high levels of\ncorrelation detection, they mainly fall short of finding causal relations,\nnotably being limited to observations only. Notably, they struggle to identify\nthe cause from the effect when detecting a correlation between two variables.\nThis paper introduces a new way to learn causal models from a mixture of\nexperiments on the environment and observational data. The core of our method\nis the use of selected interventions, especially our learning takes into\naccount the variables where it is impossible to intervene, unlike other\napproaches. The causal model we obtain is then used to generate Causal Bayesian\nNetworks, which can be later used to perform diagnostic and predictive\ninference. We use our method on a smart home simulation, a use case where\nknowing causal relations pave the way towards explainable systems. Our\nalgorithm succeeds in generating a Causal Bayesian Network close to the\nsimulation's ground truth causal interactions, showing encouraging prospects\nfor application in real-life systems.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 22:36:04 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Fadiga", "Kanvaly", ""], ["Houz\u00e9", "Etienne", ""], ["Diaconescu", "Ada", ""], ["Dessalles", "Jean-Louis", ""]]}, {"id": "2105.10064", "submitter": "Daniel Halpern", "authors": "Daniel Halpern and Nisarg Shah", "title": "Fair and Efficient Resource Allocation with Partial Information", "comments": "Appears in the Proceedings of IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental problem of allocating indivisible goods to agents\nwith additive preferences. We consider eliciting from each agent only a ranking\nof her $k$ most preferred goods instead of her full cardinal valuations. We\ncharacterize the value of $k$ needed to achieve envy-freeness up to one good\nand approximate maximin share guarantee, two widely studied fairness notions.\nWe also analyze the multiplicative loss in social welfare incurred due to the\nlack of full information with and without the fairness requirements.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 23:19:25 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 15:51:20 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Halpern", "Daniel", ""], ["Shah", "Nisarg", ""]]}, {"id": "2105.10095", "submitter": "Rui Wang", "authors": "Rui Wang, Deyu Zhou, Yuxuan Xiong, Haiping Huang", "title": "Variational Gaussian Topic Model with Invertible Neural Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural topic models have triggered a surge of interest in extracting topics\nfrom text automatically since they avoid the sophisticated derivations in\nconventional topic models. However, scarce neural topic models incorporate the\nword relatedness information captured in word embedding into the modeling\nprocess. To address this issue, we propose a novel topic modeling approach,\ncalled Variational Gaussian Topic Model (VaGTM). Based on the variational\nauto-encoder, the proposed VaGTM models each topic with a multivariate Gaussian\nin decoder to incorporate word relatedness. Furthermore, to address the\nlimitation that pre-trained word embeddings of topic-associated words do not\nfollow a multivariate Gaussian, Variational Gaussian Topic Model with\nInvertible neural Projections (VaGTM-IP) is extended from VaGTM. Three\nbenchmark text corpora are used in experiments to verify the effectiveness of\nVaGTM and VaGTM-IP. The experimental results show that VaGTM and VaGTM-IP\noutperform several competitive baselines and obtain more coherent topics.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 02:23:02 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Wang", "Rui", ""], ["Zhou", "Deyu", ""], ["Xiong", "Yuxuan", ""], ["Huang", "Haiping", ""]]}, {"id": "2105.10104", "submitter": "Lin Xu", "authors": "Leilei Cao, Yao Xiao, and Lin Xu", "title": "EMface: Detecting Hard Faces by Exploring Receptive Field Pyraminds", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scale variation is one of the most challenging problems in face detection.\nModern face detectors employ feature pyramids to deal with scale variation.\nHowever, it might break the feature consistency across different scales of\nfaces. In this paper, we propose a simple yet effective method named the\nreceptive field pyramids (RFP) method to enhance the representation ability of\nfeature pyramids. It can learn different receptive fields in each feature map\nadaptively based on the varying scales of detected faces. Empirical results on\ntwo face detection benchmark datasets, i.e., WIDER FACE and UFDD, demonstrate\nthat our proposed method can accelerate the inference rate significantly while\nachieving state-of-the-art performance. The source code of our method is\navailable at \\url{https://github.com/emdata-ailab/EMface}.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 03:01:37 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Cao", "Leilei", ""], ["Xiao", "Yao", ""], ["Xu", "Lin", ""]]}, {"id": "2105.10112", "submitter": "Lin Xu", "authors": "Zhiyuan Chen, Guang Yao, Wennan Ma, Lin Xu", "title": "IDEAL: Independent Domain Embedding Augmentation Learning", "comments": "11 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Many efforts have been devoted to designing sampling, mining, and weighting\nstrategies in high-level deep metric learning (DML) loss objectives. However,\nlittle attention has been paid to low-level but essential data transformation.\nIn this paper, we develop a novel mechanism, the independent domain embedding\naugmentation learning ({IDEAL}) method. It can simultaneously learn multiple\nindependent embedding spaces for multiple domains generated by predefined data\ntransformations. Our IDEAL is orthogonal to existing DML techniques and can be\nseamlessly combined with prior DML approaches for enhanced performance.\nEmpirical results on visual retrieval tasks demonstrate the superiority of the\nproposed method. For example, the IDEAL improves the performance of MS loss by\na large margin, 84.5\\% $\\rightarrow$ 87.1\\% on Cars-196, and 65.8\\%\n$\\rightarrow$ 69.5\\% on CUB-200 at Recall$@1$. Our IDEAL with MS loss also\nachieves the new state-of-the-art performance on three image retrieval\nbenchmarks, \\ie, \\emph{Cars-196}, \\emph{CUB-200}, and \\emph{SOP}. It\noutperforms the most recent DML approaches, such as Circle loss and XBM,\nsignificantly. The source code and pre-trained models of our method will be\navailable at\\emph{\\url{https://github.com/emdata-ailab/IDEAL}}.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 03:40:24 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Chen", "Zhiyuan", ""], ["Yao", "Guang", ""], ["Ma", "Wennan", ""], ["Xu", "Lin", ""]]}, {"id": "2105.10118", "submitter": "Eric Wang", "authors": "Eric Wang, Pasha Khosravi, Guy Van den Broeck", "title": "Probabilistic Sufficient Explanations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the behavior of learned classifiers is an important task, and\nvarious black-box explanations, logical reasoning approaches, and\nmodel-specific methods have been proposed. In this paper, we introduce\nprobabilistic sufficient explanations, which formulate explaining an instance\nof classification as choosing the \"simplest\" subset of features such that only\nobserving those features is \"sufficient\" to explain the classification. That\nis, sufficient to give us strong probabilistic guarantees that the model will\nbehave similarly when all features are observed under the data distribution. In\naddition, we leverage tractable probabilistic reasoning tools such as\nprobabilistic circuits and expected predictions to design a scalable algorithm\nfor finding the desired explanations while keeping the guarantees intact. Our\nexperiments demonstrate the effectiveness of our algorithm in finding\nsufficient explanations, and showcase its advantages compared to Anchors and\nlogical explanations.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 04:03:10 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Wang", "Eric", ""], ["Khosravi", "Pasha", ""], ["Broeck", "Guy Van den", ""]]}, {"id": "2105.10131", "submitter": "Koji Mineshima", "authors": "Yuri Sato, Koji Mineshima, Kazuhiro Ueda", "title": "Visual representation of negation: Real world data analysis on comic\n  image design", "comments": "To appear in Proceedings of the 43rd Annual Conference of the\n  Cognitive Science Society (CogSci 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  There has been a widely held view that visual representations (e.g.,\nphotographs and illustrations) do not depict negation, for example, one that\ncan be expressed by a sentence \"the train is not coming\". This view is\nempirically challenged by analyzing the real-world visual representations of\ncomic (manga) illustrations. In the experiment using image captioning tasks, we\ngave people comic illustrations and asked them to explain what they could read\nfrom them. The collected data showed that some comic illustrations could depict\nnegation without any aid of sequences (multiple panels) or conventional devices\n(special symbols). This type of comic illustrations was subjected to further\nexperiments, classifying images into those containing negation and those not\ncontaining negation. While this image classification was easy for humans, it\nwas difficult for data-driven machines, i.e., deep learning models (CNN), to\nachieve the same high performance. Given the findings, we argue that some comic\nillustrations evoke background knowledge and thus can depict negation with\npurely visual elements.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 04:57:43 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Sato", "Yuri", ""], ["Mineshima", "Koji", ""], ["Ueda", "Kazuhiro", ""]]}, {"id": "2105.10158", "submitter": "Chenhao Xie", "authors": "Chenhao Xie, Jiaqing Liang, Jingping Liu, Chengsong Huang, Wenhao\n  Huang, Yanghua Xiao", "title": "Revisiting the Negative Data of Distantly Supervised Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Distantly supervision automatically generates plenty of training samples for\nrelation extraction. However, it also incurs two major problems: noisy labels\nand imbalanced training data. Previous works focus more on reducing wrongly\nlabeled relations (false positives) while few explore the missing relations\nthat are caused by incompleteness of knowledge base (false negatives).\nFurthermore, the quantity of negative labels overwhelmingly surpasses the\npositive ones in previous problem formulations. In this paper, we first provide\na thorough analysis of the above challenges caused by negative data. Next, we\nformulate the problem of relation extraction into as a positive unlabeled\nlearning task to alleviate false negative problem. Thirdly, we propose a\npipeline approach, dubbed \\textsc{ReRe}, that performs sentence-level relation\ndetection then subject/object extraction to achieve sample-efficient training.\nExperimental results show that the proposed method consistently outperforms\nexisting approaches and remains excellent performance even learned with a large\nquantity of false positive samples.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 06:44:19 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Xie", "Chenhao", ""], ["Liang", "Jiaqing", ""], ["Liu", "Jingping", ""], ["Huang", "Chengsong", ""], ["Huang", "Wenhao", ""], ["Xiao", "Yanghua", ""]]}, {"id": "2105.10176", "submitter": "Josef Bajada", "authors": "Josef Bajada, Maria Fox and Derek Long", "title": "Efficient Temporal Piecewise-Linear Numeric Planning with Lazy\n  Consistency Checking", "comments": "Submitted to IEEE Transactions on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art temporal planners that support continuous numeric effects\ntypically interweave search with scheduling to ensure temporal consistency. If\nsuch effects are linear, this process often makes use of Linear Programming\n(LP) to model the relationship between temporal constraints and conditions on\nnumeric fluents that are subject to duration-dependent effects. While very\neffective on benchmark domains, this approach does not scale well when solving\nreal-world problems that require long plans. We propose a set of techniques\nthat allow the planner to compute LP consistency checks lazily where possible,\nsignificantly reducing the computation time required, thus allowing the planner\nto solve larger problem instances within an acceptable time-frame. We also\npropose an algorithm to perform duration-dependent goal checking more\nselectively. Furthermore, we propose an LP formulation with a smaller footprint\nthat removes linearity restrictions on discrete effects applied within segments\nof the plan where a numeric fluent is not duration dependent. The effectiveness\nof these techniques is demonstrated on domains that use a mix of discrete and\ncontinuous effects, which is typical of real-world planning problems. The\nresultant planner is not only more efficient, but outperforms most\nstate-of-the-art temporal-numeric and hybrid planners, in terms of both\ncoverage and scalability.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 07:36:54 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Bajada", "Josef", ""], ["Fox", "Maria", ""], ["Long", "Derek", ""]]}, {"id": "2105.10197", "submitter": "Lukas Heppe", "authors": "Katharina Morik and Helena Kotthaus and Lukas Heppe and Danny Heinrich\n  and Raphael Fischer and Sascha M\\\"ucke and Andreas Pauly and Matthias Jakobs\n  and Nico Piatkowski", "title": "Yes We Care! -- Certification for Machine Learning Methods through the\n  Care Label Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applications have become ubiquitous. Their applications from\nmachine embedded control in production over process optimization in diverse\nareas (e.g., traffic, finance, sciences) to direct user interactions like\nadvertising and recommendations. This has led to an increased effort of making\nmachine learning trustworthy. Explainable and fair AI have already matured.\nThey address knowledgeable users and application engineers. However, there are\nusers that want to deploy a learned model in a similar way as their washing\nmachine. These stakeholders do not want to spend time understanding the model.\nInstead, they want to rely on guaranteed properties. What are the relevant\nproperties? How can they be expressed to stakeholders without presupposing\nmachine learning knowledge? How can they be guaranteed for a certain\nimplementation of a model? These questions move far beyond the current\nstate-of-the-art and we want to address them here. We propose a unified\nframework that certifies learning methods via care labels. They are easy to\nunderstand and draw inspiration from well-known certificates like textile\nlabels or property cards of electronic devices. Our framework considers both,\nthe machine learning theory and a given implementation. We test the\nimplementation's compliance with theoretical properties and bounds. In this\npaper, we illustrate care labels by a prototype implementation of a\ncertification suite for a selection of probabilistic graphical models.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 08:15:21 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Morik", "Katharina", ""], ["Kotthaus", "Helena", ""], ["Heppe", "Lukas", ""], ["Heinrich", "Danny", ""], ["Fischer", "Raphael", ""], ["M\u00fccke", "Sascha", ""], ["Pauly", "Andreas", ""], ["Jakobs", "Matthias", ""], ["Piatkowski", "Nico", ""]]}, {"id": "2105.10211", "submitter": "Won Joon Yun", "authors": "Won Joon Yun, Sungwon Yi, and Joongheon Kim", "title": "Multi-Agent Deep Reinforcement Learning using Attentive Graph Neural\n  Architectures for Real-Time Strategy Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In real-time strategy (RTS) game artificial intelligence research, various\nmulti-agent deep reinforcement learning (MADRL) algorithms are widely and\nactively used nowadays. Most of the research is based on StarCraft II\nenvironment because it is the most well-known RTS games in world-wide. In our\nproposed MADRL-based algorithm, distributed MADRL is fundamentally used that is\ncalled QMIX. In addition to QMIX-based distributed computation, we consider\nstate categorization which can reduce computational complexity significantly.\nFurthermore, self-attention mechanisms are used for identifying the\nrelationship among agents in the form of graphs. Based on these approaches, we\npropose a categorized state graph attention policy (CSGA-policy). As observed\nin the performance evaluation of our proposed CSGA-policy with the most\nwell-known StarCraft II simulation environment, our proposed algorithm works\nwell in various settings, as expected.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 09:05:25 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Yun", "Won Joon", ""], ["Yi", "Sungwon", ""], ["Kim", "Joongheon", ""]]}, {"id": "2105.10266", "submitter": "Carl-Johan Hoel", "authors": "Carl-Johan Hoel, Krister Wolff, Leo Laine", "title": "Ensemble Quantile Networks: Uncertainty-Aware Reinforcement Learning\n  with Applications in Autonomous Driving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) can be used to create a decision-making agent for\nautonomous driving. However, previous approaches provide only black-box\nsolutions, which do not offer information on how confident the agent is about\nits decisions. An estimate of both the aleatoric and epistemic uncertainty of\nthe agent's decisions is fundamental for real-world applications of autonomous\ndriving. Therefore, this paper introduces the Ensemble Quantile Networks (EQN)\nmethod, which combines distributional RL with an ensemble approach, to obtain a\ncomplete uncertainty estimate. The distribution over returns is estimated by\nlearning its quantile function implicitly, which gives the aleatoric\nuncertainty, whereas an ensemble of agents is trained on bootstrapped data to\nprovide a Bayesian estimation of the epistemic uncertainty. A criterion for\nclassifying which decisions that have an unacceptable uncertainty is also\nintroduced. The results show that the EQN method can balance risk and time\nefficiency in different occluded intersection scenarios, by considering the\nestimated aleatoric uncertainty. Furthermore, it is shown that the trained\nagent can use the epistemic uncertainty information to identify situations that\nthe agent has not been trained for and thereby avoid making unfounded,\npotentially dangerous, decisions outside of the training distribution.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 10:36:16 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Hoel", "Carl-Johan", ""], ["Wolff", "Krister", ""], ["Laine", "Leo", ""]]}, {"id": "2105.10267", "submitter": "Philipp Ennen", "authors": "Philipp Ennen, Yen-Ting Lin, Ali Girayhan Ozbay, Ferdinando Insalata,\n  Maolin Li, Ye Tian, Sepehr Jalali, Da-shan Shiu", "title": "Towards a Universal NLG for Dialogue Systems and Simulators with Future\n  Bridging", "comments": "11 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a dialogue system pipeline, a natural language generation (NLG) unit\nconverts the dialogue direction and content to a corresponding natural language\nrealization. A recent trend for dialogue systems is to first pre-train on large\ndatasets and then fine-tune in a supervised manner using datasets annotated\nwith application-specific features. Though novel behaviours can be learned from\ncustom annotation, the required effort severely bounds the quantity of the\ntraining set, and the application-specific nature limits the reuse. In light of\nthe recent success of data-driven approaches, we propose the novel future\nbridging NLG (FBNLG) concept for dialogue systems and simulators. The critical\nstep is for an FBNLG to accept a future user or system utterance to bridge the\npresent context towards. Future bridging enables self supervised training over\nannotation-free datasets, decoupled the training of NLG from the rest of the\nsystem. An FBNLG, pre-trained with massive datasets, is expected to apply in\nclassical or new dialogue scenarios with minimal adaptation effort. We evaluate\na prototype FBNLG to show that future bridging can be a viable approach to a\nuniversal few-shot NLG for task-oriented and chit-chat dialogues.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 10:37:10 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 10:33:55 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Ennen", "Philipp", ""], ["Lin", "Yen-Ting", ""], ["Ozbay", "Ali Girayhan", ""], ["Insalata", "Ferdinando", ""], ["Li", "Maolin", ""], ["Tian", "Ye", ""], ["Jalali", "Sepehr", ""], ["Shiu", "Da-shan", ""]]}, {"id": "2105.10272", "submitter": "Hema Karande", "authors": "Hema Karande, Rahee Walambe, Victor Benjamin, Ketan Kotecha and T. S.\n  Raghu", "title": "Stance Detection with BERT Embeddings for Credibility Analysis of\n  Information on Social Media", "comments": null, "journal-ref": null, "doi": "10.7717/peerj-cs.467", "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The evolution of electronic media is a mixed blessing. Due to the easy\naccess, low cost, and faster reach of the information, people search out and\ndevour news from online social networks. In contrast, the increasing acceptance\nof social media reporting leads to the spread of fake news. This is a minacious\nproblem that causes disputes and endangers societal stability and harmony. Fake\nnews spread has gained attention from researchers due to its vicious nature.\nproliferation of misinformation in all media, from the internet to cable news,\npaid advertising and local news outlets, has made it essential for people to\nidentify the misinformation and sort through the facts. Researchers are trying\nto analyze the credibility of information and curtail false information on such\nplatforms. Credibility is the believability of the piece of information at\nhand. Analyzing the credibility of fake news is challenging due to the intent\nof its creation and the polychromatic nature of the news. In this work, we\npropose a model for detecting fake news. Our method investigates the content of\nthe news at the early stage i.e. when the news is published but is yet to be\ndisseminated through social media. Our work interprets the content with\nautomatic feature extraction and the relevance of the text pieces. In summary,\nwe introduce stance as one of the features along with the content of the\narticle and employ the pre-trained contextualized word embeddings BERT to\nobtain the state-of-art results for fake news detection. The experiment\nconducted on the real-world dataset indicates that our model outperforms the\nprevious work and enables fake news detection with an accuracy of 95.32%.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 10:46:43 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Karande", "Hema", ""], ["Walambe", "Rahee", ""], ["Benjamin", "Victor", ""], ["Kotecha", "Ketan", ""], ["Raghu", "T. S.", ""]]}, {"id": "2105.10278", "submitter": "Yacine Izza", "authors": "Yacine Izza and Joao Marques-Silva", "title": "On Explaining Random Forests with SAT", "comments": "8 pages, 1 figure, 1 table, IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Random Forest (RFs) are among the most widely used Machine Learning (ML)\nclassifiers. Even though RFs are not interpretable, there are no dedicated\nnon-heuristic approaches for computing explanations of RFs. Moreover, there is\nrecent work on polynomial algorithms for explaining ML models, including naive\nBayes classifiers. Hence, one question is whether finding explanations of RFs\ncan be solved in polynomial time. This paper answers this question negatively,\nby proving that computing one PI-explanation of an RF is D^P-complete.\nFurthermore, the paper proposes a propositional encoding for computing\nexplanations of RFs, thus enabling finding PI-explanations with a SAT solver.\nThis contrasts with earlier work on explaining boosted trees (BTs) and neural\nnetworks (NNs), which requires encodings based on SMT/MILP. Experimental\nresults, obtained on a wide range of publicly available datasets, demontrate\nthat the proposed SAT-based approach scales to RFs of sizes common in practical\napplications. Perhaps more importantly, the experimental results demonstrate\nthat, for the vast majority of examples considered, the SAT-based approach\nproposed in this paper significantly outperforms existing heuristic approaches.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 11:05:14 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Izza", "Yacine", ""], ["Marques-Silva", "Joao", ""]]}, {"id": "2105.10288", "submitter": "Mustafa Ayazoglu", "authors": "Mustafa Ayazoglu", "title": "Extremely Lightweight Quantization Robust Real-Time Single-Image Super\n  Resolution for Mobile Devices", "comments": null, "journal-ref": "IEEE Computer Vision Pattern Recognition Workshops (Mobile AI 2021\n  Workshop)", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Single-Image Super Resolution (SISR) is a classical computer vision problem\nand it has been studied for over decades. With the recent success of deep\nlearning methods, recent work on SISR focuses solutions with deep learning\nmethodologies and achieves state-of-the-art results. However most of the\nstate-of-the-art SISR methods contain millions of parameters and layers, which\nlimits their practical applications. In this paper, we propose a hardware\n(Synaptics Dolphin NPU) limitation aware, extremely lightweight quantization\nrobust real-time super resolution network (XLSR). The proposed model's building\nblock is inspired from root modules for Image classification. We successfully\napplied root modules to SISR problem, further more to make the model uint8\nquantization robust we used Clipped ReLU at the last layer of the network and\nachieved great balance between reconstruction quality and runtime. Furthermore,\nalthough the proposed network contains 30x fewer parameters than VDSR its\nperformance surpasses it on Div2K validation set. The network proved itself by\nwinning Mobile AI 2021 Real-Time Single Image Super Resolution Challenge.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 11:29:48 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Ayazoglu", "Mustafa", ""]]}, {"id": "2105.10311", "submitter": "Junyi Li", "authors": "Junyi Li, Tianyi Tang, Wayne Xin Zhao and Ji-Rong Wen", "title": "Pretrained Language Models for Text Generation: A Survey", "comments": "Accepted by IJCAI 2021 Survey Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text generation has become one of the most important yet challenging tasks in\nnatural language processing (NLP). The resurgence of deep learning has greatly\nadvanced this field by neural generation models, especially the paradigm of\npretrained language models (PLMs). In this paper, we present an overview of the\nmajor advances achieved in the topic of PLMs for text generation. As the\npreliminaries, we present the general task definition and briefly describe the\nmainstream architectures of PLMs for text generation. As the core content, we\ndiscuss how to adapt existing PLMs to model different input data and satisfy\nspecial properties in the generated text. We further summarize several\nimportant fine-tuning strategies for text generation. Finally, we present\nseveral future directions and conclude this paper. Our survey aims to provide\ntext generation researchers a synthesis and pointer to related research.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 12:27:44 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 01:19:47 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Li", "Junyi", ""], ["Tang", "Tianyi", ""], ["Zhao", "Wayne Xin", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "2105.10317", "submitter": "David Mark Bossens", "authors": "David M. Bossens and Danesh Tarapore", "title": "On the use of feature-maps and parameter control for improved\n  quality-diversity meta-evolution", "comments": "extended version of GECCO'21 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Quality-Diversity (QD) algorithms, which evolve a behaviourally diverse\narchive of high-performing solutions, the behaviour space is a difficult design\nchoice that should be tailored to the target application. In QD meta-evolution,\none evolves a population of QD algorithms to optimise the behaviour space based\non an archive-level objective, the meta-fitness. This paper proposes an\nimproved meta-evolution system such that (i) the database used to rapidly\npopulate new archives is reformulated to prevent loss of quality-diversity;\n(ii) the linear transformation of base-features is generalised to a\nfeature-map, a function of the base-features parametrised by the meta-genotype;\nand (iii) the mutation rate of the QD algorithm and the number of generations\nper meta-generation are controlled dynamically. Experiments on an 8-joint\nplanar robot arm compare feature-maps (linear, non-linear, and\nfeature-selection), parameter control strategies (static, endogenous,\nreinforcement learning, and annealing), and traditional MAP-Elites variants,\nfor a total of 49 experimental conditions. Results reveal that non-linear and\nfeature-selection feature-maps yield a 15-fold and 3-fold improvement in\nmeta-fitness, respectively, over linear feature-maps. Reinforcement learning\nranks among top parameter control methods. Finally, our approach allows the\nrobot arm to recover a reach of over 80% for most damages and at least 60% for\nsevere damages.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 12:43:27 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Bossens", "David M.", ""], ["Tarapore", "Danesh", ""]]}, {"id": "2105.10334", "submitter": "Siru Ouyang", "authors": "Siru Ouyang, Zhuosheng Zhang and Hai Zhao", "title": "Fact-driven Logical Reasoning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logical reasoning, which is closely related to human cognition, is of vital\nimportance in human's understanding of texts. Recent years have witnessed\nincreasing attentions on machine's logical reasoning abilities. However,\nprevious studies commonly apply ad-hoc methods to model pre-defined relation\npatterns, such as linking named entities, which only considers global knowledge\ncomponents that are related to commonsense, without local perception of\ncomplete facts or events. Such methodology is obviously insufficient to deal\nwith complicated logical structures. Therefore, we argue that the natural logic\nunits would be the group of backbone constituents of the sentence such as the\nsubject-verb-object formed \"facts\", covering both global and local knowledge\npieces that are necessary as the basis for logical reasoning. Beyond building\nthe ad-hoc graphs, we propose a more general and convenient fact-driven\napproach to construct a supergraph on top of our newly defined fact units, and\nenhance the supergraph with further explicit guidance of local question and\noption interactions. Experiments on two challenging logical reasoning benchmark\ndatasets, ReClor and LogiQA, show that our proposed model, \\textsc{Focal\nReasoner}, outperforms the baseline models dramatically. It can also be\nsmoothly applied to other downstream tasks such as MuTual, a dialogue reasoning\ndataset, achieving competitive results.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 13:11:13 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Ouyang", "Siru", ""], ["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""]]}, {"id": "2105.10368", "submitter": "Pedro A. Moreno-Sanchez PhD", "authors": "Pedro A. Moreno-Sanchez", "title": "An Explainable Classification Model for Chronic Kidney Disease Patients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, Chronic Kidney Disease (CKD) is experiencing a globally increasing\nincidence and high cost to health systems. A delayed recognition leads to\npremature mortality due to progressive loss of kidney function. The employment\nof data mining to discover subtle patterns in CKD indicators would contribute\nto an early diagnosis. This work develops a classifier model that would support\nhealthcare professionals in the early diagnosis of CKD patients. Through a data\npipeline, an exhaustive search is performed to find the best data mining\nclassifier with different parameters of the data preparation's sub-stages like\ndata missing or feature selection. Therefore, Extra Trees is selected as the\nbest classifier with a 100% and 99% of accuracy with, respectively,\ncross-validation technique and with new unseen data. Moreover, the 8 features\nselected are employed to assess the explainability of the model's results\ndenoting which features are more relevant in the model's output.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 14:09:43 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Moreno-Sanchez", "Pedro A.", ""]]}, {"id": "2105.10369", "submitter": "Ziyuan Zhao", "authors": "Shumeng Li, Ziyuan Zhao, Kaixin Xu, Zeng Zeng, Cuntai Guan", "title": "Hierarchical Consistency Regularized Mean Teacher for Semi-supervised 3D\n  Left Atrium Segmentation", "comments": "Submitted to EMBC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has achieved promising segmentation performance on 3D left\natrium MR images. However, annotations for segmentation tasks are expensive,\ncostly and difficult to obtain. In this paper, we introduce a novel\nhierarchical consistency regularized mean teacher framework for 3D left atrium\nsegmentation. In each iteration, the student model is optimized by multi-scale\ndeep supervision and hierarchical consistency regularization, concurrently.\nExtensive experiments have shown that our method achieves competitive\nperformance as compared with full annotation, outperforming other\nstateof-the-art semi-supervised segmentation methods.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 14:15:45 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Li", "Shumeng", ""], ["Zhao", "Ziyuan", ""], ["Xu", "Kaixin", ""], ["Zeng", "Zeng", ""], ["Guan", "Cuntai", ""]]}, {"id": "2105.10377", "submitter": "Andrea Apicella", "authors": "Andrea Apicella, Francesco Isgr\\`o, Andrea Pollastro, Roberto Prevete", "title": "Dynamic Filters in Graph Convolutional Neural Networks", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last few years, we have seen increasing data generated from\nnon-Euclidean domains, which are usually represented as graphs with complex\nrelationships, and Graph Neural Networks (GNN) have gained a high interest\nbecause of their potential in processing graph-structured data. In particular,\nthere is a strong interest in exploring the possibilities in performing\nconvolution on graphs using an extension of the GNN architecture, generally\nreferred to as Graph Convolutional Neural Networks (GCNN). Convolution on\ngraphs has been achieved mainly in two forms: spectral and spatial\nconvolutions. Due to the higher flexibility in exploring and exploiting the\ngraph structure of data, recently, there is an increasing interest in\ninvestigating the possibilities that the spatial approach can offer. The idea\nof finding a way to adapt the network behaviour to the inputs they process to\nmaximize the total performances has aroused much interest in the neural\nnetworks literature over the years. This paper presents a novel method to adapt\nthe behaviour of a GCNN to the input proposing two ways to perform spatial\nconvolution on graphs using input-based filters which are dynamically\ngenerated. Our model also investigates the problem of discovering and refining\nrelations among nodes. The experimental assessment confirms the capabilities of\nthe proposed approach, which achieves satisfying results using simple\narchitectures with a low number of filters.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 14:36:39 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 07:39:31 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Apicella", "Andrea", ""], ["Isgr\u00f2", "Francesco", ""], ["Pollastro", "Andrea", ""], ["Prevete", "Roberto", ""]]}, {"id": "2105.10381", "submitter": "Eric Gaussier", "authors": "Karim Assaad, Emilie Devijver, Eric Gaussier, Ali Ait-Bachir", "title": "Entropy-based Discovery of Summary Causal Graphs in Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address in this study the problem of learning a summary causal graph on\ntime series with potentially different sampling rates. To do so, we first\npropose a new temporal mutual information measure defined on a window-based\nrepresentation of time series. We then show how this measure relates to an\nentropy reduction principle that can be seen as a special case of the\nProbabilistic Raising Principle. We finally combine these two ingredients in a\nPC-like algorithm to construct the summary causal graph. This algorithm is\nevaluated on several datasets that shows both its efficacy and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 14:47:18 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Assaad", "Karim", ""], ["Devijver", "Emilie", ""], ["Gaussier", "Eric", ""], ["Ait-Bachir", "Ali", ""]]}, {"id": "2105.10441", "submitter": "Timur Bagautdinov", "authors": "Timur Bagautdinov, Chenglei Wu, Tomas Simon, Fabian Prada, Takaaki\n  Shiratori, Shih-En Wei, Weipeng Xu, Yaser Sheikh, Jason Saragih", "title": "Driving-Signal Aware Full-Body Avatars", "comments": null, "journal-ref": null, "doi": "10.1145/3450626.3459850", "report-no": null, "categories": "cs.CV cs.AI cs.GR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a learning-based method for building driving-signal aware\nfull-body avatars. Our model is a conditional variational autoencoder that can\nbe animated with incomplete driving signals, such as human pose and facial\nkeypoints, and produces a high-quality representation of human geometry and\nview-dependent appearance. The core intuition behind our method is that better\ndrivability and generalization can be achieved by disentangling the driving\nsignals and remaining generative factors, which are not available during\nanimation. To this end, we explicitly account for information deficiency in the\ndriving signal by introducing a latent space that exclusively captures the\nremaining information, thus enabling the imputation of the missing factors\nrequired during full-body animation, while remaining faithful to the driving\nsignal. We also propose a learnable localized compression for the driving\nsignal which promotes better generalization, and helps minimize the influence\nof global chance-correlations often found in real datasets. For a given driving\nsignal, the resulting variational model produces a compact space of uncertainty\nfor missing factors that allows for an imputation strategy best suited to a\nparticular application. We demonstrate the efficacy of our approach on the\nchallenging problem of full-body animation for virtual telepresence with\ndriving signals acquired from minimal sensors placed in the environment and\nmounted on a VR-headset.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 16:22:38 GMT"}, {"version": "v2", "created": "Fri, 25 Jun 2021 18:30:39 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Bagautdinov", "Timur", ""], ["Wu", "Chenglei", ""], ["Simon", "Tomas", ""], ["Prada", "Fabian", ""], ["Shiratori", "Takaaki", ""], ["Wei", "Shih-En", ""], ["Xu", "Weipeng", ""], ["Sheikh", "Yaser", ""], ["Saragih", "Jason", ""]]}, {"id": "2105.10448", "submitter": "Ricardo Real", "authors": "Ric Real, James Gopsill, David Jones, Chris Snider, Ben Hicks", "title": "Distinguishing artefacts: evaluating the saturation point of\n  convolutional neural networks", "comments": "6 Pages, 5 Figures, 2 Tables, Conference, Design Engineering, CNN,\n  Digital Twin", "journal-ref": "January 2021 Procedia CIRP 100:385-390", "doi": "10.1016/j.procir.2021.05.089", "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Prior work has shown Convolutional Neural Networks (CNNs) trained on\nsurrogate Computer Aided Design (CAD) models are able to detect and classify\nreal-world artefacts from photographs. The applications of which support\ntwinning of digital and physical assets in design, including rapid extraction\nof part geometry from model repositories, information search \\& retrieval and\nidentifying components in the field for maintenance, repair, and recording. The\nperformance of CNNs in classification tasks have been shown dependent on\ntraining data set size and number of classes. Where prior works have used\nrelatively small surrogate model data sets ($<100$ models), the question\nremains as to the ability of a CNN to differentiate between models in\nincreasingly large model repositories. This paper presents a method for\ngenerating synthetic image data sets from online CAD model repositories, and\nfurther investigates the capacity of an off-the-shelf CNN architecture trained\non synthetic data to classify models as class size increases. 1,000 CAD models\nwere curated and processed to generate large scale surrogate data sets,\nfeaturing model coverage at steps of 10$^{\\circ}$, 30$^{\\circ}$, 60$^{\\circ}$,\nand 120$^{\\circ}$ degrees. The findings demonstrate the capability of computer\nvision algorithms to classify artefacts in model repositories of up to 200,\nbeyond this point the CNN's performance is observed to deteriorate\nsignificantly, limiting its present ability for automated twinning of physical\nto digital artefacts. Although, a match is more often found in the top-5\nresults showing potential for information search and retrieval on large\nrepositories of surrogate models.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 16:33:20 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Real", "Ric", ""], ["Gopsill", "James", ""], ["Jones", "David", ""], ["Snider", "Chris", ""], ["Hicks", "Ben", ""]]}, {"id": "2105.10457", "submitter": "Aissatou Diallo", "authors": "A\\\"issatou Diallo and Johannes F\\\"urnkranz", "title": "Elliptical Ordinal Embedding", "comments": "14 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ordinal embedding aims at finding a low dimensional representation of objects\nfrom a set of constraints of the form \"item $j$ is closer to item $i$ than item\n$k$\". Typically, each object is mapped onto a point vector in a low dimensional\nmetric space. We argue that mapping to a density instead of a point vector\nprovides some interesting advantages, including an inherent reflection of the\nuncertainty about the representation itself and its relative location in the\nspace. Indeed, in this paper, we propose to embed each object as a Gaussian\ndistribution. We investigate the ability of these embeddings to capture the\nunderlying structure of the data while satisfying the constraints, and explore\nproperties of the representation. Experiments on synthetic and real-world\ndatasets showcase the advantages of our approach. In addition, we illustrate\nthe merit of modelling uncertainty, which enriches the visual perception of the\nmapped objects in the space.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 16:54:53 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 16:45:02 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Diallo", "A\u00efssatou", ""], ["F\u00fcrnkranz", "Johannes", ""]]}, {"id": "2105.10461", "submitter": "Jeffrey Krichmar", "authors": "Jeffrey L. Krichmar", "title": "Edelman's Steps Toward a Conscious Artifact", "comments": "7 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In 2006, during a meeting of a working group of scientists in La Jolla,\nCalifornia at The Neurosciences Institute (NSI), Gerald Edelman described a\nroadmap towards the creation of a Conscious Artifact. As far as I know, this\nroadmap was not published. However, it did shape my thinking and that of many\nothers in the years since that meeting. This short paper, which is based on my\nnotes taken during the meeting, describes the key steps in this roadmap. I\nbelieve it is as groundbreaking today as it was more than 15 years ago.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 00:13:06 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 03:18:50 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Krichmar", "Jeffrey L.", ""]]}, {"id": "2105.10488", "submitter": "Stephen Bonner", "authors": "Stephen Bonner and Ian P Barrett and Cheng Ye and Rowan Swiers and Ola\n  Engkvist and Charles Tapley Hoyt and William L Hamilton", "title": "Understanding the Performance of Knowledge Graph Embeddings in Drug\n  Discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.BM cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Knowledge Graphs (KG) and associated Knowledge Graph Embedding (KGE) models\nhave recently begun to be explored in the context of drug discovery and have\nthe potential to assist in key challenges such as target identification. In the\ndrug discovery domain, KGs can be employed as part of a process which can\nresult in lab-based experiments being performed, or impact on other decisions,\nincurring significant time and financial costs and most importantly, ultimately\ninfluencing patient healthcare. For KGE models to have impact in this domain, a\nbetter understanding of not only of performance, but also the various factors\nwhich determine it, is required.\n  In this study we investigate, over the course of many thousands of\nexperiments, the predictive performance of five KGE models on two public drug\ndiscovery-oriented KGs. Our goal is not to focus on the best overall model or\nconfiguration, instead we take a deeper look at how performance can be affected\nby changes in the training setup, choice of hyperparameters, model parameter\ninitialisation seed and different splits of the datasets. Our results highlight\nthat these factors have significant impact on performance and can even affect\nthe ranking of models. Indeed these factors should be reported along with model\narchitectures to ensure complete reproducibility and fair comparisons of future\nwork, and we argue this is critical for the acceptance of use, and impact of\nKGEs in a biomedical setting. To aid reproducibility of our own work, we\nrelease all experimentation code.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 11:39:54 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 09:50:05 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Bonner", "Stephen", ""], ["Barrett", "Ian P", ""], ["Ye", "Cheng", ""], ["Swiers", "Rowan", ""], ["Engkvist", "Ola", ""], ["Hoyt", "Charles Tapley", ""], ["Hamilton", "William L", ""]]}, {"id": "2105.10497", "submitter": "Salman Khan Dr.", "authors": "Muzammal Naseer, Kanchana Ranasinghe, Salman Khan, Munawar Hayat,\n  Fahad Shahbaz Khan, Ming-Hsuan Yang", "title": "Intriguing Properties of Vision Transformers", "comments": "Code: https://git.io/Js15X", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision transformers (ViT) have demonstrated impressive performance across\nvarious machine vision problems. These models are based on multi-head\nself-attention mechanisms that can flexibly attend to a sequence of image\npatches to encode contextual cues. An important question is how such\nflexibility in attending image-wide context conditioned on a given patch can\nfacilitate handling nuisances in natural images e.g., severe occlusions, domain\nshifts, spatial permutations, adversarial and natural perturbations. We\nsystematically study this question via an extensive set of experiments\nencompassing three ViT families and comparisons with a high-performing\nconvolutional neural network (CNN). We show and analyze the following\nintriguing properties of ViT: (a) Transformers are highly robust to severe\nocclusions, perturbations and domain shifts, e.g., retain as high as 60% top-1\naccuracy on ImageNet even after randomly occluding 80% of the image content.\n(b) The robust performance to occlusions is not due to a bias towards local\ntextures, and ViTs are significantly less biased towards textures compared to\nCNNs. When properly trained to encode shape-based features, ViTs demonstrate\nshape recognition capability comparable to that of human visual system,\npreviously unmatched in the literature. (c) Using ViTs to encode shape\nrepresentation leads to an interesting consequence of accurate semantic\nsegmentation without pixel-level supervision. (d) Off-the-shelf features from a\nsingle ViT model can be combined to create a feature ensemble, leading to high\naccuracy rates across a range of classification datasets in both traditional\nand few-shot learning paradigms. We show effective features of ViTs are due to\nflexible and dynamic receptive fields possible via the self-attention\nmechanism.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 17:59:18 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 13:21:50 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Naseer", "Muzammal", ""], ["Ranasinghe", "Kanchana", ""], ["Khan", "Salman", ""], ["Hayat", "Munawar", ""], ["Khan", "Fahad Shahbaz", ""], ["Yang", "Ming-Hsuan", ""]]}, {"id": "2105.10541", "submitter": "Anna Kononova", "authors": "Anna V. Kononova, Ofer M. Shir, Teus Tukker, Pierluigi Frisco, Shutong\n  Zeng, Thomas B\\\"ack", "title": "Addressing the Multiplicity of Solutions in Optical Lens Design as a\n  Niching Evolutionary Algorithms Computational Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Optimal Lens Design constitutes a fundamental, long-standing real-world\noptimization challenge. Potentially large number of optima, rich variety of\ncritical points, as well as solid understanding of certain optimal designs per\nsimple problem instances, provide altogether the motivation to address it as a\nniching challenge. This study applies established Niching-CMA-ES heuristic to\ntackle this design problem (6-dimensional Cooke triplet) in a simulation-based\nfashion. The outcome of employing Niching-CMA-ES `out-of-the-box' proves\nsuccessful, and yet it performs best when assisted by a local searcher which\naccurately drives the search into optima. The obtained search-points are\ncorroborated based upon concrete knowledge of this problem-instance,\naccompanied by gradient and Hessian calculations for validation. We extensively\nreport on this computational campaign, which overall resulted in (i) the\nlocation of 19 out of 21 known minima within a single run, (ii) the discovery\nof 540 new optima. These are new minima similar in shape to 21 theoretical\nsolutions, but some of them have better merit function value (unknown\nheretofore), (iii) the identification of numerous infeasibility pockets\nthroughout the domain (also unknown heretofore). We conclude that niching\nmechanism is well-suited to address this problem domain, and hypothesize on the\napparent multidimensional structures formed by the attained new solutions.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 19:10:54 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Kononova", "Anna V.", ""], ["Shir", "Ofer M.", ""], ["Tukker", "Teus", ""], ["Frisco", "Pierluigi", ""], ["Zeng", "Shutong", ""], ["B\u00e4ck", "Thomas", ""]]}, {"id": "2105.10552", "submitter": "Rene Warren", "authors": "Eric Chen, Justin Chu, Jessica Zhang, Rene L. Warren, Inanc Birol", "title": "GapPredict: A Language Model for Resolving Gaps in Draft Genome\n  Assemblies", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Short-read DNA sequencing instruments can yield over 1e+12 bases per run,\ntypically composed of reads 150 bases long. Despite this high throughput, de\nnovo assembly algorithms have difficulty reconstructing contiguous genome\nsequences using short reads due to both repetitive and difficult-to-sequence\nregions in these genomes. Some of the short read assembly challenges are\nmitigated by scaffolding assembled sequences using paired-end reads. However,\nunresolved sequences in these scaffolds appear as \"gaps\". Here, we introduce\nGapPredict, a tool that uses a character-level language model to predict\nunresolved nucleotides in scaffold gaps. We benchmarked GapPredict against the\nstate-of-the-art gap-filling tool Sealer, and observed that the former can fill\n65.6% of the sampled gaps that were left unfilled by the latter, demonstrating\nthe practical utility of deep learning approaches to the gap-filling problem in\ngenome sequence assembly.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 19:54:41 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 00:55:42 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Chen", "Eric", ""], ["Chu", "Justin", ""], ["Zhang", "Jessica", ""], ["Warren", "Rene L.", ""], ["Birol", "Inanc", ""]]}, {"id": "2105.10577", "submitter": "Zack Dulberg", "authors": "Zack Dulberg, Taylor Webb, Jonathan Cohen", "title": "Modelling the development of counting with memory-augmented neural\n  networks", "comments": "Accepted talk at Proceedings of the 42nd Annual Meeting of the\n  Cognitive Science Society", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning to count is an important example of the broader human capacity for\nsystematic generalization, and the development of counting is often\ncharacterized by an inflection point when children rapidly acquire proficiency\nwith the procedures that support this ability. We aimed to model this process\nby training a reinforcement learning agent to select N items from a binary\nvector when instructed (known as the give-$N$ task). We found that a\nmemory-augmented modular network architecture based on the recently proposed\nEmergent Symbol Binding Network (ESBN) exhibited an inflection during learning\nthat resembled human development. This model was also capable of systematic\nextrapolation outside the range of its training set - for example, trained only\nto select between 1 and 10 items, it could succeed at selecting 11 to 15 items\nas long as it could make use of an arbitrary count sequence of at least that\nlength. The close parallels to child development and the capacity for\nextrapolation suggest that our model could shed light on the emergence of\nsystematicity in humans.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 21:17:06 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Dulberg", "Zack", ""], ["Webb", "Taylor", ""], ["Cohen", "Jonathan", ""]]}, {"id": "2105.10585", "submitter": "Phil Long", "authors": "Philip M. Long", "title": "Properties of the After Kernel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Neural Tangent Kernel (NTK) is the wide-network limit of a kernel defined\nusing neural networks at initialization, whose embedding is the gradient of the\noutput of the network with respect to its parameters. We study the \"after\nkernel\", which is defined using the same embedding, except after training, for\nneural networks with standard architectures, on binary classification problems\nextracted from MNIST and CIFAR-10, trained using SGD in a standard way. For\nsome dataset-architecture pairs, after a few epochs of neural network training,\na hard-margin SVM using the network's after kernel is much more accurate than\nwhen the network's initial kernel is used. For networks with an architecture\nsimilar to VGG, the after kernel is more \"global\", in the sense that it is less\ninvariant to transformations of input images that disrupt the global structure\nof the image while leaving the local statistics largely intact. For fully\nconnected networks, the after kernel is less global in this sense. The after\nkernel tends to be more invariant to small shifts, rotations and zooms; data\naugmentation does not improve these invariances. The (finite approximation to\nthe) conjugate kernel, obtained using the last layer of hidden nodes,\nsometimes, but not always, provides a good approximation to the NTK and the\nafter kernel.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 21:50:18 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 21:39:21 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Long", "Philip M.", ""]]}, {"id": "2105.10587", "submitter": "Michael Tashman", "authors": "Michael Tashman, John Hoffman, Jiayi Xie, Fengdan Ye, Atefeh Morsali,\n  Lee Winikor, Rouzbeh Gerami", "title": "Techniques Toward Optimizing Viewability in RTB Ad Campaigns Using\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is an effective technique for training\ndecision-making agents through interactions with their environment. The advent\nof deep learning has been associated with highly notable successes with\nsequential decision making problems - such as defeating some of the\nhighest-ranked human players at Go. In digital advertising, real-time bidding\n(RTB) is a common method of allocating advertising inventory through real-time\nauctions. Bidding strategies need to incorporate logic for dynamically\nadjusting parameters in order to deliver pre-assigned campaign goals. Here we\ndiscuss techniques toward using RL to train bidding agents. As a campaign\nmetric we particularly focused on viewability: the percentage of inventory\nwhich goes on to be viewed by an end user.\n  This paper is presented as a survey of techniques and experiments which we\ndeveloped through the course of this research. We discuss expanding our\ntraining data to include edge cases by training on simulated interactions. We\ndiscuss the experimental results comparing the performance of several promising\nRL algorithms, and an approach to hyperparameter optimization of an\nactor/critic training pipeline through Bayesian optimization. Finally, we\npresent live-traffic tests of some of our RL agents against a rule-based\nfeedback-control approach, demonstrating the potential for this method as well\nas areas for further improvement. This paper therefore presents an arrangement\nof our findings in this quickly developing field, and ways that it can be\napplied to an RTB use case.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 21:56:12 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Tashman", "Michael", ""], ["Hoffman", "John", ""], ["Xie", "Jiayi", ""], ["Ye", "Fengdan", ""], ["Morsali", "Atefeh", ""], ["Winikor", "Lee", ""], ["Gerami", "Rouzbeh", ""]]}, {"id": "2105.10598", "submitter": "Coen Needell", "authors": "Coen D. Needell and Wilma A. Bainbridge", "title": "Embracing New Techniques in Deep Learning for Estimating Image\n  Memorability", "comments": "27 pages, 15 figures, Presented at the Proceedings of the Vision\n  Sciences Society 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Various work has suggested that the memorability of an image is consistent\nacross people, and thus can be treated as an intrinsic property of an image.\nUsing computer vision models, we can make specific predictions about what\npeople will remember or forget. While older work has used now-outdated deep\nlearning architectures to predict image memorability, innovations in the field\nhave given us new techniques to apply to this problem. Here, we propose and\nevaluate five alternative deep learning models which exploit developments in\nthe field from the last five years, largely the introduction of residual neural\nnetworks, which are intended to allow the model to use semantic information in\nthe memorability estimation process. These new models were tested against the\nprior state of the art with a combined dataset built to optimize both\nwithin-category and across-category predictions. Our findings suggest that the\nkey prior memorability network had overstated its generalizability and was\noverfit on its training set. Our new models outperform this prior model,\nleading us to conclude that Residual Networks outperform simpler convolutional\nneural networks in memorability regression. We make our new state-of-the-art\nmodel readily available to the research community, allowing memory researchers\nto make predictions about memorability on a wider range of images.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 23:05:23 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Needell", "Coen D.", ""], ["Bainbridge", "Wilma A.", ""]]}, {"id": "2105.10606", "submitter": "Parag Dakle", "authors": "Parag Pravin Dakle and Dan I. Moldovan", "title": "CEREC: A Corpus for Entity Resolution in Email Conversations", "comments": null, "journal-ref": "Proceedings of the 28th International Conference on Computational\n  Linguistics, pp. 339-349. 2020", "doi": "10.18653/v1/2020.coling-main.30", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present the first large scale corpus for entity resolution in email\nconversations (CEREC). The corpus consists of 6001 email threads from the Enron\nEmail Corpus containing 36,448 email messages and 60,383 entity coreference\nchains. The annotation is carried out as a two-step process with minimal manual\neffort. Experiments are carried out for evaluating different features and\nperformance of four baselines on the created corpus. For the task of mention\nidentification and coreference resolution, a best performance of 59.2 F1 is\nreported, highlighting the room for improvement. An in-depth qualitative and\nquantitative error analysis is presented to understand the limitations of the\nbaselines considered.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 23:40:12 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 03:08:01 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Dakle", "Parag Pravin", ""], ["Moldovan", "Dan I.", ""]]}, {"id": "2105.10686", "submitter": "Baudouin Denis de Senneville PhD", "authors": "Vincent Estrade, Michel Daudon, Emmanuel Richard, Jean-Christophe\n  Bernhard, Franck Bladou, Gregoire Robert, Baudouin Denis de Senneville", "title": "Towards Automatic Recognition of Pure & Mixed Stones using\n  Intraoperative Endoscopic Digital Images", "comments": "19 pages, 3 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Objective: To assess automatic computer-aided in-situ recognition of\nmorphological features of pure and mixed urinary stones using intraoperative\ndigital endoscopic images acquired in a clinical setting. Materials and\nmethods: In this single-centre study, an experienced urologist intraoperatively\nand prospectively examined the surface and section of all kidney stones\nencountered. Calcium oxalate monohydrate (COM/Ia), dihydrate (COD/IIb) and uric\nacid (UA/IIIb) morphological criteria were collected and classified to generate\nannotated datasets. A deep convolutional neural network (CNN) was trained to\npredict the composition of both pure and mixed stones. To explain the\npredictions of the deep neural network model, coarse localisation heat-maps\nwere plotted to pinpoint key areas identified by the network. Results: This\nstudy included 347 and 236 observations of stone surface and stone section,\nrespectively. A highest sensitivity of 98 % was obtained for the type \"pure\nIIIb/UA\" using surface images. The most frequently encountered morphology was\nthat of the type \"pure Ia/COM\"; it was correctly predicted in 91 % and 94 % of\ncases using surface and section images, respectively. Of the mixed type\n\"Ia/COM+IIb/COD\", Ia/COM was predicted in 84 % of cases using surface images,\nIIb/COD in 70 % of cases, and both in 65 % of cases. Concerning mixed\nIa/COM+IIIb/UA stones, Ia/COM was predicted in 91 % of cases using section\nimages, IIIb/UA in 69 % of cases, and both in 74 % of cases. Conclusions: This\npreliminary study demonstrates that deep convolutional neural networks are\npromising to identify kidney stone composition from endoscopic images acquired\nintraoperatively. Both pure and mixed stone composition could be discriminated.\nCollected in a clinical setting, surface and section images analysed by deep\nCNN provide valuable information about stone morphology for computer-aided\ndiagnosis.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 10:52:19 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Estrade", "Vincent", ""], ["Daudon", "Michel", ""], ["Richard", "Emmanuel", ""], ["Bernhard", "Jean-Christophe", ""], ["Bladou", "Franck", ""], ["Robert", "Gregoire", ""], ["de Senneville", "Baudouin Denis", ""]]}, {"id": "2105.10707", "submitter": "Yifan Jia", "authors": "Yifan Jia, Jingyi Wang, Christopher M. Poskitt, Sudipta Chattopadhyay,\n  Jun Sun, Yuqi Chen", "title": "Adversarial Attacks and Mitigation for Anomaly Detectors of\n  Cyber-Physical Systems", "comments": "Accepted by the International Journal of Critical Infrastructure\n  Protection (IJCIP)", "journal-ref": "Int. J. Crit. Infrastructure Prot. 34:100452, 2021", "doi": "10.1016/j.ijcip.2021.100452", "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The threats faced by cyber-physical systems (CPSs) in critical infrastructure\nhave motivated research into a multitude of attack detection mechanisms,\nincluding anomaly detectors based on neural network models. The effectiveness\nof anomaly detectors can be assessed by subjecting them to test suites of\nattacks, but less consideration has been given to adversarial attackers that\ncraft noise specifically designed to deceive them. While successfully applied\nin domains such as images and audio, adversarial attacks are much harder to\nimplement in CPSs due to the presence of other built-in defence mechanisms such\nas rule checkers(or invariant checkers). In this work, we present an\nadversarial attack that simultaneously evades the anomaly detectors and rule\ncheckers of a CPS. Inspired by existing gradient-based approaches, our\nadversarial attack crafts noise over the sensor and actuator values, then uses\na genetic algorithm to optimise the latter, ensuring that the neural network\nand the rule checking system are both deceived.We implemented our approach for\ntwo real-world critical infrastructure testbeds, successfully reducing the\nclassification accuracy of their detectors by over 50% on average, while\nsimultaneously avoiding detection by rule checkers. Finally, we explore whether\nthese attacks can be mitigated by training the detectors on adversarial\nsamples.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 12:19:03 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Jia", "Yifan", ""], ["Wang", "Jingyi", ""], ["Poskitt", "Christopher M.", ""], ["Chattopadhyay", "Sudipta", ""], ["Sun", "Jun", ""], ["Chen", "Yuqi", ""]]}, {"id": "2105.10709", "submitter": "Tirtharaj Dash", "authors": "Tirtharaj Dash, Ashwin Srinivasan, A Baskar", "title": "Inclusion of Domain-Knowledge into GNNs using Mode-Directed Inverse\n  Entailment", "comments": "submitted to Machine Learning Journal (MLJ)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general technique for constructing Graph Neural Networks (GNNs)\ncapable of using multi-relational domain knowledge. The technique is based on\nmode-directed inverse entailment (MDIE) developed in Inductive Logic\nProgramming (ILP). Given a data instance $e$ and background knowledge $B$, MDIE\nidentifies a most-specific logical formula $\\bot_B(e)$ that contains all the\nrelational information in $B$ that is related to $e$. We transform $\\bot_B(e)$\ninto a corresponding \"bottom-graph\" that can be processed for use by standard\nGNN implementations. This transformation allows a principled way of\nincorporating generic background knowledge into GNNs: we use the term `BotGNN'\nfor this form of graph neural networks. For several GNN variants, using\nreal-world datasets with substantial background knowledge, we show that BotGNNs\nperform significantly better than both GNNs without background knowledge and a\nrecently proposed simplified technique for including domain knowledge into\nGNNs. We also provide experimental evidence comparing BotGNNs favourably to\nmulti-layer perceptrons (MLPs) that use features representing a\n\"propositionalised\" form of the background knowledge; and BotGNNs to a standard\nILP based on the use of most-specific clauses. Taken together, these results\npoint to BotGNNs as capable of combining the computational efficacy of GNNs\nwith the representational versatility of ILP.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 12:25:13 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Dash", "Tirtharaj", ""], ["Srinivasan", "Ashwin", ""], ["Baskar", "A", ""]]}, {"id": "2105.10716", "submitter": "Won Joon Yun", "authors": "Won Joon Yun, Byungju Lim, Soyi Jung, Young-Chai Ko, Jihong Park,\n  Joongheon Kim, Mehdi Bennis", "title": "Attention-based Reinforcement Learning for Real-Time UAV Semantic\n  Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, we study the problem of air-to-ground ultra-reliable and\nlow-latency communication (URLLC) for a moving ground user. This is done by\ncontrolling multiple unmanned aerial vehicles (UAVs) in real time while\navoiding inter-UAV collisions. To this end, we propose a novel multi-agent deep\nreinforcement learning (MADRL) framework, coined a graph attention exchange\nnetwork (GAXNet). In GAXNet, each UAV constructs an attention graph locally\nmeasuring the level of attention to its neighboring UAVs, while exchanging the\nattention weights with other UAVs so as to reduce the attention mismatch\nbetween them. Simulation results corroborates that GAXNet achieves up to 4.5x\nhigher rewards during training. At execution, without incurring inter-UAV\ncollisions, GAXNet achieves 6.5x lower latency with the target 0.0000001 error\nrate, compared to a state-of-the-art baseline framework.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 12:43:25 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Yun", "Won Joon", ""], ["Lim", "Byungju", ""], ["Jung", "Soyi", ""], ["Ko", "Young-Chai", ""], ["Park", "Jihong", ""], ["Kim", "Joongheon", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2105.10719", "submitter": "Jie Ren", "authors": "Jie Ren, Zhanpeng Zhou, Qirui Chen, Quanshi Zhang", "title": "Learning Baseline Values for Shapley Values", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to formulate the problem of estimating the optimal baseline\nvalues for the Shapley value in game theory. The Shapley value measures the\nattribution of each input variable of a complex model, which is computed as the\nmarginal benefit from the presence of this variable w.r.t.its absence under\ndifferent contexts. To this end, people usually set the input variable to its\nbaseline value to represent the absence of this variable (i.e.the no-signal\nstate of this variable). Previous studies usually determine the baseline values\nin an empirical manner, which hurts the trustworthiness of the Shapley value.\nIn this paper, we revisit the feature representation of a deep model from the\nperspective of game theory, and define the multi-variate interaction patterns\nof input variables to define the no-signal state of an input variable. Based on\nthe multi-variate interaction, we learn the optimal baseline value of each\ninput variable. Experimental results have demonstrated the effectiveness of our\nmethod.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 13:03:18 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 08:49:00 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Ren", "Jie", ""], ["Zhou", "Zhanpeng", ""], ["Chen", "Qirui", ""], ["Zhang", "Quanshi", ""]]}, {"id": "2105.10735", "submitter": "Mina Khan", "authors": "Mina Khan and Pattie Maes", "title": "PAL: Intelligence Augmentation using Egocentric Visual Context Detection", "comments": null, "journal-ref": "CVPR EPIC Workshop 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Egocentric visual context detection can support intelligence augmentation\napplications. We created a wearable system, called PAL, for wearable,\npersonalized, and privacy-preserving egocentric visual context detection. PAL\nhas a wearable device with a camera, heart-rate sensor, on-device deep\nlearning, and audio input/output. PAL also has a mobile/web application for\npersonalized context labeling. We used on-device deep learning models for\ngeneric object and face detection, low-shot custom face and context recognition\n(e.g., activities like brushing teeth), and custom context clustering (e.g.,\nindoor locations). The models had over 80\\% accuracy in in-the-wild contexts\n(~1000 images) and we tested PAL for intelligence augmentation applications\nlike behavior change. We have made PAL is open-source to further support\nintelligence augmentation using personalized and privacy-preserving egocentric\nvisual contexts.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 14:01:22 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Khan", "Mina", ""], ["Maes", "Pattie", ""]]}, {"id": "2105.10762", "submitter": "Yuchen Jin", "authors": "Yuchen Jin, Tianyi Zhou, Liangyu Zhao, Yibo Zhu, Chuanxiong Guo, Marco\n  Canini, Arvind Krishnamurthy", "title": "AutoLRS: Automatic Learning-Rate Schedule by Bayesian Optimization on\n  the Fly", "comments": "Published as a conference paper at ICLR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The learning rate (LR) schedule is one of the most important hyper-parameters\nneeding careful tuning in training DNNs. However, it is also one of the least\nautomated parts of machine learning systems and usually costs significant\nmanual effort and computing. Though there are pre-defined LR schedules and\noptimizers with adaptive LR, they introduce new hyperparameters that need to be\ntuned separately for different tasks/datasets. In this paper, we consider the\nquestion: Can we automatically tune the LR over the course of training without\nhuman involvement? We propose an efficient method, AutoLRS, which automatically\noptimizes the LR for each training stage by modeling training dynamics. AutoLRS\naims to find an LR applied to every $\\tau$ steps that minimizes the resulted\nvalidation loss. We solve this black-box optimization on the fly by Bayesian\noptimization (BO). However, collecting training instances for BO requires a\nsystem to evaluate each LR queried by BO's acquisition function for $\\tau$\nsteps, which is prohibitively expensive in practice. Instead, we apply each\ncandidate LR for only $\\tau'\\ll\\tau$ steps and train an exponential model to\npredict the validation loss after $\\tau$ steps. This mutual-training process\nbetween BO and the loss-prediction model allows us to limit the training steps\ninvested in the BO search. We demonstrate the advantages and the generality of\nAutoLRS through extensive experiments of training DNNs for tasks from diverse\ndomains using different optimizers. The LR schedules auto-generated by AutoLRS\nlead to a speedup of $1.22\\times$, $1.43\\times$, and $1.5\\times$ when training\nResNet-50, Transformer, and BERT, respectively, compared to the LR schedules in\ntheir original papers, and an average speedup of $1.31\\times$ over\nstate-of-the-art heavily-tuned LR schedules.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 16:41:10 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Jin", "Yuchen", ""], ["Zhou", "Tianyi", ""], ["Zhao", "Liangyu", ""], ["Zhu", "Yibo", ""], ["Guo", "Chuanxiong", ""], ["Canini", "Marco", ""], ["Krishnamurthy", "Arvind", ""]]}, {"id": "2105.10777", "submitter": "Tao Teng", "authors": "Tao Teng, Miguel Fernandes, Matteo Gatti, Stefano Poni, Claudio\n  Semini, Darwin Caldwell, Fei Chen", "title": "Whole-Body Control on Non-holonomic Mobile Manipulation for Grapevine\n  Winter Pruning Automation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobile manipulators that combine mobility and manipulability, are\nincreasingly being used for various unstructured application scenarios in the\nfield, e.g. vineyards. Therefore, the coordinated motion of the mobile base and\nmanipulator is an essential feature of the overall performance. In this paper,\nwe explore a whole-body motion controller of a robot which is composed of a\n2-DoFs non-holonomic wheeled mobile base with a 7-DoFs manipulator\n(non-holonomic wheeled mobile manipulator, NWMM) This robotic platform is\ndesigned to efficiently undertake complex grapevine pruning tasks. In the\ncontrol framework, a task priority coordinated motion of the NWMM is\nguaranteed. Lower-priority tasks are projected into the null space of the\ntop-priority tasks so that higher-priority tasks are completed without\ninterruption from lower-priority tasks. The proposed controller was evaluated\nin a grapevine spur pruning experiment scenario.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 17:41:22 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Teng", "Tao", ""], ["Fernandes", "Miguel", ""], ["Gatti", "Matteo", ""], ["Poni", "Stefano", ""], ["Semini", "Claudio", ""], ["Caldwell", "Darwin", ""], ["Chen", "Fei", ""]]}, {"id": "2105.10799", "submitter": "Gabriele Pisciotta", "authors": "Gabriele Pisciotta, Miriana Somenzi, Elisa Barisani, Giulio Rossetti", "title": "Sockpuppet Detection: a Telegram case study", "comments": null, "journal-ref": "The 9th International Conference on Complex Networks and their\n  Applications - Book of Abstract (2021), pp. 414 (978-2-9557050-4-9)", "doi": "10.5281/zenodo.4744934", "report-no": null, "categories": "cs.SI cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In Online Social Networks (OSN) numerous are the cases in which users create\nmultiple accounts that publicly seem to belong to different people but are\nactually fake identities of the same person. These fictitious characters can be\nexploited to carry out abusive behaviors such as manipulating opinions,\nspreading fake news and disturbing other users. In literature this problem is\nknown as the Sockpuppet problem. In our work we focus on Telegram, a\nwide-spread instant messaging application, often known for its exploitation by\nmembers of organized crime and terrorism, and more in general for its high\npresence of people who have offensive behaviors.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 19:28:10 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Pisciotta", "Gabriele", ""], ["Somenzi", "Miriana", ""], ["Barisani", "Elisa", ""], ["Rossetti", "Giulio", ""]]}, {"id": "2105.10830", "submitter": "Blai Bonet", "authors": "Ivan D. Rodriguez, Blai Bonet, Javier Romero, Hector Geffner", "title": "Learning First-Order Representations for Planning from Black-Box States:\n  New Results", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Bonet and Geffner have shown that first-order representations for\nplanning domains can be learned from the structure of the state space without\nany prior knowledge about the action schemas or domain predicates. For this,\nthe learning problem is formulated as the search for a simplest first-order\ndomain description D that along with information about instances I_i (number of\nobjects and initial state) determine state space graphs G(P_i) that match the\nobserved state graphs G_i where P_i = (D, I_i). The search is cast and solved\napproximately by means of a SAT solver that is called over a large family of\npropositional theories that differ just in the parameters encoding the possible\nnumber of action schemas and domain predicates, their arities, and the number\nof objects. In this work, we push the limits of these learners by moving to an\nanswer set programming (ASP) encoding using the CLINGO system. The new\nencodings are more transparent and concise, extending the range of possible\nmodels while facilitating their exploration. We show that the domains\nintroduced by Bonet and Geffner can be solved more efficiently in the new\napproach, often optimally, and furthermore, that the approach can be easily\nextended to handle partial information about the state graphs as well as noise\nthat prevents some states from being distinguished.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 00:08:42 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Rodriguez", "Ivan D.", ""], ["Bonet", "Blai", ""], ["Romero", "Javier", ""], ["Geffner", "Hector", ""]]}, {"id": "2105.10861", "submitter": "Tung Nguyen Thanh", "authors": "Thanh-Tung Nguyen, Xuan-Phi Nguyen, Shafiq Joty, Xiaoli Li", "title": "RST Parsing from Scratch", "comments": "Accepted to NAACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel top-down end-to-end formulation of document-level\ndiscourse parsing in the Rhetorical Structure Theory (RST) framework. In this\nformulation, we consider discourse parsing as a sequence of splitting decisions\nat token boundaries and use a seq2seq network to model the splitting decisions.\nOur framework facilitates discourse parsing from scratch without requiring\ndiscourse segmentation as a prerequisite; rather, it yields segmentation as\npart of the parsing process. Our unified parsing model adopts a beam search to\ndecode the best tree structure by searching through a space of high-scoring\ntrees. With extensive experiments on the standard English RST discourse\ntreebank, we demonstrate that our parser outperforms existing methods by a good\nmargin in both end-to-end parsing and parsing with gold segmentation. More\nimportantly, it does so without using any handcrafted features, making it\nfaster and easily adaptable to new languages and domains.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 06:19:38 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Nguyen", "Thanh-Tung", ""], ["Nguyen", "Xuan-Phi", ""], ["Joty", "Shafiq", ""], ["Li", "Xiaoli", ""]]}, {"id": "2105.10872", "submitter": "Hao Huang", "authors": "Hao Huang, Yongtao Wang, Zhaoyu Chen, Yuheng Li, Zhi Tang, Wei Chu,\n  Jingdong Chen, Weisi Lin, Kai-Kuang Ma", "title": "CMUA-Watermark: A Cross-Model Universal Adversarial Watermark for\n  Combating Deepfakes", "comments": "9 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Malicious application of deepfakes (i.e., technologies can generate target\nfaces or face attributes) has posed a huge threat to our society. The fake\nmultimedia content generated by deepfake models can harm the reputation and\neven threaten the property of the person who has been impersonated.\nFortunately, the adversarial watermark could be used for combating deepfake\nmodels, leading them to generate distorted images. The existing methods require\nan individual training process for every facial image, to generate the\nadversarial watermark against a specific deepfake model, which are extremely\ninefficient. To address this problem, we propose a universal adversarial attack\nmethod on deepfake models, to generate a Cross-Model Universal Adversarial\nWatermark (CMUA-Watermark) that can protect thousands of facial images from\nmultiple deepfake models. Specifically, we first propose a cross-model\nuniversal attack pipeline by attacking multiple deepfake models and combining\ngradients from these models iteratively. Then we introduce a batch-based method\nto alleviate the conflict of adversarial watermarks generated by different\nfacial images. Finally, we design a more reasonable and comprehensive\nevaluation method for evaluating the effectiveness of the adversarial\nwatermark. Experimental results demonstrate that the proposed CMUA-Watermark\ncan effectively distort the fake facial images generated by deepfake models and\nsuccessfully protect facial images from deepfakes in real scenes.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 07:28:36 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Huang", "Hao", ""], ["Wang", "Yongtao", ""], ["Chen", "Zhaoyu", ""], ["Li", "Yuheng", ""], ["Tang", "Zhi", ""], ["Chu", "Wei", ""], ["Chen", "Jingdong", ""], ["Lin", "Weisi", ""], ["Ma", "Kai-Kuang", ""]]}, {"id": "2105.10902", "submitter": "Ikram Kourbane", "authors": "Ikram Kourbane, Yakup Genc", "title": "A hybrid classification-regression approach for 3D hand pose estimation\n  using graph convolutional networks", "comments": "18 pages, 8 figures, 6 tables, 4 Algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Hand pose estimation is a crucial part of a wide range of augmented reality\nand human-computer interaction applications. Predicting the 3D hand pose from a\nsingle RGB image is challenging due to occlusion and depth ambiguities.\nGCN-based (Graph Convolutional Networks) methods exploit the structural\nrelationship similarity between graphs and hand joints to model kinematic\ndependencies between joints. These techniques use predefined or globally\nlearned joint relationships, which may fail to capture pose-dependent\nconstraints. To address this problem, we propose a two-stage GCN-based\nframework that learns per-pose relationship constraints. Specifically, the\nfirst phase quantizes the 2D/3D space to classify the joints into 2D/3D blocks\nbased on their locality. This spatial dependency information guides this phase\nto estimate reliable 2D and 3D poses. The second stage further improves the 3D\nestimation through a GCN-based module that uses an adaptative nearest neighbor\nalgorithm to determine joint relationships. Extensive experiments show that our\nmulti-stage GCN approach yields an efficient model that produces accurate 2D/3D\nhand poses and outperforms the state-of-the-art on two public datasets.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 10:09:10 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Kourbane", "Ikram", ""], ["Genc", "Yakup", ""]]}, {"id": "2105.10904", "submitter": "Ikram Kourbane", "authors": "Ikram Kourbane, Yakup Genc", "title": "Skeleton-aware multi-scale heatmap regression for 2D hand pose\n  estimation", "comments": "5 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Existing RGB-based 2D hand pose estimation methods learn the joint locations\nfrom a single resolution, which is not suitable for different hand sizes. To\ntackle this problem, we propose a new deep learning-based framework that\nconsists of two main modules. The former presents a segmentation-based approach\nto detect the hand skeleton and localize the hand bounding box. The second\nmodule regresses the 2D joint locations through a multi-scale heatmap\nregression approach that exploits the predicted hand skeleton as a constraint\nto guide the model. Furthermore, we construct a new dataset that is suitable\nfor both hand detection and pose estimation. We qualitatively and\nquantitatively validate our method on two datasets. Results demonstrate that\nthe proposed method outperforms state-of-the-art and can recover the pose even\nin cluttered images and complex poses.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 10:23:51 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Kourbane", "Ikram", ""], ["Genc", "Yakup", ""]]}, {"id": "2105.10907", "submitter": "Unnikrishnan Menon", "authors": "Unnikrishnan Rajendran Menon and Anirudh Rajiv Menon", "title": "An Efficient Application of Neuroevolution for Competitive Multiagent\n  Learning", "comments": "13 pages, 7 figures, 2 tables", "journal-ref": "Transactions on Machine Learning and Artificial Intelligence,\n  9(3), 1-13 (2021)", "doi": "10.14738/tmlai.93.10149", "report-no": "TMLAI-10149", "categories": "cs.AI cs.MA cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multiagent systems provide an ideal environment for the evaluation and\nanalysis of real-world problems using reinforcement learning algorithms. Most\ntraditional approaches to multiagent learning are affected by long training\nperiods as well as high computational complexity. NEAT (NeuroEvolution of\nAugmenting Topologies) is a popular evolutionary strategy used to obtain the\nbest performing neural network architecture often used to tackle optimization\nproblems in the field of artificial intelligence. This paper utilizes the NEAT\nalgorithm to achieve competitive multiagent learning on a modified pong game\nenvironment in an efficient manner. The competing agents abide by different\nrules while having similar observation space parameters. The proposed algorithm\nutilizes this property of the environment to define a singular\nneuroevolutionary procedure that obtains the optimal policy for all the agents.\nThe compiled results indicate that the proposed implementation achieves ideal\nbehaviour in a very short training period when compared to existing multiagent\nreinforcement learning models.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 10:34:48 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Menon", "Unnikrishnan Rajendran", ""], ["Menon", "Anirudh Rajiv", ""]]}, {"id": "2105.10919", "submitter": "Piotr Mi{\\l}o\\'s", "authors": "Maciej Wo{\\l}czyk, Micha{\\l} Zaj\\k{a}c, Razvan Pascanu, {\\L}ukasz\n  Kuci\\'nski, Piotr Mi{\\l}o\\'s", "title": "Continual World: A Robotic Benchmark For Continual Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Continual learning (CL) -- the ability to continuously learn, building on\npreviously acquired knowledge -- is a natural requirement for long-lived\nautonomous reinforcement learning (RL) agents. While building such agents, one\nneeds to balance opposing desiderata, such as constraints on capacity and\ncompute, the ability to not catastrophically forget, and to exhibit positive\ntransfer on new tasks. Understanding the right trade-off is conceptually and\ncomputationally challenging, which we argue has led the community to overly\nfocus on catastrophic forgetting. In response to these issues, we advocate for\nthe need to prioritize forward transfer and propose Continual World, a\nbenchmark consisting of realistic and meaningfully diverse robotic tasks built\non top of Meta-World as a testbed. Following an in-depth empirical evaluation\nof existing CL methods, we pinpoint their limitations and highlight unique\nalgorithmic challenges in the RL setting. Our benchmark aims to provide a\nmeaningful and computationally inexpensive challenge for the community and thus\nhelp better understand the performance of existing and future solutions.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 11:33:04 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 13:03:28 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Wo\u0142czyk", "Maciej", ""], ["Zaj\u0105c", "Micha\u0142", ""], ["Pascanu", "Razvan", ""], ["Kuci\u0144ski", "\u0141ukasz", ""], ["Mi\u0142o\u015b", "Piotr", ""]]}, {"id": "2105.10923", "submitter": "Mayukh Bagchi", "authors": "Mayukh Bagchi", "title": "Towards Knowledge Organization Ecosystems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  It is needless to mention the (already established) overarching importance of\nknowledge organization and its tried-and-tested high-quality schemes in\nknowledge-based Artificial Intelligence (AI) systems. But equally, it is also\nhard to ignore that, increasingly, standalone KOSs are becoming functionally\nineffective components for such systems, given their inability to capture the\ncontinuous facetization and drift of domains. The paper proposes a radical\nre-conceptualization of KOSs as a first step to solve such an inability, and,\naccordingly, contributes in the form of the following dimensions: (i) an\nexplicit characterization of Knowledge Organization Ecosystems (KOEs) (possibly\nfor the first time) and their positioning as pivotal components in realizing\nsustainable knowledge-based AI solutions, (ii) as a consequence of such a novel\ncharacterization, a first examination and characterization of KOEs as\nSocio-Technical Systems (STSs), thus opening up an entirely new stream of\nresearch in knowledge-based AI, and (iii) motivating KOEs not to be mere STSs\nbut STSs which are grounded in Ethics and Responsible Artificial Intelligence\ncardinals from their very genesis. The paper grounds the above contributions in\nrelevant research literature in a distributed fashion throughout the paper, and\nfinally concludes by outlining the future research possibilities.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 12:30:01 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Bagchi", "Mayukh", ""]]}, {"id": "2105.10950", "submitter": "Konstantin Sidorov", "authors": "Konstantin Sidorov, Alexander Morozov", "title": "A review of approaches to modeling applied vehicle routing problems", "comments": "16 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Due to the practical importance of vehicle routing problems (VRP), there\nexists an ever-growing body of research in algorithms and (meta)heuristics for\nsolving such problems. However, the diversity of VRP domains creates the\nseparate problem of modeling such problems -- describing the domain entities\n(and, in particular, the planning decisions), the set of valid planning\ndecisions, and the preferences between different plans. In this paper, we\nreview the approaches for modeling vehicle routing problems. To make the\ncomparison more straightforward, we formulate several criteria for evaluating\nmodeling methods reflecting the practical requirements of the development of\noptimization algorithms for such problems. Finally, as a result of this\ncomparison, we discuss several future research avenues in the field of modeling\nVRP domains.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 14:50:14 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Sidorov", "Konstantin", ""], ["Morozov", "Alexander", ""]]}, {"id": "2105.10956", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Hai Zhao", "title": "Structural Pre-training for Dialogue Comprehension", "comments": "Accepted by ACL-IJCNLP 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pre-trained language models (PrLMs) have demonstrated superior performance\ndue to their strong ability to learn universal language representations from\nself-supervised pre-training. However, even with the help of the powerful\nPrLMs, it is still challenging to effectively capture task-related knowledge\nfrom dialogue texts which are enriched by correlations among speaker-aware\nutterances. In this work, we present SPIDER, Structural Pre-traIned DialoguE\nReader, to capture dialogue exclusive features. To simulate the dialogue-like\nfeatures, we propose two training objectives in addition to the original LM\nobjectives: 1) utterance order restoration, which predicts the order of the\npermuted utterances in dialogue context; 2) sentence backbone regularization,\nwhich regularizes the model to improve the factual correctness of summarized\nsubject-verb-object triplets. Experimental results on widely used dialogue\nbenchmarks verify the effectiveness of the newly introduced self-supervised\ntasks.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 15:16:54 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Zhao", "Hai", ""]]}, {"id": "2105.10993", "submitter": "Nir Greshler", "authors": "Nir Greshler, Ofir Gordon, Oren Salzman, and Nahum Shimkin", "title": "Cooperative Multi-Agent Path Finding: Beyond Path Planning and Collision\n  Avoidance", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Cooperative Multi-Agent Path Finding (Co-MAPF) problem, an\nextension to the classical MAPF problem, where cooperative behavior is\nincorporated. In this setting, a group of autonomous agents operate in a shared\nenvironment and have to complete cooperative tasks while avoiding collisions\nwith the other agents in the group. This extension naturally models many\nreal-world applications, where groups of agents are required to collaborate in\norder to complete a given task. To this end, we formalize the Co-MAPF problem\nand introduce Cooperative Conflict-Based Search (Co-CBS), a CBS-based algorithm\nfor solving the problem optimally for a wide set of Co-MAPF problems. Co-CBS\nuses a cooperation-planning module integrated into CBS such that cooperation\nplanning is decoupled from path planning. Finally, we present empirical results\non several MAPF benchmarks demonstrating our algorithm's properties.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 18:25:46 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Greshler", "Nir", ""], ["Gordon", "Ofir", ""], ["Salzman", "Oren", ""], ["Shimkin", "Nahum", ""]]}, {"id": "2105.11000", "submitter": "Beau Schelble", "authors": "Nathan J. McNeese, Beau G. Schelble, Lorenzo Barberis Canonico,\n  Mustafa Demir", "title": "Who/What is My Teammate? Team Composition Considerations in Human-AI\n  Teaming", "comments": "12 Pages, 6 Figures, IEEE Transactions on Human-Machine Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  There are many unknowns regarding the characteristics and dynamics of\nhuman-AI teams, including a lack of understanding of how certain human-human\nteaming concepts may or may not apply to human-AI teams and how this\ncomposition affects team performance. This paper outlines an experimental\nresearch study that investigates essential aspects of human-AI teaming such as\nteam performance, team situation awareness, and perceived team cognition in\nvarious mixed composition teams (human-only, human-human-AI, human-AI-AI, and\nAI-only) through a simulated emergency response management scenario. Results\nindicate dichotomous outcomes regarding perceived team cognition and\nperformance metrics, as perceived team cognition was not predictive of\nperformance. Performance metrics like team situational awareness and team score\nshowed that teams composed of all human participants performed at a lower level\nthan mixed human-AI teams, with the AI-only teams attaining the highest\nperformance. Perceived team cognition was highest in human-only teams, with\nmixed composition teams reporting perceived team cognition 58% below the\nall-human teams. These results inform future mixed teams of the potential\nperformance gains in utilizing mixed teams' over human-only teams in certain\napplications, while also highlighting mixed teams' adverse effects on perceived\nteam cognition.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 19:06:18 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["McNeese", "Nathan J.", ""], ["Schelble", "Beau G.", ""], ["Canonico", "Lorenzo Barberis", ""], ["Demir", "Mustafa", ""]]}, {"id": "2105.11018", "submitter": "Lei Sha", "authors": "Lei Sha, Patrick Hohenecker, Thomas Lukasiewicz", "title": "Controlling Text Edition by Changing Answers of Specific Questions", "comments": null, "journal-ref": "ACL 2021 findings", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we introduce the new task of controllable text edition, in\nwhich we take as input a long text, a question, and a target answer, and the\noutput is a minimally modified text, so that it fits the target answer. This\ntask is very important in many situations, such as changing some conditions,\nconsequences, or properties in a legal document, or changing some key\ninformation of an event in a news text. This is very challenging, as it is hard\nto obtain a parallel corpus for training, and we need to first find all text\npositions that should be changed and then decide how to change them. We\nconstructed the new dataset WikiBioCTE for this task based on the existing\ndataset WikiBio (originally created for table-to-text generation). We use\nWikiBioCTE for training, and manually labeled a test set for testing. We also\npropose novel evaluation metrics and a novel method for solving the new task.\nExperimental results on the test set show that our proposed method is a good\nfit for this novel NLP task.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 20:44:15 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Sha", "Lei", ""], ["Hohenecker", "Patrick", ""], ["Lukasiewicz", "Thomas", ""]]}, {"id": "2105.11021", "submitter": "Pasccal Fischer", "authors": "Pascal Fischer, Alen Smajic, Alexander Mehler, Giuseppe Abrami", "title": "Multi-Type-TD-TSR -- Extracting Tables from Document Images using a\n  Multi-stage Pipeline for Table Detection and Table Structure Recognition:\n  from OCR to Structured Table Representations", "comments": "8 pages, 8 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As global trends are shifting towards data-driven industries, the demand for\nautomated algorithms that can convert digital images of scanned documents into\nmachine readable information is rapidly growing. Besides the opportunity of\ndata digitization for the application of data analytic tools, there is also a\nmassive improvement towards automation of processes, which previously would\nrequire manual inspection of the documents. Although the introduction of\noptical character recognition technologies mostly solved the task of converting\nhuman-readable characters from images into machine-readable characters, the\ntask of extracting table semantics has been less focused on over the years. The\nrecognition of tables consists of two main tasks, namely table detection and\ntable structure recognition. Most prior work on this problem focuses on either\ntask without offering an end-to-end solution or paying attention to real\napplication conditions like rotated images or noise artefacts inside the\ndocument image. Recent work shows a clear trend towards deep learning\napproaches coupled with the use of transfer learning for the task of table\nstructure recognition due to the lack of sufficiently large datasets. In this\npaper we present a multistage pipeline named Multi-Type-TD-TSR, which offers an\nend-to-end solution for the problem of table recognition. It utilizes\nstate-of-the-art deep learning models for table detection and differentiates\nbetween 3 different types of tables based on the tables' borders. For the table\nstructure recognition we use a deterministic non-data driven algorithm, which\nworks on all table types. We additionally present two algorithms. One for\nunbordered tables and one for bordered tables, which are the base of the used\ntable structure recognition algorithm. We evaluate Multi-Type-TD-TSR on the\nICDAR 2019 table structure recognition dataset and achieve a new\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 21:17:18 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Fischer", "Pascal", ""], ["Smajic", "Alen", ""], ["Mehler", "Alexander", ""], ["Abrami", "Giuseppe", ""]]}, {"id": "2105.11028", "submitter": "Milad Khademinori", "authors": "Milad Khademi Nori, Sangseok Yun, and Il-Min Kim", "title": "Fast Federated Learning by Balancing Communication Trade-Offs", "comments": "14 pages, 24 figures, accepted for publication in IEEE Transactions\n  on Communications", "journal-ref": null, "doi": "10.1109/TCOMM.2021.3083316", "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated Learning (FL) has recently received a lot of attention for\nlarge-scale privacy-preserving machine learning. However, high communication\noverheads due to frequent gradient transmissions decelerate FL. To mitigate the\ncommunication overheads, two main techniques have been studied: (i) local\nupdate of weights characterizing the trade-off between communication and\ncomputation and (ii) gradient compression characterizing the trade-off between\ncommunication and precision. To the best of our knowledge, studying and\nbalancing those two trade-offs jointly and dynamically while considering their\nimpacts on convergence has remained unresolved even though it promises\nsignificantly faster FL. In this paper, we first formulate our problem to\nminimize learning error with respect to two variables: local update\ncoefficients and sparsity budgets of gradient compression who characterize\ntrade-offs between communication and computation/precision, respectively. We\nthen derive an upper bound of the learning error in a given wall-clock time\nconsidering the interdependency between the two variables. Based on this\ntheoretical analysis, we propose an enhanced FL scheme, namely Fast FL (FFL),\nthat jointly and dynamically adjusts the two variables to minimize the learning\nerror. We demonstrate that FFL consistently achieves higher accuracies faster\nthan similar schemes existing in the literature.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 21:55:14 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Nori", "Milad Khademi", ""], ["Yun", "Sangseok", ""], ["Kim", "Il-Min", ""]]}, {"id": "2105.11039", "submitter": "Linyu Lin", "authors": "Linyu Lin, Paridhi Athe, Pascal Rouxelin, Maria Avramova, Abhinav\n  Gupta, Robert Youngblood, Nam Dinh", "title": "Digital-Twin-Based Improvements to Diagnosis, Prognosis, Strategy\n  Assessment, and Discrepancy Checking in a Nearly Autonomous Management and\n  Control System", "comments": "44 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SY eess.SY physics.ins-det", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Nearly Autonomous Management and Control System (NAMAC) is a\ncomprehensive control system that assists plant operations by furnishing\ncontrol recommendations to operators in a broad class of situations. This study\nrefines a NAMAC system for making reasonable recommendations during complex\nloss-of-flow scenarios with a validated Experimental Breeder Reactor II\nsimulator, digital twins improved by machine-learning algorithms, a\nmulti-attribute decision-making scheme, and a discrepancy checker for\nidentifying unexpected recommendation effects. We assessed the performance of\neach NAMAC component, while we demonstrated and evaluated the capability of\nNAMAC in a class of loss-of-flow scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 23:05:07 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Lin", "Linyu", ""], ["Athe", "Paridhi", ""], ["Rouxelin", "Pascal", ""], ["Avramova", "Maria", ""], ["Gupta", "Abhinav", ""], ["Youngblood", "Robert", ""], ["Dinh", "Nam", ""]]}, {"id": "2105.11071", "submitter": "Fangfang Liu", "authors": "Fangfang Liu and Jia-huai You", "title": "Alternating Fixpoint Operator for Hybrid MKNF Knowledge Bases as an\n  Approximator of AFT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Approximation fixpoint theory (AFT) provides an algebraic framework for the\nstudy of fixpoints of operators on bilattices and has found its applications in\ncharacterizing semantics for various classes of logic programs and nonmonotonic\nlanguages. In this paper, we show one more application of this kind: the\nalternating fixpoint operator by Knorr et al. for the study of the well-founded\nsemantics for hybrid MKNF knowledge bases is in fact an approximator of AFT in\ndisguise, which, thanks to the power of abstraction of AFT, characterizes not\nonly the well-founded semantics but also two-valued as well as three-valued\nsemantics for hybrid MKNF knowledge bases. Furthermore, we show an improved\napproximator for these knowledge bases, of which the least stable fixpoint is\ninformation richer than the one formulated from Knorr et al.'s construction.\nThis leads to an improved computation for the well-founded semantics. This work\nis built on an extension of AFT that supports consistent as well as\ninconsistent pairs in the induced product bilattice, to deal with\ninconsistencies that arise in the context of hybrid MKNF knowledge bases. This\npart of the work can be considered generalizing the original AFT from symmetric\napproximators to arbitrary approximators.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 02:32:51 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 11:46:41 GMT"}, {"version": "v3", "created": "Thu, 8 Jul 2021 05:40:51 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Liu", "Fangfang", ""], ["You", "Jia-huai", ""]]}, {"id": "2105.11082", "submitter": "Shrikanth N.C.", "authors": "N.C. Shrikanth and Tim Menzies", "title": "The Early Bird Catches the Worm: Better Early Life Cycle Defect\n  Predictors", "comments": "15 pages (In Review)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Before researchers rush to reason across all available data, they should\nfirst check if the information is densest within some small region. We say this\nsince, in 240 GitHub projects, we find that the information in that data\n``clumps'' towards the earliest parts of the project. In fact, a defect\nprediction model learned from just the first 150 commits works as well, or\nbetter than state-of-the-art alternatives. Using just this early life cycle\ndata, we can build models very quickly (using weeks, not months, of CPU time).\nAlso, we can find simple models (with just two features) that generalize to\nhundreds of software projects. Based on this experience, we warn that prior\nwork on generalizing software engineering defect prediction models may have\nneedlessly complicated an inherently simple process. Further, prior work that\nfocused on later-life cycle data now needs to be revisited since their\nconclusions were drawn from relatively uninformative regions. Replication note:\nall our data and scripts are online at\nhttps://github.com/snaraya7/early-defect-prediction-tse.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 03:49:09 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Shrikanth", "N. C.", ""], ["Menzies", "Tim", ""]]}, {"id": "2105.11098", "submitter": "Fandong Meng", "authors": "Mengqi Miao, Fandong Meng, Yijin Liu, Xiao-Hua Zhou, Jie Zhou", "title": "Prevent the Language Model from being Overconfident in Neural Machine\n  Translation", "comments": "Accepted as a long paper at ACL 2021. Code is available at:\n  https://github.com/Mlair77/nmt_adequacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Neural Machine Translation (NMT) model is essentially a joint language\nmodel conditioned on both the source sentence and partial translation.\nTherefore, the NMT model naturally involves the mechanism of the Language Model\n(LM) that predicts the next token only based on partial translation. Despite\nits success, NMT still suffers from the hallucination problem, generating\nfluent but inadequate translations. The main reason is that NMT pays excessive\nattention to the partial translation while neglecting the source sentence to\nsome extent, namely overconfidence of the LM. Accordingly, we define the Margin\nbetween the NMT and the LM, calculated by subtracting the predicted probability\nof the LM from that of the NMT model for each token. The Margin is negatively\ncorrelated to the overconfidence degree of the LM. Based on the property, we\npropose a Margin-based Token-level Objective (MTO) and a Margin-based\nSentencelevel Objective (MSO) to maximize the Margin for preventing the LM from\nbeing overconfident. Experiments on WMT14 English-to-German, WMT19\nChinese-to-English, and WMT14 English-to-French translation tasks demonstrate\nthe effectiveness of our approach, with 1.36, 1.50, and 0.63 BLEU improvements,\nrespectively, compared to the Transformer baseline. The human evaluation\nfurther verifies that our approaches improve translation adequacy as well as\nfluency.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 05:34:09 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 15:57:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Miao", "Mengqi", ""], ["Meng", "Fandong", ""], ["Liu", "Yijin", ""], ["Zhou", "Xiao-Hua", ""], ["Zhou", "Jie", ""]]}, {"id": "2105.11115", "submitter": "Shunyu Yao", "authors": "Shunyu Yao, Binghui Peng, Christos Papadimitriou, Karthik Narasimhan", "title": "Self-Attention Networks Can Process Bounded Hierarchical Languages", "comments": "ACL 2021. 19 pages with extended appendix. Code:\n  https://github.com/princeton-nlp/dyck-transformer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite their impressive performance in NLP, self-attention networks were\nrecently proved to be limited for processing formal languages with hierarchical\nstructure, such as $\\mathsf{Dyck}_k$, the language consisting of well-nested\nparentheses of $k$ types. This suggested that natural language can be\napproximated well with models that are too weak for formal languages, or that\nthe role of hierarchy and recursion in natural language might be limited. We\nqualify this implication by proving that self-attention networks can process\n$\\mathsf{Dyck}_{k, D}$, the subset of $\\mathsf{Dyck}_{k}$ with depth bounded by\n$D$, which arguably better captures the bounded hierarchical structure of\nnatural language. Specifically, we construct a hard-attention network with\n$D+1$ layers and $O(\\log k)$ memory size (per token per layer) that recognizes\n$\\mathsf{Dyck}_{k, D}$, and a soft-attention network with two layers and\n$O(\\log k)$ memory size that generates $\\mathsf{Dyck}_{k, D}$. Experiments show\nthat self-attention networks trained on $\\mathsf{Dyck}_{k, D}$ generalize to\nlonger inputs with near-perfect accuracy, and also verify the theoretical\nmemory advantage of self-attention networks over recurrent networks.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 06:42:58 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Yao", "Shunyu", ""], ["Peng", "Binghui", ""], ["Papadimitriou", "Christos", ""], ["Narasimhan", "Karthik", ""]]}, {"id": "2105.11119", "submitter": "Hongyu Gong", "authors": "Hongyu Gong, Alberto Valido, Katherine M. Ingram, Giulia Fanti, Suma\n  Bhat, Dorothy L. Espelage", "title": "Abusive Language Detection in Heterogeneous Contexts: Dataset Collection\n  and the Role of Supervised Attention", "comments": "AAAI 2021 (AI for Social Impact track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Abusive language is a massive problem in online social platforms. Existing\nabusive language detection techniques are particularly ill-suited to comments\ncontaining heterogeneous abusive language patterns, i.e., both abusive and\nnon-abusive parts. This is due in part to the lack of datasets that explicitly\nannotate heterogeneity in abusive language. We tackle this challenge by\nproviding an annotated dataset of abusive language in over 11,000 comments from\nYouTube. We account for heterogeneity in this dataset by separately annotating\nboth the comment as a whole and the individual sentences that comprise each\ncomment. We then propose an algorithm that uses a supervised attention\nmechanism to detect and categorize abusive content using multi-task learning.\nWe empirically demonstrate the challenges of using traditional techniques on\nheterogeneous content and the comparative gains in performance of the proposed\napproach over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 06:50:19 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Gong", "Hongyu", ""], ["Valido", "Alberto", ""], ["Ingram", "Katherine M.", ""], ["Fanti", "Giulia", ""], ["Bhat", "Suma", ""], ["Espelage", "Dorothy L.", ""]]}, {"id": "2105.11132", "submitter": "Durgesh Agrawal", "authors": "Durgesh Agrawal and Yash Pote and Kuldeep S Meel", "title": "Partition Function Estimation: A Quantitative Study", "comments": "10 pages, 3 figures, 2 tables, to be published in IJCAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic graphical models have emerged as a powerful modeling tool for\nseveral real-world scenarios where one needs to reason under uncertainty. A\ngraphical model's partition function is a central quantity of interest, and its\ncomputation is key to several probabilistic reasoning tasks. Given the\n#P-hardness of computing the partition function, several techniques have been\nproposed over the years with varying guarantees on the quality of estimates and\ntheir runtime behavior. This paper seeks to present a survey of 18 techniques\nand a rigorous empirical study of their behavior across an extensive set of\nbenchmarks. Our empirical study draws up a surprising observation: exact\ntechniques are as efficient as the approximate ones, and therefore, we conclude\nwith an optimistic view of opportunities for the design of approximate\ntechniques with enhanced scalability. Motivated by the observation of an order\nof magnitude difference between the Virtual Best Solver and the best performing\ntool, we envision an exciting line of research focused on the development of\nportfolio solvers.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 07:25:43 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Agrawal", "Durgesh", ""], ["Pote", "Yash", ""], ["Meel", "Kuldeep S", ""]]}, {"id": "2105.11134", "submitter": "Jiacheng Ye", "authors": "Jiacheng Ye, Tao Gui, Yichao Luo, Yige Xu, Qi Zhang", "title": "One2Set: Generating Diverse Keyphrases as a Set", "comments": "Accepted by ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, the sequence-to-sequence models have made remarkable progress on\nthe task of keyphrase generation (KG) by concatenating multiple keyphrases in a\npredefined order as a target sequence during training. However, the keyphrases\nare inherently an unordered set rather than an ordered sequence. Imposing a\npredefined order will introduce wrong bias during training, which can highly\npenalize shifts in the order between keyphrases. In this work, we propose a new\ntraining paradigm One2Set without predefining an order to concatenate the\nkeyphrases. To fit this paradigm, we propose a novel model that utilizes a\nfixed set of learned control codes as conditions to generate a set of\nkeyphrases in parallel. To solve the problem that there is no correspondence\nbetween each prediction and target during training, we propose a $K$-step\ntarget assignment mechanism via bipartite matching, which greatly increases the\ndiversity and reduces the duplication ratio of generated keyphrases. The\nexperimental results on multiple benchmarks demonstrate that our approach\nsignificantly outperforms the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 07:29:47 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Ye", "Jiacheng", ""], ["Gui", "Tao", ""], ["Luo", "Yichao", ""], ["Xu", "Yige", ""], ["Zhang", "Qi", ""]]}, {"id": "2105.11147", "submitter": "Luigi Bellomarini", "authors": "Luigi Bellomarini, Emanuel Sallinger", "title": "Harmless but Useful: Beyond Separable Equality Constraints in Datalog+/-", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Ontological query answering is the problem of answering queries in the\npresence of schema constraints representing the domain of interest. Datalog+/-\nis a common family of languages for schema constraints, including\ntuple-generating dependencies (TGDs) and equality-generating dependencies\n(EGDs). The interplay of TGDs and EGDs leads to undecidability or\nintractability of query answering when adding EGDs to tractable Datalog+/-\nfragments, like Warded Datalog+/-, for which, in the sole presence of TGDs,\nquery answering is PTIME in data complexity. There have been attempts to limit\nthe interaction of TGDs and EGDs and guarantee tractability, in particular with\nthe introduction of separable EGDs, to make EGDs irrelevant for query answering\nas long as the set of constraints is satisfied. While being tractable,\nseparable EGDs have limited expressive power.\n  We propose a more general class of EGDs, which we call \"harmless\", that\nsubsume separable EGDs and allow to model a much broader class of problems.\nUnlike separable EGDs, harmless EGDs, besides enforcing ground equality\nconstraints, specialize the query answer by grounding or renaming the labelled\nnulls introduced by existential quantification in the TGDs. Harmless EGDs\ncapture the cases when the answer obtained in the presence of EGDs is less\ngeneral than the one obtained with TGDs only. We conclude that the theoretical\nproblem of deciding whether a set of constraints contains harmless EGDs is\nundecidable. We contribute a sufficient syntactic condition characterizing\nharmless EGDs, broad and useful in practice. We focus on Warded Datalog+/- with\nharmless EGDs and argue that, in such fragment, query answering is decidable\nand PTIME in data complexity. We study chase-based techniques for query\nanswering in Warded Datalog+/- with harmless EGDs, conducive to an efficient\nalgorithm to be implemented in state-of-the-art reasoners.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 08:22:16 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 05:52:54 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Bellomarini", "Luigi", ""], ["Sallinger", "Emanuel", ""]]}, {"id": "2105.11174", "submitter": "Han Wang", "authors": "Han Wang, Yang Liu, Chenguang Zhu, Linjun Shou, Ming Gong, Yichong Xu,\n  Michael Zeng", "title": "Retrieval Enhanced Model for Commonsense Generation", "comments": "Findings of ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Commonsense generation is a challenging task of generating a plausible\nsentence describing an everyday scenario using provided concepts. Its\nrequirement of reasoning over commonsense knowledge and compositional\ngeneralization ability even puzzles strong pre-trained language generation\nmodels. We propose a novel framework using retrieval methods to enhance both\nthe pre-training and fine-tuning for commonsense generation. We retrieve\nprototype sentence candidates by concept matching and use them as auxiliary\ninput. For fine-tuning, we further boost its performance with a trainable\nsentence retriever. We demonstrate experimentally on the large-scale CommonGen\nbenchmark that our approach achieves new state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 09:49:17 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Wang", "Han", ""], ["Liu", "Yang", ""], ["Zhu", "Chenguang", ""], ["Shou", "Linjun", ""], ["Gong", "Ming", ""], ["Xu", "Yichong", ""], ["Zeng", "Michael", ""]]}, {"id": "2105.11228", "submitter": "Yuchao Li", "authors": "Yuchao Li, Shaohui Lin, Jianzhuang Liu, Qixiang Ye, Mengdi Wang, Fei\n  Chao, Fan Yang, Jincheng Ma, Qi Tian, Rongrong Ji", "title": "Towards Compact CNNs via Collaborative Compression", "comments": "This paper is published in CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Channel pruning and tensor decomposition have received extensive attention in\nconvolutional neural network compression. However, these two techniques are\ntraditionally deployed in an isolated manner, leading to significant accuracy\ndrop when pursuing high compression rates. In this paper, we propose a\nCollaborative Compression (CC) scheme, which joints channel pruning and tensor\ndecomposition to compress CNN models by simultaneously learning the model\nsparsity and low-rankness. Specifically, we first investigate the compression\nsensitivity of each layer in the network, and then propose a Global Compression\nRate Optimization that transforms the decision problem of compression rate into\nan optimization problem. After that, we propose multi-step heuristic\ncompression to remove redundant compression units step-by-step, which fully\nconsiders the effect of the remaining compression space (i.e., unremoved\ncompression units). Our method demonstrates superior performance gains over\nprevious ones on various datasets and backbone architectures. For example, we\nachieve 52.9% FLOPs reduction by removing 48.4% parameters on ResNet-50 with\nonly a Top-1 accuracy drop of 0.56% on ImageNet 2012.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 12:07:38 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Li", "Yuchao", ""], ["Lin", "Shaohui", ""], ["Liu", "Jianzhuang", ""], ["Ye", "Qixiang", ""], ["Wang", "Mengdi", ""], ["Chao", "Fei", ""], ["Yang", "Fan", ""], ["Ma", "Jincheng", ""], ["Tian", "Qi", ""], ["Ji", "Rongrong", ""]]}, {"id": "2105.11266", "submitter": "Kristijonas \\v{C}yras", "authors": "Kristijonas \\v{C}yras, Antonio Rago, Emanuele Albini, Pietro Baroni,\n  Francesca Toni", "title": "Argumentative XAI: A Survey", "comments": "IJCAI 2021 Survey Track preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable AI (XAI) has been investigated for decades and, together with AI\nitself, has witnessed unprecedented growth in recent years. Among various\napproaches to XAI, argumentative models have been advocated in both the AI and\nsocial science literature, as their dialectical nature appears to match some\nbasic desirable features of the explanation activity. In this survey we\noverview XAI approaches built using methods from the field of computational\nargumentation, leveraging its wide array of reasoning abstractions and\nexplanation delivery methods. We overview the literature focusing on different\ntypes of explanation (intrinsic and post-hoc), different models with which\nargumentation-based explanations are deployed, different forms of delivery, and\ndifferent argumentation frameworks they use. We also lay out a roadmap for\nfuture work.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 13:32:59 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["\u010cyras", "Kristijonas", ""], ["Rago", "Antonio", ""], ["Albini", "Emanuele", ""], ["Baroni", "Pietro", ""], ["Toni", "Francesca", ""]]}, {"id": "2105.11267", "submitter": "Alasdair Hill", "authors": "Alasdair Hill, Ekaterina Komendantskaya, Matthew L. Daggitt and Ronald\n  P. A. Petrick", "title": "Actions You Can Handle: Dependent Types for AI Plans", "comments": "14 pages, 5 figures, Accepted to TyDe 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Verification of AI is a challenge that has engineering, algorithmic and\nprogramming language components. For example, AI planners are deployed to model\nactions of autonomous agents. They comprise a number of searching algorithms\nthat, given a set of specified properties, find a sequence of actions that\nsatisfy these properties. Although AI planners are mature tools from the\nalgorithmic and engineering points of view, they have limitations as\nprogramming languages. Decidable and efficient automated search entails\nrestrictions on the syntax of the language, prohibiting use of higher-order\nproperties or recursion. This paper proposes a methodology for embedding plans\nproduced by AI planners into dependently-typed language Agda, which enables\nusers to reason about and verify more general and abstract properties of plans,\nand also provides a more holistic programming language infrastructure for\nmodelling plan execution.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 13:33:56 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 20:12:06 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Hill", "Alasdair", ""], ["Komendantskaya", "Ekaterina", ""], ["Daggitt", "Matthew L.", ""], ["Petrick", "Ronald P. A.", ""]]}, {"id": "2105.11269", "submitter": "Deng Cai", "authors": "Deng Cai and Yan Wang and Huayang Li and Wai Lam and Lemao Liu", "title": "Neural Machine Translation with Monolingual Translation Memory", "comments": "ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prior work has proved that Translation memory (TM) can boost the performance\nof Neural Machine Translation (NMT). In contrast to existing work that uses\nbilingual corpus as TM and employs source-side similarity search for memory\nretrieval, we propose a new framework that uses monolingual memory and performs\nlearnable memory retrieval in a cross-lingual manner. Our framework has unique\nadvantages. First, the cross-lingual memory retriever allows abundant\nmonolingual data to be TM. Second, the memory retriever and NMT model can be\njointly optimized for the ultimate translation goal. Experiments show that the\nproposed method obtains substantial improvements. Remarkably, it even\noutperforms strong TM-augmented NMT baselines using bilingual TM. Owning to the\nability to leverage monolingual data, our model also demonstrates effectiveness\nin low-resource and domain adaptation scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 13:35:19 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 07:41:52 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Cai", "Deng", ""], ["Wang", "Yan", ""], ["Li", "Huayang", ""], ["Lam", "Wai", ""], ["Liu", "Lemao", ""]]}, {"id": "2105.11283", "submitter": "Eugene Valassakis", "authors": "Eugene Valassakis, Norman Di Palo and Edward Johns", "title": "Coarse-to-Fine for Sim-to-Real: Sub-Millimetre Precision Across Wide\n  Task Spaces", "comments": "To be published at IROS 2021. 8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of zero-shot sim-to-real when the task\nrequires both highly precise control with sub-millimetre error tolerance, and\nwide task space generalisation. Our framework involves a coarse-to-fine\ncontroller, where trajectories begin with classical motion planning using\nICP-based pose estimation, and transition to a learned end-to-end controller\nwhich maps images to actions and is trained in simulation with domain\nrandomisation. In this way, we achieve precise control whilst also generalising\nthe controller across wide task spaces, and keeping the robustness of\nvision-based, end-to-end control. Real-world experiments on a range of\ndifferent tasks show that, by exploiting the best of both worlds, our framework\nsignificantly outperforms purely motion planning methods, and purely\nlearning-based methods. Furthermore, we answer a range of questions on best\npractices for precise sim-to-real transfer, such as how different image sensor\nmodalities and image feature representations perform.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 14:12:38 GMT"}, {"version": "v2", "created": "Thu, 29 Jul 2021 13:42:53 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Valassakis", "Eugene", ""], ["Di Palo", "Norman", ""], ["Johns", "Edward", ""]]}, {"id": "2105.11308", "submitter": "Henderik Alex Proper", "authors": "H. A. Proper and Th. P. van der Weide", "title": "A General Theory for the Evolution of Application Models -- Full version", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article we focus on evolving information systems. First a\ndelimitation of the concept of evolution is provided, resulting in a first\nattempt to a general theory for such evolutions. The theory makes a distinction\nbetween the underlying information structure at the conceptual level, its\nevolution on the one hand, and the description and semantics of operations on\nthe information structure and its population on the other hand. Main issues\nwithin this theory are object typing, type relatedness and identification of\nobjects. In terms of these concepts, we propose some axioms on the\nwell-formedness of evolution. In this general theory, the underlying data model\nis a parameter, making the theory applicable for a wide range of modelling\ntechniques, including object-role modelling and object oriented techniques.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:24:35 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Proper", "H. A.", ""], ["van der Weide", "Th. P.", ""]]}, {"id": "2105.11328", "submitter": "Rich Riley Mr", "authors": "Henry Charlesworth, Adrian Millea, Eddie Pottrill, Rich Riley", "title": "Room Clearance with Feudal Hierarchical Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Reinforcement learning (RL) is a general framework that allows systems to\nlearn autonomously through trial-and-error interaction with their environment.\nIn recent years combining RL with expressive, high-capacity neural network\nmodels has led to impressive performance in a diverse range of domains.\nHowever, dealing with the large state and action spaces often required for\nproblems in the real world still remains a significant challenge. In this paper\nwe introduce a new simulation environment, \"Gambit\", designed as a tool to\nbuild scenarios that can drive RL research in a direction useful for military\nanalysis. Using this environment we focus on an abstracted and simplified room\nclearance scenario, where a team of blue agents have to make their way through\na building and ensure that all rooms are cleared of (and remain clear) of enemy\nred agents. We implement a multi-agent version of feudal hierarchical RL that\nintroduces a command hierarchy where a commander at the higher level sends\norders to multiple agents at the lower level who simply have to learn to follow\nthese orders. We find that breaking the task down in this way allows us to\nsolve a number of non-trivial floorplans that require the coordination of\nmultiple agents much more efficiently than the standard baseline RL algorithms\nwe compare with. We then go on to explore how qualitatively different behaviour\ncan emerge depending on what we prioritise in the agent's reward function (e.g.\nclearing the building quickly vs. prioritising rescuing civilians).\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 15:05:58 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Charlesworth", "Henry", ""], ["Millea", "Adrian", ""], ["Pottrill", "Eddie", ""], ["Riley", "Rich", ""]]}, {"id": "2105.11343", "submitter": "Jia Shen", "authors": "Jia Tracy Shen, Michiharu Yamashita, Ethan Prihar, Neil Heffernan,\n  Xintao Wu, Sean McGrew, Dongwon Lee", "title": "Classifying Math KCs via Task-Adaptive Pre-Trained BERT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Educational content labeled with proper knowledge components (KCs) are\nparticularly useful to teachers or content organizers. However, manually\nlabeling educational content is labor intensive and error-prone. To address\nthis challenge, prior research proposed machine learning based solutions to\nauto-label educational content with limited success. In this work, we\nsignificantly improve prior research by (1) expanding the input types to\ninclude KC descriptions, instructional video titles, and problem descriptions\n(i.e., three types of prediction task), (2) doubling the granularity of the\nprediction from 198 to 385 KC labels (i.e., more practical setting but much\nharder multinomial classification problem), (3) improving the prediction\naccuracies by 0.5-2.3% using Task-adaptive Pre-trained BERT, outperforming six\nbaselines, and (4) proposing a simple evaluation measure by which we can\nrecover 56-73% of mispredicted KC labels. All codes and data sets in the\nexperiments are available at:https://github.com/tbs17/TAPT-BERT\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 15:27:33 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Shen", "Jia Tracy", ""], ["Yamashita", "Michiharu", ""], ["Prihar", "Ethan", ""], ["Heffernan", "Neil", ""], ["Wu", "Xintao", ""], ["McGrew", "Sean", ""], ["Lee", "Dongwon", ""]]}, {"id": "2105.11348", "submitter": "Pranav Garimidi", "authors": "Artem Baklanov, Pranav Garimidi, Vasilis Gkatzelis, Daniel Schoepflin", "title": "PROPm Allocations of Indivisible Goods to Multiple Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the classic problem of fairly allocating a set of indivisible goods\namong a group of agents, and focus on the notion of approximate proportionality\nknown as PROPm. Prior work showed that there exists an allocation that\nsatisfies this notion of fairness for instances involving up to five agents,\nbut fell short of proving that this is true in general. We extend this result\nto show that a PROPm allocation is guaranteed to exist for all instances,\nindependent of the number of agents or goods. Our proof is constructive,\nproviding an algorithm that computes such an allocation and, unlike prior work,\nthe running time of this algorithm is polynomial in both the number of agents\nand the number of goods.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 15:34:33 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Baklanov", "Artem", ""], ["Garimidi", "Pranav", ""], ["Gkatzelis", "Vasilis", ""], ["Schoepflin", "Daniel", ""]]}, {"id": "2105.11367", "submitter": "Fan Lai", "authors": "Fan Lai, Yinwei Dai, Xiangfeng Zhu, Mosharaf Chowdhury", "title": "FedScale: Benchmarking Model and System Performance of Federated\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present FedScale, a diverse set of challenging and realistic benchmark\ndatasets to facilitate scalable, comprehensive, and reproducible federated\nlearning (FL) research. FedScale datasets are large-scale, encompassing a\ndiverse range of important FL tasks, such as image classification, object\ndetection, language modeling, speech recognition, and reinforcement learning.\nFor each dataset, we provide a unified evaluation protocol using realistic data\nsplits and evaluation metrics. To meet the pressing need for reproducing\nrealistic FL at scale, we have also built an efficient evaluation platform to\nsimplify and standardize the process of FL experimental setup and model\nevaluation. Our evaluation platform provides flexible APIs to implement new FL\nalgorithms and includes new execution backends with minimal developer efforts.\nFinally, we perform indepth benchmark experiments on these datasets. Our\nexperiments suggest fruitful opportunities in heterogeneity-aware\nco-optimizations of the system and statistical efficiency under realistic FL\ncharacteristics. FedScale is open-source with permissive licenses and actively\nmaintained,1 and we welcome feedback and contributions from the community.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 15:55:27 GMT"}, {"version": "v2", "created": "Sun, 13 Jun 2021 03:58:13 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Lai", "Fan", ""], ["Dai", "Yinwei", ""], ["Zhu", "Xiangfeng", ""], ["Chowdhury", "Mosharaf", ""]]}, {"id": "2105.11385", "submitter": "Maayan Goldstein", "authors": "Maayan Goldstein and Cecilia Gonzalez-Alvarez", "title": "Augmenting Modelers with Semantic Autocompletion of Processes", "comments": "Accepted for publication at Business Process Management Forum - BPM\n  Forum 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Business process modelers need to have expertise and knowledge of the domain\nthat may not always be available to them. Therefore, they may benefit from\ntools that mine collections of existing processes and recommend element(s) to\nbe added to a new process that they are constructing. In this paper, we present\na method for process autocompletion at design time, that is based on the\nsemantic similarity of sub-processes. By converting sub-processes to textual\nparagraphs and encoding them as numerical vectors, we can find semantically\nsimilar ones, and thereafter recommend the next element. To achieve this, we\nleverage a state-of-the-art technique for embedding natural language as\nvectors. We evaluate our approach on open source and proprietary datasets and\nshow that our technique is accurate for processes in various domains.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 16:23:07 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Goldstein", "Maayan", ""], ["Gonzalez-Alvarez", "Cecilia", ""]]}, {"id": "2105.11412", "submitter": "Kiran Purohit", "authors": "Kiran Purohit, Owais Iqbal and Ankan Mullick", "title": "Reproducibility Report: Contextualizing Hate Speech Classifiers with\n  Post-hoc Explanation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The presented report evaluates Contextualizing Hate Speech Classifiers with\nPost-hoc Explanation paper within the scope of ML Reproducibility Challenge\n2020. Our work focuses on both aspects constituting the paper: the method\nitself and the validity of the stated results. In the following sections, we\nhave described the paper, related works, algorithmic frameworks, our\nexperiments and evaluations.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 17:02:24 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Purohit", "Kiran", ""], ["Iqbal", "Owais", ""], ["Mullick", "Ankan", ""]]}, {"id": "2105.11422", "submitter": "Ouyang Ou", "authors": "Mengxiao Tian, Hao Guo, Chengjiang Long", "title": "Multi-Level Attentive Convoluntional Neural Network for Crowd Counting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently the crowd counting has received more and more attention. Especially\nthe technology of high-density environment has become an important research\ncontent, and the relevant methods for the existence of extremely dense crowd\nare not optimal. In this paper, we propose a multi-level attentive\nConvolutional Neural Network (MLAttnCNN) for crowd counting. We extract\nhigh-level contextual information with multiple different scales applied in\npooling, and use multi-level attention modules to enrich the characteristics at\ndifferent layers to achieve more efficient multi-scale feature fusion, which is\nable to be used to generate a more accurate density map with dilated\nconvolutions and a $1\\times 1$ convolution. The extensive experiments on three\navailable public datasets show that our proposed network achieves\noutperformance to the state-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 17:29:00 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Tian", "Mengxiao", ""], ["Guo", "Hao", ""], ["Long", "Chengjiang", ""]]}, {"id": "2105.11453", "submitter": "Zeheng Wang", "authors": "Zeheng Wang, Liang Li, Ross C. C. Leon and Arne Laucht", "title": "Improving Machine Learning-Based Modeling of Semiconductor Devices by\n  Data Self-Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the electronics industry, introducing Machine Learning (ML)-based\ntechniques can enhance Technology Computer-Aided Design (TCAD) methods.\nHowever, the performance of ML models is highly dependent on their training\ndatasets. Particularly in the semiconductor industry, given the fact that the\nfabrication process of semiconductor devices is complicated and expensive, it\nis of great difficulty to obtain datasets with sufficient size and good\nquality. In this paper, we propose a strategy for improving ML-based device\nmodeling by data self-augmentation using variational autoencoder-based\ntechniques, where initially only a few experimental data points are required\nand TCAD tools are not essential. Taking a deep neural network-based prediction\ntask of the Ohmic resistance value in Gallium Nitride devices as an example, we\napply our proposed strategy to augment data points and achieve a reduction in\nthe mean absolute error of predicting the experimental results by up to 70%.\nThe proposed method could be easily modified for different tasks, rendering it\nof high interest to the semiconductor industry in general.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 00:52:44 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Wang", "Zeheng", ""], ["Li", "Liang", ""], ["Leon", "Ross C. C.", ""], ["Laucht", "Arne", ""]]}, {"id": "2105.11479", "submitter": "Ernest Davis", "authors": "Ernest Davis", "title": "A Flawed Dataset for Symbolic Equation Verification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.SC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Arabshahi, Singh, and Anandkumar (2018) propose a method for creating a\ndataset of symbolic mathematical equations for the tasks of symbolic equation\nverification and equation completion. Unfortunately, a dataset constructed\nusing the method they propose will suffer from two serious flaws. First, the\nclass of true equations that the procedure can generate will be very limited.\nSecond, because true and false equations are generated in completely different\nways, there are likely to be artifactual features that allow easy\ndiscrimination.\n  Moreover, over the class of equations they consider, there is an extremely\nsimple probabilistic procedure that solves the problem of equation verification\nwith extremely high reliability. The usefulness of this problem in general as a\ntestbed for AI systems is therefore doubtful.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 18:05:38 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 14:46:53 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 01:34:45 GMT"}, {"version": "v4", "created": "Fri, 28 May 2021 03:05:46 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Davis", "Ernest", ""]]}, {"id": "2105.11531", "submitter": "Francisco P\\'erez-Galarce", "authors": "F. P\\'erez-Galarce, K. Pichara, P. Huijse, M. Catelan, D. Mery", "title": "Informative Bayesian model selection for RR Lyrae star classifiers", "comments": null, "journal-ref": null, "doi": "10.1093/mnras/stab320", "report-no": null, "categories": "astro-ph.IM cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning has achieved an important role in the automatic\nclassification of variable stars, and several classifiers have been proposed\nover the last decade. These classifiers have achieved impressive performance in\nseveral astronomical catalogues. However, some scientific articles have also\nshown that the training data therein contain multiple sources of bias. Hence,\nthe performance of those classifiers on objects not belonging to the training\ndata is uncertain, potentially resulting in the selection of incorrect models.\nBesides, it gives rise to the deployment of misleading classifiers. An example\nof the latter is the creation of open-source labelled catalogues with biased\npredictions. In this paper, we develop a method based on an informative\nmarginal likelihood to evaluate variable star classifiers. We collect\ndeterministic rules that are based on physical descriptors of RR Lyrae stars,\nand then, to mitigate the biases, we introduce those rules into the marginal\nlikelihood estimation. We perform experiments with a set of Bayesian Logistic\nRegressions, which are trained to classify RR Lyraes, and we found that our\nmethod outperforms traditional non-informative cross-validation strategies,\neven when penalized models are assessed. Our methodology provides a more\nrigorous alternative to assess machine learning models using astronomical\nknowledge. From this approach, applications to other classes of variable stars\nand algorithmic improvements can be developed.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 20:55:04 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["P\u00e9rez-Galarce", "F.", ""], ["Pichara", "K.", ""], ["Huijse", "P.", ""], ["Catelan", "M.", ""], ["Mery", "D.", ""]]}, {"id": "2105.11537", "submitter": "Shiwei Lyu", "authors": "Shiwei Lyu, Shuai Ling, Kaihao Guo, Haipeng Zhang, Kunpeng Zhang,\n  Suting Hong, Qing Ke, Jinjie Gu", "title": "Graph Neural Network Based VC Investment Success Prediction", "comments": "11pages, 5figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the start-ups that will eventually succeed is essentially\nimportant for the venture capital business and worldwide policy makers,\nespecially at an early stage such that rewards can possibly be exponential.\n  Though various empirical studies and data-driven modeling work have been\ndone, the predictive power of the complex networks of stakeholders including\nventure capital investors, start-ups, and start-ups' managing members has not\nbeen thoroughly explored. We design an incremental representation learning\nmechanism and a sequential learning model, utilizing the network structure\ntogether with the rich attributes of the nodes. In general, our method achieves\nthe state-of-the-art prediction performance on a comprehensive dataset of\nglobal venture capital investments and surpasses human investors by large\nmargins. Specifically, it excels at predicting the outcomes for start-ups in\nindustries such as healthcare and IT. Meanwhile, we shed light on impacts on\nstart-up success from observable factors including gender, education, and\nnetworking, which can be of value for practitioners as well as policy makers\nwhen they screen ventures of high growth potentials.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 14:29:45 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Lyu", "Shiwei", ""], ["Ling", "Shuai", ""], ["Guo", "Kaihao", ""], ["Zhang", "Haipeng", ""], ["Zhang", "Kunpeng", ""], ["Hong", "Suting", ""], ["Ke", "Qing", ""], ["Gu", "Jinjie", ""]]}, {"id": "2105.11545", "submitter": "Nasim Baharisangari", "authors": "Nasim Baharisangari, Jean-Rapha\\\"el Gaglione, Daniel Neider, Ufuk\n  Topcu, Zhe Xu", "title": "Uncertainty-Aware Signal Temporal Logic Inference", "comments": "11 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Temporal logic inference is the process of extracting formal descriptions of\nsystem behaviors from data in the form of temporal logic formulas. The existing\ntemporal logic inference methods mostly neglect uncertainties in the data,\nwhich results in limited applicability of such methods in real-world\ndeployments. In this paper, we first investigate the uncertainties associated\nwith trajectories of a system and represent such uncertainties in the form of\ninterval trajectories. We then propose two uncertainty-aware signal temporal\nlogic (STL) inference approaches to classify the undesired behaviors and\ndesired behaviors of a system. Instead of classifying finitely many\ntrajectories, we classify infinitely many trajectories within the interval\ntrajectories. In the first approach, we incorporate robust semantics of STL\nformulas with respect to an interval trajectory to quantify the margin at which\nan STL formula is satisfied or violated by the interval trajectory. The second\napproach relies on the first learning algorithm and exploits the decision tree\nto infer STL formulas to classify behaviors of a given system. The proposed\napproaches also work for non-separable data by optimizing the worst-case\nrobustness in inferring an STL formula. Finally, we evaluate the performance of\nthe proposed algorithms in two case studies, where the proposed algorithms show\nreductions in the computation time by up to four orders of magnitude in\ncomparison with the sampling-based baseline algorithms (for a dataset with 800\nsampled trajectories in total).\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 21:26:57 GMT"}, {"version": "v2", "created": "Sun, 30 May 2021 17:02:42 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Baharisangari", "Nasim", ""], ["Gaglione", "Jean-Rapha\u00ebl", ""], ["Neider", "Daniel", ""], ["Topcu", "Ufuk", ""], ["Xu", "Zhe", ""]]}, {"id": "2105.11549", "submitter": "Hongjing Zhang", "authors": "Hongjing Zhang, Ian Davidson", "title": "Deep Descriptive Clustering", "comments": "Paper accepted at IJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on explainable clustering allows describing clusters when the\nfeatures are interpretable. However, much modern machine learning focuses on\ncomplex data such as images, text, and graphs where deep learning is used but\nthe raw features of data are not interpretable. This paper explores a novel\nsetting for performing clustering on complex data while simultaneously\ngenerating explanations using interpretable tags. We propose deep descriptive\nclustering that performs sub-symbolic representation learning on complex data\nwhile generating explanations based on symbolic data. We form good clusters by\nmaximizing the mutual information between empirical distribution on the inputs\nand the induced clustering labels for clustering objectives. We generate\nexplanations by solving an integer linear programming that generates concise\nand orthogonal descriptions for each cluster. Finally, we allow the explanation\nto inform better clustering by proposing a novel pairwise loss with\nself-generated constraints to maximize the clustering and explanation module's\nconsistency. Experimental results on public data demonstrate that our model\noutperforms competitive baselines in clustering performance while offering\nhigh-quality cluster-level explanations.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 21:40:16 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Zhang", "Hongjing", ""], ["Davidson", "Ian", ""]]}, {"id": "2105.11589", "submitter": "Karthik Gopalakrishnan", "authors": "Ayush Shrivastava, Karthik Gopalakrishnan, Yang Liu, Robinson\n  Piramuthu, Gokhan T\\\"ur, Devi Parikh, Dilek Hakkani-T\\\"ur", "title": "VISITRON: Visual Semantics-Aligned Interactively Trained\n  Object-Navigator", "comments": "Accepted at NAACL 2021, Visually Grounded Interaction and Language\n  (ViGIL) Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive robots navigating photo-realistic environments face challenges\nunderlying vision-and-language navigation (VLN), but in addition, they need to\nbe trained to handle the dynamic nature of dialogue. However, research in\nCooperative Vision-and-Dialog Navigation (CVDN), where a navigator interacts\nwith a guide in natural language in order to reach a goal, treats the dialogue\nhistory as a VLN-style static instruction. In this paper, we present VISITRON,\na navigator better suited to the interactive regime inherent to CVDN by being\ntrained to: i) identify and associate object-level concepts and semantics\nbetween the environment and dialogue history, ii) identify when to interact vs.\nnavigate via imitation learning of a binary classification head. We perform\nextensive ablations with VISITRON to gain empirical insights and improve\nperformance on CVDN. VISITRON is competitive with models on the static CVDN\nleaderboard. We also propose a generalized interactive regime to fine-tune and\nevaluate VISITRON and future such models with pre-trained guides for\nadaptability.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 00:21:54 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Shrivastava", "Ayush", ""], ["Gopalakrishnan", "Karthik", ""], ["Liu", "Yang", ""], ["Piramuthu", "Robinson", ""], ["T\u00fcr", "Gokhan", ""], ["Parikh", "Devi", ""], ["Hakkani-T\u00fcr", "Dilek", ""]]}, {"id": "2105.11593", "submitter": "Guohua Xin", "authors": "Guangquan Xu, GuoHua Xin, Litao Jiao, Jian Liu, Shaoying Liu, Meiqi\n  Feng, and Xi Zheng", "title": "OFEI: A Semi-black-box Android Adversarial Sample Attack Framework\n  Against DLaaS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing popularity of Android devices, Android malware is seriously\nthreatening the safety of users. Although such threats can be detected by deep\nlearning as a service (DLaaS), deep neural networks as the weakest part of\nDLaaS are often deceived by the adversarial samples elaborated by attackers. In\nthis paper, we propose a new semi-black-box attack framework called\none-feature-each-iteration (OFEI) to craft Android adversarial samples. This\nframework modifies as few features as possible and requires less classifier\ninformation to fool the classifier. We conduct a controlled experiment to\nevaluate our OFEI framework by comparing it with the benchmark methods JSMF,\nGenAttack and pointwise attack. The experimental results show that our OFEI has\na higher misclassification rate of 98.25%. Furthermore, OFEI can extend the\ntraditional white-box attack methods in the image field, such as fast gradient\nsign method (FGSM) and DeepFool, to craft adversarial samples for Android.\nFinally, to enhance the security of DLaaS, we use two uncertainties of the\nBayesian neural network to construct the combined uncertainty, which is used to\ndetect adversarial samples and achieves a high detection rate of 99.28%.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 01:02:05 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Xu", "Guangquan", ""], ["Xin", "GuoHua", ""], ["Jiao", "Litao", ""], ["Liu", "Jian", ""], ["Liu", "Shaoying", ""], ["Feng", "Meiqi", ""], ["Zheng", "Xi", ""]]}, {"id": "2105.11601", "submitter": "Lei Li", "authors": "Lei Li, Yongfeng Zhang, Li Chen", "title": "Personalized Transformer for Explainable Recommendation", "comments": "Published as a conference paper at ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Personalization of natural language generation plays a vital role in a large\nspectrum of tasks, such as explainable recommendation, review summarization and\ndialog systems. In these tasks, user and item IDs are important identifiers for\npersonalization. Transformer, which is demonstrated with strong language\nmodeling capability, however, is not personalized and fails to make use of the\nuser and item IDs since the ID tokens are not even in the same semantic space\nas the words. To address this problem, we present a PErsonalized Transformer\nfor Explainable Recommendation (PETER), on which we design a simple and\neffective learning objective that utilizes the IDs to predict the words in the\ntarget explanation, so as to endow the IDs with linguistic meanings and to\nachieve personalized Transformer. Besides generating explanations, PETER can\nalso make recommendations, which makes it a unified model for the whole\nrecommendation-explanation pipeline. Extensive experiments show that our small\nunpretrained model outperforms fine-tuned BERT on the generation task, in terms\nof both effectiveness and efficiency, which highlights the importance and the\nnice utility of our design.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 01:42:47 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 01:19:31 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Li", "Lei", ""], ["Zhang", "Yongfeng", ""], ["Chen", "Li", ""]]}, {"id": "2105.11611", "submitter": "Zijian Gao", "authors": "Zijian Gao, Kele Xu, Bo Ding, Huaimin Wang, Yiying Li, Hongda Jia", "title": "KnowSR: Knowledge Sharing among Homogeneous Agents in Multi-agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep reinforcement learning (RL) algorithms have made great\nprogress in multi-agent domain. However, due to characteristics of RL, training\nfor complex tasks would be resource-intensive and time-consuming. To meet this\nchallenge, mutual learning strategy between homogeneous agents is essential,\nwhich is under-explored in previous studies, because most existing methods do\nnot consider to use the knowledge of agent models. In this paper, we present an\nadaptation method of the majority of multi-agent reinforcement learning (MARL)\nalgorithms called KnowSR which takes advantage of the differences in learning\nbetween agents. We employ the idea of knowledge distillation (KD) to share\nknowledge among agents to shorten the training phase. To empirically\ndemonstrate the robustness and effectiveness of KnowSR, we performed extensive\nexperiments on state-of-the-art MARL algorithms in collaborative and\ncompetitive scenarios. The results demonstrate that KnowSR outperforms recently\nreported methodologies, emphasizing the importance of the proposed knowledge\nsharing for MARL.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 02:19:41 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Gao", "Zijian", ""], ["Xu", "Kele", ""], ["Ding", "Bo", ""], ["Wang", "Huaimin", ""], ["Li", "Yiying", ""], ["Jia", "Hongda", ""]]}, {"id": "2105.11617", "submitter": "Amartya Mukherjee", "authors": "Amartya Mukherjee", "title": "A Comparison of Reward Functions in Q-Learning Applied to a Cart\n  Position Problem", "comments": "19 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO math.OC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Growing advancements in reinforcement learning has led to advancements in\ncontrol theory. Reinforcement learning has effectively solved the inverted\npendulum problem and more recently the double inverted pendulum problem. In\nreinforcement learning, our agents learn by interacting with the control system\nwith the goal of maximizing rewards. In this paper, we explore three such\nreward functions in the cart position problem. This paper concludes that a\ndiscontinuous reward function that gives non-zero rewards to agents only if\nthey are within a given distance from the desired position gives the best\nresults.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 02:26:01 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Mukherjee", "Amartya", ""]]}, {"id": "2105.11654", "submitter": "Jianhao Ding", "authors": "Jianhao Ding, Zhaofei Yu, Yonghong Tian and Tiejun Huang", "title": "Optimal ANN-SNN Conversion for Fast and Accurate Inference in Deep\n  Spiking Neural Networks", "comments": "9 pages, 7 figures, 2 tables. To appear in the 30th International\n  Joint Conference on Artificial Intelligence (IJCAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural Networks (SNNs), as bio-inspired energy-efficient neural\nnetworks, have attracted great attentions from researchers and industry. The\nmost efficient way to train deep SNNs is through ANN-SNN conversion. However,\nthe conversion usually suffers from accuracy loss and long inference time,\nwhich impede the practical application of SNN. In this paper, we theoretically\nanalyze ANN-SNN conversion and derive sufficient conditions of the optimal\nconversion. To better correlate ANN-SNN and get greater accuracy, we propose\nRate Norm Layer to replace the ReLU activation function in source ANN training,\nenabling direct conversion from a trained ANN to an SNN. Moreover, we propose\nan optimal fit curve to quantify the fit between the activation value of source\nANN and the actual firing rate of target SNN. We show that the inference time\ncan be reduced by optimizing the upper bound of the fit curve in the revised\nANN to achieve fast inference. Our theory can explain the existing work on fast\nreasoning and get better results. The experimental results show that the\nproposed method achieves near loss less conversion with VGG-16,\nPreActResNet-18, and deeper structures. Moreover, it can reach 8.6x faster\nreasoning performance under 0.265x energy consumption of the typical method.\nThe code is available at\nhttps://github.com/DingJianhao/OptSNNConvertion-RNL-RIL.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 04:15:06 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Ding", "Jianhao", ""], ["Yu", "Zhaofei", ""], ["Tian", "Yonghong", ""], ["Huang", "Tiejun", ""]]}, {"id": "2105.11674", "submitter": "Andrea Baisero", "authors": "Andrea Baisero and Christopher Amato", "title": "Unbiased Asymmetric Actor-Critic for Partially Observable Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In partially observable reinforcement learning, offline training gives access\nto latent information which is not available during online training and/or\nexecution, such as the system state. Asymmetric actor-critic methods exploit\nsuch information by training a history-based policy via a state-based critic.\nHowever, many asymmetric methods lack theoretical foundation, and are only\nevaluated on limited domains. We examine the theory of asymmetric actor-critic\nmethods which use state-based critics, and expose fundamental issues which\nundermine the validity of a common variant, and its ability to address high\npartial observability. We propose an unbiased asymmetric actor-critic variant\nwhich is able to exploit state information while remaining theoretically sound,\nmaintaining the validity of the policy gradient theorem, and introducing no\nbias and relatively low variance into the training process. An empirical\nevaluation performed on domains which exhibit significant partial observability\nconfirms our analysis, and shows the unbiased asymmetric actor-critic converges\nto better policies and/or faster than symmetric actor-critic and standard\nasymmetric actor-critic baselines.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 05:18:44 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Baisero", "Andrea", ""], ["Amato", "Christopher", ""]]}, {"id": "2105.11686", "submitter": "Hanxu Zhou", "authors": "Zhi-Qin John Xu, Hanxu Zhou, Tao Luo, Yaoyu Zhang", "title": "Towards Understanding the Condensation of Two-layer Neural Networks at\n  Initial Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  It is important to study what implicit regularization is imposed on the loss\nfunction during the training that leads over-parameterized neural networks\n(NNs) to good performance on real dataset. Empirically, existing works have\nshown that weights of NNs condense on isolated orientations with small\ninitialization. The condensation implies that the NN learns features from the\ntraining data and is effectively a much smaller network. In this work, we show\nthat the singularity of the activation function at original point is a key\nfactor to understanding the condensation at initial training stage. Our\nexperiments suggest that the maximal number of condensed orientations is twice\nof the singularity order. Our theoretical analysis confirms experiments for two\ncases, one is for the first-order singularity activation function and the other\nis for the one-dimensional input. This work takes a step towards understanding\nhow small initialization implicitly leads NNs to condensation at initial\ntraining, which is crucial to understand the training and the learning of deep\nNNs.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 05:47:55 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 04:23:57 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Xu", "Zhi-Qin John", ""], ["Zhou", "Hanxu", ""], ["Luo", "Tao", ""], ["Zhang", "Yaoyu", ""]]}, {"id": "2105.11694", "submitter": "Jihao Liu", "authors": "Jihao Liu and Ming Zhang and Yangting Sun and Boxiao Liu and Guanglu\n  Song and Yu Liu and Hongsheng Li", "title": "FNAS: Uncertainty-Aware Fast Neural Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL)-based neural architecture search (NAS) generally\nguarantees better convergence yet suffers from the requirement of huge\ncomputational resources compared with gradient-based approaches, due to the\nrollout bottleneck -- exhaustive training for each sampled generation on proxy\ntasks. In this paper, we propose a general pipeline to accelerate the\nconvergence of the rollout process as well as the RL process in NAS. It is\nmotivated by the interesting observation that both the architecture and the\nparameter knowledge can be transferred between different experiments and even\ndifferent tasks. We first introduce an uncertainty-aware critic (value\nfunction) in Proximal Policy Optimization (PPO) to utilize the architecture\nknowledge in previous experiments, which stabilizes the training process and\nreduces the searching time by 4 times. Further, an architecture knowledge pool\ntogether with a block similarity function is proposed to utilize parameter\nknowledge and reduces the searching time by 2 times. It is the first to\nintroduce block-level weight sharing in RLbased NAS. The block similarity\nfunction guarantees a 100% hitting ratio with strict fairness. Besides, we show\nthat a simply designed off-policy correction factor used in \"replay buffer\" in\nRL optimization can further reduce half of the searching time. Experiments on\nthe Mobile Neural Architecture Search (MNAS) search space show the proposed\nFast Neural Architecture Search (FNAS) accelerates standard RL-based NAS\nprocess by ~10x (e.g. ~256 2x2 TPUv2 x days / 20,000 GPU x hour -> 2,000 GPU x\nhour for MNAS), and guarantees better performance on various vision tasks.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 06:32:52 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 10:36:28 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 07:53:59 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Liu", "Jihao", ""], ["Zhang", "Ming", ""], ["Sun", "Yangting", ""], ["Liu", "Boxiao", ""], ["Song", "Guanglu", ""], ["Liu", "Yu", ""], ["Li", "Hongsheng", ""]]}, {"id": "2105.11697", "submitter": "Pietro Barbiero", "authors": "Pietro Barbiero, Gabriele Ciravegna, Dobrik Georgiev, Franscesco\n  Giannini", "title": "PyTorch, Explain! A Python library for Logic Explained Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  \"PyTorch, Explain!\" is a Python module integrating a variety of\nstate-of-the-art approaches to provide logic explanations from neural networks.\nThis package focuses on bringing these methods to non-specialists. It has\nminimal dependencies and it is distributed under the Apache 2.0 licence\nallowing both academic and commercial use. Source code and documentation can be\ndownloaded from the github repository:\nhttps://github.com/pietrobarbiero/pytorch_explain.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 06:41:54 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 11:22:28 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Barbiero", "Pietro", ""], ["Ciravegna", "Gabriele", ""], ["Georgiev", "Dobrik", ""], ["Giannini", "Franscesco", ""]]}, {"id": "2105.11698", "submitter": "Yi Cheng", "authors": "Yi Cheng, Siyao Li, Bang Liu, Ruihui Zhao, Sujian Li, Chenghua Lin and\n  Yefeng Zheng", "title": "Guiding the Growth: Difficulty-Controllable Question Generation through\n  Step-by-Step Rewriting", "comments": "Accepted by ACL 2021 (long paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the task of Difficulty-Controllable Question Generation\n(DCQG), which aims at generating questions with required difficulty levels.\nPrevious research on this task mainly defines the difficulty of a question as\nwhether it can be correctly answered by a Question Answering (QA) system,\nlacking interpretability and controllability. In our work, we redefine question\ndifficulty as the number of inference steps required to answer it and argue\nthat Question Generation (QG) systems should have stronger control over the\nlogic of generated questions. To this end, we propose a novel framework that\nprogressively increases question difficulty through step-by-step rewriting\nunder the guidance of an extracted reasoning chain. A dataset is automatically\nconstructed to facilitate the research, on which extensive experiments are\nconducted to test the performance of our method.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 06:43:13 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Cheng", "Yi", ""], ["Li", "Siyao", ""], ["Liu", "Bang", ""], ["Zhao", "Ruihui", ""], ["Li", "Sujian", ""], ["Lin", "Chenghua", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2105.11702", "submitter": "Zhao Yang", "authors": "Zhao Yang, Mike Preuss, Aske Plaat", "title": "Transfer Learning and Curriculum Learning in Sokoban", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Transfer learning can speed up training in machine learning and is regularly\nused in classification tasks. It reuses prior knowledge from other tasks to\npre-train networks for new tasks. In reinforcement learning, learning actions\nfor a behavior policy that can be applied to new environments is still a\nchallenge, especially for tasks that involve much planning. Sokoban is a\nchallenging puzzle game. It has been used widely as a benchmark in\nplanning-based reinforcement learning. In this paper, we show how prior\nknowledge improves learning in Sokoban tasks. We find that reusing feature\nrepresentations learned previously can accelerate learning new, more complex,\ninstances. In effect, we show how curriculum learning, from simple to complex\ntasks, works in Sokoban. Furthermore, feature representations learned in\nsimpler instances are more general, and thus lead to positive transfers towards\nmore complex tasks, but not vice versa. We have also studied which part of the\nknowledge is most important for transfer to succeed, and identify which layers\nshould be used for pre-training.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 07:01:32 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Yang", "Zhao", ""], ["Preuss", "Mike", ""], ["Plaat", "Aske", ""]]}, {"id": "2105.11730", "submitter": "Jinyang Liu", "authors": "Jinyang Liu, Sheng Di, Kai Zhao, Sian Jin, Dingwen Tao, Xin Liang,\n  Zizhong Chen, Franck Cappello", "title": "Exploring Autoencoder-based Error-bounded Compression for Scientific\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Error-bounded lossy compression is becoming an indispensable technique for\nthe success of today's scientific projects with vast volumes of data produced\nduring the simulations or instrument data acquisitions. Not only can it\nsignificantly reduce data size, but it also can control the compression errors\nbased on user-specified error bounds. Autoencoder (AE) models have been widely\nused in image compression, but few AE-based compression approaches support\nerror-bounding features, which are highly required by scientific applications.\nTo address this issue, we explore using convolutional autoencoders to improve\nerror-bounded lossy compression for scientific data, with the following three\nkey contributions. (1) We provide an in-depth investigation of the\ncharacteristics of various autoencoder models and develop an error-bounded\nautoencoder-based framework in terms of the SZ model. (2) We optimize the\ncompression quality for main stages in our designed AE-based error-bounded\ncompression framework, fine-tuning the block sizes and latent sizes and also\noptimizing the compression efficiency of latent vectors. (3) We evaluate our\nproposed solution using five real-world scientific datasets and comparing them\nwith six other related works. Experiments show that our solution exhibits a\nvery competitive compression quality from among all the compressors in our\ntests. In absolute terms, it can obtain a much better compression quality (100%\n~ 800% improvement in compression ratio with the same data distortion) compared\nwith SZ2.1 and ZFP in cases with a high compression ratio.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 07:53:32 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 22:15:29 GMT"}, {"version": "v3", "created": "Tue, 20 Jul 2021 03:07:52 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Liu", "Jinyang", ""], ["Di", "Sheng", ""], ["Zhao", "Kai", ""], ["Jin", "Sian", ""], ["Tao", "Dingwen", ""], ["Liang", "Xin", ""], ["Chen", "Zizhong", ""], ["Cappello", "Franck", ""]]}, {"id": "2105.11734", "submitter": "Robin Brochier", "authors": "Robin Brochier, Fr\\'ed\\'eric B\\'echet", "title": "Predicting Links on Wikipedia with Anchor Text Information", "comments": "ACM SIGIR Conference on Research and Development in Information\n  Retrieval, Jul 2021, New York, France", "journal-ref": null, "doi": "10.1145/3404835.3462994", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia, the largest open-collaborative online encyclopedia, is a corpus of\ndocuments bound together by internal hyperlinks. These links form the building\nblocks of a large network whose structure contains important information on the\nconcepts covered in this encyclopedia. The presence of a link between two\narticles, materialised by an anchor text in the source page pointing to the\ntarget page, can increase readers' understanding of a topic. However, the\nprocess of linking follows specific editorial rules to avoid both under-linking\nand over-linking. In this paper, we study the transductive and the inductive\ntasks of link prediction on several subsets of the English Wikipedia and\nidentify some key challenges behind automatic linking based on anchor text\ninformation. We propose an appropriate evaluation sampling methodology and\ncompare several algorithms. Moreover, we propose baseline models that provide a\ngood estimation of the overall difficulty of the tasks.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 07:57:57 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Brochier", "Robin", ""], ["B\u00e9chet", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2105.11738", "submitter": "Gwendal Simon", "authors": "Massimo Gallo, Alessandro Finamore, Gwendal Simon, and Dario Rossi", "title": "FENXI: Deep-learning Traffic Analytics at the Edge", "comments": "14 pages, 12 figures. Accepted for publication at the Sixth ACM/IEEE\n  Symposium on Edge Computing (SEC'21), December 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Live traffic analysis at the first aggregation point in the ISP network\nenables the implementation of complex traffic engineering policies but is\nlimited by the scarce processing capabilities, especially for Deep Learning\n(DL) based analytics. The introduction of specialized hardware accelerators\ni.e., Tensor Processing Unit (TPU), offers the opportunity to enhance the\nprocessing capabilities of network devices at the edge. Yet, to date, no packet\nprocessing pipeline is capable of offering DL-based analysis capabilities in\nthe data-plane, without interfering with network operations.\n  In this paper, we present FENXI, a system to run complex analytics by\nleveraging TPU. The design of FENXI decouples forwarding operations and traffic\nanalytics which operates at different granularities i.e., packet and flow\nlevels. We conceive two independent modules that asynchronously communicate to\nexchange network data and analytics results, and design data structures to\nextract flow level statistics without impacting per-packet processing. We\nprototyped and evaluated FENXI on general-purpose servers considering both\nadversarial and realistic network conditions. Our analysis shows that FENXI can\nsustain 100 Gbps line rate traffic processing requiring only limited resources,\nwhile also dynamically adapting to variable network conditions.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 08:02:44 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Gallo", "Massimo", ""], ["Finamore", "Alessandro", ""], ["Simon", "Gwendal", ""], ["Rossi", "Dario", ""]]}, {"id": "2105.11741", "submitter": "Yuanmeng Yan", "authors": "Yuanmeng Yan, Rumei Li, Sirui Wang, Fuzheng Zhang, Wei Wu and Weiran\n  Xu", "title": "ConSERT: A Contrastive Framework for Self-Supervised Sentence\n  Representation Transfer", "comments": "Accepted by ACL2021, 10 pages, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning high-quality sentence representations benefits a wide range of\nnatural language processing tasks. Though BERT-based pre-trained language\nmodels achieve high performance on many downstream tasks, the native derived\nsentence representations are proved to be collapsed and thus produce a poor\nperformance on the semantic textual similarity (STS) tasks. In this paper, we\npresent ConSERT, a Contrastive Framework for Self-Supervised Sentence\nRepresentation Transfer, that adopts contrastive learning to fine-tune BERT in\nan unsupervised and effective way. By making use of unlabeled texts, ConSERT\nsolves the collapse issue of BERT-derived sentence representations and make\nthem more applicable for downstream tasks. Experiments on STS datasets\ndemonstrate that ConSERT achieves an 8\\% relative improvement over the previous\nstate-of-the-art, even comparable to the supervised SBERT-NLI. And when further\nincorporating NLI supervision, we achieve new state-of-the-art performance on\nSTS tasks. Moreover, ConSERT obtains comparable results with only 1000 samples\navailable, showing its robustness in data scarcity scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 08:15:01 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Yan", "Yuanmeng", ""], ["Li", "Rumei", ""], ["Wang", "Sirui", ""], ["Zhang", "Fuzheng", ""], ["Wu", "Wei", ""], ["Xu", "Weiran", ""]]}, {"id": "2105.11763", "submitter": "Emilio Gamba", "authors": "Emilio Gamba, Bart Bogaerts and Tias Guns", "title": "Efficiently Explaining CSPs with Unsatisfiable Subset Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We build on a recently proposed method for explaining solutions of constraint\nsatisfaction problems. An explanation here is a sequence of simple inference\nsteps, where the simplicity of an inference step is measured by the number and\ntypes of constraints and facts used, and where the sequence explains all\nlogical consequences of the problem. We build on these formal foundations and\ntackle two emerging questions, namely how to generate explanations that are\nprovably optimal (with respect to the given cost metric) and how to generate\nthem efficiently. To answer these questions, we develop 1) an implicit hitting\nset algorithm for finding optimal unsatisfiable subsets; 2) a method to reduce\nmultiple calls for (optimal) unsatisfiable subsets to a single call that takes\nconstraints on the subset into account, and 3) a method for re-using relevant\ninformation over multiple calls to these algorithms. The method is also\napplicable to other problems that require finding cost-optimal unsatiable\nsubsets. We specifically show that this approach can be used to effectively\nfind sequences of optimal explanation steps for constraint satisfaction\nproblems like logic grid puzzles.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 08:57:43 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 15:32:09 GMT"}, {"version": "v3", "created": "Thu, 17 Jun 2021 15:45:09 GMT"}, {"version": "v4", "created": "Mon, 5 Jul 2021 08:39:04 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Gamba", "Emilio", ""], ["Bogaerts", "Bart", ""], ["Guns", "Tias", ""]]}, {"id": "2105.11798", "submitter": "Carlos Basto", "authors": "Carlos Basto", "title": "Extending the Abstraction of Personality Types based on MBTI with\n  Machine Learning and Natural Language Processing", "comments": "23 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A data-centric approach with Natural Language Processing (NLP) to predict\npersonality types based on the MBTI (an introspective self-assessment\nquestionnaire that indicates different psychological preferences about how\npeople perceive the world and make decisions) through systematic enrichment of\ntext representation, based on the domain of the area, under the generation of\nfeatures based on three types of analysis: sentimental, grammatical and\naspects. The experimentation had a robust baseline of stacked models, with\npremature optimization of hyperparameters through grid search, with gradual\nfeedback, for each of the four classifiers (dichotomies) of MBTI. The results\nshowed that attention to the data iteration loop focused on quality,\nexplanatory power and representativeness for the abstraction of more\nrelevant/important resources for the studied phenomenon made it possible to\nimprove the evaluation metrics results more quickly and less costly than\ncomplex models such as the LSTM or state of the art ones as BERT, as well as\nthe importance of these results by comparisons made from various perspectives.\nIn addition, the study demonstrated a broad spectrum for the evolution and\ndeepening of the task and possible approaches for a greater extension of the\nabstraction of personality types.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 10:00:16 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Basto", "Carlos", ""]]}, {"id": "2105.11828", "submitter": "Dominik Seu{\\ss}", "authors": "Dominik Seu{\\ss}", "title": "Bridging the Gap Between Explainable AI and Uncertainty Quantification\n  to Enhance Trustability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After the tremendous advances of deep learning and other AI methods, more\nattention is flowing into other properties of modern approaches, such as\ninterpretability, fairness, etc. combined in frameworks like Responsible AI.\nTwo research directions, namely Explainable AI and Uncertainty Quantification\nare becoming more and more important, but have been so far never combined and\njointly explored. In this paper, I show how both research areas provide\npotential for combination, why more research should be done in this direction\nand how this would lead to an increase in trustability in AI systems.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 10:53:58 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Seu\u00df", "Dominik", ""]]}, {"id": "2105.11844", "submitter": "Francisco P\\'erez-Hern\\'andez", "authors": "P\\'erez-Hern\\'andez Francisco, Rodr\\'iguez-Ortega Jos\\'e, Benhammou\n  Yassir, Herrera Francisco, Tabik Siham", "title": "Small and large scale critical infrastructures detection based on deep\n  learning using high resolution orthogonal images", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The detection of critical infrastructures is of high importance in several\nfields such as security, anomaly detection, land use planning and land use\nchange detection. However, critical infrastructures detection in aerial and\nsatellite images is still a challenge as each one has completely different size\nand requires different spacial resolution to be identified correctly.\nHeretofore, there are no special datasets for training critical infrastructures\ndetectors. This paper presents a smart dataset as well as a\nresolution-independent critical infrastructure detection system. In particular,\nguided by the performance of the detection model, we built a dataset organized\ninto two scales, small and large scale, and designed a two-stage deep learning\ndetection of different scale critical infrastructures (DetDSCI) methodology in\northo-images. DetDSCI methodology first determines the input image zoom level\nusing a classification model, then analyses the input image with the\nappropriate scale detection model. Our experiments show that DetDSCI\nmethodology achieves up to 37,53% F1 improvement with respect to the baseline\ndetector.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 11:38:15 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Francisco", "P\u00e9rez-Hern\u00e1ndez", ""], ["Jos\u00e9", "Rodr\u00edguez-Ortega", ""], ["Yassir", "Benhammou", ""], ["Francisco", "Herrera", ""], ["Siham", "Tabik", ""]]}, {"id": "2105.11864", "submitter": "Timo Bertram", "authors": "Timo Bertram, Johannes F\\\"urnkranz, Martin M\\\"uller", "title": "Predicting Human Card Selection in Magic: The Gathering with Contextual\n  Preference Ranking", "comments": "IEEE Conference on Games 2021 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drafting, i.e., the selection of a subset of items from a larger candidate\nset, is a key element of many games and related problems. It encompasses team\nformation in sports or e-sports, as well as deck selection in many modern card\ngames. The key difficulty of drafting is that it is typically not sufficient to\nsimply evaluate each item in a vacuum and to select the best items. The\nevaluation of an item depends on the context of the set of items that were\nalready selected earlier, as the value of a set is not just the sum of the\nvalues of its members - it must include a notion of how well items go together.\n  In this paper, we study drafting in the context of the card game Magic: The\nGathering. We propose the use of a contextual preference network, which learns\nto compare two possible extensions of a given deck of cards. We demonstrate\nthat the resulting network is better able to evaluate card decks in this game\nthan previous attempts.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 12:07:27 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 10:15:47 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Bertram", "Timo", ""], ["F\u00fcrnkranz", "Johannes", ""], ["M\u00fcller", "Martin", ""]]}, {"id": "2105.11866", "submitter": "Zekun Li", "authors": "Zekun Li, Shu Wu, Zeyu Cui, Xiaoyu Zhang", "title": "GraphFM: Graph Factorization Machines for Feature Interaction Modeling", "comments": "submitted to tkde", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Factorization machine (FM) is a prevalent approach to modeling pairwise\n(second-order) feature interactions when dealing with high-dimensional sparse\ndata. However, on the one hand, FM fails to capture higher-order feature\ninteractions suffering from combinatorial expansion, on the other hand, taking\ninto account interaction between every pair of features may introduce noise and\ndegrade prediction accuracy. To solve the problems, we propose a novel approach\nGraph Factorization Machine (GraphFM) by naturally representing features in the\ngraph structure. In particular, a novel mechanism is designed to select the\nbeneficial feature interactions and formulate them as edges between features.\nThen our proposed model which integrates the interaction function of FM into\nthe feature aggregation strategy of Graph Neural Network (GNN), can model\narbitrary-order feature interactions on the graph-structured features by\nstacking layers. Experimental results on several real-world datasets has\ndemonstrated the rationality and effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 12:10:54 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 09:33:33 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Li", "Zekun", ""], ["Wu", "Shu", ""], ["Cui", "Zeyu", ""], ["Zhang", "Xiaoyu", ""]]}, {"id": "2105.11877", "submitter": "Achintha Ihalage", "authors": "Achintha Ihalage and Yang Hao", "title": "Analogical discovery of disordered perovskite oxides by crystal\n  structure information hidden in unsupervised material fingerprints", "comments": null, "journal-ref": "npj Comput Mater 7, 75 (2021)", "doi": "10.1038/s41524-021-00536-2", "report-no": null, "categories": "cond-mat.mtrl-sci cond-mat.dis-nn cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Compositional disorder induces myriad captivating phenomena in perovskites.\nTarget-driven discovery of perovskite solid solutions has been a great\nchallenge due to the analytical complexity introduced by disorder. Here, we\ndemonstrate that an unsupervised deep learning strategy can find fingerprints\nof disordered materials that embed perovskite formability and underlying\ncrystal structure information by learning only from the chemical composition,\nmanifested in (A1-xA'x)BO3 and A(B1-xB'x)O3 formulae. This phenomenon can be\ncapitalized to predict the crystal symmetry of experimental compositions,\noutperforming several supervised machine learning (ML) algorithms. The educated\nnature of material fingerprints has led to the conception of analogical\nmaterials discovery that facilitates inverse exploration of promising\nperovskites based on similarity investigation with known materials. The search\nspace of unstudied perovskites is screened from ~600,000 feasible compounds\nusing experimental data powered ML models and automated web mining tools at a\n94% success rate. This concept further provides insights on possible phase\ntransitions and computational modelling of complex compositions. The proposed\nquantitative analysis of materials analogies is expected to bridge the gap\nbetween the existing materials literature and the undiscovered terrain.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 12:25:53 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Ihalage", "Achintha", ""], ["Hao", "Yang", ""]]}, {"id": "2105.11888", "submitter": "Saman Ahmadi", "authors": "Saman Ahmadi, Guido Tack, Daniel Harabor, Philip Kilby", "title": "Bi-objective Search with Bi-directional A*", "comments": "16 pages, 4 figures, in Proceedings of The European Symposium on\n  Algorithms 2021 (ESA21), Changes: including the backward search of BOBA*", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bi-objective search is a well-known algorithmic problem, concerned with\nfinding a set of optimal solutions in a two-dimensional domain. This problem\nhas a wide variety of applications such as planning in transport systems or\noptimal control in energy systems. Recently, bi-objective A*-based search\n(BOA*) has shown state-of-the-art performance in large networks. This paper\ndevelops a bi-directional and parallel variant of BOA*, enriched with several\nspeed-up heuristics. Our experimental results on 1,000 benchmark cases show\nthat our bi-directional A* algorithm for bi-objective search (BOBA*) can\noptimally solve all of the benchmark cases within the time limit, outperforming\nthe state of the art BOA*, bi-objective Dijkstra and bi-directional\nbi-objective Dijkstra by an average runtime improvement of a factor of five\nover all of the benchmark instances.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 12:46:25 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 04:32:30 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Ahmadi", "Saman", ""], ["Tack", "Guido", ""], ["Harabor", "Daniel", ""], ["Kilby", "Philip", ""]]}, {"id": "2105.11903", "submitter": "Yanran Li", "authors": "Yanran Li and Ke Li and Hongke Ning and xiaoqiang Xia and Yalong Guo\n  and Chen Wei and Jianwei Cui and Bin Wang", "title": "Towards an Online Empathetic Chatbot with Emotion Causes", "comments": "SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3463042", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Existing emotion-aware conversational models usually focus on controlling the\nresponse contents to align with a specific emotion class, whereas empathy is\nthe ability to understand and concern the feelings and experience of others.\nHence, it is critical to learn the causes that evoke the users' emotion for\nempathetic responding, a.k.a. emotion causes. To gather emotion causes in\nonline environments, we leverage counseling strategies and develop an\nempathetic chatbot to utilize the causal emotion information. On a real-world\nonline dataset, we verify the effectiveness of the proposed approach by\ncomparing our chatbot with several SOTA methods using automatic metrics,\nexpert-based human judgements as well as user-based online evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 02:52:46 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Li", "Yanran", ""], ["Li", "Ke", ""], ["Ning", "Hongke", ""], ["Xia", "xiaoqiang", ""], ["Guo", "Yalong", ""], ["Wei", "Chen", ""], ["Cui", "Jianwei", ""], ["Wang", "Bin", ""]]}, {"id": "2105.11904", "submitter": "Yongbin Liu", "authors": "Qing Lin, Yongbin Liu, Wen Wen, Zhihua Tao", "title": "Ensemble Making Few-Shot Learning Stronger", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning has been proposed and rapidly emerging as a viable means\nfor completing various tasks. Many few-shot models have been widely used for\nrelation learning tasks. However, each of these models has a shortage of\ncapturing a certain aspect of semantic features, for example, CNN on long-range\ndependencies part, Transformer on local features. It is difficult for a single\nmodel to adapt to various relation learning, which results in the high variance\nproblem. Ensemble strategy could be competitive on improving the accuracy of\nfew-shot relation extraction and mitigating high variance risks. This paper\nexplores an ensemble approach to reduce the variance and introduces fine-tuning\nand feature attention strategies to calibrate relation-level features. Results\non several few-shot relation learning tasks show that our model significantly\noutperforms the previous state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 17:11:10 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Lin", "Qing", ""], ["Liu", "Yongbin", ""], ["Wen", "Wen", ""], ["Tao", "Zhihua", ""]]}, {"id": "2105.11977", "submitter": "Olivier Sigaud", "authors": "Olivier Sigaud and Hugo Caselles-Dupr\\'e and C\\'edric Colas and Ahmed\n  Akakzia and Pierre-Yves Oudeyer and Mohamed Chetouani", "title": "Towards Teachable Autonomous Agents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Autonomous discovery and direct instruction are two extreme sources of\nlearning in children, but educational sciences have shown that intermediate\napproaches such as assisted discovery or guided play resulted in better\nacquisition of skills. When turning to Artificial Intelligence, the above\ndichotomy is translated into the distinction between autonomous agents which\nlearn in isolation and interactive learning agents which can be taught by\nsocial partners but generally lack autonomy. In between should stand teachable\nautonomous agents: agents learning from both internal and teaching signals to\nbenefit from the higher efficiency of assisted discovery. Such agents could\nlearn on their own in the real world, but non-expert users could drive their\nlearning behavior towards their expectations. More fundamentally, combining\nboth capabilities might also be a key step towards general intelligence. In\nthis paper we elucidate obstacles along this research line. First, we build on\na seminal work of Bruner to extract relevant features of the assisted discovery\nprocesses. Second, we describe current research on autotelic agents, i.e.\nagents equipped with forms of intrinsic motivations that enable them to\nrepresent, self-generate and pursue their own goals. We argue that autotelic\ncapabilities are paving the way towards teachable and autonomous agents.\nFinally, we adopt a social learning perspective on tutoring interactions and we\nhighlight some components that are currently missing to autotelic agents before\nthey can be taught by ordinary people using natural pedagogy, and we provide a\nlist of specific research questions that emerge from this perspective.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 14:28:58 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Sigaud", "Olivier", ""], ["Caselles-Dupr\u00e9", "Hugo", ""], ["Colas", "C\u00e9dric", ""], ["Akakzia", "Ahmed", ""], ["Oudeyer", "Pierre-Yves", ""], ["Chetouani", "Mohamed", ""]]}, {"id": "2105.11982", "submitter": "Xinyue Xiong", "authors": "Dongxia Wu, Liyao Gao, Xinyue Xiong, Matteo Chinazzi, Alessandro\n  Vespignani, Yi-An Ma, Rose Yu", "title": "Quantifying Uncertainty in Deep Spatiotemporal Forecasting", "comments": "arXiv admin note: text overlap with arXiv:2102.06684", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is gaining increasing popularity for spatiotemporal\nforecasting. However, prior works have mostly focused on point estimates\nwithout quantifying the uncertainty of the predictions. In high stakes domains,\nbeing able to generate probabilistic forecasts with confidence intervals is\ncritical to risk assessment and decision making. Hence, a systematic study of\nuncertainty quantification (UQ) methods for spatiotemporal forecasting is\nmissing in the community. In this paper, we describe two types of\nspatiotemporal forecasting problems: regular grid-based and graph-based. Then\nwe analyze UQ methods from both the Bayesian and the frequentist point of view,\ncasting in a unified framework via statistical decision theory. Through\nextensive experiments on real-world road network traffic, epidemics, and air\nquality forecasting tasks, we reveal the statistical and computational\ntrade-offs for different UQ methods: Bayesian methods are typically more robust\nin mean prediction, while confidence levels obtained from frequentist methods\nprovide more extensive coverage over data variations. Computationally, quantile\nregression type methods are cheaper for a single confidence interval but\nrequire re-training for different intervals. Sampling based methods generate\nsamples that can form multiple confidence intervals, albeit at a higher\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 14:35:46 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 12:59:06 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Wu", "Dongxia", ""], ["Gao", "Liyao", ""], ["Xiong", "Xinyue", ""], ["Chinazzi", "Matteo", ""], ["Vespignani", "Alessandro", ""], ["Ma", "Yi-An", ""], ["Yu", "Rose", ""]]}, {"id": "2105.11989", "submitter": "Rushabh Patel", "authors": "Rushabh Patel, Yanhui Guo", "title": "Graph Based Link Prediction between Human Phenotypes and Genes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: The learning of genotype-phenotype associations and history of\nhuman disease by doing detailed and precise analysis of phenotypic\nabnormalities can be defined as deep phenotyping. To understand and detect this\ninteraction between phenotype and genotype is a fundamental step when\ntranslating precision medicine to clinical practice. The recent advances in the\nfield of machine learning is efficient to predict these interactions between\nabnormal human phenotypes and genes.\n  Methods: In this study, we developed a framework to predict links between\nhuman phenotype ontology (HPO) and genes. The annotation data from the\nheterogeneous knowledge resources i.e., orphanet, is used to parse human\nphenotype-gene associations. To generate the embeddings for the nodes (HPO &\ngenes), an algorithm called node2vec was used. It performs node sampling on\nthis graph based on random walks, then learns features over these sampled nodes\nto generate embeddings. These embeddings were used to perform the downstream\ntask to predict the presence of the link between these nodes using 5 different\nsupervised machine learning algorithms.\n  Results: The downstream link prediction task shows that the Gradient Boosting\nDecision Tree based model (LightGBM) achieved an optimal AUROC 0.904 and AUCPR\n0.784. In addition, LightGBM achieved an optimal weighted F1 score of 0.87.\nCompared to the other 4 methods LightGBM is able to find more accurate\ninteraction/link between human phenotype & gene pairs.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 14:47:07 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 18:28:30 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Patel", "Rushabh", ""], ["Guo", "Yanhui", ""]]}, {"id": "2105.12026", "submitter": "Philipp-Jan Honysz", "authors": "Philipp-Jan Honysz and Alexander Schulze-Struchtrup and Sebastian\n  Buschj\\\"ager and Katharina Morik", "title": "Providing Meaningful Data Summarizations Using Exemplar-based Clustering\n  in Industry 4.0", "comments": "arXiv admin note: substantial text overlap with arXiv:2101.08763", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data summarizations are a valuable tool to derive knowledge from large data\nstreams and have proven their usefulness in a great number of applications.\nSummaries can be found by optimizing submodular functions. These functions map\nsubsets of data to real values, which indicate their \"representativeness\" and\nwhich should be maximized to find a diverse summary of the underlying data. In\nthis paper, we studied Exemplar-based clustering as a submodular function and\nprovide a GPU algorithm to cope with its high computational complexity. We\nshow, that our GPU implementation provides speedups of up to 72x using\nsingle-precision and up to 452x using half-precision computation compared to\nconventional CPU algorithms. We also show, that the GPU algorithm not only\nprovides remarkable runtime benefits with workstation-grade GPUs but also with\nlow-power embedded computation units for which speedups of up to 35x are\npossible. Furthermore, we apply our algorithm to real-world data from injection\nmolding manufacturing processes and discuss how found summaries help with\nsteering this specific process to cut costs and reduce the manufacturing of bad\nparts. Beyond pure speedup considerations, we show, that our approach can\nprovide summaries within reasonable time frames for this kind of industrial,\nreal-world data.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 15:55:14 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 21:46:04 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Honysz", "Philipp-Jan", ""], ["Schulze-Struchtrup", "Alexander", ""], ["Buschj\u00e4ger", "Sebastian", ""], ["Morik", "Katharina", ""]]}, {"id": "2105.12031", "submitter": "Edoardo Lamon", "authors": "Fabio Fusaro (1 and 2), Edoardo Lamon (1), Elena De Momi (2), Arash\n  Ajoudani (1) ((1) Human-Robot Interfaces and physical Interaction, Istituto\n  Italiano di Tecnologia, Genoa, Italy, (2) Department of Electronics,\n  Information and Bioengineering, Politecnico di Milano Politecnico di Milano,\n  Milan, Italy)", "title": "An Integrated Dynamic Method for Allocating Roles and Planning Tasks for\n  Mixed Human-Robot Teams", "comments": "6 pages, 5 figures, submitted to the 30th IEEE International\n  Conference on Robot and Human Interactive Communication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel integrated dynamic method based on Behavior Trees\nfor planning and allocating tasks in mixed human robot teams, suitable for\nmanufacturing environments. The Behavior Tree formulation allows encoding a\nsingle job as a compound of different tasks with temporal and logic\nconstraints. In this way, instead of the well-studied offline centralized\noptimization problem, the role allocation problem is solved with multiple\nsimplified online optimization sub-problem, without complex and cross-schedule\ntask dependencies. These sub-problems are defined as Mixed-Integer Linear\nPrograms, that, according to the worker-actions related costs and the workers'\navailability, allocate the yet-to-execute tasks among the available workers. To\ncharacterize the behavior of the developed method, we opted to perform\ndifferent simulation experiments in which the results of the action-worker\nallocation and computational complexity are evaluated. The obtained results,\ndue to the nature of the algorithm and to the possibility of simulating the\nagents' behavior, should describe well also how the algorithm performs in real\nexperiments.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 16:10:30 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Fusaro", "Fabio", "", "1 and 2"], ["Lamon", "Edoardo", ""], ["De Momi", "Elena", ""], ["Ajoudani", "Arash", ""]]}, {"id": "2105.12037", "submitter": "Arianna Casanova", "authors": "Juerg Kohlas, Arianna Casanova, Marco Zaffalon", "title": "Information algebras of coherent sets of gambles in general possibility\n  spaces", "comments": "Accepted at ISIPTA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we show that coherent sets of gambles can be embedded into the\nalgebraic structure of information algebra. This leads firstly, to a new\nperspective of the algebraic and logical structure of desirability and\nsecondly, it connects desirability, hence imprecise probabilities, to other\nformalism in computer science sharing the same underlying structure. Both the\ndomain-free and the labeled view of the information algebra of coherent sets of\ngambles are presented, considering general possibility spaces.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 16:18:39 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Kohlas", "Juerg", ""], ["Casanova", "Arianna", ""], ["Zaffalon", "Marco", ""]]}, {"id": "2105.12051", "submitter": "Zhixiang Chen", "authors": "Zhixiang Chen, Yikun Lei, Pai Liu, Guibing Guo", "title": "NEUer at SemEval-2021 Task 4: Complete Summary Representation by Filling\n  Answers into Question for Matching Reading Comprehension", "comments": "accepted by SemEval2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SemEval task 4 aims to find a proper option from multiple candidates to\nresolve the task of machine reading comprehension. Most existing approaches\npropose to concat question and option together to form a context-aware model.\nHowever, we argue that straightforward concatenation can only provide a\ncoarse-grained context for the MRC task, ignoring the specific positions of the\noption relative to the question. In this paper, we propose a novel MRC model by\nfilling options into the question to produce a fine-grained context (defined as\nsummary) which can better reveal the relationship between option and question.\nWe conduct a series of experiments on the given dataset, and the results show\nthat our approach outperforms other counterparts to a large extent.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 16:31:26 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Chen", "Zhixiang", ""], ["Lei", "Yikun", ""], ["Liu", "Pai", ""], ["Guo", "Guibing", ""]]}, {"id": "2105.12092", "submitter": "Anselmo Pitombeira-Neto", "authors": "Anselmo R. Pitombeira-Neto, Helano P. Santos, Ticiana L. Coelho da\n  Silva, Jos\\'e Antonio F. de Macedo", "title": "Trajectory Modeling via Random Utility Inverse Reinforcement Learning", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of modeling trajectories of drivers in a road network\nfrom the perspective of inverse reinforcement learning. As rational agents,\ndrivers are trying to maximize some reward function unknown to an external\nobserver as they make up their trajectories. We apply the concept of random\nutility from microeconomic theory to model the unknown reward function as a\nfunction of observable features plus an error term which represents features\nknown only to the driver. We develop a parameterized generative model for the\ntrajectories based on a random utility Markov decision process formulation of\ndrivers decisions. We show that maximum entropy inverse reinforcement learning\nis a particular case of our proposed formulation when we assume a Gumbel\ndensity function for the unobserved reward error terms. We illustrate Bayesian\ninference on model parameters through a case study with real trajectory data\nfrom a large city obtained from sensors placed on sparsely distributed points\non the street network.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 17:19:09 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Pitombeira-Neto", "Anselmo R.", ""], ["Santos", "Helano P.", ""], ["da Silva", "Ticiana L. Coelho", ""], ["de Macedo", "Jos\u00e9 Antonio F.", ""]]}, {"id": "2105.12196", "submitter": "Siqi Liu", "authors": "Siqi Liu, Guy Lever, Zhe Wang, Josh Merel, S. M. Ali Eslami, Daniel\n  Hennes, Wojciech M. Czarnecki, Yuval Tassa, Shayegan Omidshafiei, Abbas\n  Abdolmaleki, Noah Y. Siegel, Leonard Hasenclever, Luke Marris, Saran\n  Tunyasuvunakool, H. Francis Song, Markus Wulfmeier, Paul Muller, Tuomas\n  Haarnoja, Brendan D. Tracey, Karl Tuyls, Thore Graepel, Nicolas Heess", "title": "From Motor Control to Team Play in Simulated Humanoid Football", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.NE cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent behaviour in the physical world exhibits structure at multiple\nspatial and temporal scales. Although movements are ultimately executed at the\nlevel of instantaneous muscle tensions or joint torques, they must be selected\nto serve goals defined on much longer timescales, and in terms of relations\nthat extend far beyond the body itself, ultimately involving coordination with\nother agents. Recent research in artificial intelligence has shown the promise\nof learning-based approaches to the respective problems of complex movement,\nlonger-term planning and multi-agent coordination. However, there is limited\nresearch aimed at their integration. We study this problem by training teams of\nphysically simulated humanoid avatars to play football in a realistic virtual\nenvironment. We develop a method that combines imitation learning, single- and\nmulti-agent reinforcement learning and population-based training, and makes use\nof transferable representations of behaviour for decision making at different\nlevels of abstraction. In a sequence of stages, players first learn to control\na fully articulated body to perform realistic, human-like movements such as\nrunning and turning; they then acquire mid-level football skills such as\ndribbling and shooting; finally, they develop awareness of others and play as a\nteam, bridging the gap between low-level motor control at a timescale of\nmilliseconds, and coordinated goal-directed behaviour as a team at the\ntimescale of tens of seconds. We investigate the emergence of behaviours at\ndifferent levels of abstraction, as well as the representations that underlie\nthese behaviours using several analysis techniques, including statistics from\nreal-world sports analytics. Our work constitutes a complete demonstration of\nintegrated decision-making at multiple scales in a physically embodied\nmulti-agent setting. See project video at https://youtu.be/KHMwq9pv7mg.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 20:17:10 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Liu", "Siqi", ""], ["Lever", "Guy", ""], ["Wang", "Zhe", ""], ["Merel", "Josh", ""], ["Eslami", "S. M. Ali", ""], ["Hennes", "Daniel", ""], ["Czarnecki", "Wojciech M.", ""], ["Tassa", "Yuval", ""], ["Omidshafiei", "Shayegan", ""], ["Abdolmaleki", "Abbas", ""], ["Siegel", "Noah Y.", ""], ["Hasenclever", "Leonard", ""], ["Marris", "Luke", ""], ["Tunyasuvunakool", "Saran", ""], ["Song", "H. Francis", ""], ["Wulfmeier", "Markus", ""], ["Muller", "Paul", ""], ["Haarnoja", "Tuomas", ""], ["Tracey", "Brendan D.", ""], ["Tuyls", "Karl", ""], ["Graepel", "Thore", ""], ["Heess", "Nicolas", ""]]}, {"id": "2105.12205", "submitter": "Alessandro Antonucci", "authors": "Alessandro Antonucci and Francesca Mangili and Claudio Bonesana and\n  Giorgia Adorni", "title": "A New Score for Adaptive Tests in Bayesian and Credal Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A test is adaptive when its sequence and number of questions is dynamically\ntuned on the basis of the estimated skills of the taker. Graphical models, such\nas Bayesian networks, are used for adaptive tests as they allow to model the\nuncertainty about the questions and the skills in an explainable fashion,\nespecially when coping with multiple skills. A better elicitation of the\nuncertainty in the question/skills relations can be achieved by interval\nprobabilities. This turns the model into a credal network, thus making more\nchallenging the inferential complexity of the queries required to select\nquestions. This is especially the case for the information theoretic quantities\nused as scores to drive the adaptive mechanism. We present an alternative\nfamily of scores, based on the mode of the posterior probabilities, and hence\neasier to explain. This makes considerably simpler the evaluation in the credal\ncase, without significantly affecting the quality of the adaptive process.\nNumerical tests on synthetic and real-world data are used to support this\nclaim.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 20:35:42 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Antonucci", "Alessandro", ""], ["Mangili", "Francesca", ""], ["Bonesana", "Claudio", ""], ["Adorni", "Giorgia", ""]]}, {"id": "2105.12213", "submitter": "Danny Arlen De Jes\\'us G\\'omez-Ram\\'irez", "authors": "Danny A. J. Gomez-Ramirez, Yoe A. Herrera-Jaramillo, Johana C.\n  Ortega-Giraldo, Alex M. Ardila-Garcia", "title": "Some Pragmatic Prevention's Guidelines regarding SARS-CoV-2 and COVID-19\n  in Latin-America inspired by mixed Machine Learning Techniques and Artificial\n  Mathematical Intelligence. Case Study: Colombia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use an enhanced methodology combining specific forms of AI techniques,\nopinion mining and artificial mathematical intelligence (AMI), with public data\non the spread of the coronavirus SARS-CoV-2 and the incidence of COVID-19\ndisease in Colombia during the first three months since the first reported\npositive case. The results obtained, together with conceptual tools coming from\nthe global taxonomy of fundamental cognitive mechanisms emerging in AMI and\nwith suitable contextual information from Colombian public health and\nmainstream social media, allowed us to stating specific preventive guidelines\nfor a better restructuring of initial safe and stable life conditions in\nColombia, and in an extended manner in similar Latin American Countries. More\nspecifically, we describe three major guidelines: 1) regular creative\nvisualization and effective planning, 2) the continuous use of constructive\nlinguistic frameworks, and 3) frequent and moderate use of kinesthetic\nroutines. They should be understood as effective tools from a cognitive and\nbehavioural perspective, rather than from a biological one. Even more, the\nfirst two guidelines should be acknowledged in integral cooperation with the\nthird one regarding the global effect of COVID-19 in human beings as a whole,\nthis includes the mind and body.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 22:06:52 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Gomez-Ramirez", "Danny A. J.", ""], ["Herrera-Jaramillo", "Yoe A.", ""], ["Ortega-Giraldo", "Johana C.", ""], ["Ardila-Garcia", "Alex M.", ""]]}, {"id": "2105.12247", "submitter": "Sayan Nag", "authors": "Sayan Nag", "title": "Graph Self Supervised Learning: the BT, the HSIC, and the VICReg", "comments": "Paper Accepted in the Weakly Supervised Representation Learning\n  Workshop, IJCAI 2021 (IJCAI2021-WSRL)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CG cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Self-supervised learning and pre-training strategies have developed over the\nlast few years especially for Convolutional Neural Networks (CNNs). Recently\napplication of such methods can also be noticed for Graph Neural Networks\n(GNNs) . In this paper, we have used a graph based self-supervised learning\nstrategy with different loss functions (Barlow Twins[Zbontar et al., 2021],\nHSIC[Tsai et al., 2021], VICReg[Bardes et al., 2021]) which have shown\npromising results when applied with CNNs previously. We have also proposed a\nhybrid loss function combining the advantages of VICReg and HSIC and called it\nas VICRegHSIC. The performance of these aforementioned methods have been\ncompared when applied to different datasets such as MUTAG, PROTEINS and\nIMDB-Binary. Moreover, the impact of different batch sizes, projector\ndimensions and data augmentation strategies have also been explored\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 22:34:19 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 04:51:26 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 03:18:43 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Nag", "Sayan", ""]]}, {"id": "2105.12272", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Mengjiao Yang", "title": "Provable Representation Learning for Imitation with Contrastive Fourier\n  Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In imitation learning, it is common to learn a behavior policy to match an\nunknown target policy via max-likelihood training on a collected set of target\ndemonstrations. In this work, we consider using offline experience datasets -\npotentially far from the target distribution - to learn low-dimensional state\nrepresentations that provably accelerate the sample-efficiency of downstream\nimitation learning. A central challenge in this setting is that the unknown\ntarget policy itself may not exhibit low-dimensional behavior, and so there is\na potential for the representation learning objective to alias states in which\nthe target policy acts differently. Circumventing this challenge, we derive a\nrepresentation learning objective which provides an upper bound on the\nperformance difference between the target policy and a lowdimensional policy\ntrained with max-likelihood, and this bound is tight regardless of whether the\ntarget policy itself exhibits low-dimensional structure. Moving to the\npracticality of our method, we show that our objective can be implemented as\ncontrastive learning, in which the transition dynamics are approximated by\neither an implicit energy-based model or, in some special cases, an implicit\nlinear model with representations given by random Fourier features. Experiments\non both tabular environments and high-dimensional Atari games provide\nquantitative evidence for the practical benefits of our proposed objective.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 00:31:30 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Nachum", "Ofir", ""], ["Yang", "Mengjiao", ""]]}, {"id": "2105.12277", "submitter": "Michael Taylor", "authors": "Michael Taylor, Sergey Bashkirov, Javier Fernandez Rico, Ike Toriyama,\n  Naoyuki Miyada, Hideki Yanagisawa, Kensaku Ishizuka", "title": "Learning Bipedal Robot Locomotion from Human Movement", "comments": "8 pages, 12 figures, 1 table. Accepted to ICRA 2021. For\n  supplementary video, see https://www.youtube.com/watch?v=k4oXPD4kVM0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching an anthropomorphic robot from human example offers the opportunity\nto impart humanlike qualities on its movement. In this work we present a\nreinforcement learning based method for teaching a real world bipedal robot to\nperform movements directly from human motion capture data. Our method\nseamlessly transitions from training in a simulation environment to executing\non a physical robot without requiring any real world training iterations or\noffline steps. To overcome the disparity in joint configurations between the\nrobot and the motion capture actor, our method incorporates motion re-targeting\ninto the training process. Domain randomization techniques are used to\ncompensate for the differences between the simulated and physical systems. We\ndemonstrate our method on an internally developed humanoid robot with movements\nranging from a dynamic walk cycle to complex balancing and waving. Our\ncontroller preserves the style imparted by the motion capture data and exhibits\ngraceful failure modes resulting in safe operation for the robot. This work was\nperformed for research purposes only.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 00:49:37 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Taylor", "Michael", ""], ["Bashkirov", "Sergey", ""], ["Rico", "Javier Fernandez", ""], ["Toriyama", "Ike", ""], ["Miyada", "Naoyuki", ""], ["Yanagisawa", "Hideki", ""], ["Ishizuka", "Kensaku", ""]]}, {"id": "2105.12287", "submitter": "Debjyoti Paul", "authors": "Debjyoti Paul, Jie Cao, Feifei Li, Vivek Srikumar", "title": "Database Workload Characterization with Query Plan Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart databases are adopting artificial intelligence (AI) technologies to\nachieve {\\em instance optimality}, and in the future, databases will come with\nprepackaged AI models within their core components. The reason is that every\ndatabase runs on different workloads, demands specific resources, and settings\nto achieve optimal performance. It prompts the necessity to understand\nworkloads running in the system along with their features comprehensively,\nwhich we dub as workload characterization.\n  To address this workload characterization problem, we propose our query plan\nencoders that learn essential features and their correlations from query plans.\nOur pretrained encoders capture the {\\em structural} and the {\\em computational\nperformance} of queries independently. We show that our pretrained encoders are\nadaptable to workloads that expedite the transfer learning process. We\nperformed independent assessments of structural encoder and performance\nencoders with multiple downstream tasks. For the overall evaluation of our\nquery plan encoders, we architect two downstream tasks (i) query latency\nprediction and (ii) query classification. These tasks show the importance of\nfeature-based workload characterization. We also performed extensive\nexperiments on individual encoders to verify the effectiveness of\nrepresentation learning and domain adaptability.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 01:17:27 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Paul", "Debjyoti", ""], ["Cao", "Jie", ""], ["Li", "Feifei", ""], ["Srikumar", "Vivek", ""]]}, {"id": "2105.12319", "submitter": "Saeed Hadadan", "authors": "Saeed Hadadan, Shuhong Chen, Matthias Zwicker", "title": "Neural Radiosity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Neural Radiosity, an algorithm to solve the rendering equation\nby minimizing the norm of its residual similar as in traditional radiosity\ntechniques. Traditional basis functions used in radiosity techniques, such as\npiecewise polynomials or meshless basis functions are typically limited to\nrepresenting isotropic scattering from diffuse surfaces. Instead, we propose to\nleverage neural networks to represent the full four-dimensional radiance\ndistribution, directly optimizing network parameters to minimize the norm of\nthe residual. Our approach decouples solving the rendering equation from\nrendering (perspective) images similar as in traditional radiosity techniques,\nand allows us to efficiently synthesize arbitrary views of a scene. In\naddition, we propose a network architecture using geometric learnable features\nthat improves convergence of our solver compared to previous techniques. Our\napproach leads to an algorithm that is simple to implement, and we demonstrate\nits effectiveness on a variety of scenes with non-diffuse surfaces.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 04:10:00 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Hadadan", "Saeed", ""], ["Chen", "Shuhong", ""], ["Zwicker", "Matthias", ""]]}, {"id": "2105.12328", "submitter": "Huale Li", "authors": "Huale Li, Xuan Wang, Zengyue Guo, Jiajia Zhang, Shuhan Qi", "title": "NNCFR: Minimize Counterfactual Regret with Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Counterfactual Regret Minimization (CFR)} is the popular method for finding\napproximate Nash equilibrium in two-player zero-sum games with imperfect\ninformation. CFR solves games by travsersing the full game tree iteratively,\nwhich limits its scalability in larger games. When applying CFR to solve\nlarge-scale games in previously, large-scale games are abstracted into\nsmall-scale games firstly. Secondly, CFR is used to solve the abstract game.\nAnd finally, the solution strategy is mapped back to the original large-scale\ngame. However, this process requires considerable expert knowledge, and the\naccuracy of abstraction is closely related to expert knowledge. In addition,\nthe abstraction also loses certain information, which will eventually affect\nthe accuracy of the solution strategy. Towards this problem, a recent method,\n\\textit{Deep CFR} alleviates the need for abstraction and expert knowledge by\napplying deep neural networks directly to CFR in full games. In this paper, we\nintroduces \\textit{Neural Network Counterfactual Regret Minimization (NNCFR)},\nan improved variant of \\textit{Deep CFR} that has a faster convergence by\nconstructing a dueling netwok as the value network. Moreover, an evaluation\nmodule is designed by combining the value network and Monte Carlo, which\nreduces the approximation error of the value network. In addition, a new loss\nfunction is designed in the procedure of training policy network in the\nproposed \\textit{NNCFR}, which can be good to make the policy network more\nstable. The extensive experimental tests are conducted to show that the\n\\textit{NNCFR} converges faster and performs more stable than \\textit{Deep\nCFR}, and outperforms \\textit{Deep CFR} with respect to exploitability and\nhead-to-head performance on test games.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 04:58:36 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Li", "Huale", ""], ["Wang", "Xuan", ""], ["Guo", "Zengyue", ""], ["Zhang", "Jiajia", ""], ["Qi", "Shuhan", ""]]}, {"id": "2105.12344", "submitter": "Jinyu Tian", "authors": "Jinyu Tian, Jiantao Zhou, and Jia Duan", "title": "Probabilistic Selective Encryption of Convolutional Neural Networks for\n  Hierarchical Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Model protection is vital when deploying Convolutional Neural Networks (CNNs)\nfor commercial services, due to the massive costs of training them. In this\nwork, we propose a selective encryption (SE) algorithm to protect CNN models\nfrom unauthorized access, with a unique feature of providing hierarchical\nservices to users. Our algorithm firstly selects important model parameters via\nthe proposed Probabilistic Selection Strategy (PSS). It then encrypts the most\nimportant parameters with the designed encryption method called Distribution\nPreserving Random Mask (DPRM), so as to maximize the performance degradation by\nencrypting only a very small portion of model parameters. We also design a set\nof access permissions, using which different amounts of the most important\nmodel parameters can be decrypted. Hence, different levels of model performance\ncan be naturally provided for users. Experimental results demonstrate that the\nproposed scheme could effectively protect the classification model VGG19 by\nmerely encrypting 8% parameters of convolutional layers. We also implement the\nproposed model protection scheme in the denoising model DnCNN, showcasing the\nhierarchical denoising services\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 06:15:58 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Tian", "Jinyu", ""], ["Zhou", "Jiantao", ""], ["Duan", "Jia", ""]]}, {"id": "2105.12348", "submitter": "Xinran Li", "authors": "Xinran Li, Kuo-Yi Lin, Min Meng, Xiuxian Li, Li Li, Yiguang Hong and\n  Jie Chen", "title": "Composition and Application of Current Advanced Driving Assistance\n  System: A Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the growing awareness of driving safety and the development of\nsophisticated technologies, advanced driving assistance system (ADAS) has been\nequipped in more and more vehicles with higher accuracy and lower price. The\nlatest progress in this field has called for a review to sum up the\nconventional knowledge of ADAS, the state-of-the-art researches, and novel\napplications in real-world. With the help of this kind of review, newcomers in\nthis field can get basic knowledge easier and other researchers may be inspired\nwith potential future development possibility.\n  This paper makes a general introduction about ADAS by analyzing its hardware\nsupport and computation algorithms. Different types of perception sensors are\nintroduced from their interior feature classifications, installation positions,\nsupporting ADAS functions, and pros and cons. The comparisons between different\nsensors are concluded and illustrated from their inherent characters and\nspecific usages serving for each ADAS function. The current algorithms for ADAS\nfunctions are also collected and briefly presented in this paper from both\ntraditional methods and novel ideas. Additionally, discussions about the\ndefinition of ADAS from different institutes are reviewed in this paper, and\nfuture approaches about ADAS in China are introduced in particular.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 06:26:24 GMT"}, {"version": "v2", "created": "Thu, 10 Jun 2021 14:00:57 GMT"}, {"version": "v3", "created": "Wed, 23 Jun 2021 12:56:13 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Li", "Xinran", ""], ["Lin", "Kuo-Yi", ""], ["Meng", "Min", ""], ["Li", "Xiuxian", ""], ["Li", "Li", ""], ["Hong", "Yiguang", ""], ["Chen", "Jie", ""]]}, {"id": "2105.12364", "submitter": "Nawshad Farruque", "authors": "Nawshad Farruque, Chenyang Huang, Osmar Zaiane, Randy Goebel", "title": "Basic and Depression Specific Emotion Identification in Tweets:\n  Multi-label Classification Experiments", "comments": "Accepted at CICLing, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present empirical analysis on basic and depression specific\nmulti-emotion mining in Tweets with the help of state of the art multi-label\nclassifiers. We choose our basic emotions from a hybrid emotion model\nconsisting of the common emotions from four highly regarded psychological\nmodels of emotions. Moreover, we augment that emotion model with new emotion\ncategories because of their importance in the analysis of depression. Most of\nthose additional emotions have not been used in previous emotion mining\nresearch. Our experimental analyses show that a cost sensitive RankSVM\nalgorithm and a Deep Learning model are both robust, measured by both Macro\nF-measures and Micro F-measures. This suggests that these algorithms are\nsuperior in addressing the widely known data imbalance problem in multi-label\nlearning. Moreover, our application of Deep Learning performs the best, giving\nit an edge in modeling deep semantic features of our extended emotional\ncategories.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 07:13:50 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 09:08:03 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Farruque", "Nawshad", ""], ["Huang", "Chenyang", ""], ["Zaiane", "Osmar", ""], ["Goebel", "Randy", ""]]}, {"id": "2105.12366", "submitter": "Dhirendra Singh Dr", "authors": "Dhirendra Singh and Ken Strahan and Jim McLennan and Joel Robertson\n  and Bhagya Wickramasinghe", "title": "What will they do? Modelling self-evacuation archetypes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI physics.soc-ph", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  A decade on from the devastating Black Saturday bushfires in Victoria,\nAustralia, we are at a point where computer simulations of community\nevacuations are starting to be used within the emergency services. While fire\nprogression modelling is embedded in strategic and operational settings at all\nlevels of government across Victoria, modelling of community response to such\nfires is only just starting to be evaluated in earnest. For community response\nmodels to become integral to bushfire planning and preparedness, the key\nquestion to be addressed is: when faced with a bushfire, what will a community\nreally do? Typically this understanding has come from local experience and\nexpertise within the community and services, however the trend is to move\ntowards more informed data driven approaches. In this paper we report on the\nlatest work within the emergency sector in this space. Particularly, we discuss\nthe application of Strahan et al.'s self-evacuation archetypes to an\nagent-based model of community evacuation in regional Victoria. This work is\npart of the consolidated bushfire evacuation modelling collaboration between\nseveral emergency management stakeholders.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 07:16:40 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Singh", "Dhirendra", ""], ["Strahan", "Ken", ""], ["McLennan", "Jim", ""], ["Robertson", "Joel", ""], ["Wickramasinghe", "Bhagya", ""]]}, {"id": "2105.12436", "submitter": "Chi Zhang", "authors": "Chi Zhang (1), Christian Berger (1), Marco Dozza (2) ((1) Department\n  of Computer Science and Engineering, University of Gothenburg, Gothenburg,\n  Sweden, (2) Department of Maritime Sciences and Mechanics, Chalmers\n  University of Technology, Gothenburg, Sweden)", "title": "Social-IWSTCNN: A Social Interaction-Weighted Spatio-Temporal\n  Convolutional Neural Network for Pedestrian Trajectory Prediction in Urban\n  Traffic Scenarios", "comments": "8 pages, 4 figures. Accepted in IEEE Intelligent Vehicles Symposium\n  (IV), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Pedestrian trajectory prediction in urban scenarios is essential for\nautomated driving. This task is challenging because the behavior of pedestrians\nis influenced by both their own history paths and the interactions with others.\nPrevious research modeled these interactions with pooling mechanisms or\naggregating with hand-crafted attention weights. In this paper, we present the\nSocial Interaction-Weighted Spatio-Temporal Convolutional Neural Network\n(Social-IWSTCNN), which includes both the spatial and the temporal features. We\npropose a novel design, namely the Social Interaction Extractor, to learn the\nspatial and social interaction features of pedestrians. Most previous works\nused ETH and UCY datasets which include five scenes but do not cover urban\ntraffic scenarios extensively for training and evaluation. In this paper, we\nuse the recently released large-scale Waymo Open Dataset in urban traffic\nscenarios, which includes 374 urban training scenes and 76 urban testing scenes\nto analyze the performance of our proposed algorithm in comparison to the\nstate-of-the-art (SOTA) models. The results show that our algorithm outperforms\nSOTA algorithms such as Social-LSTM, Social-GAN, and Social-STGCNN on both\nAverage Displacement Error (ADE) and Final Displacement Error (FDE).\nFurthermore, our Social-IWSTCNN is 54.8 times faster in data pre-processing\nspeed, and 4.7 times faster in total test speed than the current best SOTA\nalgorithm Social-STGCNN.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 09:53:19 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Zhang", "Chi", ""], ["Berger", "Christian", ""], ["Dozza", "Marco", ""]]}, {"id": "2105.12441", "submitter": "Akis Linardos", "authors": "Akis Linardos, Matthias K\\\"ummerer, Ori Press, Matthias Bethge", "title": "Calibrated prediction in and out-of-domain for state-of-the-art saliency\n  modeling", "comments": "Joint first authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Since 2014 transfer learning has become the key driver for the improvement of\nspatial saliency prediction; however, with stagnant progress in the last 3-5\nyears. We conduct a large-scale transfer learning study which tests different\nImageNet backbones, always using the same read out architecture and learning\nprotocol adopted from DeepGaze II. By replacing the VGG19 backbone of DeepGaze\nII with ResNet50 features we improve the performance on saliency prediction\nfrom 78% to 85%. However, as we continue to test better ImageNet models as\nbackbones (such as EfficientNetB5) we observe no additional improvement on\nsaliency prediction. By analyzing the backbones further, we find that\ngeneralization to other datasets differs substantially, with models being\nconsistently overconfident in their fixation predictions. We show that by\ncombining multiple backbones in a principled manner a good confidence\ncalibration on unseen datasets can be achieved. This yields a significant leap\nin benchmark performance in and out-of-domain with a 15 percent point\nimprovement over DeepGaze II to 93% on MIT1003, marking a new state of the art\non the MIT/Tuebingen Saliency Benchmark in all available metrics (AUC: 88.3%,\nsAUC: 79.4%, CC: 82.4%).\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 09:59:56 GMT"}, {"version": "v2", "created": "Thu, 27 May 2021 15:21:50 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Linardos", "Akis", ""], ["K\u00fcmmerer", "Matthias", ""], ["Press", "Ori", ""], ["Bethge", "Matthias", ""]]}, {"id": "2105.12449", "submitter": "Daniel Loureiro", "authors": "Daniel Loureiro, Al\\'ipio M\\'ario Jorge, Jose Camacho-Collados", "title": "LMMS Reloaded: Transformer-based Sense Embeddings for Disambiguation and\n  Beyond", "comments": "Under review, 81 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributional semantics based on neural approaches is a cornerstone of\nNatural Language Processing, with surprising connections to human meaning\nrepresentation as well. Recent Transformer-based Language Models have proven\ncapable of producing contextual word representations that reliably convey\nsense-specific information, simply as a product of self-supervision. Prior work\nhas shown that these contextual representations can be used to accurately\nrepresent large sense inventories as sense embeddings, to the extent that a\ndistance-based solution to Word Sense Disambiguation (WSD) tasks outperforms\nmodels trained specifically for the task. Still, there remains much to\nunderstand on how to use these Neural Language Models (NLMs) to produce sense\nembeddings that can better harness each NLM's meaning representation abilities.\nIn this work we introduce a more principled approach to leverage information\nfrom all layers of NLMs, informed by a probing analysis on 14 NLM variants. We\nalso emphasize the versatility of these sense embeddings in contrast to\ntask-specific models, applying them on several sense-related tasks, besides\nWSD, while demonstrating improved performance using our proposed approach over\nprior work focused on sense embeddings. Finally, we discuss unexpected findings\nregarding layer and model performance variations, and potential applications\nfor downstream tasks.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 10:14:22 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Loureiro", "Daniel", ""], ["Jorge", "Al\u00edpio M\u00e1rio", ""], ["Camacho-Collados", "Jose", ""]]}, {"id": "2105.12497", "submitter": "Ali Raza", "authors": "Ali Raza, Kim Phuc Tran, Ludovic Koehl and Shujun Li", "title": "Designing ECG Monitoring Healthcare System with Federated Transfer\n  Learning and Explainable AI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning play a vital role in classifying different arrhythmias using\nthe electrocardiography (ECG) data. Nevertheless, training deep learning models\nnormally requires a large amount of data and it can lead to privacy concerns.\nUnfortunately, a large amount of healthcare data cannot be easily collected\nfrom a single silo. Additionally, deep learning models are like black-box, with\nno explainability of the predicted results, which is often required in clinical\nhealthcare. This limits the application of deep learning in real-world health\nsystems. In this paper, we design a new explainable artificial intelligence\n(XAI) based deep learning framework in a federated setting for ECG-based\nhealthcare applications. The federated setting is used to solve issues such as\ndata availability and privacy concerns. Furthermore, the proposed framework\nsetting effectively classifies arrhythmia's using an autoencoder and a\nclassifier, both based on a convolutional neural network (CNN). Additionally,\nwe propose an XAI-based module on top of the proposed classifier to explain the\nclassification results, which help clinical practitioners make quick and\nreliable decisions. The proposed framework was trained and tested using the\nMIT-BIH Arrhythmia database. The classifier achieved accuracy up to 94% and 98%\nfor arrhythmia detection using noisy and clean data, respectively, with\nfive-fold cross-validation.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 11:59:44 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Raza", "Ali", ""], ["Tran", "Kim Phuc", ""], ["Koehl", "Ludovic", ""], ["Li", "Shujun", ""]]}, {"id": "2105.12500", "submitter": "Noam Hazon", "authors": "David Zar, Noam Hazon, Amos Azaria", "title": "Explaining Ridesharing: Selection of Explanations for Increasing User\n  Satisfaction", "comments": "19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Transportation services play a crucial part in the development of modern\nsmart cities. In particular, on-demand ridesharing services, which group\ntogether passengers with similar itineraries, are already operating in several\nmetropolitan areas. These services can be of significant social and\nenvironmental benefit, by reducing travel costs, road congestion and CO2\nemissions.\n  Unfortunately, despite their advantages, not many people opt to use these\nridesharing services. We believe that increasing the user satisfaction from the\nservice will cause more people to utilize it, which, in turn, will improve the\nquality of the service, such as the waiting time, cost, travel time, and\nservice availability. One possible way for increasing user satisfaction is by\nproviding appropriate explanations comparing the alternative modes of\ntransportation, such as a private taxi ride and public transportation. For\nexample, a passenger may be more satisfied from a shared-ride if she is told\nthat a private taxi ride would have cost her 50% more. Therefore, the problem\nis to develop an agent that provides explanations that will increase the user\nsatisfaction.\n  We model our environment as a signaling game and show that a rational agent,\nwhich follows the perfect Bayesian equilibrium, must reveal all of the\ninformation regarding the possible alternatives to the passenger. In addition,\nwe develop a machine learning based agent that, when given a shared-ride along\nwith its possible alternatives, selects the explanations that are most likely\nto increase user satisfaction. Using feedback from humans we show that our\nmachine learning based agent outperforms the rational agent and an agent that\nrandomly chooses explanations, in terms of user satisfaction.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 12:03:09 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Zar", "David", ""], ["Hazon", "Noam", ""], ["Azaria", "Amos", ""]]}, {"id": "2105.12514", "submitter": "Johannes Hartmann", "authors": "Johannes Hartmann", "title": "Finding optimal strategies in sequential games with the novel selection\n  monad", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recently discovered monad, Tx = Selection (x -> r) -> r, provides an\nelegant way to finnd optimal strategies in sequential games. During this\nthesis, a library was developed which provides a set of useful functions using\nthe selection monad to compute optimal games and AIs for sequential games. In\norder to explore the selection monads ability to support these AI\nimplementations, three example case studies were developed using Haskell: The\ntwo-player game Connect Four, a Sudoku solver and a simplified version of\nChess. These case studies show how to elegantly implement a game AI.\nFurthermore, a performance analysis of these case studies was done, identifying\nthe major points where performance can be increased.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 12:33:32 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Hartmann", "Johannes", ""]]}, {"id": "2105.12532", "submitter": "Sherzod Hakimov", "authors": "Hussain Kanafani, Junaid Ahmed Ghauri, Sherzod Hakimov, Ralph Ewerth", "title": "Unsupervised Video Summarization via Multi-source Features", "comments": "Accepted for publication at the ACM International Conference on\n  Multimedia Retrieval (ICMR) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video summarization aims at generating a compact yet representative visual\nsummary that conveys the essence of the original video. The advantage of\nunsupervised approaches is that they do not require human annotations to learn\nthe summarization capability and generalize to a wider range of domains.\nPrevious work relies on the same type of deep features, typically based on a\nmodel pre-trained on ImageNet data. Therefore, we propose the incorporation of\nmultiple feature sources with chunk and stride fusion to provide more\ninformation about the visual content. For a comprehensive evaluation on the two\nbenchmarks TVSum and SumMe, we compare our method with four state-of-the-art\napproaches. Two of these approaches were implemented by ourselves to reproduce\nthe reported results. Our evaluation shows that we obtain state-of-the-art\nresults on both datasets, while also highlighting the shortcomings of previous\nwork with regard to the evaluation methodology. Finally, we perform error\nanalysis on videos for the two benchmark datasets to summarize and spot the\nfactors that lead to misclassifications.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 13:12:46 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Kanafani", "Hussain", ""], ["Ghauri", "Junaid Ahmed", ""], ["Hakimov", "Sherzod", ""], ["Ewerth", "Ralph", ""]]}, {"id": "2105.12552", "submitter": "Eduard Torres", "authors": "Carlos Ans\\'otegui, Felip Many\\`a, Jesus Ojeda, Josep M. Salvia,\n  Eduard Torres", "title": "Incomplete MaxSAT Approaches for Combinatorial Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a Satisfiability (SAT)-based approach for building Mixed Covering\nArrays with Constraints of minimum length, referred to as the Covering Array\nNumber problem. This problem is central in Combinatorial Testing for the\ndetection of system failures. In particular, we show how to apply Maximum\nSatisfiability (MaxSAT) technology by describing efficient encodings for\ndifferent classes of complete and incomplete MaxSAT solvers to compute optimal\nand suboptimal solutions, respectively. Similarly, we show how to solve through\nMaxSAT technology a closely related problem, the Tuple Number problem, which we\nextend to incorporate constraints. For this problem, we additionally provide a\nnew MaxSAT-based incomplete algorithm. The extensive experimental evaluation we\ncarry out on the available Mixed Covering Arrays with Constraints benchmarks\nand the comparison with state-of-the-art tools confirm the good performance of\nour approaches.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 14:00:56 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Ans\u00f3tegui", "Carlos", ""], ["Many\u00e0", "Felip", ""], ["Ojeda", "Jesus", ""], ["Salvia", "Josep M.", ""], ["Torres", "Eduard", ""]]}, {"id": "2105.12564", "submitter": "Rushabh Patel", "authors": "Rushabh Patel", "title": "Predicting invasive ductal carcinoma using a Reinforcement Sample\n  Learning Strategy using Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Invasive ductal carcinoma is a prevalent, potentially deadly disease\nassociated with a high rate of morbidity and mortality. Its malignancy is the\nsecond leading cause of death from cancer in women. The mammogram is an\nextremely useful resource for mass detection and invasive ductal carcinoma\ndiagnosis. We are proposing a method for Invasive ductal carcinoma that will\nuse convolutional neural networks (CNN) on mammograms to assist radiologists in\ndiagnosing the disease. Due to the varying image clarity and structure of\ncertain mammograms, it is difficult to observe major cancer characteristics\nsuch as microcalcification and mass, and it is often difficult to interpret and\ndiagnose these attributes. The aim of this study is to establish a novel method\nfor fully automated feature extraction and classification in invasive ductal\ncarcinoma computer-aided diagnosis (CAD) systems. This article presents a tumor\nclassification algorithm that makes novel use of convolutional neural networks\non breast mammogram images to increase feature extraction and training speed.\nThe algorithm makes two contributions.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 14:14:45 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Patel", "Rushabh", ""]]}, {"id": "2105.12584", "submitter": "Fanzhen Liu", "authors": "Xing Su, Shan Xue, Fanzhen Liu, Jia Wu, Jian Yang, Chuan Zhou, Wenbin\n  Hu, Cecile Paris, Surya Nepal, Di Jin, Quan Z. Sheng, Philip S. Yu", "title": "A Comprehensive Survey on Community Detection with Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A community reveals the features and connections of its members that are\ndifferent from those in other communities in a network. Detecting communities\nis of great significance in network analysis. Despite the classical spectral\nclustering and statistical inference methods, we notice a significant\ndevelopment of deep learning techniques for community detection in recent years\nwith their advantages in handling high dimensional network data. Hence, a\ncomprehensive overview of community detection's latest progress through deep\nlearning is timely to both academics and practitioners. This survey devises and\nproposes a new taxonomy covering different categories of the state-of-the-art\nmethods, including deep learning-based models upon deep neural networks, deep\nnonnegative matrix factorization and deep sparse filtering. The main category,\ni.e., deep neural networks, is further divided into convolutional networks,\ngraph attention networks, generative adversarial networks and autoencoders. The\nsurvey also summarizes the popular benchmark data sets, model evaluation\nmetrics, and open-source implementations to address experimentation settings.\nWe then discuss the practical applications of community detection in various\ndomains and point to implementation scenarios. Finally, we outline future\ndirections by suggesting challenging topics in this fast-growing deep learning\nfield.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 14:37:07 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Su", "Xing", ""], ["Xue", "Shan", ""], ["Liu", "Fanzhen", ""], ["Wu", "Jia", ""], ["Yang", "Jian", ""], ["Zhou", "Chuan", ""], ["Hu", "Wenbin", ""], ["Paris", "Cecile", ""], ["Nepal", "Surya", ""], ["Jin", "Di", ""], ["Sheng", "Quan Z.", ""], ["Yu", "Philip S.", ""]]}, {"id": "2105.12585", "submitter": "Fanchao Qi", "authors": "Fanchao Qi, Yangyi Chen, Fengyu Wang, Zhiyuan Liu, Xiao Chen, Maosong\n  Sun", "title": "Automatic Construction of Sememe Knowledge Bases via Dictionaries", "comments": "Accepted by Findings of ACL at ACL-IJCNLP 2021. Camera-ready version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A sememe is defined as the minimum semantic unit in linguistics. Sememe\nknowledge bases (SKBs), which comprise words annotated with sememes, enable\nsememes to be applied to natural language processing. So far a large body of\nresearch has showcased the unique advantages and effectiveness of SKBs in\nvarious tasks. However, most languages have no SKBs, and manual construction of\nSKBs is time-consuming and labor-intensive. To tackle this challenge, we\npropose a simple and fully automatic method of building an SKB via an existing\ndictionary. We use this method to build an English SKB and a French SKB, and\nconduct comprehensive evaluations from both intrinsic and extrinsic\nperspectives. Experimental results demonstrate that the automatically built\nEnglish SKB is even superior to HowNet, the most widely used SKB that takes\ndecades to build manually. And both the English and French SKBs can bring\nobvious performance enhancement in multiple downstream tasks. All the code and\ndata of this paper (except the copyrighted dictionaries) can be obtained at\nhttps://github.com/thunlp/DictSKB.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 14:41:01 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 08:21:55 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Qi", "Fanchao", ""], ["Chen", "Yangyi", ""], ["Wang", "Fengyu", ""], ["Liu", "Zhiyuan", ""], ["Chen", "Xiao", ""], ["Sun", "Maosong", ""]]}, {"id": "2105.12626", "submitter": "Sergio Altares", "authors": "Sergio Altares-L\\'opez, Angela Ribeiro, Juan Jos\\'e Garc\\'ia-Ripoll", "title": "Automatic design of quantum feature maps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a new technique for the automatic generation of optimal ad-hoc\nans\\\"atze for classification by using quantum support vector machine (QSVM).\nThis efficient method is based on NSGA-II multiobjective genetic algorithms\nwhich allow both maximize the accuracy and minimize the ansatz size. It is\ndemonstrated the validity of the technique by a practical example with a\nnon-linear dataset, interpreting the resulting circuit and its outputs. We also\nshow other application fields of the technique that reinforce the validity of\nthe method, and a comparison with classical classifiers in order to understand\nthe advantages of using quantum machine learning.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 15:31:10 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Altares-L\u00f3pez", "Sergio", ""], ["Ribeiro", "Angela", ""], ["Garc\u00eda-Ripoll", "Juan Jos\u00e9", ""]]}, {"id": "2105.12628", "submitter": "Yujia Bao", "authors": "Yujia Bao, Shiyu Chang, Regina Barzilay", "title": "Predict then Interpolate: A Simple Algorithm to Learn Stable Classifiers", "comments": "ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose Predict then Interpolate (PI), a simple algorithm for learning\ncorrelations that are stable across environments. The algorithm follows from\nthe intuition that when using a classifier trained on one environment to make\npredictions on examples from another environment, its mistakes are informative\nas to which correlations are unstable. In this work, we prove that by\ninterpolating the distributions of the correct predictions and the wrong\npredictions, we can uncover an oracle distribution where the unstable\ncorrelation vanishes. Since the oracle interpolation coefficients are not\naccessible, we use group distributionally robust optimization to minimize the\nworst-case risk across all such interpolations. We evaluate our method on both\ntext classification and image classification. Empirical results demonstrate\nthat our algorithm is able to learn robust classifiers (outperforms IRM by\n23.85% on synthetic environments and 12.41% on natural environments). Our code\nand data are available at https://github.com/YujiaBao/Predict-then-Interpolate.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 15:37:48 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Bao", "Yujia", ""], ["Chang", "Shiyu", ""], ["Barzilay", "Regina", ""]]}, {"id": "2105.12639", "submitter": "Namuk Park", "authors": "Namuk Park, Songkuk Kim", "title": "Blurs Make Results Clearer: Spatial Smoothings to Improve Accuracy,\n  Uncertainty, and Robustness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian neural networks (BNNs) have shown success in the areas of\nuncertainty estimation and robustness. However, a crucial challenge prohibits\ntheir use in practice: Bayesian NNs require a large number of predictions to\nproduce reliable results, leading to a significant increase in computational\ncost. To alleviate this issue, we propose spatial smoothing, a method that\nensembles neighboring feature map points of CNNs. By simply adding a few blur\nlayers to the models, we empirically show that the spatial smoothing improves\naccuracy, uncertainty estimation, and robustness of BNNs across a whole range\nof ensemble sizes. In particular, BNNs incorporating the spatial smoothing\nachieve high predictive performance merely with a handful of ensembles.\nMoreover, this method also can be applied to canonical deterministic neural\nnetworks to improve the performances. A number of evidences suggest that the\nimprovements can be attributed to the smoothing and flattening of the loss\nlandscape. In addition, we provide a fundamental explanation for prior works -\nnamely, global average pooling, pre-activation, and ReLU6 - by addressing to\nthem as special cases of the spatial smoothing. These not only enhance\naccuracy, but also improve uncertainty estimation and robustness by making the\nloss landscape smoother in the same manner as the spatial smoothing. The code\nis available at https://github.com/xxxnell/spatial-smoothing.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 15:58:11 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Park", "Namuk", ""], ["Kim", "Songkuk", ""]]}, {"id": "2105.12655", "submitter": "Ruchir Puri", "authors": "Ruchir Puri, David S. Kung, Geert Janssen, Wei Zhang, Giacomo\n  Domeniconi, Vladmir Zolotov, Julian Dolby, Jie Chen, Mihir Choudhury, Lindsey\n  Decker, Veronika Thost, Luca Buratti, Saurabh Pujar, Ulrich Finkler", "title": "Project CodeNet: A Large-Scale AI for Code Dataset for Learning a\n  Diversity of Coding Tasks", "comments": "11 Pages including references, 10 pages of appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in deep learning and machine learning algorithms have enabled\nbreakthrough progress in computer vision, speech recognition, natural language\nprocessing and beyond. In addition, over the last several decades, software has\nbeen built into the fabric of every aspect of our society. Together, these two\ntrends have generated new interest in the fast-emerging research area of AI for\nCode. As software development becomes ubiquitous across all industries and code\ninfrastructure of enterprise legacy applications ages, it is more critical than\never to increase software development productivity and modernize legacy\napplications. Over the last decade, datasets like ImageNet, with its large\nscale and diversity, have played a pivotal role in algorithmic advancements\nfrom computer vision to language and speech understanding. In this paper, we\npresent Project CodeNet, a first-of-its-kind, very large scale, diverse, and\nhigh-quality dataset to accelerate the algorithmic advancements in AI for Code.\nIt consists of 14M code samples and about 500M lines of code in 55 different\nprogramming languages. Project CodeNet is not only unique in its scale, but\nalso in the diversity of coding tasks it can help benchmark: from code\nsimilarity and classification for advances in code recommendation algorithms,\nand code translation between a large variety programming languages, to advances\nin code performance (both runtime, and memory) improvement techniques. CodeNet\nalso provides sample input and output test sets for over 7M code samples, which\ncan be critical for determining code equivalence in different languages. As a\nusability feature, we provide several preprocessing tools in Project CodeNet to\ntransform source codes into representations that can be readily used as inputs\ninto machine learning models.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 00:13:29 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Puri", "Ruchir", ""], ["Kung", "David S.", ""], ["Janssen", "Geert", ""], ["Zhang", "Wei", ""], ["Domeniconi", "Giacomo", ""], ["Zolotov", "Vladmir", ""], ["Dolby", "Julian", ""], ["Chen", "Jie", ""], ["Choudhury", "Mihir", ""], ["Decker", "Lindsey", ""], ["Thost", "Veronika", ""], ["Buratti", "Luca", ""], ["Pujar", "Saurabh", ""], ["Finkler", "Ulrich", ""]]}, {"id": "2105.12682", "submitter": "Luyang Kong", "authors": "Luyang Kong, Christopher Winestock, Parminder Bhatia", "title": "Zero-shot Medical Entity Retrieval without Annotation: Learning From\n  Rich Knowledge Graph Semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Medical entity retrieval is an integral component for understanding and\ncommunicating information across various health systems. Current approaches\ntend to work well on specific medical domains but generalize poorly to unseen\nsub-specialties. This is of increasing concern under a public health crisis as\nnew medical conditions and drug treatments come to light frequently. Zero-shot\nretrieval is challenging due to the high degree of ambiguity and variability in\nmedical corpora, making it difficult to build an accurate similarity measure\nbetween mentions and concepts. Medical knowledge graphs (KG), however, contain\nrich semantics including large numbers of synonyms as well as its curated\ngraphical structures. To take advantage of this valuable information, we\npropose a suite of learning tasks designed for training efficient zero-shot\nentity retrieval models. Without requiring any human annotation, our knowledge\ngraph enriched architecture significantly outperforms common zero-shot\nbenchmarks including BM25 and Clinical BERT with 7% to 30% higher recall across\nmultiple major medical ontologies, such as UMLS, SNOMED, and ICD-10.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 16:53:48 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Kong", "Luyang", ""], ["Winestock", "Christopher", ""], ["Bhatia", "Parminder", ""]]}, {"id": "2105.12724", "submitter": "Boyuan Chen", "authors": "Boyuan Chen, Yuhang Hu, Lianfeng Li, Sara Cummings, Hod Lipson", "title": "Smile Like You Mean It: Driving Animatronic Robotic Face with Learned\n  Models", "comments": "ICRA 2021. Website:http://www.cs.columbia.edu/~bchen/aiface/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ability to generate intelligent and generalizable facial expressions is\nessential for building human-like social robots. At present, progress in this\nfield is hindered by the fact that each facial expression needs to be\nprogrammed by humans. In order to adapt robot behavior in real time to\ndifferent situations that arise when interacting with human subjects, robots\nneed to be able to train themselves without requiring human labels, as well as\nmake fast action decisions and generalize the acquired knowledge to diverse and\nnew contexts. We addressed this challenge by designing a physical animatronic\nrobotic face with soft skin and by developing a vision-based self-supervised\nlearning framework for facial mimicry. Our algorithm does not require any\nknowledge of the robot's kinematic model, camera calibration or predefined\nexpression set. By decomposing the learning process into a generative model and\nan inverse model, our framework can be trained using a single motor babbling\ndataset. Comprehensive evaluations show that our method enables accurate and\ndiverse face mimicry across diverse human subjects. The project website is at\nhttp://www.cs.columbia.edu/~bchen/aiface/\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 17:57:19 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Chen", "Boyuan", ""], ["Hu", "Yuhang", ""], ["Li", "Lianfeng", ""], ["Cummings", "Sara", ""], ["Lipson", "Hod", ""]]}, {"id": "2105.12754", "submitter": "Margot Hanley", "authors": "Margot Hanley, Solon Barocas, Karen Levy, Shiri Azenkot, Helen\n  Nissenbaum", "title": "Computer Vision and Conflicting Values: Describing People with Automated\n  Alt Text", "comments": null, "journal-ref": "Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and\n  Society (AIES '21)", "doi": "10.1145/3461702.3462620", "report-no": null, "categories": "cs.CY cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Scholars have recently drawn attention to a range of controversial issues\nposed by the use of computer vision for automatically generating descriptions\nof people in images. Despite these concerns, automated image description has\nbecome an important tool to ensure equitable access to information for blind\nand low vision people. In this paper, we investigate the ethical dilemmas faced\nby companies that have adopted the use of computer vision for producing alt\ntext: textual descriptions of images for blind and low vision people, We use\nFacebook's automatic alt text tool as our primary case study. First, we analyze\nthe policies that Facebook has adopted with respect to identity categories,\nsuch as race, gender, age, etc., and the company's decisions about whether to\npresent these terms in alt text. We then describe an alternative -- and manual\n-- approach practiced in the museum community, focusing on how museums\ndetermine what to include in alt text descriptions of cultural artifacts. We\ncompare these policies, using notable points of contrast to develop an analytic\nframework that characterizes the particular apprehensions behind these policy\nchoices. We conclude by considering two strategies that seem to sidestep some\nof these concerns, finding that there are no easy ways to avoid the normative\ndilemmas posed by the use of computer vision to automate alt text.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 18:01:16 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Hanley", "Margot", ""], ["Barocas", "Solon", ""], ["Levy", "Karen", ""], ["Azenkot", "Shiri", ""], ["Nissenbaum", "Helen", ""]]}, {"id": "2105.12774", "submitter": "Sabyasachi Sahoo", "authors": "Prashant Kumar, Sabyasachi Sahoo, Vanshil Shah, Vineetha Kondameedi,\n  Abhinav Jain, Akshaj Verma, Chiranjib Bhattacharyya, Vinay Viswanathan", "title": "DSLR: Dynamic to Static LiDAR Scan Reconstruction Using Adversarially\n  Trained Autoencoder", "comments": "17 pages, 15 figures, Accepted at AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate reconstruction of static environments from LiDAR scans of scenes\ncontaining dynamic objects, which we refer to as Dynamic to Static Translation\n(DST), is an important area of research in Autonomous Navigation. This problem\nhas been recently explored for visual SLAM, but to the best of our knowledge no\nwork has been attempted to address DST for LiDAR scans. The problem is of\ncritical importance due to wide-spread adoption of LiDAR in Autonomous\nVehicles. We show that state-of the art methods developed for the visual domain\nwhen adapted for LiDAR scans perform poorly.\n  We develop DSLR, a deep generative model which learns a mapping between\ndynamic scan to its static counterpart through an adversarially trained\nautoencoder. Our model yields the first solution for DST on LiDAR that\ngenerates static scans without using explicit segmentation labels. DSLR cannot\nalways be applied to real world data due to lack of paired dynamic-static\nscans. Using Unsupervised Domain Adaptation, we propose DSLR-UDA for transfer\nto real world data and experimentally show that this performs well in real\nworld settings. Additionally, if segmentation information is available, we\nextend DSLR to DSLR-Seg to further improve the reconstruction quality.\n  DSLR gives the state of the art performance on simulated and real-world\ndatasets and also shows at least 4x improvement. We show that DSLR, unlike the\nexisting baselines, is a practically viable model with its reconstruction\nquality within the tolerable limits for tasks pertaining to autonomous\nnavigation like SLAM in dynamic environments.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 18:19:21 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Kumar", "Prashant", ""], ["Sahoo", "Sabyasachi", ""], ["Shah", "Vanshil", ""], ["Kondameedi", "Vineetha", ""], ["Jain", "Abhinav", ""], ["Verma", "Akshaj", ""], ["Bhattacharyya", "Chiranjib", ""], ["Viswanathan", "Vinay", ""]]}, {"id": "2105.12781", "submitter": "Supreeth Mysore Shivanandamurthy", "authors": "Supreeth Mysore Shivanandamurthy, Ishan. G. Thakkar, Sayed Ahmad\n  Salehi", "title": "ATRIA: A Bit-Parallel Stochastic Arithmetic Based Accelerator for\n  In-DRAM CNN Processing", "comments": "Preprint accepted in ISVLSI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With the rapidly growing use of Convolutional Neural Networks (CNNs) in\nreal-world applications related to machine learning and Artificial Intelligence\n(AI), several hardware accelerator designs for CNN inference and training have\nbeen proposed recently. In this paper, we present ATRIA, a novel bit-pArallel\nsTochastic aRithmetic based In-DRAM Accelerator for energy-efficient and\nhigh-speed inference of CNNs. ATRIA employs light-weight modifications in DRAM\ncell arrays to implement bit-parallel stochastic arithmetic based acceleration\nof multiply-accumulate (MAC) operations inside DRAM. ATRIA significantly\nimproves the latency, throughput, and efficiency of processing CNN inferences\nby performing 16 MAC operations in only five consecutive memory operation\ncycles. We mapped the inference tasks of four benchmark CNNs on ATRIA to\ncompare its performance with five state-of-the-art in-DRAM CNN accelerators\nfrom prior work. The results of our analysis show that ATRIA exhibits only 3.5%\ndrop in CNN inference accuracy and still achieves improvements of up to 3.2x in\nframes-per-second (FPS) and up to 10x in efficiency (FPS/W/mm2), compared to\nthe best-performing in-DRAM accelerator from prior work.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 18:36:01 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Shivanandamurthy", "Supreeth Mysore", ""], ["Thakkar", "Ishan. G.", ""], ["Salehi", "Sayed Ahmad", ""]]}, {"id": "2105.12807", "submitter": "Xiaoyu Zhang", "authors": "Eloise Withnell, Xiaoyu Zhang, Kai Sun, Yike Guo", "title": "XOmiVAE: an interpretable deep learning model for cancer classification\n  using high-dimensional omics data", "comments": "12 pages, 7 figures, 10 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.AI cs.LG q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lack of explainability is one of the most prominent disadvantages of deep\nlearning applications in omics. This \"black box\" problem can undermine the\ncredibility and limit the practical implementation of biomedical deep learning\nmodels. Here we present XOmiVAE, a variational autoencoder (VAE) based\ninterpretable deep learning model for cancer classification using\nhigh-dimensional omics data. XOmiVAE is capable of revealing the contribution\nof each gene and latent dimension for each classification prediction, and the\ncorrelation between each gene and each latent dimension. It is also\ndemonstrated that XOmiVAE can explain not only the supervised classification\nbut the unsupervised clustering results from the deep learning network. To the\nbest of our knowledge, XOmiVAE is one of the first activation level-based\ninterpretable deep learning models explaining novel clusters generated by VAE.\nThe explainable results generated by XOmiVAE were validated by both the\nperformance of downstream tasks and the biomedical knowledge. In our\nexperiments, XOmiVAE explanations of deep learning based cancer classification\nand clustering aligned with current domain knowledge including biological\nannotation and academic literature, which shows great potential for novel\nbiomedical knowledge discovery from deep learning models.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 19:55:12 GMT"}, {"version": "v2", "created": "Sun, 4 Jul 2021 08:50:15 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Withnell", "Eloise", ""], ["Zhang", "Xiaoyu", ""], ["Sun", "Kai", ""], ["Guo", "Yike", ""]]}, {"id": "2105.12815", "submitter": "Anna Grim", "authors": "Anna Grim and Pedro Felzenszwalb", "title": "Convex Combination Belief Propagation Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce new message passing algorithms for inference with graphical\nmodels. The standard min-sum and sum-product belief propagation algorithms are\nguaranteed to converge when the graph is tree-structured, but may not converge\nand can be sensitive to the initialization when the graph contains cycles. This\npaper describes modifications to the standard belief propagation algorithms\nthat are guaranteed to converge to a unique solution regardless of the topology\nof the graph.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 20:06:57 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Grim", "Anna", ""], ["Felzenszwalb", "Pedro", ""]]}, {"id": "2105.12823", "submitter": "Alireza Shamsoshoara", "authors": "Alireza Shamsoshoara, Fatemeh Afghah, Erik Blasch, Jonathan Ashdown,\n  Mehdi Bennis", "title": "UAV-Assisted Communication in Remote Disaster Areas using Imitation\n  Learning", "comments": "15 pages, 14 Figures, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The damage to cellular towers during natural and man-made disasters can\ndisturb the communication services for cellular users. One solution to the\nproblem is using unmanned aerial vehicles to augment the desired communication\nnetwork. The paper demonstrates the design of a UAV-Assisted Imitation Learning\n(UnVAIL) communication system that relays the cellular users' information to a\nneighbor base station. Since the user equipment (UEs) are equipped with buffers\nwith limited capacity to hold packets, UnVAIL alternates between different UEs\nto reduce the chance of buffer overflow, positions itself optimally close to\nthe selected UE to reduce service time, and uncovers a network pathway by\nacting as a relay node. UnVAIL utilizes Imitation Learning (IL) as a\ndata-driven behavioral cloning approach to accomplish an optimal scheduling\nsolution. Results demonstrate that UnVAIL performs similar to a human expert\nknowledge-based planning in communication timeliness, position accuracy, and\nenergy consumption with an accuracy of 97.52% when evaluated on a developed\nsimulator to train the UAV.\n", "versions": [{"version": "v1", "created": "Fri, 2 Apr 2021 00:26:44 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Shamsoshoara", "Alireza", ""], ["Afghah", "Fatemeh", ""], ["Blasch", "Erik", ""], ["Ashdown", "Jonathan", ""], ["Bennis", "Mehdi", ""]]}, {"id": "2105.12846", "submitter": "Matthew Stephenson", "authors": "Matthew Stephenson, Dennis J. N. J. Soemers, Eric Piette, Cameron\n  Browne", "title": "General Game Heuristic Prediction Based on Ludeme Descriptions", "comments": "4 pages, 1 figure, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the performance of different general-game-playing\nheuristics for games in the Ludii general game system. Based on these results,\nwe train several regression learning models to predict the performance of these\nheuristics based on each game's description file. We also provide a condensed\nanalysis of the games available in Ludii, and the different ludemes that define\nthem.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 21:17:47 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 07:16:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Stephenson", "Matthew", ""], ["Soemers", "Dennis J. N. J.", ""], ["Piette", "Eric", ""], ["Browne", "Cameron", ""]]}, {"id": "2105.12887", "submitter": "Chuan-An Lin", "authors": "Nazib Sorathiya, Chuan-An Lin, Daniel Chen Daniel Xiong, Scott Zin, Yi\n  Zhang, He Sarina Yang, Sharon Xiaolei Huang", "title": "Multi-turn Dialog System on Single-turn Data in Medical Domain", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently there has been a huge interest in dialog systems. This interest has\nalso been developed in the field of the medical domain where researchers are\nfocusing on building a dialog system in the medical domain. This research is\nfocused on the multi-turn dialog system trained on the multi-turn dialog data.\nIt is difficult to gather a huge amount of multi-turn conversational data in\nthe medical domain that is verified by professionals and can be trusted.\nHowever, there are several frequently asked questions (FAQs) or single-turn QA\npairs that have information that is verified by the experts and can be used to\nbuild a multi-turn dialog system.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 00:42:11 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Sorathiya", "Nazib", ""], ["Lin", "Chuan-An", ""], ["Xiong", "Daniel Chen Daniel", ""], ["Zin", "Scott", ""], ["Zhang", "Yi", ""], ["Yang", "He Sarina", ""], ["Huang", "Sharon Xiaolei", ""]]}, {"id": "2105.12898", "submitter": "Duong Dung", "authors": "Tri Dung Duong, Qian Li, Guandong Xu", "title": "Stochastic Intervention for Causal Effect Estimation", "comments": "Accepted in IJCNN 21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal inference methods are widely applied in various decision-making\ndomains such as precision medicine, optimal policy and economics. Central to\nthese applications is the treatment effect estimation of intervention\nstrategies. Current estimation methods are mostly restricted to the\ndeterministic treatment, which however, is unable to address the stochastic\nspace treatment policies. Moreover, previous methods can only make binary\nyes-or-no decisions based on the treatment effect, lacking the capability of\nproviding fine-grained effect estimation degree to explain the process of\ndecision making. In our study, we therefore advance the causal inference\nresearch to estimate stochastic intervention effect by devising a new\nstochastic propensity score and stochastic intervention effect estimator (SIE).\nMeanwhile, we design a customized genetic algorithm specific to stochastic\nintervention effect (Ge-SIO) with the aim of providing causal evidence for\ndecision making. We provide the theoretical analysis and conduct an empirical\nstudy to justify that our proposed measures and algorithms can achieve a\nsignificant performance lift in comparison with state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 01:12:03 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Duong", "Tri Dung", ""], ["Li", "Qian", ""], ["Xu", "Guandong", ""]]}, {"id": "2105.12899", "submitter": "Xijun Li", "authors": "Xijun Li, Weilin Luo, Mingxuan Yuan, Jun Wang, Jiawen Lu, Jie Wang,\n  Jinhu Lu and Jia Zeng", "title": "Learning to Optimize Industry-Scale Dynamic Pickup and Delivery Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Dynamic Pickup and Delivery Problem (DPDP) is aimed at dynamically\nscheduling vehicles among multiple sites in order to minimize the cost when\ndelivery orders are not known a priori. Although DPDP plays an important role\nin modern logistics and supply chain management, state-of-the-art DPDP\nalgorithms are still limited on their solution quality and efficiency. In\npractice, they fail to provide a scalable solution as the numbers of vehicles\nand sites become large. In this paper, we propose a data-driven approach,\nSpatial-Temporal Aided Double Deep Graph Network (ST-DDGN), to solve\nindustry-scale DPDP. In our method, the delivery demands are first forecast\nusing spatial-temporal prediction method, which guides the neural network to\nperceive spatial-temporal distribution of delivery demand when dispatching\nvehicles. Besides, the relationships of individuals such as vehicles are\nmodelled by establishing a graph-based value function. ST-DDGN incorporates\nattention-based graph embedding with Double DQN (DDQN). As such, it can make\nthe inference across vehicles more efficiently compared with traditional\nmethods. Our method is entirely data driven and thus adaptive, i.e., the\nrelational representation of adjacent vehicles can be learned and corrected by\nST-DDGN from data periodically. We have conducted extensive experiments over\nreal-world data to evaluate our solution. The results show that ST-DDGN reduces\n11.27% number of the used vehicles and decreases 13.12% total transportation\ncost on average over the strong baselines, including the heuristic algorithm\ndeployed in our UAT (User Acceptance Test) environment and a variety of vanilla\nDRL methods. We are due to fully deploy our solution into our online logistics\nsystem and it is estimated that millions of USD logistics cost can be saved per\nyear.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 01:16:00 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Li", "Xijun", ""], ["Luo", "Weilin", ""], ["Yuan", "Mingxuan", ""], ["Wang", "Jun", ""], ["Lu", "Jiawen", ""], ["Wang", "Jie", ""], ["Lu", "Jinhu", ""], ["Zeng", "Jia", ""]]}, {"id": "2105.12908", "submitter": "Masood Feyzbakhsh Rankooh", "authors": "Masood Feyzbakhsh Rankooh, Jussi Rintanen", "title": "Propositional Encodings of Acyclicity and Reachability by using Vertex\n  Elimination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce novel methods for encoding acyclicity and s-t-reachability\nconstraints for propositional formulas with underlying directed graphs. They\nare based on vertex elimination graphs, which makes them suitable for cases\nwhere the underlying graph is sparse. In contrast to solvers with ad hoc\nconstraint propagators for acyclicity and reachability constraints such as\nGraphSAT, our methods encode these constraints as standard propositional\nclauses, making them directly applicable with any SAT solver. An empirical\nstudy demonstrates that our methods together with an efficient SAT solver can\noutperform both earlier encodings of these constraints as well as GraphSAT,\nparticularly when underlying graphs are sparse.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 01:57:53 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Rankooh", "Masood Feyzbakhsh", ""], ["Rintanen", "Jussi", ""]]}, {"id": "2105.12917", "submitter": "Yang Li", "authors": "Yang Li, Yi Zeng, Dongcheng Zhao", "title": "BSNN: Towards Faster and Better Conversion of Artificial Neural Networks\n  to Spiking Neural Networks with Bistable Neurons", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The spiking neural network (SNN) computes and communicates information\nthrough discrete binary events. It is considered more biologically plausible\nand more energy-efficient than artificial neural networks (ANN) in emerging\nneuromorphic hardware. However, due to the discontinuous and non-differentiable\ncharacteristics, training SNN is a relatively challenging task. Recent work has\nachieved essential progress on an excellent performance by converting ANN to\nSNN. Due to the difference in information processing, the converted deep SNN\nusually suffers serious performance loss and large time delay. In this paper,\nwe analyze the reasons for the performance loss and propose a novel bistable\nspiking neural network (BSNN) that addresses the problem of spikes of\ninactivated neurons (SIN) caused by the phase lead and phase lag. Also, when\nResNet structure-based ANNs are converted, the information of output neurons is\nincomplete due to the rapid transmission of the shortcut path. We design\nsynchronous neurons (SN) to help efficiently improve performance. Experimental\nresults show that the proposed method only needs 1/4-1/10 of the time steps\ncompared to previous work to achieve nearly lossless conversion. We demonstrate\nstate-of-the-art ANN-SNN conversion for VGG16, ResNet20, and ResNet34 on\nchallenging datasets including CIFAR-10 (95.16% top-1), CIFAR-100 (78.12%\ntop-1), and ImageNet (72.64% top-1).\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 02:38:02 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Li", "Yang", ""], ["Zeng", "Yi", ""], ["Zhao", "Dongcheng", ""]]}, {"id": "2105.12918", "submitter": "Likang Wu", "authors": "Likang Wu, Zhi Li, Hongke Zhao, Qi Liu, Enhong Chen", "title": "Estimating Fund-Raising Performance for Start-up Projects from a Market\n  Graph Perspective", "comments": "accepted by Pattern Recognition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the online innovation market, the fund-raising performance of the start-up\nproject is a concerning issue for creators, investors and platforms.\nUnfortunately, existing studies always focus on modeling the fund-raising\nprocess after the publishment of a project but the predicting of a project\nattraction in the market before setting up is largely unexploited. Usually,\nthis prediction is always with great challenges to making a comprehensive\nunderstanding of both the start-up project and market environment. To that end,\nin this paper, we present a focused study on this important problem from a\nmarket graph perspective. Specifically, we propose a Graph-based Market\nEnvironment (GME) model for predicting the fund-raising performance of the\nunpublished project by exploiting the market environment. In addition, we\ndiscriminatively model the project competitiveness and market preferences by\ndesigning two graph-based neural network architectures and incorporating them\ninto a joint optimization stage. Furthermore, to explore the information\npropagation problem with dynamic environment in a large-scale market graph, we\nextend the GME model with parallelizing competitiveness quantification and\nhierarchical propagation algorithm. Finally, we conduct extensive experiments\non real-world data. The experimental results clearly demonstrate the\neffectiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 02:39:30 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wu", "Likang", ""], ["Li", "Zhi", ""], ["Zhao", "Hongke", ""], ["Liu", "Qi", ""], ["Chen", "Enhong", ""]]}, {"id": "2105.12923", "submitter": "Tianqi Wang", "authors": "Tianqi Wang, Dong Eui Chang", "title": "Robust Navigation for Racing Drones based on Imitation Learning and\n  Modularization", "comments": "Published at the 2021 International Conference on Robotics and\n  Automation (ICRA 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a vision-based modularized drone racing navigation system\nthat uses a customized convolutional neural network (CNN) for the perception\nmodule to produce high-level navigation commands and then leverages a\nstate-of-the-art planner and controller to generate low-level control commands,\nthus exploiting the advantages of both data-based and model-based approaches.\nUnlike the state-of-the-art method which only takes the current camera image as\nthe CNN input, we further add the latest three drone states as part of the\ninputs. Our method outperforms the state-of-the-art method in various track\nlayouts and offers two switchable navigation behaviors with a single trained\nnetwork. The CNN-based perception module is trained to imitate an expert policy\nthat automatically generates ground truth navigation commands based on the\npre-computed global trajectories. Owing to the extensive randomization and our\nmodified dataset aggregation (DAgger) policy during data collection, our\nnavigation system, which is purely trained in simulation with synthetic\ntextures, successfully operates in environments with randomly-chosen\nphotorealistic textures without further fine-tuning.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 03:26:40 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wang", "Tianqi", ""], ["Chang", "Dong Eui", ""]]}, {"id": "2105.12926", "submitter": "Changye Yang", "authors": "Changye Yang, Sriram Baireddy, Enyu Cai, Valerian Meline, Denise\n  Caldwell, Anjali S. Iyer-Pascuzzi, Edward J. Delp", "title": "Image-Based Plant Wilting Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many plants become limp or droop through heat, loss of water, or disease.\nThis is also known as wilting. In this paper, we examine plant wilting caused\nby bacterial infection. In particular, we want to design a metric for wilting\nbased on images acquired of the plant. A quantifiable wilting metric will be\nuseful in studying bacterial wilt and identifying resistance genes. Since there\nis no standard way to estimate wilting, it is common to use ad hoc visual\nscores. This is very subjective and requires expert knowledge of the plants and\nthe disease mechanism. Our solution consists of using various wilting metrics\nacquired from RGB images of the plants. We also designed several experiments to\ndemonstrate that our metrics are effective at estimating wilting in plants.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 03:29:21 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Yang", "Changye", ""], ["Baireddy", "Sriram", ""], ["Cai", "Enyu", ""], ["Meline", "Valerian", ""], ["Caldwell", "Denise", ""], ["Iyer-Pascuzzi", "Anjali S.", ""], ["Delp", "Edward J.", ""]]}, {"id": "2105.12954", "submitter": "Gabriele Farina", "authors": "Gabriele Farina, Christian Kroer, Tuomas Sandholm", "title": "Better Regularization for Sequential Decision Spaces: Fast Convergence\n  Rates for Nash, Correlated, and Team Equilibria", "comments": "Accepted for publication at EC21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the application of iterative first-order methods to the problem of\ncomputing equilibria of large-scale two-player extensive-form games.\nFirst-order methods must typically be instantiated with a regularizer that\nserves as a distance-generating function for the decision sets of the players.\nFor the case of two-player zero-sum games, the state-of-the-art theoretical\nconvergence rate for Nash equilibrium is achieved by using the dilated entropy\nfunction. In this paper, we introduce a new entropy-based distance-generating\nfunction for two-player zero-sum games, and show that this function achieves\nsignificantly better strong convexity properties than the dilated entropy,\nwhile maintaining the same easily-implemented closed-form proximal mapping.\nExtensive numerical simulations show that these superior theoretical properties\ntranslate into better numerical performance as well.\n  We then generalize our new entropy distance function, as well as general\ndilated distance functions, to the scaled extension operator. The scaled\nextension operator is a way to recursively construct convex sets, which\ngeneralizes the decision polytope of extensive-form games, as well as the\nconvex polytopes corresponding to correlated and team equilibria. By\ninstantiating first-order methods with our regularizers, we develop the first\naccelerated first-order methods for computing correlated equilibra and ex-ante\ncoordinated team equilibria. Our methods have a guaranteed $1/T$ rate of\nconvergence, along with linear-time proximal updates.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 06:10:24 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Farina", "Gabriele", ""], ["Kroer", "Christian", ""], ["Sandholm", "Tuomas", ""]]}, {"id": "2105.12960", "submitter": "Jacob Schrum", "authors": "Jacob Schrum, Benjamin Capps, Kirby Steckel, Vanessa Volz, Sebastian\n  Risi", "title": "Hybrid Encoding For Generating Large Scale Game Level Patterns With\n  Local Variations Using a GAN", "comments": "arXiv admin note: substantial text overlap with arXiv:2004.01703", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are a powerful indirect\ngenotype-to-phenotype mapping for evolutionary search, but they have\nlimitations. In particular, GAN output does not scale to arbitrary dimensions,\nand there is no obvious way to combine GAN outputs into a cohesive whole, which\nwould be useful in many areas, such as video game level generation. Game levels\noften consist of several segments, sometimes repeated directly or with\nvariation, organized into an engaging pattern. Such patterns can be produced\nwith Compositional Pattern Producing Networks (CPPNs). Specifically, a CPPN can\ndefine latent vector GAN inputs as a function of geometry, which provides a way\nto organize level segments output by a GAN into a complete level. However, a\ncollection of latent vectors can also be evolved directly, to produce more\nchaotic levels. Here, we propose a new hybrid approach that evolves CPPNs\nfirst, but allows the latent vectors to evolve later, and combines the benefits\nof both approaches. These approaches are evaluated in Super Mario Bros. and The\nLegend of Zelda. We previously demonstrated via divergent search (MAP-Elites)\nthat CPPNs better cover the space of possible levels than directly evolved\nlevels. Here, we show that the hybrid approach can cover areas that neither of\nthe other methods can and achieves comparable or superior QD scores.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 06:27:19 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Schrum", "Jacob", ""], ["Capps", "Benjamin", ""], ["Steckel", "Kirby", ""], ["Volz", "Vanessa", ""], ["Risi", "Sebastian", ""]]}, {"id": "2105.12964", "submitter": "Tan Sixiang", "authors": "Tan Sixiang", "title": "Feature Reuse and Fusion for Real-time Semantic segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For real-time semantic segmentation, how to increase the speed while\nmaintaining high resolution is a problem that has been discussed and solved.\nBackbone design and fusion design have always been two essential parts of\nreal-time semantic segmentation. We hope to design a light-weight network based\non previous design experience and reach the level of state-of-the-art real-time\nsemantic segmentation without any pre-training. To achieve this goal, a\nencoder-decoder architectures are proposed to solve this problem by applying a\ndecoder network onto a backbone model designed for real-time segmentation tasks\nand designed three different ways to fuse semantics and detailed information in\nthe aggregation phase. We have conducted extensive experiments on two semantic\nsegmentation benchmarks. Experiments on the Cityscapes and CamVid datasets show\nthat the proposed FRFNet strikes a balance between speed calculation and\naccuracy. It achieves 72% Mean Intersection over Union (mIoU%) on the\nCityscapes test dataset with the speed of 144 on a single RTX 1080Ti card. The\nCode is available at https://github.com/favoMJ/FRFNet.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 06:47:02 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 15:56:13 GMT"}, {"version": "v3", "created": "Fri, 18 Jun 2021 07:17:09 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Sixiang", "Tan", ""]]}, {"id": "2105.12967", "submitter": "Fandong Meng", "authors": "Fusheng Wang, Jianhao Yan, Fandong Meng, Jie Zhou", "title": "Selective Knowledge Distillation for Neural Machine Translation", "comments": "Accepted as a long paper at ACL 2021. Code is available at\n  https://github.com/LeslieOverfitting/selective_distillation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) models achieve state-of-the-art performance\non many translation benchmarks. As an active research field in NMT, knowledge\ndistillation is widely applied to enhance the model's performance by\ntransferring teacher model's knowledge on each training sample. However,\nprevious work rarely discusses the different impacts and connections among\nthese samples, which serve as the medium for transferring teacher knowledge. In\nthis paper, we design a novel protocol that can effectively analyze the\ndifferent impacts of samples by comparing various samples' partitions. Based on\nabove protocol, we conduct extensive experiments and find that the teacher's\nknowledge is not the more, the better. Knowledge over specific samples may even\nhurt the whole performance of knowledge distillation. Finally, to address these\nissues, we propose two simple yet effective strategies, i.e., batch-level and\nglobal-level selections, to pick suitable samples for distillation. We evaluate\nour approaches on two large-scale machine translation tasks, WMT'14\nEnglish->German and WMT'19 Chinese->English. Experimental results show that our\napproaches yield up to +1.28 and +0.89 BLEU points improvements over the\nTransformer baseline, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 06:54:12 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wang", "Fusheng", ""], ["Yan", "Jianhao", ""], ["Meng", "Fandong", ""], ["Zhou", "Jie", ""]]}, {"id": "2105.12971", "submitter": "Renjie Pi Mr", "authors": "Lewei Yao, Renjie Pi, Hang Xu, Wei Zhang, Zhenguo Li, Tong Zhang", "title": "Joint-DetNAS: Upgrade Your Detector with NAS, Pruning and Dynamic\n  Distillation", "comments": "Accepted by CVPR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Joint-DetNAS, a unified NAS framework for object detection, which\nintegrates 3 key components: Neural Architecture Search, pruning, and Knowledge\nDistillation. Instead of naively pipelining these techniques, our Joint-DetNAS\noptimizes them jointly. The algorithm consists of two core processes: student\nmorphism optimizes the student's architecture and removes the redundant\nparameters, while dynamic distillation aims to find the optimal matching\nteacher. For student morphism, weight inheritance strategy is adopted, allowing\nthe student to flexibly update its architecture while fully utilize the\npredecessor's weights, which considerably accelerates the search; To facilitate\ndynamic distillation, an elastic teacher pool is trained via integrated\nprogressive shrinking strategy, from which teacher detectors can be sampled\nwithout additional cost in subsequent searches. Given a base detector as the\ninput, our algorithm directly outputs the derived student detector with high\nperformance without additional training. Experiments demonstrate that our\nJoint-DetNAS outperforms the naive pipelining approach by a great margin. Given\na classic R101-FPN as the base detector, Joint-DetNAS is able to boost its mAP\nfrom 41.4 to 43.9 on MS COCO and reduce the latency by 47%, which is on par\nwith the SOTA EfficientDet while requiring less search cost. We hope our\nproposed method can provide the community with a new way of jointly optimizing\nNAS, KD and pruning.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 07:25:43 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Yao", "Lewei", ""], ["Pi", "Renjie", ""], ["Xu", "Hang", ""], ["Zhang", "Wei", ""], ["Li", "Zhenguo", ""], ["Zhang", "Tong", ""]]}, {"id": "2105.12986", "submitter": "Arianna Casanova", "authors": "Juerg Kohlas, Arianna Casanova, Marco Zaffalon", "title": "Algebras of Sets and Coherent Sets of Gambles", "comments": "Submitted to ECSQARU 2021. arXiv admin note: text overlap with\n  arXiv:2105.12037", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a recent work we have shown how to construct an information algebra of\ncoherent sets of gambles defined on general possibility spaces. Here we analyze\nthe connection of such an algebra with the set algebra of subsets of the\npossibility space on which gambles are defined and the set algebra of sets of\nits atoms. Set algebras are particularly important information algebras since\nthey are their prototypical structures. Furthermore, they are the algebraic\ncounterparts of classical propositional logic. As a consequence, this paper\nalso details how propositional logic is naturally embedded into the theory of\nimprecise probabilities.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 08:14:38 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Kohlas", "Juerg", ""], ["Casanova", "Arianna", ""], ["Zaffalon", "Marco", ""]]}, {"id": "2105.12995", "submitter": "Thomas Dopierre", "authors": "Thomas Dopierre, Christophe Gravier, Wilfried Logerais", "title": "ProtAugment: Unsupervised diverse short-texts paraphrasing for intent\n  detection meta-learning", "comments": "Accepted at the 59th Annual Meeting of the Association for\n  Computational Linguistics (ACL2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research considers few-shot intent detection as a meta-learning\nproblem: the model is learning to learn from a consecutive set of small tasks\nnamed episodes. In this work, we propose ProtAugment, a meta-learning algorithm\nfor short texts classification (the intent detection task). ProtAugment is a\nnovel extension of Prototypical Networks, that limits overfitting on the bias\nintroduced by the few-shots classification objective at each episode. It relies\non diverse paraphrasing: a conditional language model is first fine-tuned for\nparaphrasing, and diversity is later introduced at the decoding stage at each\nmeta-learning episode. The diverse paraphrasing is unsupervised as it is\napplied to unlabelled data, and then fueled to the Prototypical Network\ntraining objective as a consistency loss. ProtAugment is the state-of-the-art\nmethod for intent detection meta-learning, at no extra labeling efforts and\nwithout the need to fine-tune a conditional language model on a given\napplication domain.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 08:31:27 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Dopierre", "Thomas", ""], ["Gravier", "Christophe", ""], ["Logerais", "Wilfried", ""]]}, {"id": "2105.13031", "submitter": "Dario  Izzo", "authors": "Dario Izzo and Pablo G\\'omez", "title": "Geodesy of irregular small bodies via neural density fields: geodesyNets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.EP cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel approach based on artificial neural networks, so-called\ngeodesyNets, and present compelling evidence of their ability to serve as\naccurate geodetic models of highly irregular bodies using minimal prior\ninformation on the body. The approach does not rely on the body shape\ninformation but, if available, can harness it. GeodesyNets learn a\nthree-dimensional, differentiable, function representing the body density,\nwhich we call neural density field. The body shape, as well as other geodetic\nproperties, can easily be recovered. We investigate six different shapes\nincluding the bodies 101955 Bennu, 67P Churyumov-Gerasimenko, 433 Eros and\n25143 Itokawa for which shape models developed during close proximity surveys\nare available. Both heterogeneous and homogeneous mass distributions are\nconsidered. The gravitational acceleration computed from the trained\ngeodesyNets models, as well as the inferred body shape, show great accuracy in\nall cases with a relative error on the predicted acceleration smaller than 1\\%\neven close to the asteroid surface. When the body shape information is\navailable, geodesyNets can seamlessly exploit it and be trained to represent a\nhigh-fidelity neural density field able to give insights into the internal\nstructure of the body. This work introduces a new unexplored approach to\ngeodesy, adding a powerful tool to consolidated ones based on spherical\nharmonics, mascon models and polyhedral gravity.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 09:56:12 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Izzo", "Dario", ""], ["G\u00f3mez", "Pablo", ""]]}, {"id": "2105.13066", "submitter": "Zijing Ou", "authors": "Zijing Ou, Qinliang Su, Jianxing Yu, Bang Liu, Jingwen Wang, Ruihui\n  Zhao, Changyou Chen and Yefeng Zheng", "title": "Integrating Semantics and Neighborhood Information with Graph-Driven\n  Generative Models for Document Retrieval", "comments": null, "journal-ref": "ACL2021", "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the need of fast retrieval speed and small memory footprint, document\nhashing has been playing a crucial role in large-scale information retrieval.\nTo generate high-quality hashing code, both semantics and neighborhood\ninformation are crucial. However, most existing methods leverage only one of\nthem or simply combine them via some intuitive criteria, lacking a theoretical\nprinciple to guide the integration process. In this paper, we encode the\nneighborhood information with a graph-induced Gaussian distribution, and\npropose to integrate the two types of information with a graph-driven\ngenerative model. To deal with the complicated correlations among documents, we\nfurther propose a tree-structured approximation method for learning. Under the\napproximation, we prove that the training objective can be decomposed into\nterms involving only singleton or pairwise documents, enabling the model to be\ntrained as efficiently as uncorrelated ones. Extensive experimental results on\nthree benchmark datasets show that our method achieves superior performance\nover state-of-the-art methods, demonstrating the effectiveness of the proposed\nmodel for simultaneously preserving semantic and neighborhood information.\\\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 11:29:03 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Ou", "Zijing", ""], ["Su", "Qinliang", ""], ["Yu", "Jianxing", ""], ["Liu", "Bang", ""], ["Wang", "Jingwen", ""], ["Zhao", "Ruihui", ""], ["Chen", "Changyou", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2105.13073", "submitter": "Zujie Liang", "authors": "Zujie Liang, Huang Hu, Can Xu, Chongyang Tao, Xiubo Geng, Yining Chen,\n  Fan Liang and Daxin Jiang", "title": "Maria: A Visual Experience Powered Conversational Agent", "comments": "Accepted by ACL 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arguably, the visual perception of conversational agents to the physical\nworld is a key way for them to exhibit the human-like intelligence.\nImage-grounded conversation is thus proposed to address this challenge.\nExisting works focus on exploring the multimodal dialog models that ground the\nconversation on a given image. In this paper, we take a step further to study\nimage-grounded conversation under a fully open-ended setting where no paired\ndialog and image are assumed available. Specifically, we present Maria, a\nneural conversation agent powered by the visual world experiences which are\nretrieved from a large-scale image index. Maria consists of three flexible\ncomponents, i.e., text-to-image retriever, visual concept detector and\nvisual-knowledge-grounded response generator. The retriever aims to retrieve a\ncorrelated image to the dialog from an image index, while the visual concept\ndetector extracts rich visual knowledge from the image. Then, the response\ngenerator is grounded on the extracted visual knowledge and dialog context to\ngenerate the target response. Extensive experiments demonstrate Maria\noutperforms previous state-of-the-art methods on automatic metrics and human\nevaluation, and can generate informative responses that have some visual\ncommonsense of the physical world.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 11:45:29 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 09:48:55 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Liang", "Zujie", ""], ["Hu", "Huang", ""], ["Xu", "Can", ""], ["Tao", "Chongyang", ""], ["Geng", "Xiubo", ""], ["Chen", "Yining", ""], ["Liang", "Fan", ""], ["Jiang", "Daxin", ""]]}, {"id": "2105.13074", "submitter": "Yinyu Lan", "authors": "Yinyu Lan, Shizhu He, Xiangrong Zeng, Shengping Liu, Kang Liu, Jun\n  Zhao", "title": "Path-based knowledge reasoning with textual semantic information for\n  medical knowledge graph completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background Knowledge graphs (KGs), especially medical knowledge graphs, are\noften significantly incomplete, so it necessitating a demand for medical\nknowledge graph completion (MedKGC). MedKGC can find new facts based on the\nexited knowledge in the KGs. The path-based knowledge reasoning algorithm is\none of the most important approaches to this task. This type of method has\nreceived great attention in recent years because of its high performance and\ninterpretability. In fact, traditional methods such as path ranking algorithm\n(PRA) take the paths between an entity pair as atomic features. However, the\nmedical KGs are very sparse, which makes it difficult to model effective\nsemantic representation for extremely sparse path features. The sparsity in the\nmedical KGs is mainly reflected in the long-tailed distribution of entities and\npaths. Previous methods merely consider the context structure in the paths of\nthe knowledge graph and ignore the textual semantics of the symbols in the\npath. Therefore, their performance cannot be further improved due to the two\naspects of entity sparseness and path sparseness. To address the above issues,\nthis paper proposes two novel path-based reasoning methods to solve the\nsparsity issues of entity and path respectively, which adopts the textual\nsemantic information of entities and paths for MedKGC. By using the pre-trained\nmodel BERT, combining the textual semantic representations of the entities and\nthe relationships, we model the task of symbolic reasoning in the medical KG as\na numerical computing issue in textual semantic representation.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 11:45:59 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 02:38:35 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Lan", "Yinyu", ""], ["He", "Shizhu", ""], ["Zeng", "Xiangrong", ""], ["Liu", "Shengping", ""], ["Liu", "Kang", ""], ["Zhao", "Jun", ""]]}, {"id": "2105.13127", "submitter": "Lorenzo Pellegrini", "authors": "Lorenzo Pellegrini, Vincenzo Lomonaco, Gabriele Graffieti, Davide\n  Maltoni", "title": "Continual Learning at the Edge: Real-Time Training on Smartphone Devices", "comments": "6 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On-device training for personalized learning is a challenging research\nproblem. Being able to quickly adapt deep prediction models at the edge is\nnecessary to better suit personal user needs. However, adaptation on the edge\nposes some questions on both the efficiency and sustainability of the learning\nprocess and on the ability to work under shifting data distributions. Indeed,\nnaively fine-tuning a prediction model only on the newly available data results\nin catastrophic forgetting, a sudden erasure of previously acquired knowledge.\nIn this paper, we detail the implementation and deployment of a hybrid\ncontinual learning strategy (AR1*) on a native Android application for\nreal-time on-device personalization without forgetting. Our benchmark, based on\nan extension of the CORe50 dataset, shows the efficiency and effectiveness of\nour solution.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 12:00:31 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Pellegrini", "Lorenzo", ""], ["Lomonaco", "Vincenzo", ""], ["Graffieti", "Gabriele", ""], ["Maltoni", "Davide", ""]]}, {"id": "2105.13131", "submitter": "Soumyajit Chatterjee Mr.", "authors": "Ratna Mandal, Prasenjit Karmakar, Soumyajit Chatterjee, Debaleen Das\n  Spandan, Shouvit Pradhan, Sujoy Saha, Sandip Chakraborty and Subrata Nandi", "title": "Exploiting Multi-modal Contextual Sensing for City-bus's Stay Location\n  Characterization: Towards Sub-60 Seconds Accurate Arrival Time Prediction", "comments": "20 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent city transportation systems are one of the core infrastructures\nof a smart city. The true ingenuity of such an infrastructure lies in providing\nthe commuters with real-time information about citywide transports like public\nbuses, allowing her to pre-plan the travel. However, providing prior\ninformation for transportation systems like public buses in real-time is\ninherently challenging because of the diverse nature of different\nstay-locations that a public bus stops. Although straightforward factors stay\nduration, extracted from unimodal sources like GPS, at these locations look\nerratic, a thorough analysis of public bus GPS trails for 720km of bus travels\nat the city of Durgapur, a semi-urban city in India, reveals that several other\nfine-grained contextual features can characterize these locations accurately.\nAccordingly, we develop BuStop, a system for extracting and characterizing the\nstay locations from multi-modal sensing using commuters' smartphones. Using\nthis multi-modal information BuStop extracts a set of granular contextual\nfeatures that allow the system to differentiate among the different\nstay-location types. A thorough analysis of BuStop using the collected dataset\nindicates that the system works with high accuracy in identifying different\nstay locations like regular bus stops, random ad-hoc stops, stops due to\ntraffic congestion stops at traffic signals, and stops at sharp turns.\nAdditionally, we also develop a proof-of-concept setup on top of BuStop to\nanalyze the potential of the framework in predicting expected arrival time, a\ncritical piece of information required to pre-plan travel, at any given bus\nstop. Subsequent analysis of the PoC framework, through simulation over the\ntest dataset, shows that characterizing the stay-locations indeed helps make\nmore accurate arrival time predictions with deviations less than 60s from the\nground-truth arrival time.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 13:47:10 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Mandal", "Ratna", ""], ["Karmakar", "Prasenjit", ""], ["Chatterjee", "Soumyajit", ""], ["Spandan", "Debaleen Das", ""], ["Pradhan", "Shouvit", ""], ["Saha", "Sujoy", ""], ["Chakraborty", "Sandip", ""], ["Nandi", "Subrata", ""]]}, {"id": "2105.13135", "submitter": "Jinbae Im", "authors": "Jinbae Im, Moonki Kim, Hoyeop Lee, Hyunsouk Cho, Sehee Chung", "title": "Self-Supervised Multimodal Opinion Summarization", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recently, opinion summarization, which is the generation of a summary from\nmultiple reviews, has been conducted in a self-supervised manner by considering\na sampled review as a pseudo summary. However, non-text data such as image and\nmetadata related to reviews have been considered less often. To use the\nabundant information contained in non-text data, we propose a self-supervised\nmultimodal opinion summarization framework called MultimodalSum. Our framework\nobtains a representation of each modality using a separate encoder for each\nmodality, and the text decoder generates a summary. To resolve the inherent\nheterogeneity of multimodal data, we propose a multimodal training pipeline. We\nfirst pretrain the text encoder--decoder based solely on text modality data.\nSubsequently, we pretrain the non-text modality encoders by considering the\npretrained text decoder as a pivot for the homogeneous representation of\nmultimodal data. Finally, to fuse multimodal representations, we train the\nentire framework in an end-to-end manner. We demonstrate the superiority of\nMultimodalSum by conducting experiments on Yelp and Amazon datasets.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 13:29:05 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Im", "Jinbae", ""], ["Kim", "Moonki", ""], ["Lee", "Hoyeop", ""], ["Cho", "Hyunsouk", ""], ["Chung", "Sehee", ""]]}, {"id": "2105.13151", "submitter": "Nieves Montes", "authors": "Nieves Montes", "title": "A Computational Model of the Institutional Analysis and Development\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI econ.TH", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Institutional Analysis and Development (IAD) framework is a conceptual\ntoolbox put forward by Elinor Ostrom and colleagues in an effort to identify\nand delineate the universal common variables that structure the immense variety\nof human interactions. The framework identifies rules as one of the core\nconcepts to determine the structure of interactions, and acknowledges their\npotential to steer a community towards more beneficial and socially desirable\noutcomes. This work presents the first attempt to turn the IAD framework into a\ncomputational model to allow communities of agents to formally perform what-if\nanalysis on a given rule configuration. To do so, we define the Action\nSituation Language -- or ASL -- whose syntax is hgighly tailored to the\ncomponents of the IAD framework and that we use to write descriptions of social\ninteractions. ASL is complemented by a game engine that generates its semantics\nas an extensive-form game. These models, then, can be analyzed with the\nstandard tools of game theory to predict which outcomes are being most\nincentivized, and evaluated according to their socially relevant properties.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 13:53:56 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Montes", "Nieves", ""]]}, {"id": "2105.13155", "submitter": "Jan Niklas Adams", "authors": "Jan Niklas Adams, Sebastiaan J. van Zelst, Lara Quack, Kathrin\n  Hausmann, Wil M.P. van der Aalst, and Thomas Rose", "title": "A Framework for Explainable Concept Drift Detection in Process Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rapidly changing business environments expose companies to high levels of\nuncertainty. This uncertainty manifests itself in significant changes that tend\nto occur over the lifetime of a process and possibly affect its performance. It\nis important to understand the root causes of such changes since this allows us\nto react to change or anticipate future changes. Research in process mining has\nso far only focused on detecting, locating and characterizing significant\nchanges in a process and not on finding root causes of such changes. In this\npaper, we aim to close this gap. We propose a framework that adds an\nexplainability level onto concept drift detection in process mining and\nprovides insights into the cause-effect relationships behind significant\nchanges. We define different perspectives of a process, detect concept drifts\nin these perspectives and plug the perspectives into a causality check that\ndetermines whether these concept drifts can be causal to each other. We\nshowcase the effectiveness of our framework by evaluating it on both synthetic\nand real event data. Our experiments show that our approach unravels\ncause-effect relationships and provides novel insights into executed processes.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 14:03:19 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Adams", "Jan Niklas", ""], ["van Zelst", "Sebastiaan J.", ""], ["Quack", "Lara", ""], ["Hausmann", "Kathrin", ""], ["van der Aalst", "Wil M. P.", ""], ["Rose", "Thomas", ""]]}, {"id": "2105.13225", "submitter": "Qing Sun", "authors": "Qing Sun, Parminder Bhatia", "title": "Neural Entity Recognition with Gazetteer based Fusion", "comments": null, "journal-ref": "the Association for Computational Linguistics (ACL) 2021", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating external knowledge into Named Entity Recognition (NER) systems\nhas been widely studied in the generic domain. In this paper, we focus on\nclinical domain where only limited data is accessible and interpretability is\nimportant. Recent advancement in technology and the acceleration of clinical\ntrials has resulted in the discovery of new drugs, procedures as well as\nmedical conditions. These factors motivate towards building robust zero-shot\nNER systems which can quickly adapt to new medical terminology. We propose an\nauxiliary gazetteer model and fuse it with an NER system, which results in\nbetter robustness and interpretability across different clinical datasets. Our\ngazetteer based fusion model is data efficient, achieving +1.7 micro-F1 gains\non the i2b2 dataset using 20% training data, and brings + 4.7 micro-F1 gains on\nnovel entity mentions never presented during training. Moreover, our fusion\nmodel is able to quickly adapt to new mentions in gazetteers without\nre-training and the gains from the proposed fusion model are transferable to\nrelated datasets.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 15:14:15 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Sun", "Qing", ""], ["Bhatia", "Parminder", ""]]}, {"id": "2105.13231", "submitter": "Daniel Toyama", "authors": "Daniel Toyama, Philippe Hamel, Anita Gergely, Gheorghe Comanici,\n  Amelia Glaese, Zafarali Ahmed, Tyler Jackson, Shibl Mourad and Doina Precup", "title": "AndroidEnv: A Reinforcement Learning Platform for Android", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce AndroidEnv, an open-source platform for Reinforcement Learning\n(RL) research built on top of the Android ecosystem. AndroidEnv allows RL\nagents to interact with a wide variety of apps and services commonly used by\nhumans through a universal touchscreen interface. Since agents train on a\nrealistic simulation of an Android device, they have the potential to be\ndeployed on real devices. In this report, we give an overview of the\nenvironment, highlighting the significant features it provides for research,\nand we present an empirical evaluation of some popular reinforcement learning\nagents on a set of tasks built on this platform.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 15:20:14 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Toyama", "Daniel", ""], ["Hamel", "Philippe", ""], ["Gergely", "Anita", ""], ["Comanici", "Gheorghe", ""], ["Glaese", "Amelia", ""], ["Ahmed", "Zafarali", ""], ["Jackson", "Tyler", ""], ["Mourad", "Shibl", ""], ["Precup", "Doina", ""]]}, {"id": "2105.13264", "submitter": "Iana Sereda", "authors": "Iana Sereda and Grigory Osipov", "title": "How saccadic vision might help with theinterpretability of deep networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe how some problems (interpretability,lack of object-orientedness)\nof modern deep networks potentiallycould be solved by adapting a biologically\nplausible saccadicmechanism of perception. A sketch of such a saccadic\nvisionmodel is proposed. Proof of concept experimental results areprovided to\nsupport the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 16:02:40 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Sereda", "Iana", ""], ["Osipov", "Grigory", ""]]}, {"id": "2105.13283", "submitter": "Lara Hoffmann", "authors": "Lara Hoffmann and Clemens Elster", "title": "Deep Ensembles from a Bayesian Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep ensembles can be seen as the current state-of-the-art for uncertainty\nquantification in deep learning. While the approach was originally proposed as\nan non-Bayesian technique, arguments towards its Bayesian footing have been put\nforward as well. We show that deep ensembles can be viewed as an approximate\nBayesian method by specifying the corresponding assumptions. Our finding leads\nto an improved approximation which results in an increased epistemic part of\nthe uncertainty. Numerical examples suggest that the improved approximation can\nlead to more reliable uncertainties. Analytical derivations ensure easy\ncalculation of results.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 16:30:52 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Hoffmann", "Lara", ""], ["Elster", "Clemens", ""]]}, {"id": "2105.13284", "submitter": "David Biagioni", "authors": "Erotokritos Skordilis, Yi Hou, Charles Tripp, Matthew Moniot, Peter\n  Graf, David Biagioni", "title": "A Modular and Transferable Reinforcement Learning Framework for the\n  Fleet Rebalancing Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.AI cs.LG cs.MA cs.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Mobility on demand (MoD) systems show great promise in realizing flexible and\nefficient urban transportation. However, significant technical challenges arise\nfrom operational decision making associated with MoD vehicle dispatch and fleet\nrebalancing. For this reason, operators tend to employ simplified algorithms\nthat have been demonstrated to work well in a particular setting. To help\nbridge the gap between novel and existing methods, we propose a modular\nframework for fleet rebalancing based on model-free reinforcement learning (RL)\nthat can leverage an existing dispatch method to minimize system cost. In\nparticular, by treating dispatch as part of the environment dynamics, a\ncentralized agent can learn to intermittently direct the dispatcher to\nreposition free vehicles and mitigate against fleet imbalance. We formulate RL\nstate and action spaces as distributions over a grid partitioning of the\noperating area, making the framework scalable and avoiding the complexities\nassociated with multiagent RL. Numerical experiments, using real-world trip and\nnetwork data, demonstrate that this approach has several distinct advantages\nover baseline methods including: improved system cost; high degree of\nadaptability to the selected dispatch method; and the ability to perform\nscale-invariant transfer learning between problem instances with similar\nvehicle and request distributions.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 16:32:28 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Skordilis", "Erotokritos", ""], ["Hou", "Yi", ""], ["Tripp", "Charles", ""], ["Moniot", "Matthew", ""], ["Graf", "Peter", ""], ["Biagioni", "David", ""]]}, {"id": "2105.13287", "submitter": "Dung Nguyen", "authors": "Dung Nguyen and Anil Vullikanti", "title": "Differentially Private Densest Subgraph Detection", "comments": "Accepted by ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Densest subgraph detection is a fundamental graph mining problem, with a\nlarge number of applications. There has been a lot of work on efficient\nalgorithms for finding the densest subgraph in massive networks. However, in\nmany domains, the network is private, and returning a densest subgraph can\nreveal information about the network. Differential privacy is a powerful\nframework to handle such settings. We study the densest subgraph problem in the\nedge privacy model, in which the edges of the graph are private. We present the\nfirst sequential and parallel differentially private algorithms for this\nproblem. We show that our algorithms have an additive approximation guarantee.\nWe evaluate our algorithms on a large number of real-world networks, and\nobserve a good privacy-accuracy tradeoff when the network has high density.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 16:36:03 GMT"}, {"version": "v2", "created": "Fri, 18 Jun 2021 17:33:02 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Nguyen", "Dung", ""], ["Vullikanti", "Anil", ""]]}, {"id": "2105.13289", "submitter": "Li Yang", "authors": "Li Yang, Abdallah Moubayed, Abdallah Shami", "title": "MTH-IDS: A Multi-Tiered Hybrid Intrusion Detection System for Internet\n  of Vehicles", "comments": "Accepted and to appear in IEEE Internet of Things Journal; Code is\n  available at Github link:\n  https://github.com/Western-OC2-Lab/Intrusion-Detection-System-Using-Machine-Learning", "journal-ref": null, "doi": "10.1109/JIOT.2021.3084796", "report-no": null, "categories": "cs.CR cs.AI cs.LG cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern vehicles, including connected vehicles and autonomous vehicles,\nnowadays involve many electronic control units connected through intra-vehicle\nnetworks to implement various functionalities and perform actions. Modern\nvehicles are also connected to external networks through vehicle-to-everything\ntechnologies, enabling their communications with other vehicles,\ninfrastructures, and smart devices. However, the improving functionality and\nconnectivity of modern vehicles also increase their vulnerabilities to\ncyber-attacks targeting both intra-vehicle and external networks due to the\nlarge attack surfaces. To secure vehicular networks, many researchers have\nfocused on developing intrusion detection systems (IDSs) that capitalize on\nmachine learning methods to detect malicious cyber-attacks. In this paper, the\nvulnerabilities of intra-vehicle and external networks are discussed, and a\nmulti-tiered hybrid IDS that incorporates a signature-based IDS and an\nanomaly-based IDS is proposed to detect both known and unknown attacks on\nvehicular networks. Experimental results illustrate that the proposed system\ncan detect various types of known attacks with 99.99% accuracy on the\nCAN-intrusion-dataset representing the intra-vehicle network data and 99.88%\naccuracy on the CICIDS2017 dataset illustrating the external vehicular network\ndata. For the zero-day attack detection, the proposed system achieves high\nF1-scores of 0.963 and 0.800 on the above two datasets, respectively. The\naverage processing time of each data packet on a vehicle-level machine is less\nthan 0.6 ms, which shows the feasibility of implementing the proposed system in\nreal-time vehicle systems. This emphasizes the effectiveness and efficiency of\nthe proposed IDS.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 17:36:35 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Yang", "Li", ""], ["Moubayed", "Abdallah", ""], ["Shami", "Abdallah", ""]]}, {"id": "2105.13336", "submitter": "Kaixin Zhang", "authors": "Kaixin Zhang, Hongzhi Wang, Tongxin Li, Han Hu, Jiye Qiu, Songling Zou", "title": "TENSILE: A Tensor granularity dynamic GPU memory scheduler method\n  towards multiple dynamic workloads system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.DB cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep learning has been an area of intense researching. However, as\na kind of computing intensive task, deep learning highly relies on the the\nscale of the GPU memory, which is usually expensive and scarce. Although there\nare some extensive works have been proposed for dynamic GPU memory management,\nthey are hard to be applied to systems with multitasking dynamic workloads,\nsuch as in-database machine learning system.\n  In this paper, we demonstrated TENSILE, a method of managing GPU memory in\ntensor granularity to reduce the GPU memory peak, with taking the multitasking\ndynamic workloads into consideration. As far as we know, TENSILE is the first\nmethod which is designed to manage multiple workloads' GPU memory using. We\nimplement TENSILE on our own deep learning framework, and evaluated its\nperformance. The experiment results shows that our method can achieve less time\noverhead than prior works with more GPU memory saved.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 17:46:16 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 03:31:38 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Zhang", "Kaixin", ""], ["Wang", "Hongzhi", ""], ["Li", "Tongxin", ""], ["Hu", "Han", ""], ["Qiu", "Jiye", ""], ["Zou", "Songling", ""]]}, {"id": "2105.13351", "submitter": "Drew Linsley", "authors": "Drew Linsley, Girik Malik, Junkyung Kim, Lakshmi N Govindarajan, Ennio\n  Mingolla, and Thomas Serre", "title": "Tracking Without Re-recognition in Humans and Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Imagine trying to track one particular fruitfly in a swarm of hundreds.\nHigher biological visual systems have evolved to track moving objects by\nrelying on both appearance and motion features. We investigate if\nstate-of-the-art deep neural networks for visual tracking are capable of the\nsame. For this, we introduce PathTracker, a synthetic visual challenge that\nasks human observers and machines to track a target object in the midst of\nidentical-looking \"distractor\" objects. While humans effortlessly learn\nPathTracker and generalize to systematic variations in task design,\nstate-of-the-art deep networks struggle. To address this limitation, we\nidentify and model circuit mechanisms in biological brains that are implicated\nin tracking objects based on motion cues. When instantiated as a recurrent\nnetwork, our circuit model learns to solve PathTracker with a robust visual\nstrategy that rivals human performance and explains a significant proportion of\ntheir decision-making on the challenge. We also show that the success of this\ncircuit model extends to object tracking in natural videos. Adding it to a\ntransformer-based architecture for object tracking builds tolerance to visual\nnuisances that affect object appearance, resulting in a new state-of-the-art\nperformance on the large-scale TrackingNet object tracking challenge. Our work\nhighlights the importance of building artificial vision models that can help us\nbetter understand human vision and improve computer vision.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 17:56:37 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 00:26:33 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Linsley", "Drew", ""], ["Malik", "Girik", ""], ["Kim", "Junkyung", ""], ["Govindarajan", "Lakshmi N", ""], ["Mingolla", "Ennio", ""], ["Serre", "Thomas", ""]]}, {"id": "2105.13420", "submitter": "Zhenwen Dai", "authors": "Zhenwen Dai, Praveen Chandar, Ghazal Fazelnia, Ben Carterette, Mounia\n  Lalmas-Roelleke", "title": "Model Selection for Production System via Automated Online Experiments", "comments": "NeurIPS 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A challenge that machine learning practitioners in the industry face is the\ntask of selecting the best model to deploy in production. As a model is often\nan intermediate component of a production system, online controlled experiments\nsuch as A/B tests yield the most reliable estimation of the effectiveness of\nthe whole system, but can only compare two or a few models due to budget\nconstraints. We propose an automated online experimentation mechanism that can\nefficiently perform model selection from a large pool of models with a small\nnumber of online experiments. We derive the probability distribution of the\nmetric of interest that contains the model uncertainty from our Bayesian\nsurrogate model trained using historical logs. Our method efficiently\nidentifies the best model by sequentially selecting and deploying a list of\nmodels from the candidate set that balance exploration-exploitation. Using\nsimulations based on real data, we demonstrate the effectiveness of our method\non two different tasks.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 19:48:23 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Dai", "Zhenwen", ""], ["Chandar", "Praveen", ""], ["Fazelnia", "Ghazal", ""], ["Carterette", "Ben", ""], ["Lalmas-Roelleke", "Mounia", ""]]}, {"id": "2105.13431", "submitter": "Giorgio Angelotti", "authors": "Giorgio Angelotti, Nicolas Drougard, Caroline Ponzoni Carvalho Chanel", "title": "Exploitation vs Caution: Risk-sensitive Policies for Offline Learning", "comments": "Preprint, under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offline model learning for planning is a branch of machine learning that\ntrains agents to perform actions in an unknown environment using a fixed batch\nof previously collected experiences. The limited size of the data set hinders\nthe estimate of the Value function of the relative Markov Decision Process\n(MDP), bounding the performance of the obtained policy in the real world. In\nthis context, recent works showed that planning with a discount factor lower\nthan the one used during the evaluation phase yields more performing policies.\nHowever, the optimal discount factor is finally chosen by cross-validation. Our\naim is to show that looking for a sub-optimal solution of a Bayesian MDP might\nlead to better performances with respect to the current baselines that work in\nthe offline setting. Hence, we propose Exploitation vs Caution (EvC), an\nalgorithm that automatically selects the policy that solves a Risk-sensitive\nBayesian MDP in a set of policies obtained by solving several MDPs\ncharacterized by different discount factors and transition dynamics. On one\nhand, the Bayesian formalism elegantly includes model uncertainty and on\nanother hand the introduction of a risk-sensitive utility function guarantees\nrobustness. We evaluated the proposed approach in different discrete simple\nenvironments offering a fair variety of MDP classes. We also compared the\nobtained results with state-of-the-art offline learning for planning baselines\nsuch as MOPO and MOReL. In the tested scenarios EvC is more robust than the\nsaid approaches suggesting that sub-optimally solving an Offline Risk-sensitive\nBayesian MDP (ORBMDP) could define a sound framework for planning under model\nuncertainty.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 20:12:20 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Angelotti", "Giorgio", ""], ["Drougard", "Nicolas", ""], ["Chanel", "Caroline Ponzoni Carvalho", ""]]}, {"id": "2105.13448", "submitter": "Jitendra Parmar", "authors": "Jitendra Parmar, Satyendra Singh Chouhan and Santosh Singh Rathore", "title": "Open-world Machine Learning: Applications, Challenges, and Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Traditional machine learning especially supervised learning follows the\nassumptions of closed-world learning i.e., for each testing class a training\nclass is available. However, such machine learning models fail to identify the\nclasses which were not available during training time. These classes can be\nreferred to as unseen classes. Whereas, open-world machine learning deals with\narbitrary inputs (data with unseen classes) to machine learning systems.\nMoreover, traditional machine learning is static learning which is not\nappropriate for an active environment where the perspective and sources, and/or\nvolume of data are changing rapidly. In this paper, first, we present an\noverview of open-world learning with importance to the real-world context.\nNext, different dimensions of open-world learning are explored and discussed.\nThe area of open-world learning gained the attention of the research community\nin the last decade only. We have searched through different online digital\nlibraries and scrutinized the work done in the last decade. This paper presents\na systematic review of various techniques for open-world machine learning. It\nalso presents the research gaps, challenges, and future directions in\nopen-world learning. This paper will help researchers to understand the\ncomprehensive developments of open-world learning and the likelihoods to extend\nthe research in suitable areas. It will also help to select applicable\nmethodologies and datasets to explore this further.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 21:05:10 GMT"}], "update_date": "2021-06-14", "authors_parsed": [["Parmar", "Jitendra", ""], ["Chouhan", "Satyendra Singh", ""], ["Rathore", "Santosh Singh", ""]]}, {"id": "2105.13461", "submitter": "Enpeng Yuan", "authors": "Enpeng Yuan, Pascal Van Hentenryck", "title": "Learning Model-Based Vehicle-Relocation Decisions for Real-Time\n  Ride-Sharing: Hybridizing Learning and Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale ride-sharing systems combine real-time dispatching and routing\noptimization over a rolling time horizon with a model predictive control (MPC)\ncomponent that relocates idle vehicles to anticipate the demand. The MPC\noptimization operates over a longer time horizon to compensate for the inherent\nmyopic nature of the real-time dispatching. These longer time horizons are\nbeneficial for the quality of relocation decisions but increase computational\ncomplexity. Consequently, the ride-sharing operators are often forced to use a\nrelatively short time horizon. To address this computational challenge, this\npaper proposes a hybrid approach that combines machine learning and\noptimization. The machine-learning component learns the optimal solution to the\nMPC on the aggregated level to overcome the sparsity and high-dimensionality of\nthe solution. The optimization component transforms the machine-learning\nprediction back to the original granularity through a tractable transportation\nmodel. As a consequence, the original NP-hard MPC problem is reduced to a\npolynomial time prediction and optimization, which allows the ride-sharing\noperators to consider a longer time horizon. Experimental results show that the\nhybrid approach achieves significantly better service quality than the MPC\noptimization in terms of average rider waiting time, due to its ability to\nmodel a longer horizon.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 21:48:05 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 16:39:16 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Yuan", "Enpeng", ""], ["Van Hentenryck", "Pascal", ""]]}, {"id": "2105.13464", "submitter": "Shreyas Saxena", "authors": "Shreyas Saxena, Nidhi Vyas, Dennis DeCoste", "title": "Training With Data Dependent Dynamic Learning Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently many first and second order variants of SGD have been proposed to\nfacilitate training of Deep Neural Networks (DNNs). A common limitation of\nthese works stem from the fact that they use the same learning rate across all\ninstances present in the dataset. This setting is widely adopted under the\nassumption that loss functions for each instance are similar in nature, and\nhence, a common learning rate can be used. In this work, we relax this\nassumption and propose an optimization framework which accounts for difference\nin loss function characteristics across instances. More specifically, our\noptimizer learns a dynamic learning rate for each instance present in the\ndataset. Learning a dynamic learning rate for each instance allows our\noptimization framework to focus on different modes of training data during\noptimization. When applied to an image classification task, across different\nCNN architectures, learning dynamic learning rates leads to consistent gains\nover standard optimizers. When applied to a dataset containing corrupt\ninstances, our framework reduces the learning rates on noisy instances, and\nimproves over the state-of-the-art. Finally, we show that our optimization\nframework can be used for personalization of a machine learning model towards a\nknown targeted data distribution.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 21:52:29 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Saxena", "Shreyas", ""], ["Vyas", "Nidhi", ""], ["DeCoste", "Dennis", ""]]}, {"id": "2105.13471", "submitter": "Carlos Aspillaga", "authors": "Carlos Aspillaga, Marcelo Mendoza, Alvaro Soto", "title": "Inspecting the concept knowledge graph encoded by modern language models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The field of natural language understanding has experienced exponential\nprogress in the last few years, with impressive results in several tasks. This\nsuccess has motivated researchers to study the underlying knowledge encoded by\nthese models. Despite this, attempts to understand their semantic capabilities\nhave not been successful, often leading to non-conclusive, or contradictory\nconclusions among different works. Via a probing classifier, we extract the\nunderlying knowledge graph of nine of the most influential language models of\nthe last years, including word embeddings, text generators, and context\nencoders. This probe is based on concept relatedness, grounded on WordNet. Our\nresults reveal that all the models encode this knowledge, but suffer from\nseveral inaccuracies. Furthermore, we show that the different architectures and\ntraining strategies lead to different model biases. We conduct a systematic\nevaluation to discover specific factors that explain why some concepts are\nchallenging. We hope our insights will motivate the development of models that\ncapture concepts more precisely.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 22:19:19 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 13:29:09 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Aspillaga", "Carlos", ""], ["Mendoza", "Marcelo", ""], ["Soto", "Alvaro", ""]]}, {"id": "2105.13493", "submitter": "Patrick Kidger", "authors": "Patrick Kidger and James Foster and Xuechen Li and Terry Lyons", "title": "Efficient and Accurate Gradients for Neural SDEs", "comments": "Submitted to NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural SDEs combine many of the best qualities of both RNNs and SDEs: memory\nefficient training, high-capacity function approximation, and strong priors on\nmodel space. This makes them a natural choice for modelling many types of\ntemporal dynamics. Training a Neural SDE (either as a VAE or as a GAN) requires\nbackpropagating through an SDE solve. This may be done by solving a\nbackwards-in-time SDE whose solution is the desired parameter gradients.\nHowever, this has previously suffered from severe speed and accuracy issues,\ndue to high computational cost and numerical truncation errors. Here, we\novercome these issues through several technical innovations. First, we\nintroduce the \\textit{reversible Heun method}. This is a new SDE solver that is\n\\textit{algebraically reversible}: eliminating numerical gradient errors, and\nthe first such solver of which we are aware. Moreover it requires half as many\nfunction evaluations as comparable solvers, giving up to a $1.98\\times$\nspeedup. Second, we introduce the \\textit{Brownian Interval}: a new, fast,\nmemory efficient, and exact way of sampling \\textit{and reconstructing}\nBrownian motion. With this we obtain up to a $10.6\\times$ speed improvement\nover previous techniques, which in contrast are both approximate and relatively\nslow. Third, when specifically training Neural SDEs as GANs (Kidger et al.\n2021), we demonstrate how SDE-GANs may be trained through careful weight\nclipping and choice of activation function. This reduces computational cost\n(giving up to a $1.87\\times$ speedup) and removes the numerical truncation\nerrors associated with gradient penalty. Altogether, we outperform the\nstate-of-the-art by substantial margins, with respect to training speed, and\nwith respect to classification, prediction, and MMD test metrics. We have\ncontributed implementations of all of our techniques to the torchsde library to\nhelp facilitate their adoption.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 22:59:36 GMT"}, {"version": "v2", "created": "Tue, 15 Jun 2021 17:34:54 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Kidger", "Patrick", ""], ["Foster", "James", ""], ["Li", "Xuechen", ""], ["Lyons", "Terry", ""]]}, {"id": "2105.13514", "submitter": "Duong Dung", "authors": "Tri Dung Duong, Qian Li, Guandong Xu", "title": "Stochastic Intervention for Causal Inference via Reinforcement Learning", "comments": "Under review for Neurocomputiong. arXiv admin note: substantial text\n  overlap with arXiv:2105.12898", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Causal inference methods are widely applied in various decision-making\ndomains such as precision medicine, optimal policy and economics. Central to\ncausal inference is the treatment effect estimation of intervention strategies,\nsuch as changes in drug dosing and increases in financial aid. Existing methods\nare mostly restricted to the deterministic treatment and compare outcomes under\ndifferent treatments. However, they are unable to address the substantial\nrecent interest of treatment effect estimation under stochastic treatment,\ne.g., \"how all units health status change if they adopt 50\\% dose reduction\".\nIn other words, they lack the capability of providing fine-grained treatment\neffect estimation to support sound decision-making. In our study, we advance\nthe causal inference research by proposing a new effective framework to\nestimate the treatment effect on stochastic intervention. Particularly, we\ndevelop a stochastic intervention effect estimator (SIE) based on nonparametric\ninfluence function, with the theoretical guarantees of robustness and fast\nconvergence rates. Additionally, we construct a customised reinforcement\nlearning algorithm based on the random search solver which can effectively find\nthe optimal policy to produce the greatest expected outcomes for the\ndecision-making process. Finally, we conduct an empirical study to justify that\nour framework can achieve significant performance in comparison with\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 00:11:22 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Duong", "Tri Dung", ""], ["Li", "Qian", ""], ["Xu", "Guandong", ""]]}, {"id": "2105.13562", "submitter": "Ashutosh Modi", "authors": "Vijit Malik and Rishabh Sanjay and Shubham Kumar Nigam and Kripa Ghosh\n  and Shouvik Kumar Guha and Arnab Bhattacharya and Ashutosh Modi", "title": "ILDC for CJPE: Indian Legal Documents Corpus for Court Judgment\n  Prediction and Explanation", "comments": "Accepted at ACL 2021, 17 Pages (9 Pages main paper, 4 pages\n  references, 4 pages appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  An automated system that could assist a judge in predicting the outcome of a\ncase would help expedite the judicial process. For such a system to be\npractically useful, predictions by the system should be explainable. To promote\nresearch in developing such a system, we introduce ILDC (Indian Legal Documents\nCorpus). ILDC is a large corpus of 35k Indian Supreme Court cases annotated\nwith original court decisions. A portion of the corpus (a separate test set) is\nannotated with gold standard explanations by legal experts. Based on ILDC, we\npropose the task of Court Judgment Prediction and Explanation (CJPE). The task\nrequires an automated system to predict an explainable outcome of a case. We\nexperiment with a battery of baseline models for case predictions and propose a\nhierarchical occlusion based model for explainability. Our best prediction\nmodel has an accuracy of 78% versus 94% for human legal experts, pointing\ntowards the complexity of the prediction task. The analysis of explanations by\nthe proposed algorithm reveals a significant difference in the point of view of\nthe algorithm and legal experts for explaining the judgments, pointing towards\nscope for future research.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 03:07:32 GMT"}, {"version": "v2", "created": "Mon, 31 May 2021 11:17:43 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Malik", "Vijit", ""], ["Sanjay", "Rishabh", ""], ["Nigam", "Shubham Kumar", ""], ["Ghosh", "Kripa", ""], ["Guha", "Shouvik Kumar", ""], ["Bhattacharya", "Arnab", ""], ["Modi", "Ashutosh", ""]]}, {"id": "2105.13575", "submitter": "Lin Xu", "authors": "Yichen Cao, Yufei Wei, Shichao Liu, Lin Xu", "title": "2nd Place Solution for IJCAI-PRICAI 2020 3D AI Challenge: 3D Object\n  Reconstruction from A Single Image", "comments": "5 pages, 2 figures, 5 tables", "journal-ref": "IJCAI 2020 workshop", "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present our solution for the {\\it IJCAI--PRICAI--20 3D AI\nChallenge: 3D Object Reconstruction from A Single Image}. We develop a variant\nof AtlasNet that consumes single 2D images and generates 3D point clouds\nthrough 2D to 3D mapping. To push the performance to the limit and present\nguidance on crucial implementation choices, we conduct extensive experiments to\nanalyze the influence of decoder design and different settings on the\nnormalization, projection, and sampling methods. Our method achieves 2nd place\nin the final track with a score of $70.88$, a chamfer distance of $36.87$, and\na mean f-score of $59.18$. The source code of our method will be available at\nhttps://github.com/em-data/Enhanced_AtlasNet_3DReconstruction.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 03:54:39 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Cao", "Yichen", ""], ["Wei", "Yufei", ""], ["Liu", "Shichao", ""], ["Xu", "Lin", ""]]}, {"id": "2105.13585", "submitter": "Clifford Bohm", "authors": "Douglas Kirkpatrick, Victoria Cao, Clifford Bohm", "title": "Fragmentation; a Tool for Finding Information, Encryption and Data Flow\n  in Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.AI cs.NE math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce a new information-theoretic measure, fragmentation (F) which can\nbe used to determine how fragmented predictive information is in a system. The\nconcept can be extended to generate fragmentation matrices that can illustrate\ninformation flows through digital brains, in the form of directed graphs.\nFragmentation and fragmentation matrices can provide new insights into digital\nbrains structure and function, in other words, how causal digital networks\n\"think\" and process information. In addition to describing F we demonstrate how\nit can be used to examine how complex processing arises in neural networks,\nincluding differences in lifetime processing and incidents of incidental\nencryption.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 04:49:14 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Kirkpatrick", "Douglas", ""], ["Cao", "Victoria", ""], ["Bohm", "Clifford", ""]]}, {"id": "2105.13591", "submitter": "Guangyin Jin", "authors": "Guangyin Jin, Huan Yan, Fuxian Li, Jincai Huang, Yong Li", "title": "Spatio-Temporal Dual Graph Neural Networks for Travel Time Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Travel time estimation is one of the core tasks for the development of\nintelligent transportation systems. Most previous works model the road segments\nor intersections separately by learning their spatio-temporal characteristics\nto estimate travel time. However, due to the continuous alternations of the\nroad segments and intersections in a path, the dynamic features are supposed to\nbe coupled and interactive. Therefore, modeling one of them limits further\nimprovement in accuracy of estimating travel time. To address the above\nproblems, a novel graph-based deep learning framework for travel time\nestimation is proposed in this paper, namely Spatio-Temporal Dual Graph Neural\nNetworks (STDGNN). Specifically, we first establish the node-wise and edge-wise\ngraphs to respectively characterize the adjacency relations of intersections\nand that of road segments. In order to extract the joint spatio-temporal\ncorrelations of the intersections and road segments, we adopt the\nspatio-temporal dual graph learning approach that incorporates multiple\nspatial-temporal dual graph learning modules with multi-scale network\narchitectures for capturing multi-level spatial-temporal information from the\ndual graph. Finally, we employ the multi-task learning approach to estimate the\ntravel time of a given whole route, each road segment and intersection\nsimultaneously. We conduct extensive experiments to evaluate our proposed model\non three real-world trajectory datasets, and the experimental results show that\nSTDGNN significantly outperforms several state-of-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 05:15:45 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 16:09:05 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Jin", "Guangyin", ""], ["Yan", "Huan", ""], ["Li", "Fuxian", ""], ["Huang", "Jincai", ""], ["Li", "Yong", ""]]}, {"id": "2105.13609", "submitter": "Vektor Dewanto", "authors": "Vektor Dewanto, Marcus Gallagher", "title": "A nearly Blackwell-optimal policy gradient method", "comments": "26 pages (9-page main content), refined the appendices", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  For continuing environments, reinforcement learning methods commonly maximize\na discounted reward criterion with discount factor close to 1 in order to\napproximate the steady-state reward (the gain). However, such a criterion only\nconsiders the long-run performance, ignoring the transient behaviour. In this\nwork, we develop a policy gradient method that optimizes the gain, then the\nbias (which indicates the transient performance and is important to capably\nselect from policies with equal gain). We derive expressions that enable\nsampling for the gradient of the bias, and its preconditioning Fisher matrix.\nWe further propose an algorithm that solves the corresponding bi-level\noptimization using a logarithmic barrier. Experimental results provide insights\ninto the fundamental mechanisms of our proposal.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 06:37:02 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 00:44:49 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Dewanto", "Vektor", ""], ["Gallagher", "Marcus", ""]]}, {"id": "2105.13630", "submitter": "Bin Sun", "authors": "Bin Sun, Shaoxiong Feng, Yiwei Li, Jiamou Liu and Kan Li", "title": "THINK: A Novel Conversation Model for Generating Grammatically Correct\n  and Coherent Responses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many existing conversation models that are based on the encoder-decoder\nframework have focused on ways to make the encoder more complicated to enrich\nthe context vectors so as to increase the diversity and informativeness of\ngenerated responses. However, these approaches face two problems. First, the\ndecoder is too simple to effectively utilize the previously generated\ninformation and tends to generate duplicated and self-contradicting responses.\nSecond, the complex encoder tends to generate diverse but incoherent responses\nbecause the complex context vectors may deviate from the original semantics of\ncontext. In this work, we proposed a conversation model named \"THINK\" (Teamwork\ngeneration Hover around Impressive Noticeable Keywords) to make the decoder\nmore complicated and avoid generating duplicated and self-contradicting\nresponses. The model simplifies the context vectors and increases the coherence\nof generated responses in a reasonable way. For this model, we propose Teamwork\ngeneration framework and Semantics Extractor. Compared with other baselines,\nboth automatic and human evaluation showed the advantages of our model.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 07:11:32 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Sun", "Bin", ""], ["Feng", "Shaoxiong", ""], ["Li", "Yiwei", ""], ["Liu", "Jiamou", ""], ["Li", "Kan", ""]]}, {"id": "2105.13650", "submitter": "Huayang Li", "authors": "Wei Bi, Huayang Li, Jiacheng Huang", "title": "Data Augmentation for Text Generation Without Any Augmented Data", "comments": "Accepted into the main conference of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data augmentation is an effective way to improve the performance of many\nneural text generation models. However, current data augmentation methods need\nto define or choose proper data mapping functions that map the original samples\ninto the augmented samples. In this work, we derive an objective to formulate\nthe problem of data augmentation on text generation tasks without any use of\naugmented data constructed by specific mapping functions. Our proposed\nobjective can be efficiently optimized and applied to popular loss functions on\ntext generation tasks with a convergence rate guarantee. Experiments on five\ndatasets of two text generation tasks show that our approach can approximate or\neven surpass popular data augmentation methods.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 07:56:51 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Bi", "Wei", ""], ["Li", "Huayang", ""], ["Huang", "Jiacheng", ""]]}, {"id": "2105.13662", "submitter": "Simon Razniewski", "authors": "Tuan-Phong Nguyen, Simon Razniewski, Gerhard Weikum", "title": "Inside ASCENT: Exploring a Deep Commonsense Knowledge Base and its Usage\n  in Question Answering", "comments": "Demo website: https://ascent.mpi-inf.mpg.de; introductory video:\n  https://youtu.be/qMkJXqu_Yd4", "journal-ref": "ACL 2021 system demonstration", "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  ASCENT is a fully automated methodology for extracting and consolidating\ncommonsense assertions from web contents (Nguyen et al., WWW 2021). It advances\ntraditional triple-based commonsense knowledge representation by capturing\nsemantic facets like locations and purposes, and composite concepts, i.e.,\nsubgroups and related aspects of subjects. In this demo, we present a web\nportal that allows users to understand its construction process, explore its\ncontent, and observe its impact in the use case of question answering. The demo\nwebsite and an introductory video are both available online.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 08:17:33 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Nguyen", "Tuan-Phong", ""], ["Razniewski", "Simon", ""], ["Weikum", "Gerhard", ""]]}, {"id": "2105.13665", "submitter": "Han Wu", "authors": "Han Wu, Kun Xu, Linfeng Song, Lifeng Jin, Haisong Zhang, Linqi Song", "title": "Domain-Adaptive Pretraining Methods for Dialogue Understanding", "comments": "6 pages, to appear in ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Language models like BERT and SpanBERT pretrained on open-domain data have\nobtained impressive gains on various NLP tasks. In this paper, we probe the\neffectiveness of domain-adaptive pretraining objectives on downstream tasks. In\nparticular, three objectives, including a novel objective focusing on modeling\npredicate-argument relations, are evaluated on two challenging dialogue\nunderstanding tasks. Experimental results demonstrate that domain-adaptive\npretraining with proper objectives can significantly improve the performance of\na strong baseline on these tasks, achieving the new state-of-the-art\nperformances.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 08:25:27 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Wu", "Han", ""], ["Xu", "Kun", ""], ["Song", "Linfeng", ""], ["Jin", "Lifeng", ""], ["Zhang", "Haisong", ""], ["Song", "Linqi", ""]]}, {"id": "2105.13698", "submitter": "Fan Huang", "authors": "Fan Huang", "title": "Network Activities Recognition and Analysis Based on Supervised Machine\n  Learning Classification Methods Using J48 and Na\\\"ive Bayes Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network activities recognition has always been a significant component of\nintrusion detection. However, with the increasing network traffic flow and\ncomplexity of network behavior, it is becoming more and more difficult to\nidentify the specific behavior quickly and accurately by user network\nmonitoring software. It also requires the system security staff to pay close\nattention to the latest intrusion monitoring technology and methods. All of\nthese greatly increase the difficulty and complexity of intrusion detection\ntasks. The application of machine learning methods based on supervised\nclassification technology would help to liberate the network security staff\nfrom the heavy and boring tasks. A finetuned model would accurately recognize\nuser behavior, which could provide persistent monitoring with a relative high\naccuracy and good adaptability. Finally, the results of network activities\nrecognition by J48 and Na\\\"ive Bayes algorithms are introduced and evaluated.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 09:44:14 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Huang", "Fan", ""]]}, {"id": "2105.13700", "submitter": "Mikolas Janota", "authors": "Mikol\\'a\\v{s} Janota and Haniel Barbosa and Pascal Fontaine and Andrew\n  Reynolds", "title": "Fair and Adventurous Enumeration of Quantifier Instantiations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  SMT solvers generally tackle quantifiers by instantiating their variables\nwith tuples of terms from the ground part of the formula. Recent enumerative\napproaches for quantifier instantiation consider tuples of terms in some\nheuristic order. This paper studies different strategies to order such tuples\nand their impact on performance. We decouple the ordering problem into two\nparts. First is the order of the sequence of terms to consider for each\nquantified variable, and second is the order of the instantiation tuples\nthemselves. While the most and least preferred tuples, i.e. those with all\nvariables assigned to the most or least preferred terms, are clear, the\ncombinations in between allow flexibility in an implementation. We look at\nprincipled strategies of complete enumeration, where some strategies are more\nfair, meaning they treat all the variables the same but some strategies may be\nmore adventurous, meaning that they may venture further down the preference\nlist. We further describe new techniques for discarding irrelevant\ninstantiations which are crucial for the performance of these strategies in\npractice. These strategies are implemented in the SMT solver cvc5, where they\ncontribute to the diversification of the solver's configuration space, as shown\nby our experimental results.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 09:51:47 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Janota", "Mikol\u00e1\u0161", ""], ["Barbosa", "Haniel", ""], ["Fontaine", "Pascal", ""], ["Reynolds", "Andrew", ""]]}, {"id": "2105.13745", "submitter": "Yaowei Zheng", "authors": "Xiaohui Guo, Richong Zhang, Yaowei Zheng, Yongyi Mao", "title": "Robust Regularization with Adversarial Labelling of Perturbed Samples", "comments": "Accepted to IJCAI2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches have suggested that the predictive accuracy of neural\nnetwork may contend with its adversarial robustness. This presents challenges\nin designing effective regularization schemes that also provide strong\nadversarial robustness. Revisiting Vicinal Risk Minimization (VRM) as a\nunifying regularization principle, we propose Adversarial Labelling of\nPerturbed Samples (ALPS) as a regularization scheme that aims at improving the\ngeneralization ability and adversarial robustness of the trained model. ALPS\ntrains neural networks with synthetic samples formed by perturbing each\nauthentic input sample towards another one along with an adversarially assigned\nlabel. The ALPS regularization objective is formulated as a min-max problem, in\nwhich the outer problem is minimizing an upper-bound of the VRM loss, and the\ninner problem is L$_1$-ball constrained adversarial labelling on perturbed\nsample. The analytic solution to the induced inner maximization problem is\nelegantly derived, which enables computational efficiency. Experiments on the\nSVHN, CIFAR-10, CIFAR-100 and Tiny-ImageNet datasets show that the ALPS has a\nstate-of-the-art regularization performance while also serving as an effective\nadversarial training scheme.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 11:26:49 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Guo", "Xiaohui", ""], ["Zhang", "Richong", ""], ["Zheng", "Yaowei", ""], ["Mao", "Yongyi", ""]]}, {"id": "2105.13754", "submitter": "Bogdan Trasnea", "authors": "Sorin Grigorescu, Mihai Zaha, Bogdan Trasnea and Cosmin Ginerica", "title": "Embedded Vision for Self-Driving on Forest Roads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Forest roads in Romania are unique natural wildlife sites used for recreation\nby countless tourists. In order to protect and maintain these roads, we propose\nRovisLab AMTU (Autonomous Mobile Test Unit), which is a robotic system designed\nto autonomously navigate off-road terrain and inspect if any deforestation or\ndamage occurred along tracked route. AMTU's core component is its embedded\nvision module, optimized for real-time environment perception. For achieving a\nhigh computation speed, we use a learning system to train a multi-task Deep\nNeural Network (DNN) for scene and instance segmentation of objects, while the\nkeypoints required for simultaneous localization and mapping are calculated\nusing a handcrafted FAST feature detector and the Lucas-Kanade tracking\nalgorithm. Both the DNN and the handcrafted backbone are run in parallel on the\nGPU of an NVIDIA AGX Xavier board. We show experimental results on the test\ntrack of our research facility.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 09:05:08 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Grigorescu", "Sorin", ""], ["Zaha", "Mihai", ""], ["Trasnea", "Bogdan", ""], ["Ginerica", "Cosmin", ""]]}, {"id": "2105.13765", "submitter": "Yasir K{\\i}l{\\i}\\c{c}", "authors": "Yasir Kilic", "title": "Exploiting Transductive Property of Graph Convolutional Neural Networks\n  with Less Labeling Effort", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, machine learning approaches on Graph data have become very popular.\nIt was observed that significant results were obtained by including implicit or\nexplicit logical connections between data samples that make up the data to the\nmodel. In this context, the developing GCN model has made significant\nexperimental contributions with Convolution filters applied to graph data. This\nmodel follows Transductive and Semi-Supervised Learning approach. Due to its\ntransductive property, all of the data samples, which is partially labeled, are\ngiven as input to the model. Labeling, which is a cost, is very important.\nWithin the scope of this study, the following research question is tried to be\nanswered: If at least how many samples are labeled, the optimum model success\nis achieved? In addition, some experimental contributions have been made on the\naccuracy of the model, whichever sampling approach is used with fixed labeling\neffort. According to the experiments, the success of the model can be increased\nby using the local centrality metric.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 05:33:31 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Kilic", "Yasir", ""]]}, {"id": "2105.13771", "submitter": "Tuomo Sipola", "authors": "Janne Alatalo, Joni Korpihalkola, Tuomo Sipola, Tero Kokkonen", "title": "Chromatic and spatial analysis of one-pixel attacks against an image\n  classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  One-pixel attack is a curious way of deceiving neural network classifier by\nchanging only one pixel in the input image. The full potential and boundaries\nof this attack method are not yet fully understood. In this research, the\nsuccessful and unsuccessful attacks are studied in more detail to illustrate\nthe working mechanisms of a one-pixel attack created using differential\nevolution. The data comes from our earlier studies where we applied the attack\nagainst medical imaging. We used a real breast cancer tissue dataset and a real\nclassifier as the attack target. This research presents ways to analyze\nchromatic and spatial distributions of one-pixel attacks. In addition, we\npresent one-pixel attack confidence maps to illustrate the behavior of the\ntarget classifier. We show that the more effective attacks change the color of\nthe pixel more, and that the successful attacks are situated at the center of\nthe images. This kind of analysis is not only useful for understanding the\nbehavior of the attack but also the qualities of the classifying neural\nnetwork.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 12:21:58 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 12:46:33 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Alatalo", "Janne", ""], ["Korpihalkola", "Joni", ""], ["Sipola", "Tuomo", ""], ["Kokkonen", "Tero", ""]]}, {"id": "2105.13789", "submitter": "Maxwell Hogan Mr", "authors": "Maxwell Hogan, Duarte Rondao, Nabil Aouf, and Olivier Dubois-Matra", "title": "Using Convolutional Neural Networks for Relative Pose Estimation of a\n  Non-Cooperative Spacecraft with Thermal Infrared Imagery", "comments": "14 pages; 11 figures; European Space Agency Guidance, Navigation and\n  Control Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent interest in on-orbit servicing and Active Debris Removal (ADR)\nmissions have driven the need for technologies to enable non-cooperative\nrendezvous manoeuvres. Such manoeuvres put heavy burden on the perception\ncapabilities of a chaser spacecraft. This paper demonstrates Convolutional\nNeural Networks (CNNs) capable of providing an initial coarse pose estimation\nof a target from a passive thermal infrared camera feed. Thermal cameras offer\na promising alternative to visible cameras, which struggle in low light\nconditions and are susceptible to overexposure. Often, thermal information on\nthe target is not available a priori; this paper therefore proposes using\nvisible images to train networks. The robustness of the models is demonstrated\non two different targets, first on synthetic data, and then in a laboratory\nenvironment for a realistic scenario that might be faced during an ADR mission.\nGiven that there is much concern over the use of CNN in critical applications\ndue to their black box nature, we use innovative techniques to explain what is\nimportant to our network and fault conditions.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 12:51:38 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Hogan", "Maxwell", ""], ["Rondao", "Duarte", ""], ["Aouf", "Nabil", ""], ["Dubois-Matra", "Olivier", ""]]}, {"id": "2105.13801", "submitter": "Jonathan Dumas", "authors": "Jonathan Dumas, Colin Cointe, Antoine Wehenkel, Antonio Sutera, Xavier\n  Fettweis, and Bertrand Corn\\'elusse", "title": "A Probabilistic Forecast-Driven Strategy for a Risk-Aware Participation\n  in the Capacity Firming Market", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The core contribution is to propose a probabilistic forecast-driven strategy,\nmodeled as a min-max-min robust optimization problem with recourse, and solved\nusing a Benders-dual cutting plane algorithm in a tractable manner. The\nconvergence is improved by building an initial set of cuts. In addition, a\ndynamic risk-averse parameters selection strategy based on the quantile\nforecasts distribution is proposed. A secondary contribution is to use a\nrecently developed deep learning model known as normalizing flows to generate\nquantile forecasts of renewable generation for the robust optimization problem.\nThis technique provides a general mechanism for defining expressive probability\ndistributions, only requiring the specification of a base distribution and a\nseries of bijective transformations. Overall, the robust approach improves the\nresults over a deterministic approach with nominal point forecasts by finding a\ntrade-off between conservative and risk-seeking policies. The case study uses\nthe photovoltaic generation monitored on-site at the University of Li\\`ege\n(ULi\\`ege), Belgium.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 13:13:07 GMT"}, {"version": "v2", "created": "Mon, 21 Jun 2021 12:24:20 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Dumas", "Jonathan", ""], ["Cointe", "Colin", ""], ["Wehenkel", "Antoine", ""], ["Sutera", "Antonio", ""], ["Fettweis", "Xavier", ""], ["Corn\u00e9lusse", "Bertrand", ""]]}, {"id": "2105.13806", "submitter": "Aras Dargazany", "authors": "Aras Dargazany", "title": "DRL: Deep Reinforcement Learning for Intelligent Robot Control --\n  Concept, Literature, and Future", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combination of machine learning (for generating machine intelligence),\ncomputer vision (for better environment perception), and robotic systems (for\ncontrolled environment interaction) motivates this work toward proposing a\nvision-based learning framework for intelligent robot control as the ultimate\ngoal (vision-based learning robot). This work specifically introduces deep\nreinforcement learning as the the learning framework, a General-purpose\nframework for AI (AGI) meaning application-independent and\nplatform-independent. In terms of robot control, this framework is proposing\nspecifically a high-level control architecture independent of the low-level\ncontrol, meaning these two required level of control can be developed\nseparately from each other. In this aspect, the high-level control creates the\nrequired intelligence for the control of the platform using the recorded\nlow-level controlling data from that same platform generated by a trainer. The\nrecorded low-level controlling data is simply indicating the successful and\nfailed experiences or sequences of experiments conducted by a trainer using the\nsame robotic platform. The sequences of the recorded data are composed of\nobservation data (input sensor), generated reward (feedback value) and action\ndata (output controller). For experimental platform and experiments, vision\nsensors are used for perception of the environment, different kinematic\ncontrollers create the required motion commands based on the platform\napplication, deep learning approaches generate the required intelligence, and\nfinally reinforcement learning techniques incrementally improve the generated\nintelligence until the mission is accomplished by the robot.\n", "versions": [{"version": "v1", "created": "Tue, 20 Apr 2021 15:26:10 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Dargazany", "Aras", ""]]}, {"id": "2105.13810", "submitter": "Benjamin Maschler", "authors": "Benjamin Lindemann, Benjamin Maschler, Nada Sahlab, and Michael\n  Weyrich", "title": "A Survey on Anomaly Detection for Technical Systems using LSTM Networks", "comments": "14 pages, 6 figures, 4 tables. Accepted for publication by Computers\n  in Industry", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Anomalies represent deviations from the intended system operation and can\nlead to decreased efficiency as well as partial or complete system failure. As\nthe causes of anomalies are often unknown due to complex system dynamics,\nefficient anomaly detection is necessary. Conventional detection approaches\nrely on statistical and time-invariant methods that fail to address the complex\nand dynamic nature of anomalies. With advances in artificial intelligence and\nincreasing importance for anomaly detection and prevention in various domains,\nartificial neural network approaches enable the detection of more complex\nanomaly types while considering temporal and contextual characteristics. In\nthis article, a survey on state-of-the-art anomaly detection using deep neural\nand especially long short-term memory networks is conducted. The investigated\napproaches are evaluated based on the application scenario, data and anomaly\ntypes as well as further metrics. To highlight the potential of upcoming\nanomaly detection techniques, graph-based and transfer learning approaches are\nalso included in the survey, enabling the analysis of heterogeneous data as\nwell as compensating for its shortage and improving the handling of dynamic\nprocesses.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 13:24:40 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Lindemann", "Benjamin", ""], ["Maschler", "Benjamin", ""], ["Sahlab", "Nada", ""], ["Weyrich", "Michael", ""]]}, {"id": "2105.13812", "submitter": "Brigitte Krenn", "authors": "Brigitte Krenn, Stephanie Gross, Bernhard Dieber, Horst Pichler,\n  Kathrin Meyer", "title": "A proxemics game between festival visitors and an industrial robot", "comments": "5 pager, 2 pictures, HRI21 Workshop on \"Exploring Applications for\n  Autonomous Non-Verbal Human-Robot Interactions\" March 8 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With increased applications of collaborative robots (cobots) in industrial\nworkplaces, behavioural effects of human-cobot interactions need to be further\ninvestigated. This is of particular importance as nonverbal behaviours of\ncollaboration partners in human-robot teams significantly influence the\nexperience of the human interaction partners and the success of the\ncollaborative task. During the Ars Electronica 2020 Festival for Art,\nTechnology and Society (Linz, Austria), we invited visitors to exploratively\ninteract with an industrial robot, exhibiting restricted interaction\ncapabilities: extending and retracting its arm, depending on the movements of\nthe volunteer. The movements of the arm were pre-programmed and telecontrolled\nfor safety reasons (which was not obvious to the participants). We recorded\nvideo data of these interactions and investigated general nonverbal behaviours\nof the humans interacting with the robot, as well as nonverbal behaviours of\npeople in the audience. Our results showed that people were more interested in\nexploring the robot's action and perception capabilities than just reproducing\nthe interaction game as introduced by the instructors. We also found that the\nmajority of participants interacting with the robot approached it up to a\ndistance which would be perceived as threatening or intimidating, if it were a\nhuman interaction partner. Regarding bystanders, we found examples where people\nmade movements as if trying out variants of the current participant's\nbehaviour.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 13:26:00 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Krenn", "Brigitte", ""], ["Gross", "Stephanie", ""], ["Dieber", "Bernhard", ""], ["Pichler", "Horst", ""], ["Meyer", "Kathrin", ""]]}, {"id": "2105.13841", "submitter": "Huiqi Deng", "authors": "Huiqi Deng, Na Zou, Mengnan Du, Weifu Chen, Guocan Feng, Xia Hu", "title": "A General Taylor Framework for Unifying and Revisiting Attribution\n  Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attribution methods provide an insight into the decision-making process of\nmachine learning models, especially deep neural networks, by assigning\ncontribution scores to each individual feature. However, the attribution\nproblem has not been well-defined, which lacks a unified guideline to the\ncontribution assignment process. Furthermore, existing attribution methods\noften built upon various empirical intuitions and heuristics. There still lacks\na general theoretical framework that not only can offer a good description of\nthe attribution problem, but also can be applied to unifying and revisiting\nexisting attribution methods. To bridge the gap, in this paper, we propose a\nTaylor attribution framework, which models the attribution problem as how to\ndecide individual payoffs in a coalition. Then, we reformulate fourteen\nmainstream attribution methods into the Taylor framework and analyze these\nattribution methods in terms of rationale, fidelity, and limitation in the\nframework. Moreover, we establish three principles for a good attribution in\nthe Taylor attribution framework, i.e., low approximation error, correct Taylor\ncontribution assignment, and unbiased baseline selection. Finally, we\nempirically validate the Taylor reformulations and reveal a positive\ncorrelation between the attribution performance and the number of principles\nfollowed by the attribution method via benchmarking on real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 13:57:16 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Deng", "Huiqi", ""], ["Zou", "Na", ""], ["Du", "Mengnan", ""], ["Chen", "Weifu", ""], ["Feng", "Guocan", ""], ["Hu", "Xia", ""]]}, {"id": "2105.13854", "submitter": "Andriy Temko Dr", "authors": "Alison O'Shea, Gordon Lightbody, Geraldine Boylan, Andriy Temko", "title": "Neonatal seizure detection from raw multi-channel EEG using a fully\n  convolutional architecture", "comments": null, "journal-ref": "Neural Networks (2020)", "doi": "10.1016/j.neunet.2019.11.023", "report-no": null, "categories": "cs.LG cs.AI stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A deep learning classifier for detecting seizures in neonates is proposed.\nThis architecture is designed to detect seizure events from raw\nelectroencephalogram (EEG) signals as opposed to the state-of-the-art hand\nengineered feature-based representation employed in traditional machine\nlearning based solutions. The seizure detection system utilises only\nconvolutional layers in order to process the multichannel time domain signal\nand is designed to exploit the large amount of weakly labelled data in the\ntraining stage. The system performance is assessed on a large database of\ncontinuous EEG recordings of 834h in duration; this is further validated on a\nheld-out publicly available dataset and compared with two baseline SVM based\nsystems.\n  The developed system achieves a 56% relative improvement with respect to a\nfeature-based state-of-the art baseline, reaching an AUC of 98.5%; this also\ncompares favourably both in terms of performance and run-time. The effect of\nvarying architectural parameters is thoroughly studied. The performance\nimprovement is achieved through novel architecture design which allows more\nefficient usage of available training data and end-to-end optimisation from the\nfront-end feature extraction to the back-end classification. The proposed\narchitecture opens new avenues for the application of deep learning to neonatal\nEEG, where the performance becomes a function of the amount of training data\nwith less dependency on the availability of precise clinical labels.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 14:08:36 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["O'Shea", "Alison", ""], ["Lightbody", "Gordon", ""], ["Boylan", "Geraldine", ""], ["Temko", "Andriy", ""]]}, {"id": "2105.13856", "submitter": "Zhuoyuan Mao", "authors": "Zhuoyuan Mao, Prakhar Gupta, Chenhui Chu, Martin Jaggi and Sadao\n  Kurohashi", "title": "Lightweight Cross-Lingual Sentence Representation Learning", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale models for learning fixed-dimensional cross-lingual sentence\nrepresentations like LASER (Artetxe and Schwenk, 2019b) lead to significant\nimprovement in performance on downstream tasks. However, further increases and\nmodifications based on such large-scale models are usually impractical due to\nmemory limitations. In this work, we introduce a lightweight dual-transformer\narchitecture with just 2 layers for generating memory-efficient cross-lingual\nsentence representations. We explore different training tasks and observe that\ncurrent cross-lingual training tasks leave a lot to be desired for this shallow\narchitecture. To ameliorate this, we propose a novel cross-lingual language\nmodel, which combines the existing single-word masked language model with the\nnewly proposed cross-lingual token-level reconstruction task. We further\naugment the training task by the introduction of two computationally-lite\nsentence-level contrastive learning tasks to enhance the alignment of\ncross-lingual sentence representation space, which compensates for the learning\nbottleneck of the lightweight transformer for generative tasks. Our comparisons\nwith competing models on cross-lingual sentence retrieval and multilingual\ndocument classification confirm the effectiveness of the newly proposed\ntraining tasks for a shallow model.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 14:10:48 GMT"}, {"version": "v2", "created": "Sat, 12 Jun 2021 16:03:16 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Mao", "Zhuoyuan", ""], ["Gupta", "Prakhar", ""], ["Chu", "Chenhui", ""], ["Jaggi", "Martin", ""], ["Kurohashi", "Sadao", ""]]}, {"id": "2105.13857", "submitter": "Emil Carlsson", "authors": "Emil Carlsson, Devdatt Dubhashi, Fredrik D. Johansson", "title": "Learning Approximate and Exact Numeral Systems via Reinforcement\n  Learning", "comments": "CogSci 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work (Xu et al., 2020) has suggested that numeral systems in different\nlanguages are shaped by a functional need for efficient communication in an\ninformation-theoretic sense. Here we take a learning-theoretic approach and\nshow how efficient communication emerges via reinforcement learning. In our\nframework, two artificial agents play a Lewis signaling game where the goal is\nto convey a numeral concept. The agents gradually learn to communicate using\nreinforcement learning and the resulting numeral systems are shown to be\nefficient in the information-theoretic framework of Regier et al. (2015);\nGibson et al. (2017). They are also shown to be similar to human numeral\nsystems of same type. Our results thus provide a mechanistic explanation via\nreinforcement learning of the recent results in Xu et al. (2020) and can\npotentially be generalized to other semantic domains.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 14:12:10 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Carlsson", "Emil", ""], ["Dubhashi", "Devdatt", ""], ["Johansson", "Fredrik D.", ""]]}, {"id": "2105.13878", "submitter": "Xiaonan Li", "authors": "Xiaonan Li, Yunfan Shao, Tianxiang Sun, Hang Yan, Xipeng Qiu, Xuanjing\n  Huang", "title": "Accelerating BERT Inference for Sequence Labeling via Early-Exit", "comments": "Accepted to the ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both performance and efficiency are crucial factors for sequence labeling\ntasks in many real-world scenarios. Although the pre-trained models (PTMs) have\nsignificantly improved the performance of various sequence labeling tasks,\ntheir computational cost is expensive. To alleviate this problem, we extend the\nrecent successful early-exit mechanism to accelerate the inference of PTMs for\nsequence labeling tasks. However, existing early-exit mechanisms are\nspecifically designed for sequence-level tasks, rather than sequence labeling.\nIn this paper, we first propose a simple extension of sentence-level early-exit\nfor sequence labeling tasks. To further reduce the computational cost, we also\npropose a token-level early-exit mechanism that allows partial tokens to exit\nearly at different layers. Considering the local dependency inherent in\nsequence labeling, we employed a window-based criterion to decide for a token\nwhether or not to exit. The token-level early-exit brings the gap between\ntraining and inference, so we introduce an extra self-sampling fine-tuning\nstage to alleviate it. The extensive experiments on three popular sequence\nlabeling tasks show that our approach can save up to 66%-75% inference cost\nwith minimal performance degradation. Compared with competitive compressed\nmodels such as DistilBERT, our approach can achieve better performance under\nthe same speed-up ratios of 2X, 3X, and 4X.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 14:39:26 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 12:31:37 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Li", "Xiaonan", ""], ["Shao", "Yunfan", ""], ["Sun", "Tianxiang", ""], ["Yan", "Hang", ""], ["Qiu", "Xipeng", ""], ["Huang", "Xuanjing", ""]]}, {"id": "2105.13880", "submitter": "Yujia Qin", "authors": "Yujia Qin, Yankai Lin, Jing Yi, Jiajie Zhang, Xu Han, Zhengyan Zhang,\n  Yusheng Su, Zhiyuan Liu, Peng Li, Maosong Sun, Jie Zhou", "title": "Knowledge Inheritance for Pre-trained Language Models", "comments": "preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent explorations of large-scale pre-trained language models (PLMs) such as\nGPT-3 have revealed the power of PLMs with huge amounts of parameters, setting\noff a wave of training ever-larger PLMs. However, training a large-scale PLM\nrequires tremendous amounts of computational resources, which is time-consuming\nand expensive. In addition, existing large-scale PLMs are mainly trained from\nscratch individually, ignoring the availability of many existing well-trained\nPLMs. To this end, we explore the question that how can previously trained PLMs\nbenefit training larger PLMs in future. Specifically, we introduce a novel\npre-training framework named \"knowledge inheritance\" (KI), which combines both\nself-learning and teacher-guided learning to efficiently train larger PLMs.\nSufficient experimental results demonstrate the feasibility of our KI\nframework. We also conduct empirical analyses to explore the effects of teacher\nPLMs' pre-training settings, including model architecture, pre-training data,\netc. Finally, we show that KI can well support lifelong learning and knowledge\ntransfer.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 14:43:26 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Qin", "Yujia", ""], ["Lin", "Yankai", ""], ["Yi", "Jing", ""], ["Zhang", "Jiajie", ""], ["Han", "Xu", ""], ["Zhang", "Zhengyan", ""], ["Su", "Yusheng", ""], ["Liu", "Zhiyuan", ""], ["Li", "Peng", ""], ["Sun", "Maosong", ""], ["Zhou", "Jie", ""]]}, {"id": "2105.13906", "submitter": "Saif Ur Rehaman", "authors": "Saif Ur Rehman, Muhammad Rashid Razzaq, Muhammad Hadi Hussian", "title": "Training of SSD(Single Shot Detector) for Facial Detection using Nvidia\n  Jetson Nano", "comments": "7 Pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.DC eess.IV", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In this project, we have used the computer vision algorithm SSD (Single Shot\ndetector) computer vision algorithm and trained this algorithm from the dataset\nwhich consists of 139 Pictures. Images were labeled using Intel CVAT (Computer\nVision Annotation Tool)\n  We trained this model for facial detection. We have deployed our trained\nmodel and software in the Nvidia Jetson Nano Developer kit. Model code is\nwritten in Pytorch's deep learning framework. The programming language used is\nPython.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 15:16:24 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Rehman", "Saif Ur", ""], ["Razzaq", "Muhammad Rashid", ""], ["Hussian", "Muhammad Hadi", ""]]}, {"id": "2105.13947", "submitter": "Anna Rogers", "authors": "Anna Rogers", "title": "Changing the World by Changing the Data", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NLP community is currently investing a lot more research and resources into\ndevelopment of deep learning models than training data. While we have made a\nlot of progress, it is now clear that our models learn all kinds of spurious\npatterns, social biases, and annotation artifacts. Algorithmic solutions have\nso far had limited success. An alternative that is being actively discussed is\nmore careful design of datasets so as to deliver specific signals. This\nposition paper maps out the arguments for and against data curation, and argues\nthat fundamentally the point is moot: curation already is and will be\nhappening, and it is changing the world. The question is only how much thought\nwe want to invest into that process.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 16:17:22 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Rogers", "Anna", ""]]}, {"id": "2105.13959", "submitter": "Sonal Kumar", "authors": "Sreyan Ghosh, Sonal Kumar", "title": "Cisco at SemEval-2021 Task 5: What's Toxic?: Leveraging Transformers for\n  Multiple Toxic Span Extraction from Online Comments", "comments": "9 pages, accepted at SemEval-2021 co-located with ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Social network platforms are generally used to share positive, constructive,\nand insightful content. However, in recent times, people often get exposed to\nobjectionable content like threat, identity attacks, hate speech, insults,\nobscene texts, offensive remarks or bullying. Existing work on toxic speech\ndetection focuses on binary classification or on differentiating toxic speech\namong a small set of categories. This paper describes the system proposed by\nteam Cisco for SemEval-2021 Task 5: Toxic Spans Detection, the first shared\ntask focusing on detecting the spans in the text that attribute to its\ntoxicity, in English language. We approach this problem primarily in two ways:\na sequence tagging approach and a dependency parsing approach. In our sequence\ntagging approach we tag each token in a sentence under a particular tagging\nscheme. Our best performing architecture in this approach also proved to be our\nbest performing architecture overall with an F1 score of 0.6922, thereby\nplacing us 7th on the final evaluation phase leaderboard. We also explore a\ndependency parsing approach where we extract spans from the input sentence\nunder the supervision of target span boundaries and rank our spans using a\nbiaffine model. Finally, we also provide a detailed analysis of our results and\nmodel performance in our paper.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 16:27:49 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Ghosh", "Sreyan", ""], ["Kumar", "Sonal", ""]]}, {"id": "2105.13975", "submitter": "Veronika Thost", "authors": "Arthur Feeney and Rishabh Gupta and Veronika Thost and Rico Angell and\n  Gayathri Chandu and Yash Adhikari and Tengfei Ma", "title": "Relation Matters in Sampling: A Scalable Multi-Relational Graph Neural\n  Network for Drug-Drug Interaction Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sampling is an established technique to scale graph neural networks to large\ngraphs. Current approaches however assume the graphs to be homogeneous in terms\nof relations and ignore relation types, critically important in biomedical\ngraphs. Multi-relational graphs contain various types of relations that usually\ncome with variable frequency and have different importance for the problem at\nhand. We propose an approach to modeling the importance of relation types for\nneighborhood sampling in graph neural networks and show that we can learn the\nright balance: relation-type probabilities that reflect both frequency and\nimportance. Our experiments on drug-drug interaction prediction show that\nstate-of-the-art graph neural networks profit from relation-dependent sampling\nin terms of both accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 16:55:09 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Feeney", "Arthur", ""], ["Gupta", "Rishabh", ""], ["Thost", "Veronika", ""], ["Angell", "Rico", ""], ["Chandu", "Gayathri", ""], ["Adhikari", "Yash", ""], ["Ma", "Tengfei", ""]]}, {"id": "2105.13984", "submitter": "Pierce Burke", "authors": "Pierce Burke and Richard Klein", "title": "Confident in the Crowd: Bayesian Inference to Improve Data Labelling in\n  Crowdsourcing", "comments": "6 pages, 4 figures", "journal-ref": "2020 International SAUPEC/RobMech/PRASA Conference, 2020, pp. 1-6", "doi": "10.1109/SAUPEC/RobMech/PRASA48453.2020.9041099", "report-no": null, "categories": "cs.LG cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increased interest in machine learning and big data problems, the\nneed for large amounts of labelled data has also grown. However, it is often\ninfeasible to get experts to label all of this data, which leads many\npractitioners to crowdsourcing solutions. In this paper, we present new\ntechniques to improve the quality of the labels while attempting to reduce the\ncost. The naive approach to assigning labels is to adopt a majority vote\nmethod, however, in the context of data labelling, this is not always ideal as\ndata labellers are not equally reliable. One might, instead, give higher\npriority to certain labellers through some kind of weighted vote based on past\nperformance. This paper investigates the use of more sophisticated methods,\nsuch as Bayesian inference, to measure the performance of the labellers as well\nas the confidence of each label. The methods we propose follow an iterative\nimprovement algorithm which attempts to use the least amount of workers\nnecessary to achieve the desired confidence in the inferred label. This paper\nexplores simulated binary classification problems with simulated workers and\nquestions to test the proposed methods. Our methods outperform the standard\nvoting methods in both cost and accuracy while maintaining higher reliability\nwhen there is disagreement within the crowd.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 17:09:45 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Burke", "Pierce", ""], ["Klein", "Richard", ""]]}, {"id": "2105.13986", "submitter": "Caleb Bowyer", "authors": "Caleb M. Bowyer", "title": "Improving Generalization in Mountain Car Through the Partitioned\n  Parameterized Policy Approach via Quasi-Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The reinforcement learning problem of finding a control policy that minimizes\nthe minimum time objective for the Mountain Car environment is considered.\nParticularly, a class of parameterized nonlinear feedback policies is optimized\nover to reach the top of the highest mountain peak in minimum time. The\noptimization is carried out using quasi-Stochastic Gradient Descent (qSGD)\nmethods. In attempting to find the optimal minimum time policy, a new\nparameterized policy approach is considered that seeks to learn an optimal\npolicy parameter for different regions of the state space, rather than rely on\na single macroscopic policy parameter for the entire state space. This\npartitioned parameterized policy approach is shown to outperform the uniform\nparameterized policy approach and lead to greater generalization than prior\nmethods, where the Mountain Car became trapped in circular trajectories in the\nstate space.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 17:11:10 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Bowyer", "Caleb M.", ""]]}, {"id": "2105.13988", "submitter": "Emanuele Guidotti", "authors": "Emanuele Guidotti, Alfio Ferrara", "title": "An Explainable Probabilistic Classifier for Categorical Data Inspired to\n  Quantum Physics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI quant-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents Sparse Tensor Classifier (STC), a supervised\nclassification algorithm for categorical data inspired by the notion of\nsuperposition of states in quantum physics. By regarding an observation as a\nsuperposition of features, we introduce the concept of wave-particle duality in\nmachine learning and propose a generalized framework that unifies the classical\nand the quantum probability. We show that STC possesses a wide range of\ndesirable properties not available in most other machine learning methods but\nit is at the same time exceptionally easy to comprehend and use. Empirical\nevaluation of STC on structured data and text classification demonstrates that\nour methodology achieves state-of-the-art performances compared to both\nstandard classifiers and deep learning, at the additional benefit of requiring\nminimal data pre-processing and hyper-parameter tuning. Moreover, STC provides\na native explanation of its predictions both for single instances and for each\ntarget label globally.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 15:41:30 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Guidotti", "Emanuele", ""], ["Ferrara", "Alfio", ""]]}, {"id": "2105.14039", "submitter": "Andrew Lampinen", "authors": "Andrew Kyle Lampinen, Stephanie C.Y. Chan, Andrea Banino, Felix Hill", "title": "Towards mental time travel: a hierarchical memory for reinforcement\n  learning agents", "comments": "10 pages main text; 22 pages total", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning agents often forget details of the past, especially\nafter delays or distractor tasks. Agents with common memory architectures\nstruggle to recall and integrate across multiple timesteps of a past event, or\neven to recall the details of a single timestep that is followed by distractor\ntasks. To address these limitations, we propose a Hierarchical Transformer\nMemory (HTM), which helps agents to remember the past in detail. HTM stores\nmemories by dividing the past into chunks, and recalls by first performing\nhigh-level attention over coarse summaries of the chunks, and then performing\ndetailed attention within only the most relevant chunks. An agent with HTM can\ntherefore \"mentally time-travel\" -- remember past events in detail without\nattending to all intervening events. We show that agents with HTM substantially\noutperform agents with other memory architectures at tasks requiring long-term\nrecall, retention, or reasoning over memory. These include recalling where an\nobject is hidden in a 3D environment, rapidly learning to navigate efficiently\nin a new neighborhood, and rapidly learning and retaining new object names.\nAgents with HTM can extrapolate to task sequences an order of magnitude longer\nthan they were trained on, and can even generalize zero-shot from a\nmeta-learning setting to maintaining knowledge across episodes. HTM improves\nagent sample efficiency, generalization, and generality (by solving tasks that\npreviously required specialized architectures). Our work is a step towards\nagents that can learn, interact, and adapt in complex and temporally-extended\nenvironments.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 18:12:28 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Lampinen", "Andrew Kyle", ""], ["Chan", "Stephanie C. Y.", ""], ["Banino", "Andrea", ""], ["Hill", "Felix", ""]]}, {"id": "2105.14064", "submitter": "Chien-Sheng Wu", "authors": "Chien-Sheng Wu and Linqing Liu and Wenhao Liu and Pontus Stenetorp and\n  Caiming Xiong", "title": "Controllable Abstractive Dialogue Summarization with Sketch Supervision", "comments": "ACL-Findings 2021. Code is released at\n  https://github.com/salesforce/ConvSumm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we aim to improve abstractive dialogue summarization quality\nand, at the same time, enable granularity control. Our model has two primary\ncomponents and stages: 1) a two-stage generation strategy that generates a\npreliminary summary sketch serving as the basis for the final summary. This\nsummary sketch provides a weakly supervised signal in the form of\npseudo-labeled interrogative pronoun categories and key phrases extracted using\na constituency parser. 2) A simple strategy to control the granularity of the\nfinal summary, in that our model can automatically determine or control the\nnumber of generated summary sentences for a given dialogue by predicting and\nhighlighting different text spans from the source text. Our model achieves\nstate-of-the-art performance on the largest dialogue summarization corpus\nSAMSum, with as high as 50.79 in ROUGE-L score. In addition, we conduct a case\nstudy and show competitive human evaluation results and controllability to\nhuman-annotated summaries.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 19:05:36 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 05:16:05 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Wu", "Chien-Sheng", ""], ["Liu", "Linqing", ""], ["Liu", "Wenhao", ""], ["Stenetorp", "Pontus", ""], ["Xiong", "Caiming", ""]]}, {"id": "2105.14069", "submitter": "Arman Dehpanah", "authors": "Arman Dehpanah, Muheeb Faizan Ghori, Jonathan Gemmell, Bamshad\n  Mobasher", "title": "The Evaluation of Rating Systems in Team-based Battle Royale Games", "comments": "Updated references -- 10 pages, 1 figure, Accepted in the 23rd\n  International Conference on Artificial Intelligence (ICAI'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online competitive games have become a mainstream entertainment platform. To\ncreate a fair and exciting experience, these games use rating systems to match\nplayers with similar skills. While there has been an increasing amount of\nresearch on improving the performance of these systems, less attention has been\npaid to how their performance is evaluated. In this paper, we explore the\nutility of several metrics for evaluating three popular rating systems on a\nreal-world dataset of over 25,000 team battle royale matches. Our results\nsuggest considerable differences in their evaluation patterns. Some metrics\nwere highly impacted by the inclusion of new players. Many could not capture\nthe real differences between certain groups of players. Among all metrics\nstudied, normalized discounted cumulative gain (NDCG) demonstrated more\nreliable performance and more flexibility. It alleviated most of the challenges\nfaced by the other metrics while adding the freedom to adjust the focus of the\nevaluations on different groups of players.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 19:22:07 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 20:40:26 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Dehpanah", "Arman", ""], ["Ghori", "Muheeb Faizan", ""], ["Gemmell", "Jonathan", ""], ["Mobasher", "Bamshad", ""]]}, {"id": "2105.14073", "submitter": "Murat Cubuktepe", "authors": "Franck Djeumou, Murat Cubuktepe, Craig Lennon, Ufuk Topcu", "title": "Task-Guided Inverse Reinforcement Learning Under Partial Information", "comments": "Submitted to NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of inverse reinforcement learning (IRL), where the\nlearning agent recovers a reward function using expert demonstrations. Most of\nthe existing IRL techniques make the often unrealistic assumption that the\nagent has access to full information about the environment. We remove this\nassumption by developing an algorithm for IRL in partially observable Markov\ndecision processes (POMDPs), where an agent cannot directly observe the current\nstate of the POMDP. The algorithm addresses several limitations of existing\ntechniques that do not take the \\emph{information asymmetry} between the expert\nand the agent into account. First, it adopts causal entropy as the measure of\nthe likelihood of the expert demonstrations as opposed to entropy in most\nexisting IRL techniques and avoids a common source of algorithmic complexity.\nSecond, it incorporates task specifications expressed in temporal logic into\nIRL. Such specifications may be interpreted as side information available to\nthe learner a priori in addition to the demonstrations, and may reduce the\ninformation asymmetry between the expert and the agent. Nevertheless, the\nresulting formulation is still nonconvex due to the intrinsic nonconvexity of\nthe so-called \\emph{forward problem}, i.e., computing an optimal policy given a\nreward function, in POMDPs. We address this nonconvexity through sequential\nconvex programming and introduce several extensions to solve the forward\nproblem in a scalable manner. This scalability allows computing policies that\nincorporate memory at the expense of added computational cost yet also achieves\nhigher performance compared to memoryless policies. We demonstrate that, even\nwith severely limited data, the algorithm learns reward functions and policies\nthat satisfy the task and induce a similar behavior to the expert by leveraging\nthe side information and incorporating memory into the policy.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 19:36:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Djeumou", "Franck", ""], ["Cubuktepe", "Murat", ""], ["Lennon", "Craig", ""], ["Topcu", "Ufuk", ""]]}, {"id": "2105.14074", "submitter": "Rohan Chitnis", "authors": "Rohan Chitnis, Tom Silver, Joshua B. Tenenbaum, Tomas Lozano-Perez,\n  Leslie Pack Kaelbling", "title": "Learning Neuro-Symbolic Relational Transition Models for Bilevel\n  Planning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite recent, independent progress in model-based reinforcement learning\nand integrated symbolic-geometric robotic planning, synthesizing these\ntechniques remains challenging because of their disparate assumptions and\nstrengths. In this work, we take a step toward bridging this gap with\nNeuro-Symbolic Relational Transition Models (NSRTs), a novel class of\ntransition models that are data-efficient to learn, compatible with powerful\nrobotic planning methods, and generalizable over objects. NSRTs have both\nsymbolic and neural components, enabling a bilevel planning scheme where\nsymbolic AI planning in an outer loop guides continuous planning with neural\nmodels in an inner loop. Experiments in four robotic planning domains show that\nNSRTs can be learned after only tens or hundreds of training episodes, and then\nused for fast planning in new tasks that require up to 60 actions to reach the\ngoal and involve many more objects than were seen during training. Video:\nhttps://tinyurl.com/chitnis-nsrts\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 19:37:18 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chitnis", "Rohan", ""], ["Silver", "Tom", ""], ["Tenenbaum", "Joshua B.", ""], ["Lozano-Perez", "Tomas", ""], ["Kaelbling", "Leslie Pack", ""]]}, {"id": "2105.14083", "submitter": "Glenn Dawson", "authors": "Glenn Dawson, Robi Polikar", "title": "Rethinking Noisy Label Models: Labeler-Dependent Noise with Adversarial\n  Awareness", "comments": "9 pages, 3 figures, 3 algorithms. Currently under blind review at\n  NeurIPS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most studies on learning from noisy labels rely on unrealistic models of\ni.i.d. label noise, such as class-conditional transition matrices. More recent\nwork on instance-dependent noise models are more realistic, but assume a single\ngenerative process for label noise across the entire dataset. We propose a more\nprincipled model of label noise that generalizes instance-dependent noise to\nmultiple labelers, based on the observation that modern datasets are typically\nannotated using distributed crowdsourcing methods. Under our labeler-dependent\nmodel, label noise manifests itself under two modalities: natural error of\ngood-faith labelers, and adversarial labels provided by malicious actors. We\npresent two adversarial attack vectors that more accurately reflect the label\nnoise that may be encountered in real-world settings, and demonstrate that\nunder our multimodal noisy labels model, state-of-the-art approaches for\nlearning from noisy labels are defeated by adversarial label attacks. Finally,\nwe propose a multi-stage, labeler-aware, model-agnostic framework that reliably\nfilters noisy labels by leveraging knowledge about which data partitions were\nlabeled by which labeler, and show that our proposed framework remains robust\neven in the presence of extreme adversarial label noise.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 19:58:18 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 01:40:37 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Dawson", "Glenn", ""], ["Polikar", "Robi", ""]]}, {"id": "2105.14086", "submitter": "Xiaopei Wan", "authors": "Xiaopei Wan, Shengjie Chen, Yujiu Yang, Zhenhua Guo, Fangbo Tao", "title": "Augmenting Anchors by the Detector Itself", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  It is difficult to determine the scale and aspect ratio of anchors for\nanchor-based object detection methods. Current state-of-the-art object\ndetectors either determine anchor parameters according to objects' shape and\nscale in a dataset, or avoid this problem by utilizing anchor-free method. In\nthis paper, we propose a gradient-free anchor augmentation method named AADI,\nwhich means Augmenting Anchors by the Detector Itself. AADI is not an\nanchor-free method, but it converts the scale and aspect ratio of anchors from\na continuous space to a discrete space, which greatly alleviates the problem of\nanchors' designation. Furthermore, AADI does not add any parameters or\nhyper-parameters, which is beneficial for future research and downstream tasks.\nExtensive experiments on COCO dataset show that AADI has obvious advantages for\nboth two-stage and single-stage methods, specifically, AADI achieves at least\n2.1 AP improvements on Faster R-CNN and 1.6 AP improvements on RetinaNet, using\nResNet-50 model. We hope that this simple and cost-efficient method can be\nwidely used in object detection.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 20:11:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wan", "Xiaopei", ""], ["Chen", "Shengjie", ""], ["Yang", "Yujiu", ""], ["Guo", "Zhenhua", ""], ["Tao", "Fangbo", ""]]}, {"id": "2105.14088", "submitter": "Liang Luo", "authors": "Liang Luo, Jacob Nelson, Arvind Krishnamurthy, Luis Ceze", "title": "Cloud Collectives: Towards Cloud-aware Collectives forML Workloads with\n  Rank Reordering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  ML workloads are becoming increasingly popular in the cloud. Good cloud\ntraining performance is contingent on efficient parameter exchange among VMs.\nWe find that Collectives, the widely used distributed communication algorithms,\ncannot perform optimally out of the box due to the hierarchical topology of\ndatacenter networks and multi-tenancy nature of the cloudenvironment.In this\npaper, we present Cloud Collectives , a prototype that accelerates collectives\nby reordering theranks of participating VMs such that the communication pattern\ndictated by the selected collectives operation best exploits the locality in\nthe network.Collectives is non-intrusive, requires no code changes nor rebuild\nof an existing application, and runs without support from cloud providers. Our\npreliminary application of Cloud Collectives on allreduce operations in public\nclouds results in a speedup of up to 3.7x in multiple microbenchmarks and 1.3x\nin real-world workloads of distributed training of deep neural networks and\ngradient boosted decision trees using state-of-the-art frameworks.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 20:14:38 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Luo", "Liang", ""], ["Nelson", "Jacob", ""], ["Krishnamurthy", "Arvind", ""], ["Ceze", "Luis", ""]]}, {"id": "2105.14108", "submitter": "Christian David Marton", "authors": "Christian David Marton, Guillaume Lajoie, Kanaka Rajan", "title": "Efficient and robust multi-task learning in the brain with modular task\n  primitives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In a real-world setting biological agents do not have infinite resources to\nlearn new things. It is thus useful to recycle previously acquired knowledge in\na way that allows for faster, less resource-intensive acquisition of multiple\nnew skills. Neural networks in the brain are likely not entirely re-trained\nwith new tasks, but how they leverage existing computations to learn new tasks\nis not well understood. In this work, we study this question in artificial\nneural networks trained on commonly used neuroscience paradigms. Building on\nrecent work from the multi-task learning literature, we propose two\ningredients: (1) network modularity, and (2) learning task primitives.\nTogether, these ingredients form inductive biases we call structural and\nfunctional, respectively. Using a corpus of nine different tasks, we show that\na modular network endowed with task primitives allows for learning multiple\ntasks well while keeping parameter counts, and updates, low. We also show that\nthe skills acquired with our approach are more robust to a broad range of\nperturbations compared to those acquired with other multi-task learning\nstrategies. This work offers a new perspective on achieving efficient\nmulti-task learning in the brain, and makes predictions for novel neuroscience\nexperiments in which targeted perturbations are employed to explore solution\nspaces.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 21:07:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Marton", "Christian David", ""], ["Lajoie", "Guillaume", ""], ["Rajan", "Kanaka", ""]]}, {"id": "2105.14111", "submitter": "Jack Koch", "authors": "Jack Koch, Lauro Langosco, Jacob Pfau, James Le, Lee Sharkey", "title": "Objective Robustness in Deep Reinforcement Learning", "comments": "small revisions, corrected figure for ablation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study objective robustness failures, a type of out-of-distribution\nrobustness failure in reinforcement learning (RL). Objective robustness\nfailures occur when an RL agent retains its capabilities out-of-distribution\nyet pursues the wrong objective. This kind of failure presents different risks\nthan the robustness problems usually considered in the literature, since it\ninvolves agents that leverage their capabilities to pursue the wrong objective\nrather than simply failing to do anything useful. We provide the first explicit\nempirical demonstrations of objective robustness failures and present a partial\ncharacterization of its causes.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 21:13:34 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 21:48:02 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Koch", "Jack", ""], ["Langosco", "Lauro", ""], ["Pfau", "Jacob", ""], ["Le", "James", ""], ["Sharkey", "Lee", ""]]}, {"id": "2105.14119", "submitter": "Adam Kalai", "authors": "Adam Tauman Kalai, Varun Kanade", "title": "Towards optimally abstaining from prediction", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A common challenge across all areas of machine learning is that training data\nis not distributed like test data, due to natural shifts, \"blind spots,\" or\nadversarial examples. We consider a model where one may abstain from\npredicting, at a fixed cost. In particular, our transductive abstention\nalgorithm takes labeled training examples and unlabeled test examples as input,\nand provides predictions with optimal prediction loss guarantees. The loss\nbounds match standard generalization bounds when test examples are i.i.d. from\nthe training distribution, but add an additional term that is the cost of\nabstaining times the statistical distance between the train and test\ndistribution (or the fraction of adversarial examples). For linear regression,\nwe give a polynomial-time algorithm based on Celis-Dennis-Tapia optimization\nalgorithms. For binary classification, we show how to efficiently implement it\nusing a proper agnostic learner (i.e., an Empirical Risk Minimizer) for the\nclass of interest. Our work builds on a recent abstention algorithm of\nGoldwasser, Kalais, and Montasser (2020) for transductive binary\nclassification.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 21:44:48 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kalai", "Adam Tauman", ""], ["Kanade", "Varun", ""]]}, {"id": "2105.14125", "submitter": "Vaneet Aggarwal", "authors": "Qinbo Bai and Mridul Agarwal and Vaneet Aggarwal", "title": "Joint Optimization of Multi-Objective Reinforcement Learning with Policy\n  Gradient Based Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SY eess.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many engineering problems have multiple objectives, and the overall aim is to\noptimize a non-linear function of these objectives. In this paper, we formulate\nthe problem of maximizing a non-linear concave function of multiple long-term\nobjectives. A policy-gradient based model-free algorithm is proposed for the\nproblem. To compute an estimate of the gradient, a biased estimator is\nproposed. The proposed algorithm is shown to achieve convergence to within an\n$\\epsilon$ of the global optima after sampling\n$\\mathcal{O}(\\frac{M^4\\sigma^2}{(1-\\gamma)^8\\epsilon^4})$ trajectories where\n$\\gamma$ is the discount factor and $M$ is the number of the agents, thus\nachieving the same dependence on $\\epsilon$ as the policy gradient algorithm\nfor the standard reinforcement learning.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 22:20:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Bai", "Qinbo", ""], ["Agarwal", "Mridul", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "2105.14127", "submitter": "Michael Gimelfarb Mr.", "authors": "Michael Gimelfarb, Andr\\'e Barreto, Scott Sanner, Chi-Guhn Lee", "title": "Risk-Aware Transfer in Reinforcement Learning using Successor Features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sample efficiency and risk-awareness are central to the development of\npractical reinforcement learning (RL) for complex decision-making. The former\ncan be addressed by transfer learning and the latter by optimizing some utility\nfunction of the return. However, the problem of transferring skills in a\nrisk-aware manner is not well-understood. In this paper, we address the problem\nof risk-aware policy transfer between tasks in a common domain that differ only\nin their reward functions, in which risk is measured by the variance of reward\nstreams. Our approach begins by extending the idea of generalized policy\nimprovement to maximize entropic utilities, thus extending policy improvement\nvia dynamic programming to sets of policies and levels of risk-aversion. Next,\nwe extend the idea of successor features (SF), a value function representation\nthat decouples the environment dynamics from the rewards, to capture the\nvariance of returns. Our resulting risk-aware successor features (RaSF)\nintegrate seamlessly within the RL framework, inherit the superior task\ngeneralization ability of SFs, and incorporate risk-awareness into the\ndecision-making. Experiments on a discrete navigation domain and control of a\nsimulated robotic arm demonstrate the ability of RaSFs to outperform\nalternative methods including SFs, when taking the risk of the learned policies\ninto account.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 22:22:03 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Gimelfarb", "Michael", ""], ["Barreto", "Andr\u00e9", ""], ["Sanner", "Scott", ""], ["Lee", "Chi-Guhn", ""]]}, {"id": "2105.14138", "submitter": "Hao Tang", "authors": "Guanglei Yang, Hao Tang, Zhun Zhong, Mingli Ding, Ling Shao, Nicu\n  Sebe, Elisa Ricci", "title": "Transformer-Based Source-Free Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the task of source-free domain adaptation (SFDA),\nwhere the source data are not available during target adaptation. Previous\nworks on SFDA mainly focus on aligning the cross-domain distributions. However,\nthey ignore the generalization ability of the pretrained source model, which\nlargely influences the initial target outputs that are vital to the target\nadaptation stage. To address this, we make the interesting observation that the\nmodel accuracy is highly correlated with whether or not attention is focused on\nthe objects in an image. To this end, we propose a generic and effective\nframework based on Transformer, named TransDA, for learning a generalized model\nfor SFDA. Specifically, we apply the Transformer as the attention module and\ninject it into a convolutional network. By doing so, the model is encouraged to\nturn attention towards the object regions, which can effectively improve the\nmodel's generalization ability on the target domains. Moreover, a novel\nself-supervised knowledge distillation approach is proposed to adapt the\nTransformer with target pseudo-labels, thus further encouraging the network to\nfocus on the object regions. Experiments on three domain adaptation tasks,\nincluding closed-set, partial-set, and open-set adaption, demonstrate that\nTransDA can greatly improve the adaptation accuracy and produce\nstate-of-the-art results. The source code and trained models are available at\nhttps://github.com/ygjwd12345/TransDA.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 23:06:26 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Yang", "Guanglei", ""], ["Tang", "Hao", ""], ["Zhong", "Zhun", ""], ["Ding", "Mingli", ""], ["Shao", "Ling", ""], ["Sebe", "Nicu", ""], ["Ricci", "Elisa", ""]]}, {"id": "2105.14149", "submitter": "Nandini Ramanan", "authors": "Charanraj Thimmisetty, Praveen Tiwari, Didac Gil de la Iglesia,\n  Nandini Ramanan, Marjorie Sayer, Viswesh Ananthakrishnan, and Claudionor\n  Nunes Coelho Jr", "title": "Log2NS: Enhancing Deep Learning Based Analysis of Logs With Formal to\n  Prevent Survivorship Bias", "comments": "10 pages, 5 tables, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Analysis of large observational data sets generated by a reactive system is a\ncommon challenge in debugging system failures and determining their root cause.\nOne of the major problems is that these observational data suffer from\nsurvivorship bias. Examples include analyzing traffic logs from networks, and\nsimulation logs from circuit design. In such applications, users want to detect\nnon-spurious correlations from observational data and obtain actionable\ninsights about them. In this paper, we introduce log to Neuro-symbolic\n(Log2NS), a framework that combines probabilistic analysis from machine\nlearning (ML) techniques on observational data with certainties derived from\nsymbolic reasoning on an underlying formal model. We apply the proposed\nframework to network traffic debugging by employing the following steps. To\ndetect patterns in network logs, we first generate global embedding vector\nrepresentations of entities such as IP addresses, ports, and applications.\nNext, we represent large log flow entries as clusters that make it easier for\nthe user to visualize and detect interesting scenarios that will be further\nanalyzed. To generalize these patterns, Log2NS provides an ability to query\nfrom static logs and correlation engines for positive instances, as well as\nformal reasoning for negative and unseen instances. By combining the strengths\nof deep learning and symbolic methods, Log2NS provides a very powerful\nreasoning and debugging tool for log-based data. Empirical evaluations on a\nreal internal data set demonstrate the capabilities of Log2NS.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 00:01:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Thimmisetty", "Charanraj", ""], ["Tiwari", "Praveen", ""], ["de la Iglesia", "Didac Gil", ""], ["Ramanan", "Nandini", ""], ["Sayer", "Marjorie", ""], ["Ananthakrishnan", "Viswesh", ""], ["Coelho", "Claudionor Nunes", "Jr"]]}, {"id": "2105.14162", "submitter": "Zhibo Zhang", "authors": "Ruiwen Li (co-first author), Zhibo Zhang (co-first author), Jiani Li,\n  Scott Sanner, Jongseong Jang, Yeonjeong Jeong, Dongsub Shim", "title": "EDDA: Explanation-driven Data Augmentation to Improve Model and\n  Explanation Alignment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Recent years have seen the introduction of a range of methods for post-hoc\nexplainability of image classifier predictions. However, these post-hoc\nexplanations may not always align perfectly with classifier predictions, which\nposes a significant challenge when attempting to debug models based on such\nexplanations. To this end, we seek a methodology that can improve alignment\nbetween model predictions and explanation method that is both agnostic to the\nmodel and explanation classes and which does not require ground truth\nexplanations. We achieve this through a novel explanation-driven data\naugmentation (EDDA) method that augments the training data with occlusions of\nexisting data stemming from model-explanations; this is based on the simple\nmotivating principle that occluding salient regions for the model prediction\nshould decrease the model confidence in the prediction, while occluding\nnon-salient regions should not change the prediction -- if the model and\nexplainer are aligned. To verify that this augmentation method improves model\nand explainer alignment, we evaluate the methodology on a variety of datasets,\nimage classification models, and explanation methods. We verify in all cases\nthat our explanation-driven data augmentation method improves alignment of the\nmodel and explanation in comparison to no data augmentation and non-explanation\ndriven data augmentation methods. In conclusion, this approach provides a novel\nmodel- and explainer-agnostic methodology for improving alignment between model\npredictions and explanations, which we see as a critical step forward for\npractical deployment and debugging of image classification models.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 00:42:42 GMT"}, {"version": "v2", "created": "Sat, 19 Jun 2021 00:01:42 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Li", "Ruiwen", "", "co-first author"], ["Zhang", "Zhibo", "", "co-first author"], ["Li", "Jiani", ""], ["Sanner", "Scott", ""], ["Jang", "Jongseong", ""], ["Jeong", "Yeonjeong", ""], ["Shim", "Dongsub", ""]]}, {"id": "2105.14167", "submitter": "Zeming Chen", "authors": "Zeming Chen, Qiyue Gao, Lawrence S. Moss", "title": "NeuralLog: Natural Language Inference with Joint Neural and Logical\n  Reasoning", "comments": "8 pages, 4 figures, The 10th Joint Conference on Lexical and\n  Computational Semantics (*SEM2021) @ ACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning (DL) based language models achieve high performance on various\nbenchmarks for Natural Language Inference (NLI). And at this time, symbolic\napproaches to NLI are receiving less attention. Both approaches (symbolic and\nDL) have their advantages and weaknesses. However, currently, no method\ncombines them in a system to solve the task of NLI. To merge symbolic and deep\nlearning methods, we propose an inference framework called NeuralLog, which\nutilizes both a monotonicity-based logical inference engine and a neural\nnetwork language model for phrase alignment. Our framework models the NLI task\nas a classic search problem and uses the beam search algorithm to search for\noptimal inference paths. Experiments show that our joint logic and neural\ninference system improves accuracy on the NLI task and can achieve state-of-art\naccuracy on the SICK and MED datasets.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 01:02:40 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 04:52:20 GMT"}, {"version": "v3", "created": "Thu, 10 Jun 2021 05:36:30 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Chen", "Zeming", ""], ["Gao", "Qiyue", ""], ["Moss", "Lawrence S.", ""]]}, {"id": "2105.14189", "submitter": "Lingzhi Wang", "authors": "Lingzhi Wang, Xingshan Zeng, Kam-Fai Wong", "title": "Quotation Recommendation and Interpretation Based on Transformation from\n  Queries to Quotations", "comments": "ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To help individuals express themselves better, quotation recommendation is\nreceiving growing attention. Nevertheless, most prior efforts focus on modeling\nquotations and queries separately and ignore the relationship between the\nquotations and the queries. In this work, we introduce a transformation matrix\nthat directly maps the query representations to quotation representations. To\nbetter learn the mapping relationship, we employ a mapping loss that minimizes\nthe distance of two semantic spaces (one for quotation and another for\nmapped-query). Furthermore, we explore using the words in history queries to\ninterpret the figurative language of quotations, where quotation-aware\nattention is applied on top of history queries to highlight the indicator\nwords. Experiments on two datasets in English and Chinese show that our model\noutperforms previous state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 07:25:59 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 06:07:23 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Wang", "Lingzhi", ""], ["Zeng", "Xingshan", ""], ["Wong", "Kam-Fai", ""]]}, {"id": "2105.14194", "submitter": "Nikolay Ivanov", "authors": "Nikolay Ivanov and Qiben Yan", "title": "Constraint-Based Inference of Heuristics for Foreign Exchange Trade\n  Model Optimization", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.AI cs.CE cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Foreign Exchange (Forex) is a large decentralized market, on which\ntrading analysis and algorithmic trading are popular. Research efforts have\nbeen focusing on proof of efficiency of certain technical indicators. We\ndemonstrate, however, that the values of indicator functions are not\nreproducible and often reduce the number of trade opportunities, compared to\nprice-action trading.\n  In this work, we develop two dataset-agnostic Forex trading heuristic\ntemplates with high rate of trading signals. In order to determine most optimal\nparameters for the given heuristic prototypes, we perform a machine learning\nsimulation of 10 years of Forex price data over three low-margin instruments\nand 6 different OHLC granularities. As a result, we develop a specific and\nreproducible list of most optimal trade parameters found for each\ninstrument-granularity pair, with 118 pips of average daily profit for the\noptimized configuration.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 00:36:02 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ivanov", "Nikolay", ""], ["Yan", "Qiben", ""]]}, {"id": "2105.14201", "submitter": "Qianren Mao", "authors": "Xi Li, Qianren Mao, Hao Peng, Hongdong Zhu, Jianxin Li, Zheng Wang", "title": "Automated Timeline Length Selection for Flexible Timeline Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By producing summaries for long-running events, timeline summarization (TLS)\nunderpins many information retrieval tasks. Successful TLS requires identifying\nan appropriate set of key dates (the timeline length) to cover. However, doing\nso is challenging as the right length can change from one topic to another.\nExisting TLS solutions either rely on an event-agnostic fixed length or an\nexpert-supplied setting. Neither of the strategies is desired for real-life TLS\nscenarios. A fixed, event-agnostic setting ignores the diversity of events and\ntheir development and hence can lead to low-quality TLS. Relying on\nexpert-crafted settings is neither scalable nor sustainable for processing many\ndynamically changing events. This paper presents a better TLS approach for\nautomatically and dynamically determining the TLS timeline length. We achieve\nthis by employing the established elbow method from the machine learning\ncommunity to automatically find the minimum number of dates within the time\nseries to generate concise and informative summaries. We applied our approach\nto four TLS datasets of English and Chinese and compared them against three\nprior methods. Experimental results show that our approach delivers comparable\nor even better summaries over state-of-art TLS methods, but it achieves this\nwithout expert involvement.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 03:47:10 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Li", "Xi", ""], ["Mao", "Qianren", ""], ["Peng", "Hao", ""], ["Zhu", "Hongdong", ""], ["Li", "Jianxin", ""], ["Wang", "Zheng", ""]]}, {"id": "2105.14207", "submitter": "Takuma Udagawa", "authors": "Takuma Udagawa and Akiko Aizawa", "title": "Maintaining Common Ground in Dynamic Environments", "comments": "Accepted at TACL; pre-MIT Press publication version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Common grounding is the process of creating and maintaining mutual\nunderstandings, which is a critical aspect of sophisticated human\ncommunication. While various task settings have been proposed in existing\nliterature, they mostly focus on creating common ground under static context\nand ignore the aspect of maintaining them overtime under dynamic context. In\nthis work, we propose a novel task setting to study the ability of both\ncreating and maintaining common ground in dynamic environments. Based on our\nminimal task formulation, we collected a large-scale dataset of 5,617 dialogues\nto enable fine-grained evaluation and analysis of various dialogue systems.\nThrough our dataset analyses, we highlight novel challenges introduced in our\nsetting, such as the usage of complex spatio-temporal expressions to create and\nmaintain common ground. Finally, we conduct extensive experiments to assess the\ncapabilities of our baseline dialogue system and discuss future prospects of\nour research.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 04:14:29 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Udagawa", "Takuma", ""], ["Aizawa", "Akiko", ""]]}, {"id": "2105.14212", "submitter": "Danny Arlen De Jes\\'us G\\'omez-Ram\\'irez", "authors": "Danny A. J. Gomez-Ramirez, Egil Nordqvist", "title": "Towards a General Many-Sorted Framework for Describing Certain Kinds of\n  Legal Statutes with a Potential Computational Realization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Examining a 20th-century Scandinavian legal theoretical tradition, we can\nextract an ontological naturalistic, a logical empiristic, and a modern\nidealistic rationale. We introduce the mathematical syntactic figure present in\nthe `logical empiricism' in a contemporary mathematical logic. A new formal\nframework for describing explicit purchase statutes (Sweden) is gradually\ndeveloped and subsequently proposed. This new framework is based on a\nmany-sorted first-order logic (MFOL) approach, where the semantics are grounded\nin concrete `physical' objects and situations with a legal relevance.\nSpecifically, we present a concrete formal syntactic translation of one of the\ncentral statutes of Swedish legislation for the purchase of immovable property.\nAdditionally, we discuss the potential implications that a subsequent\ndevelopment of such formalisations would have for constructing artificial\nagents (e.g., software) that can be used as `co-creative' legal assistance for\nsolving highly complex legal issues concerning the transfer of property, among\nothers.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 05:01:06 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Gomez-Ramirez", "Danny A. J.", ""], ["Nordqvist", "Egil", ""]]}, {"id": "2105.14219", "submitter": "Francesc Wilhelmi", "authors": "Francesc Wilhelmi, David G\\'oez, Paola Soto, Ramon Vall\\'es, Mohammad\n  Alfaifi, Abdulrahman Algunayah, Jorge Martin-P\\'erez, Luigi Girletti,\n  Rajasekar Mohan, K Venkat Ramnan, Boris Bellalta", "title": "Machine Learning for Performance Prediction of Channel Bonding in\n  Next-Generation IEEE 802.11 WLANs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advent of Artificial Intelligence (AI)-empowered communications,\nindustry, academia, and standardization organizations are progressing on the\ndefinition of mechanisms and procedures to address the increasing complexity of\nfuture 5G and beyond communications. In this context, the International\nTelecommunication Union (ITU) organized the first AI for 5G Challenge to bring\nindustry and academia together to introduce and solve representative problems\nrelated to the application of Machine Learning (ML) to networks. In this paper,\nwe present the results gathered from Problem Statement~13 (PS-013), organized\nby Universitat Pompeu Fabra (UPF), which primary goal was predicting the\nperformance of next-generation Wireless Local Area Networks (WLANs) applying\nChannel Bonding (CB) techniques. In particular, we overview the ML models\nproposed by participants (including Artificial Neural Networks, Graph Neural\nNetworks, Random Forest regression, and gradient boosting) and analyze their\nperformance on an open dataset generated using the IEEE 802.11ax-oriented\nKomondor network simulator. The accuracy achieved by the proposed methods\ndemonstrates the suitability of ML for predicting the performance of WLANs.\nMoreover, we discuss the importance of abstracting WLAN interactions to achieve\nbetter results, and we argue that there is certainly room for improvement in\nthroughput prediction through ML.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 05:33:07 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wilhelmi", "Francesc", ""], ["G\u00f3ez", "David", ""], ["Soto", "Paola", ""], ["Vall\u00e9s", "Ramon", ""], ["Alfaifi", "Mohammad", ""], ["Algunayah", "Abdulrahman", ""], ["Martin-P\u00e9rez", "Jorge", ""], ["Girletti", "Luigi", ""], ["Mohan", "Rajasekar", ""], ["Ramnan", "K Venkat", ""], ["Bellalta", "Boris", ""]]}, {"id": "2105.14220", "submitter": "Rifat Shahriyar", "authors": "Masum Hasan, Tanveer Muttaqueen, Abdullah Al Ishtiaq, Kazi Sajeed\n  Mehrab, Md. Mahim Anjum Haque, Tahmid Hasan, Wasi Uddin Ahmad, Anindya Iqbal,\n  Rifat Shahriyar", "title": "CoDesc: A Large Code-Description Parallel Dataset", "comments": "Findings of the Association for Computational Linguistics, ACL 2021\n  (camera-ready)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Translation between natural language and source code can help software\ndevelopment by enabling developers to comprehend, ideate, search, and write\ncomputer programs in natural language. Despite growing interest from the\nindustry and the research community, this task is often difficult due to the\nlack of large standard datasets suitable for training deep neural models,\nstandard noise removal methods, and evaluation benchmarks. This leaves\nresearchers to collect new small-scale datasets, resulting in inconsistencies\nacross published works. In this study, we present CoDesc -- a large parallel\ndataset composed of 4.2 million Java methods and natural language descriptions.\nWith extensive analysis, we identify and remove prevailing noise patterns from\nthe dataset. We demonstrate the proficiency of CoDesc in two complementary\ntasks for code-description pairs: code summarization and code search. We show\nthat the dataset helps improve code search by up to 22\\% and achieves the new\nstate-of-the-art in code summarization. Furthermore, we show CoDesc's\neffectiveness in pre-training--fine-tuning setup, opening possibilities in\nbuilding pretrained language models for Java. To facilitate future research, we\nrelease the dataset, a data processing tool, and a benchmark at\n\\url{https://github.com/csebuetnlp/CoDesc}.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 05:40:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Hasan", "Masum", ""], ["Muttaqueen", "Tanveer", ""], ["Ishtiaq", "Abdullah Al", ""], ["Mehrab", "Kazi Sajeed", ""], ["Haque", "Md. Mahim Anjum", ""], ["Hasan", "Tahmid", ""], ["Ahmad", "Wasi Uddin", ""], ["Iqbal", "Anindya", ""], ["Shahriyar", "Rifat", ""]]}, {"id": "2105.14224", "submitter": "Fan Hu", "authors": "Fan Hu, Lei Wang, Yishen Hu, Dongqi Wang, Weijie Wang, Jianbing Jiang,\n  Nan Li and Peng Yin", "title": "A Novel Framework Integrating AI Model and Enzymological Experiments\n  Promotes Identification of SARS-CoV-2 3CL Protease Inhibitors and\n  Activity-based Probe", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The identification of protein-ligand interaction plays a key role in\nbiochemical research and drug discovery. Although deep learning has recently\nshown great promise in discovering new drugs, there remains a gap between deep\nlearning-based and experimental approaches. Here we propose a novel framework,\nnamed AIMEE, integrating AI Model and Enzymology Experiments, to identify\ninhibitors against 3CL protease of SARS-CoV-2, which has taken a significant\ntoll on people across the globe. From a bioactive chemical library, we have\nconducted two rounds of experiments and identified six novel inhibitors with a\nhit rate of 29.41%, and four of them showed an IC50 value less than 3 {\\mu}M.\nMoreover, we explored the interpretability of the central model in AIMEE,\nmapping the deep learning extracted features to domain knowledge of chemical\nproperties. Based on this knowledge, a commercially available compound was\nselected and proven to be an activity-based probe of 3CLpro. This work\nhighlights the great potential of combining deep learning models and\nbiochemical experiments for intelligent iteration and expanding the boundaries\nof drug discovery.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 06:23:05 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Hu", "Fan", ""], ["Wang", "Lei", ""], ["Hu", "Yishen", ""], ["Wang", "Dongqi", ""], ["Wang", "Weijie", ""], ["Jiang", "Jianbing", ""], ["Li", "Nan", ""], ["Yin", "Peng", ""]]}, {"id": "2105.14239", "submitter": "Andrey Zhitnikov", "authors": "Ori Sztyglic, Andrey Zhitnikov, Vadim Indelman", "title": "Simplified Belief-Dependent Reward MCTS Planning with Guaranteed Tree\n  Consistency", "comments": "The first two authors contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Partially Observable Markov Decision Processes (POMDPs) are notoriously hard\nto solve. Most advanced state-of-the-art online solvers leverage ideas of Monte\nCarlo Tree Search (MCTS). These solvers rapidly converge to the most promising\nbranches of the belief tree, avoiding the suboptimal sections. Most of these\nalgorithms are designed to utilize straightforward access to the state reward\nand assume the belief-dependent reward is nothing but expectation over the\nstate reward. Thus, they are inapplicable to a more general and essential\nsetting of belief-dependent rewards. One example of such reward is differential\nentropy approximated using a set of weighted particles of the belief. Such an\ninformation-theoretic reward introduces a significant computational burden. In\nthis paper, we embed the paradigm of simplification into the MCTS algorithm. In\nparticular, we present Simplified Information-Theoretic Particle Filter Tree\n(SITH-PFT), a novel variant to the MCTS algorithm that considers\ninformation-theoretic rewards but avoids the need to calculate them completely.\nWe replace the costly calculation of information-theoretic rewards with\nadaptive upper and lower bounds. These bounds are easy to calculate and\ntightened only by the demand of our algorithm. Crucially, we guarantee\nprecisely the same belief tree and solution that would be obtained by MCTS,\nwhich explicitly calculates the original information-theoretic rewards. Our\napproach is general; namely, any converging to the reward bounds can be easily\nplugged-in to achieve substantial speedup without any loss in performance.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 07:25:11 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Sztyglic", "Ori", ""], ["Zhitnikov", "Andrey", ""], ["Indelman", "Vadim", ""]]}, {"id": "2105.14240", "submitter": "Qi Tian", "authors": "Qi Tian, Kun Kuang, Kelu Jiang, Fei Wu, Yisen Wang", "title": "Analysis and Applications of Class-wise Robustness in Adversarial\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Adversarial training is one of the most effective approaches to improve model\nrobustness against adversarial examples. However, previous works mainly focus\non the overall robustness of the model, and the in-depth analysis on the role\nof each class involved in adversarial training is still missing. In this paper,\nwe propose to analyze the class-wise robustness in adversarial training. First,\nwe provide a detailed diagnosis of adversarial training on six benchmark\ndatasets, i.e., MNIST, CIFAR-10, CIFAR-100, SVHN, STL-10 and ImageNet.\nSurprisingly, we find that there are remarkable robustness discrepancies among\nclasses, leading to unbalance/unfair class-wise robustness in the robust\nmodels. Furthermore, we keep investigating the relations between classes and\nfind that the unbalanced class-wise robustness is pretty consistent among\ndifferent attack and defense methods. Moreover, we observe that the stronger\nattack methods in adversarial learning achieve performance improvement mainly\nfrom a more successful attack on the vulnerable classes (i.e., classes with\nless robustness). Inspired by these interesting findings, we design a simple\nbut effective attack method based on the traditional PGD attack, named\nTemperature-PGD attack, which proposes to enlarge the robustness disparity\namong classes with a temperature factor on the confidence distribution of each\nimage. Experiments demonstrate our method can achieve a higher attack rate than\nthe PGD attack. Furthermore, from the defense perspective, we also make some\nmodifications in the training and inference phase to improve the robustness of\nthe most vulnerable class, so as to mitigate the large difference in class-wise\nrobustness. We believe our work can contribute to a more comprehensive\nunderstanding of adversarial training as well as rethinking the class-wise\nproperties in robust models.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 07:28:35 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 18:00:46 GMT"}, {"version": "v3", "created": "Tue, 22 Jun 2021 07:53:39 GMT"}, {"version": "v4", "created": "Wed, 23 Jun 2021 05:00:03 GMT"}, {"version": "v5", "created": "Tue, 29 Jun 2021 07:00:25 GMT"}], "update_date": "2021-06-30", "authors_parsed": [["Tian", "Qi", ""], ["Kuang", "Kun", ""], ["Jiang", "Kelu", ""], ["Wu", "Fei", ""], ["Wang", "Yisen", ""]]}, {"id": "2105.14255", "submitter": "Hengrong Lan", "authors": "Hengrong Lan, Juze Zhang, Changchun Yang, and Fei Gao", "title": "Compressed Sensing for Photoacoustic Computed Tomography Using an\n  Untrained Neural Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photoacoustic (PA) computed tomography (PACT) shows great potentials in\nvarious preclinical and clinical applications. A great number of measurements\nare the premise that obtains a high-quality image, which implies a low imaging\nrate or a high system cost. The artifacts or sidelobes could pollute the image\nif we decrease the number of measured channels or limit the detected view. In\nthis paper, a novel compressed sensing method for PACT using an untrained\nneural network is proposed, which decreases half number of the measured\nchannels and recoveries enough details. This method uses a neural network to\nreconstruct without the requirement for any additional learning based on the\ndeep image prior. The model can reconstruct the image only using a few\ndetections with gradient descent. Our method can cooperate with other existing\nregularization, and further improve the quality. In addition, we introduce a\nshape prior to easily converge the model to the image. We verify the\nfeasibility of untrained network based compressed sensing in PA image\nreconstruction, and compare this method with a conventional method using total\nvariation minimization. The experimental results show that our proposed method\noutperforms 32.72% (SSIM) with the traditional compressed sensing method in the\nsame regularization. It could dramatically reduce the requirement for the\nnumber of transducers, by sparsely sampling the raw PA data, and improve the\nquality of PA image significantly.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 09:01:58 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Lan", "Hengrong", ""], ["Zhang", "Juze", ""], ["Yang", "Changchun", ""], ["Gao", "Fei", ""]]}, {"id": "2105.14259", "submitter": "Mingfu Xue", "authors": "Mingfu Xue, Yinghao Wu, Zhiyu Wu, Yushu Zhang, Jian Wang, Weiqiang Liu", "title": "Detecting Backdoor in Deep Neural Networks via Intentional Adversarial\n  Perturbations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent researches show that deep learning model is susceptible to backdoor\nattacks. Many defenses against backdoor attacks have been proposed. However,\nexisting defense works require high computational overhead or backdoor attack\ninformation such as the trigger size, which is difficult to satisfy in\nrealistic scenarios. In this paper, a novel backdoor detection method based on\nadversarial examples is proposed. The proposed method leverages intentional\nadversarial perturbations to detect whether an image contains a trigger, which\ncan be applied in both the training stage and the inference stage (sanitize the\ntraining set in training stage and detect the backdoor instances in inference\nstage). Specifically, given an untrusted image, the adversarial perturbation is\nadded to the image intentionally. If the prediction of the model on the\nperturbed image is consistent with that on the unperturbed image, the input\nimage will be considered as a backdoor instance. Compared with most existing\ndefense works, the proposed adversarial perturbation based method requires low\ncomputational resources and maintains the visual quality of the images.\nExperimental results show that, the backdoor detection rate of the proposed\ndefense method is 99.63%, 99.76% and 99.91% on Fashion-MNIST, CIFAR-10 and\nGTSRB datasets, respectively. Besides, the proposed method maintains the visual\nquality of the image as the l2 norm of the added perturbation are as low as\n2.8715, 3.0513 and 2.4362 on Fashion-MNIST, CIFAR-10 and GTSRB datasets,\nrespectively. In addition, it is also demonstrated that the proposed method can\nachieve high defense performance against backdoor attacks under different\nattack settings (trigger transparency, trigger size and trigger pattern).\nCompared with the existing defense work (STRIP), the proposed method has better\ndetection performance on all the three datasets, and is more efficient than\nSTRIP.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 09:33:05 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 12:30:56 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Xue", "Mingfu", ""], ["Wu", "Yinghao", ""], ["Wu", "Zhiyu", ""], ["Zhang", "Yushu", ""], ["Wang", "Jian", ""], ["Liu", "Weiqiang", ""]]}, {"id": "2105.14276", "submitter": "Rossella Arcucci Dr", "authors": "Robin Hendrickx, Rossella Arcucci, Julio Amador D{\\i}az Lopez, Yi-Ke\n  Guo, and Mark Kennedy", "title": "Correcting public opinion trends through Bayesian data assimilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring public opinion is a key focus during democratic elections, enabling\ncandidates to gauge their popularity and alter their campaign strategies\naccordingly. Traditional survey polling remains the most popular estimation\ntechnique, despite its cost and time intensity, measurement errors, lack of\nreal-time capabilities and lagged representation of public opinion. In recent\nyears, Twitter opinion mining has attempted to combat these issues. Despite\nachieving promising results, it experiences its own set of shortcomings such as\nan unrepresentative sample population and a lack of long term stability. This\npaper aims to merge data from both these techniques using Bayesian data\nassimilation to arrive at a more accurate estimate of true public opinion for\nthe Brexit referendum. This paper demonstrates the effectiveness of the\nproposed approach using Twitter opinion data and survey data from trusted\npollsters. Firstly, the possible existence of a time gap of 16 days between the\ntwo data sets is identified. This gap is subsequently incorporated into a\nproposed assimilation architecture. This method was found to adequately\nincorporate information from both sources and measure a strong upward trend in\nLeave support leading up to the Brexit referendum. The proposed technique\nprovides useful estimates of true opinion, which is essential to future opinion\nmeasurement and forecasting research.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 11:39:56 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Hendrickx", "Robin", ""], ["Arcucci", "Rossella", ""], ["Lopez", "Julio Amador D\u0131az", ""], ["Guo", "Yi-Ke", ""], ["Kennedy", "Mark", ""]]}, {"id": "2105.14326", "submitter": "Shriya Gupta", "authors": "Shriya T.P. Gupta, Basabdatta Sen Bhattacharya", "title": "Implementing a foveal-pit inspired filter in a Spiking Convolutional\n  Neural Network: a preliminary study", "comments": "8 pages, 8 figures, 4 tables. 2020 International Joint Conference on\n  Neural Networks (IJCNN)", "journal-ref": null, "doi": "10.1109/IJCNN48605.2020.9207612", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We have presented a Spiking Convolutional Neural Network (SCNN) that\nincorporates retinal foveal-pit inspired Difference of Gaussian filters and\nrank-order encoding. The model is trained using a variant of the\nbackpropagation algorithm adapted to work with spiking neurons, as implemented\nin the Nengo library. We have evaluated the performance of our model on two\npublicly available datasets - one for digit recognition task, and the other for\nvehicle recognition task. The network has achieved up to 90% accuracy, where\nloss is calculated using the cross-entropy function. This is an improvement\nover around 57% accuracy obtained with the alternate approach of performing the\nclassification without any kind of neural filtering. Overall, our\nproof-of-concept study indicates that introducing biologically plausible\nfiltering in existing SCNN architecture will work well with noisy input images\nsuch as those in our vehicle recognition task. Based on our results, we plan to\nenhance our SCNN by integrating lateral inhibition-based redundancy reduction\nprior to rank-ordering, which will further improve the classification accuracy\nby the network.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 15:28:30 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Gupta", "Shriya T. P.", ""], ["Bhattacharya", "Basabdatta Sen", ""]]}, {"id": "2105.14329", "submitter": "Gerrit Gro{\\ss}mann", "authors": "Gerrit Gro{\\ss}mann, Julian Zimmerlin, Michael Backenk\\\"ohler, Verena\n  Wolf", "title": "GINA: Neural Relational Inference From Independent Snapshots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR cs.MA physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamical systems in which local interactions among agents give rise to\ncomplex emerging phenomena are ubiquitous in nature and society. This work\nexplores the problem of inferring the unknown interaction structure\n(represented as a graph) of such a system from measurements of its constituent\nagents or individual components (represented as nodes). We consider a setting\nwhere the underlying dynamical model is unknown and where different\nmeasurements (i.e., snapshots) may be independent (e.g., may stem from\ndifferent experiments). We propose GINA (Graph Inference Network Architecture),\na graph neural network (GNN) to simultaneously learn the latent interaction\ngraph and, conditioned on the interaction graph, the prediction of a node's\nobservable state based on adjacent vertices. GINA is based on the hypothesis\nthat the ground truth interaction graph -- among all other potential graphs --\nallows to predict the state of a node, given the states of its neighbors, with\nthe highest accuracy. We test this hypothesis and demonstrate GINA's\neffectiveness on a wide range of interaction graphs and dynamical processes.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 15:42:33 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Gro\u00dfmann", "Gerrit", ""], ["Zimmerlin", "Julian", ""], ["Backenk\u00f6hler", "Michael", ""], ["Wolf", "Verena", ""]]}, {"id": "2105.14331", "submitter": "Shriya Gupta", "authors": "Shriya T.P. Gupta, Pablo Linares-Serrano, Basabdatta Sen Bhattacharya,\n  Teresa Serrano-Gotarredona", "title": "Foveal-pit inspired filtering of DVS spike response", "comments": "6 pages, 4 figures, 2 tables. 2021 55th Annual Conference on\n  Information Sciences and Systems (CISS), 2021", "journal-ref": null, "doi": "10.1109/CISS50987.2021.9400245", "report-no": null, "categories": "cs.CV cs.AI cs.AR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present results of processing Dynamic Vision Sensor (DVS)\nrecordings of visual patterns with a retinal model based on foveal-pit inspired\nDifference of Gaussian (DoG) filters. A DVS sensor was stimulated with varying\nnumber of vertical white and black bars of different spatial frequencies moving\nhorizontally at a constant velocity. The output spikes generated by the DVS\nsensor were applied as input to a set of DoG filters inspired by the receptive\nfield structure of the primate visual pathway. In particular, these filters\nmimic the receptive fields of the midget and parasol ganglion cells (spiking\nneurons of the retina) that sub-serve the photo-receptors of the foveal-pit.\nThe features extracted with the foveal-pit model are used for further\nclassification using a spiking convolutional neural network trained with a\nbackpropagation variant adapted for spiking neural networks.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 16:01:39 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Gupta", "Shriya T. P.", ""], ["Linares-Serrano", "Pablo", ""], ["Bhattacharya", "Basabdatta Sen", ""], ["Serrano-Gotarredona", "Teresa", ""]]}, {"id": "2105.14347", "submitter": "Peratham Wiriyathammabhum Mr.", "authors": "Peratham Wiriyathammabhum", "title": "Is Sluice Resolution really just Question Answering?", "comments": "Extended Abstract at the The First Workshop on Understanding Implicit\n  and Underspecified Language @ ACL-2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Sluice resolution is a problem where a system needs to output the\ncorresponding antecedents of wh-ellipses. The antecedents are elided contents\nbehind the wh-words but are implicitly referred to using contexts. Previous\nwork frames sluice resolution as question answering where this setting\noutperforms all its preceding works by large margins. Ellipsis and questions\nare referentially dependent expressions (anaphoras) and retrieving the\ncorresponding antecedents are like answering questions to output pieces of\nclarifying information. However, the task is not fully solved. Therefore, we\nwant to further investigate what makes sluice resolution differ to question\nanswering and fill in the error gaps. We also present some results using recent\nstate-of-the-art question answering systems which improve the previous work\n(86.01 to 90.39 F1).\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 17:51:02 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wiriyathammabhum", "Peratham", ""]]}, {"id": "2105.14357", "submitter": "Kuntal Kumar Pal", "authors": "Kuntal Kumar Pal, Kazuaki Kashihara, Pratyay Banerjee, Swaroop Mishra,\n  Ruoyu Wang, Chitta Baral", "title": "Constructing Flow Graphs from Procedural Cybersecurity Texts", "comments": "13 pages, 5 pages, accepted in the Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Following procedural texts written in natural languages is challenging. We\nmust read the whole text to identify the relevant information or identify the\ninstruction flows to complete a task, which is prone to failures. If such texts\nare structured, we can readily visualize instruction-flows, reason or infer a\nparticular step, or even build automated systems to help novice agents achieve\na goal. However, this structure recovery task is a challenge because of such\ntexts' diverse nature. This paper proposes to identify relevant information\nfrom such texts and generate information flows between sentences. We built a\nlarge annotated procedural text dataset (CTFW) in the cybersecurity domain\n(3154 documents). This dataset contains valuable instructions regarding\nsoftware vulnerability analysis experiences. We performed extensive experiments\non CTFW with our LM-GNN model variants in multiple settings. To show the\ngeneralizability of both this task and our method, we also experimented with\nprocedural texts from two other domains (Maintenance Manual and Cooking), which\nare substantially different from cybersecurity. Our experiments show that Graph\nConvolution Network with BERT sentence embeddings outperforms BERT in all three\ndomains\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 19:06:35 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Pal", "Kuntal Kumar", ""], ["Kashihara", "Kazuaki", ""], ["Banerjee", "Pratyay", ""], ["Mishra", "Swaroop", ""], ["Wang", "Ruoyu", ""], ["Baral", "Chitta", ""]]}, {"id": "2105.14363", "submitter": "Niladri Chatterji", "authors": "Niladri S. Chatterji, Aldo Pacchiano, Peter L. Bartlett, Michael I.\n  Jordan", "title": "On the Theory of Reinforcement Learning with Once-per-Episode Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a theory of reinforcement learning (RL) in which the learner\nreceives binary feedback only once at the end of an episode. While this is an\nextreme test case for theory, it is also arguably more representative of\nreal-world applications than the traditional requirement in RL practice that\nthe learner receive feedback at every time step. Indeed, in many real-world\napplications of reinforcement learning, such as self-driving cars and robotics,\nit is easier to evaluate whether a learner's complete trajectory was either\n\"good\" or \"bad,\" but harder to provide a reward signal at each step. To show\nthat learning is possible in this more challenging setting, we study the case\nwhere trajectory labels are generated by an unknown parametric model, and\nprovide a statistically and computationally efficient algorithm that achieves\nsub-linear regret.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 19:48:51 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 05:16:09 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chatterji", "Niladri S.", ""], ["Pacchiano", "Aldo", ""], ["Bartlett", "Peter L.", ""], ["Jordan", "Michael I.", ""]]}, {"id": "2105.14371", "submitter": "Bahare Salmani", "authors": "Bahare Salmani and Joost-Pieter Katoen", "title": "Fine-Tuning the Odds in Bayesian Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper proposes various new analysis techniques for Bayes networks in\nwhich conditional probability tables (CPTs) may contain symbolic variables. The\nkey idea is to exploit scalable and powerful techniques for synthesis problems\nin parametric Markov chains. Our techniques are applicable to arbitrarily many,\npossibly dependent parameters that may occur in various CPTs. This lifts the\nsevere restrictions on parameters, e.g., by restricting the number of\nparametrized CPTs to one or two, or by avoiding parameter dependencies between\nseveral CPTs, in existing works for parametric Bayes networks (pBNs). We\ndescribe how our techniques can be used for various pBN synthesis problems\nstudied in the literature such as computing sensitivity functions (and values),\nsimple and difference parameter tuning, ratio parameter tuning, and minimal\nchange tuning. Experiments on several benchmarks show that our prototypical\ntool built on top of the probabilistic model checker Storm can handle several\nhundreds of parameters.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 20:41:56 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 11:27:00 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Salmani", "Bahare", ""], ["Katoen", "Joost-Pieter", ""]]}, {"id": "2105.14373", "submitter": "S\\'ergio Barreto Junior", "authors": "S\\'ergio Barreto, Ricardo Moura, Jonnathan Carvalho, Aline Paes,\n  Alexandre Plastino", "title": "Sentiment analysis in tweets: an assessment study from classical to\n  modern text representation models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  With the growth of social medias, such as Twitter, plenty of user-generated\ndata emerge daily. The short texts published on Twitter -- the tweets -- have\nearned significant attention as a rich source of information to guide many\ndecision-making processes. However, their inherent characteristics, such as the\ninformal, and noisy linguistic style, remain challenging to many natural\nlanguage processing (NLP) tasks, including sentiment analysis. Sentiment\nclassification is tackled mainly by machine learning-based classifiers. The\nliterature has adopted word representations from distinct natures to transform\ntweets to vector-based inputs to feed sentiment classifiers. The\nrepresentations come from simple count-based methods, such as bag-of-words, to\nmore sophisticated ones, such as BERTweet, built upon the trendy BERT\narchitecture. Nevertheless, most studies mainly focus on evaluating those\nmodels using only a small number of datasets. Despite the progress made in\nrecent years in language modelling, there is still a gap regarding a robust\nevaluation of induced embeddings applied to sentiment analysis on tweets.\nFurthermore, while fine-tuning the model from downstream tasks is prominent\nnowadays, less attention has been given to adjustments based on the specific\nlinguistic style of the data. In this context, this study fulfils an assessment\nof existing language models in distinguishing the sentiment expressed in tweets\nby using a rich collection of 22 datasets from distinct domains and five\nclassification algorithms. The evaluation includes static and contextualized\nrepresentations. Contexts are assembled from Transformer-based autoencoder\nmodels that are also fine-tuned based on the masked language model task, using\na plethora of strategies.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 21:05:28 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Barreto", "S\u00e9rgio", ""], ["Moura", "Ricardo", ""], ["Carvalho", "Jonnathan", ""], ["Paes", "Aline", ""], ["Plastino", "Alexandre", ""]]}, {"id": "2105.14398", "submitter": "Fangyu Liu", "authors": "Fangyu Liu, Ivan Vuli\\'c, Anna Korhonen, Nigel Collier", "title": "Learning Domain-Specialised Representations for Cross-Lingual Biomedical\n  Entity Linking", "comments": "ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Injecting external domain-specific knowledge (e.g., UMLS) into pretrained\nlanguage models (LMs) advances their capability to handle specialised in-domain\ntasks such as biomedical entity linking (BEL). However, such abundant expert\nknowledge is available only for a handful of languages (e.g., English). In this\nwork, by proposing a novel cross-lingual biomedical entity linking task\n(XL-BEL) and establishing a new XL-BEL benchmark spanning 10 typologically\ndiverse languages, we first investigate the ability of standard\nknowledge-agnostic as well as knowledge-enhanced monolingual and multilingual\nLMs beyond the standard monolingual English BEL task. The scores indicate large\ngaps to English performance. We then address the challenge of transferring\ndomain-specific knowledge in resource-rich languages to resource-poor ones. To\nthis end, we propose and evaluate a series of cross-lingual transfer methods\nfor the XL-BEL task, and demonstrate that general-domain bitext helps propagate\nthe available English knowledge to languages with little to no in-domain data.\nRemarkably, we show that our proposed domain-specific transfer methods yield\nconsistent gains across all target languages, sometimes up to 20 Precision@1\npoints, without any in-domain knowledge in the target language, and without any\nin-domain parallel data.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 00:50:00 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Liu", "Fangyu", ""], ["Vuli\u0107", "Ivan", ""], ["Korhonen", "Anna", ""], ["Collier", "Nigel", ""]]}, {"id": "2105.14399", "submitter": "David Mac\\^edo", "authors": "David Mac\\^edo, Teresa Ludermir", "title": "Improving Entropic Out-of-Distribution Detection using Isometric\n  Distances and the Minimum Distance Score", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current out-of-distribution detection approaches usually present special\nrequirements (e.g., collecting outlier data and hyperparameter validation) and\nproduce side effects (classification accuracy drop and slow/inefficient\ninferences). Recently, entropic out-of-distribution detection has been proposed\nas a seamless approach (i.e., a solution that avoids all the previously\nmentioned drawbacks). The entropic out-of-distribution detection solution\ncomprises the IsoMax loss for training and the entropic score for\nout-of-distribution detection. The IsoMax loss works as a SoftMax loss drop-in\nreplacement because swapping the SoftMax loss with the IsoMax loss requires no\nchanges in the model's architecture or training procedures/hyperparameters. In\nthis paper, we propose to perform what we call an isometrization of the\ndistances used in the IsoMax loss. Additionally, we propose to replace the\nentropic score with the minimum distance score. Our experiments showed that\nthese simple modifications increase out-of-distribution detection performance\nwhile keeping the solution seamless. Code available at\n$\\href{https://github.com/dlmacedo/entropic-out-of-distribution-detection}{\\text{entropic\nout-of-distribution detection}}$.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 00:55:03 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 15:18:07 GMT"}, {"version": "v3", "created": "Sun, 18 Jul 2021 04:02:03 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Mac\u00eado", "David", ""], ["Ludermir", "Teresa", ""]]}, {"id": "2105.14422", "submitter": "Hengrui Cai", "authors": "Hengrui Cai, Zhihao Cen, Ling Leng, Rui Song", "title": "Periodic-GP: Learning Periodic World with Gaussian Process Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the sequential decision optimization on the periodic environment,\nthat occurs in a wide variety of real-world applications when the data involves\nseasonality, such as the daily demand of drivers in ride-sharing and dynamic\ntraffic patterns in transportation. In this work, we focus on learning the\nstochastic periodic world by leveraging this seasonal law. To deal with the\ngeneral action space, we use the bandit based on Gaussian process (GP) as the\nbase model due to its flexibility and generality, and propose the Periodic-GP\nmethod with a temporal periodic kernel based on the upper confidence bound.\nTheoretically, we provide a new regret bound of the proposed method, by\nexplicitly characterizing the periodic kernel in the periodic stationary model.\nEmpirically, the proposed algorithm significantly outperforms the existing\nmethods in both synthetic data experiments and a real data application on\nMadrid traffic pollution.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 03:40:16 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 20:14:01 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 03:09:01 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Cai", "Hengrui", ""], ["Cen", "Zhihao", ""], ["Leng", "Ling", ""], ["Song", "Rui", ""]]}, {"id": "2105.14426", "submitter": "Pratik Kayal", "authors": "Pratik Kayal, Mrinal Anand, Harsh Desai, Mayank Singh", "title": "ICDAR 2021 Competition on Scientific Table Image Recognition to LaTeX", "comments": "This submission has been removed by arXiv administrators because the\n  submitter did not have the right to grant the license at the time of\n  submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tables present important information concisely in many scientific documents.\nVisual features like mathematical symbols, equations, and spanning cells make\nstructure and content extraction from tables embedded in research documents\ndifficult. This paper discusses the dataset, tasks, participants' methods, and\nresults of the ICDAR 2021 Competition on Scientific Table Image Recognition to\nLaTeX. Specifically, the task of the competition is to convert a tabular image\nto its corresponding LaTeX source code. We proposed two subtasks. In Subtask 1,\nwe ask the participants to reconstruct the LaTeX structure code from an image.\nIn Subtask 2, we ask the participants to reconstruct the LaTeX content code\nfrom an image. This report describes the datasets and ground truth\nspecification, details the performance evaluation metrics used, presents the\nfinal results, and summarizes the participating methods. Submission by team\nVCGroup got the highest Exact Match accuracy score of 74% for Subtask 1 and 55%\nfor Subtask 2, beating previous baselines by 5% and 12%, respectively. Although\nimprovements can still be made to the recognition capabilities of models, this\ncompetition contributes to the development of fully automated table recognition\nsystems by challenging practitioners to solve problems under specific\nconstraints and sharing their approaches; the platform will remain available\nfor post-challenge submissions at\nhttps://competitions.codalab.org/competitions/26979 .\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 04:17:55 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kayal", "Pratik", ""], ["Anand", "Mrinal", ""], ["Desai", "Harsh", ""], ["Singh", "Mayank", ""]]}, {"id": "2105.14444", "submitter": "Jin Xu", "authors": "Jin Xu, Xu Tan, Renqian Luo, Kaitao Song, Jian Li, Tao Qin, Tie-Yan\n  Liu", "title": "NAS-BERT: Task-Agnostic and Adaptive-Size BERT Compression with Neural\n  Architecture Search", "comments": "Accepted by KDD 2021", "journal-ref": null, "doi": "10.1145/3447548.3467262", "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While pre-trained language models (e.g., BERT) have achieved impressive\nresults on different natural language processing tasks, they have large numbers\nof parameters and suffer from big computational and memory costs, which make\nthem difficult for real-world deployment. Therefore, model compression is\nnecessary to reduce the computation and memory cost of pre-trained models. In\nthis work, we aim to compress BERT and address the following two challenging\npractical issues: (1) The compression algorithm should be able to output\nmultiple compressed models with different sizes and latencies, in order to\nsupport devices with different memory and latency limitations; (2) The\nalgorithm should be downstream task agnostic, so that the compressed models are\ngenerally applicable for different downstream tasks. We leverage techniques in\nneural architecture search (NAS) and propose NAS-BERT, an efficient method for\nBERT compression. NAS-BERT trains a big supernet on a search space containing a\nvariety of architectures and outputs multiple compressed models with adaptive\nsizes and latency. Furthermore, the training of NAS-BERT is conducted on\nstandard self-supervised pre-training tasks (e.g., masked language model) and\ndoes not depend on specific downstream tasks. Thus, the compressed models can\nbe used across various downstream tasks. The technical challenge of NAS-BERT is\nthat training a big supernet on the pre-training task is extremely costly. We\nemploy several techniques including block-wise search, search space pruning,\nand performance approximation to improve search efficiency and accuracy.\nExtensive experiments on GLUE and SQuAD benchmark datasets demonstrate that\nNAS-BERT can find lightweight models with better accuracy than previous\napproaches, and can be directly applied to different downstream tasks with\nadaptive model sizes for different requirements of memory or latency.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 07:20:27 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Xu", "Jin", ""], ["Tan", "Xu", ""], ["Luo", "Renqian", ""], ["Song", "Kaitao", ""], ["Li", "Jian", ""], ["Qin", "Tao", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "2105.14452", "submitter": "Xinghan Liu", "authors": "Xinghan Liu and Emiliano Lorini", "title": "A logic for binary classifiers and their explanation", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed a renewed interest in Boolean function in\nexplaining binary classifiers in the field of explainable AI (XAI). The\nstandard approach of Boolean function is propositional logic. We present a\nmodal language of a ceteris paribus nature which supports reasoning about\nbinary classifiers and their properties. We study families of decision models\nfor binary classifiers, axiomatize them and show completeness of our\naxiomatics. Moreover, we prove that the variant of our modal language with\nfinite propositional atoms interpreted over these models is NP-complete. We\nleverage the language to formalize counterfactual conditional as well as a\nbunch of notions of explanation such as abductive, contrastive and\ncounterfactual explanations, and biases. Finally, we present two extensions of\nour language: a dynamic extension by the notion of assignment enabling\nclassifier change and an epistemic extension in which the classifier's\nuncertainty about the actual input can be represented.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 07:49:56 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Liu", "Xinghan", ""], ["Lorini", "Emiliano", ""]]}, {"id": "2105.14462", "submitter": "Zhiyong Wu", "authors": "Zhiyong Wu, Lingpeng Kong, Wei Bi, Xiang Li, Ben Kao", "title": "Good for Misconceived Reasons: An Empirical Revisiting on the Need for\n  Visual Context in Multimodal Machine Translation", "comments": "To appear at ACL 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A neural multimodal machine translation (MMT) system is one that aims to\nperform better translation by extending conventional text-only translation\nmodels with multimodal information. Many recent studies report improvements\nwhen equipping their models with the multimodal module, despite the controversy\nof whether such improvements indeed come from the multimodal part. We revisit\nthe contribution of multimodal information in MMT by devising two interpretable\nMMT models. To our surprise, although our models replicate similar gains as\nrecently developed multimodal-integrated systems achieved, our models learn to\nignore the multimodal information. Upon further investigation, we discover that\nthe improvements achieved by the multimodal models over text-only counterparts\nare in fact results of the regularization effect. We report empirical findings\nthat highlight the importance of MMT models' interpretability, and discuss how\nour findings will benefit future research.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 08:27:16 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wu", "Zhiyong", ""], ["Kong", "Lingpeng", ""], ["Bi", "Wei", ""], ["Li", "Xiang", ""], ["Kao", "Ben", ""]]}, {"id": "2105.14463", "submitter": "Batya Kenig", "authors": "Batya Kenig", "title": "Approximate Implication with d-Separation", "comments": "Accepted for the 37th conference on Uncertainty in Artificial\n  Intelligence (UAI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IT math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The graphical structure of Probabilistic Graphical Models (PGMs) encodes the\nconditional independence (CI) relations that hold in the modeled distribution.\nGraph algorithms, such as d-separation, use this structure to infer additional\nconditional independencies, and to query whether a specific CI holds in the\ndistribution. The premise of all current systems-of-inference for deriving CIs\nin PGMs, is that the set of CIs used for the construction of the PGM hold\nexactly. In practice, algorithms for extracting the structure of PGMs from\ndata, discover approximate CIs that do not hold exactly in the distribution. In\nthis paper, we ask how the error in this set propagates to the inferred CIs\nread off the graphical structure. More precisely, what guarantee can we provide\non the inferred CI when the set of CIs that entailed it hold only\napproximately? It has recently been shown that in the general case, no such\nguarantee can be provided. We prove that such a guarantee exists for the set of\nCIs inferred in directed graphical models, making the d-separation algorithm a\nsound and complete system for inferring approximate CIs. We also prove an\napproximation guarantee for independence relations derived from marginal CIs.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 08:30:14 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kenig", "Batya", ""]]}, {"id": "2105.14471", "submitter": "Chin-Jui Chang", "authors": "Chin-Jui Chang, Yu-Wei Chu, Chao-Hsien Ting, Hao-Kang Liu, Zhang-Wei\n  Hong, Chun-Yi Lee", "title": "Reducing the Deployment-Time Inference Control Costs of Deep\n  Reinforcement Learning Agents via an Asymmetric Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep reinforcement learning (DRL) has been demonstrated to provide promising\nresults in several challenging decision making and control tasks. However, the\nrequired inference costs of deep neural networks (DNNs) could prevent DRL from\nbeing applied to mobile robots which cannot afford high energy-consuming\ncomputations. To enable DRL methods to be affordable in such energy-limited\nplatforms, we propose an asymmetric architecture that reduces the overall\ninference costs via switching between a computationally expensive policy and an\neconomic one. The experimental results evaluated on a number of representative\nbenchmark suites for robotic control tasks demonstrate that our method is able\nto reduce the inference costs while retaining the agent's overall performance.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 09:14:39 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chang", "Chin-Jui", ""], ["Chu", "Yu-Wei", ""], ["Ting", "Chao-Hsien", ""], ["Liu", "Hao-Kang", ""], ["Hong", "Zhang-Wei", ""], ["Lee", "Chun-Yi", ""]]}, {"id": "2105.14478", "submitter": "Yian Li", "authors": "Yian Li, Hai Zhao", "title": "Pre-training Universal Language Representation", "comments": "Accepted by ACL-IJCNLP 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the well-developed cut-edge representation learning for language,\nmost language representation models usually focus on specific levels of\nlinguistic units. This work introduces universal language representation\nlearning, i.e., embeddings of different levels of linguistic units or text with\nquite diverse lengths in a uniform vector space. We propose the training\nobjective MiSAD that utilizes meaningful n-grams extracted from large unlabeled\ncorpus by a simple but effective algorithm for pre-trained language models.\nThen we empirically verify that well designed pre-training scheme may\neffectively yield universal language representation, which will bring great\nconvenience when handling multiple layers of linguistic objects in a unified\nway. Especially, our model achieves the highest accuracy on analogy tasks in\ndifferent language levels and significantly improves the performance on\ndownstream tasks in the GLUE benchmark and a question answering dataset.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 09:29:01 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Li", "Yian", ""], ["Zhao", "Hai", ""]]}, {"id": "2105.14500", "submitter": "Boxiang Wang", "authors": "Boxiang Wang, Qifan Xu, Zhengda Bian, Yang You", "title": "2.5-dimensional distributed model training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data parallelism does a good job in speeding up the training. However, when\nit comes to the case when the memory of a single device can not host a whole\nmodel, data parallelism would not have the chance to do anything. Another\noption is to split the model by operator, or horizontally. Megatron-LM\nintroduced a 1-Dimensional distributed method to use GPUs to speed up the\ntraining process. Optimus is a 2D solution for distributed tensor parallelism.\nHowever, these methods have a high communication overhead and a low scaling\nefficiency on large-scale computing clusters. To solve this problem, we\ninvestigate the 2.5-Dimensional distributed tensor parallelism.Introduced by\nSolomonik et al., 2.5-Dimensional Matrix Multiplication developed an effective\nmethod to perform multiple Cannon's algorithm at the same time to increase the\nefficiency. With many restrictions of Cannon's Algorithm and a huge amount of\nshift operation, we need to invent a new method of 2.5-dimensional matrix\nmultiplication to enhance the performance. Absorbing the essence from both\nSUMMA and 2.5-Dimensional Matrix Multiplication, we introduced SUMMA2.5-LM for\nlanguage models to overcome the abundance of unnecessary transmission loss\nresult from the increasing size of language model parallelism. Compared to\nprevious 1D and 2D model parallelization of language models, our SUMMA2.5-LM\nmanaged to reduce the transmission cost on each layer, which could get a 1.45X\nefficiency according to our weak scaling result between 2.5-D [4,4,4]\narrangement and 2-D [8,8,1] arrangement.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 11:06:49 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Boxiang", ""], ["Xu", "Qifan", ""], ["Bian", "Zhengda", ""], ["You", "Yang", ""]]}, {"id": "2105.14506", "submitter": "Jivitesh Sharma", "authors": "Jivitesh Sharma, Rohan Yadav, Ole-Christoffer Granmo and Lei Jiao", "title": "Human Interpretable AI: Enhancing Tsetlin Machine Stochasticity with\n  Drop Clause", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this article, we introduce a novel variant of the Tsetlin machine (TM)\nthat randomly drops clauses, the key learning elements of a TM. In effect, TM\nwith drop clause ignores a random selection of the clauses in each epoch,\nselected according to a predefined probability. In this way, additional\nstochasticity is introduced in the learning phase of TM. Along with producing\nmore distinct and well-structured patterns that improve the performance, we\nalso show that dropping clauses increases learning robustness. To explore the\neffects clause dropping has on accuracy, training time, and interpretability,\nwe conduct extensive experiments on various benchmark datasets in natural\nlanguage processing (NLP) (IMDb and SST2) as well as computer vision (MNIST and\nCIFAR10). In brief, we observe from +2% to +4% increase in accuracy and 2x to\n4x faster learning. We further employ the Convolutional TM to document\ninterpretable results on the CIFAR10 dataset. To the best of our knowledge,\nthis is the first time an interpretable machine learning algorithm has been\nused to produce pixel-level human-interpretable results on CIFAR10. Also,\nunlike previous interpretable methods that focus on attention visualisation or\ngradient interpretability, we show that the TM is a more general interpretable\nmethod. That is, by producing rule-based propositional logic expressions that\nare \\emph{human}-interpretable, the TM can explain how it classifies a\nparticular instance at the pixel level for computer vision and at the word\nlevel for NLP.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 11:29:49 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Sharma", "Jivitesh", ""], ["Yadav", "Rohan", ""], ["Granmo", "Ole-Christoffer", ""], ["Jiao", "Lei", ""]]}, {"id": "2105.14517", "submitter": "Jiaqi Chen", "authors": "Jiaqi Chen, Jianheng Tang, Jinghui Qin, Xiaodan Liang, Lingbo Liu,\n  Eric P. Xing, Liang Lin", "title": "GeoQA: A Geometric Question Answering Benchmark Towards Multimodal\n  Numerical Reasoning", "comments": "Accepted to Findings of ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic math problem solving has recently attracted increasing attention as\na long-standing AI benchmark. In this paper, we focus on solving geometric\nproblems, which requires a comprehensive understanding of textual descriptions,\nvisual diagrams, and theorem knowledge. However, the existing methods were\nhighly dependent on handcraft rules and were merely evaluated on small-scale\ndatasets. Therefore, we propose a Geometric Question Answering dataset GeoQA,\ncontaining 5,010 geometric problems with corresponding annotated programs,\nwhich illustrate the solving process of the given problems. Compared with\nanother publicly available dataset GeoS, GeoQA is 25 times larger, in which the\nprogram annotations can provide a practical testbed for future research on\nexplicit and explainable numerical reasoning. Moreover, we introduce a Neural\nGeometric Solver (NGS) to address geometric problems by comprehensively parsing\nmultimodal information and generating interpretable programs. We further add\nmultiple self-supervised auxiliary tasks on NGS to enhance cross-modal semantic\nrepresentation. Extensive experiments on GeoQA validate the effectiveness of\nour proposed NGS and auxiliary tasks. However, the results are still\nsignificantly lower than human performance, which leaves large room for future\nresearch. Our benchmark and code are released at\nhttps://github.com/chen-judge/GeoQA .\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 12:34:17 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 02:53:03 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Chen", "Jiaqi", ""], ["Tang", "Jianheng", ""], ["Qin", "Jinghui", ""], ["Liang", "Xiaodan", ""], ["Liu", "Lingbo", ""], ["Xing", "Eric P.", ""], ["Lin", "Liang", ""]]}, {"id": "2105.14538", "submitter": "Jia-Hong Huang", "authors": "Jia-Hong Huang, Ting-Wei Wu, Chao-Han Huck Yang, Marcel Worring", "title": "Longer Version for \"Deep Context-Encoding Network for Retinal Image\n  Captioning\"", "comments": "This paper is a longer version of \"Deep Context-Encoding Network for\n  Retinal Image Captioning\" which is accepted by IEEE International Conference\n  on Image Processing (ICIP), 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatically generating medical reports for retinal images is one of the\npromising ways to help ophthalmologists reduce their workload and improve work\nefficiency. In this work, we propose a new context-driven encoding network to\nautomatically generate medical reports for retinal images. The proposed model\nis mainly composed of a multi-modal input encoder and a fused-feature decoder.\nOur experimental results show that our proposed method is capable of\neffectively leveraging the interactive information between the input image and\ncontext, i.e., keywords in our case. The proposed method creates more accurate\nand meaningful reports for retinal images than baseline models and achieves\nstate-of-the-art performance. This performance is shown in several commonly\nused metrics for the medical report generation task: BLEU-avg (+16%), CIDEr\n(+10.2%), and ROUGE (+8.6%).\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 13:37:03 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Huang", "Jia-Hong", ""], ["Wu", "Ting-Wei", ""], ["Yang", "Chao-Han Huck", ""], ["Worring", "Marcel", ""]]}, {"id": "2105.14556", "submitter": "Yinhe Zheng Dr.", "authors": "Yida Wang, Yinhe Zheng, Yong Jiang, Minlie Huang", "title": "Diversifying Dialog Generation via Adaptive Label Smoothing", "comments": "ACL2021 Main Track (Long Paper), Code Available in\n  https://github.com/lemon234071/AdaLabel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural dialogue generation models trained with the one-hot target\ndistribution suffer from the over-confidence issue, which leads to poor\ngeneration diversity as widely reported in the literature. Although existing\napproaches such as label smoothing can alleviate this issue, they fail to adapt\nto diverse dialog contexts. In this paper, we propose an Adaptive Label\nSmoothing (AdaLabel) approach that can adaptively estimate a target label\ndistribution at each time step for different contexts. The maximum probability\nin the predicted distribution is used to modify the soft target distribution\nproduced by a novel light-weight bi-directional decoder module. The resulting\ntarget distribution is aware of both previous and future contexts and is\nadjusted to avoid over-training the dialogue model. Our model can be trained in\nan end-to-end manner. Extensive experiments on two benchmark datasets show that\nour approach outperforms various competitive baselines in producing diverse\nresponses.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 14:41:09 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Yida", ""], ["Zheng", "Yinhe", ""], ["Jiang", "Yong", ""], ["Huang", "Minlie", ""]]}, {"id": "2105.14557", "submitter": "Chengbin Hou", "authors": "Chengbin Hou, Guoji Fu, Peng Yang, Shan He, Ke Tang", "title": "Robust Dynamic Network Embedding via Ensembles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic Network Embedding (DNE) has recently attracted considerable attention\ndue to the advantage of network embedding in various applications and the\ndynamic nature of many real-world networks. For dynamic networks, the degree of\nchanges, i.e., defined as the averaged number of changed edges between\nconsecutive snapshots spanning a dynamic network, could be very different in\nreal-world scenarios. Although quite a few DNE methods have been proposed, it\nstill remains unclear that whether and to what extent the existing DNE methods\nare robust to the degree of changes, which is however an important factor in\nboth academic research and industrial applications. In this work, we\ninvestigate the robustness issue of DNE methods w.r.t. the degree of changes\nfor the first time and accordingly, propose a robust DNE method. Specifically,\nthe proposed method follows the notion of ensembles where the base learner\nadopts an incremental Skip-Gram neural embedding approach. To further boost the\nperformance, a novel strategy is proposed to enhance the diversity among base\nlearners at each timestep by capturing different levels of local-global\ntopology. Extensive experiments demonstrate the benefits of special designs in\nthe proposed method, and the superior performance of the proposed method\ncompared to state-of-the-art methods. The comparative study also reveals the\nrobustness issue of some DNE methods. The source code is available at\nhttps://github.com/houchengbin/SG-EDNE\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 14:44:26 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Hou", "Chengbin", ""], ["Fu", "Guoji", ""], ["Yang", "Peng", ""], ["He", "Shan", ""], ["Tang", "Ke", ""]]}, {"id": "2105.14564", "submitter": "Danish Sattar", "authors": "Ramy Maarouf, Danish Sattar, and Ashraf Matrawy", "title": "Evaluating Resilience of Encrypted Traffic Classification Against\n  Adversarial Evasion Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning and deep learning algorithms can be used to classify\nencrypted Internet traffic. Classification of encrypted traffic can become more\nchallenging in the presence of adversarial attacks that target the learning\nalgorithms. In this paper, we focus on investigating the effectiveness of\ndifferent evasion attacks and see how resilient machine and deep learning\nalgorithms are. Namely, we test C4.5 Decision Tree, K-Nearest Neighbor (KNN),\nArtificial Neural Network (ANN), Convolutional Neural Networks (CNN) and\nRecurrent Neural Networks (RNN). In most of our experimental results, deep\nlearning shows better resilience against the adversarial samples in comparison\nto machine learning. Whereas, the impact of the attack varies depending on the\ntype of attack.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 15:07:12 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Maarouf", "Ramy", ""], ["Sattar", "Danish", ""], ["Matrawy", "Ashraf", ""]]}, {"id": "2105.14568", "submitter": "Ronald Pereira", "authors": "Ronald D. R. Pereira and Fabr\\'icio Murai", "title": "How effective are Graph Neural Networks in Fraud Detection for Network\n  Data?", "comments": "12 pages, in Portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph-based Neural Networks (GNNs) are recent models created for learning\nrepresentations of nodes (and graphs), which have achieved promising results\nwhen detecting patterns that occur in large-scale data relating different\nentities. Among these patterns, financial fraud stands out for its\nsocioeconomic relevance and for presenting particular challenges, such as the\nextreme imbalance between the positive (fraud) and negative (legitimate\ntransactions) classes, and the concept drift (i.e., statistical properties of\nthe data change over time). Since GNNs are based on message propagation, the\nrepresentation of a node is strongly impacted by its neighbors and by the\nnetwork's hubs, amplifying the imbalance effects. Recent works attempt to adapt\nundersampling and oversampling strategies for GNNs in order to mitigate this\neffect without, however, accounting for concept drift. In this work, we conduct\nexperiments to evaluate existing techniques for detecting network fraud,\nconsidering the two previous challenges. For this, we use real data sets,\ncomplemented by synthetic data created from a new methodology introduced here.\nBased on this analysis, we propose a series of improvement points that should\nbe investigated in future research.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 15:17:13 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Pereira", "Ronald D. R.", ""], ["Murai", "Fabr\u00edcio", ""]]}, {"id": "2105.14584", "submitter": "Gunhee Nam", "authors": "Gunhee Nam, Miran Heo, Seoung Wug Oh, Joon-Young Lee, Seon Joo Kim", "title": "Polygonal Point Set Tracking", "comments": "14 pages, 10 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a novel learning-based polygonal point set tracking\nmethod. Compared to existing video object segmentation~(VOS) methods that\npropagate pixel-wise object mask information, we propagate a polygonal point\nset over frames.\n  Specifically, the set is defined as a subset of points in the target contour,\nand our goal is to track corresponding points on the target contour. Those\noutputs enable us to apply various visual effects such as motion tracking, part\ndeformation, and texture mapping. To this end, we propose a new method to track\nthe corresponding points between frames by the global-local alignment with\ndelicately designed losses and regularization terms. We also introduce a novel\nlearning strategy using synthetic and VOS datasets that makes it possible to\ntackle the problem without developing the point correspondence dataset. Since\nthe existing datasets are not suitable to validate our method, we build a new\npolygonal point set tracking dataset and demonstrate the superior performance\nof our method over the baselines and existing contour-based VOS methods. In\naddition, we present visual-effects applications of our method on part\ndistortion and text mapping.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 17:12:36 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Nam", "Gunhee", ""], ["Heo", "Miran", ""], ["Oh", "Seoung Wug", ""], ["Lee", "Joon-Young", ""], ["Kim", "Seon Joo", ""]]}, {"id": "2105.14607", "submitter": "Adnan Akhunzada", "authors": "Adnan Akhunzada (Senior Member, IEEE), Sherali Zeadally (Senior\n  Member, IEEE), Saif ul Islam", "title": "Power and Performance Efficient SDN-Enabled Fog Architecture", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Software Defined Networks (SDNs) have dramatically simplified network\nmanagement. However, enabling pure SDNs to respond in real-time while handling\nmassive amounts of data still remains a challenging task. In contrast, fog\ncomputing has strong potential to serve large surges of data in real-time. SDN\ncontrol plane enables innovation, and greatly simplifies network operations and\nmanagement thereby providing a promising solution to implement energy and\nperformance aware SDN-enabled fog computing. Besides, power efficiency and\nperformance evaluation in SDN-enabled fog computing is an area that has not yet\nbeen fully explored by the research community. We present a novel SDN-enabled\nfog architecture to improve power efficacy and performance by leveraging\ncooperative and non-cooperative policy-based computing. Preliminary results\nfrom extensive simulation demonstrate an improvement in the power utilization\nas well as the overall performance (i.e., processing time, response time).\nFinally, we discuss several open research issues that need further\ninvestigation in the future.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 19:28:52 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Akhunzada", "Adnan", "", "Senior Member, IEEE"], ["Zeadally", "Sherali", "", "Senior\n  Member, IEEE"], ["Islam", "Saif ul", ""]]}, {"id": "2105.14677", "submitter": "Biswadeep Chakraborty", "authors": "Biswadeep Chakraborty, Saibal Mukhopadhyay", "title": "Characterization of Generalizability of Spike Time Dependent Plasticity\n  trained Spiking Neural Networks", "comments": "15 pages, submitted to Frontiers in Neuroscience. arXiv admin note:\n  text overlap with arXiv:2010.08195, arXiv:2006.09313 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A Spiking Neural Network (SNN) trained with Spike Time Dependent Plasticity\n(STDP) is a neuro-inspired unsupervised learning method for various machine\nlearning applications. This paper studies the generalizability properties of\nthe STDP learning processes using the Hausdorff dimension of the trajectories\nof the learning algorithm. The paper analyzes the effects of STDP learning\nmodels and associated hyper-parameters on the generalizability properties of an\nSNN and characterizes the generalizability vs learnability trade-off in an SNN.\nThe analysis is used to develop a Bayesian optimization approach to optimize\nthe hyper-parameters for an STDP model to improve the generalizability\nproperties of an SNN.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 02:19:06 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chakraborty", "Biswadeep", ""], ["Mukhopadhyay", "Saibal", ""]]}, {"id": "2105.14682", "submitter": "Liangming Pan", "authors": "Liangming Pan, Wenhu Chen, Wenhan Xiong, Min-Yen Kan, William Yang\n  Wang", "title": "Zero-shot Fact Verification by Claim Generation", "comments": "ACL-IJCNLP 2021 (main conference, short paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Neural models for automated fact verification have achieved promising results\nthanks to the availability of large, human-annotated datasets. However, for\neach new domain that requires fact verification, creating a dataset by manually\nwriting claims and linking them to their supporting evidence is expensive. We\ndevelop QACG, a framework for training a robust fact verification model by\nusing automatically generated claims that can be supported, refuted, or\nunverifiable from evidence from Wikipedia. QACG generates question-answer pairs\nfrom the evidence and then converts them into different types of claims.\nExperiments on the FEVER dataset show that our QACG framework significantly\nreduces the demand for human-annotated training data. In a zero-shot scenario,\nQACG improves a RoBERTa model's F1 from 50% to 77%, equivalent in performance\nto 2K+ manually-curated examples. Our QACG code is publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 03:13:52 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Pan", "Liangming", ""], ["Chen", "Wenhu", ""], ["Xiong", "Wenhan", ""], ["Kan", "Min-Yen", ""], ["Wang", "William Yang", ""]]}, {"id": "2105.14706", "submitter": "Zsolt Zombori", "authors": "Zsolt Zombori, Josef Urban, Miroslav Ol\\v{s}\\'ak", "title": "The Role of Entropy in Guiding a Connection Prover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study how to learn good algorithms for selecting reasoning\nsteps in theorem proving. We explore this in the connection tableau calculus\nimplemented by leanCoP where the partial tableau provides a clean and compact\nnotion of a state to which a limited number of inferences can be applied. We\nstart by incorporating a state-of-the-art learning algorithm -- a graph neural\nnetwork (GNN) -- into the plCoP theorem prover. Then we use it to observe the\nsystem's behaviour in a reinforcement learning setting, i.e., when learning\ninference guidance from successful Monte-Carlo tree searches on many problems.\nDespite its better pattern matching capability, the GNN initially performs\nworse than a simpler previously used learning algorithm. We observe that the\nsimpler algorithm is less confident, i.e., its recommendations have higher\nentropy. This leads us to explore how the entropy of the inference selection\nimplemented via the neural network influences the proof search. This is related\nto research in human decision-making under uncertainty, and in particular the\nprobability matching theory. Our main result shows that a proper entropy\nregularisation, i.e., training the GNN not to be overconfident, greatly\nimproves plCoP's performance on a large mathematical corpus.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 04:57:44 GMT"}, {"version": "v2", "created": "Fri, 16 Jul 2021 12:43:12 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Zombori", "Zsolt", ""], ["Urban", "Josef", ""], ["Ol\u0161\u00e1k", "Miroslav", ""]]}, {"id": "2105.14713", "submitter": "Mingbao Lin", "authors": "Mingbao Lin, Yuchao Li, Yuxin Zhang, Bohong Chen, Fei Chao, Mengdi\n  Wang, Shen Li, Jun Yang, Rongrong Ji", "title": "1$\\times$N Block Pattern for Network Sparsity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Though network sparsity emerges as a promising direction to overcome the\ndrastically increasing size of neural networks, it remains an open problem to\nconcurrently maintain model accuracy as well as achieve significant speedups on\ngeneral CPUs. In this paper, we propose one novel concept of $1\\times N$ block\nsparsity pattern (block pruning) to break this limitation. In particular,\nconsecutive $N$ output kernels with the same input channel index are grouped\ninto one block, which serves as a basic pruning granularity of our pruning\npattern. Our $1 \\times N$ sparsity pattern prunes these blocks considered\nunimportant. We also provide a workflow of filter rearrangement that first\nrearranges the weight matrix in the output channel dimension to derive more\ninfluential blocks for accuracy improvements, and then applies similar\nrearrangement to the next-layer weights in the input channel dimension to\nensure correct convolutional operations. Moreover, the output computation after\nour $1 \\times N$ block sparsity can be realized via a parallelized block-wise\nvectorized operation, leading to significant speedups on general CPUs-based\nplatforms. The efficacy of our pruning pattern is proved with experiments on\nILSVRC-2012. For example, in the case of 50% sparsity and $N=4$, our pattern\nobtains about 3.0% improvements over filter pruning in the top-1 accuracy of\nMobileNet-V2. Meanwhile, it obtains 56.04ms inference savings on Cortex-A7 CPU\nover weight pruning. Code is available at https://github.com/lmbxmu/1xN.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 05:50:33 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 11:59:07 GMT"}, {"version": "v3", "created": "Tue, 15 Jun 2021 08:09:24 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Lin", "Mingbao", ""], ["Li", "Yuchao", ""], ["Zhang", "Yuxin", ""], ["Chen", "Bohong", ""], ["Chao", "Fei", ""], ["Wang", "Mengdi", ""], ["Li", "Shen", ""], ["Yang", "Jun", ""], ["Ji", "Rongrong", ""]]}, {"id": "2105.14730", "submitter": "Benjamin Maschler", "authors": "Benjamin Maschler, Timo M\\\"uller, Andreas L\\\"ocklin and Michael\n  Weyrich", "title": "Transfer Learning as an Enhancement for Reconfiguration Management of\n  Cyber-Physical Production Systems", "comments": "6 pages, 4 figures, 1 table. Submitted for publication at CIRP ICME\n  2021", "journal-ref": null, "doi": "10.13140/RG.2.2.14077.69606", "report-no": null, "categories": "cs.LG cs.AI cs.SE cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Reconfiguration demand is increasing due to frequent requirement changes for\nmanufacturing systems. Recent approaches aim at investigating feasible\nconfiguration alternatives from which they select the optimal one. This relies\non processes whose behavior is not reliant on e.g. the production sequence.\nHowever, when machine learning is used, components' behavior depends on the\nprocess' specifics, requiring additional concepts to successfully conduct\nreconfiguration management. Therefore, we propose the enhancement of the\ncomprehensive reconfiguration management with transfer learning. This provides\nthe ability to assess the machine learning dependent behavior of the different\nCPPS configurations with reduced effort and further assists the recommissioning\nof the chosen one. A real cyber-physical production system from the discrete\nmanufacturing domain is utilized to demonstrate the aforementioned proposal.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 06:50:58 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Maschler", "Benjamin", ""], ["M\u00fcller", "Timo", ""], ["L\u00f6cklin", "Andreas", ""], ["Weyrich", "Michael", ""]]}, {"id": "2105.14737", "submitter": "Jin-Hwa Kim", "authors": "Jin-Hwa Kim, Do-Hyeong Kim, Saehoon Yi, Taehoon Lee", "title": "Semi-orthogonal Embedding for Efficient Unsupervised Anomaly\n  Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the efficiency of semi-orthogonal embedding for unsupervised\nanomaly segmentation. The multi-scale features from pre-trained CNNs are\nrecently used for the localized Mahalanobis distances with significant\nperformance. However, the increased feature size is problematic to scale up to\nthe bigger CNNs, since it requires the batch-inverse of multi-dimensional\ncovariance tensor. Here, we generalize an ad-hoc method, random feature\nselection, into semi-orthogonal embedding for robust approximation, cubically\nreducing the computational cost for the inverse of multi-dimensional covariance\ntensor. With the scrutiny of ablation studies, the proposed method achieves a\nnew state-of-the-art with significant margins for the MVTec AD, KolektorSDD,\nKolektorSDD2, and mSTC datasets. The theoretical and empirical analyses offer\ninsights and verification of our straightforward yet cost-effective approach.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 07:02:20 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kim", "Jin-Hwa", ""], ["Kim", "Do-Hyeong", ""], ["Yi", "Saehoon", ""], ["Lee", "Taehoon", ""]]}, {"id": "2105.14750", "submitter": "Siyuan Li", "authors": "Siyuan Li, Jin Zhang, Jianhao Wang, Chongjie Zhang", "title": "Efficient Hierarchical Exploration with Stable Subgoal Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Goal-conditioned hierarchical reinforcement learning (HRL) serves as a\nsuccessful approach to solving complex and temporally extended tasks. Recently,\nits success has been extended to more general settings by concurrently learning\nhierarchical policies and subgoal representations. However, online subgoal\nrepresentation learning exacerbates the non-stationary issue of HRL and\nintroduces challenges for exploration in high-level policy learning. In this\npaper, we propose a state-specific regularization that stabilizes subgoal\nembeddings in well-explored areas while allowing representation updates in less\nexplored state regions. Benefiting from this stable representation, we design\nmeasures of novelty and potential for subgoals, and develop an efficient\nhierarchical exploration strategy that actively seeks out new promising\nsubgoals and states. Experimental results show that our method significantly\noutperforms state-of-the-art baselines in continuous control tasks with sparse\nrewards and further demonstrate the stability and efficiency of the subgoal\nrepresentation learning of this work, which promotes superior policy learning.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 07:28:59 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Li", "Siyuan", ""], ["Zhang", "Jin", ""], ["Wang", "Jianhao", ""], ["Zhang", "Chongjie", ""]]}, {"id": "2105.14772", "submitter": "Anis Elgabli", "authors": "Anis Elgabli, Chaouki Ben Issaid, Amrit S. Bedi, Mehdi Bennis, Vaneet\n  Aggarwal", "title": "Energy-Efficient and Federated Meta-Learning via Projected Stochastic\n  Gradient Ascent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose an energy-efficient federated meta-learning\nframework. The objective is to enable learning a meta-model that can be\nfine-tuned to a new task with a few number of samples in a distributed setting\nand at low computation and communication energy consumption. We assume that\neach task is owned by a separate agent, so a limited number of tasks is used to\ntrain a meta-model. Assuming each task was trained offline on the agent's local\ndata, we propose a lightweight algorithm that starts from the local models of\nall agents, and in a backward manner using projected stochastic gradient ascent\n(P-SGA) finds a meta-model. The proposed method avoids complex computations\nsuch as computing hessian, double looping, and matrix inversion, while\nachieving high performance at significantly less energy consumption compared to\nthe state-of-the-art methods such as MAML and iMAML on conducted experiments\nfor sinusoid regression and image classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 08:15:44 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Elgabli", "Anis", ""], ["Issaid", "Chaouki Ben", ""], ["Bedi", "Amrit S.", ""], ["Bennis", "Mehdi", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "2105.14796", "submitter": "Binbin Xie", "authors": "Binbin Xie, Jinsong Su, Yubin Ge, Xiang Li, Jianwei Cui, Junfeng Yao\n  and Bin Wang", "title": "Improving Tree-Structured Decoder Training for Code Generation via\n  Mutual Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code generation aims to automatically generate a piece of code given an input\nnatural language utterance. Currently, among dominant models, it is treated as\na sequence-to-tree task, where a decoder outputs a sequence of actions\ncorresponding to the pre-order traversal of an Abstract Syntax Tree. However,\nsuch a decoder only exploits the preorder traversal based preceding actions,\nwhich are insufficient to ensure correct action predictions. In this paper, we\nfirst throughly analyze the context modeling difference between neural code\ngeneration models with different traversals based decodings (preorder traversal\nvs breadth-first traversal), and then propose to introduce a mutual learning\nframework to jointly train these models. Under this framework, we continuously\nenhance both two models via mutual distillation, which involves synchronous\nexecutions of two one-to-one knowledge transfers at each training step. More\nspecifically, we alternately choose one model as the student and the other as\nits teacher, and require the student to fit the training data and the action\nprediction distributions of its teacher. By doing so, both models can fully\nabsorb the knowledge from each other and thus could be improved simultaneously.\nExperimental results and in-depth analysis on several benchmark datasets\ndemonstrate the effectiveness of our approach. We release our code at\nhttps://github.com/DeepLearnXMU/CGML.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 08:44:13 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Xie", "Binbin", ""], ["Su", "Jinsong", ""], ["Ge", "Yubin", ""], ["Li", "Xiang", ""], ["Cui", "Jianwei", ""], ["Yao", "Junfeng", ""], ["Wang", "Bin", ""]]}, {"id": "2105.14802", "submitter": "Yafu Li", "authors": "Yafu Li, Yongjing Yin, Yulong Chen and Yue Zhang", "title": "On Compositional Generalization of Neural Machine Translation", "comments": "To appear at the ACL 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern neural machine translation (NMT) models have achieved competitive\nperformance in standard benchmarks such as WMT. However, there still exist\nsignificant issues such as robustness, domain generalization, etc. In this\npaper, we study NMT models from the perspective of compositional generalization\nby building a benchmark dataset, CoGnition, consisting of 216k clean and\nconsistent sentence pairs. We quantitatively analyze effects of various factors\nusing compound translation error rate, then demonstrate that the NMT model\nfails badly on compositional generalization, although it performs remarkably\nwell under traditional metrics.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 09:04:29 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Li", "Yafu", ""], ["Yin", "Yongjing", ""], ["Chen", "Yulong", ""], ["Zhang", "Yue", ""]]}, {"id": "2105.14803", "submitter": "Manish Shukla", "authors": "Rosni K Vasu, Sanjay Seetharaman, Shubham Malaviya, Manish Shukla,\n  Sachin Lodha", "title": "Gradient-based Data Subversion Attack Against Binary Classifiers", "comments": "26 pages, 3 Figures, 8 tables, adversarial attacks, data poisoning\n  attacks, label contamination, transferability of attack, susceptibility", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Machine learning based data-driven technologies have shown impressive\nperformances in a variety of application domains. Most enterprises use data\nfrom multiple sources to provide quality applications. The reliability of the\nexternal data sources raises concerns for the security of the machine learning\ntechniques adopted. An attacker can tamper the training or test datasets to\nsubvert the predictions of models generated by these techniques. Data poisoning\nis one such attack wherein the attacker tries to degrade the performance of a\nclassifier by manipulating the training data.\n  In this work, we focus on label contamination attack in which an attacker\npoisons the labels of data to compromise the functionality of the system. We\ndevelop Gradient-based Data Subversion strategies to achieve model degradation\nunder the assumption that the attacker has limited-knowledge of the victim\nmodel. We exploit the gradients of a differentiable convex loss function\n(residual errors) with respect to the predicted label as a warm-start and\nformulate different strategies to find a set of data instances to contaminate.\nFurther, we analyze the transferability of attacks and the susceptibility of\nbinary classifiers. Our experiments show that the proposed approach outperforms\nthe baselines and is computationally efficient.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 09:04:32 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Vasu", "Rosni K", ""], ["Seetharaman", "Sanjay", ""], ["Malaviya", "Shubham", ""], ["Shukla", "Manish", ""], ["Lodha", "Sachin", ""]]}, {"id": "2105.14809", "submitter": "Xuancheng Huang", "authors": "Xuancheng Huang, Jingfang Xu, Maosong Sun, and Yang Liu", "title": "Transfer Learning for Sequence Generation: from Single-source to\n  Multi-source", "comments": "ACL2021 main track long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Multi-source sequence generation (MSG) is an important kind of sequence\ngeneration tasks that takes multiple sources, including automatic post-editing,\nmulti-source translation, multi-document summarization, etc. As MSG tasks\nsuffer from the data scarcity problem and recent pretrained models have been\nproven to be effective for low-resource downstream tasks, transferring\npretrained sequence-to-sequence models to MSG tasks is essential. Although\ndirectly finetuning pretrained models on MSG tasks and concatenating multiple\nsources into a single long sequence is regarded as a simple method to transfer\npretrained models to MSG tasks, we conjecture that the direct finetuning method\nleads to catastrophic forgetting and solely relying on pretrained\nself-attention layers to capture cross-source information is not sufficient.\nTherefore, we propose a two-stage finetuning method to alleviate the\npretrain-finetune discrepancy and introduce a novel MSG model with a fine\nencoder to learn better representations in MSG tasks. Experiments show that our\napproach achieves new state-of-the-art results on the WMT17 APE task and\nmulti-source translation task using the WMT14 test set. When adapted to\ndocument-level translation, our framework outperforms strong baselines\nsignificantly.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 09:12:38 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Huang", "Xuancheng", ""], ["Xu", "Jingfang", ""], ["Sun", "Maosong", ""], ["Liu", "Yang", ""]]}, {"id": "2105.14815", "submitter": "Thiemo Wambsganss", "authors": "Thiemo Wambsganss, Christina Niklaus, Matthias S\\\"ollner, Siegfried\n  Handschuh and Jan Marco Leimeister", "title": "Supporting Cognitive and Emotional Empathic Writing of Students", "comments": "to be published in The Joint Conference of the 59th Annual Meeting of\n  the Association for Computational Linguistics and the 11th International\n  Joint Conference on Natural Language Processing (ACL-IJCNLP 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present an annotation approach to capturing emotional and cognitive\nempathy in student-written peer reviews on business models in German. We\npropose an annotation scheme that allows us to model emotional and cognitive\nempathy scores based on three types of review components. Also, we conducted an\nannotation study with three annotators based on 92 student essays to evaluate\nour annotation scheme. The obtained inter-rater agreement of {\\alpha}=0.79 for\nthe components and the multi-{\\pi}=0.41 for the empathy scores indicate that\nthe proposed annotation scheme successfully guides annotators to a substantial\nto moderate agreement. Moreover, we trained predictive models to detect the\nannotated empathy structures and embedded them in an adaptive writing support\nsystem for students to receive individual empathy feedback independent of an\ninstructor, time, and location. We evaluated our tool in a peer learning\nexercise with 58 students and found promising results for perceived empathy\nskill learning, perceived feedback accuracy, and intention to use. Finally, we\npresent our freely available corpus of 500 empathy-annotated, student-written\npeer reviews on business models and our annotation guidelines to encourage\nfuture research on the design and development of empathy support systems.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 09:18:50 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wambsganss", "Thiemo", ""], ["Niklaus", "Christina", ""], ["S\u00f6llner", "Matthias", ""], ["Handschuh", "Siegfried", ""], ["Leimeister", "Jan Marco", ""]]}, {"id": "2105.14820", "submitter": "Pierre Blanchart", "authors": "Pierre Blanchart", "title": "An exact counterfactual-example-based approach to tree-ensemble models\n  interpretability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Explaining the decisions of machine learning models is becoming a necessity\nin many areas where trust in ML models decision is key to their\naccreditation/adoption. The ability to explain models decisions also allows to\nprovide diagnosis in addition to the model decision, which is highly valuable\nin scenarios such as fault detection. Unfortunately, high-performance models do\nnot exhibit the necessary transparency to make their decisions fully\nunderstandable. And the black-boxes approaches, which are used to explain such\nmodel decisions, suffer from a lack of accuracy in tracing back the exact cause\nof a model decision regarding a given input. Indeed, they do not have the\nability to explicitly describe the decision regions of the model around that\ninput, which is necessary to determine what influences the model towards one\ndecision or the other. We thus asked ourselves the question: is there a\ncategory of high-performance models among the ones currently used for which we\ncould explicitly and exactly characterise the decision regions in the input\nfeature space using a geometrical characterisation? Surprisingly we came out\nwith a positive answer for any model that enters the category of tree ensemble\nmodels, which encompasses a wide range of high-performance models such as\nXGBoost, LightGBM, random forests ... We could derive an exact geometrical\ncharacterisation of their decision regions under the form of a collection of\nmultidimensional intervals. This characterisation makes it straightforward to\ncompute the optimal counterfactual (CF) example associated with a query point.\nWe demonstrate several possibilities of the approach, such as computing the CF\nexample based only on a subset of features. This allows to obtain more\nplausible explanations by adding prior knowledge about which variables the user\ncan control. An adaptation to CF reasoning on regression problems is also\nenvisaged.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 09:32:46 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Blanchart", "Pierre", ""]]}, {"id": "2105.14824", "submitter": "Thomas Baumhauer", "authors": "Thomas Baumhauer and Djordje Slijepcevic and Matthias Zeppelzauer", "title": "Bounded logit attention: Learning to explain image classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable artificial intelligence is the attempt to elucidate the workings\nof systems too complex to be directly accessible to human cognition through\nsuitable side-information referred to as \"explanations\". We present a trainable\nexplanation module for convolutional image classifiers we call bounded logit\nattention (BLA). The BLA module learns to select a subset of the convolutional\nfeature map for each input instance, which then serves as an explanation for\nthe classifier's prediction. BLA overcomes several limitations of the\ninstancewise feature selection method \"learning to explain\" (L2X) introduced by\nChen et al. (2018): 1) BLA scales to real-world sized image classification\nproblems, and 2) BLA offers a canonical way to learn explanations of variable\nsize. Due to its modularity BLA lends itself to transfer learning setups and\ncan also be employed as a post-hoc add-on to trained classifiers. Beyond\nexplainability, BLA may serve as a general purpose method for differentiable\napproximation of subset selection. In a user study we find that BLA\nexplanations are preferred over explanations generated by the popular\n(Grad-)CAM method.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 09:36:05 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Baumhauer", "Thomas", ""], ["Slijepcevic", "Djordje", ""], ["Zeppelzauer", "Matthias", ""]]}, {"id": "2105.14829", "submitter": "Stephen James", "authors": "Stephen James and Andrew J. Davison", "title": "Q-attention: Enabling Efficient Learning for Vision-based Robotic\n  Manipulation", "comments": "Videos and code found at: https://sites.google.com/view/q-attention", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the success of reinforcement learning methods, they have yet to have\ntheir breakthrough moment when applied to a broad range of robotic manipulation\ntasks. This is partly due to the fact that reinforcement learning algorithms\nare notoriously difficult and time consuming to train, which is exacerbated\nwhen training from images rather than full-state inputs. As humans perform\nmanipulation tasks, our eyes closely monitor every step of the process with our\ngaze focusing sequentially on the objects being manipulated. With this in mind,\nwe present our Attention-driven Robotic Manipulation (ARM) algorithm, which is\na general manipulation algorithm that can be applied to a range of\nsparse-rewarded tasks, given only a small number of demonstrations. ARM splits\nthe complex task of manipulation into a 3 stage pipeline: (1) a Q-attention\nagent extracts interesting pixel locations from RGB and point cloud inputs, (2)\na next-best pose agent that accepts crops from the Q-attention agent and\noutputs poses, and (3) a control agent that takes the goal pose and outputs\njoint actions. We show that current learning algorithms fail on a range of\nRLBench tasks, whilst ARM is successful.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 09:44:16 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["James", "Stephen", ""], ["Davison", "Andrew J.", ""]]}, {"id": "2105.14849", "submitter": "Albert Zeyer", "authors": "Albert Zeyer and Ralf Schl\\\"uter and Hermann Ney", "title": "Why does CTC result in peaky behavior?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.NE cs.SD eess.AS math.ST stat.TH", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The peaky behavior of CTC models is well known experimentally. However, an\nunderstanding about why peaky behavior occurs is missing, and whether this is a\ngood property. We provide a formal analysis of the peaky behavior and gradient\ndescent convergence properties of the CTC loss and related training criteria.\nOur analysis provides a deep understanding why peaky behavior occurs and when\nit is suboptimal. On a simple example which should be trivial to learn for any\nmodel, we prove that a feed-forward neural network trained with CTC from\nuniform initialization converges towards peaky behavior with a 100% error rate.\nOur analysis further explains why CTC only works well together with the blank\nlabel. We further demonstrate that peaky behavior does not occur on other\nrelated losses including a label prior model, and that this improves\nconvergence.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 10:03:14 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 21:44:23 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Zeyer", "Albert", ""], ["Schl\u00fcter", "Ralf", ""], ["Ney", "Hermann", ""]]}, {"id": "2105.14875", "submitter": "Jakaria Rabbi", "authors": "Ovishake Sen, Mohtasim Fuad, MD. Nazrul Islam, Jakaria Rabbi, MD.\n  Kamrul Hasan, Mohammed Baz, Mehedi Masud, Md. Abdul Awal, Awal Ahmed Fime,\n  Md. Tahmid Hasan Fuad, Delowar Sikder, and MD. Akil Raihan Iftee", "title": "Bangla Natural Language Processing: A Comprehensive Review of Classical,\n  Machine Learning, and Deep Learning Based Methods", "comments": "This preprint will be submitted to IEEE Access Journal and it\n  contains total of 43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bangla language is the seventh most spoken language, with 265 million\nnative and non-native speakers worldwide. However, English is the predominant\nlanguage for online resources and technical knowledge, journals, and\ndocumentation. Consequently, many Bangla-speaking people, who have limited\ncommand of English, face hurdles to utilize English resources. To bridge the\ngap between limited support and increasing demand, researchers conducted many\nexperiments and developed valuable tools and techniques to create and process\nBangla language materials. Many efforts are also ongoing to make it easy to use\nthe Bangla language in the online and technical domains. There are some review\npapers to understand the past, previous, and future Bangla Natural Language\nProcessing (BNLP) trends. The studies are mainly concentrated on the specific\ndomains of BNLP, such as sentiment analysis, speech recognition, optical\ncharacter recognition, and text summarization. There is an apparent scarcity of\nresources that contain a comprehensive study of the recent BNLP tools and\nmethods. Therefore, in this paper, we present a thorough review of 71 BNLP\nresearch papers and categorize them into 11 categories, namely Information\nExtraction, Machine Translation, Named Entity Recognition, Parsing, Parts of\nSpeech Tagging, Question Answering System, Sentiment Analysis, Spam and Fake\nDetection, Text Summarization, Word Sense Disambiguation, and Speech Processing\nand Recognition. We study articles published between 1999 to 2021, and 50% of\nthe papers were published after 2015. We discuss Classical, Machine Learning\nand Deep Learning approaches with different datasets while addressing the\nlimitations and current and future trends of the BNLP.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 10:58:58 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 09:40:12 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Sen", "Ovishake", ""], ["Fuad", "Mohtasim", ""], ["Islam", "MD. Nazrul", ""], ["Rabbi", "Jakaria", ""], ["Hasan", "MD. Kamrul", ""], ["Baz", "Mohammed", ""], ["Masud", "Mehedi", ""], ["Awal", "Md. Abdul", ""], ["Fime", "Awal Ahmed", ""], ["Fuad", "Md. Tahmid Hasan", ""], ["Sikder", "Delowar", ""], ["Iftee", "MD. Akil Raihan", ""]]}, {"id": "2105.14877", "submitter": "Thanh Vinh Vo", "authors": "Thanh Vinh Vo, Pengfei Wei, Trong Nghia Hoang, Tze-Yun Leong", "title": "Adaptive Multi-Source Causal Inference", "comments": "Preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data scarcity is a tremendous challenge in causal effect estimation. In this\npaper, we propose to exploit additional data sources to facilitate estimating\ncausal effects in the target population. Specifically, we leverage additional\nsource datasets which share similar causal mechanisms with the target\nobservations to help infer causal effects of the target population. We propose\nthree levels of knowledge transfer, through modelling the outcomes, treatments,\nand confounders. To achieve consistent positive transfer, we introduce\nlearnable parametric transfer factors to adaptively control the transfer\nstrength, and thus achieving a fair and balanced knowledge transfer between the\nsources and the target. The proposed method can infer causal effects in the\ntarget population without prior knowledge of data discrepancy between the\nadditional data sources and the target. Experiments on both synthetic and\nreal-world datasets show the effectiveness of the proposed method as compared\nwith recent baselines.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 11:02:37 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Vo", "Thanh Vinh", ""], ["Wei", "Pengfei", ""], ["Hoang", "Trong Nghia", ""], ["Leong", "Tze-Yun", ""]]}, {"id": "2105.14878", "submitter": "Mingjun Zhao", "authors": "Mingjun Zhao, Haijiang Wu, Di Niu, Zixuan Wang, Xiaoli Wang", "title": "Verdi: Quality Estimation and Error Detection for Bilingual", "comments": "Accepted by The Web Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Translation Quality Estimation is critical to reducing post-editing efforts\nin machine translation and to cross-lingual corpus cleaning. As a research\nproblem, quality estimation (QE) aims to directly estimate the quality of\ntranslation in a given pair of source and target sentences, and highlight the\nwords that need corrections, without referencing to golden translations. In\nthis paper, we propose Verdi, a novel framework for word-level and\nsentence-level post-editing effort estimation for bilingual corpora. Verdi\nadopts two word predictors to enable diverse features to be extracted from a\npair of sentences for subsequent quality estimation, including a\ntransformer-based neural machine translation (NMT) model and a pre-trained\ncross-lingual language model (XLM). We exploit the symmetric nature of\nbilingual corpora and apply model-level dual learning in the NMT predictor,\nwhich handles a primal task and a dual task simultaneously with weight sharing,\nleading to stronger context prediction ability than single-direction NMT\nmodels. By taking advantage of the dual learning scheme, we further design a\nnovel feature to directly encode the translated target information without\nrelying on the source context. Extensive experiments conducted on WMT20 QE\ntasks demonstrate that our method beats the winner of the competition and\noutperforms other baseline methods by a great margin. We further use the\nsentence-level scores provided by Verdi to clean a parallel corpus and observe\nbenefits on both model performance and training efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 11:04:13 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhao", "Mingjun", ""], ["Wu", "Haijiang", ""], ["Niu", "Di", ""], ["Wang", "Zixuan", ""], ["Wang", "Xiaoli", ""]]}, {"id": "2105.14880", "submitter": "Gaochen Wu", "authors": "Gaochen Wu, Bin Xu, Dejie Chang, Bangchang Liu", "title": "A Multilingual Modeling Method for Span-Extraction Reading Comprehension", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Span-extraction reading comprehension models have made tremendous advances\nenabled by the availability of large-scale, high-quality training datasets.\nDespite such rapid progress and widespread application, extractive reading\ncomprehension datasets in languages other than English remain scarce, and\ncreating such a sufficient amount of training data for each language is costly\nand even impossible. An alternative to creating large-scale high-quality\nmonolingual span-extraction training datasets is to develop multilingual\nmodeling approaches and systems which can transfer to the target language\nwithout requiring training data in that language. In this paper, in order to\nsolve the scarce availability of extractive reading comprehension training data\nin the target language, we propose a multilingual extractive reading\ncomprehension approach called XLRC by simultaneously modeling the existing\nextractive reading comprehension training data in a multilingual environment\nusing self-adaptive attention and multilingual attention. Specifically, we\nfirstly construct multilingual parallel corpora by translating the existing\nextractive reading comprehension datasets (i.e., CMRC 2018) from the target\nlanguage (i.e., Chinese) into different language families (i.e., English).\nSecondly, to enhance the final target representation, we adopt self-adaptive\nattention (SAA) to combine self-attention and inter-attention to extract the\nsemantic relations from each pair of the target and source languages.\nFurthermore, we propose multilingual attention (MLA) to learn the rich\nknowledge from various language families. Experimental results show that our\nmodel outperforms the state-of-the-art baseline (i.e., RoBERTa_Large) on the\nCMRC 2018 task, which demonstrate the effectiveness of our proposed\nmulti-lingual modeling approach and show the potentials in multilingual NLP\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 11:05:30 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wu", "Gaochen", ""], ["Xu", "Bin", ""], ["Chang", "Dejie", ""], ["Liu", "Bangchang", ""]]}, {"id": "2105.14894", "submitter": "Jan K\\v{r}et\\'insk\\'y", "authors": "Jan K\\v{r}et\\'insk\\'y", "title": "LTL-Constrained Steady-State Policy Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Decision-making policies for agents are often synthesized with the constraint\nthat a formal specification of behaviour is satisfied. Here we focus on\ninfinite-horizon properties. On the one hand, Linear Temporal Logic (LTL) is a\npopular example of a formalism for qualitative specifications. On the other\nhand, Steady-State Policy Synthesis (SSPS) has recently received considerable\nattention as it provides a more quantitative and more behavioural perspective\non specifications, in terms of the frequency with which states are visited.\nFinally, rewards provide a classic framework for quantitative properties. In\nthis paper, we study Markov decision processes (MDP) with the specification\ncombining all these three types. The derived policy maximizes the reward among\nall policies ensuring the LTL specification with the given probability and\nadhering to the steady-state constraints. To this end, we provide a unified\nsolution reducing the multi-type specification to a multi-dimensional long-run\naverage reward. This is enabled by Limit-Deterministic B\\\"uchi Automata (LDBA),\nrecently studied in the context of LTL model checking on MDP, and allows for an\nelegant solution through a simple linear programme. The algorithm also extends\nto the general $\\omega$-regular properties and runs in time polynomial in the\nsizes of the MDP as well as the LDBA.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 11:35:42 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["K\u0159et\u00ednsk\u00fd", "Jan", ""]]}, {"id": "2105.14900", "submitter": "Paavo Parmas", "authors": "Paavo Parmas and Masashi Sugiyama", "title": "A unified view of likelihood ratio and reparameterization gradients", "comments": "AISTATS2021; Earlier paper was split in two (arXiv:1910.06419). Refer\n  to the current paper for the unified view, but see the earlier paper for\n  discussion on an importance sampling technique", "journal-ref": "In International Conference on Artificial Intelligence and\n  Statistics (pp. 4078-4086). PMLR (2021, March)", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Reparameterization (RP) and likelihood ratio (LR) gradient estimators are\nused to estimate gradients of expectations throughout machine learning and\nreinforcement learning; however, they are usually explained as simple\nmathematical tricks, with no insight into their nature. We use a first\nprinciples approach to explain that LR and RP are alternative methods of\nkeeping track of the movement of probability mass, and the two are connected\nvia the divergence theorem. Moreover, we show that the space of all possible\nestimators combining LR and RP can be completely parameterized by a flow field\n$u(x)$ and an importance sampling distribution $q(x)$. We prove that there\ncannot exist a single-sample estimator of this type outside our characterized\nspace, thus, clarifying where we should be searching for better Monte Carlo\ngradient estimators.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 11:53:08 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Parmas", "Paavo", ""], ["Sugiyama", "Masashi", ""]]}, {"id": "2105.14915", "submitter": "Hamed Rahimi", "authors": "Hamed Rahimi, Iago Felipe Trentin, Fano Ramparany, Olivier Boissier", "title": "SMASH: a Semantic-enabled Multi-agent Approach for Self-adaptation of\n  Human-centered IoT", "comments": "Submitted to PAAMS 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, IoT devices have an enlarging scope of activities spanning from\nsensing, computing to acting and even more, learning, reasoning and planning.\nAs the number of IoT applications increases, these objects are becoming more\nand more ubiquitous. Therefore, they need to adapt their functionality in\nresponse to the uncertainties of their environment to achieve their goals. In\nHuman-centered IoT, objects and devices have direct interactions with human\nbeings and have access to online contextual information. Self-adaptation of\nsuch applications is a crucial subject that needs to be addressed in a way that\nrespects human goals and human values. Hence, IoT applications must be equipped\nwith self-adaptation techniques to manage their run-time uncertainties locally\nor in cooperation with each other. This paper presents SMASH: a multi-agent\napproach for self-adaptation of IoT applications in human-centered\nenvironments. In this paper, we have considered the Smart Home as the case\nstudy of smart environments. SMASH agents are provided with a 4-layer\narchitecture based on the BDI agent model that integrates human values with\ngoal-reasoning, planning, and acting. It also takes advantage of a\nsemantic-enabled platform called Home'In to address interoperability issues\namong non-identical agents and devices with heterogeneous protocols and data\nformats. This approach is compared with the literature and is validated by\ndeveloping a scenario as the proof of concept. The timely responses of SMASH\nagents show the feasibility of the proposed approach in human-centered\nenvironments.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 12:33:27 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Rahimi", "Hamed", ""], ["Trentin", "Iago Felipe", ""], ["Ramparany", "Fano", ""], ["Boissier", "Olivier", ""]]}, {"id": "2105.14923", "submitter": "Bestoun Ahmed Dr.", "authors": "Kamal Z. Zamli, Md. Abdul Kader, Saiful Azad, Bestoun S. Ahmed", "title": "Hybrid Henry Gas Solubility Optimization Algorithm with Dynamic\n  Cluster-to-Algorithm Mapping for Search-based Software Engineering Problems", "comments": "31 pages", "journal-ref": "Neural Computing and Applications 2021", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper discusses a new variant of the Henry Gas Solubility Optimization\n(HGSO) Algorithm, called Hybrid HGSO (HHGSO). Unlike its predecessor, HHGSO\nallows multiple clusters serving different individual meta-heuristic algorithms\n(i.e., with its own defined parameters and local best) to coexist within the\nsame population. Exploiting the dynamic cluster-to-algorithm mapping via\npenalized and reward model with adaptive switching factor, HHGSO offers a novel\napproach for meta-heuristic hybridization consisting of Jaya Algorithm, Sooty\nTern Optimization Algorithm, Butterfly Optimization Algorithm, and Owl Search\nAlgorithm, respectively. The acquired results from the selected two case\nstudies (i.e., involving team formation problem and combinatorial test suite\ngeneration) indicate that the hybridization has notably improved the\nperformance of HGSO and gives superior performance against other competing\nmeta-heuristic and hyper-heuristic algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 12:42:15 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zamli", "Kamal Z.", ""], ["Kader", "Md. Abdul", ""], ["Azad", "Saiful", ""], ["Ahmed", "Bestoun S.", ""]]}, {"id": "2105.14924", "submitter": "Runxin Xu", "authors": "Runxin Xu, Tianyu Liu, Lei Li, Baobao Chang", "title": "Document-level Event Extraction via Heterogeneous Graph-based\n  Interaction Model with a Tracker", "comments": "Accepted by ACL-IJCNLP 2021 main conference (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document-level event extraction aims to recognize event information from a\nwhole piece of article. Existing methods are not effective due to two\nchallenges of this task: a) the target event arguments are scattered across\nsentences; b) the correlation among events in a document is non-trivial to\nmodel. In this paper, we propose Heterogeneous Graph-based Interaction Model\nwith a Tracker (GIT) to solve the aforementioned two challenges. For the first\nchallenge, GIT constructs a heterogeneous graph interaction network to capture\nglobal interactions among different sentences and entity mentions. For the\nsecond, GIT introduces a Tracker module to track the extracted events and hence\ncapture the interdependency among the events. Experiments on a large-scale\ndataset (Zheng et al., 2019) show GIT outperforms the previous methods by 2.8\nF1. Further analysis reveals GIT is effective in extracting multiple correlated\nevents and event arguments that scatter across the document. Our code is\navailable at https://github.com/RunxinXu/GIT.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 12:45:03 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Xu", "Runxin", ""], ["Liu", "Tianyu", ""], ["Li", "Lei", ""], ["Chang", "Baobao", ""]]}, {"id": "2105.14940", "submitter": "Zae Myung Kim", "authors": "Zae Myung Kim, Laurent Besacier, Vassilina Nikoulina, Didier Schwab", "title": "Do Multilingual Neural Machine Translation Models Contain Language Pair\n  Specific Attention Heads?", "comments": "10 pages, accepted at Findings of ACL 2021 (short)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies on the analysis of the multilingual representations focus on\nidentifying whether there is an emergence of language-independent\nrepresentations, or whether a multilingual model partitions its weights among\ndifferent languages. While most of such work has been conducted in a\n\"black-box\" manner, this paper aims to analyze individual components of a\nmultilingual neural translation (NMT) model. In particular, we look at the\nencoder self-attention and encoder-decoder attention heads (in a many-to-one\nNMT model) that are more specific to the translation of a certain language pair\nthan others by (1) employing metrics that quantify some aspects of the\nattention weights such as \"variance\" or \"confidence\", and (2) systematically\nranking the importance of attention heads with respect to translation quality.\nExperimental results show that surprisingly, the set of most important\nattention heads are very similar across the language pairs and that it is\npossible to remove nearly one-third of the less important heads without hurting\nthe translation quality greatly.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 13:15:55 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kim", "Zae Myung", ""], ["Besacier", "Laurent", ""], ["Nikoulina", "Vassilina", ""], ["Schwab", "Didier", ""]]}, {"id": "2105.14944", "submitter": "Anh Nguyen", "authors": "Giang Nguyen, Daeyoung Kim, Anh Nguyen", "title": "The effectiveness of feature attribution methods and its correlation\n  with automatic evaluation scores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explaining the decisions of an Artificial Intelligence (AI) model is\nincreasingly critical in many real-world, high-stake applications. Hundreds of\npapers have either proposed new feature attribution methods, discussed or\nharnessed these tools in their work. However, despite humans being the target\nend-users, most attribution methods were only evaluated on proxy\nautomatic-evaluation metrics. In this paper, we conduct the first, large-scale\nuser study on 320 lay and 11 expert users to shed light on the effectiveness of\nstate-of-the-art attribution methods in assisting humans in ImageNet\nclassification, Stanford Dogs fine-grained classification, and these two tasks\nbut when the input image contains adversarial perturbations. We found that, in\noverall, feature attribution is surprisingly not more effective than showing\nhumans nearest training-set examples. On a hard task of fine-grained dog\ncategorization, presenting attribution maps to humans does not help, but\ninstead hurts the performance of human-AI teams compared to AI alone.\nImportantly, we found automatic attribution-map evaluation measures to\ncorrelate poorly with the actual human-AI team performance. Our findings\nencourage the community to rigorously test their methods on the downstream\nhuman-in-the-loop applications and to rethink the existing evaluation metrics.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 13:23:50 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 22:00:51 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Nguyen", "Giang", ""], ["Kim", "Daeyoung", ""], ["Nguyen", "Anh", ""]]}, {"id": "2105.15013", "submitter": "Jianhong Wang", "authors": "Jianhong Wang, Jinxin Wang, Yuan Zhang, Yunjie Gu, Tae-Kyun Kim", "title": "SHAQ: Incorporating Shapley Value Theory into Q-Learning for Multi-Agent\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Value factorisation proves to be a very useful technique in multi-agent\nreinforcement learning (MARL), but the underlying mechanism is not yet fully\nunderstood. This paper explores a theoretic basis for value factorisation. We\ngeneralise the Shapley value in the coalitional game theory to a Markov convex\ngame (MCG) and use it to guide value factorisation in MARL. We show that the\ngeneralised Shapley value possesses several features such as (1) accurate\nestimation of the maximum global value, (2) fairness in the factorisation of\nthe global value, and (3) being sensitive to dummy agents. The proposed theory\nyields a new learning algorithm called Sharpley Q-learning (SHAQ), which\ninherits the important merits of ordinary Q-learning but extends it to MARL. In\ncomparison with prior-arts, SHAQ has a much weaker assumption (MCG) that is\nmore compatible with real-world problems, but has superior explainability and\nperformance in many cases. We demonstrated SHAQ and verified the theoretic\nclaims on Predator-Prey and StarCraft Multi-Agent Challenge (SMAC).\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 14:50:52 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Jianhong", ""], ["Wang", "Jinxin", ""], ["Zhang", "Yuan", ""], ["Gu", "Yunjie", ""], ["Kim", "Tae-Kyun", ""]]}, {"id": "2105.15033", "submitter": "Mosha Chen", "authors": "Dejie Chang, Mosha Chen, Chaozhen Liu, Liping Liu, Dongdong Li, Wei\n  Li, Fei Kong, Bangchang Liu, Xiaobin Luo, Ji Qi, Qiao Jin, Bin Xu", "title": "DiaKG: an Annotated Diabetes Dataset for Medical Knowledge Graph\n  Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge Graph has been proven effective in modeling structured information\nand conceptual knowledge, especially in the medical domain. However, the lack\nof high-quality annotated corpora remains a crucial problem for advancing the\nresearch and applications on this task. In order to accelerate the research for\ndomain-specific knowledge graphs in the medical domain, we introduce DiaKG, a\nhigh-quality Chinese dataset for Diabetes knowledge graph, which contains\n22,050 entities and 6,890 relations in total. We implement recent typical\nmethods for Named Entity Recognition and Relation Extraction as a benchmark to\nevaluate the proposed dataset thoroughly. Empirical results show that the DiaKG\nis challenging for most existing methods and further analysis is conducted to\ndiscuss future research direction for improvements. We hope the release of this\ndataset can assist the construction of diabetes knowledge graphs and facilitate\nAI-based applications.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 15:12:49 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Chang", "Dejie", ""], ["Chen", "Mosha", ""], ["Liu", "Chaozhen", ""], ["Liu", "Liping", ""], ["Li", "Dongdong", ""], ["Li", "Wei", ""], ["Kong", "Fei", ""], ["Liu", "Bangchang", ""], ["Luo", "Xiaobin", ""], ["Qi", "Ji", ""], ["Jin", "Qiao", ""], ["Xu", "Bin", ""]]}, {"id": "2105.15034", "submitter": "Fei Tang", "authors": "Fei Tang, Michael Kopp", "title": "A remark on a paper of Krotov and Hopfield [arXiv:2008.06996]", "comments": "1 page, 8 formulae", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI cs.CV cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In their recent paper titled \"Large Associative Memory Problem in\nNeurobiology and Machine Learning\" [arXiv:2008.06996] the authors gave a\nbiologically plausible microscopic theory from which one can recover many dense\nassociative memory models discussed in the literature. We show that the layers\nof the recent \"MLP-mixer\" [arXiv:2105.01601] as well as the essentially\nequivalent model in [arXiv:2105.02723] are amongst them.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 15:13:00 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 07:14:13 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Tang", "Fei", ""], ["Kopp", "Michael", ""]]}, {"id": "2105.15037", "submitter": "Fuhui Zhou", "authors": "Hao Zhang, Fuhui Zhou, Qihui Wu, Wei Wu, Rose Qingyang Hu", "title": "A Novel Automatic Modulation Classification Scheme Based on Multi-Scale\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic modulation classification enables intelligent communications and it\nis of crucial importance in today's and future wireless communication networks.\nAlthough many automatic modulation classification schemes have been proposed,\nthey cannot tackle the intra-class diversity problem caused by the dynamic\nchanges of the wireless communication environment. In order to overcome this\nproblem, inspired by face recognition, a novel automatic modulation\nclassification scheme is proposed by using the multi-scale network in this\npaper. Moreover, a novel loss function that combines the center loss and the\ncross entropy loss is exploited to learn both discriminative and separable\nfeatures in order to further improve the classification performance. Extensive\nsimulation results demonstrate that our proposed automatic modulation\nclassification scheme can achieve better performance than the benchmark schemes\nin terms of the classification accuracy. The influence of the network\nparameters and the loss function with the two-stage training strategy on the\nclassification accuracy of our proposed scheme are investigated.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 15:18:58 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhang", "Hao", ""], ["Zhou", "Fuhui", ""], ["Wu", "Qihui", ""], ["Wu", "Wei", ""], ["Hu", "Rose Qingyang", ""]]}, {"id": "2105.15041", "submitter": "Francisco Luis Giambelluca", "authors": "Francisco Luis Giambelluca, Marcelo A. Cappelletti, Jorge Osio, Luis\n  A. Giambelluca", "title": "Scorpion detection and classification systems based on computer vision\n  and deep learning for health security purposes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, two novel automatic and real-time systems for the detection\nand classification of two genera of scorpions found in La Plata city\n(Argentina) were developed using computer vision and deep learning techniques.\nThe object detection technique was implemented with two different methods, YOLO\n(You Only Look Once) and MobileNet, based on the shape features of the\nscorpions. High accuracy values of 88% and 91%, and high recall values of 90%\nand 97%, have been achieved for both models, respectively, which guarantees\nthat they can successfully detect scorpions. In addition, the MobileNet method\nhas been shown to have excellent performance to detect scorpions within an\nuncontrolled environment and to perform multiple detections. The MobileNet\nmodel was also used for image classification in order to successfully\ndistinguish between dangerous scorpion (Tityus) and non-dangerous scorpion\n(Bothriurus) with the purpose of providing a health security tool. Applications\nfor smartphones were developed, with the advantage of the portability of the\nsystems, which can be used as a help tool for emergency services, or for\nbiological research purposes. The developed systems can be easily scalable to\nother genera and species of scorpions to extend the region where these\napplications can be used.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 15:26:09 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Giambelluca", "Francisco Luis", ""], ["Cappelletti", "Marcelo A.", ""], ["Osio", "Jorge", ""], ["Giambelluca", "Luis A.", ""]]}, {"id": "2105.15054", "submitter": "Prithviraj Ammanabrolu", "authors": "Wai Man Si, Prithviraj Ammanabrolu, Mark O. Riedl", "title": "Telling Stories through Multi-User Dialogue by Modeling Character\n  Relations", "comments": "In Proceedings of SIGDIAL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores character-driven story continuation, in which the story\nemerges through characters' first- and second-person narration as well as\ndialogue -- requiring models to select language that is consistent with a\ncharacter's persona and their relationships with other characters while\nfollowing and advancing the story. We hypothesize that a multi-task model that\ntrains on character dialogue plus character relationship information improves\ntransformer-based story continuation. To this end, we extend the Critical Role\nDungeons and Dragons Dataset (Rameshkumar and Bailey, 2020) -- consisting of\ndialogue transcripts of people collaboratively telling a story while playing\nthe role-playing game Dungeons and Dragons -- with automatically extracted\nrelationships between each pair of interacting characters as well as their\npersonas. A series of ablations lend evidence to our hypothesis, showing that\nour multi-task model using character relationships improves story continuation\naccuracy over strong baselines.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 15:39:41 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Si", "Wai Man", ""], ["Ammanabrolu", "Prithviraj", ""], ["Riedl", "Mark O.", ""]]}, {"id": "2105.15065", "submitter": "Amar Prakash Azad", "authors": "Amar Prakash Azad, Supriyo Ghosh, Ajay Gupta, Harshit Kumar and\n  Prateeti Mohapatra", "title": "Picking Pearl From Seabed: Extracting Artefacts from Noisy Issue\n  Triaging Collaborative Conversations for Hybrid Cloud Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Site Reliability Engineers (SREs) play a key role in issue identification and\nresolution. After an issue is reported, SREs come together in a virtual room\n(collaboration platform) to triage the issue. While doing so, they leave behind\na wealth of information which can be used later for triaging similar issues.\nHowever, usability of the conversations offer challenges due to them being i)\nnoisy and ii) unlabelled. This paper presents a novel approach for issue\nartefact extraction from the noisy conversations with minimal labelled data. We\npropose a combination of unsupervised and supervised model with minimum human\nintervention that leverages domain knowledge to predict artefacts for a small\namount of conversation data and use that for fine-tuning an already pretrained\nlanguage model for artefact prediction on a large amount of conversation data.\nExperimental results on our dataset show that the proposed ensemble of\nunsupervised and supervised model is better than using either one of them\nindividually.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 15:51:44 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Azad", "Amar Prakash", ""], ["Ghosh", "Supriyo", ""], ["Gupta", "Ajay", ""], ["Kumar", "Harshit", ""], ["Mohapatra", "Prateeti", ""]]}, {"id": "2105.15075", "submitter": "Yulin Wang", "authors": "Yulin Wang, Rui Huang, Shiji Song, Zeyi Huang, Gao Huang", "title": "Not All Images are Worth 16x16 Words: Dynamic Vision Transformers with\n  Adaptive Sequence Length", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Vision Transformers (ViT) have achieved remarkable success in large-scale\nimage recognition. They split every 2D image into a fixed number of patches,\neach of which is treated as a token. Generally, representing an image with more\ntokens would lead to higher prediction accuracy, while it also results in\ndrastically increased computational cost. To achieve a decent trade-off between\naccuracy and speed, the number of tokens is empirically set to 16x16. In this\npaper, we argue that every image has its own characteristics, and ideally the\ntoken number should be conditioned on each individual input. In fact, we have\nobserved that there exist a considerable number of \"easy\" images which can be\naccurately predicted with a mere number of 4x4 tokens, while only a small\nfraction of \"hard\" ones need a finer representation. Inspired by this\nphenomenon, we propose a Dynamic Transformer to automatically configure a\nproper number of tokens for each input image. This is achieved by cascading\nmultiple Transformers with increasing numbers of tokens, which are sequentially\nactivated in an adaptive fashion at test time, i.e., the inference is\nterminated once a sufficiently confident prediction is produced. We further\ndesign efficient feature reuse and relationship reuse mechanisms across\ndifferent components of the Dynamic Transformer to reduce redundant\ncomputations. Extensive empirical results on ImageNet, CIFAR-10, and CIFAR-100\ndemonstrate that our method significantly outperforms the competitive baselines\nin terms of both theoretical computational efficiency and practical inference\nspeed.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 16:04:10 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Yulin", ""], ["Huang", "Rui", ""], ["Song", "Shiji", ""], ["Huang", "Zeyi", ""], ["Huang", "Gao", ""]]}, {"id": "2105.15101", "submitter": "Saeed Ghadiri", "authors": "Saeed Ghadiri", "title": "Anchor Nodes Positioning for Self-localization in Wireless Sensor\n  Networks using Belief Propagation and Evolutionary Algorithms", "comments": "5 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.AI eess.SP", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Locating each node in a wireless sensor network is essential for starting the\nmonitoring job and sending information about the area. One method that has been\nused in hard and inaccessible environments is randomly scattering each node in\nthe area. In order to reduce the cost of using GPS at each node, some nodes\nshould be equipped with GPS (anchors), Then using the belief propagation\nalgorithm, locate other nodes. The number of anchor nodes must be reduced since\nthey are expensive. Furthermore, the location of these nodes affects the\nalgorithm's performance. Using multi-objective optimization, an algorithm is\nintroduced in this paper that minimizes the estimated location error and the\nnumber of anchor nodes. According to simulation results, This algorithm\nproposes a set of solutions with less energy consumption and less error than\nsimilar algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 19 Apr 2021 10:05:33 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Ghadiri", "Saeed", ""]]}, {"id": "2105.15135", "submitter": "Sajib Mistry", "authors": "Sajib Mistry and Athman Bouguettaya", "title": "Reputation Bootstrapping for Composite Services using CP-nets", "comments": "14 Pages, accepted and to appear in IEEE Transactions on Services\n  Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a novel framework to bootstrap the reputation of on-demand service\ncompositions. On-demand compositions are usually context-aware and have little\nor no direct consumer feedback. The reputation bootstrapping of single or\natomic services does not consider the topology of the composition and\nrelationships among reputation-related factors. We apply Conditional Preference\nNetworks (CP-nets) of reputation-related factors for component services in a\ncomposition. The reputation of a composite service is bootstrapped by the\ncomposition of CP-nets. We consider the history of invocation among component\nservices to determine reputation-interdependence in a composition. The\ncomposition rules are constructed using the composition topology and four types\nof reputation-influence among component services. A heuristic-based Q-learning\napproach is proposed to select the optimal set of reputation-related CP-nets.\nExperimental results prove the efficiency of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 02:51:23 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Mistry", "Sajib", ""], ["Bouguettaya", "Athman", ""]]}, {"id": "2105.15147", "submitter": "Mohammad Sina Kiarostami", "authors": "Mohammad Sina Kiarostami", "title": "Comparing Two Different Approaches in Big Data and Business Analysis for\n  Churn Prediction with the Focus on How Apache Spark Employed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Due to the significant importance of Big Data analysis, especially in\nbusiness-related topics such as improving services, finding potential\ncustomers, and selecting practical approaches to manage income and expenses,\nmany companies attempt to collaborate with scientists to find how, why, and\nwhat they should analysis. In this work, we would like to compare and discuss\ntwo different approaches that employed in business analysis topic in Big Data\nwith more consideration on how they utilized Spark. Both studies have\ninvestigated Churn Prediction as their case study for their proposed approaches\nsince it is an essential topic in business analysis for companies to recognize\na customer intends to leave or stop using their services. Here, we focus on\nApache Spark since it has provided several solutions to handle a massive amount\nof data in recent years efficiently. This feature in Spark makes it one of the\nmost robust candidate tools to upfront with a Big Data problem, particularly\ntime and resource are concerns.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 12:19:30 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kiarostami", "Mohammad Sina", ""]]}, {"id": "2105.15164", "submitter": "Asma Ghandeharioun", "authors": "Asma Ghandeharioun, Been Kim, Chun-Liang Li, Brendan Jou, Brian Eoff,\n  Rosalind W. Picard", "title": "DISSECT: Disentangled Simultaneous Explanations via Concept Traversals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explaining deep learning model inferences is a promising venue for scientific\nunderstanding, improving safety, uncovering hidden biases, evaluating fairness,\nand beyond, as argued by many scholars. One of the principal benefits of\ncounterfactual explanations is allowing users to explore \"what-if\" scenarios\nthrough what does not and cannot exist in the data, a quality that many other\nforms of explanation such as heatmaps and influence functions are inherently\nincapable of doing. However, most previous work on generative explainability\ncannot disentangle important concepts effectively, produces unrealistic\nexamples, or fails to retain relevant information. We propose a novel approach,\nDISSECT, that jointly trains a generator, a discriminator, and a concept\ndisentangler to overcome such challenges using little supervision. DISSECT\ngenerates Concept Traversals (CTs), defined as a sequence of generated examples\nwith increasing degrees of concepts that influence a classifier's decision. By\ntraining a generative model from a classifier's signal, DISSECT offers a way to\ndiscover a classifier's inherent \"notion\" of distinct concepts automatically\nrather than rely on user-predefined concepts. We show that DISSECT produces CTs\nthat (1) disentangle several concepts, (2) are influential to a classifier's\ndecision and are coupled to its reasoning due to joint training (3), are\nrealistic, (4) preserve relevant information, and (5) are stable across similar\ninputs. We validate DISSECT on several challenging synthetic and realistic\ndatasets where previous methods fall short of satisfying desirable criteria for\ninterpretability and show that it performs consistently well and better than\nexisting methods. Finally, we present experiments showing applications of\nDISSECT for detecting potential biases of a classifier and identifying spurious\nartifacts that impact predictions.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 17:11:56 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ghandeharioun", "Asma", ""], ["Kim", "Been", ""], ["Li", "Chun-Liang", ""], ["Jou", "Brendan", ""], ["Eoff", "Brian", ""], ["Picard", "Rosalind W.", ""]]}, {"id": "2105.15191", "submitter": "Siddharth Divi", "authors": "Siddharth Divi, Habiba Farrukh, Berkay Celik", "title": "Unifying Distillation with Personalization in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) is a decentralized privacy-preserving learning\ntechnique in which clients learn a joint collaborative model through a central\naggregator without sharing their data. In this setting, all clients learn a\nsingle common predictor (FedAvg), which does not generalize well on each\nclient's local data due to the statistical data heterogeneity among clients. In\nthis paper, we address this problem with PersFL, a discrete two-stage\npersonalized learning algorithm. In the first stage, PersFL finds the optimal\nteacher model of each client during the FL training phase. In the second stage,\nPersFL distills the useful knowledge from optimal teachers into each user's\nlocal model. The teacher model provides each client with some rich, high-level\nrepresentation that a client can easily adapt to its local model, which\novercomes the statistical heterogeneity present at different clients. We\nevaluate PersFL on CIFAR-10 and MNIST datasets using three data-splitting\nstrategies to control the diversity between clients' data distributions. We\nempirically show that PersFL outperforms FedAvg and three state-of-the-art\npersonalization methods, pFedMe, Per-FedAvg, and FedPer on majority data-splits\nwith minimal communication cost. Further, we study the performance of PersFL on\ndifferent distillation objectives, how this performance is affected by the\nequitable notion of fairness among clients, and the number of required\ncommunication rounds. PersFL code is available at https://tinyurl.com/hdh5zhxs\nfor public use and validation.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 17:54:29 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Divi", "Siddharth", ""], ["Farrukh", "Habiba", ""], ["Celik", "Berkay", ""]]}]