[{"id": "1805.00121", "submitter": "Juan Duque Rodriguez", "authors": "Juan Ar\\'evalo, Juan Ram\\'on Duque, Marco Creatura", "title": "A Missing Information Loss function for implicit feedback datasets", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent factor models for Recommender Systems with implicit feedback typically\ntreat unobserved user-item interactions (i.e. missing information) as negative\nfeedback. This is frequently done either through negative sampling (point--wise\nloss) or with a ranking loss function (pair-- or list--wise estimation). Since\na zero preference recommendation is a valid solution for most common objective\nfunctions, regarding unknown values as actual zeros results in users having a\nzero preference recommendation for most of the available items. In this paper\nwe propose a novel objective function, the \\emph{Missing Information Loss}\n(MIL), that explicitly forbids treating unobserved user-item interactions as\npositive or negative feedback. We apply this loss to both traditional Matrix\nFactorization and user--based Denoising Autoencoder, and compare it with other\nestablished objective functions such as cross-entropy (both point- and\npair-wise) or the recently proposed multinomial log-likelihood. MIL achieves\ncompetitive performance in ranking-aware metrics when applied to three\ndatasets. Furthermore, we show that such a relevance in the recommendation is\nobtained while displaying popular items less frequently (up to a $20 \\%$\ndecrease with respect to the best competing method). This debiasing from the\nrecommendation of popular items favours the appearance of infrequent items (up\nto a $50 \\%$ increase of long-tail recommendations), a valuable feature for\nRecommender Systems with a large catalogue of products.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 22:38:05 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 08:16:50 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Ar\u00e9valo", "Juan", ""], ["Duque", "Juan Ram\u00f3n", ""], ["Creatura", "Marco", ""]]}, {"id": "1805.00145", "submitter": "Xiaoxiao Guo", "authors": "Xiaoxiao Guo, Hui Wu, Yu Cheng, Steven Rennie, Gerald Tesauro, Rogerio\n  Schmidt Feris", "title": "Dialog-based Interactive Image Retrieval", "comments": "accepted at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing methods for interactive image retrieval have demonstrated the merit\nof integrating user feedback, improving retrieval results. However, most\ncurrent systems rely on restricted forms of user feedback, such as binary\nrelevance responses, or feedback based on a fixed set of relative attributes,\nwhich limits their impact. In this paper, we introduce a new approach to\ninteractive image search that enables users to provide feedback via natural\nlanguage, allowing for more natural and effective interaction. We formulate the\ntask of dialog-based interactive image retrieval as a reinforcement learning\nproblem, and reward the dialog system for improving the rank of the target\nimage during each dialog turn. To mitigate the cumbersome and costly process of\ncollecting human-machine conversations as the dialog system learns, we train\nour system with a user simulator, which is itself trained to describe the\ndifferences between target and candidate images. The efficacy of our approach\nis demonstrated in a footwear retrieval application. Experiments on both\nsimulated and real-world data show that 1) our proposed learning framework\nachieves better accuracy than other supervised and reinforcement learning\nbaselines and 2) user feedback based on natural language rather than\npre-specified attributes leads to more effective retrieval results, and a more\nnatural and expressive communication interface.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 01:13:01 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 17:56:08 GMT"}, {"version": "v3", "created": "Thu, 20 Dec 2018 22:13:05 GMT"}], "update_date": "2018-12-24", "authors_parsed": [["Guo", "Xiaoxiao", ""], ["Wu", "Hui", ""], ["Cheng", "Yu", ""], ["Rennie", "Steven", ""], ["Tesauro", "Gerald", ""], ["Feris", "Rogerio Schmidt", ""]]}, {"id": "1805.00150", "submitter": "Zheng Zhang", "authors": "Zheng Zhang, Minlie Huang, Zhongzhou Zhao, Feng Ji, Haiqing Chen,\n  Xiaoyan Zhu", "title": "Memory-augmented Dialogue Management for Task-oriented Dialogue Systems", "comments": "25 pages, 9 figures, Under review of ACM Transactions on Information\n  Systems (TOIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue management (DM) decides the next action of a dialogue system\naccording to the current dialogue state, and thus plays a central role in\ntask-oriented dialogue systems. Since dialogue management requires to have\naccess to not only local utterances, but also the global semantics of the\nentire dialogue session, modeling the long-range history information is a\ncritical issue. To this end, we propose a novel Memory-Augmented Dialogue\nmanagement model (MAD) which employs a memory controller and two additional\nmemory structures, i.e., a slot-value memory and an external memory. The\nslot-value memory tracks the dialogue state by memorizing and updating the\nvalues of semantic slots (for instance, cuisine, price, and location), and the\nexternal memory augments the representation of hidden states of traditional\nrecurrent neural networks through storing more context information. To update\nthe dialogue state efficiently, we also propose slot-level attention on user\nutterances to extract specific semantic information for each slot. Experiments\nshow that our model can obtain state-of-the-art performance and outperforms\nexisting baselines.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 02:14:00 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Zhang", "Zheng", ""], ["Huang", "Minlie", ""], ["Zhao", "Zhongzhou", ""], ["Ji", "Feng", ""], ["Chen", "Haiqing", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1805.00165", "submitter": "Fernando Gama", "authors": "Fernando Gama and Antonio G. Marques and Geert Leus and Alejandro\n  Ribeiro", "title": "Convolutional Neural Network Architectures for Signals Supported on\n  Graphs", "comments": "Submitted to IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2018.2887403", "report-no": null, "categories": "eess.SP cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two architectures that generalize convolutional neural networks (CNNs) for\nthe processing of signals supported on graphs are introduced. We start with the\nselection graph neural network (GNN), which replaces linear time invariant\nfilters with linear shift invariant graph filters to generate convolutional\nfeatures and reinterprets pooling as a possibly nonlinear subsampling stage\nwhere nearby nodes pool their information in a set of preselected sample nodes.\nA key component of the architecture is to remember the position of sampled\nnodes to permit computation of convolutional features at deeper layers. The\nsecond architecture, dubbed aggregation GNN, diffuses the signal through the\ngraph and stores the sequence of diffused components observed by a designated\nnode. This procedure effectively aggregates all components into a stream of\ninformation having temporal structure to which the convolution and pooling\nstages of regular CNNs can be applied. A multinode version of aggregation GNNs\nis further introduced for operation in large scale graphs. An important\nproperty of selection and aggregation GNNs is that they reduce to conventional\nCNNs when particularized to time signals reinterpreted as graph signals in a\ncirculant graph. Comparative numerical analyses are performed in a source\nlocalization application over synthetic and real-world networks. Performance is\nalso evaluated for an authorship attribution problem and text category\nclassification. Multinode aggregation GNNs are consistently the best performing\nGNN architecture.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 03:04:31 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 01:17:25 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Gama", "Fernando", ""], ["Marques", "Antonio G.", ""], ["Leus", "Geert", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1805.00184", "submitter": "Pouya Pezeshkpour", "authors": "Pouya Pezeshkpour, Carlos Guestrin, Sameer Singh", "title": "Compact Factorization of Matrices Using Generalized Round-Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization is a well-studied task in machine learning for compactly\nrepresenting large, noisy data. In our approach, instead of using the\ntraditional concept of matrix rank, we define a new notion of link-rank based\non a non-linear link function used within factorization. In particular, by\napplying the round function on a factorization to obtain ordinal-valued\nmatrices, we introduce generalized round-rank (GRR). We show that not only are\nthere many full-rank matrices that are low GRR, but further, that these\nmatrices cannot be approximated well by low-rank linear factorization. We\nprovide uniqueness conditions of this formulation and provide gradient\ndescent-based algorithms. Finally, we present experiments on real-world\ndatasets to demonstrate that the GRR-based factorization is significantly more\naccurate than linear factorization, while converging faster and using lower\nrank representations.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 04:41:58 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Pezeshkpour", "Pouya", ""], ["Guestrin", "Carlos", ""], ["Singh", "Sameer", ""]]}, {"id": "1805.00185", "submitter": "Thanh Nguyen", "authors": "Thanh Hai Nguyen, Enrico Pontelli, Tran Cao Son", "title": "Phylotastic: An Experiment in Creating, Manipulating, and Evolving\n  Phylogenetic Biology Workflows Using Logic Programming", "comments": "Paper presented at the 34th International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 17 pages,\n  LaTeX, 10 PDF figures (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evolutionary Biologists have long struggled with the challenge of developing\nanalysis workflows in a flexible manner, thus facilitating the reuse of\nphylogenetic knowledge. An evolutionary biology workflow can be viewed as a\nplan which composes web services that can retrieve, manipulate, and produce\nphylogenetic trees. The Phylotastic project was launched two years ago as a\ncollaboration between evolutionary biologists and computer scientists, with the\ngoal of developing an open architecture to facilitate the creation of such\nanalysis workflows. While composition of web services is a problem that has\nbeen extensively explored in the literature, including within the logic\nprogramming domain, the incarnation of the problem in Phylotastic provides a\nnumber of additional challenges. Along with the need to integrate preferences\nand formal ontologies in the description of the desired workflow, evolutionary\nbiologists tend to construct workflows in an incremental manner, by\nsuccessively refining the workflow, by indicating desired changes (e.g.,\nexclusion of certain services, modifications of the desired output). This leads\nto the need of successive iterations of incremental replanning, to develop a\nnew workflow that integrates the requested changes while minimizing the changes\nto the original workflow. This paper illustrates how Phylotastic has addressed\nthe challenges of creating and refining phylogenetic analysis workflows using\nlogic programming technology and how such solutions have been used within the\ngeneral framework of the Phylotastic project. Under consideration in Theory and\nPractice of Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 04:54:45 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Nguyen", "Thanh Hai", ""], ["Pontelli", "Enrico", ""], ["Son", "Tran Cao", ""]]}, {"id": "1805.00195", "submitter": "Chaitanya Kulkarni", "authors": "Chaitanya Kulkarni, Wei Xu, Alan Ritter, Raghu Machiraju", "title": "An Annotated Corpus for Machine Reading of Instructions in Wet Lab\n  Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an effort to annotate a corpus of natural language instructions\nconsisting of 622 wet lab protocols to facilitate automatic or semi-automatic\nconversion of protocols into a machine-readable format and benefit biological\nresearch. Experimental results demonstrate the utility of our corpus for\ndeveloping machine learning approaches to shallow semantic parsing of\ninstructional texts. We make our annotated Wet Lab Protocol Corpus available to\nthe research community.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 05:52:12 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Kulkarni", "Chaitanya", ""], ["Xu", "Wei", ""], ["Ritter", "Alan", ""], ["Machiraju", "Raghu", ""]]}, {"id": "1805.00215", "submitter": "Shun Yi", "authors": "Shun Yi", "title": "Internal node bagging", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel view to understand how dropout works as an inexplicit\nensemble learning method, which doesn't point out how many and which nodes to\nlearn a certain feature. We propose a new training method named internal node\nbagging, it explicitly forces a group of nodes to learn a certain feature in\ntraining time, and combine those nodes to be one node in inference time. It\nmeans we can use much more parameters to improve model's fitting ability in\ntraining time while keeping model small in inference time. We test our method\non several benchmark datasets and find it performs significantly better than\ndropout on small models.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 07:16:24 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 14:28:04 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 13:12:49 GMT"}, {"version": "v4", "created": "Wed, 18 Jul 2018 03:00:08 GMT"}, {"version": "v5", "created": "Fri, 21 Sep 2018 01:50:44 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Yi", "Shun", ""]]}, {"id": "1805.00254", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Benjamin Roth and Hinrich Sch\\\"utze", "title": "Joint Bootstrapping Machines for High Confidence Relation Extraction", "comments": "In Proceedings of the 16th Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics: Human Language\n  Technologies (NAACL-HLT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised bootstrapping techniques for relationship extraction from\ntext iteratively expand a set of initial seed instances. Due to the lack of\nlabeled data, a key challenge in bootstrapping is semantic drift: if a false\npositive instance is added during an iteration, then all following iterations\nare contaminated. We introduce BREX, a new bootstrapping method that protects\nagainst such contamination by highly effective confidence assessment. This is\nachieved by using entity and template seeds jointly (as opposed to just one as\nin previous work), by expanding entities and templates in parallel and in a\nmutually constraining fashion in each iteration and by introducing\nhigherquality similarity measures for templates. Experimental results show that\nBREX achieves an F1 that is 0.13 (0.87 vs. 0.74) better than the state of the\nart for four relationships.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 09:39:19 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Gupta", "Pankaj", ""], ["Roth", "Benjamin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1805.00307", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Kosuke Tanabe, Issei Tachibana", "title": "Tourist Navigation in Android Smartphone by using Emotion Generating\n  Calculations and Mental State Transition Networks", "comments": "6 pages, 8 figures, Proc. of The 6th International conference on Soft\n  Computing and Intelligent Systems and The 13th International Symposium on\n  Advanced Intelligent Systems(SCIS-ISIS 2012). arXiv admin note: substantial\n  text overlap with arXiv:1804.03994, arXiv:1804.02657, arXiv:1804.04946; text\n  overlap with arXiv:1804.02813", "journal-ref": null, "doi": "10.1109/SCIS-ISIS.2012.6505087", "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mental State Transition Network which consists of mental states connected to\neach other is a basic concept of approximating to human psychological and\nmental responses. It can represent transition from an emotional state to other\none with stimulus by calculating Emotion Generating Calculations method. A\ncomputer agent can transit a mental state in MSTN based on analysis of emotion\nby EGC method. In this paper, the Andorid EGC which the agent works in Android\nsmartphone can evaluate the feelings in the conversation. The tourist\nnavigation system with the proposed technique in this paper will be expected to\nbe an emotional oriented interface in Android smartphone.\n", "versions": [{"version": "v1", "created": "Sun, 8 Apr 2018 04:16:45 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Ichimura", "Takumi", ""], ["Tanabe", "Kosuke", ""], ["Tachibana", "Issei", ""]]}, {"id": "1805.00314", "submitter": "Josiah Wang", "authors": "Josiah Wang, Pranava Madhyastha, Lucia Specia", "title": "Object Counts! Bringing Explicit Detections Back into Image Captioning", "comments": "Please cite: In Proceedings of 2018 Conference of the North American\n  Chapter of the Association for Computational Linguistics (NAACL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of explicit object detectors as an intermediate step to image\ncaptioning - which used to constitute an essential stage in early work - is\noften bypassed in the currently dominant end-to-end approaches, where the\nlanguage model is conditioned directly on a mid-level image embedding. We argue\nthat explicit detections provide rich semantic information, and can thus be\nused as an interpretable representation to better understand why end-to-end\nimage captioning systems work well. We provide an in-depth analysis of\nend-to-end image captioning by exploring a variety of cues that can be derived\nfrom such object detections. Our study reveals that end-to-end image captioning\nsystems rely on matching image representations to generate captions, and that\nencoding the frequency, size and position of objects are complementary and all\nplay a role in forming a good image representation. It also reveals that\ndifferent object categories contribute in different ways towards image\ncaptioning.\n", "versions": [{"version": "v1", "created": "Mon, 23 Apr 2018 14:51:46 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Wang", "Josiah", ""], ["Madhyastha", "Pranava", ""], ["Specia", "Lucia", ""]]}, {"id": "1805.00326", "submitter": "Ivona Tautkute", "authors": "Ivona Tautkute, Tomasz Trzcinski, Adam Bielski", "title": "I Know How You Feel: Emotion Recognition with Facial Landmarks", "comments": "CVPRW 2018, The IEEE Conference on Computer Vision and Pattern\n  Recognition (CVPR) Workshops 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classification of human emotions remains an important and challenging task\nfor many computer vision algorithms, especially in the era of humanoid robots\nwhich coexist with humans in their everyday life. Currently proposed methods\nfor emotion recognition solve this task using multi-layered convolutional\nnetworks that do not explicitly infer any facial features in the classification\nphase. In this work, we postulate a fundamentally different approach to solve\nemotion recognition task that relies on incorporating facial landmarks as a\npart of the classification loss function. To that end, we extend a recently\nproposed Deep Alignment Network (DAN), that achieves state-of-the-art results\nin the recent facial landmark recognition challenge, with a term related to\nfacial features. Thanks to this simple modification, our model called\nEmotionalDAN is able to outperform state-of-the-art emotion classification\nmethods on two challenging benchmark dataset by up to 5%.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 19:06:50 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 18:29:02 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Tautkute", "Ivona", ""], ["Trzcinski", "Tomasz", ""], ["Bielski", "Adam", ""]]}, {"id": "1805.00460", "submitter": "Andrew Shin", "authors": "Andrew Shin, Yoshitaka Ushiku, Tatsuya Harada", "title": "Customized Image Narrative Generation via Interactive Visual Question\n  Generation and Answering", "comments": "To Appear at CVPR 2018 as spotlight presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image description task has been invariably examined in a static manner with\nqualitative presumptions held to be universally applicable, regardless of the\nscope or target of the description. In practice, however, different viewers may\npay attention to different aspects of the image, and yield different\ndescriptions or interpretations under various contexts. Such diversity in\nperspectives is difficult to derive with conventional image description\ntechniques. In this paper, we propose a customized image narrative generation\ntask, in which the users are interactively engaged in the generation process by\nproviding answers to the questions. We further attempt to learn the user's\ninterest via repeating such interactive stages, and to automatically reflect\nthe interest in descriptions for new images. Experimental results demonstrate\nthat our model can generate a variety of descriptions from single image that\ncover a wider range of topics than conventional models, while being\ncustomizable to the target user of interaction.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 11:27:45 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Shin", "Andrew", ""], ["Ushiku", "Yoshitaka", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1805.00462", "submitter": "Haichao Zhang", "authors": "Haichao Zhang, Haonan Yu and Wei Xu", "title": "Interactive Language Acquisition with One-shot Visual Concept Learning\n  through a Conversational Game", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building intelligent agents that can communicate with and learn from humans\nin natural language is of great value. Supervised language learning is limited\nby the ability of capturing mainly the statistics of training data, and is\nhardly adaptive to new scenarios or flexible for acquiring new knowledge\nwithout inefficient retraining or catastrophic forgetting. We highlight the\nperspective that conversational interaction serves as a natural interface both\nfor language learning and for novel knowledge acquisition and propose a joint\nimitation and reinforcement approach for grounded language learning through an\ninteractive conversational game. The agent trained with this approach is able\nto actively acquire information by asking questions about novel objects and use\nthe just-learned knowledge in subsequent conversations in a one-shot fashion.\nResults compared with other methods verified the effectiveness of the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 07:14:59 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Zhang", "Haichao", ""], ["Yu", "Haonan", ""], ["Xu", "Wei", ""]]}, {"id": "1805.00587", "submitter": "Chenyu You", "authors": "Chenyu You and Qingsong Yang and Hongming Shan and Lars Gjesteby and\n  Guang Li and Shenghong Ju and Zhuiyang Zhang and Zhen Zhao and Yi Zhang and\n  Wenxiang Cong and Ge Wang", "title": "Structure-sensitive Multi-scale Deep Neural Network for Low-Dose CT\n  Denoising", "comments": "IEEE Access 2018", "journal-ref": null, "doi": "10.1109/ACCESS.2018.2858196", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computed tomography (CT) is a popular medical imaging modality in clinical\napplications. At the same time, the x-ray radiation dose associated with CT\nscans raises public concerns due to its potential risks to the patients. Over\nthe past years, major efforts have been dedicated to the development of\nLow-Dose CT (LDCT) methods. However, the radiation dose reduction compromises\nthe signal-to-noise ratio (SNR), leading to strong noise and artifacts that\ndown-grade CT image quality. In this paper, we propose a novel 3D noise\nreduction method, called Structure-sensitive Multi-scale Generative Adversarial\nNet (SMGAN), to improve the LDCT image quality. Specifically, we incorporate\nthree-dimensional (3D) volumetric information to improve the image quality.\nAlso, different loss functions for training denoising models are investigated.\nExperiments show that the proposed method can effectively preserve structural\nand texture information from normal-dose CT (NDCT) images, and significantly\nsuppress noise and artifacts. Qualitative visual assessments by three\nexperienced radiologists demonstrate that the proposed method retrieves more\ndetailed information, and outperforms competing methods.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 00:37:05 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 04:42:53 GMT"}, {"version": "v3", "created": "Fri, 10 Aug 2018 06:36:06 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["You", "Chenyu", ""], ["Yang", "Qingsong", ""], ["Shan", "Hongming", ""], ["Gjesteby", "Lars", ""], ["Li", "Guang", ""], ["Ju", "Shenghong", ""], ["Zhang", "Zhuiyang", ""], ["Zhao", "Zhen", ""], ["Zhang", "Yi", ""], ["Cong", "Wenxiang", ""], ["Wang", "Ge", ""]]}, {"id": "1805.00630", "submitter": "Ming Dong", "authors": "Ming Dong, Benzhe Li, Alex Nassif", "title": "A Data-Driven Residential Transformer Overloading Risk Assessment Method", "comments": "10 Pages, 4 figures, IEEE Transactions on Power Delivery, 2018", "journal-ref": "IEEE Transactions on Power Delivery ( Volume: 34 , Issue: 1 , Feb.\n  2019 )", "doi": "10.1109/TPWRD.2018.2882215", "report-no": null, "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Residential transformer population is a critical type of asset that many\nelectric utility companies have been attempting to manage proactively and\neffectively to reduce unexpected failures and life losses that are often caused\nby transformer overloading. Within the typical power asset portfolio, the\nresidential transformer asset is often large in population, having lowest\nreliability design, lacking transformer loading data and susceptible to\ncustomer loading behaviors such as adoption of distributed energy resources and\nelectric vehicles. On the bright side, the availability of more residential\noperation data along with the advancement of data analytics techniques have\nprovided a new path to further our understanding of local residential\ntransformer overloading risks statistically. This research developed a new\ndata-driven method to combine clustering analysis and the simulation of\ntransformer temperature rise and insulation life loss to quantitatively and\nstatistically assess the overloading risk of residential transformer population\nin one area and suggest proper risk management measures according to the\nassessment results. Case studies from an actual Canadian utility company have\nbeen presented and discussed in detail to demonstrate the applicability and\nusefulness of the proposed method.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 05:22:56 GMT"}, {"version": "v2", "created": "Sun, 9 Dec 2018 06:34:32 GMT"}, {"version": "v3", "created": "Wed, 1 Jul 2020 04:30:09 GMT"}], "update_date": "2020-07-02", "authors_parsed": [["Dong", "Ming", ""], ["Li", "Benzhe", ""], ["Nassif", "Alex", ""]]}, {"id": "1805.00634", "submitter": "Joohyung Lee", "authors": "Joohyung Lee and Yi Wang", "title": "A Probabilistic Extension of Action Language BC+", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 18 pages,\n  LaTeX, 1 PDF figures (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic extension of action language BC+. Just like BC+ is\ndefined as a high-level notation of answer set programs for describing\ntransition systems, the proposed language, which we call pBC+, is defined as a\nhigh-level notation of LPMLN programs---a probabilistic extension of answer set\nprograms. We show how probabilistic reasoning about transition systems, such as\nprediction, postdiction, and planning problems, as well as probabilistic\ndiagnosis for dynamic domains, can be modeled in pBC+ and computed using an\nimplementation of LPMLN.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 05:37:42 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2018 04:09:17 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Lee", "Joohyung", ""], ["Wang", "Yi", ""]]}, {"id": "1805.00643", "submitter": "Joohyung Lee", "authors": "Joohyung Lee and Zhun Yang", "title": "Translating LPOD and CR-Prolog2 into Standard Answer Set Programs", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 18 pages,\n  LaTeX, 0 PDF figures (arXiv:YYMM.NNNNN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Logic Programs with Ordered Disjunction (LPOD) is an extension of standard\nanswer set programs to handle preference using the construct of ordered\ndisjunction, and CR-Prolog2 is an extension of standard answer set programs\nwith consistency restoring rules and LPOD-like ordered disjunction. We present\nreductions of each of these languages into the standard ASP language, which\ngives us an alternative way to understand the extensions in terms of the\nstandard ASP language.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 06:16:50 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Lee", "Joohyung", ""], ["Yang", "Zhun", ""]]}, {"id": "1805.00660", "submitter": "Pedro Cabalar", "authors": "Pedro Cabalar, Jorge Fandinno, Luis Fari\\~nas del Cerro and David\n  Pearce", "title": "Functional ASP with Intensional Sets: Application to Gelfond-Zhang\n  Aggregates", "comments": "Paper presented at the 34nd International Conference on Logic\n  Programming (ICLP 2018), Oxford, UK, July 14 to July 17, 2018 16 pages,\n  LaTeX, 0 PDF figures (arXiv:)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a variant of Answer Set Programming (ASP) with\nevaluable functions that extends their application to sets of objects,\nsomething that allows a fully logical treatment of aggregates. Formally, we\nstart from the syntax of First Order Logic with equality and the semantics of\nQuantified Equilibrium Logic with evaluable functions (QELF). Then, we proceed\nto incorporate a new kind of logical term, intensional set (a construct\ncommonly used to denote the set of objects characterised by a given formula),\nand to extend QELF semantics for this new type of expression. In our extended\napproach, intensional sets can be arbitrarily used as predicate or function\narguments or even nested inside other intensional sets, just as regular\nfirst-order logical terms. As a result, aggregates can be naturally formed by\nthe application of some evaluable function (count, sum, maximum, etc) to a set\nof objects expressed as an intensional set. This approach has several\nadvantages. First, while other semantics for aggregates depend on some\nsyntactic transformation (either via a reduct or a formula translation), the\nQELF interpretation treats them as regular evaluable functions, providing a\ncompositional semantics and avoiding any kind of syntactic restriction. Second,\naggregates can be explicitly defined now within the logical language by the\nsimple addition of formulas that fix their meaning in terms of multiple\napplications of some (commutative and associative) binary operation. For\ninstance, we can use recursive rules to define sum in terms of integer\naddition. Last, but not least, we prove that the semantics we obtain for\naggregates coincides with the one defined by Gelfond and Zhang for the Alog\nlanguage, when we restrict to that syntactic fragment. (Under consideration for\nacceptance in TPLP)\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 07:58:55 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Cabalar", "Pedro", ""], ["Fandinno", "Jorge", ""], ["del Cerro", "Luis Fari\u00f1as", ""], ["Pearce", "David", ""]]}, {"id": "1805.00705", "submitter": "Elham Jebal Barezi Sarbijan Ms", "authors": "Onno Kampman, Elham J. Barezi, Dario Bertero, Pascale Fung", "title": "Investigating Audio, Visual, and Text Fusion Methods for End-to-End\n  Automatic Personality Prediction", "comments": "Accepted at ACL2018 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a tri-modal architecture to predict Big Five personality trait\nscores from video clips with different channels for audio, text, and video\ndata. For each channel, stacked Convolutional Neural Networks are employed. The\nchannels are fused both on decision-level and by concatenating their respective\nfully connected layers. It is shown that a multimodal fusion approach\noutperforms each single modality channel, with an improvement of 9.4\\% over the\nbest individual modality (video). Full backpropagation is also shown to be\nbetter than a linear combination of modalities, meaning complex interactions\nbetween modalities can be leveraged to build better models. Furthermore, we can\nsee the prediction relevance of each modality for each trait. The described\nmodel can be used to increase the emotional intelligence of virtual agents.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 10:03:13 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 07:20:31 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Kampman", "Onno", ""], ["Barezi", "Elham J.", ""], ["Bertero", "Dario", ""], ["Fung", "Pascale", ""]]}, {"id": "1805.00728", "submitter": "Jialin Liu Ph.D", "authors": "Vanessa Volz, Jacob Schrum, Jialin Liu, Simon M. Lucas, Adam Smith,\n  Sebastian Risi", "title": "Evolving Mario Levels in the Latent Space of a Deep Convolutional\n  Generative Adversarial Network", "comments": "8 pages, GECCO2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Networks (GANs) are a machine learning approach\ncapable of generating novel example outputs across a space of provided training\nexamples. Procedural Content Generation (PCG) of levels for video games could\nbenefit from such models, especially for games where there is a pre-existing\ncorpus of levels to emulate. This paper trains a GAN to generate levels for\nSuper Mario Bros using a level from the Video Game Level Corpus. The approach\nsuccessfully generates a variety of levels similar to one in the original\ncorpus, but is further improved by application of the Covariance Matrix\nAdaptation Evolution Strategy (CMA-ES). Specifically, various fitness functions\nare used to discover levels within the latent space of the GAN that maximize\ndesired properties. Simple static properties are optimized, such as a given\ndistribution of tile types. Additionally, the champion A* agent from the 2009\nMario AI competition is used to assess whether a level is playable, and how\nmany jumping actions are required to beat it. These fitness functions allow for\nthe discovery of levels that exist within the space of examples designed by\nexperts, and also guide the search towards levels that fulfill one or more\nspecified objectives.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 10:59:36 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Volz", "Vanessa", ""], ["Schrum", "Jacob", ""], ["Liu", "Jialin", ""], ["Lucas", "Simon M.", ""], ["Smith", "Adam", ""], ["Risi", "Sebastian", ""]]}, {"id": "1805.00741", "submitter": "Hengyi Cai", "authors": "Hengyi Cai, Xingguang Ji, Yonghao Song, Yan Jin, Yang Zhang, Mairgup\n  Mansur, Xiaofang Zhao", "title": "KNPTC: Knowledge and Neural Machine Translation Powered Chinese Pinyin\n  Typo Correction", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Chinese pinyin input methods are very important for Chinese language\nprocessing. Actually, users may make typos inevitably when they input pinyin.\nMoreover, pinyin typo correction has become an increasingly important task with\nthe popularity of smartphones and the mobile Internet. How to exploit the\nknowledge of users typing behaviors and support the typo correction for acronym\npinyin remains a challenging problem. To tackle these challenges, we propose\nKNPTC, a novel approach based on neural machine translation (NMT). In contrast\nto previous work, KNPTC is able to integrate explicit knowledge into NMT for\npinyin typo correction, and is able to learn to correct a variety of typos\nwithout the guidance of manually selected constraints or languagespecific\nfeatures. In this approach, we first obtain the transition probabilities\nbetween adjacent letters based on large-scale real-life datasets. Then, we\nconstruct the \"ground-truth\" alignments of training sentence pairs by utilizing\nthese probabilities. Furthermore, these alignments are integrated into NMT to\ncapture sensible pinyin typo correction patterns. KNPTC is applied to correct\ntypos in real-life datasets, which achieves 32.77% increment on average in\naccuracy rate of typo correction compared against the state-of-the-art system.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 11:33:45 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Cai", "Hengyi", ""], ["Ji", "Xingguang", ""], ["Song", "Yonghao", ""], ["Jin", "Yan", ""], ["Zhang", "Yang", ""], ["Mansur", "Mairgup", ""], ["Zhao", "Xiaofang", ""]]}, {"id": "1805.00751", "submitter": "Jiamou Liu", "authors": "Bo Yan, Yiping Liu, Jiamou Liu, Yijin Cai, Hongyi Su, Hong Zheng", "title": "From the Periphery to the Center: Information Brokerage in an Evolving\n  Network", "comments": "The conference version of the paper has been accepted at IJCAI-ECAI\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interpersonal ties are pivotal to individual efficacy, status and performance\nin an agent society. This paper explores three important and interrelated\nthemes in social network theory: the center/periphery partition of the network;\nnetwork dynamics; and social integration of newcomers. We tackle the question:\nHow would a newcomer harness information brokerage to integrate into a dynamic\nnetwork going from periphery to center? We model integration as the interplay\nbetween the newcomer and the dynamics network and capture information brokerage\nusing a process of relationship building. We analyze theoretical guarantees for\nthe newcomer to reach the center through tactics; proving that a winning tactic\nalways exists for certain types of network dynamics. We then propose three\ntactics and show their superior performance over alternative methods on four\nreal-world datasets and four network models. In general, our tactics place the\nnewcomer to the center by adding very few new edges on dynamic networks with\napproximately 14000 nodes.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 11:58:28 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Yan", "Bo", ""], ["Liu", "Yiping", ""], ["Liu", "Jiamou", ""], ["Cai", "Yijin", ""], ["Su", "Hongyi", ""], ["Zheng", "Hong", ""]]}, {"id": "1805.00779", "submitter": "Toon Van Craenendonck", "authors": "Toon Van Craenendonck, Wannes Meert, Sebastijan Dumancic, Hendrik\n  Blockeel", "title": "COBRAS-TS: A new approach to Semi-Supervised Clustering of Time Series", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is ubiquitous in data analysis, including analysis of time series.\nIt is inherently subjective: different users may prefer different clusterings\nfor a particular dataset. Semi-supervised clustering addresses this by allowing\nthe user to provide examples of instances that should (not) be in the same\ncluster. This paper studies semi-supervised clustering in the context of time\nseries. We show that COBRAS, a state-of-the-art semi-supervised clustering\nmethod, can be adapted to this setting. We refer to this approach as COBRAS-TS.\nAn extensive experimental evaluation supports the following claims: (1)\nCOBRAS-TS far outperforms the current state of the art in semi-supervised\nclustering for time series, and thus presents a new baseline for the field; (2)\nCOBRAS-TS can identify clusters with separated components; (3) COBRAS-TS can\nidentify clusters that are characterized by small local patterns; (4) a small\namount of semi-supervision can greatly improve clustering quality for time\nseries; (5) the choice of the clustering algorithm matters (contrary to earlier\nclaims in the literature).\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 13:06:58 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Van Craenendonck", "Toon", ""], ["Meert", "Wannes", ""], ["Dumancic", "Sebastijan", ""], ["Blockeel", "Hendrik", ""]]}, {"id": "1805.00787", "submitter": "Jack Hall", "authors": "Jack Hall", "title": "Cognition in Dynamical Systems, Second Edition", "comments": "50 pages including references. Base file is `cognition.tex`. All\n  figures are generated by TikZ. This is a revised version of my doctoral\n  thesis, which was published under the name of John Wendell Hall since The\n  University of Texas at Austin required my full name. All of this work is\n  unpublished aside from the UT library, where the first edition is stored as\n  my dissertation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.GT cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognition is the process of knowing. As carried out by a dynamical system, it\nis the process by which the system absorbs information into its state. A\ncomplex network of agents cognizes knowledge about its environment, internal\ndynamics and initial state by forming emergent, macro-level patterns. Such\npatterns require each agent to find its place while partially aware of the\nwhole pattern. Such partial awareness can be achieved by separating the system\ndynamics into two parts by timescale: the propagation dynamics and the pattern\ndynamics. The fast propagation dynamics describe the spread of signals across\nthe network. If they converge to a fixed point for any quasi-static state of\nthe slow pattern dynamics, that fixed point represents an aggregate of\nmacro-level information. On longer timescales, agents coordinate via positive\nfeedback to form patterns, which are defined using closed walks in the graph of\nagents. Patterns can be coherent, in that every part of the pattern depends on\nevery other part for context. Coherent patterns are acausal, in that (a) they\ncannot be predicted and (b) no part of the stored knowledge can be mapped to\nany part of the pattern, or vice versa. A cognitive network's knowledge is\nencoded or embodied by the selection of patterns which emerge. The theory of\ncognition summarized here can model autocatalytic reaction-diffusion systems,\nartificial neural networks, market economies and ant colony optimization, among\nmany other real and virtual systems. This theory suggests a new understanding\nof complexity as a lattice of contexts rather than a single measure.\n", "versions": [{"version": "v1", "created": "Mon, 9 Apr 2018 04:12:08 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Hall", "Jack", ""]]}, {"id": "1805.00851", "submitter": "Dimiter Dobrev", "authors": "Dimiter Dobrev", "title": "How does the AI understand what's going on", "comments": null, "journal-ref": "International Journal \"Information Theories and Applications\",\n  Vol. 24, Number 4, 2017, pp.345-369", "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most researchers regard AI as a static function without memory. This is one\nof the few articles where AI is seen as a device with memory. When we have\nmemory, we can ask ourselves: \"Where am I?\", and \"What is going on?\" When we\nhave no memory, we have to assume that we are always in the same place and that\nthe world is always in the same state.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 11:06:29 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Dobrev", "Dimiter", ""]]}, {"id": "1805.00873", "submitter": "Bestoun Ahmed Dr.", "authors": "Kamal Z. Zamli and Fakhrud Din and Bestoun S. Ahmed and Miroslav Bures", "title": "A Hybrid Q-Learning Sine-Cosine-based Strategy for Addressing the\n  Combinatorial Test Suite Minimization Problem", "comments": "41 pages", "journal-ref": "PLoS One 2018", "doi": "10.1371/journal.pone.0195675", "report-no": null, "categories": "cs.AI cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The sine-cosine algorithm (SCA) is a new population-based meta-heuristic\nalgorithm. In addition to exploiting sine and cosine functions to perform local\nand global searches (hence the name sine-cosine), the SCA introduces several\nrandom and adaptive parameters to facilitate the search process. Although it\nshows promising results, the search process of the SCA is vulnerable to local\nminima/maxima due to the adoption of a fixed switch probability and the bounded\nmagnitude of the sine and cosine functions (from -1 to 1). In this paper, we\npropose a new hybrid Q-learning sine-cosine- based strategy, called the\nQ-learning sine-cosine algorithm (QLSCA). Within the QLSCA, we eliminate the\nswitching probability. Instead, we rely on the Q-learning algorithm (based on\nthe penalty and reward mechanism) to dynamically identify the best operation\nduring runtime. Additionally, we integrate two new operations (L\\'evy flight\nmotion and crossover) into the QLSCA to facilitate jumping out of local\nminima/maxima and enhance the solution diversity. To assess its performance, we\nadopt the QLSCA for the combinatorial test suite minimization problem.\nExperimental results reveal that the QLSCA is statistically superior with\nregard to test suite size reduction compared to recent state-of-the-art\nstrategies, including the original SCA, the particle swarm test generator\n(PSTG), adaptive particle swarm optimization (APSO) and the cuckoo search\nstrategy (CS) at the 95% confidence level. However, concerning the comparison\nwith discrete particle swarm optimization (DPSO), there is no significant\ndifference in performance at the 95% confidence level. On a positive note, the\nQLSCA statistically outperforms the DPSO in certain configurations at the 90%\nconfidence level.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 12:44:04 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Zamli", "Kamal Z.", ""], ["Din", "Fakhrud", ""], ["Ahmed", "Bestoun S.", ""], ["Bures", "Miroslav", ""]]}, {"id": "1805.00900", "submitter": "Micael Carvalho", "authors": "Micael Carvalho, R\\'emi Cad\\`ene, David Picard, Laure Soulier,\n  Matthieu Cord", "title": "Images & Recipes: Retrieval in the cooking context", "comments": "Published at DECOR / ICDE 2018. Extended version accepted at SIGIR\n  2018, available here: arXiv:1804.11146", "journal-ref": null, "doi": "10.1109/ICDEW.2018.00035", "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the machine learning community allowed different use cases\nto emerge, as its association to domains like cooking which created the\ncomputational cuisine. In this paper, we tackle the picture-recipe alignment\nproblem, having as target application the large-scale retrieval task (finding a\nrecipe given a picture, and vice versa). Our approach is validated on the\nRecipe1M dataset, composed of one million image-recipe pairs and additional\nclass information, for which we achieve state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 16:34:01 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Carvalho", "Micael", ""], ["Cad\u00e8ne", "R\u00e9mi", ""], ["Picard", "David", ""], ["Soulier", "Laure", ""], ["Cord", "Matthieu", ""]]}, {"id": "1805.00909", "submitter": "Sergey Levine", "authors": "Sergey Levine", "title": "Reinforcement Learning and Control as Probabilistic Inference: Tutorial\n  and Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The framework of reinforcement learning or optimal control provides a\nmathematical formalization of intelligent decision making that is powerful and\nbroadly applicable. While the general form of the reinforcement learning\nproblem enables effective reasoning about uncertainty, the connection between\nreinforcement learning and inference in probabilistic models is not immediately\nobvious. However, such a connection has considerable value when it comes to\nalgorithm design: formalizing a problem as probabilistic inference in principle\nallows us to bring to bear a wide array of approximate inference tools, extend\nthe model in flexible and powerful ways, and reason about compositionality and\npartial observability. In this article, we will discuss how a generalization of\nthe reinforcement learning or optimal control problem, which is sometimes\ntermed maximum entropy reinforcement learning, is equivalent to exact\nprobabilistic inference in the case of deterministic dynamics, and variational\ninference in the case of stochastic dynamics. We will present a detailed\nderivation of this framework, overview prior work that has drawn on this and\nrelated ideas to propose new reinforcement learning and control algorithms, and\ndescribe perspectives on future research.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 17:11:20 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 16:14:58 GMT"}, {"version": "v3", "created": "Sun, 20 May 2018 20:03:59 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Levine", "Sergey", ""]]}, {"id": "1805.00912", "submitter": "Tao Shen", "authors": "Tao Shen, Tianyi Zhou, Guodong Long, Jing Jiang, Chengqi Zhang", "title": "Tensorized Self-Attention: Efficiently Modeling Pairwise and Global\n  Dependencies Together", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks equipped with self-attention have parallelizable computation,\nlight-weight structure, and the ability to capture both long-range and local\ndependencies. Further, their expressive power and performance can be boosted by\nusing a vector to measure pairwise dependency, but this requires to expand the\nalignment matrix to a tensor, which results in memory and computation\nbottlenecks. In this paper, we propose a novel attention mechanism called\n\"Multi-mask Tensorized Self-Attention\" (MTSA), which is as fast and as\nmemory-efficient as a CNN, but significantly outperforms previous\nCNN-/RNN-/attention-based models. MTSA 1) captures both pairwise (token2token)\nand global (source2token) dependencies by a novel compatibility function\ncomposed of dot-product and additive attentions, 2) uses a tensor to represent\nthe feature-wise alignment scores for better expressive power but only requires\nparallelizable matrix multiplications, and 3) combines multi-head with\nmulti-dimensional attentions, and applies a distinct positional mask to each\nhead (subspace), so the memory and computation can be distributed to multiple\nheads, each with sequential information encoded independently. The experiments\nshow that a CNN/RNN-free model based on MTSA achieves state-of-the-art or\ncompetitive performance on nine NLP benchmarks with compelling memory- and\ntime-efficiency.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 17:16:48 GMT"}, {"version": "v2", "created": "Sun, 6 May 2018 05:49:30 GMT"}, {"version": "v3", "created": "Sun, 9 Sep 2018 06:58:09 GMT"}, {"version": "v4", "created": "Tue, 26 Mar 2019 09:07:00 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Shen", "Tao", ""], ["Zhou", "Tianyi", ""], ["Long", "Guodong", ""], ["Jiang", "Jing", ""], ["Zhang", "Chengqi", ""]]}, {"id": "1805.00983", "submitter": "Aidin Ferdowsi", "authors": "Aidin Ferdowsi, Ursula Challita, Walid Saad, Narayan B. Mandayam", "title": "Robust Deep Reinforcement Learning for Security and Safety in Autonomous\n  Vehicle Systems", "comments": "8 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To operate effectively in tomorrow's smart cities, autonomous vehicles (AVs)\nmust rely on intra-vehicle sensors such as camera and radar as well as\ninter-vehicle communication. Such dependence on sensors and communication links\nexposes AVs to cyber-physical (CP) attacks by adversaries that seek to take\ncontrol of the AVs by manipulating their data. Thus, to ensure safe and optimal\nAV dynamics control, the data processing functions at AVs must be robust to\nsuch CP attacks. To this end, in this paper, the state estimation process for\nmonitoring AV dynamics, in presence of CP attacks, is analyzed and a novel\nadversarial deep reinforcement learning (RL) algorithm is proposed to maximize\nthe robustness of AV dynamics control to CP attacks. The attacker's action and\nthe AV's reaction to CP attacks are studied in a game-theoretic framework. In\nthe formulated game, the attacker seeks to inject faulty data to AV sensor\nreadings so as to manipulate the inter-vehicle optimal safe spacing and\npotentially increase the risk of AV accidents or reduce the vehicle flow on the\nroads. Meanwhile, the AV, acting as a defender, seeks to minimize the\ndeviations of spacing so as to ensure robustness to the attacker's actions.\nSince the AV has no information about the attacker's action and due to the\ninfinite possibilities for data value manipulations, the outcome of the\nplayers' past interactions are fed to long-short term memory (LSTM) blocks.\nEach player's LSTM block learns the expected spacing deviation resulting from\nits own action and feeds it to its RL algorithm. Then, the the attacker's RL\nalgorithm chooses the action which maximizes the spacing deviation, while the\nAV's RL algorithm tries to find the optimal action that minimizes such\ndeviation.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 19:03:37 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 16:13:09 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Ferdowsi", "Aidin", ""], ["Challita", "Ursula", ""], ["Saad", "Walid", ""], ["Mandayam", "Narayan B.", ""]]}, {"id": "1805.01048", "submitter": "Baibhab Chatterjee", "authors": "Baibhab Chatterjee, Debayan Das and Shreyas Sen", "title": "RF-PUF: IoT Security Enhancement through Authentication of Wireless\n  Nodes using In-situ Machine Learning", "comments": "Presented in Hardware Oriented Security and Trust (HOST), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physical unclonable functions (PUF) in silicon exploit die-to-die\nmanufacturing variations during fabrication for uniquely identifying each die.\nSince it is practically a hard problem to recreate exact silicon features\nacross dies, a PUFbased authentication system is robust, secure and\ncost-effective, as long as bias removal and error correction are taken into\naccount. In this work, we utilize the effects of inherent process variation on\nanalog and radio-frequency (RF) properties of multiple wireless transmitters\n(Tx) in a sensor network, and detect the features at the receiver (Rx) using a\ndeep neural network based framework. The proposed mechanism/framework, called\nRF-PUF, harnesses already existing RF communication hardware and does not\nrequire any additional PUF-generation circuitry in the Tx for practical\nimplementation. Simulation results indicate that the RF-PUF framework can\ndistinguish up to 10000 transmitters (with standard foundry defined variations\nfor a 65 nm process, leading to non-idealities such as LO offset and I-Q\nimbalance) under varying channel conditions, with a probability of false\ndetection < 10e-3\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 22:43:03 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Chatterjee", "Baibhab", ""], ["Das", "Debayan", ""], ["Sen", "Shreyas", ""]]}, {"id": "1805.01060", "submitter": "Ziqi Zheng", "authors": "Ziqi Zheng, Chenjie Cao, Xingwei Chen, Guoqiang Xu", "title": "Multimodal Emotion Recognition for One-Minute-Gradual Emotion Challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continuous dimensional emotion modelled by arousal and valence can depict\ncomplex changes of emotions. In this paper, we present our works on arousal and\nvalence predictions for One-Minute-Gradual (OMG) Emotion Challenge. Multimodal\nrepresentations are first extracted from videos using a variety of acoustic,\nvideo and textual models and support vector machine (SVM) is then used for\nfusion of multimodal signals to make final predictions. Our solution achieves\nConcordant Correlation Coefficient (CCC) scores of 0.397 and 0.520 on arousal\nand valence respectively for the validation dataset, which outperforms the\nbaseline systems with the best CCC scores of 0.15 and 0.23 on arousal and\nvalence by a large margin.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 00:10:10 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Zheng", "Ziqi", ""], ["Cao", "Chenjie", ""], ["Chen", "Xingwei", ""], ["Xu", "Guoqiang", ""]]}, {"id": "1805.01109", "submitter": "Tom Everitt", "authors": "Tom Everitt, Gary Lea, Marcus Hutter", "title": "AGI Safety Literature Review", "comments": "Published in International Joint Conference on Artificial\n  Intelligence (IJCAI), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of Artificial General Intelligence (AGI) promises to be a\nmajor event. Along with its many potential benefits, it also raises serious\nsafety concerns (Bostrom, 2014). The intention of this paper is to provide an\neasily accessible and up-to-date collection of references for the emerging\nfield of AGI safety. A significant number of safety problems for AGI have been\nidentified. We list these, and survey recent research on solving them. We also\ncover works on how best to think of AGI from the limited knowledge we have\ntoday, predictions for when AGI will first be created, and what will happen\nafter its creation. Finally, we review the current public policy on AGI.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 04:26:48 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 16:30:20 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Everitt", "Tom", ""], ["Lea", "Gary", ""], ["Hutter", "Marcus", ""]]}, {"id": "1805.01141", "submitter": "Rui Wang", "authors": "Rui Wang, Jeff Clune, and Kenneth O. Stanley", "title": "VINE: An Open Source Interactive Data Visualization Tool for\n  Neuroevolution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in deep neuroevolution have demonstrated that evolutionary\nalgorithms, such as evolution strategies (ES) and genetic algorithms (GA), can\nscale to train deep neural networks to solve difficult reinforcement learning\n(RL) problems. However, it remains a challenge to analyze and interpret the\nunderlying process of neuroevolution in such high dimensions. To begin to\naddress this challenge, this paper presents an interactive data visualization\ntool called VINE (Visual Inspector for NeuroEvolution) aimed at helping\nneuroevolution researchers and end-users better understand and explore this\nfamily of algorithms. VINE works seamlessly with a breadth of neuroevolution\nalgorithms, including ES and GA, and addresses the difficulty of observing the\nunderlying dynamics of the learning process through an interactive\nvisualization of the evolving agent's behavior characterizations over\ngenerations. As neuroevolution scales to neural networks with millions or more\nconnections, visualization tools like VINE that offer fresh insight into the\nunderlying dynamics of evolution become increasingly valuable and important for\ninspiring new innovations and applications.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 07:21:43 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Wang", "Rui", ""], ["Clune", "Jeff", ""], ["Stanley", "Kenneth O.", ""]]}, {"id": "1805.01157", "submitter": "Jiaxu Cui", "authors": "Jiaxu Cui and Bo Yang", "title": "Graph Bayesian Optimization: Algorithms, Evaluations and Applications", "comments": "This work is in progress, and contains 27 pages, 14 figures, an\n  appendix, the contrast algorithm in last experiment ( see Figure 11)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network structure optimization is a fundamental task in complex network\nanalysis. However, almost all the research on Bayesian optimization is aimed at\noptimizing the objective functions with vectorial inputs. In this work, we\nfirst present a flexible framework, denoted graph Bayesian optimization, to\nhandle arbitrary graphs in the Bayesian optimization community. By combining\nthe proposed framework with graph kernels, it can take full advantage of\nimplicit graph structural features to supplement explicit features guessed\naccording to the experience, such as tags of nodes and any attributes of\ngraphs. The proposed framework can identify which features are more important\nduring the optimization process. We apply the framework to solve four problems\nincluding two evaluations and two applications to demonstrate its efficacy and\npotential applications.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 08:13:48 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 13:49:41 GMT"}, {"version": "v3", "created": "Fri, 25 May 2018 08:45:29 GMT"}, {"version": "v4", "created": "Tue, 6 Nov 2018 06:49:13 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Cui", "Jiaxu", ""], ["Yang", "Bo", ""]]}, {"id": "1805.01214", "submitter": "Marius Lindauer", "authors": "Marius Lindauer, Jan N. van Rijn and Lars Kotthoff", "title": "The Algorithm Selection Competitions 2015 and 2017", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The algorithm selection problem is to choose the most suitable algorithm for\nsolving a given problem instance. It leverages the complementarity between\ndifferent approaches that is present in many areas of AI. We report on the\nstate of the art in algorithm selection, as defined by the Algorithm Selection\ncompetitions in 2015 and 2017. The results of these competitions show how the\nstate of the art improved over the years. We show that although performance in\nsome cases is very good, there is still room for improvement in other cases.\nFinally, we provide insights into why some scenarios are hard, and pose\nchallenges to the community on how to advance the current state of the art.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 10:47:31 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 08:58:54 GMT"}], "update_date": "2018-10-05", "authors_parsed": [["Lindauer", "Marius", ""], ["van Rijn", "Jan N.", ""], ["Kotthoff", "Lars", ""]]}, {"id": "1805.01217", "submitter": "Marco Lippi", "authors": "Marco Lippi, Przemyslaw Palka, Giuseppe Contissa, Francesca Lagioia,\n  Hans-Wolfgang Micklitz, Giovanni Sartor, Paolo Torroni", "title": "CLAUDETTE: an Automated Detector of Potentially Unfair Clauses in Online\n  Terms of Service", "comments": null, "journal-ref": "Artif. Intell. Law 27 (2019) 117-139", "doi": "10.1007/s10506-019-09243-2", "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Terms of service of on-line platforms too often contain clauses that are\npotentially unfair to the consumer. We present an experimental study where\nmachine learning is employed to automatically detect such potentially unfair\nclauses. Results show that the proposed system could provide a valuable tool\nfor lawyers and consumers alike.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 10:53:54 GMT"}, {"version": "v2", "created": "Mon, 18 Feb 2019 14:17:02 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Lippi", "Marco", ""], ["Palka", "Przemyslaw", ""], ["Contissa", "Giuseppe", ""], ["Lagioia", "Francesca", ""], ["Micklitz", "Hans-Wolfgang", ""], ["Sartor", "Giovanni", ""], ["Torroni", "Paolo", ""]]}, {"id": "1805.01270", "submitter": "Konstantin Yakovlev S", "authors": "Anton Andreychuk and Konstantin Yakovlev", "title": "Two Techniques That Enhance the Performance of Multi-robot Prioritized\n  Path Planning", "comments": "Camera-ready version of the submitted article (extended abstract) to\n  AAMAS'18 conference (Robotics track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and empirically evaluate two techniques aimed at enhancing the\nperformance of multi-robot prioritized path planning. The first technique is\nthe deterministic procedure for re-scheduling (as opposed to well-known\napproach based on random restarts), the second one is the heuristic procedure\nthat modifies the search-space of the individual planner involved in the\nprioritized path finding.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 12:54:27 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Andreychuk", "Anton", ""], ["Yakovlev", "Konstantin", ""]]}, {"id": "1805.01276", "submitter": "Zied Bouraoui", "authors": "Zied Bouraoui and Steven Schockaert", "title": "Learning Conceptual Space Representations of Interrelated Concepts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several recently proposed methods aim to learn conceptual space\nrepresentations from large text collections. These learned representations\nasso- ciate each object from a given domain of interest with a point in a\nhigh-dimensional Euclidean space, but they do not model the concepts from this\ndo- main, and can thus not directly be used for catego- rization and related\ncognitive tasks. A natural solu- tion is to represent concepts as Gaussians,\nlearned from the representations of their instances, but this can only be\nreliably done if sufficiently many in- stances are given, which is often not\nthe case. In this paper, we introduce a Bayesian model which addresses this\nproblem by constructing informative priors from background knowledge about how\nthe concepts of interest are interrelated with each other. We show that this\nleads to substantially better pre- dictions in a knowledge base completion\ntask.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 13:08:47 GMT"}, {"version": "v2", "created": "Fri, 4 May 2018 07:59:29 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Bouraoui", "Zied", ""], ["Schockaert", "Steven", ""]]}, {"id": "1805.01369", "submitter": "Grigoriy Sterling", "authors": "Grigoriy Sterling, Andrey Belyaev, Maxim Ryabov", "title": "Framewise approach in multimodal emotion recognition in OMG challenge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we described our approach achieves $53\\%$ of unweighted\naccuracy over $7$ emotions and $0.05$ and $0.09$ mean squared errors for\narousal and valence in OMG emotion recognition challenge. Our results were\nobtained with ensemble of single modality models trained on voice and face data\nfrom video separately. We consider each stream as a sequence of frames. Next we\nestimated features from frames and handle it with recurrent neural network. As\naudio frame we mean short $0.4$ second spectrogram interval. For features\nestimation for face pictures we used own ResNet neural network pretrained on\nAffectNet database. Each short spectrogram was considered as a picture and\nprocessed by convolutional network too. As a base audio model we used ResNet\npretrained in speaker recognition task. Predictions from both modalities were\nfused on decision level and improve single-channel approaches by a few percent\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 15:21:44 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Sterling", "Grigoriy", ""], ["Belyaev", "Andrey", ""], ["Ryabov", "Maxim", ""]]}, {"id": "1805.01374", "submitter": "Baibhab Chatterjee", "authors": "Baibhab Chatterjee, Debayan Das, Shovan Maity and Shreyas Sen", "title": "RF-PUF: Enhancing IoT Security through Authentication of Wireless Nodes\n  using In-situ Machine Learning", "comments": "Accepted: in the IEEE Internet of Things Journal (JIoT), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional authentication in radio-frequency (RF) systems enable secure data\ncommunication within a network through techniques such as digital signatures\nand hash-based message authentication codes (HMAC), which suffer from key\nrecovery attacks. State-of-the-art IoT networks such as Nest also use Open\nAuthentication (OAuth 2.0) protocols that are vulnerable to cross-site-recovery\nforgery (CSRF), which shows that these techniques may not prevent an adversary\nfrom copying or modeling the secret IDs or encryption keys using invasive, side\nchannel, learning or software attacks. Physical unclonable functions (PUF), on\nthe other hand, can exploit manufacturing process variations to uniquely\nidentify silicon chips which makes a PUF-based system extremely robust and\nsecure at low cost, as it is practically impossible to replicate the same\nsilicon characteristics across dies. Taking inspiration from human\ncommunication, which utilizes inherent variations in the voice signatures to\nidentify a certain speaker, we present RF- PUF: a deep neural network-based\nframework that allows real-time authentication of wireless nodes, using the\neffects of inherent process variation on RF properties of the wireless\ntransmitters (Tx), detected through in-situ machine learning at the receiver\n(Rx) end. The proposed method utilizes the already-existing asymmetric RF\ncommunication framework and does not require any additional circuitry for PUF\ngeneration or feature extraction. Simulation results involving the process\nvariations in a standard 65 nm technology node, and features such as LO offset\nand I-Q imbalance detected with a neural network having 50 neurons in the\nhidden layer indicate that the framework can distinguish up to 4800\ntransmitters with an accuracy of 99.9% (~ 99% for 10,000 transmitters) under\nvarying channel conditions, and without the need for traditional preambles.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 15:28:44 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 20:15:40 GMT"}, {"version": "v3", "created": "Tue, 19 Jun 2018 02:00:32 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Chatterjee", "Baibhab", ""], ["Das", "Debayan", ""], ["Maity", "Shovan", ""], ["Sen", "Shreyas", ""]]}, {"id": "1805.01388", "submitter": "Rens Wouter van der Heijden", "authors": "Rens Wouter van der Heijden, Henning Kopp, Frank Kargl", "title": "Multi-Source Fusion Operations in Subjective Logic", "comments": "8 pages, Pre-Print of accepted paper for FUSION 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of multi-source fusion is to combine information from more than\ntwo evidence sources, or subjective opinions from multiple actors. For\nsubjective logic, a number of different fusion operators have been proposed,\neach matching a fusion scenario with different assumptions. However, not all of\nthese operators are associative, and therefore multi-source fusion is not\nwell-defined for these settings. In this paper, we address this challenge, and\ndefine multi-source fusion for weighted belief fusion (WBF) and consensus &\ncompromise fusion (CCF). For WBF, we show the definition to be equivalent to\nthe intuitive formulation under the bijective mapping between subjective logic\nand Dirichlet evidence PDFs. For CCF, since there is no independent\ngeneralization, we show that the resulting multi-source fusion produces valid\nopinions, and explain why our generalization is sound. For completeness, we\nalso provide corrections to previous results for averaging and cumulative\nbelief fusion (ABF and CBF), as well as belief constraint fusion (BCF), which\nis an extension of Dempster's rule. With our generalizations of fusion\noperators, fusing information from multiple sources is now well-defined for all\ndifferent fusion types defined in subjective logic. This enables wider\napplicability of subjective logic in applications where multiple actors\ninteract.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 16:02:24 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["van der Heijden", "Rens Wouter", ""], ["Kopp", "Henning", ""], ["Kargl", "Frank", ""]]}, {"id": "1805.01396", "submitter": "David Jaime Tena Cucala", "authors": "David Tena Cucala, Bernardo Cuenca Grau, Ian Horrocks", "title": "Consequence-based Reasoning for Description Logics with Disjunction,\n  Inverse Roles, Number Restrictions, and Nominals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a consequence-based calculus for concept subsumption and\nclassification in the description logic ALCHOIQ, which extends ALC with role\nhierarchies, inverse roles, number restrictions, and nominals. By using\nstandard transformations, our calculus extends to SROIQ, which covers all of\nOWL 2 DL except for datatypes. A key feature of our calculus is its\npay-as-you-go behaviour: unlike existing algorithms, our calculus is worst-case\noptimal for all the well-known proper fragments of ALCHOIQ, albeit not for the\nfull logic.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 16:06:51 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Cucala", "David Tena", ""], ["Grau", "Bernardo Cuenca", ""], ["Horrocks", "Ian", ""]]}, {"id": "1805.01416", "submitter": "Pedro M. Ferreira", "authors": "Pedro M. Ferreira, Diogo Pernes, Kelwin Fernandes, Ana Rebelo and\n  Jaime S. Cardoso", "title": "Dimensional emotion recognition using visual and textual cues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of automatic emotion recognition in the\nscope of the One-Minute Gradual-Emotional Behavior challenge (OMG-Emotion\nchallenge). The underlying objective of the challenge is the automatic\nestimation of emotion expressions in the two-dimensional emotion representation\nspace (i.e., arousal and valence). The adopted methodology is a weighted\nensemble of several models from both video and text modalities. For video-based\nrecognition, two different types of visual cues (i.e., face and facial\nlandmarks) were considered to feed a multi-input deep neural network. Regarding\nthe text modality, a sequential model based on a simple recurrent architecture\nwas implemented. In addition, we also introduce a model based on high-level\nfeatures in order to embed domain knowledge in the learning process.\nExperimental results on the OMG-Emotion validation set demonstrate the\neffectiveness of the implemented ensemble model as it clearly outperforms the\ncurrent baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 16:42:20 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Ferreira", "Pedro M.", ""], ["Pernes", "Diogo", ""], ["Fernandes", "Kelwin", ""], ["Rebelo", "Ana", ""], ["Cardoso", "Jaime S.", ""]]}, {"id": "1805.01452", "submitter": "Dimitrios Kollias", "authors": "Dimitrios Kollias, Stefanos Zafeiriou", "title": "A Multi-component CNN-RNN Approach for Dimensional Emotion Recognition\n  in-the-wild", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.HC eess.IV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents our approach to the One-Minute Gradual-Emotion\nRecognition (OMG-Emotion) Challenge, focusing on dimensional emotion\nrecognition through visual analysis of the provided emotion videos. The\napproach is based on a Convolutional and Recurrent (CNN-RNN) deep neural\narchitecture we have developed for the relevant large AffWild Emotion Database.\nWe extended and adapted this architecture, by letting a combination of multiple\nfeatures generated in the CNN component be explored by RNN subnets. Our target\nhas been to obtain best performance on the OMG-Emotion visual validation data\nset, while learning the respective visual training data set. Extended\nexperimentation has led to best architectures for the estimation of the values\nof the valence and arousal emotion dimensions over these data sets.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 17:54:44 GMT"}, {"version": "v2", "created": "Sun, 6 May 2018 01:01:00 GMT"}, {"version": "v3", "created": "Tue, 8 May 2018 09:43:17 GMT"}, {"version": "v4", "created": "Mon, 12 Nov 2018 23:17:42 GMT"}, {"version": "v5", "created": "Fri, 13 Dec 2019 23:32:41 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Kollias", "Dimitrios", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1805.01509", "submitter": "Saba Al-Sayouri", "authors": "Saba A. Al-Sayouri, Danai Koutra, Evangelos E. Papalexakis, Sarah S.\n  Lam", "title": "RECS: Robust Graph Embedding Using Connection Subgraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of graph embeddings or node representation learning in a variety\nof downstream tasks, such as node classification, link prediction, and\nrecommendation systems, has led to their popularity in recent years.\nRepresentation learning algorithms aim to preserve local and global network\nstructure by identifying node neighborhood notions. However, many existing\nalgorithms generate embeddings that fail to properly preserve the network\nstructure, or lead to unstable representations due to random processes (e.g.,\nrandom walks to generate context) and, thus, cannot generate to multi-graph\nproblems. In this paper, we propose RECS, a novel, stable graph embedding\nalgorithmic framework. RECS learns graph representations using connection\nsubgraphs by employing the analogy of graphs with electrical circuits. It\npreserves both local and global connectivity patterns, and addresses the issue\nof high-degree nodes. Further, it exploits the strength of weak ties and\nmeta-data that have been neglected by baselines. The experiments show that RECS\noutperforms state-of-the-art algorithms by up to 36.85% on multi-label\nclassification problem. Further, in contrast to baselines, RECS, being\ndeterministic, is completely stable.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 18:47:43 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 04:17:46 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 22:18:21 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Al-Sayouri", "Saba A.", ""], ["Koutra", "Danai", ""], ["Papalexakis", "Evangelos E.", ""], ["Lam", "Sarah S.", ""]]}, {"id": "1805.01627", "submitter": "Debabrota Basu", "authors": "Debabrota Basu, Pierre Senellart and St\\'ephane Bressan", "title": "BelMan: Bayesian Bandits on the Belief--Reward Manifold", "comments": "36 pages, 14 figures, accepted in ECML PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We propose a generic, Bayesian, information geometric approach to the\nexploration--exploitation trade-off in multi-armed bandit problems. Our\napproach, BelMan, uniformly supports pure exploration,\nexploration--exploitation, and two-phase bandit problems. The knowledge on\nbandit arms and their reward distributions is summarised by the barycentre of\nthe joint distributions of beliefs and rewards of the arms, the\n\\emph{pseudobelief-reward}, within the beliefs-rewards manifold. BelMan\nalternates \\emph{information projection} and \\emph{reverse information\nprojection}, i.e., projection of the pseudobelief-reward onto beliefs-rewards\nto choose the arm to play, and projection of the resulting beliefs-rewards onto\nthe pseudobelief-reward. It introduces a mechanism that infuses an exploitative\nbias by means of a \\emph{focal distribution}, i.e., a reward distribution that\ngradually concentrates on higher rewards. Comparative performance evaluation\nwith state-of-the-art algorithms shows that BelMan is not only competitive but\ncan also outperform other approaches in specific setups, for instance involving\nmany arms and continuous rewards.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 07:11:53 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 00:25:16 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Basu", "Debabrota", ""], ["Senellart", "Pierre", ""], ["Bressan", "St\u00e9phane", ""]]}, {"id": "1805.01702", "submitter": "Kun Chen", "authors": "Kun Chen, Kechao Cai, Longbo Huang, John C.S. Lui", "title": "Beyond the Click-Through Rate: Web Link Selection with Multi-level\n  Feedback", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web link selection problem is to select a small subset of web links from\na large web link pool, and to place the selected links on a web page that can\nonly accommodate a limited number of links, e.g., advertisements,\nrecommendations, or news feeds. Despite the long concerned click-through rate\nwhich reflects the attractiveness of the link itself, the revenue can only be\nobtained from user actions after clicks, e.g., purchasing after being directed\nto the product pages by recommendation links. Thus, the web links have an\nintrinsic \\emph{multi-level feedback structure}. With this observation, we\nconsider the context-free web link selection problem, where the objective is to\nmaximize revenue while ensuring that the attractiveness is no less than a\npreset threshold. The key challenge of the problem is that each link's\nmulti-level feedbacks are stochastic, and unobservable unless the link is\nselected. We model this problem with a constrained stochastic multi-armed\nbandit formulation, and design an efficient link selection algorithm, called\nConstrained Upper Confidence Bound algorithm (\\textbf{Con-UCB}), and prove\n$O(\\sqrt{T\\ln T})$ bounds on both the regret and the violation of the\nattractiveness constraint. We conduct extensive experiments on three real-world\ndatasets, and show that \\textbf{Con-UCB} outperforms state-of-the-art\ncontext-free bandit algorithms concerning the multi-level feedback structure.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 10:37:27 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Chen", "Kun", ""], ["Cai", "Kechao", ""], ["Huang", "Longbo", ""], ["Lui", "John C. S.", ""]]}, {"id": "1805.01825", "submitter": "Markus Schr\\\"oder", "authors": "Markus Schr\\\"oder and J\\\"orn Hees and Ansgar Bernardi and Daniel Ewert\n  and Peter Klotz and Steffen Stadtm\\\"uller", "title": "Simplified SPARQL REST API - CRUD on JSON Object Graphs via URI Paths", "comments": "5 pages, 2 figures, ESWC 2018 demo paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the Semantic Web community, SPARQL is one of the predominant languages\nto query and update RDF knowledge. However, the complexity of SPARQL, the\nunderlying graph structure and various encodings are common sources of\nconfusion for Semantic Web novices.\n  In this paper we present a general purpose approach to convert any given\nSPARQL endpoint into a simple to use REST API. To lower the initial hurdle, we\nrepresent the underlying graph as an interlinked view of nested JSON objects\nthat can be traversed by the API path.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 09:57:13 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Schr\u00f6der", "Markus", ""], ["Hees", "J\u00f6rn", ""], ["Bernardi", "Ansgar", ""], ["Ewert", "Daniel", ""], ["Klotz", "Peter", ""], ["Stadtm\u00fcller", "Steffen", ""]]}, {"id": "1805.01831", "submitter": "Francesco Conti", "authors": "Daniele Palossi, Antonio Loquercio, Francesco Conti, Eric Flamand,\n  Davide Scaramuzza, Luca Benini", "title": "A 64mW DNN-based Visual Navigation Engine for Autonomous Nano-Drones", "comments": "15 pages, 13 figures, 5 tables, 2 listings, accepted for publication\n  in the IEEE Internet of Things Journal (IEEE IOTJ)", "journal-ref": null, "doi": "10.1109/JIOT.2019.2917066", "report-no": null, "categories": "cs.RO cs.AI cs.NE eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fully-autonomous miniaturized robots (e.g., drones), with artificial\nintelligence (AI) based visual navigation capabilities are extremely\nchallenging drivers of Internet-of-Things edge intelligence capabilities.\nVisual navigation based on AI approaches, such as deep neural networks (DNNs)\nare becoming pervasive for standard-size drones, but are considered out of\nreach for nanodrones with size of a few cm${}^\\mathrm{2}$. In this work, we\npresent the first (to the best of our knowledge) demonstration of a navigation\nengine for autonomous nano-drones capable of closed-loop end-to-end DNN-based\nvisual navigation. To achieve this goal we developed a complete methodology for\nparallel execution of complex DNNs directly on-bard of resource-constrained\nmilliwatt-scale nodes. Our system is based on GAP8, a novel parallel\nultra-low-power computing platform, and a 27 g commercial, open-source\nCrazyFlie 2.0 nano-quadrotor. As part of our general methodology we discuss the\nsoftware mapping techniques that enable the state-of-the-art deep convolutional\nneural network presented in [1] to be fully executed on-board within a strict 6\nfps real-time constraint with no compromise in terms of flight results, while\nall processing is done with only 64 mW on average. Our navigation engine is\nflexible and can be used to span a wide performance range: at its peak\nperformance corner it achieves 18 fps while still consuming on average just\n3.5% of the power envelope of the deployed nano-aircraft.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 15:47:33 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 16:01:07 GMT"}, {"version": "v3", "created": "Mon, 13 May 2019 13:37:53 GMT"}, {"version": "v4", "created": "Tue, 14 May 2019 08:40:00 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Palossi", "Daniele", ""], ["Loquercio", "Antonio", ""], ["Conti", "Francesco", ""], ["Flamand", "Eric", ""], ["Scaramuzza", "Davide", ""], ["Benini", "Luca", ""]]}, {"id": "1805.01837", "submitter": "Mathias Niepert", "authors": "Mathias Niepert and Alberto Garcia-Duran", "title": "Towards a Spectrum of Graph Convolutional Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our ongoing work on understanding the limitations of graph\nconvolutional networks (GCNs) as well as our work on generalizations of graph\nconvolutions for representing more complex node attribute dependencies. Based\non an analysis of GCNs with the help of the corresponding computation graphs,\nwe propose a generalization of existing GCNs where the aggregation operations\nare (a) determined by structural properties of the local neighborhood graphs\nand (b) not restricted to weighted averages. We show that the proposed approach\nis strictly more expressive while requiring only a modest increase in the\nnumber of parameters and computations. We also show that the proposed\ngeneralization is identical to standard convolutional layers when applied to\nregular grid graphs.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 16:13:36 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Niepert", "Mathias", ""], ["Garcia-Duran", "Alberto", ""]]}, {"id": "1805.01890", "submitter": "Kamran Kowsari", "authors": "Kamran Kowsari, Mojtaba Heidarysafa, Donald E. Brown, Kiana Jafari\n  Meimandi, Laura E. Barnes", "title": "RMDL: Random Multimodel Deep Learning for Classification", "comments": "Best Paper award ACM ICISDM", "journal-ref": null, "doi": "10.1145/3206098.3206111", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continually increasing number of complex datasets each year necessitates\never improving machine learning methods for robust and accurate categorization\nof these data. This paper introduces Random Multimodel Deep Learning (RMDL): a\nnew ensemble, deep learning approach for classification. Deep learning models\nhave achieved state-of-the-art results across many domains. RMDL solves the\nproblem of finding the best deep learning structure and architecture while\nsimultaneously improving robustness and accuracy through ensembles of deep\nlearning architectures. RDML can accept as input a variety data to include\ntext, video, images, and symbolic. This paper describes RMDL and shows test\nresults for image and text data including MNIST, CIFAR-10, WOS, Reuters, IMDB,\nand 20newsgroup. These test results show that RDML produces consistently better\nperformance than standard methods over a broad range of data types and\nclassification problems.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 19:36:43 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 16:08:33 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Kowsari", "Kamran", ""], ["Heidarysafa", "Mojtaba", ""], ["Brown", "Donald E.", ""], ["Meimandi", "Kiana Jafari", ""], ["Barnes", "Laura E.", ""]]}, {"id": "1805.01907", "submitter": "Yunhao Tang", "authors": "Yunhao Tang and Shipra Agrawal", "title": "Exploration by Distributional Reinforcement Learning", "comments": "IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework based on distributional reinforcement learning and\nrecent attempts to combine Bayesian parameter updates with deep reinforcement\nlearning. We show that our proposed framework conceptually unifies multiple\nprevious methods in exploration. We also derive a practical algorithm that\nachieves efficient exploration on challenging control tasks.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 18:07:21 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 16:57:32 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Tang", "Yunhao", ""], ["Agrawal", "Shipra", ""]]}, {"id": "1805.01954", "submitter": "Faraz Torabi", "authors": "Faraz Torabi, Garrett Warnell, Peter Stone", "title": "Behavioral Cloning from Observation", "comments": "International Joint Conference on Artificial Intelligence (IJCAI\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Humans often learn how to perform tasks via imitation: they observe others\nperform a task, and then very quickly infer the appropriate actions to take\nbased on their observations. While extending this paradigm to autonomous agents\nis a well-studied problem in general, there are two particular aspects that\nhave largely been overlooked: (1) that the learning is done from observation\nonly (i.e., without explicit action information), and (2) that the learning is\ntypically done very quickly. In this work, we propose a two-phase, autonomous\nimitation learning technique called behavioral cloning from observation (BCO),\nthat aims to provide improved performance with respect to both of these\naspects. First, we allow the agent to acquire experience in a self-supervised\nfashion. This experience is used to develop a model which is then utilized to\nlearn a particular task by observing an expert perform that task without the\nknowledge of the specific actions taken. We experimentally compare BCO to\nimitation learning methods, including the state-of-the-art, generative\nadversarial imitation learning (GAIL) technique, and we show comparable task\nperformance in several different simulation domains while exhibiting increased\nlearning speed after expert trajectories become available.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 22:36:58 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 21:48:52 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Torabi", "Faraz", ""], ["Warnell", "Garrett", ""], ["Stone", "Peter", ""]]}, {"id": "1805.01956", "submitter": "Michael Everett", "authors": "Michael Everett, Yu Fan Chen, Jonathan P. How", "title": "Motion Planning Among Dynamic, Decision-Making Agents with Deep\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots that navigate among pedestrians use collision avoidance algorithms to\nenable safe and efficient operation. Recent works present deep reinforcement\nlearning as a framework to model the complex interactions and cooperation.\nHowever, they are implemented using key assumptions about other agents'\nbehavior that deviate from reality as the number of agents in the environment\nincreases. This work extends our previous approach to develop an algorithm that\nlearns collision avoidance among a variety of types of dynamic agents without\nassuming they follow any particular behavior rules. This work also introduces a\nstrategy using LSTM that enables the algorithm to use observations of an\narbitrary number of other agents, instead of previous methods that have a fixed\nobservation size. The proposed algorithm outperforms our previous approach in\nsimulation as the number of agents increases, and the algorithm is demonstrated\non a fully autonomous robotic vehicle traveling at human walking speed, without\nthe use of a 3D Lidar.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 22:45:08 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Everett", "Michael", ""], ["Chen", "Yu Fan", ""], ["How", "Jonathan P.", ""]]}, {"id": "1805.01960", "submitter": "Joshua Brul\\'e", "authors": "Joshua Brul\\'e", "title": "Causal programming: inference with structural causal models as finding\n  instances of a relation", "comments": "30 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a causal inference relation and causal programming as\ngeneral frameworks for causal inference with structural causal models. A tuple,\n$\\langle M, I, Q, F \\rangle$, is an instance of the relation if a formula, $F$,\ncomputes a causal query, $Q$, as a function of known population probabilities,\n$I$, in every model entailed by a set of model assumptions, $M$. Many problems\nin causal inference can be viewed as the problem of enumerating instances of\nthe relation that satisfy given criteria. This unifies a number of previously\nstudied problems, including causal effect identification, causal discovery and\nrecovery from selection bias. In addition, the relation supports formalizing\nnew problems in causal inference with structural causal models, such as the\nproblem of research design. Causal programming is proposed as a further\ngeneralization of causal inference as the problem of finding optimal instances\nof the relation, with respect to a cost function.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 23:14:36 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Brul\u00e9", "Joshua", ""]]}, {"id": "1805.01987", "submitter": "Zheyuan Ryan Shi", "authors": "Zheyuan Ryan Shi, Ziye Tang, Long Tran-Thanh, Rohit Singh, Fei Fang", "title": "Designing the Game to Play: Optimizing Payoff Structure in Security\n  Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective game-theoretic modeling of defender-attacker behavior is becoming\nincreasingly important. In many domains, the defender functions not only as a\nplayer but also the designer of the game's payoff structure. We study\nStackelberg Security Games where the defender, in addition to allocating\ndefensive resources to protect targets from the attacker, can strategically\nmanipulate the attacker's payoff under budget constraints in weighted L^p-norm\nform regarding the amount of change. Focusing on problems with weighted\nL^1-norm form constraint, we present (i) a mixed integer linear program-based\nalgorithm with approximation guarantee; (ii) a branch-and-bound based algorithm\nwith improved efficiency achieved by effective pruning; (iii) a polynomial time\napproximation scheme for a special but practical class of problems. In\naddition, we show that problems under budget constraints in L^0-norm form and\nweighted L^\\infty-norm form can be solved in polynomial time. We provide an\nextensive experimental evaluation of our proposed algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 03:07:19 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 04:32:52 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Shi", "Zheyuan Ryan", ""], ["Tang", "Ziye", ""], ["Tran-Thanh", "Long", ""], ["Singh", "Rohit", ""], ["Fang", "Fei", ""]]}, {"id": "1805.02070", "submitter": "Yu-Jhe Li", "authors": "Yu-Jhe Li, Hsin-Yu Chang, Yu-Jing Lin, Po-Wei Wu, and Yu-Chiang Frank\n  Wang", "title": "Deep Reinforcement Learning for Playing 2.5D Fighting Games", "comments": "ICIP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning has shown its success in game playing. However,\n2.5D fighting games would be a challenging task to handle due to ambiguity in\nvisual appearances like height or depth of the characters. Moreover, actions in\nsuch games typically involve particular sequential action orders, which also\nmakes the network design very difficult. Based on the network of Asynchronous\nAdvantage Actor-Critic (A3C), we create an OpenAI-gym-like gaming environment\nwith the game of Little Fighter 2 (LF2), and present a novel A3C+ network for\nlearning RL agents. The introduced model includes a Recurrent Info network,\nwhich utilizes game-related info features with recurrent layers to observe\ncombo skills for fighting. In the experiments, we consider LF2 in different\nsettings, which successfully demonstrates the use of our proposed model for\nlearning 2.5D fighting games.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 15:34:03 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Li", "Yu-Jhe", ""], ["Chang", "Hsin-Yu", ""], ["Lin", "Yu-Jing", ""], ["Wu", "Po-Wei", ""], ["Wang", "Yu-Chiang Frank", ""]]}, {"id": "1805.02102", "submitter": "Maria Luisa Damiani", "authors": "Maria Luisa Damiani, Fatima Hachem, Issa Hamza, Nathan Ranc, Paul\n  Moorcroft, Francesca Cagnacci", "title": "Cluster-based trajectory segmentation with local noise", "comments": "41 pages, Data Mining and Knowledge Discovery (2018)", "journal-ref": "Data Mining and Knowledge Discovery, 2018, Vol 32, Issue 4,\n  1017-1055", "doi": "10.1007/s10618-018-0561-2", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework for the partitioning of a spatial trajectory in a\nsequence of segments based on spatial density and temporal criteria. The result\nis a set of temporally separated clusters interleaved by sub-sequences of\nunclustered points. A major novelty is the proposal of an outlier or noise\nmodel based on the distinction between intra-cluster (local noise) and\ninter-cluster noise (transition): the local noise models the temporary absence\nfrom a residence while the transition the definitive departure towards a next\nresidence. We analyze in detail the properties of the model and present a\ncomprehensive solution for the extraction of temporally ordered clusters. The\neffectiveness of the solution is evaluated first qualitatively and next\nquantitatively by contrasting the segmentation with ground truth. The ground\ntruth consists of a set of trajectories of labeled points simulating animal\nmovement. Moreover, we show that the approach can streamline the discovery of\nadditional derived patterns, by presenting a novel technique for the analysis\nof periodic movement. From a methodological perspective, a valuable aspect of\nthis research is that it combines the theoretical investigation with the\napplication and external validation of the segmentation framework. This paves\nthe way to an effective deployment of the solution in broad and challenging\nfields such as e-science.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 18:46:46 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Damiani", "Maria Luisa", ""], ["Hachem", "Fatima", ""], ["Hamza", "Issa", ""], ["Ranc", "Nathan", ""], ["Moorcroft", "Paul", ""], ["Cagnacci", "Francesca", ""]]}, {"id": "1805.02114", "submitter": "Mansur Arief", "authors": "Mansur Arief, Peter Glynn, Ding Zhao", "title": "An Accelerated Approach to Safely and Efficiently Test Pre-Production\n  Autonomous Vehicles on Public Streets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various automobile and mobility companies, for instance Ford, Uber and Waymo,\nare currently testing their pre-produced autonomous vehicle (AV) fleets on the\npublic roads. However, due to rareness of the safety-critical cases and,\neffectively, unlimited number of possible traffic scenarios, these on-road\ntesting efforts have been acknowledged as tedious, costly, and risky. In this\nstudy, we propose Accelerated De- ployment framework to safely and efficiently\nestimate the AVs performance on public streets. We showed that by appropriately\naddressing the gradual accuracy improvement and adaptively selecting meaningful\nand safe environment under which the AV is deployed, the proposed framework\nyield to highly accurate estimation with much faster evaluation time, and more\nimportantly, lower deployment risk. Our findings provide an answer to the\ncurrently heated and active discussions on how to properly test AV performance\non public roads so as to achieve safe, efficient, and statistically-reliable\ntesting framework for AV technologies.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2018 20:56:03 GMT"}, {"version": "v2", "created": "Sun, 9 Sep 2018 02:02:51 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Arief", "Mansur", ""], ["Glynn", "Peter", ""], ["Zhao", "Ding", ""]]}, {"id": "1805.02181", "submitter": "Christian Jilek", "authors": "Christian Jilek, Markus Schr\\\"oder, Sven Schwarz, Heiko Maus, Andreas\n  Dengel", "title": "Context Spaces as the Cornerstone of a Near-Transparent &\n  Self-Reorganizing Semantic Desktop", "comments": "5 pages, 2 figures (high-res versions in attachments), 1 demo video\n  (in attachments)", "journal-ref": "The Semantic Web: ESWC 2018 Satellite Events, pp. 89-94, Springer", "doi": "10.1007/978-3-319-98192-5_17", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Semantic Desktops are still reproached for being too complicated to\nuse or not scaling well. Besides, a real \"killer app\" is still missing. In this\npaper, we present a new prototype inspired by NEPOMUK and its successors having\na semantic graph and ontologies as its basis. In addition, we introduce the\nidea of context spaces that users can directly interact with and work on. To\nmake them available in all applications without further ado, the system is\ntransparently integrated using mostly standard protocols complemented by a\nsidebar for advanced features. By exploiting collected context information and\napplying Managed Forgetting features (like hiding, condensation or deletion),\nthe system is able to dynamically reorganize itself, which also includes a kind\nof tidy-up-itself functionality. We therefore expect it to be more scalable\nwhile providing new levels of user support. An early prototype has been\nimplemented and is presented in this demo.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 10:07:13 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Jilek", "Christian", ""], ["Schr\u00f6der", "Markus", ""], ["Schwarz", "Sven", ""], ["Maus", "Heiko", ""], ["Dengel", "Andreas", ""]]}, {"id": "1805.02205", "submitter": "Ruiwei Wang", "authors": "Ruiwei Wang, Wei Xia and Roland H. C. Yap", "title": "Correlation Heuristics for Constraint Programming", "comments": "Paper presented at the 29th IEEE International Conference on Tools\n  with Artificial Intelligence, ICTAI 2017, Boston, Massachusetts, USA,\n  November 6-8, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective general-purpose search strategies are an important component in\nConstraint Programming. We introduce a new idea, namely, using correlations\nbetween variables to guide search. Variable correlations are measured and\nmaintained by using domain changes during constraint propagation. We propose\ntwo variable heuristics based on the correlation matrix, crbs-sum and crbs-max.\nWe evaluate our correlation heuristics with well known heuristics, namely,\ndom/wdeg, impact-based search and activity-based search. Experiments on a large\nset of benchmarks show that our correlation heuristics are competitive with the\nother heuristics, and can be the fastest on many series.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 13:09:17 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 08:36:58 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Wang", "Ruiwei", ""], ["Xia", "Wei", ""], ["Yap", "Roland H. C.", ""]]}, {"id": "1805.02241", "submitter": "Juliao Braga", "authors": "Juliao Braga and Nizam Omar and Luciana F. Thome", "title": "Acquisition and use of knowledge over a restricted domain by intelligent\n  agents", "comments": "5 pages", "journal-ref": null, "doi": "10.1145/3077286.3077293", "report-no": null, "categories": "cs.AI cs.MA cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This short paper provides a description of an architecture to acquisition and\nuse of knowledge by intelligent agents over a restricted domain of the Internet\nInfrastructure. The proposed architecture is added to an intelligent agent\ndeployment model over a very useful server for Internet Autonomous System\nadministrators. Such servers, which are heavily dependent on arbitrary and\neventual updates of human beings, become unreliable. This is a position paper\nthat proposes three research questions that are still in progress.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 16:32:19 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Braga", "Juliao", ""], ["Omar", "Nizam", ""], ["Thome", "Luciana F.", ""]]}, {"id": "1805.02264", "submitter": "Alex Cheng", "authors": "Alex Cheng and Jules White", "title": "Automated Diagnosis of Clinic Workflows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outpatient clinics often run behind schedule due to patients who arrive late\nor appointments that run longer than expected. We sought to develop a\ngeneralizable method that would allow healthcare providers to diagnose problems\nin workflow that disrupt the schedule on any given provider clinic day. We use\na constraint optimization problem to identify the least number of appointment\nmodifications that make the rest of the schedule run on-time. We apply this\nmethod to an outpatient clinic at Vanderbilt. For patient seen in this clinic\nbetween March 27, 2017 and April 21, 2017, long cycle times tended to affect\nthe overall schedule more than late patients. Results from this workflow\ndiagnosis method could be used to inform interventions to help clinics run\nsmoothly, thus decreasing patient wait times and increasing provider\nutilization.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 18:43:34 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Cheng", "Alex", ""], ["White", "Jules", ""]]}, {"id": "1805.02279", "submitter": "Naji Khosravan", "authors": "Naji Khosravan and Ulas Bagci", "title": "S4ND: Single-Shot Single-Scale Lung Nodule Detection", "comments": "Accepted for publication at MICCAI 2018 (21st International\n  Conference on Medical Image Computing and Computer Assisted Intervention)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state of the art lung nodule detection studies rely on computationally\nexpensive multi-stage frameworks to detect nodules from CT scans. To address\nthis computational challenge and provide better performance, in this paper we\npropose S4ND, a new deep learning based method for lung nodule detection. Our\napproach uses a single feed forward pass of a single network for detection and\nprovides better performance when compared to the current literature. The whole\ndetection pipeline is designed as a single $3D$ Convolutional Neural Network\n(CNN) with dense connections, trained in an end-to-end manner. S4ND does not\nrequire any further post-processing or user guidance to refine detection\nresults. Experimentally, we compared our network with the current\nstate-of-the-art object detection network (SSD) in computer vision as well as\nthe state-of-the-art published method for lung nodule detection (3D DCNN). We\nused publically available $888$ CT scans from LUNA challenge dataset and showed\nthat the proposed method outperforms the current literature both in terms of\nefficiency and accuracy by achieving an average FROC-score of $0.897$. We also\nprovide an in-depth analysis of our proposed network to shed light on the\nunclear paradigms of tiny object detection.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 21:32:14 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 18:26:28 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Khosravan", "Naji", ""], ["Bagci", "Ulas", ""]]}, {"id": "1805.02290", "submitter": "Zahra Riahi Samani", "authors": "Zahra Riahi Samani, Mehrnoush Shamsfard", "title": "The State of the Art in Developing Fuzzy Ontologies: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conceptual formalism supported by typical ontologies may not be sufficient to\nrepresent uncertainty information which is caused due to the lack of clear cut\nboundaries between concepts of a domain. Fuzzy ontologies are proposed to offer\na way to deal with this uncertainty. This paper describes the state of the art\nin developing fuzzy ontologies. The survey is produced by studying about 35\nworks on developing fuzzy ontologies from a batch of 100 articles in the field\nof fuzzy ontologies.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 22:59:22 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Samani", "Zahra Riahi", ""], ["Shamsfard", "Mehrnoush", ""]]}, {"id": "1805.02356", "submitter": "Jieli Zhou", "authors": "Xin Qian, Ziyi Zhong, Jieli Zhou", "title": "Multimodal Machine Translation with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.MA cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal machine translation is one of the applications that integrates\ncomputer vision and language processing. It is a unique task given that in the\nfield of machine translation, many state-of-the-arts algorithms still only\nemploy textual information. In this work, we explore the effectiveness of\nreinforcement learning in multimodal machine translation. We present a novel\nalgorithm based on the Advantage Actor-Critic (A2C) algorithm that specifically\ncater to the multimodal machine translation task of the EMNLP 2018 Third\nConference on Machine Translation (WMT18). We experiment our proposed algorithm\non the Multi30K multilingual English-German image description dataset and the\nFlickr30K image entity dataset. Our model takes two channels of inputs, image\nand text, uses translation evaluation metrics as training rewards, and achieves\nbetter results than supervised learning MLE baseline models. Furthermore, we\ndiscuss the prospects and limitations of using reinforcement learning for\nmachine translation. Our experiment results suggest a promising reinforcement\nlearning solution to the general task of multimodal sequence to sequence\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 06:12:32 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Qian", "Xin", ""], ["Zhong", "Ziyi", ""], ["Zhou", "Jieli", ""]]}, {"id": "1805.02363", "submitter": "Martin Mladenov", "authors": "Craig Boutilier, Alon Cohen, Amit Daniely, Avinatan Hassidim, Yishay\n  Mansour, Ofer Meshi, Martin Mladenov, Dale Schuurmans", "title": "Planning and Learning with Stochastic Action Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many practical uses of reinforcement learning (RL) the set of actions\navailable at a given state is a random variable, with realizations governed by\nan exogenous stochastic process. Somewhat surprisingly, the foundations for\nsuch sequential decision processes have been unaddressed. In this work, we\nformalize and investigate MDPs with stochastic action sets (SAS-MDPs) to\nprovide these foundations. We show that optimal policies and value functions in\nthis model have a structure that admits a compact representation. From an RL\nperspective, we show that Q-learning with sampled action sets is sound. In\nmodel-based settings, we consider two important special cases: when individual\nactions are available with independent probabilities; and a sampling-based\nmodel for unknown distributions. We develop poly-time value and policy\niteration methods for both cases; and in the first, we offer a poly-time linear\nprogramming solution.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 06:48:41 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 19:31:44 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Boutilier", "Craig", ""], ["Cohen", "Alon", ""], ["Daniely", "Amit", ""], ["Hassidim", "Avinatan", ""], ["Mansour", "Yishay", ""], ["Meshi", "Ofer", ""], ["Mladenov", "Martin", ""], ["Schuurmans", "Dale", ""]]}, {"id": "1805.02393", "submitter": "Nikos Voskarides", "authors": "Nikos Voskarides, and Edgar Meij, and Ridho Reinanda, and Abhinav\n  Khaitan, and Miles Osborne, and Giorgio Stefanoni, and Prabhanjan Kambadur,\n  and Maarten de Rijke", "title": "Weakly-supervised Contextualization of Knowledge Graph Facts", "comments": "SIGIR 2018: 41st international ACM SIGIR conference on Research and\n  Development in Information Retrieval. July version: corrected typos", "journal-ref": null, "doi": "10.1145/3209978.3210031", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) model facts about the world, they consist of nodes\n(entities such as companies and people) that are connected by edges (relations\nsuch as founderOf). Facts encoded in KGs are frequently used by search\napplications to augment result pages. When presenting a KG fact to the user,\nproviding other facts that are pertinent to that main fact can enrich the user\nexperience and support exploratory information needs. KG fact contextualization\nis the task of augmenting a given KG fact with additional and useful KG facts.\nThe task is challenging because of the large size of KGs, discovering other\nrelevant facts even in a small neighborhood of the given fact results in an\nenormous amount of candidates. We introduce a neural fact contextualization\nmethod (NFCM) to address the KG fact contextualization task. NFCM first\ngenerates a set of candidate facts in the neighborhood of a given fact and then\nranks the candidate facts using a supervised learning to rank model. The\nranking model combines features that we automatically learn from data and that\nrepresent the query-candidate facts with a set of hand-crafted features we\ndevised or adjusted for this task. In order to obtain the annotations required\nto train the learning to rank model at scale, we generate training data\nautomatically using distant supervision on a large entity-tagged text corpus.\nWe show that ranking functions learned on this data are effective at\ncontextualizing KG facts. Evaluation using human assessors shows that it\nsignificantly outperforms several competitive baselines.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 08:22:57 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2018 21:04:52 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Voskarides", "Nikos", ""], ["Meij", "Edgar", ""], ["Reinanda", "Ridho", ""], ["Khaitan", "Abhinav", ""], ["Osborne", "Miles", ""], ["Stefanoni", "Giorgio", ""], ["Kambadur", "Prabhanjan", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1805.02404", "submitter": "Harrie Oosterhuis", "authors": "Harrie Oosterhuis and Maarten de Rijke", "title": "Ranking for Relevance and Display Preferences in Complex Presentation\n  Layouts", "comments": null, "journal-ref": null, "doi": "10.1145/3209978.3209992", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to Rank has traditionally considered settings where given the\nrelevance information of objects, the desired order in which to rank the\nobjects is clear. However, with today's large variety of users and layouts this\nis not always the case. In this paper, we consider so-called complex ranking\nsettings where it is not clear what should be displayed, that is, what the\nrelevant items are, and how they should be displayed, that is, where the most\nrelevant items should be placed. These ranking settings are complex as they\ninvolve both traditional ranking and inferring the best display order. Existing\nlearning to rank methods cannot handle such complex ranking settings as they\nassume that the display order is known beforehand. To address this gap we\nintroduce a novel Deep Reinforcement Learning method that is capable of\nlearning complex rankings, both the layout and the best ranking given the\nlayout, from weak reward signals. Our proposed method does so by selecting\ndocuments and positions sequentially, hence it ranks both the documents and\npositions, which is why we call it the Double-Rank Model (DRM). Our experiments\nshow that DRM outperforms all existing methods in complex ranking settings,\nthus it leads to substantial ranking improvements in cases where the display\norder is not known a priori.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 08:48:18 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Oosterhuis", "Harrie", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1805.02408", "submitter": "Shu Guo", "authors": "Boyang Ding, Quan Wang, Bin Wang, Li Guo", "title": "Improving Knowledge Graph Embedding Using Simple Constraints", "comments": "To appear in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding knowledge graphs (KGs) into continuous vector spaces is a focus of\ncurrent research. Early works performed this task via simple models developed\nover KG triples. Recent attempts focused on either designing more complicated\ntriple scoring models, or incorporating extra information beyond triples. This\npaper, by contrast, investigates the potential of using very simple constraints\nto improve KG embedding. We examine non-negativity constraints on entity\nrepresentations and approximate entailment constraints on relation\nrepresentations. The former help to learn compact and interpretable\nrepresentations for entities. The latter further encode regularities of logical\nentailment between relations into their distributed representations. These\nconstraints impose prior beliefs upon the structure of the embedding space,\nwithout negative impacts on efficiency or scalability. Evaluation on WordNet,\nFreebase, and DBpedia shows that our approach is simple yet surprisingly\neffective, significantly and consistently outperforming competitive baselines.\nThe constraints imposed indeed improve model interpretability, leading to a\nsubstantially increased structuring of the embedding space. Code and data are\navailable at https://github.com/iieir-km/ComplEx-NNE_AER.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 09:03:14 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 03:30:46 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Ding", "Boyang", ""], ["Wang", "Quan", ""], ["Wang", "Bin", ""], ["Guo", "Li", ""]]}, {"id": "1805.02682", "submitter": "Karl Schmitt", "authors": "James P. Canning, Emma E. Ingram, Sammantha Nowak-Wolff, Adriana M.\n  Ortiz, Nesreen K. Ahmed, Ryan A. Rossi, Karl R. B. Schmitt, and Sucheta\n  Soundarajan", "title": "Predicting Graph Categories from Structural Properties", "comments": "This submission has been withdrawn by one of the authors due to an\n  unresolved conflict between the authors. This version of the article did not\n  receive consent for posting to arXiv.org from authors: Karl R. B. Schmitt,\n  Sucheta Soundarajan, James P. Canning, Emma E. Ingram, Sammantha Nowak-Wolff,\n  Adriana M. Ortiz", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper has been withdrawn from arXiv.org due to a disagreement among the\nauthors related to several peer-review comments received prior to submission on\narXiv.org. Even though the current version of this paper is withdrawn, there\nwas no disagreement between authors on the novel work in this paper.\n  One specific issue was the discussion of related work by Ikehara \\& Clauset\n(found on page 8 of the previously posted version). Peer-review comments on a\nsimilar version made ALL authors aware that the discussion misrepresented their\nwork prior to submission to arXiv.org. However, some authors choose to post to\narXiv a minimally updated version without the consent of all authors or\nproperly addressing this attribution issue. ================ Original Paper\nAbstract: Complex networks are often categorized according to the underlying\nphenomena that they represent such as molecular interactions, re-tweets, and\nbrain activity. In this work, we investigate the problem of predicting the\ncategory (domain) of arbitrary networks. This includes complex networks from\ndifferent domains as well as synthetically generated graphs from five different\nnetwork models. A classification accuracy of $96.6\\%$ is achieved using a\nrandom forest classifier with both real and synthetic networks. This work makes\ntwo important findings. First, our results indicate that complex networks from\nvarious domains have distinct structural properties that allow us to predict\nwith high accuracy the category of a new previously unseen network. Second,\nsynthetic graphs are trivial to classify as the classification model can\npredict with near-certainty the network model used to generate it. Overall, the\nresults demonstrate that networks drawn from different domains (and network\nmodels) are trivial to distinguish using only a handful of simple structural\nproperties.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 18:22:51 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 17:47:24 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Canning", "James P.", ""], ["Ingram", "Emma E.", ""], ["Nowak-Wolff", "Sammantha", ""], ["Ortiz", "Adriana M.", ""], ["Ahmed", "Nesreen K.", ""], ["Rossi", "Ryan A.", ""], ["Schmitt", "Karl R. B.", ""], ["Soundarajan", "Sucheta", ""]]}, {"id": "1805.02686", "submitter": "Evangelos Pournaras", "authors": "Evangelos Pournaras, Srivatsan Yadhunathan, Ada Diaconescu", "title": "Holarchic Structures for Decentralized Deep Learning - A Performance\n  Analysis", "comments": null, "journal-ref": null, "doi": "10.1007/s10586-019-02906-4", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structure plays a key role in learning performance. In centralized\ncomputational systems, hyperparameter optimization and regularization\ntechniques such as dropout are computational means to enhance learning\nperformance by adjusting the deep hierarchical structure. However, in\ndecentralized deep learning by the Internet of Things, the structure is an\nactual network of autonomous interconnected devices such as smart phones that\ninteract via complex network protocols. Self-adaptation of the learning\nstructure is a challenge. Uncertainties such as network latency, node and link\nfailures or even bottlenecks by limited processing capacity and energy\navailability can signif- icantly downgrade learning performance. Network\nself-organization and self-management is complex, while it requires additional\ncomputational and network resources that hinder the feasibility of\ndecentralized deep learning. In contrast, this paper introduces a self-adaptive\nlearning approach based on holarchic learning structures for exploring,\nmitigating and boosting learning performance in distributed environments with\nuncertainties. A large-scale performance analysis with 864000 experiments fed\nwith synthetic and real-world data from smart grid and smart city pilot\nprojects confirm the cost-effectiveness of holarchic structures for\ndecentralized deep learning.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 18:33:43 GMT"}, {"version": "v2", "created": "Mon, 17 Sep 2018 21:51:57 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Pournaras", "Evangelos", ""], ["Yadhunathan", "Srivatsan", ""], ["Diaconescu", "Ada", ""]]}, {"id": "1805.02716", "submitter": "Eliu Huerta", "authors": "E. A. Huerta, Daniel George, Zhizhen Zhao and Gabrielle Allen", "title": "Real-time regression analysis with deep convolutional neural networks", "comments": "3 pages. Position Paper accepted to SciML2018: DOE ASCR Workshop on\n  Scientific Machine Learning. North Bethesda, MD, United States, January\n  30-February 1, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG astro-ph.IM cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the development of novel deep learning algorithms to enable\nreal-time regression analysis for time series data. We showcase the application\nof this new method with a timely case study, and then discuss the applicability\nof this approach to tackle similar challenges across science domains.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 19:43:26 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Huerta", "E. A.", ""], ["George", "Daniel", ""], ["Zhao", "Zhizhen", ""], ["Allen", "Gabrielle", ""]]}, {"id": "1805.02754", "submitter": "Thomio Watanabe", "authors": "Thomio Watanabe and Denis Wolf", "title": "Verisimilar Percept Sequences Tests for Autonomous Driving Intelligent\n  Agent Assessment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The autonomous car technology promises to replace human drivers with safer\ndriving systems. But although autonomous cars can become safer than human\ndrivers this is a long process that is going to be refined over time. Before\nthese vehicles are deployed on urban roads a minimum safety level must be\nassured. Since the autonomous car technology is still under development there\nis no standard methodology to evaluate such systems. It is important to\ncompletely understand the technology that is being developed to design\nefficient means to evaluate it. In this paper we assume safety-critical systems\nreliability as a safety measure. We model an autonomous road vehicle as an\nintelligent agent and we approach its evaluation from an artificial\nintelligence perspective. Our focus is the evaluation of perception and\ndecision making systems and also to propose a systematic method to evaluate\ntheir integration in the vehicle. We identify critical aspects of the data\ndependency from the artificial intelligence state of the art models and we also\npropose procedures to reproduce them.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 21:32:56 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Watanabe", "Thomio", ""], ["Wolf", "Denis", ""]]}, {"id": "1805.02785", "submitter": "Joshua Bertram", "authors": "Joshua R. Bertram, Xuxi Yang, and Peng Wei", "title": "Fast Online Exact Solutions for Deterministic MDPs with Sparse Rewards", "comments": "Submitted to NIPS 2018; preprint version posted here. 8 pages\n  content, appendices include pseudocode and proof for algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov Decision Processes (MDPs) are a mathematical framework for modeling\nsequential decision making under uncertainty. The classical approaches for\nsolving MDPs are well known and have been widely studied, some of which rely on\napproximation techniques to solve MDPs with large state space and/or action\nspace. However, most of these classical solution approaches and their\napproximation techniques still take much computation time to converge and\nusually must be re-computed if the reward function is changed. This paper\nintroduces a novel alternative approach for exactly and efficiently solving\ndeterministic, continuous MDPs with sparse reward sources. When the environment\nis such that the \"distance\" between states can be determined in constant time,\ne.g. grid world, our algorithm offers $O( |R|^2 \\times |A|^2 \\times |S|)$,\nwhere $|R|$ is the number of reward sources, $|A|$ is the number of actions,\nand $|S|$ is the number of states. Memory complexity for the algorithm is $O(\n|S| + |R| \\times |A|)$. This new approach opens new avenues for boosting\ncomputational performance for certain classes of MDPs and is of tremendous\nvalue for MDP applications such as robotics and unmanned systems. This paper\ndescribes the algorithm and presents numerical experiment results to\ndemonstrate its powerful computational performance. We also provide rigorous\nmathematical description of the approach.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 00:12:43 GMT"}, {"version": "v2", "created": "Wed, 9 May 2018 12:48:00 GMT"}, {"version": "v3", "created": "Thu, 17 May 2018 15:55:27 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Bertram", "Joshua R.", ""], ["Yang", "Xuxi", ""], ["Wei", "Peng", ""]]}, {"id": "1805.02856", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui, Jian Su", "title": "Reasoning with Sarcasm by Reading In-between", "comments": "Accepted to ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sarcasm is a sophisticated speech act which commonly manifests on social\ncommunities such as Twitter and Reddit. The prevalence of sarcasm on the social\nweb is highly disruptive to opinion mining systems due to not only its tendency\nof polarity flipping but also usage of figurative language. Sarcasm commonly\nmanifests with a contrastive theme either between positive-negative sentiments\nor between literal-figurative scenarios. In this paper, we revisit the notion\nof modeling contrast in order to reason with sarcasm. More specifically, we\npropose an attention-based neural model that looks in-between instead of\nacross, enabling it to explicitly model contrast and incongruity. We conduct\nextensive experiments on six benchmark datasets from Twitter, Reddit and the\nInternet Argument Corpus. Our proposed model not only achieves state-of-the-art\nperformance on all datasets but also enjoys improved interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 06:46:03 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""], ["Su", "Jian", ""]]}, {"id": "1805.02859", "submitter": "Duligur Ibeling", "authors": "Duligur Ibeling, Thomas Icard", "title": "On the Conditional Logic of Simulation Models", "comments": "IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose analyzing conditional reasoning by appeal to a notion of\nintervention on a simulation program, formalizing and subsuming a number of\napproaches to conditional thinking in the recent AI literature. Our main\nresults include a series of axiomatizations, allowing comparison between this\nframework and existing frameworks (normality-ordering models, causal structural\nequation models), and a complexity result establishing NP-completeness of the\nsatisfiability problem. Perhaps surprisingly, some of the basic logical\nprinciples common to all existing approaches are invalidated in our causal\nsimulation approach. We suggest that this additional flexibility is important\nin modeling some intuitive examples.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 07:08:13 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Ibeling", "Duligur", ""], ["Icard", "Thomas", ""]]}, {"id": "1805.02861", "submitter": "Anton\\'in Ku\\v{c}era", "authors": "Tom\\'a\\v{s} Br\\'azdil, Anton\\'in Ku\\v{c}era, Vojt\\v{e}ch \\v{R}eh\\'ak", "title": "Synthesizing Efficient Solutions for Patrolling Problems in the Internet\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an algorithm for constructing efficient patrolling strategies in\nthe Internet environment, where the protected targets are nodes connected to\nthe network and the patrollers are software agents capable of\ndetecting/preventing undesirable activities on the nodes. The algorithm is\nbased on a novel compositional principle designed for a special class of\nstrategies, and it can quickly construct (sub)optimal solutions even if the\nnumber of targets reaches hundreds of millions.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 07:15:53 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 10:22:58 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Br\u00e1zdil", "Tom\u00e1\u0161", ""], ["Ku\u010dera", "Anton\u00edn", ""], ["\u0158eh\u00e1k", "Vojt\u011bch", ""]]}, {"id": "1805.02867", "submitter": "Maxim Milakov", "authors": "Maxim Milakov (NVIDIA), Natalia Gimelshein (NVIDIA)", "title": "Online normalizer calculation for softmax", "comments": "1) Added link to the benchmark code, 2) Benchmarked Safe Softmax +\n  Top-K fused and attributed part of 5x explicitly to fusion in sections 5.2\n  and 6, 3) Stylistic changes, 4) Minor clarifications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Softmax function is ubiquitous in machine learning, multiple previous\nworks suggested faster alternatives for it. In this paper we propose a way to\ncompute classical Softmax with fewer memory accesses and hypothesize that this\nreduction in memory accesses should improve Softmax performance on actual\nhardware. The benchmarks confirm this hypothesis: Softmax accelerates by up to\n1.3x and Softmax+TopK combined and fused by up to 5x.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 07:34:17 GMT"}, {"version": "v2", "created": "Sat, 28 Jul 2018 06:51:27 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Milakov", "Maxim", "", "NVIDIA"], ["Gimelshein", "Natalia", "", "NVIDIA"]]}, {"id": "1805.02874", "submitter": "Ferran Alet", "authors": "Ferran Alet, Rohan Chitnis, Leslie P. Kaelbling, Tomas Lozano-Perez", "title": "Finding Frequent Entities in Continuous Data", "comments": null, "journal-ref": "IJCAI 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications that involve processing high-dimensional data, it is\nimportant to identify a small set of entities that account for a significant\nfraction of detections. Rather than formalize this as a clustering problem, in\nwhich all detections must be grouped into hard or soft categories, we formalize\nit as an instance of the frequent items or heavy hitters problem, which finds\ngroups of tightly clustered objects that have a high density in the feature\nspace. We show that the heavy hitters formulation generates solutions that are\nmore accurate and effective than the clustering formulation. In addition, we\npresent a novel online algorithm for heavy hitters, called HAC, which addresses\nproblems in continuous space, and demonstrate its effectiveness on real video\nand household domains.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 07:52:19 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Alet", "Ferran", ""], ["Chitnis", "Rohan", ""], ["Kaelbling", "Leslie P.", ""], ["Lozano-Perez", "Tomas", ""]]}, {"id": "1805.02895", "submitter": "Dong Zhou", "authors": "Dong Zhou, Huimin Ma, Yuhan Dong", "title": "Driving maneuvers prediction based on cognition-driven and data-driven\n  method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced Driver Assistance Systems (ADAS) improve driving safety\nsignificantly. They alert drivers from unsafe traffic conditions when a\ndangerous maneuver appears. Traditional methods to predict driving maneuvers\nare mostly based on data-driven models alone. However, existing methods to\nunderstand the driver's intention remain an ongoing challenge due to a lack of\nintersection of human cognition and data analysis. To overcome this challenge,\nwe propose a novel method that combines both the cognition-driven model and the\ndata-driven model. We introduce a model named Cognitive Fusion-RNN (CF-RNN)\nwhich fuses the data inside the vehicle and the data outside the vehicle in a\ncognitive way. The CF-RNN model consists of two Long Short-Term Memory (LSTM)\nbranches regulated by human reaction time. Experiments on the Brain4Cars\nbenchmark dataset demonstrate that the proposed method outperforms previous\nmethods and achieves state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 08:35:52 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Zhou", "Dong", ""], ["Ma", "Huimin", ""], ["Dong", "Yuhan", ""]]}, {"id": "1805.02896", "submitter": "Ilya Verenich", "authors": "Ilya Verenich, Marlon Dumas, Marcello La Rosa, Fabrizio Maggi, Irene\n  Teinemaa", "title": "Survey and cross-benchmark comparison of remaining time prediction\n  methods in business process monitoring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predictive business process monitoring methods exploit historical process\nexecution logs to generate predictions about running instances (called cases)\nof a business process, such as the prediction of the outcome, next activity or\nremaining cycle time of a given process case. These insights could be used to\nsupport operational managers in taking remedial actions as business processes\nunfold, e.g. shifting resources from one case onto another to ensure this\nlatter is completed on time. A number of methods to tackle the remaining cycle\ntime prediction problem have been proposed in the literature. However, due to\ndifferences in their experimental setup, choice of datasets, evaluation\nmeasures and baselines, the relative merits of each method remain unclear. This\narticle presents a systematic literature review and taxonomy of methods for\nremaining time prediction in the context of business processes, as well as a\ncross-benchmark comparison of 16 such methods based on 16 real-life datasets\noriginating from different industry domains.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 08:38:58 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 21:56:51 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Verenich", "Ilya", ""], ["Dumas", "Marlon", ""], ["La Rosa", "Marcello", ""], ["Maggi", "Fabrizio", ""], ["Teinemaa", "Irene", ""]]}, {"id": "1805.02912", "submitter": "Christoph Schwering", "authors": "Yijia Chen, Abdallah Saffidine, Christoph Schwering", "title": "The Complexity of Limited Belief Reasoning -- The Quantifier-Free Case", "comments": "15 pages, 1 figure, 1 table, Twenty-seventh International Joint\n  Conference on Artificial Intelligence (IJCAI-18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classical view of epistemic logic is that an agent knows all the logical\nconsequences of their knowledge base. This assumption of logical omniscience is\noften unrealistic and makes reasoning computationally intractable. One approach\nto avoid logical omniscience is to limit reasoning to a certain belief level,\nwhich intuitively measures the reasoning \"depth.\" This paper investigates the\ncomputational complexity of reasoning with belief levels. First we show that\nwhile reasoning remains tractable if the level is constant, the complexity\njumps to PSPACE-complete -- that is, beyond classical reasoning -- when the\nbelief level is part of the input. Then we further refine the picture using\nparameterized complexity theory to investigate how the belief level and the\nnumber of non-logical symbols affect the complexity.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 09:20:21 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Chen", "Yijia", ""], ["Saffidine", "Abdallah", ""], ["Schwering", "Christoph", ""]]}, {"id": "1805.02971", "submitter": "Nan Li", "authors": "Mingdong Ou, Nan Li, Shenghuo Zhu, Rong Jin", "title": "Multinomial Logit Bandit with Linear Utility Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multinomial logit bandit is a sequential subset selection problem which\narises in many applications. In each round, the player selects a\n$K$-cardinality subset from $N$ candidate items, and receives a reward which is\ngoverned by a {\\it multinomial logit} (MNL) choice model considering both item\nutility and substitution property among items. The player's objective is to\ndynamically learn the parameters of MNL model and maximize cumulative reward\nover a finite horizon $T$. This problem faces the exploration-exploitation\ndilemma, and the involved combinatorial nature makes it non-trivial. In recent\nyears, there have developed some algorithms by exploiting specific\ncharacteristics of the MNL model, but all of them estimate the parameters of\nMNL model separately and incur a regret no better than\n$\\tilde{O}\\big(\\sqrt{NT}\\big)$ which is not preferred for large candidate set\nsize $N$. In this paper, we consider the {\\it linear utility} MNL choice model\nwhose item utilities are represented as linear functions of $d$-dimension item\nfeatures, and propose an algorithm, titled {\\bf LUMB}, to exploit the\nunderlying structure. It is proven that the proposed algorithm achieves\n$\\tilde{O}\\big(dK\\sqrt{T}\\big)$ regret which is free of candidate set size.\nExperiments show the superiority of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 12:23:54 GMT"}, {"version": "v2", "created": "Mon, 4 Mar 2019 08:04:16 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Ou", "Mingdong", ""], ["Li", "Nan", ""], ["Zhu", "Shenghuo", ""], ["Jin", "Rong", ""]]}, {"id": "1805.03090", "submitter": "Melkior Ornik", "authors": "Melkior Ornik, Ufuk Topcu", "title": "Deception in Optimal Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider an adversarial scenario where one agent seeks to\nachieve an objective and its adversary seeks to learn the agent's intentions\nand prevent the agent from achieving its objective. The agent has an incentive\nto try to deceive the adversary about its intentions, while at the same time\nworking to achieve its objective. The primary contribution of this paper is to\nintroduce a mathematically rigorous framework for the notion of deception\nwithin the context of optimal control. The central notion introduced in the\npaper is that of a belief-induced reward: a reward dependent not only on the\nagent's state and action, but also adversary's beliefs. Design of an optimal\ndeceptive strategy then becomes a question of optimal control design on the\nproduct of the agent's state space and the adversary's belief space. The\nproposed framework allows for deception to be defined in an arbitrary control\nsystem endowed with a reward function, as well as with additional\nspecifications limiting the agent's control policy. In addition to defining\ndeception, we discuss design of optimally deceptive strategies under\nuncertainties in agent's knowledge about the adversary's learning process. In\nthe latter part of the paper, we focus on a setting where the agent's behavior\nis governed by a Markov decision process, and show that the design of optimally\ndeceptive strategies under lack of knowledge about the adversary naturally\nreduces to previously discussed problems in control design on partially\nobservable or uncertain Markov decision processes. Finally, we present two\nexamples of deceptive strategies: a \"cops and robbers\" scenario and an example\nwhere an agent may use camouflage while moving. We show that optimally\ndeceptive strategies in such examples follow the intuitive idea of how to\ndeceive an adversary in the above settings.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 15:08:40 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Ornik", "Melkior", ""], ["Topcu", "Ufuk", ""]]}, {"id": "1805.03094", "submitter": "Kristina Lerman", "authors": "Nazanin Alipourfard and Peter G. Fennell and Kristina Lerman", "title": "Using Simpson's Paradox to Discover Interesting Patterns in Behavioral\n  Data", "comments": "Proceedings of the 12th International Conference on Web and Social\n  Media", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a data-driven discovery method that leverages Simpson's paradox\nto uncover interesting patterns in behavioral data. Our method systematically\ndisaggregates data to identify subgroups within a population whose behavior\ndeviates significantly from the rest of the population. Given an outcome of\ninterest and a set of covariates, the method follows three steps. First, it\ndisaggregates data into subgroups, by conditioning on a particular covariate,\nso as minimize the variation of the outcome within the subgroups. Next, it\nmodels the outcome as a linear function of another covariate, both in the\nsubgroups and in the aggregate data. Finally, it compares trends to identify\ndisaggregations that produce subgroups with different behaviors from the\naggregate. We illustrate the method by applying it to three real-world\nbehavioral datasets, including Q\\&A site Stack Exchange and online learning\nplatforms Khan Academy and Duolingo.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 15:11:18 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Alipourfard", "Nazanin", ""], ["Fennell", "Peter G.", ""], ["Lerman", "Kristina", ""]]}, {"id": "1805.03108", "submitter": "Joseph Ramsey", "authors": "Joseph Ramsey and Bryan Andrews", "title": "FASK with Interventional Knowledge Recovers Edges from the Sachs Model", "comments": "13 pages, 21 figures, 2 tables, Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a procedure that, in one step from continuous data with minimal\npreparation, recovers the graph found by Sachs et al. \\cite{sachs2005causal},\nwith only a few edges different. The algorithm, Fast Adjacency Skewness (FASK),\nrelies on a mixture of linear reasoning and reasoning from the skewness of\nvariables; the Sachs data is a good candidate for this procedure since the\nskewness of the variables is quite pronounced. We review the ground truth model\nfrom Sachs et al. as well as some of the fluctuations seen in the protein\nabundances in the system, give the Sachs model and the FASK model, and perform\na detailed comparison. Some variation in hyper-parameters is explored, though\nthe main result uses values at or near the defaults learned from work modeling\nfMRI data.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 15:49:04 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Ramsey", "Joseph", ""], ["Andrews", "Bryan", ""]]}, {"id": "1805.03138", "submitter": "Fatemeh Zahedi", "authors": "Fatemeh Zahedi and Zahra Zahedi", "title": "A review of neuro-fuzzy systems based on intelligent control", "comments": "4 pages, 7 figures, 1 table, Journal of Electrical and Electronic\n  Engineering", "journal-ref": "Journal of Electrical and Electronic Engineering 2015; 3(2-1):\n  58-61", "doi": "10.11648/j.jeee.s.2015030201.23", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The system's ability to adapt and self-organize are two key factors when it\ncomes to how well the system can survive the changes to the environment and the\nplant they work within. Intelligent control improves these two factors in\ncontrollers. Considering the increasing complexity of dynamic systems along\nwith their need for feedback controls, using more complicated controls has\nbecome necessary and intelligent control can be a suitable response to this\nnecessity. This paper briefly describes the structure of intelligent control\nand provides a review on fuzzy logic and neural networks which are some of the\nbase methods for intelligent control. The different aspects of these two\nmethods are then compared together and an example of a combined method is\npresented.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 12:30:22 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Zahedi", "Fatemeh", ""], ["Zahedi", "Zahra", ""]]}, {"id": "1805.03141", "submitter": "Ji Liu", "authors": "Ji Liu and Noel Moreno Lemus and Esther Pacitti and Fabio Porto and\n  Patrick Valduriez", "title": "Parallel Computation of PDFs on Big Spatial Data Using Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider big spatial data, which is typically produced in scientific areas\nsuch as geological or seismic interpretation. The spatial data can be produced\nby observation (e.g. using sensors or soil instrument) or numerical simulation\nprograms and correspond to points that represent a 3D soil cube area. However,\nerrors in signal processing and modeling create some uncertainty, and thus a\nlack of accuracy in identifying geological or seismic phenomenons. Such\nuncertainty must be carefully analyzed. To analyze uncertainty, the main\nsolution is to compute a Probability Density Function (PDF) of each point in\nthe spatial cube area. However, computing PDFs on big spatial data can be very\ntime consuming (from several hours to even months on a parallel computer). In\nthis paper, we propose a new solution to efficiently compute such PDFs in\nparallel using Spark, with three methods: data grouping, machine learning\nprediction and sampling. We evaluate our solution by extensive experiments on\ndifferent computer clusters using big data ranging from hundreds of GB to\nseveral TB. The experimental results show that our solution scales up very well\nand can reduce the execution time by a factor of 33 (in the order of seconds or\nminutes) compared with a baseline method.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 16:22:25 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Liu", "Ji", ""], ["Lemus", "Noel Moreno", ""], ["Pacitti", "Esther", ""], ["Porto", "Fabio", ""], ["Valduriez", "Patrick", ""]]}, {"id": "1805.03162", "submitter": "Tong Niu", "authors": "Tong Niu, Mohit Bansal", "title": "Polite Dialogue Generation Without Parallel Data", "comments": "To Appear in TACL Journal (16 pages) (first submission cycle: Oct1\n  2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stylistic dialogue response generation, with valuable applications in\npersonality-based conversational agents, is a challenging task because the\nresponse needs to be fluent, contextually-relevant, as well as\nparalinguistically accurate. Moreover, parallel datasets for\nregular-to-stylistic pairs are usually unavailable. We present three\nweakly-supervised models that can generate diverse polite (or rude) dialogue\nresponses without parallel data. Our late fusion model (Fusion) merges the\ndecoder of an encoder-attention-decoder dialogue model with a language model\ntrained on stand-alone polite utterances. Our label-fine-tuning (LFT) model\nprepends to each source sequence a politeness-score scaled label (predicted by\nour state-of-the-art politeness classifier) during training, and at test time\nis able to generate polite, neutral, and rude responses by simply scaling the\nlabel embedding by the corresponding score. Our reinforcement learning model\n(Polite-RL) encourages politeness generation by assigning rewards proportional\nto the politeness classifier score of the sampled response. We also present two\nretrieval-based polite dialogue model baselines. Human evaluation validates\nthat while the Fusion and the retrieval-based models achieve politeness with\npoorer context-relevance, the LFT and Polite-RL models can produce\nsignificantly more polite responses without sacrificing dialogue quality.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 16:56:15 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Niu", "Tong", ""], ["Bansal", "Mohit", ""]]}, {"id": "1805.03359", "submitter": "Peter Henderson", "authors": "Joshua Romoff, Peter Henderson, Alexandre Pich\\'e, Vincent\n  Francois-Lavet, Joelle Pineau", "title": "Reward Estimation for Variance Reduction in Deep Reinforcement Learning", "comments": "Version 1 as appears in the International Conference on Learning\n  Representations (ICLR) 2018 Workshop Track; Version 2 as appears in the\n  Proceedings of The 2nd Conference on Robot Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) agents require the specification of a reward\nsignal for learning behaviours. However, introduction of corrupt or stochastic\nrewards can yield high variance in learning. Such corruption may be a direct\nresult of goal misspecification, randomness in the reward signal, or\ncorrelation of the reward with external factors that are not known to the\nagent. Corruption or stochasticity of the reward signal can be especially\nproblematic in robotics, where goal specification can be particularly difficult\nfor complex tasks. While many variance reduction techniques have been studied\nto improve the robustness of the RL process, handling such stochastic or\ncorrupted reward structures remains difficult. As an alternative for handling\nthis scenario in model-free RL methods, we suggest using an estimator for both\nrewards and value functions. We demonstrate that this improves performance\nunder corrupted stochastic rewards in both the tabular and non-linear function\napproximation settings for a variety of noise types and environments. The use\nof reward estimation is a robust and easy-to-implement improvement for handling\ncorrupted reward signals in model-free RL.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 03:11:29 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 20:36:53 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Romoff", "Joshua", ""], ["Henderson", "Peter", ""], ["Pich\u00e9", "Alexandre", ""], ["Francois-Lavet", "Vincent", ""], ["Pineau", "Joelle", ""]]}, {"id": "1805.03364", "submitter": "Andy Shih", "authors": "Andy Shih, Arthur Choi, Adnan Darwiche", "title": "A Symbolic Approach to Explaining Bayesian Network Classifiers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an approach for explaining Bayesian network classifiers, which is\nbased on compiling such classifiers into decision functions that have a\ntractable and symbolic form. We introduce two types of explanations for why a\nclassifier may have classified an instance positively or negatively and suggest\nalgorithms for computing these explanations. The first type of explanation\nidentifies a minimal set of the currently active features that is responsible\nfor the current classification, while the second type of explanation identifies\na minimal set of features whose current state (active or not) is sufficient for\nthe classification. We consider in particular the compilation of Naive and\nLatent-Tree Bayesian network classifiers into Ordered Decision Diagrams (ODDs),\nproviding a context for evaluating our proposal using case studies and\nexperiments based on classifiers from the literature.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 03:56:24 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Shih", "Andy", ""], ["Choi", "Arthur", ""], ["Darwiche", "Adnan", ""]]}, {"id": "1805.03379", "submitter": "Manqing Dong", "authors": "Manqing Dong, Lina Yao, Xianzhi Wang, Boualem Benatallah, Chaoran\n  Huang, Xiaodong Ning", "title": "Opinion Fraud Detection via Neural Autoencoder Decision Forest", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online reviews play an important role in influencing buyers' daily purchase\ndecisions. However, fake and meaningless reviews, which cannot reflect users'\ngenuine purchase experience and opinions, widely exist on the Web and pose\ngreat challenges for users to make right choices. Therefore,it is desirable to\nbuild a fair model that evaluates the quality of products by distinguishing\nspamming reviews. We present an end-to-end trainable unified model to leverage\nthe appealing properties from Autoencoder and random forest. A stochastic\ndecision tree model is implemented to guide the global parameter learning\nprocess. Extensive experiments were conducted on a large Amazon review dataset.\nThe proposed model consistently outperforms a series of compared methods.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 05:44:19 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Dong", "Manqing", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Benatallah", "Boualem", ""], ["Huang", "Chaoran", ""], ["Ning", "Xiaodong", ""]]}, {"id": "1805.03382", "submitter": "Song Zuo", "authors": "Weiran Shen and Pingzhong Tang and Song Zuo", "title": "Automated Mechanism Design via Neural Networks", "comments": "Published at AAMAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using AI approaches to automatically design mechanisms has been a central\nresearch mission at the interface of AI and economics [Conitzer and Sandholm,\n2002]. Previous approaches that attempt to design revenue optimal auctions for\nthe multi-dimensional settings fall short in at least one of the three aspects:\n1) representation -- search in a space that probably does not even contain the\noptimal mechanism; 2) exactness -- finding a mechanism that is either not\ntruthful or far from optimal; 3) domain dependence -- need a different design\nfor different environment settings.\n  To resolve the three difficulties, in this paper, we put forward -- MenuNet\n-- a unified neural network based framework that automatically learns to design\nrevenue optimal mechanisms. Our framework consists of a mechanism network that\ntakes an input distribution for training and outputs a mechanism, as well as a\nbuyer network that takes a mechanism as input and output an action. Such a\nseparation in design mitigates the difficulty to impose incentive compatibility\nconstraints on the mechanism, by making it a rational choice of the buyer. As a\nresult, our framework easily overcomes the previously mentioned difficulty in\nincorporating IC constraints and always returns exactly incentive compatible\nmechanisms.\n  We then apply our framework to a number of multi-item revenue optimal design\nsettings, for a few of which the theoretically optimal mechanisms are unknown.\nWe then go on to theoretically prove that the mechanisms found by our framework\nare indeed optimal.\n  To the best of our knowledge, we are the first to apply neural networks to\ndiscover optimal auction mechanisms with provable optimality.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 05:57:29 GMT"}, {"version": "v2", "created": "Mon, 3 May 2021 13:26:26 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Shen", "Weiran", ""], ["Tang", "Pingzhong", ""], ["Zuo", "Song", ""]]}, {"id": "1805.03435", "submitter": "Dan Busbridge", "authors": "Vitalii Zhelezniak, Dan Busbridge, April Shen, Samuel L. Smith and\n  Nils Y. Hammerla", "title": "Decoding Decoders: Finding Optimal Representation Spaces for\n  Unsupervised Similarity Tasks", "comments": "ICLR 2018 Workshop Track, 15 pages, 3 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental evidence indicates that simple models outperform complex deep\nnetworks on many unsupervised similarity tasks. We provide a simple yet\nrigorous explanation for this behaviour by introducing the concept of an\noptimal representation space, in which semantically close symbols are mapped to\nrepresentations that are close under a similarity measure induced by the\nmodel's objective function. In addition, we present a straightforward procedure\nthat, without any retraining or architectural modifications, allows deep\nrecurrent models to perform equally well (and sometimes better) when compared\nto shallow models. To validate our analysis, we conduct a set of consistent\nempirical evaluations and introduce several new sentence embedding models in\nthe process. Even though this work is presented within the context of natural\nlanguage processing, the insights are readily applicable to other domains that\nrely on distributed representations for transfer tasks.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 09:41:51 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Zhelezniak", "Vitalii", ""], ["Busbridge", "Dan", ""], ["Shen", "April", ""], ["Smith", "Samuel L.", ""], ["Hammerla", "Nils Y.", ""]]}, {"id": "1805.03545", "submitter": "Martyn Amos", "authors": "Huw Lloyd and Martyn Amos", "title": "Solving Sudoku with Ant Colony Optimisation", "comments": "Submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a new Ant Colony Optimisation-based algorithm for\nSudoku, which out-performs existing methods on large instances. Our method\nincludes a novel anti-stagnation operator, which we call Best Value\nEvaporation.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 14:14:08 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Lloyd", "Huw", ""], ["Amos", "Martyn", ""]]}, {"id": "1805.03586", "submitter": "Baoxiang Wang", "authors": "Jiajin Li, Baoxiang Wang", "title": "Policy Optimization with Second-Order Advantage Information", "comments": "International Joint Conference on Artificial Intelligence (IJCAI)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy optimization on high-dimensional continuous control tasks exhibits its\ndifficulty caused by the large variance of the policy gradient estimators. We\npresent the action subspace dependent gradient (ASDG) estimator which\nincorporates the Rao-Blackwell theorem (RB) and Control Variates (CV) into a\nunified framework to reduce the variance. To invoke RB, our proposed algorithm\n(POSA) learns the underlying factorization structure among the action space\nbased on the second-order advantage information. POSA captures the quadratic\ninformation explicitly and efficiently by utilizing the wide & deep\narchitecture. Empirical studies show that our proposed approach demonstrates\nthe performance improvements on high-dimensional synthetic settings and OpenAI\nGym's MuJoCo continuous control tasks.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 15:23:58 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 09:47:11 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Li", "Jiajin", ""], ["Wang", "Baoxiang", ""]]}, {"id": "1805.03642", "submitter": "Yanshuai Cao", "authors": "Avishek Joey Bose, Huan Ling, Yanshuai Cao", "title": "Adversarial Contrastive Estimation", "comments": "Association for Computational Linguistics, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning by contrasting positive and negative samples is a general strategy\nadopted by many methods. Noise contrastive estimation (NCE) for word embeddings\nand translating embeddings for knowledge graphs are examples in NLP employing\nthis approach. In this work, we view contrastive learning as an abstraction of\nall such methods and augment the negative sampler into a mixture distribution\ncontaining an adversarially learned sampler. The resulting adaptive sampler\nfinds harder negative examples, which forces the main model to learn a better\nrepresentation of the data. We evaluate our proposal on learning word\nembeddings, order embeddings and knowledge graph embeddings and observe both\nfaster convergence and improved results on multiple metrics.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 04:06:30 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 20:20:39 GMT"}, {"version": "v3", "created": "Thu, 2 Aug 2018 20:34:14 GMT"}], "update_date": "2018-08-06", "authors_parsed": [["Bose", "Avishek Joey", ""], ["Ling", "Huan", ""], ["Cao", "Yanshuai", ""]]}, {"id": "1805.03643", "submitter": "Fei Tian", "authors": "Yang Fan, Fei Tian, Tao Qin, Xiang-Yang Li, Tie-Yan Liu", "title": "Learning to Teach", "comments": "ICLR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Teaching plays a very important role in our society, by spreading human\nknowledge and educating our next generations. A good teacher will select\nappropriate teaching materials, impact suitable methodologies, and set up\ntargeted examinations, according to the learning behaviors of the students. In\nthe field of artificial intelligence, however, one has not fully explored the\nrole of teaching, and pays most attention to machine \\emph{learning}. In this\npaper, we argue that equal attention, if not more, should be paid to teaching,\nand furthermore, an optimization framework (instead of heuristics) should be\nused to obtain good teaching strategies. We call this approach `learning to\nteach'. In the approach, two intelligent agents interact with each other: a\nstudent model (which corresponds to the learner in traditional machine learning\nalgorithms), and a teacher model (which determines the appropriate data, loss\nfunction, and hypothesis space to facilitate the training of the student\nmodel). The teacher model leverages the feedback from the student model to\noptimize its own teaching strategies by means of reinforcement learning, so as\nto achieve teacher-student co-evolution. To demonstrate the practical value of\nour proposed approach, we take the training of deep neural networks (DNN) as an\nexample, and show that by using the learning to teach techniques, we are able\nto use much less training data and fewer iterations to achieve almost the same\naccuracy for different kinds of DNN models (e.g., multi-layer perceptron,\nconvolutional neural networks and recurrent neural networks) under various\nmachine learning tasks (e.g., image classification and text understanding).\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 04:41:26 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Fan", "Yang", ""], ["Tian", "Fei", ""], ["Qin", "Tao", ""], ["Li", "Xiang-Yang", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1805.03696", "submitter": "Rohitash Chandra", "authors": "Rohitash Chandra, Danial Azam, R. Dietmar M\\\"uller, Tristan Salles,\n  Sally Cripps", "title": "Bayeslands: A Bayesian inference approach for parameter uncertainty\n  quantification in Badlands", "comments": null, "journal-ref": "Computers & Geoscience, Volume 131, October 2019, Pages 89-101", "doi": "10.1016/j.cageo.2019.06.012", "report-no": null, "categories": "physics.geo-ph cs.AI cs.CE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bayesian inference provides a rigorous methodology for estimation and\nuncertainty quantification of parameters in geophysical forward models.\nBadlands (basin and landscape dynamics model) is a landscape evolution model\nthat simulates topography development at various space and time scales.\nBadlands consists of a number of geophysical parameters that needs estimation\nwith appropriate uncertainty quantification; given the observed present-day\nground truth such as surface topography and the stratigraphy of sediment\ndeposition through time. The inference of unknown parameters is challenging due\nto the scarcity of data, sensitivity of the parameter setting and complexity of\nthe Badlands model. In this paper, we take a Bayesian approach to provide\ninference using Markov chain Monte Carlo sampling (MCMC). We present\n\\textit{Bayeslands}; a Bayesian framework for Badlands that fuses information\nobtained from complex forward models with observational data and prior\nknowledge. As a proof-of-concept, we consider a synthetic and real-world\ntopography with two parameters for Bayeslands inference, namely precipitation\nand erodibility. The results of the experiments show that Bayeslands yields a\npromising distribution of the parameters. Moreover, we demonstrate the\nchallenge in sampling irregular and multi-modal posterior distributions using a\nlikelihood surface that has a range of sub-optimal modes.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 08:25:30 GMT"}, {"version": "v2", "created": "Mon, 5 Jul 2021 10:46:43 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Chandra", "Rohitash", ""], ["Azam", "Danial", ""], ["M\u00fcller", "R. Dietmar", ""], ["Salles", "Tristan", ""], ["Cripps", "Sally", ""]]}, {"id": "1805.03714", "submitter": "Zelda Mariet", "authors": "Vitaly Kuznetsov and Zelda Mariet", "title": "Foundations of Sequence-to-Sequence Modeling for Time Series", "comments": "To appear at AISTATS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The availability of large amounts of time series data, paired with the\nperformance of deep-learning algorithms on a broad class of problems, has\nrecently led to significant interest in the use of sequence-to-sequence models\nfor time series forecasting. We provide the first theoretical analysis of this\ntime series forecasting framework. We include a comparison of\nsequence-to-sequence modeling to classical time series models, and as such our\ntheory can serve as a quantitative guide for practitioners choosing between\ndifferent modeling methodologies.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 20:03:37 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 15:55:15 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Kuznetsov", "Vitaly", ""], ["Mariet", "Zelda", ""]]}, {"id": "1805.03716", "submitter": "Omer Levy", "authors": "Omer Levy, Kenton Lee, Nicholas FitzGerald, Luke Zettlemoyer", "title": "Long Short-Term Memory as a Dynamically Computed Element-wise Weighted\n  Sum", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LSTMs were introduced to combat vanishing gradients in simple RNNs by\naugmenting them with gated additive recurrent connections. We present an\nalternative view to explain the success of LSTMs: the gates themselves are\nversatile recurrent models that provide more representational power than\npreviously appreciated. We do this by decoupling the LSTM's gates from the\nembedded simple RNN, producing a new class of RNNs where the recurrence\ncomputes an element-wise weighted sum of context-independent functions of the\ninput. Ablations on a range of problems demonstrate that the gating mechanism\nalone performs as well as an LSTM in most settings, strongly suggesting that\nthe gates are doing much more in practice than just alleviating vanishing\ngradients.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 20:05:58 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Levy", "Omer", ""], ["Lee", "Kenton", ""], ["FitzGerald", "Nicholas", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1805.03720", "submitter": "Matthew Guzdial", "authors": "Matthew Guzdial, Nicholas Liao, Vishwa Shah, and Mark O. Riedl", "title": "Creative Invention Benchmark", "comments": "8 pages, 4 figures, International Conference on Computational\n  Creativity", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the Creative Invention Benchmark (CrIB), a\n2000-problem benchmark for evaluating a particular facet of computational\ncreativity. Specifically, we address combinational p-creativity, the creativity\nat play when someone combines existing knowledge to achieve a solution novel to\nthat individual. We present generation strategies for the five problem\ncategories of the benchmark and a set of initial baselines.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 20:20:41 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Guzdial", "Matthew", ""], ["Liao", "Nicholas", ""], ["Shah", "Vishwa", ""], ["Riedl", "Mark O.", ""]]}, {"id": "1805.03801", "submitter": "Bei Shi", "authors": "Bei Shi, Zihao Fu, Lidong Bing and Wai Lam", "title": "Learning Domain-Sensitive and Sentiment-Aware Word Embeddings", "comments": "11 pages, published in ACL2018", "journal-ref": "ACL2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings have been widely used in sentiment classification because of\ntheir efficacy for semantic representations of words. Given reviews from\ndifferent domains, some existing methods for word embeddings exploit sentiment\ninformation, but they cannot produce domain-sensitive embeddings. On the other\nhand, some other existing methods can generate domain-sensitive word\nembeddings, but they cannot distinguish words with similar contexts but\nopposite sentiment polarity. We propose a new method for learning\ndomain-sensitive and sentiment-aware embeddings that simultaneously capture the\ninformation of sentiment semantics and domain sensitivity of individual words.\nOur method can automatically determine and produce domain-common embeddings and\ndomain-specific embeddings. The differentiation of domain-common and\ndomain-specific words enables the advantage of data augmentation of common\nsemantics from multiple domains and capture the varied semantics of specific\nwords from different domains at the same time. Experimental results show that\nour model provides an effective way to learn domain-sensitive and\nsentiment-aware word embeddings which benefit sentiment classification at both\nsentence level and lexicon term level.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 03:39:32 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Shi", "Bei", ""], ["Fu", "Zihao", ""], ["Bing", "Lidong", ""], ["Lam", "Wai", ""]]}, {"id": "1805.03830", "submitter": "Varsha Embar", "authors": "Soumya Wadhwa and Varsha Embar and Matthias Grabmair and Eric Nyberg", "title": "Towards Inference-Oriented Reading Comprehension: ParallelQA", "comments": "Accepted at Workshop on New Forms of Generalization in Deep Learning\n  and Natural Language Processing, NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the tendency of end-to-end neural Machine\nReading Comprehension (MRC) models to match shallow patterns rather than\nperform inference-oriented reasoning on RC benchmarks. We aim to test the\nability of these systems to answer questions which focus on referential\ninference. We propose ParallelQA, a strategy to formulate such questions using\nparallel passages. We also demonstrate that existing neural models fail to\ngeneralize well to this setting.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 05:47:46 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Wadhwa", "Soumya", ""], ["Embar", "Varsha", ""], ["Grabmair", "Matthias", ""], ["Nyberg", "Eric", ""]]}, {"id": "1805.03852", "submitter": "Yanjing Wang", "authors": "Yanjing Wang and Jeremy Seligman", "title": "When Names Are Not Commonly Known: Epistemic Logic with Assignments", "comments": "18 pages, to appear in proceedings of AiML2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LO math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In standard epistemic logic, agent names are usually assumed to be common\nknowledge implicitly. This is unreasonable for various applications. Inspired\nby term modal logic and assignment operators in dynamic logic, we introduce a\nlightweight modal predicate logic where names can be non-rigid. The language\ncan handle various de dicto and de re distinctions in a natural way. The main\ntechnical result is a complete axiomatisation of this logic over S5 models.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 06:56:53 GMT"}, {"version": "v2", "created": "Sun, 24 Jun 2018 16:51:53 GMT"}], "update_date": "2018-06-26", "authors_parsed": [["Wang", "Yanjing", ""], ["Seligman", "Jeremy", ""]]}, {"id": "1805.03876", "submitter": "Wei Xia", "authors": "Wei Xia and Roland H. C. Yap", "title": "Learning Robust Search Strategies Using a Bandit-Based Approach", "comments": "Published at the Proceedings of 32th AAAI Conference on Artificial\n  Intelligence (AAAI'18)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Effective solving of constraint problems often requires choosing good or\nspecific search heuristics. However, choosing or designing a good search\nheuristic is non-trivial and is often a manual process. In this paper, rather\nthan manually choosing/designing search heuristics, we propose the use of\nbandit-based learning techniques to automatically select search heuristics. Our\napproach is online where the solver learns and selects from a set of heuristics\nduring search. The goal is to obtain automatic search heuristics which give\nrobust performance. Preliminary experiments show that our adaptive technique is\nmore robust than the original search heuristics. It can also outperform the\noriginal heuristics.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 08:30:37 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Xia", "Wei", ""], ["Yap", "Roland H. C.", ""]]}, {"id": "1805.03885", "submitter": "Niel Chah", "authors": "Niel Chah", "title": "OK Google, What Is Your Ontology? Or: Exploring Freebase Classification\n  to Understand Google's Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper reconstructs the Freebase data dumps to understand the underlying\nontology behind Google's semantic search feature. The Freebase knowledge base\nwas a major Semantic Web and linked data technology that was acquired by Google\nin 2010 to support the Google Knowledge Graph, the backend for Google search\nresults that include structured answers to queries instead of a series of links\nto external resources. After its shutdown in 2016, Freebase is contained in a\ndata dump of 1.9 billion Resource Description Format (RDF) triples. A\nrecomposition of the Freebase ontology will be analyzed in relation to concepts\nand insights from the literature on classification by Bowker and Star. This\npaper will explore how the Freebase ontology is shaped by many of the forces\nthat also shape classification systems through a deep dive into the ontology\nand a small correlational study. These findings will provide a glimpse into the\nproprietary blackbox Knowledge Graph and what is meant by Google's mission to\n\"organize the world's information and make it universally accessible and\nuseful\".\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 08:39:40 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 11:54:16 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Chah", "Niel", ""]]}, {"id": "1805.03887", "submitter": "Luca Venturini", "authors": "Luca Venturini, Elena Baralis, Paolo Garza", "title": "Scaling associative classification for very large datasets", "comments": null, "journal-ref": "J Big Data (2017) 4: 44", "doi": "10.1186/s40537-017-0107-2", "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Supervised learning algorithms are nowadays successfully scaling up to\ndatasets that are very large in volume, leveraging the potential of in-memory\ncluster-computing Big Data frameworks. Still, massive datasets with a number of\nlarge-domain categorical features are a difficult challenge for any classifier.\nMost off-the-shelf solutions cannot cope with this problem. In this work we\nintroduce DAC, a Distributed Associative Classifier. DAC exploits ensemble\nlearning to distribute the training of an associative classifier among parallel\nworkers and improve the final quality of the model. Furthermore, it adopts\nseveral novel techniques to reach high scalability without sacrificing quality,\namong which a preventive pruning of classification rules in the extraction\nphase based on Gini impurity. We ran experiments on Apache Spark, on a real\nlarge-scale dataset with more than 4 billion records and 800 million distinct\ncategories. The results showed that DAC improves on a state-of-the-art solution\nin both prediction quality and execution time. Since the generated model is\nhuman-readable, it can not only classify new records, but also allow\nunderstanding both the logic behind the prediction and the properties of the\nmodel, becoming a useful aid for decision makers.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 08:41:55 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Venturini", "Luca", ""], ["Baralis", "Elena", ""], ["Garza", "Paolo", ""]]}, {"id": "1805.03989", "submitter": "Junyang Lin", "authors": "Junyang Lin, Xu Sun, Shuming Ma and Qi Su", "title": "Global Encoding for Abstractive Summarization", "comments": "Accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In neural abstractive summarization, the conventional sequence-to-sequence\n(seq2seq) model often suffers from repetition and semantic irrelevance. To\ntackle the problem, we propose a global encoding framework, which controls the\ninformation flow from the encoder to the decoder based on the global\ninformation of the source context. It consists of a convolutional gated unit to\nperform global encoding to improve the representations of the source-side\ninformation. Evaluations on the LCSTS and the English Gigaword both demonstrate\nthat our model outperforms the baseline models, and the analysis shows that our\nmodel is capable of reducing repetition.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 14:11:51 GMT"}, {"version": "v2", "created": "Sun, 10 Jun 2018 15:29:18 GMT"}], "update_date": "2018-06-14", "authors_parsed": [["Lin", "Junyang", ""], ["Sun", "Xu", ""], ["Ma", "Shuming", ""], ["Su", "Qi", ""]]}, {"id": "1805.04007", "submitter": "Yinhao Li", "authors": "Yinhao Li, Awa Alqahtani, Ellis Solaiman, Charith Perera, Prem Prakash\n  Jayaraman, Boualem Benatallah, and Rajiv Ranjan", "title": "A Unified Knowledge Representation and Context-aware Recommender System\n  in Internet of Things", "comments": "This paper is an incomplete draft. Therefore, I would like to\n  withdraw it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the rapidly developing Internet of Things (IoT), numerous and diverse\nphysical devices, Edge devices, Cloud infrastructure, and their quality of\nservice requirements (QoS), need to be represented within a unified\nspecification in order to enable rapid IoT application development, monitoring,\nand dynamic reconfiguration. But heterogeneities among different configuration\nknowledge representation models pose limitations for acquisition, discovery and\ncuration of configuration knowledge for coordinated IoT applications. This\npaper proposes a unified data model to represent IoT resource configuration\nknowledge artifacts. It also proposes IoT-CANE (Context-Aware recommendatioN\nsystEm) to facilitate incremental knowledge acquisition and declarative context\ndriven knowledge recommendation.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 14:42:00 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 13:59:41 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Li", "Yinhao", ""], ["Alqahtani", "Awa", ""], ["Solaiman", "Ellis", ""], ["Perera", "Charith", ""], ["Jayaraman", "Prem Prakash", ""], ["Benatallah", "Boualem", ""], ["Ranjan", "Rajiv", ""]]}, {"id": "1805.04025", "submitter": "Chenxi Liu", "authors": "Alan L. Yuille, Chenxi Liu", "title": "Deep Nets: What have they ever done for Vision?", "comments": "To appear in IJCV", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is an opinion paper about the strengths and weaknesses of Deep Nets for\nvision. They are at the heart of the enormous recent progress in artificial\nintelligence and are of growing importance in cognitive science and\nneuroscience. They have had many successes but also have several limitations\nand there is limited understanding of their inner workings. At present Deep\nNets perform very well on specific visual tasks with benchmark datasets but\nthey are much less general purpose, flexible, and adaptive than the human\nvisual system. We argue that Deep Nets in their current form are unlikely to be\nable to overcome the fundamental problem of computer vision, namely how to deal\nwith the combinatorial explosion, caused by the enormous complexity of natural\nimages, and obtain the rich understanding of visual scenes that the human\nvisual achieves. We argue that this combinatorial explosion takes us into a\nregime where \"big data is not enough\" and where we need to rethink our methods\nfor benchmarking performance and evaluating vision algorithms. We stress that,\nas vision algorithms are increasingly used in real world applications, that\nperformance evaluation is not merely an academic exercise but has important\nconsequences in the real world. It is impractical to review the entire Deep Net\nliterature so we restrict ourselves to a limited range of topics and references\nwhich are intended as entry points into the literature. The views expressed in\nthis paper are our own and do not necessarily represent those of anybody else\nin the computer vision community.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 15:43:44 GMT"}, {"version": "v2", "created": "Fri, 11 Jan 2019 01:47:35 GMT"}, {"version": "v3", "created": "Fri, 16 Oct 2020 19:52:59 GMT"}, {"version": "v4", "created": "Wed, 25 Nov 2020 15:34:56 GMT"}], "update_date": "2020-11-26", "authors_parsed": [["Yuille", "Alan L.", ""], ["Liu", "Chenxi", ""]]}, {"id": "1805.04032", "submitter": "Jose Camacho-Collados", "authors": "Jose Camacho-Collados and Mohammad Taher Pilehvar", "title": "From Word to Sense Embeddings: A Survey on Vector Representations of\n  Meaning", "comments": "46 pages, 8 figures. Published in Journal of Artificial Intelligence\n  Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past years, distributed semantic representations have proved to be\neffective and flexible keepers of prior knowledge to be integrated into\ndownstream applications. This survey focuses on the representation of meaning.\nWe start from the theoretical background behind word vector space models and\nhighlight one of their major limitations: the meaning conflation deficiency,\nwhich arises from representing a word with all its possible meanings as a\nsingle vector. Then, we explain how this deficiency can be addressed through a\ntransition from the word level to the more fine-grained level of word senses\n(in its broader acceptation) as a method for modelling unambiguous lexical\nmeaning. We present a comprehensive overview of the wide range of techniques in\nthe two main branches of sense representation, i.e., unsupervised and\nknowledge-based. Finally, this survey covers the main evaluation procedures and\napplications for this type of representation, and provides an analysis of four\nof its important aspects: interpretability, sense granularity, adaptability to\ndifferent domains and compositionality.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 15:56:48 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 08:18:28 GMT"}, {"version": "v3", "created": "Fri, 26 Oct 2018 09:34:36 GMT"}], "update_date": "2018-10-29", "authors_parsed": [["Camacho-Collados", "Jose", ""], ["Pilehvar", "Mohammad Taher", ""]]}, {"id": "1805.04049", "submitter": "Emiliano De Cristofaro", "authors": "Luca Melis and Congzheng Song and Emiliano De Cristofaro and Vitaly\n  Shmatikov", "title": "Exploiting Unintended Feature Leakage in Collaborative Learning", "comments": "Proceedings of 40th IEEE Symposium on Security & Privacy (S&P 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative machine learning and related techniques such as federated\nlearning allow multiple participants, each with his own training dataset, to\nbuild a joint model by training locally and periodically exchanging model\nupdates. We demonstrate that these updates leak unintended information about\nparticipants' training data and develop passive and active inference attacks to\nexploit this leakage. First, we show that an adversarial participant can infer\nthe presence of exact data points -- for example, specific locations -- in\nothers' training data (i.e., membership inference). Then, we show how this\nadversary can infer properties that hold only for a subset of the training data\nand are independent of the properties that the joint model aims to capture. For\nexample, he can infer when a specific person first appears in the photos used\nto train a binary gender classifier. We evaluate our attacks on a variety of\ntasks, datasets, and learning configurations, analyze their limitations, and\ndiscuss possible defenses.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 16:28:44 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 13:52:36 GMT"}, {"version": "v3", "created": "Thu, 1 Nov 2018 12:47:40 GMT"}], "update_date": "2018-11-02", "authors_parsed": [["Melis", "Luca", ""], ["Song", "Congzheng", ""], ["De Cristofaro", "Emiliano", ""], ["Shmatikov", "Vitaly", ""]]}, {"id": "1805.04107", "submitter": "Claire N\\'edellec", "authors": "Claire N\\'edellec, Robert Bossy, Estelle Chaix, Louise Del\\'eger", "title": "Text-mining and ontologies: new approaches to knowledge discovery of\n  microbial diversity", "comments": "5 pages", "journal-ref": "Proceedings of the 4th International Microbial Diversity\n  Conference. pp. 221-227, ed. Marco Gobetti. Pub. Simtra. ISBN\n  978-88-943010-0-7, Bari, October 2017", "doi": null, "report-no": null, "categories": "q-bio.QM cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Microbiology research has access to a very large amount of public information\non the habitats of microorganisms. Many areas of microbiology research uses\nthis information, primarily in biodiversity studies. However the habitat\ninformation is expressed in unstructured natural language form, which hinders\nits exploitation at large-scale. It is very common for similar habitats to be\ndescribed by different terms, which makes them hard to compare automatically,\ne.g. intestine and gut. The use of a common reference to standardize these\nhabitat descriptions as claimed by (Ivana et al., 2010) is a necessity. We\npropose the ontology called OntoBiotope that we have been developing since\n2010. The OntoBiotope ontology is in a formal machine-readable representation\nthat enables indexing of information as well as conceptualization and\nreasoning.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 11:38:45 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 14:52:02 GMT"}], "update_date": "2018-11-01", "authors_parsed": [["N\u00e9dellec", "Claire", ""], ["Bossy", "Robert", ""], ["Chaix", "Estelle", ""], ["Del\u00e9ger", "Louise", ""]]}, {"id": "1805.04156", "submitter": "Julia Stoyanovich", "authors": "Benny Kimelfeld, Phokion G. Kolaitis, Julia Stoyanovich", "title": "Computational Social Choice Meets Databases", "comments": "This is an extended version of \"Computational Social Choice Meets\n  Databases\" by Kimelfeld, Kolaitis and Stoyanovich, to appear in IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel framework that aims to create bridges between the\ncomputational social choice and the database management communities. This\nframework enriches the tasks currently supported in computational social choice\nwith relational database context, thus making it possible to formulate\nsophisticated queries about voting rules, candidates, voters, issues, and\npositions. At the conceptual level, we give rigorous semantics to queries in\nthis framework by introducing the notions of necessary answers and possible\nanswers to queries. At the technical level, we embark on an investigation of\nthe computational complexity of the necessary answers. We establish a number of\nresults about the complexity of the necessary answers of conjunctive queries\ninvolving positional scoring rules that contrast sharply with earlier results\nabout the complexity of the necessary winners.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 20:05:59 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Kimelfeld", "Benny", ""], ["Kolaitis", "Phokion G.", ""], ["Stoyanovich", "Julia", ""]]}, {"id": "1805.04201", "submitter": "Adithya Murali", "authors": "Adithyavairavan Murali, Yin Li, Dhiraj Gandhi, Abhinav Gupta", "title": "Learning to Grasp Without Seeing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Can a robot grasp an unknown object without seeing it? In this paper, we\npresent a tactile-sensing based approach to this challenging problem of\ngrasping novel objects without prior knowledge of their location or physical\nproperties. Our key idea is to combine touch based object localization with\ntactile based re-grasping. To train our learning models, we created a\nlarge-scale grasping dataset, including more than 30 RGB frames and over 2.8\nmillion tactile samples from 7800 grasp interactions of 52 objects. To learn a\nrepresentation of tactile signals, we propose an unsupervised auto-encoding\nscheme, which shows a significant improvement of 4-9% over prior methods on a\nvariety of tactile perception tasks. Our system consists of two steps. First,\nour touch localization model sequentially 'touch-scans' the workspace and uses\na particle filter to aggregate beliefs from multiple hits of the target. It\noutputs an estimate of the object's location, from which an initial grasp is\nestablished. Next, our re-grasping model learns to progressively improve grasps\nwith tactile feedback based on the learned features. This network learns to\nestimate grasp stability and predict adjustment for the next grasp. Re-grasping\nthus is performed iteratively until our model identifies a stable grasp.\nFinally, we demonstrate extensive experimental results on grasping a large set\nof novel objects using tactile sensing alone. Furthermore, when applied on top\nof a vision-based policy, our re-grasping model significantly boosts the\noverall accuracy by 10.6%. We believe this is the first attempt at learning to\ngrasp with only tactile sensing and without any prior object knowledge.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 22:56:45 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Murali", "Adithyavairavan", ""], ["Li", "Yin", ""], ["Gandhi", "Dhiraj", ""], ["Gupta", "Abhinav", ""]]}, {"id": "1805.04212", "submitter": "Vicente Ivan Sanchez Carmona", "authors": "Vicente Ivan Sanchez Carmona, Jeff Mitchell, Sebastian Riedel", "title": "Behavior Analysis of NLI Models: Uncovering the Influence of Three\n  Factors on Robustness", "comments": "Accepted at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Inference is a challenging task that has received\nsubstantial attention, and state-of-the-art models now achieve impressive test\nset performance in the form of accuracy scores. Here, we go beyond this single\nevaluation metric to examine robustness to semantically-valid alterations to\nthe input data. We identify three factors - insensitivity, polarity and unseen\npairs - and compare their impact on three SNLI models under a variety of\nconditions. Our results demonstrate a number of strengths and weaknesses in the\nmodels' ability to generalise to new in-domain instances. In particular, while\nstrong performance is possible on unseen hypernyms, unseen antonyms are more\nchallenging for all the models. More generally, the models suffer from an\ninsensitivity to certain small but semantically significant alterations, and\nare also often influenced by simple statistical correlations between words and\ntraining labels. Overall, we show that evaluations of NLI models can benefit\nfrom studying the influence of factors intrinsic to the models or found in the\ndataset used.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 00:43:59 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Carmona", "Vicente Ivan Sanchez", ""], ["Mitchell", "Jeff", ""], ["Riedel", "Sebastian", ""]]}, {"id": "1805.04220", "submitter": "Matthew Gombolay", "authors": "Matthew Gombolay, Reed Jensen, Jessica Stigile, Toni Golen, Neel Shah,\n  Sung-Hyun Son, and Julie Shah", "title": "Human-Machine Collaborative Optimization via Apprenticeship Scheduling", "comments": "Portions of this paper were published in the Proceedings of the\n  International Joint Conference on Artificial Intelligence (IJCAI) in 2016 and\n  in the Proceedings of Robotics: Science and Systems (RSS) in 2016. The paper\n  consists of 50 pages with 11 figures and 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordinating agents to complete a set of tasks with intercoupled temporal and\nresource constraints is computationally challenging, yet human domain experts\ncan solve these difficult scheduling problems using paradigms learned through\nyears of apprenticeship. A process for manually codifying this domain knowledge\nwithin a computational framework is necessary to scale beyond the\n``single-expert, single-trainee\" apprenticeship model. However, human domain\nexperts often have difficulty describing their decision-making processes,\ncausing the codification of this knowledge to become laborious. We propose a\nnew approach for capturing domain-expert heuristics through a pairwise ranking\nformulation. Our approach is model-free and does not require enumerating or\niterating through a large state space. We empirically demonstrate that this\napproach accurately learns multifaceted heuristics on a synthetic data set\nincorporating job-shop scheduling and vehicle routing problems, as well as on\ntwo real-world data sets consisting of demonstrations of experts solving a\nweapon-to-target assignment problem and a hospital resource allocation problem.\nWe also demonstrate that policies learned from human scheduling demonstration\nvia apprenticeship learning can substantially improve the efficiency of a\nbranch-and-bound search for an optimal schedule. We employ this human-machine\ncollaborative optimization technique on a variant of the weapon-to-target\nassignment problem. We demonstrate that this technique generates solutions\nsubstantially superior to those produced by human domain experts at a rate up\nto 9.5 times faster than an optimization approach and can be applied to\noptimally solve problems twice as complex as those solved by a human\ndemonstrator.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 01:53:05 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Gombolay", "Matthew", ""], ["Jensen", "Reed", ""], ["Stigile", "Jessica", ""], ["Golen", "Toni", ""], ["Shah", "Neel", ""], ["Son", "Sung-Hyun", ""], ["Shah", "Julie", ""]]}, {"id": "1805.04238", "submitter": "Wenjie Huang", "authors": "Wenjie Huang, William B. Haskell", "title": "Stochastic Approximation for Risk-aware Markov Decision Processes", "comments": "34 pages, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a stochastic approximation-type algorithm to solve finite\nstate/action, infinite-horizon, risk-aware Markov decision processes. Our\nalgorithm has two loops. The inner loop computes the risk by solving a\nstochastic saddle-point problem. The outer loop performs $Q$-learning to\ncompute an optimal risk-aware policy. Several widely investigated risk measures\n(e.g. conditional value-at-risk, optimized certainty equivalent, and absolute\nsemi-deviation) are covered by our algorithm. Almost sure convergence and the\nconvergence rate of the algorithm are established. For an error tolerance\n$\\epsilon>0$ for the optimal $Q$-value estimation gap and learning rate\n$k\\in(1/2,\\,1]$, the overall convergence rate of our algorithm is\n$\\Omega((\\ln(1/\\delta\\epsilon)/\\epsilon^{2})^{1/k}+(\\ln(1/\\epsilon))^{1/(1-k)})$\nwith probability at least $1-\\delta$.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 04:06:39 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 05:01:17 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 05:22:47 GMT"}, {"version": "v4", "created": "Wed, 4 Dec 2019 03:00:56 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Huang", "Wenjie", ""], ["Haskell", "William B.", ""]]}, {"id": "1805.04247", "submitter": "Moshiur R Farazi", "authors": "Moshiur R Farazi, Salman H Khan", "title": "Reciprocal Attention Fusion for Visual Question Answering", "comments": "To appear in the British Machine Vision Conference (BMVC), September\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing attention mechanisms either attend to local image grid or object\nlevel features for Visual Question Answering (VQA). Motivated by the\nobservation that questions can relate to both object instances and their parts,\nwe propose a novel attention mechanism that jointly considers reciprocal\nrelationships between the two levels of visual details. The bottom-up attention\nthus generated is further coalesced with the top-down information to only focus\non the scene elements that are most relevant to a given question. Our design\nhierarchically fuses multi-modal information i.e., language, object- and\ngird-level features, through an efficient tensor decomposition scheme. The\nproposed model improves the state-of-the-art single model performances from\n67.9% to 68.2% on VQAv1 and from 65.7% to 67.4% on VQAv2, demonstrating a\nsignificant boost.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 06:13:56 GMT"}, {"version": "v2", "created": "Sun, 22 Jul 2018 06:16:54 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Farazi", "Moshiur R", ""], ["Khan", "Salman H", ""]]}, {"id": "1805.04253", "submitter": "Lisa Andreevna Chalaguine", "authors": "Lisa A. Chalaguine, Anthony Hunter, Henry W. W. Potts, Fiona L.\n  Hamilton", "title": "Argument Harvesting Using Chatbots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much research in computational argumentation assumes that arguments and\ncounterarguments can be obtained in some way. Yet, to improve and apply models\nof argument, we need methods for acquiring them. Current approaches include\nargument mining from text, hand coding of arguments by researchers, or\ngenerating arguments from knowledge bases. In this paper, we propose a new\napproach, which we call argument harvesting, that uses a chatbot to enter into\na dialogue with a participant to get arguments and counterarguments from him or\nher. Because it is automated, the chatbot can be used repeatedly in many\ndialogues, and thereby it can generate a large corpus. We describe the\narchitecture of the chatbot, provide methods for managing a corpus of arguments\nand counterarguments, and an evaluation of our approach in a case study\nconcerning attitudes of women to participation in sport.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 06:55:32 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Chalaguine", "Lisa A.", ""], ["Hunter", "Anthony", ""], ["Potts", "Henry W. W.", ""], ["Hamilton", "Fiona L.", ""]]}, {"id": "1805.04396", "submitter": "Alban Laflaqui\\`ere Dr", "authors": "Alban Laflaqui\\`ere", "title": "A Sensorimotor Perspective on Grounding the Semantic of Simple Visual\n  Features", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Machine Learning and Robotics, the semantic content of visual features is\nusually provided to the system by a human who interprets its content. On the\ncontrary, strictly unsupervised approaches have difficulties relating the\nstatistics of sensory inputs to their semantic content without also relying on\nprior knowledge introduced in the system. We proposed in this paper to tackle\nthis problem from a sensorimotor perspective. In line with the Sensorimotor\nContingencies Theory, we make the fundamental assumption that the semantic\ncontent of sensory inputs at least partially stems from the way an agent can\nactively transform it. We illustrate our approach by formalizing how simple\nvisual features can induce invariants in a naive agent's sensorimotor\nexperience, and evaluate it on a simple simulated visual system. Without any a\npriori knowledge about the way its sensorimotor information is encoded, we show\nhow an agent can characterize the uniformity and edge-ness of the visual\nfeatures it interacts with.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 13:41:54 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Laflaqui\u00e8re", "Alban", ""]]}, {"id": "1805.04419", "submitter": "Tuyen Le Pham", "authors": "Le Pham Tuyen, Ngo Anh Vien, Abu Layek, TaeChoong Chung", "title": "Deep Hierarchical Reinforcement Learning Algorithm in Partially\n  Observable Markov Decision Processes", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": "10.1109/ACCESS.2018.2854283", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In recent years, reinforcement learning has achieved many remarkable\nsuccesses due to the growing adoption of deep learning techniques and the rapid\ngrowth in computing power. Nevertheless, it is well-known that flat\nreinforcement learning algorithms are often not able to learn well and\ndata-efficient in tasks having hierarchical structures, e.g. consisting of\nmultiple subtasks. Hierarchical reinforcement learning is a principled approach\nthat is able to tackle these challenging tasks. On the other hand, many\nreal-world tasks usually have only partial observability in which state\nmeasurements are often imperfect and partially observable. The problems of RL\nin such settings can be formulated as a partially observable Markov decision\nprocess (POMDP). In this paper, we study hierarchical RL in POMDP in which the\ntasks have only partial observability and possess hierarchical properties. We\npropose a hierarchical deep reinforcement learning approach for learning in\nhierarchical POMDP. The deep hierarchical RL algorithm is proposed to apply to\nboth MDP and POMDP learning. We evaluate the proposed algorithm on various\nchallenging hierarchical POMDP.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 14:30:21 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Tuyen", "Le Pham", ""], ["Vien", "Ngo Anh", ""], ["Layek", "Abu", ""], ["Chung", "TaeChoong", ""]]}, {"id": "1805.04493", "submitter": "Zhaodong Wang", "authors": "Zhaodong Wang, Matthew E. Taylor", "title": "Interactive Reinforcement Learning with Dynamic Reuse of Prior Knowledge\n  from Human/Agent's Demonstration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning has enjoyed multiple successes in recent years.\nHowever, these successes typically require very large amounts of data before an\nagent achieves acceptable performance. This paper introduces a novel way of\ncombating such requirements by leveraging existing (human or agent) knowledge.\nIn particular, this paper uses demonstrations from agents and humans, allowing\nan untrained agent to quickly achieve high performance. We empirically compare\nwith, and highlight the weakness of, HAT and CHAT, methods of transferring\nknowledge from a source agent/human to a target agent. This paper introduces an\neffective transfer approach, DRoP, combining the offline knowledge\n(demonstrations recorded before learning) with online confidence-based\nperformance analysis. DRoP dynamically involves the demonstrator's knowledge,\nintegrating it into the reinforcement learning agent's online learning loop to\nachieve efficient and robust learning.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 17:12:11 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Wang", "Zhaodong", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1805.04514", "submitter": "Kenneth Young", "authors": "Kenny Young, Baoxiang Wang, Matthew E. Taylor", "title": "Metatrace Actor-Critic: Online Step-size Tuning by Meta-gradient Descent\n  for Reinforcement Learning Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has had many successes in both \"deep\" and\n\"shallow\" settings. In both cases, significant hyperparameter tuning is often\nrequired to achieve good performance. Furthermore, when nonlinear function\napproximation is used, non-stationarity in the state representation can lead to\nlearning instability. A variety of techniques exist to combat this --- most\nnotably large experience replay buffers or the use of multiple parallel actors.\nThese techniques come at the cost of moving away from the online RL problem as\nit is traditionally formulated (i.e., a single agent learning online without\nmaintaining a large database of training examples). Meta-learning can\npotentially help with both these issues by tuning hyperparameters online and\nallowing the algorithm to more robustly adjust to non-stationarity in a\nproblem. This paper applies meta-gradient descent to derive a set of step-size\ntuning algorithms specifically for online RL control with eligibility traces.\nOur novel technique, Metatrace, makes use of an eligibility trace analogous to\nmethods like $TD(\\lambda)$. We explore tuning both a single scalar step-size\nand a separate step-size for each learned parameter. We evaluate Metatrace\nfirst for control with linear function approximation in the classic mountain\ncar problem and then in a noisy, non-stationary version. Finally, we apply\nMetatrace for control with nonlinear function approximation in 5 games in the\nArcade Learning Environment where we explore how it impacts learning speed and\nrobustness to initial step-size choice. Results show that the meta-step-size\nparameter of Metatrace is easy to set, Metatrace can speed learning, and\nMetatrace can allow an RL algorithm to deal with non-stationarity in the\nlearning task.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 20:00:50 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 17:40:08 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Young", "Kenny", ""], ["Wang", "Baoxiang", ""], ["Taylor", "Matthew E.", ""]]}, {"id": "1805.04582", "submitter": "Tammo Rukat", "authors": "Tammo Rukat, Chris C. Holmes, Christopher Yau", "title": "TensOrMachine: Probabilistic Boolean Tensor Decomposition", "comments": "To be published at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG q-bio.GN stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean tensor decomposition approximates data of multi-way binary\nrelationships as product of interpretable low-rank binary factors, following\nthe rules of Boolean algebra. Here, we present its first probabilistic\ntreatment. We facilitate scalable sampling-based posterior inference by\nexploitation of the combinatorial structure of the factor conditionals. Maximum\na posteriori decompositions feature higher accuracies than existing techniques\nthroughout a wide range of simulated conditions. Moreover, the probabilistic\napproach facilitates the treatment of missing data and enables model selection\nwith much greater accuracy. We investigate three real-world data-sets. First,\ntemporal interaction networks in a hospital ward and behavioural data of\nuniversity students demonstrate the inference of instructive latent patterns.\nNext, we decompose a tensor with more than 10 billion data points, indicating\nrelations of gene expression in cancer patients. Not only does this demonstrate\nscalability, it also provides an entirely novel perspective on relational\nproperties of continuous data and, in the present example, on the molecular\nheterogeneity of cancer. Our implementation is available on GitHub:\nhttps://github.com/TammoR/LogicalFactorisationMachines.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 20:23:35 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Rukat", "Tammo", ""], ["Holmes", "Chris C.", ""], ["Yau", "Christopher", ""]]}, {"id": "1805.04661", "submitter": "Filip Klubi\\v{c}ka", "authors": "Filip Klubi\\v{c}ka and Raquel Fern\\'andez", "title": "Examining a hate speech corpus for hate speech detection and popularity\n  prediction", "comments": "8 pages, 1 figure, 10 tables, published in proceedings of 4REAL2018:\n  Workshop on Replicability and Reproducibility of Research Results in Science\n  and Technology of Language", "journal-ref": "In Proceedings of 4REAL Workshop 9-16 (2018)", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As research on hate speech becomes more and more relevant every day, most of\nit is still focused on hate speech detection. By attempting to replicate a hate\nspeech detection experiment performed on an existing Twitter corpus annotated\nfor hate speech, we highlight some issues that arise from doing research in the\nfield of hate speech, which is essentially still in its infancy. We take a\ncritical look at the training corpus in order to understand its biases, while\nalso using it to venture beyond hate speech detection and investigate whether\nit can be used to shed light on other facets of research, such as popularity of\nhate tweets.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 06:00:47 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Klubi\u010dka", "Filip", ""], ["Fern\u00e1ndez", "Raquel", ""]]}, {"id": "1805.04680", "submitter": "Dongyeop Kang", "authors": "Dongyeop Kang and Tushar Khot and Ashish Sabharwal and Eduard Hovy", "title": "AdvEntuRe: Adversarial Training for Textual Entailment with\n  Knowledge-Guided Examples", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of learning textual entailment models with limited\nsupervision (5K-10K training examples), and present two complementary\napproaches for it. First, we propose knowledge-guided adversarial example\ngenerators for incorporating large lexical resources in entailment models via\nonly a handful of rule templates. Second, to make the entailment model - a\ndiscriminator - more robust, we propose the first GAN-style approach for\ntraining it using a natural language example generator that iteratively adjusts\nbased on the discriminator's performance. We demonstrate effectiveness using\ntwo entailment datasets, where the proposed methods increase accuracy by 4.7%\non SciTail and by 2.8% on a 1% training sub-sample of SNLI. Notably, even a\nsingle hand-written rule, negate, improves the accuracy on the negation\nexamples in SNLI by 6.1%.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 07:52:59 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Kang", "Dongyeop", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Hovy", "Eduard", ""]]}, {"id": "1805.04748", "submitter": "Juan Cruz Barsce", "authors": "Juan Cruz Barsce, Jorge A. Palombarini, Ernesto C. Mart\\'inez", "title": "Towards Autonomous Reinforcement Learning: Automatic Setting of\n  Hyper-parameters using Bayesian Optimization", "comments": "Paper submitted to CLEI Electronic Journal. This is an extended\n  version of the conference paper presented at Latin American Computer\n  Conference (CLEI), 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase of machine learning usage by industries and scientific\ncommunities in a variety of tasks such as text mining, image recognition and\nself-driving cars, automatic setting of hyper-parameter in learning algorithms\nis a key factor for achieving satisfactory performance regardless of user\nexpertise in the inner workings of the techniques and methodologies. In\nparticular, for a reinforcement learning algorithm, the efficiency of an agent\nlearning a control policy in an uncertain environment is heavily dependent on\nthe hyper-parameters used to balance exploration with exploitation. In this\nwork, an autonomous learning framework that integrates Bayesian optimization\nwith Gaussian process regression to optimize the hyper-parameters of a\nreinforcement learning algorithm, is proposed. Also, a bandits-based approach\nto achieve a balance between computational costs and decreasing uncertainty\nabout the Q-values, is presented. A gridworld example is used to highlight how\nhyper-parameter configurations of a learning algorithm (SARSA) are iteratively\nimproved based on two performance functions.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 16:42:55 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Barsce", "Juan Cruz", ""], ["Palombarini", "Jorge A.", ""], ["Mart\u00ednez", "Ernesto C.", ""]]}, {"id": "1805.04749", "submitter": "Juan Cruz Barsce", "authors": "Juan Cruz Barsce, Jorge A. Palombarini, Ernesto C. Mart\\'inez", "title": "A Cognitive Approach to Real-time Rescheduling using SOAR-RL", "comments": "Conference paper presented in the Argentinian Congress of Computer\n  Science 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring flexible and efficient manufacturing of customized products in an\nincreasing dynamic and turbulent environment without sacrificing cost\neffectiveness, product quality and on-time delivery has become a key issue for\nmost industrial enterprises. A promising approach to cope with this challenge\nis the integration of cognitive capabilities in systems and processes with the\naim of expanding the knowledge base used to perform managerial and operational\ntasks. In this work, a novel approach to real-time rescheduling is proposed in\norder to achieve sustainable improvements in flexibility and adaptability of\nproduction systems through the integration of artificial cognitive\ncapabilities, involving perception, reasoning/learning and planning skills.\nMoreover, an industrial example is discussed where the SOAR cognitive\narchitecture capabilities are integrated in a software prototype, showing that\nthe approach enables the rescheduling system to respond to events in an\nautonomic way, and to acquire experience through intensive simulation while\nperforming repair tasks.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 16:53:53 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Barsce", "Juan Cruz", ""], ["Palombarini", "Jorge A.", ""], ["Mart\u00ednez", "Ernesto C.", ""]]}, {"id": "1805.04752", "submitter": "Juan Cruz Barsce", "authors": "Jorge A. Palombarini, Juan Cruz Barsce, Ernesto C. Mart\\'inez", "title": "Generating Rescheduling Knowledge using Reinforcement Learning in a\n  Cognitive Architecture", "comments": "Conference paper presented in the Jornadas Argentinas de\n  Inform\\'atica (JAIIO) 2014. arXiv admin note: text overlap with\n  arXiv:1805.04749", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to reach higher degrees of flexibility, adaptability and autonomy in\nmanufacturing systems, it is essential to develop new rescheduling\nmethodologies which resort to cognitive capabilities, similar to those found in\nhuman beings. Artificial cognition is important for designing planning and\ncontrol systems that generate and represent knowledge about heuristics for\nrepair-based scheduling. Rescheduling knowledge in the form of decision rules\nis used to deal with unforeseen events and disturbances reactively in real\ntime, and take advantage of the ability to act interactively with the user to\ncounteract the effects of disruptions. In this work, to achieve the\naforementioned goals, a novel approach to generate rescheduling knowledge in\nthe form of dynamic first-order logical rules is proposed. The proposed\napproach is based on the integration of reinforcement learning with artificial\ncognitive capabilities involving perception and reasoning/learning skills\nembedded in the Soar cognitive architecture. An industrial example is discussed\nshowing that the approach enables the scheduling system to assess its\noperational range in an autonomic way, and to acquire experience through\nintensive simulation while performing repair tasks.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 17:05:56 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Palombarini", "Jorge A.", ""], ["Barsce", "Juan Cruz", ""], ["Mart\u00ednez", "Ernesto C.", ""]]}, {"id": "1805.04770", "submitter": "Tommaso Furlanello", "authors": "Tommaso Furlanello, Zachary C. Lipton, Michael Tschannen, Laurent Itti\n  and Anima Anandkumar", "title": "Born Again Neural Networks", "comments": "Published @ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge distillation (KD) consists of transferring knowledge from one\nmachine learning model (the teacher}) to another (the student). Commonly, the\nteacher is a high-capacity model with formidable performance, while the student\nis more compact. By transferring knowledge, one hopes to benefit from the\nstudent's compactness. %we desire a compact model with performance close to the\nteacher's. We study KD from a new perspective: rather than compressing models,\nwe train students parameterized identically to their teachers. Surprisingly,\nthese {Born-Again Networks (BANs), outperform their teachers significantly,\nboth on computer vision and language modeling tasks. Our experiments with BANs\nbased on DenseNets demonstrate state-of-the-art performance on the CIFAR-10\n(3.5%) and CIFAR-100 (15.5%) datasets, by validation error. Additional\nexperiments explore two distillation objectives: (i) Confidence-Weighted by\nTeacher Max (CWTM) and (ii) Dark Knowledge with Permuted Predictions (DKPP).\nBoth methods elucidate the essential components of KD, demonstrating a role of\nthe teacher outputs on both predicted and non-predicted classes. We present\nexperiments with students of various capacities, focusing on the under-explored\ncase where students overpower teachers. Our experiments show significant\nadvantages from transferring knowledge between DenseNets and ResNets in either\ndirection.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 19:48:50 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2018 10:46:28 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Furlanello", "Tommaso", ""], ["Lipton", "Zachary C.", ""], ["Tschannen", "Michael", ""], ["Itti", "Laurent", ""], ["Anandkumar", "Anima", ""]]}, {"id": "1805.04803", "submitter": "Tiancheng Zhao", "authors": "Tiancheng Zhao and Maxine Eskenazi", "title": "Zero-Shot Dialog Generation with Cross-Domain Latent Actions", "comments": "Accepted as a long paper in SIGDIAL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces zero-shot dialog generation (ZSDG), as a step towards\nneural dialog systems that can instantly generalize to new situations with\nminimal data. ZSDG enables an end-to-end generative dialog system to generalize\nto a new domain for which only a domain description is provided and no training\ndialogs are available. Then a novel learning framework, Action Matching, is\nproposed. This algorithm can learn a cross-domain embedding space that models\nthe semantics of dialog responses which, in turn, lets a neural dialog\ngeneration model generalize to new domains. We evaluate our methods on a new\nsynthetic dialog dataset, and an existing human-human dialog dataset. Results\nshow that our method has superior performance in learning dialog models that\nrapidly adapt their behavior to new domains and suggests promising future\nresearch.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 01:07:32 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Zhao", "Tiancheng", ""], ["Eskenazi", "Maxine", ""]]}, {"id": "1805.04813", "submitter": "Wenhu Chen", "authors": "Shuo Ren, Wenhu Chen, Shujie Liu, Mu Li, Ming Zhou, Shuai Ma", "title": "Triangular Architecture for Rare Language Translation", "comments": "Accepted to ACL 2018, 10 pages, 5 figures, 5 tables (with 5-5-5-5\n  high score)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Machine Translation (NMT) performs poor on the low-resource language\npair $(X,Z)$, especially when $Z$ is a rare language. By introducing another\nrich language $Y$, we propose a novel triangular training architecture (TA-NMT)\nto leverage bilingual data $(Y,Z)$ (may be small) and $(X,Y)$ (can be rich) to\nimprove the translation performance of low-resource pairs. In this triangular\narchitecture, $Z$ is taken as the intermediate latent variable, and translation\nmodels of $Z$ are jointly optimized with a unified bidirectional EM algorithm\nunder the goal of maximizing the translation likelihood of $(X,Y)$. Empirical\nresults demonstrate that our method significantly improves the translation\nquality of rare languages on MultiUN and IWSLT2012 datasets, and achieves even\nbetter performance combining back-translation methods.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 03:35:09 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 04:56:06 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Ren", "Shuo", ""], ["Chen", "Wenhu", ""], ["Liu", "Shujie", ""], ["Li", "Mu", ""], ["Zhou", "Ming", ""], ["Ma", "Shuai", ""]]}, {"id": "1805.04829", "submitter": "Alexander Amini", "authors": "Alexander Amini, Ava Soleimany, Sertac Karaman, Daniela Rus", "title": "Spatial Uncertainty Sampling for End-to-End Control", "comments": "Originally published in Neural Information Processing Systems (NIPS)\n  Workshop on Bayesian Deep Learning 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end trained neural networks (NNs) are a compelling approach to\nautonomous vehicle control because of their ability to learn complex tasks\nwithout manual engineering of rule-based decisions. However, challenging road\nconditions, ambiguous navigation situations, and safety considerations require\nreliable uncertainty estimation for the eventual adoption of full-scale\nautonomous vehicles. Bayesian deep learning approaches provide a way to\nestimate uncertainty by approximating the posterior distribution of weights\ngiven a set of training data. Dropout training in deep NNs approximates\nBayesian inference in a deep Gaussian process and can thus be used to estimate\nmodel uncertainty. In this paper, we propose a Bayesian NN for end-to-end\ncontrol that estimates uncertainty by exploiting feature map correlation during\ntraining. This approach achieves improved model fits, as well as tighter\nuncertainty estimates, than traditional element-wise dropout. We evaluate our\nalgorithms on a challenging dataset collected over many different road types,\ntimes of day, and weather conditions, and demonstrate how uncertainties can be\nused in conjunction with a human controller in a parallel autonomous setting.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 06:19:14 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 01:10:40 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Amini", "Alexander", ""], ["Soleimany", "Ava", ""], ["Karaman", "Sertac", ""], ["Rus", "Daniela", ""]]}, {"id": "1805.04912", "submitter": "Duc Nguyen", "authors": "Duc Minh Nguyen and Evaggelia Tsiligianni and Nikos Deligiannis", "title": "Extendable Neural Matrix Completion", "comments": "5 pages, 2 figures, ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix completion is one of the key problems in signal processing and machine\nlearning, with applications ranging from image pro- cessing and data gathering\nto classification and recommender sys- tems. Recently, deep neural networks\nhave been proposed as la- tent factor models for matrix completion and have\nachieved state- of-the-art performance. Nevertheless, a major problem with\nexisting neural-network-based models is their limited capabilities to extend to\nsamples unavailable at the training stage. In this paper, we propose a deep\ntwo-branch neural network model for matrix completion. The proposed model not\nonly inherits the predictive power of neural net- works, but is also capable of\nextending to partially observed samples outside the training set, without the\nneed of retraining or fine-tuning. Experimental studies on popular movie rating\ndatasets prove the ef- fectiveness of our model compared to the state of the\nart, in terms of both accuracy and extendability.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 16:46:36 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Nguyen", "Duc Minh", ""], ["Tsiligianni", "Evaggelia", ""], ["Deligiannis", "Nikos", ""]]}, {"id": "1805.04955", "submitter": "Thomas Stepleton", "authors": "Thomas Stepleton, Razvan Pascanu, Will Dabney, Siddhant M. Jayakumar,\n  Hubert Soyer, Remi Munos", "title": "Low-pass Recurrent Neural Networks - A memory architecture for\n  longer-term correlation discovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) agents performing complex tasks must be able to\nremember observations and actions across sizable time intervals. This is\nespecially true during the initial learning stages, when exploratory behaviour\ncan increase the delay between specific actions and their effects. Many new or\npopular approaches for learning these distant correlations employ\nbackpropagation through time (BPTT), but this technique requires storing\nobservation traces long enough to span the interval between cause and effect.\nBesides memory demands, learning dynamics like vanishing gradients and slow\nconvergence due to infrequent weight updates can reduce BPTT's practicality;\nmeanwhile, although online recurrent network learning is a developing topic,\nmost approaches are not efficient enough to use as replacements. We propose a\nsimple, effective memory strategy that can extend the window over which BPTT\ncan learn without requiring longer traces. We explore this approach empirically\non a few tasks and discuss its implications.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 21:35:08 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Stepleton", "Thomas", ""], ["Pascanu", "Razvan", ""], ["Dabney", "Will", ""], ["Jayakumar", "Siddhant M.", ""], ["Soyer", "Hubert", ""], ["Munos", "Remi", ""]]}, {"id": "1805.04961", "submitter": "Hang Ma", "authors": "Hang Ma, Glenn Wagner, Ariel Felner, Jiaoyang Li, T. K. Satish Kumar,\n  Sven Koenig", "title": "Multi-Agent Path Finding with Deadlines: Preliminary Results", "comments": "AAMAS 2018, to appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize the problem of multi-agent path finding with deadlines\n(MAPF-DL). The objective is to maximize the number of agents that can reach\ntheir given goal vertices from their given start vertices within a given\ndeadline, without colliding with each other. We first show that the MAPF-DL\nproblem is NP-hard to solve optimally. We then present an optimal MAPF-DL\nalgorithm based on a reduction of the MAPF-DL problem to a flow problem and a\nsubsequent compact integer linear programming formulation of the resulting\nreduced abstracted multi-commodity flow network.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 21:44:19 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Ma", "Hang", ""], ["Wagner", "Glenn", ""], ["Felner", "Ariel", ""], ["Li", "Jiaoyang", ""], ["Kumar", "T. K. Satish", ""], ["Koenig", "Sven", ""]]}, {"id": "1805.05081", "submitter": "Zhongyang Li", "authors": "Zhongyang Li, Xiao Ding, Ting Liu", "title": "Constructing Narrative Event Evolutionary Graph for Script Event\n  Prediction", "comments": "This paper has been accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Script event prediction requires a model to predict the subsequent event\ngiven an existing event context. Previous models based on event pairs or event\nchains cannot make full use of dense event connections, which may limit their\ncapability of event prediction. To remedy this, we propose constructing an\nevent graph to better utilize the event network information for script event\nprediction. In particular, we first extract narrative event chains from large\nquantities of news corpus, and then construct a narrative event evolutionary\ngraph (NEEG) based on the extracted chains. NEEG can be seen as a knowledge\nbase that describes event evolutionary principles and patterns. To solve the\ninference problem on NEEG, we present a scaled graph neural network (SGNN) to\nmodel event interactions and learn better event representations. Instead of\ncomputing the representations on the whole graph, SGNN processes only the\nconcerned nodes each time, which makes our model feasible to large-scale\ngraphs. By comparing the similarity between input context event representations\nand candidate event representations, we can choose the most reasonable\nsubsequent event. Experimental results on widely used New York Times corpus\ndemonstrate that our model significantly outperforms state-of-the-art baseline\nmethods, by using standard multiple choice narrative cloze evaluation.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 09:23:26 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 13:53:08 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Li", "Zhongyang", ""], ["Ding", "Xiao", ""], ["Liu", "Ting", ""]]}, {"id": "1805.05086", "submitter": "S\\'ebastien Ehrhardt", "authors": "Sebastien Ehrhardt and Aron Monszpart and Niloy Mitra and Andrea\n  Vedaldi", "title": "Unsupervised Intuitive Physics from Visual Observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While learning models of intuitive physics is an increasingly active area of\nresearch, current approaches still fall short of natural intelligences in one\nimportant regard: they require external supervision, such as explicit access to\nphysical states, at training and sometimes even at test times. Some authors\nhave relaxed such requirements by supplementing the model with an handcrafted\nphysical simulator. Still, the resulting methods are unable to automatically\nlearn new complex environments and to understand physical interactions within\nthem. In this work, we demonstrated for the first time learning such predictors\ndirectly from raw visual observations and without relying on simulators. We do\nso in two steps: first, we learn to track mechanically-salient objects in\nvideos using causality and equivariance, two unsupervised learning principles\nthat do not require auto-encoding. Second, we demonstrate that the extracted\npositions are sufficient to successfully train visual motion predictors that\ncan take the underlying environment into account. We validate our predictors on\nsynthetic datasets; then, we introduce a new dataset, ROLL4REAL, consisting of\nreal objects rolling on complex terrains (pool table, elliptical bowl, and\nrandom height-field). We show that in all such cases it is possible to learn\nreliable extrapolators of the object trajectories from raw videos alone,\nwithout any form of external supervision and with no more prior knowledge than\nthe choice of a convolutional neural network architecture.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 09:41:23 GMT"}, {"version": "v2", "created": "Fri, 29 Mar 2019 11:15:22 GMT"}], "update_date": "2019-04-01", "authors_parsed": [["Ehrhardt", "Sebastien", ""], ["Monszpart", "Aron", ""], ["Mitra", "Niloy", ""], ["Vedaldi", "Andrea", ""]]}, {"id": "1805.05225", "submitter": "Tamer Alkhouli", "authors": "Albert Zeyer, Tamer Alkhouli, and Hermann Ney", "title": "RETURNN as a Generic Flexible Neural Toolkit with Application to\n  Translation and Speech Recognition", "comments": "accepted as demo paper on ACL 2018", "journal-ref": null, "doi": "10.18653/v1/P18-4022", "report-no": null, "categories": "cs.NE cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compare the fast training and decoding speed of RETURNN of attention\nmodels for translation, due to fast CUDA LSTM kernels, and a fast pure\nTensorFlow beam search decoder. We show that a layer-wise pretraining scheme\nfor recurrent attention models gives over 1% BLEU improvement absolute and it\nallows to train deeper recurrent encoder networks. Promising preliminary\nresults on max. expected BLEU training are presented. We are able to train\nstate-of-the-art models for translation and end-to-end models for speech\nrecognition and show results on WMT 2017 and Switchboard. The flexibility of\nRETURNN allows a fast research feedback loop to experiment with alternative\narchitectures, and its generality allows to use it on a wide range of\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 15:23:40 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 13:33:46 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Zeyer", "Albert", ""], ["Alkhouli", "Tamer", ""], ["Ney", "Hermann", ""]]}, {"id": "1805.05230", "submitter": "Gavin Rens", "authors": "Gavin Rens and Abhaya Nayak and Thomas Meyer", "title": "Maximizing Expected Impact in an Agent Reputation Network -- Technical\n  Report", "comments": "18 pages including bibliography", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many multi-agent systems (MASs) are situated in stochastic environments. Some\nsuch systems that are based on the partially observable Markov decision process\n(POMDP) do not take the benevolence of other agents for granted. We propose a\nnew POMDP-based framework which is general enough for the specification of a\nvariety of stochastic MAS domains involving the impact of agents on each\nother's reputations. A unique feature of this framework is that actions are\nspecified as either undirected (regular) or directed (towards a particular\nagent), and a new directed transition function is provided for modeling the\neffects of reputation in interactions. Assuming that an agent must maintain a\ngood enough reputation to survive in the network, a planning algorithm is\ndeveloped for an agent to select optimal actions in stochastic MASs.\nPreliminary evaluation is provided via an example specification and by\ndetermining the algorithm's complexity.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 15:29:26 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Rens", "Gavin", ""], ["Nayak", "Abhaya", ""], ["Meyer", "Thomas", ""]]}, {"id": "1805.05250", "submitter": "Juliao Braga", "authors": "Juliao Braga and Joao Nuno Silva and Patricia Takako Endo and Jessica\n  Ribas and Nizam Omar", "title": "Blockchain to Improve Security, Knowledge and Collaboration Inter-Agent\n  Communication over Restrict Domains of the Internet Infrastructure", "comments": "13 pages, CSBC 2018, V Workshop pre IETF, July 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes the deployment and implementation of a blockchain to\nimprove the security, knowledge, intelligence and collaboration during the\ninter-agent communication processes in restrict domains of the Internet\nInfrastructure. It is a work that proposes the application of a blockchain,\nplatform independent, on a particular model of agents, but that can be used in\nsimilar proposals, once the results on the specific model were satisfactory.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 15:57:03 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 09:34:32 GMT"}, {"version": "v3", "created": "Wed, 8 Aug 2018 09:39:02 GMT"}, {"version": "v4", "created": "Thu, 9 Aug 2018 09:50:45 GMT"}], "update_date": "2018-08-10", "authors_parsed": [["Braga", "Juliao", ""], ["Silva", "Joao Nuno", ""], ["Endo", "Patricia Takako", ""], ["Ribas", "Jessica", ""], ["Omar", "Nizam", ""]]}, {"id": "1805.05287", "submitter": "Zhibing Zhao", "authors": "Zhibing Zhao, Haoming Li, Junming Wang, Jeffrey Kephart, Nicholas\n  Mattei, Hui Su, Lirong Xia", "title": "A Cost-Effective Framework for Preference Elicitation and Aggregation", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.HC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a cost-effective framework for preference elicitation and\naggregation under the Plackett-Luce model with features. Given a budget, our\nframework iteratively computes the most cost-effective elicitation questions in\norder to help the agents make a better group decision.\n  We illustrate the viability of the framework with experiments on Amazon\nMechanical Turk, which we use to estimate the cost of answering different types\nof elicitation questions. We compare the prediction accuracy of our framework\nwhen adopting various information criteria that evaluate the expected\ninformation gain from a question. Our experiments show carefully designed\ninformation criteria are much more efficient, i.e., they arrive at the correct\nanswer using fewer queries, than randomly asking questions given the budget\nconstraint.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 16:57:36 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2018 13:50:56 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Zhao", "Zhibing", ""], ["Li", "Haoming", ""], ["Wang", "Junming", ""], ["Kephart", "Jeffrey", ""], ["Mattei", "Nicholas", ""], ["Su", "Hui", ""], ["Xia", "Lirong", ""]]}, {"id": "1805.05345", "submitter": "Cristian Danescu-Niculescu-Mizil", "authors": "Justine Zhang, Jonathan P. Chang, Cristian Danescu-Niculescu-Mizil,\n  Lucas Dixon, Yiqing Hua, Nithum Thain, Dario Taraborelli", "title": "Conversations Gone Awry: Detecting Early Signs of Conversational Failure", "comments": "To appear in the Proceedings of ACL 2018, 15 pages, 1 figure. Data,\n  quiz, code and additional information at\n  http://www.cs.cornell.edu/~cristian/Conversations_gone_awry.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.HC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges online social systems face is the prevalence of\nantisocial behavior, such as harassment and personal attacks. In this work, we\nintroduce the task of predicting from the very start of a conversation whether\nit will get out of hand. As opposed to detecting undesirable behavior after the\nfact, this task aims to enable early, actionable prediction at a time when the\nconversation might still be salvaged.\n  To this end, we develop a framework for capturing pragmatic devices---such as\npoliteness strategies and rhetorical prompts---used to start a conversation,\nand analyze their relation to its future trajectory. Applying this framework in\na controlled setting, we demonstrate the feasibility of detecting early warning\nsigns of antisocial behavior in online discussions.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 18:00:03 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Zhang", "Justine", ""], ["Chang", "Jonathan P.", ""], ["Danescu-Niculescu-Mizil", "Cristian", ""], ["Dixon", "Lucas", ""], ["Hua", "Yiqing", ""], ["Thain", "Nithum", ""], ["Taraborelli", "Dario", ""]]}, {"id": "1805.05377", "submitter": "Nicholas FitzGerald", "authors": "Nicholas FitzGerald, Julian Michael, Luheng He, Luke Zettlemoyer", "title": "Large-Scale QA-SRL Parsing", "comments": "10 pages, 3 figures, 8 tables. Accepted to ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new large-scale corpus of Question-Answer driven Semantic Role\nLabeling (QA-SRL) annotations, and the first high-quality QA-SRL parser. Our\ncorpus, QA-SRL Bank 2.0, consists of over 250,000 question-answer pairs for\nover 64,000 sentences across 3 domains and was gathered with a new\ncrowd-sourcing scheme that we show has high precision and good recall at modest\ncost. We also present neural models for two QA-SRL subtasks: detecting argument\nspans for a predicate and generating questions to label the semantic\nrelationship. The best models achieve question accuracy of 82.6% and span-level\naccuracy of 77.6% (under human evaluation) on the full pipelined QA-SRL\nprediction task. They can also, as we show, be used to gather additional\nannotations at low cost.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 18:50:11 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["FitzGerald", "Nicholas", ""], ["Michael", "Julian", ""], ["He", "Luheng", ""], ["Zettlemoyer", "Luke", ""]]}, {"id": "1805.05388", "submitter": "Nikunj Saunshi", "authors": "Mikhail Khodak, Nikunj Saunshi, Yingyu Liang, Tengyu Ma, Brandon\n  Stewart, Sanjeev Arora", "title": "A La Carte Embedding: Cheap but Effective Induction of Semantic Feature\n  Vectors", "comments": "11 pages, 2 figures, To appear in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivations like domain adaptation, transfer learning, and feature learning\nhave fueled interest in inducing embeddings for rare or unseen words, n-grams,\nsynsets, and other textual features. This paper introduces a la carte\nembedding, a simple and general alternative to the usual word2vec-based\napproaches for building such representations that is based upon recent\ntheoretical results for GloVe-like embeddings. Our method relies mainly on a\nlinear transformation that is efficiently learnable using pretrained word\nvectors and linear regression. This transform is applicable on the fly in the\nfuture when a new text feature or rare word is encountered, even if only a\nsingle usage example is available. We introduce a new dataset showing how the a\nla carte method requires fewer examples of words in context to learn\nhigh-quality embeddings and we obtain state-of-the-art results on a nonce task\nand some unsupervised document classification tasks.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 19:11:33 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Khodak", "Mikhail", ""], ["Saunshi", "Nikunj", ""], ["Liang", "Yingyu", ""], ["Ma", "Tengyu", ""], ["Stewart", "Brandon", ""], ["Arora", "Sanjeev", ""]]}, {"id": "1805.05408", "submitter": "Nikita Tomin", "authors": "Nikita Tomin, Victor Kurbatsky, Michael Negnevitsky", "title": "The Concept of the Deep Learning-Based System \"Artificial Dispatcher\" to\n  Power System Control and Dispatch", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Year by year control of normal and emergency conditions of up-to-date power\nsystems becomes an increasingly complicated problem. With the increasing\ncomplexity the existing control system of power system conditions which\nincludes operative actions of the dispatcher and work of special automatic\ndevices proves to be insufficiently effective more and more frequently, which\nraises risks of dangerous and emergency conditions in power systems. The paper\nis aimed at compensating for the shortcomings of man (a cognitive barrier,\nexposure to stresses and so on) and automatic devices by combining their strong\npoints, i.e. the dispatcher's intelligence and the speed of automatic devices\nby virtue of development of the intelligent system \"Artificial dispatcher\" on\nthe basis of deep machine learning technology. For realization of the system\n\"Artificial dispatcher\" in addition to deep learning it is planned to attract\nthe game theory approaches to formalize work of the up-to-date power system as\na game problem. The \"gain\" for \"Artificial dispatcher\" will consist in bringing\nin a power system in the normal steady-state or post-emergency conditions by\nmeans of the required control actions.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 07:21:42 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Tomin", "Nikita", ""], ["Kurbatsky", "Victor", ""], ["Negnevitsky", "Michael", ""]]}, {"id": "1805.05445", "submitter": "Markus Hecher", "authors": "Johannes K. Fichte, Michael Morak, Markus Hecher, Stefan Woltran", "title": "Exploiting Treewidth for Projected Model Counting and its Limits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a novel algorithm to solve projected model\ncounting (PMC). PMC asks to count solutions of a Boolean formula with respect\nto a given set of projected variables, where multiple solutions that are\nidentical when restricted to the projected variables count as only one\nsolution. Our algorithm exploits small treewidth of the primal graph of the\ninput instance. It runs in time $O({2^{2^{k+4}} n^2})$ where k is the treewidth\nand n is the input size of the instance. In other words, we obtain that the\nproblem PMC is fixed-parameter tractable when parameterized by treewidth.\nFurther, we take the exponential time hypothesis (ETH) into consideration and\nestablish lower bounds of bounded treewidth algorithms for PMC, yielding\nasymptotically tight runtime bounds of our algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 21:02:28 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Fichte", "Johannes K.", ""], ["Morak", "Michael", ""], ["Hecher", "Markus", ""], ["Woltran", "Stefan", ""]]}, {"id": "1805.05447", "submitter": "Maartje Ter Hoeve", "authors": "Maartje ter Hoeve, Anne Schuth, Daan Odijk, Maarten de Rijke", "title": "Faithfully Explaining Rankings in a News Recommender System", "comments": "9 pages, 3 tables, 3 figures, 4 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing demand for algorithms to explain their outcomes. So\nfar, there is no method that explains the rankings produced by a ranking\nalgorithm. To address this gap we propose LISTEN, a LISTwise ExplaiNer, to\nexplain rankings produced by a ranking algorithm. To efficiently use LISTEN in\nproduction, we train a neural network to learn the underlying explanation space\ncreated by LISTEN; we call this model Q-LISTEN. We show that LISTEN produces\nfaithful explanations and that Q-LISTEN is able to learn these explanations.\nMoreover, we show that LISTEN is safe to use in a real world environment: users\nof a news recommendation system do not behave significantly differently when\nthey are exposed to explanations generated by LISTEN instead of manually\ngenerated explanations.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 21:13:04 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["ter Hoeve", "Maartje", ""], ["Schuth", "Anne", ""], ["Odijk", "Daan", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1805.05456", "submitter": "Manish Sharma", "authors": "Manish Sharma, Akash Anand, Rupika Srivastava and Lakshmi Kaligounder", "title": "Wearable Audio and IMU Based Shot Detection in Racquet Sports", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wearables like smartwatches which are embedded with sensors and powerful\nprocessors, provide a strong platform for development of analytics solutions in\nsports domain. To analyze players' games, while motion sensor based shot\ndetection has been extensively studied in sports like Tennis, Golf, Baseball;\nTable Tennis and Badminton are relatively less explored due to possible less\nintense hand motion during shots. In our paper, we propose a novel,\ncomputationally inexpensive and real-time system for shot detection in table\ntennis, based on fusion of Inertial Measurement Unit (IMU) and audio sensor\ndata embedded in a wrist-worn wearable. The system builds upon our presented\nmethodology for synchronizing IMU and audio sensor input in time using detected\nshots and achieves 95.6% accuracy. To our knowledge, it is the first\nfusion-based solution for sports analysis in wearables. Shot detectors for\nother racquet sports as well as further analytics to provide features like shot\nclassification, rally analysis and recommendations, can easily be built over\nour proposed solution.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 21:31:59 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Sharma", "Manish", ""], ["Anand", "Akash", ""], ["Srivastava", "Rupika", ""], ["Kaligounder", "Lakshmi", ""]]}, {"id": "1805.05492", "submitter": "Pramod Kaushik Mudrakarta", "authors": "Pramod Kaushik Mudrakarta, Ankur Taly, Mukund Sundararajan, Kedar\n  Dhamdhere", "title": "Did the Model Understand the Question?", "comments": "ACL 2018 long paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze state-of-the-art deep learning models for three tasks: question\nanswering on (1) images, (2) tables, and (3) passages of text. Using the notion\nof \\emph{attribution} (word importance), we find that these deep networks often\nignore important question terms. Leveraging such behavior, we perturb questions\nto craft a variety of adversarial examples. Our strongest attacks drop the\naccuracy of a visual question answering model from $61.1\\%$ to $19\\%$, and that\nof a tabular question answering model from $33.5\\%$ to $3.3\\%$. Additionally,\nwe show how attributions can strengthen attacks proposed by Jia and Liang\n(2017) on paragraph comprehension models. Our results demonstrate that\nattributions can augment standard measures of accuracy and empower\ninvestigation of model performance. When a model is accurate but for the wrong\nreasons, attributions can surface erroneous logic in the model that indicates\ninadequacies in the test data.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 23:10:28 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Mudrakarta", "Pramod Kaushik", ""], ["Taly", "Ankur", ""], ["Sundararajan", "Mukund", ""], ["Dhamdhere", "Kedar", ""]]}, {"id": "1805.05518", "submitter": "EPTCS", "authors": "Yamine Ait Ameur (IRIT/INPT-ENSEEIHT, Toulouse, France), Idir Ait\n  Sadoune (LRI/CentraleSupelec/Paris-Saclay University, Plateau de Saclay,\n  France), Kahina Hacid (IRIT/INPT-ENSEEIHT, Toulouse, France), Linda Mohand\n  Oussaid (LRI/CentraleSupelec/Paris-Saclay University, Plateau de Saclay,\n  France)", "title": "Formal Modelling of Ontologies : An Event-B based Approach Using the\n  Rodin Platform", "comments": "In Proceedings IMPEX 2017 and FM&MDD 2017, arXiv:1805.04636", "journal-ref": "EPTCS 271, 2018, pp. 24-33", "doi": "10.4204/EPTCS.271.2", "report-no": null, "categories": "cs.SE cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on the results of the French ANR IMPEX research project\ndealing with making explicit domain knowledge in design models. Ontologies are\nformalised as theories with sets, axioms, theorems and reasoning rules. They\nare integrated to design models through an annotation mechanism. Event-B has\nbeen chosen as the ground formal modelling technique for all our developments.\nIn this paper, we particularly describe how ontologies are formalised as\nEvent-B theories.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 01:20:18 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Ameur", "Yamine Ait", "", "IRIT/INPT-ENSEEIHT, Toulouse, France"], ["Sadoune", "Idir Ait", "", "LRI/CentraleSupelec/Paris-Saclay University, Plateau de Saclay,\n  France"], ["Hacid", "Kahina", "", "IRIT/INPT-ENSEEIHT, Toulouse, France"], ["Oussaid", "Linda Mohand", "", "LRI/CentraleSupelec/Paris-Saclay University, Plateau de Saclay,\n  France"]]}, {"id": "1805.05537", "submitter": "Jungsik Hwang", "authors": "Jungsik Hwang, Jun Tani", "title": "A Dynamic Neural Network Approach to Generating Robot's Novel Actions: A\n  Simulation Experiment", "comments": "9 pages, 5 figures, Accepted in the 15th International Conference on\n  Ubiquitous Robots (UR2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we investigate how a robot can generate novel and creative\nactions from its own experience of learning basic actions. Inspired by a\nmachine learning approach to computational creativity, we propose a dynamic\nneural network model that can learn and generate robot's actions. We conducted\na set of simulation experiments with a humanoid robot. The results showed that\nthe proposed model was able to learn the basic actions and also to generate\nnovel actions by modulating and combining those learned actions. The analysis\non the neural activities illustrated that the ability to generate creative\nactions emerged from the model's nonlinear memory structure self-organized\nduring training. The results also showed that the different way of learning the\nbasic actions induced the self-organization of the memory structure with the\ndifferent characteristics, resulting in the generation of different levels of\ncreative actions. Our approach can be utilized in human-robot interaction in\nwhich a user can interactively explore the robot's memory to control its\nbehavior and also discover other novel actions.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 02:53:36 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Hwang", "Jungsik", ""], ["Tani", "Jun", ""]]}, {"id": "1805.05603", "submitter": "Rakshit Agrawal", "authors": "Jack W. Stokes, Rakshit Agrawal, Geoff McDonald", "title": "Neural Classification of Malicious Scripts: A study with JavaScript and\n  VBScript", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious scripts are an important computer infection threat vector. Our\nanalysis reveals that the two most prevalent types of malicious scripts include\nJavaScript and VBScript. The percentage of detected JavaScript attacks are on\nthe rise. To address these threats, we investigate two deep recurrent models,\nLaMP (LSTM and Max Pooling) and CPoLS (Convoluted Partitioning of Long\nSequences), which process JavaScript and VBScript as byte sequences. Lower\nlayers capture the sequential nature of these byte sequences while higher\nlayers classify the resulting embedding as malicious or benign. Unlike\npreviously proposed solutions, our models are trained in an end-to-end fashion\nallowing discriminative training even for the sequential processing layers.\nEvaluating these models on a large corpus of 296,274 JavaScript files indicates\nthat the best performing LaMP model has a 65.9% true positive rate (TPR) at a\nfalse positive rate (FPR) of 1.0%. Similarly, the best CPoLS model has a TPR of\n45.3% at an FPR of 1.0%. LaMP and CPoLS yield a TPR of 69.3% and 67.9%,\nrespectively, at an FPR of 1.0% on a collection of 240,504 VBScript files.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 07:22:24 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Stokes", "Jack W.", ""], ["Agrawal", "Rakshit", ""], ["McDonald", "Geoff", ""]]}, {"id": "1805.05622", "submitter": "Marko Smilevski", "authors": "Marko Smilevski, Ilija Lalkovski, Gjorgji Madjarov", "title": "Stories for Images-in-Sequence by using Visual and Narrative Components", "comments": "12 pages, 4 figures, ICT Innovations 2018", "journal-ref": "ICT Innovations 2018. Engineering and Life Sciences. ICT 2018.\n  Communications in Computer and Information Science, vol 940. Springer, Cham\n  (2018) pp. 148-159", "doi": "10.1007/978-3-030-00825-3_13", "report-no": null, "categories": "cs.AI cs.CL cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research in AI is focusing towards generating narrative stories about\nvisual scenes. It has the potential to achieve more human-like understanding\nthan just basic description generation of images- in-sequence. In this work, we\npropose a solution for generating stories for images-in-sequence that is based\non the Sequence to Sequence model. As a novelty, our encoder model is composed\nof two separate encoders, one that models the behaviour of the image sequence\nand other that models the sentence-story generated for the previous image in\nthe sequence of images. By using the image sequence encoder we capture the\ntemporal dependencies between the image sequence and the sentence-story and by\nusing the previous sentence-story encoder we achieve a better story flow. Our\nsolution generates long human-like stories that not only describe the visual\ncontext of the image sequence but also contains narrative and evaluative\nlanguage. The obtained results were confirmed by manual human evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 08:15:40 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 20:36:51 GMT"}, {"version": "v3", "created": "Sat, 22 Sep 2018 23:49:05 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Smilevski", "Marko", ""], ["Lalkovski", "Ilija", ""], ["Madjarov", "Gjorgji", ""]]}, {"id": "1805.05714", "submitter": "Tom Hanika", "authors": "Tom Hanika and Friedrich Martin Schneider and Gerd Stumme", "title": "Intrinsic dimension and its application to association rules", "comments": "4 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The curse of dimensionality in the realm of association rules is twofold.\nFirstly, we have the well known exponential increase in computational\ncomplexity with increasing item set size. Secondly, there is a \\emph{related\ncurse} concerned with the distribution of (spare) data itself in high\ndimension. The former problem is often coped with by projection, i.e., feature\nselection, whereas the best known strategy for the latter is avoidance. This\nwork summarizes the first attempt to provide a computationally feasible method\nfor measuring the extent of dimension curse present in a data set with respect\nto a particular class machine of learning procedures. This recent development\nenables the application of various other methods from geometric analysis to be\ninvestigated and applied in machine learning procedures in the presence of high\ndimension.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 11:40:50 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Hanika", "Tom", ""], ["Schneider", "Friedrich Martin", ""], ["Stumme", "Gerd", ""]]}, {"id": "1805.05769", "submitter": "Ariel Rosenfeld", "authors": "Ariel Rosenfeld, Moshe Cohen, Matthew E. Taylor, Sarit Kraus", "title": "Leveraging human knowledge in tabular reinforcement learning: A study of\n  human subjects", "comments": "To appear in the Knowledge Engineering Review (KER) journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) can be extremely effective in solving complex,\nreal-world problems. However, injecting human knowledge into an RL agent may\nrequire extensive effort and expertise on the human designer's part. To date,\nhuman factors are generally not considered in the development and evaluation of\npossible RL approaches. In this article, we set out to investigate how\ndifferent methods for injecting human knowledge are applied, in practice, by\nhuman designers of varying levels of knowledge and skill. We perform the first\nempirical evaluation of several methods, including a newly proposed method\nnamed SASS which is based on the notion of similarities in the agent's\nstate-action space. Through this human study, consisting of 51 human\nparticipants, we shed new light on the human factors that play a key role in\nRL. We find that the classical reward shaping technique seems to be the most\nnatural method for most designers, both expert and non-expert, to speed up RL.\nHowever, we further find that our proposed method SASS can be effectively and\nefficiently combined with reward shaping, and provides a beneficial alternative\nto using only a single speedup method with minimal human designer effort\noverhead.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 13:51:31 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Rosenfeld", "Ariel", ""], ["Cohen", "Moshe", ""], ["Taylor", "Matthew E.", ""], ["Kraus", "Sarit", ""]]}, {"id": "1805.05773", "submitter": "Vikram Mullachery", "authors": "Vikram Mullachery, Samarth Tiwari", "title": "Online Bandit Linear Optimization: A Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces the concepts around Online Bandit Linear Optimization\nand explores an efficient setup called SCRiBLe (Self-Concordant Regularization\nin Bandit Learning) created by Abernethy et. al.\\cite{abernethy}. The SCRiBLe\nsetup and algorithm yield a $O(\\sqrt{T})$ regret bound and polynomial run time\ncomplexity bound on the dimension of the input space. In this article we build\nup to the bandit linear optimization case and study SCRiBLe.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 18:12:19 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Mullachery", "Vikram", ""], ["Tiwari", "Samarth", ""]]}, {"id": "1805.05827", "submitter": "Oleksii Abramenko", "authors": "Oleksii Abramenko and Alexander Jung", "title": "Graph Signal Sampling via Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate the problem of sampling and recovering clustered graph signal as\na multi-armed bandit (MAB) problem. This formulation lends naturally to\nlearning sampling strategies using the well-known gradient MAB algorithm. In\nparticular, the sampling strategy is represented as a probability distribution\nover the individual arms of the MAB and optimized using gradient ascent. Some\nillustrative numerical experiments indicate that the sampling strategies based\non the gradient MAB algorithm outperform existing sampling methods.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 14:46:45 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Abramenko", "Oleksii", ""], ["Jung", "Alexander", ""]]}, {"id": "1805.05838", "submitter": "Tribhuvanesh Orekondy", "authors": "Tribhuvanesh Orekondy, Seong Joon Oh, Yang Zhang, Bernt Schiele, Mario\n  Fritz", "title": "Gradient-Leaks: Understanding and Controlling Deanonymization in\n  Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CV cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Federated Learning (FL) systems are gaining popularity as a solution to\ntraining Machine Learning (ML) models from large-scale user data collected on\npersonal devices (e.g., smartphones) without their raw data leaving the device.\nAt the core of FL is a network of anonymous user devices sharing training\ninformation (model parameter updates) computed locally on personal data.\nHowever, the type and degree to which user-specific information is encoded in\nthe model updates is poorly understood. In this paper, we identify model\nupdates encode subtle variations in which users capture and generate data. The\nvariations provide a strong statistical signal, allowing an adversary to\neffectively deanonymize participating devices using a limited set of auxiliary\ndata. We analyze resulting deanonymization attacks on diverse tasks on\nreal-world (anonymized) user-generated data across a range of closed- and\nopen-world scenarios. We study various strategies to mitigate the risks of\ndeanonymization. As random perturbation methods do not offer convincing\noperating points, we propose data-augmentation strategies which introduces\nadversarial biases in device data and thereby, offer substantial protection\nagainst deanonymization threats with little effect on utility.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 15:12:45 GMT"}, {"version": "v2", "created": "Wed, 2 Oct 2019 12:02:07 GMT"}, {"version": "v3", "created": "Sun, 13 Sep 2020 15:56:36 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["Orekondy", "Tribhuvanesh", ""], ["Oh", "Seong Joon", ""], ["Zhang", "Yang", ""], ["Schiele", "Bernt", ""], ["Fritz", "Mario", ""]]}, {"id": "1805.05855", "submitter": "Xin-She Yang", "authors": "Xin-She Yang", "title": "Social Algorithms", "comments": "Encyclopedia of Complexity and Systems Science, 2017", "journal-ref": null, "doi": "10.1007/978-3-642-27737-5_678-1", "report-no": null, "categories": "cs.NE cs.AI cs.CC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article concerns the review of a special class of swarm intelligence\nbased algorithms for solving optimization problems and these algorithms can be\nreferred to as social algorithms. Social algorithms use multiple agents and the\nsocial interactions to design rules for algorithms so as to mimic certain\nsuccessful characteristics of the social/biological systems such as ants, bees,\nbats, birds and animals.\n", "versions": [{"version": "v1", "created": "Sun, 22 Apr 2018 13:44:18 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Yang", "Xin-She", ""]]}, {"id": "1805.05859", "submitter": "Chris Russell", "authors": "Joshua R. Loftus, Chris Russell, Matt J. Kusner, and Ricardo Silva", "title": "Causal Reasoning for Algorithmic Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we argue for the importance of causal reasoning in creating\nfair algorithms for decision making. We give a review of existing approaches to\nfairness, describe work in causality necessary for the understanding of causal\napproaches, argue why causality is necessary for any approach that wishes to be\nfair, and give a detailed analysis of the many recent approaches to\ncausality-based fairness.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 15:42:35 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Loftus", "Joshua R.", ""], ["Russell", "Chris", ""], ["Kusner", "Matt J.", ""], ["Silva", "Ricardo", ""]]}, {"id": "1805.05935", "submitter": "Daniel R. Jiang", "authors": "Daniel R. Jiang, Emmanuel Ekwedike, Han Liu", "title": "Feedback-Based Tree Search for Reinforcement Learning", "comments": "19 pages, to be presented at ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by recent successes of Monte-Carlo tree search (MCTS) in a number of\nartificial intelligence (AI) application domains, we propose a model-based\nreinforcement learning (RL) technique that iteratively applies MCTS on batches\nof small, finite-horizon versions of the original infinite-horizon Markov\ndecision process. The terminal condition of the finite-horizon problems, or the\nleaf-node evaluator of the decision tree generated by MCTS, is specified using\na combination of an estimated value function and an estimated policy function.\nThe recommendations generated by the MCTS procedure are then provided as\nfeedback in order to refine, through classification and regression, the\nleaf-node evaluator for the next iteration. We provide the first sample\ncomplexity bounds for a tree search-based RL algorithm. In addition, we show\nthat a deep neural network implementation of the technique can create a\ncompetitive AI agent for the popular multi-player online battle arena (MOBA)\ngame King of Glory.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 17:53:58 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Jiang", "Daniel R.", ""], ["Ekwedike", "Emmanuel", ""], ["Liu", "Han", ""]]}, {"id": "1805.06020", "submitter": "Tambet Matiisen", "authors": "Tambet Matiisen, Aqeel Labash, Daniel Majoral, Jaan Aru, Raul Vicente", "title": "Do deep reinforcement learning agents model intentions?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inferring other agents' mental states such as their knowledge, beliefs and\nintentions is thought to be essential for effective interactions with other\nagents. Recently, multiagent systems trained via deep reinforcement learning\nhave been shown to succeed in solving different tasks, but it remains unclear\nhow each agent modeled or represented other agents in their environment. In\nthis work we test whether deep reinforcement learning agents explicitly\nrepresent other agents' intentions (their specific aims or goals) during a task\nin which the agents had to coordinate the covering of different spots in a 2D\nenvironment. In particular, we tracked over time the performance of a linear\ndecoder trained to predict the final goal of all agents from the hidden state\nof each agent's neural network controller. We observed that the hidden layers\nof agents represented explicit information about other agents' goals, i.e. the\ntarget landmark they ended up covering. We also performed a series of\nexperiments, in which some agents were replaced by others with fixed goals, to\ntest the level of generalization of the trained agents. We noticed that during\nthe training phase the agents developed a differential preference for each\ngoal, which hindered generalization. To alleviate the above problem, we propose\nsimple changes to the MADDPG training algorithm which leads to better\ngeneralization against unseen agents. We believe that training protocols\npromoting more active intention reading mechanisms, e.g. by preventing simple\nsymmetry-breaking solutions, is a promising direction towards achieving a more\nrobust generalization in different cooperative and competitive tasks.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 20:15:05 GMT"}, {"version": "v2", "created": "Mon, 21 May 2018 14:42:57 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Matiisen", "Tambet", ""], ["Labash", "Aqeel", ""], ["Majoral", "Daniel", ""], ["Aru", "Jaan", ""], ["Vicente", "Raul", ""]]}, {"id": "1805.06061", "submitter": "Roy Schwartz", "authors": "Roy Schwartz, Sam Thomson, and Noah A. Smith", "title": "SoPa: Bridging CNNs, RNNs, and Weighted Finite-State Machines", "comments": "ACL 2018, 12 pages. Code available at\n  https://github.com/Noahs-ARK/soft_patterns", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent and convolutional neural networks comprise two distinct families of\nmodels that have proven to be useful for encoding natural language utterances.\nIn this paper we present SoPa, a new model that aims to bridge these two\napproaches. SoPa combines neural representation learning with weighted\nfinite-state automata (WFSAs) to learn a soft version of traditional surface\npatterns. We show that SoPa is an extension of a one-layer CNN, and that such\nCNNs are equivalent to a restricted version of SoPa, and accordingly, to a\nrestricted form of WFSA. Empirically, on three text classification tasks, SoPa\nis comparable or better than both a BiLSTM (RNN) baseline and a CNN baseline,\nand is particularly useful in small data settings.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 23:03:01 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Schwartz", "Roy", ""], ["Thomson", "Sam", ""], ["Smith", "Noah A.", ""]]}, {"id": "1805.06064", "submitter": "Qingyun Wang", "authors": "Qingyun Wang, Zhihao Zhou, Lifu Huang, Spencer Whitehead, Boliang\n  Zhang, Heng Ji, Kevin Knight", "title": "Paper Abstract Writing through Editing Mechanism", "comments": "* Equal contribution. 6 pages. Accepted by ACL 2018; The code and\n  dataset are available at https://github.com/EagleW/Writing-editing-Network", "journal-ref": null, "doi": "10.18653/v1/P18-2042", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a paper abstract writing system based on an attentive neural\nsequence-to-sequence model that can take a title as input and automatically\ngenerate an abstract. We design a novel Writing-editing Network that can attend\nto both the title and the previously generated abstract drafts and then\niteratively revise and polish the abstract. With two series of Turing tests,\nwhere the human judges are asked to distinguish the system-generated abstracts\nfrom human-written ones, our system passes Turing tests by junior domain\nexperts at a rate up to 30% and by non-expert at a rate up to 80%.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 23:13:23 GMT"}], "update_date": "2020-11-03", "authors_parsed": [["Wang", "Qingyun", ""], ["Zhou", "Zhihao", ""], ["Huang", "Lifu", ""], ["Whitehead", "Spencer", ""], ["Zhang", "Boliang", ""], ["Ji", "Heng", ""], ["Knight", "Kevin", ""]]}, {"id": "1805.06085", "submitter": "Jungwook Choi", "authors": "Jungwook Choi, Zhuo Wang, Swagath Venkataramani, Pierce I-Jen Chuang,\n  Vijayalakshmi Srinivasan, Kailash Gopalakrishnan", "title": "PACT: Parameterized Clipping Activation for Quantized Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning algorithms achieve high classification accuracy at the expense\nof significant computation cost. To address this cost, a number of quantization\nschemes have been proposed - but most of these techniques focused on quantizing\nweights, which are relatively smaller in size compared to activations. This\npaper proposes a novel quantization scheme for activations during training -\nthat enables neural networks to work well with ultra low precision weights and\nactivations without any significant accuracy degradation. This technique,\nPArameterized Clipping acTivation (PACT), uses an activation clipping parameter\n$\\alpha$ that is optimized during training to find the right quantization\nscale. PACT allows quantizing activations to arbitrary bit precisions, while\nachieving much better accuracy relative to published state-of-the-art\nquantization schemes. We show, for the first time, that both weights and\nactivations can be quantized to 4-bits of precision while still achieving\naccuracy comparable to full precision networks across a range of popular models\nand datasets. We also show that exploiting these reduced-precision\ncomputational units in hardware can enable a super-linear improvement in\ninferencing performance due to a significant reduction in the area of\naccelerator compute engines coupled with the ability to retain the quantized\nmodel and activation data in on-chip memories.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 01:19:43 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 07:33:19 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Choi", "Jungwook", ""], ["Wang", "Zhuo", ""], ["Venkataramani", "Swagath", ""], ["Chuang", "Pierce I-Jen", ""], ["Srinivasan", "Vijayalakshmi", ""], ["Gopalakrishnan", "Kailash", ""]]}, {"id": "1805.06104", "submitter": "Sina Shaham", "authors": "Sina Shaham, Ming Ding, Bo Liu, Zihuai Lin, Jun Li", "title": "Privacy Preservation in Location-Based Services: A Novel Metric and\n  Attack Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen rising needs for location-based services in our\neveryday life. Aside from the many advantages provided by these services, they\nhave caused serious concerns regarding the location privacy of users. An\nadversary such as an untrusted location-based server can monitor the queried\nlocations by a user to infer critical information such as the user's home\naddress, health conditions, shopping habits, etc. To address this issue,\ndummy-based algorithms have been developed to increase the anonymity of users,\nand thus, protecting their privacy. Unfortunately, the existing algorithms only\nconsider a limited amount of side information known by an adversary which may\nface more serious challenges in practice. In this paper, we incorporate a new\ntype of side information based on consecutive location changes of users and\npropose a new metric called transition-entropy to investigate the location\nprivacy preservation, followed by two algorithms to improve the\ntransition-entropy for a given dummy generation algorithm. Then, we develop an\nattack model based on the Viterbi algorithm which can significantly threaten\nthe location privacy of the users. Next, in order to protect the users from\nViterbi attack, we propose an algorithm called robust dummy generation (RDG)\nwhich can resist against the Viterbi attack while maintaining a high\nperformance in terms of the privacy metrics introduced in the paper. All the\nalgorithms are applied and analyzed on a real-life dataset.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 02:51:10 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Shaham", "Sina", ""], ["Ding", "Ming", ""], ["Liu", "Bo", ""], ["Lin", "Zihuai", ""], ["Li", "Jun", ""]]}, {"id": "1805.06126", "submitter": "Igor Halperin", "authors": "Igor Halperin and Ilya Feldshteyn", "title": "Market Self-Learning of Signals, Impact and Optimal Trading: Invisible\n  Hand Inference with Free Energy", "comments": "56 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.CP cs.AI cs.LG nlin.AO q-fin.PM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple model of a non-equilibrium self-organizing market where\nasset prices are partially driven by investment decisions of a bounded-rational\nagent. The agent acts in a stochastic market environment driven by various\nexogenous \"alpha\" signals, agent's own actions (via market impact), and noise.\nUnlike traditional agent-based models, our agent aggregates all traders in the\nmarket, rather than being a representative agent. Therefore, it can be\nidentified with a bounded-rational component of the market itself, providing a\nparticular implementation of an Invisible Hand market mechanism. In such\nsetting, market dynamics are modeled as a fictitious self-play of such\nbounded-rational market-agent in its adversarial stochastic environment. As\nrewards obtained by such self-playing market agent are not observed from market\ndata, we formulate and solve a simple model of such market dynamics based on a\nneuroscience-inspired Bounded Rational Information Theoretic Inverse\nReinforcement Learning (BRIT-IRL). This results in effective asset price\ndynamics with a non-linear mean reversion - which in our model is generated\ndynamically, rather than being postulated. We argue that our model can be used\nin a similar way to the Black-Litterman model. In particular, it represents, in\na simple modeling framework, market views of common predictive signals, market\nimpacts and implied optimal dynamic portfolio allocations, and can be used to\nassess values of private signals. Moreover, it allows one to quantify a\n\"market-implied\" optimal investment strategy, along with a measure of market\nrationality. Our approach is numerically light, and can be implemented using\nstandard off-the-shelf software such as TensorFlow.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 04:37:01 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Halperin", "Igor", ""], ["Feldshteyn", "Ilya", ""]]}, {"id": "1805.06146", "submitter": "Xianfu Chen", "authors": "Xianfu Chen, Honggang Zhang, Celimuge Wu, Shiwen Mao, Yusheng Ji,\n  Mehdi Bennis", "title": "Optimized Computation Offloading Performance in Virtual Edge Computing\n  Systems via Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the quality of computation experience for mobile devices,\nmobile-edge computing (MEC) is a promising paradigm by providing computing\ncapabilities in close proximity within a sliced radio access network (RAN),\nwhich supports both traditional communication and MEC services. Nevertheless,\nthe design of computation offloading policies for a virtual MEC system remains\nchallenging. Specifically, whether to execute a computation task at the mobile\ndevice or to offload it for MEC server execution should adapt to the\ntime-varying network dynamics. In this paper, we consider MEC for a\nrepresentative mobile user in an ultra-dense sliced RAN, where multiple base\nstations (BSs) are available to be selected for computation offloading. The\nproblem of solving an optimal computation offloading policy is modelled as a\nMarkov decision process, where our objective is to maximize the long-term\nutility performance whereby an offloading decision is made based on the task\nqueue state, the energy queue state as well as the channel qualities between MU\nand BSs. To break the curse of high dimensionality in state space, we first\npropose a double deep Q-network (DQN) based strategic computation offloading\nalgorithm to learn the optimal policy without knowing a priori knowledge of\nnetwork dynamics. Then motivated by the additive structure of the utility\nfunction, a Q-function decomposition technique is combined with the double DQN,\nwhich leads to novel learning algorithm for the solving of stochastic\ncomputation offloading. Numerical experiments show that our proposed learning\nalgorithms achieve a significant improvement in computation offloading\nperformance compared with the baseline policies.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 06:21:02 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Chen", "Xianfu", ""], ["Zhang", "Honggang", ""], ["Wu", "Celimuge", ""], ["Mao", "Shiwen", ""], ["Ji", "Yusheng", ""], ["Bennis", "Mehdi", ""]]}, {"id": "1805.06148", "submitter": "Charmin Asirimath Pingamage Don", "authors": "Charmin Asirimath, Jayampathy Ratnayake, Chathuranga Weeraddana", "title": "Critical Points to Determine Persistence Homology", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation of the simplicial complexes of a large point cloud often relies\non extracting a sample, to reduce the associated computational burden. The\nstudy considers sampling critical points of a Morse function associated to a\npoint cloud, to approximate the Vietoris-Rips complex or the witness complex\nand compute persistence homology. The effectiveness of the novel approach is\ncompared with the farthest point sampling, in a context of classifying human\nface images into ethnics groups using persistence homology.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 06:25:21 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Asirimath", "Charmin", ""], ["Ratnayake", "Jayampathy", ""], ["Weeraddana", "Chathuranga", ""]]}, {"id": "1805.06150", "submitter": "Aleksandra Faust", "authors": "Pararth Shah, Marek Fiser, Aleksandra Faust, J. Chase Kew, and Dilek\n  Hakkani-Tur", "title": "FollowNet: Robot Navigation by Following Natural Language Directions\n  with Deep Reinforcement Learning", "comments": "7 pages, 8 figures", "journal-ref": "Third Workshop in Machine Learning in the Planning and Control of\n  Robot Motion at ICRA, 2018", "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding and following directions provided by humans can enable robots\nto navigate effectively in unknown situations. We present FollowNet, an\nend-to-end differentiable neural architecture for learning multi-modal\nnavigation policies. FollowNet maps natural language instructions as well as\nvisual and depth inputs to locomotion primitives. FollowNet processes\ninstructions using an attention mechanism conditioned on its visual and depth\ninput to focus on the relevant parts of the command while performing the\nnavigation task. Deep reinforcement learning (RL) a sparse reward learns\nsimultaneously the state representation, the attention function, and control\npolicies. We evaluate our agent on a dataset of complex natural language\ndirections that guide the agent through a rich and realistic dataset of\nsimulated homes. We show that the FollowNet agent learns to execute previously\nunseen instructions described with a similar vocabulary, and successfully\nnavigates along paths not encountered during training. The agent shows 30%\nimprovement over a baseline model without the attention mechanism, with 52%\nsuccess rate at novel instructions.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 06:29:18 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Shah", "Pararth", ""], ["Fiser", "Marek", ""], ["Faust", "Aleksandra", ""], ["Kew", "J. Chase", ""], ["Hakkani-Tur", "Dilek", ""]]}, {"id": "1805.06242", "submitter": "Chandrakant Bothe", "authors": "Chandrakant Bothe, Sven Magg, Cornelius Weber and Stefan Wermter", "title": "Conversational Analysis using Utterance-level Attention-based\n  Bidirectional Recurrent Neural Networks", "comments": "Proceedings of INTERSPEECH 2018", "journal-ref": null, "doi": "10.21437/Interspeech.2018-2527", "report-no": null, "categories": "cs.CL cs.AI cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches for dialogue act recognition have shown that context from\npreceding utterances is important to classify the subsequent one. It was shown\nthat the performance improves rapidly when the context is taken into account.\nWe propose an utterance-level attention-based bidirectional recurrent neural\nnetwork (Utt-Att-BiRNN) model to analyze the importance of preceding utterances\nto classify the current one. In our setup, the BiRNN is given the input set of\ncurrent and preceding utterances. Our model outperforms previous models that\nuse only preceding utterances as context on the used corpus. Another\ncontribution of the article is to discover the amount of information in each\nutterance to classify the subsequent one and to show that context-based\nlearning not only improves the performance but also achieves higher confidence\nin the classification. We use character- and word-level features to represent\nthe utterances. The results are presented for character and word feature\nrepresentations and as an ensemble model of both representations. We found that\nwhen classifying short utterances, the closest preceding utterances contributes\nto a higher degree.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 10:51:56 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 12:11:59 GMT"}], "update_date": "2020-03-17", "authors_parsed": [["Bothe", "Chandrakant", ""], ["Magg", "Sven", ""], ["Weber", "Cornelius", ""], ["Wermter", "Stefan", ""]]}, {"id": "1805.06248", "submitter": "Ryo Nakahashi", "authors": "Ryo Nakahashi, Seiji Yamada", "title": "Modeling Human Inference of Others' Intentions in Complex Situations\n  with Plan Predictability Bias", "comments": "Accepted at Cogsci 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent approach based on Bayesian inverse planning for the \"theory of mind\"\nhas shown good performance in modeling human cognition. However, perfect\ninverse planning differs from human cognition during one kind of complex tasks\ndue to human bounded rationality. One example is an environment in which there\nare many available plans for achieving a specific goal. We propose a \"plan\npredictability oriented model\" as a model of inferring other peoples' goals in\ncomplex environments. This model adds the bias that people prefer predictable\nplans. This bias is calculated with simple plan prediction. We tested this\nmodel with a behavioral experiment in which humans observed the partial path of\ngoal-directed actions. Our model had a higher correlation with human inference.\nWe also confirmed the robustness of our model with complex tasks and determined\nthat it can be improved by taking account of individual differences in \"bounded\nrationality\".\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 11:30:56 GMT"}, {"version": "v2", "created": "Thu, 27 Sep 2018 09:40:53 GMT"}, {"version": "v3", "created": "Wed, 20 Nov 2019 11:22:47 GMT"}], "update_date": "2019-11-21", "authors_parsed": [["Nakahashi", "Ryo", ""], ["Yamada", "Seiji", ""]]}, {"id": "1805.06250", "submitter": "Michael Garcia Ortiz", "authors": "Michael Garcia Ortiz and Alban Laflaqui\\`ere", "title": "Learning Representations of Spatial Displacement through Sensorimotor\n  Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robots act in their environment through sequences of continuous motor\ncommands. Because of the dimensionality of the motor space, as well as the\ninfinite possible combinations of successive motor commands, agents need\ncompact representations that capture the structure of the resulting\ndisplacements. In the case of an autonomous agent with no a priori knowledge\nabout its sensorimotor apparatus, this compression has to be learned. We\npropose to use Recurrent Neural Networks to encode motor sequences into a\ncompact representation, which is used to predict the consequence of motor\nsequences in term of sensory changes. We show that sensory prediction can\nsuccessfully guide the compression of motor sequences into representations that\nare organized topologically in term of spatial displacement.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 11:41:52 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Ortiz", "Michael Garcia", ""], ["Laflaqui\u00e8re", "Alban", ""]]}, {"id": "1805.06280", "submitter": "Chandrakant Bothe", "authors": "Chandrakant Bothe, Cornelius Weber, Sven Magg, and Stefan Wermter", "title": "A Context-based Approach for Dialogue Act Recognition using Simple\n  Recurrent Neural Networks", "comments": "Proceedings of the Eleventh International Conference on Language\n  Resources and Evaluation (LREC 2018)", "journal-ref": null, "doi": null, "report-no": "id:525, pages:1952--1957", "categories": "cs.CL cs.AI cs.HC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue act recognition is an important part of natural language\nunderstanding. We investigate the way dialogue act corpora are annotated and\nthe learning approaches used so far. We find that the dialogue act is\ncontext-sensitive within the conversation for most of the classes.\nNevertheless, previous models of dialogue act classification work on the\nutterance-level and only very few consider context. We propose a novel\ncontext-based learning method to classify dialogue acts using a character-level\nlanguage model utterance representation, and we notice significant improvement.\nWe evaluate this method on the Switchboard Dialogue Act corpus, and our results\nshow that the consideration of the preceding utterances as a context of the\ncurrent utterance improves dialogue act detection.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 12:58:18 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Bothe", "Chandrakant", ""], ["Weber", "Cornelius", ""], ["Magg", "Sven", ""], ["Wermter", "Stefan", ""]]}, {"id": "1805.06297", "submitter": "Mikel Artetxe", "authors": "Mikel Artetxe, Gorka Labaka, Eneko Agirre", "title": "A robust self-learning method for fully unsupervised cross-lingual\n  mappings of word embeddings", "comments": "ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has managed to learn cross-lingual word embeddings without\nparallel data by mapping monolingual embeddings to a shared space through\nadversarial training. However, their evaluation has focused on favorable\nconditions, using comparable corpora or closely-related languages, and we show\nthat they often fail in more realistic scenarios. This work proposes an\nalternative approach based on a fully unsupervised initialization that\nexplicitly exploits the structural similarity of the embeddings, and a robust\nself-learning algorithm that iteratively improves this solution. Our method\nsucceeds in all tested scenarios and obtains the best published results in\nstandard datasets, even surpassing previous supervised systems. Our\nimplementation is released as an open source project at\nhttps://github.com/artetxem/vecmap\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 13:23:48 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 17:21:53 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Artetxe", "Mikel", ""], ["Labaka", "Gorka", ""], ["Agirre", "Eneko", ""]]}, {"id": "1805.06368", "submitter": "Victor G. Turrisi Costa", "authors": "Victor Guilherme Turrisi da Costa, Andr\\'e Carlos Ponce de Leon\n  Ferreira de Carvalho, Sylvio Barbon Junior", "title": "Strict Very Fast Decision Tree: a memory conservative algorithm for data\n  stream mining", "comments": "7 pages, 26 figures, Under R1 revision in Pattern Recognition Letters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with memory and time constraints are current challenges when learning\nfrom data streams with a massive amount of data. Many algorithms have been\nproposed to handle these difficulties, among them, the Very Fast Decision Tree\n(VFDT) algorithm. Although the VFDT has been widely used in data stream mining,\nin the last years, several authors have suggested modifications to increase its\nperformance, putting aside memory concerns by proposing memory-costly\nsolutions. Besides, most data stream mining solutions have been centred around\nensembles, which combine the memory costs of their weak learners, usually\nVFDTs. To reduce the memory cost, keeping the predictive performance, this\nstudy proposes the Strict VFDT (SVFDT), a novel algorithm based on the VFDT.\nThe SVFDT algorithm minimises unnecessary tree growth, substantially reducing\nmemory usage and keeping competitive predictive performance. Moreover, since it\ncreates much more shallow trees than VFDT, SVFDT can achieve a shorter\nprocessing time. Experiments were carried out comparing the SVFDT with the VFDT\nin 11 benchmark data stream datasets. This comparison assessed the trade-off\nbetween accuracy, memory, and processing time. Statistical analysis showed that\nthe proposed algorithm obtained similar predictive performance and\nsignificantly reduced processing time and memory use. Thus, SVFDT is a suitable\noption for data stream mining with memory and time limitations, recommended as\na weak learner in ensemble-based solutions.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 15:28:39 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 13:57:51 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["da Costa", "Victor Guilherme Turrisi", ""], ["de Carvalho", "Andr\u00e9 Carlos Ponce de Leon Ferreira", ""], ["Junior", "Sylvio Barbon", ""]]}, {"id": "1805.06502", "submitter": "Qingxiang Wang", "authors": "Qingxiang Wang, Cezary Kaliszyk, Josef Urban", "title": "First Experiments with Neural Translation of Informal to Formal\n  Mathematics", "comments": "Submission to CICM'2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on our experiments to train deep neural networks that automatically\ntranslate informalized LaTeX-written Mizar texts into the formal Mizar\nlanguage. To the best of our knowledge, this is the first time when neural\nnetworks have been adopted in the formalization of mathematics. Using Luong et\nal.'s neural machine translation model (NMT), we tested our aligned\ninformal-formal corpora against various hyperparameters and evaluated their\nresults. Our experiments show that our best performing model configurations are\nable to generate correct Mizar statements on 65.73\\% of the inference data,\nwith the union of all models covering 79.17\\%. These results indicate that\nformalization through artificial neural network is a promising approach for\nautomated formalization of mathematics. We present several case studies to\nillustrate our results.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 09:11:43 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 10:02:22 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Wang", "Qingxiang", ""], ["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""]]}, {"id": "1805.06503", "submitter": "Ameet Deshpande", "authors": "Ameet Deshpande and Vedant Somani", "title": "Weight Initialization in Neural Language Models", "comments": "17 pages, 20 figures and/or tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic Similarity is an important application which finds its use in many\ndownstream NLP applications. Though the task is mathematically defined,\nsemantic similarity's essence is to capture the notions of similarity\nimpregnated in humans. Machines use some heuristics to calculate the similarity\nbetween words, but these are typically corpus dependent or are useful for\nspecific domains. The difference between Semantic Similarity and Semantic\nRelatedness motivates the development of new algorithms. For a human, the word\ncar and road are probably as related as car and bus. But this may not be the\ncase for computational methods. Ontological methods are good at encoding\nSemantic Similarity and Vector Space models are better at encoding Semantic\nRelatedness. There is a dearth of methods which leverage ontologies to create\nbetter vector representations. The aim of this proposal is to explore in the\ndirection of a hybrid method which combines statistical/vector space methods\nlike Word2Vec and Ontological methods like WordNet to leverage the advantages\nprovided by both.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 03:08:58 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Deshpande", "Ameet", ""], ["Somani", "Vedant", ""]]}, {"id": "1805.06504", "submitter": "Shen Li", "authors": "Shen Li, Zhe Zhao, Renfen Hu, Wensi Li, Tao Liu, Xiaoyong Du", "title": "Analogical Reasoning on Chinese Morphological and Semantic Relations", "comments": null, "journal-ref": "Proceedings of the 56th Annual Meeting of the Association for\n  Computational Linguistics (Volume 2: Short Papers), 138--143, 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Analogical reasoning is effective in capturing linguistic regularities. This\npaper proposes an analogical reasoning task on Chinese. After delving into\nChinese lexical knowledge, we sketch 68 implicit morphological relations and 28\nexplicit semantic relations. A big and balanced dataset CA8 is then built for\nthis task, including 17813 questions. Furthermore, we systematically explore\nthe influences of vector representations, context features, and corpora on\nanalogical reasoning. With the experiments, CA8 is proved to be a reliable\nbenchmark for evaluating Chinese word embeddings.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 15:24:32 GMT"}], "update_date": "2018-08-27", "authors_parsed": [["Li", "Shen", ""], ["Zhao", "Zhe", ""], ["Hu", "Renfen", ""], ["Li", "Wensi", ""], ["Liu", "Tao", ""], ["Du", "Xiaoyong", ""]]}, {"id": "1805.06511", "submitter": "Zakaria Aldeneh", "authors": "Zakaria Aldeneh, Dimitrios Dimitriadis, Emily Mower Provost", "title": "Improving End-of-turn Detection in Spoken Dialogues by Detecting Speaker\n  Intentions as a Secondary Task", "comments": "ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work focuses on the use of acoustic cues for modeling turn-taking in\ndyadic spoken dialogues. Previous work has shown that speaker intentions (e.g.,\nasking a question, uttering a backchannel, etc.) can influence turn-taking\nbehavior and are good predictors of turn-transitions in spoken dialogues.\nHowever, speaker intentions are not readily available for use by automated\nsystems at run-time; making it difficult to use this information to anticipate\na turn-transition. To this end, we propose a multi-task neural approach for\npredicting turn- transitions and speaker intentions simultaneously. Our results\nshow that adding the auxiliary task of speaker intention prediction improves\nthe performance of turn-transition prediction in spoken dialogues, without\nrelying on additional input features during run-time.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 05:38:14 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Aldeneh", "Zakaria", ""], ["Dimitriadis", "Dimitrios", ""], ["Provost", "Emily Mower", ""]]}, {"id": "1805.06524", "submitter": "Ming Li", "authors": "Ming Li, Peilun Xiao, and Ju Zhang", "title": "Hybrid Adaptive Fuzzy Extreme Learning Machine for text classification", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In traditional ELM and its improved versions suffer from the problems of\noutliers or noises due to overfitting and imbalance due to distribution. We\npropose a novel hybrid adaptive fuzzy ELM(HA-FELM), which introduces a fuzzy\nmembership function to the traditional ELM method to deal with the above\nproblems. We define the fuzzy membership function not only basing on the\ndistance between each sample and the center of the class but also the density\namong samples which based on the quantum harmonic oscillator model. The\nproposed fuzzy membership function overcomes the shortcoming of the traditional\nfuzzy membership function and could make itself adjusted according to the\nspecific distribution of different samples adaptively. Experiments show the\nproposed HA-FELM can produce better performance than SVM, ELM, and RELM in text\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 06:11:27 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Li", "Ming", ""], ["Xiao", "Peilun", ""], ["Zhang", "Ju", ""]]}, {"id": "1805.06525", "submitter": "Ming Li", "authors": "Ming Li, Peilun Xiao, and Ju Zhang", "title": "Text classification based on ensemble extreme learning machine", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach based on cost-sensitive ensemble\nweighted extreme learning machine; we call this approach AE1-WELM. We apply\nthis approach to text classification. AE1-WELM is an algorithm including\nbalanced and imbalanced multiclassification for text classification. Weighted\nELM assigning the different weights to the different samples improves the\nclassification accuracy to a certain extent, but weighted ELM considers the\ndifferences between samples in the different categories only and ignores the\ndifferences between samples within the same categories. We measure the\nimportance of the documents by the sample information entropy, and generate\ncost-sensitive matrix and factor based on the document importance, then embed\nthe cost-sensitive weighted ELM into the AdaBoost.M1 framework seamlessly.\nVector space model(VSM) text representation produces the high dimensions and\nsparse features which increase the burden of ELM. To overcome this problem, we\ndevelop a text classification framework combining the word vector and AE1-WELM.\nThe experimental results show that our method provides an accurate, reliable\nand effective solution for text classification.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 06:10:46 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Li", "Ming", ""], ["Xiao", "Peilun", ""], ["Zhang", "Ju", ""]]}, {"id": "1805.06539", "submitter": "Tineke Blom", "authors": "Tineke Blom, Stephan Bongers, Joris M. Mooij", "title": "Beyond Structural Causal Models: Causal Constraints Models", "comments": "Published in Proceedings of the 35th Annual Conference on Uncertainty\n  in Artificial Intelligence (UAI-19)", "journal-ref": "Proceedings of the 35th Annual Conference on Uncertainty in\n  Artificial Intelligence, 2019", "doi": null, "report-no": null, "categories": "cs.AI stat.ME stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Structural Causal Models (SCMs) provide a popular causal modeling framework.\nIn this work, we show that SCMs are not flexible enough to give a complete\ncausal representation of dynamical systems at equilibrium. Instead, we propose\na generalization of the notion of an SCM, that we call Causal Constraints Model\n(CCM), and prove that CCMs do capture the causal semantics of such systems. We\nshow how CCMs can be constructed from differential equations and initial\nconditions and we illustrate our ideas further on a simple but ubiquitous\n(bio)chemical reaction. Our framework also allows to model functional laws,\nsuch as the ideal gas law, in a sensible and intuitive way.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 22:04:28 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 12:33:01 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 10:21:44 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Blom", "Tineke", ""], ["Bongers", "Stephan", ""], ["Mooij", "Joris M.", ""]]}, {"id": "1805.06549", "submitter": "Josiah Wang", "authors": "Pranava Madhyastha, Josiah Wang, Lucia Specia", "title": "Defoiling Foiled Image Captions", "comments": "In Proceedings of the 2018 Conference of the North American Chapter\n  of the Association for Computational Linguistics (NAACL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the task of detecting foiled image captions, i.e. identifying\nwhether a caption contains a word that has been deliberately replaced by a\nsemantically similar word, thus rendering it inaccurate with respect to the\nimage being described. Solving this problem should in principle require a\nfine-grained understanding of images to detect linguistically valid\nperturbations in captions. In such contexts, encoding sufficiently descriptive\nimage information becomes a key challenge. In this paper, we demonstrate that\nit is possible to solve this task using simple, interpretable yet powerful\nrepresentations based on explicit object information. Our models achieve\nstate-of-the-art performance on a standard dataset, with scores exceeding those\nachieved by humans on the task. We also measure the upper-bound performance of\nour models using gold standard annotations. Our analysis reveals that the\nsimpler model performs well even without image information, suggesting that the\ndataset contains strong linguistic bias.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 22:50:17 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Madhyastha", "Pranava", ""], ["Wang", "Josiah", ""], ["Specia", "Lucia", ""]]}, {"id": "1805.06593", "submitter": "Chang Xu", "authors": "Chang Xu, Cecile Paris, Surya Nepal, Ross Sparks", "title": "Cross-Target Stance Classification with Self-Attention Networks", "comments": "In Proceedings of the 56th Annual Meeting of the Association for\n  Computational Linguistics (ACL2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In stance classification, the target on which the stance is made defines the\nboundary of the task, and a classifier is usually trained for prediction on the\nsame target. In this work, we explore the potential for generalizing\nclassifiers between different targets, and propose a neural model that can\napply what has been learned from a source target to a destination target. We\nshow that our model can find useful information shared between relevant targets\nwhich improves generalization in certain scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 03:39:23 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 10:49:28 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Xu", "Chang", ""], ["Paris", "Cecile", ""], ["Nepal", "Surya", ""], ["Sparks", "Ross", ""]]}, {"id": "1805.06606", "submitter": "Woo Yong Choi", "authors": "Chan Woo Lee, Kyu Ye Song, Jihoon Jeong, Woo Yong Choi", "title": "Convolutional Attention Networks for Multimodal Emotion Recognition from\n  Speech and Text Data", "comments": "Inaccurate scientific facts listed in document", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emotion recognition has become a popular topic of interest, especially in the\nfield of human computer interaction. Previous works involve unimodal analysis\nof emotion, while recent efforts focus on multi-modal emotion recognition from\nvision and speech. In this paper, we propose a new method of learning about the\nhidden representations between just speech and text data using convolutional\nattention networks. Compared to the shallow model which employs simple\nconcatenation of feature vectors, the proposed attention model performs much\nbetter in classifying emotion from speech and text data contained in the\nCMU-MOSEI dataset.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 05:51:00 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 07:04:40 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Lee", "Chan Woo", ""], ["Song", "Kyu Ye", ""], ["Jeong", "Jihoon", ""], ["Choi", "Woo Yong", ""]]}, {"id": "1805.06610", "submitter": "Wenyi Wang Mr.", "authors": "Wenyi Wang", "title": "A Formulation of Recursive Self-Improvement and Its Possible Efficiency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recursive self-improving (RSI) systems have been dreamed of since the early\ndays of computer science and artificial intelligence. However, many existing\nstudies on RSI systems remain philosophical, and lacks clear formulation and\nresults. In this paper, we provide a formal definition for one class of RSI\nsystems, and then demonstrate the existence of computable and efficient RSI\nsystems on a restricted version. We use simulation to empirically show that we\nachieve logarithmic runtime complexity with respect to the size of the search\nspace, and these results suggest it is possible to achieve an efficient\nrecursive self-improvement.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 06:08:37 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Wang", "Wenyi", ""]]}, {"id": "1805.06621", "submitter": "Tom\\'as Angles", "authors": "Tom\\'as Angles and St\\'ephane Mallat", "title": "Generative networks as inverse problems with Scattering transforms", "comments": "International Conference on Learning Representations, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative Adversarial Nets (GANs) and Variational Auto-Encoders (VAEs)\nprovide impressive image generations from Gaussian white noise, but the\nunderlying mathematics are not well understood. We compute deep convolutional\nnetwork generators by inverting a fixed embedding operator. Therefore, they do\nnot require to be optimized with a discriminator or an encoder. The embedding\nis Lipschitz continuous to deformations so that generators transform linear\ninterpolations between input white noise vectors into deformations between\noutput images. This embedding is computed with a wavelet Scattering transform.\nNumerical experiments demonstrate that the resulting Scattering generators have\nsimilar properties as GANs or VAEs, without learning a discriminative network\nor an encoder.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 07:12:18 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Angles", "Tom\u00e1s", ""], ["Mallat", "St\u00e9phane", ""]]}, {"id": "1805.06632", "submitter": "Wenjie Huang", "authors": "William B. Haskell, Wenjie Huang, Huifu Xu", "title": "Preference Elicitation and Robust Optimization with Multi-Attribute\n  Quasi-Concave Choice Functions", "comments": "36 pages, 4 figures, submitted to Operations Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.AI cs.IR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision maker's preferences are often captured by some choice functions\nwhich are used to rank prospects. In this paper, we consider ambiguity in\nchoice functions over a multi-attribute prospect space. Our main result is a\nrobust preference model where the optimal decision is based on the worst-case\nchoice function from an ambiguity set constructed through preference\nelicitation with pairwise comparisons of prospects. Differing from existing\nworks in the area, our focus is on quasi-concave choice functions rather than\nconcave functions and this enables us to cover a wide range of utility/risk\npreference problems including multi-attribute expected utility and $S$-shaped\naspirational risk preferences. The robust choice function is increasing and\nquasi-concave but not necessarily translation invariant, a key property of\nmonetary risk measures. We propose two approaches based respectively on the\nsupport functions and level functions of quasi-concave functions to develop\ntractable formulations of the maximin preference robust optimization model. The\nformer gives rise to a mixed integer linear programming problem whereas the\nlatter is equivalent to solving a sequence of convex risk minimization\nproblems. To assess the effectiveness of the proposed robust preference\noptimization model and numerical schemes, we apply them to a security budget\nallocation problem and report some preliminary results from experiments.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 07:37:33 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Haskell", "William B.", ""], ["Huang", "Wenjie", ""], ["Xu", "Huifu", ""]]}, {"id": "1805.06664", "submitter": "Sarmimala Saikia", "authors": "S Saikia, R Verma, P Agarwal, G Shroff, L Vig and A Srinivasan", "title": "Evolutionary RL for Container Loading", "comments": "6 Pages, 2 figures, accepted in ESANN 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loading the containers on the ship from a yard, is an impor- tant part of\nport operations. Finding the optimal sequence for the loading of containers, is\nknown to be computationally hard and is an example of combinatorial\noptimization, which leads to the application of simple heuristics in practice.\nIn this paper, we propose an approach which uses a mix of Evolutionary\nStrategies and Reinforcement Learning (RL) tech- niques to find an\napproximation of the optimal solution. The RL based agent uses the Policy\nGradient method, an evolutionary reward strategy and a Pool of good\n(not-optimal) solutions to find the approximation. We find that the RL agent\nlearns near-optimal solutions that outperforms the heuristic solutions. We also\nobserve that the RL agent assisted with a pool generalizes better for unseen\nproblems than an RL agent without a pool. We present our results on synthetic\ndata as well as on subsets of real-world problems taken from container\nterminal. The results validate that our approach does comparatively better than\nthe heuristics solutions available, and adapts to unseen problems better.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 09:19:35 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Saikia", "S", ""], ["Verma", "R", ""], ["Agarwal", "P", ""], ["Shroff", "G", ""], ["Vig", "L", ""], ["Srinivasan", "A", ""]]}, {"id": "1805.06753", "submitter": "Yitan Wang", "authors": "Guangzeng Xie, Yitan Wang, Shuchang Zhou, Zhihua Zhang", "title": "Interpolatron: Interpolation or Extrapolation Schemes to Accelerate\n  Optimization for Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper we explore acceleration techniques for large scale nonconvex\noptimization problems with special focuses on deep neural networks. The\nextrapolation scheme is a classical approach for accelerating stochastic\ngradient descent for convex optimization, but it does not work well for\nnonconvex optimization typically. Alternatively, we propose an interpolation\nscheme to accelerate nonconvex optimization and call the method Interpolatron.\nWe explain motivation behind Interpolatron and conduct a thorough empirical\nanalysis. Empirical results on DNNs of great depths (e.g., 98-layer ResNet and\n200-layer ResNet) on CIFAR-10 and ImageNet show that Interpolatron can converge\nmuch faster than the state-of-the-art methods such as the SGD with momentum and\nAdam. Furthermore, Anderson's acceleration, in which mixing coefficients are\ncomputed by least-squares estimation, can also be used to improve the\nperformance. Both Interpolatron and Anderson's acceleration are easy to\nimplement and tune. We also show that Interpolatron has linear convergence rate\nunder certain regularity assumptions.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 13:29:33 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Xie", "Guangzeng", ""], ["Wang", "Yitan", ""], ["Zhou", "Shuchang", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1805.06822", "submitter": "Gilad Cohen", "authors": "Gilad Cohen, Guillermo Sapiro, Raja Giryes", "title": "DNN or k-NN: That is the Generalize vs. Memorize Question", "comments": "Poster presented in NIPS 2018 \"Integration of Deep Learning Theories\"\n  workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the relationship between the classification performed by\ndeep neural networks (DNNs) and the decision of various classical classifiers,\nnamely k-nearest neighbours (k-NN), support vector machines (SVM) and logistic\nregression (LR), at various layers of the network. This comparison provides us\nwith new insights as to the ability of neural networks to both memorize the\ntraining data and generalize to new data at the same time, where k-NN serves as\nthe ideal estimator that perfectly memorizes the data. We show that\nmemorization of non-generalizing networks happens only at the last layers.\nMoreover, the behavior of DNNs compared to the linear classifiers SVM and LR is\nquite the same on the training and test data regardless of whether the network\ngeneralizes. On the other hand, the similarity to k-NN holds only at the\nabsence of overfitting. Our results suggests that k-NN behavior of the network\non new data is a sign of generalization. Moreover, it shows that memorization\nand generalization, which are traditionally considered to be contradicting to\neach other, are compatible and complementary.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 15:31:22 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 06:58:53 GMT"}, {"version": "v3", "created": "Mon, 28 May 2018 06:44:35 GMT"}, {"version": "v4", "created": "Wed, 19 Dec 2018 19:41:15 GMT"}, {"version": "v5", "created": "Wed, 6 Feb 2019 15:34:43 GMT"}, {"version": "v6", "created": "Sun, 10 Feb 2019 12:03:54 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Cohen", "Gilad", ""], ["Sapiro", "Guillermo", ""], ["Giryes", "Raja", ""]]}, {"id": "1805.06824", "submitter": "Akshat Agarwal", "authors": "Akshat Agarwal, Ryan Hope and Katia Sycara", "title": "Learning Time-Sensitive Strategies in Space Fortress", "comments": "10 pages, 3 figures. Withdrawn, superseded by arXiv:1809.02206", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although there has been remarkable progress and impressive performance on\nreinforcement learning (RL) on Atari games, there are many problems with\nchallenging characteristics that have not yet been explored in Deep Learning\nfor RL. These include reward sparsity, abrupt context-dependent reversals of\nstrategy and time-sensitive game play. In this paper, we present Space\nFortress, a game that incorporates all these characteristics and experimentally\nshow that the presence of any of these renders state of the art Deep RL\nalgorithms incapable of learning. Then, we present our enhancements to an\nexisting algorithm and show big performance increases through each enhancement\nthrough an ablation study. We discuss how each of these enhancements was able\nto help and also argue that appropriate transfer learning boosts performance.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 15:36:42 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 22:57:38 GMT"}, {"version": "v3", "created": "Sun, 24 Jun 2018 18:12:34 GMT"}, {"version": "v4", "created": "Thu, 13 Sep 2018 22:08:17 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Agarwal", "Akshat", ""], ["Hope", "Ryan", ""], ["Sycara", "Katia", ""]]}, {"id": "1805.06861", "submitter": "Carl Schultz", "authors": "Carl Schultz, Mehul Bhatt, Jakob Suchan, Przemys{\\l}aw Wa{\\l}\\k{e}ga", "title": "Answer Set Programming Modulo `Space-Time'", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present ASP Modulo `Space-Time', a declarative representational and\ncomputational framework to perform commonsense reasoning about regions with\nboth spatial and temporal components. Supported are capabilities for mixed\nqualitative-quantitative reasoning, consistency checking, and inferring\ncompositions of space-time relations; these capabilities combine and synergise\nfor applications in a range of AI application areas where the processing and\ninterpretation of spatio-temporal data is crucial. The framework and resulting\nsystem is the only general KR-based method for declaratively reasoning about\nthe dynamics of `space-time' regions as first-class objects. We present an\nempirical evaluation (with scalability and robustness results), and include\ndiverse application examples involving interpretation and control tasks.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 17:05:30 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Schultz", "Carl", ""], ["Bhatt", "Mehul", ""], ["Suchan", "Jakob", ""], ["Wa\u0142\u0119ga", "Przemys\u0142aw", ""]]}, {"id": "1805.06864", "submitter": "Ram\\'on Pino P\\'erez", "authors": "Franklin Camacho and Gerardo Chac\\'on and Ram\\'on Pino Per\\'ez", "title": "Resource allocation under uncertainty: an algebraic and qualitative\n  treatment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We use an algebraic viewpoint, namely a matrix framework to deal with the\nproblem of resource allocation under uncertainty in the context of a\nqualitative approach. Our basic qualitative data are a plausibility relation\nover the resources, a hierarchical relation over the agents and of course the\npreference that the agents have over the resources. With this data we propose a\nqualitative binary relation $\\unrhd$ between allocations such that\n$\\mathcal{F}\\unrhd \\mathcal{G}$ has the following intended meaning: the\nallocation $\\mathcal{F}$ produces more or equal social welfare than the\nallocation $\\mathcal{G}$. We prove that there is a family of allocations which\nare maximal with respect to $\\unrhd$. We prove also that there is a notion of\nsimple deal such that optimal allocations can be reached by sequences of simple\ndeals. Finally, we introduce some mechanism for discriminating {optimal}\nallocations.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 17:06:07 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Camacho", "Franklin", ""], ["Chac\u00f3n", "Gerardo", ""], ["Per\u00e9z", "Ram\u00f3n Pino", ""]]}, {"id": "1805.06879", "submitter": "James Bagrow", "authors": "James P. Bagrow and Daniel Berenberg and Joshua Bongard", "title": "Neural language representations predict outcomes of scientific research", "comments": "8 pages, 3 figures, plus supporting material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CY cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many research fields codify their findings in standard formats, often by\nreporting correlations between quantities of interest. But the space of all\ntestable correlates is far larger than scientific resources can currently\naddress, so the ability to accurately predict correlations would be useful to\nplan research and allocate resources. Using a dataset of approximately 170,000\ncorrelational findings extracted from leading social science journals, we show\nthat a trained neural network can accurately predict the reported correlations\nusing only the text descriptions of the correlates. Accurate predictive models\nsuch as these can guide scientists towards promising untested correlates,\nbetter quantify the information gained from new findings, and has implications\nfor moving artificial intelligence systems from predicting structures to\npredicting relationships in the real world.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 17:40:12 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Bagrow", "James P.", ""], ["Berenberg", "Daniel", ""], ["Bongard", "Joshua", ""]]}, {"id": "1805.06881", "submitter": "Bastien Maubert", "authors": "Aur\\`ele Barri\\`ere, Bastien Maubert, Aniello Murano and Sasha Rubin", "title": "Changing Observations in Epistemic Temporal Logic", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.MA", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study dynamic changes of agents' observational power in logics of\nknowledge and time. We consider CTL*K, the extension of CTL* with knowledge\noperators, and enrich it with a new operator that models a change in an agent's\nway of observing the system. We extend the classic semantics of knowledge for\nperfect-recall agents to account for changes of observation, and we show that\nthis new operator strictly increases the expressivity of CTL*K. We reduce the\nmodel-checking problem for our logic to that for CTL*K, which is known to be\ndecidable. This provides a solution to the model-checking problem for our\nlogic, but its complexity is not optimal. Indeed we provide a direct decision\nprocedure with better complexity.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 17:45:01 GMT"}, {"version": "v2", "created": "Mon, 3 Sep 2018 14:24:22 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Barri\u00e8re", "Aur\u00e8le", ""], ["Maubert", "Bastien", ""], ["Murano", "Aniello", ""], ["Rubin", "Sasha", ""]]}, {"id": "1805.06924", "submitter": "Sergio Romano", "authors": "Pablo Tano, Sergio Romano, Mariano Sigman, Alejo Salles and Santiago\n  Figueira", "title": "Towards a more flexible Language of Thought: Bayesian grammar updates\n  after each concept exposure", "comments": null, "journal-ref": "Phys. Rev. E 101, 042128 (2020)", "doi": "10.1103/PhysRevE.101.042128", "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recent approaches to human concept learning have successfully combined the\npower of symbolic, infinitely productive rule systems and statistical learning\nto explain our ability to learn new concepts from just a few examples. The aim\nof most of these studies is to reveal the underlying language structuring these\nrepresentations and providing a general substrate for thought. However,\ndescribing a model of thought that is fixed once trained is against the\nextensive literature that shows how experience shapes concept learning. Here,\nwe ask about the plasticity of these symbolic descriptive languages. We perform\na concept learning experiment that demonstrates that humans can change very\nrapidly the repertoire of symbols they use to identify concepts, by compiling\nexpressions which are frequently used into new symbols of the language. The\npattern of concept learning times is accurately described by a Bayesian agent\nthat rationally updates the probability of compiling a new expression according\nto how useful it has been to compress concepts so far. By portraying the\nLanguage of Thought as a flexible system of rules, we also highlight the\ndifficulties to pin it down empirically.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 18:56:09 GMT"}, {"version": "v2", "created": "Thu, 26 Sep 2019 20:15:54 GMT"}], "update_date": "2020-04-29", "authors_parsed": [["Tano", "Pablo", ""], ["Romano", "Sergio", ""], ["Sigman", "Mariano", ""], ["Salles", "Alejo", ""], ["Figueira", "Santiago", ""]]}, {"id": "1805.06962", "submitter": "Tommaso Dreossi", "authors": "Tommaso Dreossi, Shromona Ghosh, Xiangyu Yue, Kurt Keutzer, Alberto\n  Sangiovanni-Vincentelli, Sanjit A. Seshia", "title": "Counterexample-Guided Data Augmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel framework for augmenting data sets for machine learning\nbased on counterexamples. Counterexamples are misclassified examples that have\nimportant properties for retraining and improving the model. Key components of\nour framework include a counterexample generator, which produces data items\nthat are misclassified by the model and error tables, a novel data structure\nthat stores information pertaining to misclassifications. Error tables can be\nused to explain the model's vulnerabilities and are used to efficiently\ngenerate counterexamples for augmentation. We show the efficacy of the proposed\nframework by comparing it to classical augmentation techniques on a case study\nof object detection in autonomous driving based on deep neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 20:42:07 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Dreossi", "Tommaso", ""], ["Ghosh", "Shromona", ""], ["Yue", "Xiangyu", ""], ["Keutzer", "Kurt", ""], ["Sangiovanni-Vincentelli", "Alberto", ""], ["Seshia", "Sanjit A.", ""]]}, {"id": "1805.06966", "submitter": "Florian Kreyssig", "authors": "Florian Kreyssig, Inigo Casanueva, Pawel Budzianowski, Milica Gasic", "title": "Neural User Simulation for Corpus-based Policy Optimisation for Spoken\n  Dialogue Systems", "comments": "Accepted to SIGDIAL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User Simulators are one of the major tools that enable offline training of\ntask-oriented dialogue systems. For this task the Agenda-Based User Simulator\n(ABUS) is often used. The ABUS is based on hand-crafted rules and its output is\nin semantic form. Issues arise from both properties such as limited diversity\nand the inability to interface a text-level belief tracker. This paper\nintroduces the Neural User Simulator (NUS) whose behaviour is learned from a\ncorpus and which generates natural language, hence needing a less labelled\ndataset than simulators generating a semantic output. In comparison to much of\nthe past work on this topic, which evaluates user simulators on corpus-based\nmetrics, we use the NUS to train the policy of a reinforcement learning based\nSpoken Dialogue System. The NUS is compared to the ABUS by evaluating the\npolicies that were trained using the simulators. Cross-model evaluation is\nperformed i.e. training on one simulator and testing on the other. Furthermore,\nthe trained policies are tested on real users. In both evaluation tasks the NUS\noutperformed the ABUS.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 21:00:03 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Kreyssig", "Florian", ""], ["Casanueva", "Inigo", ""], ["Budzianowski", "Pawel", ""], ["Gasic", "Milica", ""]]}, {"id": "1805.06992", "submitter": "Jun Wang", "authors": "Jun Wang, Sujoy Sikdar, Tyler Shepherd, Zhibing Zhao, Chunheng Jiang,\n  Lirong Xia", "title": "Practical Algorithms for STV and Ranked Pairs with Parallel Universes\n  Tiebreaking", "comments": "15 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  STV and ranked pairs (RP) are two well-studied voting rules for group\ndecision-making. They proceed in multiple rounds, and are affected by how ties\nare broken in each round. However, the literature is surprisingly vague about\nhow ties should be broken. We propose the first algorithms for computing the\nset of alternatives that are winners under some tiebreaking mechanism under STV\nand RP, which is also known as parallel-universes tiebreaking (PUT).\nUnfortunately, PUT-winners are NP-complete to compute under STV and RP, and\nstandard search algorithms from AI do not apply. We propose multiple DFS-based\nalgorithms along with pruning strategies and heuristics to prioritize search\ndirection to significantly improve the performance using machine learning. We\nalso propose novel ILP formulations for PUT-winners under STV and RP,\nrespectively. Experiments on synthetic and real-world data show that our\nalgorithms are overall significantly faster than ILP, while there are a few\ncases where ILP is significantly faster for RP.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 23:20:57 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Wang", "Jun", ""], ["Sikdar", "Sujoy", ""], ["Shepherd", "Tyler", ""], ["Zhao", "Zhibing", ""], ["Jiang", "Chunheng", ""], ["Xia", "Lirong", ""]]}, {"id": "1805.07008", "submitter": "Marc Brittain", "authors": "Marc Brittain and Peng Wei", "title": "Hierarchical Reinforcement Learning with Deep Nested Agents", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep hierarchical reinforcement learning has gained a lot of attention in\nrecent years due to its ability to produce state-of-the-art results in\nchallenging environments where non-hierarchical frameworks fail to learn useful\npolicies. However, as problem domains become more complex, deep hierarchical\nreinforcement learning can become inefficient, leading to longer convergence\ntimes and poor performance. We introduce the Deep Nested Agent framework, which\nis a variant of deep hierarchical reinforcement learning where information from\nthe main agent is propagated to the low level $nested$ agent by incorporating\nthis information into the nested agent's state. We demonstrate the\neffectiveness and performance of the Deep Nested Agent framework by applying it\nto three scenarios in Minecraft with comparisons to a deep non-hierarchical\nsingle agent framework, as well as, a deep hierarchical framework.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 01:06:36 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Brittain", "Marc", ""], ["Wei", "Peng", ""]]}, {"id": "1805.07029", "submitter": "Jeongyeol Baek", "authors": "JeongYeol Baek, Ioana Veronica Chelu, Livia Iordache, Vlad Paunescu,\n  HyunJoo Ryu, Alexandru Ghiuta, Andrei Petreanu, YunSung Soh, Andrei Leica,\n  ByeongMoon Jeon", "title": "Scene Understanding Networks for Autonomous Driving based on Around View\n  Monitoring System", "comments": "Accepted by CVPR 2018 Workshop on Autonomous Driving", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern driver assistance systems rely on a wide range of sensors (RADAR,\nLIDAR, ultrasound and cameras) for scene understanding and prediction. These\nsensors are typically used for detecting traffic participants and scene\nelements required for navigation. In this paper we argue that relying on camera\nbased systems, specifically Around View Monitoring (AVM) system has great\npotential to achieve these goals in both parking and driving modes with\ndecreased costs. The contributions of this paper are as follows: we present a\nnew end-to-end solution for delimiting the safe drivable area for each frame by\nmeans of identifying the closest obstacle in each direction from the driving\nvehicle, we use this approach to calculate the distance to the nearest\nobstacles and we incorporate it into a unified end-to-end architecture capable\nof joint object detection, curb detection and safe drivable area detection.\nFurthermore, we describe the family of networks for both a high accuracy\nsolution and a low complexity solution. We also introduce further augmentation\nof the base architecture with 3D object detection.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 02:54:54 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Baek", "JeongYeol", ""], ["Chelu", "Ioana Veronica", ""], ["Iordache", "Livia", ""], ["Paunescu", "Vlad", ""], ["Ryu", "HyunJoo", ""], ["Ghiuta", "Alexandru", ""], ["Petreanu", "Andrei", ""], ["Soh", "YunSung", ""], ["Leica", "Andrei", ""], ["Jeon", "ByeongMoon", ""]]}, {"id": "1805.07035", "submitter": "Morad Behandish", "authors": "Morad Behandish, Saigopal Nelaturi, and Johan de Kleer", "title": "Automated Process Planning for Hybrid Manufacturing", "comments": "Special Issue on symposium on Solid and Physical Modeling (SPM'2018)", "journal-ref": "Journal of Computer-Aided Design, 2018", "doi": "10.1016/j.cad.2018.04.022", "report-no": null, "categories": "cs.CG cs.AI cs.GR cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hybrid manufacturing (HM) technologies combine additive and subtractive\nmanufacturing (AM/SM) capabilities, leveraging AM's strengths in fabricating\ncomplex geometries and SM's precision and quality to produce finished parts. We\npresent a systematic approach to automated computer-aided process planning\n(CAPP) for HM that can identify non-trivial, qualitatively distinct, and\ncost-optimal combinations of AM/SM modalities. A multimodal HM process plan is\nrepresented by a finite Boolean expression of AM and SM manufacturing\nprimitives, such that the expression evaluates to an 'as-manufactured'\nartifact. We show that primitives that respect spatial constraints such as\naccessibility and collision avoidance may be constructed by solving inverse\nconfiguration space problems on the 'as-designed' artifact and manufacturing\ninstruments. The primitives generate a finite Boolean algebra (FBA) that\nenumerates the entire search space for planning. The FBA's canonical\nintersection terms (i.e., 'atoms') provide the complete domain decomposition to\nreframe manufacturability analysis and process planning into purely symbolic\nreasoning, once a subcollection of atoms is found to be interchangeable with\nthe design target. The approach subsumes unimodal (all-AM or all-SM) process\nplanning as special cases. We demonstrate the practical potency of our\nframework and its computational efficiency when applied to process planning of\ncomplex 3D parts with dramatically different AM and SM instruments.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 03:27:35 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Behandish", "Morad", ""], ["Nelaturi", "Saigopal", ""], ["de Kleer", "Johan", ""]]}, {"id": "1805.07039", "submitter": "Weili Nie", "authors": "Weili Nie, Yang Zhang and Ankit Patel", "title": "A Theoretical Explanation for Perplexing Behaviors of\n  Backpropagation-based Visualizations", "comments": "21 pages, ICML 2018 (We revised the proofs of Theorem 1 and 2 in\n  Appendix)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Backpropagation-based visualizations have been proposed to interpret\nconvolutional neural networks (CNNs), however a theory is missing to justify\ntheir behaviors: Guided backpropagation (GBP) and deconvolutional network\n(DeconvNet) generate more human-interpretable but less class-sensitive\nvisualizations than saliency map. Motivated by this, we develop a theoretical\nexplanation revealing that GBP and DeconvNet are essentially doing (partial)\nimage recovery which is unrelated to the network decisions. Specifically, our\nanalysis shows that the backward ReLU introduced by GBP and DeconvNet, and the\nlocal connections in CNNs are the two main causes of compelling visualizations.\nExtensive experiments are provided that support the theoretical analysis.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 03:45:06 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 21:54:22 GMT"}, {"version": "v3", "created": "Fri, 8 Jun 2018 03:48:33 GMT"}, {"version": "v4", "created": "Thu, 13 Feb 2020 16:23:39 GMT"}], "update_date": "2020-02-17", "authors_parsed": [["Nie", "Weili", ""], ["Zhang", "Yang", ""], ["Patel", "Ankit", ""]]}, {"id": "1805.07069", "submitter": "Mahdi Shaghaghi", "authors": "Mahdi Shaghaghi, Raviraj S. Adve, Zhen Ding", "title": "Multifunction Cognitive Radar Task Scheduling Using Monte Carlo Tree\n  Search and Policy Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A modern radar may be designed to perform multiple functions, such as\nsurveillance, tracking, and fire control. Each function requires the radar to\nexecute a number of transmit-receive tasks. A radar resource management (RRM)\nmodule makes decisions on parameter selection, prioritization, and scheduling\nof such tasks. RRM becomes especially challenging in overload situations, where\nsome tasks may need to be delayed or even dropped. In general, task scheduling\nis an NP-hard problem. In this work, we develop the branch-and-bound (B&B)\nmethod which obtains the optimal solution but at exponential computational\ncomplexity. On the other hand, heuristic methods have low complexity but\nprovide relatively poor performance. We resort to machine learning-based\ntechniques to address this issue; specifically we propose an approximate\nalgorithm based on the Monte Carlo tree search method. Along with using bound\nand dominance rules to eliminate nodes from the search tree, we use a policy\nnetwork to help to reduce the width of the search. Such a network can be\ntrained using solutions obtained by running the B&B method offline on problems\nwith feasible complexity. We show that the proposed method provides\nnear-optimal performance, but with computational complexity orders of magnitude\nsmaller than the B&B algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 06:58:16 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Shaghaghi", "Mahdi", ""], ["Adve", "Raviraj S.", ""], ["Ding", "Zhen", ""]]}, {"id": "1805.07075", "submitter": "Shalini Ghosh", "authors": "Shalini Ghosh, Amaury Mercier, Dheeraj Pichapati, Susmit Jha, Vinod\n  Yegneswaran, Patrick Lincoln", "title": "Trusted Neural Networks for Safety-Constrained Autonomous Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Trusted Neural Network (TNN) models, which are deep neural network\nmodels that satisfy safety constraints critical to the application domain. We\ninvestigate different mechanisms for incorporating rule-based knowledge in the\nform of first-order logic constraints into a TNN model, where rules that encode\nsafety are accompanied by weights indicating their relative importance. This\nframework allows the TNN model to learn from knowledge available in form of\ndata as well as logical rules. We propose multiple approaches for solving this\nproblem: (a) a multi-headed model structure that allows trade-off between\nsatisfying logical constraints and fitting training data in a unified training\nframework, and (b) creating a constrained optimization problem and solving it\nin dual formulation by posing a new constrained loss function and using a\nproximal gradient descent algorithm. We demonstrate the efficacy of our TNN\nframework through experiments using the open-source TORCS~\\cite{BernhardCAA15}\n3D simulator for self-driving cars. Experiments using our first approach of a\nmulti-headed TNN model, on a dataset generated by a customized version of\nTORCS, show that (1) adding safety constraints to a neural network model\nresults in increased performance and safety, and (2) the improvement increases\nwith increasing importance of the safety constraints. Experiments were also\nperformed using the second approach of proximal algorithm for constrained\noptimization --- they demonstrate how the proposed method ensures that (1) the\noverall TNN model satisfies the constraints even when the training data\nviolates some of the constraints, and (2) the proximal gradient descent\nalgorithm on the constrained objective converges faster than the unconstrained\nversion.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 07:17:15 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Ghosh", "Shalini", ""], ["Mercier", "Amaury", ""], ["Pichapati", "Dheeraj", ""], ["Jha", "Susmit", ""], ["Yegneswaran", "Vinod", ""], ["Lincoln", "Patrick", ""]]}, {"id": "1805.07107", "submitter": "Stephen Pauwels", "authors": "Stephen Pauwels, Toon Calders", "title": "Extending Dynamic Bayesian Networks for Anomaly Detection in Complex\n  Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Checking various log files from different processes can be a tedious task as\nthese logs contain lots of events, each with a (possibly large) number of\nattributes. We developed a way to automatically model log files and detect\noutlier traces in the data. For that we extend Dynamic Bayesian Networks to\nmodel the normal behavior found in log files. We introduce a new algorithm that\nis able to learn a model of a log file starting from the data itself. The model\nis capable of scoring traces even when new values or new combinations of values\nappear in the log file.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 09:23:12 GMT"}, {"version": "v2", "created": "Fri, 17 Aug 2018 13:08:31 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Pauwels", "Stephen", ""], ["Calders", "Toon", ""]]}, {"id": "1805.07180", "submitter": "Yong Lai", "authors": "Yong Lai", "title": "Approximate Model Counting by Partial Knowledge Compilation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model counting is the problem of computing the number of satisfying\nassignments of a given propositional formula. Although exact model counters can\nbe naturally furnished by most of the knowledge compilation (KC) methods, in\npractice, they fail to generate the compiled results for the exact counting of\nmodels for certain formulas due to the explosion in sizes. Decision-DNNF is an\nimportant KC language that captures most of the practical compilers. We propose\na generalized Decision-DNNF (referred to as partial Decision-DNNF) via\nintroducing a class of new leaf vertices (called unknown vertices), and then\npropose an algorithm called PartialKC to generate randomly partial\nDecision-DNNF formulas from the given formulas. An unbiased estimate of the\nmodel number can be computed via a randomly partial Decision-DNNF formula. Each\ncalling of PartialKC consists of multiple callings of MicroKC, while each of\nthe latter callings is a process of importance sampling equipped with KC\ntechnologies. The experimental results show that PartialKC is more accurate\nthan both SampleSearch and SearchTreeSampler, PartialKC scales better than\nSearchTreeSampler, and the KC technologies can obviously accelerate sampling.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 12:51:48 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Lai", "Yong", ""]]}, {"id": "1805.07193", "submitter": "Markus Braun", "authors": "Markus Braun, Sebastian Krebs, Fabian Flohr, and Dariu M. Gavrila", "title": "The EuroCity Persons Dataset: A Novel Benchmark for Object Detection", "comments": "Submitted to IEEE Trans. on Pattern Analysis and Machine Intelligence", "journal-ref": "Published in IEEE Trans. on Pattern Analysis and Machine\n  Intelligence, 2019", "doi": "10.1109/TPAMI.2019.2897684", "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data has had a great share in the success of deep learning in computer\nvision. Recent works suggest that there is significant further potential to\nincrease object detection performance by utilizing even bigger datasets. In\nthis paper, we introduce the EuroCity Persons dataset, which provides a large\nnumber of highly diverse, accurate and detailed annotations of pedestrians,\ncyclists and other riders in urban traffic scenes. The images for this dataset\nwere collected on-board a moving vehicle in 31 cities of 12 European countries.\nWith over 238200 person instances manually labeled in over 47300 images,\nEuroCity Persons is nearly one order of magnitude larger than person datasets\nused previously for benchmarking. The dataset furthermore contains a large\nnumber of person orientation annotations (over 211200). We optimize four\nstate-of-the-art deep learning approaches (Faster R-CNN, R-FCN, SSD and YOLOv3)\nto serve as baselines for the new object detection benchmark. In experiments\nwith previous datasets we analyze the generalization capabilities of these\ndetectors when trained with the new dataset. We furthermore study the effect of\nthe training set size, the dataset diversity (day- vs. night-time, geographical\nregion), the dataset detail (i.e. availability of object orientation\ninformation) and the annotation quality on the detector performance. Finally,\nwe analyze error sources and discuss the road ahead.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 13:17:46 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 15:20:52 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Braun", "Markus", ""], ["Krebs", "Sebastian", ""], ["Flohr", "Fabian", ""], ["Gavrila", "Dariu M.", ""]]}, {"id": "1805.07196", "submitter": "Daowen Qiu", "authors": "Weilin Deng, Jingkai Yang, Daowen Qiu", "title": "Supervisory Control of Probabilistic Discrete Event Systems under\n  Partial Observation", "comments": "36 pages, comments are welcome", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The supervisory control of probabilistic discrete event systems (PDESs) is\ninvestigated under the assumptions that the supervisory controller (supervisor)\nis probabilistic and has a partial observation. The probabilistic P-supervisor\nis defined, which specifies a probability distribution on the control patterns\nfor each observation. The notions of the probabilistic controllability and\nobservability are proposed and demonstrated to be a necessary and sufficient\nconditions for the existence of the probabilistic P-supervisors. Moreover, the\npolynomial verification algorithms for the probabilistic controllability and\nobservability are put forward. In addition, the infimal probabilistic\ncontrollable and observable superlanguage is introduced and computed as the\nsolution of the optimal control problem of PDESs. Several examples are\npresented to illustrate the results obtained.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 03:07:50 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Deng", "Weilin", ""], ["Yang", "Jingkai", ""], ["Qiu", "Daowen", ""]]}, {"id": "1805.07233", "submitter": "Kaixuan Chen", "authors": "Kaixuan Chen, Lina Yao, Xianzhi Wang, Dalin Zhang, Tao Gu, Zhiwen Yu,\n  Zheng Yang", "title": "Interpretable Parallel Recurrent Neural Networks with Convolutional\n  Attentions for Multi-Modality Activity Modeling", "comments": "arXiv admin note: substantial text overlap with arXiv:1711.07661", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal features play a key role in wearable sensor-based human activity\nrecognition (HAR). Selecting the most salient features adaptively is a\npromising way to maximize the effectiveness of multimodal sensor data. In this\nregard, we propose a \"collect fully and select wisely\" principle as well as an\ninterpretable parallel recurrent model with convolutional attentions to improve\nthe recognition performance. We first collect modality features and the\nrelations between each pair of features to generate activity frames, and then\nintroduce an attention mechanism to select the most prominent regions from\nactivity frames precisely. The selected frames not only maximize the\nutilization of valid features but also reduce the number of features to be\ncomputed effectively. We further analyze the accuracy and interpretability of\nthe proposed model based on extensive experiments. The results show that our\nmodel achieves competitive performance on two benchmarked datasets and works\nwell in real life scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 02:43:02 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Chen", "Kaixuan", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Zhang", "Dalin", ""], ["Gu", "Tao", ""], ["Yu", "Zhiwen", ""], ["Yang", "Zheng", ""]]}, {"id": "1805.07239", "submitter": "Stepan Kochemazov", "authors": "Alexander Semenov, Ilya Otpuschennikov, Irina Gribanova, Oleg Zaikin,\n  Stepan Kochemazov", "title": "Translation of Algorithmic Descriptions of Discrete Functions to SAT\n  with Applications to Cryptanalysis Problems", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 16, Issue 1 (March 2,\n  2020) lmcs:6177", "doi": "10.23638/LMCS-16(1:29)2020", "report-no": null, "categories": "cs.LO cs.AI cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the present paper, we propose a technology for translating algorithmic\ndescriptions of discrete functions to SAT. The proposed technology is aimed at\napplications in algebraic cryptanalysis. We describe how cryptanalysis problems\nare reduced to SAT in such a way that it should be perceived as natural by the\ncryptographic community. In~the theoretical part of the paper we justify the\nmain principles of general reduction to SAT for discrete functions from a class\ncontaining the majority of functions employed in cryptography. Then, we\ndescribe the Transalg software tool developed based on these principles with\nSAT-based cryptanalysis specifics in mind. We demonstrate the results of\napplications of Transalg to construction of a number of attacks on various\ncryptographic functions. Some of the corresponding attacks are state of the\nart. We compare the functional capabilities of the proposed tool with that of\nother domain-specific software tools which can be used to reduce cryptanalysis\nproblems to SAT, and also with the CBMC system widely employed in symbolic\nverification. The paper also presents vast experimental data, obtained using\nthe SAT solvers that took first places at the SAT competitions in the recent\nseveral years.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 09:18:14 GMT"}, {"version": "v2", "created": "Mon, 18 Mar 2019 08:42:30 GMT"}, {"version": "v3", "created": "Tue, 19 Mar 2019 05:21:43 GMT"}, {"version": "v4", "created": "Fri, 4 Oct 2019 03:02:26 GMT"}, {"version": "v5", "created": "Thu, 27 Feb 2020 22:29:29 GMT"}], "update_date": "2020-06-17", "authors_parsed": [["Semenov", "Alexander", ""], ["Otpuschennikov", "Ilya", ""], ["Gribanova", "Irina", ""], ["Zaikin", "Oleg", ""], ["Kochemazov", "Stepan", ""]]}, {"id": "1805.07249", "submitter": "Shrihari Vasudevan", "authors": "Shrihari Vasudevan", "title": "Dynamic learning rate using Mutual Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper demonstrates dynamic hyper-parameter setting, for deep neural\nnetwork training, using Mutual Information (MI). The specific hyper-parameter\nstudied in this paper is the learning rate. MI between the output layer and\ntrue outcomes is used to dynamically set the learning rate of the network\nthrough the training cycle; the idea is also extended to layer-wise setting of\nlearning rate. Two approaches are demonstrated - tracking relative change in\nmutual information and, additionally tracking its value relative to a reference\nmeasure. The paper does not attempt to recommend a specific learning rate\npolicy. Experiments demonstrate that mutual information may be effectively used\nto dynamically set learning rate and achieve competitive to better outcomes in\ncompetitive to better time.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 14:46:20 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 07:34:51 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Vasudevan", "Shrihari", ""]]}, {"id": "1805.07274", "submitter": "Ghulam Ahmed Ansari", "authors": "Ghulam Ahmed Ansari, Sagar J P, Sarath Chandar, Balaraman Ravindran", "title": "Language Expansion In Text-Based Games", "comments": "9 pages. arXiv admin note: text overlap with arXiv:1511.06295 by\n  other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text-based games are suitable test-beds for designing agents that can learn\nby interaction with the environment in the form of natural language text. Very\nrecently, deep reinforcement learning based agents have been successfully\napplied for playing text-based games. In this paper, we explore the possibility\nof designing a single agent to play several text-based games and of expanding\nthe agent's vocabulary using the vocabulary of agents trained for multiple\ngames. To this extent, we explore the application of recently proposed policy\ndistillation method for video games to the text-based game setting. We also use\ntext-based games as a test-bed to analyze and hence understand policy\ndistillation approach in detail.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 10:43:04 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Ansari", "Ghulam Ahmed", ""], ["P", "Sagar J", ""], ["Chandar", "Sarath", ""], ["Ravindran", "Balaraman", ""]]}, {"id": "1805.07340", "submitter": "Siddhartha Brahma", "authors": "Siddhartha Brahma", "title": "Improved Sentence Modeling using Suffix Bidirectional LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks have become ubiquitous in computing representations\nof sequential data, especially textual data in natural language processing. In\nparticular, Bidirectional LSTMs are at the heart of several neural models\nachieving state-of-the-art performance in a wide variety of tasks in NLP.\nHowever, BiLSTMs are known to suffer from sequential bias - the contextual\nrepresentation of a token is heavily influenced by tokens close to it in a\nsentence. We propose a general and effective improvement to the BiLSTM model\nwhich encodes each suffix and prefix of a sequence of tokens in both forward\nand reverse directions. We call our model Suffix Bidirectional LSTM or\nSuBiLSTM. This introduces an alternate bias that favors long range\ndependencies. We apply SuBiLSTMs to several tasks that require sentence\nmodeling. We demonstrate that using SuBiLSTM instead of a BiLSTM in existing\nmodels leads to improvements in performance in learning general sentence\nrepresentations, text classification, textual entailment and paraphrase\ndetection. Using SuBiLSTM we achieve new state-of-the-art results for\nfine-grained sentiment classification and question classification.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 17:46:25 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 22:16:36 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Brahma", "Siddhartha", ""]]}, {"id": "1805.07349", "submitter": "Amir Khoshaman", "authors": "Amir H. Khoshaman and Mohammad H. Amin", "title": "GumBolt: Extending Gumbel trick to Boltzmann priors", "comments": "10 pages, 2 Figures, 2 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boltzmann machines (BMs) are appealing candidates for powerful priors in\nvariational autoencoders (VAEs), as they are capable of capturing nontrivial\nand multi-modal distributions over discrete variables. However,\nnon-differentiability of the discrete units prohibits using the\nreparameterization trick, essential for low-noise back propagation. The Gumbel\ntrick resolves this problem in a consistent way by relaxing the variables and\ndistributions, but it is incompatible with BM priors. Here, we propose the\nGumBolt, a model that extends the Gumbel trick to BM priors in VAEs. GumBolt is\nsignificantly simpler than the recently proposed methods with BM prior and\noutperforms them by a considerable margin. It achieves state-of-the-art\nperformance on permutation invariant MNIST and OMNIGLOT datasets in the scope\nof models with only discrete latent variables. Moreover, the performance can be\nfurther improved by allowing multi-sampled (importance-weighted) estimation of\nlog-likelihood in training, which was not possible with previous models.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 17:59:17 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 17:30:53 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Khoshaman", "Amir H.", ""], ["Amin", "Mohammad H.", ""]]}, {"id": "1805.07398", "submitter": "Abhijit Mahabal", "authors": "Abhijit Mahabal, Dan Roth, Sid Mittal", "title": "Robust Handling of Polysemy via Sparse Representations", "comments": "*Sem 2018, New Orleans. 9 pages plus references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Words are polysemous and multi-faceted, with many shades of meanings. We\nsuggest that sparse distributed representations are more suitable than other,\ncommonly used, (dense) representations to express these multiple facets, and\npresent Category Builder, a working system that, as we show, makes use of\nsparse representations to support multi-faceted lexical representations. We\nargue that the set expansion task is well suited to study these meaning\ndistinctions since a word may belong to multiple sets with a different reason\nfor membership in each. We therefore exhibit the performance of Category\nBuilder on this task, while showing that our representation captures at the\nsame time analogy problems such as \"the Ganga of Egypt\" or \"the Voldemort of\nTolkien\". Category Builder is shown to be a more expressive lexical\nrepresentation and to outperform dense representations such as Word2Vec in some\nanalogy classes despite being shown only two of the three input terms.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 18:58:38 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Mahabal", "Abhijit", ""], ["Roth", "Dan", ""], ["Mittal", "Sid", ""]]}, {"id": "1805.07429", "submitter": "Chai Wah Wu", "authors": "Chai Wah Wu", "title": "Designing communication systems via iterative improvement: error\n  correction coding with Bayes decoder and codebook optimized for source symbol\n  error", "comments": "18 pages, added Section 7", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In most error correction coding (ECC) frameworks, the typical error metric is\nthe bit error rate (BER) which measures the number of bit errors. For this\nmetric, the positions of the bits are not relevant to the decoding, and in many\nnoise models, not relevant to the BER either. In many applications this is\nunsatisfactory as typically all bits are not equal and have different\nsignificance. We look at ECC from a Bayesian perspective and introduce Bayes\nestimators with general loss functions to take into account the bit\nsignificance. We propose ECC schemes that optimize this error metric. As the\nproblem is highly nonlinear, traditional ECC construction techniques are not\napplicable. Using exhaustive search is cost prohibitive, and thus we use\niterative improvement search techniques to find good codebooks. We optimize\nboth general codebooks and linear codes. We provide numerical experiments to\nshow that they can be superior to classical linear block codes such as Hamming\ncodes and decoding methods such as minimum distance decoding.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 20:23:44 GMT"}, {"version": "v2", "created": "Mon, 10 Sep 2018 01:29:12 GMT"}, {"version": "v3", "created": "Tue, 16 Oct 2018 04:04:16 GMT"}, {"version": "v4", "created": "Tue, 23 Apr 2019 18:13:34 GMT"}], "update_date": "2019-04-25", "authors_parsed": [["Wu", "Chai Wah", ""]]}, {"id": "1805.07431", "submitter": "Chai Wah Wu", "authors": "Chai Wah Wu", "title": "Can machine learning identify interesting mathematics? An exploration\n  using empirically observed laws", "comments": "9 pages, minor edits and fixed typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the possibility of using machine learning to identify interesting\nmathematical structures by using certain quantities that serve as fingerprints.\nIn particular, we extract features from integer sequences using two empirical\nlaws: Benford's law and Taylor's law and experiment with various classifiers to\nidentify whether a sequence is, for example, nice, important, multiplicative,\neasy to compute or related to primes or palindromes.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 20:32:03 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 22:17:07 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 01:45:24 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Wu", "Chai Wah", ""]]}, {"id": "1805.07433", "submitter": "Nuri Cingillioglu", "authors": "Nuri Cingillioglu, Alessandra Russo", "title": "DeepLogic: Towards End-to-End Differentiable Logical Reasoning", "comments": "Camera-ready AAAI-MAKE19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining machine learning with logic-based expert systems in order to get\nthe best of both worlds are becoming increasingly popular. However, to what\nextent machine learning can already learn to reason over rule-based knowledge\nis still an open problem. In this paper, we explore how symbolic logic, defined\nas logic programs at a character level, is learned to be represented in a\nhigh-dimensional vector space using RNN-based iterative neural networks to\nperform reasoning. We create a new dataset that defines 12 classes of logic\nprograms exemplifying increased level of complexity of logical reasoning and\ntrain the networks in an end-to-end fashion to learn whether a logic program\nentails a given query. We analyse how learning the inference algorithm gives\nrise to representations of atoms, literals and rules within logic programs and\nevaluate against increasing lengths of predicate and constant symbols as well\nas increasing steps of multi-hop reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 20:36:21 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 13:15:41 GMT"}, {"version": "v3", "created": "Thu, 7 Mar 2019 21:19:06 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Cingillioglu", "Nuri", ""], ["Russo", "Alessandra", ""]]}, {"id": "1805.07440", "submitter": "Linnan Wang", "authors": "Linnan Wang, Yiyang Zhao, Yuu Jinnai, Yuandong Tian, Rodrigo Fonseca", "title": "Neural Architecture Search using Deep Neural Networks and Monte Carlo\n  Tree Search", "comments": "To appear in the Thirty-Fourth AAAI conference on Artificial\n  Intelligence (AAAI-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural Architecture Search (NAS) has shown great success in automating the\ndesign of neural networks, but the prohibitive amount of computations behind\ncurrent NAS methods requires further investigations in improving the sample\nefficiency and the network evaluation cost to get better results in a shorter\ntime. In this paper, we present a novel scalable Monte Carlo Tree Search (MCTS)\nbased NAS agent, named AlphaX, to tackle these two aspects. AlphaX improves the\nsearch efficiency by adaptively balancing the exploration and exploitation at\nthe state level, and by a Meta-Deep Neural Network (DNN) to predict network\naccuracies for biasing the search toward a promising region. To amortize the\nnetwork evaluation cost, AlphaX accelerates MCTS rollouts with a distributed\ndesign and reduces the number of epochs in evaluating a network by transfer\nlearning, which is guided with the tree structure in MCTS. In 12 GPU days and\n1000 samples, AlphaX found an architecture that reaches 97.84\\% top-1 accuracy\non CIFAR-10, and 75.5\\% top-1 accuracy on ImageNet, exceeding SOTA NAS methods\nin both the accuracy and sampling efficiency. Particularly, we also evaluate\nAlphaX on NASBench-101, a large scale NAS dataset; AlphaX is 3x and 2.8x more\nsample efficient than Random Search and Regularized Evolution in finding the\nglobal optimum. Finally, we show the searched architecture improves a variety\nof vision applications from Neural Style Transfer, to Image Captioning and\nObject Detection.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 20:57:41 GMT"}, {"version": "v2", "created": "Wed, 19 Dec 2018 07:47:47 GMT"}, {"version": "v3", "created": "Mon, 25 Feb 2019 06:50:28 GMT"}, {"version": "v4", "created": "Wed, 2 Oct 2019 01:04:05 GMT"}, {"version": "v5", "created": "Thu, 21 Nov 2019 17:45:31 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Wang", "Linnan", ""], ["Zhao", "Yiyang", ""], ["Jinnai", "Yuu", ""], ["Tian", "Yuandong", ""], ["Fonseca", "Rodrigo", ""]]}, {"id": "1805.07470", "submitter": "Stephen McAleer", "authors": "Stephen McAleer, Forest Agostinelli, Alexander Shmakov, Pierre Baldi", "title": "Solving the Rubik's Cube Without Human Knowledge", "comments": "First three authors contributed equally. Submitted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A generally intelligent agent must be able to teach itself how to solve\nproblems in complex domains with minimal human supervision. Recently, deep\nreinforcement learning algorithms combined with self-play have achieved\nsuperhuman proficiency in Go, Chess, and Shogi without human data or domain\nknowledge. In these environments, a reward is always received at the end of the\ngame, however, for many combinatorial optimization environments, rewards are\nsparse and episodes are not guaranteed to terminate. We introduce Autodidactic\nIteration: a novel reinforcement learning algorithm that is able to teach\nitself how to solve the Rubik's Cube with no human assistance. Our algorithm is\nable to solve 100% of randomly scrambled cubes while achieving a median solve\nlength of 30 moves -- less than or equal to solvers that employ human domain\nknowledge.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:07:31 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["McAleer", "Stephen", ""], ["Agostinelli", "Forest", ""], ["Shmakov", "Alexander", ""], ["Baldi", "Pierre", ""]]}, {"id": "1805.07472", "submitter": "Jeremy Morton", "authors": "Jeremy Morton, Freddie D. Witherden, Antony Jameson, Mykel J.\n  Kochenderfer", "title": "Deep Dynamical Modeling and Control of Unsteady Fluid Flows", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The design of flow control systems remains a challenge due to the nonlinear\nnature of the equations that govern fluid flow. However, recent advances in\ncomputational fluid dynamics (CFD) have enabled the simulation of complex fluid\nflows with high accuracy, opening the possibility of using learning-based\napproaches to facilitate controller design. We present a method for learning\nthe forced and unforced dynamics of airflow over a cylinder directly from CFD\ndata. The proposed approach, grounded in Koopman theory, is shown to produce\nstable dynamical models that can predict the time evolution of the cylinder\nsystem over extended time horizons. Finally, by performing model predictive\ncontrol with the learned dynamical models, we are able to find a\nstraightforward, interpretable control law for suppressing vortex shedding in\nthe wake of the cylinder.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:14:17 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 02:31:56 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Morton", "Jeremy", ""], ["Witherden", "Freddie D.", ""], ["Jameson", "Antony", ""], ["Kochenderfer", "Mykel J.", ""]]}, {"id": "1805.07473", "submitter": "Yuhong Guo", "authors": "Meng Ye and Yuhong Guo", "title": "Progressive Ensemble Networks for Zero-Shot Recognition", "comments": "CVPR19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the advancement of supervised image recognition algorithms, their\ndependence on the availability of labeled data and the rapid expansion of image\ncategories raise the significant challenge of zero-shot learning. Zero-shot\nlearning (ZSL) aims to transfer knowledge from labeled classes into unlabeled\nclasses to reduce human labeling effort. In this paper, we propose a novel\nprogressive ensemble network model with multiple projected label embeddings to\naddress zero-shot image recognition. The ensemble network is built by learning\nmultiple image classification functions with a shared feature extraction\nnetwork but different label embedding representations, which enhance the\ndiversity of the classifiers and facilitate information transfer to unlabeled\nclasses. A progressive training framework is then deployed to gradually label\nthe most confident images in each unlabeled class with predicted pseudo-labels\nand update the ensemble network with the training data augmented by the\npseudo-labels. The proposed model performs training on both labeled and\nunlabeled data. It can naturally bridge the domain shift problem in visual\nappearances and be extended to the generalized zero-shot learning scenario. We\nconduct experiments on multiple ZSL datasets and the empirical results\ndemonstrate the efficacy of the proposed model.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:24:12 GMT"}, {"version": "v2", "created": "Sat, 6 Apr 2019 22:07:42 GMT"}], "update_date": "2019-04-09", "authors_parsed": [["Ye", "Meng", ""], ["Guo", "Yuhong", ""]]}, {"id": "1805.07476", "submitter": "Sina Ghiassian", "authors": "Sina Ghiassian, Huizhen Yu, Banafsheh Rafiee, Richard S. Sutton", "title": "Two geometric input transformation methods for fast online reinforcement\n  learning with neural nets", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We apply neural nets with ReLU gates in online reinforcement learning. Our\ngoal is to train these networks in an incremental manner, without the\ncomputationally expensive experience replay. By studying how individual neural\nnodes behave in online training, we recognize that the global nature of ReLU\ngates can cause undesirable learning interference in each node's learning\nbehavior. We propose reducing such interferences with two efficient input\ntransformation methods that are geometric in nature and match well the\ngeometric property of ReLU gates. The first one is tile coding, a classic\nbinary encoding scheme originally designed for local generalization based on\nthe topological structure of the input space. The second one (EmECS) is a new\nmethod we introduce; it is based on geometric properties of convex sets and\ntopological embedding of the input space into the boundary of a convex set. We\ndiscuss the behavior of the network when it operates on the transformed inputs.\nWe also compare it experimentally with some neural nets that do not use the\nsame input transformations, and with the classic algorithm of tile coding plus\na linear function approximator, and on several online reinforcement learning\ntasks, we show that the neural net with tile coding or EmECS can achieve not\nonly faster learning but also more accurate approximations. Our results\nstrongly suggest that geometric input transformation of this type can be\neffective for interference reduction and takes us a step closer to fully\nincremental reinforcement learning with neural nets.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:35:14 GMT"}, {"version": "v2", "created": "Thu, 6 Sep 2018 21:09:44 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Ghiassian", "Sina", ""], ["Yu", "Huizhen", ""], ["Rafiee", "Banafsheh", ""], ["Sutton", "Richard S.", ""]]}, {"id": "1805.07494", "submitter": "Hyoungwook Nam", "authors": "Hyoungwook Nam, Segwang Kim, Kyomin Jung", "title": "Number Sequence Prediction Problems for Evaluating Computational Powers\n  of Neural Networks", "comments": "Accepted to 2019 AAAI Conference on Artificial Intelligence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by number series tests to measure human intelligence, we suggest\nnumber sequence prediction tasks to assess neural network models' computational\npowers for solving algorithmic problems. We define the complexity and\ndifficulty of a number sequence prediction task with the structure of the\nsmallest automaton that can generate the sequence. We suggest two types of\nnumber sequence prediction problems: the number-level and the digit-level\nproblems. The number-level problems format sequences as 2-dimensional grids of\ndigits and the digit-level problems provide a single digit input per a time\nstep. The complexity of a number-level sequence prediction can be defined with\nthe depth of an equivalent combinatorial logic, and the complexity of a\ndigit-level sequence prediction can be defined with an equivalent state\nautomaton for the generation rule. Experiments with number-level sequences\nsuggest that CNN models are capable of learning the compound operations of\nsequence generation rules, but the depths of the compound operations are\nlimited. For the digit-level problems, simple GRU and LSTM models can solve\nsome problems with the complexity of finite state automata. Memory augmented\nmodels such as Stack-RNN, Attention, and Neural Turing Machines can solve the\nreverse-order task which has the complexity of simple pushdown automaton.\nHowever, all of above cannot solve general Fibonacci, Arithmetic or Geometric\nsequence generation problems that represent the complexity of queue automata or\nTuring machines. The results show that our number sequence prediction problems\neffectively evaluate machine learning models' computational capabilities.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 02:36:13 GMT"}, {"version": "v2", "created": "Sat, 10 Nov 2018 09:43:26 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Nam", "Hyoungwook", ""], ["Kim", "Segwang", ""], ["Jung", "Kyomin", ""]]}, {"id": "1805.07504", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang", "title": "Deep Loopy Neural Network Model for Graph Structured Data Representation\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing deep learning models may encounter great challenges in handling\ngraph structured data. In this paper, we introduce a new deep learning model\nfor graph data specifically, namely the deep loopy neural network.\nSignificantly different from the previous deep models, inside the deep loopy\nneural network, there exist a large number of loops created by the extensive\nconnections among nodes in the input graph data, which makes model learning an\ninfeasible task. To resolve such a problem, in this paper, we will introduce a\nnew learning algorithm for the deep loopy neural network specifically. Instead\nof learning the model variables based on the original model, in the proposed\nlearning algorithm, errors will be back-propagated through the edges in a group\nof extracted spanning trees. Extensive numerical experiments have been done on\nseveral real-world graph datasets, and the experimental results demonstrate the\neffectiveness of both the proposed model and the learning algorithm in handling\ngraph data.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 03:33:20 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 17:45:22 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Zhang", "Jiawei", ""]]}, {"id": "1805.07505", "submitter": "Yang Liu", "authors": "Xiang Ao, Yang Liu, Zhen Huang, Luo Zuo, Qing He", "title": "Free-rider Episode Screening via Dual Partition Model", "comments": "The 23rd International Conference on Database Systems for Advanced\n  Applications(DASFAA 2018), 16 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the drawbacks of frequent episode mining is that overwhelmingly many\nof the discovered patterns are redundant. Free-rider episode, as a typical\nexample, consists of a real pattern doped with some additional noise events.\nBecause of the possible high support of the inside noise events, such\nfree-rider episodes may have abnormally high support that they cannot be\nfiltered by frequency based framework. An effective technique for filtering\nfree-rider episodes is using a partition model to divide an episode into two\nconsecutive subepisodes and comparing the observed support of such episode with\nits expected support under the assumption that these two subepisodes occur\nindependently. In this paper, we take more complex subepisodes into\nconsideration and develop a novel partition model named EDP for free-rider\nepisode filtering from a given set of episodes. It combines (1) a dual\npartition strategy which divides an episode to an underlying real pattern and\npotential noises; (2) a novel definition of the expected support of a\nfree-rider episode based on the proposed partition strategy. We can deem the\nepisode interesting if the observed support is substantially higher than the\nexpected support estimated by our model. The experiments on synthetic and\nreal-world datasets demonstrate EDP can effectively filter free-rider episodes\ncompared with existing state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 03:34:09 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Ao", "Xiang", ""], ["Liu", "Yang", ""], ["Huang", "Zhen", ""], ["Zuo", "Luo", ""], ["He", "Qing", ""]]}, {"id": "1805.07535", "submitter": "Gera Weiss", "authors": "Liat Cohen, Dror Fried, Gera Weiss", "title": "An optimal approximation of discrete random variables with respect to\n  the Kolmogorov distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an algorithm that takes a discrete random variable $X$ and a\nnumber $m$ and computes a random variable whose support (set of possible\noutcomes) is of size at most $m$ and whose Kolmogorov distance from $X$ is\nminimal. In addition to a formal theoretical analysis of the correctness and of\nthe computational complexity of the algorithm, we present a detailed empirical\nevaluation that shows how the proposed approach performs in practice in\ndifferent applications and domains.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 07:38:18 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Cohen", "Liat", ""], ["Fried", "Dror", ""], ["Weiss", "Gera", ""]]}, {"id": "1805.07541", "submitter": "Yu Zhang", "authors": "Yu Zhang, Ying Wei, Qiang Yang", "title": "Learning to Multitask", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multitask learning has shown promising performance in many applications and\nmany multitask models have been proposed. In order to identify an effective\nmultitask model for a given multitask problem, we propose a learning framework\ncalled learning to multitask (L2MT). To achieve the goal, L2MT exploits\nhistorical multitask experience which is organized as a training set consists\nof several tuples, each of which contains a multitask problem with multiple\ntasks, a multitask model, and the relative test error. Based on such training\nset, L2MT first uses a proposed layerwise graph neural network to learn task\nembeddings for all the tasks in a multitask problem and then learns an\nestimation function to estimate the relative test error based on task\nembeddings and the representation of the multitask model based on a unified\nformulation. Given a new multitask problem, the estimation function is used to\nidentify a suitable multitask model. Experiments on benchmark datasets show the\neffectiveness of the proposed L2MT framework.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 08:07:30 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Zhang", "Yu", ""], ["Wei", "Ying", ""], ["Yang", "Qiang", ""]]}, {"id": "1805.07547", "submitter": "Emilio Cartoni", "authors": "Emilio Cartoni, Gianluca Baldassarre", "title": "Autonomous discovery of the goal space to learn a parameterized skill", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A parameterized skill is a mapping from multiple goals/task parameters to the\npolicy parameters to accomplish them. Existing works in the literature show how\na parameterized skill can be learned given a task space that defines all the\npossible achievable goals. In this work, we focus on tasks defined in terms of\nfinal states (goals), and we face on the challenge where the agent aims to\nautonomously acquire a parameterized skill to manipulate an initially unknown\nenvironment. In this case, the task space is not known a priori and the agent\nhas to autonomously discover it. The agent may posit as a task space its whole\nsensory space (i.e. the space of all possible sensor readings) as the\nachievable goals will certainly be a subset of this space. However, the space\nof achievable goals may be a very tiny subspace in relation to the whole\nsensory space, thus directly using the sensor space as task space exposes the\nagent to the curse of dimensionality and makes existing autonomous skill\nacquisition algorithms inefficient. In this work we present an algorithm that\nactively discovers the manifold of the achievable goals within the sensor\nspace. We validate the algorithm by employing it in multiple different\nsimulated scenarios where the agent actions achieve different types of goals:\nmoving a redundant arm, pushing an object, and changing the color of an object.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 08:18:39 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Cartoni", "Emilio", ""], ["Baldassarre", "Gianluca", ""]]}, {"id": "1805.07563", "submitter": "Josef Urban", "authors": "Cezary Kaliszyk, Josef Urban, Henryk Michalewski, Mirek Ol\\v{s}\\'ak", "title": "Reinforcement Learning of Theorem Proving", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a theorem proving algorithm that uses practically no domain\nheuristics for guiding its connection-style proof search. Instead, it runs many\nMonte-Carlo simulations guided by reinforcement learning from previous proof\nattempts. We produce several versions of the prover, parameterized by different\nlearning and guiding algorithms. The strongest version of the system is trained\non a large corpus of mathematical problems and evaluated on previously unseen\nproblems. The trained system solves within the same number of inferences over\n40% more problems than a baseline prover, which is an unusually high\nimprovement in this hard AI domain. To our knowledge this is the first time\nreinforcement learning has been convincingly applied to solving general\nmathematical problems on a large scale.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 10:05:43 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kaliszyk", "Cezary", ""], ["Urban", "Josef", ""], ["Michalewski", "Henryk", ""], ["Ol\u0161\u00e1k", "Mirek", ""]]}, {"id": "1805.07592", "submitter": "Maryam Aziz", "authors": "Maryam Aziz, Jesse Anderton, Javed Aslam", "title": "Adaptively Pruning Features for Boosted Decision Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boosted decision trees enjoy popularity in a variety of applications;\nhowever, for large-scale datasets, the cost of training a decision tree in each\nround can be prohibitively expensive. Inspired by ideas from the multi-arm\nbandit literature, we develop a highly efficient algorithm for computing exact\ngreedy-optimal decision trees, outperforming the state-of-the-art Quick Boost\nmethod. We further develop a framework for deriving lower bounds on the problem\nthat applies to a wide family of conceivable algorithms for the task (including\nour algorithm and Quick Boost), and we demonstrate empirically on a wide\nvariety of data sets that our algorithm is near-optimal within this family of\nalgorithms. We also derive a lower bound applicable to any algorithm solving\nthe task, and we demonstrate that our algorithm empirically achieves\nperformance close to this best-achievable lower bound.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 13:44:57 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Aziz", "Maryam", ""], ["Anderton", "Jesse", ""], ["Aslam", "Javed", ""]]}, {"id": "1805.07603", "submitter": "Zichuan Lin", "authors": "Zichuan Lin, Tianqi Zhao, Guangwen Yang, Lintao Zhang", "title": "Episodic Memory Deep Q-Networks", "comments": "Accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) algorithms have made huge progress in recent\nyears by leveraging the power of deep neural networks (DNN). Despite the\nsuccess, deep RL algorithms are known to be sample inefficient, often requiring\nmany rounds of interaction with the environments to obtain satisfactory\nperformance. Recently, episodic memory based RL has attracted attention due to\nits ability to latch on good actions quickly. In this paper, we present a\nsimple yet effective biologically inspired RL algorithm called Episodic Memory\nDeep Q-Networks (EMDQN), which leverages episodic memory to supervise an agent\nduring training. Experiments show that our proposed method can lead to better\nsample efficiency and is more likely to find good policies. It only requires\n1/5 of the interactions of DQN to achieve many state-of-the-art performances on\nAtari games, significantly outperforming regular DQN and other episodic memory\nbased RL algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 14:33:00 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Lin", "Zichuan", ""], ["Zhao", "Tianqi", ""], ["Yang", "Guangwen", ""], ["Zhang", "Lintao", ""]]}, {"id": "1805.07648", "submitter": "Vishvak Murahari", "authors": "Vishvak S Murahari, Thomas Ploetz", "title": "On Attention Models for Human Activity Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Most approaches that model time-series data in human activity recognition\nbased on body-worn sensing (HAR) use a fixed size temporal context to represent\ndifferent activities. This might, however, not be apt for sets of activities\nwith individ- ually varying durations. We introduce attention models into HAR\nresearch as a data driven approach for exploring relevant temporal context.\nAttention models learn a set of weights over input data, which we leverage to\nweight the temporal context being considered to model each sensor reading. We\nconstruct attention models for HAR by adding attention layers to a state-\nof-the-art deep learning HAR model (DeepConvLSTM) and evaluate our approach on\nbenchmark datasets achieving sig- nificant increase in performance. Finally, we\nvisualize the learned weights to better understand what constitutes relevant\ntemporal context.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 20:13:05 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Murahari", "Vishvak S", ""], ["Ploetz", "Thomas", ""]]}, {"id": "1805.07683", "submitter": "Yu Jin", "authors": "Yu Jin, Joseph F. JaJa", "title": "Learning Graph-Level Representations with Recurrent Neural Networks", "comments": "Submit to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently a variety of methods have been developed to encode graphs into\nlow-dimensional vectors that can be easily exploited by machine learning\nalgorithms. The majority of these methods start by embedding the graph nodes\ninto a low-dimensional vector space, followed by using some scheme to aggregate\nthe node embeddings. In this work, we develop a new approach to learn\ngraph-level representations, which includes a combination of unsupervised and\nsupervised learning components. We start by learning a set of node\nrepresentations in an unsupervised fashion. Graph nodes are mapped into node\nsequences sampled from random walk approaches approximated by the\nGumbel-Softmax distribution. Recurrent neural network (RNN) units are modified\nto accommodate both the node representations as well as their neighborhood\ninformation. Experiments on standard graph classification benchmarks\ndemonstrate that our proposed approach achieves superior or comparable\nperformance relative to the state-of-the-art algorithms in terms of convergence\nspeed and classification accuracy. We further illustrate the effectiveness of\nthe different components used by our approach.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 00:26:37 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 14:41:16 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 03:11:16 GMT"}, {"version": "v4", "created": "Tue, 11 Sep 2018 18:19:09 GMT"}], "update_date": "2018-09-13", "authors_parsed": [["Jin", "Yu", ""], ["JaJa", "Joseph F.", ""]]}, {"id": "1805.07708", "submitter": "Yinlam Chow", "authors": "Yinlam Chow and Ofir Nachum and Edgar Duenez-Guzman and Mohammad\n  Ghavamzadeh", "title": "A Lyapunov-based Approach to Safe Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many real-world reinforcement learning (RL) problems, besides optimizing\nthe main objective function, an agent must concurrently avoid violating a\nnumber of constraints. In particular, besides optimizing performance it is\ncrucial to guarantee the safety of an agent during training as well as\ndeployment (e.g. a robot should avoid taking actions - exploratory or not -\nwhich irrevocably harm its hardware). To incorporate safety in RL, we derive\nalgorithms under the framework of constrained Markov decision problems (CMDPs),\nan extension of the standard Markov decision problems (MDPs) augmented with\nconstraints on expected cumulative costs. Our approach hinges on a novel\n\\emph{Lyapunov} method. We define and present a method for constructing\nLyapunov functions, which provide an effective way to guarantee the global\nsafety of a behavior policy during training via a set of local, linear\nconstraints. Leveraging these theoretical underpinnings, we show how to use the\nLyapunov approach to systematically transform dynamic programming (DP) and RL\nalgorithms into their safe counterparts. To illustrate their effectiveness, we\nevaluate these algorithms in several CMDP planning and decision-making tasks on\na safety benchmark domain. Our results show that our proposed method\nsignificantly outperforms existing baselines in balancing constraint\nsatisfaction and performance.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 05:12:04 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Chow", "Yinlam", ""], ["Nachum", "Ofir", ""], ["Duenez-Guzman", "Edgar", ""], ["Ghavamzadeh", "Mohammad", ""]]}, {"id": "1805.07715", "submitter": "Andri Ashfahani", "authors": "Andri Ashfahani, Mahardhika Pratama, Edwin Lughofer, Qing Cai, and\n  Huang Sheng", "title": "An Online RFID Localization in the Manufacturing Shopfloor", "comments": null, "journal-ref": "Predictive Maintenance in Dynamic Systems: Advanced Methods,\n  Decision Support Tools and Real-World Applications 2019", "doi": "10.1007/978-3-030-05645-2_10", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  {Radio Frequency Identification technology has gained popularity for cheap\nand easy deployment. In the realm of manufacturing shopfloor, it can be used to\ntrack the location of manufacturing objects to achieve better efficiency. The\nunderlying challenge of localization lies in the non-stationary characteristics\nof manufacturing shopfloor which calls for an adaptive life-long learning\nstrategy in order to arrive at accurate localization results. This paper\npresents an evolving model based on a novel evolving intelligent system, namely\nevolving Type-2 Quantum Fuzzy Neural Network (eT2QFNN), which features an\ninterval type-2 quantum fuzzy set with uncertain jump positions. The quantum\nfuzzy set possesses a graded membership degree which enables better\nidentification of overlaps between classes. The eT2QFNN works fully in the\nevolving mode where all parameters including the number of rules are\nautomatically adjusted and generated on the fly. The parameter adjustment\nscenario relies on decoupled extended Kalman filter method. Our numerical study\nshows that eT2QFNN is able to deliver comparable accuracy compared to\nstate-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 06:27:53 GMT"}, {"version": "v2", "created": "Wed, 29 May 2019 18:56:04 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Ashfahani", "Andri", ""], ["Pratama", "Mahardhika", ""], ["Lughofer", "Edwin", ""], ["Cai", "Qing", ""], ["Sheng", "Huang", ""]]}, {"id": "1805.07732", "submitter": "Chao Qu", "authors": "Chao Qu, Shie Mannor, Huan Xu", "title": "Nonlinear Distributional Gradient Temporal-Difference Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We devise a distributional variant of gradient temporal-difference (TD)\nlearning. Distributional reinforcement learning has been demonstrated to\noutperform the regular one in the recent study\n\\citep{bellemare2017distributional}. In the policy evaluation setting, we\ndesign two new algorithms called distributional GTD2 and distributional TDC\nusing the Cram{\\'e}r distance on the distributional version of the Bellman\nerror objective function, which inherits advantages of both the nonlinear\ngradient TD algorithms and the distributional RL approach. In the control\nsetting, we propose the distributional Greedy-GQ using the similar derivation.\nWe prove the asymptotic almost-sure convergence of distributional GTD2 and TDC\nto a local optimal solution for general smooth function approximators, which\nincludes neural networks that have been widely used in recent study to solve\nthe real-life RL problems. In each step, the computational complexities of\nabove three algorithms are linear w.r.t.\\ the number of the parameters of the\nfunction approximator, thus can be implemented efficiently for neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 08:43:05 GMT"}, {"version": "v2", "created": "Sun, 27 Jan 2019 04:58:44 GMT"}, {"version": "v3", "created": "Wed, 3 Apr 2019 03:38:05 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Qu", "Chao", ""], ["Mannor", "Shie", ""], ["Xu", "Huan", ""]]}, {"id": "1805.07733", "submitter": "Zongqing Lu", "authors": "Jiechuan Jiang and Zongqing Lu", "title": "Learning Attentional Communication for Multi-Agent Cooperation", "comments": "NIPS'18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication could potentially be an effective way for multi-agent\ncooperation. However, information sharing among all agents or in predefined\ncommunication architectures that existing methods adopt can be problematic.\nWhen there is a large number of agents, agents cannot differentiate valuable\ninformation that helps cooperative decision making from globally shared\ninformation. Therefore, communication barely helps, and could even impair the\nlearning of multi-agent cooperation. Predefined communication architectures, on\nthe other hand, restrict communication among agents and thus restrain potential\ncooperation. To tackle these difficulties, in this paper, we propose an\nattentional communication model that learns when communication is needed and\nhow to integrate shared information for cooperative decision making. Our model\nleads to efficient and effective communication for large-scale multi-agent\ncooperation. Empirically, we show the strength of our model in a variety of\ncooperative scenarios, where agents are able to develop more coordinated and\nsophisticated strategies than existing methods.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 08:45:50 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 09:15:28 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 04:09:49 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Jiang", "Jiechuan", ""], ["Lu", "Zongqing", ""]]}, {"id": "1805.07780", "submitter": "Vik Goel", "authors": "Vik Goel, Jameson Weng, Pascal Poupart", "title": "Unsupervised Video Object Segmentation for Deep Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new technique for deep reinforcement learning that automatically\ndetects moving objects and uses the relevant information for action selection.\nThe detection of moving objects is done in an unsupervised way by exploiting\nstructure from motion. Instead of directly learning a policy from raw images,\nthe agent first learns to detect and segment moving objects by exploiting flow\ninformation in video sequences. The learned representation is then used to\nfocus the policy of the agent on the moving objects. Over time, the agent\nidentifies which objects are critical for decision making and gradually builds\na policy based on relevant moving objects. This approach, which we call\nMotion-Oriented REinforcement Learning (MOREL), is demonstrated on a suite of\nAtari games where the ability to detect moving objects reduces the amount of\ninteraction needed with the environment to obtain a good policy. Furthermore,\nthe resulting policy is more interpretable than policies that directly map\nimages to actions or values with a black box neural network. We can gain\ninsight into the policy by inspecting the segmentation and motion of each\nobject detected by the agent. This allows practitioners to confirm whether a\npolicy is making decisions based on sensible information.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 15:45:03 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Goel", "Vik", ""], ["Weng", "Jameson", ""], ["Poupart", "Pascal", ""]]}, {"id": "1805.07782", "submitter": "Neel Guha", "authors": "Neel Guha, Virginia Smith", "title": "Model Aggregation via Good-Enough Model Spaces", "comments": "21 pages, 6 figures, 8 tablees", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many applications, the training data for a machine learning task is\npartitioned across multiple nodes, and aggregating this data may be infeasible\ndue to communication, privacy, or storage constraints. Existing distributed\noptimization methods for learning global models in these settings typically\naggregate local updates from each node in an iterative fashion. However, these\napproaches require many rounds of communication between nodes, and assume that\nupdates can be synchronously shared across a connected network. In this work,\nwe present Good-Enough Model Spaces (GEMS), a novel framework for learning a\nglobal model by carefully intersecting the sets of \"good-enough\" models across\neach node. Our approach utilizes minimal communication and does not require\nsharing of data between nodes. We present methods for learning both convex\nmodels and neural networks within this framework and discuss how small samples\nof held-out data can be used for post-learning fine-tuning. In experiments on\nimage and medical datasets, our approach on average improves upon other\nbaseline aggregation techniques such as ensembling or model averaging by as\nmuch as 15 points (accuracy).\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 15:58:14 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2018 15:47:06 GMT"}, {"version": "v3", "created": "Tue, 4 Jun 2019 18:34:56 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Guha", "Neel", ""], ["Smith", "Virginia", ""]]}, {"id": "1805.07797", "submitter": "Naveen Sundar Govindarajulu", "authors": "Naveen Sundar Govindarajulu and Selmer Bringjsord and Rikhiya Ghosh", "title": "One Formalization of Virtue Ethics via Learning", "comments": "IACAP 2018\n  (http://www.iacap.org/wp-content/uploads/2017/10/IACAP-2018-short-program.pdf)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given that there exist many different formal and precise treatments of\ndeontologi- cal and consequentialist ethics, we turn to virtue ethics and\nconsider what could be a formalization of virtue ethics that makes it amenable\nto automation. We present an embroyonic formalization in a cognitive calculus\n(which subsumes a quantified first-order logic) that has been previously used\nto model robust ethical principles, in both the deontological and\nconsequentialist traditions.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 17:03:47 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Govindarajulu", "Naveen Sundar", ""], ["Bringjsord", "Selmer", ""], ["Ghosh", "Rikhiya", ""]]}, {"id": "1805.07798", "submitter": "Simon Du", "authors": "Simon S. Du, Surbhi Goel", "title": "Improved Learning of One-hidden-layer Convolutional Neural Networks with\n  Overlaps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.DS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new algorithm to learn a one-hidden-layer convolutional neural\nnetwork where both the convolutional weights and the outputs weights are\nparameters to be learned. Our algorithm works for a general class of\n(potentially overlapping) patches, including commonly used structures for\ncomputer vision tasks. Our algorithm draws ideas from (1) isotonic regression\nfor learning neural networks and (2) landscape analysis of non-convex matrix\nfactorization problems. We believe these findings may inspire further\ndevelopment in designing provable algorithms for learning neural networks and\nother complex models.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 17:07:25 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 23:29:24 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Du", "Simon S.", ""], ["Goel", "Surbhi", ""]]}, {"id": "1805.07802", "submitter": "Dimche Kostadinov", "authors": "Dimche Kostadinov, Behrooz Razeghi, Sohrab Ferdowsi, Slava\n  Voloshynovskiy", "title": "Network Learning with Local Propagation", "comments": "preprint, a similar version submitted to NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a locally decoupled network parameter learning with local\npropagation. Three elements are taken into account: (i) sets of nonlinear\ntransforms that describe the representations at all nodes, (ii) a local\nobjective at each node related to the corresponding local representation goal,\nand (iii) a local propagation model that relates the nonlinear error vectors at\neach node with the goal error vectors from the directly connected nodes. The\nmodeling concepts (i), (ii) and (iii) offer several advantages, including (a) a\nunified learning principle for any network that is represented as a graph, (b)\nunderstanding and interpretation of the local and the global learning dynamics,\n(c) decoupled and parallel parameter learning, (d) a possibility for learning\nin infinitely long, multi-path and multi-goal networks. Numerical experiments\nvalidate the potential of the learning principle. The preliminary results show\nadvantages in comparison to the state-of-the-art methods, w.r.t. the learning\ntime and the network size while having comparable recognition accuracy.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 17:21:05 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Kostadinov", "Dimche", ""], ["Razeghi", "Behrooz", ""], ["Ferdowsi", "Sohrab", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1805.07805", "submitter": "Elad Sarafian", "authors": "Elad Sarafian, Aviv Tamar and Sarit Kraus", "title": "Constrained Policy Improvement for Safe and Efficient Reinforcement\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a policy improvement algorithm for Reinforcement Learning (RL)\nwhich is called Rerouted Behavior Improvement (RBI). RBI is designed to take\ninto account the evaluation errors of the Q-function. Such errors are common in\nRL when learning the $Q$-value from finite past experience data. Greedy\npolicies or even constrained policy optimization algorithms which ignore these\nerrors may suffer from an improvement penalty (i.e. a negative policy\nimprovement). To minimize the improvement penalty, the RBI idea is to attenuate\nrapid policy changes of low probability actions which were less frequently\nsampled. This approach is shown to avoid catastrophic performance degradation\nand reduce regret when learning from a batch of past experience. Through a\ntwo-armed bandit with Gaussian distributed rewards example, we show that it\nalso increases data efficiency when the optimal action has a high variance. We\nevaluate RBI in two tasks in the Atari Learning Environment: (1) learning from\nobservations of multiple behavior policies and (2) iterative RL. Our results\ndemonstrate the advantage of RBI over greedy policies and other constrained\npolicy optimization algorithms as a safe learning approach and as a general\ndata efficient learning algorithm. An anonymous Github repository of our RBI\nimplementation is found at https://github.com/eladsar/rbi.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 17:47:03 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 06:19:34 GMT"}, {"version": "v3", "created": "Wed, 10 Jul 2019 20:12:07 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Sarafian", "Elad", ""], ["Tamar", "Aviv", ""], ["Kraus", "Sarit", ""]]}, {"id": "1805.07828", "submitter": "Ping Guo", "authors": "Ping Guo (School of Systems Science, Beijing Normal University,\n  Beijing, China)", "title": "A VEST of the Pseudoinverse Learning Algorithm", "comments": "ELM is another name of the PIL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we briefly review the basic scheme of the pseudoinverse\nlearning (PIL) algorithm and present some discussions on the PIL, as well as\nits variants. The PIL algorithm, first presented in 1995, is a non-gradient\ndescent and non-iterative learning algorithm for multi-layer neural networks\nand has several advantages compared with gradient descent based algorithms.\nSome new viewpoints to PIL algorithm are presented, and several common pitfalls\nin practical implementation of the neural network learning task are also\naddressed. In addition, we show that so called extreme learning machine is a\nVariant crEated by Simple name alTernation (VEST) of the PIL algorithm for\nsingle hidden layer feedforward neural networks.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 21:46:29 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 14:36:25 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Guo", "Ping", "", "School of Systems Science, Beijing Normal University,\n  Beijing, China"]]}, {"id": "1805.07830", "submitter": "Shayegan Omidshafiei", "authors": "Shayegan Omidshafiei, Dong-Ki Kim, Miao Liu, Gerald Tesauro, Matthew\n  Riemer, Christopher Amato, Murray Campbell, Jonathan P. How", "title": "Learning to Teach in Cooperative Multiagent Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective human knowledge has clearly benefited from the fact that\ninnovations by individuals are taught to others through communication. Similar\nto human social groups, agents in distributed learning systems would likely\nbenefit from communication to share knowledge and teach skills. The problem of\nteaching to improve agent learning has been investigated by prior works, but\nthese approaches make assumptions that prevent application of teaching to\ngeneral multiagent problems, or require domain expertise for problems they can\napply to. This learning to teach problem has inherent complexities related to\nmeasuring long-term impacts of teaching that compound the standard multiagent\ncoordination challenges. In contrast to existing works, this paper presents the\nfirst general framework and algorithm for intelligent agents to learn to teach\nin a multiagent environment. Our algorithm, Learning to Coordinate and Teach\nReinforcement (LeCTR), addresses peer-to-peer teaching in cooperative\nmultiagent reinforcement learning. Each agent in our approach learns both when\nand what to advise, then uses the received advice to improve local learning.\nImportantly, these roles are not fixed; these agents learn to assume the role\nof student and/or teacher at the appropriate moments, requesting and providing\nadvice in order to improve teamwide performance and learning. Empirical\ncomparisons against state-of-the-art teaching methods show that our teaching\nagents not only learn significantly faster, but also learn to coordinate in\ntasks where existing methods fail.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 22:23:46 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 14:10:38 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 16:21:50 GMT"}, {"version": "v4", "created": "Fri, 31 Aug 2018 18:36:15 GMT"}], "update_date": "2018-09-05", "authors_parsed": [["Omidshafiei", "Shayegan", ""], ["Kim", "Dong-Ki", ""], ["Liu", "Miao", ""], ["Tesauro", "Gerald", ""], ["Riemer", "Matthew", ""], ["Amato", "Christopher", ""], ["Campbell", "Murray", ""], ["How", "Jonathan P.", ""]]}, {"id": "1805.07848", "submitter": "Yaniv Taigman", "authors": "Noam Mor, Lior Wolf, Adam Polyak, Yaniv Taigman", "title": "A Universal Music Translation Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for translating music across musical instruments, genres,\nand styles. This method is based on a multi-domain wavenet autoencoder, with a\nshared encoder and a disentangled latent space that is trained end-to-end on\nwaveforms. Employing a diverse training dataset and large net capacity, the\ndomain-independent encoder allows us to translate even from musical domains\nthat were not seen during training. The method is unsupervised and does not\nrely on supervision in the form of matched samples between domains or musical\ntranscriptions. We evaluate our method on NSynth, as well as on a dataset\ncollected from professional musicians, and achieve convincing translations,\neven when translating from whistling, potentially enabling the creation of\ninstrumental music by untrained humans.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 00:20:03 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 17:23:54 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Mor", "Noam", ""], ["Wolf", "Lior", ""], ["Polyak", "Adam", ""], ["Taigman", "Yaniv", ""]]}, {"id": "1805.07871", "submitter": "Prashant Doshi", "authors": "Saurabh Arora and Prashant Doshi and Bikramjit Banerjee", "title": "A Framework and Method for Online Inverse Reinforcement Learning", "comments": null, "journal-ref": "Journal of Autonomous Agents and Multi-Agent Systems, Volume 35,\n  Article number: 4 (2021)", "doi": "10.1007/s10458-020-09485-4", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverse reinforcement learning (IRL) is the problem of learning the\npreferences of an agent from the observations of its behavior on a task. While\nthis problem has been well investigated, the related problem of {\\em online}\nIRL---where the observations are incrementally accrued, yet the demands of the\napplication often prohibit a full rerun of an IRL method---has received\nrelatively less attention. We introduce the first formal framework for online\nIRL, called incremental IRL (I2RL), and a new method that advances maximum\nentropy IRL with hidden variables, to this setting. Our formal analysis shows\nthat the new method has a monotonically improving performance with more\ndemonstration data, as well as probabilistically bounded error, both under full\nand partial observability. Experiments in a simulated robotic application of\npenetrating a continuous patrol under occlusion shows the relatively improved\nperformance and speed up of the new method and validates the utility of online\nIRL.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 02:27:58 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Arora", "Saurabh", ""], ["Doshi", "Prashant", ""], ["Banerjee", "Bikramjit", ""]]}, {"id": "1805.07874", "submitter": "Yu-Chiao Chiu", "authors": "Hung-I Harry Chen, Yu-Chiao Chiu, Tinghe Zhang, Songyao Zhang, Yufei\n  Huang, Yidong Chen", "title": "GSAE: an autoencoder with embedded gene-set nodes for genomics\n  functional characterization", "comments": "Presented in the International Conference on Intelligent Biology and\n  Medicine (ICIBM 2018) at Los Angeles, CA, USA and published in BMC Systems\n  Biology 2018, 12(Suppl 8):142", "journal-ref": "BMC Systems Biology 2018, 12(Suppl 8):142", "doi": "10.1186/s12918-018-0642-2", "report-no": null, "categories": "stat.ML cs.AI cs.LG q-bio.GN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bioinformatics tools have been developed to interpret gene expression data at\nthe gene set level, and these gene set based analyses improve the biologists'\ncapability to discover functional relevance of their experiment design. While\nelucidating gene set individually, inter gene sets association is rarely taken\ninto consideration. Deep learning, an emerging machine learning technique in\ncomputational biology, can be used to generate an unbiased combination of gene\nset, and to determine the biological relevance and analysis consistency of\nthese combining gene sets by leveraging large genomic data sets. In this study,\nwe proposed a gene superset autoencoder (GSAE), a multi-layer autoencoder model\nwith the incorporation of a priori defined gene sets that retain the crucial\nbiological features in the latent layer. We introduced the concept of the gene\nsuperset, an unbiased combination of gene sets with weights trained by the\nautoencoder, where each node in the latent layer is a superset. Trained with\ngenomic data from TCGA and evaluated with their accompanying clinical\nparameters, we showed gene supersets' ability of discriminating tumor subtypes\nand their prognostic capability. We further demonstrated the biological\nrelevance of the top component gene sets in the significant supersets. Using\nautoencoder model and gene superset at its latent layer, we demonstrated that\ngene supersets retain sufficient biological information with respect to tumor\nsubtypes and clinical prognostic significance. Superset also provides high\nreproducibility on survival analysis and accurate prediction for cancer\nsubtypes.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 02:37:54 GMT"}, {"version": "v2", "created": "Fri, 28 Dec 2018 20:53:26 GMT"}], "update_date": "2019-01-01", "authors_parsed": [["Chen", "Hung-I Harry", ""], ["Chiu", "Yu-Chiao", ""], ["Zhang", "Tinghe", ""], ["Zhang", "Songyao", ""], ["Huang", "Yufei", ""], ["Chen", "Yidong", ""]]}, {"id": "1805.07883", "submitter": "Yining Wang", "authors": "Simon S. Du, Yining Wang, Xiyu Zhai, Sivaraman Balakrishnan, Ruslan\n  Salakhutdinov, Aarti Singh", "title": "How Many Samples are Needed to Estimate a Convolutional or Recurrent\n  Neural Network?", "comments": "Revised version, with new results on recurrent neural networks.\n  Preliminary version in NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is widely believed that the practical success of Convolutional Neural\nNetworks (CNNs) and Recurrent Neural Networks (RNNs) owes to the fact that CNNs\nand RNNs use a more compact parametric representation than their\nFully-Connected Neural Network (FNN) counterparts, and consequently require\nfewer training examples to accurately estimate their parameters. We initiate\nthe study of rigorously characterizing the sample-complexity of estimating CNNs\nand RNNs. We show that the sample-complexity to learn CNNs and RNNs scales\nlinearly with their intrinsic dimension and this sample-complexity is much\nsmaller than for their FNN counterparts. For both CNNs and RNNs, we also\npresent lower bounds showing our sample complexities are tight up to\nlogarithmic factors. Our main technical tools for deriving these results are a\nlocalized empirical process analysis and a new technical lemma characterizing\nthe convolutional and recurrent structure. We believe that these tools may\ninspire further developments in understanding CNNs and RNNs.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 03:56:17 GMT"}, {"version": "v2", "created": "Wed, 28 Nov 2018 04:18:24 GMT"}, {"version": "v3", "created": "Sun, 30 Jun 2019 00:24:50 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Du", "Simon S.", ""], ["Wang", "Yining", ""], ["Zhai", "Xiyu", ""], ["Balakrishnan", "Sivaraman", ""], ["Salakhutdinov", "Ruslan", ""], ["Singh", "Aarti", ""]]}, {"id": "1805.07894", "submitter": "Yang Song", "authors": "Yang Song, Rui Shu, Nate Kushman, Stefano Ermon", "title": "Constructing Unrestricted Adversarial Examples with Generative Models", "comments": "Neural Information Processing Systems (NeurIPS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adversarial examples are typically constructed by perturbing an existing data\npoint within a small matrix norm, and current defense methods are focused on\nguarding against this type of attack. In this paper, we propose unrestricted\nadversarial examples, a new threat model where the attackers are not restricted\nto small norm-bounded perturbations. Different from perturbation-based attacks,\nwe propose to synthesize unrestricted adversarial examples entirely from\nscratch using conditional generative models. Specifically, we first train an\nAuxiliary Classifier Generative Adversarial Network (AC-GAN) to model the\nclass-conditional distribution over data samples. Then, conditioned on a\ndesired class, we search over the AC-GAN latent space to find images that are\nlikely under the generative model and are misclassified by a target classifier.\nWe demonstrate through human evaluation that unrestricted adversarial examples\ngenerated this way are legitimate and belong to the desired class. Our\nempirical results on the MNIST, SVHN, and CelebA datasets show that\nunrestricted adversarial examples can bypass strong adversarial training and\ncertified defense methods designed for traditional adversarial attacks.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 05:19:08 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 03:55:54 GMT"}, {"version": "v3", "created": "Thu, 20 Sep 2018 05:46:09 GMT"}, {"version": "v4", "created": "Sun, 2 Dec 2018 22:18:56 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Song", "Yang", ""], ["Shu", "Rui", ""], ["Kushman", "Nate", ""], ["Ermon", "Stefano", ""]]}, {"id": "1805.07897", "submitter": "Roope Tervo", "authors": "Roope Tervo, Joonas Karjalainen, Alexander Jung", "title": "Predicting Electricity Outages Caused by Convective Storms", "comments": "IEEE DSW 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of predicting power outages in an electrical power\ngrid due to hazards produced by convective storms. These storms produce extreme\nweather phenomena such as intense wind, tornadoes and lightning over a small\narea. In this paper, we discuss the application of state-of-the-art machine\nlearning techniques, such as random forest classifiers and deep neural\nnetworks, to predict the amount of damage caused by storms. We cast this\napplication as a classification problem where the goal is to classify storm\ncells into a finite number of classes, each corresponding to a certain amount\nof expected damage. The classification method use as input features estimates\nfor storm cell location and movement which has to be extracted from the raw\ndata.\n  A main challenge of this application is that the training data is heavily\nimbalanced as the occurrence of extreme weather events is rare. In order to\naddress this issue, we applied SMOTE technique.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 05:28:22 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Tervo", "Roope", ""], ["Karjalainen", "Joonas", ""], ["Jung", "Alexander", ""]]}, {"id": "1805.07907", "submitter": "Joy Bose", "authors": "Kushal Singla, Joy Bose", "title": "IoT2Vec: Identification of Similar IoT Devices via Activity Footprints", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.NE cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a smart home or smart office environment with a number of IoT\ndevices connected and passing data between one another. The footprints of the\ndata transferred can provide valuable information about the devices, which can\nbe used to (a) identify the IoT devices and (b) in case of failure, to identify\nthe correct replacements for these devices. In this paper, we generate the\nembeddings for IoT devices in a smart home using Word2Vec, and explore the\npossibility of having a similar concept for IoT devices, aka IoT2Vec. These\nembeddings can be used in a number of ways, such as to find similar devices in\nan IoT device store, or as a signature of each type of IoT device. We show\nresults of a feasibility study on the CASAS dataset of IoT device activity\nlogs, using our method to identify the patterns in embeddings of various types\nof IoT devices in a household.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 06:31:52 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Singla", "Kushal", ""], ["Bose", "Joy", ""]]}, {"id": "1805.07932", "submitter": "Jin-Hwa Kim", "authors": "Jin-Hwa Kim, Jaehyun Jun, Byoung-Tak Zhang", "title": "Bilinear Attention Networks", "comments": "Accepted by NIPS 2018; Figure 1 was updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention networks in multimodal learning provide an efficient way to utilize\ngiven visual information selectively. However, the computational cost to learn\nattention distributions for every pair of multimodal input channels is\nprohibitively expensive. To solve this problem, co-attention builds two\nseparate attention distributions for each modality neglecting the interaction\nbetween multimodal inputs. In this paper, we propose bilinear attention\nnetworks (BAN) that find bilinear attention distributions to utilize given\nvision-language information seamlessly. BAN considers bilinear interactions\namong two groups of input channels, while low-rank bilinear pooling extracts\nthe joint representations for each pair of channels. Furthermore, we propose a\nvariant of multimodal residual networks to exploit eight-attention maps of the\nBAN efficiently. We quantitatively and qualitatively evaluate our model on\nvisual question answering (VQA 2.0) and Flickr30k Entities datasets, showing\nthat BAN significantly outperforms previous methods and achieves new\nstate-of-the-arts on both datasets.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 07:58:31 GMT"}, {"version": "v2", "created": "Fri, 19 Oct 2018 11:29:49 GMT"}], "update_date": "2018-10-22", "authors_parsed": [["Kim", "Jin-Hwa", ""], ["Jun", "Jaehyun", ""], ["Zhang", "Byoung-Tak", ""]]}, {"id": "1805.07935", "submitter": "Yuan Cheng Ph.D", "authors": "Yuan Cheng, Guangya Li, Hai-Bao Chen, Sheldon X.-D. Tan and Hao Yu", "title": "DEEPEYE: A Compact and Accurate Video Comprehension at Terminal Devices\n  Compressed with Quantization and Tensorization", "comments": "10 pages, 9 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As it requires a huge number of parameters when exposed to high dimensional\ninputs in video detection and classification, there is a grand challenge to\ndevelop a compact yet accurate video comprehension at terminal devices. Current\nworks focus on optimizations of video detection and classification in a\nseparated fashion. In this paper, we introduce a video comprehension (object\ndetection and action recognition) system for terminal devices, namely DEEPEYE.\nBased on You Only Look Once (YOLO), we have developed an 8-bit quantization\nmethod when training YOLO; and also developed a tensorized-compression method\nof Recurrent Neural Network (RNN) composed of features extracted from YOLO. The\ndeveloped quantization and tensorization can significantly compress the\noriginal network model yet with maintained accuracy. Using the challenging\nvideo datasets: MOMENTS and UCF11 as benchmarks, the results show that the\nproposed DEEPEYE achieves 3.994x model compression rate with only 0.47% mAP\ndecreased; and 15,047x parameter reduction and 2.87x speed-up with 16.58%\naccuracy improvement.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 08:08:07 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 16:17:33 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Cheng", "Yuan", ""], ["Li", "Guangya", ""], ["Chen", "Hai-Bao", ""], ["Tan", "Sheldon X. -D.", ""], ["Yu", "Hao", ""]]}, {"id": "1805.07941", "submitter": "Sean O. Settle", "authors": "Sean O. Settle, Manasa Bollavaram, Paolo D'Alberto, Elliott Delaye,\n  Oscar Fernandez, Nicholas Fraser, Aaron Ng, Ashish Sirasao, Michael Wu", "title": "Quantizing Convolutional Neural Networks for Low-Power High-Throughput\n  Inference Engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning as a means to inferencing has proliferated thanks to its\nversatility and ability to approach or exceed human-level accuracy. These\ncomputational models have seemingly insatiable appetites for computational\nresources not only while training, but also when deployed at scales ranging\nfrom data centers all the way down to embedded devices. As such, increasing\nconsideration is being made to maximize the computational efficiency given\nlimited hardware and energy resources and, as a result, inferencing with\nreduced precision has emerged as a viable alternative to the IEEE 754 Standard\nfor Floating-Point Arithmetic. We propose a quantization scheme that allows\ninferencing to be carried out using arithmetic that is fundamentally more\nefficient when compared to even half-precision floating-point. Our quantization\nprocedure is significant in that we determine our quantization scheme\nparameters by calibrating against its reference floating-point model using a\nsingle inference batch rather than (re)training and achieve end-to-end post\nquantization accuracies comparable to the reference model.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 08:31:46 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Settle", "Sean O.", ""], ["Bollavaram", "Manasa", ""], ["D'Alberto", "Paolo", ""], ["Delaye", "Elliott", ""], ["Fernandez", "Oscar", ""], ["Fraser", "Nicholas", ""], ["Ng", "Aaron", ""], ["Sirasao", "Ashish", ""], ["Wu", "Michael", ""]]}, {"id": "1805.07956", "submitter": "Jonathan Efroni", "authors": "Yonathan Efroni, Gal Dalal, Bruno Scherrer, Shie Mannor", "title": "Multiple-Step Greedy Policies in Online and Approximate Reinforcement\n  Learning", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple-step lookahead policies have demonstrated high empirical competence\nin Reinforcement Learning, via the use of Monte Carlo Tree Search or Model\nPredictive Control. In a recent work \\cite{efroni2018beyond}, multiple-step\ngreedy policies and their use in vanilla Policy Iteration algorithms were\nproposed and analyzed. In this work, we study multiple-step greedy algorithms\nin more practical setups. We begin by highlighting a counter-intuitive\ndifficulty, arising with soft-policy updates: even in the absence of\napproximations, and contrary to the 1-step-greedy case, monotonic policy\nimprovement is not guaranteed unless the update stepsize is sufficiently large.\nTaking particular care about this difficulty, we formulate and analyze online\nand approximate algorithms that use such a multi-step greedy operator.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 09:17:09 GMT"}, {"version": "v2", "created": "Thu, 20 Sep 2018 12:39:27 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Efroni", "Yonathan", ""], ["Dalal", "Gal", ""], ["Scherrer", "Bruno", ""], ["Mannor", "Shie", ""]]}, {"id": "1805.07966", "submitter": "Sopan Khosla", "authors": "Sopan Khosla, Niyati Chhaya, Kushal Chawla", "title": "Aff2Vec: Affect--Enriched Distributional Word Representations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Human communication includes information, opinions, and reactions. Reactions\nare often captured by the affective-messages in written as well as verbal\ncommunications. While there has been work in affect modeling and to some extent\naffective content generation, the area of affective word distributions in not\nwell studied. Synsets and lexica capture semantic relationships across words.\nThese models however lack in encoding affective or emotional word\ninterpretations. Our proposed model, Aff2Vec provides a method for enriched\nword embeddings that are representative of affective interpretations of words.\nAff2Vec outperforms the state--of--the--art in intrinsic word-similarity tasks.\nFurther, the use of Aff2Vec representations outperforms baseline embeddings in\ndownstream natural language understanding tasks including sentiment analysis,\npersonality detection, and frustration prediction.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 10:10:16 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Khosla", "Sopan", ""], ["Chhaya", "Niyati", ""], ["Chawla", "Kushal", ""]]}, {"id": "1805.08079", "submitter": "Menachem Adelman", "authors": "Menachem Adelman, Kfir Y. Levy, Ido Hakimi, Mark Silberstein", "title": "Faster Neural Network Training with Approximate Tensor Operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel technique for faster DNN training which systematically\napplies sample-based approximation to the constituent tensor operations, i.e.,\nmatrix multiplications and convolutions. We introduce new sampling techniques,\nstudy their theoretical properties, and prove that they provide the same\nconvergence guarantees when applied to SGD DNN training. We apply approximate\ntensor operations to single and multi-node training of MLP and CNN networks on\nMNIST, CIFAR-10 and ImageNet datasets. We demonstrate up to 66% reduction in\nthe amount of computations and communication, and up to 1.37x faster training\ntime while maintaining negligible or no impact on the final test accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 14:14:14 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 14:37:43 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Adelman", "Menachem", ""], ["Levy", "Kfir Y.", ""], ["Hakimi", "Ido", ""], ["Silberstein", "Mark", ""]]}, {"id": "1805.08180", "submitter": "Andrew Levy", "authors": "Andrew Levy, Robert Platt, Kate Saenko", "title": "Hierarchical Reinforcement Learning with Hindsight", "comments": "Duplicate. See arXiv:1712.00948 \"Learning Multi-Level Hierarchies\n  with Hindsight\" for latest version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement Learning (RL) algorithms can suffer from poor sample efficiency\nwhen rewards are delayed and sparse. We introduce a solution that enables\nagents to learn temporally extended actions at multiple levels of abstraction\nin a sample efficient and automated fashion. Our approach combines universal\nvalue functions and hindsight learning, allowing agents to learn policies\nbelonging to different time scales in parallel. We show that our method\nsignificantly accelerates learning in a variety of discrete and continuous\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:02:53 GMT"}, {"version": "v2", "created": "Fri, 8 Mar 2019 17:52:47 GMT"}], "update_date": "2019-03-11", "authors_parsed": [["Levy", "Andrew", ""], ["Platt", "Robert", ""], ["Saenko", "Kate", ""]]}, {"id": "1805.08191", "submitter": "Zhe Gan", "authors": "Qiuyuan Huang, Zhe Gan, Asli Celikyilmaz, Dapeng Wu, Jianfeng Wang,\n  Xiaodong He", "title": "Hierarchically Structured Reinforcement Learning for Topically Coherent\n  Visual Story Generation", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a hierarchically structured reinforcement learning approach to\naddress the challenges of planning for generating coherent multi-sentence\nstories for the visual storytelling task. Within our framework, the task of\ngenerating a story given a sequence of images is divided across a two-level\nhierarchical decoder. The high-level decoder constructs a plan by generating a\nsemantic concept (i.e., topic) for each image in sequence. The low-level\ndecoder generates a sentence for each image using a semantic compositional\nnetwork, which effectively grounds the sentence generation conditioned on the\ntopic. The two decoders are jointly trained end-to-end using reinforcement\nlearning. We evaluate our model on the visual storytelling (VIST) dataset.\nEmpirical results from both automatic and human evaluations demonstrate that\nthe proposed hierarchically structured reinforced training achieves\nsignificantly better performance compared to a strong flat deep reinforcement\nlearning baseline.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:23:31 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 20:11:56 GMT"}, {"version": "v3", "created": "Fri, 18 Jan 2019 07:58:43 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Huang", "Qiuyuan", ""], ["Gan", "Zhe", ""], ["Celikyilmaz", "Asli", ""], ["Wu", "Dapeng", ""], ["Wang", "Jianfeng", ""], ["He", "Xiaodong", ""]]}, {"id": "1805.08195", "submitter": "Noam Brown", "authors": "Noam Brown, Tuomas Sandholm, Brandon Amos", "title": "Depth-Limited Solving for Imperfect-Information Games", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental challenge in imperfect-information games is that states do not\nhave well-defined values. As a result, depth-limited search algorithms used in\nsingle-agent settings and perfect-information games do not apply. This paper\nintroduces a principled way to conduct depth-limited solving in\nimperfect-information games by allowing the opponent to choose among a number\nof strategies for the remainder of the game at the depth limit. Each one of\nthese strategies results in a different set of values for leaf nodes. This\nforces an agent to be robust to the different strategies an opponent may\nemploy. We demonstrate the effectiveness of this approach by building a\nmaster-level heads-up no-limit Texas hold'em poker AI that defeats two prior\ntop agents using only a 4-core CPU and 16 GB of memory. Developing such a\npowerful agent would have previously required a supercomputer.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 17:41:32 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Brown", "Noam", ""], ["Sandholm", "Tuomas", ""], ["Amos", "Brandon", ""]]}, {"id": "1805.08249", "submitter": "Konrad Zolna", "authors": "Konrad Zolna and Krzysztof J. Geras and Kyunghyun Cho", "title": "Classifier-agnostic saliency map extraction", "comments": null, "journal-ref": "Computer Vision and Image Understanding, Volume 196, 2020, 102969,\n  ISSN 1077-3142", "doi": "10.1016/j.cviu.2020.102969", "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently available methods for extracting saliency maps identify parts of\nthe input which are the most important to a specific fixed classifier. We show\nthat this strong dependence on a given classifier hinders their performance. To\naddress this problem, we propose classifier-agnostic saliency map extraction,\nwhich finds all parts of the image that any classifier could use, not just one\ngiven in advance. We observe that the proposed approach extracts higher quality\nsaliency maps than prior work while being conceptually simple and easy to\nimplement. The method sets the new state of the art result for localization\ntask on the ImageNet data, outperforming all existing weakly-supervised\nlocalization techniques, despite not using the ground truth labels at the\ninference time. The code reproducing the results is available at\nhttps://github.com/kondiz/casme .\n  The final version of this manuscript is published in Computer Vision and\nImage Understanding and is available online at\nhttps://doi.org/10.1016/j.cviu.2020.102969 .\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 18:36:52 GMT"}, {"version": "v2", "created": "Tue, 2 Oct 2018 19:14:19 GMT"}, {"version": "v3", "created": "Sun, 19 Jul 2020 16:56:49 GMT"}], "update_date": "2020-07-21", "authors_parsed": [["Zolna", "Konrad", ""], ["Geras", "Krzysztof J.", ""], ["Cho", "Kyunghyun", ""]]}, {"id": "1805.08256", "submitter": "Solimul Chowdhury", "authors": "Md Solimul Chowdhury and Victor Silva", "title": "Evolving Real-Time Heuristics Search Algorithms with Building Blocks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The research area of real-time heuristics search has produced quite many\nalgorithms. In the landscape of real-time heuristics search research, it is not\nrare to find that an algorithm X that appears to perform better than algorithm\nY on a group of problems, performed worse than Y for another group of problems.\nIf these published algorithms are combined to generate a more powerful space of\nalgorithms, then that novel space of algorithms may solve a distribution of\nproblems more efficiently. Based on this intuition, a recent work Bulitko 2016\nhas defined the task of finding a combination of heuristics search algorithms\nas a survival task. In this evolutionary approach, a space of algorithms is\ndefined over a set of building blocks published algorithms and a simulated\nevolution is used to recombine these building blocks to find out the best\nalgorithm from that space of algorithms.\n  In this paper, we extend the set of building blocks by adding one published\nalgorithm, namely lookahead based A-star shaped local search space generation\nmethod from LSSLRTA-star, plus an unpublished novel strategy to generate local\nsearch space with Greedy Best First Search. Then we perform experiments in the\nnew space of algorithms, which show that the best algorithms selected by the\nevolutionary process have the following property: the deeper is the lookahead\ndepth of an algorithm, the lower is its suboptimality and scrubbing complexity.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 18:52:00 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Chowdhury", "Md Solimul", ""], ["Silva", "Victor", ""]]}, {"id": "1805.08263", "submitter": "Rohan Chitnis", "authors": "Rohan Chitnis, Leslie Pack Kaelbling, Tom\\'as Lozano-P\\'erez", "title": "Learning What Information to Give in Partially Observed Domains", "comments": "CoRL 2018 final version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many robotic applications, an autonomous agent must act within and explore\na partially observed environment that is unobserved by its human teammate. We\nconsider such a setting in which the agent can, while acting, transmit\ndeclarative information to the human that helps them understand aspects of this\nunseen environment. In this work, we address the algorithmic question of how\nthe agent should plan out what actions to take and what information to\ntransmit. Naturally, one would expect the human to have preferences, which we\nmodel information-theoretically by scoring transmitted information based on the\nchange it induces in weighted entropy of the human's belief state. We formulate\nthis setting as a belief MDP and give a tractable algorithm for solving it\napproximately. Then, we give an algorithm that allows the agent to learn the\nhuman's preferences online, through exploration. We validate our approach\nexperimentally in simulated discrete and continuous partially observed\nsearch-and-recover domains. Visit http://tinyurl.com/chitnis-corl-18 for a\nsupplementary video.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 19:16:02 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 22:30:30 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 23:24:52 GMT"}, {"version": "v4", "created": "Thu, 27 Sep 2018 18:39:19 GMT"}], "update_date": "2018-10-01", "authors_parsed": [["Chitnis", "Rohan", ""], ["Kaelbling", "Leslie Pack", ""], ["Lozano-P\u00e9rez", "Tom\u00e1s", ""]]}, {"id": "1805.08296", "submitter": "Ofir Nachum", "authors": "Ofir Nachum, Shixiang Gu, Honglak Lee, Sergey Levine", "title": "Data-Efficient Hierarchical Reinforcement Learning", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical reinforcement learning (HRL) is a promising approach to extend\ntraditional reinforcement learning (RL) methods to solve more complex tasks.\nYet, the majority of current HRL methods require careful task-specific design\nand on-policy training, making them difficult to apply in real-world scenarios.\nIn this paper, we study how we can develop HRL algorithms that are general, in\nthat they do not make onerous additional assumptions beyond standard RL\nalgorithms, and efficient, in the sense that they can be used with modest\nnumbers of interaction samples, making them suitable for real-world problems\nsuch as robotic control. For generality, we develop a scheme where lower-level\ncontrollers are supervised with goals that are learned and proposed\nautomatically by the higher-level controllers. To address efficiency, we\npropose to use off-policy experience for both higher and lower-level training.\nThis poses a considerable challenge, since changes to the lower-level behaviors\nchange the action space for the higher-level policy, and we introduce an\noff-policy correction to remedy this challenge. This allows us to take\nadvantage of recent advances in off-policy model-free RL to learn both higher-\nand lower-level policies using substantially fewer environment interactions\nthan on-policy algorithms. We term the resulting HRL agent HIRO and find that\nit is generally applicable and highly sample-efficient. Our experiments show\nthat HIRO can be used to learn highly complex behaviors for simulated robots,\nsuch as pushing objects and utilizing them to reach target locations, learning\nfrom only a few million samples, equivalent to a few days of real-time\ninteraction. In comparisons with a number of prior HRL methods, we find that\nour approach substantially outperforms previous state-of-the-art techniques.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 21:33:44 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 07:53:39 GMT"}, {"version": "v3", "created": "Sat, 29 Sep 2018 02:36:13 GMT"}, {"version": "v4", "created": "Fri, 5 Oct 2018 12:39:37 GMT"}], "update_date": "2018-10-08", "authors_parsed": [["Nachum", "Ofir", ""], ["Gu", "Shixiang", ""], ["Lee", "Honglak", ""], ["Levine", "Sergey", ""]]}, {"id": "1805.08311", "submitter": "Mohammad Ghasemzadeh", "authors": "Mohammad Ghasemzadeh, Fang Lin, Bita Darvish Rouhani, Farinaz\n  Koushanfar, Ke Huang", "title": "AgileNet: Lightweight Dictionary-based Few-shot Learning", "comments": "10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The success of deep learning models is heavily tied to the use of massive\namount of labeled data and excessively long training time. With the emergence\nof intelligent edge applications that use these models, the critical challenge\nis to obtain the same inference capability on a resource-constrained device\nwhile providing adaptability to cope with the dynamic changes in the data. We\npropose AgileNet, a novel lightweight dictionary-based few-shot learning\nmethodology which provides reduced complexity deep neural network for efficient\nexecution at the edge while enabling low-cost updates to capture the dynamics\nof the new data. Evaluations of state-of-the-art few-shot learning benchmarks\ndemonstrate the superior accuracy of AgileNet compared to prior arts.\nAdditionally, AgileNet is the first few-shot learning approach that prevents\nmodel updates by eliminating the knowledge obtained from the primary training.\nThis property is ensured through the dictionaries learned by our novel\nend-to-end structured decomposition, which also reduces the memory footprint\nand computation complexity to match the edge device constraints.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 22:36:11 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Ghasemzadeh", "Mohammad", ""], ["Lin", "Fang", ""], ["Rouhani", "Bita Darvish", ""], ["Koushanfar", "Farinaz", ""], ["Huang", "Ke", ""]]}, {"id": "1805.08313", "submitter": "Jessie Huang", "authors": "Jessie Huang, Fa Wu, Doina Precup, Yang Cai", "title": "Learning Safe Policies with Expert Guidance", "comments": "Appears in NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a framework for ensuring safe behavior of a reinforcement learning\nagent when the reward function may be difficult to specify. In order to do\nthis, we rely on the existence of demonstrations from expert policies, and we\nprovide a theoretical framework for the agent to optimize in the space of\nrewards consistent with its existing knowledge. We propose two methods to solve\nthe resulting optimization: an exact ellipsoid-based method and a method in the\nspirit of the \"follow-the-perturbed-leader\" algorithm. Our experiments\ndemonstrate the behavior of our algorithm in both discrete and continuous\nproblems. The trained agent safely avoids states with potential negative\neffects while imitating the behavior of the expert in the other states.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 22:40:07 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 17:17:23 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Huang", "Jessie", ""], ["Wu", "Fa", ""], ["Precup", "Doina", ""], ["Cai", "Yang", ""]]}, {"id": "1805.08322", "submitter": "Yuxin Chen", "authors": "Anette Hunziker, Yuxin Chen, Oisin Mac Aodha, Manuel Gomez Rodriguez,\n  Andreas Krause, Pietro Perona, Yisong Yue, Adish Singla", "title": "Teaching Multiple Concepts to a Forgetful Learner", "comments": "NeurIPS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we help a forgetful learner learn multiple concepts within a limited\ntime frame? While there have been extensive studies in designing optimal\nschedules for teaching a single concept given a learner's memory model,\nexisting approaches for teaching multiple concepts are typically based on\nheuristic scheduling techniques without theoretical guarantees. In this paper,\nwe look at the problem from the perspective of discrete optimization and\nintroduce a novel algorithmic framework for teaching multiple concepts with\nstrong performance guarantees. Our framework is both generic, allowing the\ndesign of teaching schedules for different memory models, and also interactive,\nallowing the teacher to adapt the schedule to the underlying forgetting\nmechanisms of the learner. Furthermore, for a well-known memory model, we are\nable to identify a regime of model parameters where our framework is guaranteed\nto achieve high performance. We perform extensive evaluations using simulations\nalong with real user studies in two concrete applications: (i) an educational\napp for online vocabulary teaching; and (ii) an app for teaching novices how to\nrecognize animal species from images. Our results demonstrate the effectiveness\nof our algorithm compared to popular heuristic approaches.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 23:34:11 GMT"}, {"version": "v2", "created": "Thu, 14 Jun 2018 16:20:41 GMT"}, {"version": "v3", "created": "Tue, 9 Oct 2018 16:25:03 GMT"}, {"version": "v4", "created": "Fri, 25 Oct 2019 17:07:54 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Hunziker", "Anette", ""], ["Chen", "Yuxin", ""], ["Mac Aodha", "Oisin", ""], ["Rodriguez", "Manuel Gomez", ""], ["Krause", "Andreas", ""], ["Perona", "Pietro", ""], ["Yue", "Yisong", ""], ["Singla", "Adish", ""]]}, {"id": "1805.08329", "submitter": "Haonan Yu", "authors": "Haonan Yu, Xiaochen Lian, Haichao Zhang, Wei Xu", "title": "Guided Feature Transformation (GFT): A Neural Language Grounding Module\n  for Embodied Agents", "comments": "CoRL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.LG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently there has been a rising interest in training agents, embodied in\nvirtual environments, to perform language-directed tasks by deep reinforcement\nlearning. In this paper, we propose a simple but effective neural language\ngrounding module for embodied agents that can be trained end to end from\nscratch taking raw pixels, unstructured linguistic commands, and sparse rewards\nas the inputs. We model the language grounding process as a language-guided\ntransformation of visual features, where latent sentence embeddings are used as\nthe transformation matrices. In several language-directed navigation tasks that\nfeature challenging partial observability and require simple reasoning, our\nmodule significantly outperforms the state of the art. We also release\nXWorld3D, an easy-to-customize 3D environment that can potentially be modified\nto evaluate a variety of embodied agents.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 00:16:39 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 18:16:40 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Yu", "Haonan", ""], ["Lian", "Xiaochen", ""], ["Zhang", "Haichao", ""], ["Xu", "Wei", ""]]}, {"id": "1805.08347", "submitter": "Jongmin Jerome Baek", "authors": "Min Baek", "title": "How To Solve Moral Conundrums with Computability Theory", "comments": "Conclusion is incorrect", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Various moral conundrums plague population ethics: the Non-Identity Problem,\nthe Procreation Asymmetry, the Repugnant Conclusion, and more. I argue that the\naforementioned moral conundrums have a structure neatly accounted for, and\nsolved by, some ideas in computability theory. I introduce a mathematical model\nbased on computability theory and show how previous arguments pertaining to\nthese conundrums fit into the model. This paper proceeds as follows. First, I\ndo a very brief survey of the history of computability theory in moral\nphilosophy. Second, I follow various papers, and show how their arguments fit\ninto, or don't fit into, our model. Third, I discuss the implications of our\nmodel to the question why the human race should or should not continue to\nexist. Finally, I show that our model may be interpreted according to a\nConfucian-Taoist moral principle.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 01:47:16 GMT"}, {"version": "v2", "created": "Mon, 7 Dec 2020 22:46:39 GMT"}, {"version": "v3", "created": "Sun, 25 Apr 2021 23:48:42 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Baek", "Min", ""]]}, {"id": "1805.08427", "submitter": "Long Ouyang", "authors": "Long Ouyang", "title": "Bayesian Inference of Regular Expressions from Human-Generated Example\n  Strings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In programming by example, users \"write\" programs by generating a small\nnumber of input-output examples and asking the computer to synthesize\nconsistent programs. We consider a challenging problem in this domain: learning\nregular expressions (regexes) from positive and negative example strings. This\nproblem is challenging, as (1) user-generated examples may not be informative\nenough to sufficiently constrain the hypothesis space, and (2) even if\nuser-generated examples are in principle informative, there is still a massive\nsearch space to examine. We frame regex induction as the problem of inferring a\nprobabilistic regular grammar and propose an efficient inference approach that\nuses a novel stochastic process recognition model. This model incrementally\n\"grows\" a grammar using positive examples as a scaffold. We show that this\napproach is competitive with human ability to learn regexes from examples.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 07:28:21 GMT"}, {"version": "v2", "created": "Wed, 26 Sep 2018 21:45:53 GMT"}], "update_date": "2018-09-28", "authors_parsed": [["Ouyang", "Long", ""]]}, {"id": "1805.08440", "submitter": "Philipp Oberdiek", "authors": "Philipp Oberdiek, Matthias Rottmann, Hanno Gottschalk", "title": "Classification Uncertainty of Deep Neural Networks Based on Gradient\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the quantification of uncertainty of Convolutional Neural Networks\n(CNNs) based on gradient metrics. Unlike the classical softmax entropy, such\nmetrics gather information from all layers of the CNN. We show for the EMNIST\ndigits data set that for several such metrics we achieve the same meta\nclassification accuracy -- i.e. the task of classifying predictions as correct\nor incorrect without knowing the actual label -- as for entropy thresholding.\nWe apply meta classification to unknown concepts (out-of-distribution samples)\n-- EMNIST/Omniglot letters, CIFAR10 and noise -- and demonstrate that meta\nclassification rates for unknown concepts can be increased when using entropy\ntogether with several gradient based metrics as input quantities for a meta\nclassifier. Meta classifiers only trained on the uncertainty metrics of known\nconcepts, i.e. EMNIST digits, usually do not perform equally well for all\nunknown concepts. If we however allow the meta classifier to be trained on\nuncertainty metrics for some out-of-distribution samples, meta classification\nfor concepts remote from EMNIST digits (then termed known unknowns) can be\nimproved considerably.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 08:07:14 GMT"}, {"version": "v2", "created": "Thu, 26 Jul 2018 10:37:11 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Oberdiek", "Philipp", ""], ["Rottmann", "Matthias", ""], ["Gottschalk", "Hanno", ""]]}, {"id": "1805.08455", "submitter": "Massimiliano Ruocco", "authors": "Silje Christensen, Simen Johnsrud, Massimiliano Ruocco, Heri\n  Ramampiaro", "title": "Context-Aware Sequence-to-Sequence Models for Conversational Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work proposes a novel approach based on sequence-to-sequence (seq2seq)\nmodels for context-aware conversational systems. Exist- ing seq2seq models have\nbeen shown to be good for generating natural responses in a data-driven\nconversational system. However, they still lack mechanisms to incorporate\nprevious conversation turns. We investigate RNN-based methods that efficiently\nintegrate previous turns as a context for generating responses. Overall, our\nexperimental results based on human judgment demonstrate the feasibility and\neffectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 08:34:10 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Christensen", "Silje", ""], ["Johnsrud", "Simen", ""], ["Ruocco", "Massimiliano", ""], ["Ramampiaro", "Heri", ""]]}, {"id": "1805.08456", "submitter": "Stefan Mengel", "authors": "Michael Lampis and Stefan Mengel and Valia Mitsou", "title": "QBF as an Alternative to Courcelle's Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose reductions to quantified Boolean formulas (QBF) as a new approach\nto showing fixed-parameter linear algorithms for problems parameterized by\ntreewidth. We demonstrate the feasibility of this approach by giving new\nalgorithms for several well-known problems from artificial intelligence that\nare in general complete for the second level of the polynomial hierarchy. By\nreduction from QBF we show that all resulting algorithms are essentially\noptimal in their dependence on the treewidth. Most of the problems that we\nconsider were already known to be fixed-parameter linear by using Courcelle's\nTheorem or dynamic programming, but we argue that our approach has clear\nadvantages over these techniques: on the one hand, in contrast to Courcelle's\nTheorem, we get concrete and tight guarantees for the runtime dependence on the\ntreewidth. On the other hand, we avoid tedious dynamic programming and, after\nshowing some normalization results for CNF-formulas, our upper bounds often\nboil down to a few lines.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 08:35:41 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Lampis", "Michael", ""], ["Mengel", "Stefan", ""], ["Mitsou", "Valia", ""]]}, {"id": "1805.08522", "submitter": "Guillermo Valle-P\\'erez", "authors": "Guillermo Valle-P\\'erez, Chico Q. Camargo, Ard A. Louis", "title": "Deep learning generalizes because the parameter-function map is biased\n  towards simple functions", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep neural networks (DNNs) generalize remarkably well without explicit\nregularization even in the strongly over-parametrized regime where classical\nlearning theory would instead predict that they would severely overfit. While\nmany proposals for some kind of implicit regularization have been made to\nrationalise this success, there is no consensus for the fundamental reason why\nDNNs do not strongly overfit. In this paper, we provide a new explanation. By\napplying a very general probability-complexity bound recently derived from\nalgorithmic information theory (AIT), we argue that the parameter-function map\nof many DNNs should be exponentially biased towards simple functions. We then\nprovide clear evidence for this strong simplicity bias in a model DNN for\nBoolean functions, as well as in much larger fully connected and convolutional\nnetworks applied to CIFAR10 and MNIST. As the target functions in many real\nproblems are expected to be highly structured, this intrinsic simplicity bias\nhelps explain why deep networks generalize well on real world problems. This\npicture also facilitates a novel PAC-Bayes approach where the prior is taken\nover the DNN input-output function space, rather than the more conventional\nprior over parameter space. If we assume that the training algorithm samples\nparameters close to uniformly within the zero-error region then the PAC-Bayes\ntheorem can be used to guarantee good expected generalization for target\nfunctions producing high-likelihood training sets. By exploiting recently\ndiscovered connections between DNNs and Gaussian processes to estimate the\nmarginal likelihood, we produce relatively tight generalization PAC-Bayes error\nbounds which correlate well with the true error on realistic datasets such as\nMNIST and CIFAR10 and for architectures including convolutional and fully\nconnected networks.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 11:51:36 GMT"}, {"version": "v2", "created": "Wed, 23 May 2018 10:55:36 GMT"}, {"version": "v3", "created": "Fri, 28 Sep 2018 18:22:18 GMT"}, {"version": "v4", "created": "Wed, 27 Feb 2019 23:40:35 GMT"}, {"version": "v5", "created": "Sun, 21 Apr 2019 10:16:54 GMT"}], "update_date": "2019-04-23", "authors_parsed": [["Valle-P\u00e9rez", "Guillermo", ""], ["Camargo", "Chico Q.", ""], ["Louis", "Ard A.", ""]]}, {"id": "1805.08588", "submitter": "Hongyao Tang", "authors": "Hongyao Tang, Li Wang, Zan Wang, Tim Baarslag, Jianye Hao", "title": "An Optimal Rewiring Strategy for Reinforcement Social Learning in\n  Cooperative Multiagent Systems", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiagent coordination in cooperative multiagent systems (MASs) has been\nwidely studied in both fixed-agent repeated interaction setting and the static\nsocial learning framework. However, two aspects of dynamics in real-world\nmultiagent scenarios are currently missing in existing works. First, the\nnetwork topologies can be dynamic where agents may change their connections\nthrough rewiring during the course of interactions. Second, the game matrix\nbetween each pair of agents may not be static and usually not known as a prior.\nBoth the network dynamic and game uncertainty increase the coordination\ndifficulty among agents. In this paper, we consider a multiagent dynamic social\nlearning environment in which each agent can choose to rewire potential\npartners and interact with randomly chosen neighbors in each round. We propose\nan optimal rewiring strategy for agents to select most beneficial peers to\ninteract with for the purpose of maximizing the accumulated payoff in repeated\ninteractions. We empirically demonstrate the effectiveness and robustness of\nour approach through comparing with benchmark strategies. The performance of\nthree representative learning strategies under our social learning framework\nwith our optimal rewiring is investigated as well.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 14:20:11 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Tang", "Hongyao", ""], ["Wang", "Li", ""], ["Wang", "Zan", ""], ["Baarslag", "Tim", ""], ["Hao", "Jianye", ""]]}, {"id": "1805.08592", "submitter": "Susumu Katayama", "authors": "Susumu Katayama", "title": "Computable Variants of AIXI which are More Powerful than AIXItl", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Unlimited Computable AI, or UCAI, that is a family of\ncomputable variants of AIXI. UCAI is more powerful than AIXItl, that is a\nconventional family of computable variants of AIXI, in the following ways: 1)\nUCAI supports models of terminating computation, including typed lambda\ncalculus, while AIXItl only supports Turing machine with timeout t, which can\nbe simulated by typed lambda calculus for any t; 2) unlike UCAI, AIXItl limits\nthe program length to l.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 14:09:49 GMT"}, {"version": "v2", "created": "Thu, 9 Aug 2018 18:11:01 GMT"}, {"version": "v3", "created": "Fri, 25 Jan 2019 10:43:23 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Katayama", "Susumu", ""]]}, {"id": "1805.08645", "submitter": "Deniz Ozsoyeller", "authors": "Deniz Ozsoyeller", "title": "Multi-robot Symmetric Rendezvous Search on the Line with an Unknown\n  Initial Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the symmetric rendezvous search problem on the line\nwith n > 2 robots that are unaware of their locations and the initial distances\nbetween them. In the symmetric version of this problem, the robots execute the\nsame strategy. The multi-robot symmetric rendezvous algorithm, MSR presented in\nthis paper is an extension our symmetric rendezvous algorithm, SR presented in\n[23]. We study both the synchronous and asynchronous cases of the problem. The\nasynchronous version of MSR algorithm is called MASR algorithm. We consider\nthat robots start executing MASR at different times. We perform the theoretical\nanalysis of MSR and MASR, and show that their competitive ratios are\n$O(n^{0.67})$ and $O(n^{1.5})$, respectively. Finally, we confirm our\ntheoretical results through simulations.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 08:05:24 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Ozsoyeller", "Deniz", ""]]}, {"id": "1805.08657", "submitter": "Grigorios Chrysos", "authors": "Grigorios G. Chrysos, Jean Kossaifi, Stefanos Zafeiriou", "title": "Robust Conditional Generative Adversarial Networks", "comments": "To appear in ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conditional generative adversarial networks (cGAN) have led to large\nimprovements in the task of conditional image generation, which lies at the\nheart of computer vision. The major focus so far has been on performance\nimprovement, while there has been little effort in making cGAN more robust to\nnoise. The regression (of the generator) might lead to arbitrarily large errors\nin the output, which makes cGAN unreliable for real-world applications. In this\nwork, we introduce a novel conditional GAN model, called RoCGAN, which\nleverages structure in the target space of the model to address the issue. Our\nmodel augments the generator with an unsupervised pathway, which promotes the\noutputs of the generator to span the target manifold even in the presence of\nintense noise. We prove that RoCGAN share similar theoretical properties as GAN\nand experimentally verify that our model outperforms existing state-of-the-art\ncGAN architectures by a large margin in a variety of domains including images\nfrom natural scenes and faces.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 15:14:11 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 07:59:35 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Chrysos", "Grigorios G.", ""], ["Kossaifi", "Jean", ""], ["Zafeiriou", "Stefanos", ""]]}, {"id": "1805.08698", "submitter": "Junwen Bai", "authors": "Junwen Bai, Zihang Lai, Runzhe Yang, Yexiang Xue, John Gregoire, Carla\n  Gomes", "title": "End-to-End Refinement Guided by Pre-trained Prototypical Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world tasks involve identifying patterns from data satisfying\nbackground or prior knowledge. In domains like materials discovery, due to the\nflaws and biases in raw experimental data, the identification of X-ray\ndiffraction patterns (XRD) often requires a huge amount of manual work in\nfinding refined phases that are similar to the ideal theoretical ones.\nAutomatically refining the raw XRDs utilizing the simulated theoretical data is\nthus desirable. We propose imitation refinement, a novel approach to refine\nimperfect input patterns, guided by a pre-trained classifier incorporating\nprior knowledge from simulated theoretical data, such that the refined patterns\nimitate the ideal data. The classifier is trained on the ideal simulated data\nto classify patterns and learns an embedding space where each class is\nrepresented by a prototype. The refiner learns to refine the imperfect patterns\nwith small modifications, such that their embeddings are closer to the\ncorresponding prototypes. We show that the refiner can be trained in both\nsupervised and unsupervised fashions. We further illustrate the effectiveness\nof the proposed approach both qualitatively and quantitatively in a digit\nrefinement task and an X-ray diffraction pattern refinement task in materials\ndiscovery.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 22:18:24 GMT"}, {"version": "v2", "created": "Tue, 11 Dec 2018 16:51:58 GMT"}], "update_date": "2018-12-12", "authors_parsed": [["Bai", "Junwen", ""], ["Lai", "Zihang", ""], ["Yang", "Runzhe", ""], ["Xue", "Yexiang", ""], ["Gregoire", "John", ""], ["Gomes", "Carla", ""]]}, {"id": "1805.08743", "submitter": "Alexandros Kouris", "authors": "Alexandros Kouris, Stylianos I. Venieris, Christos-Savvas Bouganis", "title": "CascadeCNN: Pushing the performance limits of quantisation", "comments": "Accepted at SysML Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents CascadeCNN, an automated toolflow that pushes the\nquantisation limits of any given CNN model, to perform high-throughput\ninference by exploiting the computation time-accuracy trade-off. Without the\nneed for retraining, a two-stage architecture tailored for any given FPGA\ndevice is generated, consisting of a low- and a high-precision unit. A\nconfidence evaluation unit is employed between them to identify misclassified\ncases at run time and forward them to the high-precision unit or terminate\ncomputation. Experiments demonstrate that CascadeCNN achieves a performance\nboost of up to 55% for VGG-16 and 48% for AlexNet over the baseline design for\nthe same resource budget and accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 17:06:02 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Kouris", "Alexandros", ""], ["Venieris", "Stylianos I.", ""], ["Bouganis", "Christos-Savvas", ""]]}, {"id": "1805.08747", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang, Limeng Cui, Fisher B. Gouza", "title": "EgoCoder: Intelligent Program Synthesis with Hierarchical Sequential\n  Neural Network Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming has been an important skill for researchers and practitioners in\ncomputer science and other related areas. To learn basic programing skills, a\nlong-time systematic training is usually required for beginners. According to a\nrecent market report, the computer software market is expected to continue\nexpanding at an accelerating speed, but the market supply of qualified software\ndevelopers can hardly meet such a huge demand. In recent years, the surge of\ntext generation research works provides the opportunities to address such a\ndilemma through automatic program synthesis. In this paper, we propose to make\nour try to solve the program synthesis problem from a data mining perspective.\nTo address the problem, a novel generative model, namely EgoCoder, will be\nintroduced in this paper. EgoCoder effectively parses program code into\nabstract syntax trees (ASTs), where the tree nodes will contain the program\ncode/comment content and the tree structure can capture the program logic\nflows. Based on a new unit model called Hsu, EgoCoder can effectively capture\nboth the hierarchical and sequential patterns in the program ASTs. Extensive\nexperiments will be done to compare EgoCoder with the state-of-the-art text\ngeneration methods, and the experimental results have demonstrated the\neffectiveness of EgoCoder in addressing the program synthesis problem.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 17:11:35 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Zhang", "Jiawei", ""], ["Cui", "Limeng", ""], ["Gouza", "Fisher B.", ""]]}, {"id": "1805.08751", "submitter": "Jiawei Zhang", "authors": "Jiawei Zhang, Bowen Dong, Philip S. Yu", "title": "FAKEDETECTOR: Effective Fake News Detection with Deep Diffusive Neural\n  Network", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, due to the booming development of online social networks,\nfake news for various commercial and political purposes has been appearing in\nlarge numbers and widespread in the online world. With deceptive words, online\nsocial network users can get infected by these online fake news easily, which\nhas brought about tremendous effects on the offline society already. An\nimportant goal in improving the trustworthiness of information in online social\nnetworks is to identify the fake news timely. This paper aims at investigating\nthe principles, methodologies and algorithms for detecting fake news articles,\ncreators and subjects from online social networks and evaluating the\ncorresponding performance. This paper addresses the challenges introduced by\nthe unknown characteristics of fake news and diverse connections among news\narticles, creators and subjects. This paper introduces a novel automatic fake\nnews credibility inference model, namely FAKEDETECTOR. Based on a set of\nexplicit and latent features extracted from the textual information,\nFAKEDETECTOR builds a deep diffusive network model to learn the representations\nof news articles, creators and subjects simultaneously. Extensive experiments\nhave been done on a real-world fake news dataset to compare FAKEDETECTOR with\nseveral state-of-the-art models, and the experimental results have demonstrated\nthe effectiveness of the proposed model.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 17:23:32 GMT"}, {"version": "v2", "created": "Sat, 10 Aug 2019 11:40:16 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Zhang", "Jiawei", ""], ["Dong", "Bowen", ""], ["Yu", "Philip S.", ""]]}, {"id": "1805.08768", "submitter": "Felix Sattler", "authors": "Felix Sattler, Simon Wiedemann, Klaus-Robert M\\\"uller, Wojciech Samek", "title": "Sparse Binary Compression: Towards Distributed Deep Learning with\n  minimal Communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, progressively larger deep neural networks are trained on ever\ngrowing data corpora. As this trend is only going to increase in the future,\ndistributed training schemes are becoming increasingly relevant. A major issue\nin distributed training is the limited communication bandwidth between\ncontributing nodes or prohibitive communication cost in general. These\nchallenges become even more pressing, as the number of computation nodes\nincreases. To counteract this development we propose sparse binary compression\n(SBC), a compression framework that allows for a drastic reduction of\ncommunication cost for distributed training. SBC combines existing techniques\nof communication delay and gradient sparsification with a novel binarization\nmethod and optimal weight update encoding to push compression gains to new\nlimits. By doing so, our method also allows us to smoothly trade-off gradient\nsparsity and temporal sparsity to adapt to the requirements of the learning\ntask. Our experiments show, that SBC can reduce the upstream communication on a\nvariety of convolutional and recurrent neural network architectures by more\nthan four orders of magnitude without significantly harming the convergence\nspeed in terms of forward-backward passes. For instance, we can train ResNet50\non ImageNet in the same number of iterations to the baseline accuracy, using\n$\\times 3531$ less bits or train it to a $1\\%$ lower accuracy using $\\times\n37208$ less bits. In the latter case, the total upstream communication required\nis cut from 125 terabytes to 3.35 gigabytes for every participating client.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 17:54:13 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Sattler", "Felix", ""], ["Wiedemann", "Simon", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1805.08776", "submitter": "Arbaaz Khan", "authors": "Arbaaz Khan, Clark Zhang, Daniel D. Lee, Vijay Kumar, Alejandro\n  Ribeiro", "title": "Scalable Centralized Deep Multi-Agent Reinforcement Learning via Policy\n  Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore using deep reinforcement learning for problems with\nmultiple agents. Most existing methods for deep multi-agent reinforcement\nlearning consider only a small number of agents. When the number of agents\nincreases, the dimensionality of the input and control spaces increase as well,\nand these methods do not scale well. To address this, we propose casting the\nmulti-agent reinforcement learning problem as a distributed optimization\nproblem. Our algorithm assumes that for multi-agent settings, policies of\nindividual agents in a given population live close to each other in parameter\nspace and can be approximated by a single policy. With this simple assumption,\nwe show our algorithm to be extremely effective for reinforcement learning in\nmulti-agent settings. We demonstrate its effectiveness against existing\ncomparable approaches on co-operative and competitive tasks.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 00:31:03 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Khan", "Arbaaz", ""], ["Zhang", "Clark", ""], ["Lee", "Daniel D.", ""], ["Kumar", "Vijay", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1805.08874", "submitter": "Debasmit Das", "authors": "Debasmit Das, C.S. George Lee", "title": "Unsupervised Domain Adaptation using Regularized Hyper-graph Matching", "comments": "Final version appeared in IEEE International Conference on Image\n  Processing 2018", "journal-ref": null, "doi": "10.1109/ICIP.2018.8451152", "report-no": null, "categories": "cs.CV cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain adaptation (DA) addresses the real-world image classification problem\nof discrepancy between training (source) and testing (target) data\ndistributions. We propose an unsupervised DA method that considers the presence\nof only unlabelled data in the target domain. Our approach centers on finding\nmatches between samples of the source and target domains. The matches are\nobtained by treating the source and target domains as hyper-graphs and carrying\nout a class-regularized hyper-graph matching using first-, second- and\nthird-order similarities between the graphs. We have also developed a\ncomputationally efficient algorithm by initially selecting a subset of the\nsamples to construct a graph and then developing a customized optimization\nroutine for graph-matching based on Conditional Gradient and Alternating\nDirection Multiplier Method. This allows the proposed method to be used widely.\nWe also performed a set of experiments on standard object recognition datasets\nto validate the effectiveness of our framework over state-of-the-art\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 21:38:38 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 17:18:53 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Das", "Debasmit", ""], ["Lee", "C. S. George", ""]]}, {"id": "1805.08877", "submitter": "Chidubem Arachie", "authors": "Chidubem Arachie and Bert Huang", "title": "Adversarial Label Learning", "comments": "Accepted at AAAI19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of training classifiers without labels. We propose a\nweakly supervised method---adversarial label learning---that trains classifiers\nto perform well against an adversary that chooses labels for training data. The\nweak supervision constrains what labels the adversary can choose. The method\ntherefore minimizes an upper bound of the classifier's error rate using\nprojected primal-dual subgradient descent. Minimizing this bound protects\nagainst bias and dependencies in the weak supervision. Experiments on three\nreal datasets show that our method can train without labels and outperforms\nother approaches for weakly supervised learning.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 21:41:20 GMT"}, {"version": "v2", "created": "Thu, 7 Jun 2018 22:15:08 GMT"}, {"version": "v3", "created": "Tue, 29 Jan 2019 20:47:00 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Arachie", "Chidubem", ""], ["Huang", "Bert", ""]]}, {"id": "1805.08882", "submitter": "Adam Gleave", "authors": "Adam Gleave and Oliver Habryka", "title": "Multi-task Maximum Entropy Inverse Reinforcement Learning", "comments": "Presented at 1st Workshop on Goal Specifications for Reinforcement\n  Learning (ICML/IJCAI/AAMAS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-task Inverse Reinforcement Learning (IRL) is the problem of inferring\nmultiple reward functions from expert demonstrations. Prior work, built on\nBayesian IRL, is unable to scale to complex environments due to computational\nconstraints. This paper contributes a formulation of multi-task IRL in the more\ncomputationally efficient Maximum Causal Entropy (MCE) IRL framework.\nExperiments show our approach can perform one-shot imitation learning in a\ngridworld environment that single-task IRL algorithms need hundreds of\ndemonstrations to solve. We outline preliminary work using meta-learning to\nextend our method to the function approximator setting of modern MCE IRL\nalgorithms. Evaluating on multi-task variants of common simulated robotics\nbenchmarks, we discover serious limitations of these IRL algorithms, and\nconclude with suggestions for further work.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 21:57:34 GMT"}, {"version": "v2", "created": "Sun, 15 Jul 2018 13:58:18 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Gleave", "Adam", ""], ["Habryka", "Oliver", ""]]}, {"id": "1805.08899", "submitter": "Bojian Zheng", "authors": "Bojian Zheng, Abhishek Tiwari, Nandita Vijaykumar, Gennady Pekhimenko", "title": "Echo: Compiler-based GPU Memory Footprint Reduction for LSTM RNN\n  Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Long-Short-Term-Memory Recurrent Neural Networks (LSTM RNNs) are a\npopular class of machine learning models for analyzing sequential data. Their\ntraining on modern GPUs, however, is limited by the GPU memory capacity. Our\nprofiling results of the LSTM RNN-based Neural Machine Translation (NMT) model\nreveal that feature maps of the attention and RNN layers form the memory\nbottleneck and runtime is unevenly distributed across different layers when\ntraining on GPUs. Based on these two observations, we propose to recompute the\nfeature maps rather than stashing them persistently in the GPU memory.\n  While the idea of feature map recomputation has been considered before,\nexisting solutions fail to deliver satisfactory footprint reduction, as they do\nnot address two key challenges. For each feature map recomputation to be\neffective and efficient, its effect on (1) the total memory footprint, and (2)\nthe total execution time has to be carefully estimated. To this end, we propose\n*Echo*, a new compiler-based optimization scheme that addresses the first\nchallenge with a practical mechanism that estimates the memory benefits of\nrecomputation over the entire computation graph, and the second challenge by\nnon-conservatively estimating the recomputation overhead leveraging layer\nspecifics. *Echo* reduces the GPU memory footprint automatically and\ntransparently without any changes required to the training source code, and is\neffective for models beyond LSTM RNNs.\n  We evaluate *Echo* on numerous state-of-the-art machine learning workloads on\nreal systems with modern GPUs and observe footprint reduction ratios of 1.89X\non average and 3.13X maximum. Such reduction can be converted into faster\ntraining with a larger batch size, savings in GPU energy consumption (e.g.,\ntraining with one GPU as fast as with four), and/or an increase in the maximum\nnumber of layers under the same GPU memory budget.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 23:01:25 GMT"}, {"version": "v2", "created": "Sun, 9 Dec 2018 06:11:50 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 00:34:17 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 03:26:15 GMT"}, {"version": "v5", "created": "Thu, 28 Nov 2019 22:34:49 GMT"}], "update_date": "2019-12-02", "authors_parsed": [["Zheng", "Bojian", ""], ["Tiwari", "Abhishek", ""], ["Vijaykumar", "Nandita", ""], ["Pekhimenko", "Gennady", ""]]}, {"id": "1805.08913", "submitter": "Rui Shu", "authors": "Rui Shu, Hung H. Bui, Shengjia Zhao, Mykel J. Kochenderfer, Stefano\n  Ermon", "title": "Amortized Inference Regularization", "comments": "NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The variational autoencoder (VAE) is a popular model for density estimation\nand representation learning. Canonically, the variational principle suggests to\nprefer an expressive inference model so that the variational approximation is\naccurate. However, it is often overlooked that an overly-expressive inference\nmodel can be detrimental to the test set performance of both the amortized\nposterior approximator and, more importantly, the generative density estimator.\nIn this paper, we leverage the fact that VAEs rely on amortized inference and\npropose techniques for amortized inference regularization (AIR) that control\nthe smoothness of the inference model. We demonstrate that, by applying AIR, it\nis possible to improve VAE generalization on both inference and generative\nperformance. Our paper challenges the belief that amortized inference is simply\na mechanism for approximating maximum likelihood training and illustrates that\nregularization of the amortization family provides a new direction for\nunderstanding and improving generalization in VAEs.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 00:14:56 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 18:56:45 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Shu", "Rui", ""], ["Bui", "Hung H.", ""], ["Zhao", "Shengjia", ""], ["Kochenderfer", "Mykel J.", ""], ["Ermon", "Stefano", ""]]}, {"id": "1805.08915", "submitter": "Vahid Behzadan", "authors": "Vahid Behzadan, Arslan Munir and Roman V. Yampolskiy", "title": "A Psychopathological Approach to Safety Engineering in AI and AGI", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity of dynamics in AI techniques is already approaching that of\ncomplex adaptive systems, thus curtailing the feasibility of formal\ncontrollability and reachability analysis in the context of AI safety. It\nfollows that the envisioned instances of Artificial General Intelligence (AGI)\nwill also suffer from challenges of complexity. To tackle such issues, we\npropose the modeling of deleterious behaviors in AI and AGI as psychological\ndisorders, thereby enabling the employment of psychopathological approaches to\nanalysis and control of misbehaviors. Accordingly, we present a discussion on\nthe feasibility of the psychopathological approaches to AI safety, and propose\ngeneral directions for research on modeling, diagnosis, and treatment of\npsychological disorders in AGI.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 00:19:07 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Behzadan", "Vahid", ""], ["Munir", "Arslan", ""], ["Yampolskiy", "Roman V.", ""]]}, {"id": "1805.08930", "submitter": "Fang Liu", "authors": "Fang Liu, Zizhan Zheng and Ness Shroff", "title": "Analysis of Thompson Sampling for Graphical Bandits Without the Graphs", "comments": "Accepted by UAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study multi-armed bandit problems with graph feedback, in which the\ndecision maker is allowed to observe the neighboring actions of the chosen\naction, in a setting where the graph may vary over time and is never fully\nrevealed to the decision maker. We show that when the feedback graphs are\nundirected, the original Thompson Sampling achieves the optimal (within\nlogarithmic factors) regret $\\tilde{O}\\left(\\sqrt{\\beta_0(G)T}\\right)$ over\ntime horizon $T$, where $\\beta_0(G)$ is the average independence number of the\nlatent graphs. To the best of our knowledge, this is the first result showing\nthat the original Thompson Sampling is optimal for graphical bandits in the\nundirected setting. A slightly weaker regret bound of Thompson Sampling in the\ndirected setting is also presented. To fill this gap, we propose a variant of\nThompson Sampling, that attains the optimal regret in the directed setting\nwithin a logarithmic factor. Both algorithms can be implemented efficiently and\ndo not require the knowledge of the feedback graphs at any time.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 01:47:56 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Liu", "Fang", ""], ["Zheng", "Zizhan", ""], ["Shroff", "Ness", ""]]}, {"id": "1805.08948", "submitter": "Maria Dimakopoulou", "authors": "Maria Dimakopoulou, Ian Osband, Benjamin Van Roy", "title": "Scalable Coordinated Exploration in Concurrent Reinforcement Learning", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a team of reinforcement learning agents that concurrently operate\nin a common environment, and we develop an approach to efficient coordinated\nexploration that is suitable for problems of practical scale. Our approach\nbuilds on seed sampling (Dimakopoulou and Van Roy, 2018) and randomized value\nfunction learning (Osband et al., 2016). We demonstrate that, for simple\ntabular contexts, the approach is competitive with previously proposed tabular\nmodel learning methods (Dimakopoulou and Van Roy, 2018). With a\nhigher-dimensional problem and a neural network value function representation,\nthe approach learns quickly with far fewer agents than alternative exploration\nschemes.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 03:36:01 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 08:23:55 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Dimakopoulou", "Maria", ""], ["Osband", "Ian", ""], ["Van Roy", "Benjamin", ""]]}, {"id": "1805.08966", "submitter": "Ramya Ramakrishnan", "authors": "Ramya Ramakrishnan, Ece Kamar, Debadeepta Dey, Julie Shah, Eric\n  Horvitz", "title": "Discovering Blind Spots in Reinforcement Learning", "comments": "To appear at AAMAS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Agents trained in simulation may make errors in the real world due to\nmismatches between training and execution environments. These mistakes can be\ndangerous and difficult to discover because the agent cannot predict them a\npriori. We propose using oracle feedback to learn a predictive model of these\nblind spots to reduce costly errors in real-world applications. We focus on\nblind spots in reinforcement learning (RL) that occur due to incomplete state\nrepresentation: The agent does not have the appropriate features to represent\nthe true state of the world and thus cannot distinguish among numerous states.\nWe formalize the problem of discovering blind spots in RL as a noisy supervised\nlearning problem with class imbalance. We learn models to predict blind spots\nin unseen regions of the state space by combining techniques for label\naggregation, calibration, and supervised learning. The models take into\nconsideration noise emerging from different forms of oracle feedback, including\ndemonstrations and corrections. We evaluate our approach on two domains and\nshow that it achieves higher predictive performance than baseline methods, and\nthat the learned model can be used to selectively query an oracle at execution\ntime to prevent errors. We also empirically analyze the biases of various\nfeedback types and how they influence the discovery of blind spots.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 05:30:17 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Ramakrishnan", "Ramya", ""], ["Kamar", "Ece", ""], ["Dey", "Debadeepta", ""], ["Shah", "Julie", ""], ["Horvitz", "Eric", ""]]}, {"id": "1805.08975", "submitter": "Peter Karkus", "authors": "Peter Karkus, David Hsu and Wee Sun Lee", "title": "Particle Filter Networks with Application to Visual Localization", "comments": "CoRL 2018 camera ready", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI cs.CV cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle filtering is a powerful approach to sequential state estimation and\nfinds application in many domains, including robot localization, object\ntracking, etc. To apply particle filtering in practice, a critical challenge is\nto construct probabilistic system models, especially for systems with complex\ndynamics or rich sensory inputs such as camera images. This paper introduces\nthe Particle Filter Network (PFnet), which encodes both a system model and a\nparticle filter algorithm in a single neural network. The PF-net is fully\ndifferentiable and trained end-to-end from data. Instead of learning a generic\nsystem model, it learns a model optimized for the particle filter algorithm. We\napply the PF-net to a visual localization task, in which a robot must localize\nin a rich 3-D world, using only a schematic 2-D floor map. In simulation\nexperiments, PF-net consistently outperforms alternative learning\narchitectures, as well as a traditional model-based method, under a variety of\nsensor inputs. Further, PF-net generalizes well to new, unseen environments.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 06:21:08 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 17:44:03 GMT"}, {"version": "v3", "created": "Thu, 25 Oct 2018 17:23:11 GMT"}], "update_date": "2019-05-29", "authors_parsed": [["Karkus", "Peter", ""], ["Hsu", "David", ""], ["Lee", "Wee Sun", ""]]}, {"id": "1805.09042", "submitter": "James Whittington", "authors": "James C. R. Whittington, Timothy H. Muller, Shirley Mark, Caswell\n  Barry, Timothy E. J. Behrens", "title": "Generalisation of structural knowledge in the hippocampal-entorhinal\n  system", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central problem to understanding intelligence is the concept of\ngeneralisation. This allows previously learnt structure to be exploited to\nsolve tasks in novel situations differing in their particularities. We take\ninspiration from neuroscience, specifically the hippocampal-entorhinal system\nknown to be important for generalisation. We propose that to generalise\nstructural knowledge, the representations of the structure of the world, i.e.\nhow entities in the world relate to each other, need to be separated from\nrepresentations of the entities themselves. We show, under these principles,\nartificial neural networks embedded with hierarchy and fast Hebbian memory, can\nlearn the statistics of memories and generalise structural knowledge. Spatial\nneuronal representations mirroring those found in the brain emerge, suggesting\nspatial cognition is an instance of more general organising principles. We\nfurther unify many entorhinal cell types as basis functions for constructing\ntransition graphs, and show these representations effectively utilise memories.\nWe experimentally support model assumptions, showing a preserved relationship\nbetween entorhinal grid and hippocampal place cells across environments.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 10:32:45 GMT"}, {"version": "v2", "created": "Mon, 29 Oct 2018 12:27:02 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Whittington", "James C. R.", ""], ["Muller", "Timothy H.", ""], ["Mark", "Shirley", ""], ["Barry", "Caswell", ""], ["Behrens", "Timothy E. J.", ""]]}, {"id": "1805.09044", "submitter": "Yao Liu", "authors": "Yao Liu, Omer Gottesman, Aniruddh Raghu, Matthieu Komorowski, Aldo\n  Faisal, Finale Doshi-Velez, Emma Brunskill", "title": "Representation Balancing MDPs for Off-Policy Policy Evaluation", "comments": "appeared at NeurIPS 18; updated style file", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of off-policy policy evaluation (OPPE) in RL. In\ncontrast to prior work, we consider how to estimate both the individual policy\nvalue and average policy value accurately. We draw inspiration from recent work\nin causal reasoning, and propose a new finite sample generalization error bound\nfor value estimates from MDP models. Using this upper bound as an objective, we\ndevelop a learning algorithm of an MDP model with a balanced representation,\nand show that our approach can yield substantially lower MSE in common\nsynthetic benchmarks and a HIV treatment simulation domain.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 10:43:16 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2018 00:53:09 GMT"}, {"version": "v3", "created": "Tue, 16 Apr 2019 05:21:47 GMT"}, {"version": "v4", "created": "Wed, 17 Apr 2019 19:54:27 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Liu", "Yao", ""], ["Gottesman", "Omer", ""], ["Raghu", "Aniruddh", ""], ["Komorowski", "Matthieu", ""], ["Faisal", "Aldo", ""], ["Doshi-Velez", "Finale", ""], ["Brunskill", "Emma", ""]]}, {"id": "1805.09045", "submitter": "Yao Liu", "authors": "Yao Liu, Emma Brunskill", "title": "When Simple Exploration is Sample Efficient: Identifying Sufficient\n  Conditions for Random Exploration to Yield PAC RL Algorithms", "comments": "Appeared in The 14th European Workshop on Reinforcement Learning\n  (EWRL), 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient exploration is one of the key challenges for reinforcement learning\n(RL) algorithms. Most traditional sample efficiency bounds require strategic\nexploration. Recently many deep RL algorithms with simple heuristic exploration\nstrategies that have few formal guarantees, achieve surprising success in many\ndomains. These results pose an important question about understanding these\nexploration strategies such as $e$-greedy, as well as understanding what\ncharacterize the difficulty of exploration in MDPs. In this work we propose\nproblem specific sample complexity bounds of $Q$ learning with random walk\nexploration that rely on several structural properties. We also link our\ntheoretical results to some empirical benchmark domains, to illustrate if our\nbound gives polynomial sample complexity in these domains and how that is\nrelated with the empirical performance.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 10:43:56 GMT"}, {"version": "v2", "created": "Wed, 13 Jun 2018 07:11:34 GMT"}, {"version": "v3", "created": "Sat, 4 Aug 2018 01:13:03 GMT"}, {"version": "v4", "created": "Wed, 17 Apr 2019 19:58:38 GMT"}], "update_date": "2019-04-19", "authors_parsed": [["Liu", "Yao", ""], ["Brunskill", "Emma", ""]]}, {"id": "1805.09137", "submitter": "Vikram Mullachery", "authors": "Vikram Mullachery, Vishal Motwani", "title": "Image Captioning", "comments": "arXiv admin note: text overlap with arXiv:1609.06647 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses and demonstrates the outcomes from our experimentation\non Image Captioning. Image captioning is a much more involved task than image\nrecognition or classification, because of the additional challenge of\nrecognizing the interdependence between the objects/concepts in the image and\nthe creation of a succinct sentential narration. Experiments on several labeled\ndatasets show the accuracy of the model and the fluency of the language it\nlearns solely from image descriptions. As a toy application, we apply image\ncaptioning to create video captions, and we advance a few hypotheses on the\nchallenges we encountered.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 19:13:16 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Mullachery", "Vikram", ""], ["Motwani", "Vishal", ""]]}, {"id": "1805.09145", "submitter": "Matthias Jurisch", "authors": "Matthias Jurisch, Bodo Igler", "title": "RDF2Vec-based Classification of Ontology Alignment Changes", "comments": "6 pages, accepted at Workshop on Deep Learning for Knowledge Graphs\n  and Semantic Technologies (DL4KGS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When ontologies cover overlapping topics, the overlap can be represented\nusing ontology alignments. These alignments need to be continuously adapted to\nchanging ontologies. Especially for large ontologies this is a costly task\noften consisting of manual work. Finding changes that do not lead to an\nadaption of the alignment can potentially make this process significantly\neasier. This work presents an approach to finding these changes based on RDF\nembeddings and common classification techniques. To examine the feasibility of\nthis approach, an evaluation on a real-world dataset is presented. In this\nevaluation, the best classifiers reached a precision of 0.8.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 13:34:51 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Jurisch", "Matthias", ""], ["Igler", "Bodo", ""]]}, {"id": "1805.09157", "submitter": "Vernon Asuncion Va", "authors": "Vernon Asuncion and Yan Zhang", "title": "A New Finitely Controllable Class of Tuple Generating Dependencies: The\n  Triangularly-Guarded Class", "comments": "Submitted for review. arXiv admin note: substantial text overlap with\n  arXiv:1804.05997", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce a new class of tuple-generating dependencies\n(TGDs) called triangularly-guarded (TG) TGDs. We show that conjunctive query\nanswering under this new class of TGDs is decidable since this new class of\nTGDs also satisfies the finite controllability (FC) property. We further show\nthat this new class strictly contains some other decidable classes such as\nweak-acyclic, guarded, sticky and shy. In this sense, the class TG provides a\nunified representation of all these aforementioned classes of TGDs.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 23:29:09 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Asuncion", "Vernon", ""], ["Zhang", "Yan", ""]]}, {"id": "1805.09169", "submitter": "Maaz Amjad", "authors": "Maaz Amjad, fariha Bukhari, Iqra Ameer, Alexander Gelbukh", "title": "A distinct approach to diagnose Dengue Fever with the help of Soft Set\n  Theory", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mathematics has played a substantial role to revolutionize the medical\nscience. Intelligent systems based on mathematical theories have proved to be\nefficient in diagnosing various diseases. In this paper, we used an expert\nsystem based on soft set theory and fuzzy set theory named as a soft expert\nsystem to diagnose tropical disease dengue. The objective to use soft expert\nsystem is to predict the risk level of a patient having dengue fever by using\ninput variables like age, TLC, SGOT, platelets count and blood pressure. The\nproposed method explicitly demonstrates the exact percentage of the risk level\nof dengue fever automatically circumventing for all possible (medical)\nimprecisions.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 16:30:10 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 06:37:38 GMT"}, {"version": "v3", "created": "Wed, 21 Nov 2018 17:21:26 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Amjad", "Maaz", ""], ["Bukhari", "fariha", ""], ["Ameer", "Iqra", ""], ["Gelbukh", "Alexander", ""]]}, {"id": "1805.09197", "submitter": "No\\'e Tits", "authors": "No\\'e Tits, Kevin El Haddad, Thierry Dutoit", "title": "ASR-based Features for Emotion Recognition: A Transfer Learning Approach", "comments": "Accepted to be published in the First Workshop on Computational\n  Modeling of Human Multimodal Language - ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.AI cs.CL cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade, the applications of signal processing have\ndrastically improved with deep learning. However areas of affecting computing\nsuch as emotional speech synthesis or emotion recognition from spoken language\nremains challenging. In this paper, we investigate the use of a neural\nAutomatic Speech Recognition (ASR) as a feature extractor for emotion\nrecognition. We show that these features outperform the eGeMAPS feature set to\npredict the valence and arousal emotional dimensions, which means that the\naudio-to-text mapping learning by the ASR system contain information related to\nthe emotional dimensions in spontaneous speech. We also examine the\nrelationship between first layers (closer to speech) and last layers (closer to\ntext) of the ASR and valence/arousal.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 14:38:39 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 16:50:08 GMT"}, {"version": "v3", "created": "Fri, 1 Jun 2018 08:14:19 GMT"}], "update_date": "2018-06-04", "authors_parsed": [["Tits", "No\u00e9", ""], ["Haddad", "Kevin El", ""], ["Dutoit", "Thierry", ""]]}, {"id": "1805.09218", "submitter": "Thomas Moerland", "authors": "Thomas M. Moerland, Joost Broekens, Aske Plaat and Catholijn M. Jonker", "title": "Monte Carlo Tree Search for Asymmetric Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an extension of Monte Carlo Tree Search (MCTS) that strongly\nincreases its efficiency for trees with asymmetry and/or loops. Asymmetric\ntermination of search trees introduces a type of uncertainty for which the\nstandard upper confidence bound (UCB) formula does not account. Our first\nalgorithm (MCTS-T), which assumes a non-stochastic environment, backs-up tree\nstructure uncertainty and leverages it for exploration in a modified UCB\nformula. Results show vastly improved efficiency in a well-known asymmetric\ndomain in which MCTS performs arbitrarily bad. Next, we connect the ideas about\nasymmetric termination to the presence of loops in the tree, where the same\nstate appears multiple times in a single trace. An extension to our algorithm\n(MCTS-T+), which in addition to non-stochasticity assumes full state\nobservability, further increases search efficiency for domains with loops as\nwell. Benchmark testing on a set of OpenAI Gym and Atari 2600 games indicates\nthat our algorithms always perform better than or at least equivalent to\nstandard MCTS, and could be first-choice tree search algorithms for\nnon-stochastic, fully-observable environments.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 15:19:40 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Moerland", "Thomas M.", ""], ["Broekens", "Joost", ""], ["Plaat", "Aske", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "1805.09235", "submitter": "Przemys\u00c5\u0082aw Spurek", "authors": "Szymon Knop, Jacek Tabor, Przemys{\\l}aw Spurek, Igor Podolak, Marcin\n  Mazur, Stanis{\\l}aw Jastrz\\k{e}bski", "title": "Cramer-Wold AutoEncoder", "comments": null, "journal-ref": "Journal of Machine Learning Research, 21, 164, 1-28 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new generative model, Cramer-Wold Autoencoder (CWAE). Following\nWAE, we directly encourage normality of the latent space. Our paper uses also\nthe recent idea from Sliced WAE (SWAE) model, which uses one-dimensional\nprojections as a method of verifying closeness of two distributions. The\ncrucial new ingredient is the introduction of a new (Cramer-Wold) metric in the\nspace of densities, which replaces the Wasserstein metric used in SWAE. We show\nthat the Cramer-Wold metric between Gaussian mixtures is given by a simple\nanalytic formula, which results in the removal of sampling necessary to\nestimate the cost function in WAE and SWAE models. As a consequence, while\ndrastically simplifying the optimization procedure, CWAE produces samples of a\nmatching perceptual quality to other SOTA models.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 15:48:31 GMT"}, {"version": "v2", "created": "Thu, 4 Oct 2018 17:31:37 GMT"}, {"version": "v3", "created": "Tue, 2 Jul 2019 09:00:24 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["Knop", "Szymon", ""], ["Tabor", "Jacek", ""], ["Spurek", "Przemys\u0142aw", ""], ["Podolak", "Igor", ""], ["Mazur", "Marcin", ""], ["Jastrz\u0119bski", "Stanis\u0142aw", ""]]}, {"id": "1805.09238", "submitter": "Ron Shoham", "authors": "Ron Shoham and Haim Permuter", "title": "Highway State Gating for Recurrent Highway Networks: improving\n  information flow through time", "comments": "Accepted at CSCML (Cyber Security Cryptography and Machine Learning)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent Neural Networks (RNNs) play a major role in the field of sequential\nlearning, and have outperformed traditional algorithms on many benchmarks.\nTraining deep RNNs still remains a challenge, and most of the state-of-the-art\nmodels are structured with a transition depth of 2-4 layers. Recurrent Highway\nNetworks (RHNs) were introduced in order to tackle this issue. These have\nachieved state-of-the-art performance on a few benchmarks using a depth of 10\nlayers. However, the performance of this architecture suffers from a\nbottleneck, and ceases to improve when an attempt is made to add more layers.\nIn this work, we analyze the causes for this, and postulate that the main\nsource is the way that the information flows through time. We introduce a novel\nand simple variation for the RHN cell, called Highway State Gating (HSG), which\nallows adding more layers, while continuing to improve performance. By using a\ngating mechanism for the state, we allow the net to \"choose\" whether to pass\ninformation directly through time, or to gate it. This mechanism also allows\nthe gradient to back-propagate directly through time and, therefore, results in\na slightly faster convergence. We use the Penn Treebank (PTB) dataset as a\nplatform for empirical proof of concept. Empirical results show that the\nimprovement due to Highway State Gating is for all depths, and as the depth\nincreases, the improvement also increases.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 15:53:10 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Shoham", "Ron", ""], ["Permuter", "Haim", ""]]}, {"id": "1805.09244", "submitter": "Davide Bacciu", "authors": "Davide Bacciu and Andrea Bongiorno", "title": "Concentric ESN: Assessing the Effect of Modularity in Cycle Reservoirs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper introduces concentric Echo State Network, an approach to design\nreservoir topologies that tries to bridge the gap between deterministically\nconstructed simple cycle models and deep reservoir computing approaches. We\nshow how to modularize the reservoir into simple unidirectional and concentric\ncycles with pairwise bidirectional jump connections between adjacent loops. We\nprovide a preliminary experimental assessment showing how concentric reservoirs\nyield to superior predictive accuracy and memory capacity with respect to\nsingle cycle reservoirs and deep reservoir models.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 15:58:57 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Bacciu", "Davide", ""], ["Bongiorno", "Andrea", ""]]}, {"id": "1805.09267", "submitter": "Prashant Doshi", "authors": "Roi Ceren and Prashant Doshi and Keyang He", "title": "Reinforcement Learning for Heterogeneous Teams with PALO Bounds", "comments": null, "journal-ref": "Neurocomputing, Volume 420, 8 January 2021, Pages 36-56", "doi": "10.1016/j.neucom.2020.08.054", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce reinforcement learning for heterogeneous teams in which rewards\nfor an agent are additively factored into local costs, stimuli unique to each\nagent, and global rewards, those shared by all agents in the domain. Motivating\ndomains include coordination of varied robotic platforms, which incur different\ncosts for the same action, but share an overall goal. We present two templates\nfor learning in this setting with factored rewards: a generalization of\nPerkins' Monte Carlo exploring starts for POMDPs to canonical MPOMDPs, with a\nsingle policy mapping joint observations of all agents to joint actions\n(MCES-MP); and another with each agent individually mapping joint observations\nto their own action (MCES-FMP). We use probably approximately local optimal\n(PALO) bounds to analyze sample complexity, instantiating these templates to\nPALO learning. We promote sample efficiency by including a policy space pruning\ntechnique, and evaluate the approaches on three domains of heterogeneous agents\ndemonstrating that MCES-FMP yields improved policies in less samples compared\nto MCES-MP and a previous benchmark.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 16:27:51 GMT"}], "update_date": "2020-11-19", "authors_parsed": [["Ceren", "Roi", ""], ["Doshi", "Prashant", ""], ["He", "Keyang", ""]]}, {"id": "1805.09416", "submitter": "Hejian Sang", "authors": "Hejian Sang, Jia Liu", "title": "Adaptive Stochastic Gradient Langevin Dynamics: Taming Convergence and\n  Saddle Point Escape Time", "comments": "24 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we propose a new adaptive stochastic gradient Langevin\ndynamics (ASGLD) algorithmic framework and its two specialized versions, namely\nadaptive stochastic gradient (ASG) and adaptive gradient Langevin\ndynamics(AGLD), for non-convex optimization problems. All proposed algorithms\ncan escape from saddle points with at most $O(\\log d)$ iterations, which is\nnearly dimension-free. Further, we show that ASGLD and ASG converge to a local\nminimum with at most $O(\\log d/\\epsilon^4)$ iterations. Also, ASGLD with full\ngradients or ASGLD with a slowly linearly increasing batch size converge to a\nlocal minimum with iterations bounded by $O(\\log d/\\epsilon^2)$, which\noutperforms existing first-order methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 20:26:56 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Sang", "Hejian", ""], ["Liu", "Jia", ""]]}, {"id": "1805.09460", "submitter": "Yotam Hechtlinger", "authors": "Yotam Hechtlinger, Barnab\\'as P\\'oczos and Larry Wasserman", "title": "Cautious Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most classifiers operate by selecting the maximum of an estimate of the\nconditional distribution $p(y|x)$ where $x$ stands for the features of the\ninstance to be classified and $y$ denotes its label. This often results in a\n{\\em hubristic bias}: overconfidence in the assignment of a definite label.\nUsually, the observations are concentrated on a small volume but the classifier\nprovides definite predictions for the entire space. We propose constructing\nconformal prediction sets which contain a set of labels rather than a single\nlabel. These conformal prediction sets contain the true label with probability\n$1-\\alpha$. Our construction is based on $p(x|y)$ rather than $p(y|x)$ which\nresults in a classifier that is very cautious: it outputs the null set ---\nmeaning \"I don't know\" --- when the object does not resemble the training\nexamples. An important property of our approach is that adversarial attacks are\nlikely to be predicted as the null set or would also include the true label. We\ndemonstrate the performance on the ImageNet ILSVRC dataset and the CelebA and\nIMDB-Wiki facial datasets using high dimensional features obtained from state\nof the art convolutional neural networks.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 00:17:24 GMT"}, {"version": "v2", "created": "Wed, 27 Feb 2019 19:27:58 GMT"}], "update_date": "2019-03-01", "authors_parsed": [["Hechtlinger", "Yotam", ""], ["P\u00f3czos", "Barnab\u00e1s", ""], ["Wasserman", "Larry", ""]]}, {"id": "1805.09476", "submitter": "Rad Niazadeh", "authors": "Vaggos Chatziafratis, Rad Niazadeh, Moses Charikar", "title": "Hierarchical Clustering with Structural Constraints", "comments": "In Proc. 35th International Conference on Machine Learning (ICML\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical clustering is a popular unsupervised data analysis method. For\nmany real-world applications, we would like to exploit prior information about\nthe data that imposes constraints on the clustering hierarchy, and is not\ncaptured by the set of features available to the algorithm. This gives rise to\nthe problem of \"hierarchical clustering with structural constraints\".\nStructural constraints pose major challenges for bottom-up approaches like\naverage/single linkage and even though they can be naturally incorporated into\ntop-down divisive algorithms, no formal guarantees exist on the quality of\ntheir output. In this paper, we provide provable approximation guarantees for\ntwo simple top-down algorithms, using a recently introduced optimization\nviewpoint of hierarchical clustering with pairwise similarity information\n[Dasgupta, 2016]. We show how to find good solutions even in the presence of\nconflicting prior information, by formulating a constraint-based regularization\nof the objective. We further explore a variation of this objective for\ndissimilarity information [Cohen-Addad et al., 2018] and improve upon current\ntechniques. Finally, we demonstrate our approach on a real dataset for the\ntaxonomy application.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 01:32:19 GMT"}, {"version": "v2", "created": "Sat, 14 Jul 2018 16:12:51 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Chatziafratis", "Vaggos", ""], ["Niazadeh", "Rad", ""], ["Charikar", "Moses", ""]]}, {"id": "1805.09495", "submitter": "Jiecao Chen", "authors": "Jiecao Chen, Erfan Sadeqi Azer, Qin Zhang", "title": "A Practical Algorithm for Distributed Clustering and Outlier Detection", "comments": "Accepted to NIPS 2018. 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the classic $k$-means/median clustering, which are fundamental\nproblems in unsupervised learning, in the setting where data are partitioned\nacross multiple sites, and where we are allowed to discard a small portion of\nthe data by labeling them as outliers. We propose a simple approach based on\nconstructing small summary for the original dataset. The proposed method is\ntime and communication efficient, has good approximation guarantees, and can\nidentify the global outliers effectively. To the best of our knowledge, this is\nthe first practical algorithm with theoretical guarantees for distributed\nclustering with outliers. Our experiments on both real and synthetic data have\ndemonstrated the clear superiority of our algorithm against all the baseline\nalgorithms in almost all metrics.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 03:00:55 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2018 00:56:10 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Chen", "Jiecao", ""], ["Azer", "Erfan Sadeqi", ""], ["Zhang", "Qin", ""]]}, {"id": "1805.09496", "submitter": "Yuanlong Li", "authors": "Yuanlong Li, Linsen Dong, Xin Zhou, Yonggang Wen and Kyle Guan", "title": "Intelligent Trainer for Model-Based Reinforcement Learning", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Model-based reinforcement learning (MBRL) has been proposed as a promising\nalternative solution to tackle the high sampling cost challenge in the\ncanonical reinforcement learning (RL), by leveraging a learned model to\ngenerate synthesized data for policy training purpose. The MBRL framework,\nnevertheless, is inherently limited by the convoluted process of jointly\nlearning control policy and configuring hyper-parameters (e.g., global/local\nmodels, real and synthesized data, etc). The training process could be tedious\nand prohibitively costly. In this research, we propose an \"reinforcement on\nreinforcement\" (RoR) architecture to decompose the convoluted tasks into two\nlayers of reinforcement learning. The inner layer is the canonical model-based\nRL training process environment (TPE), which learns the control policy for the\nunderlying system and exposes interfaces to access states, actions and rewards.\nThe outer layer presents an RL agent, called as AI trainer, to learn an optimal\nhyper-parameter configuration for the inner TPE. This decomposition approach\nprovides a desirable flexibility to implement different trainer designs, called\nas \"train the trainer\". In our research, we propose and optimize two\nalternative trainer designs: 1) a uni-head trainer and 2) a multi-head trainer.\nOur proposed RoR framework is evaluated for five tasks in the OpenAI gym (i.e.,\nPendulum, Mountain Car, Reacher, Half Cheetah and Swimmer). Compared to three\nother baseline algorithms, our proposed Train-the-Trainer algorithm has a\ncompetitive performance in auto-tuning capability, with upto 56% expected\nsampling cost saving without knowing the best parameter setting in advance. The\nproposed trainer framework can be easily extended to other cases in which the\nhyper-parameter tuning is costly.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 03:08:40 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 09:14:20 GMT"}, {"version": "v3", "created": "Thu, 27 Dec 2018 03:22:35 GMT"}, {"version": "v4", "created": "Sun, 10 Mar 2019 05:13:36 GMT"}, {"version": "v5", "created": "Sat, 23 Mar 2019 13:45:03 GMT"}, {"version": "v6", "created": "Wed, 5 Jun 2019 13:02:28 GMT"}], "update_date": "2019-06-06", "authors_parsed": [["Li", "Yuanlong", ""], ["Dong", "Linsen", ""], ["Zhou", "Xin", ""], ["Wen", "Yonggang", ""], ["Guan", "Kyle", ""]]}, {"id": "1805.09613", "submitter": "Thomas Moerland", "authors": "Thomas M. Moerland, Joost Broekens, Aske Plaat and Catholijn M. Jonker", "title": "A0C: Alpha Zero in Continuous Action Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A core novelty of Alpha Zero is the interleaving of tree search and deep\nlearning, which has proven very successful in board games like Chess, Shogi and\nGo. These games have a discrete action space. However, many real-world\nreinforcement learning domains have continuous action spaces, for example in\nrobotic control, navigation and self-driving cars. This paper presents the\nnecessary theoretical extensions of Alpha Zero to deal with continuous action\nspace. We also provide some preliminary experiments on the Pendulum swing-up\ntask, empirically showing the feasibility of our approach. Thereby, this work\nprovides a first step towards the application of iterated search and learning\nin domains with a continuous action space.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 11:33:49 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Moerland", "Thomas M.", ""], ["Broekens", "Joost", ""], ["Plaat", "Aske", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "1805.09622", "submitter": "Or Litany", "authors": "Or Litany and Daniel Freedman", "title": "SOSELETO: A Unified Approach to Transfer Learning and Training with\n  Noisy Labels", "comments": "ICLR workshop on Learning from Limited Labeled Data (LLD) -- Best\n  Paper Award", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present SOSELETO (SOurce SELEction for Target Optimization), a new method\nfor exploiting a source dataset to solve a classification problem on a target\ndataset. SOSELETO is based on the following simple intuition: some source\nexamples are more informative than others for the target problem. To capture\nthis intuition, source samples are each given weights; these weights are solved\nfor jointly with the source and target classification problems via a bilevel\noptimization scheme. The target therefore gets to choose the source samples\nwhich are most informative for its own classification task. Furthermore, the\nbilevel nature of the optimization acts as a kind of regularization on the\ntarget, mitigating overfitting. SOSELETO may be applied to both classic\ntransfer learning, as well as the problem of training on datasets with noisy\nlabels; we show state of the art results on both of these problems.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 12:03:58 GMT"}, {"version": "v2", "created": "Thu, 9 May 2019 15:41:44 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Litany", "Or", ""], ["Freedman", "Daniel", ""]]}, {"id": "1805.09653", "submitter": "Jay Heo", "authors": "Jay Heo, Hae Beom Lee, Saehoon Kim, Juho Lee, Kwang Joon Kim, Eunho\n  Yang, and Sung Ju Hwang", "title": "Uncertainty-Aware Attention for Reliable Interpretation and Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attention mechanism is effective in both focusing the deep learning models on\nrelevant features and interpreting them. However, attentions may be unreliable\nsince the networks that generate them are often trained in a weakly-supervised\nmanner. To overcome this limitation, we introduce the notion of input-dependent\nuncertainty to the attention mechanism, such that it generates attention for\neach feature with varying degrees of noise based on the given input, to learn\nlarger variance on instances it is uncertain about. We learn this\nUncertainty-aware Attention (UA) mechanism using variational inference, and\nvalidate it on various risk prediction tasks from electronic health records on\nwhich our model significantly outperforms existing attention models. The\nanalysis of the learned attentions shows that our model generates attentions\nthat comply with clinicians' interpretation, and provide richer interpretation\nvia learned variance. Further evaluation of both the accuracy of the\nuncertainty calibration and the prediction performance with \"I don't know\"\ndecision show that UA yields networks with high reliability as well.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 13:17:08 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Heo", "Jay", ""], ["Lee", "Hae Beom", ""], ["Kim", "Saehoon", ""], ["Lee", "Juho", ""], ["Kim", "Kwang Joon", ""], ["Yang", "Eunho", ""], ["Hwang", "Sung Ju", ""]]}, {"id": "1805.09655", "submitter": "Victor Zhong", "authors": "Victor Zhong, Caiming Xiong, Richard Socher", "title": "Global-Locally Self-Attentive Dialogue State Tracker", "comments": "ACL 2018. 10 pages, 5 figures. Source code:\n  https://github.com/salesforce/glad", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue state tracking, which estimates user goals and requests given the\ndialogue context, is an essential part of task-oriented dialogue systems. In\nthis paper, we propose the Global-Locally Self-Attentive Dialogue State Tracker\n(GLAD), which learns representations of the user utterance and previous system\nactions with global-local modules. Our model uses global modules to share\nparameters between estimators for different types (called slots) of dialogue\nstates, and uses local modules to learn slot-specific features. We show that\nthis significantly improves tracking of rare states and achieves\nstate-of-the-art performance on the WoZ and DSTC2 state tracking tasks. GLAD\nobtains 88.1% joint goal accuracy and 97.1% request accuracy on WoZ,\noutperforming prior work by 3.7% and 5.5%. On DSTC2, our model obtains 74.5%\njoint goal accuracy and 97.5% request accuracy, outperforming prior work by\n1.1% and 1.0%.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 19:23:38 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 22:11:50 GMT"}, {"version": "v3", "created": "Thu, 6 Sep 2018 23:58:53 GMT"}], "update_date": "2018-09-10", "authors_parsed": [["Zhong", "Victor", ""], ["Xiong", "Caiming", ""], ["Socher", "Richard", ""]]}, {"id": "1805.09657", "submitter": "Dieuwke Hupkes", "authors": "Dieuwke Hupkes, Anand Singh, Kris Korrel, German Kruszewski, Elia\n  Bruni", "title": "Learning compositionally through attentive guidance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural network models have been successfully applied to domains that\nrequire substantial generalisation skills, recent studies have implied that\nthey struggle when solving the task they are trained on requires inferring its\nunderlying compositional structure. In this paper, we introduce Attentive\nGuidance, a mechanism to direct a sequence to sequence model equipped with\nattention to find more compositional solutions. We test it on two tasks,\ndevised precisely to assess the compositional capabilities of neural models,\nand we show that vanilla sequence to sequence models with attention overfit the\ntraining distribution, while the guided versions come up with compositional\nsolutions that fit the training and testing distributions almost equally well.\nMoreover, the learned solutions generalise even in cases where the training and\ntesting distributions strongly diverge. In this way, we demonstrate that\nsequence to sequence models are capable of finding compositional solutions\nwithout requiring extra components. These results helps to disentangle the\ncauses for the lack of systematic compositionality in neural networks, which\ncan in turn fuel future work.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2018 10:33:00 GMT"}, {"version": "v2", "created": "Fri, 7 Sep 2018 09:46:30 GMT"}, {"version": "v3", "created": "Mon, 10 Sep 2018 12:02:27 GMT"}, {"version": "v4", "created": "Fri, 5 Jul 2019 12:41:30 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Hupkes", "Dieuwke", ""], ["Singh", "Anand", ""], ["Korrel", "Kris", ""], ["Kruszewski", "German", ""], ["Bruni", "Elia", ""]]}, {"id": "1805.09676", "submitter": "Robert Bridges", "authors": "Robert A. Bridges, Maria A. Vincent, Kelly M. T. Huffer, John R.\n  Goodall, Jessie D. Jamieson, Zachary Burch", "title": "Forming IDEAS Interactive Data Exploration & Analysis System", "comments": "4 page short paper on IDEAS System, 4 figures", "journal-ref": "Workshop on Information Security Workers, USENIX SOUPS 2018", "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern cyber security operations collect an enormous amount of logging and\nalerting data. While analysts have the ability to query and compute simple\nstatistics and plots from their data, current analytical tools are too simple\nto admit deep understanding. To detect advanced and novel attacks, analysts\nturn to manual investigations. While commonplace, current investigations are\ntime-consuming, intuition-based, and proving insufficient. Our hypothesis is\nthat arming the analyst with easy-to-use data science tools will increase their\nwork efficiency, provide them with the ability to resolve hypotheses with\nscientific inquiry of their data, and support their decisions with evidence\nover intuition. To this end, we present our work to build IDEAS (Interactive\nData Exploration and Analysis System). We present three real-world use-cases\nthat drive the system design from the algorithmic capabilities to the user\ninterface. Finally, a modular and scalable software architecture is discussed\nalong with plans for our pilot deployment with a security operation command.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 13:54:24 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2018 19:50:20 GMT"}], "update_date": "2018-06-22", "authors_parsed": [["Bridges", "Robert A.", ""], ["Vincent", "Maria A.", ""], ["Huffer", "Kelly M. T.", ""], ["Goodall", "John R.", ""], ["Jamieson", "Jessie D.", ""], ["Burch", "Zachary", ""]]}, {"id": "1805.09692", "submitter": "Sam Ritter", "authors": "Samuel Ritter, Jane X. Wang, Zeb Kurth-Nelson, Siddhant M. Jayakumar,\n  Charles Blundell, Razvan Pascanu, Matthew Botvinick", "title": "Been There, Done That: Meta-Learning with Episodic Recall", "comments": "ICML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Meta-learning agents excel at rapidly learning new tasks from open-ended task\ndistributions; yet, they forget what they learn about each task as soon as the\nnext begins. When tasks reoccur - as they do in natural environments -\nmetalearning agents must explore again instead of immediately exploiting\npreviously discovered solutions. We propose a formalism for generating\nopen-ended yet repetitious environments, then develop a meta-learning\narchitecture for solving these environments. This architecture melds the\nstandard LSTM working memory with a differentiable neural episodic memory. We\nexplore the capabilities of agents with this episodic LSTM in five\nmeta-learning environments with reoccurring tasks, ranging from bandits to\nnavigation and stochastic sequential decision problems.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 14:15:27 GMT"}, {"version": "v2", "created": "Fri, 6 Jul 2018 14:59:58 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Ritter", "Samuel", ""], ["Wang", "Jane X.", ""], ["Kurth-Nelson", "Zeb", ""], ["Jayakumar", "Siddhant M.", ""], ["Blundell", "Charles", ""], ["Pascanu", "Razvan", ""], ["Botvinick", "Matthew", ""]]}, {"id": "1805.09697", "submitter": "Arnab Bhattacharyya", "authors": "Jayadev Acharya, Arnab Bhattacharyya, Constantinos Daskalakis,\n  Saravanan Kandasamy", "title": "Learning and Testing Causal Models with Interventions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider testing and learning problems on causal Bayesian networks as\ndefined by Pearl (Pearl, 2009). Given a causal Bayesian network $\\mathcal{M}$\non a graph with $n$ discrete variables and bounded in-degree and bounded\n`confounded components', we show that $O(\\log n)$ interventions on an unknown\ncausal Bayesian network $\\mathcal{X}$ on the same graph, and\n$\\tilde{O}(n/\\epsilon^2)$ samples per intervention, suffice to efficiently\ndistinguish whether $\\mathcal{X}=\\mathcal{M}$ or whether there exists some\nintervention under which $\\mathcal{X}$ and $\\mathcal{M}$ are farther than\n$\\epsilon$ in total variation distance. We also obtain sample/time/intervention\nefficient algorithms for: (i) testing the identity of two unknown causal\nBayesian networks on the same graph; and (ii) learning a causal Bayesian\nnetwork on a given graph. Although our algorithms are non-adaptive, we show\nthat adaptivity does not help in general: $\\Omega(\\log n)$ interventions are\nnecessary for testing the identity of two unknown causal Bayesian networks on\nthe same graph, even adaptively. Our algorithms are enabled by a new\nsubadditivity inequality for the squared Hellinger distance between two causal\nBayesian networks.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 14:31:09 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Acharya", "Jayadev", ""], ["Bhattacharyya", "Arnab", ""], ["Daskalakis", "Constantinos", ""], ["Kandasamy", "Saravanan", ""]]}, {"id": "1805.09701", "submitter": "Pan Lu", "authors": "Pan Lu, Lei Ji, Wei Zhang, Nan Duan, Ming Zhou, Jianyong Wang", "title": "R-VQA: Learning Visual Relation Facts with Semantic Attention for Visual\n  Question Answering", "comments": "10 pages, 5 figures, accepted as an oral paper in SIGKDD 2018", "journal-ref": null, "doi": "10.1145/3219819.3220036", "report-no": null, "categories": "cs.CV cs.AI cs.CL cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Visual Question Answering (VQA) has emerged as one of the most\nsignificant tasks in multimodal learning as it requires understanding both\nvisual and textual modalities. Existing methods mainly rely on extracting image\nand question features to learn their joint feature embedding via multimodal\nfusion or attention mechanism. Some recent studies utilize external\nVQA-independent models to detect candidate entities or attributes in images,\nwhich serve as semantic knowledge complementary to the VQA task. However, these\ncandidate entities or attributes might be unrelated to the VQA task and have\nlimited semantic capacities. To better utilize semantic knowledge in images, we\npropose a novel framework to learn visual relation facts for VQA. Specifically,\nwe build up a Relation-VQA (R-VQA) dataset based on the Visual Genome dataset\nvia a semantic similarity module, in which each data consists of an image, a\ncorresponding question, a correct answer and a supporting relation fact. A\nwell-defined relation detector is then adopted to predict visual\nquestion-related relation facts. We further propose a multi-step attention\nmodel composed of visual attention and semantic attention sequentially to\nextract related visual knowledge and semantic knowledge. We conduct\ncomprehensive experiments on the two benchmark datasets, demonstrating that our\nmodel achieves state-of-the-art performance and verifying the benefit of\nconsidering visual relation facts.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 14:43:30 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 03:45:04 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Lu", "Pan", ""], ["Ji", "Lei", ""], ["Zhang", "Wei", ""], ["Duan", "Nan", ""], ["Zhou", "Ming", ""], ["Wang", "Jianyong", ""]]}, {"id": "1805.09780", "submitter": "Abhirut Gupta", "authors": "Abhirut Gupta, Abhay Khosla, Gautam Singh, Gargi Dasgupta", "title": "Mining Procedures from Technical Support Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Guided troubleshooting is an inherent task in the domain of technical support\nservices. When a customer experiences an issue with the functioning of a\ntechnical service or a product, an expert user helps guide the customer through\na set of steps comprising a troubleshooting procedure. The objective is to\nidentify the source of the problem through a set of diagnostic steps and\nobservations, and arrive at a resolution. Procedures containing these set of\ndiagnostic steps and observations in response to different problems are common\nartifacts in the body of technical support documentation. The ability to use\nmachine learning and linguistics to understand and leverage these procedures\nfor applications like intelligent chatbots or robotic process automation, is\ncrucial. Existing research on question answering or intelligent chatbots does\nnot look within procedures or deep-understand them. In this paper, we outline a\nsystem for mining procedures from technical support documents. We create models\nfor solving important subproblems like extraction of procedures, identifying\ndecision points within procedures, identifying blocks of instructions\ncorresponding to these decision points and mapping instructions within a\ndecision block. We also release a dataset containing our manual annotations on\npublicly available support documents, to promote further research on the\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 16:58:24 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Gupta", "Abhirut", ""], ["Khosla", "Abhay", ""], ["Singh", "Gautam", ""], ["Dasgupta", "Gargi", ""]]}, {"id": "1805.09801", "submitter": "Zhongwen Xu", "authors": "Zhongwen Xu, Hado van Hasselt, David Silver", "title": "Meta-Gradient Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of reinforcement learning algorithms is to estimate and/or optimise\nthe value function. However, unlike supervised learning, no teacher or oracle\nis available to provide the true value function. Instead, the majority of\nreinforcement learning algorithms estimate and/or optimise a proxy for the\nvalue function. This proxy is typically based on a sampled and bootstrapped\napproximation to the true value function, known as a return. The particular\nchoice of return is one of the chief components determining the nature of the\nalgorithm: the rate at which future rewards are discounted; when and how values\nshould be bootstrapped; or even the nature of the rewards themselves. It is\nwell-known that these decisions are crucial to the overall success of RL\nalgorithms. We discuss a gradient-based meta-learning algorithm that is able to\nadapt the nature of the return, online, whilst interacting and learning from\nthe environment. When applied to 57 games on the Atari 2600 environment over\n200 million frames, our algorithm achieved a new state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 17:45:11 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Xu", "Zhongwen", ""], ["van Hasselt", "Hado", ""], ["Silver", "David", ""]]}, {"id": "1805.09822", "submitter": "Holger Schwenk", "authors": "Holger Schwenk", "title": "Filtering and Mining Parallel Data in a Joint Multilingual Space", "comments": "8 pages", "journal-ref": "ACL, July 2018, Melbourne", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We learn a joint multilingual sentence embedding and use the distance between\nsentences in different languages to filter noisy parallel data and to mine for\nparallel data in large news collections. We are able to improve a competitive\nbaseline on the WMT'14 English to German task by 0.3 BLEU by filtering out 25%\nof the training data. The same approach is used to mine additional bitexts for\nthe WMT'14 system and to obtain competitive results on the BUCC shared task to\nidentify parallel sentences in comparable corpora. The approach is generic, it\ncan be applied to many language pairs and it is independent of the architecture\nof the machine translation system.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 13:09:59 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Schwenk", "Holger", ""]]}, {"id": "1805.09843", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Guoyin Wang, Wenlin Wang, Martin Renqiang Min, Qinliang\n  Su, Yizhe Zhang, Chunyuan Li, Ricardo Henao, Lawrence Carin", "title": "Baseline Needs More Love: On Simple Word-Embedding-Based Models and\n  Associated Pooling Mechanisms", "comments": "To appear at ACL 2018 (code: https://github.com/dinghanshen/SWEM)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many deep learning architectures have been proposed to model the\ncompositionality in text sequences, requiring a substantial number of\nparameters and expensive computations. However, there has not been a rigorous\nevaluation regarding the added value of sophisticated compositional functions.\nIn this paper, we conduct a point-by-point comparative study between Simple\nWord-Embedding-based Models (SWEMs), consisting of parameter-free pooling\noperations, relative to word-embedding-based RNN/CNN models. Surprisingly,\nSWEMs exhibit comparable or even superior performance in the majority of cases\nconsidered. Based upon this understanding, we propose two additional pooling\nstrategies over learned word embeddings: (i) a max-pooling operation for\nimproved interpretability; and (ii) a hierarchical pooling operation, which\npreserves spatial (n-gram) information within text sequences. We present\nexperiments on 17 datasets encompassing three tasks: (i) (long) document\nclassification; (ii) text sequence matching; and (iii) short text tasks,\nincluding classification and tagging. The source code and datasets can be\nobtained from https:// github.com/dinghanshen/SWEM.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 18:27:21 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Shen", "Dinghan", ""], ["Wang", "Guoyin", ""], ["Wang", "Wenlin", ""], ["Min", "Martin Renqiang", ""], ["Su", "Qinliang", ""], ["Zhang", "Yizhe", ""], ["Li", "Chunyuan", ""], ["Henao", "Ricardo", ""], ["Carin", "Lawrence", ""]]}, {"id": "1805.09866", "submitter": "Fabio Massimo Zennaro", "authors": "Fabio Massimo Zennaro, Magdalena Ivanovska", "title": "Pooling of Causal Models under Counterfactual Fairness via Causal\n  Judgement Aggregation", "comments": "8 pages, 4 figures, workshop paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of combining multiple probabilistic\ncausal models, provided by different experts, under the requirement that the\naggregated model satisfy the criterion of counterfactual fairness. We build\nupon the work on causal models and fairness in machine learning, and we express\nthe problem of combining multiple models within the framework of opinion\npooling. We propose two simple algorithms, grounded in the theory of\ncounterfactual fairness and causal judgment aggregation, that are guaranteed to\ngenerate aggregated probabilistic causal models respecting the criterion of\nfairness, and we compare their behaviors on a toy case study.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 19:39:20 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 12:56:06 GMT"}], "update_date": "2018-10-02", "authors_parsed": [["Zennaro", "Fabio Massimo", ""], ["Ivanovska", "Magdalena", ""]]}, {"id": "1805.09880", "submitter": "Ronald de Haan", "authors": "Ronald de Haan, Iris van de Pol", "title": "On the Computational Complexity of Model Checking for Dynamic Epistemic\n  Logic with S5 Models", "comments": "To appear in the Journal of Applied Logics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic epistemic logic (DEL) is a logical framework for representing and\nreasoning about knowledge change for multiple agents. An important\ncomputational task in this framework is the model checking problem, which has\nbeen shown to be PSPACE-hard even for S5 models and two agents---in the\npresence of other features, such as multi-pointed models. We answer open\nquestions in the literature about the complexity of this problem in more\nrestricted settings. We provide a detailed complexity analysis of the model\nchecking problem for DEL, where we consider various combinations of\nrestrictions, such as the number of agents, whether the models are\nsingle-pointed or multi-pointed, and whether postconditions are allowed in the\nupdates. In particular, we show that the problem is already PSPACE-hard in (1)\nthe case of one agent, multi-pointed S5 models, and no postconditions, and (2)\nthe case of two agents, only single-pointed S5 models, and no postconditions.\nIn addition, we study the setting where only semi-private announcements are\nallowed as updates. We show that for this case the problem is already\nPSPACE-hard when restricted to two agents and three propositional variables.\nThe results that we obtain in this paper help outline the exact boundaries of\nthe restricted settings for which the model checking problem for DEL is\ncomputationally tractable.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 20:11:34 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2020 13:02:52 GMT"}], "update_date": "2020-09-21", "authors_parsed": [["de Haan", "Ronald", ""], ["van de Pol", "Iris", ""]]}, {"id": "1805.09901", "submitter": "Oktay Gunluk", "authors": "Sanjeeb Dash, Oktay G\\\"unl\\\"uk and Dennis Wei", "title": "Boolean Decision Rules via Column Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the learning of Boolean rules in either disjunctive\nnormal form (DNF, OR-of-ANDs, equivalent to decision rule sets) or conjunctive\nnormal form (CNF, AND-of-ORs) as an interpretable model for classification. An\ninteger program is formulated to optimally trade classification accuracy for\nrule simplicity. Column generation (CG) is used to efficiently search over an\nexponential number of candidate clauses (conjunctions or disjunctions) without\nthe need for heuristic rule mining. This approach also bounds the gap between\nthe selected rule set and the best possible rule set on the training data. To\nhandle large datasets, we propose an approximate CG algorithm using\nrandomization. Compared to three recently proposed alternatives, the CG\nalgorithm dominates the accuracy-simplicity trade-off in 7 out of 15 datasets.\nWhen maximized for accuracy, CG is competitive with rule learners designed for\nthis purpose, sometimes finding significantly simpler solutions that are no\nless accurate.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 21:12:26 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2020 23:11:57 GMT"}], "update_date": "2020-08-07", "authors_parsed": [["Dash", "Sanjeeb", ""], ["G\u00fcnl\u00fck", "Oktay", ""], ["Wei", "Dennis", ""]]}, {"id": "1805.09938", "submitter": "Francesco Leofante", "authors": "Francesco Leofante, Nina Narodytska, Luca Pulina, Armando Tacchella", "title": "Automated Verification of Neural Networks: Advances, Challenges and\n  Perspectives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are one of the most investigated and widely used techniques\nin Machine Learning. In spite of their success, they still find limited\napplication in safety- and security-related contexts, wherein assurance about\nnetworks' performances must be provided. In the recent past, automated\nreasoning techniques have been proposed by several researchers to close the gap\nbetween neural networks and applications requiring formal guarantees about\ntheir behavior. In this work, we propose a primer of such techniques and a\ncomprehensive categorization of existing approaches for the automated\nverification of neural networks. A discussion about current limitations and\ndirections for future investigation is provided to foster research on this\ntopic at the crossroads of Machine Learning and Automated Reasoning.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 00:19:57 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Leofante", "Francesco", ""], ["Narodytska", "Nina", ""], ["Pulina", "Luca", ""], ["Tacchella", "Armando", ""]]}, {"id": "1805.09951", "submitter": "Bingxin Zhang", "authors": "Hossein Rastgoftar, Bingxin Zhang, Ella M. Atkins", "title": "A Data-Driven Approach for Autonomous Motion Planning and Control in\n  Off-Road Driving Scenarios", "comments": "8 pages, 9 figures, this paper will appear in the 2018 American\n  Control Conference(ACC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel data-driven approach to vehicle motion planning\nand control in off-road driving scenarios. For autonomous off-road driving,\nenvironmental conditions impact terrain traversability as a function of\nweather, surface composition, and slope. Geographical information system (GIS)\nand National Centers for Environmental Information datasets are processed to\nprovide this information for interactive planning and control system elements.\nA top-level global route planner (GRP) defines optimal waypoints using dynamic\nprogramming (DP). A local path planner (LPP) computes a desired trajectory\nbetween waypoints such that infeasible control states and collisions with\nobstacles are avoided. The LPP also updates the GRP with real-time sensing and\ncontrol data. A low-level feedback controller applies feedback linearization to\nasymptotically track the specified LPP trajectory. Autonomous driving\nsimulation results are presented for traversal of terrains in Oregon and\nIndiana case studies.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 02:13:54 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Rastgoftar", "Hossein", ""], ["Zhang", "Bingxin", ""], ["Atkins", "Ella M.", ""]]}, {"id": "1805.09964", "submitter": "Kirthevasan Kandasamy", "authors": "Kirthevasan Kandasamy, Willie Neiswanger, Reed Zhang, Akshay\n  Krishnamurthy, Jeff Schneider, Barnabas Poczos", "title": "Myopic Bayesian Design of Experiments via Posterior Sampling and\n  Probabilistic Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design a new myopic strategy for a wide class of sequential design of\nexperiment (DOE) problems, where the goal is to collect data in order to to\nfulfil a certain problem specific goal. Our approach, Myopic Posterior Sampling\n(MPS), is inspired by the classical posterior (Thompson) sampling algorithm for\nmulti-armed bandits and leverages the flexibility of probabilistic programming\nand approximate Bayesian inference to address a broad set of problems.\nEmpirically, this general-purpose strategy is competitive with more specialised\nmethods in a wide array of DOE tasks, and more importantly, enables addressing\ncomplex DOE goals where no existing method seems applicable. On the theoretical\nside, we leverage ideas from adaptive submodularity and reinforcement learning\nto derive conditions under which MPS achieves sublinear regret against natural\nbenchmark policies.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 03:36:09 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Kandasamy", "Kirthevasan", ""], ["Neiswanger", "Willie", ""], ["Zhang", "Reed", ""], ["Krishnamurthy", "Akshay", ""], ["Schneider", "Jeff", ""], ["Poczos", "Barnabas", ""]]}, {"id": "1805.09975", "submitter": "Daniel McDuff", "authors": "Daniel McDuff and Ashish Kapoor", "title": "Visceral Machines: Risk-Aversion in Reinforcement Learning with\n  Intrinsic Physiological Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As people learn to navigate the world, autonomic nervous system (e.g., \"fight\nor flight\") responses provide intrinsic feedback about the potential\nconsequence of action choices (e.g., becoming nervous when close to a cliff\nedge or driving fast around a bend.) Physiological changes are correlated with\nthese biological preparations to protect one-self from danger. We present a\nnovel approach to reinforcement learning that leverages a task-independent\nintrinsic reward function trained on peripheral pulse measurements that are\ncorrelated with human autonomic nervous system responses. Our hypothesis is\nthat such reward functions can circumvent the challenges associated with sparse\nand skewed rewards in reinforcement learning settings and can help improve\nsample efficiency. We test this in a simulated driving environment and show\nthat it can increase the speed of learning and reduce the number of collisions\nduring the learning stage.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 04:22:31 GMT"}, {"version": "v2", "created": "Fri, 22 Mar 2019 03:30:42 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["McDuff", "Daniel", ""], ["Kapoor", "Ashish", ""]]}, {"id": "1805.09979", "submitter": "Armin Haller", "authors": "Krzysztof Janowicz, Armin Haller, Simon J D Cox, Danh Le Phuoc, Maxime\n  Lefrancois", "title": "SOSA: A Lightweight Ontology for Sensors, Observations, Samples, and\n  Actuators", "comments": null, "journal-ref": "Journal of Web Semantics, 2018", "doi": "10.1016/j.websem.2018.06.003", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Sensor, Observation, Sample, and Actuator (SOSA) ontology provides a\nformal but lightweight general-purpose specification for modeling the\ninteraction between the entities involved in the acts of observation,\nactuation, and sampling. SOSA is the result of rethinking the W3C-XG Semantic\nSensor Network (SSN) ontology based on changes in scope and target audience,\ntechnical developments, and lessons learned over the past years. SOSA also acts\nas a replacement of SSN's Stimulus Sensor Observation (SSO) core. It has been\ndeveloped by the first joint working group of the Open Geospatial Consortium\n(OGC) and the World Wide Web Consortium (W3C) on \\emph{Spatial Data on the\nWeb}. In this work, we motivate the need for SOSA, provide an overview of the\nmain classes and properties, and briefly discuss its integration with the new\nrelease of the SSN ontology as well as various other alignments to\nspecifications such as OGC's Observations and Measurements (O\\&M),\nDolce-Ultralite (DUL), and other prominent ontologies. We will also touch upon\ncommon modeling problems and application areas related to publishing and\nsearching observation, sampling, and actuation data on the Web. The SOSA\nontology and standard can be accessed at\n\\url{https://www.w3.org/TR/vocab-ssn/}.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 04:41:54 GMT"}, {"version": "v2", "created": "Tue, 25 Dec 2018 10:13:53 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Janowicz", "Krzysztof", ""], ["Haller", "Armin", ""], ["Cox", "Simon J D", ""], ["Phuoc", "Danh Le", ""], ["Lefrancois", "Maxime", ""]]}, {"id": "1805.09980", "submitter": "Lingfei Wu", "authors": "Xiaojie Guo, Lingfei Wu, and Liang Zhao", "title": "Deep Graph Translation", "comments": "9 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the tremendous success of deep generative models on generating\ncontinuous data like image and audio, in the most recent year, few deep graph\ngenerative models have been proposed to generate discrete data such as graphs.\nThey are typically unconditioned generative models which has no control on\nmodes of the graphs being generated. Differently, in this paper, we are\ninterested in a new problem named \\emph{Deep Graph Translation}: given an input\ngraph, we want to infer a target graph based on their underlying (both global\nand local) translation mapping. Graph translation could be highly desirable in\nmany applications such as disaster management and rare event forecasting, where\nthe rare and abnormal graph patterns (e.g., traffic congestions and terrorism\nevents) will be inferred prior to their occurrence even without historical data\non the abnormal patterns for this graph (e.g., a road network or human contact\nnetwork). To achieve this, we propose a novel Graph-Translation-Generative\nAdversarial Networks (GT-GAN) which will generate a graph translator from input\nto target graphs. GT-GAN consists of a graph translator where we propose new\ngraph convolution and deconvolution layers to learn the global and local\ntranslation mapping. A new conditional graph discriminator has also been\nproposed to classify target graphs by conditioning on input graphs. Extensive\nexperiments on multiple synthetic and real-world datasets demonstrate the\neffectiveness and scalability of the proposed GT-GAN.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 04:56:07 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 16:06:37 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["Guo", "Xiaojie", ""], ["Wu", "Lingfei", ""], ["Zhao", "Liang", ""]]}, {"id": "1805.10000", "submitter": "Yang Yu", "authors": "Jing-Cheng Shi, Yang Yu, Qing Da, Shi-Yong Chen, An-Xiang Zeng", "title": "Virtual-Taobao: Virtualizing Real-world Online Retail Environment for\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applying reinforcement learning in physical-world tasks is extremely\nchallenging. It is commonly infeasible to sample a large number of trials, as\nrequired by current reinforcement learning methods, in a physical environment.\nThis paper reports our project on using reinforcement learning for better\ncommodity search in Taobao, one of the largest online retail platforms and\nmeanwhile a physical environment with a high sampling cost. Instead of training\nreinforcement learning in Taobao directly, we present our approach: first we\nbuild Virtual Taobao, a simulator learned from historical customer behavior\ndata through the proposed GAN-SD (GAN for Simulating Distributions) and MAIL\n(multi-agent adversarial imitation learning), and then we train policies in\nVirtual Taobao with no physical costs in which ANC (Action Norm Constraint)\nstrategy is proposed to reduce over-fitting. In experiments, Virtual Taobao is\ntrained from hundreds of millions of customers' records, and its properties are\ncompared with the real environment. The results disclose that Virtual Taobao\nfaithfully recovers important properties of the real environment. We also show\nthat the policies trained in Virtual Taobao can have significantly superior\nonline performance to the traditional supervised approaches. We hope our work\ncould shed some light on reinforcement learning applications in complex\nphysical environments.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 06:39:31 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Shi", "Jing-Cheng", ""], ["Yu", "Yang", ""], ["Da", "Qing", ""], ["Chen", "Shi-Yong", ""], ["Zeng", "An-Xiang", ""]]}, {"id": "1805.10005", "submitter": "Haifang Li", "authors": "Haifang Li, Yingce Xia and Wensheng Zhang", "title": "Finite Sample Analysis of LSTD with Random Projections and Eligibility\n  Traces", "comments": "IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy evaluation with linear function approximation is an important problem\nin reinforcement learning. When facing high-dimensional feature spaces, such a\nproblem becomes extremely hard considering the computation efficiency and\nquality of approximations. We propose a new algorithm, LSTD($\\lambda$)-RP,\nwhich leverages random projection techniques and takes eligibility traces into\nconsideration to tackle the above two challenges. We carry out theoretical\nanalysis of LSTD($\\lambda$)-RP, and provide meaningful upper bounds of the\nestimation error, approximation error and total generalization error. These\nresults demonstrate that LSTD($\\lambda$)-RP can benefit from random projection\nand eligibility traces strategies, and LSTD($\\lambda$)-RP can achieve better\nperformances than prior LSTD-RP and LSTD($\\lambda$) algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 07:04:42 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Li", "Haifang", ""], ["Xia", "Yingce", ""], ["Zhang", "Wensheng", ""]]}, {"id": "1805.10123", "submitter": "Boris Oreshkin N", "authors": "Boris N. Oreshkin and Pau Rodriguez and Alexandre Lacoste", "title": "TADAM: Task dependent adaptive metric for improved few-shot learning", "comments": null, "journal-ref": "Advances in Neural Information Processing Systems 31, 2018", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning has become essential for producing models that generalize\nfrom few examples. In this work, we identify that metric scaling and metric\ntask conditioning are important to improve the performance of few-shot\nalgorithms. Our analysis reveals that simple metric scaling completely changes\nthe nature of few-shot algorithm parameter updates. Metric scaling provides\nimprovements up to 14% in accuracy for certain metrics on the mini-Imagenet\n5-way 5-shot classification task. We further propose a simple and effective way\nof conditioning a learner on the task sample set, resulting in learning a\ntask-dependent metric space. Moreover, we propose and empirically test a\npractical end-to-end optimization procedure based on auxiliary task co-training\nto learn a task-dependent metric space. The resulting few-shot learning model\nbased on the task-dependent scaled metric achieves state of the art on\nmini-Imagenet. We confirm these results on another few-shot dataset that we\nintroduce in this paper based on CIFAR100. Our code is publicly available at\nhttps://github.com/ElementAI/TADAM.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 20:17:59 GMT"}, {"version": "v2", "created": "Mon, 28 May 2018 22:42:57 GMT"}, {"version": "v3", "created": "Tue, 6 Nov 2018 14:36:12 GMT"}, {"version": "v4", "created": "Fri, 25 Jan 2019 18:47:30 GMT"}], "update_date": "2019-01-28", "authors_parsed": [["Oreshkin", "Boris N.", ""], ["Rodriguez", "Pau", ""], ["Lacoste", "Alexandre", ""]]}, {"id": "1805.10129", "submitter": "Ryan Faulkner", "authors": "Ryan Faulkner, Doina Precup", "title": "Dyna Planning using a Feature Based Generative Model", "comments": "8 pages, 7 figures", "journal-ref": "24th Annual Proceedings of the Advances in Neural Information\n  Processing Systems (2010) pp. 1-9", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dyna-style reinforcement learning is a powerful approach for problems where\nnot much real data is available. The main idea is to supplement real\ntrajectories, or sequences of sampled states over time, with simulated ones\nsampled from a learned model of the environment. However, in large state\nspaces, the problem of learning a good generative model of the environment has\nbeen open so far. We propose to use deep belief networks to learn an\nenvironment model for use in Dyna. We present our approach and validate it\nempirically on problems where the state observations consist of images. Our\nresults demonstrate that using deep belief networks, which are full generative\nmodels, significantly outperforms the use of linear expectation models,\nproposed in Sutton et al. (2008)\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 23:23:34 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Faulkner", "Ryan", ""], ["Precup", "Doina", ""]]}, {"id": "1805.10174", "submitter": "Stylianos Venieris", "authors": "Stylianos I. Venieris and Christos-Savvas Bouganis", "title": "f-CNN$^{\\text{x}}$: A Toolflow for Mapping Multi-CNN Applications on\n  FPGAs", "comments": "Accepted at the 28th International Conference on Field Programmable\n  Logic & Applications (FPL) 2018", "journal-ref": null, "doi": "10.1109/FPL.2018.00072", "report-no": null, "categories": "cs.CV cs.AI cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predictive power of Convolutional Neural Networks (CNNs) has been an\nintegral factor for emerging latency-sensitive applications, such as autonomous\ndrones and vehicles. Such systems employ multiple CNNs, each one trained for a\nparticular task. The efficient mapping of multiple CNNs on a single FPGA device\nis a challenging task as the allocation of compute resources and external\nmemory bandwidth needs to be optimised at design time. This paper proposes\nf-CNN$^{\\text{x}}$, an automated toolflow for the optimised mapping of multiple\nCNNs on FPGAs, comprising a novel multi-CNN hardware architecture together with\nan automated design space exploration method that considers the user-specified\nperformance requirements for each model to allocate compute resources and\ngenerate a synthesisable accelerator. Moreover, f-CNN$^{\\text{x}}$ employs a\nnovel scheduling algorithm that alleviates the limitations of the memory\nbandwidth contention between CNNs and sustains the high utilisation of the\narchitecture. Experimental evaluation shows that f-CNN$^{\\text{x}}$'s designs\noutperform contention-unaware FPGA mappings by up to 50% and deliver up to 6.8x\nhigher performance-per-Watt over highly optimised GPU designs for multi-CNN\nsystems.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 14:25:18 GMT"}, {"version": "v2", "created": "Mon, 7 Jun 2021 20:16:36 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Venieris", "Stylianos I.", ""], ["Bouganis", "Christos-Savvas", ""]]}, {"id": "1805.10255", "submitter": "Manoj Kumar", "authors": "Manoj Kumar, George E. Dahl, Vijay Vasudevan, Mohammad Norouzi", "title": "Parallel Architecture and Hyperparameter Search via Successive Halving\n  and Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple and powerful algorithm for parallel black box\noptimization called Successive Halving and Classification (SHAC). The algorithm\noperates in $K$ stages of parallel function evaluations and trains a cascade of\nbinary classifiers to iteratively cull the undesirable regions of the search\nspace. SHAC is easy to implement, requires no tuning of its own configuration\nparameters, is invariant to the scale of the objective function and can be\nbuilt using any choice of binary classifier. We adopt tree-based classifiers\nwithin SHAC and achieve competitive performance against several strong\nbaselines for optimizing synthetic functions, hyperparameters and\narchitectures.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 17:12:38 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Kumar", "Manoj", ""], ["Dahl", "George E.", ""], ["Vasudevan", "Vijay", ""], ["Norouzi", "Mohammad", ""]]}, {"id": "1805.10354", "submitter": "Rolando Estrada", "authors": "Blake Camp, Jaya Krishna Mandivarapu, Rolando Estrada", "title": "Self-Net: Lifelong Learning via Continual Self-Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning a set of tasks over time, also known as continual learning (CL), is\none of the most challenging problems in artificial intelligence. While recent\napproaches achieve some degree of CL in deep neural networks, they either (1)\ngrow the network parameters linearly with the number of tasks, (2) require\nstoring training data from previous tasks, or (3) restrict the network's\nability to learn new tasks. To address these issues, we propose a novel\nframework, Self-Net, that uses an autoencoder to learn a set of low-dimensional\nrepresentations of the weights learned for different tasks. We demonstrate that\nthese low-dimensional vectors can then be used to generate high-fidelity\nrecollections of the original weights. Self-Net can incorporate new tasks over\ntime with little retraining and with minimal loss in performance for older\ntasks. Our system does not require storing prior training data and its\nparameters grow only logarithmically with the number of tasks. We show that our\ntechnique outperforms current state-of-the-art approaches on numerous\ndatasets---including continual versions of MNIST, CIFAR10, CIFAR100, and\nAtari---and we demonstrate that our method can achieve over 10X storage\ncompression in a continual fashion. To the best of our knowledge, we are the\nfirst to use autoencoders to sequentially encode sets of network weights to\nenable continual learning.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 20:24:45 GMT"}, {"version": "v2", "created": "Wed, 5 Dec 2018 21:37:07 GMT"}, {"version": "v3", "created": "Fri, 12 Jul 2019 01:05:46 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Camp", "Blake", ""], ["Mandivarapu", "Jaya Krishna", ""], ["Estrada", "Rolando", ""]]}, {"id": "1805.10364", "submitter": "Hojjat Aghakhani", "authors": "Hojjat Aghakhani, Aravind Machiry, Shirin Nilizadeh, Christopher\n  Kruegel, and Giovanni Vigna", "title": "Detecting Deceptive Reviews using Generative Adversarial Networks", "comments": "accepted at 1st Deep Learning and Security Workshop co-located with\n  the 39th IEEE Symposium on Security and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, consumer review sites have become the main target of\ndeceptive opinion spam, where fictitious opinions or reviews are deliberately\nwritten to sound authentic. Most of the existing work to detect the deceptive\nreviews focus on building supervised classifiers based on syntactic and lexical\npatterns of an opinion. With the successful use of Neural Networks on various\nclassification applications, in this paper, we propose FakeGAN a system that\nfor the first time augments and adopts Generative Adversarial Networks (GANs)\nfor a text classification task, in particular, detecting deceptive reviews.\nUnlike standard GAN models which have a single Generator and Discriminator\nmodel, FakeGAN uses two discriminator models and one generative model. The\ngenerator is modeled as a stochastic policy agent in reinforcement learning\n(RL), and the discriminators use Monte Carlo search algorithm to estimate and\npass the intermediate action-value as the RL reward to the generator. Providing\nthe generator model with two discriminator models avoids the mod collapse issue\nby learning from both distributions of truthful and deceptive reviews. Indeed,\nour experiments show that using two discriminators provides FakeGAN high\nstability, which is a known issue for GAN architectures. While FakeGAN is built\nupon a semi-supervised classifier, known for less accuracy, our evaluation\nresults on a dataset of TripAdvisor hotel reviews show the same performance in\nterms of accuracy as of the state-of-the-art approaches that apply supervised\nmachine learning. These results indicate that GANs can be effective for text\nclassification tasks. Specifically, FakeGAN is effective at detecting deceptive\nreviews.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 21:06:56 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Aghakhani", "Hojjat", ""], ["Machiry", "Aravind", ""], ["Nilizadeh", "Shirin", ""], ["Kruegel", "Christopher", ""], ["Vigna", "Giovanni", ""]]}, {"id": "1805.10407", "submitter": "Sang Michael Xie", "authors": "Neal Jean, Sang Michael Xie, Stefano Ermon", "title": "Semi-supervised Deep Kernel Learning: Regression with Unlabeled Data by\n  Minimizing Predictive Variance", "comments": "In Proceedings of Neural Information Processing Systems (NeurIPS)\n  2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large amounts of labeled data are typically required to train deep learning\nmodels. For many real-world problems, however, acquiring additional data can be\nexpensive or even impossible. We present semi-supervised deep kernel learning\n(SSDKL), a semi-supervised regression model based on minimizing predictive\nvariance in the posterior regularization framework. SSDKL combines the\nhierarchical representation learning of neural networks with the probabilistic\nmodeling capabilities of Gaussian processes. By leveraging unlabeled data, we\nshow improvements on a diverse set of real-world regression tasks over\nsupervised deep kernel learning and semi-supervised methods such as VAT and\nmean teacher adapted for regression.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 00:47:14 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2018 00:36:05 GMT"}, {"version": "v3", "created": "Sat, 5 Jan 2019 18:41:06 GMT"}, {"version": "v4", "created": "Mon, 4 Mar 2019 18:55:13 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Jean", "Neal", ""], ["Xie", "Sang Michael", ""], ["Ermon", "Stefano", ""]]}, {"id": "1805.10408", "submitter": "Hanie Sedghi", "authors": "Hanie Sedghi, Vineet Gupta, Philip M. Long", "title": "The Singular Values of Convolutional Layers", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We characterize the singular values of the linear transformation associated\nwith a standard 2D multi-channel convolutional layer, enabling their efficient\ncomputation. This characterization also leads to an algorithm for projecting a\nconvolutional layer onto an operator-norm ball. We show that this is an\neffective regularizer; for example, it improves the test error of a deep\nresidual network using batch normalization on CIFAR-10 from 6.2\\% to 5.3\\%.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 00:49:27 GMT"}, {"version": "v2", "created": "Wed, 6 Mar 2019 00:06:27 GMT"}], "update_date": "2019-03-07", "authors_parsed": [["Sedghi", "Hanie", ""], ["Gupta", "Vineet", ""], ["Long", "Philip M.", ""]]}, {"id": "1805.10461", "submitter": "V\\'ictor Guti\\'errez-Basulto", "authors": "V\\'ictor Guti\\'errez-Basulto and Steven Schockaert", "title": "From Knowledge Graph Embedding to Ontology Embedding? An Analysis of the\n  Compatibility between Vector Space Representations and Rules", "comments": "Full version of a paper accepted at KR-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the successful application of low-dimensional\nvector space representations of knowledge graphs to predict missing facts or\nfind erroneous ones. However, it is not yet well-understood to what extent\nontological knowledge, e.g. given as a set of (existential) rules, can be\nembedded in a principled way. To address this shortcoming, in this paper we\nintroduce a general framework based on a view of relations as regions, which\nallows us to study the compatibility between ontological knowledge and\ndifferent types of vector space embeddings. Our technical contribution is\ntwo-fold. First, we show that some of the most popular existing embedding\nmethods are not capable of modelling even very simple types of rules, which in\nparticular also means that they are not able to learn the type of dependencies\ncaptured by such rules. Second, we study a model in which relations are\nmodelled as convex regions. We show particular that ontologies which are\nexpressed using so-called quasi-chained existential rules can be exactly\nrepresented using convex regions, such that any set of facts which is induced\nusing that vector space embedding is logically consistent and deductively\nclosed with respect to the input ontology.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 10:56:47 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 05:35:21 GMT"}, {"version": "v3", "created": "Tue, 21 Aug 2018 14:21:04 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Guti\u00e9rrez-Basulto", "V\u00edctor", ""], ["Schockaert", "Steven", ""]]}, {"id": "1805.10503", "submitter": "Pengfei Zhang", "authors": "Ning Sun, Jinmin Yi, Pengfei Zhang, Huitao Shen and Hui Zhai", "title": "Deep Learning Topological Invariants of Band Insulators", "comments": "8 pages, 5 figures", "journal-ref": "Phys. Rev. B 98, 085402 (2018)", "doi": "10.1103/PhysRevB.98.085402", "report-no": null, "categories": "cond-mat.str-el cs.AI cs.LG physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we design and train deep neural networks to predict topological\ninvariants for one-dimensional four-band insulators in AIII class whose\ntopological invariant is the winding number, and two-dimensional two-band\ninsulators in A class whose topological invariant is the Chern number. Given\nHamiltonians in the momentum space as the input, neural networks can predict\ntopological invariants for both classes with accuracy close to or higher than\n90%, even for Hamiltonians whose invariants are beyond the training data set.\nDespite the complexity of the neural network, we find that the output of\ncertain intermediate hidden layers resembles either the winding angle for\nmodels in AIII class or the solid angle (Berry curvature) for models in A\nclass, indicating that neural networks essentially capture the mathematical\nformula of topological invariants. Our work demonstrates the ability of neural\nnetworks to predict topological invariants for complicated models with local\nHamiltonians as the only input, and offers an example that even a deep neural\nnetwork is understandable.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 16:10:47 GMT"}, {"version": "v2", "created": "Sat, 9 Jun 2018 10:48:10 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Sun", "Ning", ""], ["Yi", "Jinmin", ""], ["Zhang", "Pengfei", ""], ["Shen", "Huitao", ""], ["Zhai", "Hui", ""]]}, {"id": "1805.10528", "submitter": "Reza Ghaeini", "authors": "Reza Ghaeini, Xiaoli Z. Fern, Hamed Shahbazi, Prasad Tadepalli", "title": "Dependent Gated Reading for Cloze-Style Question Answering", "comments": "Accepted as a long paper at COLING 2018, 16 pages, 12 figures", "journal-ref": "COLING 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel deep learning architecture to address the cloze-style\nquestion answering task. Existing approaches employ reading mechanisms that do\nnot fully exploit the interdependency between the document and the query. In\nthis paper, we propose a novel \\emph{dependent gated reading} bidirectional GRU\nnetwork (DGR) to efficiently model the relationship between the document and\nthe query during encoding and decision making. Our evaluation shows that DGR\nobtains highly competitive performance on well-known machine comprehension\nbenchmarks such as the Children's Book Test (CBT-NE and CBT-CN) and Who DiD\nWhat (WDW, Strict and Relaxed). Finally, we extensively analyze and validate\nour model by ablation and attention studies.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 19:26:35 GMT"}, {"version": "v2", "created": "Fri, 1 Jun 2018 21:38:49 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Ghaeini", "Reza", ""], ["Fern", "Xiaoli Z.", ""], ["Shahbazi", "Hamed", ""], ["Tadepalli", "Prasad", ""]]}, {"id": "1805.10548", "submitter": "Ismail Elezi", "authors": "Lukas Tuggener, Ismail Elezi, Jurgen Schmidhuber and Thilo Stadelmann", "title": "Deep Watershed Detector for Music Object Recognition", "comments": "Accepted on The 19th International Society for Music Information\n  Retrieval Conference 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical Music Recognition (OMR) is an important and challenging area within\nmusic information retrieval, the accurate detection of music symbols in digital\nimages is a core functionality of any OMR pipeline. In this paper, we introduce\na novel object detection method, based on synthetic energy maps and the\nwatershed transform, called Deep Watershed Detector (DWD). Our method is\nspecifically tailored to deal with high resolution images that contain a large\nnumber of very small objects and is therefore able to process full pages of\nwritten music. We present state-of-the-art detection results of common music\nsymbols and show DWD's ability to work with synthetic scores equally well as on\nhandwritten music.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 22:13:16 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Tuggener", "Lukas", ""], ["Elezi", "Ismail", ""], ["Schmidhuber", "Jurgen", ""], ["Stadelmann", "Thilo", ""]]}, {"id": "1805.10582", "submitter": "Sen Zhao", "authors": "Sen Zhao, Mahdi Milani Fard, Harikrishna Narasimhan and Maya Gupta", "title": "Metric-Optimized Example Weights", "comments": "Proceedings of the 36th International Conference on Machine Learning\n  (ICML'19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world machine learning applications often have complex test metrics, and\nmay have training and test data that are not identically distributed. Motivated\nby known connections between complex test metrics and cost-weighted learning,\nwe propose addressing these issues by using a weighted loss function with a\nstandard loss, where the weights on the training examples are learned to\noptimize the test metric on a validation set. These metric-optimized example\nweights can be learned for any test metric, including black box and customized\nones for specific applications. We illustrate the performance of the proposed\nmethod on diverse public benchmark datasets and real-world applications. We\nalso provide a generalization bound for the method.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 06:12:50 GMT"}, {"version": "v2", "created": "Fri, 17 May 2019 06:13:30 GMT"}, {"version": "v3", "created": "Sat, 15 Jun 2019 19:09:40 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Zhao", "Sen", ""], ["Fard", "Mahdi Milani", ""], ["Narasimhan", "Harikrishna", ""], ["Gupta", "Maya", ""]]}, {"id": "1805.10587", "submitter": "Jiewen Wu", "authors": "Freddy Lecue and Jiewen Wu", "title": "Semantic Explanations of Predictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main objective of explanations is to transmit knowledge to humans. This\nwork proposes to construct informative explanations for predictions made from\nmachine learning models. Motivated by the observations from social sciences,\nour approach selects data points from the training sample that exhibit special\ncharacteristics crucial for explanation, for instance, ones contrastive to the\nclassification prediction and ones representative of the models. Subsequently,\nsemantic concepts are derived from the selected data points through the use of\ndomain ontologies. These concepts are filtered and ranked to produce\ninformative explanations that improves human understanding. The main features\nof our approach are that (1) knowledge about explanations is captured in the\nform of ontological concepts, (2) explanations include contrastive evidences in\naddition to normal evidences, and (3) explanations are user relevant.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 06:55:15 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Lecue", "Freddy", ""], ["Wu", "Jiewen", ""]]}, {"id": "1805.10636", "submitter": "Federico Errica", "authors": "Davide Bacciu, Federico Errica, Alessio Micheli", "title": "Contextual Graph Markov Model: A Deep and Generative Approach to Graph\n  Processing", "comments": null, "journal-ref": "Proceedings of the 35th International Conference on Machine\n  Learning, PMLR 80 (2018) 294-303", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the Contextual Graph Markov Model, an approach combining ideas\nfrom generative models and neural networks for the processing of graph data. It\nfounds on a constructive methodology to build a deep architecture comprising\nlayers of probabilistic models that learn to encode the structured information\nin an incremental fashion. Context is diffused in an efficient and scalable way\nacross the graph vertexes and edges. The resulting graph encoding is used in\ncombination with discriminative models to address structure classification\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 15:04:05 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 09:45:51 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Bacciu", "Davide", ""], ["Errica", "Federico", ""], ["Micheli", "Alessio", ""]]}, {"id": "1805.10662", "submitter": "Supratik Paul", "authors": "Supratik Paul, Michael A. Osborne, Shimon Whiteson", "title": "Fingerprint Policy Optimisation for Robust Reinforcement Learning", "comments": "ICML 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Policy gradient methods ignore the potential value of adjusting environment\nvariables: unobservable state features that are randomly determined by the\nenvironment in a physical setting, but are controllable in a simulator. This\ncan lead to slow learning, or convergence to suboptimal policies, if the\nenvironment variable has a large impact on the transition dynamics. In this\npaper, we present fingerprint policy optimisation (FPO), which finds a policy\nthat is optimal in expectation across the distribution of environment\nvariables. The central idea is to use Bayesian optimisation (BO) to actively\nselect the distribution of the environment variable that maximises the\nimprovement generated by each iteration of the policy gradient method. To make\nthis BO practical, we contribute two easy-to-compute low-dimensional\nfingerprints of the current policy. Our experiments show that FPO can\nefficiently learn policies that are robust to significant rare events, which\nare unlikely to be observable under random sampling, but are key to learning\ngood policies.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 17:50:22 GMT"}, {"version": "v2", "created": "Sat, 15 Sep 2018 14:20:57 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 14:07:49 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Paul", "Supratik", ""], ["Osborne", "Michael A.", ""], ["Whiteson", "Shimon", ""]]}, {"id": "1805.10672", "submitter": "Ali Shakiba", "authors": "Ali Shakiba, Amir Kafshdar Goharshady, MohammadReza Hooshmandasl,\n  Mohsen Alambardar Meybodi", "title": "A note on belief structures and S-approximation spaces", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study relations between evidence theory and S-approximation spaces. Both\ntheories have their roots in the analysis of Dempster's multivalued mappings\nand lower and upper probabilities and have close relations to rough sets. We\nshow that an S-approximation space, satisfying a monotonicity condition, can\ninduce a natural belief structure which is a fundamental block in evidence\ntheory. We also demonstrate that one can induce a natural belief structure on\none set, given a belief structure on another set if those sets are related by a\npartial monotone S-approximation space.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 18:14:01 GMT"}, {"version": "v2", "created": "Sat, 2 Jun 2018 20:15:50 GMT"}, {"version": "v3", "created": "Sat, 23 Mar 2019 08:59:15 GMT"}, {"version": "v4", "created": "Sat, 28 Mar 2020 12:31:41 GMT"}], "update_date": "2020-03-31", "authors_parsed": [["Shakiba", "Ali", ""], ["Goharshady", "Amir Kafshdar", ""], ["Hooshmandasl", "MohammadReza", ""], ["Meybodi", "Mohsen Alambardar", ""]]}, {"id": "1805.10693", "submitter": "Chara Podimata", "authors": "Yiling Chen, Chara Podimata, Ariel D. Procaccia, Nisarg Shah", "title": "Strategyproof Linear Regression in High Dimensions", "comments": "In the Proceedings of the 19th ACM Conference on Economics and\n  Computation (EC), 2018 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is part of an emerging line of work at the intersection of machine\nlearning and mechanism design, which aims to avoid noise in training data by\ncorrectly aligning the incentives of data sources. Specifically, we focus on\nthe ubiquitous problem of linear regression, where strategyproof mechanisms\nhave previously been identified in two dimensions. In our setting, agents have\nsingle-peaked preferences and can manipulate only their response variables. Our\nmain contribution is the discovery of a family of group strategyproof linear\nregression mechanisms in any number of dimensions, which we call generalized\nresistant hyperplane mechanisms. The game-theoretic properties of these\nmechanisms -- and, in fact, their very existence -- are established through a\nconnection to a discrete version of the Ham Sandwich Theorem.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 21:31:56 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Chen", "Yiling", ""], ["Podimata", "Chara", ""], ["Procaccia", "Ariel D.", ""], ["Shah", "Nisarg", ""]]}, {"id": "1805.10723", "submitter": "VIctor Dibia", "authors": "Victor Dibia, Aaron Cox, Justin Weisz", "title": "Designing for Democratization: Introducing Novices to Artificial\n  Intelligence Via Maker Kits", "comments": "Early paper draft - Updated references, author list, figure captions,\n  acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing research highlight the myriad of benefits realized when technology\nis sufficiently democratized and made accessible to non-technical or novice\nusers. However, democratizing complex technologies such as artificial\nintelligence (AI) remains hard. In this work, we draw on theoretical\nunderpinnings from the democratization of innovation, in exploring the design\nof maker kits that help introduce novice users to complex technologies. We\nreport on our work designing TJBot: an open source cardboard robot that can be\nprogrammed using pre-built AI services. We highlight principles we adopted in\nthis process (approachable design, simplicity, extensibility and\naccessibility), insights we learned from showing the kit at workshops (66\nparticipants) and how users interacted with the project on GitHub over a\n12-month period (Nov 2016 - Nov 2017). We find that the project succeeds in\nattracting novice users (40% of users who forked the project are new to GitHub)\nand a variety of demographics are interested in prototyping use cases such as\nhome automation, task delegation, teaching and learning.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 01:30:04 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 19:31:37 GMT"}, {"version": "v3", "created": "Sat, 5 Jan 2019 20:11:55 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Dibia", "Victor", ""], ["Cox", "Aaron", ""], ["Weisz", "Justin", ""]]}, {"id": "1805.10768", "submitter": "Heonseok Ha", "authors": "Heonseok Ha, Uiwon Hwang, Yongjun Hong, Jahee Jang, Sungroh Yoon", "title": "Deep Trustworthy Knowledge Tracing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge tracing (KT), a key component of an intelligent tutoring system, is\na machine learning technique that estimates the mastery level of a student\nbased on his/her past performance. The objective of KT is to predict a\nstudent's response to the next question. Compared with traditional KT models,\ndeep learning-based KT (DLKT) models show better predictive performance because\nof the representation power of deep neural networks. Various methods have been\nproposed to improve the performance of DLKT, but few studies have been\nconducted on the reliability of DLKT. In this work, we claim that the existing\nDLKTs are not reliable in real education environments. To substantiate the\nclaim, we show limitations of DLKT from various perspectives such as knowledge\nstate update failure, catastrophic forgetting, and non-interpretability. We\nthen propose a novel regularization to address these problems. The proposed\nmethod allows us to achieve trustworthy DLKT. In addition, the proposed model\nwhich is trained on scenarios with forgetting can also be easily extended to\nscenarios without forgetting.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 04:50:24 GMT"}, {"version": "v2", "created": "Mon, 1 Oct 2018 02:56:16 GMT"}, {"version": "v3", "created": "Wed, 18 Sep 2019 04:49:53 GMT"}], "update_date": "2019-09-19", "authors_parsed": [["Ha", "Heonseok", ""], ["Hwang", "Uiwon", ""], ["Hong", "Yongjun", ""], ["Jang", "Jahee", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1805.10777", "submitter": "Liangqu Long", "authors": "Liangqu Long, Wei Wang, Jun Wen, Meihui Zhang, Qian Lin, Beng Chin Ooi", "title": "Object-Level Representation Learning for Few-Shot Image Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Few-shot learning that trains image classifiers over few labeled examples per\ncategory is a challenging task. In this paper, we propose to exploit an\nadditional big dataset with different categories to improve the accuracy of\nfew-shot learning over our target dataset. Our approach is based on the\nobservation that images can be decomposed into objects, which may appear in\nimages from both the additional dataset and our target dataset. We use the\nobject-level relation learned from the additional dataset to infer the\nsimilarity of images in our target dataset with unseen categories. Nearest\nneighbor search is applied to do image classification, which is a\nnon-parametric model and thus does not need fine-tuning. We evaluate our\nalgorithm on two popular datasets, namely Omniglot and MiniImagenet. We obtain\n8.5\\% and 2.7\\% absolute improvements for 5-way 1-shot and 5-way 5-shot\nexperiments on MiniImagenet, respectively. Source code will be published upon\nacceptance.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 05:46:17 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Long", "Liangqu", ""], ["Wang", "Wei", ""], ["Wen", "Jun", ""], ["Zhang", "Meihui", ""], ["Lin", "Qian", ""], ["Ooi", "Beng Chin", ""]]}, {"id": "1805.10795", "submitter": "Elad Tzoreff", "authors": "Elad Tzoreff, Olga Kogan and Yoni Choukroun", "title": "Deep Discriminative Latent Space for Clustering", "comments": "A version of this paper has been submitted to NIPS 2018. The paper\n  contains 9 pages including references, and 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is one of the most fundamental tasks in data analysis and machine\nlearning. It is central to many data-driven applications that aim to separate\nthe data into groups with similar patterns. Moreover, clustering is a complex\nprocedure that is affected significantly by the choice of the data\nrepresentation method. Recent research has demonstrated encouraging clustering\nresults by learning effectively these representations. In most of these works a\ndeep auto-encoder is initially pre-trained to minimize a reconstruction loss,\nand then jointly optimized with clustering centroids in order to improve the\nclustering objective. Those works focus mainly on the clustering phase of the\nprocedure, while not utilizing the potential benefit out of the initial phase.\nIn this paper we propose to optimize an auto-encoder with respect to a\ndiscriminative pairwise loss function during the auto-encoder pre-training\nphase. We demonstrate the high accuracy obtained by the proposed method as well\nas its rapid convergence (e.g. reaching above 92% accuracy on MNIST during the\npre-training phase, in less than 50 epochs), even with small networks.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 07:34:14 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Tzoreff", "Elad", ""], ["Kogan", "Olga", ""], ["Choukroun", "Yoni", ""]]}, {"id": "1805.10817", "submitter": "Nicola Pezzotti", "authors": "Nicola Pezzotti, Julian Thijssen, Alexander Mordvintsev, Thomas Hollt,\n  Baldur van Lew, Boudewijn P.F. Lelieveldt, Elmar Eisemann and Anna Vilanova", "title": "GPGPU Linear Complexity t-SNE Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The t-distributed Stochastic Neighbor Embedding (tSNE) algorithm has become\nin recent years one of the most used and insightful techniques for the\nexploratory data analysis of high-dimensional data. tSNE reveals clusters of\nhigh-dimensional data points at different scales while it requires only minimal\ntuning of its parameters. Despite these advantages, the computational\ncomplexity of the algorithm limits its application to relatively small\ndatasets. To address this problem, several evolutions of tSNE have been\ndeveloped in recent years, mainly focusing on the scalability of the similarity\ncomputations between data points. However, these contributions are insufficient\nto achieve interactive rates when visualizing the evolution of the tSNE\nembedding for large datasets. In this work, we present a novel approach to the\nminimization of the tSNE objective function that heavily relies on modern\ngraphics hardware and has linear computational complexity. Our technique does\nnot only beat the state of the art, but can even be executed on the client side\nin a browser. We propose to approximate the repulsion forces between data\npoints using adaptive-resolution textures that are drawn at every iteration\nwith WebGL. This approximation allows us to reformulate the tSNE minimization\nproblem as a series of tensor operation that are computed with TensorFlow.js, a\nJavaScript library for scalable tensor computations.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 08:49:46 GMT"}, {"version": "v2", "created": "Thu, 8 Aug 2019 20:45:40 GMT"}], "update_date": "2019-08-12", "authors_parsed": [["Pezzotti", "Nicola", ""], ["Thijssen", "Julian", ""], ["Mordvintsev", "Alexander", ""], ["Hollt", "Thomas", ""], ["van Lew", "Baldur", ""], ["Lelieveldt", "Boudewijn P. F.", ""], ["Eisemann", "Elmar", ""], ["Vilanova", "Anna", ""]]}, {"id": "1805.10820", "submitter": "Riccardo Guidotti", "authors": "Riccardo Guidotti, Anna Monreale, Salvatore Ruggieri, Dino Pedreschi,\n  Franco Turini, Fosca Giannotti", "title": "Local Rule-Based Explanations of Black Box Decision Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent years have witnessed the rise of accurate but obscure decision\nsystems which hide the logic of their internal decision processes to the users.\nThe lack of explanations for the decisions of black box systems is a key\nethical issue, and a limitation to the adoption of machine learning components\nin socially sensitive and safety-critical contexts. %Therefore, we need\nexplanations that reveals the reasons why a predictor takes a certain decision.\nIn this paper we focus on the problem of black box outcome explanation, i.e.,\nexplaining the reasons of the decision taken on a specific instance. We propose\nLORE, an agnostic method able to provide interpretable and faithful\nexplanations. LORE first leans a local interpretable predictor on a synthetic\nneighborhood generated by a genetic algorithm. Then it derives from the logic\nof the local interpretable predictor a meaningful explanation consisting of: a\ndecision rule, which explains the reasons of the decision; and a set of\ncounterfactual rules, suggesting the changes in the instance's features that\nlead to a different outcome. Wide experiments show that LORE outperforms\nexisting methods and baselines both in the quality of explanations and in the\naccuracy in mimicking the black box.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 08:56:40 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Guidotti", "Riccardo", ""], ["Monreale", "Anna", ""], ["Ruggieri", "Salvatore", ""], ["Pedreschi", "Dino", ""], ["Turini", "Franco", ""], ["Giannotti", "Fosca", ""]]}, {"id": "1805.10852", "submitter": "Chaehan So", "authors": "Chaehan So", "title": "A Pragmatic AI Approach to Creating Artistic Visual Variations by Neural\n  Style Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On a constant quest for inspiration, designers can become more effective with\ntools that facilitate their creative process and let them overcome design\nfixation. This paper explores the practicality of applying neural style\ntransfer as an emerging design tool for generating creative digital content. To\nthis aim, the present work explores a well-documented neural style transfer\nalgorithm (Johnson 2016) in four experiments on four relevant visual\nparameters: number of iterations, learning rate, total variation, content vs.\nstyle weight. The results allow a pragmatic recommendation of parameter\nconfiguration (number of iterations: 200 to 300, learning rate: 2e-1 to 4e-1,\ntotal variation: 1e-4 to 1e-8, content weights vs. style weights: 50:100 to\n200:100) that saves extensive experimentation time and lowers the technical\nentry barrier. With this rule-of-thumb insight, visual designers can\neffectively apply deep learning to create artistic visual variations of digital\ncontent. This could enable designers to leverage AI for creating design works\nas state-of-the-art.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 10:24:20 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["So", "Chaehan", ""]]}, {"id": "1805.10872", "submitter": "Robin Manhaeve", "authors": "Robin Manhaeve, Sebastijan Duman\\v{c}i\\'c, Angelika Kimmig, Thomas\n  Demeester, Luc De Raedt", "title": "DeepProbLog: Neural Probabilistic Logic Programming", "comments": "Accepted for spotlight at NeurIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce DeepProbLog, a probabilistic logic programming language that\nincorporates deep learning by means of neural predicates. We show how existing\ninference and learning techniques can be adapted for the new language. Our\nexperiments demonstrate that DeepProbLog supports both symbolic and subsymbolic\nrepresentations and inference, 1) program induction, 2) probabilistic (logic)\nprogramming, and 3) (deep) learning from examples. To the best of our\nknowledge, this work is the first to propose a framework where general-purpose\nneural networks and expressive probabilistic-logical modeling and reasoning are\nintegrated in a way that exploits the full expressiveness and strengths of both\nworlds and can be trained end-to-end based on examples.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 11:33:00 GMT"}, {"version": "v2", "created": "Wed, 12 Dec 2018 09:56:40 GMT"}], "update_date": "2018-12-13", "authors_parsed": [["Manhaeve", "Robin", ""], ["Duman\u010di\u0107", "Sebastijan", ""], ["Kimmig", "Angelika", ""], ["Demeester", "Thomas", ""], ["De Raedt", "Luc", ""]]}, {"id": "1805.10884", "submitter": "Gabriel Maicas", "authors": "Gabriel Maicas, Andrew P. Bradley, Jacinto C. Nascimento, Ian Reid,\n  Gustavo Carneiro", "title": "Training Medical Image Analysis Systems like Radiologists", "comments": "Oral Presentation at MICCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The training of medical image analysis systems using machine learning\napproaches follows a common script: collect and annotate a large dataset, train\nthe classifier on the training set, and test it on a hold-out test set. This\nprocess bears no direct resemblance with radiologist training, which is based\non solving a series of tasks of increasing difficulty, where each task involves\nthe use of significantly smaller datasets than those used in machine learning.\nIn this paper, we propose a novel training approach inspired by how\nradiologists are trained. In particular, we explore the use of meta-training\nthat models a classifier based on a series of tasks. Tasks are selected using\nteacher-student curriculum learning, where each task consists of simple\nclassification problems containing small training sets. We hypothesize that our\nproposed meta-training approach can be used to pre-train medical image analysis\nmodels. This hypothesis is tested on the automatic breast screening\nclassification from DCE-MRI trained with weakly labeled datasets. The\nclassification performance achieved by our approach is shown to be the best in\nthe field for that application, compared to state of art baseline approaches:\nDenseNet, multiple instance learning and multi-task learning.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 12:11:03 GMT"}, {"version": "v2", "created": "Tue, 12 Jun 2018 12:42:04 GMT"}, {"version": "v3", "created": "Mon, 4 Feb 2019 05:12:29 GMT"}], "update_date": "2019-02-05", "authors_parsed": [["Maicas", "Gabriel", ""], ["Bradley", "Andrew P.", ""], ["Nascimento", "Jacinto C.", ""], ["Reid", "Ian", ""], ["Carneiro", "Gustavo", ""]]}, {"id": "1805.10900", "submitter": "Richard Forster", "authors": "Richard Forster, Agnes Fulop", "title": "Hierarchical clustering with deep Q-learning", "comments": "Submitted for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The reconstruction and analyzation of high energy particle physics data is\njust as important as the analyzation of the structure in real world networks.\nIn a previous study it was explored how hierarchical clustering algorithms can\nbe combined with kt cluster algorithms to provide a more generic clusterization\nmethod. Building on that, this paper explores the possibilities to involve deep\nlearning in the process of cluster computation, by applying reinforcement\nlearning techniques. The result is a model, that by learning on a modest\ndataset of 10; 000 nodes during 70 epochs can reach 83; 77% precision in\npredicting the appropriate clusters.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 12:59:51 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Forster", "Richard", ""], ["Fulop", "Agnes", ""]]}, {"id": "1805.10956", "submitter": "Wenlin Yao", "authors": "Wenlin Yao and Ruihong Huang", "title": "Temporal Event Knowledge Acquisition via Identifying Narratives", "comments": "11 pages, accepted by ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by the double temporality characteristic of narrative texts, we\npropose a novel approach for acquiring rich temporal \"before/after\" event\nknowledge across sentences in narrative stories. The double temporality states\nthat a narrative story often describes a sequence of events following the\nchronological order and therefore, the temporal order of events matches with\ntheir textual order. We explored narratology principles and built a weakly\nsupervised approach that identifies 287k narrative paragraphs from three large\ntext corpora. We then extracted rich temporal event knowledge from these\nnarrative paragraphs. Such event knowledge is shown useful to improve temporal\nrelation classification and outperform several recent neural network models on\nthe narrative cloze task.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 14:51:27 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Yao", "Wenlin", ""], ["Huang", "Ruihong", ""]]}, {"id": "1805.10966", "submitter": "German I. Parisi", "authors": "German I. Parisi, Jun Tani, Cornelius Weber, Stefan Wermter", "title": "Lifelong Learning of Spatiotemporal Representations with Dual-Memory\n  Recurrent Self-Organization", "comments": null, "journal-ref": "Parisi GI, Tani J, Weber C and Wermter S (2018) Lifelong Learning\n  of Spatiotemporal Representations With Dual-Memory Recurrent\n  Self-Organization. Front. Neurorobot. 12:78", "doi": "10.3389/fnbot.2018.00078", "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Artificial autonomous agents and robots interacting in complex environments\nare required to continually acquire and fine-tune knowledge over sustained\nperiods of time. The ability to learn from continuous streams of information is\nreferred to as lifelong learning and represents a long-standing challenge for\nneural network models due to catastrophic forgetting. Computational models of\nlifelong learning typically alleviate catastrophic forgetting in experimental\nscenarios with given datasets of static images and limited complexity, thereby\ndiffering significantly from the conditions artificial agents are exposed to.\nIn more natural settings, sequential information may become progressively\navailable over time and access to previous experience may be restricted. In\nthis paper, we propose a dual-memory self-organizing architecture for lifelong\nlearning scenarios. The architecture comprises two growing recurrent networks\nwith the complementary tasks of learning object instances (episodic memory) and\ncategories (semantic memory). Both growing networks can expand in response to\nnovel sensory experience: the episodic memory learns fine-grained\nspatiotemporal representations of object instances in an unsupervised fashion\nwhile the semantic memory uses task-relevant signals to regulate structural\nplasticity levels and develop more compact representations from episodic\nexperience. For the consolidation of knowledge in the absence of external\nsensory input, the episodic memory periodically replays trajectories of neural\nreactivations. We evaluate the proposed model on the CORe50 benchmark dataset\nfor continuous object recognition, showing that we significantly outperform\ncurrent methods of lifelong learning in three different incremental learning\nscenarios\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 15:08:19 GMT"}, {"version": "v2", "created": "Mon, 24 Sep 2018 20:17:54 GMT"}, {"version": "v3", "created": "Tue, 30 Oct 2018 18:58:01 GMT"}, {"version": "v4", "created": "Wed, 19 Dec 2018 00:41:53 GMT"}], "update_date": "2018-12-20", "authors_parsed": [["Parisi", "German I.", ""], ["Tani", "Jun", ""], ["Weber", "Cornelius", ""], ["Wermter", "Stefan", ""]]}, {"id": "1805.11004", "submitter": "Han Guo", "authors": "Han Guo, Ramakanth Pasunuru, Mohit Bansal", "title": "Soft Layer-Specific Multi-Task Summarization with Entailment and\n  Question Generation", "comments": "ACL 2018 (16 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An accurate abstractive summary of a document should contain all its salient\ninformation and should be logically entailed by the input document. We improve\nthese important aspects of abstractive summarization via multi-task learning\nwith the auxiliary tasks of question generation and entailment generation,\nwhere the former teaches the summarization model how to look for salient\nquestioning-worthy details, and the latter teaches the model how to rewrite a\nsummary which is a directed-logical subset of the input document. We also\npropose novel multi-task architectures with high-level (semantic)\nlayer-specific sharing across multiple encoder and decoder layers of the three\ntasks, as well as soft-sharing mechanisms (and show performance ablations and\nanalysis examples of each contribution). Overall, we achieve statistically\nsignificant improvements over the state-of-the-art on both the CNN/DailyMail\nand Gigaword datasets, as well as on the DUC-2002 transfer setup. We also\npresent several quantitative and qualitative analysis studies of our model's\nlearned saliency and entailment skills.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 16:05:39 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Guo", "Han", ""], ["Pasunuru", "Ramakanth", ""], ["Bansal", "Mohit", ""]]}, {"id": "1805.11008", "submitter": "Kuan Liu", "authors": "Kuan Liu and Xing Shi and Prem Natarajan", "title": "A Sequential Embedding Approach for Item Recommendation with\n  Heterogeneous Attributes", "comments": "A shorter version appeared in ICDM 2017 SERecsys workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attributes, such as metadata and profile, carry useful information which in\nprinciple can help improve accuracy in recommender systems. However, existing\napproaches have difficulty in fully leveraging attribute information due to\npractical challenges such as heterogeneity and sparseness. These approaches\nalso fail to combine recurrent neural networks which have recently shown\neffectiveness in item recommendations in applications such as video and music\nbrowsing. To overcome the challenges and to harvest the advantages of sequence\nmodels, we present a novel approach, Heterogeneous Attribute Recurrent Neural\nNetworks (HA-RNN), which incorporates heterogeneous attributes and captures\nsequential dependencies in \\textit{both} items and attributes. HA-RNN extends\nrecurrent neural networks with 1) a hierarchical attribute combination input\nlayer and 2) an output attribute embedding layer. We conduct extensive\nexperiments on two large-scale datasets. The new approach show significant\nimprovements over the state-of-the-art models. Our ablation experiments\ndemonstrate the effectiveness of the two components to address heterogeneous\nattribute challenges including variable lengths and attribute sparseness. We\nfurther investigate why sequence modeling works well by conducting exploratory\nstudies and show sequence models are more effective when data scale increases.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 16:07:46 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Liu", "Kuan", ""], ["Shi", "Xing", ""], ["Natarajan", "Prem", ""]]}, {"id": "1805.11025", "submitter": "Ankit Goyal", "authors": "Ankit Goyal, Jian Wang and Jia Deng", "title": "Think Visually: Question Answering through Virtual Imagery", "comments": "Accepted in ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of geometric reasoning in the context of\nquestion-answering. We introduce Dynamic Spatial Memory Network (DSMN), a new\ndeep network architecture designed for answering questions that admit latent\nvisual representations. DSMN learns to generate and reason over such\nrepresentations. Further, we propose two synthetic benchmarks, FloorPlanQA and\nShapeIntersection, to evaluate the geometric reasoning capability of QA\nsystems. Experimental results validate the effectiveness of our proposed DSMN\nfor visual thinking tasks.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 13:43:56 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Goyal", "Ankit", ""], ["Wang", "Jian", ""], ["Deng", "Jia", ""]]}, {"id": "1805.11074", "submitter": "Chen Tessler", "authors": "Chen Tessler, Daniel J. Mankowitz, Shie Mannor", "title": "Reward Constrained Policy Optimization", "comments": "Accepted as a poster to ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving tasks in Reinforcement Learning is no easy feat. As the goal of the\nagent is to maximize the accumulated reward, it often learns to exploit\nloopholes and misspecifications in the reward signal resulting in unwanted\nbehavior. While constraints may solve this issue, there is no closed form\nsolution for general constraints. In this work we present a novel\nmulti-timescale approach for constrained policy optimization, called `Reward\nConstrained Policy Optimization' (RCPO), which uses an alternative penalty\nsignal to guide the policy towards a constraint satisfying one. We prove the\nconvergence of our approach and provide empirical evidence of its ability to\ntrain constraint satisfying policies.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 17:31:11 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 09:31:44 GMT"}, {"version": "v3", "created": "Wed, 26 Dec 2018 11:09:40 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Tessler", "Chen", ""], ["Mankowitz", "Daniel J.", ""], ["Mannor", "Shie", ""]]}, {"id": "1805.11080", "submitter": "Yen-Chun Chen", "authors": "Yen-Chun Chen, Mohit Bansal", "title": "Fast Abstractive Summarization with Reinforce-Selected Sentence\n  Rewriting", "comments": "ACL 2018 (17 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by how humans summarize long documents, we propose an accurate and\nfast summarization model that first selects salient sentences and then rewrites\nthem abstractively (i.e., compresses and paraphrases) to generate a concise\noverall summary. We use a novel sentence-level policy gradient method to bridge\nthe non-differentiable computation between these two neural networks in a\nhierarchical way, while maintaining language fluency. Empirically, we achieve\nthe new state-of-the-art on all metrics (including human evaluation) on the\nCNN/Daily Mail dataset, as well as significantly higher abstractiveness scores.\nMoreover, by first operating at the sentence-level and then the word-level, we\nenable parallel decoding of our neural generative model that results in\nsubstantially faster (10-20x) inference speed as well as 4x faster training\nconvergence than previous long-paragraph encoder-decoder models. We also\ndemonstrate the generalization of our model on the test-only DUC-2002 dataset,\nwhere we achieve higher scores than a state-of-the-art model.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 17:49:10 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Chen", "Yen-Chun", ""], ["Bansal", "Mohit", ""]]}, {"id": "1805.11088", "submitter": "Guiliang Liu", "authors": "Guiliang Liu and Oliver Schulte", "title": "Deep Reinforcement Learning in Ice Hockey for Context-Aware Player\n  Evaluation", "comments": "This paper has been accepted by IJCAI 2018", "journal-ref": null, "doi": "10.24963/ijcai.2018/478", "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of machine learning models have been proposed to assess the\nperformance of players in professional sports. However, they have only a\nlimited ability to model how player performance depends on the game context.\nThis paper proposes a new approach to capturing game context: we apply Deep\nReinforcement Learning (DRL) to learn an action-value Q function from 3M\nplay-by-play events in the National Hockey League (NHL). The neural network\nrepresentation integrates both continuous context signals and game history,\nusing a possession-based LSTM. The learned Q-function is used to value players'\nactions under different game contexts. To assess a player's overall\nperformance, we introduce a novel Game Impact Metric (GIM) that aggregates the\nvalues of the player's actions. Empirical Evaluation shows GIM is consistent\nthroughout a play season, and correlates highly with standard success measures\nand future salary.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 19:23:51 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 16:55:07 GMT"}, {"version": "v3", "created": "Mon, 16 Jul 2018 14:08:47 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Liu", "Guiliang", ""], ["Schulte", "Oliver", ""]]}, {"id": "1805.11090", "submitter": "Moustafa Alzantot", "authors": "Moustafa Alzantot, Yash Sharma, Supriyo Chakraborty, Huan Zhang,\n  Cho-Jui Hsieh, Mani Srivastava", "title": "GenAttack: Practical Black-box Attacks with Gradient-Free Optimization", "comments": "Accepted in The Genetic and Evolutionary Computation Conference\n  (GECCO) 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks are vulnerable to adversarial examples, even in the\nblack-box setting, where the attacker is restricted solely to query access.\nExisting black-box approaches to generating adversarial examples typically\nrequire a significant number of queries, either for training a substitute\nnetwork or performing gradient estimation. We introduce GenAttack, a\ngradient-free optimization technique that uses genetic algorithms for\nsynthesizing adversarial examples in the black-box setting. Our experiments on\ndifferent datasets (MNIST, CIFAR-10, and ImageNet) show that GenAttack can\nsuccessfully generate visually imperceptible adversarial examples against\nstate-of-the-art image recognition models with orders of magnitude fewer\nqueries than previous approaches. Against MNIST and CIFAR-10 models, GenAttack\nrequired roughly 2,126 and 2,568 times fewer queries respectively, than ZOO,\nthe prior state-of-the-art black-box attack. In order to scale up the attack to\nlarge-scale high-dimensional ImageNet models, we perform a series of\noptimizations that further improve the query efficiency of our attack leading\nto 237 times fewer queries against the Inception-v3 model than ZOO.\nFurthermore, we show that GenAttack can successfully attack some\nstate-of-the-art ImageNet defenses, including ensemble adversarial training and\nnon-differentiable or randomized input transformations. Our results suggest\nthat evolutionary algorithms open up a promising area of research into\neffective black-box attacks.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 06:40:55 GMT"}, {"version": "v2", "created": "Mon, 17 Dec 2018 08:08:31 GMT"}, {"version": "v3", "created": "Mon, 1 Jul 2019 00:32:03 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Alzantot", "Moustafa", ""], ["Sharma", "Yash", ""], ["Chakraborty", "Supriyo", ""], ["Zhang", "Huan", ""], ["Hsieh", "Cho-Jui", ""], ["Srivastava", "Mani", ""]]}, {"id": "1805.11122", "submitter": "Rico Jonschkowski", "authors": "Rico Jonschkowski, Divyam Rastogi, Oliver Brock", "title": "Differentiable Particle Filters: End-to-End Learning with Algorithmic\n  Priors", "comments": "Accepted at Robotics: Science and Systems 2018\n  (http://www.roboticsconference.org)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present differentiable particle filters (DPFs): a differentiable\nimplementation of the particle filter algorithm with learnable motion and\nmeasurement models. Since DPFs are end-to-end differentiable, we can\nefficiently train their models by optimizing end-to-end state estimation\nperformance, rather than proxy objectives such as model accuracy. DPFs encode\nthe structure of recursive state estimation with prediction and measurement\nupdate that operate on a probability distribution over states. This structure\nrepresents an algorithmic prior that improves learning performance in state\nestimation problems while enabling explainability of the learned model. Our\nexperiments on simulated and real data show substantial benefits from end-to-\nend learning with algorithmic priors, e.g. reducing error rates by ~80%. Our\nexperiments also show that, unlike long short-term memory networks, DPFs learn\nlocalization in a policy-agnostic way and thus greatly improve generalization.\nSource code is available at\nhttps://github.com/tu-rbo/differentiable-particle-filters .\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 18:30:56 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 02:56:52 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Jonschkowski", "Rico", ""], ["Rastogi", "Divyam", ""], ["Brock", "Oliver", ""]]}, {"id": "1805.11144", "submitter": "Daniel Rasmussen", "authors": "Daniel Rasmussen", "title": "NengoDL: Combining deep learning and neuromorphic modelling methods", "comments": "22 pages, 9 figures; v2 fixes a link in the metadata; v3 minor text\n  updates and updating code snippets to 2.0 syntax", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  NengoDL is a software framework designed to combine the strengths of\nneuromorphic modelling and deep learning. NengoDL allows users to construct\nbiologically detailed neural models, intermix those models with deep learning\nelements (such as convolutional networks), and then efficiently simulate those\nmodels in an easy-to-use, unified framework. In addition, NengoDL allows users\nto apply deep learning training methods to optimize the parameters of\nbiological neural models. In this paper we present basic usage examples,\nbenchmarking, and details on the key implementation elements of NengoDL. More\ndetails can be found at https://www.nengo.ai/nengo-dl .\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 19:36:45 GMT"}, {"version": "v2", "created": "Wed, 30 May 2018 00:13:05 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2019 16:25:30 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Rasmussen", "Daniel", ""]]}, {"id": "1805.11154", "submitter": "Wen Zhang", "authors": "Wen Zhang, Jiawei Hu, Yang Feng and Qun Liu", "title": "Refining Source Representations with Relation Networks for Neural\n  Machine Translation", "comments": "12pages, 7 figures, accepted for COLING-2018. arXiv admin note:\n  substantial text overlap with arXiv:1709.03980", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although neural machine translation with the encoder-decoder framework has\nachieved great success recently, it still suffers drawbacks of forgetting\ndistant information, which is an inherent disadvantage of recurrent neural\nnetwork structure, and disregarding relationship between source words during\nencoding step. Whereas in practice, the former information and relationship are\noften useful in current step. We target on solving these problems and thus\nintroduce relation networks to learn better representations of the source. The\nrelation networks are able to facilitate memorization capability of recurrent\nneural network via associating source words with each other, this would also\nhelp retain their relationships. Then the source representations and all the\nrelations are fed into the attention component together while decoding, with\nthe main encoder-decoder framework unchanged. Experiments on several datasets\nshow that our method can improve the translation performance significantly over\nthe conventional encoder-decoder model and even outperform the approach\ninvolving supervised syntactic knowledge.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 13:34:52 GMT"}, {"version": "v2", "created": "Sun, 9 Sep 2018 16:26:43 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Zhang", "Wen", ""], ["Hu", "Jiawei", ""], ["Feng", "Yang", ""], ["Liu", "Qun", ""]]}, {"id": "1805.11166", "submitter": "Hugo Jair  Escalante", "authors": "Miguel A. Alvarez-Carmona, Luis Pellegrin, Manuel Montes-y-G\\'omez,\n  Fernando S\\'anchez-Vega, Hugo Jair Escalante, A. Pastor L\\'opez-Monroy, Luis\n  Villase\\~nor-Pineda, Esa\\'u Villatoro-Tello", "title": "A visual approach for age and gender identification on Twitter", "comments": null, "journal-ref": "Miguel A. Alvarez-Carmona, Luis Pellegrin et al. A visual approach\n  for age and gender identification on Twitter. Journal of Intelligent and\n  Fuzzy Systems, vol. 34, no. 5, pp. 3133-3145, 2018", "doi": "10.3233/JIFS-169497", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of Author Profiling (AP) is to identify demographic aspects (e.g.,\nage, gender) from a given set of authors by analyzing their written texts.\nRecently, the AP task has gained interest in many problems related to computer\nforensics, psychology, marketing, but specially in those related with social\nmedia exploitation. As known, social media data is shared through a wide range\nof modalities (e.g., text, images and audio), representing valuable information\nto be exploited for extracting valuable insights from users. Nevertheless, most\nof the current work in AP using social media data has been devoted to analyze\ntextual information only, and there are very few works that have started\nexploring the gender identification using visual information. Contrastingly,\nthis paper focuses in exploiting the visual modality to perform both age and\ngender identification in social media, specifically in Twitter. Our goal is to\nevaluate the pertinence of using visual information in solving the AP task.\nAccordingly, we have extended the Twitter corpus from PAN 2014, incorporating\nposted images from all the users, making a distinction between tweeted and\nretweeted images. Performed experiments provide interesting evidence on the\nusefulness of visual information in comparison with traditional textual\nrepresentations for the AP task.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 20:31:18 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Alvarez-Carmona", "Miguel A.", ""], ["Pellegrin", "Luis", ""], ["Montes-y-G\u00f3mez", "Manuel", ""], ["S\u00e1nchez-Vega", "Fernando", ""], ["Escalante", "Hugo Jair", ""], ["L\u00f3pez-Monroy", "A. Pastor", ""], ["Villase\u00f1or-Pineda", "Luis", ""], ["Villatoro-Tello", "Esa\u00fa", ""]]}, {"id": "1805.11170", "submitter": "Nikolaj Tatti", "authors": "Nikolaj Tatti", "title": "Strongly polynomial efficient approximation scheme for segmentation", "comments": null, "journal-ref": null, "doi": "10.1016/j.ipl.2018.09.007", "report-no": null, "categories": "cs.DS cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partitioning a sequence of length $n$ into $k$ coherent segments (Seg) is one\nof the classic optimization problems. As long as the optimization criterion is\nadditive, Seg can be solved exactly in $O(n^2k)$ time using a classic dynamic\nprogram. Due to the quadratic term, computing the exact segmentation may be too\nexpensive for long sequences, which has led to development of approximate\nsolutions. We consider an existing estimation scheme that computes $(1 +\n\\epsilon)$ approximation in polylogarithmic time. We augment this algorithm,\nmaking it strongly polynomial. We do this by first solving a slightly different\nsegmentation problem (MaxSeg), where the quality of the segmentation is the\nmaximum penalty of an individual segment. By using this solution to initialize\nthe estimation scheme, we are able to obtain a strongly polynomial algorithm.\nIn addition, we consider a cumulative version of Seg, where we are asked to\ndiscover the optimal segmentation for each prefix of the input sequence. We\npropose a strongly polynomial algorithm that yields $(1 + \\epsilon)$\napproximation in $O(nk^2 / \\epsilon)$ time. Finally, we consider a cumulative\nversion of MaxSeg, and show that we can solve the problem in $O(nk \\log k)$\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 20:55:47 GMT"}, {"version": "v2", "created": "Tue, 5 Feb 2019 15:30:31 GMT"}], "update_date": "2019-02-06", "authors_parsed": [["Tatti", "Nikolaj", ""]]}, {"id": "1805.11199", "submitter": "Nantas Nardelli", "authors": "Nantas Nardelli, Gabriel Synnaeve, Zeming Lin, Pushmeet Kohli, Philip\n  H. S. Torr, Nicolas Usunier", "title": "Value Propagation Networks", "comments": "Updated to match ICLR 2019 OpenReview's version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Value Propagation (VProp), a set of parameter-efficient\ndifferentiable planning modules built on Value Iteration which can successfully\nbe trained using reinforcement learning to solve unseen tasks, has the\ncapability to generalize to larger map sizes, and can learn to navigate in\ndynamic environments. We show that the modules enable learning to plan when the\nenvironment also includes stochastic elements, providing a cost-efficient\nlearning system to build low-level size-invariant planners for a variety of\ninteractive navigation problems. We evaluate on static and dynamic\nconfigurations of MazeBase grid-worlds, with randomly generated environments of\nseveral different sizes, and on a StarCraft navigation scenario, with more\ncomplex dynamics, and pixels as input.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 23:21:32 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2019 17:48:22 GMT"}], "update_date": "2019-03-26", "authors_parsed": [["Nardelli", "Nantas", ""], ["Synnaeve", "Gabriel", ""], ["Lin", "Zeming", ""], ["Kohli", "Pushmeet", ""], ["Torr", "Philip H. S.", ""], ["Usunier", "Nicolas", ""]]}, {"id": "1805.11232", "submitter": "Gon\\c{c}alo Abreu", "authors": "Gon\\c{c}alo Abreu, Rui Neves, Nuno Horta", "title": "Currency exchange prediction using machine learning, genetic algorithms\n  and technical analysis", "comments": "23 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technical analysis is used to discover investment opportunities. To test this\nhypothesis we propose an hybrid system using machine learning techniques\ntogether with genetic algorithms. Using technical analysis there are more ways\nto represent a currency exchange time series than the ones it is possible to\ntest computationally, i.e., it is unfeasible to search the whole input feature\nspace thus a genetic algorithm is an alternative. In this work, an architecture\nfor automatic feature selection is proposed to optimize the cross validated\nperformance estimation of a Naive Bayes model using a genetic algorithm. The\nproposed architecture improves the return on investment of the unoptimized\nsystem from 0,43% to 10,29% in the validation set. The features selected and\nthe model decision boundary are visualized using the algorithm t-Distributed\nStochastic Neighbor embedding.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 03:36:34 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Abreu", "Gon\u00e7alo", ""], ["Neves", "Rui", ""], ["Horta", "Nuno", ""]]}, {"id": "1805.11234", "submitter": "Junwei Bao", "authors": "Junwei Bao, Duyu Tang, Nan Duan, Zhao Yan, Yuanhua Lv, Ming Zhou,\n  Tiejun Zhao", "title": "Table-to-Text: Describing Table Region with Natural Language", "comments": "9 pages, 4 figures. This paper has been published by AAAI2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a generative model to generate a natural language\nsentence describing a table region, e.g., a row. The model maps a row from a\ntable to a continuous vector and then generates a natural language sentence by\nleveraging the semantics of a table. To deal with rare words appearing in a\ntable, we develop a flexible copying mechanism that selectively replicates\ncontents from the table in the output sequence. Extensive experiments\ndemonstrate the accuracy of the model and the power of the copying mechanism.\nOn two synthetic datasets, WIKIBIO and SIMPLEQUESTIONS, our model improves the\ncurrent state-of-the-art BLEU-4 score from 34.70 to 40.26 and from 33.32 to\n39.12, respectively. Furthermore, we introduce an open-domain dataset\nWIKITABLETEXT including 13,318 explanatory sentences for 4,962 tables. Our\nmodel achieves a BLEU-4 score of 38.23, which outperforms template based and\nlanguage model based approaches.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 03:39:35 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Bao", "Junwei", ""], ["Tang", "Duyu", ""], ["Duan", "Nan", ""], ["Yan", "Zhao", ""], ["Lv", "Yuanhua", ""], ["Zhou", "Ming", ""], ["Zhao", "Tiejun", ""]]}, {"id": "1805.11324", "submitter": "Tim Pearce", "authors": "Tim Pearce, Nicolas Anastassacos, Mohamed Zaki, Andy Neely", "title": "Bayesian Inference with Anchored Ensembles of Neural Networks, and\n  Application to Exploration in Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of ensembles of neural networks (NNs) for the quantification of\npredictive uncertainty is widespread. However, the current justification is\nintuitive rather than analytical. This work proposes one minor modification to\nthe normal ensembling methodology, which we prove allows the ensemble to\nperform Bayesian inference, hence converging to the corresponding Gaussian\nProcess as both the total number of NNs, and the size of each, tend to\ninfinity. This working paper provides early-stage results in a reinforcement\nlearning setting, analysing the practicality of the technique for an ensemble\nof small, finite number. Using the uncertainty estimates produced by anchored\nensembles to govern the exploration-exploitation process results in steadier,\nmore stable learning.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 09:36:16 GMT"}, {"version": "v2", "created": "Fri, 15 Jun 2018 17:03:00 GMT"}, {"version": "v3", "created": "Mon, 2 Jul 2018 11:45:45 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Pearce", "Tim", ""], ["Anastassacos", "Nicolas", ""], ["Zaki", "Mohamed", ""], ["Neely", "Andy", ""]]}, {"id": "1805.11350", "submitter": "Nikola Mrk\\v{s}i\\'c", "authors": "Nikola Mrk\\v{s}i\\'c and Ivan Vuli\\'c", "title": "Fully Statistical Neural Belief Tracking", "comments": "Accepted as a short paper for the 56th Annual Meeting of the\n  Association for Computational Linguistics (ACL 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an improvement to the existing data-driven Neural Belief\nTracking (NBT) framework for Dialogue State Tracking (DST). The existing NBT\nmodel uses a hand-crafted belief state update mechanism which involves an\nexpensive manual retuning step whenever the model is deployed to a new dialogue\ndomain. We show that this update mechanism can be learned jointly with the\nsemantic decoding and context modelling parts of the NBT model, eliminating the\nlast rule-based module from this DST framework. We propose two different\nstatistical update mechanisms and show that dialogue dynamics can be modelled\nwith a very small number of additional model parameters. In our DST evaluation\nover three languages, we show that this model achieves competitive performance\nand provides a robust framework for building resource-light DST models.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 10:41:08 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Mrk\u0161i\u0107", "Nikola", ""], ["Vuli\u0107", "Ivan", ""]]}, {"id": "1805.11375", "submitter": "Mohit Kumar", "authors": "Mohit Kumar, Stefano Teso, Luc De Raedt", "title": "Automating Personnel Rostering by Learning Constraints Using Tensors", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems in operations research require that constraints be specified in\nthe model. Determining the right constraints is a hard and laborsome task. We\npropose an approach to automate this process using artificial intelligence and\nmachine learning principles. So far there has been only little work on learning\nconstraints within the operations research community. We focus on personnel\nrostering and scheduling problems in which there are often past schedules\navailable and show that it is possible to automatically learn constraints from\nsuch examples. To realize this, we adapted some techniques from the constraint\nprogramming community and we have extended them in order to cope with\nmultidimensional examples. The method uses a tensor representation of the\nexample, which helps in capturing the dimensionality as well as the structure\nof the example, and applies tensor operations to find the constraints that are\nsatisfied by the example. To evaluate the proposed algorithm, we used\nconstraints from the Nurse Rostering Competition and generated solutions that\nsatisfy these constraints; these solutions were then used as examples to learn\nconstraints. Experiments demonstrate that the proposed algorithm is capable of\nproducing human readable constraints that capture the underlying\ncharacteristics of the examples.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 12:04:13 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Kumar", "Mohit", ""], ["Teso", "Stefano", ""], ["De Raedt", "Luc", ""]]}, {"id": "1805.11447", "submitter": "El Mahdi El Mhamdi", "authors": "Henrik Aslund, El Mahdi El Mhamdi, Rachid Guerraoui, Alexandre Maurer", "title": "Virtuously Safe Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.GT stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We show that when a third party, the adversary, steps into the two-party\nsetting (agent and operator) of safely interruptible reinforcement learning, a\ntrade-off has to be made between the probability of following the optimal\npolicy in the limit, and the probability of escaping a dangerous situation\ncreated by the adversary. So far, the work on safely interruptible agents has\nassumed a perfect perception of the agent about its environment (no adversary),\nand therefore implicitly set the second probability to zero, by explicitly\nseeking a value of one for the first probability. We show that (1) agents can\nbe made both interruptible and adversary-resilient, and (2) the\ninterruptibility can be made safe in the sense that the agent itself will not\nseek to avoid it. We also solve the problem that arises when the agent does not\ngo completely greedy, i.e. issues with safe exploration in the limit.\nResilience to perturbed perception, safe exploration in the limit, and safe\ninterruptibility are the three pillars of what we call \\emph{virtuously safe\nreinforcement learning}.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 13:34:39 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Aslund", "Henrik", ""], ["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Maurer", "Alexandre", ""]]}, {"id": "1805.11452", "submitter": "Takashi Sano", "authors": "Takashi Sano", "title": "An Analytic Solution to the Inverse Ising Problem in the Tree-reweighted\n  Approximation", "comments": "8 pages, to be published in proceedings of the 2018 International\n  Joint Conference on Neural Networks (IJCNN 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cond-mat.dis-nn cond-mat.stat-mech cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many iterative and non-iterative methods have been developed for inverse\nproblems associated with Ising models. Aiming to derive an accurate\nnon-iterative method for the inverse problems, we employ the tree-reweighted\napproximation. Using the tree-reweighted approximation, we can optimize the\nrigorous lower bound of the objective function. By solving the moment-matching\nand self-consistency conditions analytically, we can derive the interaction\nmatrix as a function of the given data statistics. With this solution, we can\nobtain the optimal interaction matrix without iterative computation. To\nevaluate the accuracy of the proposed inverse formula, we compared our results\nto those obtained by existing inverse formulae derived with other\napproximations. In an experiment to reconstruct the interaction matrix, we\nfound that the proposed formula returns the best estimates in\nstrongly-attractive regions for various graph structures. We also performed an\nexperiment using real-world biological data. When applied to finding the\nconnectivity of neurons from spike train data, the proposed formula gave the\nclosest result to that obtained by a gradient ascent algorithm, which typically\nrequires thousands of iterations.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 13:38:18 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Sano", "Takashi", ""]]}, {"id": "1805.11535", "submitter": "Yi Tay", "authors": "Yi Tay, Anh Tuan Luu, Siu Cheung Hui", "title": "CoupleNet: Paying Attention to Couples with Coupled Attention for\n  Relationship Recommendation", "comments": "Accepted at ICWSM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dating and romantic relationships not only play a huge role in our personal\nlives but also collectively influence and shape society. Today, many romantic\npartnerships originate from the Internet, signifying the importance of\ntechnology and the web in modern dating. In this paper, we present a text-based\ncomputational approach for estimating the relationship compatibility of two\nusers on social media. Unlike many previous works that propose reciprocal\nrecommender systems for online dating websites, we devise a distant supervision\nheuristic to obtain real world couples from social platforms such as Twitter.\nOur approach, the CoupleNet is an end-to-end deep learning based estimator that\nanalyzes the social profiles of two users and subsequently performs a\nsimilarity match between the users. Intuitively, our approach performs both\nuser profiling and match-making within a unified end-to-end framework.\nCoupleNet utilizes hierarchical recurrent neural models for learning\nrepresentations of user profiles and subsequently coupled attention mechanisms\nto fuse information aggregated from two users. To the best of our knowledge,\nour approach is the first data-driven deep learning approach for our novel\nrelationship recommendation problem. We benchmark our CoupleNet against several\nmachine learning and deep learning baselines. Experimental results show that\nour approach outperforms all approaches significantly in terms of precision.\nQualitative analysis shows that our model is capable of also producing\nexplainable results to users.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 15:14:41 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Tay", "Yi", ""], ["Luu", "Anh Tuan", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1805.11546", "submitter": "Alexander Ororbia", "authors": "Alexander G. Ororbia, Ankur Mali, Matthew A. Kelly, and David Reitter", "title": "Like a Baby: Visually Situated Neural Language Acquisition", "comments": "Final submission (camera-ready), accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the benefits of visual context in training neural language models\nto perform next-word prediction. A multi-modal neural architecture is\nintroduced that outperform its equivalent trained on language alone with a 2\\%\ndecrease in perplexity, even when no visual context is available at test.\nFine-tuning the embeddings of a pre-trained state-of-the-art bidirectional\nlanguage model (BERT) in the language modeling framework yields a 3.5\\%\nimprovement. The advantage for training with visual context when testing\nwithout is robust across different languages (English, German and Spanish) and\ndifferent models (GRU, LSTM, $\\Delta$-RNN, as well as those that use BERT\nembeddings). Thus, language models perform better when they learn like a baby,\ni.e, in a multi-modal environment. This finding is compatible with the theory\nof situated cognition: language is inseparable from its physical context.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 15:53:30 GMT"}, {"version": "v2", "created": "Tue, 4 Jun 2019 05:11:20 GMT"}], "update_date": "2019-06-05", "authors_parsed": [["Ororbia", "Alexander G.", ""], ["Mali", "Ankur", ""], ["Kelly", "Matthew A.", ""], ["Reitter", "David", ""]]}, {"id": "1805.11548", "submitter": "Luchen Li", "authors": "Luchen Li and Matthieu Komorowski and Aldo A. Faisal", "title": "The Actor Search Tree Critic (ASTC) for Off-Policy POMDP Learning in\n  Medical Decision Making", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Off-policy reinforcement learning enables near-optimal policy from suboptimal\nexperience, thereby provisions opportunity for artificial intelligence\napplications in healthcare. Previous works have mainly framed patient-clinician\ninteractions as Markov decision processes, while true physiological states are\nnot necessarily fully observable from clinical data. We capture this situation\nwith partially observable Markov decision process, in which an agent optimises\nits actions in a belief represented as a distribution of patient states\ninferred from individual history trajectories. A Gaussian mixture model is\nfitted for the observed data. Moreover, we take into account the fact that\nnuance in pharmaceutical dosage could presumably result in significantly\ndifferent effect by modelling a continuous policy through a Gaussian\napproximator directly in the policy space, i.e. the actor. To address the\nchallenge of infinite number of possible belief states which renders exact\nvalue iteration intractable, we evaluate and plan for only every encountered\nbelief, through heuristic search tree by tightly maintaining lower and upper\nbounds of the true value of belief. We further resort to function\napproximations to update value bounds estimation, i.e. the critic, so that the\ntree search can be improved through more compact bounds at the fringe nodes\nthat will be back-propagated to the root. Both actor and critic parameters are\nlearned via gradient-based approaches. Our proposed policy trained from real\nintensive care unit data is capable of dictating dosing on vasopressors and\nintravenous fluids for sepsis patients that lead to the best patient outcomes.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 15:55:33 GMT"}, {"version": "v2", "created": "Thu, 31 May 2018 09:06:43 GMT"}, {"version": "v3", "created": "Sun, 3 Jun 2018 16:37:31 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Li", "Luchen", ""], ["Komorowski", "Matthieu", ""], ["Faisal", "Aldo A.", ""]]}, {"id": "1805.11555", "submitter": "Neil Urquhart", "authors": "Neil Urquhart, Emma Hart", "title": "Optimisation and Illumination of a Real-world Workforce Scheduling and\n  Routing Application via Map-Elites", "comments": "This is pre-print, a link to the published version will be added when\n  it is published", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Workforce Scheduling and Routing Problems (WSRP) are very common in many\npractical domains, and usually, have a number of objectives. Illumination\nalgorithms such as Map-Elites (ME) have recently gained traction in application\nto {\\em design} problems, in providing multiple diverse solutions as well as\nilluminating the solution space in terms of user-defined characteristics, but\ntypically require significant computational effort to produce the solution\narchive. We investigate whether ME can provide an effective approach to solving\nWSRP, a {\\em repetitive} problem in which solutions have to be produced quickly\nand often. The goals of the paper are two-fold. The first is to evaluate\nwhether ME can provide solutions of competitive quality to an Evolutionary\nAlgorithm (EA) in terms of a single objective function, and the second to\nexamine its ability to provide a repertoire of solutions that maximise user\nchoice. We find that very small computational budgets favour the EA in terms of\nquality, but ME outperforms the EA at larger budgets, provides a more diverse\narray of solutions, and lends insight to the end-user.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 16:03:06 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Urquhart", "Neil", ""], ["Hart", "Emma", ""]]}, {"id": "1805.11592", "submitter": "Yusuf Aytar", "authors": "Yusuf Aytar, Tobias Pfaff, David Budden, Tom Le Paine, Ziyu Wang,\n  Nando de Freitas", "title": "Playing hard exploration games by watching YouTube", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep reinforcement learning methods traditionally struggle with tasks where\nenvironment rewards are particularly sparse. One successful method of guiding\nexploration in these domains is to imitate trajectories provided by a human\ndemonstrator. However, these demonstrations are typically collected under\nartificial conditions, i.e. with access to the agent's exact environment setup\nand the demonstrator's action and reward trajectories. Here we propose a\ntwo-stage method that overcomes these limitations by relying on noisy,\nunaligned footage without access to such data. First, we learn to map unaligned\nvideos from multiple sources to a common representation using self-supervised\nobjectives constructed over both time and modality (i.e. vision and sound).\nSecond, we embed a single YouTube video in this representation to construct a\nreward function that encourages an agent to imitate human gameplay. This method\nof one-shot imitation allows our agent to convincingly exceed human-level\nperformance on the infamously hard exploration games Montezuma's Revenge,\nPitfall! and Private Eye for the first time, even if the agent is not presented\nwith any environment rewards.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 17:19:36 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2018 15:59:27 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Aytar", "Yusuf", ""], ["Pfaff", "Tobias", ""], ["Budden", "David", ""], ["Paine", "Tom Le", ""], ["Wang", "Ziyu", ""], ["de Freitas", "Nando", ""]]}, {"id": "1805.11593", "submitter": "Tobias Pohlen", "authors": "Tobias Pohlen, Bilal Piot, Todd Hester, Mohammad Gheshlaghi Azar, Dan\n  Horgan, David Budden, Gabriel Barth-Maron, Hado van Hasselt, John Quan, Mel\n  Ve\\v{c}er\\'ik, Matteo Hessel, R\\'emi Munos, Olivier Pietquin", "title": "Observe and Look Further: Achieving Consistent Performance on Atari", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite significant advances in the field of deep Reinforcement Learning\n(RL), today's algorithms still fail to learn human-level policies consistently\nover a set of diverse tasks such as Atari 2600 games. We identify three key\nchallenges that any algorithm needs to master in order to perform well on all\ngames: processing diverse reward distributions, reasoning over long time\nhorizons, and exploring efficiently. In this paper, we propose an algorithm\nthat addresses each of these challenges and is able to learn human-level\npolicies on nearly all Atari games. A new transformed Bellman operator allows\nour algorithm to process rewards of varying densities and scales; an auxiliary\ntemporal consistency loss allows us to train stably using a discount factor of\n$\\gamma = 0.999$ (instead of $\\gamma = 0.99$) extending the effective planning\nhorizon by an order of magnitude; and we ease the exploration problem by using\nhuman demonstrations that guide the agent towards rewarding states. When tested\non a set of 42 Atari games, our algorithm exceeds the performance of an average\nhuman on 40 games using a common set of hyper parameters. Furthermore, it is\nthe first deep RL algorithm to solve the first level of Montezuma's Revenge.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 17:19:59 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Pohlen", "Tobias", ""], ["Piot", "Bilal", ""], ["Hester", "Todd", ""], ["Azar", "Mohammad Gheshlaghi", ""], ["Horgan", "Dan", ""], ["Budden", "David", ""], ["Barth-Maron", "Gabriel", ""], ["van Hasselt", "Hado", ""], ["Quan", "John", ""], ["Ve\u010der\u00edk", "Mel", ""], ["Hessel", "Matteo", ""], ["Munos", "R\u00e9mi", ""], ["Pietquin", "Olivier", ""]]}, {"id": "1805.11648", "submitter": "Michael Hind", "authors": "Noel C. F. Codella, Michael Hind, Karthikeyan Natesan Ramamurthy,\n  Murray Campbell, Amit Dhurandhar, Kush R. Varshney, Dennis Wei, Aleksandra\n  Mojsilovic", "title": "Teaching Meaningful Explanations", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adoption of machine learning in high-stakes applications such as\nhealthcare and law has lagged in part because predictions are not accompanied\nby explanations comprehensible to the domain user, who often holds the ultimate\nresponsibility for decisions and outcomes. In this paper, we propose an\napproach to generate such explanations in which training data is augmented to\ninclude, in addition to features and labels, explanations elicited from domain\nusers. A joint model is then learned to produce both labels and explanations\nfrom the input features. This simple idea ensures that explanations are\ntailored to the complexity expectations and domain knowledge of the consumer.\nEvaluation spans multiple modeling techniques on a game dataset, a (visual)\naesthetics dataset, a chemical odor dataset and a Melanoma dataset showing that\nour approach is generalizable across domains and algorithms. Results\ndemonstrate that meaningful explanations can be reliably taught to machine\nlearning algorithms, and in some cases, also improve modeling accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 18:35:44 GMT"}, {"version": "v2", "created": "Tue, 11 Sep 2018 01:44:51 GMT"}], "update_date": "2018-09-12", "authors_parsed": [["Codella", "Noel C. F.", ""], ["Hind", "Michael", ""], ["Ramamurthy", "Karthikeyan Natesan", ""], ["Campbell", "Murray", ""], ["Dhurandhar", "Amit", ""], ["Varshney", "Kush R.", ""], ["Wei", "Dennis", ""], ["Mojsilovic", "Aleksandra", ""]]}, {"id": "1805.11704", "submitter": "Arna Ghosh", "authors": "Arna Ghosh, Fabien dal Maso, Marc Roig, Georgios D Mitsis and\n  Marie-H\\'el\\`ene Boudrias", "title": "Deep Semantic Architecture with discriminative feature visualization for\n  neuroimage analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.NC cs.AI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neuroimaging data analysis often involves \\emph{a-priori} selection of data\nfeatures to study the underlying neural activity. Since this could lead to\nsub-optimal feature selection and thereby prevent the detection of subtle\npatterns in neural activity, data-driven methods have recently gained\npopularity for optimizing neuroimaging data analysis pipelines and thereby,\nimproving our understanding of neural mechanisms. In this context, we developed\na deep convolutional architecture that can identify discriminating patterns in\nneuroimaging data and applied it to electroencephalography (EEG) recordings\ncollected from 25 subjects performing a hand motor task before and after a rest\nperiod or a bout of exercise. The deep network was trained to classify subjects\ninto exercise and control groups based on differences in their EEG signals.\nSubsequently, we developed a novel method termed the cue-combination for Class\nActivation Map (ccCAM), which enabled us to identify discriminating\nspatio-temporal features within definite frequency bands (23--33 Hz) and assess\nthe effects of exercise on the brain. Additionally, the proposed architecture\nallowed the visualization of the differences in the propagation of underlying\nneural activity across the cortex between the two groups, for the first time in\nour knowledge. Our results demonstrate the feasibility of using deep network\narchitectures for neuroimaging analysis in different contexts such as, for the\nidentification of robust brain biomarkers to better characterize and\npotentially treat neurological disorders.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 20:55:09 GMT"}, {"version": "v2", "created": "Fri, 29 Jun 2018 20:17:16 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Ghosh", "Arna", ""], ["Maso", "Fabien dal", ""], ["Roig", "Marc", ""], ["Mitsis", "Georgios D", ""], ["Boudrias", "Marie-H\u00e9l\u00e8ne", ""]]}, {"id": "1805.11706", "submitter": "Quan Vuong", "authors": "Quan Vuong, Yiming Zhang, Keith W. Ross", "title": "Supervised Policy Update for Deep Reinforcement Learning", "comments": "Accepted as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new sample-efficient methodology, called Supervised Policy\nUpdate (SPU), for deep reinforcement learning. Starting with data generated by\nthe current policy, SPU formulates and solves a constrained optimization\nproblem in the non-parameterized proximal policy space. Using supervised\nregression, it then converts the optimal non-parameterized policy to a\nparameterized policy, from which it draws new samples. The methodology is\ngeneral in that it applies to both discrete and continuous action spaces, and\ncan handle a wide variety of proximity constraints for the non-parameterized\noptimization problem. We show how the Natural Policy Gradient and Trust Region\nPolicy Optimization (NPG/TRPO) problems, and the Proximal Policy Optimization\n(PPO) problem can be addressed by this methodology. The SPU implementation is\nmuch simpler than TRPO. In terms of sample efficiency, our extensive\nexperiments show SPU outperforms TRPO in Mujoco simulated robotic tasks and\noutperforms PPO in Atari video game tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 20:57:19 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 16:58:54 GMT"}, {"version": "v3", "created": "Fri, 21 Dec 2018 03:20:00 GMT"}, {"version": "v4", "created": "Mon, 24 Dec 2018 01:42:07 GMT"}], "update_date": "2018-12-27", "authors_parsed": [["Vuong", "Quan", ""], ["Zhang", "Yiming", ""], ["Ross", "Keith W.", ""]]}, {"id": "1805.11711", "submitter": "Katja Hofmann", "authors": "Justas Dauparas, Ryota Tomioka, and Katja Hofmann", "title": "Depth and nonlinearity induce implicit exploration for RL", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The question of how to explore, i.e., take actions with uncertain outcomes to\nlearn about possible future rewards, is a key question in reinforcement\nlearning (RL). Here, we show a surprising result: We show that Q-learning with\nnonlinear Q-function and no explicit exploration (i.e., a purely greedy policy)\ncan learn several standard benchmark tasks, including mountain car, equally\nwell as, or better than, the most commonly-used $\\epsilon$-greedy exploration.\nWe carefully examine this result and show that both the depth of the Q-network\nand the type of nonlinearity are important to induce such deterministic\nexploration.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 21:21:18 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Dauparas", "Justas", ""], ["Tomioka", "Ryota", ""], ["Hofmann", "Katja", ""]]}, {"id": "1805.11714", "submitter": "Michael Zollh\\\"ofer", "authors": "Hyeongwoo Kim, Pablo Garrido, Ayush Tewari, Weipeng Xu, Justus Thies,\n  Matthias Nie{\\ss}ner, Patrick P\\'erez, Christian Richardt, Michael\n  Zollh\\\"ofer, Christian Theobalt", "title": "Deep Video Portraits", "comments": "SIGGRAPH 2018, Video: https://www.youtube.com/watch?v=qc5P2bvfl44", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel approach that enables photo-realistic re-animation of\nportrait videos using only an input video. In contrast to existing approaches\nthat are restricted to manipulations of facial expressions only, we are the\nfirst to transfer the full 3D head position, head rotation, face expression,\neye gaze, and eye blinking from a source actor to a portrait video of a target\nactor. The core of our approach is a generative neural network with a novel\nspace-time architecture. The network takes as input synthetic renderings of a\nparametric face model, based on which it predicts photo-realistic video frames\nfor a given target actor. The realism in this rendering-to-video transfer is\nachieved by careful adversarial training, and as a result, we can create\nmodified target videos that mimic the behavior of the synthetically-created\ninput. In order to enable source-to-target video re-animation, we render a\nsynthetic target video with the reconstructed head animation parameters from a\nsource video, and feed it into the trained network -- thus taking full control\nof the target. With the ability to freely recombine source and target\nparameters, we are able to demonstrate a large variety of video rewrite\napplications without explicitly modeling hair, body or background. For\ninstance, we can reenact the full head using interactive user-controlled\nediting, and realize high-fidelity visual dubbing. To demonstrate the high\nquality of our output, we conduct an extensive series of experiments and\nevaluations, where for instance a user study shows that our video edits are\nhard to detect.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 21:31:14 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Kim", "Hyeongwoo", ""], ["Garrido", "Pablo", ""], ["Tewari", "Ayush", ""], ["Xu", "Weipeng", ""], ["Thies", "Justus", ""], ["Nie\u00dfner", "Matthias", ""], ["P\u00e9rez", "Patrick", ""], ["Richardt", "Christian", ""], ["Zollh\u00f6fer", "Michael", ""], ["Theobalt", "Christian", ""]]}, {"id": "1805.11730", "submitter": "Kuan Liu", "authors": "Kuan Liu, Yanen Li, Ning Xu, Prem Natarajan", "title": "Learn to Combine Modalities in Multimodal Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combining complementary information from multiple modalities is intuitively\nappealing for improving the performance of learning-based approaches. However,\nit is challenging to fully leverage different modalities due to practical\nchallenges such as varying levels of noise and conflicts between modalities.\nExisting methods do not adopt a joint approach to capturing synergies between\nthe modalities while simultaneously filtering noise and resolving conflicts on\na per sample basis. In this work we propose a novel deep neural network based\ntechnique that multiplicatively combines information from different source\nmodalities. Thus the model training process automatically focuses on\ninformation from more reliable modalities while reducing emphasis on the less\nreliable modalities. Furthermore, we propose an extension that multiplicatively\ncombines not only the single-source modalities, but a set of mixtured source\nmodalities to better capture cross-modal signal correlations. We demonstrate\nthe effectiveness of our proposed technique by presenting empirical results on\nthree multimodal classification tasks from different domains. The results show\nconsistent accuracy improvements on all three tasks.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 22:24:48 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Liu", "Kuan", ""], ["Li", "Yanen", ""], ["Xu", "Ning", ""], ["Natarajan", "Prem", ""]]}, {"id": "1805.11752", "submitter": "Oluwatobi Olabiyi", "authors": "Oluwatobi Olabiyi, Alan Salimov, Anish Khazane, Erik T. Mueller", "title": "Multi-turn Dialogue Response Generation in an Adversarial Learning\n  Framework", "comments": "Accepted at ACL 2019 Workshop on NLP for Conversational AI", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE stat.ML", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  We propose an adversarial learning approach for generating multi-turn\ndialogue responses. Our proposed framework, hredGAN, is based on conditional\ngenerative adversarial networks (GANs). The GAN's generator is a modified\nhierarchical recurrent encoder-decoder network (HRED) and the discriminator is\na word-level bidirectional RNN that shares context and word embeddings with the\ngenerator. During inference, noise samples conditioned on the dialogue history\nare used to perturb the generator's latent space to generate several possible\nresponses. The final response is the one ranked best by the discriminator. The\nhredGAN shows improved performance over existing methods: (1) it generalizes\nbetter than networks trained using only the log-likelihood criterion, and (2)\nit generates longer, more informative and more diverse responses with high\nutterance and topic relevance even with limited training data. This improvement\nis demonstrated on the Movie triples and Ubuntu dialogue datasets using both\nautomatic and human evaluations.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 00:05:53 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 20:49:03 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 13:35:08 GMT"}, {"version": "v4", "created": "Tue, 18 Jun 2019 13:26:28 GMT"}, {"version": "v5", "created": "Wed, 26 Jun 2019 14:39:24 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Olabiyi", "Oluwatobi", ""], ["Salimov", "Alan", ""], ["Khazane", "Anish", ""], ["Mueller", "Erik T.", ""]]}, {"id": "1805.11768", "submitter": "Michael Green", "authors": "Michael Cerny Green, Ahmed Khalifa, Gabriella A. B. Barros, and Julian\n  Togelius", "title": "\"Press Space to Fire\": Automatic Video Game Tutorial Generation", "comments": "6 pages, 4 figures, 1 table, Published at the EXAG workshop as a part\n  of AIIDE 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the problem of tutorial generation for games, i.e. to generate\ntutorials which can teach players to play games, as an AI problem. This problem\ncan be approached in several ways, including generating natural language\ndescriptions of game rules, generating instructive game levels, and generating\ndemonstrations of how to play a game using agents that play in a human-like\nmanner. We further argue that the General Video Game AI framework provides a\nuseful testbed for addressing this problem.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 01:21:33 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Green", "Michael Cerny", ""], ["Khalifa", "Ahmed", ""], ["Barros", "Gabriella A. B.", ""], ["Togelius", "Julian", ""]]}, {"id": "1805.11778", "submitter": "Sakyasingha Dasgupta", "authors": "Fernando Camaro Nogues, Andrew Huie, Sakyasingha Dasgupta", "title": "Object Detection using Domain Randomization and Generative Adversarial\n  Refinement of Synthetic Images", "comments": "CVPR 2018 Deep Vision Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an application of domain randomization and\ngenerative adversarial networks (GAN) to train a near real-time object detector\nfor industrial electric parts, entirely in a simulated environment. Large scale\navailability of labelled real world data is typically rare and difficult to\nobtain in many industrial settings. As such here, only a few hundred of\nunlabelled real images are used to train a Cyclic-GAN network, in combination\nwith various degree of domain randomization procedures. We demonstrate that\nthis enables robust translation of synthetic images to the real world domain.\nWe show that a combination of the original synthetic (simulation) and GAN\ntranslated images, when used for training a Mask-RCNN object detection network\nachieves greater than 0.95 mean average precision in detecting and classifying\na collection of industrial electric parts. We evaluate the performance across\ndifferent combinations of training data.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 02:27:10 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 09:50:33 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Nogues", "Fernando Camaro", ""], ["Huie", "Andrew", ""], ["Dasgupta", "Sakyasingha", ""]]}, {"id": "1805.11799", "submitter": "Taro Sekiyama", "authors": "Taro Sekiyama and Kohei Suenaga", "title": "Automated proof synthesis for propositional logic with deep neural\n  networks", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.LG cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the application of deep learning, a machine learning\ntechnique that uses deep neural networks (DNN) in its core, to an automated\ntheorem proving (ATP) problem. To this end, we construct a statistical model\nwhich quantifies the likelihood that a proof is indeed a correct one of a given\nproposition. Based on this model, we give a proof-synthesis procedure that\nsearches for a proof in the order of the likelihood. This procedure uses an\nestimator of the likelihood of an inference rule being applied at each step of\na proof. As an implementation of the estimator, we propose a\nproposition-to-proof architecture, which is a DNN tailored to the automated\nproof synthesis problem. To empirically demonstrate its usefulness, we apply\nour model to synthesize proofs of propositional logic. We train the\nproposition-to-proof model using a training dataset of proposition-proof pairs.\nThe evaluation against a benchmark set shows the very high accuracy and an\nimprovement to the recent work of neural proof synthesis.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 04:22:51 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Sekiyama", "Taro", ""], ["Suenaga", "Kohei", ""]]}, {"id": "1805.11815", "submitter": "Puneet Kohli", "authors": "Puneet Kohli and Anjali Chadha", "title": "Enabling Pedestrian Safety using Computer Vision Techniques: A Case\n  Study of the 2018 Uber Inc. Self-driving Car Crash", "comments": "10 pages, 8 figures, 3 tables", "journal-ref": "Arai K., Bhatia R. (eds) Advances in Information and\n  Communication. FICC 2019. Lecture Notes in Networks and Systems, vol 69.\n  Springer, Cham", "doi": "10.1007/978-3-030-12388-8_19", "report-no": null, "categories": "cs.CV cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human lives are important. The decision to allow self-driving vehicles\noperate on our roads carries great weight. This has been a hot topic of debate\nbetween policy-makers, technologists and public safety institutions. The recent\nUber Inc. self-driving car crash, resulting in the death of a pedestrian, has\nstrengthened the argument that autonomous vehicle technology is still not ready\nfor deployment on public roads. In this work, we analyze the Uber car crash and\nshed light on the question, \"Could the Uber Car Crash have been avoided?\". We\napply state-of-the-art Computer Vision models to this highly practical\nscenario. More generally, our experimental results are an evaluation of various\nimage enhancement and object recognition techniques for enabling pedestrian\nsafety in low-lighting conditions using the Uber crash as a case study.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 05:38:30 GMT"}], "update_date": "2020-03-03", "authors_parsed": [["Kohli", "Puneet", ""], ["Chadha", "Anjali", ""]]}, {"id": "1805.11818", "submitter": "Volkan Cirik", "authors": "Volkan Cirik, Louis-Philippe Morency, Taylor Berg-Kirkpatrick", "title": "Visual Referring Expression Recognition: What Do Systems Actually Learn?", "comments": "NAACL2018 short", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.CV cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an empirical analysis of the state-of-the-art systems for\nreferring expression recognition -- the task of identifying the object in an\nimage referred to by a natural language expression -- with the goal of gaining\ninsight into how these systems reason about language and vision. Surprisingly,\nwe find strong evidence that even sophisticated and linguistically-motivated\nmodels for this task may ignore the linguistic structure, instead relying on\nshallow correlations introduced by unintended biases in the data selection and\nannotation process. For example, we show that a system trained and tested on\nthe input image $\\textit{without the input referring expression}$ can achieve a\nprecision of 71.2% in top-2 predictions. Furthermore, a system that predicts\nonly the object category given the input can achieve a precision of 84.2% in\ntop-2 predictions. These surprisingly positive results for what should be\ndeficient prediction scenarios suggest that careful analysis of what our models\nare learning -- and further, how our data is constructed -- is critical as we\nseek to make substantive progress on grounded language tasks.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 06:03:21 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Cirik", "Volkan", ""], ["Morency", "Louis-Philippe", ""], ["Berg-Kirkpatrick", "Taylor", ""]]}, {"id": "1805.11820", "submitter": "Christian Blum", "authors": "Christian Blum and Haroldo Gambini Santos", "title": "Generic CP-Supported CMSA for Binary Integer Linear Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Construct, Merge, Solve and Adapt (CMSA) is a general hybrid metaheuristic\nfor solving combinatorial optimization problems. At each iteration, CMSA (1)\nconstructs feasible solutions to the tackled problem instance in a\nprobabilistic way and (2) solves a reduced problem instance (if possible) to\noptimality. The construction of feasible solutions is hereby problem-specific,\nusually involving a fast greedy heuristic. The goal of this paper is to design\na problem-agnostic CMSA variant whose exclusive input is an integer linear\nprogram (ILP). In order to reduce the complexity of this task, the current\nstudy is restricted to binary ILPs. In addition to a basic problem-agnostic\nCMSA variant, we also present an extended version that makes use of a\nconstraint propagation engine for constructing solutions. The results show that\nour technique is able to match the upper bounds of the standalone application\nof CPLEX in the context of rather easy-to-solve instances, while it generally\noutperforms the standalone application of CPLEX in the context of hard\ninstances. Moreover, the results indicate that the support of the constraint\npropagation engine is useful in the context of problems for which finding\nfeasible solutions is rather difficult.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 06:22:34 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Blum", "Christian", ""], ["Santos", "Haroldo Gambini", ""]]}, {"id": "1805.11867", "submitter": "Chao-Chun Hsu", "authors": "Chao-Chun Hsu, Szu-Min Chen, Ming-Hsun Hsieh, Lun-Wei Ku", "title": "Using Inter-Sentence Diverse Beam Search to Reduce Redundancy in Visual\n  Storytelling", "comments": "Challenge paper in storytelling workshop co-located with NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual storytelling includes two important parts: coherence between the story\nand images as well as the story structure. For image to text neural network\nmodels, similar images in the sequence would provide close information for\nstory generator to obtain almost identical sentence. However, repeatedly\nnarrating same objects or events will undermine a good story structure. In this\npaper, we proposed an inter-sentence diverse beam search to generate a more\nexpressive story. Comparing to some recent models of visual storytelling task,\nwhich generate story without considering the generated sentence of the previous\npicture, our proposed method can avoid generating identical sentence even given\na sequence of similar pictures.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 08:59:44 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Hsu", "Chao-Chun", ""], ["Chen", "Szu-Min", ""], ["Hsieh", "Ming-Hsun", ""], ["Ku", "Lun-Wei", ""]]}, {"id": "1805.11984", "submitter": "Mihai Andries", "authors": "Mihai Andries, Atabak Dehban, Jos\\'e Santos-Victor", "title": "Automatic generation of object shapes with desired functionalities", "comments": "12 pages, 9 figures, 28 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D objects (artefacts) are made to fulfill functions. Designing an object\noften starts with defining a list of functionalities that it should provide,\nalso known as functional requirements. Today, the design of 3D object models is\nstill a slow and largely artisanal activity, with few Computer-Aided Design\n(CAD) tools existing to aid the exploration of the design solution space. To\naccelerate the design process, we introduce an algorithm for generating object\nshapes with desired functionalities. Following the concept of form follows\nfunction, we assume that existing object shapes were rationally chosen to\nprovide desired functionalities. First, we use an artificial neural network to\nlearn a function-to-form mapping by analysing a dataset of objects labeled with\ntheir functionalities. Then, we combine forms providing one or more desired\nfunctions, generating an object shape that is expected to provide all of them.\nFinally, we verify in simulation whether the generated object possesses the\ndesired functionalities, by defining and executing functionality tests on it.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 14:00:40 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2018 20:11:52 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Andries", "Mihai", ""], ["Dehban", "Atabak", ""], ["Santos-Victor", "Jos\u00e9", ""]]}, {"id": "1805.12069", "submitter": "Eray Ozkural", "authors": "Eray \\\"Ozkural", "title": "Omega: An Architecture for AI Unification", "comments": "This is a high-level overview of the Omega AGI architecture which is\n  the basis of a data science automation system. Submitted to a workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the open-ended, modular, self-improving Omega AI unification\narchitecture which is a refinement of Solomonoff's Alpha architecture, as\nconsidered from first principles. The architecture embodies several crucial\nprinciples of general intelligence including diversity of representations,\ndiversity of data types, integrated memory, modularity, and higher-order\ncognition. We retain the basic design of a fundamental algorithmic substrate\ncalled an \"AI kernel\" for problem solving and basic cognitive functions like\nmemory, and a larger, modular architecture that re-uses the kernel in many\nways. Omega includes eight representation languages and six classes of neural\nnetworks, which are briefly introduced. The architecture is intended to\ninitially address data science automation, hence it includes many problem\nsolving methods for statistical tasks. We review the broad software\narchitecture, higher-order cognition, self-improvement, modular neural\narchitectures, intelligent agents, the process and memory hierarchy, hardware\nabstraction, peer-to-peer computing, and data abstraction facility.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 22:08:28 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["\u00d6zkural", "Eray", ""]]}, {"id": "1805.12085", "submitter": "Lazar Supic", "authors": "Lazar Supic, Rawan Naous, Ranko Sredojevic, Aleksandra Faust, Vladimir\n  Stojanovic", "title": "MPDCompress - Matrix Permutation Decomposition Algorithm for Deep Neural\n  Network Compression", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks (DNNs) have become the state-of-the-art technique for\nmachine learning tasks in various applications. However, due to their size and\nthe computational complexity, large DNNs are not readily deployable on edge\ndevices in real-time. To manage complexity and accelerate computation, network\ncompression techniques based on pruning and quantization have been proposed and\nshown to be effective in reducing network size. However, such network\ncompression can result in irregular matrix structures that are mismatched with\nmodern hardware-accelerated platforms, such as graphics processing units (GPUs)\ndesigned to perform the DNN matrix multiplications in a structured\n(block-based) way. We propose MPDCompress, a DNN compression algorithm based on\nmatrix permutation decomposition via random mask generation. In-training\napplication of the masks molds the synaptic weight connection matrix to a\nsub-graph separation format. Aided by the random permutations, a\nhardware-desirable block matrix is generated, allowing for a more efficient\nimplementation and compression of the network. To show versatility, we\nempirically verify MPDCompress on several network models, compression rates,\nand image datasets. On the LeNet 300-100 model (MNIST dataset), Deep MNIST, and\nCIFAR10, we achieve 10 X network compression with less than 1% accuracy loss\ncompared to non-compressed accuracy performance. On AlexNet for the full\nImageNet ILSVRC-2012 dataset, we achieve 8 X network compression with less than\n1% accuracy loss, with top-5 and top-1 accuracies of 79.6% and 56.4%,\nrespectively. Finally, we observe that the algorithm can offer inference\nspeedups across various hardware platforms, with 4 X faster operation achieved\non several mobile GPUs.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 17:01:30 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Supic", "Lazar", ""], ["Naous", "Rawan", ""], ["Sredojevic", "Ranko", ""], ["Faust", "Aleksandra", ""], ["Stojanovic", "Vladimir", ""]]}, {"id": "1805.12090", "submitter": "Luigi Vigneri", "authors": "Spyridon Vassilaras, Luigi Vigneri, Nikolaos Liakopoulos, Georgios S.\n  Paschos, Apostolos Destounis, Thrasyvoulos Spyropoulos, and Merouane Debbah", "title": "Problem-Adapted Artificial Intelligence for Online Network Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future 5G wireless networks will rely on agile and automated network\nmanagement, where the usage of diverse resources must be jointly optimized with\nsurgical accuracy. A number of key wireless network functionalities (e.g.,\ntraffic steering, power control) give rise to hard optimization problems. What\nis more, high spatio-temporal traffic variability coupled with the need to\nsatisfy strict per slice/service SLAs in modern networks, suggest that these\nproblems must be constantly (re-)solved, to maintain close-to-optimal\nperformance. To this end, we propose the framework of Online Network\nOptimization (ONO), which seeks to maintain both agile and efficient control\nover time, using an arsenal of data-driven, online learning, and AI-based\ntechniques. Since the mathematical tools and the studied regimes vary widely\namong these methodologies, a theoretical comparison is often out of reach.\nTherefore, the important question `what is the right ONO technique?' remains\nopen to date. In this paper, we discuss the pros and cons of each technique and\npresent a direct quantitative comparison for a specific use case, using real\ndata. Our results suggest that carefully combining the insights of problem\nmodeling with state-of-the-art AI techniques provides significant advantages at\nreasonable complexity.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 17:12:48 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 09:54:12 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Vassilaras", "Spyridon", ""], ["Vigneri", "Luigi", ""], ["Liakopoulos", "Nikolaos", ""], ["Paschos", "Georgios S.", ""], ["Destounis", "Apostolos", ""], ["Spyropoulos", "Thrasyvoulos", ""], ["Debbah", "Merouane", ""]]}, {"id": "1805.12114", "submitter": "Roberto Calandra", "authors": "Kurtland Chua and Roberto Calandra and Rowan McAllister and Sergey\n  Levine", "title": "Deep Reinforcement Learning in a Handful of Trials using Probabilistic\n  Dynamics Models", "comments": "NIPS 2018, video and code available at\n  https://sites.google.com/view/drl-in-a-handful-of-trials/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model-based reinforcement learning (RL) algorithms can attain excellent\nsample efficiency, but often lag behind the best model-free algorithms in terms\nof asymptotic performance. This is especially true with high-capacity\nparametric function approximators, such as deep networks. In this paper, we\nstudy how to bridge this gap, by employing uncertainty-aware dynamics models.\nWe propose a new algorithm called probabilistic ensembles with trajectory\nsampling (PETS) that combines uncertainty-aware deep network dynamics models\nwith sampling-based uncertainty propagation. Our comparison to state-of-the-art\nmodel-based and model-free deep RL algorithms shows that our approach matches\nthe asymptotic performance of model-free algorithms on several challenging\nbenchmark tasks, while requiring significantly fewer samples (e.g., 8 and 125\ntimes fewer samples than Soft Actor Critic and Proximal Policy Optimization\nrespectively on the half-cheetah task).\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 17:55:21 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2018 17:19:02 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Chua", "Kurtland", ""], ["Calandra", "Roberto", ""], ["McAllister", "Rowan", ""], ["Levine", "Sergey", ""]]}, {"id": "1805.12115", "submitter": "Mehwish Alam Miss", "authors": "Aldo Gangemi, Mehwish Alam, Valentina Presutti", "title": "Amnestic Forgery: an Ontology of Conceptual Metaphors", "comments": null, "journal-ref": null, "doi": "10.3233/978-1-61499-910-2-159", "report-no": null, "categories": "cs.CL cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents Amnestic Forgery, an ontology for metaphor semantics,\nbased on MetaNet, which is inspired by the theory of Conceptual Metaphor.\nAmnestic Forgery reuses and extends the Framester schema, as an ideal ontology\ndesign framework to deal with both semiotic and referential aspects of frames,\nroles, mappings, and eventually blending. The description of the resource is\nsupplied by a discussion of its applications, with examples taken from metaphor\ngeneration, and the referential problems of metaphoric mappings. Both schema\nand data are available from the Framester SPARQL endpoint.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 17:56:32 GMT"}], "update_date": "2021-01-01", "authors_parsed": [["Gangemi", "Aldo", ""], ["Alam", "Mehwish", ""], ["Presutti", "Valentina", ""]]}, {"id": "1805.12183", "submitter": "Christopher George", "authors": "Christopher A. George, Pranab Banerjee, Kendra E. Moore", "title": "Context Exploitation using Hierarchical Bayesian Models", "comments": "4 pages; 3 figures; 5 tables", "journal-ref": "Proceedings of the National Fire Control Symposium, February 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of how to improve automatic target recognition by\nfusing the naive sensor-level classification decisions with \"intuition,\" or\ncontext, in a mathematically principled way. This is a general approach that is\ncompatible with many definitions of context, but for specificity, we consider\ncontext as co-occurrence in imagery. In particular, we consider images that\ncontain multiple objects identified at various confidence levels. We learn the\npatterns of co-occurrence in each context, then use these patterns as\nhyper-parameters for a Hierarchical Bayesian Model. The result is that\nlow-confidence sensor classification decisions can be dramatically improved by\nfusing those readings with context. We further use hyperpriors to address the\ncase where multiple contexts may be appropriate. We also consider the Bayesian\nNetwork, an alternative to the Hierarchical Bayesian Model, which is\ncomputationally more efficient but assumes that context and sensor readings are\nuncorrelated.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 19:09:11 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["George", "Christopher A.", ""], ["Banerjee", "Pranab", ""], ["Moore", "Kendra E.", ""]]}, {"id": "1805.12279", "submitter": "Tolga Birdal", "authors": "Tolga Birdal, Umut \\c{S}im\\c{s}ekli, M. Onur Eken, Slobodan Ilic", "title": "Bayesian Pose Graph Optimization via Bingham Distributions and Tempered\n  Geodesic MCMC", "comments": "Published at NeurIPS 2018, 25 pages with supplements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.CG cs.RO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Tempered Geodesic Markov Chain Monte Carlo (TG-MCMC) algorithm\nfor initializing pose graph optimization problems, arising in various scenarios\nsuch as SFM (structure from motion) or SLAM (simultaneous localization and\nmapping). TG-MCMC is first of its kind as it unites asymptotically global\nnon-convex optimization on the spherical manifold of quaternions with posterior\nsampling, in order to provide both reliable initial poses and uncertainty\nestimates that are informative about the quality of individual solutions. We\ndevise rigorous theoretical convergence guarantees for our method and\nextensively evaluate it on synthetic and real benchmark datasets. Besides its\nelegance in formulation and theory, we show that our method is robust to\nmissing data, noise and the estimated uncertainties capture intuitive\nproperties of the data.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 01:14:57 GMT"}, {"version": "v2", "created": "Sat, 30 Mar 2019 17:23:30 GMT"}], "update_date": "2019-04-02", "authors_parsed": [["Birdal", "Tolga", ""], ["\u015eim\u015fekli", "Umut", ""], ["Eken", "M. Onur", ""], ["Ilic", "Slobodan", ""]]}, {"id": "1805.12316", "submitter": "Puyudi Yang", "authors": "Puyudi Yang, Jianbo Chen, Cho-Jui Hsieh, Jane-Ling Wang, Michael I.\n  Jordan", "title": "Greedy Attack and Gumbel Attack: Generating Adversarial Examples for\n  Discrete Data", "comments": "The first two authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a probabilistic framework for studying adversarial attacks on\ndiscrete data. Based on this framework, we derive a perturbation-based method,\nGreedy Attack, and a scalable learning-based method, Gumbel Attack, that\nillustrate various tradeoffs in the design of attacks. We demonstrate the\neffectiveness of these methods using both quantitative metrics and human\nevaluation on various state-of-the-art models for text classification,\nincluding a word-based CNN, a character-based CNN and an LSTM. As as example of\nour results, we show that the accuracy of character-based convolutional\nnetworks drops to the level of random selection by modifying only five\ncharacters through Greedy Attack.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 04:40:32 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Yang", "Puyudi", ""], ["Chen", "Jianbo", ""], ["Hsieh", "Cho-Jui", ""], ["Wang", "Jane-Ling", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1805.12346", "submitter": "Marcos Baez", "authors": "Svetlana Nikitina, Florian Daniel, Marcos Baez, Fabio Casati", "title": "Crowdsourcing for Reminiscence Chatbot Design", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work-in-progress paper we discuss the challenges in identifying\neffective and scalable crowd-based strategies for designing content,\nconversation logic, and meaningful metrics for a reminiscence chatbot targeted\nat older adults. We formalize the problem and outline the main research\nquestions that drive the research agenda in chatbot design for reminiscence and\nfor relational agents for older adults in general.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 07:06:11 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Nikitina", "Svetlana", ""], ["Daniel", "Florian", ""], ["Baez", "Marcos", ""], ["Casati", "Fabio", ""]]}, {"id": "1805.12352", "submitter": "Xiaodong Gu", "authors": "Xiaodong Gu, Kyunghyun Cho, Jung-Woo Ha, Sunghun Kim", "title": "DialogWAE: Multimodal Response Generation with Conditional Wasserstein\n  Auto-Encoder", "comments": "Published as a conference paper at ICLR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders~(VAEs) have shown a promise in data-driven\nconversation modeling. However, most VAE conversation models match the\napproximate posterior distribution over the latent variables to a simple prior\nsuch as standard normal distribution, thereby restricting the generated\nresponses to a relatively simple (e.g., unimodal) scope. In this paper, we\npropose DialogWAE, a conditional Wasserstein autoencoder~(WAE) specially\ndesigned for dialogue modeling. Unlike VAEs that impose a simple distribution\nover the latent variables, DialogWAE models the distribution of data by\ntraining a GAN within the latent variable space. Specifically, our model\nsamples from the prior and posterior distributions over the latent variables by\ntransforming context-dependent random noise using neural networks and minimizes\nthe Wasserstein distance between the two distributions. We further develop a\nGaussian mixture prior network to enrich the latent space. Experiments on two\npopular datasets show that DialogWAE outperforms the state-of-the-art\napproaches in generating more coherent, informative and diverse responses.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 07:25:04 GMT"}, {"version": "v2", "created": "Tue, 26 Feb 2019 02:32:44 GMT"}], "update_date": "2019-02-27", "authors_parsed": [["Gu", "Xiaodong", ""], ["Cho", "Kyunghyun", ""], ["Ha", "Jung-Woo", ""], ["Kim", "Sunghun", ""]]}, {"id": "1805.12387", "submitter": "Laurent Orseau", "authors": "Laurent Orseau, Simon McGregor McGill, Shane Legg", "title": "Agents and Devices: A Relative Definition of Agency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  According to Dennett, the same system may be described using a `physical'\n(mechanical) explanatory stance, or using an `intentional' (belief- and\ngoal-based) explanatory stance. Humans tend to find the physical stance more\nhelpful for certain systems, such as planets orbiting a star, and the\nintentional stance for others, such as living animals. We define a formal\ncounterpart of physical and intentional stances within computational theory: a\ndescription of a system as either a device, or an agent, with the key\ndifference being that `devices' are directly described in terms of an\ninput-output mapping, while `agents' are described in terms of the function\nthey optimise. Bayes' rule can then be applied to calculate the subjective\nprobability of a system being a device or an agent, based only on its\nbehaviour. We illustrate this using the trajectories of an object in a toy\ngrid-world domain.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 09:12:14 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Orseau", "Laurent", ""], ["McGill", "Simon McGregor", ""], ["Legg", "Shane", ""]]}, {"id": "1805.12393", "submitter": "Yuyu Zhang", "authors": "Yuyu Zhang, Hanjun Dai, Kamil Toraman, Le Song", "title": "KG^2: Learning to Reason Science Exam Questions with Contextual\n  Knowledge Graph Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AI2 Reasoning Challenge (ARC), a new benchmark dataset for question\nanswering (QA) has been recently released. ARC only contains natural science\nquestions authored for human exams, which are hard to answer and require\nadvanced logic reasoning. On the ARC Challenge Set, existing state-of-the-art\nQA systems fail to significantly outperform random baseline, reflecting the\ndifficult nature of this task. In this paper, we propose a novel framework for\nanswering science exam questions, which mimics human solving process in an\nopen-book exam. To address the reasoning challenge, we construct contextual\nknowledge graphs respectively for the question itself and supporting sentences.\nOur model learns to reason with neural embeddings of both knowledge graphs.\nExperiments on the ARC Challenge Set show that our model outperforms the\nprevious state-of-the-art QA systems.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 09:39:14 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Zhang", "Yuyu", ""], ["Dai", "Hanjun", ""], ["Toraman", "Kamil", ""], ["Song", "Le", ""]]}, {"id": "1805.12402", "submitter": "Ernesto Jimenez-Ruiz", "authors": "Ernesto Jimenez-Ruiz and Asan Agibetov and Matthias Samwald and\n  Valerie Cross", "title": "Breaking-down the Ontology Alignment Task with a Lexical Index and\n  Neural Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large ontologies still pose serious challenges to state-of-the-art ontology\nalignment systems. In the paper we present an approach that combines a lexical\nindex, a neural embedding model and locality modules to effectively divide an\ninput ontology matching task into smaller and more tractable matching\n(sub)tasks. We have conducted a comprehensive evaluation using the datasets of\nthe Ontology Alignment Evaluation Initiative. The results are encouraging and\nsuggest that the proposed methods are adequate in practice and can be\nintegrated within the workflow of state-of-the-art systems.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 09:57:01 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Jimenez-Ruiz", "Ernesto", ""], ["Agibetov", "Asan", ""], ["Samwald", "Matthias", ""], ["Cross", "Valerie", ""]]}, {"id": "1805.12475", "submitter": "Michael Green", "authors": "Gabriella A. B. Barros, Michael Cerny Green, Antonios Liapis, and\n  Julian Togelius", "title": "Data-driven Design: A Case for Maximalist Game Design", "comments": "9 pages, 2 Figures, Accepted in ICCC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximalism in art refers to drawing on and combining multiple different\nsources for art creation, embracing the resulting collisions and heterogeneity.\nThis paper discusses the use of maximalism in game design and particularly in\ndata games, which are games that are generated partly based on open data. Using\nData Adventures, a series of generators that create adventure games from data\nsources such as Wikipedia and OpenStreetMap, as a lens we explore several\ntradeoffs and issues in maximalist game design. This includes the tension\nbetween transformation and fidelity, between decorative and functional content,\nand legal and ethical issues resulting from this type of generativity. This\npaper sketches out the design space of maximalist data-driven games, a design\nspace that is mostly unexplored.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 00:43:03 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Barros", "Gabriella A. B.", ""], ["Green", "Michael Cerny", ""], ["Liapis", "Antonios", ""], ["Togelius", "Julian", ""]]}, {"id": "1805.12487", "submitter": "Seong Joon Oh", "authors": "Edgar Tretschk, Seong Joon Oh, Mario Fritz", "title": "Sequential Attacks on Agents for Long-Term Adversarial Goals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CR cs.CV stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) has advanced greatly in the past few years with\nthe employment of effective deep neural networks (DNNs) on the policy networks.\nWith the great effectiveness came serious vulnerability issues with DNNs that\nsmall adversarial perturbations on the input can change the output of the\nnetwork. Several works have pointed out that learned agents with a DNN policy\nnetwork can be manipulated against achieving the original task through a\nsequence of small perturbations on the input states. In this paper, we\ndemonstrate furthermore that it is also possible to impose an arbitrary\nadversarial reward on the victim policy network through a sequence of attacks.\nOur method involves the latest adversarial attack technique, Adversarial\nTransformer Network (ATN), that learns to generate the attack and is easy to\nintegrate into the policy network. As a result of our attack, the victim agent\nis misguided to optimise for the adversarial reward over time. Our results\nexpose serious security threats for RL applications in safety-critical systems\nincluding drones, medical analysis, and self-driving cars.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 14:22:09 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 17:31:14 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Tretschk", "Edgar", ""], ["Oh", "Seong Joon", ""], ["Fritz", "Mario", ""]]}, {"id": "1805.12495", "submitter": "Reza Shahbazi", "authors": "Reza Shahbazi", "title": "Invariant Representation of Mathematical Expressions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While there exist many methods in machine learning for comparison of letter\nstring data, most are better equipped to handle strings that represent natural\nlanguage, and their performance will not hold up when presented with strings\nthat correspond to mathematical expressions. Based on the graphical\nrepresentation of the expression tree, here we propose a simple method for\nencoding such expressions that is only sensitive to their structural\nproperties, and invariant to the specifics which can vary between two seemingly\ndifferent, but semantically similar mathematical expressions.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 22:48:59 GMT"}, {"version": "v2", "created": "Thu, 11 Feb 2021 20:44:04 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Shahbazi", "Reza", ""]]}, {"id": "1805.12514", "submitter": "Eric Wong", "authors": "Eric Wong, Frank R. Schmidt, Jan Hendrik Metzen, J. Zico Kolter", "title": "Scaling provable adversarial defenses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work has developed methods for learning deep network classifiers that\nare provably robust to norm-bounded adversarial perturbation; however, these\nmethods are currently only possible for relatively small feedforward networks.\nIn this paper, in an effort to scale these approaches to substantially larger\nmodels, we extend previous work in three main directions. First, we present a\ntechnique for extending these training procedures to much more general\nnetworks, with skip connections (such as ResNets) and general nonlinearities;\nthe approach is fully modular, and can be implemented automatically (analogous\nto automatic differentiation). Second, in the specific case of $\\ell_\\infty$\nadversarial perturbations and networks with ReLU nonlinearities, we adopt a\nnonlinear random projection for training, which scales linearly in the number\nof hidden units (previous approaches scaled quadratically). Third, we show how\nto further improve robust error through cascade models. On both MNIST and CIFAR\ndata sets, we train classifiers that improve substantially on the state of the\nart in provable robust adversarial error bounds: from 5.8% to 3.1% on MNIST\n(with $\\ell_\\infty$ perturbations of $\\epsilon=0.1$), and from 80% to 36.4% on\nCIFAR (with $\\ell_\\infty$ perturbations of $\\epsilon=2/255$). Code for all\nexperiments in the paper is available at\nhttps://github.com/locuslab/convex_adversarial/.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 15:25:10 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 19:53:03 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Wong", "Eric", ""], ["Schmidt", "Frank R.", ""], ["Metzen", "Jan Hendrik", ""], ["Kolter", "J. Zico", ""]]}, {"id": "1805.12559", "submitter": "Aris Filos-Ratsikas", "authors": "Aris Filos-Ratsikas, Paul W. Goldberg", "title": "The Complexity of Splitting Necklaces and Bisecting Ham Sandwiches", "comments": "58 pages, 20 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.AI cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We resolve the computational complexity of two problems known as\nNECKLACE-SPLITTING and DISCRETE HAM SANDWICH, showing that they are\nPPA-complete. For NECKLACE SPLITTING, this result is specific to the important\nspecial case in which two thieves share the necklace. We do this via a\nPPA-completeness result for an approximate version of the CONSENSUS-HALVING\nproblem, strengthening our recent result that the problem is PPA-complete for\ninverse-exponential precision. At the heart of our construction is a smooth\nembedding of the high-dimensional M\\\"obius strip in the CONSENSUS-HALVING\nproblem. These results settle the status of PPA as a class that captures the\ncomplexity of \"natural\" problems whose definitions do not incorporate a\ncircuit.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 16:57:56 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 12:18:25 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Filos-Ratsikas", "Aris", ""], ["Goldberg", "Paul W.", ""]]}, {"id": "1805.12565", "submitter": "Tal Friedman", "authors": "Tal Friedman, Guy Van den Broeck", "title": "Approximate Knowledge Compilation by Online Collapsed Importance\n  Sampling", "comments": "paper + supplementary material", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce collapsed compilation, a novel approximate inference algorithm\nfor discrete probabilistic graphical models. It is a collapsed sampling\nalgorithm that incrementally selects which variable to sample next based on the\npartial sample obtained so far. This online collapsing, together with knowledge\ncompilation inference on the remaining variables, naturally exploits local\nstructure and context- specific independence in the distribution. These\nproperties are naturally exploited in exact inference, but are difficult to\nharness for approximate inference. More- over, by having a partially compiled\ncircuit available during sampling, collapsed compilation has access to a highly\neffective proposal distribution for importance sampling. Our experimental\nevaluation shows that collapsed compilation performs well on standard\nbenchmarks. In particular, when the amount of exact inference is equally\nlimited, collapsed compilation is competitive with the state of the art, and\noutperforms it on several benchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 17:13:13 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Friedman", "Tal", ""], ["Broeck", "Guy Van den", ""]]}]