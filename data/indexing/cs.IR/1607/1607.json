[{"id": "1607.00024", "submitter": "Tal Hadad", "authors": "Tal Hadad", "title": "Review Based Rating Prediction", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems are an important units in today's e-commerce\napplications, such as targeted advertising, personalized marketing and\ninformation retrieval. In recent years, the importance of contextual\ninformation has motivated generation of personalized recommendations according\nto the available contextual information of users.\n  Compared to the traditional systems which mainly utilize users' rating\nhistory, review-based recommendation hopefully provide more relevant results to\nusers. We introduce a review-based recommendation approach that obtains\ncontextual information by mining user reviews. The proposed approach relate to\nfeatures obtained by analyzing textual reviews using methods developed in\nNatural Language Processing (NLP) and information retrieval discipline to\ncompute a utility function over a given item. An item utility is a measure that\nshows how much it is preferred according to user's current context.\n  In our system, the context inference is modeled as similarity between the\nusers reviews history and the item reviews history. As an example application,\nwe used our method to mine contextual data from customers' reviews of movies\nand use it to produce review-based rating prediction. The predicted ratings can\ngenerate recommendations that are item-based and should appear at the\nrecommended items list in the product page. Our evaluations suggest that our\nsystem can help produce better prediction rating scores in comparison to the\nstandard prediction methods.\n", "versions": [{"version": "v1", "created": "Thu, 30 Jun 2016 20:16:58 GMT"}, {"version": "v2", "created": "Tue, 5 Jul 2016 18:50:22 GMT"}, {"version": "v3", "created": "Wed, 27 Jul 2016 11:06:09 GMT"}, {"version": "v4", "created": "Thu, 28 Jul 2016 07:48:46 GMT"}], "update_date": "2016-07-29", "authors_parsed": [["Hadad", "Tal", ""]]}, {"id": "1607.00167", "submitter": "Pedro Saleiro", "authors": "Jo\\~ao Oliveira, Mike Pinto, Pedro Saleiro, Jorge Teixeira", "title": "SentiBubbles: Topic Modeling and Sentiment Visualization of\n  Entity-centric Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Media users tend to mention entities when reacting to news events. The\nmain purpose of this work is to create entity-centric aggregations of tweets on\na daily basis. By applying topic modeling and sentiment analysis, we create\ndata visualization insights about current events and people reactions to those\nevents from an entity-centric perspective.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 09:15:13 GMT"}, {"version": "v2", "created": "Tue, 23 Jan 2018 21:20:34 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Oliveira", "Jo\u00e3o", ""], ["Pinto", "Mike", ""], ["Saleiro", "Pedro", ""], ["Teixeira", "Jorge", ""]]}, {"id": "1607.00223", "submitter": "Claudio Gennaro", "authors": "Claudio Gennaro", "title": "Memory Based Collaborative Filtering with Lucene", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory Based Collaborative Filtering is a widely used approach to provide\nrecommendations. It exploits similarities between ratings across a population\nof users by forming a weighted vote to predict unobserved ratings. Bespoke\nsolutions are frequently adopted to deal with the problem of high quality\nrecommendations on large data sets. A disadvantage of this approach, however,\nis the loss of generality and flexibility of the general collaborative\nfiltering systems. In this paper, we have developed a methodology that allows\none to build a scalable and effective collaborative filtering system on top of\na conventional full-text search engine such as Apache Lucene.\n", "versions": [{"version": "v1", "created": "Fri, 1 Jul 2016 12:45:43 GMT"}], "update_date": "2016-07-04", "authors_parsed": [["Gennaro", "Claudio", ""]]}, {"id": "1607.00570", "submitter": "Cedric De Boom", "authors": "Cedric De Boom, Steven Van Canneyt, Thomas Demeester, Bart Dhoedt", "title": "Representation learning for very short texts using weighted word\n  embedding aggregation", "comments": "8 pages, 3 figures, 2 tables, appears in Pattern Recognition Letters", "journal-ref": null, "doi": "10.1016/j.patrec.2016.06.012", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Short text messages such as tweets are very noisy and sparse in their use of\nvocabulary. Traditional textual representations, such as tf-idf, have\ndifficulty grasping the semantic meaning of such texts, which is important in\napplications such as event detection, opinion mining, news recommendation, etc.\nWe constructed a method based on semantic word embeddings and frequency\ninformation to arrive at low-dimensional representations for short texts\ndesigned to capture semantic similarity. For this purpose we designed a\nweight-based model and a learning procedure based on a novel median-based loss\nfunction. This paper discusses the details of our model and the optimization\nmethods, together with the experimental results on both Wikipedia and Twitter\ndata. We find that our method outperforms the baseline approaches in the\nexperiments, and that it generalizes well on different word embeddings without\nretraining. Our method is therefore capable of retaining most of the semantic\ninformation in the text, and is applicable out-of-the-box.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jul 2016 23:10:09 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["De Boom", "Cedric", ""], ["Van Canneyt", "Steven", ""], ["Demeester", "Thomas", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1607.00647", "submitter": "Shenglin Zhao", "authors": "Shenglin Zhao, Irwin King, and Michael R. Lyu", "title": "A Survey of Point-of-interest Recommendation in Location-based Social\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Point-of-interest (POI) recommendation that suggests new places for users to\nvisit arises with the popularity of location-based social networks (LBSNs). Due\nto the importance of POI recommendation in LBSNs, it has attracted much\nacademic and industrial interest. In this paper, we offer a systematic review\nof this field, summarizing the contributions of individual efforts and\nexploring their relations. We discuss the new properties and challenges in POI\nrecommendation, compared with traditional recommendation problems, e.g., movie\nrecommendation. Then, we present a comprehensive review in three aspects:\ninfluential factors for POI recommendation, methodologies employed for POI\nrecommendation, and different tasks in POI recommendation. Specifically, we\npropose three taxonomies to classify POI recommendation systems. First, we\ncategorize the systems by the influential factors check-in characteristics,\nincluding the geographical information, social relationship, temporal\ninfluence, and content indications. Second, we categorize the systems by the\nmethodology, including systems modeled by fused methods and joint methods.\nThird, we categorize the systems as general POI recommendation and successive\nPOI recommendation by subtle differences in the recommendation task whether to\nbe bias to the recent check-in. For each category, we summarize the\ncontributions and system features, and highlight the representative work.\nMoreover, we discuss the available data sets and the popular metrics. Finally,\nwe point out the possible future directions in this area and conclude this\nsurvey.\n", "versions": [{"version": "v1", "created": "Sun, 3 Jul 2016 14:42:18 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Zhao", "Shenglin", ""], ["King", "Irwin", ""], ["Lyu", "Michael R.", ""]]}, {"id": "1607.00719", "submitter": "Le Dong", "authors": "Gaipeng Kong, Le Dong, Wenpu Dong, Liang Zheng, Qi Tian", "title": "Coarse2Fine: Two-Layer Fusion For Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of large-scale image retrieval. We propose a\ntwo-layer fusion method which takes advantage of global and local cues and\nranks database images from coarse to fine (C2F). Departing from the previous\nmethods fusing multiple image descriptors simultaneously, C2F is featured by a\nlayered procedure composed by filtering and refining. In particular, C2F\nconsists of three components. 1) Distractor filtering. With holistic\nrepresentations, noise images are filtered out from the database, so the number\nof candidate images to be used for comparison with the query can be greatly\nreduced. 2) Adaptive weighting. For a certain query, the similarity of\ncandidate images can be estimated by holistic similarity scores in\ncomplementary to the local ones. 3) Candidate refining. Accurate retrieval is\nconducted via local features, combining the pre-computed adaptive weights.\nExperiments are presented on two benchmarks, \\emph{i.e.,} Holidays and Ukbench\ndatasets. We show that our method outperforms recent fusion methods in terms of\nstorage consumption and computation complexity, and that the accuracy is\ncompetitive to the state-of-the-arts.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2016 01:56:20 GMT"}], "update_date": "2016-07-05", "authors_parsed": [["Kong", "Gaipeng", ""], ["Dong", "Le", ""], ["Dong", "Wenpu", ""], ["Zheng", "Liang", ""], ["Tian", "Qi", ""]]}, {"id": "1607.01050", "submitter": "Sriraam Natarajan", "authors": "Shuo Yang, Mohammed Korayem, Khalifeh AlJadda, Trey Grainger, Sriraam\n  Natarajan", "title": "Application of Statistical Relational Learning to Hybrid Recommendation\n  Systems", "comments": "Statistical Relational AI 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems usually involve exploiting the relations among known\nfeatures and content that describe items (content-based filtering) or the\noverlap of similar users who interacted with or rated the target item\n(collaborative filtering). To combine these two filtering approaches, current\nmodel-based hybrid recommendation systems typically require extensive feature\nengineering to construct a user profile. Statistical Relational Learning (SRL)\nprovides a straightforward way to combine the two approaches. However, due to\nthe large scale of the data used in real world recommendation systems, little\nresearch exists on applying SRL models to hybrid recommendation systems, and\nessentially none of that research has been applied on real big-data-scale\nsystems. In this paper, we proposed a way to adapt the state-of-the-art in SRL\nlearning approaches to construct a real hybrid recommendation system.\nFurthermore, in order to satisfy a common requirement in recommendation systems\n(i.e. that false positives are more undesirable and therefore penalized more\nharshly than false negatives), our approach can also allow tuning the trade-off\nbetween the precision and recall of the system in a principled way. Our\nexperimental results demonstrate the efficiency of our proposed approach as\nwell as its improved performance on recommendation precision.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2016 21:21:59 GMT"}], "update_date": "2016-07-06", "authors_parsed": [["Yang", "Shuo", ""], ["Korayem", "Mohammed", ""], ["AlJadda", "Khalifeh", ""], ["Grainger", "Trey", ""], ["Natarajan", "Sriraam", ""]]}, {"id": "1607.01274", "submitter": "Baiyang Wang", "authors": "Baiyang Wang, Diego Klabjan", "title": "Temporal Topic Analysis with Endogenous and Exogenous Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of modeling temporal textual data taking endogenous\nand exogenous processes into account. Such text documents arise in real world\napplications, including job advertisements and economic news articles, which\nare influenced by the fluctuations of the general economy. We propose a\nhierarchical Bayesian topic model which imposes a \"group-correlated\"\nhierarchical structure on the evolution of topics over time incorporating both\nprocesses, and show that this model can be estimated from Markov chain Monte\nCarlo sampling methods. We further demonstrate that this model captures the\nintrinsic relationships between the topic distribution and the time-dependent\nfactors, and compare its performance with latent Dirichlet allocation (LDA) and\ntwo other related models. The model is applied to two collections of documents\nto illustrate its empirical performance: online job advertisements from\nDirectEmployers Association and journalists' postings on BusinessInsider.com.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jul 2016 01:16:55 GMT"}], "update_date": "2016-07-06", "authors_parsed": [["Wang", "Baiyang", ""], ["Klabjan", "Diego", ""]]}, {"id": "1607.01381", "submitter": "Yahel David", "authors": "Yahel David, Dotan Di Castro and Zohar Karnin", "title": "One-Shot Session Recommendation Systems with Combinatorial Items", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, content recommendation systems in large websites (or\n\\emph{content providers}) capture an increased focus. While the type of content\nvaries, e.g.\\ movies, articles, music, advertisements, etc., the high level\nproblem remains the same. Based on knowledge obtained so far on the user,\nrecommend the most desired content. In this paper we present a method to handle\nthe well known user-cold-start problem in recommendation systems. In this\nscenario, a recommendation system encounters a new user and the objective is to\npresent items as relevant as possible with the hope of keeping the user's\nsession as long as possible. We formulate an optimization problem aimed to\nmaximize the length of this initial session, as this is believed to be the key\nto have the user come back and perhaps register to the system. In particular,\nour model captures the fact that a single round with low quality recommendation\nis likely to terminate the session. In such a case, we do not proceed to the\nnext round as the user leaves the system, possibly never to seen again. We\ndenote this phenomenon a \\emph{One-Shot Session}. Our optimization problem is\nformulated as an MDP where the action space is of a combinatorial nature as we\nrecommend in each round, multiple items. This huge action space presents a\ncomputational challenge making the straightforward solution intractable. We\nanalyze the structure of the MDP to prove monotone and submodular like\nproperties that allow a computationally efficient solution via a method denoted\nby \\emph{Greedy Value Iteration} (G-VI).\n", "versions": [{"version": "v1", "created": "Tue, 5 Jul 2016 19:40:56 GMT"}], "update_date": "2016-07-06", "authors_parsed": [["David", "Yahel", ""], ["Di Castro", "Dotan", ""], ["Karnin", "Zohar", ""]]}, {"id": "1607.01869", "submitter": "Mihajlo Grbovic", "authors": "Mihajlo Grbovic, Nemanja Djuric, Vladan Radosavljevic, Fabrizio\n  Silvestri, Ricardo Baeza-Yates, Andrew Feng, Erik Ordentlich, Lee Yang, Gavin\n  Owens", "title": "Scalable Semantic Matching of Queries to Ads in Sponsored Search\n  Advertising", "comments": "10 pages, 4 figures, 39th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval, SIGIR 2016, Pisa, Italy", "journal-ref": "39th International ACM SIGIR Conference on Research and\n  Development in Information Retrieval, SIGIR 2016, Pisa, Italy", "doi": "10.1145/2911451.2911538.", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sponsored search represents a major source of revenue for web search engines.\nThis popular advertising model brings a unique possibility for advertisers to\ntarget users' immediate intent communicated through a search query, usually by\ndisplaying their ads alongside organic search results for queries deemed\nrelevant to their products or services. However, due to a large number of\nunique queries it is challenging for advertisers to identify all such relevant\nqueries. For this reason search engines often provide a service of advanced\nmatching, which automatically finds additional relevant queries for advertisers\nto bid on. We present a novel advanced matching approach based on the idea of\nsemantic embeddings of queries and ads. The embeddings were learned using a\nlarge data set of user search sessions, consisting of search queries, clicked\nads and search links, while utilizing contextual information such as dwell time\nand skipped ads. To address the large-scale nature of our problem, both in\nterms of data and vocabulary size, we propose a novel distributed algorithm for\ntraining of the embeddings. Finally, we present an approach for overcoming a\ncold-start problem associated with new ads and queries. We report results of\neditorial evaluation and online tests on actual search traffic. The results\nshow that our approach significantly outperforms baselines in terms of\nrelevance, coverage, and incremental revenue. Lastly, we open-source learned\nquery embeddings to be used by researchers in computational advertising and\nrelated fields.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2016 03:43:12 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Grbovic", "Mihajlo", ""], ["Djuric", "Nemanja", ""], ["Radosavljevic", "Vladan", ""], ["Silvestri", "Fabrizio", ""], ["Baeza-Yates", "Ricardo", ""], ["Feng", "Andrew", ""], ["Ordentlich", "Erik", ""], ["Yang", "Lee", ""], ["Owens", "Gavin", ""]]}, {"id": "1607.01958", "submitter": "Kalyani Joshi Ms", "authors": "Joshi Kalyani, Prof. H. N. Bharathi, Prof. Rao Jyothi", "title": "Stock trend prediction using news sentiment analysis", "comments": "11 PAGES, 4 FIGURES", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient Market Hypothesis is the popular theory about stock prediction.\nWith its failure much research has been carried in the area of prediction of\nstocks. This project is about taking non quantifiable data such as financial\nnews articles about a company and predicting its future stock trend with news\nsentiment classification. Assuming that news articles have impact on stock\nmarket, this is an attempt to study relationship between news and stock trend.\nTo show this, we created three different classification models which depict\npolarity of news articles being positive or negative. Observations show that RF\nand SVM perform well in all types of testing. Na\\\"ive Bayes gives good result\nbut not compared to the other two. Experiments are conducted to evaluate\nvarious aspects of the proposed model and encouraging results are obtained in\nall of the experiments. The accuracy of the prediction model is more than 80%\nand in comparison with news random labeling with 50% of accuracy; the model has\nincreased the accuracy by 30%.\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2016 10:48:34 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Kalyani", "Joshi", ""], ["Bharathi", "Prof. H. N.", ""], ["Jyothi", "Prof. Rao", ""]]}, {"id": "1607.02062", "submitter": "Georg Groh", "authors": "Christoph Fuchs and Akash Nayyar and Ruth Nussbaumer and Georg Groh", "title": "Estimating the Dissemination of Social and Mobile Search in Categories\n  of Information Needs Using Websites as Proxies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing popularity of social means to satisfy information needs\nusing Social Media (e.g., Social Media Question Asking, SMQA) or Social\nInformation Retrieval approaches, this paper tries to identify types of\ninformation needs which are inherently social and therefore better suited for\nthose techniques. We describe an experiment where prominent websites from\nvarious content categories are used to represent their respective content area\nand allow to correlate attributes of the content areas. The underlying\nassumption is that successful websites for focused content areas perfectly\nalign with the information seekers' requirements when satisfying information\nneeds in the respective content areas. Based on a manually collected dataset of\nURLs from websites covering a broad range of topics taken from Alexa\n(http://www.alexa.com} (retrieved 2015-11-04)) (a company that publishes\nstatistics about web traffic), a crowdsourcing approach is employed to rate the\ninformation needs that could get solved by the respective URLs according to\nseveral dimensions (incl. sociality and mobility) to investigate possible\ncorrelations with other attributes. Our results suggest that information needs\nwhich do not require a certain formal expertise play an important role in\nsocial information retrieval and that some content areas are better suited for\nsocial information retrieval (e.g., Factual Knowledge & News, Games, Lifestyle)\nthan others (e.g., Health & Lifestyle).\n", "versions": [{"version": "v1", "created": "Thu, 7 Jul 2016 16:01:41 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Fuchs", "Christoph", ""], ["Nayyar", "Akash", ""], ["Nussbaumer", "Ruth", ""], ["Groh", "Georg", ""]]}, {"id": "1607.02355", "submitter": "Dr. Zubair Asghar", "authors": "Aurangzeb khan, Khairullah khan, Shakeel Ahmad, Fazal Masood Kundi,\n  Irum Tareen, Muhammad Zubair Asghar", "title": "Lexical Based Semantic Orientation of Online Customer Reviews and Blogs", "comments": null, "journal-ref": "Journal of American Science 2014;10(8)\n  http://www.jofamericanscience.org", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Rapid increase in internet users along with growing power of online review\nsites and social media has given birth to sentiment analysis or opinion mining,\nwhich aims at determining what other people think and comment. Sentiments or\nOpinions contain public generated content about products, services, policies\nand politics. People are usually interested to seek positive and negative\nopinions containing likes and dislikes, shared by users for features of\nparticular product or service. This paper proposed sentence-level lexical based\ndomain independent sentiment classification method for different types of data\nsuch as reviews and blogs. The proposed method is based on general lexicons\ni.e. WordNet, SentiWordNet and user defined lexical dictionaries for semantic\norientation. The relations and glosses of these dictionaries provide solution\nto the domain portability problem. The method performs better than word and\ntext level corpus based machine learning methods for semantic orientation. The\nresults show the proposed method performs better as it shows precision of 87%\nand83% at document and sentence levels respectively for online comments.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 13:20:35 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["khan", "Aurangzeb", ""], ["khan", "Khairullah", ""], ["Ahmad", "Shakeel", ""], ["Kundi", "Fazal Masood", ""], ["Tareen", "Irum", ""], ["Asghar", "Muhammad Zubair", ""]]}, {"id": "1607.02501", "submitter": "Nemanja Spasojevic", "authors": "Adithya Rao, Nemanja Spasojevic", "title": "Actionable and Political Text Classification using Word Embeddings and\n  LSTM", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we apply word embeddings and neural networks with Long\nShort-Term Memory (LSTM) to text classification problems, where the\nclassification criteria are decided by the context of the application. We\nexamine two applications in particular. The first is that of Actionability,\nwhere we build models to classify social media messages from customers of\nservice providers as Actionable or Non-Actionable. We build models for over 30\ndifferent languages for actionability, and most of the models achieve accuracy\naround 85%, with some reaching over 90% accuracy. We also show that using LSTM\nneural networks with word embeddings vastly outperform traditional techniques.\nSecond, we explore classification of messages with respect to political\nleaning, where social media messages are classified as Democratic or\nRepublican. The model is able to classify messages with a high accuracy of\n87.57%. As part of our experiments, we vary different hyperparameters of the\nneural networks, and report the effect of such variation on the accuracy. These\nactionability models have been deployed to production and help company agents\nprovide customer support by prioritizing which messages to respond to. The\nmodel for political leaning has been opened and made available for wider use.\n", "versions": [{"version": "v1", "created": "Fri, 8 Jul 2016 19:53:56 GMT"}, {"version": "v2", "created": "Wed, 13 Jul 2016 20:53:32 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Rao", "Adithya", ""], ["Spasojevic", "Nemanja", ""]]}, {"id": "1607.02576", "submitter": "K Paramesha", "authors": "K Paramesha and K C Ravishankar", "title": "Analysis of opinionated text for opinion mining", "comments": "Sentiment Analysis, Features, Feature Engineering, Emotions, Word\n  Sense Disambiguation, Sentiment Lexicons, Meta-Information", "journal-ref": "Machine Learning and Applications: An International Journal\n  (MLAIJ) Vol.3, No.2, June 2016", "doi": "10.5121/mlaij.2016.3204", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In sentiment analysis, the polarities of the opinions expressed on an\nobject/feature are determined to assess the sentiment of a sentence or document\nwhether it is positive/negative/neutral. Naturally, the object/feature is a\nnoun representation which refers to a product or a component of a product, let\nus say, the \"lens\" in a camera and opinions emanating on it are captured in\nadjectives, verbs, adverbs and noun words themselves. Apart from such words,\nother meta-information and diverse effective features are also going to play an\nimportant role in influencing the sentiment polarity and contribute\nsignificantly to the performance of the system. In this paper, some of the\nassociated information/meta-data are explored and investigated in the sentiment\ntext. Based on the analysis results presented here, there is scope for further\nassessment and utilization of the meta-information as features in text\ncategorization, ranking text document, identification of spam documents and\npolarity classification problems.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jul 2016 07:11:43 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2016 15:54:29 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Paramesha", "K", ""], ["Ravishankar", "K C", ""]]}, {"id": "1607.02641", "submitter": "Dominik Wurzer Dominik Wurzer", "authors": "Dominik Wurzer, Miles Osborne, Victor Lavrenko", "title": "Randomised Relevance Model", "comments": "Information Retrieval, Query Expansion, Locality Sensitive Hashing,\n  Randomized Algorithm, Relevance Model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relevance Models are well-known retrieval models and capable of producing\ncompetitive results. However, because they use query expansion they can be very\nslow. We address this slowness by incorporating two variants of locality\nsensitive hashing (LSH) into the query expansion process. Results on two\ndocument collections suggest that we can obtain large reductions in the amount\nof work, with a small reduction in effectiveness. Our approach is shown to be\nadditive when pruning query terms.\n", "versions": [{"version": "v1", "created": "Sat, 9 Jul 2016 18:10:06 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Wurzer", "Dominik", ""], ["Osborne", "Miles", ""], ["Lavrenko", "Victor", ""]]}, {"id": "1607.02754", "submitter": "Zhiyuan Fang", "authors": "Zhiyuan Fang, Lingqi Zhang, Kun Chen", "title": "Hybrid Recommender System Based on Personal Behavior Mining", "comments": "15 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommender systems are mostly well known for their applications in\ne-commerce sites and are mostly static models. Classical personalized\nrecommender algorithm includes item-based collaborative filtering method\napplied in Amazon, matrix factorization based collaborative filtering algorithm\nfrom Netflix, etc. In this article, we hope to combine traditional model with\nbehavior pattern extraction method. We use desensitized mobile transaction\nrecord provided by T-mall, Alibaba to build a hybrid dynamic recommender\nsystem. The sequential pattern mining aims to find frequent sequential pattern\nin sequence database and is applied in this hybrid model to predict customers'\npayment behavior thus contributing to the accuracy of the model.\n", "versions": [{"version": "v1", "created": "Sun, 10 Jul 2016 15:32:03 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Fang", "Zhiyuan", ""], ["Zhang", "Lingqi", ""], ["Chen", "Kun", ""]]}, {"id": "1607.02858", "submitter": "Takuya Kitazawa", "authors": "Takuya Kitazawa", "title": "Incremental Factorization Machines for Persistently Cold-starting Online\n  Item Recommendation", "comments": "4 pages, 6 figures, The 1st Workshop on Profiling User Preferences\n  for Dynamic Online and Real-Time Recommendations, RecSys 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-world item recommenders commonly suffer from a persistent cold-start\nproblem which is caused by dynamically changing users and items. In order to\novercome the problem, several context-aware recommendation techniques have been\nrecently proposed. In terms of both feasibility and performance, factorization\nmachine (FM) is one of the most promising methods as generalization of the\nconventional matrix factorization techniques. However, since online algorithms\nare suitable for dynamic data, the static FMs are still inadequate. Thus, this\npaper proposes incremental FMs (iFMs), a general online factorization\nframework, and specially extends iFMs into an online item recommender. The\nproposed framework can be a promising baseline for further development of the\nproduction recommender systems. Evaluation is done empirically both on\nsynthetic and real-world unstable datasets.\n", "versions": [{"version": "v1", "created": "Mon, 11 Jul 2016 08:37:42 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Kitazawa", "Takuya", ""]]}, {"id": "1607.03274", "submitter": "Maria Han Veiga", "authors": "Maria Han Veiga and Carsten Eickhoff", "title": "A Cross-Platform Collection of Social Network Profiles", "comments": "4 pages, 5 figures, SIGIR 2016, short paper. SIGIR 2016 Proceedings\n  of the 39th International ACM SIGIR conference on Research and Development in\n  Information Retrieval", "journal-ref": null, "doi": "10.1145/2911451.2914666", "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of Internet-enabled devices and services has led to a\nshifting balance between digital and analogue aspects of our everyday lives. In\nthe face of this development there is a growing demand for the study of privacy\nhazards, the potential for unique user de-anonymization and information leakage\nbetween the various social media profiles many of us maintain. To enable the\nstructured study of such adversarial effects, this paper presents a dedicated\ndataset of cross-platform social network personas (i.e., the same person has\naccounts on multiple platforms). The corpus comprises 850 users who generate\npredominantly English content. Each user object contains the online footprint\nof the same person in three distinct social networks: Twitter, Instagram and\nFoursquare. In total, it encompasses over 2.5M tweets, 340k check-ins and 42k\nInstagram posts. We describe the collection methodology, characteristics of the\ndataset, and how to obtain it. Finally, we discuss a common use case,\ncross-platform user identification.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2016 09:09:58 GMT"}], "update_date": "2016-07-13", "authors_parsed": [["Veiga", "Maria Han", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "1607.03296", "submitter": "Lorenz Kuhn", "authors": "Lorenz Kuhn and Carsten Eickhoff", "title": "Implicit Negative Feedback in Clinical Information Retrieval", "comments": null, "journal-ref": null, "doi": "10.1145/2911451.2917761", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we reflect on ways to improve the quality of bio-medical\ninformation retrieval by drawing implicit negative feedback from negated\ninformation in noisy natural language search queries. We begin by studying the\nextent to which negations occur in clinical texts and quantify their\ndetrimental effect on retrieval performance. Subsequently, we present a number\nof query reformulation and ranking approaches that remedy these shortcomings by\nresolving natural language negations. Our experimental results are based on\ndata collected in the course of the TREC Clinical Decision Support Track and\nshow consistent improvements compared to state-of-the-art methods. Using our\nnovel algorithms, we are able to reduce the negative impact of negations on\nearly precision by up to 65%.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2016 10:15:15 GMT"}], "update_date": "2016-08-08", "authors_parsed": [["Kuhn", "Lorenz", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "1607.03406", "submitter": "Renata Khasanova", "authors": "Renata Khasanova, Xiaowen Dong, Pascal Frossard", "title": "Multi-modal image retrieval with random walk on multi-layer graphs", "comments": null, "journal-ref": null, "doi": "10.1109/ISM.2016.0011", "report-no": null, "categories": "cs.IR cs.CV cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of large collections of image data is still a challenging\nproblem due to the difficulty of capturing the true concepts in visual data.\nThe similarity between images could be computed using different and possibly\nmultimodal features such as color or edge information or even text labels. This\nmotivates the design of image analysis solutions that are able to effectively\nintegrate the multi-view information provided by different feature sets. We\ntherefore propose a new image retrieval solution that is able to sort images\nthrough a random walk on a multi-layer graph, where each layer corresponds to a\ndifferent type of information about the image data. We study in depth the\ndesign of the image graph and propose in particular an effective method to\nselect the edge weights for the multi-layer graph, such that the image ranking\nscores are optimised. We then provide extensive experiments in different\nreal-world photo collections, which confirm the high performance of our new\nimage retrieval algorithm that generally surpasses state-of-the-art solutions\ndue to a more meaningful image similarity computation.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2016 15:35:01 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Khasanova", "Renata", ""], ["Dong", "Xiaowen", ""], ["Frossard", "Pascal", ""]]}, {"id": "1607.03502", "submitter": "Manuel J. A. Eugster", "authors": "Manuel J. A. Eugster, Tuukka Ruotsalo, Michiel M. Spap\\'e, Oswald\n  Barral, Niklas Ravaja, Giulio Jacucci, Samuel Kaski", "title": "Natural brain-information interfaces: Recommending information by\n  relevance inferred from human brain signals", "comments": null, "journal-ref": "Scientific Reports 6, Article number: 38580 (2016)", "doi": "10.1038/srep38580", "report-no": null, "categories": "cs.IR cs.HC q-bio.NC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding relevant information from large document collections such as the\nWorld Wide Web is a common task in our daily lives. Estimation of a user's\ninterest or search intention is necessary to recommend and retrieve relevant\ninformation from these collections. We introduce a brain-information interface\nused for recommending information by relevance inferred directly from brain\nsignals. In experiments, participants were asked to read Wikipedia documents\nabout a selection of topics while their EEG was recorded. Based on the\nprediction of word relevance, the individual's search intent was modeled and\nsuccessfully used for retrieving new, relevant documents from the whole English\nWikipedia corpus. The results show that the users' interests towards digital\ncontent can be modeled from the brain signals evoked by reading. The introduced\nbrain-relevance paradigm enables the recommendation of information without any\nexplicit user interaction, and may be applied across diverse\ninformation-intensive applications.\n", "versions": [{"version": "v1", "created": "Tue, 12 Jul 2016 20:17:00 GMT"}], "update_date": "2016-12-09", "authors_parsed": [["Eugster", "Manuel J. A.", ""], ["Ruotsalo", "Tuukka", ""], ["Spap\u00e9", "Michiel M.", ""], ["Barral", "Oswald", ""], ["Ravaja", "Niklas", ""], ["Jacucci", "Giulio", ""], ["Kaski", "Samuel", ""]]}, {"id": "1607.04228", "submitter": "Evgeny Frolov", "authors": "Evgeny Frolov, Ivan Oseledets", "title": "Fifty Shades of Ratings: How to Benefit from a Negative Feedback in\n  Top-N Recommendations Tasks", "comments": "Accepted as a long paper at ACM RecSys 2016 conference, 8 pages, 6\n  figures, 2 tables", "journal-ref": null, "doi": "10.1145/2959100.2959170", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conventional collaborative filtering techniques treat a top-n recommendations\nproblem as a task of generating a list of the most relevant items. This\nformulation, however, disregards an opposite - avoiding recommendations with\ncompletely irrelevant items. Due to that bias, standard algorithms, as well as\ncommonly used evaluation metrics, become insensitive to negative feedback. In\norder to resolve this problem we propose to treat user feedback as a\ncategorical variable and model it with users and items in a ternary way. We\nemploy a third-order tensor factorization technique and implement a higher\norder folding-in method to support online recommendations. The method is\nequally sensitive to entire spectrum of user ratings and is able to accurately\npredict relevant items even from a negative only feedback. Our method may\npartially eliminate the need for complicated rating elicitation process as it\nprovides means for personalized recommendations from the very beginning of an\ninteraction with a recommender system. We also propose a modification of\nstandard metrics which helps to reveal unwanted biases and account for\nsensitivity to a negative feedback. Our model achieves state-of-the-art quality\nin standard recommendation tasks while significantly outperforming other\nmethods in the cold-start \"no-positive-feedback\" scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 14 Jul 2016 17:55:33 GMT"}], "update_date": "2016-07-15", "authors_parsed": [["Frolov", "Evgeny", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1607.04373", "submitter": "Ruining He", "authors": "Ruining He, Chen Fang, Zhaowen Wang, Julian McAuley", "title": "Vista: A Visually, Socially, and Temporally-aware Model for Artistic\n  Recommendation", "comments": "8 pages, 3 figures", "journal-ref": null, "doi": "10.1145/2959100.2959152", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding users' interactions with highly subjective content---like\nartistic images---is challenging due to the complex semantics that guide our\npreferences. On the one hand one has to overcome `standard' recommender systems\nchallenges, such as dealing with large, sparse, and long-tailed datasets. On\nthe other, several new challenges present themselves, such as the need to model\ncontent in terms of its visual appearance, or even social dynamics, such as a\npreference toward a particular artist that is independent of the art they\ncreate.\n  In this paper we build large-scale recommender systems to model the dynamics\nof a vibrant digital art community, Behance, consisting of tens of millions of\ninteractions (clicks and `appreciates') of users toward digital art.\nMethodologically, our main contributions are to model (a) rich content,\nespecially in terms of its visual appearance; (b) temporal dynamics, in terms\nof how users prefer `visually consistent' content within and across sessions;\nand (c) social dynamics, in terms of how users exhibit preferences both towards\ncertain art styles, as well as the artists themselves.\n", "versions": [{"version": "v1", "created": "Fri, 15 Jul 2016 03:35:56 GMT"}], "update_date": "2016-07-18", "authors_parsed": [["He", "Ruining", ""], ["Fang", "Chen", ""], ["Wang", "Zhaowen", ""], ["McAuley", "Julian", ""]]}, {"id": "1607.04660", "submitter": "Ognjen Arandjelovi\\'c PhD", "authors": "Victor Andrei and Ognjen Arandjelovic", "title": "Identification of promising research directions using machine learning\n  aided medical literature analysis", "comments": "arXiv admin note: substantial text overlap with arXiv:1512.08008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly expanding corpus of medical research literature presents major\nchallenges in the understanding of previous work, the extraction of maximum\ninformation from collected data, and the identification of promising research\ndirections. We present a case for the use of advanced machine learning\ntechniques as an aide in this task and introduce a novel methodology that is\nshown to be capable of extracting meaningful information from large\nlongitudinal corpora, and of tracking complex temporal changes within it.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2016 12:55:36 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Andrei", "Victor", ""], ["Arandjelovic", "Ognjen", ""]]}, {"id": "1607.05088", "submitter": "Giorgio Roffo", "authors": "Giorgio Roffo", "title": "Towards Personality-Aware Recommendation", "comments": "This paper is an overview of Personality in Computational\n  Advertising: A Benchmark, G. Roffo, ACM RecSys workshop on Emotions and\n  Personality in Personalized Systems, (EMPIRE 2016)", "journal-ref": null, "doi": "10.13140/RG.2.1.4167.0649", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade new ways of shopping online have increased the possibility\nof buying products and services more easily and faster than ever. In this new\ncontext, personality is a key determinant in the decision making of the\nconsumer when shopping. The two main reasons are: firstly, a person's buying\nchoices are influenced by psychological factors like impulsiveness, and\nsecondly, some consumers may be more susceptible to making impulse purchases\nthan others. To the best of our knowledge, the impact of personality factors on\nadvertisements has been largely neglected at the level of recommender systems.\nThis work proposes a highly innovative research which uses a personality\nperspective to determine the unique associations among the consumer's buying\ntendency and advert recommendations. As a matter of fact, the lack of a\npublicly available benchmark for computational advertising do not allow both\nthe exploration of this intriguing research direction and the evaluation of\nstate-of-the-art algorithms. We present the ADS Dataset, a publicly available\nbenchmark for computational advertising enriched with Big-Five users'\npersonality factors and 1,200 personal users' pictures. The proposed benchmark\nallows two main tasks: rating prediction over 300 real advertisements (i.e.,\nRich Media Ads, Image Ads, Text Ads) and click-through rate prediction.\nMoreover, this work carries out experiments, reviews various evaluation\ncriteria used in the literature, and provides a library for each one of them\nwithin one integrated toolbox.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2016 14:08:20 GMT"}, {"version": "v2", "created": "Thu, 21 Jul 2016 11:06:03 GMT"}, {"version": "v3", "created": "Sat, 23 Jul 2016 09:45:57 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Roffo", "Giorgio", ""]]}, {"id": "1607.05208", "submitter": "Jurandy Almeida", "authors": "Leonardo A. Duarte, Ot\\'avio A. B. Penatti, and Jurandy Almeida", "title": "Bag of Attributes for Video Event Retrieval", "comments": null, "journal-ref": "in 2018 31st SIBGRAPI Conference on Graphics, Patterns and Images\n  (SIBGRAPI), Foz do Igua\\c{c}u, Brazil, 2018, pp. 447-454", "doi": "10.1109/SIBGRAPI.2018.00064", "report-no": null, "categories": "cs.IR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the Bag-of-Attributes (BoA) model for video\nrepresentation aiming at video event retrieval. The BoA model is based on a\nsemantic feature space for representing videos, resulting in high-level video\nfeature vectors. For creating a semantic space, i.e., the attribute space, we\ncan train a classifier using a labeled image dataset, obtaining a\nclassification model that can be understood as a high-level codebook. This\nmodel is used to map low-level frame vectors into high-level vectors (e.g.,\nclassifier probability scores). Then, we apply pooling operations to the frame\nvectors to create the final bag of attributes for the video. In the BoA\nrepresentation, each dimension corresponds to one category (or attribute) of\nthe semantic space. Other interesting properties are: compactness, flexibility\nregarding the classifier, and ability to encode multiple semantic concepts in a\nsingle video representation. Our experiments considered the semantic space\ncreated by state-of-the-art convolutional neural networks pre-trained on 1000\nobject categories of ImageNet. Such deep neural networks were used to classify\neach video frame and then different coding strategies were used to encode the\nprobability distribution from the softmax layer into a frame vector. Next,\ndifferent pooling strategies were used to combine frame vectors in the BoA\nrepresentation for a video. Results using BoA were comparable or superior to\nthe baselines in the task of video event retrieval using the EVVE dataset, with\nthe advantage of providing a much more compact representation.\n", "versions": [{"version": "v1", "created": "Mon, 18 Jul 2016 17:24:23 GMT"}, {"version": "v2", "created": "Sat, 26 Dec 2020 13:47:31 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Duarte", "Leonardo A.", ""], ["Penatti", "Ot\u00e1vio A. B.", ""], ["Almeida", "Jurandy", ""]]}, {"id": "1607.05422", "submitter": "Animesh Dutta", "authors": "Abhijit Adhikari, Shivang Singh, Deepjyoti Mondal, Biswanath Dutta,\n  Animesh Dutta", "title": "A Novel Information Theoretic Framework for Finding Semantic Similarity\n  in WordNet", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information content (IC) based measures for finding semantic similarity is\ngaining preferences day by day. Semantics of concepts can be highly\ncharacterized by information theory. The conventional way for calculating IC is\nbased on the probability of appearance of concepts in corpora. Due to data\nsparseness and corpora dependency issues of those conventional approaches, a\nnew corpora independent intrinsic IC calculation measure has evolved. In this\npaper, we mainly focus on such intrinsic IC model and several topological\naspects of the underlying ontology. Accuracy of intrinsic IC calculation and\nsemantic similarity measure rely on these aspects deeply. Based on these\nanalysis we propose an information theoretic framework which comprises an\nintrinsic IC calculator and a semantic similarity model. Our approach is\ncompared with state of the art semantic similarity measures based on corpora\ndependent IC calculation as well as intrinsic IC based methods using several\nbenchmark data set. We also compare our model with the related Edge based,\nFeature based and Distributional approaches. Experimental results show that our\nintrinsic IC model gives high correlation value when applied to different\nsemantic similarity models. Our proposed semantic similarity model also\nachieves significant results when embedded with some state of the art IC models\nincluding ours.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jul 2016 06:32:26 GMT"}], "update_date": "2016-07-20", "authors_parsed": [["Adhikari", "Abhijit", ""], ["Singh", "Shivang", ""], ["Mondal", "Deepjyoti", ""], ["Dutta", "Biswanath", ""], ["Dutta", "Animesh", ""]]}, {"id": "1607.05746", "submitter": "Baichuan Zhang", "authors": "Baichuan Zhang, Murat Dundar, Mohammad Al Hasan", "title": "Bayesian Non-Exhaustive Classification A Case Study: Online Name\n  Disambiguation using Temporal Record Streams", "comments": "to appear in CIKM 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The name entity disambiguation task aims to partition the records of multiple\nreal-life persons so that each partition contains records pertaining to a\nunique person. Most of the existing solutions for this task operate in a batch\nmode, where all records to be disambiguated are initially available to the\nalgorithm. However, more realistic settings require that the name\ndisambiguation task be performed in an online fashion, in addition to, being\nable to identify records of new ambiguous entities having no preexisting\nrecords. In this work, we propose a Bayesian non-exhaustive classification\nframework for solving online name disambiguation task. Our proposed method uses\na Dirichlet process prior with a Normal * Normal * Inverse Wishart data model\nwhich enables identification of new ambiguous entities who have no records in\nthe training data. For online classification, we use one sweep Gibbs sampler\nwhich is very efficient and effective. As a case study we consider\nbibliographic data in a temporal stream format and disambiguate authors by\npartitioning their papers into homogeneous groups. Our experimental results\ndemonstrate that the proposed method is better than existing methods for\nperforming online name disambiguation task.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jul 2016 20:17:10 GMT"}, {"version": "v2", "created": "Mon, 25 Jul 2016 22:19:19 GMT"}, {"version": "v3", "created": "Fri, 2 Sep 2016 00:58:49 GMT"}], "update_date": "2016-09-05", "authors_parsed": [["Zhang", "Baichuan", ""], ["Dundar", "Murat", ""], ["Hasan", "Mohammad Al", ""]]}, {"id": "1607.05806", "submitter": "Siwei Qiang", "authors": "Siwei Qiang and Yongkun Wang and Yaohui Jin", "title": "A Local-Global LDA Model for Discovering Geographical Topics from Social\n  Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Micro-blogging services can track users' geo-locations when users check-in\ntheir places or use geo-tagging which implicitly reveals locations. This \"geo\ntracking\" can help to find topics triggered by some events in certain regions.\nHowever, discovering such topics is very challenging because of the large\namount of noisy messages (e.g. daily conversations). This paper proposes a\nmethod to model geographical topics, which can filter out irrelevant words by\ndifferent weights in the local and global contexts. Our method is based on the\nLatent Dirichlet Allocation (LDA) model but each word is generated from either\na local or a global topic distribution by its generation probabilities. We\nevaluated our model with data collected from Weibo, which is currently the most\npopular micro-blogging service for Chinese. The evaluation results demonstrate\nthat our method outperforms other baseline methods in several metrics such as\nmodel perplexity, two kinds of entropies and KL-divergence of discovered\ntopics.\n", "versions": [{"version": "v1", "created": "Wed, 20 Jul 2016 02:48:15 GMT"}], "update_date": "2016-07-21", "authors_parsed": [["Qiang", "Siwei", ""], ["Wang", "Yongkun", ""], ["Jin", "Yaohui", ""]]}, {"id": "1607.06182", "submitter": "Shiyu Chang", "authors": "Shiyu Chang, Yang Zhang, Jiliang Tang, Dawei Yin, Yi Chang, Mark A.\n  Hasegawa-Johnson, Thomas S. Huang", "title": "Streaming Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing popularity of real-world recommender systems produces data\ncontinuously and rapidly, and it becomes more realistic to study recommender\nsystems under streaming scenarios. Data streams present distinct properties\nsuch as temporally ordered, continuous and high-velocity, which poses\ntremendous challenges to traditional recommender systems. In this paper, we\ninvestigate the problem of recommendation with stream inputs. In particular, we\nprovide a principled framework termed sRec, which provides explicit\ncontinuous-time random process models of the creation of users and topics, and\nof the evolution of their interests. A variational Bayesian approach called\nrecursive meanfield approximation is proposed, which permits computationally\nefficient instantaneous on-line inference. Experimental results on several\nreal-world datasets demonstrate the advantages of our sRec over other\nstate-of-the-arts.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2016 04:10:38 GMT"}], "update_date": "2016-07-22", "authors_parsed": [["Chang", "Shiyu", ""], ["Zhang", "Yang", ""], ["Tang", "Jiliang", ""], ["Yin", "Dawei", ""], ["Chang", "Yi", ""], ["Hasegawa-Johnson", "Mark A.", ""], ["Huang", "Thomas S.", ""]]}, {"id": "1607.06215", "submitter": "Qiyue Yin", "authors": "Kaiye Wang, Qiyue Yin, Wei Wang, Shu Wu, Liang Wang", "title": "A Comprehensive Survey on Cross-modal Retrieval", "comments": "20 pages, 11 figures, 9 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, cross-modal retrieval has drawn much attention due to the\nrapid growth of multimodal data. It takes one type of data as the query to\nretrieve relevant data of another type. For example, a user can use a text to\nretrieve relevant pictures or videos. Since the query and its retrieved results\ncan be of different modalities, how to measure the content similarity between\ndifferent modalities of data remains a challenge. Various methods have been\nproposed to deal with such a problem. In this paper, we first review a number\nof representative methods for cross-modal retrieval and classify them into two\nmain groups: 1) real-valued representation learning, and 2) binary\nrepresentation learning. Real-valued representation learning methods aim to\nlearn real-valued common representations for different modalities of data. To\nspeed up the cross-modal retrieval, a number of binary representation learning\nmethods are proposed to map different modalities of data into a common Hamming\nspace. Then, we introduce several multimodal datasets in the community, and\nshow the experimental results on two commonly used multimodal datasets. The\ncomparison reveals the characteristic of different kinds of cross-modal\nretrieval methods, which is expected to benefit both practical applications and\nfuture research. Finally, we discuss open problems and future research\ndirections.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2016 07:20:44 GMT"}], "update_date": "2016-07-22", "authors_parsed": [["Wang", "Kaiye", ""], ["Yin", "Qiyue", ""], ["Wang", "Wei", ""], ["Wu", "Shu", ""], ["Wang", "Liang", ""]]}, {"id": "1607.06517", "submitter": "Edith Cohen", "authors": "Edith Cohen", "title": "HyperLogLog Hyper Extended: Sketches for Concave Sublinear Frequency\n  Statistics", "comments": "15pages; 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most common statistics computed over data elements is the number\nof distinct keys. A thread of research pioneered by Flajolet and Martin three\ndecades ago culminated in the design of optimal approximate counting sketches,\nwhich have size that is double logarithmic in the number of distinct keys and\nprovide estimates with a small relative error. Moreover, the sketches are\ncomposable, and thus suitable for streamed, parallel, or distributed\ncomputation.\n  We consider here all statistics of the frequency distribution of keys, where\na contribution of a key to the aggregate is concave and grows (sub)linearly\nwith its frequency. These fundamental aggregations are very common in text,\ngraphs, and logs analysis and include logarithms, low frequency moments, and\ncapping statistics.\n  We design composable sketches of double-logarithmic size for all concave\nsublinear statistics. Our design combines theoretical optimality and practical\nsimplicity. In a nutshell, we specify tailored mapping functions of data\nelements to output elements so that our target statistics on the data elements\nis approximated by the (max-) distinct statistics of the output elements, which\ncan be approximated using off-the-shelf sketches. Our key insight is relating\nthese target statistics to the {\\em complement Laplace} transform of the input\nfrequencies.\n", "versions": [{"version": "v1", "created": "Thu, 21 Jul 2016 21:58:37 GMT"}, {"version": "v2", "created": "Mon, 25 Jul 2016 19:08:13 GMT"}, {"version": "v3", "created": "Fri, 14 Oct 2016 18:51:18 GMT"}, {"version": "v4", "created": "Wed, 2 Nov 2016 17:27:15 GMT"}, {"version": "v5", "created": "Fri, 24 Feb 2017 03:06:17 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Cohen", "Edith", ""]]}, {"id": "1607.06532", "submitter": "Kuan-Yu Chen", "authors": "Kuan-Yu Chen, Shih-Hung Liu, Berlin Chen, Hsin-Min Wang, Hsin-Hsi Chen", "title": "Novel Word Embedding and Translation-based Language Modeling for\n  Extractive Speech Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embedding methods revolve around learning continuous distributed vector\nrepresentations of words with neural networks, which can capture semantic\nand/or syntactic cues, and in turn be used to induce similarity measures among\nwords, sentences and documents in context. Celebrated methods can be\ncategorized as prediction-based and count-based methods according to the\ntraining objectives and model architectures. Their pros and cons have been\nextensively analyzed and evaluated in recent studies, but there is relatively\nless work continuing the line of research to develop an enhanced learning\nmethod that brings together the advantages of the two model families. In\naddition, the interpretation of the learned word representations still remains\nsomewhat opaque. Motivated by the observations and considering the pressing\nneed, this paper presents a novel method for learning the word representations,\nwhich not only inherits the advantages of classic word embedding methods but\nalso offers a clearer and more rigorous interpretation of the learned word\nrepresentations. Built upon the proposed word embedding method, we further\nformulate a translation-based language modeling framework for the extractive\nspeech summarization task. A series of empirical evaluations demonstrate the\neffectiveness of the proposed word representation learning and language\nmodeling techniques in extractive speech summarization.\n", "versions": [{"version": "v1", "created": "Fri, 22 Jul 2016 00:20:09 GMT"}], "update_date": "2016-07-25", "authors_parsed": [["Chen", "Kuan-Yu", ""], ["Liu", "Shih-Hung", ""], ["Chen", "Berlin", ""], ["Wang", "Hsin-Min", ""], ["Chen", "Hsin-Hsi", ""]]}, {"id": "1607.06884", "submitter": "Ali Shemshadi", "authors": "Ali Shemshadi, Quan Z. Sheng, Wei Emma Zhang, Aixin Sun, Yongrui Qin,\n  Lina Yao", "title": "Searching for the Internet of Things on the Web: Where It Is and What It\n  Looks Like", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT), in general, is a compelling paradigm that aims\nto connect everyday objects to the Internet. Nowadays, IoT is considered as one\nof the main technologies which contribute towards reshaping our daily lives in\nthe next decade. IoT unlocks many exciting new opportunities in a variety of\napplications in research and industry domains. However, many have complained\nabout the absence of the real-world IoT data. Unsurprisingly, a common question\nthat arises regularly nowadays is \"Does the IoT already exist?\". So far, little\nhas been known about the real-world situation on IoT, its attributes, the\npresentation of data and user interests. To answer this question, in this work,\nwe conduct an in-depth analytical investigation on real IoT data. More\nspecifically, we identify IoT data sources over the Web and develop a crawler\nengine to collect large-scale real-world IoT data for the first time. We make\nthe results of our work available to the public in order to assist the\ncommunity in the future research. In particular, we collect the data of nearly\ntwo million Internet connected objects and study trends in IoT using a\nreal-world query set from an IoT search engine. Based on the collected data and\nour analysis, we identify the typical characteristics of IoT data. The most\nintriguing finding of our study is that IoT data is mainly disseminated using\nWeb Mapping while the emerging IoT solutions such as the Web of Things, are\ncurrently not well adopted. On top of our findings, we further discuss future\nchallenges and open research problems in the IoT area.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jul 2016 03:31:31 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Shemshadi", "Ali", ""], ["Sheng", "Quan Z.", ""], ["Zhang", "Wei Emma", ""], ["Sun", "Aixin", ""], ["Qin", "Yongrui", ""], ["Yao", "Lina", ""]]}, {"id": "1607.07326", "submitter": "Flavian Vasile", "authors": "Flavian Vasile, Elena Smirnova and Alexis Conneau", "title": "Meta-Prod2Vec - Product Embeddings Using Side-Information for\n  Recommendation", "comments": null, "journal-ref": null, "doi": "10.1145/2959100.2959160", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Meta-Prod2vec, a novel method to compute item similarities for\nrecommendation that leverages existing item metadata. Such scenarios are\nfrequently encountered in applications such as content recommendation, ad\ntargeting and web search. Our method leverages past user interactions with\nitems and their attributes to compute low-dimensional embeddings of items.\nSpecifically, the item metadata is in- jected into the model as side\ninformation to regularize the item embeddings. We show that the new item\nrepresenta- tions lead to better performance on recommendation tasks on an open\nmusic dataset.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 15:54:07 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Vasile", "Flavian", ""], ["Smirnova", "Elena", ""], ["Conneau", "Alexis", ""]]}, {"id": "1607.07504", "submitter": "George Tsatsanifos", "authors": "George Tsatsanifos", "title": "Verso folio: Diversified Ranking for Large Graphs with Context-Aware\n  Considerations", "comments": "12 pages of unpublished work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work is pertaining to the diversified ranking of web-resources and\ninterconnected documents that rely on a network-like structure, e.g. web-pages.\nA practical example of this would be a query for the k most relevant web-pages\nthat are also in the same time as dissimilar with each other as possible.\nRelevance and dissimilarity are quantified using an aggregation of network\ndistance and context similarity. For example, for a specific configuration of\nthe problem, we might be interested in web-pages that are similar with the\nquery in terms of their textual description but distant from each other in\nterms of the web-graph, e.g. many clicks away. In retrospect, a dearth of work\ncan be found in the literature addressing this problem taking the network\nstructure formed by the document links into consideration.\n  In this work, we propose a hill-climbing approach that is seeded with a\ndocument collection which is generated using greedy heuristics to diversify\ninitially. More importantly, we tackle the problem in the context of web-pages\nwhere there is an underlying network structure connecting the available\ndocuments and resources. This is a significant difference to the majority of\nworks that tackle the problem in terms of either content definitions, or the\ngraph structure of the data, but never addressing both aspects simultaneously.\nTo the best of our knowledge, this is the very first effort that can be found\nto combine both aspects of this important problem in an elegant fashion by also\nallowing a great degree of flexibility on how to configure the trade-offs of\n(i) document relevance over result-items' dissimilarity, and (ii) network\ndistance over content relevance or dissimilarity. Last but not least, we\npresent an extensive evaluation of our methods that demonstrate the\neffectiveness and efficiency thereof.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jul 2016 23:30:26 GMT"}], "update_date": "2016-07-27", "authors_parsed": [["Tsatsanifos", "George", ""]]}, {"id": "1607.07515", "submitter": "Shawn Mankad", "authors": "Shawn Mankad, Shengli Hu, Anandasivam Gopal", "title": "Single Stage Prediction with Embedded Topic Modeling of Online Reviews\n  for Mobile App Management", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile apps are one of the building blocks of the mobile digital economy. A\ndifferentiating feature of mobile apps to traditional enterprise software is\nonline reviews, which are available on app marketplaces and represent a\nvaluable source of consumer feedback on the app. We create a supervised topic\nmodeling approach for app developers to use mobile reviews as useful sources of\nquality and customer feedback, thereby complementing traditional software\ntesting. The approach is based on a constrained matrix factorization that\nleverages the relationship between term frequency and a given response variable\nin addition to co-occurrences between terms to recover topics that are both\npredictive of consumer sentiment and useful for understanding the underlying\ntextual themes. The factorization is combined with ordinal regression to\nprovide guidance from online reviews on a single app's performance as well as\nsystematically compare different apps over time for benchmarking of features\nand consumer sentiment. We apply our approach using a dataset of over 100,000\nmobile reviews over several years for three of the most popular online travel\nagent apps from the iTunes and Google Play marketplaces.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2016 01:23:17 GMT"}, {"version": "v2", "created": "Sat, 5 Aug 2017 14:37:29 GMT"}, {"version": "v3", "created": "Mon, 19 Feb 2018 18:34:29 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Mankad", "Shawn", ""], ["Hu", "Shengli", ""], ["Gopal", "Anandasivam", ""]]}, {"id": "1607.07904", "submitter": "Julia Kiseleva Julia Kiseleva", "authors": "Julia Kiseleva and Alexander Tuzhilin and Jaap Kamps and Melanie J.I.\n  Mueller and Lucas Bernardi and Chad Davis and Ivan Kovacek and Mats Stafseng\n  Einarsen and Djoerd Hiemstra", "title": "Beyond Movie Recommendations: Solving the Continuous Cold Start Problem\n  in E-commerceRecommendations", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.1.2488.7288", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many e-commerce websites use recommender systems or personalized rankers to\npersonalize search results based on their previous interactions. However, a\nlarge fraction of users has no prior inter-actions, making it impossible to use\ncollaborative filtering or rely on user history for personalization. Even the\nmost active users mayvisit only a few times a year and may have volatile needs\nor different personas, making their personal history a sparse and noisy signal\nat best. This paper investigates how, when we cannot rely on the user history,\nthe large scale availability of other user interactions still allows us to\nbuild meaningful profiles from the contextual data and whether such contextual\nprofiles are useful to customize the ranking, exemplified by data from a major\nonline travel agentBooking.com.Our main findings are threefold: First, we\ncharacterize the Continuous Cold Start Problem(CoCoS) from the viewpoint of\ntypical e-commerce applications. Second, as explicit situational con-text is\nnot available in typical real world applications, implicit cues from\ntransaction logs used at scale can capture essential features of situational\ncontext. Third, contextual user profiles can be created offline, resulting in a\nset of smaller models compared to a single huge non-contextual model, making\ncontextual ranking available with negligible CPU and memory footprint. Finally\nwe conclude that, in an online A/B test on live users, our contextual ranker\nin-creased user engagement substantially over a non-contextual base-line, with\nclick-through-rate (CTR) increased by 20%. This clearly demonstrates the value\nof contextual user profiles in a real world application.\n", "versions": [{"version": "v1", "created": "Tue, 26 Jul 2016 21:32:14 GMT"}], "update_date": "2016-07-28", "authors_parsed": [["Kiseleva", "Julia", ""], ["Tuzhilin", "Alexander", ""], ["Kamps", "Jaap", ""], ["Mueller", "Melanie J. I.", ""], ["Bernardi", "Lucas", ""], ["Davis", "Chad", ""], ["Kovacek", "Ivan", ""], ["Einarsen", "Mats Stafseng", ""], ["Hiemstra", "Djoerd", ""]]}, {"id": "1607.08720", "submitter": "Benjamin Rubinstein", "authors": "Jiazhen He, Benjamin I. P. Rubinstein, James Bailey, Rui Zhang, Sandra\n  Milligan", "title": "TopicResponse: A Marriage of Topic Modelling and Rasch Modelling for\n  Automatic Measurement in MOOCs", "comments": "In preparation for journal submission; Revisions to improve clarity\n  with additional examples", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the suitability of using automatically discovered topics\nfrom MOOC discussion forums for modelling students' academic abilities. The\nRasch model from psychometrics is a popular generative probabilistic model that\nrelates latent student skill, latent item difficulty, and observed student-item\nresponses within a principled, unified framework. According to scholarly\neducational theory, discovered topics can be regarded as appropriate\nmeasurement items if (1) students' participation across the discovered topics\nis well fit by the Rasch model, and if (2) the topics are interpretable to\nsubject-matter experts as being educationally meaningful. Such Rasch-scaled\ntopics, with associated difficulty levels, could be of potential benefit to\ncurriculum refinement, student assessment and personalised feedback. The\ntechnical challenge that remains, is to discover meaningful topics that\nsimultaneously achieve good statistical fit with the Rasch model. To address\nthis challenge, we combine the Rasch model with non-negative matrix\nfactorisation based topic modelling, jointly fitting both models. We\ndemonstrate the suitability of our approach with quantitative experiments on\ndata from three Coursera MOOCs, and with qualitative survey results on topic\ninterpretability on a Discrete Optimisation MOOC.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jul 2016 08:17:45 GMT"}, {"version": "v2", "created": "Mon, 20 Mar 2017 04:30:38 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["He", "Jiazhen", ""], ["Rubinstein", "Benjamin I. P.", ""], ["Bailey", "James", ""], ["Zhang", "Rui", ""], ["Milligan", "Sandra", ""]]}, {"id": "1607.08807", "submitter": "Ingmar Weber", "authors": "Palakorn Achananuparp and Ingmar Weber", "title": "Extracting Food Substitutes From Food Diary via Distributional\n  Similarity", "comments": "To appear at HealthRecSys'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the problem of identifying substitute relationship\nbetween food pairs from real-world food consumption data as the first step\ntowards the healthier food recommendation. Our method is inspired by the\ndistributional hypothesis in linguistics. Specifically, we assume that foods\nthat are consumed in similar contexts are more likely to be similar dietarily.\nFor example, a turkey sandwich can be considered a suitable substitute for a\nchicken sandwich if both tend to be consumed with french fries and salad. To\nevaluate our method, we constructed a real-world food consumption dataset from\nMyFitnessPal's public food diary entries and obtained ground-truth human\njudgements of food substitutes from a crowdsourcing service. The experiment\nresults suggest the effectiveness of the method in identifying suitable\nsubstitutes.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jul 2016 13:46:17 GMT"}], "update_date": "2016-08-01", "authors_parsed": [["Achananuparp", "Palakorn", ""], ["Weber", "Ingmar", ""]]}, {"id": "1607.08883", "submitter": "Souvick Ghosh", "authors": "Satanu Ghosh, Souvick Ghosh, Dipankar Das", "title": "Labeling of Query Words using Conditional Random Field", "comments": "4 pages in Technical Report, FIRE 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our approach on Query Word Labeling as an attempt in the\nshared task on Mixed Script Information Retrieval at Forum for Information\nRetrieval Evaluation (FIRE) 2015. The query is written in Roman script and the\nwords were in English or transliterated from Indian regional languages. A total\nof eight Indian languages were present in addition to English. We also\nidentified the Named Entities and special symbols as part of our task. A CRF\nbased machine learning framework was used for labeling the individual words\nwith their corresponding language labels. We used a dictionary based approach\nfor language identification. We also took into account the context of the word\nwhile identifying the language. Our system demonstrated an overall accuracy of\n75.5% for token level language identification. The strict F-measure scores for\nthe identification of token level language labels for Bengali, English and\nHindi are 0.7486, 0.892 and 0.7972 respectively. The overall weighted F-measure\nof our system was 0.7498.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jul 2016 18:20:24 GMT"}], "update_date": "2016-08-01", "authors_parsed": [["Ghosh", "Satanu", ""], ["Ghosh", "Souvick", ""], ["Das", "Dipankar", ""]]}]