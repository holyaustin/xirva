[{"id": "1907.00083", "submitter": "Benno Kruit", "authors": "Benno Kruit and Peter Boncz and Jacopo Urbani", "title": "Extracting Novel Facts from Tables for Knowledge Graph Completion\n  (Extended version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new end-to-end method for extending a Knowledge Graph (KG) from\ntables. Existing techniques tend to interpret tables by focusing on information\nthat is already in the KG, and therefore tend to extract many redundant facts.\nOur method aims to find more novel facts. We introduce a new technique for\ntable interpretation based on a scalable graphical model using entity\nsimilarities. Our method further disambiguates cell values using KG embeddings\nas additional ranking method. Other distinctive features are the lack of\nassumptions about the underlying KG and the enabling of a fine-grained tuning\nof the precision/recall trade-off of extracted facts. Our experiments show that\nour approach has a higher recall during the interpretation process than the\nstate-of-the-art, and is more resistant against the bias observed in extracting\nmostly redundant facts since it produces more novel extractions.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 21:11:32 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 08:33:39 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Kruit", "Benno", ""], ["Boncz", "Peter", ""], ["Urbani", "Jacopo", ""]]}, {"id": "1907.00119", "submitter": "Fakhri Abbas", "authors": "Fakhri Abbas and Xi Niu", "title": "One Size Does Not Fit All: Modeling Users' Personal Curiosity in\n  Recommender Systems", "comments": "Not satisfied with the current version. Needs a lot of improvement", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's recommender systems are criticized for recommending items that are\ntoo obvious to arouse users' interest. That's why the recommender systems\nresearch community has advocated some \"beyond accuracy\" evaluation metrics such\nas novelty, diversity, coverage, and serendipity with the hope of promoting\ninformation discovery and sustain users' interest over a long period of time.\nWhile bringing in new perspectives, most of these evaluation metrics have not\nconsidered individual users' difference: an open-minded user may favor highly\nnovel or diversified recommendations whereas a conservative user's appetite for\nnovelty or diversity may not be that large. In this paper, we developed a model\nto approximate an individual's curiosity distribution over different levels of\nstimuli guided by the well-known Wundt curve in Psychology. We measured an\nitem's surprise level to assess the stimulation level and whether it is in the\nrange of the user's appetite for stimulus. We then proposed a recommendation\nsystem framework that considers both user preference and appetite for stimulus\nwhere the curiosity is maximally aroused. Our framework differs from a typical\nrecommender system in that it leverages human's curiosity to promote intrinsic\ninterest with the system. A series of evaluation experiments have been\nconducted to show that our framework is able to rank higher the items with not\nonly high ratings but also high response likelihood. The recommendation list\ngenerated by our algorithm has higher potential of inspiring user curiosity\ncompared to traditional approaches. The personalization factor for assessing\nthe stimulus (surprise) strength further helps the recommender achieve smaller\n(better) inter-user similarity.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 00:08:27 GMT"}, {"version": "v2", "created": "Sat, 15 Feb 2020 18:05:10 GMT"}], "update_date": "2020-02-18", "authors_parsed": [["Abbas", "Fakhri", ""], ["Niu", "Xi", ""]]}, {"id": "1907.00157", "submitter": "Sandeep Singh Adhikari Mr", "authors": "Sandeep Singh Adhikari, Sukhneer Singh, Anoop Rajagopal, Aruna Rajan", "title": "Progressive Fashion Attribute Extraction", "comments": "6 pages, 6 figures, AI for fashion : KDD 2019 Workshop, August 2019,\n  Anchorage, Alaska - USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting fashion attributes from images of people wearing clothing/fashion\naccessories is a very hard multi-class classification problem. Most often, even\ncatalogues of fashion do not have all the fine-grained attributes tagged due to\nprohibitive cost of annotation. Using images of fashion articles, running\nmulti-class attribute extraction with a single model for all kinds of\nattributes (neck design detailing, sleeves detailing, etc) requires classifiers\nthat are robust to missing and ambiguously labelled data. In this work, we\npropose a progressive training approach for such multi-class classification,\nwhere weights learnt from an attribute are fine tuned for another attribute of\nthe same fashion article (say, dresses). We branch networks for each attributes\nfrom a base network progressively during training. While it may have many\nlabels, an image doesn't need to have all possible labels for fashion articles\npresent in it. We also compare our approach to multi-label classification, and\ndemonstrate improvements over overall classification accuracies using our\napproach.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 06:51:34 GMT"}], "update_date": "2021-04-13", "authors_parsed": [["Adhikari", "Sandeep Singh", ""], ["Singh", "Sukhneer", ""], ["Rajagopal", "Anoop", ""], ["Rajan", "Aruna", ""]]}, {"id": "1907.00178", "submitter": "Alexander Lerch", "authors": "Alexander Lerch and Claire Arthur and Ashis Pati and Siddharth\n  Gururani", "title": "Music Performance Analysis: A Survey", "comments": "To be published in: Proceedings of the International Society for\n  Music Information Retrieval Conference (ISMIR), Delft, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music Information Retrieval (MIR) tends to focus on the analysis of audio\nsignals. Often, a single music recording is used as representative of a \"song\"\neven though different performances of the same song may reveal different\nproperties. A performance is distinct in many ways from a (arguably more\nabstract) representation of a \"song,\" \"piece,\" or musical score. The\ncharacteristics of the (recorded) performance -- as opposed to the score or\nmusical idea -- can have a major impact on how a listener perceives music. The\nanalysis of music performance, however, has been traditionally only a\nperipheral topic for the MIR research community. This paper surveys the field\nof Music Performance Analysis (MPA) from various perspectives, discusses its\nsignificance to the field of MIR, and points out opportunities for future\nresearch in this field.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 10:43:27 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Lerch", "Alexander", ""], ["Arthur", "Claire", ""], ["Pati", "Ashis", ""], ["Gururani", "Siddharth", ""]]}, {"id": "1907.00259", "submitter": "Jakob Vo{\\ss}", "authors": "Jakob Vo{\\ss}", "title": "Infrastructure-Agnostic Hypertext", "comments": "4 pages, 2 figures, sources at\n  https://github.com/jakobib/hypertext2019/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a novel and formal interpretation of the original vision\nof hypertext: infrastructure-agnostic hypertext is independent from specific\nstandards such as data formats and network protocols. Its model is illustrated\nwith examples and references to existing technologies that allow for\nimplementation and integration in current information infrastructures such as\nthe Internet.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 19:06:31 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Vo\u00df", "Jakob", ""]]}, {"id": "1907.00400", "submitter": "Andrea Polonioli PhD", "authors": "Luca Bigon, Giovanni Cassani, Ciro Greco, Lucas Lacasa, Mattia Pavoni,\n  Andrea Polonioli and Jacopo Tagliabue", "title": "Prediction is very hard, especially about conversion. Predicting user\n  purchases from clickstream data in fashion e-commerce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowing if a user is a buyer vs window shopper solely based on clickstream\ndata is of crucial importance for ecommerce platforms seeking to implement\nreal-time accurate NBA (next best action) policies. However, due to the low\nfrequency of conversion events and the noisiness of browsing data, classifying\nuser sessions is very challenging. In this paper, we address the clickstream\nclassification problem in the fashion industry and present three major\ncontributions to the burgeoning field of AI in fashion: first, we collected,\nnormalized and prepared a novel dataset of live shopping sessions from a major\nEuropean e-commerce fashion website; second, we use the dataset to test in a\ncontrolled environment strong baselines and SOTA models from the literature;\nfinally, we propose a new discriminative neural model that outperforms neural\narchitectures recently proposed at Rakuten labs.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 15:42:53 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Bigon", "Luca", ""], ["Cassani", "Giovanni", ""], ["Greco", "Ciro", ""], ["Lacasa", "Lucas", ""], ["Pavoni", "Mattia", ""], ["Polonioli", "Andrea", ""], ["Tagliabue", "Jacopo", ""]]}, {"id": "1907.00483", "submitter": "Amit Kumar Jaiswal", "authors": "Amit Kumar Jaiswal, Haiming Liu and Ingo Frommholz", "title": "Effects of Foraging in Personalized Content-based Image Recommendation", "comments": "Accepted in Proceedings of the the 2nd International Workshop on\n  Explainable Recommendation and Search (EARS) at SIGIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC cs.MM cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A major challenge of recommender systems is to help users locating\ninteresting items. Personalized recommender systems have become very popular as\nthey attempt to predetermine the needs of users and provide them with\nrecommendations to personalize their navigation. However, few studies have\naddressed the question of what drives the users' attention to specific content\nwithin the collection and what influences the selection of interesting items.\nTo this end, we employ the lens of Information Foraging Theory (IFT) to image\nrecommendation to demonstrate how the user could utilize visual bookmarks to\nlocate interesting images. We investigate a personalized content-based image\nrecommendation system to understand what affects user attention by reinforcing\nvisual attention cues based on IFT. We further find that visual bookmarks\n(cues) lead to a stronger scent of the recommended image collection. Our\nevaluation is based on the Pinterest image collection.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 22:16:32 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 12:43:53 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Jaiswal", "Amit Kumar", ""], ["Liu", "Haiming", ""], ["Frommholz", "Ingo", ""]]}, {"id": "1907.00488", "submitter": "Jaimie Murdock", "authors": "Jaimie Murdock", "title": "Topic Modeling the Reading and Writing Behavior of Information Foragers", "comments": "Accepted Ph.D. dissertation, Indiana University, Informatics (Complex\n  Systems) and Cognitive Science, June 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The general problem of \"information foraging\" in an environment about which\nagents have incomplete information has been explored in many fields, including\ncognitive psychology, neuroscience, economics, finance, ecology, and computer\nscience. In all of these areas, the searcher aims to enhance future performance\nby surveying enough of existing knowledge to orient themselves in the\ninformation space. Individuals can be viewed as conducting a cognitive search\nin which they must balance exploration of ideas that are novel to them against\nexploitation of knowledge in domains in which they are already expert.\n  In this dissertation, I present several case studies that demonstrate how\nreading and writing behaviors interact to construct personal knowledge bases.\nThese studies use LDA topic modeling to represent the information environment\nof the texts each author read and wrote. Three studies revolve around Charles\nDarwin. Darwin left detailed records of every book he read for 23 years, from\ndisembarking from the H.M.S. Beagle to just after publication of The Origin of\nSpecies. Additionally, he left copies of his drafts before publication. I\ncharacterize his reading behavior, then show how that reading behavior\ninteracted with the drafts and subsequent revisions of The Origin of Species,\nand expand the dataset to include later readings and writings. Then, through a\nstudy of Thomas Jefferson's correspondence, I expand the study to non-book\ndata. Finally, through an examination of neuroscience citation data, I move\nfrom individual behavior to collective behavior in constructing an information\nenvironment. Together, these studies reveal \"the interplay between individual\nand collective phenomena where innovation takes place\" (Tria et al. 2014).\n", "versions": [{"version": "v1", "created": "Sun, 30 Jun 2019 22:40:37 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Murdock", "Jaimie", ""]]}, {"id": "1907.00570", "submitter": "Joris Baan", "authors": "Joris Baan, Maartje ter Hoeve, Marlies van der Wees, Anne Schuth,\n  Maarten de Rijke", "title": "Do Transformer Attention Heads Provide Transparency in Abstractive\n  Summarization?", "comments": "To appear at FACTS-IR 2019, SIGIR", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning algorithms become more powerful, often at the cost of increased\ncomplexity. In response, the demand for algorithms to be transparent is\ngrowing. In NLP tasks, attention distributions learned by attention-based deep\nlearning models are used to gain insights in the models' behavior. To which\nextent is this perspective valid for all NLP tasks? We investigate whether\ndistributions calculated by different attention heads in a transformer\narchitecture can be used to improve transparency in the task of abstractive\nsummarization. To this end, we present both a qualitative and quantitative\nanalysis to investigate the behavior of the attention heads. We show that some\nattention heads indeed specialize towards syntactically and semantically\ndistinct input. We propose an approach to evaluate to which extent the\nTransformer model relies on specifically learned attention distributions. We\nalso discuss what this implies for using attention distributions as a means of\ntransparency.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 06:46:43 GMT"}, {"version": "v2", "created": "Mon, 8 Jul 2019 14:57:07 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Baan", "Joris", ""], ["ter Hoeve", "Maartje", ""], ["van der Wees", "Marlies", ""], ["Schuth", "Anne", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1907.00590", "submitter": "Michael Niu", "authors": "Chenliang Li, Xichuan Niu, Xiangyang Luo, Zhenzhong Chen, Cong Quan", "title": "A Review-Driven Neural Model for Sequential Recommendation", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing review for a purchased item is a unique channel to express a user's\nopinion in E-Commerce. Recently, many deep learning based solutions have been\nproposed by exploiting user reviews for rating prediction. In contrast, there\nhas been few attempt to enlist the semantic signals covered by user reviews for\nthe task of collaborative filtering. In this paper, we propose a novel\nreview-driven neural sequential recommendation model (named RNS) by considering\nusers' intrinsic preference (long-term) and sequential patterns (short-term).\nIn detail, RNS is devised to encode each user or item with the aspect-aware\nrepresentations extracted from the reviews. Given a sequence of historical\npurchased items for a user, we devise a novel hierarchical attention over\nattention mechanism to capture sequential patterns at both union-level and\nindividual-level. Extensive experiments on three real-world datasets of\ndifferent domains demonstrate that RNS obtains significant performance\nimprovement over uptodate state-of-the-art sequential recommendation models.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 07:56:03 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Li", "Chenliang", ""], ["Niu", "Xichuan", ""], ["Luo", "Xiangyang", ""], ["Chen", "Zhenzhong", ""], ["Quan", "Cong", ""]]}, {"id": "1907.00635", "submitter": "Gernot Salzer", "authors": "Gernot Salzer, Agata Ciabattoni, Christian Ferm\\\"uller, Martin Haiduk,\n  Harald Kittler, Arno Lukas, Rosa Mar\\'ia Rodr\\'iguez Dom\\'inguez, Antonia\n  Wesinger, Elisabeth Riedl", "title": "Dermtrainer: A Decision Support System for Dermatological Diseases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dermtrainer is a medical decision support system that assists general\npractitioners in diagnosing skin diseases and serves as a training platform for\ndermatologists. Its key components are a comprehensive dermatological knowledge\nbase, a clinical algorithm for diagnosing skin diseases, a reasoning component\nfor deducing the most likely differential diagnoses for a patient, and a\nlibrary of high-quality images. This report describes the technical components\nof the system, in particular the ranking algorithm for retrieving appropriate\ndiseases as diagnoses.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 10:05:24 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Salzer", "Gernot", ""], ["Ciabattoni", "Agata", ""], ["Ferm\u00fcller", "Christian", ""], ["Haiduk", "Martin", ""], ["Kittler", "Harald", ""], ["Lukas", "Arno", ""], ["Dom\u00ednguez", "Rosa Mar\u00eda Rodr\u00edguez", ""], ["Wesinger", "Antonia", ""], ["Riedl", "Elisabeth", ""]]}, {"id": "1907.00687", "submitter": "Cong Quan", "authors": "Chenliang Li, Cong Quan, Li Peng, Yunwei Qi, Yuming Deng, Libing Wu", "title": "A Capsule Network for Recommendation and Explaining What You Like and\n  Dislike", "comments": "10 pages, sigir 2019 accepted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User reviews contain rich semantics towards the preference of users to\nfeatures of items. Recently, many deep learning based solutions have been\nproposed by exploiting reviews for recommendation. The attention mechanism is\nmainly adopted in these works to identify words or aspects that are important\nfor rating prediction. However, it is still hard to understand whether a user\nlikes or dislikes an aspect of an item according to what viewpoint the user\nholds and to what extent, without examining the review details. Here, we\nconsider a pair of a viewpoint held by a user and an aspect of an item as a\nlogic unit. Reasoning a rating behavior by discovering the informative logic\nunits from the reviews and resolving their corresponding sentiments could\nenable a better rating prediction with explanation. To this end, in this paper,\nwe propose a capsule network based model for rating prediction with user\nreviews, named CARP. For each user-item pair, CARP is devised to extract the\ninformative logic units from the reviews and infer their corresponding\nsentiments. The model firstly extracts the viewpoints and aspects from the user\nand item review documents respectively. Then we derive the representation of\neach logic unit based on its constituent viewpoint and aspect. A sentiment\ncapsule architecture with a novel Routing by Bi-Agreement mechanism is proposed\nto identify the informative logic unit and the sentiment based representations\nin user-item level for rating prediction. Extensive experiments are conducted\nover seven real-world datasets with diverse characteristics. Our results\ndemonstrate that the proposed CARP obtains substantial performance gain over\nrecently proposed state-of-the-art models in terms of prediction accuracy.\nFurther analysis shows that our model can successfully discover the\ninterpretable reasons at a finer level of granularity.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 12:12:00 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Li", "Chenliang", ""], ["Quan", "Cong", ""], ["Peng", "Li", ""], ["Qi", "Yunwei", ""], ["Deng", "Yuming", ""], ["Wu", "Libing", ""]]}, {"id": "1907.00710", "submitter": "Lizi Liao Ms", "authors": "Lizi Liao, Ryuichi Takanobu, Yunshan Ma, Xun Yang, Minlie Huang and\n  Tat-Seng Chua", "title": "Deep Conversational Recommender in Travel", "comments": "12 pages, 7 figures, submitted to TKDE. arXiv admin note: text\n  overlap with arXiv:1809.07070 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When traveling to a foreign country, we are often in dire need of an\nintelligent conversational agent to provide instant and informative responses\nto our various queries. However, to build such a travel agent is non-trivial.\nFirst of all, travel naturally involves several sub-tasks such as hotel\nreservation, restaurant recommendation and taxi booking etc, which invokes the\nneed for global topic control. Secondly, the agent should consider various\nconstraints like price or distance given by the user to recommend an\nappropriate venue. In this paper, we present a Deep Conversational Recommender\n(DCR) and apply to travel. It augments the sequence-to-sequence (seq2seq)\nmodels with a neural latent topic component to better guide response generation\nand make the training easier. To consider the various constraints for venue\nrecommendation, we leverage a graph convolutional network (GCN) based approach\nto capture the relationships between different venues and the match between\nvenue and dialog context. For response generation, we combine the topic-based\ncomponent with the idea of pointer networks, which allows us to effectively\nincorporate recommendation results. We perform extensive evaluation on a\nmulti-turn task-oriented dialog dataset in travel domain and the results show\nthat our method achieves superior performance as compared to a wide range of\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 04:39:26 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Liao", "Lizi", ""], ["Takanobu", "Ryuichi", ""], ["Ma", "Yunshan", ""], ["Yang", "Xun", ""], ["Huang", "Minlie", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1907.00854", "submitter": "Daniel Whitenack", "authors": "Shirish Hirekodi, Seban Sunny, Leonard Topno, Alwin Daniel, Daniel\n  Whitenack, Reuben Skewes, Stuart Cranney", "title": "Katecheo: A Portable and Modular System for Multi-Topic Question\n  Answering", "comments": "ACL 2020 system demo submission, 7 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a modular system that can be deployed on any Kubernetes cluster\nfor question answering via REST API. This system, called Katecheo, includes\nthree configurable modules that collectively enable identification of\nquestions, classification of those questions into topics, document search, and\nreading comprehension. We demonstrate the system using publicly available\nknowledge base articles extracted from Stack Exchange sites. However, users can\nextend the system to any number of topics, or domains, without the need to\nmodify any of the model serving code or train their own models. All components\nof the system are open source and available under a permissive Apache 2\nLicense.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 15:20:10 GMT"}, {"version": "v2", "created": "Fri, 31 Jan 2020 19:01:40 GMT"}], "update_date": "2020-02-04", "authors_parsed": [["Hirekodi", "Shirish", ""], ["Sunny", "Seban", ""], ["Topno", "Leonard", ""], ["Daniel", "Alwin", ""], ["Whitenack", "Daniel", ""], ["Skewes", "Reuben", ""], ["Cranney", "Stuart", ""]]}, {"id": "1907.00937", "submitter": "Priyanka Nigam", "authors": "Priyanka Nigam, Yiwei Song, Vijai Mohan, Vihan Lakshman, Weitian\n  (Allen) Ding, Ankit Shingavi, Choon Hui Teo, Hao Gu, Bing Yin", "title": "Semantic Product Search", "comments": "10 pages, 7 figures, KDD 2019 (Applied Data Science Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of semantic matching in product search, that is, given a\ncustomer query, retrieve all semantically related products from the catalog.\nPure lexical matching via an inverted index falls short in this respect due to\nseveral factors: a) lack of understanding of hypernyms, synonyms, and antonyms,\nb) fragility to morphological variants (e.g. \"woman\" vs. \"women\"), and c)\nsensitivity to spelling errors. To address these issues, we train a deep\nlearning model for semantic matching using customer behavior data. Much of the\nrecent work on large-scale semantic search using deep learning focuses on\nranking for web search. In contrast, semantic matching for product search\npresents several novel challenges, which we elucidate in this paper. We address\nthese challenges by a) developing a new loss function that has an inbuilt\nthreshold to differentiate between random negative examples, impressed but not\npurchased examples, and positive examples (purchased items), b) using average\npooling in conjunction with n-grams to capture short-range linguistic patterns,\nc) using hashing to handle out of vocabulary tokens, and d) using a model\nparallel training architecture to scale across 8 GPUs. We present compelling\noffline results that demonstrate at least 4.7% improvement in Recall@100 and\n14.5% improvement in mean average precision (MAP) over baseline\nstate-of-the-art semantic search methods using the same tokenization method.\nMoreover, we present results and discuss learnings from online A/B tests which\ndemonstrate the efficacy of our method.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:20:02 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Nigam", "Priyanka", "", "Allen"], ["Song", "Yiwei", "", "Allen"], ["Mohan", "Vijai", "", "Allen"], ["Lakshman", "Vihan", "", "Allen"], ["Weitian", "", "", "Allen"], ["Ding", "", ""], ["Shingavi", "Ankit", ""], ["Teo", "Choon Hui", ""], ["Gu", "Hao", ""], ["Yin", "Bing", ""]]}, {"id": "1907.01032", "submitter": "Giulio Ermanno Pibiri", "authors": "Giulio Ermanno Pibiri", "title": "On Slicing Sorted Integer Sequences", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Representing sorted integer sequences in small space is a central problem for\nlarge-scale retrieval systems such as Web search engines. Efficient query\nresolution, e.g., intersection or random access, is achieved by carefully\npartitioning the sequences. In this work we describe and compare two different\npartitioning paradigms: partitioning by cardinality and partitioning by\nuniverse. Although the ideas behind such paradigms have been known in the\ncoding and algorithmic community since many years, inverted index compression\nhas extensively adopted the former paradigm, whereas the latter has received\nonly little attention. As a result, an experimental comparison between these\ntwo is missing for the setting of inverted index compression. We also propose\nand implement a solution that recursively slices the universe of representation\nof a sequence to achieve compact storage and attain to fast query execution.\nAlbeit larger than some state-of-the-art representations, this slicing approach\nsubstantially improves the performance of list intersections and unions while\noperating in compressed space, thus offering an excellent space/time trade-off\nfor the problem.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 19:33:29 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 07:35:46 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Pibiri", "Giulio Ermanno", ""]]}, {"id": "1907.01098", "submitter": "Piyush Papreja", "authors": "Piyush Papreja and Hemanth Venkateswara and Sethuraman Panchanathan", "title": "Representation, Exploration and Recommendation of Music Playlists", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-43887-6_50", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Playlists have become a significant part of our listening experience because\nof the digital cloud-based services such as Spotify, Pandora, Apple Music.\nOwing to the meteoric rise in the usage of playlists, recommending playlists is\ncrucial to music services today. Although there has been a lot of work done in\nplaylist prediction, the area of playlist representation hasn't received that\nlevel of attention. Over the last few years, sequence-to-sequence models,\nespecially in the field of natural language processing, have shown the\neffectiveness of learned embeddings in capturing the semantic characteristics\nof sequences. We can apply similar concepts to music to learn fixed length\nrepresentations for playlists and use those representations for downstream\ntasks such as playlist discovery, browsing, and recommendation. In this work,\nwe formulate the problem of learning a fixed-length playlist representation in\nan unsupervised manner, using Sequence-to-sequence (Seq2seq) models,\ninterpreting playlists as sentences and songs as words. We compare our model\nwith two other encoding architectures for baseline comparison. We evaluate our\nwork using the suite of tasks commonly used for assessing sentence embeddings,\nalong with a few additional tasks pertaining to music, and a recommendation\ntask to study the traits captured by the playlist embeddings and their\neffectiveness for the purpose of music recommendation.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 23:20:45 GMT"}], "update_date": "2020-07-28", "authors_parsed": [["Papreja", "Piyush", ""], ["Venkateswara", "Hemanth", ""], ["Panchanathan", "Sethuraman", ""]]}, {"id": "1907.01102", "submitter": "Ravimal Bandara", "authors": "Ravimal Bandara, Lochandaka Ranathunga, Nor Aniza Abdullah", "title": "Nature Inspired Dimensional Reduction Technique for Fast and Invariant\n  Visual Feature Extraction", "comments": "11 pages, 11 figures, IJTCSE", "journal-ref": "International Journal of Advanced Trends in Computer Science and\n  Engineering (IJATCSE) Vol.8 No.3 (2019) 696-706", "doi": "10.30534/ijatcse/2019/57832019", "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast and invariant feature extraction is crucial in certain computer vision\napplications where the computation time is constrained in both training and\ntesting phases of the classifier. In this paper, we propose a nature-inspired\ndimensionality reduction technique for fast and invariant visual feature\nextraction. The human brain can exchange the spatial and spectral resolution to\nreconstruct missing colors in visual perception. The phenomenon is widely used\nin the printing industry to reduce the number of colors used to print, through\na technique, called color dithering. In this work, we adopt a fast\nerror-diffusion color dithering algorithm to reduce the spectral resolution and\nextract salient features by employing novel Hessian matrix analysis technique,\nwhich is then described by a spatial-chromatic histogram. The computation time,\ndescriptor dimensionality and classification performance of the proposed\nfeature are assessed under drastic variances in orientation, viewing angle and\nillumination of objects comparing with several different state-of-the-art\nhandcrafted and deep-learned features. Extensive experiments on two publicly\navailable object datasets, coil-100 and ALOI carried on both a desktop PC and a\nRaspberry Pi device show multiple advantages of using the proposed approach,\nsuch as the lower computation time, high robustness, and comparable\nclassification accuracy under weakly supervised environment. Further, it showed\nthe capability of operating solely inside a conventional SoC device utilizing a\nsmall fraction of the available hardware resources.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 16:58:45 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Bandara", "Ravimal", ""], ["Ranathunga", "Lochandaka", ""], ["Abdullah", "Nor Aniza", ""]]}, {"id": "1907.01183", "submitter": "Gong Cheng", "authors": "Xiaxia Wang, Jinchi Chen, Shuxin Li, Gong Cheng, Jeff Z. Pan, Evgeny\n  Kharlamov, Yuzhong Qu", "title": "A Framework for Evaluating Snippet Generation for Dataset Search", "comments": "17 pages, to appear at the research track of the 18th International\n  Semantic Web Conference (ISWC 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Reusing existing datasets is of considerable significance to researchers and\ndevelopers. Dataset search engines help a user find relevant datasets for\nreuse. They can present a snippet for each retrieved dataset to explain its\nrelevance to the user's data needs. This emerging problem of snippet generation\nfor dataset search has not received much research attention. To provide a basis\nfor future research, we introduce a framework for quantitatively evaluating the\nquality of a dataset snippet. The proposed metrics assess the extent to which a\nsnippet matches the query intent and covers the main content of the dataset. To\nestablish a baseline, we adapt four state-of-the-art methods from related\nfields to our problem, and perform an empirical evaluation based on real-world\ndatasets and queries. We also conduct a user study to verify our findings. The\nresults demonstrate the effectiveness of our evaluation framework, and suggest\ndirections for future research.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 05:58:18 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Wang", "Xiaxia", ""], ["Chen", "Jinchi", ""], ["Li", "Shuxin", ""], ["Cheng", "Gong", ""], ["Pan", "Jeff Z.", ""], ["Kharlamov", "Evgeny", ""], ["Qu", "Yuzhong", ""]]}, {"id": "1907.01260", "submitter": "Kareem Darwish", "authors": "Peter Stefanov and Kareem Darwish and Atanas Atanasov and Preslav\n  Nakov", "title": "Predicting the Topical Stance of Media and Popular Twitter Users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discovering the stances of media outlets and influential people on current,\ndebatable topics is important for social statisticians and policy makers. Many\nsupervised solutions exist for determining viewpoints, but manually annotating\ntraining data is costly. In this paper, we propose a cascaded method that uses\nunsupervised learning to ascertain the stance of Twitter users with respect to\na polarizing topic by leveraging their retweet behavior; then, it uses\nsupervised learning based on user labels to characterize both the general\npolitical leaning of online media and of popular Twitter users, as well as\ntheir stance with respect to the target polarizing topic. We evaluate the model\nby comparing its predictions to gold labels from the Media Bias/Fact Check\nwebsite, achieving 82.6% accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 09:39:43 GMT"}, {"version": "v2", "created": "Thu, 21 May 2020 08:15:22 GMT"}], "update_date": "2020-05-22", "authors_parsed": [["Stefanov", "Peter", ""], ["Darwish", "Kareem", ""], ["Atanasov", "Atanas", ""], ["Nakov", "Preslav", ""]]}, {"id": "1907.01300", "submitter": "Amir H. Jadidinejad", "authors": "Amir H. Jadidinejad", "title": "Learning to Reformulate the Queries on the WEB", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inability of the naive users to formulate appropriate queries is a\nfundamental problem in web search engines. Therefore, assisting users to issue\nmore effective queries is an important way to improve users' happiness. One\neffective approach is query reformulation, which generates new effective\nqueries according to the current query issued by users. Previous researches\ntypically generate words and phrases related to the original query. Since the\ndefinition of query reformulation is quite general, it is completely difficult\nto develop a uniform term-based approach for this problem. This paper uses\nreadily available data, particularly over one billion anchor phrases in\nClueweb09 corpus, in order to learn an end-to-end encoder-decoder model to\nautomatically generate effective queries. Following successful researches in\nthe field of sequence to sequence models, we employ a character-level\nconvolutional neural network with max-pooling at encoder and an attention-based\nrecurrent neural network at decoder. The whole model learned in an unsupervised\nend-to-end manner.Experiments on TREC collections show that the reformulated\nqueries automatically generated by the proposed solution can significantly\nimprove the retrieval performance.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 11:31:57 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Jadidinejad", "Amir H.", ""]]}, {"id": "1907.01326", "submitter": "Simona Rombo", "authors": "Mariella Bonomo, Gaspare Ciaccio, Andrea De Salve, Simona E. Rombo", "title": "A Semantic Approach for User-Brand Targeting in On-Line Social Networks", "comments": "10 pages, 3 figures, extended work from a conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a general framework for the recommendation of possible customers\n(users) to advertisers (e.g., brands) based on the comparison between On-line\nSocial Network profiles. In particular, we represent both user and brand\nprofiles as trees where nodes correspond to categories and sub-categories in\nthe associated On-line Social Network. When categories involve posts and\ncomments, the comparison is based on word embedding, and this allows to take\ninto account the similarity between topics popular in the brand profile and\nuser preferences. Results on real datasets show that our approach is\nsuccessfull in identifying the most suitable set of users to be used as target\nfor a given advertisement campaign.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 12:41:12 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Bonomo", "Mariella", ""], ["Ciaccio", "Gaspare", ""], ["De Salve", "Andrea", ""], ["Rombo", "Simona E.", ""]]}, {"id": "1907.01328", "submitter": "Erik Bryhn Myklebust", "authors": "Erik Bryhn Myklebust and Ernesto Jimenez-Ruiz and Jiaoyan Chen and\n  Raoul Wolf and Knut Erik Tollefsen", "title": "Knowledge Graph Embedding for Ecotoxicological Effect Prediction", "comments": null, "journal-ref": "In: Ghidini C. et al. (eds) The Semantic Web - ISWC 2019. ISWC\n  2019. Lecture Notes in Computer Science, vol 11779. Springer, Cham", "doi": "10.1007/978-3-030-30796-7_30", "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploring the effects a chemical compound has on a species takes a\nconsiderable experimental effort. Appropriate methods for estimating and\nsuggesting new effects can dramatically reduce the work needed to be done by a\nlaboratory. In this paper we explore the suitability of using a knowledge graph\nembedding approach for ecotoxicological effect prediction. A knowledge graph\nhas been constructed from publicly available data sets, including a species\ntaxonomy and chemical classification and similarity. The publicly available\neffect data is integrated to the knowledge graph using ontology alignment\ntechniques. Our experimental results show that the knowledge graph based\napproach improves the selected baselines.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 12:43:17 GMT"}, {"version": "v2", "created": "Thu, 29 Aug 2019 12:11:23 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 14:20:08 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Myklebust", "Erik Bryhn", ""], ["Jimenez-Ruiz", "Ernesto", ""], ["Chen", "Jiaoyan", ""], ["Wolf", "Raoul", ""], ["Tollefsen", "Knut Erik", ""]]}, {"id": "1907.01457", "submitter": "Sheikh Muhammad Sarwar", "authors": "Shahrzad Naseri, Sheikh Muhammad Sarwar and James Allan", "title": "Semantic Driven Fielded Entity Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach for knowledge-base entity search is to consider an entity\nas a document with multiple fields. Models that focus on matching query terms\nin different fields are popular choices for searching such entity\nrepresentations. An instance of such a model is FSDM (Fielded Sequential\nDependence Model). We propose to integrate field-level semantic features into\nFSDM. We use FSDM to retrieve a pool of documents, and then to use semantic\nfield-level features to re-rank those documents. We propose to represent\nqueries as bags of terms as well as bags of entities, and eventually, use their\ndense vector representation to compute semantic features based on query\ndocument similarity. Our proposed re-ranking approach achieves significant\nimprovement in entity retrieval on the DBpedia-Entity (v2) dataset over\nexisting FSDM model. Specifically, for all queries we achieve 2.5% and 1.2%\nsignificant improvement in NDCG@10 and NDCG@100, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 15:36:21 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Naseri", "Shahrzad", ""], ["Sarwar", "Sheikh Muhammad", ""], ["Allan", "James", ""]]}, {"id": "1907.01515", "submitter": "Yasith Jayawardana", "authors": "Yasith Jayawardana, Mark Jaime, Sashi Thapaliya, Sampath Jayarathna", "title": "Electroencephalogram (EEG) for Delineating Objective Measure of Autism\n  Spectrum Disorder (ASD) (Extended Version)", "comments": null, "journal-ref": null, "doi": "10.4018/978-1-5225-7467-5.ch002", "report-no": null, "categories": "eess.SP cs.IR cs.LG cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autism Spectrum Disorder (ASD) is a developmental disorder that often impairs\na child's normal development of the brain. According to CDC, it is estimated\nthat 1 in 6 children in the US suffer from development disorders, and 1 in 68\nchildren in the US suffer from ASD. This condition has a negative impact on a\nperson's ability to hear, socialize and communicate. Overall, ASD has a broad\nrange of symptoms and severity; hence the term spectrum is used. One of the\nmain contributors to ASD is known to be genetics. Up to date, no suitable cure\nfor ASD has been found. Early diagnosis is crucial for the long-term treatment\nof ASD, but this is challenging due to the lack of a proper objective measures.\nSubjective measures often take more time, resources, and have false positives\nor false negatives. There is a need for efficient objective measures that can\nhelp in diagnosing this disease early as possible with less effort.\n  EEG measures the electric signals of the brain via electrodes placed on\nvarious places on the scalp. These signals can be used to study complex\nneuropsychiatric issues. Studies have shown that EEG has the potential to be\nused as a biomarker for various neurological conditions including ASD. This\nchapter will outline the usage of EEG measurement for the classification of ASD\nusing machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 01:13:21 GMT"}], "update_date": "2019-07-03", "authors_parsed": [["Jayawardana", "Yasith", ""], ["Jaime", "Mark", ""], ["Thapaliya", "Sashi", ""], ["Jayarathna", "Sampath", ""]]}, {"id": "1907.01549", "submitter": "Siddhartha Devapujula", "authors": "Siddhartha Devapujula, Sagar Arora, Sumit Borar", "title": "Learning to Rank Broad and Narrow Queries in E-Commerce", "comments": "7+1 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search is a prominent channel for discovering products on an e-commerce\nplatform. Ranking products retrieved from search becomes crucial to address\ncustomer's need and optimize for business metrics. While learning to Rank\n(LETOR) models have been extensively studied and have demonstrated efficacy in\nthe context of web search; it is a relatively new research area to be explored\nin the e-commerce. In this paper, we present a framework for building LETOR\nmodel for an e-commerce platform. We analyze user queries and propose a\nmechanism to segment queries between broad and narrow based on user's intent.\nWe discuss different types of features - query, product and query-product and\ndiscuss challenges in using them. We show that sparsity in product features can\nbe tackled through a denoising auto-encoder while skip-gram based word\nembeddings help solve the query-product sparsity issues. We also present\nvarious target metrics that can be employed for evaluating search results and\ncompare their robustness. Further, we build and compare performances of both\npointwise and pairwise LETOR models on fashion category data set. We also build\nand compare distinct models for broad and narrow queries, analyze feature\nimportance across these and show that these specialized models perform better\nthan a combined model in the fashion world.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 18:30:38 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 09:17:51 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Devapujula", "Siddhartha", ""], ["Arora", "Sagar", ""], ["Borar", "Sumit", ""]]}, {"id": "1907.01591", "submitter": "Zachary Pardos", "authors": "Zachary A. Pardos and Weijie Jiang", "title": "Combating the Filter Bubble: Designing for Serendipity in a University\n  Course Recommendation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering based algorithms, including Recurrent Neural Networks\n(RNN), tend towards predicting a perpetuation of past observed behavior. In a\nrecommendation context, this can lead to an overly narrow set of suggestions\nlacking in serendipity and inadvertently placing the user in what is known as a\n\"filter bubble.\" In this paper, we grapple with the issue of the filter bubble\nin the context of a course recommendation system in production at a public\nuniversity. Most universities in the United States encourage students to\nexplore developing interests while simultaneously advising them to adhere to\ncourse taking norms which progress them towards graduation. These competing\nobjectives, and the stakes involved for students, make this context a\nparticularly meaningful one for investigating real-world recommendation\nstrategies. We introduce a novel modification to the skip-gram model applied to\nnine years of historic course enrollment sequences to learn course vector\nrepresentations used to diversify recommendations based on similarity to a\nstudent's specified favorite course. This model, which we call multifactor2vec,\nis intended to improve the semantics of the primary token embedding by also\nlearning embeddings of potentially conflated factors of the token (e.g.,\ninstructor). Our offline testing found this model improved accuracy and recall\non our course similarity and analogy validation sets over a standard skip-gram.\nIncorporating course catalog description text resulted in further improvements.\nWe compare the performance of these models to the system's existing RNN-based\nrecommendations with a user study of undergraduates (N = 70) rating six\ncharacteristics of their course recommendations. Results of the user study show\na dramatic lack of novelty in RNN recommendations and depict the characteristic\ntrade-offs that make serendipity difficult to achieve.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 19:17:43 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Pardos", "Zachary A.", ""], ["Jiang", "Weijie", ""]]}, {"id": "1907.01611", "submitter": "Yannis Tzitzikas", "authors": "Katerina Papantoniou and Yannis Tzitzikas", "title": "CS563-QA: A Collection for Evaluating Question Answering Systems", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Answering (QA) is a challenging topic since it requires tackling the\nvarious difficulties of natural language understanding. Since evaluation is\nimportant not only for identifying the strong and weak points of the various\ntechniques for QA, but also for facilitating the inception of new methods and\ntechniques, in this paper we present a collection for evaluating QA methods\nover free text that we have created. Although it is a small collection, it\ncontains cases of increasing difficulty, therefore it has an educational value\nand it can be used for rapid evaluation of QA systems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 20:00:29 GMT"}, {"version": "v2", "created": "Sat, 6 Feb 2021 19:07:42 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Papantoniou", "Katerina", ""], ["Tzitzikas", "Yannis", ""]]}, {"id": "1907.01631", "submitter": "Jeffrey Barratt", "authors": "Jeffrey Barratt, Brian Zhang", "title": "Cache-Friendly Search Trees; or, In Which Everything Beats std::set", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While a lot of work in theoretical computer science has gone into optimizing\nthe runtime and space usage of data structures, such work very often neglects a\nvery important component of modern computers: the cache. In doing so, very\noften, data structures are developed that achieve theoretically-good runtimes\nbut are slow in practice due to a large number of cache misses. In 1999, Frigo\net al. introduced the notion of a cache-oblivious algorithm: an algorithm that\nuses the cache to its advantage, regardless of the size or structure of said\ncache. Since then, various authors have designed cache-oblivious algorithms and\ndata structures for problems from matrix multiplication to array sorting. We\nfocus in this work on cache-oblivious search trees; i.e. implementing an\nordered dictionary in a cache-friendly manner. We will start by presenting an\noverview of cache-oblivious data structures, especially cache-oblivious search\ntrees. We then give practical results using these cache-oblivious structures on\nmodern-day machinery, comparing them to the standard std::set and other\ncache-friendly dictionaries such as B-trees.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jul 2019 20:55:47 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Barratt", "Jeffrey", ""], ["Zhang", "Brian", ""]]}, {"id": "1907.01636", "submitter": "Clint Pazhayidam George", "authors": "Clint P. George, Wei Xia, George Michailidis", "title": "Analyses of Multi-collection Corpora via Compound Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As electronically stored data grow in daily life, obtaining novel and\nrelevant information becomes challenging in text mining. Thus people have\nsought statistical methods based on term frequency, matrix algebra, or topic\nmodeling for text mining. Popular topic models have centered on one single text\ncollection, which is deficient for comparative text analyses. We consider a\nsetting where one can partition the corpus into subcollections. Each\nsubcollection shares a common set of topics, but there exists relative\nvariation in topic proportions among collections. Including any prior knowledge\nabout the corpus (e.g. organization structure), we propose the compound latent\nDirichlet allocation (cLDA) model, improving on previous work, encouraging\ngeneralizability, and depending less on user-input parameters. To identify the\nparameters of interest in cLDA, we study Markov chain Monte Carlo (MCMC) and\nvariational inference approaches extensively, and suggest an efficient MCMC\nmethod. We evaluate cLDA qualitatively and quantitatively using both synthetic\nand real-world corpora. The usability study on some real-world corpora\nillustrates the superiority of cLDA to explore the underlying topics\nautomatically but also model their connections and variations across multiple\ncollections.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 06:59:25 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["George", "Clint P.", ""], ["Xia", "Wei", ""], ["Michailidis", "George", ""]]}, {"id": "1907.01637", "submitter": "Syrine Krichene", "authors": "Syrine Krichene and Mike Gartrell and Clement Calauzenes", "title": "Embedding models for recommendation under contextual constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedding models, which learn latent representations of users and items based\non user-item interaction patterns, are a key component of recommendation\nsystems. In many applications, contextual constraints need to be applied to\nrefine recommendations, e.g. when a user specifies a price range or product\ncategory filter. The conventional approach, for both context-aware and standard\nmodels, is to retrieve items and apply the constraints as independent\noperations. The order in which these two steps are executed can induce\nsignificant problems. For example, applying constraints a posteriori can result\nin incomplete recommendations or low-quality results for the tail of the\ndistribution (i.e., less popular items). As a result, the additional\ninformation that the constraint brings about user intent may not be accurately\ncaptured.\n  In this paper we propose integrating the information provided by the\ncontextual constraint into the similarity computation, by merging constraint\napplication and retrieval into one operation in the embedding space. This\ntechnique allows us to generate high-quality recommendations for the specified\nconstraint. Our approach learns constraints representations jointly with the\nuser and item embeddings. We incorporate our methods into a matrix\nfactorization model, and perform an experimental evaluation on one internal and\ntwo real-world datasets. Our results show significant improvements in\npredictive performance compared to context-aware and standard models.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jun 2019 07:59:38 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Krichene", "Syrine", ""], ["Gartrell", "Mike", ""], ["Calauzenes", "Clement", ""]]}, {"id": "1907.01638", "submitter": "Fenglei Jin", "authors": "Fenglei Jin, Cuiyun Gao, Michael R. Lyu", "title": "An Online Topic Modeling Framework with Topics Automatically Labeled", "comments": "5 pages, 3 figures, ICML", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel online topic tracking framework, named\nIEDL, for tracking the topic changes related to deep learning techniques on\nStack Exchange and automatically interpreting each identified topic. The\nproposed framework combines the prior topic distributions in a time window\nduring inferring the topics in current time slice, and introduces a new ranking\nscheme to select most representative phrases and sentences for the inferred\ntopics in each time slice. Experiments on 7,076 Stack Exchange posts show the\neffectiveness of IEDL in tracking topic changes and labeling topics.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jun 2019 02:42:44 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Jin", "Fenglei", ""], ["Gao", "Cuiyun", ""], ["Lyu", "Michael R.", ""]]}, {"id": "1907.01639", "submitter": "Yu Zhu", "authors": "Yu Zhu, Yu Gong, Qingwen Liu, Yingcai Ma, Wenwu Ou, Junxiong Zhu,\n  Beidou Wang, Ziyu Guan, and Deng Cai", "title": "Query-based Interactive Recommendation by Meta-Path and Adapted\n  Attention-GRU", "comments": "9 pages, 6 figures, submitted to CIKM 2019 Applied Research Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, interactive recommender systems are becoming increasingly popular.\nThe insight is that, with the interaction between users and the system, (1)\nusers can actively intervene the recommendation results rather than passively\nreceive them, and (2) the system learns more about users so as to provide\nbetter recommendation.\n  We focus on the single-round interaction, i.e. the system asks the user a\nquestion (Step 1), and exploits his feedback to generate better recommendation\n(Step 2). A novel query-based interactive recommender system is proposed in\nthis paper, where \\textbf{personalized questions are accurately generated from\nmillions of automatically constructed questions} in Step 1, and \\textbf{the\nrecommendation is ensured to be closely-related to users' feedback} in Step 2.\nWe achieve this by transforming Step 1 into a query recommendation task and\nStep 2 into a retrieval task. The former task is our key challenge. We firstly\npropose a model based on Meta-Path to efficiently retrieve hundreds of query\ncandidates from the large query pool. Then an adapted Attention-GRU model is\ndeveloped to effectively rank these candidates for recommendation. Offline and\nonline experiments on Taobao, a large-scale e-commerce platform in China,\nverify the effectiveness of our interactive system. The system has already gone\ninto production in the homepage of Taobao App since Nov. 11, 2018 (see\nhttps://v.qq.com/x/page/s0833tkp1uo.html on how it works online). Our code and\ndataset are public in https://github.com/zyody/QueryQR.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 05:59:29 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Zhu", "Yu", ""], ["Gong", "Yu", ""], ["Liu", "Qingwen", ""], ["Ma", "Yingcai", ""], ["Ou", "Wenwu", ""], ["Zhu", "Junxiong", ""], ["Wang", "Beidou", ""], ["Guan", "Ziyu", ""], ["Cai", "Deng", ""]]}, {"id": "1907.01640", "submitter": "Khalil Damak", "authors": "Khalil Damak, Olfa Nasraoui", "title": "SeER: An Explainable Deep Learning MIDI-based Hybrid Song Recommender\n  System", "comments": "8 pages, 6 figures; added offline validation of explainability method", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State of the art music recommender systems mainly rely on either matrix\nfactorization-based collaborative filtering approaches or deep learning\narchitectures. Deep learning models usually use metadata for content-based\nfiltering or predict the next user interaction by learning from temporal\nsequences of user actions. Despite advances in deep learning for song\nrecommendation, none has taken advantage of the sequential nature of songs by\nlearning sequence models that are based on content. Aside from the importance\nof prediction accuracy, other significant aspects are important, such as\nexplainability and solving the cold start problem. In this work, we propose a\nhybrid deep learning model, called \"SeER\", that uses collaborative filtering\n(CF) and deep learning sequence models on the MIDI content of songs for\nrecommendation in order to provide more accurate personalized recommendations;\nsolve the item cold start problem; and generate a relevant explanation for a\nsong recommendation. Our evaluation experiments show promising results compared\nto state of the art baseline and hybrid song recommender systems in terms of\nranking evaluation. Moreover, based on proposed tests for offline validation,\nwe show that our personalized explanations capture properties that are in\naccordance with the user's preferences.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jun 2019 18:23:37 GMT"}, {"version": "v2", "created": "Thu, 19 Dec 2019 07:01:35 GMT"}], "update_date": "2019-12-20", "authors_parsed": [["Damak", "Khalil", ""], ["Nasraoui", "Olfa", ""]]}, {"id": "1907.01642", "submitter": "Moritz Schubotz", "authors": "Moritz Schubotz and Philipp Scharpf and Kaushal Dudhat and Yash Nagar\n  and Felix Hamborg and Bela Gipp", "title": "Introducing MathQA -- A Math-Aware Question Answering System", "comments": "Proceedings of the ACM/IEEE-CS Joint Conference on Digital Libraries\n  (JCDL), Workshop on Knowledge Discovery (2018)", "journal-ref": null, "doi": "10.1108/IDD-06-2018-0022", "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an open source math-aware Question Answering System based on Ask\nPlatypus. Our system returns as a single mathematical formula for a natural\nlanguage question in English or Hindi. This formulae originate from the\nknowledge-base Wikidata. We translate these formulae to computable data by\nintegrating the calculation engine sympy into our system. This way, users can\nenter numeric values for the variables occurring in the formula. Moreover, the\nsystem loads numeric values for constants occurring in the formula from\nWikidata. In a user study, our system outperformed a commercial computational\nmathematical knowledge engine by 13%. However, the performance of our system\nheavily depends on the size and quality of the formula data available in\nWikidata. Since only a few items in Wikidata contained formulae when we started\nthe project, we facilitated the import process by suggesting formula edits to\nWikidata editors. With the simple heuristic that the first formula is\nsignificant for the article, 80% of the suggestions were correct.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jun 2019 08:27:53 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Schubotz", "Moritz", ""], ["Scharpf", "Philipp", ""], ["Dudhat", "Kaushal", ""], ["Nagar", "Yash", ""], ["Hamborg", "Felix", ""], ["Gipp", "Bela", ""]]}, {"id": "1907.01643", "submitter": "Hemant Pugaliya", "authors": "Hemant Pugaliya, Karan Saxena, Shefali Garg, Sheetal Shalini, Prashant\n  Gupta, Eric Nyberg, Teruko Mitamura", "title": "Pentagon at MEDIQA 2019: Multi-task Learning for Filtering and\n  Re-ranking Answers using Language Inference and Question Entailment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel deep learning architectures like fine-tuned BERT and MT-DNN, have\nquickly become the state of the art, bypassing previous deep and shallow\nlearning methods by a large margin. More recently, pre-trained models from\nlarge related datasets have been able to perform well on many downstream tasks\nby just fine-tuning on domain-specific datasets . However, using powerful\nmodels on non-trivial tasks, such as ranking and large document classification,\nstill remains a challenge due to input size limitations of parallel\narchitecture and extremely small datasets (insufficient for fine-tuning). In\nthis work, we introduce an end-to-end system, trained in a multi-task setting,\nto filter and re-rank answers in the medical domain. We use task-specific\npre-trained models as deep feature extractors. Our model achieves the highest\nSpearman's Rho and Mean Reciprocal Rank of 0.338 and 0.9622 respectively, on\nthe ACL-BioNLP workshop MediQA Question Answering shared-task.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 17:48:40 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Pugaliya", "Hemant", ""], ["Saxena", "Karan", ""], ["Garg", "Shefali", ""], ["Shalini", "Sheetal", ""], ["Gupta", "Prashant", ""], ["Nyberg", "Eric", ""], ["Mitamura", "Teruko", ""]]}, {"id": "1907.01644", "submitter": "Dimitrios Rafailidis Dr", "authors": "Dimitrios Rafailidis and Gerhard Weiss", "title": "A Neural Attention Model for Adaptive Learning of Social Friends'\n  Preferences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social-based recommendation systems exploit the selections of friends to\ncombat the data sparsity on user preferences, and improve the recommendation\naccuracy of the collaborative filtering strategy. The main challenge is to\ncapture and weigh friends' preferences, as in practice they do necessarily\nmatch. In this paper, we propose a Neural Attention mechanism for Social\ncollaborative filtering, namely NAS. We design a neural architecture, to\ncarefully compute the non-linearity in friends' preferences by taking into\naccount the social latent effects of friends on user behavior. In addition, we\nintroduce a social behavioral attention mechanism to adaptively weigh the\ninfluence of friends on user preferences and consequently generate accurate\nrecommendations. Our experiments on publicly available datasets demonstrate the\neffectiveness of the proposed NAS model over other state-of-the-art methods.\nFurthermore, we study the effect of the proposed social behavioral attention\nmechanism and show that it is a key factor to our model's performance.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 15:59:28 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Rafailidis", "Dimitrios", ""], ["Weiss", "Gerhard", ""]]}, {"id": "1907.01645", "submitter": "Dimitrios Rafailidis Dr", "authors": "Dimitrios Rafailidis and Gerhard Weiss", "title": "Adaptive Deep Learning of Cross-Domain Loss in Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, users open multiple accounts on social media platforms and\ne-commerce sites, expressing their personal preferences on different domains.\nHowever, users' behaviors change across domains, depending on the content that\nusers interact with, such as movies, music, clothing and retail products. In\nthis paper, we propose an adaptive deep learning strategy for cross-domain\nrecommendation, referred to as ADC. We design a neural architecture and\nformulate a cross-domain loss function, to compute the non-linearity in user\npreferences across domains and transfer the knowledge of users' multiple\nbehaviors, accordingly. In addition, we introduce an efficient algorithm for\ncross-domain loss balancing which directly tunes gradient magnitudes and adapts\nthe learning rates based on the domains' complexities/scales when training the\nmodel via backpropagation. In doing so, ADC controls and adjusts the\ncontribution of each domain when optimizing the model parameters. Our\nexperiments on six publicly available cross-domain recommendation tasks\ndemonstrate the effectiveness of the proposed ADC model over other\nstate-of-the-art methods. Furthermore, we study the effect of the proposed\nadaptive deep learning strategy and show that ADC can well balance the impact\nof the domains with different complexities.\n", "versions": [{"version": "v1", "created": "Sat, 29 Jun 2019 16:03:44 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Rafailidis", "Dimitrios", ""], ["Weiss", "Gerhard", ""]]}, {"id": "1907.01647", "submitter": "Yong Liu Stephen", "authors": "Yong Liu, Yingtai Xiao, Qiong Wu, Chunyan Miao, Juyong Zhang", "title": "Bandit Learning for Diversified Interactive Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive recommender systems that enable the interactions between users\nand the recommender system have attracted increasing research attentions.\nPrevious methods mainly focus on optimizing recommendation accuracy. However,\nthey usually ignore the diversity of the recommendation results, thus usually\nresults in unsatisfying user experiences. In this paper, we propose a novel\ndiversified recommendation model, named Diversified Contextual Combinatorial\nBandit (DC$^2$B), for interactive recommendation with users' implicit feedback.\nSpecifically, DC$^2$B employs determinantal point process in the recommendation\nprocedure to promote diversity of the recommendation results. To learn the\nmodel parameters, a Thompson sampling-type algorithm based on variational\nBayesian inference is proposed. In addition, theoretical regret analysis is\nalso provided to guarantee the performance of DC$^2$B. Extensive experiments on\nreal datasets are performed to demonstrate the effectiveness of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jul 2019 03:52:55 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Liu", "Yong", ""], ["Xiao", "Yingtai", ""], ["Wu", "Qiong", ""], ["Miao", "Chunyan", ""], ["Zhang", "Juyong", ""]]}, {"id": "1907.01693", "submitter": "Dongrui Wu", "authors": "Chenfeng Guo, Dongrui Wu", "title": "Canonical Correlation Analysis (CCA) Based Multi-View Learning: An\n  Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-view learning (MVL) is a strategy for fusing data from different\nsources or subsets. Canonical correlation analysis (CCA) is very important in\nMVL, whose main idea is to map data from different views onto a common space\nwith maximum correlation. Traditional CCA can only be used to calculate the\nlinear correlation of two views. Besides, it is unsupervised and the label\ninformation is wasted. Many nonlinear, supervised, or generalized extensions\nhave been proposed to overcome these limitations. However, to our knowledge,\nthere is no overview for these approaches. This paper provides an overview of\nmany representative CCA-based MVL approaches.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 00:53:32 GMT"}, {"version": "v2", "created": "Sun, 2 May 2021 00:08:54 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Guo", "Chenfeng", ""], ["Wu", "Dongrui", ""]]}, {"id": "1907.01695", "submitter": "Sameera Horawalavithana", "authors": "Sameera Horawalavithana, Adriana Iamnitchi", "title": "On the Privacy of dK-Random Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real social network datasets provide significant benefits for understanding\nphenomena such as information diffusion or network evolution. Yet the privacy\nrisks raised from sharing real graph datasets, even when stripped of user\nidentity information, are significant. Previous research shows that many graph\nanonymization techniques fail against existing graph de-anonymization attacks.\nHowever, the specific reason for the success of such de-anonymization attacks\nis yet to be understood. This paper systematically studies the structural\nproperties of real graphs that make them more vulnerable to machine\nlearning-based techniques for de-anonymization. More precisely, we study the\nboundaries of anonymity based on the structural properties of real graph\ndatasets in terms of how their dK-based anonymized versions resist (or fail) to\nvarious types of attacks. Our experimental results lead to three contributions.\nFirst, we identify the strength of an attacker based on the graph\ncharacteristics of the subset of nodes from which it starts the\nde-anonymization attack. Second, we quantify the relative effectiveness of\ndK-series for graph anonymization. And third, we identify the properties of the\noriginal graph that make it more vulnerable to de-anonymization.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 01:20:15 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Horawalavithana", "Sameera", ""], ["Iamnitchi", "Adriana", ""]]}, {"id": "1907.02031", "submitter": "Lin Li", "authors": "Dong Li, Lin Li", "title": "Combining Q&A Pair Quality and Question Relevance Features on\n  Community-based Question Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Q&A community has become an important way for people to access knowledge\nand information from the Internet. However, the existing translation based on\nmodels does not consider the query specific semantics when assigning weights to\nquery terms in question retrieval. So we improve the term weighting model based\non the traditional topic translation model and further considering the quality\ncharacteristics of question and answer pairs, this paper proposes a\ncommunitybased question retrieval method that combines question and answer on\nquality and question relevance (T2LM+). We have also proposed a question\nretrieval method based on convolutional neural networks. The results show that\nCompared with the relatively advanced methods, the two methods proposed in this\npaper increase MAP by 4.91% and 6.31%.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 16:53:28 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Li", "Dong", ""], ["Li", "Lin", ""]]}, {"id": "1907.02046", "submitter": "Lin Li", "authors": "Donghang Pan, Jingling Yuan, Lin Li, Deming Sheng", "title": "Deep neural network-based classification model for Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing prosperity of social networks has brought great challenges to the\nsentimental tendency mining of users. As more and more researchers pay\nattention to the sentimental tendency of online users, rich research results\nhave been obtained based on the sentiment classification of explicit texts.\nHowever, research on the implicit sentiment of users is still in its infancy.\nAiming at the difficulty of implicit sentiment classification, a research on\nimplicit sentiment classification model based on deep neural network is carried\nout. Classification models based on DNN, LSTM, Bi-LSTM and CNN were established\nto judge the tendency of the user's implicit sentiment text. Based on the\nBi-LSTM model, the classification model of word-level attention mechanism is\nstudied. The experimental results on the public dataset show that the\nestablished LSTM series classification model and CNN classification model can\nachieve good sentiment classification effect, and the classification effect is\nsignificantly better than the DNN model. The Bi-LSTM based attention mechanism\nclassification model obtained the optimal R value in the positive category\nidentification.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 17:24:14 GMT"}], "update_date": "2019-07-04", "authors_parsed": [["Pan", "Donghang", ""], ["Yuan", "Jingling", ""], ["Li", "Lin", ""], ["Sheng", "Deming", ""]]}, {"id": "1907.02203", "submitter": "Lin Li", "authors": "Weibin Lin, Lin Li", "title": "An Item Recommendation Approach by Fusing Images based on Neural\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are rich formats of information in the network, such as rating, text,\nimage, and so on, which represent different aspects of user preferences. In the\nfield of recommendation, how to use those data effectively has become a\ndifficult subject. With the rapid development of neural network, researching on\nmulti-modal method for recommendation has become one of the major directions.\nIn the existing recommender systems, numerical rating, item description and\nreview are main information to be considered by researchers. However, the\ncharacteristics of the item may affect the user's preferences, which are rarely\nused for recommendation models. In this work, we propose a novel model to\nincorporate visual factors into predictors of people's preferences, namely\nMF-VMLP, based on the recent developments of neural collaborative filtering\n(NCF). Firstly, we get visual presentation via a pre-trained convolutional\nneural network (CNN) model. To obtain the nonlinearities interaction of latent\nvectors and visual vectors, we propose to leverage a multi-layer perceptron\n(MLP) to learn. Moreover, the combination of MF and MLP has achieved\ncollaborative filtering recommendation between users and items. Our experiments\nconduct Amazon's public dataset for experimental validation and\nroot-mean-square error (RMSE) as evaluation metrics. To some extent,\nexperimental result on a real-world data set demonstrates that our model can\nboost the recommendation performance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 03:44:54 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Lin", "Weibin", ""], ["Li", "Lin", ""]]}, {"id": "1907.02258", "submitter": "Thomas Lagkas", "authors": "Anastasios Lytos, Thomas Lagkas, Panagiotis Sarigiannidis, Kalina\n  Bontcheva", "title": "The evolution of argumentation mining: From models to social media and\n  emerging tools", "comments": "Journal of Information Processing & Management, Elsevier - Accepted\n  Version", "journal-ref": "Information Processing & Management, Volume 56, Issue 6, 2019", "doi": "10.1016/j.ipm.2019.102055", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Argumentation mining is a rising subject in the computational linguistics\ndomain focusing on extracting structured arguments from natural text, often\nfrom unstructured or noisy text. The initial approaches on modeling arguments\nwas aiming to identify a flawless argument on specific fields (Law, Scientific\nPapers) serving specific needs (completeness, effectiveness). With the emerge\nof Web 2.0 and the explosion in the use of social media both the diffusion of\nthe data and the argument structure have changed. In this survey article, we\nbridge the gap between theoretical approaches of argumentation mining and\npragmatic schemes that satisfy the needs of social media generated data,\nrecognizing the need for adapting more flexible and expandable schemes, capable\nto adjust to the argumentation conditions that exist in social media. We\nreview, compare, and classify existing approaches, techniques and tools,\nidentifying the positive outcome of combining tasks and features, and\neventually propose a conceptual architecture framework. The proposed\ntheoretical framework is an argumentation mining scheme able to identify the\ndistinct sub-tasks and capture the needs of social media text, revealing the\nneed for adopting more flexible and extensible frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 07:39:23 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Lytos", "Anastasios", ""], ["Lagkas", "Thomas", ""], ["Sarigiannidis", "Panagiotis", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "1907.02383", "submitter": "Ruth Ikwu Dr", "authors": "Ruth Ikwu, Panos Louisvieris", "title": "Detecting Cyber-Related Discussions in Online Social Platforms", "comments": null, "journal-ref": null, "doi": "10.22619/IJCSA.2019.100126", "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the use of social platforms continues to evolve, in areas such as\ncyber-security and defence, it has become imperative to develop adaptive\nmethods for tracking, identifying and investigating cyber-related activities on\nthese platforms. This paper introduces a new approach for detecting\ncyber-related discussions in online social platforms using a candidate set of\nterms that are representative of the cyber domain. The objective of this paper\nis to create a cyber lexicon with cyber-related terms that is applicable to the\nautomatic detection of cyber activities across various online platforms. The\nmethod presented in this paper applies natural language processing techniques\nto representative data from multiple social platform types such as Reddit,\nStack overflow, twitter and cyberwar news to extract candidate terms for a\ngeneric cyber lexicon. In selecting the candidate terms, we introduce the APMIS\nAggregated Pointwise Mutual Information Score in comparison with the Term\nFrequency-Term Degree Ratio (FDR Score) and Term Frequency-Inverse Document\nFrequency Score (TF-IDF Score). These scoring mechanisms are robust to account\nfor term frequency, term relevance and mutual dependence between terms.\nFinally, we evaluate the performance of the cyber lexicon by measuring its\nprecision of in classifying discussions as 'Cyber-Related' or\n'Non-Cyber-Related'.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 13:01:26 GMT"}], "update_date": "2020-06-24", "authors_parsed": [["Ikwu", "Ruth", ""], ["Louisvieris", "Panos", ""]]}, {"id": "1907.02582", "submitter": "Ana Lucic", "authors": "Ana Lucic, Hinda Haned, Maarten de Rijke", "title": "Explaining Predictions from Tree-based Boosting Ensembles", "comments": "SIGIR 2019: FACTS-IR Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how \"black-box\" models arrive at their predictions has sparked\nsignificant interest from both within and outside the AI community. Our work\nfocuses on doing this by generating local explanations about individual\npredictions for tree-based ensembles, specifically Gradient Boosting Decision\nTrees (GBDTs). Given a correctly predicted instance in the training set, we\nwish to generate a counterfactual explanation for this instance, that is, the\nminimal perturbation of this instance such that the prediction flips to the\nopposite class. Most existing methods for counterfactual explanations are (1)\nmodel-agnostic, so they do not take into account the structure of the original\nmodel, and/or (2) involve building a surrogate model on top of the original\nmodel, which is not guaranteed to represent the original model accurately.\nThere exists a method specifically for random forests; we wish to extend this\nmethod for GBDTs. This involves accounting for (1) the sequential dependency\nbetween trees and (2) training on the negative gradients instead of the\noriginal labels.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 20:43:12 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Lucic", "Ana", ""], ["Haned", "Hinda", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1907.02606", "submitter": "Saeedeh Shekarpour", "authors": "Saeedeh Shekarpour and Faisal Alshargi", "title": "A Road-map Towards Explainable Question Answering A Solution for\n  Information Pollution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The increasing rate of information pollution on the Web requires novel\nsolutions to tackle that. Question Answering (QA) interfaces are simplified and\nuser-friendly interfaces to access information on the Web. However, similar to\nother AI applications, they are black boxes which do not manifest the details\nof the learning or reasoning steps for augmenting an answer. The Explainable\nQuestion Answering (XQA) system can alleviate the pain of information pollution\nwhere it provides transparency to the underlying computational model and\nexposes an interface enabling the end-user to access and validate provenance,\nvalidity, context, circulation, interpretation, and feedbacks of information.\nThis position paper sheds light on the core concepts, expectations, and\nchallenges in favor of the following questions (i) What is an XQA system?, (ii)\nWhy do we need XQA?, (iii) When do we need XQA? (iv) How to represent the\nexplanations? (iv) How to evaluate XQA systems?\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 21:42:29 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Shekarpour", "Saeedeh", ""], ["Alshargi", "Faisal", ""]]}, {"id": "1907.02704", "submitter": "Vincent Labatut", "authors": "Vincent Labatut (LIA), Xavier Bost (LIA)", "title": "Extraction and Analysis of Fictional Character Networks: A Survey", "comments": null, "journal-ref": "ACM Computing Surveys, Association for Computing Machinery, 2019,\n  52 (5), pp.89", "doi": "10.1145/3344548", "report-no": null, "categories": "cs.SI cs.CL cs.CV cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A character network is a graph extracted from a narrative, in which vertices\nrepresent characters and edges correspond to interactions between them. A\nnumber of narrative-related problems can be addressed automatically through the\nanalysis of character networks, such as summarization, classification, or role\ndetection. Character networks are particularly relevant when considering works\nof fictions (e.g. novels, plays, movies, TV series), as their exploitation\nallows developing information retrieval and recommendation systems. However,\nworks of fiction possess specific properties making these tasks harder. This\nsurvey aims at presenting and organizing the scientific literature related to\nthe extraction of character networks from works of fiction, as well as their\nanalysis. We first describe the extraction process in a generic way, and\nexplain how its constituting steps are implemented in practice, depending on\nthe medium of the narrative, the goal of the network analysis, and other\nfactors. We then review the descriptive tools used to characterize character\nnetworks, with a focus on the way they are interpreted in this context. We\nillustrate the relevance of character networks by also providing a review of\napplications derived from their analysis. Finally, we identify the limitations\nof the existing approaches, and the most promising perspectives.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 07:27:31 GMT"}, {"version": "v2", "created": "Mon, 13 Jan 2020 09:00:13 GMT"}, {"version": "v3", "created": "Fri, 31 Jul 2020 12:51:45 GMT"}, {"version": "v4", "created": "Tue, 27 Jul 2021 13:01:30 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Labatut", "Vincent", "", "LIA"], ["Bost", "Xavier", "", "LIA"]]}, {"id": "1907.02822", "submitter": "Pavlos Mitsoulis-Ntompos", "authors": "Meisam Hejazinia, Pavlos Mitsoulis-Ntompos, Serena Zhang", "title": "Deep Personalized Re-targeting", "comments": "arXiv admin note: text overlap with arXiv:1906.11336", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting booking probability and value at the traveler level plays a\ncentral role in computational advertising for massive two-sided vacation rental\nmarketplaces. These marketplaces host millions of travelers with long shopping\ncycles, spending a lot of time in the discovery phase. The footprint of the\ntravelers in their discovery is a useful data source to help these marketplaces\nto predict shopping probability and value. However, there is no\none-size-fits-all solution for this purpose. In this paper, we propose a hybrid\nmodel that infuses deep and shallow neural network embeddings into a gradient\nboosting tree model. This approach allows the latent preferences of millions of\ntravelers to be automatically learned from sparse session logs. In addition, we\npresent the architecture that we deployed into our production system. We find\nthat there is a pragmatic sweet spot between expensive complex deep neural\nnetworks and simple shallow neural networks that can increase the prediction\nperformance of a model by seven percent, based on offline analysis.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jul 2019 11:28:23 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 11:09:01 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Hejazinia", "Meisam", ""], ["Mitsoulis-Ntompos", "Pavlos", ""], ["Zhang", "Serena", ""]]}, {"id": "1907.02844", "submitter": "Joshua Vogelstein", "authors": "Meghana Madhyastha, Percy Li, James Browne, Veronika Strnadova-Neeley,\n  Carey E. Priebe, Randal Burns, Joshua T. Vogelstein", "title": "Geodesic Learning via Unsupervised Decision Forests", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geodesic distance is the shortest path between two points in a Riemannian\nmanifold. Manifold learning algorithms, such as Isomap, seek to learn a\nmanifold that preserves geodesic distances. However, such methods operate on\nthe ambient dimensionality, and are therefore fragile to noise dimensions. We\ndeveloped an unsupervised random forest method (URerF) to approximately learn\ngeodesic distances in linear and nonlinear manifolds with noise. URerF operates\non low-dimensional sparse linear combinations of features, rather than the full\nobserved dimensionality. To choose the optimal split in a computationally\nefficient fashion, we developed a fast Bayesian Information Criterion statistic\nfor Gaussian mixture models. We introduce geodesic precision-recall curves\nwhich quantify performance relative to the true latent manifold. Empirical\nresults on simulated and real data demonstrate that URerF is robust to\nhigh-dimensional noise, where as other methods, such as Isomap, UMAP, and\nFLANN, quickly deteriorate in such settings. In particular, URerF is able to\nestimate geodesic distances on a real connectome dataset better than other\napproaches.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 14:15:07 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["Madhyastha", "Meghana", ""], ["Li", "Percy", ""], ["Browne", "James", ""], ["Strnadova-Neeley", "Veronika", ""], ["Priebe", "Carey E.", ""], ["Burns", "Randal", ""], ["Vogelstein", "Joshua T.", ""]]}, {"id": "1907.02956", "submitter": "Graham McDonald", "authors": "Graham McDonald, Craig Macdonald, Iadh Ounis", "title": "The FACTS of Technology-Assisted Sensitivity Review", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At least ninety countries implement Freedom of Information laws that state\nthat government documents must be made freely available, or opened, to the\npublic. However, many government documents contain sensitive information, such\nas personal or confidential information. Therefore, all government documents\nthat are opened to the public must first be reviewed to identify, and protect,\nany sensitive information. Historically, sensitivity review has been a\ncompletely manual process. However, with the adoption of born-digital\ndocuments, such as e-mail, human-only sensitivity review is not practical and\nthere is a need for new technologies to assist human sensitivity reviewers. In\nthis paper, we discuss how issues of fairness, accountability, confidentiality,\ntransparency and safety (FACTS) impact technology-assisted sensitivity review.\nMoreover, we outline some important areas of future FACTS research that will\nneed to be addressed within technology-assisted sensitivity review.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 17:56:25 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["McDonald", "Graham", ""], ["Macdonald", "Craig", ""], ["Ounis", "Iadh", ""]]}, {"id": "1907.03007", "submitter": "Dar\\'io Garigliotti", "authors": "Jon Arne B{\\o} Hovda and Dar\\'io Garigliotti and Krisztian Balog", "title": "NeuType: A Simple and Effective Neural Network Approach for Predicting\n  Missing Entity Type Information in Knowledge Bases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge bases store information about the semantic types of entities, which\ncan be utilized in a range of information access tasks. This information,\nhowever, is often incomplete, due to new entities emerging on a daily basis. We\naddress the task of automatically assigning types to entities in a knowledge\nbase from a type taxonomy. Specifically, we present two neural network\narchitectures, which take short entity descriptions and, optionally,\ninformation about related entities as input. Using the DBpedia knowledge base\nfor experimental evaluation, we demonstrate that these simple architectures\nyield significant improvements over the current state of the art.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 19:47:10 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Hovda", "Jon Arne B\u00f8", ""], ["Garigliotti", "Dar\u00edo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1907.03039", "submitter": "Ilse Van Der Linden", "authors": "Ilse van der Linden, Hinda Haned and Evangelos Kanoulas", "title": "Global Aggregations of Local Explanations for Black Box models", "comments": "FACTS-IR: Fairness, Accountability, Confidentiality, Transparency,\n  and Safety - SIGIR 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The decision-making process of many state-of-the-art machine learning models\nis inherently inscrutable to the extent that it is impossible for a human to\ninterpret the model directly: they are black box models. This has led to a call\nfor research on explaining black box models, for which there are two main\napproaches. Global explanations that aim to explain a model's decision making\nprocess in general, and local explanations that aim to explain a single\nprediction. Since it remains challenging to establish fidelity to black box\nmodels in globally interpretable approximations, much attention is put on local\nexplanations. However, whether local explanations are able to reliably\nrepresent the black box model and provide useful insights remains an open\nquestion. We present Global Aggregations of Local Explanations (GALE) with the\nobjective to provide insights in a model's global decision making process.\nOverall, our results reveal that the choice of aggregation matters. We find\nthat the global importance introduced by Local Interpretable Model-agnostic\nExplanations (LIME) does not reliably represent the model's global behavior.\nOur proposed aggregations are better able to represent how features affect the\nmodel's predictions, and to provide global insights by identifying\ndistinguishing features.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jul 2019 22:40:36 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["van der Linden", "Ilse", ""], ["Haned", "Hinda", ""], ["Kanoulas", "Evangelos", ""]]}, {"id": "1907.03110", "submitter": "Mohamed Seghir Hadj Ameur", "authors": "Mohamed Seghir Hadj Ameur, Farid Meziane, Ahmed Guessoum", "title": "ANETAC: Arabic Named Entity Transliteration and Classification Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we make freely accessible ANETAC our English-Arabic named\nentity transliteration and classification dataset that we built from freely\navailable parallel translation corpora. The dataset contains 79,924 instances,\neach instance is a triplet (e, a, c), where e is the English named entity, a is\nits Arabic transliteration and c is its class that can be either a Person, a\nLocation, or an Organization. The ANETAC dataset is mainly aimed for the\nresearchers that are working on Arabic named entity transliteration, but it can\nalso be used for named entity classification purposes.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 10:37:18 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Ameur", "Mohamed Seghir Hadj", ""], ["Meziane", "Farid", ""], ["Guessoum", "Ahmed", ""]]}, {"id": "1907.03191", "submitter": "Saeid Hosseini", "authors": "Saeid Hosseini, Saeed Najafipour, Ngai-Man Cheung, Hongzhi Yin,\n  Mohammad Reza Kangavari, and Xiaofang Zhou", "title": "TEAGS: Time-aware Text Embedding Approach to Generate Subgraphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contagions (e.g. virus, gossip) spread over the nodes in propagation graphs.\nWe can use the temporal and textual data of the nodes to compute the edge\nweights and then generate subgraphs with highly relevant nodes. This is\nbeneficial to many applications. Yet, challenges abound. First, the propagation\npattern between each pair of nodes may change by time. Second, not always the\nsame contagion propagates. Hence, the state-of-the-art text mining approaches\nincluding topic-modeling cannot effectively compute the edge weights. Third,\nsince the propagation is affected by time, the word-word co-occurrence patterns\nmay differ in various temporal dimensions, that can decrease the effectiveness\nof word embedding approaches. We argue that multi-aspect temporal dimensions\n(hour, day, etc) should be considered to better calculate the correlation\nweights between the nodes. In this work, we devise a novel framework that on\nthe one hand, integrates a neural network based time-aware word embedding\ncomponent to construct the word vectors through multiple temporal facets, and\non the other hand, uses a temporal generative model to compute the weights.\nSubsequently, we propose a Max-Heap Graph cutting algorithm to generate\nsubgraphs. We validate our model through comprehensive experiments on\nreal-world datasets. The results show that our model can retrieve the subgraphs\nmore effective than other rivals and the temporal dynamics should be noticed\nboth in word embedding and propagation processes.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 21:26:22 GMT"}, {"version": "v2", "created": "Wed, 21 Aug 2019 13:28:23 GMT"}, {"version": "v3", "created": "Sat, 24 Aug 2019 11:40:41 GMT"}], "update_date": "2019-08-27", "authors_parsed": [["Hosseini", "Saeid", ""], ["Najafipour", "Saeed", ""], ["Cheung", "Ngai-Man", ""], ["Yin", "Hongzhi", ""], ["Kangavari", "Mohammad Reza", ""], ["Zhou", "Xiaofang", ""]]}, {"id": "1907.03336", "submitter": "Ronny Lempel", "authors": "Sonya Liberman, Shaked Bar, Raphael Vannerom, Danny Rosenstein, Ronny\n  Lempel", "title": "Search-Based Serving Architecture of Embeddings-Based Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past 10 years, many recommendation techniques have been based on\nembedding users and items in latent vector spaces, where the inner product of a\n(user,item) pair of vectors represents the predicted affinity of the user to\nthe item. A wealth of literature has focused on the various modeling approaches\nthat result in embeddings, and has compared their quality metrics, learning\ncomplexity, etc. However, much less attention has been devoted to the issues\nsurrounding productization of an embeddings-based high throughput, low latency\nrecommender system. In particular, how the system might keep up with the\nchanging embeddings as new models are learnt. This paper describes a reference\narchitecture of a high-throughput, large scale recommendation service which\nleverages a search engine as its runtime core. We describe how the search index\nand the query builder adapt to changes in the embeddings, which often happen at\na different cadence than index builds. We provide solutions for both id-based\nand feature-based embeddings, as well as for batch indexing and incremental\nindexing setups. The described system is at the core of a Web content discovery\nservice that serves tens of billions recommendations per day in response to\nbillions of user requests.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 19:32:24 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Liberman", "Sonya", ""], ["Bar", "Shaked", ""], ["Vannerom", "Raphael", ""], ["Rosenstein", "Danny", ""], ["Lempel", "Ronny", ""]]}, {"id": "1907.03459", "submitter": "Wanyu Chen", "authors": "Wanyu Chen and Fei Cai and Honghui Chen and Maarten de Rijke", "title": "Joint Neural Collaborative Filtering for Recommender Systems", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a J-NCF method for recommender systems. The J-NCF model applies a\njoint neural network that couples deep feature learning and deep interaction\nmodeling with a rating matrix. Deep feature learning extracts feature\nrepresentations of users and items with a deep learning architecture based on a\nuser-item rating matrix. Deep interaction modeling captures non-linear\nuser-item interactions with a deep neural network using the feature\nrepresentations generated by the deep feature learning process as input. J-NCF\nenables the deep feature learning and deep interaction modeling processes to\noptimize each other through joint training, which leads to improved\nrecommendation performance. In addition, we design a new loss function for\noptimization, which takes both implicit and explicit feedback, point-wise and\npair-wise loss into account. Experiments on several real-word datasets show\nsignificant improvements of J-NCF over state-of-the-art methods, with\nimprovements of up to 8.24% on the MovieLens 100K dataset, 10.81% on the\nMovieLens 1M dataset, and 10.21% on the Amazon Movies dataset in terms of\nHR@10. NDCG@10 improvements are 12.42%, 14.24% and 15.06%, respectively. We\nalso conduct experiments to evaluate the scalability and sensitivity of J-NCF.\nOur experiments show that the J-NCF model has a competitive recommendation\nperformance with inactive users and different degrees of data sparsity when\ncompared to state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 08:44:33 GMT"}, {"version": "v2", "created": "Wed, 10 Jul 2019 07:12:38 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Chen", "Wanyu", ""], ["Cai", "Fei", ""], ["Chen", "Honghui", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1907.03595", "submitter": "Shuo Zhang", "authors": "Shuo Zhang and Krisztian Balog", "title": "Recommending Related Tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tables are an extremely powerful visual and interactive tool for structuring\nand manipulating data, making spreadsheet programs one of the most popular\ncomputer applications. In this paper we introduce and address the task of\nrecommending related tables: given an input table, identifying and returning a\nranked list of relevant tables. One of the many possible application scenarios\nfor this task is to provide users of a spreadsheet program proactively with\nrecommendations for related structured content on the Web. At its core, the\nrelated table recommendation task boils down to computing the similarity\nbetween a pair of tables. We develop a theoretically sound framework for\nperforming table matching. Our approach hinges on the idea of representing\ntable elements in multiple semantic spaces, and then combining element-level\nsimilarities using a discriminative learning model. Using a purpose-built test\ncollection from Wikipedia tables, we demonstrate that the proposed approach\ndelivers state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 13:20:28 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 05:03:41 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Zhang", "Shuo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1907.03693", "submitter": "Bhaskar Mitra", "authors": "Bhaskar Mitra, Corby Rosset, David Hawking, Nick Craswell, Fernando\n  Diaz and Emine Yilmaz", "title": "Incorporating Query Term Independence Assumption for Efficient Retrieval\n  and Ranking using Deep Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical information retrieval (IR) methods, such as query likelihood and\nBM25, score documents independently w.r.t. each query term, and then accumulate\nthe scores. Assuming query term independence allows precomputing term-document\nscores using these models---which can be combined with specialized data\nstructures, such as inverted index, for efficient retrieval. Deep neural IR\nmodels, in contrast, compare the whole query to the document and are,\ntherefore, typically employed only for late stage re-ranking. We incorporate\nquery term independence assumption into three state-of-the-art neural IR\nmodels: BERT, Duet, and CKNRM---and evaluate their performance on a passage\nranking task. Surprisingly, we observe no significant loss in result quality\nfor Duet and CKNRM---and a small degradation in the case of BERT. However, by\noperating on each query term independently, these otherwise computationally\nintensive models become amenable to offline precomputation---dramatically\nreducing the cost of query evaluations employing state-of-the-art neural\nranking models. This strategy makes it practical to use deep models for\nretrieval from large collections---and not restrict their usage to late stage\nre-ranking.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 15:58:11 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Mitra", "Bhaskar", ""], ["Rosset", "Corby", ""], ["Hawking", "David", ""], ["Craswell", "Nick", ""], ["Diaz", "Fernando", ""], ["Yilmaz", "Emine", ""]]}, {"id": "1907.03718", "submitter": "Anubrata Das", "authors": "Anubrata Das, Kunjan Mehta, Matthew Lease", "title": "CobWeb: A Research Prototype for Exploring User Bias in Political\n  Fact-Checking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effect of user bias in fact-checking has not been explored extensively\nfrom a user-experience perspective. We estimate the user bias as a function of\nthe user's perceived reputation of the news sources (e.g., a user with liberal\nbeliefs may tend to trust liberal sources). We build an interface to\ncommunicate the role of estimated user bias in the context of a fact-checking\ntask. We also explore the utility of helping users visualize their detected\nlevel of bias. 80% of the users of our system find that the presence of an\nindicator for user bias is useful in judging the veracity of a political claim.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 16:50:12 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Das", "Anubrata", ""], ["Mehta", "Kunjan", ""], ["Lease", "Matthew", ""]]}, {"id": "1907.03752", "submitter": "Vukosi Marivate", "authors": "Vukosi Marivate, Tshephisho Sefara", "title": "Improving short text classification through global augmentation methods", "comments": "Final version published in CD-MAKE 2020: Machine Learning and\n  Knowledge Extraction pp 385-399", "journal-ref": "Machine Learning and Knowledge Extraction. CD-MAKE 2020. Lecture\n  Notes in Computer Science, vol 12279 (2020)", "doi": "10.1007/978-3-030-57321-8_21", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect of different approaches to text augmentation. To do this\nwe use 3 datasets that include social media and formal text in the form of news\narticles. Our goal is to provide insights for practitioners and researchers on\nmaking choices for augmentation for classification use cases. We observe that\nWord2vec-based augmentation is a viable option when one does not have access to\na formal synonym model (like WordNet-based augmentation). The use of\n\\emph{mixup} further improves performance of all text based augmentations and\nreduces the effects of overfitting on a tested deep learning model. Round-trip\ntranslation with a translation service proves to be harder to use due to cost\nand as such is less accessible for both normal and low resource use-cases.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jul 2019 18:05:12 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2020 14:41:38 GMT"}], "update_date": "2020-12-11", "authors_parsed": [["Marivate", "Vukosi", ""], ["Sefara", "Tshephisho", ""]]}, {"id": "1907.03877", "submitter": "Tiago Machado", "authors": "Tiago Machado, Dan Gopstein, Andy Nealen and Julian Togelius", "title": "Pitako -- Recommending Game Design Elements in Cicero", "comments": "Paper accepted in the IEEE Conference on Games 2019 (COG 2019)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender Systems are widely and successfully applied in e-commerce. Could\nthey be used for design? In this paper, we introduce Pitako1, a tool that\napplies the Recommender System concept to assist humans in creative tasks. More\nspecifically, Pitako provides suggestions by taking games designed by humans as\ninputs, and recommends mechanics and dynamics as outputs. Pitako is implemented\nas a new system within the mixed-initiative AI-based Game Design Assistant,\nCicero. This paper discusses the motivation behind the implementation of Pitako\nas well as its technical details and presents usage examples. We believe that\nPitako can influence the use of recommender systems to help humans in their\ndaily tasks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 21:19:25 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Machado", "Tiago", ""], ["Gopstein", "Dan", ""], ["Nealen", "Andy", ""], ["Togelius", "Julian", ""]]}, {"id": "1907.04072", "submitter": "Udit Arora", "authors": "Udit Arora, William Scott Paka, Tanmoy Chakraborty", "title": "Multitask Learning for Blackmarket Tweet Detection", "comments": "4 pages, IEEE/ACM International Conference on Social Networks\n  Analysis and Mining (ASONAM) 2019", "journal-ref": null, "doi": "10.1145/3341161.3342934", "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online social media platforms have made the world more connected than ever\nbefore, thereby making it easier for everyone to spread their content across a\nwide variety of audiences. Twitter is one such popular platform where people\npublish tweets to spread their messages to everyone. Twitter allows users to\nRetweet other users' tweets in order to broadcast it to their network. The more\nretweets a particular tweet gets, the faster it spreads. This creates\nincentives for people to obtain artificial growth in the reach of their tweets\nby using certain blackmarket services to gain inorganic appraisals for their\ncontent.\n  In this paper, we attempt to detect such tweets that have been posted on\nthese blackmarket services in order to gain artificially boosted retweets. We\nuse a multitask learning framework to leverage soft parameter sharing between a\nclassification and a regression based task on separate inputs. This allows us\nto effectively detect tweets that have been posted to these blackmarket\nservices, achieving an F1-score of 0.89 when classifying tweets as blackmarket\nor genuine.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 10:42:33 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Arora", "Udit", ""], ["Paka", "William Scott", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "1907.04098", "submitter": "Simon Duque Anton", "authors": "Simon D. Duque Anton, Daniel Fraunholz, and Hans Dieter Schotten", "title": "Using Temporal and Topological Features for Intrusion Detection in\n  Operational Networks", "comments": "Preprint of a work accepted but not published yet at the ARES 2019", "journal-ref": null, "doi": "10.1145/3339252.3341476", "report-no": null, "categories": "cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Until two decades ago, industrial networks were deemed secure due to physical\nseparation from public networks. An abundance of successful attacks proved that\nassumption wrong. Intrusion detection solutions for industrial application need\nto meet certain requirements that differ from home- and office-environments,\nsuch as working without feedback to the process and compatibility with legacy\nsystems. Industrial systems are commonly used for several decades, updates are\noften difficult and expensive. Furthermore, most industrial protocols do not\nhave inherent authentication or encryption mechanisms, allowing for easy\nlateral movement of an intruder once the perimeter is breached. In this work,\nan algorithm for motif discovery in time series, Matrix Profiles, is used to\ndetect outliers in the timing behaviour of an industrial process. This process\nwas monitored in an experimental environment, containing ground truth labels\nafter attacks were performed. Furthermore, the graph representations of a\ndifferent industrial data set that has been emulated are used to detect\nmalicious activities. These activities can be derived from anomalous\ncommunication patterns, represented as edges in the graph. Finally, an\nintegration concept for both methods is proposed.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 11:46:55 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Anton", "Simon D. Duque", ""], ["Fraunholz", "Daniel", ""], ["Schotten", "Hans Dieter", ""]]}, {"id": "1907.04149", "submitter": "Fatima Alkhawaldeh", "authors": "Fatima T. AL-Khawaldeh", "title": "Answer Extraction for Why Arabic Questions Answering Systems: EWAQ", "comments": "5 pages", "journal-ref": "World of Computer Science and Information Technology Journal\n  (WCSIT) ISSN: 2221-0741 Vol. 5, No. 5, 82-86, 2015", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increasing amount of web information, questions answering systems\nbecomes very important to allow users to access to direct answers for their\nrequests. This paper presents an Arabic Questions Answering Systems based on\nentailment metrics. The type of questions which this paper focuses on is why\nquestions. There are many reasons lead us to develop this system: generally,\nthe lack of Arabic Questions Answering Systems and scarcity Arabic Questions\nAnswering Systems which focus on why questions. The goal of the proposed system\nin this research is to extract answers from re-ranked retrieved passages which\nare retrieved by search engines. This system extracts the answer only to why\nquestions. This system is called by EWAQ: Entailment based Why Arabic Questions\nAnswering. Each answer is scored with entailment metrics and ranked according\nto their scores in order to determine the most possible correct answer. EWAQ is\ncompared with search engines: yahoo, google and ask.com, the well-established\nweb-based Questions Answering systems, using manual test set. In EWAQ\nexperiments, it is showed that the accuracy is increased by implementing the\ntextual entailment in re-raking the retrieved relevant passages by search\nengines and deciding the correct answer. The obtained results show that using\nentailment based similarity can help significantly to tackle the why Answer\nExtraction module in Arabic language.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jul 2019 17:25:28 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["AL-Khawaldeh", "Fatima T.", ""]]}, {"id": "1907.04217", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, Vijay Gadepally, Lauren Milechin, Siddharth Samsi,\n  William Arcand, David Bestor, William Bergeron, Chansup Byun, Matthew\n  Hubbell, Michael Houle, Michael Jones, Anne Klein, Peter Michaleas, Julie\n  Mullen, Andrew Prout, Antonio Rosa, Charles Yee, Albert Reuther", "title": "Streaming 1.9 Billion Hypersparse Network Updates per Second with D4M", "comments": "6 pages; 6 figures; accepted to IEEE High Performance Extreme\n  Computing (HPEC) Conference 2019. arXiv admin note: text overlap with\n  arXiv:1807.05308, arXiv:1902.00846", "journal-ref": null, "doi": "10.1109/HPEC.2019.8916508", "report-no": null, "categories": "cs.DC cs.DB cs.DS cs.IR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dynamic Distributed Dimensional Data Model (D4M) library implements\nassociative arrays in a variety of languages (Python, Julia, and Matlab/Octave)\nand provides a lightweight in-memory database implementation of hypersparse\narrays that are ideal for analyzing many types of network data. D4M relies on\nassociative arrays which combine properties of spreadsheets, databases,\nmatrices, graphs, and networks, while providing rigorous mathematical\nguarantees, such as linearity. Streaming updates of D4M associative arrays put\nenormous pressure on the memory hierarchy. This work describes the design and\nperformance optimization of an implementation of hierarchical associative\narrays that reduces memory pressure and dramatically increases the update rate\ninto an associative array. The parameters of hierarchical associative arrays\nrely on controlling the number of entries in each level in the hierarchy before\nan update is cascaded. The parameters are easily tunable to achieve optimal\nperformance for a variety of applications. Hierarchical arrays achieve over\n40,000 updates per second in a single instance. Scaling to 34,000 instances of\nhierarchical D4M associative arrays on 1,100 server nodes on the MIT SuperCloud\nachieved a sustained update rate of 1,900,000,000 updates per second. This\ncapability allows the MIT SuperCloud to analyze extremely large streaming\nnetwork data sets.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 20:55:04 GMT"}], "update_date": "2019-12-03", "authors_parsed": [["Kepner", "Jeremy", ""], ["Gadepally", "Vijay", ""], ["Milechin", "Lauren", ""], ["Samsi", "Siddharth", ""], ["Arcand", "William", ""], ["Bestor", "David", ""], ["Bergeron", "William", ""], ["Byun", "Chansup", ""], ["Hubbell", "Matthew", ""], ["Houle", "Michael", ""], ["Jones", "Michael", ""], ["Klein", "Anne", ""], ["Michaleas", "Peter", ""], ["Mullen", "Julie", ""], ["Prout", "Andrew", ""], ["Rosa", "Antonio", ""], ["Yee", "Charles", ""], ["Reuther", "Albert", ""]]}, {"id": "1907.04286", "submitter": "William Kearns", "authors": "William R. Kearns, Wilson Lau, Jason A. Thomas", "title": "UW-BHI at MEDIQA 2019: An Analysis of Representation Methods for Medical\n  Natural Language Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in distributed language modeling have led to large\nperformance increases on a variety of natural language processing (NLP) tasks.\nHowever, it is not well understood how these methods may be augmented by\nknowledge-based approaches. This paper compares the performance and internal\nrepresentation of an Enhanced Sequential Inference Model (ESIM) between three\nexperimental conditions based on the representation method: Bidirectional\nEncoder Representations from Transformers (BERT), Embeddings of Semantic\nPredications (ESP), or Cui2Vec. The methods were evaluated on the Medical\nNatural Language Inference (MedNLI) subtask of the MEDIQA 2019 shared task.\nThis task relied heavily on semantic understanding and thus served as a\nsuitable evaluation set for the comparison of these representation methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 16:47:50 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Kearns", "William R.", ""], ["Lau", "Wilson", ""], ["Thomas", "Jason A.", ""]]}, {"id": "1907.04294", "submitter": "Siddharth Gururani", "authors": "Siddharth Gururani, Mohit Sharma, Alexander Lerch", "title": "An Attention Mechanism for Musical Instrument Recognition", "comments": "To appear in: Proceedings of the International Society for Music\n  Information Retrieval Conference (ISMIR), Delft, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While the automatic recognition of musical instruments has seen significant\nprogress, the task is still considered hard for music featuring multiple\ninstruments as opposed to single instrument recordings. Datasets for polyphonic\ninstrument recognition can be categorized into roughly two categories. Some,\nsuch as MedleyDB, have strong per-frame instrument activity annotations but are\nusually small in size. Other, larger datasets such as OpenMIC only have weak\nlabels, i.e., instrument presence or absence is annotated only for long\nsnippets of a song. We explore an attention mechanism for handling weakly\nlabeled data for multi-label instrument recognition. Attention has been found\nto perform well for other tasks with weakly labeled data. We compare the\nproposed attention model to multiple models which include a baseline binary\nrelevance random forest, recurrent neural network, and fully connected neural\nnetworks. Our results show that incorporating attention leads to an overall\nimprovement in classification accuracy metrics across all 20 instruments in the\nOpenMIC dataset. We find that attention enables models to focus on (or `attend\nto') specific time segments in the audio relevant to each instrument label\nleading to interpretable results.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 17:20:36 GMT"}], "update_date": "2019-07-10", "authors_parsed": [["Gururani", "Siddharth", ""], ["Sharma", "Mohit", ""], ["Lerch", "Alexander", ""]]}, {"id": "1907.04407", "submitter": "Mohammad Heydari", "authors": "Mohammad Heydari", "title": "Sentiment Analysis Challenges in Persian Language", "comments": "the paper structure must be completely modify from scratch", "journal-ref": null, "doi": "10.13140/RG.2.2.29169.43363", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth in data on the internet requires a data mining process to\nreach a decision to support insight. The Persian language has strong potential\nfor deep research in any aspect of natural language processing, especially\nsentimental analysis approach. Thousands of websites and blogs updates and\nmodifies by Persian users around the world that contains millions of Persian\ncontext. This range of application requires a comprehensive structured\nframework to extract beneficial information for helping enterprises to enhance\ntheir business and initiate a customer-centric management process by producing\neffective recommender systems. Sentimental analysis is an intelligent approach\nfor extracting useful information from huge amounts of data to help an\nenterprise for smart management process. In this road, machine learning and\ndeep learning techniques will become very helpful but there is the number of\nchallenges which are face to them. This paper tried to present and assert the\nmost important challenges of sentimental analysis in the Persian language. This\nlanguage is an Indo-European language which spoken by over 110 million people\naround the world and is an official language in Iran, Tajikistan, and\nAfghanistan. Its also widely used in Uzbekistan, Pakistan and Turkish by order.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 20:46:37 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2020 20:50:05 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Heydari", "Mohammad", ""]]}, {"id": "1907.04471", "submitter": "Cong Li", "authors": "Manas R. Joglekar, Cong Li, Jay K. Adams, Pranav Khaitan, Quoc V. Le", "title": "Neural Input Search for Large Scale Recommendation Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation problems with large numbers of discrete items, such as\nproducts, webpages, or videos, are ubiquitous in the technology industry. Deep\nneural networks are being increasingly used for these recommendation problems.\nThese models use embeddings to represent discrete items as continuous vectors,\nand the vocabulary sizes and embedding dimensions, although heavily influence\nthe model's accuracy, are often manually selected in a heuristical manner. We\npresent Neural Input Search (NIS), a technique for learning the optimal\nvocabulary sizes and embedding dimensions for categorical features. The goal is\nto maximize prediction accuracy subject to a constraint on the total memory\nused by all embeddings. Moreover, we argue that the traditional Single-size\nEmbedding (SE), which uses the same embedding dimension for all values of a\nfeature, suffers from inefficient usage of model capacity and training data. We\npropose a novel type of embedding, namely Multi-size Embedding (ME), which\nallows the embedding dimension to vary for different values of the feature.\nDuring training we use reinforcement learning to find the optimal vocabulary\nsize for each feature and embedding dimension for each value of the feature. In\nexperiments on two common types of large scale recommendation problems, i.e.\nretrieval and ranking problems, NIS automatically found better vocabulary and\nembedding sizes that result in $6.8\\%$ and $1.8\\%$ relative improvements on\nRecall@1 and ROC-AUC over manually optimized ones.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 00:49:06 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Joglekar", "Manas R.", ""], ["Li", "Cong", ""], ["Adams", "Jay K.", ""], ["Khaitan", "Pranav", ""], ["Le", "Quoc V.", ""]]}, {"id": "1907.04476", "submitter": "Yuxin Peng", "authors": "Xiangteng He, Yuxin Peng and Liu Xie", "title": "A New Benchmark and Approach for Fine-grained Cross-media Retrieval", "comments": "9 pages, ACM MM 2019", "journal-ref": null, "doi": "10.1145/3343031.3350974", "report-no": null, "categories": "cs.IR cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-media retrieval is to return the results of various media types\ncorresponding to the query of any media type. Existing researches generally\nfocus on coarse-grained cross-media retrieval. When users submit an image of\n\"Slaty-backed Gull\" as a query, coarse-grained cross-media retrieval treats it\nas \"Bird\", so that users can only get the results of \"Bird\", which may include\nother bird species with similar appearance (image and video), descriptions\n(text) or sounds (audio), such as \"Herring Gull\". Such coarse-grained\ncross-media retrieval is not consistent with human lifestyle, where we\ngenerally have the fine-grained requirement of returning the exactly relevant\nresults of \"Slaty-backed Gull\" instead of \"Herring Gull\". However, few\nresearches focus on fine-grained cross-media retrieval, which is a highly\nchallenging and practical task. Therefore, in this paper, we first construct a\nnew benchmark for fine-grained cross-media retrieval, which consists of 200\nfine-grained subcategories of the \"Bird\", and contains 4 media types, including\nimage, text, video and audio. To the best of our knowledge, it is the first\nbenchmark with 4 media types for fine-grained cross-media retrieval. Then, we\npropose a uniform deep model, namely FGCrossNet, which simultaneously learns 4\ntypes of media without discriminative treatments. We jointly consider three\nconstraints for better common representation learning: classification\nconstraint ensures the learning of discriminative features, center constraint\nensures the compactness characteristic of the features of the same subcategory,\nand ranking constraint ensures the sparsity characteristic of the features of\ndifferent subcategories. Extensive experiments verify the usefulness of the new\nbenchmark and the effectiveness of our FGCrossNet. They will be made available\nat https://github.com/PKU-ICST-MIPL/FGCrossNet_ACMMM2019.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 01:15:22 GMT"}, {"version": "v2", "created": "Thu, 31 Oct 2019 06:37:53 GMT"}], "update_date": "2019-11-01", "authors_parsed": [["He", "Xiangteng", ""], ["Peng", "Yuxin", ""], ["Xie", "Liu", ""]]}, {"id": "1907.04614", "submitter": "Sebastian Hofst\\\"atter", "authors": "Sebastian Hofst\\\"atter, Allan Hanbury", "title": "Let's measure run time! Extending the IR replicability infrastructure to\n  include performance aspects", "comments": "Position paper @ SIGIR 2019 Open-Source IR Replicability Challenge\n  (OSIRRC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Establishing a docker-based replicability infrastructure offers the community\na great opportunity: measuring the run time of information retrieval systems.\nThe time required to present query results to a user is paramount to the users\nsatisfaction. Recent advances in neural IR re-ranking models put the issue of\nquery latency at the forefront. They bring a complex trade-off between\nperformance and effectiveness based on a myriad of factors: the choice of\nencoding model, network architecture, hardware acceleration and many others.\nThe best performing models (currently using the BERT transformer model) run\norders of magnitude more slowly than simpler architectures. We aim to broaden\nthe focus of the neural IR community to include performance considerations --\nto sustain the practical applicability of our innovations. In this position\npaper we supply our argument with a case study exploring the performance of\ndifferent neural re-ranking models. Finally, we propose to extend the OSIRRC\ndocker-based replicability infrastructure with two performance focused\nbenchmark scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 10:56:08 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Hofst\u00e4tter", "Sebastian", ""], ["Hanbury", "Allan", ""]]}, {"id": "1907.04628", "submitter": "Thijs Laarhoven", "authors": "Thijs Laarhoven", "title": "Polytopes, lattices, and spherical codes for the nearest neighbor\n  problem", "comments": "This is the full version of the paper published in the proceedings of\n  ICALP 2020 under the same title, which only contains Section 1", "journal-ref": "ICALP 2020", "doi": "10.4230/LIPIcs.ICALP.2020.76", "report-no": null, "categories": "cs.DS cs.CC cs.CG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study locality-sensitive hash methods for the nearest neighbor problem for\nthe angular distance, focusing on the approach of first projecting down onto a\nlow-dimensional subspace, and then partitioning the projected vectors according\nto Voronoi cells induced by a suitable spherical code. This approach\ngeneralizes and interpolates between the fast but suboptimal hyperplane hashing\nof Charikar [STOC'02] and the asymptotically optimal but practically often\nslower hash families of Andoni-Indyk [FOCS'06], Andoni-Indyk-Nguyen-Razenshteyn\n[SODA'14] and Andoni-Indyk-Laarhoven-Razenshteyn-Schmidt [NIPS'15]. We set up a\nframework for analyzing the performance of any spherical code in this context,\nand we provide results for various codes from the literature, such as those\nrelated to regular polytopes and root lattices. Similar to hyperplane hashing,\nand unlike cross-polytope hashing, our analysis of collision probabilities and\nquery exponents is exact and does not hide order terms which vanish only for\nlarge $d$, facilitating an easy parameter selection.\n  For the two-dimensional case, we derive closed-form expressions for arbitrary\nspherical codes, and we show that the equilateral triangle is optimal,\nachieving a better performance than the two-dimensional analogues of hyperplane\nand cross-polytope hashing. In three and four dimensions, we numerically find\nthat the tetrahedron, $5$-cell, and $16$-cell achieve the best query exponents,\nwhile in five or more dimensions orthoplices appear to outperform regular\nsimplices, as well as the root lattice families $A_k$ and $D_k$. We argue that\nin higher dimensions, larger spherical codes will likely exist which will\noutperform orthoplices in theory, and we argue why using the $D_k$ root\nlattices will likely lead to better results in practice, due to a better\ntrade-off between the asymptotic query exponent and the concrete costs of\nhashing.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 11:38:27 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 03:50:06 GMT"}], "update_date": "2020-06-30", "authors_parsed": [["Laarhoven", "Thijs", ""]]}, {"id": "1907.04667", "submitter": "Wentao Ouyang", "authors": "Wentao Ouyang, Xiuwu Zhang, Shukui Ren, Li Li, Zhaojie Liu, Yanlong Du", "title": "Click-Through Rate Prediction with the User Memory Network", "comments": "Accepted by DLP-KDD 2019 (1st International Workshop on Deep Learning\n  Practice for High-Dimensional Sparse Data; with KDD 2019). arXiv admin note:\n  text overlap with arXiv:1906.04365, arXiv:1906.03776", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction is a critical task in online advertising\nsystems. Models like Deep Neural Networks (DNNs) are simple but stateless. They\nconsider each target ad independently and cannot directly extract useful\ninformation contained in users' historical ad impressions and clicks. In\ncontrast, models like Recurrent Neural Networks (RNNs) are stateful but\ncomplex. They model temporal dependency between users' sequential behaviors and\ncan achieve improved prediction performance than DNNs. However, both the\noffline training and online prediction process of RNNs are much more complex\nand time-consuming. In this paper, we propose Memory Augmented DNN (MA-DNN) for\npractical CTR prediction services. In particular, we create two external memory\nvectors for each user, memorizing high-level abstractions of what a user\npossibly likes and dislikes. The proposed MA-DNN achieves a good compromise\nbetween DNN and RNN. It is as simple as DNN, but has certain ability to exploit\nuseful information contained in users' historical behaviors as RNN. Both\noffline and online experiments demonstrate the effectiveness of MA-DNN for\npractical CTR prediction services. Actually, the memory component can be\naugmented to other models as well (e.g., the Wide&Deep model).\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 03:40:07 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 00:30:26 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Ouyang", "Wentao", ""], ["Zhang", "Xiuwu", ""], ["Ren", "Shukui", ""], ["Li", "Li", ""], ["Liu", "Zhaojie", ""], ["Du", "Yanlong", ""]]}, {"id": "1907.04797", "submitter": "Mohamed Wiem Mkaouer", "authors": "Eman Abdullah AlOmar, Mohamed Wiem Mkaouer, Ali Ouni, Marouane\n  Kessentini", "title": "Do Design Metrics Capture Developers Perception of Quality? An Empirical\n  Study on Self-Affirmed Refactoring Activities", "comments": "technical paper accepted in 2019 ACM/IEEE International Symposium on\n  Empirical Software Engineering and Measurement (ESEM)", "journal-ref": "2019 {ACM/IEEE} International Symposium on Empirical Software\n  Engineering and Measurement, {ESEM} 2019, Porto de Galinhas, Recife, Brazil,\n  September 19-20, 2019", "doi": "10.1109/ESEM.2019.8870177", "report-no": null, "categories": "cs.SE cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background. Refactoring is a critical task in software maintenance and is\ngenerally performed to enforce the best design and implementation practices or\nto cope with design defects. Several studies attempted to detect refactoring\nactivities through mining software repositories allowing to collect, analyze\nand get actionable data-driven insights about refactoring practices within\nsoftware projects. Aim. We aim at identifying, among the various quality models\npresented in the literature, the ones that are more in-line with the\ndeveloper's vision of quality optimization, when they explicitly mention that\nthey are refactoring to improve them. Method. We extract a large corpus of\ndesign-related refactoring activities that are applied and documented by\ndevelopers during their daily changes from 3,795 curated open source Java\nprojects. In particular, we extract a large-scale corpus of structural metrics\nand anti-pattern enhancement changes, from which we identify 1,245 quality\nimprovement commits with their corresponding refactoring operations, as\nperceived by software engineers. Thereafter, we empirically analyze the impact\nof these refactoring operations on a set of common state-of-the-art design\nquality metrics. Results. The statistical analysis of the obtained results\nshows that (i) a few state-of-the-art metrics are more popular than others; and\n(ii) some metrics are being more emphasized than others. Conclusions. We verify\nthat there are a variety of structural metrics that can represent the internal\nquality attributes with different degrees of improvement and degradation of\nsoftware quality. Most of the metrics that are mapped to the main quality\nattributes do capture developer intentions of quality improvement reported in\nthe commit messages.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 15:34:50 GMT"}], "update_date": "2020-09-15", "authors_parsed": [["AlOmar", "Eman Abdullah", ""], ["Mkaouer", "Mohamed Wiem", ""], ["Ouni", "Ali", ""], ["Kessentini", "Marouane", ""]]}, {"id": "1907.04884", "submitter": "Ronny Lempel", "authors": "David Abensur, Ivan Balashov, Shaked Bar, Ronny Lempel, Nurit\n  Moscovici, Ilan Orlov, Danny Rosenstein, Ido Tamir", "title": "Productization Challenges of Contextual Multi-Armed Bandits", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual Multi-Armed Bandits is a well-known and accepted online\noptimization algorithm, that is used in many Web experiences to tailor content\nor presentation to users' traffic. Much has been published on theoretical\nguarantees (e.g. regret bounds) of proposed algorithmic variants, but\nrelatively little attention has been devoted to the challenges encountered\nwhile productizing contextual bandits schemes in large scale settings. This\nwork enumerates several productization challenges we encountered while\nleveraging contextual bandits for two concrete use cases at scale. We discuss\nhow to (1) determine the context (engineer the features) that model the bandit\narms; (2) sanity check the health of the optimization process; (3) evaluate the\nprocess in an offline manner; (4) add potential actions (arms) on the fly to a\nrunning process; (5) subject the decision process to constraints; and (6)\niteratively improve the online learning algorithm. For each such challenge, we\nexplain the issue, provide our approach, and relate to prior art where\napplicable.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 18:45:40 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Abensur", "David", ""], ["Balashov", "Ivan", ""], ["Bar", "Shaked", ""], ["Lempel", "Ronny", ""], ["Moscovici", "Nurit", ""], ["Orlov", "Ilan", ""], ["Rosenstein", "Danny", ""], ["Tamir", "Ido", ""]]}, {"id": "1907.04891", "submitter": "Artur Strzelecki", "authors": "Artur Strzelecki and Paulina Rutecka", "title": "Featured Snippets Results in Google Web Search: An Exploratory Study", "comments": "10 pages, 6 tables, accepted to conference ICMarktech'19", "journal-ref": "Marketing and Smart Technologies 2020", "doi": "10.1007/978-981-15-1564-4_2", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper authors analyzed 163412 keywords and results with featured\nsnippets collected from localized Polish Google search engine. A method-ology\nfor retrieving data from Google search engine was proposed in terms of\nobtaining necessary data to study featured snippets. It was observed that\nalmost half of featured snippets (48%) is taken from result on first ranking\nposition. Furthermore, some correlations between prepositions and the most\noften appearing content words in keywords was discovered. Results show that\nfeatured snippets are often taken from trustworthy websites like e.g.,\nWikipedia and are mainly presented in form of a paragraph. Paragraph can be\nread by Google Assistant or Home Assistant with voice search. We conclude our\nfindings with discussion and research limitations.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 19:06:58 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2019 09:05:03 GMT"}, {"version": "v3", "created": "Tue, 3 Dec 2019 22:51:53 GMT"}], "update_date": "2019-12-05", "authors_parsed": [["Strzelecki", "Artur", ""], ["Rutecka", "Paulina", ""]]}, {"id": "1907.04905", "submitter": "Rogerio Bonatti", "authors": "Rogerio Bonatti and Arthur Gola de Paula", "title": "Development of email classifier in Brazilian Portuguese using feature\n  selection for automatic response", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic email categorization is an important application of text\nclassification. We study the automatic reply of email business messages in\nBrazilian Portuguese. We present a novel corpus containing messages from a real\napplication, and baseline categorization experiments using Naive Bayes and\nsupport Vector Machines. We then discuss the effect of lemmatization and the\nrole of part-of-speech tagging filtering on precision and recall. Support\nVector Machines classification coupled with nonlemmatized selection of verbs,\nnouns and adjectives was the best approach, with 87.3% maximum accuracy.\nStraightforward lemmatization in Portuguese led to the lowest classification\nresults in the group, with 85.3% and 81.7% precision in SVM and Naive Bayes\nrespectively. Thus, while lemmatization reduced precision and recall,\npart-of-speech filtering improved overall results.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 03:24:53 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Bonatti", "Rogerio", ""], ["de Paula", "Arthur Gola", ""]]}, {"id": "1907.04907", "submitter": "Adji Bousso Dieng", "authors": "Adji B. Dieng, Francisco J. R. Ruiz, and David M. Blei", "title": "Topic Modeling in Embedding Spaces", "comments": "Code can be found at https://github.com/adjidieng/ETM", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic modeling analyzes documents to learn meaningful patterns of words.\nHowever, existing topic models fail to learn interpretable topics when working\nwith large and heavy-tailed vocabularies. To this end, we develop the Embedded\nTopic Model (ETM), a generative model of documents that marries traditional\ntopic models with word embeddings. In particular, it models each word with a\ncategorical distribution whose natural parameter is the inner product between a\nword embedding and an embedding of its assigned topic. To fit the ETM, we\ndevelop an efficient amortized variational inference algorithm. The ETM\ndiscovers interpretable topics even with large vocabularies that include rare\nwords and stop words. It outperforms existing document models, such as latent\nDirichlet allocation (LDA), in terms of both topic quality and predictive\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 03:50:57 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Dieng", "Adji B.", ""], ["Ruiz", "Francisco J. R.", ""], ["Blei", "David M.", ""]]}, {"id": "1907.04915", "submitter": "Tao Zhou", "authors": "Wen-Bo Xie, Yan-Li Lee, Cong Wang, Duan-Bing Chen, Tao Zhou", "title": "Hierarchical Clustering Supported by Reciprocal Nearest Neighbors", "comments": "13 pages, 5 figures, 5 supplementary figures, 2 tables", "journal-ref": "Information Sciences 527 (2020) 279-292", "doi": "10.1016/j.ins.2020.04.016", "report-no": null, "categories": "cs.IR cs.SI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a fundamental analysis tool aiming at classifying data points\ninto groups based on their similarity or distance. It has found successful\napplications in all natural and social sciences, including biology, physics,\neconomics, chemistry, astronomy, psychology, and so on. Among numerous existent\nalgorithms, hierarchical clustering algorithms are of a particular advantage as\nthey can provide results under different resolutions without any predetermined\nnumber of clusters and unfold the organization of resulted clusters. At the\nsame time, they suffer a variety of drawbacks and thus are either\ntime-consuming or inaccurate. We propose a novel hierarchical clustering\napproach on the basis of a simple hypothesis that two reciprocal nearest data\npoints should be grouped in one cluster. Extensive tests on data sets across\nmultiple domains show that our method is much faster and more accurate than the\nstate-of-the-art benchmarks. We further extend our method to deal with the\ncommunity detection problem in real networks, achieving remarkably better\nresults in comparison with the well-known Girvan-Newman algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jul 2019 04:34:28 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Xie", "Wen-Bo", ""], ["Lee", "Yan-Li", ""], ["Wang", "Cong", ""], ["Chen", "Duan-Bing", ""], ["Zhou", "Tao", ""]]}, {"id": "1907.04919", "submitter": "Stefanos Poulis", "authors": "Sanjoy Dasgupta, Stefanos Poulis, Christopher Tosh", "title": "Interactive Topic Modeling with Anchor Words", "comments": "presented at 2019 ICML Workshop on Human in the Loop Learning (HILL\n  2019), Long Beach, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The formalism of anchor words has enabled the development of fast topic\nmodeling algorithms with provable guarantees. In this paper, we introduce a\nprotocol that allows users to interact with anchor words to build customized\nand interpretable topic models. Experimental evidence validating the usefulness\nof our approach is also presented.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jun 2019 23:42:23 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Dasgupta", "Sanjoy", ""], ["Poulis", "Stefanos", ""], ["Tosh", "Christopher", ""]]}, {"id": "1907.04924", "submitter": "Xichen Ding", "authors": "Xichen Ding, Jie Tang, Tracy Liu, Cheng Xu, Yaping Zhang, Feng Shi,\n  Qixia Jiang, Dan Shen", "title": "Infer Implicit Contexts in Real-time Online-to-Offline Recommendation", "comments": "9 pages,KDD,KDD2019", "journal-ref": null, "doi": "10.1145/3292500.3330716", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding users' context is essential for successful recommendations,\nespecially for Online-to-Offline (O2O) recommendation, such as Yelp, Groupon,\nand Koubei. Different from traditional recommendation where individual\npreference is mostly static, O2O recommendation should be dynamic to capture\nvariation of users' purposes across time and location. However, precisely\ninferring users' real-time contexts information, especially those implicit\nones, is extremely difficult, and it is a central challenge for O2O\nrecommendation. In this paper, we propose a new approach, called Mixture\nAttentional Constrained Denoise AutoEncoder (MACDAE), to infer implicit\ncontexts and consequently, to improve the quality of real-time O2O\nrecommendation. In MACDAE, we first leverage the interaction among users,\nitems, and explicit contexts to infer users' implicit contexts, then combine\nthe learned implicit-context representation into an end-to-end model to make\nthe recommendation. MACDAE works quite well in the real system. We conducted\nboth offline and online evaluations of the proposed approach. Experiments on\nseveral real-world datasets (Yelp, Dianping, and Koubei) show our approach\ncould achieve significant improvements over state-of-the-arts. Furthermore,\nonline A/B test suggests a 2.9% increase for click-through rate and 5.6%\nimprovement for conversion rate in real-world traffic. Our model has been\ndeployed in the product of \"Guess You Like\" recommendation in Koubei.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 05:37:30 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Ding", "Xichen", ""], ["Tang", "Jie", ""], ["Liu", "Tracy", ""], ["Xu", "Cheng", ""], ["Zhang", "Yaping", ""], ["Shi", "Feng", ""], ["Jiang", "Qixia", ""], ["Shen", "Dan", ""]]}, {"id": "1907.05171", "submitter": "Chen Xu", "authors": "Chen Xu, Quan Li, Junfeng Ge, Jinyang Gao, Xiaoyong Yang, Changhua\n  Pei, Fei Sun, Jian Wu, Hanxiao Sun, and Wenwu Ou", "title": "Privileged Features Distillation at Taobao Recommendations", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Features play an important role in the prediction tasks of e-commerce\nrecommendations. To guarantee the consistency of off-line training and on-line\nserving, we usually utilize the same features that are both available. However,\nthe consistency in turn neglects some discriminative features. For example,\nwhen estimating the conversion rate (CVR), i.e., the probability that a user\nwould purchase the item if she clicked it, features like dwell time on the item\ndetailed page are informative. However, CVR prediction should be conducted for\non-line ranking before the click happens. Thus we cannot get such post-event\nfeatures during serving.\n  We define the features that are discriminative but only available during\ntraining as the privileged features. Inspired by the distillation techniques\nwhich bridge the gap between training and inference, in this work, we propose\nprivileged features distillation (PFD). We train two models, i.e., a student\nmodel that is the same as the original one and a teacher model that\nadditionally utilizes the privileged features. Knowledge distilled from the\nmore accurate teacher is transferred to the student to improve its accuracy.\nDuring serving, only the student part is extracted and it relies on no\nprivileged features. We conduct experiments on two fundamental prediction tasks\nat Taobao recommendations, i.e., click-through rate (CTR) at coarse-grained\nranking and CVR at fine-grained ranking. By distilling the interacted features\nthat are prohibited during serving for CTR and the post-event features for CVR,\nwe achieve significant improvements over their strong baselines. During the\non-line A/B tests, the click metric is improved by +5.0% in the CTR task. And\nthe conversion metric is improved by +2.3% in the CVR task. Besides, by\naddressing several issues of training PFD, we obtain comparable training speed\nas the baselines without any distillation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 13:05:51 GMT"}, {"version": "v2", "created": "Wed, 26 Feb 2020 03:21:01 GMT"}], "update_date": "2020-02-27", "authors_parsed": [["Xu", "Chen", ""], ["Li", "Quan", ""], ["Ge", "Junfeng", ""], ["Gao", "Jinyang", ""], ["Yang", "Xiaoyong", ""], ["Pei", "Changhua", ""], ["Sun", "Fei", ""], ["Wu", "Jian", ""], ["Sun", "Hanxiao", ""], ["Ou", "Wenwu", ""]]}, {"id": "1907.05333", "submitter": "Jun Kuang", "authors": "Jun Kuang, Yixin Cao, Jianbing Zheng, Xiangnan He, Ming Gao, Aoying\n  Zhou", "title": "Improving Neural Relation Extraction with Implicit Mutual Relations", "comments": "12 pages", "journal-ref": null, "doi": "10.1109/ICDE48307.2020.00093", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation extraction (RE) aims at extracting the relation between two entities\nfrom the text corpora. It is a crucial task for Knowledge Graph (KG)\nconstruction. Most existing methods predict the relation between an entity pair\nby learning the relation from the training sentences, which contain the\ntargeted entity pair. In contrast to existing distant supervision approaches\nthat suffer from insufficient training corpora to extract relations, our\nproposal of mining implicit mutual relation from the massive unlabeled corpora\ntransfers the semantic information of entity pairs into the RE model, which is\nmore expressive and semantically plausible. After constructing an entity\nproximity graph based on the implicit mutual relations, we preserve the\nsemantic relations of entity pairs via embedding each vertex of the graph into\na low-dimensional space. As a result, we can easily and flexibly integrate the\nimplicit mutual relations and other entity information, such as entity types,\ninto the existing RE methods.\n  Our experimental results on a New York Times and another Google Distant\nSupervision datasets suggest that our proposed neural RE framework provides a\npromising improvement for the RE task, and significantly outperforms the\nstate-of-the-art methods. Moreover, the component for mining implicit mutual\nrelations is so flexible that can help to improve the performance of both\nCNN-based and RNN-based RE models significant.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jul 2019 02:16:11 GMT"}], "update_date": "2020-11-30", "authors_parsed": [["Kuang", "Jun", ""], ["Cao", "Yixin", ""], ["Zheng", "Jianbing", ""], ["He", "Xiangnan", ""], ["Gao", "Ming", ""], ["Zhou", "Aoying", ""]]}, {"id": "1907.05346", "submitter": "Jiahuan Pei", "authors": "Jiahuan Pei, Pengjie Ren, Maarten de Rijke", "title": "A Modular Task-oriented Dialogue System Using a Neural\n  Mixture-of-Experts", "comments": "Proceedings of the 2019 SIGIR Workshop WCIS: Workshop on\n  Conversational Interaction Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  End-to-end Task-oriented Dialogue Systems (TDSs) have attracted a lot of\nattention for their superiority (e.g., in terms of global optimization) over\npipeline modularized TDSs. Previous studies on end-to-end TDSs use a\nsingle-module model to generate responses for complex dialogue contexts.\nHowever, no model consistently outperforms the others in all cases. We propose\na neural Modular Task-oriented Dialogue System(MTDS) framework, in which a few\nexpert bots are combined to generate the response for a given dialogue context.\nMTDS consists of a chair bot and several expert bots. Each expert bot is\nspecialized for a particular situation, e.g., one domain, one type of action of\na system, etc. The chair bot coordinates multiple expert bots and adaptively\nselects an expert bot to generate the appropriate response. We further propose\na Token-level Mixture-of-Expert (TokenMoE) model to implement MTDS, where the\nexpert bots predict multiple tokens at each timestamp and the chair bot\ndetermines the final generated token by fully taking into consideration the\noutputs of all expert bots. Both the chair bot and the expert bots are jointly\ntrained in an end-to-end fashion. To verify the effectiveness of TokenMoE, we\ncarry out extensive experiments on a benchmark dataset. Compared with the\nbaseline using a single-module model, our TokenMoE improves the performance by\n8.1% of inform rate and 0.8% of success rate.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:25:50 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Pei", "Jiahuan", ""], ["Ren", "Pengjie", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1907.05559", "submitter": "Chuhan Wu", "authors": "Chuhan Wu, Fangzhao Wu, Mingxiao An, Jianqiang Huang, Yongfeng Huang,\n  Xing Xie", "title": "NPA: Neural News Recommendation with Personalized Attention", "comments": null, "journal-ref": null, "doi": "10.1145/3292500.3330665", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News recommendation is very important to help users find interested news and\nalleviate information overload. Different users usually have different\ninterests and the same user may have various interests. Thus, different users\nmay click the same news article with attention on different aspects. In this\npaper, we propose a neural news recommendation model with personalized\nattention (NPA). The core of our approach is a news representation model and a\nuser representation model. In the news representation model we use a CNN\nnetwork to learn hidden representations of news articles based on their titles.\nIn the user representation model we learn the representations of users based on\nthe representations of their clicked news articles. Since different words and\ndifferent news articles may have different informativeness for representing\nnews and users, we propose to apply both word- and news-level attention\nmechanism to help our model attend to important words and news articles. In\naddition, the same news article and the same word may have different\ninformativeness for different users. Thus, we propose a personalized attention\nnetwork which exploits the embedding of user ID to generate the query vector\nfor the word- and news-level attentions. Extensive experiments are conducted on\na real-world news recommendation dataset collected from MSN news, and the\nresults validate the effectiveness of our approach on news recommendation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 03:11:14 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Wu", "Chuhan", ""], ["Wu", "Fangzhao", ""], ["An", "Mingxiao", ""], ["Huang", "Jianqiang", ""], ["Huang", "Yongfeng", ""], ["Xie", "Xing", ""]]}, {"id": "1907.05562", "submitter": "Yazhou Zhang", "authors": "Yazhou Zhang, Lingling Song, Dawei Song, Peng Guo, Junwei Zhang and\n  Peng Zhang", "title": "ScenarioSA: A Large Scale Conversational Database for Interactive\n  Sentiment Analysis", "comments": "Withdrawn by arXiv administration due to policy violation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive sentiment analysis is an emerging, yet challenging, subtask of\nthe sentiment analysis problem. It aims to discover the affective state and\nsentimental change of each person in a conversation. Existing sentiment\nanalysis approaches are insufficient in modelling the interactions among\npeople. However, the development of new approaches are critically limited by\nthe lack of labelled interactive sentiment datasets. In this paper, we present\na new conversational emotion database that we have created and made publically\navailable, namely ScenarioSA. We manually label 2,214 multi-turn English\nconversations collected from natural contexts. In comparison with existing\nsentiment datasets, ScenarioSA (1) covers a wide range of scenarios; (2)\ndescribes the interactions between two speakers; and (3) reflects the\nsentimental evolution of each speaker over the course of a conversation.\nFinally, we evaluate various state-of-the-art algorithms on ScenarioSA,\ndemonstrating the need of novel interactive sentiment analysis models and the\npotential of ScenarioSA to facilitate the development of such models.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 03:34:06 GMT"}, {"version": "v2", "created": "Tue, 19 May 2020 13:02:44 GMT"}], "update_date": "2020-05-20", "authors_parsed": [["Zhang", "Yazhou", ""], ["Song", "Lingling", ""], ["Song", "Dawei", ""], ["Guo", "Peng", ""], ["Zhang", "Junwei", ""], ["Zhang", "Peng", ""]]}, {"id": "1907.05576", "submitter": "Chuhan Wu", "authors": "Chuhan Wu, Fangzhao Wu, Mingxiao An, Jianqiang Huang, Yongfeng Huang,\n  Xing Xie", "title": "Neural News Recommendation with Attentive Multi-View Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized news recommendation is very important for online news platforms\nto help users find interested news and improve user experience. News and user\nrepresentation learning is critical for news recommendation. Existing news\nrecommendation methods usually learn these representations based on single news\ninformation, e.g., title, which may be insufficient. In this paper we propose a\nneural news recommendation approach which can learn informative representations\nof users and news by exploiting different kinds of news information. The core\nof our approach is a news encoder and a user encoder. In the news encoder we\npropose an attentive multi-view learning model to learn unified news\nrepresentations from titles, bodies and topic categories by regarding them as\ndifferent views of news. In addition, we apply both word-level and view-level\nattention mechanism to news encoder to select important words and views for\nlearning informative news representations. In the user encoder we learn the\nrepresentations of users based on their browsed news and apply attention\nmechanism to select informative news for user representation learning.\nExtensive experiments on a real-world dataset show our approach can effectively\nimprove the performance of news recommendation.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 04:50:33 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Wu", "Chuhan", ""], ["Wu", "Fangzhao", ""], ["An", "Mingxiao", ""], ["Huang", "Jianqiang", ""], ["Huang", "Yongfeng", ""], ["Xie", "Xing", ""]]}, {"id": "1907.05755", "submitter": "Michael Ekstrand", "authors": "Alexandra Olteanu, Jean Garcia-Gathright, Maarten de Rijke, and\n  Michael D. Ekstrand", "title": "Proceedings of FACTS-IR 2019", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proceedings list for the program of FACTS-IR 2019, the Workshop on\nFairness, Accountability, Confidentiality, Transparency, and Safety in\nInformation Retrieval held at SIGIR 2019.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 14:08:56 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Olteanu", "Alexandra", ""], ["Garcia-Gathright", "Jean", ""], ["de Rijke", "Maarten", ""], ["Ekstrand", "Michael D.", ""]]}, {"id": "1907.05790", "submitter": "Christophe Servan", "authors": "Estelle Maudet, Oralie Cattan, Maureen de Seyssel, Christophe Servan", "title": "Qwant Research @DEFT 2019: Document matching and information retrieval\n  using clinical cases", "comments": "Article accepted at the workshop DEfi fouille de Texte (DEFT 2019).\n  Article in French", "journal-ref": "DEFT 2019", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on Qwant Research contribution to tasks 2 and 3 of the\nDEFT 2019's challenge, focusing on French clinical cases analysis. Task 2 is a\ntask on semantic similarity between clinical cases and discussions. For this\ntask, we propose an approach based on language models and evaluate the impact\non the results of different preprocessings and matching techniques. For task 3,\nwe have developed an information extraction system yielding very encouraging\nresults accuracy-wise. We have experimented two different approaches, one based\non the exclusive use of neural networks, the other based on a linguistic\nanalysis.\n", "versions": [{"version": "v1", "created": "Sat, 6 Jul 2019 08:29:21 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Maudet", "Estelle", ""], ["Cattan", "Oralie", ""], ["de Seyssel", "Maureen", ""], ["Servan", "Christophe", ""]]}, {"id": "1907.05792", "submitter": "Jatin Ganhotra", "authors": "Jatin Ganhotra, Siva Sankalp Patel, Kshitij Fadnis", "title": "Knowledge-incorporating ESIM models for Response Selection in\n  Retrieval-based Dialog Systems", "comments": "Ranked 2nd on Ubuntu and 4th on Advising task in DSTC-7 Track 1.\n  Accepted for an oral presentation at the DSTC-7 workshop at AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Goal-oriented dialog systems, which can be trained end-to-end without\nmanually encoding domain-specific features, show tremendous promise in the\ncustomer support use-case e.g. flight booking, hotel reservation, technical\nsupport, student advising etc. These dialog systems must learn to interact with\nexternal domain knowledge to achieve the desired goal e.g. recommending courses\nto a student, booking a table at a restaurant etc. This paper presents extended\nEnhanced Sequential Inference Model (ESIM) models: a) K-ESIM (Knowledge-ESIM),\nwhich incorporates the external domain knowledge and b) T-ESIM (Targeted-ESIM),\nwhich leverages information from similar conversations to improve the\nprediction accuracy. Our proposed models and the baseline ESIM model are\nevaluated on the Ubuntu and Advising datasets in the Sentence Selection track\nof the latest Dialog System Technology Challenge (DSTC7), where the goal is to\nfind the correct next utterance, given a partial conversation, from a set of\ncandidates. Our preliminary results suggest that incorporating external\nknowledge sources and leveraging information from similar dialogs leads to\nperformance improvements for predicting the next utterance.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jul 2019 15:55:24 GMT"}], "update_date": "2019-07-15", "authors_parsed": [["Ganhotra", "Jatin", ""], ["Patel", "Siva Sankalp", ""], ["Fadnis", "Kshitij", ""]]}, {"id": "1907.06146", "submitter": "Cong Fu", "authors": "Cong Fu, Changxu Wang, Deng Cai", "title": "High Dimensional Similarity Search with Satellite System Graph:\n  Efficiency, Scalability, and Unindexed Query Compatibility", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate Nearest Neighbor Search (ANNS) in high dimensional space is\nessential in database and information retrieval. Recently, there has been a\nsurge of interest in exploring efficient graph-based indices for the ANNS\nproblem. Among them, Navigating Spreading-out Graph (NSG) provides fine\ntheoretical analysis and achieves state-of-the-art performance. However, we\nfind there are several limitations with NSG: 1) NSG has no theoretical\nguarantee on nearest neighbor search when the query is not indexed in the\ndatabase; 2) NSG is too sparse which harms the search performance. In addition,\nNSG suffers from high indexing complexity. To address the above problems, we\npropose the Satellite System Graphs (SSG) and a practical variant NSSG.\nSpecifically, we propose a novel pruning strategy to produce SSGs from the\ncomplete graph. SSGs define a new family of MSNETs in which the out-edges of\neach node are distributed evenly in all directions. Each node in the graph\nbuilds effective connections to its neighborhood omnidirectionally, whereupon\nwe derive SSG's excellent theoretical properties for both indexed and unindexed\nqueries. We can adaptively adjust the sparsity of an SSG with a hyper-parameter\nto optimize the search performance. Further, NSSG is proposed to reduce the\nindexing complexity of the SSG for large-scale applications. Both theoretical\nand extensive experimental analyses are provided to demonstrate the strengths\nof the proposed approach over the existing representative algorithms. Our code\nhas been released at https://github.com/ZJULearning/SSG.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jul 2019 23:17:19 GMT"}, {"version": "v2", "created": "Mon, 3 Feb 2020 09:05:26 GMT"}, {"version": "v3", "created": "Thu, 18 Mar 2021 06:19:44 GMT"}], "update_date": "2021-03-19", "authors_parsed": [["Fu", "Cong", ""], ["Wang", "Changxu", ""], ["Cai", "Deng", ""]]}, {"id": "1907.06226", "submitter": "Jipeng Qiang", "authors": "Jipeng Qiang and Yun Li and Yi Zhu and Yunhao Yuan and Xindong Wu", "title": "Lexical Simplification with Pretrained Encoders", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lexical simplification (LS) aims to replace complex words in a given sentence\nwith their simpler alternatives of equivalent meaning. Recently unsupervised\nlexical simplification approaches only rely on the complex word itself\nregardless of the given sentence to generate candidate substitutions, which\nwill inevitably produce a large number of spurious candidates. We present a\nsimple LS approach that makes use of the Bidirectional Encoder Representations\nfrom Transformers (BERT) which can consider both the given sentence and the\ncomplex word during generating candidate substitutions for the complex word.\nSpecifically, we mask the complex word of the original sentence for feeding\ninto the BERT to predict the masked token. The predicted results will be used\nas candidate substitutions. Despite being entirely unsupervised, experimental\nresults show that our approach obtains obvious improvement compared with these\nbaselines leveraging linguistic databases and parallel corpus, outperforming\nthe state-of-the-art by more than 12 Accuracy points on three well-known\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jul 2019 14:19:22 GMT"}, {"version": "v2", "created": "Tue, 16 Jul 2019 14:36:41 GMT"}, {"version": "v3", "created": "Tue, 30 Jul 2019 03:36:12 GMT"}, {"version": "v4", "created": "Fri, 16 Aug 2019 01:48:46 GMT"}, {"version": "v5", "created": "Thu, 29 Oct 2020 03:21:25 GMT"}], "update_date": "2020-10-30", "authors_parsed": [["Qiang", "Jipeng", ""], ["Li", "Yun", ""], ["Zhu", "Yi", ""], ["Yuan", "Yunhao", ""], ["Wu", "Xindong", ""]]}, {"id": "1907.06323", "submitter": "Jianxun Lian", "authors": "Zheng Liu, Yu Xing, Jianxun Lian, Defu Lian, Ziyao Li and Xing Xie", "title": "A Novel User Representation Paradigm for Making Personalized Candidate\n  Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Candidate retrieval is a fundamental issue in recommendation system. Given\nuser's recommendation request, relevant candidates need to be retrieved in\nrealtime for subsequent ranking operations. Considering that the retrieval\noperation is conducted over considerable items, it has to be both precise and\nscalable so that high-quality candidates can be acquired within tolerable\nlatency. Unfortunately, conventional methods would trade off precision for high\nrunning efficiency, which leads to inferior retrieval quality. In contrast,\nthose deep learning-based approaches can be highly accurate in identifying\nrelevant items; yet, they are unsuitable for candidate retrieval due to their\ninherent limitation on scalability.\n  In this work, a novel framework is proposed to address the above challenges.\nThe underlying intuition is to rely on a well-trained ranking model for the\nsupervision of an efficient retrieval model, such that it will unify the\nscalability and precision as a whole. We have implemented our conceptual\nframework and made comprehensive evaluation for it, where promising results are\nachieved against representative baselines.\n  Our work is undergoing a anonymous review, and it will soon be released after\nthe notification. If you're also interested in this problem, please feel free\nto contact us.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 03:29:45 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2019 02:47:42 GMT"}], "update_date": "2019-10-22", "authors_parsed": [["Liu", "Zheng", ""], ["Xing", "Yu", ""], ["Lian", "Jianxun", ""], ["Lian", "Defu", ""], ["Li", "Ziyao", ""], ["Xie", "Xing", ""]]}, {"id": "1907.06330", "submitter": "Prateek Verma", "authors": "Prateek Verma, Aliasgar Kutiyanawala, Ke Shen", "title": "Ranking sentences from product description & bullets for better search", "comments": "Accepted at SIGIR eCom'19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Products in an ecommerce catalog contain information-rich fields like\ndescription and bullets that can be useful to extract entities (attributes)\nusing NER based systems. However, these fields are often verbose and contain\nlot of information that is not relevant from a search perspective. Treating\neach sentence within these fields equally can lead to poor full text match and\nintroduce problems in extracting attributes to develop ontologies, semantic\nsearch etc. To address this issue, we describe two methods based on extractive\nsummarization with reinforcement learning by leveraging information in product\ntitles and search click through logs to rank sentences from bullets,\ndescription, etc. Finally, we compare the accuracy of these two models.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 04:48:34 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Verma", "Prateek", ""], ["Kutiyanawala", "Aliasgar", ""], ["Shen", "Ke", ""]]}, {"id": "1907.06388", "submitter": "Behrooz Razeghi", "authors": "Behrooz Razeghi, Taras Stanko, Boris \\v{S}kori\\'c, Slava\n  Voloshynovskiy", "title": "Single-Component Privacy Guarantees in Helper Data Systems and Sparse\n  Coding with Ambiguation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.IR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the privacy of two approaches to (biometric) template\nprotection: Helper Data Systems and Sparse Ternary Coding with Ambiguization.\nIn particular, we focus on a privacy property that is often overlooked, namely\nhow much leakage exists about one specific binary property of one component of\nthe feature vector. This property is e.g. the sign or an indicator that a\nthreshold is exceeded.\n  We provide evidence that both approaches are able to protect such sensitive\nbinary variables, and discuss how system parameters need to be set.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 09:34:49 GMT"}, {"version": "v2", "created": "Tue, 1 Oct 2019 19:15:55 GMT"}], "update_date": "2019-10-03", "authors_parsed": [["Razeghi", "Behrooz", ""], ["Stanko", "Taras", ""], ["\u0160kori\u0107", "Boris", ""], ["Voloshynovskiy", "Slava", ""]]}, {"id": "1907.06412", "submitter": "Harrie Oosterhuis", "authors": "Rolf Jagerman, Harrie Oosterhuis and Maarten de Rijke", "title": "To Model or to Intervene: A Comparison of Counterfactual and Online\n  Learning to Rank from User Interactions", "comments": "SIGIR 2019", "journal-ref": null, "doi": "10.1145/3331184.3331269", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to Rank (LTR) from user interactions is challenging as user feedback\noften contains high levels of bias and noise. At the moment, two methodologies\nfor dealing with bias prevail in the field of LTR: counterfactual methods that\nlearn from historical data and model user behavior to deal with biases; and\nonline methods that perform interventions to deal with bias but use no explicit\nuser models. For practitioners the decision between either methodology is very\nimportant because of its direct impact on end users. Nevertheless, there has\nnever been a direct comparison between these two approaches to unbiased LTR. In\nthis study we provide the first benchmarking of both counterfactual and online\nLTR methods under different experimental conditions. Our results show that the\nchoice between the methodologies is consequential and depends on the presence\nof selection bias, and the degree of position bias and interaction noise. In\nsettings with little bias or noise counterfactual methods can obtain the\nhighest ranking performance; however, in other circumstances their optimization\ncan be detrimental to the user experience. Conversely, online methods are very\nrobust to bias and noise but require control over the displayed rankings. Our\nfindings confirm and contradict existing expectations on the impact of\nmodel-based and intervention-based methods in LTR, and allow practitioners to\nmake an informed decision between the two methodologies.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 10:15:31 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Jagerman", "Rolf", ""], ["Oosterhuis", "Harrie", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1907.06432", "submitter": "Mehdi Ben Lazreg", "authors": "Mehdi Ben Lazreg, Morten Goodwin, Ole-Christoffer Granmo", "title": "A Neural Turing~Machine for Conditional Transition Graph Modeling", "comments": "Submitted to IEEE Transactions on Neural Networks and Learning\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are an essential part of many machine learning problems such as\nanalysis of parse trees, social networks, knowledge graphs, transportation\nsystems, and molecular structures. Applying machine learning in these areas\ntypically involves learning the graph structure and the relationship between\nthe nodes of the graph. However, learning the graph structure is often complex,\nparticularly when the graph is cyclic, and the transitions from one node to\nanother are conditioned such as graphs used to represent a finite state\nmachine. To solve this problem, we propose to extend the memory based Neural\nTuring Machine (NTM) with two novel additions. We allow for transitions between\nnodes to be influenced by information received from external environments, and\nwe let the NTM learn the context of those transitions. We refer to this\nextension as the Conditional Neural Turing Machine (CNTM).\n  We show that the CNTM can infer conditional transition graphs by empirically\nverifiying the model on two data sets: a large set of randomly generated\ngraphs, and a graph modeling the information retrieval process during certain\ncrisis situations. The results show that the CNTM is able to reproduce the\npaths inside the graph with accuracy ranging from 82,12% for 10 nodes graphs to\n65,25% for 100 nodes graphs.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 11:14:17 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Lazreg", "Mehdi Ben", ""], ["Goodwin", "Morten", ""], ["Granmo", "Ole-Christoffer", ""]]}, {"id": "1907.06458", "submitter": "Bla\\v{z} \\v{S}krlj", "authors": "Bla\\v{z} \\v{S}krlj, Andra\\v{z} Repar and Senja Pollak", "title": "RaKUn: Rank-based Keyword extraction via Unsupervised learning and Meta\n  vertex aggregation", "comments": "The final authenticated publication is available online at\n  https://doi.org/10.1007/978-3-030-31372-2_26", "journal-ref": "Statistical Language and Speech Processing 2019 Proceedings", "doi": "10.1007/978-3-030-31372-2_26", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Keyword extraction is used for summarizing the content of a document and\nsupports efficient document retrieval, and is as such an indispensable part of\nmodern text-based systems. We explore how load centrality, a graph-theoretic\nmeasure applied to graphs derived from a given text can be used to efficiently\nidentify and rank keywords. Introducing meta vertices (aggregates of existing\nvertices) and systematic redundancy filters, the proposed method performs on\npar with state-of-the-art for the keyword extraction task on 14 diverse\ndatasets. The proposed method is unsupervised, interpretable and can also be\nused for document visualization.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 12:10:24 GMT"}, {"version": "v2", "created": "Thu, 17 Oct 2019 19:02:55 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 12:13:37 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["\u0160krlj", "Bla\u017e", ""], ["Repar", "Andra\u017e", ""], ["Pollak", "Senja", ""]]}, {"id": "1907.06465", "submitter": "Jim Smith Dr", "authors": "Felix Ritchie and Jim Smith", "title": "Confidentiality and linked data", "comments": "Paper published as part of The National Statistician's Quality\n  Review. London, December 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data providers such as government statistical agencies perform a balancing\nact: maximising information published to inform decision-making and research,\nwhile simultaneously protecting privacy. The emergence of identified\nadministrative datasets with the potential for sharing (and thus linking)\noffers huge potential benefits but significant additional risks. This article\nintroduces the principles and methods of linking data across different sources\nand points in time, focusing on potential areas of risk. We then consider\nconfidentiality risk, focusing in particular on the \"intruder\" problem central\nto the area, and looking at both risks from data producer outputs and from the\nrelease of micro-data for further analysis. Finally, we briefly consider\npotential solutions to micro-data release, both the statistical solutions\nconsidered in other contributed articles and non-statistical solutions.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 12:31:03 GMT"}], "update_date": "2020-08-10", "authors_parsed": [["Ritchie", "Felix", ""], ["Smith", "Jim", ""]]}, {"id": "1907.06484", "submitter": "Zeon Trevor Fernando", "authors": "Zeon Trevor Fernando, Jaspreet Singh, Avishek Anand", "title": "A study on the Interpretability of Neural Retrieval Models using\n  DeepSHAP", "comments": "4 pages; SIGIR 2019 Short Paper", "journal-ref": null, "doi": "10.1145/3331184.3331312", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent trend in IR has been the usage of neural networks to learn retrieval\nmodels for text based adhoc search. While various approaches and architectures\nhave yielded significantly better performance than traditional retrieval models\nsuch as BM25, it is still difficult to understand exactly why a document is\nrelevant to a query. In the ML community several approaches for explaining\ndecisions made by deep neural networks have been proposed -- including DeepSHAP\nwhich modifies the DeepLift algorithm to estimate the relative importance\n(shapley values) of input features for a given decision by comparing the\nactivations in the network for a given image against the activations caused by\na reference input. In image classification, the reference input tends to be a\nplain black image. While DeepSHAP has been well studied for image\nclassification tasks, it remains to be seen how we can adapt it to explain the\noutput of Neural Retrieval Models (NRMs). In particular, what is a good \"black\"\nimage in the context of IR? In this paper we explored various reference input\ndocument construction techniques. Additionally, we compared the explanations\ngenerated by DeepSHAP to LIME (a model agnostic approach) and found that the\nexplanations differ considerably. Our study raises concerns regarding the\nrobustness and accuracy of explanations produced for NRMs. With this paper we\naim to shed light on interesting problems surrounding interpretability in NRMs\nand highlight areas of future work.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 13:09:18 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Fernando", "Zeon Trevor", ""], ["Singh", "Jaspreet", ""], ["Anand", "Avishek", ""]]}, {"id": "1907.06554", "submitter": "Mohammad Aliannejadi", "authors": "Mohammad Aliannejadi and Hamed Zamani and Fabio Crestani and W. Bruce\n  Croft", "title": "Asking Clarifying Questions in Open-Domain Information-Seeking\n  Conversations", "comments": "To appear in SIGIR 2019", "journal-ref": null, "doi": "10.1145/3331184.3331265", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users often fail to formulate their complex information needs in a single\nquery. As a consequence, they may need to scan multiple result pages or\nreformulate their queries, which may be a frustrating experience.\nAlternatively, systems can improve user satisfaction by proactively asking\nquestions of the users to clarify their information needs. Asking clarifying\nquestions is especially important in conversational systems since they can only\nreturn a limited number of (often only one) result(s). In this paper, we\nformulate the task of asking clarifying questions in open-domain\ninformation-seeking conversational systems. To this end, we propose an offline\nevaluation methodology for the task and collect a dataset, called Qulac,\nthrough crowdsourcing. Our dataset is built on top of the TREC Web Track\n2009-2012 data and consists of over 10K question-answer pairs for 198 TREC\ntopics with 762 facets. Our experiments on an oracle model demonstrate that\nasking only one good question leads to over 170% retrieval performance\nimprovement in terms of P@1, which clearly demonstrates the potential impact of\nthe task. We further propose a retrieval framework consisting of three\ncomponents: question retrieval, question selection, and document retrieval. In\nparticular, our question selection model takes into account the original query\nand previous question-answer interactions while selecting the next question.\nOur model significantly outperforms competitive baselines. To foster research\nin this area, we have made Qulac publicly available.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 15:45:37 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Aliannejadi", "Mohammad", ""], ["Zamani", "Hamed", ""], ["Crestani", "Fabio", ""], ["Croft", "W. Bruce", ""]]}, {"id": "1907.06556", "submitter": "Emanuel Laci\\'c", "authors": "Markus Reiter-Haas, Emanuel Lacic, Tomislav Duricic, Valentin\n  Slawicek, Elisabeth Lex", "title": "Should we Embed? A Study on the Online Performance of Utilizing\n  Embeddings for Real-Time Job Recommendations", "comments": "ACM RecSys 2019 Conference, 5 pages, 1 table, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present the findings of an online study, where we explore\nthe impact of utilizing embeddings to recommend job postings under real-time\nconstraints. On the Austrian job platform Studo Jobs, we evaluate two popular\nrecommendation scenarios: (i) providing similar jobs and, (ii) personalizing\nthe job postings that are shown on the homepage. Our results show that for\nrecommending similar jobs, we achieve the best online performance in terms of\nClick-Through Rate when we employ embeddings based on the most recent\ninteraction. To personalize the job postings shown on a user's homepage,\nhowever, combining embeddings based on the frequency and recency with which a\nuser interacts with job postings results in the best online performance.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 15:53:14 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Reiter-Haas", "Markus", ""], ["Lacic", "Emanuel", ""], ["Duricic", "Tomislav", ""], ["Slawicek", "Valentin", ""], ["Lex", "Elisabeth", ""]]}, {"id": "1907.06836", "submitter": "Arash Dargahi Nobari", "authors": "Arash Dargahi Nobari, Mahmood Neshati and Sajad Sotudeh Gharebagh", "title": "Quality-aware skill translation models for expert finding on\n  StackOverflow", "comments": "Published in Information Systems journal, volume 87", "journal-ref": "Information Systems, Volume 87, 2020", "doi": "10.1016/j.is.2019.07.003", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  StackOverflow has become an emerging resource for talent recognition in\nrecent years. While users exploit technical language on StackOverflow,\nrecruiters try to find the relevant candidates for jobs using their own\nterminology. This procedure implies a gap which exists between recruiters and\ncandidates terms. Due to this gap, the state-of-the-art expert finding models\ncannot effectively address the expert finding problem on StackOverflow. We\npropose two translation models to bridge this gap. The first approach is a\nstatistical method and the second is based on word embedding approach.\nUtilizing several translations for a given query during the scoring step, the\nresult of each intermediate query is blended together to obtain the final\nranking. Here, we propose a new approach which takes the quality of documents\ninto account in scoring step. We have made several observations to visualize\nthe effectiveness of the translation approaches and also the quality-aware\nscoring approach. Our experiments indicate the following: First, while\nstatistical and word embedding translation approaches provide different\ntranslations for each query, both can considerably improve the recall. Besides,\nthe quality-aware scoring approach can improve the precision remarkably.\nFinally, our best proposed method can improve the MAP measure up to 46% on\naverage, in comparison with the state-of-the-art expert finding approach.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 04:45:49 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Nobari", "Arash Dargahi", ""], ["Neshati", "Mahmood", ""], ["Gharebagh", "Sajad Sotudeh", ""]]}, {"id": "1907.06853", "submitter": "Wenqi Fan", "authors": "Wenqi Fan, Yao Ma, Dawei Yin, Jianping Wang, Jiliang Tang, Qing Li", "title": "Deep Social Collaborative Filtering", "comments": "Accepted by 13th ACM Conference on Recommender Systems (RecSys 2019,\n  Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are crucial to alleviate the information overload problem\nin online worlds. Most of the modern recommender systems capture users'\npreference towards items via their interactions based on collaborative\nfiltering techniques. In addition to the user-item interactions, social\nnetworks can also provide useful information to understand users' preference as\nsuggested by the social theories such as homophily and influence. Recently,\ndeep neural networks have been utilized for social recommendations, which\nfacilitate both the user-item interactions and the social network information.\nHowever, most of these models cannot take full advantage of the social network\ninformation. They only use information from direct neighbors, but distant\nneighbors can also provide helpful information. Meanwhile, most of these models\ntreat neighbors' information equally without considering the specific\nrecommendations. However, for a specific recommendation case, the information\nrelevant to the specific item would be helpful. Besides, most of these models\ndo not explicitly capture the neighbor's opinions to items for social\nrecommendations, while different opinions could affect the user differently. In\nthis paper, to address the aforementioned challenges, we propose DSCF, a Deep\nSocial Collaborative Filtering framework, which can exploit the social\nrelations with various aspects for recommender systems. Comprehensive\nexperiments on two-real world datasets show the effectiveness of the proposed\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 06:05:29 GMT"}], "update_date": "2019-07-17", "authors_parsed": [["Fan", "Wenqi", ""], ["Ma", "Yao", ""], ["Yin", "Dawei", ""], ["Wang", "Jianping", ""], ["Tang", "Jiliang", ""], ["Li", "Qing", ""]]}, {"id": "1907.06902", "submitter": "Maurizio Ferrari Dacrema", "authors": "Maurizio Ferrari Dacrema, Paolo Cremonesi and Dietmar Jannach", "title": "Are We Really Making Much Progress? A Worrying Analysis of Recent Neural\n  Recommendation Approaches", "comments": "Source code available at:\n  https://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation", "journal-ref": "Proceedings of the 13th ACM Conference on Recommender Systems\n  (RecSys 2019)", "doi": "10.1145/3298689.3347058", "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning techniques have become the method of choice for researchers\nworking on algorithmic aspects of recommender systems. With the strongly\nincreased interest in machine learning in general, it has, as a result, become\ndifficult to keep track of what represents the state-of-the-art at the moment,\ne.g., for top-n recommendation tasks. At the same time, several recent\npublications point out problems in today's research practice in applied machine\nlearning, e.g., in terms of the reproducibility of the results or the choice of\nthe baselines when proposing new models. In this work, we report the results of\na systematic analysis of algorithmic proposals for top-n recommendation tasks.\nSpecifically, we considered 18 algorithms that were presented at top-level\nresearch conferences in the last years. Only 7 of them could be reproduced with\nreasonable effort. For these methods, it however turned out that 6 of them can\noften be outperformed with comparably simple heuristic methods, e.g., based on\nnearest-neighbor or graph-based techniques. The remaining one clearly\noutperformed the baselines but did not consistently outperform a well-tuned\nnon-neural linear ranking method. Overall, our work sheds light on a number of\npotential problems in today's machine learning scholarship and calls for\nimproved scientific practices in this area. Source code of our experiments and\nfull results are available at:\nhttps://github.com/MaurizioFD/RecSys2019_DeepLearning_Evaluation.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 09:11:07 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 09:44:36 GMT"}, {"version": "v3", "created": "Fri, 16 Aug 2019 18:20:03 GMT"}], "update_date": "2019-08-20", "authors_parsed": [["Dacrema", "Maurizio Ferrari", ""], ["Cremonesi", "Paolo", ""], ["Jannach", "Dietmar", ""]]}, {"id": "1907.07253", "submitter": "Mehak Dhaliwal", "authors": "Muskaan, Mehak Preet Dhaliwal and Aaditeshwar Seth", "title": "Fairness and Diversity in the Recommendation and Ranking of\n  Participatory Media Content", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online participatory media platforms that enable one-to-many communication\namong users, see a significant amount of user generated content and\nconsequently face a problem of being able to recommend a subset of this content\nto its users. We address the problem of recommending and ranking this content\nsuch that different viewpoints about a topic get exposure in a fair and diverse\nmanner. We build our model in the context of a voice-based participatory media\nplatform running in rural central India, for low-income and less-literate\ncommunities, that plays audio messages in a ranked list to users over a phone\ncall and allows them to contribute their own messages. In this paper, we\ndescribe our model and evaluate it using call-logs from the platform, to\ncompare the fairness and diversity performance of our model with the manual\neditorial processes currently being followed. Our models are generic and can be\nadapted and applied to other participatory media platforms as well.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 20:37:55 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Muskaan", "", ""], ["Dhaliwal", "Mehak Preet", ""], ["Seth", "Aaditeshwar", ""]]}, {"id": "1907.07260", "submitter": "Harrie Oosterhuis", "authors": "Harrie Oosterhuis, Rolf Jagerman and Maarten de Rijke", "title": "Unbiased Learning to Rank: Counterfactual and Online Approaches", "comments": "Abstract for tutorial appearing at SIGIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This tutorial covers and contrasts the two main methodologies in unbiased\nLearning to Rank (LTR): Counterfactual LTR and Online LTR. There has long been\nan interest in LTR from user interactions, however, this form of implicit\nfeedback is very biased. In recent years, unbiased LTR methods have been\nintroduced to remove the effect of different types of bias caused by\nuser-behavior in search. For instance, a well addressed type of bias is\nposition bias: the rank at which a document is displayed heavily affects the\ninteractions it receives. Counterfactual LTR methods deal with such types of\nbias by learning from historical interactions while correcting for the effect\nof the explicitly modelled biases. Online LTR does not use an explicit user\nmodel, in contrast, it learns through an interactive process where randomized\nresults are displayed to the user. Through randomization the effect of\ndifferent types of bias can be removed from the learning process. Though both\nmethodologies lead to unbiased LTR, their approaches differ considerably,\nfurthermore, so do their theoretical guarantees, empirical results, effects on\nthe user experience during learning, and applicability. Consequently, for\npractitioners the choice between the two is very substantial. By providing an\noverview of both approaches and contrasting them, we aim to provide an\nessential guide to unbiased LTR so as to aid in understanding and choosing\nbetween methodologies.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 21:07:22 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Oosterhuis", "Harrie", ""], ["Jagerman", "Rolf", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1907.07323", "submitter": "L\\'eo Bouscarrat", "authors": "L\\'eo Bouscarrat, Antoine Bonnefoy, Thomas Peel, C\\'ecile Pereira", "title": "STRASS: A Light and Effective Method for Extractive Summarization Based\n  on Sentence Embeddings", "comments": "To appear in 2019 ACL Student Research Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces STRASS: Summarization by TRAnsformation Selection and\nScoring. It is an extractive text summarization method which leverages the\nsemantic information in existing sentence embedding spaces. Our method creates\nan extractive summary by selecting the sentences with the closest embeddings to\nthe document embedding. The model learns a transformation of the document\nembedding to minimize the similarity between the extractive summary and the\nground truth summary. As the transformation is only composed of a dense layer,\nthe training can be done on CPU, therefore, inexpensive. Moreover, inference\ntime is short and linear according to the number of sentences. As a second\ncontribution, we introduce the French CASS dataset, composed of judgments from\nthe French Court of cassation and their corresponding summaries. On this\ndataset, our results show that our method performs similarly to the state of\nthe art extractive methods with effective training and inferring time.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jul 2019 16:14:09 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Bouscarrat", "L\u00e9o", ""], ["Bonnefoy", "Antoine", ""], ["Peel", "Thomas", ""], ["Pereira", "C\u00e9cile", ""]]}, {"id": "1907.07366", "submitter": "Yen Hao Huang", "authors": "Yen-Hao Huang, Yi-Hsin Chen, Fernando Henrique Calderon Alvarado,\n  Ssu-Rui Lee, Shu-I Wu, Yuwen Lai and Yi-Shin Chen", "title": "Leveraging Linguistic Characteristics for Bipolar Disorder Recognition\n  with Gender Differences", "comments": "Accepted by DSHealth '19: 2019 KDD Workshop on Applied Data Science\n  for Healthcare", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most previous studies on automatic recognition model for bipolar disorder\n(BD) were based on both social media and linguistic features. The present study\ninvestigates the possibility of adopting only language-based features, namely\nthe syntax and morpheme collocation. We also examine the effect of gender on\nthe results considering gender has long been recognized as an important\nmodulating factor for mental disorders, yet it received little attention in\nprevious linguistic models. The present study collects Twitter posts 3 months\nprior to the self-disclosure by 349 BD users (231 female, 118 male). We\nconstruct a set of syntactic patterns in terms of the word usage based on graph\npattern construction and pattern attention mechanism. The factors examined are\ngender differences, syntactic patterns, and bipolar recognition performance.\nThe performance indicates our F1 scores reach over 91% and outperform several\nbaselines, including those using TF-IDF, LIWC and pre-trained language models\n(ELMO and BERT). The contributions of the present study are: (1) The features\nare contextualized, domain-agnostic, and purely linguistic. (2) The performance\nof BD recognition is improved by gender-enriched linguistic pattern features,\nwhich are constructed with gender differences in language usage.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 07:37:13 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Huang", "Yen-Hao", ""], ["Chen", "Yi-Hsin", ""], ["Alvarado", "Fernando Henrique Calderon", ""], ["Lee", "Ssu-Rui", ""], ["Wu", "Shu-I", ""], ["Lai", "Yuwen", ""], ["Chen", "Yi-Shin", ""]]}, {"id": "1907.07387", "submitter": "Martin Aum\\\"uller", "authors": "Martin Aum\\\"uller and Matteo Ceccarello", "title": "The Role of Local Intrinsic Dimensionality in Benchmarking Nearest\n  Neighbor Search", "comments": "Preprint of the paper accepted at SISAP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reconsiders common benchmarking approaches to nearest neighbor\nsearch. It is shown that the concept of local intrinsic dimensionality (LID)\nallows to choose query sets of a wide range of difficulty for real-world\ndatasets. Moreover, the effect of different LID distributions on the running\ntime performance of implementations is empirically studied. To this end,\ndifferent visualization concepts are introduced that allow to get a more\nfine-grained overview of the inner workings of nearest neighbor search\nprinciples. The paper closes with remarks about the diversity of datasets\ncommonly used for nearest neighbor search benchmarking. It is shown that such\nreal-world datasets are not diverse: results on a single dataset predict\nresults on all other datasets well.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 08:39:53 GMT"}], "update_date": "2019-07-18", "authors_parsed": [["Aum\u00fcller", "Martin", ""], ["Ceccarello", "Matteo", ""]]}, {"id": "1907.07410", "submitter": "P B Mr", "authors": "Prasad Bhavana, Vikas Kumar, Vineet Padmanabhan", "title": "Block based Singular Value Decomposition approach to matrix\n  factorization for recommender systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the abundance of data in recent years, interesting challenges are posed\nin the area of recommender systems. Producing high quality recommendations with\nscalability and performance is the need of the hour. Singular Value\nDecomposition(SVD) based recommendation algorithms have been leveraged to\nproduce better results. In this paper, we extend the SVD technique further for\nscalability and performance in the context of 1) multi-threading 2) multiple\ncomputational units (with the use of Graphical Processing Units) and 3)\ndistributed computation. We propose block based matrix factorization (BMF)\npaired with SVD. This enabled us to take advantage of SVD over basic matrix\nfactorization(MF) while taking advantage of parallelism and scalability through\nBMF. We used Compute Unified Device Architecture (CUDA) platform and related\nhardware for leveraging Graphical Processing Unit (GPU) along with block based\nSVD to demonstrate the advantages in terms of performance and memory.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 09:35:56 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Bhavana", "Prasad", ""], ["Kumar", "Vikas", ""], ["Padmanabhan", "Vineet", ""]]}, {"id": "1907.07604", "submitter": "Lanyu Shang", "authors": "Lanyu Shang, Daniel Zhang, Michael Wang, Shuyue Lai, Dong Wang", "title": "Towards Reliable Online Clickbait Video Detection: A Content-Agnostic\n  Approach", "comments": "Accepted by Knowledge-Based Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online video sharing platforms (e.g., YouTube, Vimeo) have become an\nincreasingly popular paradigm for people to consume video contents. Clickbait\nvideo, whose content clearly deviates from its title/thumbnail, has emerged as\na critical problem on online video sharing platforms. Current clickbait\ndetection solutions that mainly focus on analyzing the text of the title, the\nimage of the thumbnail, or the content of the video are shown to be suboptimal\nin detecting the online clickbait videos. In this paper, we develop a novel\ncontent-agnostic scheme, Online Video Clickbait Protector (OVCP), to\neffectively detect clickbait videos by exploring the comments from the audience\nwho watched the video. Different from existing solutions, OVCP does not\ndirectly analyze the content of the video and its pre-click information (e.g.,\ntitle and thumbnail). Therefore, it is robust against sophisticated content\ncreators who often generate clickbait videos that can bypass the current\nclickbait detectors. We evaluate OVCP with a real-world dataset collected from\nYouTube. Experimental results demonstrate that OVCP is effective in identifying\nclickbait videos and significantly outperforms both state-of-the-art baseline\nmodels and human annotators.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 16:06:39 GMT"}, {"version": "v2", "created": "Thu, 18 Jul 2019 12:52:37 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Shang", "Lanyu", ""], ["Zhang", "Daniel", ""], ["Wang", "Michael", ""], ["Lai", "Shuyue", ""], ["Wang", "Dong", ""]]}, {"id": "1907.07629", "submitter": "Gabriel de Souza Pereira Moreira", "authors": "Gabriel de Souza P. Moreira, Dietmar Jannach, Adilson Marques da Cunha", "title": "On the Importance of News Content Representation in Hybrid Neural\n  Session-based Recommender Systems", "comments": "Short paper. In 7th International Workshop on News Recommendation and\n  Analytics (INRA 2019), in conjunction with RecSys 2019, September 19, 2019,\n  Copenhagen, Denmark. arXiv admin note: text overlap with arXiv:1904.10367", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  News recommender systems are designed to surface relevant information for\nonline readers by personalizing their user experiences. A particular problem in\nthat context is that online readers are often anonymous, which means that this\npersonalization can only be based on the last few recorded interactions with\nthe user, a setting named session-based recommendation. Another particularity\nof the news domain is that constantly fresh articles are published, which\nshould be immediately considered for recommendation. To deal with this item\ncold-start problem, it is important to consider the actual content of items\nwhen recommending. Hybrid approaches are therefore often considered as the\nmethod of choice in such settings. In this work, we analyze the importance of\nconsidering content information in a hybrid neural news recommender system. We\ncontrast content-aware and content-agnostic techniques and also explore the\neffects of using different content encodings. Experiments on two public\ndatasets confirm the importance of adopting a hybrid approach. Furthermore, we\nshow that the choice of the content encoding can have an impact on the\nresulting performance.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 15:27:53 GMT"}, {"version": "v2", "created": "Mon, 19 Aug 2019 13:26:53 GMT"}, {"version": "v3", "created": "Fri, 6 Sep 2019 11:29:18 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Moreira", "Gabriel de Souza P.", ""], ["Jannach", "Dietmar", ""], ["da Cunha", "Adilson Marques", ""]]}, {"id": "1907.07672", "submitter": "Shahin Atakishiyev", "authors": "Shahin Atakishiyev, Marek Z. Reformat", "title": "Analysis of Word Embeddings Using Fuzzy Clustering", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data dominated systems and applications, a concept of representing words\nin a numerical format has gained a lot of attention. There are a few approaches\nused to generate such a representation. An interesting issue that should be\nconsidered is the ability of such representations - called embeddings - to\nimitate human-based semantic similarity between words. In this study, we\nperform a fuzzy-based analysis of vector representations of words, i.e., word\nembeddings. We use two popular fuzzy clustering algorithms on count-based word\nembeddings, known as GloVe, of different dimensionality. Words from\nWordSim-353, called the gold standard, are represented as vectors and\nclustered. The results indicate that fuzzy clustering algorithms are very\nsensitive to high-dimensional data, and parameter tuning can dramatically\nchange their performance. We show that by adjusting the value of the fuzzifier\nparameter, fuzzy clustering can be successfully applied to vectors of high - up\nto one hundred - dimensions. Additionally, we illustrate that fuzzy clustering\nallows to provide interesting results regarding membership of words to\ndifferent clusters.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 23:40:46 GMT"}, {"version": "v2", "created": "Sat, 20 Jul 2019 07:48:52 GMT"}, {"version": "v3", "created": "Mon, 7 Dec 2020 07:56:30 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Atakishiyev", "Shahin", ""], ["Reformat", "Marek Z.", ""]]}, {"id": "1907.07766", "submitter": "Masoud Mansoury", "authors": "Masoud Mansoury, Robin Burke, Bamshad Mobasher", "title": "Flatter is better: Percentile Transformations for Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that explicit user ratings in recommender systems are biased\ntowards high ratings, and that users differ significantly in their usage of the\nrating scale. Implementers usually compensate for these issues through rating\nnormalization or the inclusion of a user bias term in factorization models.\nHowever, these methods adjust only for the central tendency of users'\ndistributions. In this work, we demonstrate that lack of \\textit{flatness} in\nrating distributions is negatively correlated with recommendation performance.\nWe propose a rating transformation model that compensates for skew in the\nrating distribution as well as its central tendency by converting ratings into\npercentile values as a pre-processing step before recommendation generation.\nThis transformation flattens the rating distribution, better compensates for\ndifferences in rating distributions, and improves recommendation performance.\nWe also show a smoothed version of this transformation designed to yield more\nintuitive results for users with very narrow rating distributions. A\ncomprehensive set of experiments show improved ranking performance for these\npercentile transformations with state-of-the-art recommendation algorithms in\nfour real-world data sets.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 21:12:18 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Mansoury", "Masoud", ""], ["Burke", "Robin", ""], ["Mobasher", "Bamshad", ""]]}, {"id": "1907.07768", "submitter": "Avishek Bose", "authors": "Avishek Bose, Vahid Behzadan, Carlos Aguirre, William H. Hsu", "title": "A Novel Approach for Detection and Ranking of Trendy and Emerging Cyber\n  Threat Events in Twitter Streams", "comments": "9 pages, 3 figures, and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new machine learning and text information extraction approach to\ndetection of cyber threat events in Twitter that are novel (previously\nnon-extant) and developing (marked by significance with respect to similarity\nwith a previously detected event). While some existing approaches to event\ndetection measure novelty and trendiness, typically as independent criteria and\noccasionally as a holistic measure, this work focuses on detecting both novel\nand developing events using an unsupervised machine learning approach.\nFurthermore, our proposed approach enables the ranking of cyber threat events\nbased on an importance score by extracting the tweet terms that are\ncharacterized as named entities, keywords, or both. We also impute influence to\nusers in order to assign a weighted score to noun phrases in proportion to user\ninfluence and the corresponding event scores for named entities and keywords.\nTo evaluate the performance of our proposed approach, we measure the efficiency\nand detection error rate for events over a specified time interval, relative to\nhuman annotator ground truth.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jul 2019 22:17:17 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Bose", "Avishek", ""], ["Behzadan", "Vahid", ""], ["Aguirre", "Carlos", ""], ["Hsu", "William H.", ""]]}, {"id": "1907.07818", "submitter": "Manash Pratim Barman", "authors": "Manash Pratim Barman, Amit Awekar, Sambhav Kothari", "title": "Decoding the Style and Bias of Song Lyrics", "comments": "Accepted for ACM SIGIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The central idea of this paper is to gain a deeper understanding of song\nlyrics computationally. We focus on two aspects: style and biases of song\nlyrics. All prior works to understand these two aspects are limited to manual\nanalysis of a small corpus of song lyrics. In contrast, we analyzed more than\nhalf a million songs spread over five decades. We characterize the lyrics style\nin terms of vocabulary, length, repetitiveness, speed, and readability. We have\nobserved that the style of popular songs significantly differs from other\nsongs. We have used distributed representation methods and WEAT test to measure\nvarious gender and racial biases in the song lyrics. We have observed that\nbiases in song lyrics correlate with prior results on human subjects. This\ncorrelation indicates that song lyrics reflect the biases that exist in\nsociety. Increasing consumption of music and the effect of lyrics on human\nemotions makes this analysis important.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 23:57:46 GMT"}], "update_date": "2019-07-19", "authors_parsed": [["Barman", "Manash Pratim", ""], ["Awekar", "Amit", ""], ["Kothari", "Sambhav", ""]]}, {"id": "1907.07972", "submitter": "Zulfat Miftahutdinov", "authors": "Zulfat Miftahutdinov and Elena Tutubalina", "title": "Deep Neural Models for Medical Concept Normalization in User-Generated\n  Texts", "comments": "This is preprint of the paper \"Deep Neural Models for Medical Concept\n  Normalization in User-Generated Texts\" to be published at ACL 2019 - 57th\n  Annual Meeting of the Association for Computational Linguistics, Proceedings\n  of the Student Research Workshop", "journal-ref": null, "doi": "10.18653/v1/P19-2055", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the medical concept normalization problem, i.e.,\nthe problem of mapping a health-related entity mention in a free-form text to a\nconcept in a controlled vocabulary, usually to the standard thesaurus in the\nUnified Medical Language System (UMLS). This is a challenging task since\nmedical terminology is very different when coming from health care\nprofessionals or from the general public in the form of social media texts. We\napproach it as a sequence learning problem with powerful neural networks such\nas recurrent neural networks and contextualized word representation models\ntrained to obtain semantic representations of social media expressions. Our\nexperimental evaluation over three different benchmarks shows that neural\narchitectures leverage the semantic meaning of the entity mention and\nsignificantly outperform an existing state of the art models.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 10:36:03 GMT"}], "update_date": "2019-12-17", "authors_parsed": [["Miftahutdinov", "Zulfat", ""], ["Tutubalina", "Elena", ""]]}, {"id": "1907.08346", "submitter": "Kojiro Iizuka", "authors": "Kojiro Iizuka, Takeshi Yoneda, Yoshifumi Seki", "title": "Greedy Optimized Multileaving for Personalization", "comments": "RecSys 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization plays an important role in many services. To evaluate\npersonalized rankings, online evaluation, such as A/B testing, is widely used\ntoday. Recently, multileaving has been found to be an efficient method for\nevaluating rankings in information retrieval fields. This paper describes the\nfirst attempt to optimize the multileaving method for personalization settings.\nWe clarify the challenges of applying this method to personalized rankings.\nThen, to solve these challenges, we propose greedy optimized multileaving (GOM)\nwith a new credit feedback function. The empirical results showed that GOM was\nstable for increasing ranking lengths and the number of rankers. We implemented\nGOM on our actual news recommender systems, and compared its online\nperformance. The results showed that GOM evaluated the personalized rankings\nprecisely, with significantly smaller sample sizes (< 1/10) than A/B testing.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 02:29:38 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Iizuka", "Kojiro", ""], ["Yoneda", "Takeshi", ""], ["Seki", "Yoshifumi", ""]]}, {"id": "1907.08400", "submitter": "Matteo Manica", "authors": "Matteo Manica, Christoph Auer, Valery Weber, Federico Zipoli, Michele\n  Dolfi, Peter Staar, Teodoro Laino, Costas Bekas, Akihiro Fujita, Hiroki Toda,\n  Shuichi Hirose, Yasumitsu Orii", "title": "An Information Extraction and Knowledge Graph Platform for Accelerating\n  Biochemical Discoveries", "comments": "4 pages, 1 figure, Workshop on Applied Data Science for Healthcare at\n  KDD, Anchorage, AK, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information extraction and data mining in biochemical literature is a\ndaunting task that demands resource-intensive computation and appropriate means\nto scale knowledge ingestion. Being able to leverage this immense source of\ntechnical information helps to drastically reduce costs and time to solution in\nmultiple application fields from food safety to pharmaceutics. We present a\nscalable document ingestion system that integrates data from databases and\npublications (in PDF format) in a biochemistry knowledge graph (BCKG). The BCKG\nis a comprehensive source of knowledge that can be queried to retrieve known\nbiochemical facts and to generate novel insights. After describing the\nknowledge ingestion framework, we showcase an application of our system in the\nfield of carbohydrate enzymes. The BCKG represents a way to scale knowledge\ningestion and automatically exploit prior knowledge to accelerate discovery in\nbiochemical sciences.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 08:17:30 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Manica", "Matteo", ""], ["Auer", "Christoph", ""], ["Weber", "Valery", ""], ["Zipoli", "Federico", ""], ["Dolfi", "Michele", ""], ["Staar", "Peter", ""], ["Laino", "Teodoro", ""], ["Bekas", "Costas", ""], ["Fujita", "Akihiro", ""], ["Toda", "Hiroki", ""], ["Hirose", "Shuichi", ""], ["Orii", "Yasumitsu", ""]]}, {"id": "1907.08440", "submitter": "Vijaikumar M", "authors": "Vijaikumar M and Shirish Shevade and M N Murty", "title": "Neural Cross-Domain Collaborative Filtering with Shared Entities", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-Domain Collaborative Filtering (CDCF) provides a way to alleviate data\nsparsity and cold-start problems present in recommendation systems by\nexploiting the knowledge from related domains. Existing CDCF models are either\nbased on matrix factorization or deep neural networks. Either of the techniques\nin isolation may result in suboptimal performance for the prediction task.\nAlso, most of the existing models face challenges particularly in handling\ndiversity between domains and learning complex non-linear relationships that\nexist amongst entities (users/items) within and across domains. In this work,\nwe propose an end-to-end neural network model -- NeuCDCF, to address these\nchallenges in a cross-domain setting. More importantly, NeuCDCF follows a wide\nand deep framework and it learns the representations combinedly from both\nmatrix factorization and deep neural networks. We perform experiments on four\nreal-world datasets and demonstrate that our model performs better than\nstate-of-the-art CDCF models.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 10:04:28 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["M", "Vijaikumar", ""], ["Shevade", "Shirish", ""], ["Murty", "M N", ""]]}, {"id": "1907.08501", "submitter": "Gerhard Wohlgenannt Dr.", "authors": "Gerhard Wohlgenannt, Dmitry Mouromtsev, Dmitry Pavlov, Yury Emelyanov\n  and Alexey Morozov", "title": "A Comparative Evaluation of Visual and Natural Language Question\n  Answering Over Linked Data", "comments": "KEOD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the growing number and size of Linked Data datasets, it is crucial to\nmake the data accessible and useful for users without knowledge of formal query\nlanguages. Two approaches towards this goal are knowledge graph visualization\nand natural language interfaces. Here, we investigate specifically question\nanswering (QA) over Linked Data by comparing a diagrammatic visual approach\nwith existing natural language-based systems. Given a QA benchmark (QALD7), we\nevaluate a visual method which is based on iteratively creating diagrams until\nthe answer is found, against four QA systems that have natural language queries\nas input. Besides other benefits, the visual approach provides higher\nperformance, but also requires more manual input. The results indicate that the\nmethods can be used complementary, and that such a combination has a large\npositive impact on QA performance, and also facilitates additional features\nsuch as data exploration.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 13:09:32 GMT"}], "update_date": "2019-07-22", "authors_parsed": [["Wohlgenannt", "Gerhard", ""], ["Mouromtsev", "Dmitry", ""], ["Pavlov", "Dmitry", ""], ["Emelyanov", "Yury", ""], ["Morozov", "Alexey", ""]]}, {"id": "1907.08657", "submitter": "Dany Haddad", "authors": "Dany Haddad and Joydeep Ghosh", "title": "Learning More From Less: Towards Strengthening Weak Supervision for\n  Ad-Hoc Retrieval", "comments": "SIGIR 2019", "journal-ref": null, "doi": "10.1145/3331184.3331272", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The limited availability of ground truth relevance labels has been a major\nimpediment to the application of supervised methods to ad-hoc retrieval. As a\nresult, unsupervised scoring methods, such as BM25, remain strong competitors\nto deep learning techniques which have brought on dramatic improvements in\nother domains, such as computer vision and natural language processing. Recent\nworks have shown that it is possible to take advantage of the performance of\nthese unsupervised methods to generate training data for learning-to-rank\nmodels. The key limitation to this line of work is the size of the training set\nrequired to surpass the performance of the original unsupervised method, which\ncan be as large as $10^{13}$ training examples. Building on these insights, we\npropose two methods to reduce the amount of training data required. The first\nmethod takes inspiration from crowdsourcing, and leverages multiple\nunsupervised rankers to generate soft, or noise-aware, training labels. The\nsecond identifies harmful, or mislabeled, training examples and removes them\nfrom the training set. We show that our methods allow us to surpass the\nperformance of the unsupervised baseline with far fewer training examples than\nprevious works.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 19:27:14 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Haddad", "Dany", ""], ["Ghosh", "Joydeep", ""]]}, {"id": "1907.08667", "submitter": "Katsiaryna Mirylenka", "authors": "Thomas Gschwind, Christoph Miksovic, Julian Minder, Katsiaryna\n  Mirylenka, Paolo Scotton", "title": "Fast Record Linkage for Company Entities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Record linkage is an essential part of nearly all real-world systems that\nconsume structured and unstructured data coming from different sources.\nTypically no common key is available for connecting records. Massive data\ncleaning and data integration processes often have to be completed before any\ndata analytics and further processing can be performed. Although record linkage\nis frequently regarded as a somewhat tedious but necessary step, it reveals\nvaluable insights into the data at hand. These insights guide further analytic\napproaches to the data and support data visualization.\n  In this work we focus on company entity matching, where company name,\nlocation and industry are taken into account. Our contribution is an\nend-to-end, highly scalable, enterprise-grade system that uses rule-based\nlinkage algorithms extended with a machine learning approach to account for\nshort company names. Linkage time is greatly reduced by efficient decomposition\nof the search space using MinHash. High linkage accuracy is achieved by the\nproposed thorough scoring process of the matching candidates.\n  Based on real-world ground truth datasets, we show that our approach reaches\na recall of 91% compared to 73% for baseline approaches. These results are\nachieved while scaling linearly with the number of nodes used in the system.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 20:00:41 GMT"}, {"version": "v2", "created": "Fri, 23 Aug 2019 12:29:37 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 15:22:35 GMT"}], "update_date": "2019-09-30", "authors_parsed": [["Gschwind", "Thomas", ""], ["Miksovic", "Christoph", ""], ["Minder", "Julian", ""], ["Mirylenka", "Katsiaryna", ""], ["Scotton", "Paolo", ""]]}, {"id": "1907.08671", "submitter": "Michael F\\\"arber", "authors": "Michael F\\\"arber", "title": "Linked Crunchbase: A Linked Data API and RDF Data Set About Innovative\n  Companies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Crunchbase is an online platform collecting information about startups and\ntechnology companies, including attributes and relations of companies, people,\nand investments. Data contained in Crunchbase is, to a large extent, not\navailable elsewhere, making Crunchbase to a unique data source. In this paper,\nwe present how to bring Crunchbase to the Web of Data so that its data can be\nused in the machine-readable RDF format by anyone on the Web. First, we give\ninsights into how we developed and hosted a Linked Data API for Crunchbase and\nhow sameAs links to other data sources are integrated. Then, we present our\nmethod for crawling RDF data based on this API to build a custom Crunchbase RDF\nknowledge graph. We created an RDF data set with over 347 million triples,\nincluding 781k people, 659k organizations, and 343k investments. Our Crunchbase\nLinked Data API is available online at http://linked-crunchbase.org.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 20:08:47 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["F\u00e4rber", "Michael", ""]]}, {"id": "1907.08674", "submitter": "Kiran Rama", "authors": "Kiran Rama, Pradeep Kumar, Bharat Bhasker", "title": "Deep Learning to Address Candidate Generation and Cold Start Challenges\n  in Recommender Systems: A Research Survey", "comments": "22 pages, Submitted and Presented at PAN IIM Conference in IIM\n  Bangalore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among the machine learning applications to business, recommender systems\nwould take one of the top places when it comes to success and adoption. They\nhelp the user in accelerating the process of search while helping businesses\nmaximize sales. Post phenomenal success in computer vision and speech\nrecognition, deep learning methods are beginning to get applied to recommender\nsystems. Current survey papers on deep learning in recommender systems provide\na historical overview and taxonomy of recommender systems based on type. Our\npaper addresses the gaps of providing a taxonomy of deep learning approaches to\naddress recommender systems problems in the areas of cold start and candidate\ngeneration in recommender systems. We outline different challenges in\nrecommender systems into those related to the recommendations themselves\n(include relevance, speed, accuracy and scalability), those related to the\nnature of the data (cold start problem, imbalance and sparsity) and candidate\ngeneration. We then provide a taxonomy of deep learning techniques to address\nthese challenges. Deep learning techniques are mapped to the different\nchallenges in recommender systems providing an overview of how deep learning\ntechniques can be used to address them. We contribute a taxonomy of deep\nlearning techniques to address the cold start and candidate generation problems\nin recommender systems. Cold Start is addressed through additional features\n(for audio, images, text) and by learning hidden user and item representations.\nCandidate generation has been addressed by separate networks, RNNs,\nautoencoders and hybrid methods. We also summarize the advantages and\nlimitations of these techniques while outlining areas for future research.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 06:22:38 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Rama", "Kiran", ""], ["Kumar", "Pradeep", ""], ["Bhasker", "Bharat", ""]]}, {"id": "1907.08679", "submitter": "Zitao Liu", "authors": "Tianqiao Liu, Zhiwei Wang, Jiliang Tang, Songfan Yang, Gale Yan Huang,\n  Zitao Liu", "title": "Recommender Systems with Heterogeneous Side Information", "comments": null, "journal-ref": "Proceedings of the 2019 World Wide Web Conference", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern recommender systems, both users and items are associated with rich\nside information, which can help understand users and items. Such information\nis typically heterogeneous and can be roughly categorized into flat and\nhierarchical side information. While side information has been proved to be\nvaluable, the majority of existing systems have exploited either only flat side\ninformation or only hierarchical side information due to the challenges brought\nby the heterogeneity. In this paper, we investigate the problem of exploiting\nheterogeneous side information for recommendations. Specifically, we propose a\nnovel framework jointly captures flat and hierarchical side information with\nmathematical coherence. We demonstrate the effectiveness of the proposed\nframework via extensive experiments on various real-world datasets. Empirical\nresults show that our approach is able to lead a significant performance gain\nover the state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 03:20:21 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Liu", "Tianqiao", ""], ["Wang", "Zhiwei", ""], ["Tang", "Jiliang", ""], ["Yang", "Songfan", ""], ["Huang", "Gale Yan", ""], ["Liu", "Zitao", ""]]}, {"id": "1907.08686", "submitter": "Zhipeng Li", "authors": "Zhipeng Li, Jianwei Wu, Lin Sun, Tao Rong", "title": "Combinatorial Keyword Recommendations for Sponsored Search with Deep\n  Reinforcement Learning", "comments": "6 pages, adKDD 2019", "journal-ref": "In Proceedings of 2019 AdKDD, Anchorage, Alaska, USA, August,\n  2019, 6 pages", "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sponsored search, keyword recommendations help advertisers to achieve much\nbetter performance within limited budget. Many works have been done to mine\nnumerous candidate keywords from search logs or landing pages. However, the\nstrategy to select from given candidates remains to be improved. The existing\nrelevance-based, popularity-based and regular combinatorial strategies fail to\ntake the internal or external competitions among keywords into consideration.\nIn this paper, we regard keyword recommendations as a combinatorial\noptimization problem and solve it with a modified pointer network structure.\nThe model is trained on an actor-critic based deep reinforcement learning\nframework. A pre-clustering method called Equal Size K-Means is proposed to\naccelerate the training and testing procedure on the framework by reducing the\naction space. The performance of framework is evaluated both in offline and\nonline environments, and remarkable improvements can be observed.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 13:29:04 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Li", "Zhipeng", ""], ["Wu", "Jianwei", ""], ["Sun", "Lin", ""], ["Rong", "Tao", ""]]}, {"id": "1907.08687", "submitter": "Douglas Turnbull", "authors": "Daniel Akimchuk and Timothy Clerico and Douglas Turnbull", "title": "Evaluating Recommender System Algorithms for Generating Local Music\n  Playlists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We explore the task of local music recommendation: provide listeners with\npersonalized playlists of relevant tracks by artists who play most of their\nlive events within a small geographic area. Most local artists tend to be\nobscure, long-tail artists and generally have little or no available user\npreference data associated with them. This creates a cold-start problem for\ncollaborative filtering-based recommendation algorithms that depend on large\namounts of such information to make accurate recommendations. In this paper, we\ncompare the performance of three standard recommender system algorithms\n(Item-Item Neighborhood (IIN), Alternating Least Squares for Implicit Feedback\n(ALS), and Bayesian Personalized Ranking (BPR)) on the task of local music\nrecommendation using the Million Playlist Dataset. To do this, we modify the\nstandard evaluation procedure such that the algorithms only rank tracks by\nlocal artists for each of the eight different cities. Despite the fact that\ntechniques based on matrix factorization (ALS, BPR) typically perform best on\nlarge recommendation tasks, we find that the neighborhood-based approach (IIN)\nperforms best for long-tail local music recommendation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jul 2019 17:20:33 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Akimchuk", "Daniel", ""], ["Clerico", "Timothy", ""], ["Turnbull", "Douglas", ""]]}, {"id": "1907.08696", "submitter": "Zhongkai Sun", "authors": "Zhongkai Sun, Prathusha K Sarma, William Sethares, Erik P. Bucy", "title": "Multi-modal Sentiment Analysis using Deep Canonical Correlation Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper learns multi-modal embeddings from text, audio, and video\nviews/modes of data in order to improve upon down-stream sentiment\nclassification. The experimental framework also allows investigation of the\nrelative contributions of the individual views in the final multi-modal\nembedding. Individual features derived from the three views are combined into a\nmulti-modal embedding using Deep Canonical Correlation Analysis (DCCA) in two\nways i) One-Step DCCA and ii) Two-Step DCCA. This paper learns text embeddings\nusing BERT, the current state-of-the-art in text encoders. We posit that this\nhighly optimized algorithm dominates over the contribution of other views,\nthough each view does contribute to the final result. Classification tasks are\ncarried out on two benchmark datasets and on a new Debate Emotion data set, and\ntogether these demonstrate that the one-Step DCCA outperforms the current\nstate-of-the-art in learning multi-modal embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jul 2019 21:48:28 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Sun", "Zhongkai", ""], ["Sarma", "Prathusha K", ""], ["Sethares", "William", ""], ["Bucy", "Erik P.", ""]]}, {"id": "1907.08698", "submitter": "Romain Hennequin", "authors": "Elena V. Epure, Anis Khlif, Romain Hennequin", "title": "Leveraging Knowledge Bases And Parallel Annotations For Music Genre\n  Translation", "comments": "Published in ISMIR 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Prevalent efforts have been put in automatically inferring genres of musical\nitems. Yet, the propose solutions often rely on simplifications and fail to\naddress the diversity and subjectivity of music genres. Accounting for these\nhas, though, many benefits for aligning knowledge sources, integrating data and\nenriching musical items with tags. Here, we choose a new angle for the genre\nstudy by seeking to predict what would be the genres of musical items in a\ntarget tag system, knowing the genres assigned to them within source tag\nsystems. We call this a translation task and identify three cases: 1) no common\nannotated corpus between source and target tag systems exists, 2) such a large\ncorpus exists, 3) only few common annotations exist. We propose the related\nsolutions: a knowledge-based translation modeled as taxonomy mapping, a\nstatistical translation modeled with maximum likelihood logistic regression; a\nhybrid translation modeled with maximum a posteriori logistic regression with\npriors given by the knowledge-based translation. During evaluation, the\nsolutions fit well the identified cases and the hybrid translation is\nsystematically the most effective w.r.t. multilabel classification metrics.\nThis is a first attempt to unify genre tag systems by leveraging both\nrepresentation and interpretation diversity.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jul 2019 15:23:15 GMT"}, {"version": "v2", "created": "Sat, 27 Jul 2019 20:31:33 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Epure", "Elena V.", ""], ["Khlif", "Anis", ""], ["Hennequin", "Romain", ""]]}, {"id": "1907.08873", "submitter": "Emiliano De Cristofaro", "authors": "Despoina Chatzakou, Ilias Leontiadis, Jeremy Blackburn, Emiliano De\n  Cristofaro, Gianluca Stringhini, Athena Vakali, and Nicolas Kourtellis", "title": "Detecting Cyberbullying and Cyberaggression in Social Media", "comments": "To appear in ACM Transactions on the Web (TWEB)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyberbullying and cyberaggression are increasingly worrisome phenomena\naffecting people across all demographics. More than half of young social media\nusers worldwide have been exposed to such prolonged and/or coordinated digital\nharassment. Victims can experience a wide range of emotions, with negative\nconsequences such as embarrassment, depression, isolation from other community\nmembers, which embed the risk to lead to even more critical consequences, such\nas suicide attempts.\n  In this work, we take the first concrete steps to understand the\ncharacteristics of abusive behavior in Twitter, one of today's largest social\nmedia platforms. We analyze 1.2 million users and 2.1 million tweets, comparing\nusers participating in discussions around seemingly normal topics like the NBA,\nto those more likely to be hate-related, such as the Gamergate controversy, or\nthe gender pay inequality at the BBC station. We also explore specific\nmanifestations of abusive behavior, i.e., cyberbullying and cyberaggression, in\none of the hate-related communities (Gamergate). We present a robust\nmethodology to distinguish bullies and aggressors from normal Twitter users by\nconsidering text, user, and network-based attributes. Using various\nstate-of-the-art machine learning algorithms, we classify these accounts with\nover 90% accuracy and AUC. Finally, we discuss the current status of Twitter\nuser accounts marked as abusive by our methodology, and study the performance\nof potential mechanisms that can be used by Twitter to suspend users in the\nfuture.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 22:24:44 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Chatzakou", "Despoina", ""], ["Leontiadis", "Ilias", ""], ["Blackburn", "Jeremy", ""], ["De Cristofaro", "Emiliano", ""], ["Stringhini", "Gianluca", ""], ["Vakali", "Athena", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "1907.09007", "submitter": "Issa Annamoradnejad", "authors": "Issa Annamoradnejad, Jafar Habibi", "title": "A Comprehensive Analysis of Twitter Trending Topics", "comments": "6 pages, 8 figures, 3 tables, conference paper", "journal-ref": "2019 5th International Conference on Web Research (ICWR), Tehran,\n  Iran, 2019, pp. 22-27", "doi": "10.1109/ICWR.2019.8765252", "report-no": null, "categories": "cs.SI cs.CL cs.IR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Twitter, a name, phrase, or topic that is mentioned at a greater rate than\nothers is called a \"trending topic\" or simply \"trend\". Twitter trends list has\na powerful ability to promote public events such as natural events, political\nscandals, market changes and other types of breaking news. Nevertheless, there\nhave been very few works focused on the dynamics of these trending topics. In\nthis article, we thoroughly examined the Twitter's trending topics of 2018. To\nthis end, we automatically accessed Twitter's trends API and stored the\nresulting 50 top trending topics in a novel dataset. We propose and analyze our\ndataset according to six criteria: lexical analysis, time to reach, trend\nreoccurrence, trending time, tweets count, and language analysis. Based on our\nresults, 77.6% of the topics that reached the Top-10 list were trending with\nless than 100k tweets. More than 50% of the topics could not hold the position\nfor more than an hour. English and Arabic languages comprised close to 40% and\n20% of the first rank topics, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jul 2019 17:07:07 GMT"}, {"version": "v2", "created": "Fri, 28 Aug 2020 12:31:30 GMT"}], "update_date": "2020-08-31", "authors_parsed": [["Annamoradnejad", "Issa", ""], ["Habibi", "Jafar", ""]]}, {"id": "1907.09177", "submitter": "Fuming Fang", "authors": "David Ifeoluwa Adelani, Haotian Mai, Fuming Fang, Huy H. Nguyen,\n  Junichi Yamagishi, Isao Echizen", "title": "Generating Sentiment-Preserving Fake Online Reviews Using Neural\n  Language Models and Their Human- and Machine-based Detection", "comments": "The 34-th International Conference on Advanced Information Networking\n  and Applications (AINA-2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CR cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advanced neural language models (NLMs) are widely used in sequence generation\ntasks because they are able to produce fluent and meaningful sentences. They\ncan also be used to generate fake reviews, which can then be used to attack\nonline review systems and influence the buying decisions of online shoppers. To\nperform such attacks, it is necessary for experts to train a tailored LM for a\nspecific topic. In this work, we show that a low-skilled threat model can be\nbuilt just by combining publicly available LMs and show that the produced fake\nreviews can fool both humans and machines. In particular, we use the GPT-2 NLM\nto generate a large number of high-quality reviews based on a review with the\ndesired sentiment and then using a BERT based text classifier (with accuracy of\n96%) to filter out reviews with undesired sentiments. Because none of the words\nin the review are modified, fluent samples like the training data can be\ngenerated from the learned distribution. A subjective evaluation with 80\nparticipants demonstrated that this simple method can produce reviews that are\nas fluent as those written by people. It also showed that the participants\ntended to distinguish fake reviews randomly. Three countermeasures, Grover,\nGLTR, and OpenAI GPT-2 detector, were found to be difficult to accurately\ndetect fake review.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 08:22:08 GMT"}, {"version": "v2", "created": "Tue, 3 Dec 2019 07:46:44 GMT"}], "update_date": "2019-12-04", "authors_parsed": [["Adelani", "David Ifeoluwa", ""], ["Mai", "Haotian", ""], ["Fang", "Fuming", ""], ["Nguyen", "Huy H.", ""], ["Yamagishi", "Junichi", ""], ["Echizen", "Isao", ""]]}, {"id": "1907.09280", "submitter": "Sankardeep Chakraborty", "authors": "Sankardeep Chakraborty, Kunihiko Sadakane, Srinivasa Rao Satti", "title": "Optimal In-place Algorithms for Basic Graph Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present linear time {\\it in-place} algorithms for several basic and\nfundamental graph problems including the well-known graph search methods (like\ndepth-first search, breadth-first search, maximum cardinality search),\nconnectivity problems (like biconnectivity, $2$-edge connectivity),\ndecomposition problem (like chain decomposition) among various others,\nimproving the running time (by polynomial multiplicative factor) of the recent\nresults of Chakraborty et al. [ESA, 2018] who designed $O(n^3 \\lg n)$ time\nin-place algorithms for a strict subset of the above mentioned problems. The\nrunning times of all our algorithms are essentially optimal as they run in\nlinear time. One of the main ideas behind obtaining these algorithms is the\ndetection and careful exploitation of sortedness present in the input\nrepresentation for any graph without loss of generality. This observation alone\nis powerful enough to design some basic linear time in-place algorithms, but\nmore non-trivial graph problems require extra techniques which, we believe, may\nfind other applications while designing in-place algorithms for different graph\nproblems in the future.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 12:41:59 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Chakraborty", "Sankardeep", ""], ["Sadakane", "Kunihiko", ""], ["Satti", "Srinivasa Rao", ""]]}, {"id": "1907.09328", "submitter": "Anubrata Das", "authors": "Anubrata Das and Matthew Lease", "title": "A Conceptual Framework for Evaluating Fairness in Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While search efficacy has been evaluated traditionally on the basis of result\nrelevance, fairness of search has attracted recent attention. In this work, we\ndefine a notion of distributional fairness and provide a conceptual framework\nfor evaluating search results based on it. As part of this, we formulate a set\nof axioms which an ideal evaluation framework should satisfy for distributional\nfairness. We show how existing TREC test collections can be repurposed to study\nfairness, and we measure potential data bias to inform test collection design\nfor fair search. A set of analyses show metric divergence between relevance and\nfairness, and we describe a simple but flexible interpolation strategy for\nintegrating relevance and fairness into a single metric for optimization and\nevaluation.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:09:20 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Das", "Anubrata", ""], ["Lease", "Matthew", ""]]}, {"id": "1907.09369", "submitter": "Armin Seyeditabari", "authors": "Armin Seyeditabari, Narges Tabari, Shafie Gholizadeh, Wlodek Zadrozny", "title": "Emotion Detection in Text: Focusing on Latent Representation", "comments": "6 pages, 7 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, emotion detection in text has become more popular due to its\nvast potential applications in marketing, political science, psychology,\nhuman-computer interaction, artificial intelligence, etc. In this work, we\nargue that current methods which are based on conventional machine learning\nmodels cannot grasp the intricacy of emotional language by ignoring the\nsequential nature of the text, and the context. These methods, therefore, are\nnot sufficient to create an applicable and generalizable emotion detection\nmethodology. Understanding these limitations, we present a new network based on\na bidirectional GRU model to show that capturing more meaningful information\nfrom text can significantly improve the performance of these models. The\nresults show significant improvement with an average of 26.8 point increase in\nF-measure on our test data and 38.6 increase on the totally new dataset.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 15:33:53 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Seyeditabari", "Armin", ""], ["Tabari", "Narges", ""], ["Gholizadeh", "Shafie", ""], ["Zadrozny", "Wlodek", ""]]}, {"id": "1907.09535", "submitter": "Niels M\\\"undler", "authors": "Niels M\\\"undler", "title": "Association rule mining and itemset-correlation based variants", "comments": "IEEE format, 6 pages, 4 figures, seminar paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Association rules express implication formed relations among attributes in\ndatabases of itemsets. The apriori algorithm is presented, the basis for most\nassociation rule mining algorithms. It works by pruning away rules that need\nnot be evaluated based on the user specified minimum support confidence.\nAdditionally, variations of the algorithm are presented that enable it to\nhandle quantitative attributes and to extract rules about generalizations of\nitems, but preserve the downward closure property that enables pruning.\nIntertransformation of the extensions is proposed for special cases.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 19:11:49 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["M\u00fcndler", "Niels", ""]]}, {"id": "1907.09748", "submitter": "Yaxiong Wang", "authors": "Yaxiong Wang, Hao Yang, Xueming Qian, Lin Ma, Jing Lu, Biao Li and Xin\n  Fan", "title": "Position Focused Attention Network for Image-Text Matching", "comments": "Accepted by IJCAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image-text matching tasks have recently attracted a lot of attention in the\ncomputer vision field. The key point of this cross-domain problem is how to\naccurately measure the similarity between the visual and the textual contents,\nwhich demands a fine understanding of both modalities. In this paper, we\npropose a novel position focused attention network (PFAN) to investigate the\nrelation between the visual and the textual views. In this work, we integrate\nthe object position clue to enhance the visual-text joint-embedding learning.\nWe first split the images into blocks, by which we infer the relative position\nof region in the image. Then, an attention mechanism is proposed to model the\nrelations between the image region and blocks and generate the valuable\nposition feature, which will be further utilized to enhance the region\nexpression and model a more reliable relationship between the visual image and\nthe textual sentence. Experiments on the popular datasets Flickr30K and MS-COCO\nshow the effectiveness of the proposed method. Besides the public datasets, we\nalso conduct experiments on our collected practical large-scale news dataset\n(Tencent-News) to validate the practical application value of proposed method.\nAs far as we know, this is the first attempt to test the performance on the\npractical application. Our method achieves the state-of-art performance on all\nof these three datasets.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 08:23:42 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Wang", "Yaxiong", ""], ["Yang", "Hao", ""], ["Qian", "Xueming", ""], ["Ma", "Lin", ""], ["Lu", "Jing", ""], ["Li", "Biao", ""], ["Fan", "Xin", ""]]}, {"id": "1907.09781", "submitter": "Dominik Kowald PhD", "authors": "Dominik Kowald, Elisabeth Lex, Markus Schedl", "title": "Modeling Artist Preferences of Users with Different Music Consumption\n  Patterns for Fair Music Recommendations", "comments": "EuroCSS'2019 Symposium, Zurich, Switzerland", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music recommender systems have become central parts of popular streaming\nplatforms such as Last.fm, Pandora, or Spotify to help users find music that\nfits their preferences. These systems learn from the past listening events of\nusers to recommend music a user will likely listen to in the future. Here,\ncurrent algorithms typically employ collaborative filtering (CF) utilizing\nsimilarities between users' listening behaviors. Some approaches also combine\nCF with content features into hybrid recommender systems. While music\nrecommender systems can provide quality recommendations to listeners of\nmainstream music artists, recent research has shown that they tend to\ndiscriminate listeners of unorthodox, low-mainstream artists. This is foremost\ndue to the scarcity of usage data of low-mainstream music as music consumption\npatterns are biased towards popular artists. Thus, the objective of our work is\nto provide a novel approach for modeling artist preferences of users with\ndifferent music consumption patterns and listening habits.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 09:22:25 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Kowald", "Dominik", ""], ["Lex", "Elisabeth", ""], ["Schedl", "Markus", ""]]}, {"id": "1907.09854", "submitter": "Muthu Kumar Chandrasekaran", "authors": "Muthu Kumar Chandrasekaran and Michihiro Yasunaga and Dragomir Radev\n  and Dayne Freitag and Min-Yen Kan", "title": "Overview and Results: CL-SciSumm Shared Task 2019", "comments": "In Proceedings of BIRNDL 2019 at SIGIR 2019, Paris", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CL-SciSumm Shared Task is the first medium-scale shared task on\nscientific document summarization in the computational linguistics~(CL) domain.\nIn 2019, it comprised three tasks: (1A) identifying relationships between\nciting documents and the referred document, (1B) classifying the discourse\nfacets, and (2) generating the abstractive summary. The dataset comprised 40\nannotated sets of citing and reference papers of the CL-SciSumm 2018 corpus and\n1000 more from the SciSummNet dataset. All papers are from the open access\nresearch papers in the CL domain. This overview describes the participation and\nthe official results of the CL-SciSumm 2019 Shared Task, organized as a part of\nthe 42nd Annual Conference of the Special Interest Group in Information\nRetrieval (SIGIR), held in Paris, France in July 2019. We compare the\nparticipating systems in terms of two evaluation metrics and discuss the use of\nROUGE as an evaluation metric. The annotated dataset used for this shared task\nand the scripts used for evaluation can be accessed and used by the community\nat: https://github.com/WING-NUS/scisumm-corpus.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 13:06:01 GMT"}], "update_date": "2019-07-24", "authors_parsed": [["Chandrasekaran", "Muthu Kumar", ""], ["Yasunaga", "Michihiro", ""], ["Radev", "Dragomir", ""], ["Freitag", "Dayne", ""], ["Kan", "Min-Yen", ""]]}, {"id": "1907.10401", "submitter": "Camille Roth", "authors": "Camille Roth (CAMS, CMB)", "title": "Algorithmic Distortion of Informational Landscapes", "comments": null, "journal-ref": "Intellectica, In press", "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The possible impact of algorithmic recommendation on the autonomy and free\nchoice of Internet users is being increasingly discussed, especially in terms\nof the rendering of information and the structuring of interactions. This paper\naims at reviewing and framing this issue along a double dichotomy. The first\none addresses the discrepancy between users' intentions and actions (1) under\nsome algorithmic influence and (2) without it. The second one distinguishes\nalgorithmic biases on (1) prior information rearrangement and (2) posterior\ninformation arrangement. In all cases, we focus on and differentiate situations\nwhere algorithms empirically appear to expand the cognitive and social horizon\nof users, from those where they seem to limit that horizon. We additionally\nsuggest that these biases may not be properly appraised without taking into\naccount the underlying social processes which algorithms are building upon.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jul 2019 08:13:18 GMT"}], "update_date": "2019-07-25", "authors_parsed": [["Roth", "Camille", "", "CAMS, CMB"]]}, {"id": "1907.10409", "submitter": "Muhammad Umer Anwaar", "authors": "Muhammad Umer Anwaar, Dmytro Rybalko, Martin Kleinsteuber", "title": "Mend The Learning Approach, Not the Data: Insights for Ranking\n  E-Commerce Products", "comments": "Accepted for ECML-PKDD 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Improved search quality enhances users' satisfaction, which directly impacts\nsales growth of an E-Commerce (E-Com) platform. Traditional Learning to Rank\n(LTR) algorithms require relevance judgments on products. In E-Com, getting\nsuch judgments poses an immense challenge. In the literature, it is proposed to\nemploy user feedback (such as clicks, add-to-basket (AtB) clicks and orders) to\ngenerate relevance judgments. It is done in two steps: first, query-product\npair data are aggregated from the logs and then order rate etc are calculated\nfor each pair in the logs. In this paper, we advocate counterfactual risk\nminimization (CRM) approach which circumvents the need of relevance judgements,\ndata aggregation and is better suited for learning from logged data, i.e.\ncontextual bandit feedback. Due to unavailability of public E-Com LTR dataset,\nwe provide \\textit{Mercateo dataset} from our platform. It contains more than\n10 million AtB click logs and 1 million order logs from a catalogue of about\n3.5 million products associated with 3060 queries. To the best of our\nknowledge, this is the first work which examines effectiveness of CRM approach\nin learning ranking model from real-world logged data. Our empirical evaluation\nshows that our CRM approach learns effectively from logged data and beats a\nstrong baseline ranker ($\\lambda$-MART) by a huge margin. Our method\noutperforms full-information loss (e.g. cross-entropy) on various deep neural\nnetwork models. These findings demonstrate that by adopting CRM approach, E-Com\nplatforms can get better product search quality compared to full-information\napproach. The code and dataset can be accessed at:\nhttps://github.com/ecom-research/CRM-LTR.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 12:53:15 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2019 22:34:06 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 14:39:05 GMT"}, {"version": "v4", "created": "Tue, 21 Jan 2020 15:42:29 GMT"}, {"version": "v5", "created": "Sun, 29 Mar 2020 21:16:39 GMT"}, {"version": "v6", "created": "Thu, 30 Apr 2020 10:55:32 GMT"}, {"version": "v7", "created": "Fri, 19 Jun 2020 11:31:51 GMT"}, {"version": "v8", "created": "Thu, 9 Jul 2020 07:35:56 GMT"}], "update_date": "2020-07-10", "authors_parsed": [["Anwaar", "Muhammad Umer", ""], ["Rybalko", "Dmytro", ""], ["Kleinsteuber", "Martin", ""]]}, {"id": "1907.10450", "submitter": "Kader Pustu-Iren", "authors": "Kader Pustu-Iren and Markus M\\\"uhling and Nikolaus Korfhage and Joanna\n  Bars and Sabrina Bernh\\\"oft and Angelika H\\\"orth and Bernd Freisleben and\n  Ralph Ewerth", "title": "Investigating Correlations of Inter-coder Agreement and Machine\n  Annotation Performance for Historical Video Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DL cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video indexing approaches such as visual concept classification and person\nrecognition are essential to enable fine-grained semantic search in large-scale\nvideo archives such as the historical video collection of former German\nDemocratic Republic (GDR) maintained by the German Broadcasting Archive (DRA).\nTypically, a lexicon of visual concepts has to be defined for semantic search.\nHowever, the definition of visual concepts can be more or less subjective due\nto individually differing judgments of annotators, which may have an impact on\nannotation quality and subsequently training of supervised machine learning\nmethods. In this paper, we analyze the inter-coder agreement for historical TV\ndata of the former GDR for visual concept classification and person\nrecognition. The inter-coder agreement is evaluated for a group of expert as\nwell as non-expert annotators in order to determine differences in annotation\nhomogeneity. Furthermore, correlations between visual recognition performance\nand inter-annotator agreement are measured. In this context, information about\nimage quantity and agreement are used to predict average precision for concept\nclassification. Finally, the influence of expert vs. non-expert annotations\nacquired in the study are used to evaluate person recognition.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 13:50:20 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Pustu-Iren", "Kader", ""], ["M\u00fchling", "Markus", ""], ["Korfhage", "Nikolaus", ""], ["Bars", "Joanna", ""], ["Bernh\u00f6ft", "Sabrina", ""], ["H\u00f6rth", "Angelika", ""], ["Freisleben", "Bernd", ""], ["Ewerth", "Ralph", ""]]}, {"id": "1907.10710", "submitter": "Hongfei Zhang", "authors": "Hongfei Zhang, Xia Song, Chenyan Xiong, Corby Rosset, Paul N. Bennett,\n  Nick Craswell, and Saurabh Tiwary", "title": "Generic Intent Representation in Web Search", "comments": null, "journal-ref": "SIGIR 2019: Proceedings of the 42nd International ACM SIGIR\n  Conference on Research and Development in Information Retrieval", "doi": "10.1145/3331184.3331198", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents GEneric iNtent Encoder (GEN Encoder) which learns a\ndistributed representation space for user intent in search. Leveraging large\nscale user clicks from Bing search logs as weak supervision of user intent, GEN\nEncoder learns to map queries with shared clicks into similar embeddings\nend-to-end and then finetunes on multiple paraphrase tasks. Experimental\nresults on an intrinsic evaluation task - query intent similarity modeling -\ndemonstrate GEN Encoder's robust and significant advantages over previous\nrepresentation methods. Ablation studies reveal the crucial role of learning\nfrom implicit user feedback in representing user intent and the contributions\nof multi-task learning in representation generality. We also demonstrate that\nGEN Encoder alleviates the sparsity of tail search traffic and cuts down half\nof the unseen queries by using an efficient approximate nearest neighbor search\nto effectively identify previous queries with the same search intent. Finally,\nwe demonstrate distances between GEN encodings reflect certain information\nseeking behaviors in search sessions.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 20:40:19 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Zhang", "Hongfei", ""], ["Song", "Xia", ""], ["Xiong", "Chenyan", ""], ["Rosset", "Corby", ""], ["Bennett", "Paul N.", ""], ["Craswell", "Nick", ""], ["Tiwary", "Saurabh", ""]]}, {"id": "1907.10738", "submitter": "Pratyay Banerjee", "authors": "Pratyay Banerjee, Kuntal Kumar Pal, Arindam Mitra, Chitta Baral", "title": "Careful Selection of Knowledge to solve Open Book Question Answering", "comments": "Accepted to ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open book question answering is a type of natural language based QA (NLQA)\nwhere questions are expected to be answered with respect to a given set of open\nbook facts, and common knowledge about a topic. Recently a challenge involving\nsuch QA, OpenBookQA, has been proposed. Unlike most other NLQA tasks that focus\non linguistic understanding, OpenBookQA requires deeper reasoning involving\nlinguistic understanding as well as reasoning with common knowledge. In this\npaper we address QA with respect to the OpenBookQA dataset and combine state of\nthe art language models with abductive information retrieval (IR), information\ngain based re-ranking, passage selection and weighted scoring to achieve 72.0%\naccuracy, an 11.6% improvement over the current state of the art.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 21:37:16 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Banerjee", "Pratyay", ""], ["Pal", "Kuntal Kumar", ""], ["Mitra", "Arindam", ""], ["Baral", "Chitta", ""]]}, {"id": "1907.10943", "submitter": "Sagar Uprety Mr.", "authors": "Sagar Uprety, Shahram Dehdashti, Lauren Fell, Peter Bruza, Dawei Song", "title": "Modelling Dynamic Interactions between Relevance Dimensions", "comments": "Accepted at ACM SIGIR International Conference on the Theory of\n  Information Retrieval 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relevance is an underlying concept in the field of Information Science and\nRetrieval. It is a cognitive notion consisting of several different criteria or\ndimensions. Theoretical models of relevance allude to interdependence between\nthese dimensions, where their interaction and fusion leads to the final\ninference of relevance. We study the interaction between the relevance\ndimensions using the mathematical framework of Quantum Theory. It is considered\na generalised framework to model decision making under uncertainty, involving\nmultiple perspectives and influenced by context. Specifically, we conduct a\nuser study by constructing the cognitive analogue of a famous experiment in\nQuantum Physics. The data is used to construct a complex-valued vector space\nmodel of the user's cognitive state, which is used to explain incompatibility\nand interference between relevance dimensions. The implications of our findings\nto inform the design of Information Retrieval systems are also discussed.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 10:12:01 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Uprety", "Sagar", ""], ["Dehdashti", "Shahram", ""], ["Fell", "Lauren", ""], ["Bruza", "Peter", ""], ["Song", "Dawei", ""]]}, {"id": "1907.10984", "submitter": "Sankardeep Chakraborty", "authors": "Kentaro Sumigawa, Sankardeep Chakraborty, Kunihiko Sadakane, Srinivasa\n  Rao Satti", "title": "Enumerating Range Modes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the range mode problem where given a sequence and a query range\nin it, we want to find items with maximum frequency in the range. We give time-\nand space- efficient algorithms for this problem. Our algorithms are efficient\nfor small maximum frequency cases. We also consider a natural generalization of\nthe problem: the range mode enumeration problem, for which there has been no\nknown efficient algorithms. Our algorithms have query time complexities which\nis linear to the output size plus small terms.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 11:48:57 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Sumigawa", "Kentaro", ""], ["Chakraborty", "Sankardeep", ""], ["Sadakane", "Kunihiko", ""], ["Satti", "Srinivasa Rao", ""]]}, {"id": "1907.11000", "submitter": "Ludovik Coba <", "authors": "Ludovik Coba, Panagiotis Symeonidis, Markus Zanker", "title": "Personalised novel and explainable matrix factorisation", "comments": null, "journal-ref": "Data & Knowledge Engineering Volume 122, July 2019, Pages 142-158\n  https://www.sciencedirect.com/science/article/pii/S0169023X1830332X", "doi": "10.1016/j.datak.2019.06.003", "report-no": null, "categories": "cs.IR cs.HC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recommendation systems personalise suggestions to individuals to help them in\ntheir decision making and exploration tasks. In the ideal case, these\nrecommendations, besides of being accurate, should also be novel and\nexplainable. However, up to now most platforms fail to provide both, novel\nrecommendations that advance users' exploration along with explanations to make\ntheir reasoning more transparent to them. For instance, a well-known\nrecommendation algorithm, such as matrix factorisation (MF), optimises only the\naccuracy criterion, while disregarding other quality criteria such as the\nexplainability or the novelty, of recommended items. In this paper, to the best\nof our knowledge, we propose a new model, denoted as NEMF, that allows to\ntrade-off the MF performance with respect to the criteria of novelty and\nexplainability, while only minimally compromising on accuracy. In addition, we\nrecommend a new explainability metric based on nDCG, which distinguishes a more\nexplainable item from a less explainable item. An initial user study indicates\nhow users perceive the different attributes of these \"user\" style explanations\nand our extensive experimental results demonstrate that we attain high accuracy\nby recommending also novel and explainable items.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 12:21:19 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Coba", "Ludovik", ""], ["Symeonidis", "Panagiotis", ""], ["Zanker", "Markus", ""]]}, {"id": "1907.11086", "submitter": "Alan Chern", "authors": "Alan Chern, Phuong Hoang, Madhav Sigdel, Janani Balaji, and Mohammed\n  Korayem", "title": "Automated Discovery and Classification of Training Videos for Career\n  Progression", "comments": "5 pages, 4 figures, Proceedings of the Data Collection, Curation, and\n  Labeling for Mining and Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Job transitions and upskilling are common actions taken by many industry\nworking professionals throughout their career. With the current rapidly\nchanging job landscape where requirements are constantly changing and industry\nsectors are emerging, it is especially difficult to plan and navigate a\npredetermined career path. In this work, we implemented a system to automate\nthe collection and classification of training videos to help job seekers\nidentify and acquire the skills necessary to transition to the next step in\ntheir career. We extracted educational videos and built a machine learning\nclassifier to predict video relevancy. This system allows us to discover\nrelevant videos at a large scale for job title-skill pairs. Our experiments\nshow significant improvements in the model performance by incorporating\nembedding vectors associated with the video attributes. Additionally, we\nevaluated the optimal probability threshold to extract as many videos as\npossible with minimal false positive rate.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 18:23:57 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Chern", "Alan", ""], ["Hoang", "Phuong", ""], ["Sigdel", "Madhav", ""], ["Balaji", "Janani", ""], ["Korayem", "Mohammed", ""]]}, {"id": "1907.11166", "submitter": "Fabio Paolizzo", "authors": "M. Alessandrini, A. Micarelli, A. Viziano, I. Pavone, G. Costantini,\n  D. Casali, F. Paolizzo, G. Saggio", "title": "Body-worn triaxial accelerometer coherence and reliability related to\n  static posturography in unilateral vestibular failure", "comments": "6 pages, 2 figures, 2 tables", "journal-ref": "Acta Otorhinolaryngol Ital. 2017 Jun;37(3):231-236", "doi": "10.14639/0392-100X-1334", "report-no": null, "categories": "physics.med-ph cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the fact that no study to date has shown the experimental validity of\nACC-based measures of body sway with respect to posturography for subjects with\nvestibular deficits, the aim of the present study was: i) to develop and\nvalidate a practical tool that can allow clinicians to measure postural sway\nderangements in an otoneurological setting by ACC, and ii) to provide reliable,\nsensitive and accurate automatic analysis of sway that could help in\ndiscriminating unilateral vestibular failure (UVF) patients. Thus, a group of\n13 patients (seven females, 6 males; mean age 48.6 +/- 6.4 years) affected for\nat least 6 months by UVF and 13 matched healthy subjects were instructed to\nmaintain an upright position during a static forceplate-based posturography\n(FBP) acquisition while wearing a Movit sensor (by Captiks) with 3-D\naccelerometers mounted on the posterior trunk near the body centre of mass.\nPearson product moment correlation demonstrated a high level of correspondence\nof four time-domain and three frequency-domain measures extracted by ACC and\nFBP testing; in addition, t-test demonstrated that two ACC-based time- and\nfrequency-domain parameters were reliable measures in discriminating UVF\nsubjects. These aspects, overall, should further highlight the attention of\nclinicians and researchers to this kind of sway recording technique in the\nfield of otoneurological disorders by considering the possibility to enrich the\namount of quantitative and qualitative information useful for discrimination,\ndiagnosis and treatment of UVF. In conclusion, we believe the present ACC-based\nmeasurement of sway offers a patient-friendly, reliable, inexpensive and\nefficient alternative recording technique that is useful - together with\nclinical balance and mobility tests - in various circumstances, as well as in\noutcome studies involving diagnosis, follow-up and rehabilitation of UVF\npatients.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 14:53:54 GMT"}, {"version": "v2", "created": "Mon, 29 Jul 2019 13:40:13 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Alessandrini", "M.", ""], ["Micarelli", "A.", ""], ["Viziano", "A.", ""], ["Pavone", "I.", ""], ["Costantini", "G.", ""], ["Casali", "D.", ""], ["Paolizzo", "F.", ""], ["Saggio", "G.", ""]]}, {"id": "1907.11232", "submitter": "Konstantinos Xylogiannopoulos", "authors": "Konstantinos F. Xylogiannopoulos", "title": "Exhaustive Exact String Matching: The Analysis of the Full Human Genome", "comments": "Paper accepted for publication at IEEE/ACM ASONAM 2019 conference,\n  Vancouver, BC, Canada", "journal-ref": null, "doi": "10.1145/3341161.3343517", "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exact string matching has been a fundamental problem in computer science for\ndecades because of many practical applications. Some are related to common\nprocedures, such as searching in files and text editors, or, more recently, to\nmore advanced problems such as pattern detection in Artificial Intelligence and\nBioinformatics. Tens of algorithms and methodologies have been developed for\npattern matching and several programming languages, packages, applications and\nonline systems exist that can perform exact string matching in biological\nsequences. These techniques, however, are limited to searching for specific and\npredefined strings in a sequence. In this paper a novel methodology (called\nEx2SM) is presented, which is a pipeline of execution of advanced data\nstructures and algorithms, explicitly designed for text mining, that can detect\nevery possible repeated string in multivariate biological sequences. In\ncontrast to known algorithms in literature, the methodology presented here is\nstring agnostic, i.e., it does not require an input string to search for it,\nrather it can detect every string that exists at least twice, regardless of its\nattributes such as length, frequency, alphabet, overlapping etc. The complexity\nof the problem solved and the potential of the proposed methodology is\ndemonstrated with the experimental analysis performed on the entire human\ngenome. More specifically, all repeated strings with a length of up to 50\ncharacters have been detected, an achievement which is practically impossible\nusing other algorithms due to the exponential number of possible permutations\nof such long strings.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 20:50:16 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Xylogiannopoulos", "Konstantinos F.", ""]]}, {"id": "1907.11499", "submitter": "Yumo Xu", "authors": "Yumo Xu and Mirella Lapata", "title": "Weakly Supervised Domain Detection", "comments": "To appear in Transactions of the Association for Computational\n  Linguistics (TACL); 16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce domain detection as a new natural language\nprocessing task. We argue that the ability to detect textual segments which are\ndomain-heavy, i.e., sentences or phrases which are representative of and\nprovide evidence for a given domain could enhance the robustness and\nportability of various text classification applications. We propose an\nencoder-detector framework for domain detection and bootstrap classifiers with\nmultiple instance learning (MIL). The model is hierarchically organized and\nsuited to multilabel classification. We demonstrate that despite learning with\nminimal supervision, our model can be applied to text spans of different\ngranularities, languages, and genres. We also showcase the potential of domain\ndetection for text summarization.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 11:53:15 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Xu", "Yumo", ""], ["Lapata", "Mirella", ""]]}, {"id": "1907.11510", "submitter": "Fabien Ringeval", "authors": "Fabien Ringeval, Bj\\\"orn Schuller, Michel Valstar, NIcholas Cummins,\n  Roddy Cowie, Leili Tavabi, Maximilian Schmitt, Sina Alisamir, Shahin\n  Amiriparian, Eva-Maria Messner, Siyang Song, Shuo Liu, Ziping Zhao, Adria\n  Mallol-Ragolta, Zhao Ren, Mohammad Soleymani, Maja Pantic", "title": "AVEC 2019 Workshop and Challenge: State-of-Mind, Detecting Depression\n  with AI, and Cross-Cultural Affect Recognition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CV cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Audio/Visual Emotion Challenge and Workshop (AVEC 2019) \"State-of-Mind,\nDetecting Depression with AI, and Cross-cultural Affect Recognition\" is the\nninth competition event aimed at the comparison of multimedia processing and\nmachine learning methods for automatic audiovisual health and emotion analysis,\nwith all participants competing strictly under the same conditions. The goal of\nthe Challenge is to provide a common benchmark test set for multimodal\ninformation processing and to bring together the health and emotion recognition\ncommunities, as well as the audiovisual processing communities, to compare the\nrelative merits of various approaches to health and emotion recognition from\nreal-life data. This paper presents the major novelties introduced this year,\nthe challenge guidelines, the data used, and the performance of the baseline\nsystems on the three proposed tasks: state-of-mind recognition, depression\nassessment with AI, and cross-cultural affect sensing, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jul 2019 13:41:42 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Ringeval", "Fabien", ""], ["Schuller", "Bj\u00f6rn", ""], ["Valstar", "Michel", ""], ["Cummins", "NIcholas", ""], ["Cowie", "Roddy", ""], ["Tavabi", "Leili", ""], ["Schmitt", "Maximilian", ""], ["Alisamir", "Sina", ""], ["Amiriparian", "Shahin", ""], ["Messner", "Eva-Maria", ""], ["Song", "Siyang", ""], ["Liu", "Shuo", ""], ["Zhao", "Ziping", ""], ["Mallol-Ragolta", "Adria", ""], ["Ren", "Zhao", ""], ["Soleymani", "Mohammad", ""], ["Pantic", "Maja", ""]]}, {"id": "1907.11542", "submitter": "Fabio Paolizzo", "authors": "Giovanni Costantini, Daniele Casali, Fabio Paolizzo, Marco\n  Alessandrini, Alessandro Micarelli, Andrea Viziano, Giovanni Saggio", "title": "Towards the Enhancement of Body Standing Balance Recovery by Means of a\n  Wireless Audio-Biofeedback System", "comments": "8 pages, 7 figures, 2 tables", "journal-ref": "Medical engineering & physics, 54, 74-81, 2019", "doi": "10.1016/j.medengphy.2018.01.008", "report-no": null, "categories": "eess.SP cs.IR physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Human maintain their body balance by sensorimotor controls mainly based on\ninformation gathered from vision, proprioception and vestibular systems. When\nthere is a lack of information, caused by pathologies, diseases or aging, the\nsubject may fall. In this context, we developed a system to augment information\ngathering, providing the subject with warning audio-feedback signals related to\nhis/her equilibrium. The system comprises an inertial measurement unit (IMU), a\ndata processing unit, a headphone audio device and a software application. The\nIMU is a low-weight, small-size wireless instrument that, body-back located\nbetween the L2 and L5 lumbar vertebrae, measures the subject's trunk\nkinematics. The application drives the data processing unit to feeding the\nheadphone with electric signals related to the kinematic measures.\nConsequently, the user is audio-alerted, via headphone, of his/her own\nequilibrium, hearing a pleasant sound when in a stable equilibrium, or an\nincreasing bothering sound when in an increasing unstable condition. Tests were\nconducted on a group of six older subjects (59y-61y, SD = 2.09y) and a group of\nfour young subjects (21y-26y, SD = 2.88y) to underline difference in\neffectiveness of the system, if any, related to the age of the users. For each\nsubject, standing balance tests were performed in normal or altered conditions,\nsuch as, open or closed eyes, and on a solid or foam surface The system was\nevaluated in terms of usability, reliability, and effectiveness in improving\nthe subject's balance in all conditions. As a result, the system successfully\nhelped the subjects in reducing the body swaying within 10.65%-65.90%,\ndifferences depending on subjects' age and test conditions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 12:52:26 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Costantini", "Giovanni", ""], ["Casali", "Daniele", ""], ["Paolizzo", "Fabio", ""], ["Alessandrini", "Marco", ""], ["Micarelli", "Alessandro", ""], ["Viziano", "Andrea", ""], ["Saggio", "Giovanni", ""]]}, {"id": "1907.11620", "submitter": "Tomislav Duricic", "authors": "Tomislav Duricic, Emanuel Lacic, Dominik Kowald, Elisabeth Lex", "title": "Exploiting weak ties in trust-based recommender systems using regular\n  equivalence", "comments": "Presented as a Spotlight Talk at the \"European Symposium Series on\n  Societal Challenges in Computational Social Science: Polarization and\n  Radicalization\" (Euro CSS 2019). arXiv admin note: substantial text overlap\n  with arXiv:1807.06839", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-based Collaborative Filtering (CF) is one of the most popular approaches\nto create recommender systems. CF, however, suffers from data sparsity and the\ncold-start problem since users often rate only a small fraction of available\nitems. One solution is to incorporate additional information into the\nrecommendation process such as explicit trust scores that are assigned by users\nto others or implicit trust relationships that result from social connections\nbetween users. Such relationships typically form a very sparse trust network,\nwhich can be utilized to generate recommendations for users based on people\nthey trust. In our work, we explore the use of regular equivalence applied to a\ntrust network to generate a similarity matrix that is used for selecting\nk-nearest neighbors used for item recommendation. Two vertices in a network are\nregularly equivalent if their neighbors are themselves equivalent and by using\nthe iterative approach of calculating regular equivalence, we can study the\nimpact of strong and weak ties on item recommendation. We evaluate our approach\non cold-start users on a dataset crawled from Epinions and find that by using\nweak ties in addition to strong ties, we can improve the performance of a\ntrust-based recommender in terms of recommendation accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jun 2019 09:24:04 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Duricic", "Tomislav", ""], ["Lacic", "Emanuel", ""], ["Kowald", "Dominik", ""], ["Lex", "Elisabeth", ""]]}, {"id": "1907.11754", "submitter": "Jiasheng Zhang", "authors": "Jason (Jiasheng) Zhang, Junming Yin, Dongwon Lee, Linhong Zhu", "title": "Deep Reinforcement Learning for Personalized Search Story Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, \\emph{search story}, a combined display with other organic\nchannels, has become a major source of user traffic on platforms such as\ne-commerce search platforms, news feed platforms and web and image search\nplatforms. The recommended search story guides a user to identify her own\npreference and personal intent, which subsequently influences the user's\nreal-time and long-term search behavior. %With such an increased importance of\nsearch stories, As search stories become increasingly important, in this work,\nwe study the problem of personalized search story recommendation within a\nsearch engine, which aims to suggest a search story relevant to both a search\nkeyword and an individual user's interest. To address the challenge of modeling\nboth immediate and future values of recommended search stories (i.e.,\ncross-channel effect), for which conventional supervised learning framework is\nnot applicable, we resort to a Markov decision process and propose a deep\nreinforcement learning architecture trained by both imitation learning and\nreinforcement learning. We empirically demonstrate the effectiveness of our\nproposed approach through extensive experiments on real-world data sets from\nJD.com.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 19:01:48 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Jason", "", "", "Jiasheng"], ["Zhang", "", ""], ["Yin", "Junming", ""], ["Lee", "Dongwon", ""], ["Zhu", "Linhong", ""]]}, {"id": "1907.11817", "submitter": "Firas Alomari", "authors": "F Alomari, M Harbi", "title": "Scalable Source Code Similarity Detection in Large Code Repositories", "comments": "11 pages, 5 figures, Journal", "journal-ref": "EAI Endorsed Transactions on Scalable Information Systems: Online\n  first, 2019", "doi": "10.4108/eai.13-7-2018.159353", "report-no": null, "categories": "cs.SE cs.IR cs.PL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Source code similarity are increasingly used in application development to\nidentify clones, isolate bugs, and find copy-rights violations. Similar code\nfragments can be very problematic due to the fact that errors in the original\ncode must be fixed in every copy. Other maintenance changes, such as extensions\nor patches, must be applied multiple times. Furthermore, the diversity of\ncoding styles and flexibility of modern languages makes it difficult and cost\nineffective to manually inspect large code repositories. Therefore, detection\nis only feasible by automatic techniques. We present an efficient and scalable\napproach for similar code fragment identification based on source code control\nflow graphs fingerprinting. The source code is processed to generate control\nflow graphs that are then hashed to create a unique fingerprint of the code\ncapturing semantics as well as syntax similarity. The fingerprints can then be\nefficiently stored and retrieved to perform similarity search between code\nfragments. Experimental results from our prototype implementation supports the\nvalidity of our approach and show its effectiveness and efficiency in\ncomparison with other solutions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 23:28:30 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Alomari", "F", ""], ["Harbi", "M", ""]]}, {"id": "1907.11854", "submitter": "ByungSoo Ko", "authors": "Byungsoo Ko, Minchul Shin, Geonmo Gu, HeeJae Jun, Tae Kwan Lee,\n  Youngjoon Kim", "title": "A Benchmark on Tricks for Large-scale Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many studies have been performed on metric learning, which has become a key\ningredient in top-performing methods of instance-level image retrieval.\nMeanwhile, less attention has been paid to pre-processing and post-processing\ntricks that can significantly boost performance. Furthermore, we found that\nmost previous studies used small scale datasets to simplify processing. Because\nthe behavior of a feature representation in a deep learning model depends on\nboth domain and data, it is important to understand how model behave in\nlarge-scale environments when a proper combination of retrieval tricks is used.\nIn this paper, we extensively analyze the effect of well-known pre-processing,\npost-processing tricks, and their combination for large-scale image retrieval.\nWe found that proper use of these tricks can significantly improve model\nperformance without necessitating complex architecture or introducing loss, as\nconfirmed by achieving a competitive result on the Google Landmark Retrieval\nChallenge 2019.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jul 2019 05:58:00 GMT"}, {"version": "v2", "created": "Thu, 23 Apr 2020 06:29:25 GMT"}], "update_date": "2020-04-24", "authors_parsed": [["Ko", "Byungsoo", ""], ["Shin", "Minchul", ""], ["Gu", "Geonmo", ""], ["Jun", "HeeJae", ""], ["Lee", "Tae Kwan", ""], ["Kim", "Youngjoon", ""]]}, {"id": "1907.12008", "submitter": "Chiung Ching Ho", "authors": "Wei Lun Lim, Chiung Ching Ho, Choo-Yee Ting", "title": "Fusing location and text features for sentiment classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geo-tagged Twitter data has been used recently to infer insights on the human\naspects of social media. Insights related to demographics, spatial distribution\nof cultural activities, space-time travel trajectories for humans as well as\nhappiness has been mined from geo-tagged twitter data in recent studies. To\ndate, not much study has been done on the impact of the geolocation features of\na Tweet on its sentiment. This observation has inspired us to propose the usage\nof geo-location features as a method to perform sentiment classification. In\nthis method, the sentiment classification of geo-tagged tweets is performed by\nconcatenating geo-location features and one-hot encoded word vectors as inputs\nfor convolutional neural networks (CNN) and long short-term memory (LSTM)\nnetworks. The addition of language-independent features in the form of\ngeo-location features has helped to enrich the tweet representation in order to\ncombat the sparse nature of short tweet message. The results achieved has\ndemonstrated that concatenating geo-location features to one-hot encoded word\nvectors can achieve higher accuracy as compared to the usage of word vectors\nalone for the purpose of sentiment classification.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 03:57:16 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Lim", "Wei Lun", ""], ["Ho", "Chiung Ching", ""], ["Ting", "Choo-Yee", ""]]}, {"id": "1907.12016", "submitter": "Devinder Kumar", "authors": "Devinder Kumar, Parthipan Siva, Paul Marchwica, Alexander Wong", "title": "Fairest of Them All: Establishing a Strong Baseline for Cross-Domain\n  Person ReID", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Person re-identification (ReID) remains a very difficult challenge in\ncomputer vision, and critical for large-scale video surveillance scenarios\nwhere an individual could appear in different camera views at different times.\nThere has been recent interest in tackling this challenge using cross-domain\napproaches, which leverages data from source domains that are different than\nthe target domain. Such approaches are more practical for real-world widespread\ndeployment given that they don't require on-site training (as with unsupervised\nor domain transfer approaches) or on-site manual annotation and training (as\nwith supervised approaches). In this study, we take a systematic approach to\nestablishing a large baseline source domain and target domain for cross-domain\nperson ReID. We accomplish this by conducting a comprehensive analysis to study\nthe similarities between source domains proposed in literature, and studying\nthe effects of incrementally increasing the size of the source domain. This\nallows us to establish a balanced source domain and target domain split that\npromotes variety in both source and target domains. Furthermore, using lessons\nlearned from the state-of-the-art supervised person re-identification methods,\nwe establish a strong baseline method for cross-domain person ReID. Experiments\nshow that a source domain composed of two of the largest person ReID domains\n(SYSU and MSMT) performs well across six commonly-used target domains.\nFurthermore, we show that, surprisingly, two of the recent commonly-used\ndomains (PRID and GRID) have too few query images to provide meaningful\ninsights. As such, based on our findings, we propose the following balanced\nbaseline for cross-domain person ReID consisting of: i) a fixed multi-source\ndomain consisting of SYSU, MSMT, Airport and 3DPeS, and ii) a multi-target\ndomain consisting of Market-1501, DukeMTMC-reID, CUHK03, PRID, GRID and VIPeR.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 05:20:34 GMT"}, {"version": "v2", "created": "Fri, 27 Dec 2019 18:25:34 GMT"}], "update_date": "2019-12-30", "authors_parsed": [["Kumar", "Devinder", ""], ["Siva", "Parthipan", ""], ["Marchwica", "Paul", ""], ["Wong", "Alexander", ""]]}, {"id": "1907.12079", "submitter": "Hannah Kim", "authors": "Hannah Kim, Dongjin Choi, Barry Drake, Alex Endert, Haesun Park", "title": "TopicSifter: Interactive Search Space Reduction Through Targeted Topic\n  Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic modeling is commonly used to analyze and understand large document\ncollections. However, in practice, users want to focus on specific aspects or\n\"targets\" rather than the entire corpus. For example, given a large collection\nof documents, users may want only a smaller subset which more closely aligns\nwith their interests, tasks, and domains. In particular, our paper focuses on\nlarge-scale document retrieval with high recall where any missed relevant\ndocuments can be critical. A simple keyword matching search is generally not\neffective nor efficient as 1) it is difficult to find a list of keyword queries\nthat can cover the documents of interest before exploring the dataset, 2) some\ndocuments may not contain the exact keywords of interest but may still be\nhighly relevant, and 3) some words have multiple meanings, which would result\nin irrelevant documents included in the retrieved subset. In this paper, we\npresent TopicSifter, a visual analytics system for interactive search space\nreduction. Our system utilizes targeted topic modeling based on nonnegative\nmatrix factorization and allows users to give relevance feedback in order to\nrefine their target and guide the topic modeling to the most relevant results.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jul 2019 13:27:18 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Kim", "Hannah", ""], ["Choi", "Dongjin", ""], ["Drake", "Barry", ""], ["Endert", "Alex", ""], ["Park", "Haesun", ""]]}, {"id": "1907.12305", "submitter": "Victor Bouvier", "authors": "Victor Bouvier, Philippe Very, C\\'eline Hudelot, Cl\\'ement Chastagnol", "title": "Learning Invariant Representations for Sentiment Analysis: The Missing\n  Material is Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning representations which remain invariant to a nuisance factor has a\ngreat interest in Domain Adaptation, Transfer Learning, and Fair Machine\nLearning. Finding such representations becomes highly challenging in NLP tasks\nsince the nuisance factor is entangled in a raw text. To our knowledge, a major\nissue is also that only few NLP datasets allow assessing the impact of such\nfactor. In this paper, we introduce two generalization metrics to assess model\nrobustness to a nuisance factor: \\textit{generalization under target bias} and\n\\textit{generalization onto unknown}. We combine those metrics with a simple\ndata filtering approach to control the impact of the nuisance factor on the\ndata and thus to build experimental biased datasets. We apply our method to\nstandard datasets of the literature (\\textit{Amazon} and \\textit{Yelp}). Our\nwork shows that a simple text classification baseline (i.e., sentiment analysis\non reviews) may be badly affected by the \\textit{product ID} (considered as a\nnuisance factor) when learning the polarity of a review. The method proposed is\ngeneric and applicable as soon as the nuisance variable is annotated in the\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 09:44:49 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Bouvier", "Victor", ""], ["Very", "Philippe", ""], ["Hudelot", "C\u00e9line", ""], ["Chastagnol", "Cl\u00e9ment", ""]]}, {"id": "1907.12365", "submitter": "Vikas Kumar", "authors": "Vikas Kumar", "title": "Collaborative Filtering and Multi-Label Classification with Matrix\n  Factorization", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning techniques for Recommendation System (RS) and Classification\nhas become a prime focus of research to tackle the problem of information\noverload. RS are software tools that aim at making informed decisions about the\nservices that a user may like. On the other hand, classification technique\ndeals with the categorization of a data object into one of the several\npredefined classes. In the multi-label classification problem, unlike the\ntraditional multi-class classification setting, each instance can be\nsimultaneously associated with a subset of labels. The focus of thesis is on\nthe development of novel techniques for collaborative filtering and multi-label\nclassification.\n  We propose a novel method of constructing a hierarchical bi-level maximum\nmargin matrix factorization to handle matrix completion of ordinal rating\nmatrix. Taking the cue from the alternative formulation of support vector\nmachines, a novel loss function is derived by considering proximity as an\nalternative criterion instead of margin maximization criterion for matrix\nfactorization framework.\n  We extended the concept of matrix factorization for yet another important\nproblem of machine learning namely multi-label classification which deals with\nthe classification of data with multiple labels. We propose a novel\npiecewise-linear embedding method with a low-rank constraint on parametrization\nto capture nonlinear intrinsic relationships that exist in the original feature\nand label space. We also study the embedding of labels together with the group\ninformation with an objective to build an efficient multi-label classifier. We\nassume the existence of a low-dimensional space onto which the feature vectors\nand label vectors can be embedded. We ensure that labels belonging to the same\ngroup share the same sparsity pattern in their low-rank representations.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 11:39:39 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Kumar", "Vikas", ""]]}, {"id": "1907.12366", "submitter": "Lukas Galke", "authors": "Lukas Galke, Florian Mai, Iacopo Vagliano, Ansgar Scherp", "title": "Multi-Modal Adversarial Autoencoders for Recommendations of Citations\n  and Subject Labels", "comments": "Published in: UMAP '18 Proceedings of the 26th Conference on User\n  Modeling, Adaptation and Personalization Pages 197-205", "journal-ref": null, "doi": "10.1145/3209219.3209236", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present multi-modal adversarial autoencoders for recommendation and\nevaluate them on two different tasks: citation recommendation and subject label\nrecommendation. We analyze the effects of adversarial regularization, sparsity,\nand different input modalities. By conducting 408 experiments, we show that\nadversarial regularization consistently improves the performance of\nautoencoders for recommendation. We demonstrate, however, that the two tasks\ndiffer in the semantics of item co-occurrence in the sense that item\nco-occurrence resembles relatedness in case of citations, yet implies diversity\nin case of subject labels. Our results reveal that supplying the partial item\nset as input is only helpful, when item co-occurrence resembles relatedness.\nWhen facing a new recommendation task it is therefore crucial to consider the\nsemantics of item co-occurrence for the choice of an appropriate model.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 10:23:20 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Galke", "Lukas", ""], ["Mai", "Florian", ""], ["Vagliano", "Iacopo", ""], ["Scherp", "Ansgar", ""]]}, {"id": "1907.12368", "submitter": "Armaan Kaur", "authors": "Armaan Kaur, Jaspal Kaur Saini, Divya Bansal", "title": "Detecting Radical Text over Online Media using Deep Learning", "comments": "The Paper consists of 7 pages with 5 figures. The paper is accepted\n  in Intelligent Information Feed Workshop of 25th ACM SIGKDD Conference 2019\n  for oral presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social Media has influenced the way people socially connect, interact and\nopinionize. The growth in technology has enhanced communication and\ndissemination of information. Unfortunately,many terror groups like jihadist\ncommunities have started consolidating a virtual community online for various\npurposes such as recruitment, online donations, targeting youth online and\nspread of extremist ideologies. Everyday a large number of articles, tweets,\nposts, posters, blogs, comments, views and news are posted online without a\ncheck which in turn imposes a threat to the security of any nation. However,\ndifferent agencies are working on getting down this radical content from\nvarious online social media platforms. The aim of our paper is to utilise deep\nlearning algorithm in detection of radicalization contrary to the existing\nworks based on machine learning algorithms. An LSTM based feed forward neural\nnetwork is employed to detect radical content. We collected total 61601 records\nfrom various online sources constituting news, articles and blogs. These\nrecords are annotated by domain experts into three categories: Radical(R),\nNon-Radical (NR) and Irrelevant(I) which are further applied to LSTM based\nnetwork to classify radical content. A precision of 85.9% has been achieved\nwith the proposed approach\n", "versions": [{"version": "v1", "created": "Mon, 22 Jul 2019 17:27:37 GMT"}, {"version": "v2", "created": "Tue, 30 Jul 2019 19:07:10 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Kaur", "Armaan", ""], ["Saini", "Jaspal Kaur", ""], ["Bansal", "Divya", ""]]}, {"id": "1907.12371", "submitter": "Zhihao Shen", "authors": "Zhihao Shen, Wan Du, Xi Zhao, Jianhua Zou", "title": "Retrieving Similar Trajectories from Cellular Data at City Scale", "comments": "This paper has been submitted to IEEE Transactions on Mobile\n  Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SP cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieving similar trajectories from a large trajectory dataset is important\nfor a variety of applications, like transportation planning and mobility\nanalysis. Unlike previous works based on fine-grained GPS trajectories, this\npaper investigates the feasibility of identifying similar trajectories from\ncellular data observed by mobile infrastructure, which provide more\ncomprehensive coverage. To handle the large localization errors and low sample\nrates of cellular data, we develop a holistic system, cellSim, which seamlessly\nintegrates map matching and similar trajectory search. A set of map matching\ntechniques are proposed to transform cell tower sequences into moving\ntrajectories on a road map by considering the unique features of cellular data,\nlike the dynamic density of cell towers and bidirectional roads. To further\nimprove the accuracy of similarity search, map matching outputs M trajectory\ncandidates of different confidence, and a new similarity measure scheme is\ndeveloped to process the map matching results. Meanwhile, M is dynamically\nadapted to maintain a low false positive rate of the similarity search, and two\npruning schemes are proposed to minimize the computation overhead. Extensive\nexperiments on a large-scale dataset and real-world trajectories of 1701 km\nreveal that cellSim provides high accuracy (precision 62.4% and recall of\n89.8%).\n", "versions": [{"version": "v1", "created": "Sat, 20 Jul 2019 02:33:01 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2019 07:07:09 GMT"}], "update_date": "2019-10-31", "authors_parsed": [["Shen", "Zhihao", ""], ["Du", "Wan", ""], ["Zhao", "Xi", ""], ["Zou", "Jianhua", ""]]}, {"id": "1907.12372", "submitter": "Murium Iqbal", "authors": "Murium Iqbal, Nishan Subedi, Kamelia Aryafar", "title": "Production Ranking Systems: A Review", "comments": "SIGIR eComm Accepted Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of ranking is a multi-billion dollar problem. In this paper we\npresent an overview of several production quality ranking systems. We show that\ndue to conflicting goals of employing the most effective machine learning\nmodels and responding to users in real time, ranking systems have evolved into\na system of systems, where each subsystem can be viewed as a component layer.\nWe view these layers as being data processing, representation learning,\ncandidate selection and online inference. Each layer employs different\nalgorithms and tools, with every end-to-end ranking system spanning multiple\narchitectures. Our goal is to familiarize the general audience with a working\nknowledge of ranking at scale, the tools and algorithms employed and the\nchallenges introduced by adopting a layered approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 19:30:28 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Iqbal", "Murium", ""], ["Subedi", "Nishan", ""], ["Aryafar", "Kamelia", ""]]}, {"id": "1907.12374", "submitter": "Feng Nan", "authors": "Feng Nan, Ran Ding, Ramesh Nallapati, Bing Xiang", "title": "Topic Modeling with Wasserstein Autoencoders", "comments": "In Proceedings of the 57th Annual Meeting of the Association for\n  Computational Linguistics (pp. 6345-6381)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel neural topic model in the Wasserstein autoencoders (WAE)\nframework. Unlike existing variational autoencoder based models, we directly\nenforce Dirichlet prior on the latent document-topic vectors. We exploit the\nstructure of the latent space and apply a suitable kernel in minimizing the\nMaximum Mean Discrepancy (MMD) to perform distribution matching. We discover\nthat MMD performs much better than the Generative Adversarial Network (GAN) in\nmatching high dimensional Dirichlet distribution. We further discover that\nincorporating randomness in the encoder output during training leads to\nsignificantly more coherent topics. To measure the diversity of the produced\ntopics, we propose a simple topic uniqueness metric. Together with the widely\nused coherence measure NPMI, we offer a more wholistic evaluation of topic\nquality. Experiments on several real datasets show that our model produces\nsignificantly better topics than existing topic models.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 14:08:23 GMT"}, {"version": "v2", "created": "Fri, 6 Dec 2019 21:47:06 GMT"}], "update_date": "2019-12-10", "authors_parsed": [["Nan", "Feng", ""], ["Ding", "Ran", ""], ["Nallapati", "Ramesh", ""], ["Xiang", "Bing", ""]]}, {"id": "1907.12375", "submitter": "Boxuan Zhang", "authors": "Wei Zhao, Boxuan Zhang, Beidou Wang, Ziyu Guan, Wanxian Guan, Guang\n  Qiu, Wei Ning, Jiming Chen, Hongmin Liu", "title": "Personalized Attraction Enhanced Sponsored Search with Multi-task\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a novel problem of sponsored search (SS) for E-Commerce platforms:\nhow we can attract query users to click product advertisements (ads) by\npresenting them features of products that attract them. This not only benefits\nmerchants and the platform, but also improves user experience. The problem is\nchallenging due to the following reasons: (1) We need to carefully manipulate\nthe ad content without affecting user search experience. (2) It is difficult to\nobtain users' explicit feedback of their preference in product features. (3)\nNowadays, a great portion of the search traffic in E-Commerce platforms is from\ntheir mobile apps (e.g., nearly 90% in Taobao). The situation would get worse\nin the mobile setting due to limited space. We are focused on the mobile\nsetting and propose to manipulate ad titles by adding a few selling point\nkeywords (SPs) to attract query users. We model it as a personalized attractive\nSP prediction problem and carry out both large-scale offline evaluation and\nonline A/B tests in Taobao. The contributions include: (1) We explore various\nexhibition schemes of SPs. (2) We propose a surrogate of user explicit feedback\nfor SP preference. (3) We also explore multi-task learning and various\nadditional features to boost the performance. A variant of our best model has\nalready been deployed in Taobao, leading to a 2% increase in revenue per\nthousand impressions and an opt-out rate of merchants less than 4%.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 11:00:53 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zhao", "Wei", ""], ["Zhang", "Boxuan", ""], ["Wang", "Beidou", ""], ["Guan", "Ziyu", ""], ["Guan", "Wanxian", ""], ["Qiu", "Guang", ""], ["Ning", "Wei", ""], ["Chen", "Jiming", ""], ["Liu", "Hongmin", ""]]}, {"id": "1907.12377", "submitter": "Jun Zhao", "authors": "Jun Zhao, Zhou Zhou, Ziyu Guan, Wei Zhao, Wei Ning, Guang Qiu, Xiaofei\n  He", "title": "IntentGC: a Scalable Graph Convolution Framework Fusing Heterogeneous\n  Information for Recommendation", "comments": "KDD2019", "journal-ref": null, "doi": "10.1145/3292500.3330686", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The remarkable progress of network embedding has led to state-of-the-art\nalgorithms in recommendation. However, the sparsity of user-item interactions\n(i.e., explicit preferences) on websites remains a big challenge for predicting\nusers' behaviors. Although research efforts have been made in utilizing some\nauxiliary information (e.g., social relations between users) to solve the\nproblem, the existing rich heterogeneous auxiliary relationships are still not\nfully exploited. Moreover, previous works relied on linearly combined\nregularizers and suffered parameter tuning.\n  In this work, we collect abundant relationships from common user behaviors\nand item information, and propose a novel framework named IntentGC to leverage\nboth explicit preferences and heterogeneous relationships by graph\nconvolutional networks. In addition to the capability of modeling\nheterogeneity, IntentGC can learn the importance of different relationships\nautomatically by the neural model in a nonlinear sense. To apply IntentGC to\nweb-scale applications, we design a faster graph convolutional model named\nIntentNet by avoiding unnecessary feature interactions. Empirical experiments\non two large-scale real-world datasets and online A/B tests in Alibaba\ndemonstrate the superiority of our method over state-of-the-art algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 09:09:45 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Zhao", "Jun", ""], ["Zhou", "Zhou", ""], ["Guan", "Ziyu", ""], ["Zhao", "Wei", ""], ["Ning", "Wei", ""], ["Qiu", "Guang", ""], ["He", "Xiaofei", ""]]}, {"id": "1907.12378", "submitter": "Brett Vintch", "authors": "Tim Schmeier, Sam Garrett, Joseph Chisari, and Brett Vintch", "title": "Music Recommendations in Hyperbolic Space: An Application of Empirical\n  Bayes and Hierarchical Poincar\\'e Embeddings", "comments": null, "journal-ref": "Thirteenth ACM Conference on Recommender Systems (RecSys '19),\n  September 16--20, 2019, Copenhagen, Denmark", "doi": "10.1145/3298689.3347029", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix Factorization (MF) is a common method for generating recommendations,\nwhere the proximity of entities like users or items in the embedded space\nindicates their similarity to one another. Though almost all applications\nimplicitly use a Euclidean embedding space to represent two entity types,\nrecent work has suggested that a hyperbolic Poincar\\'e ball may be more well\nsuited to representing multiple entity types, and in particular, hierarchies.\nWe describe a novel method to embed a hierarchy of related music entities in\nhyperbolic space. We also describe how a parametric empirical Bayes approach\ncan be used to estimate link reliability between entities in the hierarchy.\nApplying these methods together to build personalized playlists for users in a\ndigital music service yielded a large and statistically significant increase in\nperformance during an A/B test, as compared to the Euclidean model.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jul 2019 15:53:40 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Schmeier", "Tim", ""], ["Garrett", "Sam", ""], ["Chisari", "Joseph", ""], ["Vintch", "Brett", ""]]}, {"id": "1907.12379", "submitter": "Mengshu Liu", "authors": "Mengshu Liu, Jingya Wang, Kareem Abdelfatah, Mohammed Korayem", "title": "Tripartite Vector Representations for Better Job Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Job recommendation is a crucial part of the online job recruitment business.\nTo match the right person with the right job, a good representation of job\npostings is required. Such representations should ideally recommend jobs with\nfitting titles, aligned skill set, and reasonable commute. To address these\naspects, we utilize three information graphs ( job-job, skill-skill, job-skill)\nfrom historical job data to learn a joint representation for both job titles\nand skills in a shared latent space. This allows us to gain a representation of\njob postings/ resume using both elements, which subsequently can be combined\nwith location. In this paper, we first present how the presentation of each\ncomponent is obtained, and then we discuss how these different representations\nare combined together into one single space to acquire the final\nrepresentation. The results of comparing the proposed methodology against\ndifferent base-line methods show significant improvement in terms of relevancy.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 19:25:35 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Liu", "Mengshu", ""], ["Wang", "Jingya", ""], ["Abdelfatah", "Kareem", ""], ["Korayem", "Mohammed", ""]]}, {"id": "1907.12380", "submitter": "Agnieszka Maria S{\\l}owik", "authors": "Paula Ferm\\'in Cueto, Meeke Roet, Agnieszka S{\\l}owik", "title": "Completing partial recipes using item-based collaborative filtering to\n  recommend ingredients", "comments": "The authors contributed equally", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increased public interest in healthy lifestyles has motivated the study of\nalgorithms that encourage people to follow a healthy diet. Applying\ncollaborative filtering to build recommendation systems in domains where only\nimplicit feedback is available is also a rapidly growing research area. In this\nreport we combine these two trends by developing a recommendation system to\nsuggest ingredients that can be added to a partial recipe. We implement the\nitem-based collaborative filtering algorithm using a high-dimensional, sparse\ndataset of recipes, which inherently contains only implicit feedback. We\nexplore the effect of different similarity measures and dimensionality\nreduction on the quality of the recommendations, and find that our best method\nachieves a recall@10 of circa 40%.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jul 2019 13:42:29 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 16:05:38 GMT"}], "update_date": "2020-02-05", "authors_parsed": [["Cueto", "Paula Ferm\u00edn", ""], ["Roet", "Meeke", ""], ["S\u0142owik", "Agnieszka", ""]]}, {"id": "1907.12384", "submitter": "Olivier Jeunen", "authors": "Olivier Jeunen, David Rohde, Flavian Vasile", "title": "On the Value of Bandit Feedback for Offline Recommender System\n  Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In academic literature, recommender systems are often evaluated on the task\nof next-item prediction. The procedure aims to give an answer to the question:\n\"Given the natural sequence of user-item interactions up to time t, can we\npredict which item the user will interact with at time t+1?\". Evaluation\nresults obtained through said methodology are then used as a proxy to predict\nwhich system will perform better in an online setting. The online setting,\nhowever, poses a subtly different question: \"Given the natural sequence of\nuser-item interactions up to time t, can we get the user to interact with a\nrecommended item at time t+1?\". From a causal perspective, the system performs\nan intervention, and we want to measure its effect. Next-item prediction is\noften used as a fall-back objective when information about interventions and\ntheir effects (shown recommendations and whether they received a click) is\nunavailable. When this type of data is available, however, it can provide great\nvalue for reliably estimating online recommender system performance. Through a\nseries of simulated experiments with the RecoGym environment, we show where\ntraditional offline evaluation schemes fall short. Additionally, we show how\nso-called bandit feedback can be exploited for effective offline evaluation\nthat more accurately reflects online performance.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jul 2019 12:50:50 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Jeunen", "Olivier", ""], ["Rohde", "David", ""], ["Vasile", "Flavian", ""]]}, {"id": "1907.12388", "submitter": "Murium Iqbal", "authors": "Murium Iqbal, Kamelia Aryafar, Timothy Anderton", "title": "Style Conditioned Recommendations", "comments": "9 pages, 10 figures, Accepted to RecSys '19", "journal-ref": null, "doi": "10.1145/3298689.3347007", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Style Conditioned Recommendations (SCR) and introduce style\ninjection as a method to diversify recommendations. We use Conditional\nVariational Autoencoder (CVAE) architecture, where both the encoder and decoder\nare conditioned on a user profile learned from item content data. This allows\nus to apply style transfer methodologies to the task of recommendations, which\nwe refer to as injection. To enable style injection, user profiles are learned\nto be interpretable such that they express users' propensities for specific\npredefined styles. These are learned via label-propagation from a dataset of\nitem content, with limited labeled points. To perform injection, the condition\non the encoder is learned while the condition on the decoder is selected per\nexplicit feedback. Explicit feedback can be taken either from a user's response\nto a style or interest quiz, or from item ratings. In the absence of explicit\nfeedback, the condition at the encoder is applied to the decoder. We show a 12%\nimprovement on NDCG@20 over the traditional VAE based approach and an average\n22% improvement on AUC across all classes for predicting user style profiles\nagainst our best performing baseline. After injecting styles we compare the\nuser style profile to the style of the recommendations and show that injected\nstyles have an average +133% increase in presence. Our results show that style\ninjection is a powerful method to diversify recommendations while maintaining\npersonal relevance. Our main contribution is an application of a\nsemi-supervised approach that extends item labels to interpretable user\nprofiles.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jul 2019 15:43:12 GMT"}, {"version": "v2", "created": "Mon, 5 Aug 2019 15:51:51 GMT"}], "update_date": "2019-08-06", "authors_parsed": [["Iqbal", "Murium", ""], ["Aryafar", "Kamelia", ""], ["Anderton", "Timothy", ""]]}, {"id": "1907.12404", "submitter": "Michaela Regneri", "authors": "Michaela Regneri, Julia S. Georgi, Jurij Kost, Niklas Pietsch, and\n  Sabine Stamm", "title": "Computing the Value of Data: Towards Applied Data Minimalism", "comments": null, "journal-ref": "Second International Workshop on Energy Efficient Scalable Data\n  Mining and Machine Learning (Green Data Mining 2019)", "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to compute the monetary value of individual data\npoints, in context of an automated decision system. The proposed method enables\nus to explore and implement a paradigm of data minimalism for large-scale\nmachine learning systems. Data minimalistic implementations enhance\nscalability, while maintaining or even optimizing a system's performance. Using\ntwo types of recommender systems, we first demonstrate how much data is\nineffective in both settings. We then present a general account of computing\ndata value via sensitivity analysis, and how, in theory, individual data points\ncan be priced according to their informational contribution to automated\ndecisions. We further exemplify this method to lab-scale recommender systems\nand outline further steps towards commercial data-minimalistic applications.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 13:08:22 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Regneri", "Michaela", ""], ["Georgi", "Julia S.", ""], ["Kost", "Jurij", ""], ["Pietsch", "Niklas", ""], ["Stamm", "Sabine", ""]]}, {"id": "1907.12490", "submitter": "Rongcheng Tu", "authors": "Rong-Cheng Tu, Xian-Ling Mao, Bing Ma, Yong Hu, Tan Yan, Wei Wei and\n  Heyan Huang", "title": "Deep Cross-Modal Hashing with Hashing Functions and Unified Hash Codes\n  Jointly Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their high retrieval efficiency and low storage cost, cross-modal\nhashing methods have attracted considerable attention. Generally, compared with\nshallow cross-modal hashing methods, deep cross-modal hashing methods can\nachieve a more satisfactory performance by integrating feature learning and\nhash codes optimizing into a same framework. However, most existing deep\ncross-modal hashing methods either cannot learn a unified hash code for the two\ncorrelated data-points of different modalities in a database instance or cannot\nguide the learning of unified hash codes by the feedback of hashing function\nlearning procedure, to enhance the retrieval accuracy. To address the issues\nabove, in this paper, we propose a novel end-to-end Deep Cross-Modal Hashing\nwith Hashing Functions and Unified Hash Codes Jointly Learning (DCHUC).\nSpecifically, by an iterative optimization algorithm, DCHUC jointly learns\nunified hash codes for image-text pairs in a database and a pair of hash\nfunctions for unseen query image-text pairs. With the iterative optimization\nalgorithm, the learned unified hash codes can be used to guide the hashing\nfunction learning procedure; Meanwhile, the learned hashing functions can\nfeedback to guide the unified hash codes optimizing procedure. Extensive\nexperiments on three public datasets demonstrate that the proposed method\noutperforms the state-of-the-art cross-modal hashing methods.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jul 2019 15:39:37 GMT"}], "update_date": "2019-07-30", "authors_parsed": [["Tu", "Rong-Cheng", ""], ["Mao", "Xian-Ling", ""], ["Ma", "Bing", ""], ["Hu", "Yong", ""], ["Yan", "Tan", ""], ["Wei", "Wei", ""], ["Huang", "Heyan", ""]]}, {"id": "1907.12697", "submitter": "Feng Wei", "authors": "Feng Wei, Uyen Trang Nguyen, Hui Jiang", "title": "Dual-FOFE-net Neural Models for Entity Linking with PageRank", "comments": "ICANN 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a simple and computationally efficient approach for\nentity linking (EL), compared with recurrent neural networks (RNNs) or\nconvolutional neural networks (CNNs), by making use of feedforward neural\nnetworks (FFNNs) and the recent dual fixed-size ordinally forgetting encoding\n(dual-FOFE) method to fully encode the sentence fragment and its left/right\ncontexts into a fixed-size representation. Furthermore, in this work, we\npropose to incorporate PageRank based distillation in our candidate generation\nmodule. Our neural linking models consist of three parts: a PageRank based\ncandidate generation module, a dual-FOFE-net neural ranking model and a simple\nNIL entity clustering system. Experimental results have shown that our proposed\nneural linking models achieved higher EL accuracy than state-of-the-art models\non the TAC2016 task dataset over the baseline system, without requiring any\nin-house data or complicated handcrafted features. Moreover, it achieves a\ncompetitive accuracy on the TAC2017 task dataset.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 01:37:34 GMT"}], "update_date": "2019-07-31", "authors_parsed": [["Wei", "Feng", ""], ["Nguyen", "Uyen Trang", ""], ["Jiang", "Hui", ""]]}, {"id": "1907.13158", "submitter": "Himan Abdollahpouri", "authors": "Himan Abdollahpouri and Robin Burke", "title": "Multi-stakeholder Recommendation and its Connection to Multi-sided\n  Fairness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is growing research interest in recommendation as a multi-stakeholder\nproblem, one where the interests of multiple parties should be taken into\naccount. This category subsumes some existing well-established areas of\nrecommendation research including reciprocal and group recommendation, but a\ndetailed taxonomy of different classes of multi-stakeholder recommender systems\nis still lacking. Fairness-aware recommendation has also grown as a research\narea, but its close connection with multi-stakeholder recommendation is not\nalways recognized. In this paper, we define the most commonly observed classes\nof multi-stakeholder recommender systems and discuss how different fairness\nconcerns may come into play in such systems.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jul 2019 18:08:48 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Abdollahpouri", "Himan", ""], ["Burke", "Robin", ""]]}, {"id": "1907.13264", "submitter": "Shaikh Arifuzzaman", "authors": "Janak Dahal, Elias Ioup, Shaikh Arifuzzaman, Mahdi Abdelguerfi", "title": "Distributed Streaming Analytics on Large-scale Oceanographic Data using\n  Apache Spark", "comments": "Preprint, 12 pages, Big Data and Scalable Computing (BDSC) research\n  group, Computer Science, University of New Orleans", "journal-ref": null, "doi": null, "report-no": "BDSC-19-01-01", "categories": "cs.DC cs.DB cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Real-world data from diverse domains require real-time scalable analysis.\nLarge-scale data processing frameworks or engines such as Hadoop fall short\nwhen results are needed on-the-fly. Apache Spark's streaming library is\nincreasingly becoming a popular choice as it can stream and analyze a\nsignificant amount of data. In this paper, we analyze large-scale geo-temporal\ndata collected from the USGODAE (United States Global Ocean Data Assimilation\nExperiment) data catalog, and showcase and assess the ability of Spark stream\nprocessing. We measure the latency of streaming and monitor scalability by\nadding and removing nodes in the middle of a streaming job. We also verify the\nfault tolerance by stopping nodes in the middle of a job and making sure that\nthe job is rescheduled and completed on other nodes. We design a full-stack\napplication that automates data collection, data processing and visualizing the\nresults. We also use Google Maps API to visualize results by color coding the\nworld map with values from various analytics.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 00:00:53 GMT"}, {"version": "v2", "created": "Thu, 1 Aug 2019 01:18:03 GMT"}], "update_date": "2019-08-02", "authors_parsed": [["Dahal", "Janak", ""], ["Ioup", "Elias", ""], ["Arifuzzaman", "Shaikh", ""], ["Abdelguerfi", "Mahdi", ""]]}, {"id": "1907.13286", "submitter": "Himan Abdollahpouri", "authors": "Himan Abdollahpouri, Masoud Mansoury, Robin Burke, Bamshad Mobasher", "title": "The Unfairness of Popularity Bias in Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are known to suffer from the popularity bias problem:\npopular (i.e. frequently rated) items get a lot of exposure while less popular\nones are under-represented in the recommendations. Research in this area has\nbeen mainly focusing on finding ways to tackle this issue by increasing the\nnumber of recommended long-tail items or otherwise the overall catalog\ncoverage. In this paper, however, we look at this problem from the users'\nperspective: we want to see how popularity bias causes the recommendations to\ndeviate from what the user expects to get from the recommender system. We\ndefine three different groups of users according to their interest in popular\nitems (Niche, Diverse and Blockbuster-focused) and show the impact of\npopularity bias on the users in each group. Our experimental results on a movie\ndataset show that in many recommendation algorithms the recommendations the\nusers get are extremely concentrated on popular items even if a user is\ninterested in long-tail and non-popular items showing an extreme bias\ndisparity.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 02:23:52 GMT"}, {"version": "v2", "created": "Mon, 26 Aug 2019 20:46:55 GMT"}, {"version": "v3", "created": "Thu, 19 Sep 2019 13:50:40 GMT"}], "update_date": "2019-09-20", "authors_parsed": [["Abdollahpouri", "Himan", ""], ["Mansoury", "Masoud", ""], ["Burke", "Robin", ""], ["Mobasher", "Bamshad", ""]]}, {"id": "1907.13304", "submitter": "Zekun Li", "authors": "Zekun Li, Zeyu Cui, Shu Wu, Xiaoyu Zhang, Liang Wang", "title": "Semi-supervised Compatibility Learning Across Categories for Clothing\n  Matching", "comments": "6 pages, 4 figures, accepted by ICME2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning the compatibility between fashion items across categories is a key\ntask in fashion analysis, which can decode the secret of clothing matching. The\nmain idea of this task is to map items into a latent style space where\ncompatible items stay close. Previous works try to build such a transformation\nby minimizing the distances between annotated compatible items, which require\nmassive item-level supervision. However, these annotated data are expensive to\nobtain and hard to cover the numerous items with various styles in real\napplications. In such cases, these supervised methods fail to achieve\nsatisfactory performances. In this work, we propose a semi-supervised method to\nlearn the compatibility across categories. We observe that the distributions of\ndifferent categories have intrinsic similar structures. Accordingly, the better\ndistributions align, the closer compatible items across these categories\nbecome. To achieve the alignment, we minimize the distances between\ndistributions with unsupervised adversarial learning, and also the distances\nbetween some annotated compatible items which play the role of anchor points to\nhelp align. Experimental results on two real-world datasets demonstrate the\neffectiveness of our method.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 04:45:34 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Li", "Zekun", ""], ["Cui", "Zeyu", ""], ["Wu", "Shu", ""], ["Zhang", "Xiaoyu", ""], ["Wang", "Liang", ""]]}, {"id": "1907.13376", "submitter": "Hossein A. Rahmani", "authors": "Hossein A. Rahmani, Mohammad Aliannejadi, Rasoul Mirzaei Zadeh, Mitra\n  Baratchi, Mohsen Afsharchi, Fabio Crestani", "title": "Category-Aware Location Embedding for Point-of-Interest Recommendation", "comments": "4 pages, 1 figures", "journal-ref": null, "doi": "10.1145/3341981.3344240 10.1145/3341981.3344240 10.1145/3341981.3344240", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, Point of interest (POI) recommendation has gained ever-increasing\nimportance in various Location-Based Social Networks (LBSNs). With the recent\nadvances of neural models, much work has sought to leverage neural networks to\nlearn neural embeddings in a pre-training phase that achieve an improved\nrepresentation of POIs and consequently a better recommendation. However,\nprevious studies fail to capture crucial information about POIs such as\ncategorical information.\n  In this paper, we propose a novel neural model that generates a POI embedding\nincorporating sequential and categorical information from POIs. Our model\nconsists of a check-in module and a category module. The check-in module\ncaptures the geographical influence of POIs derived from the sequence of users'\ncheck-ins, while the category module captures the characteristics of POIs\nderived from the category information. To validate the efficacy of the model,\nwe experimented with two large-scale LBSN datasets. Our experimental results\ndemonstrate that our approach significantly outperforms state-of-the-art POI\nrecommendation methods.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 09:14:16 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Rahmani", "Hossein A.", ""], ["Aliannejadi", "Mohammad", ""], ["Zadeh", "Rasoul Mirzaei", ""], ["Baratchi", "Mitra", ""], ["Afsharchi", "Mohsen", ""], ["Crestani", "Fabio", ""]]}, {"id": "1907.13561", "submitter": "Vahab Mostafapour", "authors": "Vahab Mostafapour, O\\u{g}uz Dikenelli", "title": "Attention-Wrapped Hierarchical BLSTMs for DDI Extraction", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Drug-Drug Interactions (DDIs) Extraction refers to the efforts to generate\nhand-made or automatic tools to extract embedded information from text and\nliterature in the biomedical domain.\n  Because of restrictions in hand-made efforts and their lower speed,\nMachine-Learning, or Deep-Learning approaches have become more popular for\nextracting DDIs. In this study, we propose a novel and generic Deep-Learning\nmodel which wraps Hierarchical Bidirectional LSTMs with two Attention\nMechanisms that outperforms state-of-the-art models for DDIs Extraction, based\non the DDIExtraction-2013 corpora. This model has obtained the macro F1-score\nof 0.785, and the precision of 0.80.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jul 2019 15:42:26 GMT"}], "update_date": "2019-08-01", "authors_parsed": [["Mostafapour", "Vahab", ""], ["Dikenelli", "O\u011fuz", ""]]}]