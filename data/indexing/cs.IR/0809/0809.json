[{"id": "0809.0124", "submitter": "Peter Turney", "authors": "Peter D. Turney (National Research Council of Canada)", "title": "A Uniform Approach to Analogies, Synonyms, Antonyms, and Associations", "comments": "related work available at http://purl.org/peter.turney/", "journal-ref": "Proceedings of the 22nd International Conference on Computational\n  Linguistics (Coling 2008), August 2008, Manchester, UK, Pages 905-912", "doi": null, "report-no": "NRC 50398", "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recognizing analogies, synonyms, antonyms, and associations appear to be four\ndistinct tasks, requiring distinct NLP algorithms. In the past, the four tasks\nhave been treated independently, using a wide variety of algorithms. These four\nsemantic classes, however, are a tiny sample of the full range of semantic\nphenomena, and we cannot afford to create ad hoc algorithms for each semantic\nphenomenon; we need to seek a unified approach. We propose to subsume a broad\nrange of phenomena under analogies. To limit the scope of this paper, we\nrestrict our attention to the subsumption of synonyms, antonyms, and\nassociations. We introduce a supervised corpus-based machine learning algorithm\nfor classifying analogous word pairs, and we show that it can solve\nmultiple-choice SAT analogy questions, TOEFL synonym questions, ESL\nsynonym-antonym questions, and similar-associated-both questions from cognitive\npsychology.\n", "versions": [{"version": "v1", "created": "Sun, 31 Aug 2008 14:00:26 GMT"}], "update_date": "2008-09-02", "authors_parsed": [["Turney", "Peter D.", "", "National Research Council of Canada"]]}, {"id": "0809.0680", "submitter": "Paul Fodor", "authors": "Paul Fodor, Adam Lally, David Ferrucci", "title": "The Prolog Interface to the Unstructured Information Management\n  Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe the design and implementation of the Prolog\ninterface to the Unstructured Information Management Architecture (UIMA) and\nsome of its applications in natural language processing. The UIMA Prolog\ninterface translates unstructured data and the UIMA Common Analysis Structure\n(CAS) into a Prolog knowledge base, over which, the developers write rules and\nuse resolution theorem proving to search and generate new annotations over the\nunstructured data. These rules can explore all the previous UIMA annotations\n(such as, the syntactic structure, parsing statistics) and external Prolog\nknowledge bases (such as, Prolog WordNet and Extended WordNet) to implement a\nvariety of tasks for the natural language analysis. We also describe\napplications of this logic programming interface in question analysis (such as,\nfocus detection, answer-type and other constraints detection), shallow parsing\n(such as, relations in the syntactic structure), and answer selection.\n", "versions": [{"version": "v1", "created": "Wed, 3 Sep 2008 17:38:32 GMT"}], "update_date": "2008-09-04", "authors_parsed": [["Fodor", "Paul", ""], ["Lally", "Adam", ""], ["Ferrucci", "David", ""]]}, {"id": "0809.0723", "submitter": "L.T. Handoko", "authors": "Z. Akbar and L.T. Handoko", "title": "A Simple Mechanism for Focused Web-harvesting", "comments": "6 pages, 4 figures, Proceeding of the International Conference on\n  Advanced Computational Intelligence and Its Applications 2008", "journal-ref": null, "doi": null, "report-no": "FISIKALIPI-08079", "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focused web-harvesting is deployed to realize an automated and\ncomprehensive index databases as an alternative way for virtual topical data\nintegration. The web-harvesting has been implemented and extended by not only\nspecifying the targeted URLs, but also predefining human-edited harvesting\nparameters to improve the speed and accuracy. The harvesting parameter set\ncomprises three main components. First, the depth-scale of being harvested\nfinal pages containing desired information counted from the first page at the\ntargeted URLs. Secondly, the focus-point number to determine the exact box\ncontaining relevant information. Lastly, the combination of keywords to\nrecognize encountered hyperlinks of relevant images or full-texts embedded in\nthose final pages. All parameters are accessible and fully customizable for\neach target by the administrators of participating institutions over an\nintegrated web interface. A real implementation to the Indonesian Scientific\nIndex which covers all scientific information across Indonesia is also briefly\nintroduced.\n", "versions": [{"version": "v1", "created": "Wed, 3 Sep 2008 23:53:29 GMT"}], "update_date": "2008-09-05", "authors_parsed": [["Akbar", "Z.", ""], ["Handoko", "L. T.", ""]]}, {"id": "0809.2553", "submitter": "Paul Vitanyi", "authors": "Paul M.B. Vitanyi (CWI and Univ. Amsterdam), Frank J. Balbach (Univ.\n  Waterloo), Rudi L. Cilibrasi (CWI), and Ming Li (Univ. Waterloo)", "title": "Normalized Information Distance", "comments": "33 pages, 12 figures, pdf, in: Normalized information distance, in:\n  Information Theory and Statistical Learning, Eds. M. Dehmer, F.\n  Emmert-Streib, Springer-Verlag, New-York, To appear", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The normalized information distance is a universal distance measure for\nobjects of all kinds. It is based on Kolmogorov complexity and thus\nuncomputable, but there are ways to utilize it. First, compression algorithms\ncan be used to approximate the Kolmogorov complexity if the objects have a\nstring representation. Second, for names and abstract concepts, page count\nstatistics from the World Wide Web can be used. These practical realizations of\nthe normalized information distance can then be applied to machine learning\ntasks, expecially clustering, to perform feature-free and parameter-free data\nmining. This chapter discusses the theoretical foundations of the normalized\ninformation distance and both practical realizations. It presents numerous\nexamples of successful real-world applications based on these distance\nmeasures, ranging from bioinformatics to music clustering to machine\ntranslation.\n", "versions": [{"version": "v1", "created": "Mon, 15 Sep 2008 15:33:11 GMT"}], "update_date": "2008-09-16", "authors_parsed": [["Vitanyi", "Paul M. B.", "", "CWI and Univ. Amsterdam"], ["Balbach", "Frank J.", "", "Univ.\n  Waterloo"], ["Cilibrasi", "Rudi L.", "", "CWI"], ["Li", "Ming", "", "Univ. Waterloo"]]}, {"id": "0809.3447", "submitter": "Manas Tungare", "authors": "Manas Tungare, Manuel Perez-Quinones, Alyssa Sams", "title": "An Exploratory Study of Calendar Use", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we report on findings from an ethnographic study of how people\nuse their calendars for personal information management (PIM). Our participants\nwere faculty, staff and students who were not required to use or contribute to\nany specific calendaring solution, but chose to do so anyway. The study was\nconducted in three parts: first, an initial survey provided broad insights into\nhow calendars were used; second, this was followed up with personal interviews\nof a few participants which were transcribed and content-analyzed; and third,\nexamples of calendar artifacts were collected to inform our analysis. Findings\nfrom our study include the use of multiple reminder alarms, the reliance on\npaper calendars even among regular users of electronic calendars, and wide use\nof calendars for reporting and life-archival purposes. We conclude the paper\nwith a discussion of what these imply for designers of interactive calendar\nsystems and future work in PIM research.\n", "versions": [{"version": "v1", "created": "Fri, 19 Sep 2008 19:56:15 GMT"}], "update_date": "2008-09-22", "authors_parsed": [["Tungare", "Manas", ""], ["Perez-Quinones", "Manuel", ""], ["Sams", "Alyssa", ""]]}, {"id": "0809.4530", "submitter": "Olena Medelyan", "authors": "Olena Medelyan, David Milne, Catherine Legg and Ian H. Witten", "title": "Mining Meaning from Wikipedia", "comments": "An extensive survey of re-using information in Wikipedia in natural\n  language processing, information retrieval and extraction and ontology\n  building. Accepted for publication in International Journal of Human-Computer\n  Studies", "journal-ref": null, "doi": null, "report-no": "ISSN 1177-777X", "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia is a goldmine of information; not just for its many readers, but\nalso for the growing community of researchers who recognize it as a resource of\nexceptional scale and utility. It represents a vast investment of manual effort\nand judgment: a huge, constantly evolving tapestry of concepts and relations\nthat is being applied to a host of tasks.\n  This article provides a comprehensive description of this work. It focuses on\nresearch that extracts and makes use of the concepts, relations, facts and\ndescriptions found in Wikipedia, and organizes the work into four broad\ncategories: applying Wikipedia to natural language processing; using it to\nfacilitate information retrieval and information extraction; and as a resource\nfor ontology building. The article addresses how Wikipedia is being used as is,\nhow it is being improved and adapted, and how it is being combined with other\nstructures to create entirely new resources. We identify the research groups\nand individuals involved, and how their work has developed in the last few\nyears. We provide a comprehensive list of the open-source software they have\nproduced.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2008 04:47:19 GMT"}, {"version": "v2", "created": "Sun, 10 May 2009 01:51:15 GMT"}], "update_date": "2009-05-10", "authors_parsed": [["Medelyan", "Olena", ""], ["Milne", "David", ""], ["Legg", "Catherine", ""], ["Witten", "Ian H.", ""]]}, {"id": "0809.4668", "submitter": "Jose Ignacio Alvarez-Hamelin", "authors": "Jose Ignacio Orlicki (CoreLabs, ITBA), Pablo Ignacio Fierens (ITBA),\n  Jos\\'e Ignacio Alvarez-Hamelin (ITBA, CONICET)", "title": "Faceted Ranking of Egos in Collaborative Tagging Systems", "comments": null, "journal-ref": "WEBIST 2009, Lisboa : Portugal (2009)", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimedia uploaded content is tagged and recommended by users of\ncollaborative systems, resulting in informal classifications also known as\nfolksonomies. Faceted web ranking has been proved a reasonable alternative to a\nsingle ranking which does not take into account a personalized context. In this\npaper we analyze the online computation of rankings of users associated to\nfacets made up of multiple tags. Possible applications are user reputation\nevaluation (ego-ranking) and improvement of content quality in case of\nretrieval. We propose a solution based on PageRank as centrality measure: (i) a\nranking for each tag is computed offline on the basis of the corresponding\ntag-dependent subgraph; (ii) a faceted order is generated by merging rankings\ncorresponding to all the tags in the facet. The fundamental assumption,\nvalidated by empirical observations, is that step (i) is scalable. We also\npresent algorithms for part (ii) having time complexity O(k), where k is the\nnumber of tags in the facet, well suited to online computation.\n", "versions": [{"version": "v1", "created": "Fri, 26 Sep 2008 16:26:50 GMT"}], "update_date": "2009-03-21", "authors_parsed": [["Orlicki", "Jose Ignacio", "", "CoreLabs, ITBA"], ["Fierens", "Pablo Ignacio", "", "ITBA"], ["Alvarez-Hamelin", "Jos\u00e9 Ignacio", "", "ITBA, CONICET"]]}, {"id": "0809.4834", "submitter": "Luis Paulo Reis", "authors": "Jose Torres, Luis Paulo Reis", "title": "Relevance Feedback in Conceptual Image Retrieval: A User Evaluation", "comments": "15 Pages, 20 References", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Visual Object Information Retrieval (VOIR) system described in this paper\nimplements an image retrieval approach that combines two layers, the conceptual\nand the visual layer. It uses terms from a textual thesaurus to represent the\nconceptual information and also works with image regions, the visual\ninformation. The terms are related with the image regions through a weighted\nassociation enabling the execution of concept-level queries. VOIR uses\nregion-based relevance feedback to improve the quality of the results in each\nquery session and to discover new associations between text and image. This\npaper describes a user-centred and task-oriented comparative evaluation of VOIR\nwhich was undertaken considering three distinct versions of VOIR: a full-fledge\nversion; one supporting relevance feedback only at image level; and a third\nversion not supporting relevance feedback at all. The evaluation performed\nshowed the usefulness of region based relevance feedback in the context of VOIR\nprototype.\n", "versions": [{"version": "v1", "created": "Sun, 28 Sep 2008 10:17:20 GMT"}], "update_date": "2008-09-30", "authors_parsed": [["Torres", "Jose", ""], ["Reis", "Luis Paulo", ""]]}]