[{"id": "1707.00093", "submitter": "Robin Burke", "authors": "Robin Burke", "title": "Multisided Fairness for Recommendation", "comments": "Presented as a poster at the 2017 Workshop on Fairness,\n  Accountability, and Transparency in Machine Learning (FAT/ML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work on machine learning has begun to consider issues of fairness. In\nthis paper, we extend the concept of fairness to recommendation. In particular,\nwe show that in some recommendation contexts, fairness may be a multisided\nconcept, in which fair outcomes for multiple individuals need to be considered.\nBased on these considerations, we present a taxonomy of classes of\nfairness-aware recommender systems and suggest possible fairness-aware\nrecommendation architectures.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 04:14:02 GMT"}, {"version": "v2", "created": "Sat, 8 Jul 2017 12:13:59 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Burke", "Robin", ""]]}, {"id": "1707.00189", "submitter": "Sean MacAvaney", "authors": "Sean MacAvaney, Andrew Yates, Kai Hui, Ophir Frieder", "title": "Content-Based Weak Supervision for Ad-Hoc Re-Ranking", "comments": "SIGIR 2019 (short paper)", "journal-ref": null, "doi": "10.1145/3331184.3331316", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One challenge with neural ranking is the need for a large amount of\nmanually-labeled relevance judgments for training. In contrast with prior work,\nwe examine the use of weak supervision sources for training that yield pseudo\nquery-document pairs that already exhibit relevance (e.g., newswire\nheadline-content pairs and encyclopedic heading-paragraph pairs). We also\npropose filtering techniques to eliminate training samples that are too far out\nof domain using two techniques: a heuristic-based approach and novel supervised\nfilter that re-purposes a neural ranker. Using several leading neural ranking\narchitectures and multiple weak supervision datasets, we show that these\nsources of training pairs are effective on their own (outperforming prior weak\nsupervision techniques), and that filtering can further improve performance.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jul 2017 18:42:29 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 12:05:43 GMT"}, {"version": "v3", "created": "Fri, 5 Jul 2019 12:00:09 GMT"}], "update_date": "2019-07-08", "authors_parsed": [["MacAvaney", "Sean", ""], ["Yates", "Andrew", ""], ["Hui", "Kai", ""], ["Frieder", "Ophir", ""]]}, {"id": "1707.00331", "submitter": "Gerasimos Spanakis", "authors": "Sankalp Prabhakar, Gerasimos Spanakis, Osmar Zaiane", "title": "Reciprocal Recommender System for Learners in Massive Open Online\n  Courses (MOOCs)", "comments": "10 pages, accepted as full paper @ ICWL 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Massive open online courses (MOOC) describe platforms where users with\ncompletely different backgrounds subscribe to various courses on offer. MOOC\nforums and discussion boards offer learners a medium to communicate with each\nother and maximize their learning outcomes. However, oftentimes learners are\nhesitant to approach each other for different reasons (being shy, don't know\nthe right match, etc.). In this paper, we propose a reciprocal recommender\nsystem which matches learners who are mutually interested in, and likely to\ncommunicate with each other based on their profile attributes like age,\nlocation, gender, qualification, interests, etc. We test our algorithm on data\nsampled using the publicly available MITx-Harvardx dataset and demonstrate that\nboth attribute importance and reciprocity play an important role in forming the\nfinal recommendation list of learners. Our approach provides promising results\nfor such a system to be implemented within an actual MOOC.\n", "versions": [{"version": "v1", "created": "Sun, 2 Jul 2017 18:13:50 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Prabhakar", "Sankalp", ""], ["Spanakis", "Gerasimos", ""], ["Zaiane", "Osmar", ""]]}, {"id": "1707.00469", "submitter": "Simone Faro", "authors": "Domenico Cantone, Simone Faro and Arianna Pavone", "title": "Speeding Up String Matching by Weak Factor Recognition", "comments": "11 pages, appeared in proceedings of the Prague Stringology\n  Conference 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String matching is the problem of finding all the substrings of a text which\nmatch a given pattern. It is one of the most investigated problems in computer\nscience, mainly due to its very diverse applications in several fields.\nRecently, much research in the string matching field has focused on the\nefficiency and flexibility of the searching procedure and quite effective\ntechniques have been proposed for speeding up the existing solutions. In this\ncontext, algorithms based on factors recognition are among the best solutions.\nIn this paper, we present a simple and very efficient algorithm for string\nmatching based on a weak factor recognition and hashing. Our algorithm has a\nquadratic worst-case running time. However, despite its quadratic complexity,\nexperimental results show that our algorithm obtains in most cases the best\nrunning times when compared, under various conditions, against the most\neffective algorithms present in literature. In the case of small alphabets and\nlong patterns, the gain in running times reaches 28%. This makes our proposed\nalgorithm one of the most flexible solutions in practical cases.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 10:03:35 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Cantone", "Domenico", ""], ["Faro", "Simone", ""], ["Pavone", "Arianna", ""]]}, {"id": "1707.00506", "submitter": "Ana Freire", "authors": "Akshay Kumar Chaturvedi, Filipa Peleja, Ana Freire", "title": "Recommender System for News Articles using Supervised Learning", "comments": "36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade we have observed a mass increase of information, in\nparticular information that is shared through smartphones. Consequently, the\namount of information that is available does not allow the average user to be\naware of all his options. In this context, recommender systems use a number of\ntechniques to help a user find the desired product. Hence, nowadays recommender\nsystems play an important role. Recommender Systems' aim to identify products\nthat best fits user preferences. These techniques are advantageous to both\nusers and vendors, as it enables the user to rapidly find what he needs and the\nvendors to promote their products and sales. As the industry became aware of\nthe gains that could be accomplished by using these algorithms, also a very\ninteresting problem for many researchers, recommender systems became a very\nactive area since the mid 90's. Having in mind that this is an ongoing problem\nthe present thesis intends to observe the value of using a recommender\nalgorithm to find users likes by observing her domain preferences. In a\nbalanced probabilistic method, this thesis will show how news topics can be\nused to recommend news articles. In this thesis, we used different machine\nlearning methods to determine the user ratings for an article. To tackle this\nproblem, supervised learning methods such as linear regression, Naive Bayes and\nlogistic regression are used. All the aforementioned models have a different\nnature which has an impact on the solution of the given problem. Furthermore,\nnumber of experiments are presented and discussed to identify the feature set\nthat fits best to the problem.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 12:27:17 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Chaturvedi", "Akshay Kumar", ""], ["Peleja", "Filipa", ""], ["Freire", "Ana", ""]]}, {"id": "1707.00536", "submitter": "Peng Yang", "authors": "Peng Yang, Peilin Zhao, Xin Gao, Yong Liu", "title": "Robust Cost-Sensitive Learning for Recommendation with Implicit Feedback", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation is the task of improving customer experience through\npersonalized recommendation based on users' past feedback. In this paper, we\ninvestigate the most common scenario: the user-item (U-I) matrix of implicit\nfeedback. Even though many recommendation approaches are designed based on\nimplicit feedback, they attempt to project the U-I matrix into a low-rank\nlatent space, which is a strict restriction that rarely holds in practice. In\naddition, although misclassification costs from imbalanced classes are\nsignificantly different, few methods take the cost of classification error into\naccount. To address aforementioned issues, we propose a robust framework by\ndecomposing the U-I matrix into two components: (1) a low-rank matrix that\ncaptures the common preference, and (2) a sparse matrix that detects the\nuser-specific preference of individuals. A cost-sensitive learning model is\nembedded into the framework. Specifically, this model exploits different costs\nin the loss function for the observed and unobserved instances. We show that\nthe resulting non-smooth convex objective can be optimized efficiently by an\naccelerated projected gradient method with closed-form solutions. Morever, the\nproposed algorithm can be scaled up to large-sized datasets after a relaxation.\nThe theoretical result shows that even with a small fraction of 1's in the U-I\nmatrix $M\\in\\mathbb{R}^{n\\times m}$, the cost-sensitive error of the proposed\nmodel is upper bounded by $O(\\frac{\\alpha}{\\sqrt{mn}})$, where $\\alpha$ is a\nbias over imbalanced classes. Finally, empirical experiments are extensively\ncarried out to evaluate the effectiveness of our proposed algorithm.\nEncouraging experimental results show that our algorithm outperforms several\nstate-of-the-art algorithms on benchmark recommendation datasets.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jul 2017 13:27:56 GMT"}, {"version": "v2", "created": "Thu, 20 Jul 2017 07:02:49 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Yang", "Peng", ""], ["Zhao", "Peilin", ""], ["Gao", "Xin", ""], ["Liu", "Yong", ""]]}, {"id": "1707.00800", "submitter": "Mahmoud Mousa", "authors": "Mahmoud A. A. Mousa, Mohammed S. Sayed and Mahmoud I. Abdalla", "title": "Arabic Character Segmentation Using Projection Based Approach with\n  Profile's Amplitude Filter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arabic is one of the languages that present special challenges to Optical\ncharacter recognition (OCR). The main challenge in Arabic is that it is mostly\ncursive. Therefore, a segmentation process must be carried out to determine\nwhere the character begins and where it ends. This step is essential for\ncharacter recognition. This paper presents Arabic character segmentation\nalgorithm. The proposed algorithm uses the projection-based approach concepts\nto separate lines, words, and characters. This is done using profile's\namplitude filter and simple edge tool to find characters separations. Our\nalgorithm shows promising performance when applied on different machine printed\ndocuments with different Arabic fonts.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 02:29:07 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Mousa", "Mahmoud A. A.", ""], ["Sayed", "Mohammed S.", ""], ["Abdalla", "Mahmoud I.", ""]]}, {"id": "1707.00972", "submitter": "David Sears", "authors": "Ali Nikrang, David R. W. Sears, and Gerhard Widmer", "title": "Automatic estimation of harmonic tension by distributed representation\n  of chords", "comments": "12 pages, 4 figures. To appear in Proceedings of the 13th\n  International Symposium on Computer Music Multidisciplinary Research (CMMR),\n  Porto, Portugal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The buildup and release of a sense of tension is one of the most essential\naspects of the process of listening to music. A veridical computational model\nof perceived musical tension would be an important ingredient for many music\ninformatics applications. The present paper presents a new approach to\nmodelling harmonic tension based on a distributed representation of chords. The\nstarting hypothesis is that harmonic tension as perceived by human listeners is\nrelated, among other things, to the expectedness of harmonic units (chords) in\ntheir local harmonic context. We train a word2vec-type neural network to learn\na vector space that captures contextual similarity and expectedness, and define\na quantitative measure of harmonic tension on top of this. To assess the\nveridicality of the model, we compare its outputs on a number of well-defined\nchord classes and cadential contexts to results from pertinent empirical\nstudies in music psychology. Statistical analysis shows that the model's\npredictions conform very well with empirical evidence obtained from human\nlisteners.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jul 2017 13:31:34 GMT"}], "update_date": "2017-07-05", "authors_parsed": [["Nikrang", "Ali", ""], ["Sears", "David R. W.", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1707.01238", "submitter": "Manajit Chakraborty", "authors": "Kshitij Singh, Manajit Chakraborty and C. Ravindranath Chowdary", "title": "R-Rec: A rule-based system for contextual suggestion using\n  tag-description similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contextual Suggestion deals with search techniques for complex information\nneeds that are highly focused on context and user needs. In this paper, we\npropose \\emph{R-Rec}, a novel rule-based technique to identify and recommend\nappropriate points-of-interest to a user given her past preferences. We try to\nembody the information that the user shares in the form of rating and tags of\nany previous point(s)-of-interest and use it to rank the unrated candidate\nsuggestions. The ranking function is computed based on the similarity between a\nsuggestion and the places that the user like and the dissimilarity between the\nsuggestion and the places disliked by the user. Experiments carried out on\nTREC-Contextual Suggestion 2015 dataset reveal the efficacy of our method.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 07:32:52 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Singh", "Kshitij", ""], ["Chakraborty", "Manajit", ""], ["Chowdary", "C. Ravindranath", ""]]}, {"id": "1707.01250", "submitter": "Shlomo Berkovsky", "authors": "Amit Tiroshi, Tsvi Kuflik, Shlomo Berkovsky, Mohamed Ali Kaafar", "title": "Graph Based Recommendations: From Data Representation to Feature\n  Extraction and Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling users for the purpose of identifying their preferences and then\npersonalizing services on the basis of these models is a complex task,\nprimarily due to the need to take into consideration various explicit and\nimplicit signals, missing or uncertain information, contextual aspects, and\nmore. In this study, a novel generic approach for uncovering latent preference\npatterns from user data is proposed and evaluated. The approach relies on\nrepresenting the data using graphs, and then systematically extracting\ngraph-based features and using them to enrich the original user models. The\nextracted features encapsulate complex relationships between users, items, and\nmetadata. The enhanced user models can then serve as an input to any\nrecommendation algorithm. The proposed approach is domain-independent\n(demonstrated on data from movies, music, and business recommender systems),\nand is evaluated using several state-of-the-art machine learning methods, on\ndifferent recommendation tasks, and using different evaluation metrics. The\nresults show a unanimous improvement in the recommendation accuracy across\ntasks and domains. In addition, the evaluation provides a deeper analysis\nregarding the performance of the approach in special scenarios, including high\nsparsity and variability of ratings.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 08:08:21 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Tiroshi", "Amit", ""], ["Kuflik", "Tsvi", ""], ["Berkovsky", "Shlomo", ""], ["Kaafar", "Mohamed Ali", ""]]}, {"id": "1707.01389", "submitter": "Ladislav Peska", "authors": "Ladislav Peska and Hana Trojanova", "title": "Towards Recommender Systems for Police Photo Lineup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Photo lineups play a significant role in the eyewitness identification\nprocess. This method is used to provide evidence in the prosecution and\nsubsequent conviction of suspects. Unfortunately, there are many cases where\nlineups have led to the conviction of an innocent suspect. One of the key\nfactors affecting the incorrect identification of a suspect is the lack of\nlineup fairness, i.e. that the suspect differs significantly from all other\ncandidates. Although the process of assembling fair lineup is both highly\nimportant and time-consuming, only a handful of tools are available to simplify\nthe task. In this paper, we describe our work towards using recommender systems\nfor the photo lineup assembling task. We propose and evaluate two complementary\nmethods for item-based recommendation: one based on the visual descriptors of\nthe deep neural network, the other based on the content-based attributes of\npersons. The initial evaluation made by forensic technicians shows that\nalthough results favored visual descriptors over attribute-based similarity,\nboth approaches are functional and highly diverse in terms of recommended\nobjects. Thus, future work should involve incorporating both approaches in a\nsingle prediction method, preference learning based on the feedback from\nforensic technicians and recommendation of assembled lineups instead of single\ncandidates.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 13:38:07 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Peska", "Ladislav", ""], ["Trojanova", "Hana", ""]]}, {"id": "1707.01425", "submitter": "Souvick Ghosh", "authors": "Souvick Ghosh, Dipankar Das and Tanmoy Chakraborty", "title": "Determining sentiment in citation text and analyzing its impact on the\n  proposed ranking index", "comments": "Sentiment Analysis, Citation, Citation Sentiment Analysis, Citation\n  Polarity, Ranking, Bibliometrics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whenever human beings interact with each other, they exchange or express\nopinions, emotions, and sentiments. These opinions can be expressed in text,\nspeech or images. Analysis of these sentiments is one of the popular research\nareas of present day researchers. Sentiment analysis, also known as opinion\nmining tries to identify or classify these sentiments or opinions into two\nbroad categories - positive and negative. In recent years, the scientific\ncommunity has taken a lot of interest in analyzing sentiment in textual data\navailable in various social media platforms. Much work has been done on social\nmedia conversations, blog posts, newspaper articles and various narrative\ntexts. However, when it comes to identifying emotions from scientific papers,\nresearchers have faced some difficulties due to the implicit and hidden nature\nof opinion. By default, citation instances are considered inherently positive\nin emotion. Popular ranking and indexing paradigms often neglect the opinion\npresent while citing. In this paper, we have tried to achieve three objectives.\nFirst, we try to identify the major sentiment in the citation text and assign a\nscore to the instance. We have used a statistical classifier for this purpose.\nSecondly, we have proposed a new index (we shall refer to it hereafter as\nM-index) which takes into account both the quantitative and qualitative factors\nwhile scoring a paper. Thirdly, we developed a ranking of research papers based\non the M-index. We also try to explain how the M-index impacts the ranking of\nscientific papers.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jul 2017 15:03:30 GMT"}], "update_date": "2017-07-06", "authors_parsed": [["Ghosh", "Souvick", ""], ["Das", "Dipankar", ""], ["Chakraborty", "Tanmoy", ""]]}, {"id": "1707.01780", "submitter": "Jose Camacho-Collados", "authors": "Jose Camacho-Collados and Mohammad Taher Pilehvar", "title": "On the Role of Text Preprocessing in Neural Network Architectures: An\n  Evaluation Study on Text Categorization and Sentiment Analysis", "comments": "Blackbox EMNLP 2018. 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text preprocessing is often the first step in the pipeline of a Natural\nLanguage Processing (NLP) system, with potential impact in its final\nperformance. Despite its importance, text preprocessing has not received much\nattention in the deep learning literature. In this paper we investigate the\nimpact of simple text preprocessing decisions (particularly tokenizing,\nlemmatizing, lowercasing and multiword grouping) on the performance of a\nstandard neural text classifier. We perform an extensive evaluation on standard\nbenchmarks from text categorization and sentiment analysis. While our\nexperiments show that a simple tokenization of input text is generally\nadequate, they also highlight significant degrees of variability across\npreprocessing techniques. This reveals the importance of paying attention to\nthis usually-overlooked step in the pipeline, particularly when comparing\ndifferent models. Finally, our evaluation provides insights into the best\npreprocessing practices for training word embeddings.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 13:31:13 GMT"}, {"version": "v2", "created": "Fri, 7 Jul 2017 09:41:25 GMT"}, {"version": "v3", "created": "Thu, 23 Aug 2018 10:05:33 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Camacho-Collados", "Jose", ""], ["Pilehvar", "Mohammad Taher", ""]]}, {"id": "1707.01890", "submitter": "Gaurav Trivedi", "authors": "Gaurav Trivedi, Phuong Pham, Wendy Chapman, Rebecca Hwa, Janyce Wiebe,\n  Harry Hochheiser", "title": "An Interactive Tool for Natural Language Processing on Clinical Text", "comments": "8 pages, 2 figures, 2 tables, Presented at IUI TextVis 2015 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Natural Language Processing (NLP) systems often make use of machine learning\ntechniques that are unfamiliar to end-users who are interested in analyzing\nclinical records. Although NLP has been widely used in extracting information\nfrom clinical text, current systems generally do not support model revision\nbased on feedback from domain experts.\n  We present a prototype tool that allows end users to visualize and review the\noutputs of an NLP system that extracts binary variables from clinical text. Our\ntool combines multiple visualizations to help the users understand these\nresults and make any necessary corrections, thus forming a feedback loop and\nhelping improve the accuracy of the NLP models. We have tested our prototype in\na formative think-aloud user study with clinicians and researchers involved in\ncolonoscopy research. Results from semi-structured interviews and a System\nUsability Scale (SUS) analysis show that the users are able to quickly start\nrefining NLP models, despite having very little or no experience with machine\nlearning. Observations from these sessions suggest revisions to the interface\nto better support review workflow and interpretation of results.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 17:44:15 GMT"}, {"version": "v2", "created": "Fri, 7 Jul 2017 14:04:13 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Trivedi", "Gaurav", ""], ["Pham", "Phuong", ""], ["Chapman", "Wendy", ""], ["Hwa", "Rebecca", ""], ["Wiebe", "Janyce", ""], ["Hochheiser", "Harry", ""]]}, {"id": "1707.01917", "submitter": "Madhav Nimishakavi Mr", "authors": "Madhav Nimishakavi and Partha Talukdar", "title": "Higher-order Relation Schema Induction using Tensor Factorization with\n  Back-off and Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relation Schema Induction (RSI) is the problem of identifying type signatures\nof arguments of relations from unlabeled text. Most of the previous work in\nthis area have focused only on binary RSI, i.e., inducing only the subject and\nobject type signatures per relation. However, in practice, many relations are\nhigh-order, i.e., they have more than two arguments and inducing type\nsignatures of all arguments is necessary. For example, in the sports domain,\ninducing a schema win(WinningPlayer, OpponentPlayer, Tournament, Location) is\nmore informative than inducing just win(WinningPlayer, OpponentPlayer). We\nrefer to this problem as Higher-order Relation Schema Induction (HRSI). In this\npaper, we propose Tensor Factorization with Back-off and Aggregation (TFBA), a\nnovel framework for the HRSI problem. To the best of our knowledge, this is the\nfirst attempt at inducing higher-order relation schemata from unlabeled text.\nUsing the experimental analysis on three real world datasets, we show how TFBA\nhelps in dealing with sparsity and induce higher order schemata.\n", "versions": [{"version": "v1", "created": "Thu, 6 Jul 2017 18:02:12 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 10:45:46 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Nimishakavi", "Madhav", ""], ["Talukdar", "Partha", ""]]}, {"id": "1707.02260", "submitter": "L. Elisa Celis", "authors": "L. Elisa Celis and Nisheeth K. Vishnoi", "title": "Fair Personalization", "comments": "To appear at FAT/ML 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DS cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization is pervasive in the online space as, when combined with\nlearning, it leads to higher efficiency and revenue by allowing the most\nrelevant content to be served to each user. However, recent studies suggest\nthat such personalization can propagate societal or systemic biases, which has\nled to calls for regulatory mechanisms and algorithms to combat inequality.\nHere we propose a rigorous algorithmic framework that allows for the\npossibility to control biased or discriminatory personalization with respect to\nsensitive attributes of users without losing all of the benefits of\npersonalization.\n", "versions": [{"version": "v1", "created": "Fri, 7 Jul 2017 16:40:06 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Celis", "L. Elisa", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1707.02410", "submitter": "Ruining He", "authors": "Ruining He and Wang-Cheng Kang and Julian McAuley", "title": "Translation-based Recommendation", "comments": "9 pages, 5 figures", "journal-ref": null, "doi": "10.1145/3109859.3109882", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling the complex interactions between users and items as well as amongst\nitems themselves is at the core of designing successful recommender systems.\nOne classical setting is predicting users' personalized sequential behavior (or\n`next-item' recommendation), where the challenges mainly lie in modeling\n`third-order' interactions between a user, her previously visited item(s), and\nthe next item to consume. Existing methods typically decompose these\nhigher-order interactions into a combination of pairwise relationships, by way\nof which user preferences (user-item interactions) and sequential patterns\n(item-item interactions) are captured by separate components. In this paper, we\npropose a unified method, TransRec, to model such third-order relationships for\nlarge-scale sequential prediction. Methodologically, we embed items into a\n`transition space' where users are modeled as translation vectors operating on\nitem sequences. Empirically, this approach outperforms the state-of-the-art on\na wide spectrum of real-world datasets. Data and code are available at\nhttps://sites.google.com/a/eng.ucsd.edu/ruining-he/.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jul 2017 07:51:28 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["He", "Ruining", ""], ["Kang", "Wang-Cheng", ""], ["McAuley", "Julian", ""]]}, {"id": "1707.02459", "submitter": "Jian Ni", "authors": "Jian Ni and Radu Florian", "title": "Improving Multilingual Named Entity Recognition with Wikipedia Entity\n  Type Mapping", "comments": "11 pages, Conference on Empirical Methods in Natural Language\n  Processing (EMNLP), 2016", "journal-ref": null, "doi": "10.18653/v1/D16-1135", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art named entity recognition (NER) systems are statistical\nmachine learning models that have strong generalization capability (i.e., can\nrecognize unseen entities that do not appear in training data) based on lexical\nand contextual information. However, such a model could still make mistakes if\nits features favor a wrong entity type. In this paper, we utilize Wikipedia as\nan open knowledge base to improve multilingual NER systems. Central to our\napproach is the construction of high-accuracy, high-coverage multilingual\nWikipedia entity type mappings. These mappings are built from weakly annotated\ndata and can be extended to new languages with no human annotation or\nlanguage-dependent knowledge involved. Based on these mappings, we develop\nseveral approaches to improve an NER system. We evaluate the performance of the\napproaches via experiments on NER systems trained for 6 languages. Experimental\nresults show that the proposed approaches are effective in improving the\naccuracy of such systems on unseen entities, especially when a system is\napplied to a new domain or it is trained with little training data (up to 18.3\nF1 score improvement).\n", "versions": [{"version": "v1", "created": "Sat, 8 Jul 2017 16:17:04 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Ni", "Jian", ""], ["Florian", "Radu", ""]]}, {"id": "1707.02483", "submitter": "Jian Ni", "authors": "Jian Ni and Georgiana Dinu and Radu Florian", "title": "Weakly Supervised Cross-Lingual Named Entity Recognition via Effective\n  Annotation and Representation Projection", "comments": "11 pages, The 55th Annual Meeting of the Association for\n  Computational Linguistics (ACL), 2017", "journal-ref": null, "doi": "10.18653/v1/P17-1135", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The state-of-the-art named entity recognition (NER) systems are supervised\nmachine learning models that require large amounts of manually annotated data\nto achieve high accuracy. However, annotating NER data by human is expensive\nand time-consuming, and can be quite difficult for a new language. In this\npaper, we present two weakly supervised approaches for cross-lingual NER with\nno human annotation in a target language. The first approach is to create\nautomatically labeled NER data for a target language via annotation projection\non comparable corpora, where we develop a heuristic scheme that effectively\nselects good-quality projection-labeled data from noisy data. The second\napproach is to project distributed representations of words (word embeddings)\nfrom a target language to a source language, so that the source-language NER\nsystem can be applied to the target language without re-training. We also\ndesign two co-decoding schemes that effectively combine the outputs of the two\nprojection-based approaches. We evaluate the performance of the proposed\napproaches on both in-house and open NER data for several target languages. The\nresults show that the combined systems outperform three other weakly supervised\napproaches on the CoNLL data.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jul 2017 19:45:47 GMT"}], "update_date": "2019-11-04", "authors_parsed": [["Ni", "Jian", ""], ["Dinu", "Georgiana", ""], ["Florian", "Radu", ""]]}, {"id": "1707.02494", "submitter": "Philipp Mayr", "authors": "Ameni Kacem, Philipp Mayr", "title": "Analysis of Footnote Chasing and Citation Searching in an Academic\n  Search Engine", "comments": "10 pages, 2 figures, paper accepted at the Bibliometric-enhanced\n  Information Retrieval and Natural Language Processing for Digital Libraries\n  (BIRNDL) workshop at SIGIR 2017. arXiv admin note: text overlap with\n  arXiv:1706.00816", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In interactive information retrieval, researchers consider the user behavior\ntowards systems and search tasks in order to adapt search results by analyzing\ntheir past interactions. In this paper, we analyze the user behavior towards\nMarcia Bates' search stratagems such as 'footnote chasing' and 'citation\nsearch' in an academic search engine. We performed a preliminary analysis of\ntheir frequency and stage of use in the social sciences search engine sowiport.\nIn addition, we explored the impact of these stratagems on the whole search\nprocess performance. We can conclude that the appearance of these two search\nfeatures in real retrieval sessions lead to an improvement of the precision in\nterms of positive interactions with 16% when using footnote chasing and 17% for\nthe citation search stratagem.\n", "versions": [{"version": "v1", "created": "Sat, 8 Jul 2017 20:45:50 GMT"}, {"version": "v2", "created": "Sat, 23 Sep 2017 19:58:09 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Kacem", "Ameni", ""], ["Mayr", "Philipp", ""]]}, {"id": "1707.02546", "submitter": "Angelos Valsamis", "authors": "Fotis Aisopos, Angelos Valsamis, Alexandros Psychas, Andreas\n  Menychtas, Theodora Varvarigou", "title": "Efficient Context Management and Personalized User Recommendations in a\n  Smart Social TV environment", "comments": "In GECON2016, 13th International Conference on Economics of Grids,\n  Clouds, Systems, and Services, September 20-22, 2016, Harokopio University,\n  Athens, Greece", "journal-ref": null, "doi": "10.1007/978-3-319-61920-0_8", "report-no": null, "categories": "cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of Smart TV and related interconnected devices, second\nscreen solutions have rapidly appeared to provide more content for end-users\nand enrich their TV experience. Given the various data and sources involved -\nvideos, actors, social media and online databases- the aforementioned market\nposes great challenges concerning user context management and sophisticated\nrecommendations that can be addressed to the end-users. This paper presents an\ninnovative Context Management model and a related first and second screen\nrecommendation service, based on a user-item graph analysis as well as\ncollaborative filtering techniques in the context of a Dynamic Social & Media\nContent Syndication (SAM) platform. The model evaluation provided is based on\ndatasets collected online, presenting a comparative analysis concerning\nefficiency and effectiveness of the current approach, and illustrating its\nadded value.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 09:19:21 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Aisopos", "Fotis", ""], ["Valsamis", "Angelos", ""], ["Psychas", "Alexandros", ""], ["Menychtas", "Andreas", ""], ["Varvarigou", "Theodora", ""]]}, {"id": "1707.02581", "submitter": "Xavier Gir\\'o-i-Nieto", "authors": "Albert Jimenez, Jose M. Alvarez and Xavier Giro-i-Nieto", "title": "Class-Weighted Convolutional Features for Visual Instance Search", "comments": "To appear in the British Machine Vision Conference (BMVC), September\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image retrieval in realistic scenarios targets large dynamic datasets of\nunlabeled images. In these cases, training or fine-tuning a model every time\nnew images are added to the database is neither efficient nor scalable.\nConvolutional neural networks trained for image classification over large\ndatasets have been proven effective feature extractors for image retrieval. The\nmost successful approaches are based on encoding the activations of\nconvolutional layers, as they convey the image spatial information. In this\npaper, we go beyond this spatial information and propose a local-aware encoding\nof convolutional features based on semantic information predicted in the target\nimage. To this end, we obtain the most discriminative regions of an image using\nClass Activation Maps (CAMs). CAMs are based on the knowledge contained in the\nnetwork and therefore, our approach, has the additional advantage of not\nrequiring external information. In addition, we use CAMs to generate object\nproposals during an unsupervised re-ranking stage after a first fast search.\nOur experiments on two public available datasets for instance retrieval,\nOxford5k and Paris6k, demonstrate the competitiveness of our approach\noutperforming the current state-of-the-art when using off-the-shelf models\ntrained on ImageNet. The source code and model used in this paper are publicly\navailable at http://imatge-upc.github.io/retrieval-2017-cam/.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jul 2017 13:51:45 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Jimenez", "Albert", ""], ["Alvarez", "Jose M.", ""], ["Giro-i-Nieto", "Xavier", ""]]}, {"id": "1707.02919", "submitter": "Mehdi Allahyari", "authors": "Mehdi Allahyari, Seyedamin Pouriyeh, Mehdi Assefi, Saied Safaei,\n  Elizabeth D. Trippe, Juan B. Gutierrez, Krys Kochut", "title": "A Brief Survey of Text Mining: Classification, Clustering and Extraction\n  Techniques", "comments": "some of References format have updated", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of text that is generated every day is increasing dramatically.\nThis tremendous volume of mostly unstructured text cannot be simply processed\nand perceived by computers. Therefore, efficient and effective techniques and\nalgorithms are required to discover useful patterns. Text mining is the task of\nextracting meaningful information from text, which has gained significant\nattentions in recent years. In this paper, we describe several of the most\nfundamental text mining tasks and techniques including text pre-processing,\nclassification and clustering. Additionally, we briefly explain text mining in\nbiomedical and health care domains.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jul 2017 16:02:44 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 16:32:25 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Allahyari", "Mehdi", ""], ["Pouriyeh", "Seyedamin", ""], ["Assefi", "Mehdi", ""], ["Safaei", "Saied", ""], ["Trippe", "Elizabeth D.", ""], ["Gutierrez", "Juan B.", ""], ["Kochut", "Krys", ""]]}, {"id": "1707.03217", "submitter": "Gregor Wiedemann", "authors": "Gregor Wiedemann, Andreas Niekler", "title": "Document Retrieval for Large Scale Content Analysis using Contextualized\n  Dictionaries", "comments": "https://hal.archives-ouvertes.fr/hal-01005879; Proceedings of\n  Terminology and Knowledge Engineering 2014 (TKE'14), Berlin", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a procedure to retrieve subsets of relevant documents\nfrom large text collections for Content Analysis, e.g. in social sciences.\nDocument retrieval for this purpose needs to take account of the fact that\nanalysts often cannot describe their research objective with a small set of key\nterms, especially when dealing with theoretical or rather abstract research\ninterests. Instead, it is much easier to define a set of paradigmatic documents\nwhich reflect topics of interest as well as targeted manner of speech. Thus, in\ncontrast to classic information retrieval tasks we employ manually compiled\ncollections of reference documents to compose large queries of several hundred\nkey terms, called dictionaries. We extract dictionaries via Topic Models and\nalso use co-occurrence data from reference collections. Evaluations show that\nthe procedure improves retrieval results for this purpose compared to\nalternative methods of key term extraction as well as neglecting co-occurrence\ndata.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 11:00:44 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Wiedemann", "Gregor", ""], ["Niekler", "Andreas", ""]]}, {"id": "1707.03334", "submitter": "Jun Sakuma", "authors": "Jun Sakuma, Tatsuya Osame", "title": "Recommendation with k-anonymized Ratings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are widely used to predict personalized preferences of\ngoods or services using users' past activities, such as item ratings or\npurchase histories. If collections of such personal activities were made\npublicly available, they could be used to personalize a diverse range of\nservices, including targeted advertisement or recommendations. However, there\nwould be an accompanying risk of privacy violations. The pioneering work of\nNarayanan et al.\\ demonstrated that even if the identifiers are eliminated, the\npublic release of user ratings can allow for the identification of users by\nthose who have only a small amount of data on the users' past ratings.\n  In this paper, we assume the following setting. A collector collects user\nratings, then anonymizes and distributes them. A recommender constructs a\nrecommender system based on the anonymized ratings provided by the collector.\nBased on this setting, we exhaustively list the models of recommender systems\nthat use anonymized ratings. For each model, we then present an item-based\ncollaborative filtering algorithm for making recommendations based on\nanonymized ratings. Our experimental results show that an item-based\ncollaborative filtering based on anonymized ratings can perform better than\ncollaborative filterings based on 5--10 non-anonymized ratings. This surprising\nresult indicates that, in some settings, privacy protection does not\nnecessarily reduce the usefulness of recommendations. From the experimental\nanalysis of this counterintuitive result, we observed that the sparsity of the\nratings can be reduced by anonymization and the variance of the prediction can\nbe reduced if $k$, the anonymization parameter, is appropriately tuned. In this\nway, the predictive performance of recommendations based on anonymized ratings\ncan be improved in some settings.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 07:21:25 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Sakuma", "Jun", ""], ["Osame", "Tatsuya", ""]]}, {"id": "1707.03367", "submitter": "Jorge Lloret-Gazo", "authors": "Jorge Lloret-Gazo", "title": "Wextractor: Follow-up of the evolution of prices in web pages", "comments": "12 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the e-commerce world, the follow-up of prices in detail web pages is of\ngreat interest for things like buying a product when it falls below some\nthreshold. For doing this task, instead of bookmarking the pages and revisiting\nthem, in this paper we propose a novel web data extraction system, called\nWextractor. It consists of an extraction method and a web app for listing the\nretrieved prices. As for the final user, the main feature of Wextractor is\nusability because (s)he only has to signal the pages of interest and our system\nautomatically extracts the price from the page.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 17:12:50 GMT"}], "update_date": "2017-07-12", "authors_parsed": [["Lloret-Gazo", "Jorge", ""]]}, {"id": "1707.03423", "submitter": "Kyle Yingkai Gao", "authors": "Kyle Yingkai Gao, Jamie Callan", "title": "Scientific Table Search Using Keyword Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tables are common and important in scientific documents, yet most text-based\ndocument search systems do not capture structures and semantics specific to\ntables. How to bridge different types of mismatch between keywords queries and\nscientific tables and what influences ranking quality needs to be carefully\ninvestigated. This paper considers the structure of tables and gives different\nemphasis to table components. On the query side, thanks to external knowledge\nsuch as knowledge bases and ontologies, key concepts are extracted and used to\nbuild structured queries, and target quantity types are identified and used to\nexpand original queries. A probabilistic framework is proposed to incorporate\nstructural and semantic information from both query and table sides. We also\nconstruct and release TableArXiv, a high quality dataset with 105 queries and\ncorresponding relevance judgements for scientific table search. Experiments\ndemonstrate significantly higher accuracy overall and at the top of the\nrankings than several baseline methods.\n", "versions": [{"version": "v1", "created": "Tue, 11 Jul 2017 18:30:42 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Gao", "Kyle Yingkai", ""], ["Callan", "Jamie", ""]]}, {"id": "1707.03569", "submitter": "Georgios Balikas", "authors": "Georgios Balikas, Simon Moura, Massih-Reza Amini", "title": "Multitask Learning for Fine-Grained Twitter Sentiment Analysis", "comments": "International ACM SIGIR Conference on Research and Development in\n  Information Retrieval 2017", "journal-ref": null, "doi": "10.1145/3077136.3080702", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional sentiment analysis approaches tackle problems like ternary\n(3-category) and fine-grained (5-category) classification by learning the tasks\nseparately. We argue that such classification tasks are correlated and we\npropose a multitask approach based on a recurrent neural network that benefits\nby jointly learning them. Our study demonstrates the potential of multitask\nmodels on this type of problems and improves the state-of-the-art results in\nthe fine-grained sentiment classification problem.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 07:17:50 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Balikas", "Georgios", ""], ["Moura", "Simon", ""], ["Amini", "Massih-Reza", ""]]}, {"id": "1707.03602", "submitter": "Serkan Ayvaz", "authors": "Serkan Ayvaz, Mehmet Aydar", "title": "Using RDF Summary Graph For Keyword-based Semantic Searches", "comments": "5th International Conference on Advanced Technology & Sciences\n  (ICAT'17). Istanbul, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Semantic Web began to emerge as its standards and technologies developed\nrapidly in the recent years. The continuing development of Semantic Web\ntechnologies has facilitated publishing explicit semantics with data on the Web\nin RDF data model. This study proposes a semantic search framework to support\nefficient keyword-based semantic search on RDF data utilizing near neighbor\nexplorations. The framework augments the search results with the resources in\nclose proximity by utilizing the entity type semantics. Along with the search\nresults, the system generates a relevance confidence score measuring the\ninferred semantic relatedness of returned entities based on the degree of\nsimilarity. Furthermore, the evaluations assessing the effectiveness of the\nframework and the accuracy of the results are presented.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 08:54:48 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Ayvaz", "Serkan", ""], ["Aydar", "Mehmet", ""]]}, {"id": "1707.03659", "submitter": "Helene Perrin", "authors": "Helene Perrin, Marion Denorme, Julien Grosjean, OMICtools community,\n  Emeric Dynomant, Vincent J. Henry, Fabien Pichon, Stefan Darmoni, Arnaud\n  Desfeux, Bruno J. Gonzalez", "title": "OMICtools: a community-driven search engine for biological data analysis", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR q-bio.QM", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  With high-throughput biotechnologies generating unprecedented quantities of\ndata, researchers are faced with the challenge of locating and comparing an\nexponentially growing number of programs and websites dedicated to\ncomputational biology, in order to maximize the potential of their data.\nOMICtools is designed to meet this need with its open-access search engine\noffering an easy means of locating the right tools corresponding to each\nresearcher and their specific biological data analyses. The OMICtools website\n(https://OMICtools.com) centralizes more than 18,500 software tools and\ndatabases, manually classified, by a team of biocurators including many\nscientific experts. Key information, a direct link, and access to discussions\nand evaluations by the biomedical community are provided for each tool. Anyone\ncan join the OMICtools community and create a profile page, to share their\nexpertise and comment on tools. In addition, developers can directly upload\ntheir code versions which are registered for identification and citation in\nscientific publications, improving research traceability. The OMICtools\ncommunity links thousands of life scientists and developers worldwide, who use\nthis bioinformatics platform to accelerate their projects and biological data\nanalyses.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 11:59:47 GMT"}], "update_date": "2017-07-13", "authors_parsed": [["Perrin", "Helene", ""], ["Denorme", "Marion", ""], ["Grosjean", "Julien", ""], ["community", "OMICtools", ""], ["Dynomant", "Emeric", ""], ["Henry", "Vincent J.", ""], ["Pichon", "Fabien", ""], ["Darmoni", "Stefan", ""], ["Desfeux", "Arnaud", ""], ["Gonzalez", "Bruno J.", ""]]}, {"id": "1707.03904", "submitter": "Bhuwan Dhingra", "authors": "Bhuwan Dhingra, Kathryn Mazaitis and William W. Cohen", "title": "Quasar: Datasets for Question Answering by Search and Reading", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two new large-scale datasets aimed at evaluating systems designed\nto comprehend a natural language query and extract its answer from a large\ncorpus of text. The Quasar-S dataset consists of 37000 cloze-style\n(fill-in-the-gap) queries constructed from definitions of software entity tags\non the popular website Stack Overflow. The posts and comments on the website\nserve as the background corpus for answering the cloze questions. The Quasar-T\ndataset consists of 43000 open-domain trivia questions and their answers\nobtained from various internet sources. ClueWeb09 serves as the background\ncorpus for extracting these answers. We pose these datasets as a challenge for\ntwo related subtasks of factoid Question Answering: (1) searching for relevant\npieces of text that include the correct answer to a query, and (2) reading the\nretrieved text to answer the query. We also describe a retrieval system for\nextracting relevant sentences and documents from the corpus given a query, and\ninclude these in the release for researchers wishing to only focus on (2). We\nevaluate several baselines on both datasets, ranging from simple heuristics to\npowerful neural models, and show that these lag behind human performance by\n16.4% and 32.1% for Quasar-S and -T respectively. The datasets are available at\nhttps://github.com/bdhingra/quasar .\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 20:53:26 GMT"}, {"version": "v2", "created": "Wed, 9 Aug 2017 01:48:08 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Dhingra", "Bhuwan", ""], ["Mazaitis", "Kathryn", ""], ["Cohen", "William W.", ""]]}, {"id": "1707.04242", "submitter": "Christophe Van Gysel", "authors": "Tom Kenter, Alexey Borisov, Christophe Van Gysel, Mostafa Dehghani,\n  Maarten de Rijke, Bhaskar Mitra", "title": "Neural Networks for Information Retrieval", "comments": "Overview of full-day tutorial at SIGIR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning plays a role in many aspects of modern IR systems, and deep\nlearning is applied in all of them. The fast pace of modern-day research has\ngiven rise to many different approaches for many different IR problems. The\namount of information available can be overwhelming both for junior students\nand for experienced researchers looking for new research topics and directions.\nAdditionally, it is interesting to see what key insights into IR problems the\nnew technologies are able to give us. The aim of this full-day tutorial is to\ngive a clear overview of current tried-and-trusted neural methods in IR and how\nthey benefit IR research. It covers key architectures, as well as the most\npromising future directions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 17:46:59 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Kenter", "Tom", ""], ["Borisov", "Alexey", ""], ["Van Gysel", "Christophe", ""], ["Dehghani", "Mostafa", ""], ["de Rijke", "Maarten", ""], ["Mitra", "Bhaskar", ""]]}, {"id": "1707.04244", "submitter": "Preeti Bhargava", "authors": "Preeti Bhargava and Nemanja Spasojevic and Guoning Hu", "title": "Lithium NLP: A System for Rich Information Extraction from Noisy User\n  Generated Text on Social Media", "comments": "9 pages, 6 figures, 2 tables, EMNLP 2017 Workshop on Noisy User\n  Generated Text WNUT 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe the Lithium Natural Language Processing (NLP)\nsystem - a resource-constrained, high- throughput and language-agnostic system\nfor information extraction from noisy user generated text on social media.\nLithium NLP extracts a rich set of information including entities, topics,\nhashtags and sentiment from text. We discuss several real world applications of\nthe system currently incorporated in Lithium products. We also compare our\nsystem with existing commercial and academic NLP systems in terms of\nperformance, information extracted and languages supported. We show that\nLithium NLP is at par with and in some cases, outperforms state- of-the-art\ncommercial NLP systems.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jul 2017 17:52:51 GMT"}], "update_date": "2017-07-14", "authors_parsed": [["Bhargava", "Preeti", ""], ["Spasojevic", "Nemanja", ""], ["Hu", "Guoning", ""]]}, {"id": "1707.04457", "submitter": "David Sears", "authors": "David R. W. Sears, Andreas Arzt, Harald Frostel, Reinhard Sonnleitner,\n  and Gerhard Widmer", "title": "Modeling Harmony with Skip-Grams", "comments": "7 pages, 5 figures. To appear in Proceedings of the 18th\n  International Society for Music Information Retrieval Conference (ISMIR),\n  Suzhou, China", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String-based (or viewpoint) models of tonal harmony often struggle with data\nsparsity in pattern discovery and prediction tasks, particularly when modeling\ncomposite events like triads and seventh chords, since the number of distinct\nn-note combinations in polyphonic textures is potentially enormous. To address\nthis problem, this study examines the efficacy of skip-grams in music research,\nan alternative viewpoint method developed in corpus linguistics and natural\nlanguage processing that includes sub-sequences of n events (or n-grams) in a\nfrequency distribution if their constituent members occur within a certain\nnumber of skips.\n  Using a corpus consisting of four datasets of Western classical music in\nsymbolic form, we found that including skip-grams reduces data sparsity in\nn-gram distributions by (1) minimizing the proportion of n-grams with\nnegligible counts, and (2) increasing the coverage of contiguous n-grams in a\ntest corpus. What is more, skip-grams significantly outperformed contiguous\nn-grams in discovering conventional closing progressions (called cadences).\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 10:59:34 GMT"}, {"version": "v2", "created": "Tue, 18 Jul 2017 09:12:18 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Sears", "David R. W.", ""], ["Arzt", "Andreas", ""], ["Frostel", "Harald", ""], ["Sonnleitner", "Reinhard", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1707.04596", "submitter": "Akshay Soni", "authors": "Sheng Chen, Akshay Soni, Aasish Pappu, Yashar Mehdad", "title": "DocTag2Vec: An Embedding Based Multi-label Learning Approach for\n  Document Tagging", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tagging news articles or blog posts with relevant tags from a collection of\npredefined ones is coined as document tagging in this work. Accurate tagging of\narticles can benefit several downstream applications such as recommendation and\nsearch. In this work, we propose a novel yet simple approach called DocTag2Vec\nto accomplish this task. We substantially extend Word2Vec and Doc2Vec---two\npopular models for learning distributed representation of words and documents.\nIn DocTag2Vec, we simultaneously learn the representation of words, documents,\nand tags in a joint vector space during training, and employ the simple\n$k$-nearest neighbor search to predict tags for unseen documents. In contrast\nto previous multi-label learning methods, DocTag2Vec directly deals with raw\ntext instead of provided feature vector, and in addition, enjoys advantages\nlike the learning of tag representation, and the ability of handling newly\ncreated tags. To demonstrate the effectiveness of our approach, we conduct\nexperiments on several datasets and show promising results against\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 Jul 2017 18:05:49 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Chen", "Sheng", ""], ["Soni", "Akshay", ""], ["Pappu", "Aasish", ""], ["Mehdad", "Yashar", ""]]}, {"id": "1707.04678", "submitter": "Alexandros Tsaptsinos", "authors": "Alexandros Tsaptsinos", "title": "Lyrics-Based Music Genre Classification Using a Hierarchical Attention\n  Network", "comments": "8 pages, 4 figures, ISMIR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music genre classification, especially using lyrics alone, remains a\nchallenging topic in Music Information Retrieval. In this study we apply\nrecurrent neural network models to classify a large dataset of intact song\nlyrics. As lyrics exhibit a hierarchical layer structure - in which words\ncombine to form lines, lines form segments, and segments form a complete song -\nwe adapt a hierarchical attention network (HAN) to exploit these layers and in\naddition learn the importance of the words, lines, and segments. We test the\nmodel over a 117-genre dataset and a reduced 20-genre dataset. Experimental\nresults show that the HAN outperforms both non-neural models and simpler neural\nmodels, whilst also classifying over a higher number of genres than previous\nresearch. Through the learning process we can also visualise which words or\nlines in a song the model believes are important to classifying the genre. As a\nresult the HAN provides insights, from a computational perspective, into\nlyrical structure and language features that differentiate musical genres.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jul 2017 02:22:41 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Tsaptsinos", "Alexandros", ""]]}, {"id": "1707.04680", "submitter": "Christopher Tralie", "authors": "Christopher J. Tralie", "title": "Early MFCC And HPCP Fusion for Robust Cover Song Identification", "comments": "11 pages, 7 figures, Proceedings of The International Society for\n  Music Information Retrieval (ISMIR) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While most schemes for automatic cover song identification have focused on\nnote-based features such as HPCP and chord profiles, a few recent papers\nsurprisingly showed that local self-similarities of MFCC-based features also\nhave classification power for this task. Since MFCC and HPCP capture\ncomplementary information, we design an unsupervised algorithm that combines\nnormalized, beat-synchronous blocks of these features using cross-similarity\nfusion before attempting to locally align a pair of songs. As an added bonus,\nour scheme naturally incorporates structural information in each song to fill\nin alignment gaps where both feature sets fail. We show a striking jump in\nperformance over MFCC and HPCP alone, achieving a state of the art mean\nreciprocal rank of 0.87 on the Covers80 dataset. We also introduce a new\nmedium-sized hand designed benchmark dataset called \"Covers 1000,\" which\nconsists of 395 cliques of cover songs for a total of 1000 songs, and we show\nthat our algorithm achieves an MRR of 0.9 on this dataset for the first\ncorrectly identified song in a clique. We provide the precomputed HPCP and MFCC\nfeatures, as well as beat intervals, for all songs in the Covers 1000 dataset\nfor use in further research.\n", "versions": [{"version": "v1", "created": "Sat, 15 Jul 2017 02:47:17 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Tralie", "Christopher J.", ""]]}, {"id": "1707.04877", "submitter": "Eelco Van Der Wel", "authors": "Eelco van der Wel, Karen Ullrich", "title": "Optical Music Recognition with Convolutional Sequence-to-Sequence Models", "comments": "ISMIR 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.SD", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Optical Music Recognition (OMR) is an important technology within Music\nInformation Retrieval. Deep learning models show promising results on OMR\ntasks, but symbol-level annotated data sets of sufficient size to train such\nmodels are not available and difficult to develop. We present a deep learning\narchitecture called a Convolutional Sequence-to-Sequence model to both move\ntowards an end-to-end trainable OMR pipeline, and apply a learning process that\ntrains on full sentences of sheet music instead of individually labeled\nsymbols. The model is trained and evaluated on a human generated data set, with\nvarious image augmentations based on real-world scenarios. This data set is the\nfirst publicly available set in OMR research with sufficient size to train and\nevaluate deep learning models. With the introduced augmentations a pitch\nrecognition accuracy of 81% and a duration accuracy of 94% is achieved,\nresulting in a note level accuracy of 80%. Finally, the model is compared to\ncommercially available methods, showing a large improvements over these\napplications.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 13:11:22 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["van der Wel", "Eelco", ""], ["Ullrich", "Karen", ""]]}, {"id": "1707.04916", "submitter": "Sergio Oramas", "authors": "Sergio Oramas, Oriol Nieto, Francesco Barbieri, and Xavier Serra", "title": "Multi-label Music Genre Classification from Audio, Text, and Images\n  Using Deep Features", "comments": "In Proceedings of the 18th International Society of Music Information\n  Retrieval Conference (ISMIR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music genres allow to categorize musical items that share common\ncharacteristics. Although these categories are not mutually exclusive, most\nrelated research is traditionally focused on classifying tracks into a single\nclass. Furthermore, these categories (e.g., Pop, Rock) tend to be too broad for\ncertain applications. In this work we aim to expand this task by categorizing\nmusical items into multiple and fine-grained labels, using three different data\nmodalities: audio, text, and images. To this end we present MuMu, a new dataset\nof more than 31k albums classified into 250 genre classes. For every album we\nhave collected the cover image, text reviews, and audio tracks. Additionally,\nwe propose an approach for multi-label genre classification based on the\ncombination of feature embeddings learned with state-of-the-art deep learning\nmethodologies. Experiments show major differences between modalities, which not\nonly introduce new baselines for multi-label genre classification, but also\nsuggest that combining them yields improved results.\n", "versions": [{"version": "v1", "created": "Sun, 16 Jul 2017 17:12:30 GMT"}], "update_date": "2017-07-18", "authors_parsed": [["Oramas", "Sergio", ""], ["Nieto", "Oriol", ""], ["Barbieri", "Francesco", ""], ["Serra", "Xavier", ""]]}, {"id": "1707.05154", "submitter": "Zhuoren Jiang", "authors": "Liangcai Gao, Zhuoren Jiang, Yue Yin, Ke Yuan, Zuoyu Yan, Zhi Tang", "title": "Preliminary Exploration of Formula Embedding for Mathematical\n  Information Retrieval: can mathematical formulae be embedded like a natural\n  language?", "comments": "CIKM 2017 Workshop on Interpretable Data Mining (IDM): Bridging the\n  Gap between Shallow and Deep Models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While neural network approaches are achieving breakthrough performance in the\nnatural language related fields, there have been few similar attempts at\nmathematical language related tasks. In this study, we explore the potential of\napplying neural representation techniques to Mathematical Information Retrieval\n(MIR) tasks. In more detail, we first briefly analyze the characteristic\ndifferences between natural language and mathematical language. Then we design\na \"symbol2vec\" method to learn the vector representations of formula symbols\n(numbers, variables, operators, functions, etc.) Finally, we propose a\n\"formula2vec\" based MIR approach and evaluate its performance. Preliminary\nexperiment results show that there is a promising potential for applying\nformula embedding models to mathematical language representation and MIR tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 13:43:41 GMT"}, {"version": "v2", "created": "Tue, 29 Aug 2017 11:36:32 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Gao", "Liangcai", ""], ["Jiang", "Zhuoren", ""], ["Yin", "Yue", ""], ["Yuan", "Ke", ""], ["Yan", "Zuoyu", ""], ["Tang", "Zhi", ""]]}, {"id": "1707.05176", "submitter": "Yi Tay", "authors": "Yi Tay, Anh Tuan Luu, Siu Cheung Hui", "title": "Latent Relational Metric Learning via Memory-based Attention for\n  Collaborative Ranking", "comments": "WWW 2018", "journal-ref": null, "doi": "10.1145/3178876.3186154", "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new neural architecture for collaborative ranking with\nimplicit feedback. Our model, LRML (\\textit{Latent Relational Metric Learning})\nis a novel metric learning approach for recommendation. More specifically,\ninstead of simple push-pull mechanisms between user and item pairs, we propose\nto learn latent relations that describe each user item interaction. This helps\nto alleviate the potential geometric inflexibility of existing metric learing\napproaches. This enables not only better performance but also a greater extent\nof modeling capability, allowing our model to scale to a larger number of\ninteractions. In order to do so, we employ a augmented memory module and learn\nto attend over these memory blocks to construct latent relations. The\nmemory-based attention module is controlled by the user-item interaction,\nmaking the learned relation vector specific to each user-item pair. Hence, this\ncan be interpreted as learning an exclusive and optimal relational translation\nfor each user-item interaction. The proposed architecture demonstrates the\nstate-of-the-art performance across multiple recommendation benchmarks. LRML\noutperforms other metric learning models by $6\\%-7.5\\%$ in terms of Hits@10 and\nnDCG@10 on large datasets such as Netflix and MovieLens20M. Moreover,\nqualitative studies also demonstrate evidence that our proposed model is able\nto infer and encode explicit sentiment, temporal and attribute information\ndespite being only trained on implicit feedback. As such, this ascertains the\nability of LRML to uncover hidden relational structure within implicit\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 14:19:49 GMT"}, {"version": "v2", "created": "Sun, 7 Jan 2018 13:42:09 GMT"}, {"version": "v3", "created": "Tue, 13 Feb 2018 07:34:50 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Tay", "Yi", ""], ["Luu", "Anh Tuan", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1707.05254", "submitter": "Rose Catherine", "authors": "Rose Catherine, Kathryn Mazaitis, Maxine Eskenazi and William Cohen", "title": "Explainable Entity-based Recommendations with Knowledge Graphs", "comments": "Accepted for publication in the 11th ACM Conference on Recommender\n  Systems (RecSys 2017) - Posters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Explainable recommendation is an important task. Many methods have been\nproposed which generate explanations from the content and reviews written for\nitems. When review text is unavailable, generating explanations is still a hard\nproblem. In this paper, we illustrate how explanations can be generated in such\na scenario by leveraging external knowledge in the form of knowledge graphs.\nOur method jointly ranks items and knowledge graph entities using a\nPersonalized PageRank procedure to produce recommendations together with their\nexplanations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Jul 2017 23:18:58 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Catherine", "Rose", ""], ["Mazaitis", "Kathryn", ""], ["Eskenazi", "Maxine", ""], ["Cohen", "William", ""]]}, {"id": "1707.05340", "submitter": "Meng Wang", "authors": "Meng Wang, Jiaheng Zhang, Jun Liu, Wei Hu, Sen Wang, Xue Li, Wenqiang\n  Liu", "title": "PDD Graph: Bridging Electronic Medical Records and Biomedical Knowledge\n  Graphs via Entity Linking", "comments": "9 pages,5 figures,accepted by ISWC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic medical records contain multi-format electronic medical data that\nconsist of an abundance of medical knowledge. Facing with patient's symptoms,\nexperienced caregivers make right medical decisions based on their professional\nknowledge that accurately grasps relationships between symptoms, diagnosis and\ncorresponding treatments. In this paper, we aim to capture these relationships\nby constructing a large and high-quality heterogenous graph linking patients,\ndiseases, and drugs (PDD) in EMRs. Specifically, we propose a novel framework\nto extract important medical entities from MIMIC-III (Medical Information Mart\nfor Intensive Care III) and automatically link them with the existing\nbiomedical knowledge graphs, including ICD-9 ontology and DrugBank. The PDD\ngraph presented in this paper is accessible on the Web via the SPARQL endpoint,\nand provides a pathway for medical discovery and applications, such as\neffective treatment recommendations.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 18:04:27 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 14:36:18 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Wang", "Meng", ""], ["Zhang", "Jiaheng", ""], ["Liu", "Jun", ""], ["Hu", "Wei", ""], ["Wang", "Sen", ""], ["Li", "Xue", ""], ["Liu", "Wenqiang", ""]]}, {"id": "1707.05409", "submitter": "Liu Yang", "authors": "Liu Yang, Hamed Zamani, Yongfeng Zhang, Jiafeng Guo, W. Bruce Croft", "title": "Neural Matching Models for Question Retrieval and Next Question\n  Prediction in Conversation", "comments": "Neu-IR 2017: The SIGIR 2017 Workshop on Neural Information Retrieval\n  (SIGIR Neu-IR 2017), Tokyo, Japan, August 7-11, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent boom of AI has seen the emergence of many human-computer\nconversation systems such as Google Assistant, Microsoft Cortana, Amazon Echo\nand Apple Siri. We introduce and formalize the task of predicting questions in\nconversations, where the goal is to predict the new question that the user will\nask, given the past conversational context. This task can be modeled as a\n\"sequence matching\" problem, where two sequences are given and the aim is to\nlearn a model that maps any pair of sequences to a matching probability. Neural\nmatching models, which adopt deep neural networks to learn sequence\nrepresentations and matching scores, have attracted immense research interests\nof information retrieval and natural language processing communities. In this\npaper, we first study neural matching models for the question retrieval task\nthat has been widely explored in the literature, whereas the effectiveness of\nneural models for this task is relatively unstudied. We further evaluate the\nneural matching models in the next question prediction task in conversations.\nWe have used the publicly available Quora data and Ubuntu chat logs in our\nexperiments. Our evaluations investigate the potential of neural matching\nmodels with representation learning for question retrieval and next question\nprediction in conversations. Experimental results show that neural matching\nmodels perform well for both tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jul 2017 22:55:50 GMT"}], "update_date": "2017-07-19", "authors_parsed": [["Yang", "Liu", ""], ["Zamani", "Hamed", ""], ["Zhang", "Yongfeng", ""], ["Guo", "Jiafeng", ""], ["Croft", "W. Bruce", ""]]}, {"id": "1707.05481", "submitter": "Elena Mikhalkova", "authors": "Elena Mikhalkova and Nadezhda Ganzherli and Yuri Karyakin", "title": "A Comparative Analysis of Social Network Pages by Interests of Their\n  Followers", "comments": "11 pages, submitted for reviewing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Being a matter of cognition, user interests should be apt to classification\nindependent of the language of users, social network and content of interest\nitself. To prove it, we analyze a collection of English and Russian Twitter and\nVkontakte community pages by interests of their followers. First, we create a\nmodel of Major Interests (MaIs) with the help of expert analysis and then\nclassify a set of pages using machine learning algorithms (SVM, Neural Network,\nNaive Bayes, and some other). We take three interest domains that are typical\nof both English and Russian-speaking communities: football, rock music,\nvegetarianism. The results of classification show a greater correlation between\nRussian-Vkontakte and Russian-Twitter pages while English-Twitterpages appear\nto provide the highest score.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 05:49:30 GMT"}, {"version": "v2", "created": "Tue, 17 Oct 2017 13:57:24 GMT"}], "update_date": "2017-10-18", "authors_parsed": [["Mikhalkova", "Elena", ""], ["Ganzherli", "Nadezhda", ""], ["Karyakin", "Yuri", ""]]}, {"id": "1707.05651", "submitter": "Guangyuan Piao", "authors": "Guangyuan Piao and John G. Breslin", "title": "Factorization Machines Leveraging Lightweight Linked Open Data-enabled\n  Features for Top-N Recommendations", "comments": "This draft has been accepted at WISE2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the popularity of Linked Open Data (LOD) and the associated rise in\nfreely accessible knowledge that can be accessed via LOD, exploiting LOD for\nrecommender systems has been widely studied based on various approaches such as\ngraph-based or using different machine learning models with LOD-enabled\nfeatures. Many of the previous approaches require construction of an additional\ngraph to run graph-based algorithms or to extract path-based features by\ncombining user- item interactions (e.g., likes, dislikes) and background\nknowledge from LOD. In this paper, we investigate Factorization Machines (FMs)\nbased on particularly lightweight LOD-enabled features which can be directly\nobtained via a public SPARQL Endpoint without any additional effort to\nconstruct a graph. Firstly, we aim to study whether using FM with these\nlightweight LOD-enabled features can provide competitive performance compared\nto a learning-to-rank approach leveraging LOD as well as other well-established\napproaches such as kNN-item and BPRMF. Secondly, we are interested in finding\nout to what extent each set of LOD-enabled features contributes to the\nrecommendation performance. Experimental evaluation on a standard dataset shows\nthat our proposed approach using FM with lightweight LOD-enabled features\nprovides the best performance compared to other approaches in terms of five\nevaluation metrics. In addition, the study of the recommendation performance\nbased on different sets of LOD-enabled features indicate that property-object\nlists and PageRank scores of items are useful for improving the performance,\nand can provide the best performance through using them together for FM. We\nobserve that subject-property lists of items does not contribute to the\nrecommendation performance but rather decreases the performance.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jul 2017 14:48:07 GMT"}, {"version": "v2", "created": "Fri, 28 Jul 2017 21:46:12 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Piao", "Guangyuan", ""], ["Breslin", "John G.", ""]]}, {"id": "1707.05955", "submitter": "Chen Wu", "authors": "Chen Wu, Ming Yan, Luo Si", "title": "Session-aware Information Embedding for E-commerce Product\n  Recommendation", "comments": null, "journal-ref": "Proceedings of the 2017 ACM on Conference on Information and\n  Knowledge Management Pages 2379-2382", "doi": "10.1145/3132847.3133163", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing recommender systems assume that user's visiting history\ncan be constantly recorded. However, in recent online services, the user\nidentification may be usually unknown and only limited online user behaviors\ncan be used. It is of great importance to model the temporal online user\nbehaviors and conduct recommendation for the anonymous users. In this paper, we\npropose a list-wise deep neural network based architecture to model the limited\nuser behaviors within each session. To train the model efficiently, we first\ndesign a session embedding method to pre-train a session representation, which\nincorporates different kinds of user search behaviors such as clicks and views.\nBased on the learnt session representation, we further propose a list-wise\nranking model to generate the recommendation result for each anonymous user\nsession. We conduct quantitative experiments on a recently published dataset\nfrom an e-commerce company. The evaluation results validate the effectiveness\nof the proposed method, which can outperform the state-of-the-art\nsignificantly.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 06:55:59 GMT"}, {"version": "v2", "created": "Mon, 20 Nov 2017 13:13:09 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Wu", "Chen", ""], ["Yan", "Ming", ""], ["Si", "Luo", ""]]}, {"id": "1707.06055", "submitter": "Joao Saude", "authors": "Guilherme Ramos, Joao Saude, Carlos Caleiro, Soummya Kar", "title": "Recommendation via matrix completion using Kolmogorov complexity", "comments": "9 pages, 1 figure, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A usual way to model a recommendation system is as a matrix completion\nproblem. There are several matrix completion methods, typically using\noptimization approaches or collaborative filtering. Most approaches assume that\nthe matrix is either low rank, or that there are a small number of latent\nvariables that encode the full problem. Here, we propose a novel matrix\ncompletion algorithm for recommendation systems, without any assumptions on the\nrank and that is model free, i.e., the entries are not assumed to be a function\nof some latent variables. Instead, we use a technique akin to information\ntheory. Our method performs hybrid neighborhood-based collaborative filtering\nusing Kolmogorov complexity. It decouples the matrix completion into a vector\ncompletion problem for each user. The recommendation for one user is thus\nindependent of the recommendation for other users. This makes the algorithm\nscalable because the computations are highly parallelizable. Our results are\ncompetitive with state-of-the-art approaches on both synthetic and real-world\ndataset benchmarks.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 12:55:10 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Ramos", "Guilherme", ""], ["Saude", "Joao", ""], ["Caleiro", "Carlos", ""], ["Kar", "Soummya", ""]]}, {"id": "1707.06112", "submitter": "Prannay Khosla", "authors": "Prannay Khosla, Moumita Basu, Kripabandhu Ghosh, Saptarshi Ghosh", "title": "Microblog Retrieval for Post-Disaster Relief: Applying and Comparing\n  Neural IR Models", "comments": "8 pages, 7 figures; SIGIR 2017 Workshop on Neural Information\n  Retrieval (Neu-IR'17) August 07--11, 2017, Shinjuku, Tokyo, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microblogging sites like Twitter and Weibo have emerged as important\nsourcesof real-time information on ongoing events, including socio-political\nevents, emergency events, and so on. For instance, during emergency events\n(such as earthquakes, floods, terror attacks), microblogging sites are very\nuseful for gathering situational information in real-time. During such an\nevent, typically only a small fraction of the microblogs (tweets) posted are\nrelevant to the information need. Hence, it is necessary to design effective\nmethodologies for microblog retrieval, so that the relevant tweets can be\nautomatically extracted from large sets of documents (tweets).\n  In this work, we apply and compare various neural network-based IR models for\nmicroblog retrieval for a specific application, as follows. In a disaster\nsituation, one of the primary and practical challenges in coordinating the\npost-disaster relief operations is to know about what resources are needed and\nwhat resources are available in the disaster-affected area. Thus, in this\nstudy, we focus on extracting these two specific types of microblogs or tweets\nnamely need tweets and avail tweets, which are tweets which define some needs\nof the people and the tweets which offer some solutions or aid for the people,\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 14:28:05 GMT"}], "update_date": "2017-07-20", "authors_parsed": [["Khosla", "Prannay", ""], ["Basu", "Moumita", ""], ["Ghosh", "Kripabandhu", ""], ["Ghosh", "Saptarshi", ""]]}, {"id": "1707.06372", "submitter": "Yi Tay", "authors": "Yi Tay, Minh C. Phan, Luu Anh Tuan, Siu Cheung Hui", "title": "Learning to Rank Question Answer Pairs with Holographic Dual LSTM\n  Architecture", "comments": "SIGIR 2017 Full Paper", "journal-ref": null, "doi": "10.1145/3077136.3080790", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new deep learning architecture for learning to rank question\nanswer pairs. Our approach extends the long short-term memory (LSTM) network\nwith holographic composition to model the relationship between question and\nanswer representations. As opposed to the neural tensor layer that has been\nadopted recently, the holographic composition provides the benefits of scalable\nand rich representational learning approach without incurring huge parameter\ncosts. Overall, we present Holographic Dual LSTM (HD-LSTM), a unified\narchitecture for both deep sentence modeling and semantic matching.\nEssentially, our model is trained end-to-end whereby the parameters of the LSTM\nare optimized in a way that best explains the correlation between question and\nanswer representations. In addition, our proposed deep learning architecture\nrequires no extensive feature engineering. Via extensive experiments, we show\nthat HD-LSTM outperforms many other neural architectures on two popular\nbenchmark QA datasets. Empirical studies confirm the effectiveness of\nholographic composition over the neural tensor layer.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 04:47:00 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Tay", "Yi", ""], ["Phan", "Minh C.", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1707.06562", "submitter": "Steffen Schnitzer", "authors": "Steffen Schnitzer and Svenja Neitzel and Christoph Rensing", "title": "From Task Classification Towards Similarity Measures for Recommendation\n  in Crowdsourcing Systems", "comments": "Work in Progress Paper at HCOMP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task selection in micro-task markets can be supported by recommender systems\nto help individuals to find appropriate tasks. Previous work showed that for\nthe selection process of a micro-task the semantic aspects, such as the\nrequired action and the comprehensibility, are rated more important than\nfactual aspects, such as the payment or the required completion time. This work\ngives a foundation to create such similarity measures. Therefore, we show that\nan automatic classification based on task descriptions is possible.\nAdditionally, we propose similarity measures to cluster micro-tasks according\nto semantic aspects.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 15:06:43 GMT"}], "update_date": "2017-07-21", "authors_parsed": [["Schnitzer", "Steffen", ""], ["Neitzel", "Svenja", ""], ["Rensing", "Christoph", ""]]}, {"id": "1707.06598", "submitter": "Navid Rekabsaz", "authors": "Navid Rekabsaz and Bhaskar Mitra and Mihai Lupu and Allan Hanbury", "title": "Toward Incorporation of Relevant Documents in word2vec", "comments": "Neu-IR Workshop at the ACM Conference on Research and Development in\n  Information Retrieval (NeuIR-SIGIR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural word embedding provide significant benefit to\nvarious information retrieval tasks. However as shown by recent studies,\nadapting the embedding models for the needs of IR tasks can bring considerable\nfurther improvements. The embedding models in general define the term\nrelatedness by exploiting the terms' co-occurrences in short-window contexts.\nAn alternative (and well-studied) approach in IR for related terms to a query\nis using local information i.e. a set of top-retrieved documents. In view of\nthese two methods of term relatedness, in this work, we report our study on\nincorporating the local information of the query in the word embeddings. One\nmain challenge in this direction is that the dense vectors of word embeddings\nand their estimation of term-to-term relatedness remain difficult to interpret\nand hard to analyze. As an alternative, explicit word representations propose\nvectors whose dimensions are easily interpretable, and recent methods show\ncompetitive performance to the dense vectors. We introduce a neural-based\nexplicit representation, rooted in the conceptual ideas of the word2vec\nSkip-Gram model. The method provides interpretable explicit vectors while\nkeeping the effectiveness of the Skip-Gram model. The evaluation of various\nexplicit representations on word association collections shows that the newly\nproposed method out- performs the state-of-the-art explicit representations\nwhen tasked with ranking highly similar terms. Based on the introduced ex-\nplicit representation, we discuss our approaches on integrating local documents\nin globally-trained embedding models and discuss the preliminary results.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jul 2017 16:33:48 GMT"}, {"version": "v2", "created": "Wed, 4 Apr 2018 07:36:05 GMT"}], "update_date": "2018-04-05", "authors_parsed": [["Rekabsaz", "Navid", ""], ["Mitra", "Bhaskar", ""], ["Lupu", "Mihai", ""], ["Hanbury", "Allan", ""]]}, {"id": "1707.06932", "submitter": "Marinella Petrocchi", "authors": "Michela Fazzolari and Vittoria Cozza and Marinella Petrocchi and\n  Angelo Spognardi", "title": "A study on text-score disagreement in online reviews", "comments": "This is the accepted version of the paper. The final version will be\n  published in the Journal of Cognitive Computation, available at Springer via\n  http://dx.doi.org/10.1007/s12559-017-9496-y", "journal-ref": null, "doi": "10.1007/s12559-017-9496-y", "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on online reviews and employ artificial intelligence\ntools, taken from the cognitive computing field, to help understanding the\nrelationships between the textual part of the review and the assigned numerical\nscore. We move from the intuitions that 1) a set of textual reviews expressing\ndifferent sentiments may feature the same score (and vice-versa); and 2)\ndetecting and analyzing the mismatches between the review content and the\nactual score may benefit both service providers and consumers, by highlighting\nspecific factors of satisfaction (and dissatisfaction) in texts.\n  To prove the intuitions, we adopt sentiment analysis techniques and we\nconcentrate on hotel reviews, to find polarity mismatches therein. In\nparticular, we first train a text classifier with a set of annotated hotel\nreviews, taken from the Booking website. Then, we analyze a large dataset, with\naround 160k hotel reviews collected from Tripadvisor, with the aim of detecting\na polarity mismatch, indicating if the textual content of the review is in\nline, or not, with the associated score.\n  Using well established artificial intelligence techniques and analyzing in\ndepth the reviews featuring a mismatch between the text polarity and the score,\nwe find that -on a scale of five stars- those reviews ranked with middle scores\ninclude a mixture of positive and negative aspects.\n  The approach proposed here, beside acting as a polarity detector, provides an\neffective selection of reviews -on an initial very large dataset- that may\nallow both consumers and providers to focus directly on the review subset\nfeaturing a text/score disagreement, which conveniently convey to the user a\nsummary of positive and negative features of the review target.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 15:19:09 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Fazzolari", "Michela", ""], ["Cozza", "Vittoria", ""], ["Petrocchi", "Marinella", ""], ["Spognardi", "Angelo", ""]]}, {"id": "1707.06939", "submitter": "James Bagrow", "authors": "Xipei Liu and James P. Bagrow", "title": "Autocompletion interfaces make crowd workers slower, but their use\n  promotes response diversity", "comments": "12 pages, 6 figures", "journal-ref": "Human Computation 6:1:42-55 (2019)", "doi": "10.15346/hc.v6i1.3", "report-no": null, "categories": "cs.HC cs.CL cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creative tasks such as ideation or question proposal are powerful\napplications of crowdsourcing, yet the quantity of workers available for\naddressing practical problems is often insufficient. To enable scalable\ncrowdsourcing thus requires gaining all possible efficiency and information\nfrom available workers. One option for text-focused tasks is to allow assistive\ntechnology, such as an autocompletion user interface (AUI), to help workers\ninput text responses. But support for the efficacy of AUIs is mixed. Here we\ndesigned and conducted a randomized experiment where workers were asked to\nprovide short text responses to given questions. Our experimental goal was to\ndetermine if an AUI helps workers respond more quickly and with improved\nconsistency by mitigating typos and misspellings. Surprisingly, we found that\nneither occurred: workers assigned to the AUI treatment were slower than those\nassigned to the non-AUI control and their responses were more diverse, not\nless, than those of the control. Both the lexical and semantic diversities of\nresponses were higher, with the latter measured using word2vec. A crowdsourcer\ninterested in worker speed may want to avoid using an AUI, but using an AUI to\nboost response diversity may be valuable to crowdsourcers interested in\nreceiving as much novel information from workers as possible.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jul 2017 15:41:38 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Liu", "Xipei", ""], ["Bagrow", "James P.", ""]]}, {"id": "1707.07270", "submitter": "Yixing Fan", "authors": "Yixing Fan, Liang Pang, JianPeng Hou, Jiafeng Guo, Yanyan Lan, Xueqi\n  Cheng", "title": "MatchZoo: A Toolkit for Deep Text Matching", "comments": "2 pages, 1 figures, Neu-IR: The SIGIR 2017 Workshop on Neural\n  Information Retrieval", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, deep neural models have been widely adopted for text\nmatching tasks, such as question answering and information retrieval, showing\nimproved performance as compared with previous methods. In this paper, we\nintroduce the MatchZoo toolkit that aims to facilitate the designing, comparing\nand sharing of deep text matching models. Specifically, the toolkit provides a\nunified data preparation module for different text matching problems, a\nflexible layer-based model construction process, and a variety of training\nobjectives and evaluation metrics. In addition, the toolkit has implemented two\nschools of representative deep text matching models, namely\nrepresentation-focused models and interaction-focused models. Finally, users\ncan easily modify existing models, create and share their own models for text\nmatching in MatchZoo.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jul 2017 09:36:50 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Fan", "Yixing", ""], ["Pang", "Liang", ""], ["Hou", "JianPeng", ""], ["Guo", "Jiafeng", ""], ["Lan", "Yanyan", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1707.07426", "submitter": "Naama Kraus", "authors": "Naama Kraus, David Carmel, Idit Keidar", "title": "Tail-Tolerant Distributed Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's search engines process billions of online user queries a day over\nhuge collections of data. In order to scale, they distribute query processing\namong many nodes, where each node holds and searches over a subset of the index\ncalled shard. Responses from some nodes occasionally fail to arrive within a\nreasonable time-interval due to various reasons, such as high server load and\nnetwork congestion. Search engines typically need to respond in a timely\nmanner, and therefore skip such tail latency responses, which causes\ndegradation in search quality. In this paper, we tackle response misses due to\nhigh tail latencies with the goal of maximizing search quality.\n  Search providers today use redundancy in the form of Replication for\nmitigating response misses, by constructing multiple copies of each shard and\nsearching all replicas. This approach is not ideal, as it wastes resources on\nsearching duplicate data. We propose two strategies to reduce this waste.\nFirst, we propose rSmartRed, an optimal shard selection scheme for replicated\nindexes. Second, when feasible, we propose to replace Replication with\nRepartition, which constructs independent index instances instead of exact\ncopies. We analytically prove that rSmartRed's selection is optimal for\nReplication, and that Repartition achieves better search quality compared to\nReplication. We confirm our results with an empirical study using two\nreal-world datasets, showing that rSmartRed improves recall compared to\ncurrently used approaches. We additionally show that Repartition improves over\nReplication in typical scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 07:32:06 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Kraus", "Naama", ""], ["Carmel", "David", ""], ["Keidar", "Idit", ""]]}, {"id": "1707.07435", "submitter": "Shuai Zhang", "authors": "Shuai Zhang, Lina Yao, Aixin Sun, Yi Tay", "title": "Deep Learning based Recommender System: A Survey and New Perspectives", "comments": "The paper has been accepted by ACM Computing Surveys.\n  https://doi.acm.org/10.1145/3285029", "journal-ref": null, "doi": "10.1145/3285029", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-growing volume of online information, recommender systems have\nbeen an effective strategy to overcome such information overload. The utility\nof recommender systems cannot be overstated, given its widespread adoption in\nmany web applications, along with its potential impact to ameliorate many\nproblems related to over-choice. In recent years, deep learning has garnered\nconsiderable interest in many research fields such as computer vision and\nnatural language processing, owing not only to stellar performance but also the\nattractive property of learning feature representations from scratch. The\ninfluence of deep learning is also pervasive, recently demonstrating its\neffectiveness when applied to information retrieval and recommender systems\nresearch. Evidently, the field of deep learning in recommender system is\nflourishing. This article aims to provide a comprehensive review of recent\nresearch efforts on deep learning based recommender systems. More concretely,\nwe provide and devise a taxonomy of deep learning based recommendation models,\nalong with providing a comprehensive summary of the state-of-the-art. Finally,\nwe expand on current trends and provide new perspectives pertaining to this new\nexciting development of the field.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 08:23:26 GMT"}, {"version": "v2", "created": "Thu, 27 Jul 2017 14:44:59 GMT"}, {"version": "v3", "created": "Sat, 29 Jul 2017 14:15:51 GMT"}, {"version": "v4", "created": "Tue, 1 Aug 2017 14:25:09 GMT"}, {"version": "v5", "created": "Thu, 3 Aug 2017 06:11:24 GMT"}, {"version": "v6", "created": "Tue, 4 Sep 2018 11:58:51 GMT"}, {"version": "v7", "created": "Wed, 10 Jul 2019 01:26:36 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Zhang", "Shuai", ""], ["Yao", "Lina", ""], ["Sun", "Aixin", ""], ["Tay", "Yi", ""]]}, {"id": "1707.07493", "submitter": "Rolf Jagerman", "authors": "Rolf Jagerman, Julia Kiseleva, Maarten de Rijke", "title": "Modeling Label Ambiguity for Neural List-Wise Learning to Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  List-wise learning to rank methods are considered to be the state-of-the-art.\nOne of the major problems with these methods is that the ambiguous nature of\nrelevance labels in learning to rank data is ignored. Ambiguity of relevance\nlabels refers to the phenomenon that multiple documents may be assigned the\nsame relevance label for a given query, so that no preference order should be\nlearned for those documents. In this paper we propose a novel sampling\ntechnique for computing a list-wise loss that can take into account this\nambiguity. We show the effectiveness of the proposed method by training a\n3-layer deep neural network. We compare our new loss function to two strong\nbaselines: ListNet and ListMLE. We show that our method generalizes better and\nsignificantly outperforms other methods on the validation and test sets.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 11:28:21 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Jagerman", "Rolf", ""], ["Kiseleva", "Julia", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1707.07585", "submitter": "Weizheng Chen", "authors": "Zeya Zhang, Weizheng Chen and Hongfei Yan", "title": "Stock Prediction: a method based on extraction of news features and\n  recurrent neural networks", "comments": "in Chinese, The 22nd China Conference on Information Retrieval", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.ST cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposed a method for stock prediction. In terms of feature\nextraction, we extract the features of stock-related news besides stock prices.\nWe first select some seed words based on experience which are the symbols of\ngood news and bad news. Then we propose an optimization method and calculate\nthe positive polar of all words. After that, we construct the features of news\nbased on the positive polar of their words. In consideration of sequential\nstock prices and continuous news effects, we propose a recurrent neural network\nmodel to help predict stock prices. Compared to SVM classifier with price\nfeatures, we find our proposed method has an over 5% improvement on stock\nprediction accuracy in experiments.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jul 2017 13:40:06 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Zhang", "Zeya", ""], ["Chen", "Weizheng", ""], ["Yan", "Hongfei", ""]]}, {"id": "1707.07605", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Hosein Azarbonyad, Jaap Kamps, Maarten de Rijke", "title": "Share your Model instead of your Data: Privacy Preserving Mimic Learning\n  for Ranking", "comments": "SIGIR 2017 Workshop on Neural Information Retrieval\n  (Neu-IR'17)}{}{August 7--11, 2017, Shinjuku, Tokyo, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep neural networks have become a primary tool for solving problems in many\nfields. They are also used for addressing information retrieval problems and\nshow strong performance in several tasks. Training these models requires large,\nrepresentative datasets and for most IR tasks, such data contains sensitive\ninformation from users. Privacy and confidentiality concerns prevent many data\nowners from sharing the data, thus today the research community can only\nbenefit from research on large-scale datasets in a limited manner. In this\npaper, we discuss privacy preserving mimic learning, i.e., using predictions\nfrom a privacy preserving trained model instead of labels from the original\nsensitive training data as a supervision signal. We present the results of\npreliminary experiments in which we apply the idea of mimic learning and\nprivacy preserving mimic learning for the task of document re-ranking as one of\nthe core IR tasks. This research is a step toward laying the ground for\nenabling researchers from data-rich environments to share knowledge learned\nfrom actual users' data, which should facilitate research collaborations.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 15:23:41 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Azarbonyad", "Hosein", ""], ["Kamps", "Jaap", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1707.07660", "submitter": "Maarten De Rijke", "authors": "Dat Tien Nguyen, Shafiq Joty, Basma El Amel Boussaha, Maarten de Rijke", "title": "Thread Reconstruction in Conversational Data using Neural Coherence\n  Models", "comments": "Neu-IR: Workshop on Neural Information Retrieval 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Discussion forums are an important source of information. They are often used\nto answer specific questions a user might have and to discover more about a\ntopic of interest. Discussions in these forums may evolve in intricate ways,\nmaking it difficult for users to follow the flow of ideas. We propose a novel\napproach for automatically identifying the underlying thread structure of a\nforum discussion. Our approach is based on a neural model that computes\ncoherence scores of possible reconstructions and then selects the highest\nscoring, i.e., the most coherent one. Preliminary experiments demonstrate\npromising results outperforming a number of strong baseline methods.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 17:42:32 GMT"}, {"version": "v2", "created": "Tue, 25 Jul 2017 08:48:20 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Nguyen", "Dat Tien", ""], ["Joty", "Shafiq", ""], ["Boussaha", "Basma El Amel", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1707.07678", "submitter": "Tobias Kuhn", "authors": "Tom Jansen and Tobias Kuhn", "title": "Extracting Core Claims from Scientific Articles", "comments": "In Post-proceedings of the 28th Benelux Conference on Artificial\n  Intelligence (BNAIC 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of scientific articles has grown rapidly over the years and there\nare no signs that this growth will slow down in the near future. Because of\nthis, it becomes increasingly difficult to keep up with the latest developments\nin a scientific field. To address this problem, we present here an approach to\nhelp researchers learn about the latest developments and findings by extracting\nin a normalized form core claims from scientific articles. This normalized\nrepresentation is a controlled natural language of English sentences called\nAIDA, which has been proposed in previous work as a method to formally\nstructure and organize scientific findings and discourse. We show how such AIDA\nsentences can be automatically extracted by detecting the core claim of an\narticle, checking for AIDA compliance, and - if necessary - transforming it\ninto a compliant sentence. While our algorithm is still far from perfect, our\nresults indicate that the different steps are feasible and they support the\nclaim that AIDA sentences might be a promising approach to improve scientific\ncommunication in the future.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 15:10:40 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Jansen", "Tom", ""], ["Kuhn", "Tobias", ""]]}, {"id": "1707.07700", "submitter": "Liang Pang", "authors": "Liang Pang, Yanyan Lan, Jiafeng Guo, Jun Xu, Xueqi Cheng", "title": "A Deep Investigation of Deep IR Models", "comments": "SIGIR 2017 Workshop on Neural Information Retrieval (Neu-IR'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The effective of information retrieval (IR) systems have become more\nimportant than ever. Deep IR models have gained increasing attention for its\nability to automatically learning features from raw text; thus, many deep IR\nmodels have been proposed recently. However, the learning process of these deep\nIR models resemble a black box. Therefore, it is necessary to identify the\ndifference between automatically learned features by deep IR models and\nhand-crafted features used in traditional learning to rank approaches.\nFurthermore, it is valuable to investigate the differences between these deep\nIR models. This paper aims to conduct a deep investigation on deep IR models.\nSpecifically, we conduct an extensive empirical study on two different\ndatasets, including Robust and LETOR4.0. We first compared the automatically\nlearned features and hand-crafted features on the respects of query term\ncoverage, document length, embeddings and robustness. It reveals a number of\ndisadvantages compared with hand-crafted features. Therefore, we establish\nguidelines for improving existing deep IR models. Furthermore, we compare two\ndifferent categories of deep IR models, i.e. representation-focused models and\ninteraction-focused models. It is shown that two types of deep IR models focus\non different categories of words, including topic-related words and\nquery-related words.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jul 2017 18:14:04 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Pang", "Liang", ""], ["Lan", "Yanyan", ""], ["Guo", "Jiafeng", ""], ["Xu", "Jun", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1707.07792", "submitter": "Jimmy Lin", "authors": "Jinfeng Rao, Hua He, Haotian Zhang, Ferhan Ture, Royal Sequiera,\n  Salman Mohammed, and Jimmy Lin", "title": "Integrating Lexical and Temporal Signals in Neural Ranking Models for\n  Searching Social Media Streams", "comments": "SIGIR 2017 Workshop on Neural Information Retrieval (Neu-IR'17),\n  August 7-11, 2017, Shinjuku, Tokyo, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time is an important relevance signal when searching streams of social media\nposts. The distribution of document timestamps from the results of an initial\nquery can be leveraged to infer the distribution of relevant documents, which\ncan then be used to rerank the initial results. Previous experiments have shown\nthat kernel density estimation is a simple yet effective implementation of this\nidea. This paper explores an alternative approach to mining temporal signals\nwith recurrent neural networks. Our intuition is that neural networks provide a\nmore expressive framework to capture the temporal coherence of neighboring\ndocuments in time. To our knowledge, we are the first to integrate lexical and\ntemporal signals in an end-to-end neural network architecture, in which\nexisting neural ranking models are used to generate query-document similarity\nvectors that feed into a bidirectional LSTM layer for temporal modeling. Our\nresults are mixed: existing neural models for document ranking alone yield\nlimited improvements over simple baselines, but the integration of lexical and\ntemporal signals yield significant improvements over competitive temporal\nbaselines.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 02:29:31 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Rao", "Jinfeng", ""], ["He", "Hua", ""], ["Zhang", "Haotian", ""], ["Ture", "Ferhan", ""], ["Sequiera", "Royal", ""], ["Mohammed", "Salman", ""], ["Lin", "Jimmy", ""]]}, {"id": "1707.07804", "submitter": "Jimmy Lin", "authors": "Royal Sequiera, Gaurav Baruah, Zhucheng Tu, Salman Mohammed, Jinfeng\n  Rao, Haotian Zhang, and Jimmy Lin", "title": "Exploring the Effectiveness of Convolutional Neural Networks for Answer\n  Selection in End-to-End Question Answering", "comments": "SIGIR 2017 Workshop on Neural Information Retrieval (Neu-IR'17),\n  August 7-11, 2017, Shinjuku, Tokyo, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work on natural language question answering today focuses on answer\nselection: given a candidate list of sentences, determine which contains the\nanswer. Although important, answer selection is only one stage in a standard\nend-to-end question answering pipeline. This paper explores the effectiveness\nof convolutional neural networks (CNNs) for answer selection in an end-to-end\ncontext using the standard TrecQA dataset. We observe that a simple\nidf-weighted word overlap algorithm forms a very strong baseline, and that\ndespite substantial efforts by the community in applying deep learning to\ntackle answer selection, the gains are modest at best on this dataset.\nFurthermore, it is unclear if a CNN is more effective than the baseline in an\nend-to-end context based on standard retrieval metrics. To further explore this\nfinding, we conducted a manual user evaluation, which confirms that answers\nfrom the CNN are detectably better than those from idf-weighted word overlap.\nThis result suggests that users are sensitive to relatively small differences\nin answer selection quality.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 03:38:57 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Sequiera", "Royal", ""], ["Baruah", "Gaurav", ""], ["Tu", "Zhucheng", ""], ["Mohammed", "Salman", ""], ["Rao", "Jinfeng", ""], ["Zhang", "Haotian", ""], ["Lin", "Jimmy", ""]]}, {"id": "1707.07835", "submitter": "Ajinkya Kale", "authors": "Ajinkya Kale, Thrivikrama Taula, Sanjika Hewavitharana, Amit\n  Srivastava", "title": "Towards Semantic Query Segmentation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query Segmentation is one of the critical components for understanding users'\nsearch intent in Information Retrieval tasks. It involves grouping tokens in\nthe search query into meaningful phrases which help downstream tasks like\nsearch relevance and query understanding. In this paper, we propose a novel\napproach to segment user queries using distributed query embeddings. Our key\ncontribution is a supervised approach to the segmentation task using\nlow-dimensional feature vectors for queries, getting rid of traditional hand\ntuned and heuristic NLP features which are quite expensive.\n  We benchmark on a 50,000 human-annotated web search engine query corpus\nachieving comparable accuracy to state-of-the-art techniques. The advantage of\nour technique is its fast and does not use external knowledge-base like\nWikipedia for score boosting. This helps us generalize our approach to other\ndomains like eCommerce without any fine-tuning. We demonstrate the\neffectiveness of this method on another 50,000 human-annotated eCommerce query\ncorpus from eBay search logs. Our approach is easy to implement and generalizes\nwell across different search domains proving the power of low-dimensional\nembeddings in query segmentation task, opening up a new direction of research\nfor this problem.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 06:57:39 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Kale", "Ajinkya", ""], ["Taula", "Thrivikrama", ""], ["Hewavitharana", "Sanjika", ""], ["Srivastava", "Amit", ""]]}, {"id": "1707.07847", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui", "title": "Hyperbolic Representation Learning for Fast and Efficient Neural\n  Question Answering", "comments": "Accepted at WSDM 2018", "journal-ref": null, "doi": "10.1145/3159652.3159664", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dominant neural architectures in question answer retrieval are based on\nrecurrent or convolutional encoders configured with complex word matching\nlayers. Given that recent architectural innovations are mostly new word\ninteraction layers or attention-based matching mechanisms, it seems to be a\nwell-established fact that these components are mandatory for good performance.\nUnfortunately, the memory and computation cost incurred by these complex\nmechanisms are undesirable for practical applications. As such, this paper\ntackles the question of whether it is possible to achieve competitive\nperformance with simple neural architectures. We propose a simple but novel\ndeep learning architecture for fast and efficient question-answer ranking and\nretrieval. More specifically, our proposed model, \\textsc{HyperQA}, is a\nparameter efficient neural network that outperforms other parameter intensive\nmodels such as Attentive Pooling BiLSTMs and Multi-Perspective CNNs on multiple\nQA benchmarks. The novelty behind \\textsc{HyperQA} is a pairwise ranking\nobjective that models the relationship between question and answer embeddings\nin Hyperbolic space instead of Euclidean space. This empowers our model with a\nself-organizing ability and enables automatic discovery of latent hierarchies\nwhile learning embeddings of questions and answers. Our model requires no\nfeature engineering, no similarity matrix matching, no complicated attention\nmechanisms nor over-parameterized layers and yet outperforms and remains\ncompetitive to many models that have these functionalities on multiple\nbenchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 08:21:30 GMT"}, {"version": "v2", "created": "Thu, 27 Jul 2017 01:21:20 GMT"}, {"version": "v3", "created": "Thu, 23 Nov 2017 05:54:17 GMT"}], "update_date": "2017-11-27", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1707.07930", "submitter": "Christophe Van Gysel", "authors": "Christophe Van Gysel, Maarten de Rijke and Evangelos Kanoulas", "title": "Structural Regularities in Text-based Entity Vector Spaces", "comments": "ICTIR2017. Proceedings of the 3rd ACM International Conference on the\n  Theory of Information Retrieval. 2017", "journal-ref": null, "doi": "10.1145/3121050.3121066", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity retrieval is the task of finding entities such as people or products\nin response to a query, based solely on the textual documents they are\nassociated with. Recent semantic entity retrieval algorithms represent queries\nand experts in finite-dimensional vector spaces, where both are constructed\nfrom text sequences.\n  We investigate entity vector spaces and the degree to which they capture\nstructural regularities. Such vector spaces are constructed in an unsupervised\nmanner without explicit information about structural aspects. For concreteness,\nwe address these questions for a specific type of entity: experts in the\ncontext of expert finding. We discover how clusterings of experts correspond to\ncommittees in organizations, the ability of expert representations to encode\nthe co-author graph, and the degree to which they encode academic rank. We\ncompare latent, continuous representations created using methods based on\ndistributional semantics (LSI), topic models (LDA) and neural networks\n(word2vec, doc2vec, SERT). Vector spaces created using neural methods, such as\ndoc2vec and SERT, systematically perform better at clustering than LSI, LDA and\nword2vec. When it comes to encoding entity relations, SERT performs best.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 11:54:19 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Van Gysel", "Christophe", ""], ["de Rijke", "Maarten", ""], ["Kanoulas", "Evangelos", ""]]}, {"id": "1707.08029", "submitter": "Dietmar Jannach", "authors": "Dietmar Jannach and Gediminas Adomavicius", "title": "Price and Profit Awareness in Recommender Systems", "comments": "Presented at the 2017 Workshop on Value-Aware and Multi-Stakeholder\n  Recommendation (VAMS) collocated with ACM RecSys 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Academic research in the field of recommender systems mainly focuses on the\nproblem of maximizing the users' utility by trying to identify the most\nrelevant items for each user. However, such items are not necessarily the ones\nthat maximize the utility of the service provider (e.g., an online retailer) in\nterms of the business value, such as profit. One approach to increasing the\nproviders' utility is to incorporate purchase-oriented information, e.g., the\nprice, sales probabilities, and the resulting profit, into the recommendation\nalgorithms. In this paper we specifically focus on price- and profit-aware\nrecommender systems. We provide a brief overview of the relevant literature and\nuse numerical simulations to illustrate the potential business benefit of such\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 15:07:33 GMT"}], "update_date": "2017-07-26", "authors_parsed": [["Jannach", "Dietmar", ""], ["Adomavicius", "Gediminas", ""]]}, {"id": "1707.08113", "submitter": "Huasha Zhao Mr", "authors": "Huasha Zhao, Luo Si, Xiaogang Li, Qiong Zhang", "title": "Recommending Complementary Products in E-Commerce Push Notifications\n  with a Mixture Model Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Push notification is a key component for E-commerce mobile applications,\nwhich has been extensively used for user growth and engagement. The\neffectiveness of the push notification is generally measured by message open\nrate. A push message can contain a recommended product, a shopping news and\netc., but often only one or two items can be shown in the push message due to\nthe limit of display space. This paper proposes a mixture model approach for\npredicting push message open rate for a post-purchase complementary product\nrecommendation task. The mixture model is trained to learn latent prediction\ncontexts, which are determined by user and item profiles, and then make open\nrate predictions accordingly. The item with the highest predicted open rate is\nthen chosen to be included in the push notification message for each user. The\nparameters of the mixture model are optimized using an EM algorithm. A set of\nexperiments are conducted to evaluate the proposed method live with a popular\nE-Commerce mobile app. The results show that the proposed method is superior\nthan several existing solutions by a significant margin.\n", "versions": [{"version": "v1", "created": "Tue, 25 Jul 2017 04:36:09 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Zhao", "Huasha", ""], ["Si", "Luo", ""], ["Li", "Xiaogang", ""], ["Zhang", "Qiong", ""]]}, {"id": "1707.08275", "submitter": "Jimmy Lin", "authors": "Zhucheng Tu, Matt Crane, Royal Sequiera, Junchen Zhang, and Jimmy Lin", "title": "An Exploration of Approaches to Integrating Neural Reranking Models in\n  Multi-Stage Ranking Architectures", "comments": "SIGIR 2017 Workshop on Neural Information Retrieval (Neu-IR'17),\n  August 7-11, 2017, Shinjuku, Tokyo, Japan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore different approaches to integrating a simple convolutional neural\nnetwork (CNN) with the Lucene search engine in a multi-stage ranking\narchitecture. Our models are trained using the PyTorch deep learning toolkit,\nwhich is implemented in C/C++ with a Python frontend. One obvious integration\nstrategy is to expose the neural network directly as a service. For this, we\nuse Apache Thrift, a software framework for building scalable cross-language\nservices. In exploring alternative architectures, we observe that once trained,\nthe feedforward evaluation of neural networks is quite straightforward.\nTherefore, we can extract the parameters of a trained CNN from PyTorch and\nimport the model into Java, taking advantage of the Java Deeplearning4J library\nfor feedforward evaluation. This has the advantage that the entire end-to-end\nsystem can be implemented in Java. As a third approach, we can extract the\nneural network from PyTorch and \"compile\" it into a C++ program that exposes a\nThrift service. We evaluate these alternatives in terms of performance (latency\nand throughput) as well as ease of integration. Experiments show that\nfeedforward evaluation of the convolutional neural network is significantly\nslower in Java, while the performance of the compiled C++ network does not\nconsistently beat the PyTorch implementation.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 02:17:05 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Tu", "Zhucheng", ""], ["Crane", "Matt", ""], ["Sequiera", "Royal", ""], ["Zhang", "Junchen", ""], ["Lin", "Jimmy", ""]]}, {"id": "1707.08309", "submitter": "Subhabrata Mukherjee", "authors": "Subhabrata Mukherjee", "title": "Probabilistic Graphical Models for Credibility Analysis in Evolving\n  Online Communities", "comments": "PhD thesis, Mar 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major hurdles preventing the full exploitation of information from\nonline communities is the widespread concern regarding the quality and\ncredibility of user-contributed content. Prior works in this domain operate on\na static snapshot of the community, making strong assumptions about the\nstructure of the data (e.g., relational tables), or consider only shallow\nfeatures for text classification.\n  To address the above limitations, we propose probabilistic graphical models\nthat can leverage the joint interplay between multiple factors in online\ncommunities --- like user interactions, community dynamics, and textual content\n--- to automatically assess the credibility of user-contributed online content,\nand the expertise of users and their evolution with user-interpretable\nexplanation. To this end, we devise new models based on Conditional Random\nFields for different settings like incorporating partial expert knowledge for\nsemi-supervised learning, and handling discrete labels as well as numeric\nratings for fine-grained analysis. This enables applications such as extracting\nreliable side-effects of drugs from user-contributed posts in healthforums, and\nidentifying credible content in news communities.\n  Online communities are dynamic, as users join and leave, adapt to evolving\ntrends, and mature over time. To capture this dynamics, we propose generative\nmodels based on Hidden Markov Model, Latent Dirichlet Allocation, and Brownian\nMotion to trace the continuous evolution of user expertise and their language\nmodel over time. This allows us to identify expert users and credible content\njointly over time, improving state-of-the-art recommender systems by explicitly\nconsidering the maturity of users. This also enables applications such as\nidentifying helpful product reviews, and detecting fake and anomalous reviews\nwith limited information.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 07:41:27 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Mukherjee", "Subhabrata", ""]]}, {"id": "1707.08322", "submitter": "Qing-Yuan Jiang", "authors": "Qing-Yuan Jiang, Wu-Jun Li", "title": "Discrete Latent Factor Model for Cross-Modal Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its storage and retrieval efficiency, cross-modal hashing~(CMH) has\nbeen widely used for cross-modal similarity search in multimedia applications.\nAccording to the training strategy, existing CMH methods can be mainly divided\ninto two categories: relaxation-based continuous methods and discrete methods.\nIn general, the training of relaxation-based continuous methods is faster than\ndiscrete methods, but the accuracy of relaxation-based continuous methods is\nnot satisfactory. On the contrary, the accuracy of discrete methods is\ntypically better than relaxation-based continuous methods, but the training of\ndiscrete methods is time-consuming. In this paper, we propose a novel CMH\nmethod, called discrete latent factor model based cross-modal hashing~(DLFH),\nfor cross modal similarity search. DLFH is a discrete method which can directly\nlearn the binary hash codes for CMH. At the same time, the training of DLFH is\nefficient. Experiments on real datasets show that DLFH can achieve\nsignificantly better accuracy than existing methods, and the training time of\nDLFH is comparable to that of relaxation-based continuous methods which are\nmuch faster than existing discrete methods.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 08:49:11 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Jiang", "Qing-Yuan", ""], ["Li", "Wu-Jun", ""]]}, {"id": "1707.08361", "submitter": "Lucia Vadicamo", "authors": "Richard Connor, Lucia Vadicamo, Franco Alberto Cardillo, Fausto\n  Rabitti", "title": "Supermetric Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metric search is concerned with the efficient evaluation of queries in metric\nspaces. In general,a large space of objects is arranged in such a way that,\nwhen a further object is presented as a query, those objects most similar to\nthe query can be efficiently found. Most mechanisms rely upon the triangle\ninequality property of the metric governing the space. The triangle inequality\nproperty is equivalent to a finite embedding property, which states that any\nthree points of the space can be isometrically embedded in two-dimensional\nEuclidean space. In this paper, we examine a class of semimetric space which is\nfinitely four-embeddable in three-dimensional Euclidean space. In mathematics\nthis property has been extensively studied and is generally known as the\nfour-point property. All spaces with the four-point property are metric spaces,\nbut they also have some stronger geometric guarantees. We coin the term\nsupermetric space as, in terms of metric search, they are significantly more\ntractable. Supermetric spaces include all those governed by Euclidean, Cosine,\nJensen-Shannon and Triangular distances, and are thus commonly used within many\ndomains. In previous work we have given a generic mathematical basis for the\nsupermetric property and shown how it can improve indexing performance for a\ngiven exact search structure. Here we present a full investigation into its use\nwithin a variety of different hyperplane partition indexing structures, and go\non to show some more of its flexibility by examining a search structure whose\npartition and exclusion conditions are tailored, at each node, to suit the\nindividual reference points and data set present there. Among the results\ngiven, we show a new best performance for exact search using a well-known\nbenchmark.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 10:32:21 GMT"}, {"version": "v2", "created": "Sun, 22 Oct 2017 16:46:24 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Connor", "Richard", ""], ["Vadicamo", "Lucia", ""], ["Cardillo", "Franco Alberto", ""], ["Rabitti", "Fausto", ""]]}, {"id": "1707.08370", "submitter": "Lucia Vadicamo", "authors": "Richard Connor, Lucia Vadicamo, Fausto Rabitti", "title": "High-Dimensional Simplexes for Supermetric Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 1953, Blumenthal showed that every semi-metric space that is isometrically\nembeddable in a Hilbert space has the n-point property; we have previously\ncalled such spaces supermetric spaces. Although this is a strictly stronger\nproperty than triangle inequality, it is nonetheless closely related and many\nuseful metric spaces possess it. These include Euclidean, Cosine and\nJensen-Shannon spaces of any dimension. A simple corollary of the n-point\nproperty is that, for any (n+1) objects sampled from the space, there exists an\nn-dimensional simplex in Euclidean space whose edge lengths correspond to the\ndistances among the objects. We show how the construction of such simplexes in\nhigher dimensions can be used to give arbitrarily tight lower and upper bounds\non distances within the original space. This allows the construction of an\nn-dimensional Euclidean space, from which lower and upper bounds of the\noriginal space can be calculated, and which is itself an indexable space with\nthe n-point property. For similarity search, the engineering tradeoffs are\ngood: we show significant reductions in data size and metric cost with little\nloss of accuracy, leading to a significant overall improvement in search\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jul 2017 10:52:28 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Connor", "Richard", ""], ["Vadicamo", "Lucia", ""], ["Rabitti", "Fausto", ""]]}, {"id": "1707.08913", "submitter": "Yong Zheng", "authors": "Yong Zheng", "title": "Multi-Stakeholder Recommendation: Applications and Challenges", "comments": "Presented at the 2017 Workshop on Value-Aware and Multistakeholder\n  Recommendation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems have been successfully applied to assist decision making\nby producing a list of item recommendations tailored to user preferences.\nTraditional recommender systems only focus on optimizing the utility of the end\nusers who are the receiver of the recommendations. By contrast,\nmulti-stakeholder recommendation attempts to generate recommendations that\nsatisfy the needs of both the end users and other parties or stakeholders. This\npaper provides an overview and discussion about the multi-stakeholder\nrecommendations from the perspective of practical applications, available data\nsets, corresponding research challenges and potential solutions.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 15:52:18 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Zheng", "Yong", ""]]}, {"id": "1707.09075", "submitter": "Pedro Saleiro", "authors": "Pedro Saleiro, Natasa Milic-Frayling, Eduarda Mendes Rodrigues, Carlos\n  Soares", "title": "Early Fusion Strategy for Entity-Relationship Retrieval", "comments": "KG4IR (SIGIR workshop)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the task of entity-relationship (E-R) retrieval, i.e, given a\nquery characterizing types of two or more entities and relationships between\nthem, retrieve the relevant tuples of related entities. Answering E-R queries\nrequires gathering and joining evidence from multiple unstructured documents.\nIn this work, we consider entity and relationships of any type, i.e,\ncharacterized by context terms instead of pre-defined types or relationships.\nWe propose a novel IR-centric approach for E-R retrieval, that builds on the\nbasic early fusion design pattern for object retrieval, to provide extensible\nentity-relationship representations, suitable for complex, multi-relationships\nqueries. We performed experiments with Wikipedia articles as entity\nrepresentations combined with relationships extracted from ClueWeb-09-B with\nFACC1 entity linking. We obtained promising results using 3 different query\ncollections comprising 469 E-R queries.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jul 2017 23:33:06 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 10:15:40 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Saleiro", "Pedro", ""], ["Milic-Frayling", "Natasa", ""], ["Rodrigues", "Eduarda Mendes", ""], ["Soares", "Carlos", ""]]}, {"id": "1707.09217", "submitter": "Gerhard Gossen", "authors": "Gerhard Gossen and Elena Demidova and Thomas Risse", "title": "Extracting Event-Centric Document Collections from Large-Scale Web\n  Archives", "comments": "To be published in the proceedings of the Conference on Theory and\n  Practice of Digital Libraries (TPDL) 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web archives are typically very broad in scope and extremely large in scale.\nThis makes data analysis appear daunting, especially for non-computer\nscientists. These collections constitute an increasingly important source for\nresearchers in the social sciences, the historical sciences and journalists\ninterested in studying past events. However, there are currently no access\nmethods that help users to efficiently access information, in particular about\nspecific events, beyond the retrieval of individual disconnected documents.\nTherefore we propose a novel method to extract event-centric document\ncollections from large scale Web archives. This method relies on a specialized\nfocused extraction algorithm. Our experiments on the German Web archive\n(covering a time period of 19 years) demonstrate that our method enables the\nextraction of event-centric collections for different event types.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 13:18:01 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Gossen", "Gerhard", ""], ["Demidova", "Elena", ""], ["Risse", "Thomas", ""]]}, {"id": "1707.09258", "submitter": "Robin Burke", "authors": "Robin Burke, Himan Abdollahpouri", "title": "Patterns of Multistakeholder Recommendation", "comments": "Presented at the 2017 Workshop on Value-Aware and Multistakeholder\n  Recommendation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are personalized information systems. However, in many\nsettings, the end-user of the recommendations is not the only party whose needs\nmust be represented in recommendation generation. Incorporating this insight\ngives rise to the notion of multistakeholder recommendation, in which the\ninterests of multiple parties are represented in recommendation algorithms and\nevaluation. In this paper, we identify patterns of stakeholder utility that\ncharacterize different multistakeholder recommendation applications, and\nprovide a taxonomy of the different possible systems, only some of which have\ncurrently been implemented.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 14:42:34 GMT"}], "update_date": "2017-07-31", "authors_parsed": [["Burke", "Robin", ""], ["Abdollahpouri", "Himan", ""]]}, {"id": "1707.09790", "submitter": "Carsten Eickhoff", "authors": "Zsolt Mezei, Carsten Eickhoff", "title": "Evaluating Music Recommender Systems for Groups", "comments": "Presented at the 2017 Workshop on Value-Aware and Multistakeholder\n  Recommendation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation to groups of users is a challenging and currently only\npassingly studied task. Especially the evaluation aspect often appears ad-hoc\nand instead of truly evaluating on groups of users, synthesizes groups by\nmerging individual preferences.\n  In this paper, we present a user study, recording the individual and shared\npreferences of actual groups of participants, resulting in a robust,\nstandardized evaluation benchmark. Using this benchmarking dataset, that we\nshare with the research community, we compare the respective performance of a\nwide range of music group recommendation techniques proposed in the\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 10:00:55 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Mezei", "Zsolt", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "1707.09823", "submitter": "Chen Li", "authors": "Di Jiang, Zeyu Chen, Rongzhong Lian, Siqi Bao, Chen Li", "title": "Familia: An Open-Source Toolkit for Industrial Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Familia is an open-source toolkit for pragmatic topic modeling in industry.\nFamilia abstracts the utilities of topic modeling in industry as two paradigms:\nsemantic representation and semantic matching. Efficient implementations of the\ntwo paradigms are made publicly available for the first time. Furthermore, we\nprovide off-the-shelf topic models trained on large-scale industrial corpora,\nincluding Latent Dirichlet Allocation (LDA), SentenceLDA and Topical Word\nEmbedding (TWE). We further describe typical applications which are\nsuccessfully powered by topic modeling, in order to ease the confusions and\ndifficulties of software engineers during topic model selection and\nutilization.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 12:48:45 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Jiang", "Di", ""], ["Chen", "Zeyu", ""], ["Lian", "Rongzhong", ""], ["Bao", "Siqi", ""], ["Li", "Chen", ""]]}, {"id": "1707.09887", "submitter": "Matthias Dorfer", "authors": "Matthias Dorfer, Andreas Arzt, Gerhard Widmer", "title": "Learning Audio - Sheet Music Correspondences for Score Identification\n  and Offline Alignment", "comments": "In Proceedings of the 18th International Society for Music\n  Information Retrieval Conference (ISMIR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses the problem of matching short excerpts of audio with\ntheir respective counterparts in sheet music images. We show how to employ\nneural network-based cross-modality embedding spaces for solving the following\ntwo sheet music-related tasks: retrieving the correct piece of sheet music from\na database when given a music audio as a search query; and aligning an audio\nrecording of a piece with the corresponding images of sheet music. We\ndemonstrate the feasibility of this in experiments on classical piano music by\nfive different composers (Bach, Haydn, Mozart, Beethoven and Chopin), and\nadditionally provide a discussion on why we expect multi-modal neural networks\nto be a fruitful paradigm for dealing with sheet music and audio at the same\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 14:36:42 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Dorfer", "Matthias", ""], ["Arzt", "Andreas", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1707.09899", "submitter": "Ashwinkumar Ganesan", "authors": "Prutha Date, Ashwinkumar Ganesan, Tim Oates", "title": "Fashioning with Networks: Neural Style Transfer to Design Clothes", "comments": "ML4Fashion 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks have been highly successful in performing a\nhost of computer vision tasks such as object recognition, object detection,\nimage segmentation and texture synthesis. In 2015, Gatys et. al [7] show how\nthe style of a painter can be extracted from an image of the painting and\napplied to another normal photograph, thus recreating the photo in the style of\nthe painter. The method has been successfully applied to a wide range of images\nand has since spawned multiple applications and mobile apps. In this paper, the\nneural style transfer algorithm is applied to fashion so as to synthesize new\ncustom clothes. We construct an approach to personalize and generate new custom\nclothes based on a users preference and by learning the users fashion choices\nfrom a limited set of clothes from their closet. The approach is evaluated by\nanalyzing the generated images of clothes and how well they align with the\nusers fashion style.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 14:54:11 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Date", "Prutha", ""], ["Ganesan", "Ashwinkumar", ""], ["Oates", "Tim", ""]]}, {"id": "1707.09905", "submitter": "Qing-Yuan Jiang", "authors": "Qing-Yuan Jiang, Xue Cui, Wu-Jun Li", "title": "Deep Discrete Supervised Hashing", "comments": null, "journal-ref": null, "doi": "10.1109/TIP.2018.2864894", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hashing has been widely used for large-scale search due to its low storage\ncost and fast query speed. By using supervised information, supervised hashing\ncan significantly outperform unsupervised hashing. Recently, discrete\nsupervised hashing and deep hashing are two representative progresses in\nsupervised hashing. On one hand, hashing is essentially a discrete optimization\nproblem. Hence, utilizing supervised information to directly guide discrete\n(binary) coding procedure can avoid sub-optimal solution and improve the\naccuracy. On the other hand, deep hashing, which integrates deep feature\nlearning and hash-code learning into an end-to-end architecture, can enhance\nthe feedback between feature learning and hash-code learning. The key in\ndiscrete supervised hashing is to adopt supervised information to directly\nguide the discrete coding procedure in hashing. The key in deep hashing is to\nadopt the supervised information to directly guide the deep feature learning\nprocedure. However, there have not existed works which can use the supervised\ninformation to directly guide both discrete coding procedure and deep feature\nlearning procedure in the same framework. In this paper, we propose a novel\ndeep hashing method, called deep discrete supervised hashing (DDSH), to address\nthis problem. DDSH is the first deep hashing method which can utilize\nsupervised information to directly guide both discrete coding procedure and\ndeep feature learning procedure, and thus enhance the feedback between these\ntwo important procedures. Experiments on three real datasets show that DDSH can\noutperform other state-of-the-art baselines, including both discrete hashing\nand deep hashing baselines, for image retrieval.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jul 2017 15:00:55 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Jiang", "Qing-Yuan", ""], ["Cui", "Xue", ""], ["Li", "Wu-Jun", ""]]}]