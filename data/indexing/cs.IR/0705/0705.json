[{"id": "0705.0751", "submitter": "Pere Constans", "authors": "Pere Constans", "title": "Approximate textual retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": null, "abstract": "  An approximate textual retrieval algorithm for searching sources with high\nlevels of defects is presented. It considers splitting the words in a query\ninto two overlapping segments and subsequently building composite regular\nexpressions from interlacing subsets of the segments. This procedure reduces\nthe probability of missed occurrences due to source defects, yet diminishes the\nretrieval of irrelevant, non-contextual occurrences.\n", "versions": [{"version": "v1", "created": "Sat, 5 May 2007 17:27:42 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Constans", "Pere", ""]]}, {"id": "0705.1161", "submitter": "Lillian Lee", "authors": "Lillian Lee", "title": "IDF revisited: A simple new derivation within the Robertson-Sp\\\"arck\n  Jones probabilistic model", "comments": "To appear, Proceedings of SIGIR 2007, poster paper (2 pages)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": null, "abstract": "  There have been a number of prior attempts to theoretically justify the\neffectiveness of the inverse document frequency (IDF). Those that take as their\nstarting point Robertson and Sparck Jones's probabilistic model are based on\nstrong or complex assumptions. We show that a more intuitively plausible\nassumption suffices. Moreover, the new assumption, while conceptually very\nsimple, provides a solution to an estimation problem that had been deemed\nintractable by Robertson and Walker (1997).\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2007 20:08:13 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Lee", "Lillian", ""]]}, {"id": "0705.1886", "submitter": "Francoise Armand", "authors": "Michel Crampes (LGI2P), Sylvie Ranwez (LGI2P)", "title": "Ontology-Supported and Ontology-Driven Conceptual Navigation on the\n  World Wide Web", "comments": null, "journal-ref": "Proceedings Hypertext 2000 (2000) 80", "doi": null, "report-no": null, "categories": "cs.IR", "license": null, "abstract": "  This paper presents the principles of ontology-supported and ontology-driven\nconceptual navigation. Conceptual navigation realizes the independence between\nresources and links to facilitate interoperability and reusability. An engine\nbuilds dynamic links, assembles resources under an argumentative scheme and\nallows optimization with a possible constraint, such as the user's available\ntime. Among several strategies, two are discussed in detail with examples of\napplications. On the one hand, conceptual specifications for linking and\nassembling are embedded in the resource meta-description with the support of\nthe ontology of the domain to facilitate meta-communication. Resources are like\nagents looking for conceptual acquaintances with intention. On the other hand,\nthe domain ontology and an argumentative ontology drive the linking and\nassembling strategies.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2007 08:19:28 GMT"}], "update_date": "2007-05-23", "authors_parsed": [["Crampes", "Michel", "", "LGI2P"], ["Ranwez", "Sylvie", "", "LGI2P"]]}, {"id": "0705.2106", "submitter": "Finn {\\AA}rup Nielsen", "authors": "Finn Aarup Nielsen", "title": "Scientific citations in Wikipedia", "comments": "5 pages, 2 figures", "journal-ref": "First Monday, 12(8), 2007 August", "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": null, "abstract": "  The Internet-based encyclopaedia Wikipedia has grown to become one of the\nmost visited web-sites on the Internet. However, critics have questioned the\nquality of entries, and an empirical study has shown Wikipedia to contain\nerrors in a 2005 sample of science entries. Biased coverage and lack of sources\nare among the \"Wikipedia risks\". The present work describes a simple assessment\nof these aspects by examining the outbound links from Wikipedia articles to\narticles in scientific journals with a comparison against journal statistics\nfrom Journal Citation Reports such as impact factors. The results show an\nincreasing use of structured citation markup and good agreement with the\ncitation pattern seen in the scientific literature though with a slight\ntendency to cite articles in high-impact journals such as Nature and Science.\nThese results increase confidence in Wikipedia as an good information organizer\nfor science in general.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2007 09:42:30 GMT"}], "update_date": "2011-01-04", "authors_parsed": [["Nielsen", "Finn Aarup", ""]]}, {"id": "0705.4606", "submitter": "Marco Pellegrini", "authors": "Filippo Geraci and Marco Pellegrini", "title": "Dynamic User-Defined Similarity Searching in Semi-Structured Text\n  Retrieval", "comments": "Submitted to Spire 2007", "journal-ref": null, "doi": null, "report-no": "IIT TR-07/2007", "categories": "cs.IR cs.DS", "license": null, "abstract": "  Modern text retrieval systems often provide a similarity search utility, that\nallows the user to find efficiently a fixed number k of documents in the data\nset that are most similar to a given query (here a query is either a simple\nsequence of keywords or the identifier of a full document found in previous\nsearches that is considered of interest). We consider the case of a textual\ndatabase made of semi-structured documents. Each field, in turns, is modelled\nwith a specific vector space. The problem is more complex when we also allow\neach such vector space to have an associated user-defined dynamic weight that\ninfluences its contribution to the overall dynamic aggregated and weighted\nsimilarity. This dynamic problem has been tackled in a recent paper by\nSingitham et al. in in VLDB 2004. Their proposed solution, which we take as\nbaseline, is a variant of the cluster-pruning technique that has the potential\nfor scaling to very large corpora of documents, and is far more efficient than\nthe naive exhaustive search. We devise an alternative way of embedding weights\nin the data structure, coupled with a non-trivial application of a clustering\nalgorithm based on the furthest point first heuristic for the metric k-center\nproblem. The validity of our approach is demonstrated experimentally by showing\nsignificant performance improvements over the scheme proposed in Singitham et\nal. in VLDB 2004. We improve significantly tradeoffs between query time and\noutput quality with respect to the baseline method in Singitham et al. in in\nVLDB 2004, and also with respect to a novel method by Chierichetti et al. to\nappear in ACM PODS 2007. We also speed up the pre-processing time by a factor\nat least thirty.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2007 13:46:39 GMT"}], "update_date": "2007-06-01", "authors_parsed": [["Geraci", "Filippo", ""], ["Pellegrini", "Marco", ""]]}]