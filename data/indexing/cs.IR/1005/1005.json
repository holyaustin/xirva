[{"id": "1005.0268", "submitter": "Andri Mirzal M.Sc.", "authors": "Andri Mirzal and Masashi Furukawa", "title": "Node-Context Network Clustering using PARAFAC Tensor Decomposition", "comments": "6 pages, 4 figures, International Conference on Information &\n  Communication Technology and Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We describe a clustering method for labeled link network (semantic graph)\nthat can be used to group important nodes (highly connected nodes) with their\nrelevant link's labels by using PARAFAC tensor decomposition. In this kind of\nnetwork, the adjacency matrix can not be used to fully describe all information\nabout the network structure. We have to expand the matrix into 3-way adjacency\ntensor, so that not only the information about to which nodes a node connects\nto but by which link's labels is also included. And by applying PARAFAC\ndecomposition on this tensor, we get two lists, nodes and link's labels with\nscores attached to each node and labels, for each decomposition group. So\nclustering process to get the important nodes along with their relevant labels\ncan be done simply by sorting the lists in decreasing order. To test the\nmethod, we construct labeled link network by using blog's dataset, where the\nblogs are the nodes and labeled links are the shared words among them. The\nsimilarity measures between the results and standard measures look promising,\nespecially for two most important tasks, finding the most relevant words to\nblogs query and finding the most similar blogs to blogs query, about 0.87.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2010 12:28:42 GMT"}], "update_date": "2010-05-04", "authors_parsed": [["Mirzal", "Andri", ""], ["Furukawa", "Masashi", ""]]}, {"id": "1005.0961", "submitter": "Rdv Ijcsis", "authors": "M. Umamaheswari, S. Sivasubramanian", "title": "Performance Oriented Query Processing In GEO Based Location Search\n  Engines", "comments": "IEEE Publication format, International Journal of Computer Science\n  and Information Security, IJCSIS, Vol. 8 No. 1, April 2010, USA. ISSN 1947\n  5500, http://sites.google.com/site/ijcsis/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Geographic location search engines allow users to constrain and order search\nresults in an intuitive manner by focusing a query on a particular geographic\nregion. Geographic search technology, also called location search, has recently\nreceived significant interest from major search engine companies. Academic\nresearch in this area has focused primarily on techniques for extracting\ngeographic knowledge from the web. In this paper, we study the problem of\nefficient query processing in scalable geographic search engines. Query\nprocessing is a major bottleneck in standard web search engines, and the main\nreason for the thousands of machines used by the major engines. Geographic\nsearch engine query processing is different in that it requires a combination\nof text and spatial data processing techniques. We propose several algorithms\nfor efficient query processing in geographic search engines, integrate them\ninto an existing web search query processor, and evaluate them on large sets of\nreal data and query traces.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2010 10:09:09 GMT"}], "update_date": "2010-05-07", "authors_parsed": [["Umamaheswari", "M.", ""], ["Sivasubramanian", "S.", ""]]}, {"id": "1005.1340", "submitter": "Jacek Gwizdka", "authors": "Jacek Gwizdka", "title": "Distribution of Cognitive Load in Web Search", "comments": "To appear in the Journal of the American Society for Information\n  Science & Technology (JASIST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The search task and the system both affect the demand on cognitive resources\nduring information search. In some situations, the demands may become too high\nfor a person. This article has a three-fold goal. First, it presents and\ncritiques methods to measure cognitive load. Second, it explores the\ndistribution of load across search task stages. Finally, it seeks to improve\nour understanding of factors affecting cognitive load levels in information\nsearch. To this end, a controlled Web search experiment with forty-eight\nparticipants was conducted. Interaction logs were used to segment search tasks\nsemi-automatically into task stages. Cognitive load was assessed using a new\nvariant of the dual-task method. Average cognitive load was found to vary by\nsearch task stages. It was significantly higher during query formulation and\nuser description of a relevant document as compared to examining search results\nand viewing individual documents. Semantic information shown next to the search\nresults lists in one of the studied interfaces was found to decrease mental\ndemands during query formulation and examination of the search results list.\nThese findings demonstrate that changes in dynamic cognitive load can be\ndetected within search tasks. Dynamic assessment of cognitive load is of core\ninterest to information science because it enriches our understanding of\ncognitive demands imposed on people engaged in the search process by a task and\nthe interactive information retrieval system employed.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2010 15:37:54 GMT"}, {"version": "v2", "created": "Sun, 16 May 2010 17:12:13 GMT"}], "update_date": "2010-05-18", "authors_parsed": [["Gwizdka", "Jacek", ""]]}, {"id": "1005.2308", "submitter": "Edwin Henneken", "authors": "Edwin A. Henneken, Michael J. Kurtz, Alberto Accomazzi, Carolyn Grant,\n  Donna Thompson, Elizabeth Bohlen, Giovanni Di Milia, Jay Luker, Stephen S.\n  Murray", "title": "Finding Your Literature Match -- A Recommender System", "comments": "Contribution to the proceedings of the colloquium Future Professional\n  Communication in Astronomy II, 13-14 April 2010, Cambridge, Massachusetts. 11\n  pages, 4 figures.", "journal-ref": null, "doi": "10.1007/978-1-4419-8369-5_14", "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The universe of potentially interesting, searchable literature is expanding\ncontinuously. Besides the normal expansion, there is an additional influx of\nliterature because of interdisciplinary boundaries becoming more and more\ndiffuse. Hence, the need for accurate, efficient and intelligent search tools\nis bigger than ever. Even with a sophisticated search engine, looking for\ninformation can still result in overwhelming results. An overload of\ninformation has the intrinsic danger of scaring visitors away, and any\norganization, for-profit or not-for-profit, in the business of providing\nscholarly information wants to capture and keep the attention of its target\naudience. Publishers and search engine engineers alike will benefit from a\nservice that is able to provide visitors with recommendations that closely meet\ntheir interests. Providing visitors with special deals, new options and\nhighlights may be interesting to a certain degree, but what makes more sense\n(especially from a commercial point of view) than to let visitors do most of\nthe work by the mere action of making choices? Hiring psychics is not an\noption, so a technological solution is needed to recommend items that a visitor\nis likely to be looking for. In this presentation we will introduce such a\nsolution and argue that it is practically feasible to incorporate this approach\ninto a useful addition to any information retrieval system with enough usage.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2010 12:35:22 GMT"}], "update_date": "2016-01-27", "authors_parsed": [["Henneken", "Edwin A.", ""], ["Kurtz", "Michael J.", ""], ["Accomazzi", "Alberto", ""], ["Grant", "Carolyn", ""], ["Thompson", "Donna", ""], ["Bohlen", "Elizabeth", ""], ["Di Milia", "Giovanni", ""], ["Luker", "Jay", ""], ["Murray", "Stephen S.", ""]]}, {"id": "1005.2533", "submitter": "Yeung Chi Ho", "authors": "C. H. Yeung, G. Cimini and C.-H. Jin", "title": "Dynamics underlying Box-office: Movie Competition on Recommender Systems", "comments": "8 pages, 6 figures", "journal-ref": "Phys. Rev. E 83, 016105 (2011)", "doi": "10.1103/PhysRevE.83.016105", "report-no": null, "categories": "physics.soc-ph cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a simple model to study movie competition in the recommender\nsystems. Movies of heterogeneous quality compete against each other through\nviewers' reviews and generate interesting dynamics of box-office. By assuming\nmean-field interactions between the competing movies, we show that run-away\neffect of popularity spreading is triggered by defeating the average review\nscore, leading to hits in box-office. The average review score thus\ncharacterizes the critical movie quality necessary for transition from\nbox-office bombs to blockbusters. The major factors affecting the critical\nreview score are examined. By iterating the mean-field dynamical equations, we\nobtain qualitative agreements with simulations and real systems in the\ndynamical forms of box-office, revealing the significant role of competition in\nunderstanding box-office dynamics.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2010 14:14:23 GMT"}, {"version": "v2", "created": "Tue, 28 Sep 2010 19:17:56 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Yeung", "C. H.", ""], ["Cimini", "G.", ""], ["Jin", "C. -H.", ""]]}, {"id": "1005.3124", "submitter": "Chuang Liu", "authors": "Chuang Liu and Wei-Xing Zhou", "title": "An improved HeatS+ProbS hybrid recommendation algorithm based on\n  heterogeneous initial resource configurations", "comments": "6 pages 3 figures", "journal-ref": "Physica A 391 (22), 5704-5711 (2012)", "doi": "10.1016/j.physa.2012.06.034", "report-no": null, "categories": "physics.soc-ph cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network-based recommendation algorithms for user-object link predictions have\nachieved significant developments in recent years. For bipartite graphs, the\nreallocation of resource in such algorithms is analogous to heat spreading\n(HeatS) or probability spreading (ProbS) processes. The best algorithm to date\nis a hybrid of the HeatS and ProbS techniques with homogenous initial resource\nconfigurations, which fulfills simultaneously high accuracy and large\ndiversity. We investigate the effect of heterogeneity in initial configurations\non the HeatS+ProbS hybrid algorithm and find that both recommendation accuracy\nand diversity can be further improved in this new setting. Numerical\nexperiments show that the improvement is robust.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2010 09:24:23 GMT"}, {"version": "v2", "created": "Tue, 25 May 2010 07:01:25 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Liu", "Chuang", ""], ["Zhou", "Wei-Xing", ""]]}, {"id": "1005.3358", "submitter": "Bruce Berriman", "authors": "G. Bruce Berriman, Ewa Deelman", "title": "The Role of Provenance Management in Accelerating the Rate of\n  Astronomical Research", "comments": "8 pages, 1 figure; Proceedings of Science, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of vast quantities of data through electronic archives has\ntransformed astronomical research. It has also enabled the creation of new\nproducts, models and simulations, often from distributed input data and models,\nthat are themselves made electronically available. These products will only\nprovide maximal long-term value to astronomers when accompanied by records of\ntheir provenance; that is, records of the data and processes used in the\ncreation of such products. We use the creation of image mosaics with the\nMontage grid-enabled mosaic engine to emphasize the necessity of provenance\nmanagement and to understand the science requirements that higher-level\nproducts impose on provenance management technologies. We describe experiments\nwith one technology, the \"Provenance Aware Service Oriented Architecture\"\n(PASOA), that stores provenance information at each step in the computation of\na mosaic. The results inform the technical specifications of provenance\nmanagement systems, including the need for extensible systems built on common\nstandards. Finally, we describe examples of provenance management technology\nemerging from the fields of geophysics and oceanography that have applicability\nto astronomy applications.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2010 04:14:46 GMT"}], "update_date": "2010-05-20", "authors_parsed": [["Berriman", "G. Bruce", ""], ["Deelman", "Ewa", ""]]}, {"id": "1005.4267", "submitter": "Chriss Romy", "authors": "Uday Pratap Singh, Sanjeev Jain, Gulfishan Firdose Ahmed", "title": "Content Base Image Retrieval Using Phong Shading", "comments": "IEEE Publication format, International Journal of Computer Science\n  and Information Security, IJCSIS, Vol. 8 No. 1, April 2010, USA. ISSN 1947\n  5500, http://sites.google.com/site/ijcsis/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The digital image data is rapidly expanding in quantity and heterogeneity.\nThe traditional information retrieval techniques does not meet the user's\ndemand, so there is need to develop an efficient system for content based image\nretrieval. Content based image retrieval means retrieval of images from\ndatabase on the basis of visual features of image like as color, texture etc.\nIn our proposed method feature are extracted after applying Phong shading on\ninput image. Phong shading, flattering out the dull surfaces of the image The\nfeatures are extracted using color, texture & edge density methods. Feature\nextracted values are used to find the similarity between input query image and\nthe data base image. It can be measure by the Euclidean distance formula. The\nexperimental result shows that the proposed approach has a better retrieval\nresults with phong shading.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2010 07:28:24 GMT"}], "update_date": "2010-05-25", "authors_parsed": [["Singh", "Uday Pratap", ""], ["Jain", "Sanjeev", ""], ["Ahmed", "Gulfishan Firdose", ""]]}, {"id": "1005.4270", "submitter": "Chriss Romy", "authors": "V.Kavitha, M. Punithavalli", "title": "Clustering Time Series Data Stream - A Literature Survey", "comments": "IEEE Publication format, International Journal of Computer Science\n  and Information Security, IJCSIS, Vol. 8 No. 1, April 2010, USA. ISSN 1947\n  5500, http://sites.google.com/site/ijcsis/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Mining Time Series data has a tremendous growth of interest in today's world.\nTo provide an indication various implementations are studied and summarized to\nidentify the different problems in existing applications. Clustering time\nseries is a trouble that has applications in an extensive assortment of fields\nand has recently attracted a large amount of research. Time series data are\nfrequently large and may contain outliers. In addition, time series are a\nspecial type of data set where elements have a temporal ordering. Therefore\nclustering of such data stream is an important issue in the data mining\nprocess. Numerous techniques and clustering algorithms have been proposed\nearlier to assist clustering of time series data streams. The clustering\nalgorithms and its effectiveness on various applications are compared to\ndevelop a new method to solve the existing problem. This paper presents a\nsurvey on various clustering algorithms available for time series datasets.\nMoreover, the distinctiveness and restriction of previous research are\ndiscussed and several achievable topics for future study are recognized.\nFurthermore the areas that utilize time series clustering are also summarized.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2010 07:41:29 GMT"}], "update_date": "2010-05-25", "authors_parsed": [["Kavitha", "V.", ""], ["Punithavalli", "M.", ""]]}, {"id": "1005.4298", "submitter": "Sameer Singh", "authors": "Sameer Singh and Michael Wick and Andrew McCallum", "title": "Distantly Labeling Data for Large Scale Cross-Document Coreference", "comments": "16 pages, submitted to ECML 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-document coreference, the problem of resolving entity mentions across\nmulti-document collections, is crucial to automated knowledge base construction\nand data mining tasks. However, the scarcity of large labeled data sets has\nhindered supervised machine learning research for this task. In this paper we\ndevelop and demonstrate an approach based on ``distantly-labeling'' a data set\nfrom which we can train a discriminative cross-document coreference model. In\nparticular we build a dataset of more than a million people mentions extracted\nfrom 3.5 years of New York Times articles, leverage Wikipedia for distant\nlabeling with a generative model (and measure the reliability of such\nlabeling); then we train and evaluate a conditional random field coreference\nmodel that has factors on cross-document entities as well as mention-pairs.\nThis coreference model obtains high accuracy in resolving mentions and entities\nthat are not present in the training data, indicating applicability to\nnon-Wikipedia data. Given the large amount of data, our work is also an\nexercise demonstrating the scalability of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2010 10:35:50 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Singh", "Sameer", ""], ["Wick", "Michael", ""], ["McCallum", "Andrew", ""]]}, {"id": "1005.4376", "submitter": "Santo Fortunato Dr", "authors": "Andrea Lancichinetti, Mikko Kivela, Jari Saramaki, Santo Fortunato", "title": "Characterizing the community structure of complex networks", "comments": "15 pages, 20 figures, 4 tables", "journal-ref": "PLoS One 5(8), e11976 (2010)", "doi": "10.1371/journal.pone.0011976", "report-no": null, "categories": "physics.soc-ph cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community structure is one of the key properties of complex networks and\nplays a crucial role in their topology and function. While an impressive amount\nof work has been done on the issue of community detection, very little\nattention has been so far devoted to the investigation of communities in real\nnetworks. We present a systematic empirical analysis of the statistical\nproperties of communities in large information, communication, technological,\nbiological, and social networks. We find that the mesoscopic organization of\nnetworks of the same category is remarkably similar. This is reflected in\nseveral characteristics of community structure, which can be used as\n``fingerprints'' of specific network categories. While community size\ndistributions are always broad, certain categories of networks consist mainly\nof tree-like communities, while others have denser modules. Average path\nlengths within communities initially grow logarithmically with community size,\nbut the growth saturates or slows down for communities larger than a\ncharacteristic size. This behaviour is related to the presence of hubs within\ncommunities, whose roles differ across categories. Also the community\nembeddedness of nodes, measured in terms of the fraction of links within their\ncommunities, has a characteristic distribution for each category. Our findings\nare verified by the use of two fundamentally different community detection\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2010 16:48:03 GMT"}], "update_date": "2010-09-17", "authors_parsed": [["Lancichinetti", "Andrea", ""], ["Kivela", "Mikko", ""], ["Saramaki", "Jari", ""], ["Fortunato", "Santo", ""]]}, {"id": "1005.4457", "submitter": "Bruce Berriman", "authors": "Paul Groth, Ewa Deelman, Gideon Juve, Gaurang Mehta, Bruce Berriman", "title": "Pipeline-Centric Provenance Model", "comments": "9 pages, 4 figures", "journal-ref": "Proceedings of the 4th Workshop on Workflows in Support of\n  Large-Scale Science, 2009", "doi": null, "report-no": null, "categories": "astro-ph.IM cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new provenance model which is tailored to a class\nof workflow-based applications. We motivate the approach with use cases from\nthe astronomy community. We generalize the class of applications the approach\nis relevant to and propose a pipeline-centric provenance model. Finally, we\nevaluate the benefits in terms of storage needed by the approach when applied\nto an astronomy application.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2010 23:45:44 GMT"}], "update_date": "2010-05-26", "authors_parsed": [["Groth", "Paul", ""], ["Deelman", "Ewa", ""], ["Juve", "Gideon", ""], ["Mehta", "Gaurang", ""], ["Berriman", "Bruce", ""]]}, {"id": "1005.4752", "submitter": "Djoerd Hiemstra", "authors": "Djoerd Hiemstra and Vojkan Mihajlovic", "title": "A database approach to information retrieval: The remarkable\n  relationship between language models and region models", "comments": "Published as CTIT Technical Report 05-35", "journal-ref": null, "doi": null, "report-no": "TR-CTIT-10-15", "categories": "cs.IR cs.DB", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this report, we unify two quite distinct approaches to information\nretrieval: region models and language models. Region models were developed for\nstructured document retrieval. They provide a well-defined behaviour as well as\na simple query language that allows application developers to rapidly develop\napplications. Language models are particularly useful to reason about the\nranking of search results, and for developing new ranking approaches. The\nunified model allows application developers to define complex language modeling\napproaches as logical queries on a textual database. We show a remarkable\none-to-one relationship between region queries and the language models they\nrepresent for a wide variety of applications: simple ad-hoc search,\ncross-language retrieval, video retrieval, and web search.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2010 08:04:33 GMT"}], "update_date": "2012-05-02", "authors_parsed": [["Hiemstra", "Djoerd", ""], ["Mihajlovic", "Vojkan", ""]]}, {"id": "1005.5141", "submitter": "Pierre-Francois Marteau", "authors": "Pierre-Fran\\c{c}ois Marteau (IRISA), Sylvie Gibet (IRISA)", "title": "On Recursive Edit Distance Kernels with Application to Time Series\n  Classification", "comments": "14 pages", "journal-ref": "IEEE Transactions on Neural Networks and Learning Systems (2014)\n  1-14", "doi": "10.1109/TNNLS.2014.2333876", "report-no": "DRAFT-2013-PositiveDefiniteElasticKernels", "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes some extensions to the work on kernels dedicated to\nstring or time series global alignment based on the aggregation of scores\nobtained by local alignments. The extensions we propose allow to construct,\nfrom classical recursive definition of elastic distances, recursive edit\ndistance (or time-warp) kernels that are positive definite if some sufficient\nconditions are satisfied. The sufficient conditions we end-up with are original\nand weaker than those proposed in earlier works, although a recursive\nregularizing term is required to get the proof of the positive definiteness as\na direct consequence of the Haussler's convolution theorem. The classification\nexperiment we conducted on three classical time warp distances (two of which\nbeing metrics), using Support Vector Machine classifier, leads to conclude\nthat, when the pairwise distance matrix obtained from the training data is\n\\textit{far} from definiteness, the positive definite recursive elastic kernels\noutperform in general the distance substituting kernels for the classical\nelastic distances we have tested.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2010 18:11:15 GMT"}, {"version": "v10", "created": "Wed, 27 Nov 2013 07:57:25 GMT"}, {"version": "v11", "created": "Thu, 5 Dec 2013 14:04:32 GMT"}, {"version": "v12", "created": "Mon, 26 May 2014 06:17:30 GMT"}, {"version": "v2", "created": "Mon, 12 Jul 2010 12:45:28 GMT"}, {"version": "v3", "created": "Tue, 7 Dec 2010 11:02:10 GMT"}, {"version": "v4", "created": "Mon, 3 Jan 2011 10:32:07 GMT"}, {"version": "v5", "created": "Wed, 6 Feb 2013 16:32:52 GMT"}, {"version": "v6", "created": "Mon, 27 May 2013 08:58:31 GMT"}, {"version": "v7", "created": "Tue, 30 Jul 2013 09:21:26 GMT"}, {"version": "v8", "created": "Thu, 1 Aug 2013 14:41:48 GMT"}, {"version": "v9", "created": "Mon, 25 Nov 2013 20:31:46 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Marteau", "Pierre-Fran\u00e7ois", "", "IRISA"], ["Gibet", "Sylvie", "", "IRISA"]]}, {"id": "1005.5271", "submitter": "Secretary Aircc Journal", "authors": "Luis Alvarez Sabucedo and Luis Anido Rifon", "title": "A Restful Approach for Managing Citizen profiles Using A Semantic\n  Support", "comments": "18 Pages, IJDMS", "journal-ref": "International Journal of Database Management Systems 2.2 (2010)\n  1-18", "doi": "10.5121/ijdms.2010.2201", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Several steps are missing in the current high-speed race towards the holistic\nsupport of citizen needs in the domain of eGovernment. This paper is focused on\nhow to provide support for the citizen profile. This profile, in a wide sense,\nincludes personal information as well documents in possession of the citizen.\nThis also involves the provision of those mechanisms required to publish,\naccess and submit the convenient information to a Public Administration in due\ncurse of a transactional services provided with the last one. Main features of\nthe system are related to interoperability and possibilities for its inclusion\nin a cost effective manner in already developed platforms. To make that\npossible, this approach will take full advantage of semantic technologies and\nthe RESTful paradigm to design the entire system. The paper presents the\noverall system with some notes on the deployment of the solution for its\nfurther reuse in similar contexts.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2010 11:55:04 GMT"}], "update_date": "2010-07-15", "authors_parsed": [["Sabucedo", "Luis Alvarez", ""], ["Rifon", "Luis Anido", ""]]}, {"id": "1005.5516", "submitter": "David J Brenes", "authors": "David J. Brenes, Daniel Gayo-Avello and Rodrigo Garcia", "title": "On the Fly Query Entity Decomposition Using Snippets", "comments": "Extended version of paper submitted to CERI 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  One of the most important issues in Information Retrieval is inferring the\nintents underlying users' queries. Thus, any tool to enrich or to better\ncontextualized queries can proof extremely valuable. Entity extraction,\nprovided it is done fast, can be one of such tools. Such techniques usually\nrely on a prior training phase involving large datasets. That training is\ncostly, specially in environments which are increasingly moving towards real\ntime scenarios where latency to retrieve fresh informacion should be minimal.\nIn this paper an `on-the-fly' query decomposition method is proposed. It uses\nsnippets which are mined by means of a na\\\"ive statistical algorithm. An\ninitial evaluation of such a method is provided, in addition to a discussion on\nits applicability to different scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2010 11:41:43 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2010 11:36:05 GMT"}], "update_date": "2010-06-14", "authors_parsed": [["Brenes", "David J.", ""], ["Gayo-Avello", "Daniel", ""], ["Garcia", "Rodrigo", ""]]}]