[{"id": "0711.2023", "submitter": "Peter Turney", "authors": "Peter D. Turney (National Research Council of Canada)", "title": "Empirical Evaluation of Four Tensor Decomposition Algorithms", "comments": "related work available at http://purl.org/peter.turney/", "journal-ref": null, "doi": null, "report-no": "ERB-1152, NRC-49877", "categories": "cs.LG cs.CL cs.IR", "license": null, "abstract": "  Higher-order tensor decompositions are analogous to the familiar Singular\nValue Decomposition (SVD), but they transcend the limitations of matrices\n(second-order tensors). SVD is a powerful tool that has achieved impressive\nresults in information retrieval, collaborative filtering, computational\nlinguistics, computational vision, and other fields. However, SVD is limited to\ntwo-dimensional arrays of data (two modes), and many potential applications\nhave three or more modes, which require higher-order tensor decompositions.\nThis paper evaluates four algorithms for higher-order tensor decomposition:\nHigher-Order Singular Value Decomposition (HO-SVD), Higher-Order Orthogonal\nIteration (HOOI), Slice Projection (SP), and Multislice Projection (MP). We\nmeasure the time (elapsed run time), space (RAM and disk space requirements),\nand fit (tensor reconstruction accuracy) of the four algorithms, under a\nvariety of conditions. We find that standard implementations of HO-SVD and HOOI\ndo not scale up to larger tensors, due to increasing RAM requirements. We\nrecommend HOOI for tensors that are small enough for the available RAM and MP\nfor larger tensors.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2007 16:28:47 GMT"}], "update_date": "2007-11-14", "authors_parsed": [["Turney", "Peter D.", "", "National Research Council of Canada"]]}, {"id": "0711.2615", "submitter": "Franco Bagnoli", "authors": "Franco Bagnoli, Francesca Di Patti", "title": "A Biologically Inspired Classifier", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": null, "abstract": "  We present a method for measuring the distance among records based on the\ncorrelations of data stored in the corresponding database entries. The original\nmethod (F. Bagnoli, A. Berrones and F. Franci. Physica A 332 (2004) 509-518)\nwas formulated in the context of opinion formation. The opinions expressed over\na set of topic originate a ``knowledge network'' among individuals, where two\nindividuals are nearer the more similar their expressed opinions are. Assuming\nthat individuals' opinions are stored in a database, the authors show that it\nis possible to anticipate an opinion using the correlations in the database.\nThis corresponds to approximating the overlap between the tastes of two\nindividuals with the correlations of their expressed opinions.\n  In this paper we extend this model to nonlinear matching functions, inspired\nby biological problems such as microarray (probe-sample pairing). We\ninvestigate numerically the error between the correlation and the overlap\nmatrix for eight sequences of reference with random probes. Results show that\nthis method is particularly robust for detecting similarities in the presence\nof translocations.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2007 13:38:15 GMT"}], "update_date": "2007-11-19", "authors_parsed": [["Bagnoli", "Franco", ""], ["Di Patti", "Francesca", ""]]}, {"id": "0711.2832", "submitter": "Annie Bouyer", "authors": "Salma Chaabouni (MAP / Crai), Jc Bignon (MAP / Crai), Gilles Halin\n  (MAP / Crai)", "title": "Premi\\`ere \\'etape vers une navigation r\\'ef\\'erentielle par l'image\n  pour l'assistance \\`a la conception des ambiances lumineuses", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": null, "abstract": "  In the first design stage, image reference plays a double role of means of\nformulation and resolution of problems. In our approach, we consider image\nreference as a support of creation activity to generate ideas and we propose a\ntool for navigation in references by image in order to assist daylight ambience\ndesign. Within this paper, we present, in a first part, the semantic indexation\nmethod to be used for the indexation of our image database. In a second part we\npropose a synthetic analysis of various modes of referential navigation in\norder to propose a tool implementing all or a part of these modes.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2007 16:10:35 GMT"}], "update_date": "2007-11-20", "authors_parsed": [["Chaabouni", "Salma", "", "MAP / Crai"], ["Bignon", "Jc", "", "MAP / Crai"], ["Halin", "Gilles", "", "MAP / Crai"]]}, {"id": "0711.2867", "submitter": "Cristobald de Kerchove", "authors": "Cristobald de Kerchove, Laure Ninove, Paul Van Dooren", "title": "Maximizing PageRank via outlinks", "comments": "27 pages, 14 figures, submitted to Linear Algebra Appl", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR math.RA", "license": null, "abstract": "  We analyze linkage strategies for a set I of webpages for which the webmaster\nwants to maximize the sum of Google's PageRank scores. The webmaster can only\nchoose the hyperlinks starting from the webpages of I and has no control on the\nhyperlinks from other webpages. We provide an optimal linkage strategy under\nsome reasonable assumptions.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2007 09:43:22 GMT"}], "update_date": "2007-12-04", "authors_parsed": [["de Kerchove", "Cristobald", ""], ["Ninove", "Laure", ""], ["Van Dooren", "Paul", ""]]}, {"id": "0711.2917", "submitter": "Anne-Marie Vercoustre", "authors": "James A. Thom (RMIT), Jovan Pehcevski (INRIA Rocquencourt / INRIA\n  Sophia Antipolis), Anne-Marie Vercoustre (INRIA Rocquencourt / INRIA Sophia\n  Antipolis)", "title": "Use of Wikipedia Categories in Entity Ranking", "comments": null, "journal-ref": "Dans The 12th Australasian Document Computing Symposium (ADCS'07)\n  (2007)", "doi": null, "report-no": null, "categories": "cs.IR", "license": null, "abstract": "  Wikipedia is a useful source of knowledge that has many applications in\nlanguage processing and knowledge representation. The Wikipedia category graph\ncan be compared with the class hierarchy in an ontology; it has some\ncharacteristics in common as well as some differences. In this paper, we\npresent our approach for answering entity ranking queries from the Wikipedia.\nIn particular, we explore how to make use of Wikipedia categories to improve\nentity ranking effectiveness. Our experiments show that using categories of\nexample entities works significantly better than using loosely defined target\ncategories.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2007 12:35:48 GMT"}], "update_date": "2007-11-20", "authors_parsed": [["Thom", "James A.", "", "RMIT"], ["Pehcevski", "Jovan", "", "INRIA Rocquencourt / INRIA\n  Sophia Antipolis"], ["Vercoustre", "Anne-Marie", "", "INRIA Rocquencourt / INRIA Sophia\n  Antipolis"]]}, {"id": "0711.3128", "submitter": "Anne-Marie Vercoustre", "authors": "Anne-Marie Vercoustre (INRIA Rocquencourt / INRIA Sophia Antipolis),\n  James A. Thom (RMIT), Jovan Pehcevski (INRIA Rocquencourt / INRIA Sophia\n  Antipolis)", "title": "Entity Ranking in Wikipedia", "comments": "to appear", "journal-ref": "Dans the 23rd Annual ACM Symposium on Applied Computing (2008)", "doi": null, "report-no": null, "categories": "cs.IR", "license": null, "abstract": "  The traditional entity extraction problem lies in the ability of extracting\nnamed entities from plain text using natural language processing techniques and\nintensive training from large document collections. Examples of named entities\ninclude organisations, people, locations, or dates. There are many research\nactivities involving named entities; we are interested in entity ranking in the\nfield of information retrieval. In this paper, we describe our approach to\nidentifying and ranking entities from the INEX Wikipedia document collection.\nWikipedia offers a number of interesting features for entity identification and\nranking that we first introduce. We then describe the principles and the\narchitecture of our entity ranking system, and introduce our methodology for\nevaluation. Our preliminary results show that the use of categories and the\nlink structure of Wikipedia, together with entity examples, can significantly\nimprove retrieval effectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2007 12:40:23 GMT"}], "update_date": "2007-11-21", "authors_parsed": [["Vercoustre", "Anne-Marie", "", "INRIA Rocquencourt / INRIA Sophia Antipolis"], ["Thom", "James A.", "", "RMIT"], ["Pehcevski", "Jovan", "", "INRIA Rocquencourt / INRIA Sophia\n  Antipolis"]]}, {"id": "0711.3964", "submitter": "Cristobald de Kerchove", "authors": "Cristobald de Kerchove, Paul Van Dooren", "title": "Iterative Filtering for a Dynamical Reputation System", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": null, "abstract": "  The paper introduces a novel iterative method that assigns a reputation to n\n+ m items: n raters and m objects. Each rater evaluates a subset of objects\nleading to a n x m rating matrix with a certain sparsity pattern. From this\nrating matrix we give a nonlinear formula to define the reputation of raters\nand objects. We also provide an iterative algorithm that superlinearly\nconverges to the unique vector of reputations and this for any rating matrix.\nIn contrast to classical outliers detection, no evaluation is discarded in this\nmethod but each one is taken into account with different weights for the\nreputation of the objects. The complexity of one iteration step is linear in\nthe number of evaluations, making our algorithm efficient for large data set.\nExperiments show good robustness of the reputation of the objects against\ncheaters and spammers and good detection properties of cheaters and spammers.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2007 08:12:51 GMT"}], "update_date": "2007-11-27", "authors_parsed": [["de Kerchove", "Cristobald", ""], ["Van Dooren", "Paul", ""]]}, {"id": "0711.4142", "submitter": "Elizeu Santos-Neto", "authors": "Elizeu Santos-Neto, Matei Ripeanu, Adriana Iamnitchi", "title": "Content Reuse and Interest Sharing in Tagging Communities", "comments": "6 pages, 6 figures, AAAI Spring Symposium on Social Information\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": null, "abstract": "  Tagging communities represent a subclass of a broader class of user-generated\ncontent-sharing online communities. In such communities users introduce and tag\ncontent for later use. Although recent studies advocate and attempt to harness\nsocial knowledge in this context by exploiting collaboration among users,\nlittle research has been done to quantify the current level of user\ncollaboration in these communities. This paper introduces two metrics to\nquantify the level of collaboration: content reuse and shared interest. Using\nthese two metrics, this paper shows that the current level of collaboration in\nCiteULike and Connotea is consistently low, which significantly limits the\npotential of harnessing the social knowledge in communities. This study also\ndiscusses implications of these findings in the context of recommendation and\nreputation systems.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2007 23:05:02 GMT"}, {"version": "v2", "created": "Sat, 26 Jan 2008 01:05:50 GMT"}], "update_date": "2011-11-10", "authors_parsed": [["Santos-Neto", "Elizeu", ""], ["Ripeanu", "Matei", ""], ["Iamnitchi", "Adriana", ""]]}, {"id": "0711.4388", "submitter": "David Camacho", "authors": "Rafael Martinez, Manuel Cebrian, Francisco de Borja Rodriguez, David\n  Camacho", "title": "Contextual Information Retrieval based on Algorithmic Information Theory\n  and Statistical Outlier Detection", "comments": "Submitted to 2008 IEEE Information Theory Workshop (6 pages, 6\n  figures)", "journal-ref": null, "doi": "10.1109/ITW.2008.4578672", "report-no": null, "categories": "cs.IR cs.IT math.IT", "license": null, "abstract": "  The main contribution of this paper is to design an Information Retrieval\n(IR) technique based on Algorithmic Information Theory (using the Normalized\nCompression Distance- NCD), statistical techniques (outliers), and novel\norganization of data base structure. The paper shows how they can be integrated\nto retrieve information from generic databases using long (text-based) queries.\nTwo important problems are analyzed in the paper. On the one hand, how to\ndetect \"false positives\" when the distance among the documents is very low and\nthere is actual similarity. On the other hand, we propose a way to structure a\ndocument database which similarities distance estimation depends on the length\nof the selected text. Finally, the experimental evaluations that have been\ncarried out to study previous problems are shown.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2007 23:58:49 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Martinez", "Rafael", ""], ["Cebrian", "Manuel", ""], ["Rodriguez", "Francisco de Borja", ""], ["Camacho", "David", ""]]}]