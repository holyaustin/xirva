[{"id": "0803.0053", "submitter": "M Sabu THAMPI", "authors": "Sabu M. Thampi, K. Chandra Sekaran", "title": "Mobile Agents for Content-Based WWW Distributed Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present, the de-facto standard for providing contents in the Internet is\nthe World Wide Web. A technology, which is now emerging on the Web, is\nContent-Based Image Retrieval (CBIR). CBIR applies methods and algorithms from\ncomputer science to analyse and index images based on their visual content.\nMobile agents push the flexibility of distributed systems to their limits since\nnot only computations are dynamically distributed but also the code that\nperforms them. The current commercial applet-based methodologies for accessing\nimage database systems offer limited flexibility, scalability and robustness.\nIn this paper the author proposes a new framework for content-based WWW\ndistributed image retrieval based on Java-based mobile agents. The\nimplementation of the framework shows that its performance is comparable to,\nand in some cases outperforms, the current approach.\n", "versions": [{"version": "v1", "created": "Sat, 1 Mar 2008 08:27:59 GMT"}], "update_date": "2008-03-04", "authors_parsed": [["Thampi", "Sabu M.", ""], ["Sekaran", "K. Chandra", ""]]}, {"id": "0803.0405", "submitter": "Giulia Menconi", "authors": "Marco Franciosi, Giulia Menconi", "title": "Multi-dimensional sparse time series: feature extraction", "comments": "Keywords: multimedia mining, trend, entropy, Zipf law", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show an analysis of multi-dimensional time series via entropy and\nstatistical linguistic techniques. We define three markers encoding the\nbehavior of the series, after it has been translated into a multi-dimensional\nsymbolic sequence. The leading component and the trend of the series with\nrespect to a mobile window analysis result from the entropy analysis and label\nthe dynamical evolution of the series. The diversification formalizes the\ndifferentiation in the use of recurrent patterns, from a Zipf law point of\nview. These markers are the starting point of further analysis such as\nclassification or clustering of large database of multi-dimensional time\nseries, prediction of future behavior and attribution of new data. We also\npresent an application to economic data. We deal with measurements of money\ninvestments of some business companies in advertising market for different\nmedia sources.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2008 10:27:59 GMT"}], "update_date": "2008-03-05", "authors_parsed": [["Franciosi", "Marco", ""], ["Menconi", "Giulia", ""]]}, {"id": "0803.0822", "submitter": "Biswajit Biswal", "authors": "Biswajit Biswal", "title": "Website Optimization through Mining User Navigational Pattern", "comments": "10 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the World Wide Web's ubiquity increase and the rapid development of\nvarious online businesses, the complexity of web sites grow. The analysis of\nweb user's navigational pattern within a web site can provide useful\ninformation for server performance enhancements, restructuring a website and\ndirect marketing in e-commerce etc. In this paper, an algorithm is proposed for\nmining such navigation patterns. The key insight is that users access\ninformation of interest and follow a certain path while navigating a web site.\nIf they don't find it, they would backtrack and choose among the alternate\npaths till they reach the destination. The point they backtrack is the\nIntermediate Reference Location. Identifying such Intermediate locations and\ndestinations out of the pattern will be the main endeavor in the rest of this\nreport.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2008 10:01:08 GMT"}], "update_date": "2008-03-07", "authors_parsed": [["Biswal", "Biswajit", ""]]}, {"id": "0803.1716", "submitter": "Lokman Meho", "authors": "Lokman I. Meho and Yvonne Rogers", "title": "Citation Counting, Citation Ranking, and h-Index of Human-Computer\n  Interaction Researchers: A Comparison between Scopus and Web of Science", "comments": "35 pages, 9 tables, 3 figures, accepted for publication in the\n  Journal of the American Society for Information Science and Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study examines the differences between Scopus and Web of Science in the\ncitation counting, citation ranking, and h-index of 22 top human-computer\ninteraction (HCI) researchers from EQUATOR--a large British Interdisciplinary\nResearch Collaboration project. Results indicate that Scopus provides\nsignificantly more coverage of HCI literature than Web of Science, primarily\ndue to coverage of relevant ACM and IEEE peer-reviewed conference proceedings.\nNo significant differences exist between the two databases if citations in\njournals only are compared. Although broader coverage of the literature does\nnot significantly alter the relative citation ranking of individual\nresearchers, Scopus helps distinguish between the researchers in a more nuanced\nfashion than Web of Science in both citation counting and h-index. Scopus also\ngenerates significantly different maps of citation networks of individual\nscholars than those generated by Web of Science. The study also presents a\ncomparison of h-index scores based on Google Scholar with those based on the\nunion of Scopus and Web of Science. The study concludes that Scopus can be used\nas a sole data source for citation-based research and evaluation in HCI,\nespecially if citations in conference proceedings are sought and that h scores\nshould be manually calculated instead of relying on system calculations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2008 08:09:19 GMT"}], "update_date": "2008-03-13", "authors_parsed": [["Meho", "Lokman I.", ""], ["Rogers", "Yvonne", ""]]}, {"id": "0803.2220", "submitter": "Panagiotis Papadakos", "authors": "Panagiotis Papadakos, Giorgos Vasiliadis, Yannis Theoharis, Nikos\n  Armenatzoglou, Stella Kopidaki, Yannis Marketakis, Manos Daskalakis, Kostas\n  Karamaroudis, Giorgos Linardakis, Giannis Makrydakis, Vangelis Papathanasiou,\n  Lefteris Sardis, Petros Tsialiamanis, Georgia Troullinou, Kostas Vandikas,\n  Dimitris Velegrakis and Yannis Tzitzikas", "title": "The Anatomy of Mitos Web Search Engine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Engineering a Web search engine offering effective and efficient information\nretrieval is a challenging task. This document presents our experiences from\ndesigning and developing a Web search engine offering a wide spectrum of\nfunctionalities and we report some interesting experimental results. A rather\npeculiar design choice of the engine is that its index is based on a DBMS,\nwhile some of the distinctive functionalities that are offered include advanced\nGreek language stemming, real time result clustering, and advanced link\nanalysis techniques (also for spam page detection).\n", "versions": [{"version": "v1", "created": "Fri, 14 Mar 2008 19:18:15 GMT"}, {"version": "v2", "created": "Sun, 16 Mar 2008 17:25:19 GMT"}], "update_date": "2008-12-18", "authors_parsed": [["Papadakos", "Panagiotis", ""], ["Vasiliadis", "Giorgos", ""], ["Theoharis", "Yannis", ""], ["Armenatzoglou", "Nikos", ""], ["Kopidaki", "Stella", ""], ["Marketakis", "Yannis", ""], ["Daskalakis", "Manos", ""], ["Karamaroudis", "Kostas", ""], ["Linardakis", "Giorgos", ""], ["Makrydakis", "Giannis", ""], ["Papathanasiou", "Vangelis", ""], ["Sardis", "Lefteris", ""], ["Tsialiamanis", "Petros", ""], ["Troullinou", "Georgia", ""], ["Vandikas", "Kostas", ""], ["Velegrakis", "Dimitris", ""], ["Tzitzikas", "Yannis", ""]]}, {"id": "0803.3693", "submitter": "Rasmus Pagh", "authors": "Martin Dietzfelbinger and Rasmus Pagh", "title": "Succinct Data Structures for Retrieval and Approximate Membership", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The retrieval problem is the problem of associating data with keys in a set.\nFormally, the data structure must store a function f: U ->{0,1}^r that has\nspecified values on the elements of a given set S, a subset of U, |S|=n, but\nmay have any value on elements outside S. Minimal perfect hashing makes it\npossible to avoid storing the set S, but this induces a space overhead of\nTheta(n) bits in addition to the nr bits needed for function values. In this\npaper we show how to eliminate this overhead. Moreover, we show that for any k\nquery time O(k) can be achieved using space that is within a factor 1+e^{-k} of\noptimal, asymptotically for large n. If we allow logarithmic evaluation time,\nthe additive overhead can be reduced to O(log log n) bits whp. The time to\nconstruct the data structure is O(n), expected. A main technical ingredient is\nto utilize existing tight bounds on the probability of almost square random\nmatrices with rows of low weight to have full row rank. In addition to direct\nconstructions, we point out a close connection between retrieval structures and\nhash tables where keys are stored in an array and some kind of probing scheme\nis used. Further, we propose a general reduction that transfers the results on\nretrieval into analogous results on approximate membership, a problem\ntraditionally addressed using Bloom filters. Again, we show how to eliminate\nthe space overhead present in previously known methods, and get arbitrarily\nclose to the lower bound. The evaluation procedures of our data structures are\nextremely simple (similar to a Bloom filter). For the results stated above we\nassume free access to fully random hash functions. However, we show how to\njustify this assumption using extra space o(n) to simulate full randomness on a\nRAM.\n", "versions": [{"version": "v1", "created": "Wed, 26 Mar 2008 10:53:49 GMT"}], "update_date": "2008-03-27", "authors_parsed": [["Dietzfelbinger", "Martin", ""], ["Pagh", "Rasmus", ""]]}]