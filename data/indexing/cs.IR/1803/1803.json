[{"id": "1803.00114", "submitter": "James Sharpnack", "authors": "Liwei Wu, Cho-Jui Hsieh, James Sharpnack", "title": "SQL-Rank: A Listwise Approach to Collaborative Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a listwise approach for constructing user-specific\nrankings in recommendation systems in a collaborative fashion. We contrast the\nlistwise approach to previous pointwise and pairwise approaches, which are\nbased on treating either each rating or each pairwise comparison as an\nindependent instance respectively. By extending the work of (Cao et al. 2007),\nwe cast listwise collaborative ranking as maximum likelihood under a\npermutation model which applies probability mass to permutations based on a low\nrank latent score matrix. We present a novel algorithm called SQL-Rank, which\ncan accommodate ties and missing data and can run in linear time. We develop a\ntheoretical framework for analyzing listwise ranking methods based on a novel\nrepresentation theory for the permutation model. Applying this framework to\ncollaborative ranking, we derive asymptotic statistical rates as the number of\nusers and items grow together. We conclude by demonstrating that our SQL-Rank\nmethod often outperforms current state-of-the-art algorithms for implicit\nfeedback such as Weighted-MF and BPR and achieve favorable results when\ncompared to explicit feedback algorithms such as matrix factorization and\ncollaborative ranking.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 22:26:43 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2018 14:19:57 GMT"}, {"version": "v3", "created": "Wed, 6 Feb 2019 22:22:55 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Wu", "Liwei", ""], ["Hsieh", "Cho-Jui", ""], ["Sharpnack", "James", ""]]}, {"id": "1803.00146", "submitter": "Zainab Zolaktaf", "authors": "Zainab Zolaktaf, Reza Babanezhad, Rachel Pottinger", "title": "A Generic Top-N Recommendation Framework For Trading-off Accuracy,\n  Novelty, and Coverage", "comments": "Full version - ICDE 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Standard collaborative filtering approaches for top-N recommendation are\nbiased toward popular items. As a result, they recommend items that users are\nlikely aware of and under-represent long-tail items. This is inadequate, both\nfor consumers who prefer novel items and because concentrating on popular items\npoorly covers the item space, whereas high item space coverage increases\nproviders' revenue.\n  We present an approach that relies on historical rating data to learn user\nlong-tail novelty preferences. We integrate these preferences into a generic\nre-ranking framework that customizes balance between accuracy and coverage. We\nempirically validate that our proposedframework increases the novelty of\nrecommendations. Furthermore, by promoting long-tail items to the right group\nof users, we significantly increase the system's coverage while scalably\nmaintaining accuracy. Our framework also enables personalization of existing\nnon-personalized algorithms, making them competitive with existing personalized\nalgorithms in key performance metrics, including accuracy and coverage.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 00:39:06 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Zolaktaf", "Zainab", ""], ["Babanezhad", "Reza", ""], ["Pottinger", "Rachel", ""]]}, {"id": "1803.00189", "submitter": "Bang Liu", "authors": "Bang Liu, Di Niu, Kunfeng Lai, Linglong Kong, Yu Xu", "title": "Growing Story Forest Online from Massive Breaking News", "comments": "Accepted by CIKM 2017, 9 pages", "journal-ref": null, "doi": "10.1145/3132847.3132852", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our experience of implementing a news content organization system\nat Tencent that discovers events from vast streams of breaking news and evolves\nnews story structures in an online fashion. Our real-world system has distinct\nrequirements in contrast to previous studies on topic detection and tracking\n(TDT) and event timeline or graph generation, in that we 1) need to accurately\nand quickly extract distinguishable events from massive streams of long text\ndocuments that cover diverse topics and contain highly redundant information,\nand 2) must develop the structures of event stories in an online manner,\nwithout repeatedly restructuring previously formed stories, in order to\nguarantee a consistent user viewing experience. In solving these challenges, we\npropose Story Forest, a set of online schemes that automatically clusters\nstreaming documents into events, while connecting related events in growing\ntrees to tell evolving stories. We conducted extensive evaluation based on 60\nGB of real-world Chinese news data, although our ideas are not\nlanguage-dependent and can easily be extended to other languages, through\ndetailed pilot user experience studies. The results demonstrate the superior\ncapability of Story Forest to accurately identify events and organize news text\ninto a logical structure that is appealing to human readers, compared to\nmultiple existing algorithm frameworks.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 03:15:10 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Liu", "Bang", ""], ["Niu", "Di", ""], ["Lai", "Kunfeng", ""], ["Kong", "Linglong", ""], ["Xu", "Yu", ""]]}, {"id": "1803.00202", "submitter": "Miguel Campo PhD", "authors": "Miguel Campo, JJ Espinoza, Julie Rieger, Abhinav Taliyan", "title": "Collaborative Metric Learning Recommendation System: Application to\n  Theatrical Movie Releases", "comments": "6 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Product recommendation systems are important for major movie studios during\nthe movie greenlight process and as part of machine learning personalization\npipelines. Collaborative Filtering (CF) models have proved to be effective at\npowering recommender systems for online streaming services with explicit\ncustomer feedback data. CF models do not perform well in scenarios in which\nfeedback data is not available, in cold start situations like new product\nlaunches, and situations with markedly different customer tiers (e.g., high\nfrequency customers vs. casual customers). Generative natural language models\nthat create useful theme-based representations of an underlying corpus of\ndocuments can be used to represent new product descriptions, like new movie\nplots. When combined with CF, they have shown to increase the performance in\ncold start situations. Outside of those cases though in which explicit customer\nfeedback is available, recommender engines must rely on binary purchase data,\nwhich materially degrades performance. Fortunately, purchase data can be\ncombined with product descriptions to generate meaningful representations of\nproducts and customer trajectories in a convenient product space in which\nproximity represents similarity. Learning to measure the distance between\npoints in this space can be accomplished with a deep neural network that trains\non customer histories and on dense vectorizations of product descriptions. We\ndeveloped a system based on Collaborative (Deep) Metric Learning (CML) to\npredict the purchase probabilities of new theatrical releases. We trained and\nevaluated the model using a large dataset of customer histories, and tested the\nmodel for a set of movies that were released outside of the training window.\nInitial experiments show gains relative to models that do not train on\ncollaborative preferences.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 04:04:35 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Campo", "Miguel", ""], ["Espinoza", "JJ", ""], ["Rieger", "Julie", ""], ["Taliyan", "Abhinav", ""]]}, {"id": "1803.00458", "submitter": "TonTon Huang", "authors": "TonTon Hsien-De Huang, and Hung-Yu Kao", "title": "C-3PO: Click-sequence-aware DeeP Neural Network (DNN)-based Pop-uPs\n  RecOmmendation", "comments": "2018/12/20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the emergence of mobile and wearable devices, push notification becomes\na powerful tool to connect and maintain the relationship with App users, but\nsending inappropriate or too many messages at the wrong time may result in the\nApp being removed by the users. In order to maintain the retention rate and the\ndelivery rate of advertisement, we adopt Deep Neural Network (DNN) to develop a\npop-up recommendation system \"Click sequence-aware deeP neural network\n(DNN)-based Pop-uPs recOmmendation (C-3PO)\" enabled by collaborative\nfiltering-based hybrid user behavioral analysis. We further verified the system\nwith real data collected from the product Security Master, Clean Master and CM\nBrowser, supported by Leopard Mobile Inc. (Cheetah Mobile Taiwan Agency). In\nthis way, we can know precisely about users' preference and frequency to click\non the push notification/pop-ups, decrease the troublesome to users\nefficiently, and meanwhile increase the click through rate of push\nnotifications/pop-ups.\n", "versions": [{"version": "v1", "created": "Wed, 28 Feb 2018 15:30:54 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2018 15:00:50 GMT"}, {"version": "v3", "created": "Fri, 9 Mar 2018 12:45:25 GMT"}, {"version": "v4", "created": "Thu, 20 Dec 2018 05:58:38 GMT"}], "update_date": "2018-12-21", "authors_parsed": [["Huang", "TonTon Hsien-De", ""], ["Kao", "Hung-Yu", ""]]}, {"id": "1803.00479", "submitter": "Andreu Girbau Xalabarder", "authors": "Andreu Girbau, Ryota Hinami, Shin'ichi Satoh", "title": "Tracked Instance Search", "comments": "Accepted at ICASSP 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose tracking as a generic addition to the instance search\ntask. From video data perspective, much information that can be used is not\ntaken into account in the traditional instance search approach. This work aims\nto provide insights on exploiting such existing information by means of\ntracking and the proper combination of the results, independently of the\ninstance search system. We also present a study on the improvement of the\nsystem when using multiple independent instances (up to 4) of the same person.\nExperimental results show that our system improves substantially its\nperformance when using tracking. Best configuration improves from mAP = 0.447\nto mAP = 0.511 for a single example, and from mAP = 0.647 to mAP = 0.704 for\nmultiple (4) given examples.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 16:12:30 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Girbau", "Andreu", ""], ["Hinami", "Ryota", ""], ["Satoh", "Shin'ichi", ""]]}, {"id": "1803.00682", "submitter": "Dayong Tian", "authors": "Dayong Tian", "title": "Learning Decorrelated Hashing Codes for Multimodal Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In social networks, heterogeneous multimedia data correlate to each other,\nsuch as videos and their corresponding tags in YouTube and image-text pairs in\nFacebook. Nearest neighbor retrieval across multiple modalities on large data\nsets becomes a hot yet challenging problem. Hashing is expected to be an\nefficient solution, since it represents data as binary codes. As the bit-wise\nXOR operations can be fast handled, the retrieval time is greatly reduced. Few\nexisting multimodal hashing methods consider the correlation among hashing\nbits. The correlation has negative impact on hashing codes. When the hashing\ncode length becomes longer, the retrieval performance improvement becomes\nslower. In this paper, we propose a minimum correlation regularization (MCR)\nfor multimodal hashing. First, the sigmoid function is used to embed the data\nmatrices. Then, the MCR is applied on the output of sigmoid function. As the\noutput of sigmoid function approximates a binary code matrix, the proposed MCR\ncan efficiently decorrelate the hashing codes. Experiments show the superiority\nof the proposed method becomes greater as the code length increases.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 01:54:35 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 22:39:04 GMT"}], "update_date": "2019-05-24", "authors_parsed": [["Tian", "Dayong", ""]]}, {"id": "1803.00693", "submitter": "Yusen Zhan", "authors": "Yusen Zhan, Qing Da, Fei Xiao, An-xiang Zeng, Yang Yu", "title": "Accelerating E-Commerce Search Engine Ranking by Contextual Factor\n  Selection", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In industrial large-scale search systems, such as Taobao.com search for\ncommodities, the quality of the ranking result is getting continually improved\nby introducing more factors from complex procedures, e.g., deep neural networks\nfor extracting image factors. Meanwhile, the increasing of the factors demands\nmore computation resource and raises the system response latency. It has been\nobserved that a search instance usually requires only a small set of effective\nfactors, instead of all factors. Therefore, removing ineffective factors\nsignificantly improves the system efficiency. This paper studies the\n\\emph{Contextual Factor Selection} (CFS), which selects only a subset of\neffective factors for every search instance, for a well balance between the\nsearch quality and the response latency. We inject CFS into the search engine\nranking score to accelerate the engine, considering both ranking effectiveness\nand efficiency. The learning of the CFS model involves a combinatorial\noptimization, which is transformed as a sequential decision-making problem.\nSolving the problem by reinforcement learning, we propose the RankCFS, which\nhas been assessed in an off-line environment as well as a real-world on-line\nenvironment (Taobao.com). The empirical results show that, the proposed CFS\napproach outperforms several existing supervised/unsupervised methods for\nfeature selection in the off-line environment, and also achieves significant\nreal-world performance improvement, in term of service latency, in daily test\nas well as Singles' Day Shopping Festival in $2017$.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 03:34:20 GMT"}, {"version": "v2", "created": "Mon, 5 Mar 2018 06:40:08 GMT"}, {"version": "v3", "created": "Wed, 14 Mar 2018 08:36:18 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Zhan", "Yusen", ""], ["Da", "Qing", ""], ["Xiao", "Fei", ""], ["Zeng", "An-xiang", ""], ["Yu", "Yang", ""]]}, {"id": "1803.00719", "submitter": "Denys Katerenchuk", "authors": "Denys Katerenchuk, Andrew Rosenberg", "title": "RankDCG: Rank-Ordering Evaluation Measure", "comments": null, "journal-ref": "LREC 2016", "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking is used for a wide array of problems, most notably information\nretrieval (search). There are a number of popular approaches to the evaluation\nof ranking such as Kendall's $\\tau$, Average Precision, and nDCG. When dealing\nwith problems such as user ranking or recommendation systems, all these\nmeasures suffer from various problems, including an inability to deal with\nelements of the same rank, inconsistent and ambiguous lower bound scores, and\nan inappropriate cost function. We propose a new measure, rankDCG, that\naddresses these problems. This is a modification of the popular nDCG algorithm.\nWe provide a number of criteria for any effective ranking algorithm and show\nthat only rankDCG satisfies all of them. Results are presented on constructed\nand real data sets. We release a publicly available rankDCG evaluation package.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 04:45:56 GMT"}], "update_date": "2018-03-05", "authors_parsed": [["Katerenchuk", "Denys", ""], ["Rosenberg", "Andrew", ""]]}, {"id": "1803.00754", "submitter": "Kai-Lang Yao", "authors": "Kai-Lang Yao, Wu-Jun Li, Jianbo Yang and Xinyan Lu", "title": "Convolutional Geometric Matrix Completion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geometric matrix completion (GMC) has been proposed for recommendation by\nintegrating the relationship (link) graphs among users/items into matrix\ncompletion (MC). Traditional GMC methods typically adopt graph regularization\nto impose smoothness priors for MC. Recently, geometric deep learning on graphs\n(GDLG) is proposed to solve the GMC problem, showing better performance than\nexisting GMC methods including traditional graph regularization based methods.\nTo the best of our knowledge, there exists only one GDLG method for GMC, which\nis called RMGCNN. RMGCNN combines graph convolutional network (GCN) and\nrecurrent neural network (RNN) together for GMC. In the original work of\nRMGCNN, RMGCNN demonstrates better performance than pure GCN-based method. In\nthis paper, we propose a new GMC method, called convolutional geometric matrix\ncompletion (CGMC), for recommendation with graphs among users/items. CGMC is a\npure GCN-based method with a newly designed graph convolutional network.\nExperimental results on real datasets show that CGMC can outperform other\nstate-of-the-art methods including RMGCNN in terms of both accuracy and speed.\n", "versions": [{"version": "v1", "created": "Fri, 2 Mar 2018 08:30:44 GMT"}, {"version": "v2", "created": "Mon, 27 May 2019 06:49:54 GMT"}], "update_date": "2019-05-28", "authors_parsed": [["Yao", "Kai-Lang", ""], ["Li", "Wu-Jun", ""], ["Yang", "Jianbo", ""], ["Lu", "Xinyan", ""]]}, {"id": "1803.01245", "submitter": "Ramesh Baral", "authors": "Ramesh Baral and Tao Li and XiaoLong Zhu", "title": "CAPS: Context Aware Personalized POI Sequence Recommender System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The revolution of World Wide Web (WWW) and smart-phone technologies have been\nthe key-factor behind remarkable success of social networks. With the ease of\navailability of check-in data, the location-based social networks (LBSN) (e.g.,\nFacebook1, etc.) have been heavily explored in the past decade for\nPoint-of-Interest (POI) recommendation. Though many POI recommenders have been\ndefined, most of them have focused on recommending a single location or an\narbitrary list that is not contextually coherent. It has been cumbersome to\nrely on such systems when one needs a contextually coherent list of locations,\nthat can be used for various day-to-day activities, for e.g., itinerary\nplanning. This paper proposes a model termed as CAPS (Context-Aware\nPersonalized POI Sequence Recommender System) that generates contextually\ncoherent POI sequences relevant to user preferences. To the best of our\nknowledge, CAPS is the first attempt to formulate the contextual POI sequence\nmodeling by extending Recurrent Neural Network (RNN) and its variants. CAPS\nextends RNN by incorporating multiple contexts to the hidden layer and by\nincorporating global context (sequence features) to the hidden layers and the\noutput layer. It extends the variants of RNN (e.g., Long-short term memory\n(LSTM)) by incorporating multiple contexts and global features in the gate\nupdate relations. The major contributions of this paper are: (i) it models the\ncontextual POI sequence problem by incorporating personalized user preferences\nthrough multiple constraints (e.g., categorical, social, temporal, etc.), (ii)\nit extends RNN to incorporate the contexts of individual item and that of the\nwhole sequence. It also extends the gated functionality of variants of RNN to\nincorporate the multiple contexts, and (iii) it evaluates the proposed models\nagainst two real-world data sets.\n", "versions": [{"version": "v1", "created": "Sat, 3 Mar 2018 21:27:44 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Baral", "Ramesh", ""], ["Li", "Tao", ""], ["Zhu", "XiaoLong", ""]]}, {"id": "1803.01542", "submitter": "Zhou Yingmin", "authors": "Fuzhen Zhuang, Yingmin Zhou, Fuzheng Zhang, Xiang Ao, Xing Xie, Qing\n  He", "title": "Cross-domain novelty seeking trait mining for sequential recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has attracted a large amount of interest and research in\nlast decades, and some efforts have been made to build more precise\nrecommendation systems. Most previous transfer recommendation systems assume\nthat the target domain shares the same/similar rating patterns with the\nauxiliary source domain, which is used to improve the recommendation\nperformance. However, to the best of our knowledge, almost these works do not\nconsider the characteristics of sequential data. In this paper, we study the\nnew cross-domain recommendation scenario for mining novelty-seeking trait.\nRecent studies in psychology suggest that novelty-seeking trait is highly\nrelated to consumer behavior, which has a profound business impact on online\nrecommendation. Previous work performing on only one single target domain may\nnot fully characterize users' novelty-seeking trait well due to the data\nscarcity and sparsity, leading to the poor recommendation performance. Along\nthis line, we proposed a new cross-domain novelty-seeking trait mining model\n(CDNST for short) to improve the sequential recommendation performance by\ntransferring the knowledge from auxiliary source domain. We conduct systematic\nexperiments on three domain data sets crawled from Douban (www.douban.com) to\ndemonstrate the effectiveness of the proposed model. Moreover, we analyze how\nthe temporal property of sequential data affects the performance of CDNST, and\nconduct simulation experiments to validate our analysis.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 08:02:25 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Zhuang", "Fuzhen", ""], ["Zhou", "Yingmin", ""], ["Zhang", "Fuzheng", ""], ["Ao", "Xiang", ""], ["Xie", "Xing", ""], ["He", "Qing", ""]]}, {"id": "1803.01580", "submitter": "Andrew Krizhanovsky A", "authors": "Andrew Krizhanovsky, Alexander Kirillov", "title": "Calculated attributes of synonym sets", "comments": "6 pages, 2 tables, 2 figures, preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of formalization, proposed in this paper, is to bring together, as\nnear as possible, the theoretic linguistic problem of synonym conception and\nthe computer linguistic methods based generally on empirical intuitive\nunjustified factors. Using the word vector representation we have proposed the\ngeometric approach to mathematical modeling of synonym set (synset). The word\nembedding is based on the neural networks (Skip-gram, CBOW), developed and\nrealized as word2vec program by T. Mikolov. The standard cosine similarity is\nused as the distance between word-vectors. Several geometric characteristics of\nthe synset words are introduced: the interior of synset, the synset word rank\nand centrality. These notions are intended to select the most significant\nsynset words, i.e. the words which senses are the nearest to the sense of a\nsynset. Some experiments with proposed notions, based on RusVectores resources,\nare represented. A brief description of this work can be viewed in slides\nhttps://goo.gl/K82Fei\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 10:09:32 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Krizhanovsky", "Andrew", ""], ["Kirillov", "Alexander", ""]]}, {"id": "1803.01617", "submitter": "Zhaohui Peng", "authors": "Xinghua Wang, Zhaohui Peng, Senzhang Wang, Philip S. Yu, Wenjing Fu,\n  and Xiaoguang Hong", "title": "Cross-Domain Recommendation for Cold-Start Users via Neighborhood Based\n  Feature Mapping", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative Filtering (CF) is a widely adopted technique in recommender\nsystems. Traditional CF models mainly focus on predicting a user's preference\nto the items in a single domain such as the movie domain or the music domain. A\nmajor challenge for such models is the data sparsity problem, and especially,\nCF cannot make accurate predictions for the cold-start users who have no\nratings at all. Although Cross-Domain Collaborative Filtering (CDCF) is\nproposed for effectively transferring users' rating preference across different\ndomains, it is still difficult for existing CDCF models to tackle the\ncold-start users in the target domain due to the extreme data sparsity. In this\npaper, we propose a Cross-Domain Latent Feature Mapping (CDLFM) model for\ncold-start users in the target domain. Firstly, in order to better characterize\nusers in sparse domains, we take the users' similarity relationship on rating\nbehaviors into consideration and propose the Matrix Factorization by\nincorporating User Similarities (MFUS) in which three similarity measures are\nproposed. Next, to perform knowledge transfer across domains, we propose a\nneighborhood based gradient boosting trees method to learn the cross-domain\nuser latent feature mapping function. For each cold-start user, we learn\nhis/her feature mapping function based on the latent feature pairs of those\nlinked users who have similar rating behaviors with the cold-start user in the\nauxiliary domain. And the preference of the cold-start user in the target\ndomain can be predicted based on the mapping function and his/her latent\nfeatures in the auxiliary domain. Experimental results on two real data sets\nextracted from Amazon transaction data demonstrate the superiority of our\nproposed model against other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 11:50:46 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Wang", "Xinghua", ""], ["Peng", "Zhaohui", ""], ["Wang", "Senzhang", ""], ["Yu", "Philip S.", ""], ["Fu", "Wenjing", ""], ["Hong", "Xiaoguang", ""]]}, {"id": "1803.01937", "submitter": "Kavita Ganesan", "authors": "Kavita Ganesan", "title": "ROUGE 2.0: Updated and Improved Measures for Evaluation of Summarization\n  Tasks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation of summarization tasks is extremely crucial to determining the\nquality of machine generated summaries. Over the last decade, ROUGE has become\nthe standard automatic evaluation measure for evaluating summarization tasks.\nWhile ROUGE has been shown to be effective in capturing n-gram overlap between\nsystem and human composed summaries, there are several limitations with the\nexisting ROUGE measures in terms of capturing synonymous concepts and coverage\nof topics. Thus, often times ROUGE scores do not reflect the true quality of\nsummaries and prevents multi-faceted evaluation of summaries (i.e. by topics,\nby overall content coverage and etc). In this paper, we introduce ROUGE 2.0,\nwhich has several updated measures of ROUGE: ROUGE-N+Synonyms, ROUGE-Topic,\nROUGE-Topic+Synonyms, ROUGE-TopicUniq and ROUGE-TopicUniq+Synonyms; all of\nwhich are improvements over the core ROUGE measures.\n", "versions": [{"version": "v1", "created": "Mon, 5 Mar 2018 21:35:04 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Ganesan", "Kavita", ""]]}, {"id": "1803.02101", "submitter": "Frank Meyer", "authors": "Wissam Siblini and Frank Meyer and Pascale Kuntz", "title": "VIPE: A new interactive classification framework for large sets of short\n  texts - application to opinion mining", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a new interactive opinion mining tool that helps users to\nclassify large sets of short texts originated from Web opinion polls, technical\nforums or Twitter. From a manual multi-label pre-classification of a very\nlimited text subset, a learning algorithm predicts the labels of the remaining\ntexts of the corpus and the texts most likely associated to a selected label.\nUsing a fast matrix factorization, the algorithm is able to handle large\ncorpora and is well-adapted to interactivity by integrating the corrections\nproposed by the users on the fly. Experimental results on classical datasets of\nvarious sizes and feedbacks of users from marketing services of the\ntelecommunication company Orange confirm the quality of the obtained results.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 10:45:27 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Siblini", "Wissam", ""], ["Meyer", "Frank", ""], ["Kuntz", "Pascale", ""]]}, {"id": "1803.02179", "submitter": "Dominik Kowald", "authors": "Dominik Kowald, Paul Seitlinger, Tobias Ley, Elisabeth Lex", "title": "The Impact of Semantic Context Cues on the User Acceptance of Tag\n  Recommendations: An Online Study", "comments": "2 pages, poster", "journal-ref": "WWW'2018", "doi": "10.1145/3184558.3186899", "report-no": null, "categories": "cs.IR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present the results of an online study with the aim to shed\nlight on the impact that semantic context cues have on the user acceptance of\ntag recommendations. Therefore, we conducted a work-integrated social\nbookmarking scenario with 17 university employees in order to compare the user\nacceptance of a context-aware tag recommendation algorithm called 3Layers with\nthe user acceptance of a simple popularity-based baseline. In this scenario, we\nvalidated and verified the hypothesis that semantic context cues have a higher\nimpact on the user acceptance of tag recommendations in a collaborative tagging\nsetting than in an individual tagging setting. With this paper, we contribute\nto the sparse line of research presenting online recommendation studies.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 14:00:37 GMT"}], "update_date": "2018-03-07", "authors_parsed": [["Kowald", "Dominik", ""], ["Seitlinger", "Paul", ""], ["Ley", "Tobias", ""], ["Lex", "Elisabeth", ""]]}, {"id": "1803.02194", "submitter": "Kan Ren", "authors": "Kan Ren, Weinan Zhang, Ke Chang, Yifei Rong, Yong Yu, Jun Wang", "title": "Bidding Machine: Learning to Bid for Directly Optimizing Profits in\n  Display Advertising", "comments": "18 pages, 10 figures, Final version published in IEEE Transactions on\n  Knowledge and Data Engineering (TKDE), URL:\n  http://ieeexplore.ieee.org/document/8115218/", "journal-ref": "IEEE Transactions on Knowledge and Data Engineering, Volume: 30,\n  Issue: 4, Year: 2018, Pages: 645-659", "doi": "10.1109/TKDE.2017.2775228", "report-no": null, "categories": "cs.GT cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time bidding (RTB) based display advertising has become one of the key\ntechnological advances in computational advertising. RTB enables advertisers to\nbuy individual ad impressions via an auction in real-time and facilitates the\nevaluation and the bidding of individual impressions across multiple\nadvertisers. In RTB, the advertisers face three main challenges when optimizing\ntheir bidding strategies, namely (i) estimating the utility (e.g., conversions,\nclicks) of the ad impression, (ii) forecasting the market value (thus the cost)\nof the given ad impression, and (iii) deciding the optimal bid for the given\nauction based on the first two. Previous solutions assume the first two are\nsolved before addressing the bid optimization problem. However, these\nchallenges are strongly correlated and dealing with any individual problem\nindependently may not be globally optimal. In this paper, we propose Bidding\nMachine, a comprehensive learning to bid framework, which consists of three\noptimizers dealing with each challenge above, and as a whole, jointly optimizes\nthese three parts. We show that such a joint optimization would largely\nincrease the campaign effectiveness and the profit. From the learning\nperspective, we show that the bidding machine can be updated smoothly with both\noffline periodical batch or online sequential training schemes. Our extensive\noffline empirical study and online A/B testing verify the high effectiveness of\nthe proposed bidding machine.\n", "versions": [{"version": "v1", "created": "Thu, 1 Mar 2018 04:28:32 GMT"}, {"version": "v2", "created": "Sun, 11 Mar 2018 02:25:32 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Ren", "Kan", ""], ["Zhang", "Weinan", ""], ["Chang", "Ke", ""], ["Rong", "Yifei", ""], ["Yu", "Yong", ""], ["Wang", "Jun", ""]]}, {"id": "1803.02250", "submitter": "Tiago Cunha", "authors": "Tiago Cunha, Carlos Soares and Andr\\'e C.P.L.F. de Carvalho", "title": "CF4CF: Recommending Collaborative Filtering algorithms using\n  Collaborative Filtering", "comments": null, "journal-ref": null, "doi": "10.1145/3240323.3240378", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic solutions which enable the selection of the best algorithms for a\nnew problem are commonly found in the literature. One research area which has\nrecently received considerable efforts is Collaborative Filtering. Existing\nwork includes several approaches using Metalearning, which relate the\ncharacteristics of datasets with the performance of the algorithms. This work\nexplores an alternative approach to tackle this problem. Since, in essence,\nboth are recommendation problems, this work uses Collaborative Filtering\nalgorithms to select Collaborative Filtering algorithms. Our approach\nintegrates subsampling landmarkers, which are a data characterization approach\ncommonly used in Metalearning, with a standard Collaborative Filtering method.\nThe experimental results show that CF4CF competes with standard Metalearning\nstrategies in the problem of Collaborative Filtering algorithm selection.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 15:23:46 GMT"}], "update_date": "2018-10-04", "authors_parsed": [["Cunha", "Tiago", ""], ["Soares", "Carlos", ""], ["de Carvalho", "Andr\u00e9 C. P. L. F.", ""]]}, {"id": "1803.02349", "submitter": "Jizhe Wang", "authors": "Jizhe Wang, Pipei Huang, Huan Zhao, Zhibo Zhang, Binqiang Zhao, Dik\n  Lun Lee", "title": "Billion-scale Commodity Embedding for E-commerce Recommendation in\n  Alibaba", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems (RSs) have been the most important technology for\nincreasing the business in Taobao, the largest online consumer-to-consumer\n(C2C) platform in China. The billion-scale data in Taobao creates three major\nchallenges to Taobao's RS: scalability, sparsity and cold start. In this paper,\nwe present our technical solutions to address these three challenges. The\nmethods are based on the graph embedding framework. We first construct an item\ngraph from users' behavior history. Each item is then represented as a vector\nusing graph embedding. The item embeddings are employed to compute pairwise\nsimilarities between all items, which are then used in the recommendation\nprocess. To alleviate the sparsity and cold start problems, side information is\nincorporated into the embedding framework. We propose two aggregation methods\nto integrate the embeddings of items and the corresponding side information.\nExperimental results from offline experiments show that methods incorporating\nside information are superior to those that do not. Further, we describe the\nplatform upon which the embedding methods are deployed and the workflow to\nprocess the billion-scale data in Taobao. Using online A/B test, we show that\nthe online Click-Through-Rate (CTRs) are improved comparing to the previous\nrecommendation methods widely used in Taobao, further demonstrating the\neffectiveness and feasibility of our proposed methods in Taobao's live\nproduction environment.\n", "versions": [{"version": "v1", "created": "Tue, 6 Mar 2018 05:20:14 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 06:03:31 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Wang", "Jizhe", ""], ["Huang", "Pipei", ""], ["Zhao", "Huan", ""], ["Zhang", "Zhibo", ""], ["Zhao", "Binqiang", ""], ["Lee", "Dik Lun", ""]]}, {"id": "1803.02807", "submitter": "Simone Faro", "authors": "Simone Faro and Arianna Pavone", "title": "Flexible and Efficient Algorithms for Abelian Matching in Strings", "comments": "This is a short preliminary version of a full paper submitted to an\n  international journal. Most examples, details, lemmas and theorems have been\n  omitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The abelian pattern matching problem consists in finding all substrings of a\ntext which are permutations of a given pattern. This problem finds application\nin many areas and can be solved in linear time by a naive sliding window\napproach. In this short communication we present a new class of algorithms\nbased on a new efficient fingerprint computation approach, called\nHeap-Counting, which turns out to be fast, flexible and easy to be implemented.\nIt can be proved that our solutions have a linear worst case time complexity\nand, in addition, we present an extensive experimental evaluation which shows\nthat our newly presented algorithms are among the most efficient and flexible\nsolutions in practice for the abelian matching problem in strings.\n", "versions": [{"version": "v1", "created": "Wed, 7 Mar 2018 18:34:11 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Faro", "Simone", ""], ["Pavone", "Arianna", ""]]}, {"id": "1803.03018", "submitter": "Heishiro Kanagawa", "authors": "Heishiro Kanagawa, Hayato Kobayashi, Nobuyuki Shimizu, Yukihiro Tagami\n  and Taiji Suzuki", "title": "Cross-domain Recommendation via Deep Domain Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of users in certain services could be a clue that can be used to\ninfer their preferences and may be used to make recommendations for other\nservices they have never used. However, the cross-domain relationships between\nitems and user consumption patterns are not simple, especially when there are\nfew or no common users and items across domains. To address this problem, we\npropose a content-based cross-domain recommendation method for cold-start users\nthat does not require user- and item- overlap. We formulate recommendation as\nextreme multi-class classification where labels (items) corresponding to the\nusers are predicted. With this formulation, the problem is reduced to a domain\nadaptation setting, in which a classifier trained in the source domain is\nadapted to the target domain. For this, we construct a neural network that\ncombines an architecture for domain adaptation, Domain Separation Network, with\na denoising autoencoder for item representation. We assess the performance of\nour approach in experiments on a pair of data sets collected from movie and\nnews services of Yahoo! JAPAN and show that our approach outperforms several\nbaseline methods including a cross-domain collaborative filtering method.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 09:43:04 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Kanagawa", "Heishiro", ""], ["Kobayashi", "Hayato", ""], ["Shimizu", "Nobuyuki", ""], ["Tagami", "Yukihiro", ""], ["Suzuki", "Taiji", ""]]}, {"id": "1803.03176", "submitter": "Dominik Kowald PhD", "authors": "Dominik Kowald", "title": "Modeling Activation Processes in Human Memory to Improve Tag\n  Recommendations", "comments": "Summary of dissertation on recommender systems submitted to Graz\n  University of Technology (Austria)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis was submitted by Dr. Dominik Kowald to the Institute of\nInteractive Systems and Data Science of Graz University of Technology in\nAustria on the 5th of September 2017 for the attainment of the degree\n'Dr.techn'. The supervisors of this thesis have been Prof. Stefanie Lindstaedt\nand Ass.Prof. Elisabeth Lex from Graz University of Technology, and the\nexternal assessor has been Prof. Tobias Ley from Tallinn University.\n  In the current enthusiasm around Data Science and Big Data Analytics, it is\nimportant to mention that only theory-guided approaches will truly enable us to\nfully understand why an algorithm works and how specific results can be\nexplained. It was the goal of this dissertation research to follow this path by\ndemonstrating that a recommender system inspired by human memory theory can\nhave a true impact in the field.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 16:01:32 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Kowald", "Dominik", ""]]}, {"id": "1803.03185", "submitter": "Wen-Hao Chiang", "authors": "Wen-Hao Chiang, Li Shen, Lang Li and Xia Ning", "title": "Drug Recommendation toward Safe Polypharmacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Adverse drug reactions (ADRs) induced from high-order drug-drug interactions\n(DDIs) due to polypharmacy represent a significant public health problem. In\nthis paper, we formally formulate the to-avoid and safe (with respect to ADRs)\ndrug recommendation problems when multiple drugs have been taken\nsimultaneously. We develop a joint model with a recommendation component and an\nADR label prediction component to recommend for a prescription a set of\nto-avoid drugs that will induce ADRs if taken together with the prescription.\nWe also develop real drug-drug interaction datasets and corresponding\nevaluation protocols. Our experimental results on real datasets demonstrate the\nstrong performance of the joint model compared to other baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Mar 2018 16:22:26 GMT"}], "update_date": "2018-03-09", "authors_parsed": [["Chiang", "Wen-Hao", ""], ["Shen", "Li", ""], ["Li", "Lang", ""], ["Ning", "Xia", ""]]}, {"id": "1803.03370", "submitter": "Qi Zhu", "authors": "Huan Gui, Qi Zhu, Liyuan Liu, Aston Zhang, Jiawei Han", "title": "Expert Finding in Heterogeneous Bibliographic Networks with\n  Locally-trained Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expert finding is an important task in both industry and academia. It is\nchallenging to rank candidates with appropriate expertise for various queries.\nIn addition, different types of objects interact with one another, which\nnaturally forms heterogeneous information networks. We study the task of expert\nfinding in heterogeneous bibliographical networks based on two aspects: textual\ncontent analysis and authority ranking. Regarding the textual content analysis,\nwe propose a new method for query expansion via locally-trained embedding\nlearning with concept hierarchy as guidance, which is particularly tailored for\nspecific queries with narrow semantic meanings. Compared with global embedding\nlearning, locally-trained embedding learning projects the terms into a latent\nsemantic space constrained on relevant topics, therefore it preserves more\nprecise and subtle information for specific queries. Considering the candidate\nranking, the heterogeneous information network structure, while being largely\nignored in the previous studies of expert finding, provides additional\ninformation. Specifically, different types of interactions among objects play\ndifferent roles. We propose a ranking algorithm to estimate the authority of\nobjects in the network, treating each strongly-typed edge type individually. To\ndemonstrate the effectiveness of the proposed framework, we apply the proposed\nmethod to a large-scale bibliographical dataset with over two million entries\nand one million researcher candidates. The experiment results show that the\nproposed framework outperforms existing methods for both general and specific\nqueries.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 03:28:36 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Gui", "Huan", ""], ["Zhu", "Qi", ""], ["Liu", "Liyuan", ""], ["Zhang", "Aston", ""], ["Han", "Jiawei", ""]]}, {"id": "1803.03428", "submitter": "Joy Bose", "authors": "Anish Anil Patankar, Joy Bose, Harshit Khanna", "title": "A Bias Aware News Recommendation System", "comments": "11 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this era of fake news and political polarization, it is desirable to have\na system to enable users to access balanced news content. Current solutions\nfocus on top down, server based approaches to decide whether a news article is\nfake or biased, and display only trusted news to the end users. In this paper,\nwe follow a different approach to help the users make informed choices about\nwhich news they want to read, making users aware in real time of the bias in\nnews articles they were browsing and recommending news articles from other\nsources on the same topic with different levels of bias. We use a recent Pew\nresearch report to collect news sources that readers with varying political\ninclinations prefer to read. We then scrape news articles on a variety of\ntopics from these varied news sources. After this, we perform clustering to\nfind similar topics of the articles, as well as calculate a bias score for each\narticle. For a news article the user is currently reading, we display the bias\nscore and also display other articles on the same topic, out of the previously\ncollected articles, from different news sources. This we present to the user.\nThis approach, we hope, would make it possible for users to access more\nbalanced articles on given news topics. We present the implementation details\nof the system along with some preliminary results on news articles.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 09:19:16 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Patankar", "Anish Anil", ""], ["Bose", "Joy", ""], ["Khanna", "Harshit", ""]]}, {"id": "1803.03467", "submitter": "Hongwei Wang", "authors": "Hongwei Wang, Fuzheng Zhang, Jialin Wang, Miao Zhao, Wenjie Li, Xing\n  Xie, Minyi Guo", "title": "RippleNet: Propagating User Preferences on the Knowledge Graph for\n  Recommender Systems", "comments": "CIKM 2018", "journal-ref": null, "doi": "10.1145/3269206.3271739", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To address the sparsity and cold start problem of collaborative filtering,\nresearchers usually make use of side information, such as social networks or\nitem attributes, to improve recommendation performance. This paper considers\nthe knowledge graph as the source of side information. To address the\nlimitations of existing embedding-based and path-based methods for\nknowledge-graph-aware recommendation, we propose Ripple Network, an end-to-end\nframework that naturally incorporates the knowledge graph into recommender\nsystems. Similar to actual ripples propagating on the surface of water, Ripple\nNetwork stimulates the propagation of user preferences over the set of\nknowledge entities by automatically and iteratively extending a user's\npotential interests along links in the knowledge graph. The multiple \"ripples\"\nactivated by a user's historically clicked items are thus superposed to form\nthe preference distribution of the user with respect to a candidate item, which\ncould be used for predicting the final clicking probability. Through extensive\nexperiments on real-world datasets, we demonstrate that Ripple Network achieves\nsubstantial gains in a variety of scenarios, including movie, book and news\nrecommendation, over several state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 11:12:01 GMT"}, {"version": "v2", "created": "Sat, 19 May 2018 12:15:17 GMT"}, {"version": "v3", "created": "Tue, 7 Aug 2018 03:28:32 GMT"}, {"version": "v4", "created": "Sat, 25 Aug 2018 05:52:08 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Wang", "Hongwei", ""], ["Zhang", "Fuzheng", ""], ["Wang", "Jialin", ""], ["Zhao", "Miao", ""], ["Li", "Wenjie", ""], ["Xie", "Xing", ""], ["Guo", "Minyi", ""]]}, {"id": "1803.03502", "submitter": "Yanru Qu", "authors": "Minzhe Niu, Weinan Zhang, Yanru Qu, Xuezhi Cao, Ruiming Tang, Xiuqiang\n  He, Yong Yu", "title": "Collaborative Filtering with Graph-based Implicit Feedback", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Introducing consumed items as users' implicit feedback in matrix\nfactorization (MF) method, SVD++ is one of the most effective collaborative\nfiltering methods for personalized recommender systems. Though powerful, SVD++\nhas two limitations: (i). only user-side implicit feedback is utilized, whereas\nitem-side implicit feedback, which can also enrich item representations, is not\nleveraged;(ii). in SVD++, the interacted items are equally weighted when\ncombining the implicit feedback, which can not reflect user's true preferences\naccurately. To tackle the above limitations, in this paper we propose\nGraph-based collaborative filtering (GCF) model, Weighted Graph-based\ncollaborative filtering (W-GCF) model and Attentive Graph-based collaborative\nfiltering (A-GCF) model, which (i). generalize the implicit feedback to item\nside based on the user-item bipartite graph; (ii). flexibly learn the weights\nof individuals in the implicit feedback hence improve the model's capacity.\nComprehensive experiments show that our proposed models outperform\nstate-of-the-art models.For sparse implicit feedback scenarios, additional\nimprovement is further achieved by leveraging the step-two implicit feedback\ninformation.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 13:25:54 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Niu", "Minzhe", ""], ["Zhang", "Weinan", ""], ["Qu", "Yanru", ""], ["Cao", "Xuezhi", ""], ["Tang", "Ruiming", ""], ["He", "Xiuqiang", ""], ["Yu", "Yong", ""]]}, {"id": "1803.03532", "submitter": "Niels Dalum Hansen Mr.", "authors": "Niels Dalum Hansen, K{\\aa}re M{\\o}lbak, Ingemar Cox and Christina\n  Lioma", "title": "Predicting antimicrobial drug consumption using web search data", "comments": null, "journal-ref": null, "doi": "10.1145/3194658.3194667", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consumption of antimicrobial drugs, such as antibiotics, is linked with\nantimicrobial resistance. Surveillance of antimicrobial drug consumption is\ntherefore an important element in dealing with antimicrobial resistance. Many\ncountries lack sufficient surveillance systems. Usage of web mined data\ntherefore has the potential to improve current surveillance methods. To this\nend, we study how well antimicrobial drug consumption can be predicted based on\nweb search queries, compared to historical purchase data of antimicrobial\ndrugs. We present two prediction models (linear Elastic Net, and non-linear\nGaussian Processes), which we train and evaluate on almost 6 years of weekly\nantimicrobial drug consumption data from Denmark and web search data from\nGoogle Health Trends. We present a novel method of selecting web search queries\nby considering diseases and drugs linked to antimicrobials, as well as\nprofessional and layman descriptions of antimicrobial drugs, all of which we\nmine from the open web. We find that predictions based on web search data are\nmarginally more erroneous but overall on a par with predictions based on\npurchases of antimicrobial drugs. This marginal difference corresponds to\n$<1$\\% point mean absolute error in weekly usage. Best predictions are reported\nwhen combining both web search and purchase data.\n  This study contributes a novel alternative solution to the real-life problem\nof predicting (and hence monitoring) antimicrobial drug consumption, which is\nparticularly valuable in countries/states lacking centralised and timely\nsurveillance systems.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 14:40:05 GMT"}], "update_date": "2018-03-12", "authors_parsed": [["Hansen", "Niels Dalum", ""], ["M\u00f8lbak", "K\u00e5re", ""], ["Cox", "Ingemar", ""], ["Lioma", "Christina", ""]]}, {"id": "1803.03571", "submitter": "Rion Brattig Correia", "authors": "Rion Brattig Correia and Luciana P. de Ara\\'ujo and Mauro M. Mattos\n  and Luis M. Rocha", "title": "City-wide Analysis of Electronic Health Records Reveals Gender and Age\n  Biases in the Administration of Known Drug-Drug Interactions", "comments": null, "journal-ref": "npj Digit. Med. 2, 74 (2019)", "doi": "10.1038/s41746-019-0141-x", "report-no": null, "categories": "cs.SI cs.CY cs.IR q-bio.QM stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The occurrence of drug-drug-interactions (DDI) from multiple drug\ndispensations is a serious problem, both for individuals and health-care\nsystems, since patients with complications due to DDI are likely to reenter the\nsystem at a costlier level. We present a large-scale longitudinal study (18\nmonths) of the DDI phenomenon at the primary- and secondary-care level using\nelectronic health records (EHR) from the city of Blumenau in Southern Brazil\n(pop. $\\approx 340,000$). We found that 181 distinct drug pairs known to\ninteract were dispensed concomitantly to 12\\% of the patients in the city's\npublic health-care system. Further, 4\\% of the patients were dispensed drug\npairs that are likely to result in major adverse drug reactions (ADR)---with\ncosts estimated to be much larger than previously reported in smaller studies.\nThe large-scale analysis reveals that women have a 60\\% increased risk of DDI\nas compared to men; the increase becomes 90\\% when considering only DDI known\nto lead to major ADR. Furthermore, DDI risk increases substantially with age;\npatients aged 70-79 years have a 34\\% risk of DDI when they are dispensed two\nor more drugs concomitantly. Interestingly, a statistical null model\ndemonstrates that age- and female-specific risks from increased polypharmacy\nfail by far to explain the observed DDI risks in those populations, suggesting\nunknown social or biological causes. We also provide a network visualization of\ndrugs and demographic factors that characterize the DDI phenomenon and\ndemonstrate that accurate DDI prediction can be included in healthcare and\npublic-health management, to reduce DDI-related ADR and costs.\n", "versions": [{"version": "v1", "created": "Fri, 9 Mar 2018 15:45:12 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2018 21:57:21 GMT"}, {"version": "v3", "created": "Wed, 20 Feb 2019 15:29:36 GMT"}, {"version": "v4", "created": "Thu, 2 Jan 2020 14:08:43 GMT"}], "update_date": "2020-01-03", "authors_parsed": [["Correia", "Rion Brattig", ""], ["de Ara\u00fajo", "Luciana P.", ""], ["Mattos", "Mauro M.", ""], ["Rocha", "Luis M.", ""]]}, {"id": "1803.04141", "submitter": "Dimitrios Vasilas", "authors": "Dimitrios Vasilas (LIP6, DELYS), Marc Shapiro (DELYS, LIP6), Bradley\n  King", "title": "A Modular Design for Geo-Distributed Querying", "comments": "5th Workshop on Principles and Practice of Consistency for\n  Distributed Data, Apr 2018, Porto, Portugal. 5th Workshop on Principles and\n  Practice of Consistency for Distributed Data April 23--26, 2018, Porto,\n  Portugal, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most distributed storage systems provide limited abilities for querying data\nby attributes other than their primary keys. Supporting efficient search on\nsecondary attributes is challenging as applications pose varying requirements\nto query processing systems, and no single system design can be suitable for\nall needs. In this paper, we show how to overcome these challenges in order to\nextend distributed data stores to support queries on secondary attributes. We\npropose a modular architecture that is flexible and allows query processing\nsystems to make trade-offs according to different use case requirements. We\ndescribe adap-tive mechanisms that make use of this flexibility to enable query\nprocessing systems to dynamically adjust to query and write operation\nworkloads.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 07:39:56 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Vasilas", "Dimitrios", "", "LIP6, DELYS"], ["Shapiro", "Marc", "", "DELYS, LIP6"], ["King", "Bradley", ""]]}, {"id": "1803.04292", "submitter": "Bertil Chapuis", "authors": "Bertil Chapuis, Benoit Garbinato", "title": "Geodabs: Trajectory Indexing Meets Fingerprinting at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.DC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding trajectories and discovering motifs that are similar in large\ndatasets is a central problem for a wide range of applications. Solutions\naddressing this problem usually rely on spatial indexing and on the computation\nof a similarity measure in polynomial time. Although effective in the context\nof sparse trajectory datasets, this approach is too expensive in the context of\ndense datasets, where many trajectories potentially match with a given query.\nIn this paper, we apply fingerprinting, a copy-detection mechanism used in the\ncontext of textual data, to trajectories. To this end, we fingerprint\ntrajectories with geodabs, a construction based on geohash aimed at trajectory\nfingerprinting. We demonstrate that by relying on the properties of a space\nfilling curve geodabs can be used to build sharded inverted indexes. We show\nhow normalization affects precision and recall, two key measures in information\nretrieval. We then demonstrate that the probabilistic nature of fingerprinting\nhas a marginal effect on the quality of the results. Finally, we evaluate our\nmethod in terms of performances and show that, in contrast with existing\nmethods, it is not affected by the density of the trajectory dataset and that\nit can be efficiently distributed.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 14:48:06 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Chapuis", "Bertil", ""], ["Garbinato", "Benoit", ""]]}, {"id": "1803.04494", "submitter": "Sean Billings", "authors": "Sean Billings", "title": "Gradient Augmented Information Retrieval with Autoencoders and Semantic\n  Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper will explore the use of autoencoders for semantic hashing in the\ncontext of Information Retrieval. This paper will summarize how to efficiently\ntrain an autoencoder in order to create meaningful and low-dimensional\nencodings of data. This paper will demonstrate how computing and storing the\nclosest encodings to an input query can help speed up search time and improve\nthe quality of our search results. The novel contributions of this paper\ninvolve using the representation of the data learned by an auto-encoder in\norder to augment our search query in various ways. I present and evaluate the\nnew gradient search augmentation (GSA) approach, as well as the more well-known\npseudo-relevance-feedback (PRF) adjustment. I find that GSA helps to improve\nthe performance of the TF-IDF based information retrieval system, and PRF\ncombined with GSA works best overall for the systems compared in this paper.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 19:49:30 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Billings", "Sean", ""]]}, {"id": "1803.04514", "submitter": "Ghazaleh Beigi", "authors": "Ghazaleh Beigi and Huan Liu", "title": "Similar but Different: Exploiting Users' Congruity for Recommendation\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pervasive use of social media provides massive data about individuals'\nonline social activities and their social relations. The building block of most\nexisting recommendation systems is the similarity between users with social\nrelations, i.e., friends. While friendship ensures some homophily, the\nsimilarity of a user with her friends can vary as the number of friends\nincreases. Research from sociology suggests that friends are more similar than\nstrangers, but friends can have different interests. Exogenous information such\nas comments and ratings may help discern different degrees of agreement (i.e.,\ncongruity) among similar users. In this paper, we investigate if users'\ncongruity can be incorporated into recommendation systems to improve it's\nperformance. Experimental results demonstrate the effectiveness of embedding\ncongruity related information into recommendation systems.\n", "versions": [{"version": "v1", "created": "Mon, 12 Mar 2018 20:31:47 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 01:03:35 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Beigi", "Ghazaleh", ""], ["Liu", "Huan", ""]]}, {"id": "1803.05127", "submitter": "Xinzhi Han", "authors": "Xinzhi Han, Sen Lei", "title": "Feature Selection and Model Comparison on Microsoft Learning-to-Rank\n  Data Sets", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the rapid advance of the Internet, search engines (e.g., Google, Bing,\nYahoo!) are used by billions of users for each day. The main function of a\nsearch engine is to locate the most relevant webpages corresponding to what the\nuser requests. This report focuses on the core problem of information\nretrieval: how to learn the relevance between a document (very often webpage)\nand a query given by user. Our analysis consists of two parts: 1) we use\nstandard statistical methods to select important features among 137 candidates\ngiven by information retrieval researchers from Microsoft. We find that not all\nthe features are useful, and give interpretations on the top-selected features;\n2) we give baselines on prediction over the real-world dataset MSLR-WEB by\nusing various learning algorithms. We find that models of boosting trees,\nrandom forest in general achieve the best performance of prediction. This\nagrees with the mainstream opinion in information retrieval community that\ntree-based algorithms outperform the other candidates for this problem.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 03:57:55 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Han", "Xinzhi", ""], ["Lei", "Sen", ""]]}, {"id": "1803.05160", "submitter": "Igor Mozeti\\v{c}", "authors": "Igor Mozeti\\v{c}, Luis Torgo, Vitor Cerqueira, Jasmina Smailovi\\'c", "title": "How to evaluate sentiment classifiers for Twitter time-ordered data?", "comments": null, "journal-ref": "PLoS ONE 13(3): e0194317, 2018", "doi": "10.1371/journal.pone.0194317", "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media are becoming an increasingly important source of information\nabout the public mood regarding issues such as elections, Brexit, stock market,\netc. In this paper we focus on sentiment classification of Twitter data.\nConstruction of sentiment classifiers is a standard text mining task, but here\nwe address the question of how to properly evaluate them as there is no settled\nway to do so. Sentiment classes are ordered and unbalanced, and Twitter\nproduces a stream of time-ordered data. The problem we address concerns the\nprocedures used to obtain reliable estimates of performance measures, and\nwhether the temporal ordering of the training and test data matters. We\ncollected a large set of 1.5 million tweets in 13 European languages. We\ncreated 138 sentiment models and out-of-sample datasets, which are used as a\ngold standard for evaluations. The corresponding 138 in-sample datasets are\nused to empirically compare six different estimation procedures: three variants\nof cross-validation, and three variants of sequential validation (where test\nset always follows the training set). We find no significant difference between\nthe best cross-validation and sequential validation. However, we observe that\nall cross-validation variants tend to overestimate the performance, while the\nsequential methods tend to underestimate it. Standard cross-validation with\nrandom selection of examples is significantly worse than the blocked\ncross-validation, and should not be used to evaluate classifiers in\ntime-ordered data scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 08:16:48 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Mozeti\u010d", "Igor", ""], ["Torgo", "Luis", ""], ["Cerqueira", "Vitor", ""], ["Smailovi\u0107", "Jasmina", ""]]}, {"id": "1803.05170", "submitter": "Jianxun Lian", "authors": "Jianxun Lian, Xiaohuan Zhou, Fuzheng Zhang, Zhongxia Chen, Xing Xie,\n  Guangzhong Sun", "title": "xDeepFM: Combining Explicit and Implicit Feature Interactions for\n  Recommender Systems", "comments": "10 pages", "journal-ref": null, "doi": "10.1145/3219819.3220023", "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial features are essential for the success of many commercial\nmodels. Manually crafting these features usually comes with high cost due to\nthe variety, volume and velocity of raw data in web-scale systems.\nFactorization based models, which measure interactions in terms of vector\nproduct, can learn patterns of combinatorial features automatically and\ngeneralize to unseen features as well. With the great success of deep neural\nnetworks (DNNs) in various fields, recently researchers have proposed several\nDNN-based factorization model to learn both low- and high-order feature\ninteractions. Despite the powerful ability of learning an arbitrary function\nfrom data, plain DNNs generate feature interactions implicitly and at the\nbit-wise level. In this paper, we propose a novel Compressed Interaction\nNetwork (CIN), which aims to generate feature interactions in an explicit\nfashion and at the vector-wise level. We show that the CIN share some\nfunctionalities with convolutional neural networks (CNNs) and recurrent neural\nnetworks (RNNs). We further combine a CIN and a classical DNN into one unified\nmodel, and named this new model eXtreme Deep Factorization Machine (xDeepFM).\nOn one hand, the xDeepFM is able to learn certain bounded-degree feature\ninteractions explicitly; on the other hand, it can learn arbitrary low- and\nhigh-order feature interactions implicitly. We conduct comprehensive\nexperiments on three real-world datasets. Our results demonstrate that xDeepFM\noutperforms state-of-the-art models. We have released the source code of\nxDeepFM at \\url{https://github.com/Leavingseason/xDeepFM}.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 09:13:16 GMT"}, {"version": "v2", "created": "Thu, 15 Mar 2018 07:37:35 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 15:00:27 GMT"}], "update_date": "2019-10-28", "authors_parsed": [["Lian", "Jianxun", ""], ["Zhou", "Xiaohuan", ""], ["Zhang", "Fuzheng", ""], ["Chen", "Zhongxia", ""], ["Xie", "Xing", ""], ["Sun", "Guangzhong", ""]]}, {"id": "1803.05337", "submitter": "Micha\\\"el Defferrard", "authors": "Micha\\\"el Defferrard, Sharada P. Mohanty, Sean F. Carroll, Marcel\n  Salath\\'e", "title": "Learning to Recognize Musical Genre from Audio", "comments": "submitted to WWW'18 after challenge round-1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We here summarize our experience running a challenge with open data for\nmusical genre recognition. Those notes motivate the task and the challenge\ndesign, show some statistics about the submissions, and present the results.\n", "versions": [{"version": "v1", "created": "Tue, 13 Mar 2018 15:58:58 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Defferrard", "Micha\u00ebl", ""], ["Mohanty", "Sharada P.", ""], ["Carroll", "Sean F.", ""], ["Salath\u00e9", "Marcel", ""]]}, {"id": "1803.05401", "submitter": "Abhijit Suprem", "authors": "Abhijit Suprem and Polo Chau", "title": "Approximate Query Matching for Image Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional image recognition involves identifying the key object in a\nportrait-type image with a single object focus (ILSVRC, AlexNet, and VGG). More\nrecent approaches consider dense image recognition - segmenting an image with\nappropriate bounding boxes and performing image recognition within these\nbounding boxes (Semantic segmentation). The Visual Genome dataset [5] is an\nattempt to bridge these various approaches to a cohesive dataset for each\nsubtask - bounding box generation, image recognition, captioning, and a new\noperation: scene graph generation. Our focus is on using such scene graphs to\nperform graph search on image databases to holistically retrieve images based\non a search criteria. We develop a method to store scene graphs and metadata in\ngraph databases (using Neo4J) and to perform fast approximate retrieval of\nimages based on a graph search query. We process more complex queries than\nsingle object search, e.g. \"girl eating cake\" retrieves images that contain the\nspecified relation as well as variations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 16:57:50 GMT"}], "update_date": "2018-03-15", "authors_parsed": [["Suprem", "Abhijit", ""], ["Chau", "Polo", ""]]}, {"id": "1803.05457", "submitter": "Carissa Schoenick", "authors": "Peter Clark, Isaac Cowhey, Oren Etzioni, Tushar Khot, Ashish\n  Sabharwal, Carissa Schoenick, Oyvind Tafjord", "title": "Think you have Solved Question Answering? Try ARC, the AI2 Reasoning\n  Challenge", "comments": "10 pages, 7 tables, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new question set, text corpus, and baselines assembled to\nencourage AI research in advanced question answering. Together, these\nconstitute the AI2 Reasoning Challenge (ARC), which requires far more powerful\nknowledge and reasoning than previous challenges such as SQuAD or SNLI. The ARC\nquestion set is partitioned into a Challenge Set and an Easy Set, where the\nChallenge Set contains only questions answered incorrectly by both a\nretrieval-based algorithm and a word co-occurence algorithm. The dataset\ncontains only natural, grade-school science questions (authored for human\ntests), and is the largest public-domain set of this kind (7,787 questions). We\ntest several baselines on the Challenge Set, including leading neural models\nfrom the SQuAD and SNLI tasks, and find that none are able to significantly\noutperform a random baseline, reflecting the difficult nature of this task. We\nare also releasing the ARC Corpus, a corpus of 14M science sentences relevant\nto the task, and implementations of the three neural baseline models tested.\nCan your model perform better? We pose ARC as a challenge to the community.\n", "versions": [{"version": "v1", "created": "Wed, 14 Mar 2018 18:04:21 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Clark", "Peter", ""], ["Cowhey", "Isaac", ""], ["Etzioni", "Oren", ""], ["Khot", "Tushar", ""], ["Sabharwal", "Ashish", ""], ["Schoenick", "Carissa", ""], ["Tafjord", "Oyvind", ""]]}, {"id": "1803.05667", "submitter": "HosseinAli Rahmani Dashti", "authors": "Parisa Naderi Golshan, HosseinAli Rahmani Dashti, Shahrzad Azizi and\n  Leila Safari", "title": "A Study of Recent Contributions on Information Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on modern approaches in Information Extraction (IE) and\nits two main sub-tasks of Named Entity Recognition (NER) and Relation\nExtraction (RE). Basic concepts and the most recent approaches in this area are\nreviewed, which mainly include Machine Learning (ML) based approaches and the\nmore recent trend to Deep Learning (DL) based methods.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 10:04:27 GMT"}], "update_date": "2018-03-16", "authors_parsed": [["Golshan", "Parisa Naderi", ""], ["Dashti", "HosseinAli Rahmani", ""], ["Azizi", "Shahrzad", ""], ["Safari", "Leila", ""]]}, {"id": "1803.05796", "submitter": "Karlson Pfannschmidt", "authors": "Karlson Pfannschmidt, Pritha Gupta, Eyke H\\\"ullermeier", "title": "Deep Architectures for Learning Context-dependent Ranking Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Object ranking is an important problem in the realm of preference learning.\nOn the basis of training data in the form of a set of rankings of objects,\nwhich are typically represented as feature vectors, the goal is to learn a\nranking function that predicts a linear order of any new set of objects.\nCurrent approaches commonly focus on ranking by scoring, i.e., on learning an\nunderlying latent utility function that seeks to capture the inherent utility\nof each object. These approaches, however, are not able to take possible\neffects of context-dependence into account, where context-dependence means that\nthe utility or usefulness of an object may also depend on what other objects\nare available as alternatives. In this paper, we formalize the problem of\ncontext-dependent ranking and present two general approaches based on two\nnatural representations of context-dependent ranking functions. Both approaches\nare instantiated by means of appropriate neural network architectures, which\nare evaluated on suitable benchmark task.\n", "versions": [{"version": "v1", "created": "Thu, 15 Mar 2018 15:14:16 GMT"}, {"version": "v2", "created": "Thu, 6 Dec 2018 16:44:26 GMT"}], "update_date": "2018-12-07", "authors_parsed": [["Pfannschmidt", "Karlson", ""], ["Gupta", "Pritha", ""], ["H\u00fcllermeier", "Eyke", ""]]}, {"id": "1803.05990", "submitter": "Muhammad Kamal Hossen", "authors": "Muhammad Kamal Hossen, Md. Ali Faiad, Md. Shahnur Azad Chowdhury, and\n  Md. Sajjatul Islam", "title": "Discovering Users Topic of Interest from Tweet", "comments": null, "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 10, No 1, February 2018", "doi": "10.5121/ijcsit.2018.10108", "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays social media has become one of the largest gatherings of people in\nonline. There are many ways for the industries to promote their products to the\npublic through advertising. The variety of advertisement is increasing\ndramatically. Businessmen are so much dependent on the advertisement that\nsignificantly it really brought out success in the market and hence practiced\nby major industries. Thus, companies are trying hard to draw the attention of\ncustomers on social networks through online advertisement. One of the most\npopular social media is Twitter which is popular for short text sharing named\nTweet. People here create their profile with basic information. To ensure the\nadvertisements are shown to relative people, Twitter targets people based on\nlanguage, gender, interest, follower, device, behavior, tailored audiences,\nkeyword, and geography targeting. Twitter generates interest sets based on\ntheir activities on Twitter. What our framework does is that it determines the\ntopic of interest from a given list of Tweets if it has any. This process is\ncalled Entity Intersect Categorizing Value (EICV). Each category topic\ngenerates a set of words or phrases related to that topic. An entity set is\ncreated from processing tweets by keyword generation and Twitters data using\nTwitter API. Value of entities is matched with the set of categories. If they\ncross a threshold value, it results in the category which matched the desired\ninterest category. For smaller amounts of data sizes, the results show that our\nframework performs with higher accuracy rate.\n", "versions": [{"version": "v1", "created": "Sat, 10 Mar 2018 15:53:08 GMT"}], "update_date": "2018-03-19", "authors_parsed": [["Hossen", "Muhammad Kamal", ""], ["Faiad", "Md. Ali", ""], ["Chowdhury", "Md. Shahnur Azad", ""], ["Islam", "Md. Sajjatul", ""]]}, {"id": "1803.06390", "submitter": "Marina Sokolova", "authors": "Marina Sokolova, Victoria Bobicev", "title": "Corpus Statistics in Text Classification of Online Data", "comments": "12 pages, 6 tables, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transformation of Machine Learning (ML) from a boutique science to a\ngenerally accepted technology has increased importance of reproduction and\ntransportability of ML studies. In the current work, we investigate how corpus\ncharacteristics of textual data sets correspond to text classification results.\nWe work with two data sets gathered from sub-forums of an online health-related\nforum. Our empirical results are obtained for a multi-class sentiment analysis\napplication.\n", "versions": [{"version": "v1", "created": "Fri, 16 Mar 2018 20:19:56 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Sokolova", "Marina", ""], ["Bobicev", "Victoria", ""]]}, {"id": "1803.06540", "submitter": "Yongfeng Zhang", "authors": "Yongfeng Zhang and Qingyao Ai and Xu Chen and Pengfei Wang", "title": "Learning over Knowledge-Base Embeddings for Recommendation", "comments": null, "journal-ref": "Algorithms 11(9):137, 2018, Special Issue on Collaborative\n  Filtering and Recommender Systems", "doi": "10.3390/a11090137", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  State-of-the-art recommendation algorithms -- especially the collaborative\nfiltering (CF) based approaches with shallow or deep models -- usually work\nwith various unstructured information sources for recommendation, such as\ntextual reviews, visual images, and various implicit or explicit feedbacks.\nThough structured knowledge bases were considered in content-based approaches,\nthey have been largely neglected recently due to the availability of vast\namount of data, and the learning power of many complex models.\n  However, structured knowledge bases exhibit unique advantages in personalized\nrecommendation systems. When the explicit knowledge about users and items is\nconsidered for recommendation, the system could provide highly customized\nrecommendations based on users' historical behaviors. A great challenge for\nusing knowledge bases for recommendation is how to integrated large-scale\nstructured and unstructured data, while taking advantage of collaborative\nfiltering for highly accurate performance. Recent achievements on knowledge\nbase embedding sheds light on this problem, which makes it possible to learn\nuser and item representations while preserving the structure of their\nrelationship with external knowledge. In this work, we propose to reason over\nknowledge base embeddings for personalized recommendation. Specifically, we\npropose a knowledge base representation learning approach to embed\nheterogeneous entities for recommendation. Experimental results on real-world\ndataset verified the superior performance of our approach compared with\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 17:03:12 GMT"}, {"version": "v2", "created": "Thu, 22 Mar 2018 21:56:15 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Zhang", "Yongfeng", ""], ["Ai", "Qingyao", ""], ["Chen", "Xu", ""], ["Wang", "Pengfei", ""]]}, {"id": "1803.06555", "submitter": "Sumit Bhatia", "authors": "Sumit Bhatia, Purusharth Dwivedi and Avneet Kaur", "title": "Tell Me Why Is It So? Explaining Knowledge Graph Relationships by\n  Finding Descriptive Support Passages", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of finding descriptive explanations of facts stored in\na knowledge graph. This is important in high-risk domains such as healthcare,\nintelligence, etc. where users need additional information for decision making\nand is especially crucial for applications that rely on automatically\nconstructed knowledge bases where machine learned systems extract facts from an\ninput corpus and working of the extractors is opaque to the end-user. We follow\nan approach inspired from information retrieval and propose a simple and\nefficient, yet effective solution that takes into account passage level as well\nas document level properties to produce a ranked list of passages describing a\ngiven input relation. We test our approach using Wikidata as the knowledge base\nand Wikipedia as the source corpus and report results of user studies conducted\nto study the effectiveness of our proposed model.\n", "versions": [{"version": "v1", "created": "Sat, 17 Mar 2018 19:26:26 GMT"}], "update_date": "2018-03-20", "authors_parsed": [["Bhatia", "Sumit", ""], ["Dwivedi", "Purusharth", ""], ["Kaur", "Avneet", ""]]}, {"id": "1803.07347", "submitter": "Li He", "authors": "Li He, Liang Wang, Kaipeng Liu, Bo Wu, Weinan Zhang", "title": "Optimizing Sponsored Search Ranking Strategy by Deep Reinforcement\n  Learning", "comments": "revise some content", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sponsored search is an indispensable business model and a major revenue\ncontributor of almost all the search engines. From the advertisers' side,\nparticipating in ranking the search results by paying for the sponsored search\nadvertisement to attract more awareness and purchase facilitates their\ncommercial goal. From the users' side, presenting personalized advertisement\nreflecting their propensity would make their online search experience more\nsatisfactory. Sponsored search platforms rank the advertisements by a ranking\nfunction to determine the list of advertisements to show and the charging price\nfor the advertisers. Hence, it is crucial to find a good ranking function which\ncan simultaneously satisfy the platform, the users and the advertisers.\nMoreover, advertisements showing positions under different queries from\ndifferent users may associate with advertisement candidates of different bid\nprice distributions and click probability distributions, which requires the\nranking functions to be optimized adaptively to the traffic characteristics. In\nthis work, we proposed a generic framework to optimize the ranking functions by\ndeep reinforcement learning methods. The framework is composed of two parts: an\noffline learning part which initializes the ranking functions by learning from\na simulated advertising environment, allowing adequate exploration of the\nranking function parameter space without hurting the performance of the\ncommercial platform. An online learning part which further optimizes the\nranking functions by adapting to the online data distribution. Experimental\nresults on a large-scale sponsored search platform confirm the effectiveness of\nthe proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 10:18:26 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2018 09:29:59 GMT"}, {"version": "v3", "created": "Mon, 26 Mar 2018 05:01:47 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["He", "Li", ""], ["Wang", "Liang", ""], ["Liu", "Kaipeng", ""], ["Wu", "Bo", ""], ["Zhang", "Weinan", ""]]}, {"id": "1803.07427", "submitter": "Soujanya Poria", "authors": "Soujanya Poria, Navonil Majumder, Devamanyu Hazarika, Erik Cambria,\n  Alexander Gelbukh, Amir Hussain", "title": "Multimodal Sentiment Analysis: Addressing Key Issues and Setting up the\n  Baselines", "comments": "IEEE Intelligence Systems. arXiv admin note: substantial text overlap\n  with arXiv:1707.09538", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We compile baselines, along with dataset split, for multimodal sentiment\nanalysis. In this paper, we explore three different deep-learning based\narchitectures for multimodal sentiment classification, each improving upon the\nprevious. Further, we evaluate these architectures with multiple datasets with\nfixed train/test partition. We also discuss some major issues, frequently\nignored in multimodal sentiment analysis research, e.g., role of\nspeaker-exclusive models, importance of different modalities, and\ngeneralizability. This framework illustrates the different facets of analysis\nto be considered while performing multimodal sentiment analysis and, hence,\nserves as a new benchmark for future research in this emerging field.\n", "versions": [{"version": "v1", "created": "Mon, 19 Mar 2018 02:23:30 GMT"}, {"version": "v2", "created": "Tue, 12 Feb 2019 02:42:19 GMT"}], "update_date": "2019-02-13", "authors_parsed": [["Poria", "Soujanya", ""], ["Majumder", "Navonil", ""], ["Hazarika", "Devamanyu", ""], ["Cambria", "Erik", ""], ["Gelbukh", "Alexander", ""], ["Hussain", "Amir", ""]]}, {"id": "1803.07679", "submitter": "Fabio Daolio", "authors": "\\^Angelo Cardoso, Fabio Daolio and Sa\\'ul Vargas", "title": "Product Characterisation towards Personalisation: Learning Attributes\n  from Unstructured Data to Recommend Fashion Products", "comments": "Under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe a solution to tackle a common set of challenges in\ne-commerce, which arise from the fact that new products are continually being\nadded to the catalogue. The challenges involve properly personalising the\ncustomer experience, forecasting demand and planning the product range. We\nargue that the foundational piece to solve all of these problems is having\nconsistent and detailed information about each product, information that is\nrarely available or consistent given the multitude of suppliers and types of\nproducts. We describe in detail the architecture and methodology implemented at\nASOS, one of the world's largest fashion e-commerce retailers, to tackle this\nproblem. We then show how this quantitative understanding of the products can\nbe leveraged to improve recommendations in a hybrid recommender system\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 20 Mar 2018 22:25:29 GMT"}], "update_date": "2018-03-22", "authors_parsed": [["Cardoso", "\u00c2ngelo", ""], ["Daolio", "Fabio", ""], ["Vargas", "Sa\u00fal", ""]]}, {"id": "1803.07890", "submitter": "Tu  Nguyen", "authors": "Tu Ngoc Nguyen, Nattiya Kanhabua, Wolfgang Nejdl", "title": "Multiple Models for Recommending Temporal Aspects of Entities", "comments": "In proceedings of the 15th Extended Semantic Web Conference (ESWC\n  2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity aspect recommendation is an emerging task in semantic search that\nhelps users discover serendipitous and prominent information with respect to an\nentity, of which salience (e.g., popularity) is the most important factor in\nprevious work. However, entity aspects are temporally dynamic and often driven\nby events happening over time. For such cases, aspect suggestion based solely\non salience features can give unsatisfactory results, for two reasons. First,\nsalience is often accumulated over a long time period and does not account for\nrecency. Second, many aspects related to an event entity are strongly\ntime-dependent. In this paper, we study the task of temporal aspect\nrecommendation for a given entity, which aims at recommending the most relevant\naspects and takes into account time in order to improve search experience. We\npropose a novel event-centric ensemble ranking method that learns from multiple\ntime and type-dependent models and dynamically trades off salience and recency\ncharacteristics. Through extensive experiments on real-world query logs, we\ndemonstrate that our method is robust and achieves better effectiveness than\ncompetitive baselines.\n", "versions": [{"version": "v1", "created": "Wed, 21 Mar 2018 12:51:51 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 08:39:20 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Nguyen", "Tu Ngoc", ""], ["Kanhabua", "Nattiya", ""], ["Nejdl", "Wolfgang", ""]]}, {"id": "1803.08354", "submitter": "Mohammad Aliannejadi", "authors": "Mohammad Aliannejadi and Fabio Crestani", "title": "Venue Suggestion Using Social-Centric Scores", "comments": "Accepted in ECIR Workshop on Social Aspects in Personalization and\n  Search (SoAPS), Grenoble, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User modeling is a very important task for making relevant suggestions of\nvenues to the users. These suggestions are often based on matching the venues'\nfeatures with the users' preferences, which can be collected from previously\nvisited locations. In this paper, we present a set of relevance scores for\nmaking personalized suggestions of points of interest. These scores model each\nuser by focusing on the different types of information extracted from venues\nthat they have previously visited. In particular, we focus on scores extracted\nfrom social information available on location-based social networks. Our\nexperiments, conducted on the dataset of the TREC Contextual Suggestion Track,\nshow that social scores are more effective than scores based venues' content.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 13:47:55 GMT"}, {"version": "v2", "created": "Sun, 10 Mar 2019 17:33:06 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Aliannejadi", "Mohammad", ""], ["Crestani", "Fabio", ""]]}, {"id": "1803.08378", "submitter": "Jian Gao", "authors": "Ling-Jiao Chen, Jian Gao", "title": "A trust-based recommendation method using network diffusion processes", "comments": "14 pages, 6 figures, 2 tables", "journal-ref": "Physica A 506 (2018) 679-691", "doi": "10.1016/j.physa.2018.04.089", "report-no": null, "categories": "cs.IR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A variety of rating-based recommendation methods have been extensively\nstudied including the well-known collaborative filtering approaches and some\nnetwork diffusion-based methods, however, social trust relations are not\nsufficiently considered when making recommendations. In this paper, we\ncontribute to the literature by proposing a trust-based recommendation method,\nnamed CosRA+T, after integrating the information of trust relations into the\nresource-redistribution process. Specifically, a tunable parameter is used to\nscale the resources received by trusted users before the redistribution back to\nthe objects. Interestingly, we find an optimal scaling parameter for the\nproposed CosRA+T method to achieve its best recommendation accuracy, and the\noptimal value seems to be universal under several evaluation metrics across\ndifferent datasets. Moreover, results of extensive experiments on the two\nreal-world rating datasets with trust relations, Epinions and FriendFeed,\nsuggest that CosRA+T has a remarkable improvement in overall accuracy,\ndiversity, and novelty. Our work takes a step towards designing better\nrecommendation algorithms by employing multiple resources of social network\ninformation.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 14:35:44 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Chen", "Ling-Jiao", ""], ["Gao", "Jian", ""]]}, {"id": "1803.08612", "submitter": "Md Masudur Rahman", "authors": "Md Masudur Rahman, Jed Barson, Sydney Paul, Joshua Kayan, Federico\n  Andres Lois, Sebastian Fernandez Quezada, Christopher Parnin, Kathryn T.\n  Stolee, Baishakhi Ray", "title": "Evaluating How Developers Use General-Purpose Web-Search for Code\n  Retrieval", "comments": "Accepted at MSR-2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search is an integral part of a software development process. Developers\noften use search engines to look for information during development, including\nreusable code snippets, API understanding, and reference examples. Developers\ntend to prefer general-purpose search engines like Google, which are often not\noptimized for code related documents and use search strategies and ranking\ntechniques that are more optimized for generic, non-code related information.\nIn this paper, we explore whether a general purpose search engine like Google\nis an optimal choice for code-related searches. In particular, we investigate\nwhether the performance of searching with Google varies for code vs. non-code\nrelated searches. To analyze this, we collect search logs from 310 developers\nthat contains nearly 150,000 search queries from Google and the associated\nresult clicks. To differentiate between code-related searches and non-code\nrelated searches, we build a model which identifies the code intent of queries.\nLeveraging this model, we build an automatic classifier that detects a code and\nnon-code related query. We confirm the effectiveness of the classifier on\nmanually annotated queries where the classifier achieves a precision of 87%, a\nrecall of 86%, and an F1-score of 87%. We apply this classifier to\nautomatically annotate all the queries in the dataset. Analyzing this dataset,\nwe observe that code related searching often requires more effort (e.g., time,\nresult clicks, and query modifications) than general non-code search, which\nindicates code search performance with a general search engine is less\neffective.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 23:29:25 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Rahman", "Md Masudur", ""], ["Barson", "Jed", ""], ["Paul", "Sydney", ""], ["Kayan", "Joshua", ""], ["Lois", "Federico Andres", ""], ["Quezada", "Sebastian Fernandez", ""], ["Parnin", "Christopher", ""], ["Stolee", "Kathryn T.", ""], ["Ray", "Baishakhi", ""]]}, {"id": "1803.08651", "submitter": "Rahul Meshram", "authors": "Rahul Meshram, D. Manjunath and Nikhil Karamchandani", "title": "Learning Recommendations While Influencing Interests", "comments": "13 pages, submitted to conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized recommendation systems (RS) are extensively used in many\nservices. Many of these are based on learning algorithms where the RS uses the\nrecommendation history and the user response to learn an optimal strategy.\nFurther, these algorithms are based on the assumption that the user interests\nare rigid. Specifically, they do not account for the effect of learning\nstrategy on the evolution of the user interests. In this paper we develop\ninfluence models for a learning algorithm that is used to optimally recommend\nwebsites to web users. We adapt the model of \\cite{Ioannidis10} to include an\nitem-dependent reward to the RS from the suggestions that are accepted by the\nuser. For this we first develop a static optimisation scheme when all the\nparameters are known. Next we develop a stochastic approximation based learning\nscheme for the RS to learn the optimal strategy when the user profiles are not\nknown. Finally, we describe several user-influence models for the learning\nalgorithm and analyze their effect on the steady user interests and on the\nsteady state optimal strategy as compared to that when the users are not\ninfluenced.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 04:09:24 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Meshram", "Rahul", ""], ["Manjunath", "D.", ""], ["Karamchandani", "Nikhil", ""]]}, {"id": "1803.08721", "submitter": "Florian Boudin", "authors": "Florian Boudin", "title": "Unsupervised Keyphrase Extraction with Multipartite Graphs", "comments": "Accepted at NAACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose an unsupervised keyphrase extraction model that encodes topical\ninformation within a multipartite graph structure. Our model represents\nkeyphrase candidates and topics in a single graph and exploits their mutually\nreinforcing relationship to improve candidate ranking. We further introduce a\nnovel mechanism to incorporate keyphrase selection preferences into the model.\nExperiments conducted on three widely used datasets show significant\nimprovements over state-of-the-art graph-based models.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 10:35:42 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2018 08:49:00 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Boudin", "Florian", ""]]}, {"id": "1803.08790", "submitter": "Md Saiful Islam", "authors": "Hemayet Ahmed Chowdhury, Tanvir Alam Nibir and Md. Saiful Islam", "title": "Sentiment Analysis of Comments on Rohingya Movement with Support Vector\n  Machine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Rohingya Movement and Crisis caused a huge uproar in the political and\neconomic state of Bangladesh. Refugee movement is a recurring event and a large\namount of data in the form of opinions remains on social media such as\nFacebook, with very little analysis done on them.To analyse the comments based\non all Rohingya related posts, we had to create and modify a classifier based\non the Support Vector Machine algorithm. The code is implemented in python and\nuses scikit-learn library. A dataset on Rohingya analysis is not currently\navailable so we had to use our own data set of 2500 positive and 2500 negative\ncomments. We specifically used a support vector machine with linear kernel. A\nprevious experiment was performed by us on the same dataset using the naive\nbayes algorithm, but that did not yield impressive results.\n", "versions": [{"version": "v1", "created": "Thu, 22 Mar 2018 15:30:03 GMT"}], "update_date": "2018-03-26", "authors_parsed": [["Chowdhury", "Hemayet Ahmed", ""], ["Nibir", "Tanvir Alam", ""], ["Islam", "Md. Saiful", ""]]}, {"id": "1803.08850", "submitter": "Feichen Shen PhD", "authors": "Feichen Shen, David W Larson, James M. Naessens, Elizabeth B.\n  Habermann, Hongfang Liu, Sunghwan Sohn", "title": "Detection of Surgical Site Infection Utilizing Automated Feature\n  Generation in Clinical Notes", "comments": null, "journal-ref": null, "doi": "10.1007/s41666-018-0042-9", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Postsurgical complications (PSCs) are known as a deviation from the normal\npostsurgical course and categorized by severity and treatment requirements.\nSurgical site infection (SSI) is one of major PSCs and the most common\nhealthcare-associated infection, resulting in increased length of hospital stay\nand cost. In this work, we assessed an automated way to generate lexicon (i.e.,\nkeyword features) from clinical narratives using sublanguage analysis with\nheuristics to detect SSI and evaluated these keywords with medical experts. To\nfurther validate our approach, we also conducted decision tree algorithm on\ncohort using automatically generated keywords. The results show that our\nframework was able to identify SSI keywords from clinical narratives and to\nsupport search-based natural language processing (NLP) approaches by augmenting\nsearch queries.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 15:55:14 GMT"}, {"version": "v2", "created": "Mon, 26 Mar 2018 16:36:10 GMT"}], "update_date": "2018-12-10", "authors_parsed": [["Shen", "Feichen", ""], ["Larson", "David W", ""], ["Naessens", "James M.", ""], ["Habermann", "Elizabeth B.", ""], ["Liu", "Hongfang", ""], ["Sohn", "Sunghwan", ""]]}, {"id": "1803.08988", "submitter": "Haotian Zhang", "authors": "Haotian Zhang, Gordon V. Cormack, Maura R. Grossman, Mark D. Smucker", "title": "Evaluating Sentence-Level Relevance Feedback for High-Recall Information\n  Retrieval", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study uses a novel simulation framework to evaluate whether the time and\neffort necessary to achieve high recall using active learning is reduced by\npresenting the reviewer with isolated sentences, as opposed to full documents,\nfor relevance feedback. Under the weak assumption that more time and effort is\nrequired to review an entire document than a single sentence, simulation\nresults indicate that the use of isolated sentences for relevance feedback can\nyield comparable accuracy and higher efficiency, relative to the\nstate-of-the-art Baseline Model Implementation (BMI) of the AutoTAR Continuous\nActive Learning (\"CAL\") method employed in the TREC 2015 and 2016 Total Recall\nTrack.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 21:41:40 GMT"}, {"version": "v2", "created": "Thu, 28 Mar 2019 02:50:16 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Zhang", "Haotian", ""], ["Cormack", "Gordon V.", ""], ["Grossman", "Maura R.", ""], ["Smucker", "Mark D.", ""]]}, {"id": "1803.09000", "submitter": "Yang Yu", "authors": "Yang Yu, Vincent Ng", "title": "WikiRank: Improving Keyphrase Extraction Based on Background Knowledge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyphrase is an efficient representation of the main idea of documents. While\nbackground knowledge can provide valuable information about documents, they are\nrarely incorporated in keyphrase extraction methods. In this paper, we propose\nWikiRank, an unsupervised method for keyphrase extraction based on the\nbackground knowledge from Wikipedia. Firstly, we construct a semantic graph for\nthe document. Then we transform the keyphrase extraction problem into an\noptimization problem on the graph. Finally, we get the optimal keyphrase set to\nbe the output. Our method obtains improvements over other state-of-art models\nby more than 2% in F1-score.\n", "versions": [{"version": "v1", "created": "Fri, 23 Mar 2018 22:30:58 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Yu", "Yang", ""], ["Ng", "Vincent", ""]]}, {"id": "1803.09401", "submitter": "Anik Islam", "authors": "Anik Islam, Arifa Akter and Bayzid Ashik Hossain", "title": "HomeGuard: A Smart System to Deal with the Emergency Response of\n  Domestic Violence Victims", "comments": "10 pages, 5 figures, 2016 International Journal of Computer Science\n  Issues", "journal-ref": null, "doi": "10.20943/01201606.103112", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domestic violence is a silent crisis in the developing and underdeveloped\ncountries, though developed countries also remain drowned in the curse of it.\nIn developed countries, victims can easily report and ask help on the contrary\nin developing and underdeveloped countries victims hardly report the crimes and\nwhen it's noticed by the authority it's become too late to save or support the\nvictim. If this kind of problems can be identified at the very beginning of the\nevent and proper actions can be taken, it'll not only help the victim but also\nreduce the domestic violence crimes. This paper proposed a smart system which\ncan extract victim's situation and provide help according to it. Among of the\ndeveloping and underdeveloped countries Bangladesh has been chosen though the\nrate of reporting of domestic violence is low, the extreme report collected by\nauthorities is too high. Case studies collected by different NGO's relating to\ndomestic violence have been studied and applied to extract possible condition\nfor the victims.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 03:45:56 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Islam", "Anik", ""], ["Akter", "Arifa", ""], ["Hossain", "Bayzid Ashik", ""]]}, {"id": "1803.09551", "submitter": "Guang-Neng Hu", "authors": "Guang-Neng Hu, Xin-Yu Dai, Feng-Yu Qiu, Rui Xia, Tao Li, Shu-Jian\n  Huang, Jia-Jun Chen", "title": "Collaborative Filtering with Topic and Social Latent Factors\n  Incorporating Implicit Feedback", "comments": "27 pages, 11 figures, 6 tables, ACM TKDD 2018", "journal-ref": null, "doi": "10.1145/3127873", "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems (RSs) provide an effective way of alleviating the\ninformation overload problem by selecting personalized items for different\nusers. Latent factors based collaborative filtering (CF) has become the popular\napproaches for RSs due to its accuracy and scalability. Recently, online social\nnetworks and user-generated content provide diverse sources for recommendation\nbeyond ratings. Although {\\em social matrix factorization} (Social MF) and {\\em\ntopic matrix factorization} (Topic MF) successfully exploit social relations\nand item reviews, respectively, both of them ignore some useful information. In\nthis paper, we investigate the effective data fusion by combining the\naforementioned approaches. First, we propose a novel model {\\em \\mbox{MR3}} to\njointly model three sources of information (i.e., ratings, item reviews, and\nsocial relations) effectively for rating prediction by aligning the latent\nfactors and hidden topics. Second, we incorporate the implicit feedback from\nratings into the proposed model to enhance its capability and to demonstrate\nits flexibility. We achieve more accurate rating prediction on real-life\ndatasets over various state-of-the-art methods. Furthermore, we measure the\ncontribution from each of the three data sources and the impact of implicit\nfeedback from ratings, followed by the sensitivity analysis of hyperparameters.\nEmpirical studies demonstrate the effectiveness and efficacy of our proposed\nmodel and its extension.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 12:46:13 GMT"}], "update_date": "2021-01-15", "authors_parsed": [["Hu", "Guang-Neng", ""], ["Dai", "Xin-Yu", ""], ["Qiu", "Feng-Yu", ""], ["Xia", "Rui", ""], ["Li", "Tao", ""], ["Huang", "Shu-Jian", ""], ["Chen", "Jia-Jun", ""]]}, {"id": "1803.09587", "submitter": "Malte Ludewig", "authors": "Malte Ludewig, Dietmar Jannach", "title": "Evaluation of Session-based Recommendation Algorithms", "comments": null, "journal-ref": null, "doi": "10.1007/s11257-018-9209-6", "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems help users find relevant items of interest, for example\non e-commerce or media streaming sites. Most academic research is concerned\nwith approaches that personalize the recommendations according to long-term\nuser profiles. In many real-world applications, however, such long-term\nprofiles often do not exist and recommendations therefore have to be made\nsolely based on the observed behavior of a user during an ongoing session.\nGiven the high practical relevance of the problem, an increased interest in\nthis problem can be observed in recent years, leading to a number of proposals\nfor session-based recommendation algorithms that typically aim to predict the\nuser's immediate next actions. In this work, we present the results of an\nin-depth performance comparison of a number of such algorithms, using a variety\nof datasets and evaluation measures. Our comparison includes the most recent\napproaches based on recurrent neural networks like GRU4REC, factorized Markov\nmodel approaches such as FISM or FOSSIL, as well as simpler methods based,\ne.g., on nearest neighbor schemes. Our experiments reveal that algorithms of\nthis latter class, despite their sometimes almost trivial nature, often perform\nequally well or significantly better than today's more complex approaches based\non deep neural networks. Our results therefore suggest that there is\nsubstantial room for improvement regarding the development of more\nsophisticated session-based recommendation algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 13:46:07 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 10:14:57 GMT"}], "update_date": "2018-10-31", "authors_parsed": [["Ludewig", "Malte", ""], ["Jannach", "Dietmar", ""]]}, {"id": "1803.09799", "submitter": "Linhong Zhu", "authors": "Linhong Zhu", "title": "Demystifying Core Ranking in Pinterest Image Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pinterest Image Search Engine helps hundreds of millions of users discover\ninteresting content everyday. This motivates us to improve the image search\nquality by evolving our ranking techniques. In this work, we share how we\npractically design and deploy various ranking pipelines into Pinterest image\nsearch ecosystem. Specifically, we focus on introducing our novel research and\nstudy on three aspects: training data, user/image featurization and ranking\nmodels. Extensive offline and online studies compared the performance of\ndifferent models and demonstrated the efficiency and effectiveness of our final\nlaunched ranking models.\n", "versions": [{"version": "v1", "created": "Mon, 26 Mar 2018 19:12:02 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Zhu", "Linhong", ""]]}, {"id": "1803.09875", "submitter": "Aldo Hernandez-Suarez", "authors": "A. Hernandez-Suarez, G. Sanchez-Perez, K. Toscano-Medina, V.\n  Martinez-Hernandez, V. Sanchez and H. Perez-Meana", "title": "A Web Scraping Methodology for Bypassing Twitter API Restrictions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieving information from social networks is the first and primordial step\nmany data analysis fields such as Natural Language Processing, Sentiment\nAnalysis and Machine Learning. Important data science tasks relay on historical\ndata gathering for further predictive results. Most of the recent works use\nTwitter API, a public platform for collecting public streams of information,\nwhich allows querying chronological tweets for no more than three weeks old. In\nthis paper, we present a new methodology for collecting historical tweets\nwithin any date range using web scraping techniques bypassing for Twitter API\nrestrictions.\n", "versions": [{"version": "v1", "created": "Tue, 27 Mar 2018 03:23:19 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Hernandez-Suarez", "A.", ""], ["Sanchez-Perez", "G.", ""], ["Toscano-Medina", "K.", ""], ["Martinez-Hernandez", "V.", ""], ["Sanchez", "V.", ""], ["Perez-Meana", "H.", ""]]}, {"id": "1803.10384", "submitter": "Yuan Gong", "authors": "Yuan Gong and Christian Poellabauer", "title": "Topic Modeling Based Multi-modal Depression Detection", "comments": "Proceedings of the 7th Audio/Visual Emotion Challenge and Workshop\n  (AVEC). (Official Depression Challenge Winner)", "journal-ref": null, "doi": "10.1145/3133944.3133945", "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Major depressive disorder is a common mental disorder that affects almost 7%\nof the adult U.S. population. The 2017 Audio/Visual Emotion Challenge (AVEC)\nasks participants to build a model to predict depression levels based on the\naudio, video, and text of an interview ranging between 7-33 minutes. Since\naveraging features over the entire interview will lose most temporal\ninformation, how to discover, capture, and preserve useful temporal details for\nsuch a long interview are significant challenges. Therefore, we propose a novel\ntopic modeling based approach to perform context-aware analysis of the\nrecording. Our experiments show that the proposed approach outperforms\ncontext-unaware methods and the challenge baselines for all metrics.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 02:12:48 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Gong", "Yuan", ""], ["Poellabauer", "Christian", ""]]}, {"id": "1803.10450", "submitter": "Ugo Tanielian", "authors": "Ugo Tanielian, Anne-Marie Tousch, Flavian Vasile", "title": "Siamese Cookie Embedding Networks for Cross-Device User Matching", "comments": "The Web Conference 2018 poster 3 pages, 2 figures", "journal-ref": null, "doi": "10.1145/3184558.3186941", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, the number of devices per person has increased\nsubstantially. This poses a challenge for cookie-based personalization\napplications, such as online search and advertising, as it narrows the\npersonalization signal to a single device environment. A key task is to find\nwhich cookies belong to the same person to recover a complete cross-device user\njourney. Recent work on the topic has shown the benefits of using unsupervised\nembeddings learned on user event sequences. In this paper, we extend this\napproach to a supervised setting and introduce the Siamese Cookie Embedding\nNetwork (SCEmNet), a siamese convolutional architecture that leverages the\nmulti-modal aspect of sequences, and show significant improvement over the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 08:12:50 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Tanielian", "Ugo", ""], ["Tousch", "Anne-Marie", ""], ["Vasile", "Flavian", ""]]}, {"id": "1803.10739", "submitter": "Djordje Gligorijevic", "authors": "Jelena Gligorijevic, Djordje Gligorijevic, Ivan Stojkovic, Xiao Bai,\n  Amit Goyal and Zoran Obradovic", "title": "Deeply Supervised Semantic Model for Click-Through Rate Prediction in\n  Sponsored Search", "comments": "The first and second authors listed are co-first author", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In sponsored search it is critical to match ads that are relevant to a query\nand to accurately predict their likelihood of being clicked. Commercial search\nengines typically use machine learning models for both query-ad relevance\nmatching and click-through-rate (CTR) prediction. However, matching models are\nbased on the similarity between a query and an ad, ignoring the fact that a\nretrieved ad may not attract clicks, while click models rely on click history,\nbeing of limited use for new queries and ads. We propose a deeply supervised\narchitecture that jointly learns the semantic embeddings of a query and an ad\nas well as their corresponding CTR.We also propose a novel cohort negative\nsampling technique for learning implicit negative signals. We trained the\nproposed architecture using one billion query-ad pairs from a major commercial\nweb search engine. This architecture improves the best-performing baseline deep\nneural architectures by 2\\% of AUC for CTR prediction and by statistically\nsignificant 0.5\\% of NDCG for query-ad matching.\n", "versions": [{"version": "v1", "created": "Wed, 28 Mar 2018 17:24:32 GMT"}], "update_date": "2018-03-29", "authors_parsed": [["Gligorijevic", "Jelena", ""], ["Gligorijevic", "Djordje", ""], ["Stojkovic", "Ivan", ""], ["Bai", "Xiao", ""], ["Goyal", "Amit", ""], ["Obradovic", "Zoran", ""]]}]