[{"id": "0801.0386", "submitter": "Dimitrios Katsaros", "authors": "Dimitrios Katsaros, Leonidas Akritidis, Panayiotis Bozanis", "title": "Spam: It's Not Just for Inboxes and Search Engines! Making Hirsch\n  h-index Robust to Scientospam", "comments": "2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": null, "abstract": "  What is the 'level of excellence' of a scientist and the real impact of\nhis/her work upon the scientific thinking and practising? How can we design a\nfair, an unbiased metric -- and most importantly -- a metric robust to\nmanipulation?\n", "versions": [{"version": "v1", "created": "Wed, 2 Jan 2008 13:06:37 GMT"}], "update_date": "2008-01-03", "authors_parsed": [["Katsaros", "Dimitrios", ""], ["Akritidis", "Leonidas", ""], ["Bozanis", "Panayiotis", ""]]}, {"id": "0801.1063", "submitter": "Ivan Titov", "authors": "Ivan Titov and Ryan McDonald", "title": "Modeling Online Reviews with Multi-grain Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": null, "abstract": "  In this paper we present a novel framework for extracting the ratable aspects\nof objects from online user reviews. Extracting such aspects is an important\nchallenge in automatically mining product opinions from the web and in\ngenerating opinion-based summaries of user reviews. Our models are based on\nextensions to standard topic modeling methods such as LDA and PLSA to induce\nmulti-grain topics. We argue that multi-grain models are more appropriate for\nour task since standard models tend to produce topics that correspond to global\nproperties of objects (e.g., the brand of a product type) rather than the\naspects of an object that tend to be rated by a user. The models we present not\nonly extract ratable aspects, but also cluster them into coherent topics, e.g.,\n`waitress' and `bartender' are part of the same topic `staff' for restaurants.\nThis differentiates it from much of the previous work which extracts aspects\nthrough term frequency analysis with minimal clustering. We evaluate the\nmulti-grain models both qualitatively and quantitatively to show that they\nimprove significantly upon standard topic models.\n", "versions": [{"version": "v1", "created": "Mon, 7 Jan 2008 17:01:34 GMT"}], "update_date": "2008-01-08", "authors_parsed": [["Titov", "Ivan", ""], ["McDonald", "Ryan", ""]]}, {"id": "0801.1179", "submitter": "Bernard Jacquemin", "authors": "Bernard Jacquemin (ISC, UMR 7044, GERIICO), Sabine Ploux (ISC)", "title": "Corpus sp{\\'e}cialis{\\'e} et ressource de sp{\\'e}cialit{\\'e}", "comments": "16 pages, in French", "journal-ref": "Appears in Fran\\c{c}ois Maniez; Pascaline Dury; Nathalie Arlin;\n  Claire Rougemont. Corpus et dictionnaires de langues de sp{\\'e}cialit{\\'e},\n  Presses Universitaires de Granoble, pp.197-212, 2008", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Semantic Atlas\" is a mathematic and statistic model to visualise word senses\naccording to relations between words. The model, that has been applied to\nproximity relations from a corpus, has shown its ability to distinguish word\nsenses as the corpus' contributors comprehend them. We propose to use the model\nand a specialised corpus in order to create automatically a specialised\ndictionary relative to the corpus' domain. A morpho-syntactic analysis\nperformed on the corpus makes it possible to create the dictionary from\nsyntactic relations between lexical units. The semantic resource can be used to\nnavigate semantically - and not only lexically - through the corpus, to create\nclassical dictionaries or for diachronic studies of the language.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2008 08:21:26 GMT"}, {"version": "v2", "created": "Fri, 19 Jun 2015 12:22:39 GMT"}], "update_date": "2015-06-22", "authors_parsed": [["Jacquemin", "Bernard", "", "ISC, UMR 7044, GERIICO"], ["Ploux", "Sabine", "", "ISC"]]}, {"id": "0801.2378", "submitter": "Paolo Ferragina", "authors": "Paolo Ferragina", "title": "String algorithms and data structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": null, "abstract": "  The string-matching field has grown at a such complicated stage that various\nissues come into play when studying it: data structure and algorithmic design,\ndatabase principles, compression techniques, architectural features, cache and\nprefetching policies. The expertise nowadays required to design good string\ndata structures and algorithms is therefore transversal to many computer\nscience fields and much more study on the orchestration of known, or novel,\ntechniques is needed to make progress in this fascinating topic. This survey is\naimed at illustrating the key ideas which should constitute, in our opinion,\nthe current background of every index designer. We also discuss the positive\nfeatures and drawback of known indexing schemes and algorithms, and devote much\nattention to detail research issues and open problems both on the theoretical\nand the experimental side.\n", "versions": [{"version": "v1", "created": "Tue, 15 Jan 2008 20:54:18 GMT"}], "update_date": "2008-01-16", "authors_parsed": [["Ferragina", "Paolo", ""]]}, {"id": "0801.2618", "submitter": "Barry Doyle", "authors": "Barry Doyle (University of California, Irvine) and Cristina Videira\n  Lopes (University of California, Irvine)", "title": "Survey of Technologies for Web Application Development", "comments": "43 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.IR cs.NI", "license": null, "abstract": "  Web-based application developers face a dizzying array of platforms,\nlanguages, frameworks and technical artifacts to choose from. We survey,\nclassify, and compare technologies supporting Web application development. The\nclassification is based on (1) foundational technologies; (2)integration with\nother information sources; and (3) dynamic content generation. We further\nsurvey and classify software engineering techniques and tools that have been\nadopted from traditional programming into Web programming. We conclude that,\nalthough the infrastructure problems of the Web have largely been solved, the\ncacophony of technologies for Web-based applications reflects the lack of a\nsolid model tailored for this domain.\n", "versions": [{"version": "v1", "created": "Thu, 17 Jan 2008 05:06:44 GMT"}], "update_date": "2008-01-18", "authors_parsed": [["Doyle", "Barry", "", "University of California, Irvine"], ["Lopes", "Cristina Videira", "", "University of California, Irvine"]]}, {"id": "0801.3102", "submitter": "Eloisa Bentivegna", "authors": "Mark Wenstrom, Eloisa Bentivegna and Ali Hurson (Pennsylvania State\n  University)", "title": "Balancing transparency, efficiency and security in pervasive systems", "comments": "52 pages, to be published in Advances in Computers", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.IR", "license": null, "abstract": "  This chapter will survey pervasive computing with a look at how its\nconstraint for transparency affects issues of resource management and security.\nThe goal of pervasive computing is to render computing transparent, such that\ncomputing resources are ubiquitously offered to the user and services are\nproactively performed for a user without his or her intervention. The task of\nintegrating computing infrastructure into everyday life without making it\nexcessively invasive brings about tradeoffs between flexibility and robustness,\nefficiency and effectiveness, as well as autonomy and reliability. As the\nfeasibility of ubiquitous computing and its real potential for mass\napplications are still a matter of controversy, this chapter will look into the\nunderlying issues of resource management and authentication to discover how\nthese can be handled in a least invasive fashion. The discussion will be closed\nby an overview of the solutions proposed by current pervasive computing\nefforts, both in the area of generic platforms and for dedicated applications\nsuch as pervasive education and healthcare.\n", "versions": [{"version": "v1", "created": "Sun, 20 Jan 2008 19:15:50 GMT"}], "update_date": "2008-01-22", "authors_parsed": [["Wenstrom", "Mark", "", "Pennsylvania State\n  University"], ["Bentivegna", "Eloisa", "", "Pennsylvania State\n  University"], ["Hurson", "Ali", "", "Pennsylvania State\n  University"]]}, {"id": "0801.3199", "submitter": "Ngoc-Diep Ho", "authors": "Ngoc-Diep Ho (1), Paul Van Dooren (1) and Vincent D. Blondel (1) ((1)\n  Universit\\'e catholique de Louvain, Belgium)", "title": "Descent methods for Nonnegative Matrix Factorization", "comments": "47 pages. New convergence proof using damped version of RRI. To\n  appear in Numerical Linear Algebra in Signals, Systems and Control. Accepted.\n  Illustrating Matlab code is included in the source bundle", "journal-ref": null, "doi": null, "report-no": "2007.057", "categories": "cs.NA cs.IR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present several descent methods that can be applied to\nnonnegative matrix factorization and we analyze a recently developped fast\nblock coordinate method called Rank-one Residue Iteration (RRI). We also give a\ncomparison of these different methods and show that the new block coordinate\nmethod has better properties in terms of approximation error and complexity. By\ninterpreting this method as a rank-one approximation of the residue matrix, we\nprove that it \\emph{converges} and also extend it to the nonnegative tensor\nfactorization and introduce some variants of the method by imposing some\nadditional controllable constraints such as: sparsity, discreteness and\nsmoothness.\n", "versions": [{"version": "v1", "created": "Mon, 21 Jan 2008 15:46:43 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2008 21:20:12 GMT"}, {"version": "v3", "created": "Mon, 24 Aug 2009 22:32:24 GMT"}], "update_date": "2009-08-25", "authors_parsed": [["Ho", "Ngoc-Diep", ""], ["Van Dooren", "Paul", ""], ["Blondel", "Vincent D.", ""]]}, {"id": "0801.3908", "submitter": "Jakob Vo{\\ss}", "authors": "Jakob Voss", "title": "Encoding changing country codes for the Semantic Web with ISO 3166 and\n  SKOS", "comments": "Accepted to appear in the proceedings of the 2nd International Con-\n  ference on Metadata and Semantics Research (MTSR 2007)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": null, "abstract": "  This paper shows how authority files can be encoded for the Semantic Web with\nthe Simple Knowledge Organisation System (SKOS). In particular the application\nof SKOS for encoding the structure, management, and utilization of country\ncodes as defined in ISO 3166 is demonstrated. The proposed encoding gives a use\ncase for SKOS that includes features that have only been discussed little so\nfar, such as multiple notations, nested concept schemes, changes by versioning.\n", "versions": [{"version": "v1", "created": "Fri, 25 Jan 2008 10:40:27 GMT"}], "update_date": "2008-01-28", "authors_parsed": [["Voss", "Jakob", ""]]}]