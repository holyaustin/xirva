[{"id": "1410.0001", "submitter": "Fabien Gouyon", "authors": "Fabien Gouyon, Bob L. Sturm, Joao Lobato Oliveira, Nuno Hespanhol, and\n  Thibault Langlois", "title": "On Evaluation Validity in Music Autotagging", "comments": "Submitted for journal publication in September 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SD", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Music autotagging, an established problem in Music Information Retrieval,\naims to alleviate the human cost required to manually annotate collections of\nrecorded music with textual labels by automating the process. Many autotagging\nsystems have been proposed and evaluated by procedures and datasets that are\nnow standard (used in MIREX, for instance). Very little work, however, has been\ndedicated to determine what these evaluations really mean about an autotagging\nsystem, or the comparison of two systems, for the problem of annotating music\nin the real world. In this article, we are concerned with explaining the figure\nof merit of an autotagging system evaluated with a standard approach.\nSpecifically, does the figure of merit, or a comparison of figures of merit,\nwarrant a conclusion about how well autotagging systems have learned to\ndescribe music with a specific vocabulary? The main contributions of this paper\nare a formalization of the notion of validity in autotagging evaluation, and a\nmethod to test it in general. We demonstrate the practical use of our method in\nexperiments with three specific state-of-the-art autotagging systems --all of\nwhich are reproducible using the linked code and data. Our experiments show for\nthese specific systems in a simple and objective two-class task that the\nstandard evaluation approach does not provide valid indicators of their\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 30 Sep 2014 14:57:52 GMT"}], "update_date": "2014-10-02", "authors_parsed": [["Gouyon", "Fabien", ""], ["Sturm", "Bob L.", ""], ["Oliveira", "Joao Lobato", ""], ["Hespanhol", "Nuno", ""], ["Langlois", "Thibault", ""]]}, {"id": "1410.0471", "submitter": "Arto Klami", "authors": "Zakria Hussain, Arto Klami, Jussi Kujala, Alex P. Leung, Kitsuchart\n  Pasupa, Peter Auer, Samuel Kaski, Jorma Laaksonen and John Shawe-Taylor", "title": "PinView: Implicit Feedback in Content-Based Image Retrieval", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes PinView, a content-based image retrieval system that\nexploits implicit relevance feedback collected during a search session. PinView\ncontains several novel methods to infer the intent of the user. From relevance\nfeedback, such as eye movements or pointer clicks, and visual features of\nimages, PinView learns a similarity metric between images which depends on the\ncurrent interests of the user. It then retrieves images with a specialized\nonline learning algorithm that balances the tradeoff between exploring new\nimages and exploiting the already inferred interests of the user. We have\nintegrated PinView to the content-based image retrieval system PicSOM, which\nenables applying PinView to real-world image databases. With the new algorithms\nPinView outperforms the original PicSOM, and in online experiments with real\nusers the combination of implicit and explicit feedback gives the best results.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 08:05:19 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Hussain", "Zakria", ""], ["Klami", "Arto", ""], ["Kujala", "Jussi", ""], ["Leung", "Alex P.", ""], ["Pasupa", "Kitsuchart", ""], ["Auer", "Peter", ""], ["Kaski", "Samuel", ""], ["Laaksonen", "Jorma", ""], ["Shawe-Taylor", "John", ""]]}, {"id": "1410.0908", "submitter": "Ernest Fokoue", "authors": "Xingchen Yu and Ernest Fokoue", "title": "Probit Normal Correlated Topic Models", "comments": "11 pages, 2 figures and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The logistic normal distribution has recently been adapted via the\ntransformation of multivariate Gaus- sian variables to model the topical\ndistribution of documents in the presence of correlations among topics. In this\npaper, we propose a probit normal alternative approach to modelling correlated\ntopical structures. Our use of the probit model in the context of topic\ndiscovery is novel, as many authors have so far con- centrated solely of the\nlogistic model partly due to the formidable inefficiency of the multinomial\nprobit model even in the case of very small topical spaces. We herein\ncircumvent the inefficiency of multinomial probit estimation by using an\nadaptation of the diagonal orthant multinomial probit in the topic models\ncontext, resulting in the ability of our topic modelling scheme to handle\ncorpuses with a large number of latent topics. An additional and very important\nbenefit of our method lies in the fact that unlike with the logistic normal\nmodel whose non-conjugacy leads to the need for sophisticated sampling schemes,\nour ap- proach exploits the natural conjugacy inherent in the auxiliary\nformulation of the probit model to achieve greater simplicity. The application\nof our proposed scheme to a well known Associated Press corpus not only helps\ndiscover a large number of meaningful topics but also reveals the capturing of\ncompellingly intuitive correlations among certain topics. Besides, our proposed\napproach lends itself to even further scalability thanks to various existing\nhigh performance algorithms and architectures capable of handling millions of\ndocuments.\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2014 16:38:53 GMT"}], "update_date": "2014-10-06", "authors_parsed": [["Yu", "Xingchen", ""], ["Fokoue", "Ernest", ""]]}, {"id": "1410.0993", "submitter": "Le Li", "authors": "Le Li, Jianjun Yang, Yang Xu, Zhen Qin, Honggang Zhang", "title": "Document Clustering Based On Max-Correntropy Non-Negative Matrix\n  Factorization", "comments": "International Conference of Machine Learning and Cybernetics (ICMLC)\n  2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonnegative matrix factorization (NMF) has been successfully applied to many\nareas for classification and clustering. Commonly-used NMF algorithms mainly\ntarget on minimizing the $l_2$ distance or Kullback-Leibler (KL) divergence,\nwhich may not be suitable for nonlinear case. In this paper, we propose a new\ndecomposition method by maximizing the correntropy between the original and the\nproduct of two low-rank matrices for document clustering. This method also\nallows us to learn the new basis vectors of the semantic feature space from the\ndata. To our knowledge, we haven't seen any work has been done by maximizing\ncorrentropy in NMF to cluster high dimensional document data. Our experiment\nresults show the supremacy of our proposed method over other variants of NMF\nalgorithm on Reuters21578 and TDT2 databasets.\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2014 23:09:09 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Li", "Le", ""], ["Yang", "Jianjun", ""], ["Xu", "Yang", ""], ["Qin", "Zhen", ""], ["Zhang", "Honggang", ""]]}, {"id": "1410.1462", "submitter": "Zhi-Hua Zhou", "authors": "Nan Li and Rong Jin and Zhi-Hua Zhou", "title": "Top Rank Optimization in Linear Time", "comments": null, "journal-ref": "NIPS 2014", "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipartite ranking aims to learn a real-valued ranking function that orders\npositive instances before negative instances. Recent efforts of bipartite\nranking are focused on optimizing ranking accuracy at the top of the ranked\nlist. Most existing approaches are either to optimize task specific metrics or\nto extend the ranking loss by emphasizing more on the error associated with the\ntop ranked instances, leading to a high computational cost that is super-linear\nin the number of training instances. We propose a highly efficient approach,\ntitled TopPush, for optimizing accuracy at the top that has computational\ncomplexity linear in the number of training instances. We present a novel\nanalysis that bounds the generalization error for the top ranked instances for\nthe proposed approach. Empirical study shows that the proposed approach is\nhighly competitive to the state-of-the-art approaches and is 10-100 times\nfaster.\n", "versions": [{"version": "v1", "created": "Mon, 6 Oct 2014 17:10:23 GMT"}], "update_date": "2020-07-07", "authors_parsed": [["Li", "Nan", ""], ["Jin", "Rong", ""], ["Zhou", "Zhi-Hua", ""]]}, {"id": "1410.2085", "submitter": "Ashish Chandra", "authors": "Ashish Chandra, Mohammad Suaib, and Dr. Rizwan Beg", "title": "Low cost page quality factors to detect web spam", "comments": null, "journal-ref": "Informatics Engineering, an International Journal (IEIJ) ,Vol.2,\n  No.3, September 2014", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web spam is a big challenge for quality of search engine results. It is very\nimportant for search engines to detect web spam accurately. In this paper we\npresent 32 low cost quality factors to classify spam and ham pages on real time\nbasis. These features can be divided in to three categories: (i) URL features,\n(ii) Content features, and (iii) Link features. We developed a classifier using\nResilient Back-propagation learning algorithm of neural network and obtained\ngood accuracy. This classifier can be applied to search engine results on real\ntime because calculation of these features require very little CPU resources.\n", "versions": [{"version": "v1", "created": "Wed, 8 Oct 2014 12:46:34 GMT"}], "update_date": "2014-10-09", "authors_parsed": [["Chandra", "Ashish", ""], ["Suaib", "Mohammad", ""], ["Beg", "Dr. Rizwan", ""]]}, {"id": "1410.2265", "submitter": "Chetan  Kaushik", "authors": "Chetan Kaushik, Atul Mishra", "title": "A Scalable, Lexicon Based Technique for Sentiment Analysis", "comments": "9 pages 1 figure 2 tables", "journal-ref": "International Journal in Foundations of Computer Science &\n  Technology (IJFCST), Vol.4, No.5, September 2014", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid increase in the volume of sentiment rich social media on the web has\nresulted in an increased interest among researchers regarding Sentimental\nAnalysis and opinion mining. However, with so much social media available on\nthe web, sentiment analysis is now considered as a big data task. Hence the\nconventional sentiment analysis approaches fails to efficiently handle the vast\namount of sentiment data available now a days. The main focus of the research\nwas to find such a technique that can efficiently perform sentiment analysis on\nbig data sets. A technique that can categorize the text as positive, negative\nand neutral in a fast and accurate manner. In the research, sentiment analysis\nwas performed on a large data set of tweets using Hadoop and the performance of\nthe technique was measured in form of speed and accuracy. The experimental\nresults shows that the technique exhibits very good efficiency in handling big\nsentiment data sets.\n", "versions": [{"version": "v1", "created": "Wed, 8 Oct 2014 20:29:39 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Kaushik", "Chetan", ""], ["Mishra", "Atul", ""]]}, {"id": "1410.2324", "submitter": "Xiaofeng Zhong", "authors": "Jian Sun, Xiaofeng Zhong, Xuan Zhou, Xiaolong Fu", "title": "Recommendation Scheme Based on Converging Properties for Contents\n  Broadcasting", "comments": "6 pages. This work is present at 2015 International Workshop on\n  Networking Issues in Multimedia Entertainment (NIME'15)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Popular videos are often clicked by a mount of users in a short period. With\ncontent recommendation, the popular contents could be broadcast to the\npotential users in wireless network, to save huge transmitting resource. In\nthis paper, the contents propagation model is analyzed due to users' historical\nbehavior, location, and the converging properties in wireless data\ntransmission, with the users' communication log in the Chinese commercial\ncellular network. And a recommendation scheme is proposed to achieve high\nenergy efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 9 Oct 2014 00:53:11 GMT"}], "update_date": "2014-10-10", "authors_parsed": [["Sun", "Jian", ""], ["Zhong", "Xiaofeng", ""], ["Zhou", "Xuan", ""], ["Fu", "Xiaolong", ""]]}, {"id": "1410.2634", "submitter": "David Lillis", "authors": "David Lillis, Fergus Toolan, Rem W. Collier and John Dunnion", "title": "Extending Probabilistic Data Fusion Using Sliding Windows", "comments": null, "journal-ref": "Advances in Information Retrieval. Proceedings of the 30th\n  European Conference on Information Retrieval Research (ECIR 2008), volume\n  4956 of Lecture Notes in Computer Science, pages 358--369, Berlin, 2008.\n  Springer Berlin Heidelberg", "doi": "10.1007/978-3-540-78646-7_33", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent developments in the field of data fusion have seen a focus on\ntechniques that use training queries to estimate the probability that various\ndocuments are relevant to a given query and use that information to assign\nscores to those documents on which they are subsequently ranked. This paper\nintroduces SlideFuse, which builds on these techniques, introducing a sliding\nwindow in order to compensate for situations where little relevance information\nis available to aid in the estimation of probabilities.\n  SlideFuse is shown to perform favourably in comparison with CombMNZ, ProbFuse\nand SegFuse. CombMNZ is the standard baseline technique against which data\nfusion algorithms are compared whereas ProbFuse and SegFuse represent the\nstate-of-the-art for probabilistic data fusion methods.\n", "versions": [{"version": "v1", "created": "Thu, 9 Oct 2014 21:28:40 GMT"}], "update_date": "2014-10-13", "authors_parsed": [["Lillis", "David", ""], ["Toolan", "Fergus", ""], ["Collier", "Rem W.", ""], ["Dunnion", "John", ""]]}, {"id": "1410.3120", "submitter": "Alexander Gasnikov", "authors": "Alexander Gasnikov, Denis Dmitriev", "title": "Efficient randomized algorithms for PageRank problem", "comments": "31 pages, in Russian", "journal-ref": "Comp. Math. and Math. Phys. 2015. V. 55. no. 3. P.355-371", "doi": null, "report-no": null, "categories": "math.OC cs.IR cs.NA cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper we compare well known numerical methods of finding PageRank\nvector. We propose Markov Chain Monte Carlo method and obtain a new estimation\nfor this method. We also propose a new method for PageRank problem based on the\nreduction of this problem to the matrix game. We solve this (sparse) matrix\ngame with randomized mirror descent. It should be mentioned that we used\nnon-standard randomization (in KL-projection) goes back to\nGrigoriadis-Khachiayn (1995).\n", "versions": [{"version": "v1", "created": "Sun, 12 Oct 2014 17:19:31 GMT"}, {"version": "v2", "created": "Wed, 26 Nov 2014 13:23:57 GMT"}, {"version": "v3", "created": "Thu, 27 Nov 2014 13:09:38 GMT"}, {"version": "v4", "created": "Mon, 8 Dec 2014 22:00:41 GMT"}, {"version": "v5", "created": "Fri, 9 Jan 2015 17:13:45 GMT"}, {"version": "v6", "created": "Fri, 20 Feb 2015 21:17:55 GMT"}, {"version": "v7", "created": "Tue, 2 Jun 2015 20:51:49 GMT"}, {"version": "v8", "created": "Thu, 12 May 2016 16:03:29 GMT"}, {"version": "v9", "created": "Thu, 26 May 2016 07:19:26 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Gasnikov", "Alexander", ""], ["Dmitriev", "Denis", ""]]}, {"id": "1410.3462", "submitter": "Xirong Li", "authors": "Xirong Li", "title": "Tag Relevance Fusion for Social Image Retrieval", "comments": null, "journal-ref": null, "doi": "10.1007/s00530-014-0430-9", "report-no": null, "categories": "cs.IR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the subjective nature of social tagging, measuring the relevance of\nsocial tags with respect to the visual content is crucial for retrieving the\nincreasing amounts of social-networked images. Witnessing the limit of a single\nmeasurement of tag relevance, we introduce in this paper tag relevance fusion\nas an extension to methods for tag relevance estimation. We present a\nsystematic study, covering tag relevance fusion in early and late stages, and\nin supervised and unsupervised settings. Experiments on a large present-day\nbenchmark set show that tag relevance fusion leads to better image retrieval.\nMoreover, unsupervised tag relevance fusion is found to be practically as\neffective as supervised tag relevance fusion, but without the need of any\ntraining efforts. This finding suggests the potential of tag relevance fusion\nfor real-world deployment.\n", "versions": [{"version": "v1", "created": "Mon, 13 Oct 2014 13:27:55 GMT"}], "update_date": "2014-10-15", "authors_parsed": [["Li", "Xirong", ""]]}, {"id": "1410.3726", "submitter": "Chee Seng Chan", "authors": "Chern Hong Lim, Anhar Risnumawan and Chee Seng Chan", "title": "Scene Image is Non-Mutually Exclusive - A Fuzzy Qualitative Scene\n  Understanding", "comments": "Accepted in IEEE Transactions on Fuzzy Systems", "journal-ref": "IEEE Transactions on Fuzzy Systems, vol. 22(6), pp. 1541 - 1556,\n  2014", "doi": "10.1109/TFUZZ.2014.2298233", "report-no": null, "categories": "cs.CV cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ambiguity or uncertainty is a pervasive element of many real world decision\nmaking processes. Variation in decisions is a norm in this situation when the\nsame problem is posed to different subjects. Psychological and metaphysical\nresearch had proven that decision making by human is subjective. It is\ninfluenced by many factors such as experience, age, background, etc. Scene\nunderstanding is one of the computer vision problems that fall into this\ncategory. Conventional methods relax this problem by assuming scene images are\nmutually exclusive; and therefore, focus on developing different approaches to\nperform the binary classification tasks. In this paper, we show that scene\nimages are non-mutually exclusive, and propose the Fuzzy Qualitative Rank\nClassifier (FQRC) to tackle the aforementioned problems. The proposed FQRC\nprovides a ranking interpretation instead of binary decision. Evaluations in\nterm of qualitative and quantitative using large numbers and challenging public\nscene datasets have shown the effectiveness of our proposed method in modeling\nthe non-mutually exclusive scene images.\n", "versions": [{"version": "v1", "created": "Tue, 14 Oct 2014 15:19:43 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Lim", "Chern Hong", ""], ["Risnumawan", "Anhar", ""], ["Chan", "Chee Seng", ""]]}, {"id": "1410.3915", "submitter": "Neil Shah", "authors": "Neil Shah, Alex Beutel, Brian Gallagher, Christos Faloutsos", "title": "Spotting Suspicious Link Behavior with fBox: An Adversarial Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we detect suspicious users in large online networks? Online\npopularity of a user or product (via follows, page-likes, etc.) can be\nmonetized on the premise of higher ad click-through rates or increased sales.\nWeb services and social networks which incentivize popularity thus suffer from\na major problem of fake connections from link fraudsters looking to make a\nquick buck. Typical methods of catching this suspicious behavior use spectral\ntechniques to spot large groups of often blatantly fraudulent (but sometimes\nhonest) users. However, small-scale, stealthy attacks may go unnoticed due to\nthe nature of low-rank eigenanalysis used in practice.\n  In this work, we take an adversarial approach to find and prove claims about\nthe weaknesses of modern, state-of-the-art spectral methods and propose fBox,\nan algorithm designed to catch small-scale, stealth attacks that slip below the\nradar. Our algorithm has the following desirable properties: (a) it has\ntheoretical underpinnings, (b) it is shown to be highly effective on real data\nand (c) it is scalable (linear on the input size). We evaluate fBox on a large,\npublic 41.7 million node, 1.5 billion edge who-follows-whom social graph from\nTwitter in 2010 and with high precision identify many suspicious accounts which\nhave persisted without suspension even to this day.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 03:10:26 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Shah", "Neil", ""], ["Beutel", "Alex", ""], ["Gallagher", "Brian", ""], ["Faloutsos", "Christos", ""]]}, {"id": "1410.4500", "submitter": "Jimmy Lin", "authors": "Jimmy Lin", "title": "On the Feasibility and Implications of Self-Contained Search Engines in\n  the Browser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  JavaScript engines inside modern browsers are capable of running\nsophisticated multi-player games, rendering impressive 3D scenes, and\nsupporting complex, interactive visualizations. Can this processing power be\nharnessed for information retrieval? This paper explores the feasibility of\nbuilding a JavaScript search engine that runs completely self-contained on the\nclient side within the browser---this includes building the inverted index,\ngathering terms statistics for scoring, and performing query evaluation. The\ndesign takes advantage of the IndexDB API, which is implemented by the LevelDB\nkey-value store inside Google's Chrome browser. Experiments show that although\nthe performance of the JavaScript prototype falls far short of the open-source\nLucene search engine, it is sufficiently responsive for interactive\napplications. This feasibility demonstration opens the door to interesting\napplications in offline and private search across multiple platforms as well as\nhybrid split-execution architectures whereby clients and servers\ncollaboratively perform query evaluation. One possible future scenario is the\nrise of an online search marketplace in which commercial search engine\ncompanies and individual users participate as rational economic actors,\nbalancing privacy, resource usage, latency, and other factors based on\ncustomizable utility profiles.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2014 17:17:51 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Lin", "Jimmy", ""]]}, {"id": "1410.4616", "submitter": "Derek Doran", "authors": "Derek Doran and Swapna Gokhale and Aldo Dagnino", "title": "Accurate Local Estimation of Geo-Coordinates for Social Media Posts", "comments": "In Proceedings of the 26th International Conference on Software\n  Engineering and Knowledge Engineering, pp. 642 - 647, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Associating geo-coordinates with the content of social media posts can\nenhance many existing applications and services and enable a host of new ones.\nUnfortunately, a majority of social media posts are not tagged with\ngeo-coordinates. Even when location data is available, it may be inaccurate,\nvery broad or sometimes fictitious. Contemporary location estimation approaches\nbased on analyzing the content of these posts can identify only broad areas\nsuch as a city, which limits their usefulness. To address these shortcomings,\nthis paper proposes a methodology to narrowly estimate the geo-coordinates of\nsocial media posts with high accuracy. The methodology relies solely on the\ncontent of these posts and prior knowledge of the wide geographical region from\nwhere the posts originate. An ensemble of language models, which are smoothed\nover non-overlapping sub-regions of a wider region, lie at the heart of the\nmethodology. Experimental evaluation using a corpus of over half a million\ntweets from New York City shows that the approach, on an average, estimates\nlocations of tweets to within just 2.15km of their actual positions.\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2014 01:54:04 GMT"}], "update_date": "2014-10-20", "authors_parsed": [["Doran", "Derek", ""], ["Gokhale", "Swapna", ""], ["Dagnino", "Aldo", ""]]}, {"id": "1410.5072", "submitter": "Georgios Pitsilis", "authors": "Georgios Pitsilis and Wei Wang", "title": "Harnessing the power of Social Bookmarking for improving tag-based\n  Recommendations", "comments": "28 pages, 10 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social bookmarking and tagging has emerged a new era in user collaboration.\nCollaborative Tagging allows users to annotate content of their liking, which\nvia the appropriate algorithms can render useful for the provision of product\nrecommendations. It is the case today for tag-based algorithms to work\ncomplementary to rating-based recommendation mechanisms to predict the user\nliking to various products. In this paper we propose an alternative algorithm\nfor computing personalized recommendations of products, that uses exclusively\nthe tags provided by the users. Our approach is based on the idea of using the\nsemantic similarity of the user-provided tags for clustering them into groups\nof similar meaning. Afterwards, some measurable characteristics of users'\nAnnotation Competency are combined with other metrics, such as user similarity,\nfor computing predictions. The evaluation on data used from a real-world\ncollaborative tagging system, citeUlike, confirmed that our approach\noutperforms the baseline Vector Space model, as well as other state of the art\nalgorithms, predicting the user liking more accurately.\n", "versions": [{"version": "v1", "created": "Sun, 19 Oct 2014 13:33:29 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Pitsilis", "Georgios", ""], ["Wang", "Wei", ""]]}, {"id": "1410.5152", "submitter": "Shanghua Teng", "authors": "Christian Borgs and Jennifer Chayes and Adrian Marple and Shang-Hua\n  Teng", "title": "Fixed-Points of Social Choice: An Axiomatic Approach to Network\n  Communities", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CC cs.DS cs.GT cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first social choice theory approach to the question of what\nconstitutes a community in a social network. Inspired by the classic\npreferences models in social choice theory, we start from an abstract social\nnetwork framework, called preference networks; these consist of a finite set of\nmembers where each member has a total-ranking preference of all members in the\nset.\n  Within this framework, we develop two complementary approaches to\naxiomatically study the formation and structures of communities. (1) We apply\nsocial choice theory and define communities indirectly by postulating that they\nare fixed points of a preference aggregation function obeying certain desirable\naxioms. (2) We directly postulate desirable axioms for communities without\nreference to preference aggregation, leading to eight natural community axioms.\n  These approaches allow us to formulate and analyze community rules. We prove\na taxonomy theorem that provides a structural characterization of the family of\ncommunity rules that satisfies all eight axioms. The structure is actually\nquite beautiful: these community rules form a bounded lattice under the natural\nintersection and union operations. Our structural theorem is complemented with\na complexity result: while identifying a community by the most selective rule\nof the lattice is in P, deciding if a subset is a community by the most\ncomprehensive rule of the lattice is coNP-complete. Our studies also shed light\non the limitations of defining community rules solely based on preference\naggregation: any aggregation function satisfying Arrow's IIA axiom, or based on\ncommonly used aggregation schemes like the Borda count or generalizations\nthereof, lead to communities which violate at least one of our community\naxioms. Finally, we give a polynomial-time rule consistent with seven axioms\nand weakly satisfying the eighth axiom.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 04:37:23 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Borgs", "Christian", ""], ["Chayes", "Jennifer", ""], ["Marple", "Adrian", ""], ["Teng", "Shang-Hua", ""]]}, {"id": "1410.5209", "submitter": "Kijung Shin", "authors": "Kijung Shin, U. Kang", "title": "Distributed Methods for High-dimensional and Large-scale Tensor\n  Factorization", "comments": null, "journal-ref": "Data Mining (ICDM), 2014 IEEE International Conference on, pp.\n  989-994. IEEE, 2014", "doi": "10.1109/ICDM.2014.78", "report-no": null, "categories": "cs.NA cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a high-dimensional large-scale tensor, how can we decompose it into\nlatent factors? Can we process it on commodity computers with limited memory?\nThese questions are closely related to recommender systems, which have modeled\nrating data not as a matrix but as a tensor to utilize contextual information\nsuch as time and location. This increase in the dimension requires tensor\nfactorization methods scalable with both the dimension and size of a tensor. In\nthis paper, we propose two distributed tensor factorization methods, SALS and\nCDTF. Both methods are scalable with all aspects of data, and they show an\ninteresting trade-off between convergence speed and memory requirements. SALS\nupdates a subset of the columns of a factor matrix at a time, and CDTF, a\nspecial case of SALS, updates one column at a time. In our experiments, only\nour methods factorize a 5-dimensional tensor with 1 billion observable entries,\n10M mode length, and 1K rank, while all other state-of-the-art methods fail.\nMoreover, our methods require several orders of magnitude less memory than our\ncompetitors. We implement our methods on MapReduce with two widely-applicable\noptimization techniques: local disk caching and greedy row assignment. They\nspeed up our methods up to 98.2X and also the competitors up to 5.9X.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 09:49:46 GMT"}, {"version": "v2", "created": "Thu, 19 Feb 2015 09:52:23 GMT"}, {"version": "v3", "created": "Sat, 11 Jul 2015 07:28:07 GMT"}], "update_date": "2015-07-14", "authors_parsed": [["Shin", "Kijung", ""], ["Kang", "U.", ""]]}, {"id": "1410.5410", "submitter": "Ping Li", "authors": "Anshumali Shrivastava and Ping Li", "title": "Improved Asymmetric Locality Sensitive Hashing (ALSH) for Maximum Inner\n  Product Search (MIPS)", "comments": "arXiv admin note: text overlap with arXiv:1405.5869", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently it was shown that the problem of Maximum Inner Product Search (MIPS)\nis efficient and it admits provably sub-linear hashing algorithms. Asymmetric\ntransformations before hashing were the key in solving MIPS which was otherwise\nhard. In the prior work, the authors use asymmetric transformations which\nconvert the problem of approximate MIPS into the problem of approximate near\nneighbor search which can be efficiently solved using hashing. In this work, we\nprovide a different transformation which converts the problem of approximate\nMIPS into the problem of approximate cosine similarity search which can be\nefficiently solved using signed random projections. Theoretical analysis show\nthat the new scheme is significantly better than the original scheme for MIPS.\nExperimental evaluations strongly support the theoretical findings.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 19:54:58 GMT"}, {"version": "v2", "created": "Thu, 13 Nov 2014 20:48:36 GMT"}], "update_date": "2014-11-14", "authors_parsed": [["Shrivastava", "Anshumali", ""], ["Li", "Ping", ""]]}, {"id": "1410.5518", "submitter": "Behnam Neyshabur", "authors": "Behnam Neyshabur, Nathan Srebro", "title": "On Symmetric and Asymmetric LSHs for Inner Product Search", "comments": "11 pages, 3 figures, In Proceedings of The 32nd International\n  Conference on Machine Learning (ICML)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DS cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of designing locality sensitive hashes (LSH) for\ninner product similarity, and of the power of asymmetric hashes in this\ncontext. Shrivastava and Li argue that there is no symmetric LSH for the\nproblem and propose an asymmetric LSH based on different mappings for query and\ndatabase points. However, we show there does exist a simple symmetric LSH that\nenjoys stronger guarantees and better empirical performance than the asymmetric\nLSH they suggest. We also show a variant of the settings where asymmetry is\nin-fact needed, but there a different asymmetric LSH is required.\n", "versions": [{"version": "v1", "created": "Tue, 21 Oct 2014 02:00:34 GMT"}, {"version": "v2", "created": "Fri, 24 Oct 2014 21:31:06 GMT"}, {"version": "v3", "created": "Mon, 8 Jun 2015 19:30:35 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Neyshabur", "Behnam", ""], ["Srebro", "Nathan", ""]]}, {"id": "1410.5777", "submitter": "Leon Abdillah", "authors": "Ahmad Josi and Leon Andretti Abdillah and Suryayusra", "title": "Penerapan teknik web scraping pada mesin pencari artikel ilmiah", "comments": "6 pages, Jurnal Sistem Informasi (SISFO), vol. 5, 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search engines are a combination of hardware and computer software supplied\nby a particular company through the website which has been determined. Search\nengines collect information from the web through bots or web crawlers that\ncrawls the web periodically. The process of retrieval of information from\nexisting websites is called \"web scraping.\" Web scraping is a technique of\nextracting information from websites. Web scraping is closely related to Web\nindexing, as for how to develop a web scraping technique that is by first\nstudying the program makers HTML document from the website will be taken to the\ninformation in the HTML tag flanking the aim is for information collected after\nthe program makers learn navigation techniques on the website information will\nbe taken to a web application mimicked the scraping that we will create. It\nshould also be noted that the implementation of this writing only scraping\ninvolves a free search engine such as: portal garuda, Indonesian scientific\njournal databases (ISJD), google scholar.\n", "versions": [{"version": "v1", "created": "Sat, 18 Oct 2014 11:20:07 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Josi", "Ahmad", ""], ["Abdillah", "Leon Andretti", ""], ["Suryayusra", "", ""]]}, {"id": "1410.5815", "submitter": "Santosh Majhi", "authors": "Santosh Kumar Majhi and Padmalochan Bera", "title": "OHMF: A Query Based Optimal Healthcare Medication Framework", "comments": null, "journal-ref": "International Journal of Information Processing, 8(3), 1-12, 2014\n  ISSN : 0973-8215", "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today cloud computing infrastructure is largely being deployed in healthcare\nto access various healthcare services easily over the Internet on an as needed\nbasis. The main advantage of healthcare cloud is that it can be used as a tool\nfor patients, medical professionals and insurance providers, to query and\ncoordinate among medical departments, organizations and other healthcare\nrelated hubs. Although healthcare cloud services can enable better medication\nprocess with high responsiveness, but the privacy and other requirements of the\npatients need to be ensured in the process. Patients medical data may be\nrequired by the medical professionals, hospitals, diagnostic centers for\nanalysis and diagnosis. However, data privacy and service quality cannot be\ncompromised. In other words, there may exist various service providers\ncorresponding to a specific healthcare service. The main challenge is to find\nthe appropriate providers that comply best with patients requirement. In this\npaper, we propose a query based optimal medication framework to support the\npatients healthcare service accessibility comprehensively with considerable\nresponse time. The framework accepts related healthcare queries in natural\nlanguage through a comprehensive user-interface and then processes the input\nquery through a first order logic based evaluation engine and finds all\npossible services satisfying the requirements. First order logic is used for\nmodeling of user requirements and queries. The query evaluation engine is built\nusing zChaff, a Boolean logic satisfiability solver. The efficacy and usability\nof the framework is evaluated with initial case studies on synthetic and real\nlife healthcare cloud.\n", "versions": [{"version": "v1", "created": "Tue, 21 Oct 2014 18:18:11 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Majhi", "Santosh Kumar", ""], ["Bera", "Padmalochan", ""]]}, {"id": "1410.6466", "submitter": "Dehua Cheng", "authors": "Dehua Cheng, Xinran He, Yan Liu", "title": "Model Selection for Topic Models via Spectral Decomposition", "comments": "accepted in AISTATS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models have achieved significant successes in analyzing large-scale\ntext corpus. In practical applications, we are always confronted with the\nchallenge of model selection, i.e., how to appropriately set the number of\ntopics. Following recent advances in topic model inference via tensor\ndecomposition, we make a first attempt to provide theoretical analysis on model\nselection in latent Dirichlet allocation. Under mild conditions, we derive the\nupper bound and lower bound on the number of topics given a text collection of\nfinite size. Experimental results demonstrate that our bounds are accurate and\ntight. Furthermore, using Gaussian mixture model as an example, we show that\nour methodology can be easily generalized to model selection analysis for other\nlatent models.\n", "versions": [{"version": "v1", "created": "Thu, 23 Oct 2014 19:38:44 GMT"}, {"version": "v2", "created": "Tue, 17 Feb 2015 01:39:14 GMT"}], "update_date": "2015-02-18", "authors_parsed": [["Cheng", "Dehua", ""], ["He", "Xinran", ""], ["Liu", "Yan", ""]]}, {"id": "1410.6744", "submitter": "Kristina Lerman", "authors": "Tad Hogg and Kristina Lerman", "title": "Disentangling the Effects of Social Signals", "comments": "to appear in Human Computation Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.CY cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Peer recommendation is a crowdsourcing task that leverages the opinions of\nmany to identify interesting content online, such as news, images, or videos.\nPeer recommendation applications often use social signals, e.g., the number of\nprior recommendations, to guide people to the more interesting content. How\npeople react to social signals, in combination with content quality and its\npresentation order, determines the outcomes of peer recommendation, i.e., item\npopularity. Using Amazon Mechanical Turk, we experimentally measure the effects\nof social signals in peer recommendation. Specifically, after controlling for\nvariation due to item content and its position, we find that social signals\naffect item popularity about half as much as position and content do. These\neffects are somewhat correlated, so social signals exacerbate the \"rich get\nricher\" phenomenon, which results in a wider variance of popularity. Further,\nsocial signals change individual preferences, creating a \"herding\" effect that\nbiases people's judgments about the content. Despite this, we find that social\nsignals improve the efficiency of peer recommendation by reducing the effort\ndevoted to evaluating content while maintaining recommendation quality.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 17:16:07 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2016 17:32:01 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Hogg", "Tad", ""], ["Lerman", "Kristina", ""]]}, {"id": "1410.6751", "submitter": "Christoph Riedl", "authors": "Christoph Riedl, Richard Zanibbi, Marti A. Hearst, Siyu Zhu, Michael\n  Menietti, Jason Crusan, Ivan Metelsky, Karim R. Lakhani", "title": "Detecting Figures and Part Labels in Patents: Competition-Based\n  Development of Image Processing Algorithms", "comments": null, "journal-ref": null, "doi": "10.1007/s10032-016-0260-8", "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report the findings of a month-long online competition in which\nparticipants developed algorithms for augmenting the digital version of patent\ndocuments published by the United States Patent and Trademark Office (USPTO).\nThe goal was to detect figures and part labels in U.S. patent drawing pages.\nThe challenge drew 232 teams of two, of which 70 teams (30%) submitted\nsolutions. Collectively, teams submitted 1,797 solutions that were compiled on\nthe competition servers. Participants reported spending an average of 63 hours\ndeveloping their solutions, resulting in a total of 5,591 hours of development\ntime. A manually labeled dataset of 306 patents was used for training, online\nsystem tests, and evaluation. The design and performance of the top-5 systems\nare presented, along with a system developed after the competition which\nillustrates that winning teams produced near state-of-the-art results under\nstrict time and computation constraints. For the 1st place system, the harmonic\nmean of recall and precision (f-measure) was 88.57% for figure region\ndetection, 78.81% for figure regions with correctly recognized figure titles,\nand 70.98% for part label detection and character recognition. Data and\nsoftware from the competition are available through the online UCI Machine\nLearning repository to inspire follow-on work by the image processing\ncommunity.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 17:45:36 GMT"}, {"version": "v2", "created": "Mon, 27 Oct 2014 10:54:17 GMT"}, {"version": "v3", "created": "Tue, 11 Nov 2014 14:33:11 GMT"}], "update_date": "2016-03-11", "authors_parsed": [["Riedl", "Christoph", ""], ["Zanibbi", "Richard", ""], ["Hearst", "Marti A.", ""], ["Zhu", "Siyu", ""], ["Menietti", "Michael", ""], ["Crusan", "Jason", ""], ["Metelsky", "Ivan", ""], ["Lakhani", "Karim R.", ""]]}, {"id": "1410.7654", "submitter": "Raviraja  Holla M", "authors": "Suma D., U. Dinesh Acharya, Geetha M. and Raviraja Holla M", "title": "XML Information Retrieval:An overview", "comments": "7 pages, 0 figures", "journal-ref": "International Global Journal For Engineering Research, Volume 10\n  Issue 1, 2014 pg. 26-32", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locating and distilling the valuable relevant information continued to be the\nmajor challenges of Information Retrieval (IR) Systems owing to the explosive\ngrowth of online web information. These challenges can be considered the XML\nInformation Retrieval challenges as XML has become a de facto standard over the\nWeb. The research on XML IR starts with the classical IR strategies customized\nto XML IR. Later novel IR strategies specific to XML IR are evolved. Meanwhile\nliteratures reveal development of the rapid and intelligent IR systems. Despite\ntheir success in their specified constrained domains, they have additional\nlimitations in the complex information space. The effectiveness of IR systems\nis thus unsolved in satisfying the most. This article attemptsan overview of\nearlier efforts and the gaps in XML IR.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 06:39:32 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["D.", "Suma", ""], ["Acharya", "U. Dinesh", ""], ["M.", "Geetha", ""], ["M", "Raviraja Holla", ""]]}, {"id": "1410.7852", "submitter": "Xiaoting Zhao", "authors": "Xiaoting Zhao, Peter I. Frazier", "title": "A Markov Decision Process Analysis of the Cold Start Problem in Bayesian\n  Information Filtering", "comments": "12 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the information filtering problem, in which we face a stream of\nitems, and must decide which ones to forward to a user to maximize the number\nof relevant items shown, minus a penalty for each irrelevant item shown.\nForwarding decisions are made separately in a personalized way for each user.\nWe focus on the cold-start setting for this problem, in which we have limited\nhistorical data on the user's preferences, and must rely on feedback from\nforwarded articles to learn which the fraction of items relevant to the user in\neach of several item categories. Performing well in this setting requires\ntrading exploration vs. exploitation, forwarding items that are likely to be\nirrelevant, to allow learning that will improve later performance. In a\nBayesian setting, and using Markov decision processes, we show how the\nBayes-optimal forwarding algorithm can be computed efficiently when the user\nwill examine each forwarded article, and how an upper bound on the\nBayes-optimal procedure and a heuristic index policy can be obtained for the\nsetting when the user will examine only a limited number of forwarded items. We\npresent results from simulation experiments using parameters estimated using\nhistorical data from arXiv.org.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 01:15:20 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Zhao", "Xiaoting", ""], ["Frazier", "Peter I.", ""]]}, {"id": "1410.8034", "submitter": "Xudong Liu", "authors": "Xudong Liu, Bin Zhang, Ting Zhang and Chang Liu", "title": "Latent Feature Based FM Model For Rating Prediction", "comments": "4 pages, 3 figures, Large Scale Recommender Systems:workshop of\n  Recsys 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rating Prediction is a basic problem in Recommender System, and one of the\nmost widely used method is Factorization Machines(FM). However, traditional\nmatrix factorization methods fail to utilize the benefit of implicit feedback,\nwhich has been proved to be important in Rating Prediction problem. In this\nwork, we consider a specific situation, movie rating prediction, where we\nassume that watching history has a big influence on his/her rating behavior on\nan item. We introduce two models, Latent Dirichlet Allocation(LDA) and\nword2vec, both of which perform state-of-the-art results in training latent\nfeatures. Based on that, we propose two feature based models. One is the\nTopic-based FM Model which provides the implicit feedback to the matrix\nfactorization. The other is the Vector-based FM Model which expresses the order\ninfo of watching history. Empirical results on three datasets demonstrate that\nour method performs better than the baseline model and confirm that\nVector-based FM Model usually works better as it contains the order info.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 15:51:54 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Liu", "Xudong", ""], ["Zhang", "Bin", ""], ["Zhang", "Ting", ""], ["Liu", "Chang", ""]]}, {"id": "1410.8068", "submitter": "Shanu Sushmita", "authors": "Shanu Sushmita and Si-Chi Chin", "title": "Health Information Search Behavior on the Web: A Pilot Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searching health information on web has become an integral part of today's\nworld, and many people turn to the Web for healthcare information and\nhealthcare assessment. Our pilot study investigates users' preferences for the\ntype of search results (image, news, video, etc.), and investigates users'\nability to accurately interpret online health information for the purpose of\nself diagnosis. The preliminary results reveal that blog and news articles are\nmost sought by users when searching online information and there exist\nchallenges in the use of online health information for self-diagnosis.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 23:38:59 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Sushmita", "Shanu", ""], ["Chin", "Si-Chi", ""]]}]