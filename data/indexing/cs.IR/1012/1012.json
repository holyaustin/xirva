[{"id": "1012.0142", "submitter": "Haroldo Ribeiro", "authors": "R.S. Mendes, H.V. Ribeiro, F.C.M. Freire, A.A. Tateishi, E.K. Lenzi", "title": "Universal patterns in sound amplitudes of songs and music genres", "comments": "Accepted for publication as a Brief Report in Physical Review E", "journal-ref": "Phys. Rev. E 83, 017101 (2011)", "doi": "10.1103/PhysRevE.83.017101", "report-no": null, "categories": "physics.data-an cs.IR cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report a statistical analysis over more than eight thousand songs.\nSpecifically, we investigate the probability distribution of the normalized\nsound amplitudes. Our findings seems to suggest a universal form of\ndistribution which presents a good agreement with a one-parameter stretched\nGaussian. We also argue that this parameter can give information on music\ncomplexity, and consequently it goes towards classifying songs as well as music\ngenres. Additionally, we present statistical evidences that correlation aspects\nof the songs are directly related with the non-Gaussian nature of their sound\namplitude distributions.\n", "versions": [{"version": "v1", "created": "Wed, 1 Dec 2010 10:07:42 GMT"}], "update_date": "2011-01-18", "authors_parsed": [["Mendes", "R. S.", ""], ["Ribeiro", "H. V.", ""], ["Freire", "F. C. M.", ""], ["Tateishi", "A. A.", ""], ["Lenzi", "E. K.", ""]]}, {"id": "1012.0841", "submitter": "Pekka Malo", "authors": "Pekka Malo and Pyry Siitari and Ankur Sinha", "title": "Automated Query Learning with Wikipedia and Genetic Programming", "comments": "44 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing information retrieval systems are based on bag of words\nmodel and are not equipped with common world knowledge. Work has been done\ntowards improving the efficiency of such systems by using intelligent\nalgorithms to generate search queries, however, not much research has been done\nin the direction of incorporating human-and-society level knowledge in the\nqueries. This paper is one of the first attempts where such information is\nincorporated into the search queries using Wikipedia semantics. The paper\npresents an essential shift from conventional token based queries to concept\nbased queries, leading to an enhanced efficiency of information retrieval\nsystems. To efficiently handle the automated query learning problem, we propose\nWikipedia-based Evolutionary Semantics (Wiki-ES) framework where concept based\nqueries are learnt using a co-evolving evolutionary procedure. Learning concept\nbased queries using an intelligent evolutionary procedure yields significant\nimprovement in performance which is shown through an extensive study using\nReuters newswire documents. Comparison of the proposed framework is performed\nwith other information retrieval systems. Concept based approach has also been\nimplemented on other information retrieval systems to justify the effectiveness\nof a transition from token based queries to concept based queries.\n", "versions": [{"version": "v1", "created": "Fri, 3 Dec 2010 20:53:36 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Malo", "Pekka", ""], ["Siitari", "Pyry", ""], ["Sinha", "Ankur", ""]]}, {"id": "1012.0854", "submitter": "Pekka Malo", "authors": "Pekka Malo and Pyry Siitari and Oskar Ahlgren and Jyrki Wallenius and\n  Pekka Korhonen", "title": "Semantic Content Filtering with Wikipedia and Ontologies", "comments": "9 pages, Third International Workshop on Semantic Aspects in Data\n  Mining (SADM'10) in conjunction with the 2010 IEEE International Conference\n  on Data Mining", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of domain knowledge is generally found to improve query efficiency in\ncontent filtering applications. In particular, tangible benefits have been\nachieved when using knowledge-based approaches within more specialized fields,\nsuch as medical free texts or legal documents. However, the problem is that\nsources of domain knowledge are time-consuming to build and equally costly to\nmaintain. As a potential remedy, recent studies on Wikipedia suggest that this\nlarge body of socially constructed knowledge can be effectively harnessed to\nprovide not only facts but also accurate information about semantic\nconcept-similarities. This paper describes a framework for document filtering,\nwhere Wikipedia's concept-relatedness information is combined with a domain\nontology to produce semantic content classifiers. The approach is evaluated\nusing Reuters RCV1 corpus and TREC-11 filtering task definitions. In a\ncomparative study, the approach shows robust performance and appears to\noutperform content classifiers based on Support Vector Machines (SVM) and C4.5\nalgorithm.\n", "versions": [{"version": "v1", "created": "Fri, 3 Dec 2010 21:23:21 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Malo", "Pekka", ""], ["Siitari", "Pyry", ""], ["Ahlgren", "Oskar", ""], ["Wallenius", "Jyrki", ""], ["Korhonen", "Pekka", ""]]}, {"id": "1012.1609", "submitter": "Adrian Paschke", "authors": "R. Berlanga, E. Jimenez-Ruiz, V. Nebot", "title": "Building conceptual spaces for exploring and linking biomedical\n  resources", "comments": "in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott\n  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on\n  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,\n  December 8-10, 2010", "journal-ref": null, "doi": null, "report-no": "SWAT4LS 2010", "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The establishment of links between data (e.g., patient records) and Web\nresources (e.g., literature) and the proper visualization of such discovered\nknowledge is still a challenge in most Life Science domains (e.g.,\nbiomedicine). In this paper we present our contribution to the community in the\nform of an infrastructure to annotate information resources, to discover\nrelationships among them, and to represent and visualize the new discovered\nknowledge. Furthermore, we have also implemented a Web-based prototype tool\nwhich integrates the proposed infrastructure.\n", "versions": [{"version": "v1", "created": "Tue, 7 Dec 2010 21:16:59 GMT"}], "update_date": "2010-12-09", "authors_parsed": [["Berlanga", "R.", ""], ["Jimenez-Ruiz", "E.", ""], ["Nebot", "V.", ""]]}, {"id": "1012.1617", "submitter": "Adrian Paschke", "authors": "Sylvie Ranwez, Vincent Ranwez, Mohameth-Fran\\c{c}ois Sy, Jacky\n  Montmain, Michel Crampes", "title": "User Centered and Ontology Based Information Retrieval System for Life\n  Sciences", "comments": "in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott\n  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on\n  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,\n  December 8-10, 2010", "journal-ref": null, "doi": null, "report-no": "SWAT4LS 2010", "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Because of the increasing number of electronic data, designing efficient\ntools to retrieve and exploit documents is a major challenge. Current search\nengines suffer from two main drawbacks: there is limited interaction with the\nlist of retrieved documents and no explanation for their adequacy to the query.\nUsers may thus be confused by the selection and have no idea how to adapt their\nquery so that the results match their expectations. This paper describes a\nrequest method and an environment based on aggregating models to assess the\nrelevance of documents annotated by concepts of ontology. The selection of\ndocuments is then displayed in a semantic map to provide graphical indications\nthat make explicit to what extent they match the user's query; this man/machine\ninterface favors a more interactive exploration of data corpus.\n", "versions": [{"version": "v1", "created": "Tue, 7 Dec 2010 21:41:17 GMT"}], "update_date": "2010-12-09", "authors_parsed": [["Ranwez", "Sylvie", ""], ["Ranwez", "Vincent", ""], ["Sy", "Mohameth-Fran\u00e7ois", ""], ["Montmain", "Jacky", ""], ["Crampes", "Michel", ""]]}, {"id": "1012.1663", "submitter": "Adrian Paschke", "authors": "Ning Kang, Rogier Barendse, Zubair Afzal, Bharat Singh, Martijn J.\n  Schuemie, Erik M. van Mulligen and Jan A. Kors", "title": "A Concept Annotation System for Clinical Records", "comments": "in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott\n  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on\n  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,\n  December 8-10, 2010", "journal-ref": null, "doi": null, "report-no": "SWAT4LS 2010", "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unstructured information comprises a valuable source of data in clinical\nrecords. For text mining in clinical records, concept extraction is the first\nstep in finding assertions and relationships. This study presents a system\ndeveloped for the annotation of medical concepts, including medical problems,\ntests, and treatments, mentioned in clinical records. The system combines six\npublicly available named entity recognition system into one framework, and uses\na simple voting scheme that allows to tune precision and recall of the system\nto specific needs. The system provides both a web service interface and a UIMA\ninterface which can be easily used by other systems. The system was tested in\nthe fourth i2b2 challenge and achieved an F-score of 82.1% for the concept\nexact match task, a score which is among the top-ranking systems. To our\nknowledge, this is the first publicly available clinical record concept\nannotation system.\n", "versions": [{"version": "v1", "created": "Wed, 8 Dec 2010 00:56:45 GMT"}], "update_date": "2010-12-09", "authors_parsed": [["Kang", "Ning", ""], ["Barendse", "Rogier", ""], ["Afzal", "Zubair", ""], ["Singh", "Bharat", ""], ["Schuemie", "Martijn J.", ""], ["van Mulligen", "Erik M.", ""], ["Kors", "Jan A.", ""]]}, {"id": "1012.1666", "submitter": "Adrian Paschke", "authors": "Luke McCarthy, Ben Vandervalk, Mark Wilkinson", "title": "SPARQL Assist Language-Neutral Query Composer", "comments": "in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott\n  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on\n  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,\n  December 8-10, 2010", "journal-ref": null, "doi": null, "report-no": "SWAT4LS 2010", "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SPARQL query composition is difficult for the lay-person or even the\nexperienced bioinformatician in cases where the data model is unfamiliar.\nEstablished best-practices and internationalization concerns dictate that\nsemantic web ontologies should use terms with opaque identifiers, further\ncomplicating the task. We present SPARQL Assist: a web application that\naddresses these issues by providing context-sensitive type-ahead completion to\nexisting web forms. Ontological terms are suggested using their labels and\ndescriptions, leveraging existing XML support for internationalization and\nlanguage-neutrality.\n", "versions": [{"version": "v1", "created": "Wed, 8 Dec 2010 01:10:59 GMT"}], "update_date": "2010-12-09", "authors_parsed": [["McCarthy", "Luke", ""], ["Vandervalk", "Ben", ""], ["Wilkinson", "Mark", ""]]}, {"id": "1012.2363", "submitter": "Santo Fortunato Dr", "authors": "Andrea Lancichinetti, Filippo Radicchi, Jose' Javier Ramasco, Santo\n  Fortunato", "title": "Finding statistically significant communities in networks", "comments": "24 pages, 25 figures, 1 table. Final version published in PLoS One.\n  The code of OSLOM is freely available at http://www.oslom.org", "journal-ref": "PLoS One 6(4), e18961 (2011)", "doi": "10.1371/journal.pone.0018961", "report-no": null, "categories": "physics.soc-ph cs.IR cs.SI q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community structure is one of the main structural features of networks,\nrevealing both their internal organization and the similarity of their\nelementary units. Despite the large variety of methods proposed to detect\ncommunities in graphs, there is a big need for multi-purpose techniques, able\nto handle different types of datasets and the subtleties of community\nstructure. In this paper we present OSLOM (Order Statistics Local Optimization\nMethod), the first method capable to detect clusters in networks accounting for\nedge directions, edge weights, overlapping communities, hierarchies and\ncommunity dynamics. It is based on the local optimization of a fitness function\nexpressing the statistical significance of clusters with respect to random\nfluctuations, which is estimated with tools of Extreme and Order Statistics.\nOSLOM can be used alone or as a refinement procedure of partitions/covers\ndelivered by other techniques. We have also implemented sequential algorithms\ncombining OSLOM with other fast techniques, so that the community structure of\nvery large networks can be uncovered. Our method has a comparable performance\nas the best existing algorithms on artificial benchmark graphs. Several\napplications on real networks are shown as well. OSLOM is implemented in a\nfreely available software (http://www.oslom.org), and we believe it will be a\nvaluable tool in the analysis of networks.\n", "versions": [{"version": "v1", "created": "Fri, 10 Dec 2010 19:52:21 GMT"}, {"version": "v2", "created": "Wed, 4 May 2011 16:00:19 GMT"}], "update_date": "2011-05-05", "authors_parsed": [["Lancichinetti", "Andrea", ""], ["Radicchi", "Filippo", ""], ["Ramasco", "Jose' Javier", ""], ["Fortunato", "Santo", ""]]}, {"id": "1012.3278", "submitter": "Victor Odumuyiwa", "authors": "Victor Odumuyiwa (LORIA), David Amos (LORIA)", "title": "Collaborative Knowledge Creation and Management in Information Retrieval", "comments": "KMO 2010 Knowledge management in organizations, veszpr\\'em : Hongrie\n  (2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The final goal of Information Retrieval (IR) is knowledge production.\nHowever, it has been argued that knowledge production is not an individual\neffort but a collaborative effort. Collaboration in information retrieval is\ngeared towards knowledge sharing and creation of new knowledge by users. This\npaper discusses Collaborative Information Retrieval (CIR) and how it culminates\nto knowledge creation. It explains how created knowledge is organized and\nstructured. It describes a functional architecture for the development of a CIR\nprototype called MECOCIR. Some of the features of the prototype are presented\nas well as how they facilitate collaborative knowledge exploitation. Knowledge\ncreation is explained through the knowledge conversion/transformation processes\nproposed by Nonaka and CIR activities that facilitate these processes are\nhigh-lighted and discussed\n", "versions": [{"version": "v1", "created": "Wed, 15 Dec 2010 10:59:37 GMT"}], "update_date": "2010-12-16", "authors_parsed": [["Odumuyiwa", "Victor", "", "LORIA"], ["Amos", "David", "", "LORIA"]]}, {"id": "1012.3502", "submitter": "Wolfgang Gatterbauer", "authors": "Wolfgang Gatterbauer", "title": "Rules of Thumb for Information Acquisition from Large and Redundant Data", "comments": "40 pages, 17 figures; for details see the project page:\n  http://uniquerecall.com", "journal-ref": "Full version of upcoming ECIR 2011 conference paper", "doi": null, "report-no": null, "categories": "cs.IR cs.DB physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop an abstract model of information acquisition from redundant data.\nWe assume a random sampling process from data which provide information with\nbias and are interested in the fraction of information we expect to learn as\nfunction of (i) the sampled fraction (recall) and (ii) varying bias of\ninformation (redundancy distributions). We develop two rules of thumb with\nvarying robustness. We first show that, when information bias follows a Zipf\ndistribution, the 80-20 rule or Pareto principle does surprisingly not hold,\nand we rather expect to learn less than 40% of the information when randomly\nsampling 20% of the overall data. We then analytically prove that for large\ndata sets, randomized sampling from power-law distributions leads to \"truncated\ndistributions\" with the same power-law exponent. This second rule is very\nrobust and also holds for distributions that deviate substantially from a\nstrict power law. We further give one particular family of powerlaw functions\nthat remain completely invariant under sampling. Finally, we validate our model\nwith two large Web data sets: link distributions to domains and tag\ndistributions on delicious.com.\n", "versions": [{"version": "v1", "created": "Thu, 16 Dec 2010 02:36:13 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Gatterbauer", "Wolfgang", ""]]}, {"id": "1012.3793", "submitter": "Tao Zhou", "authors": "Yanbo Zhou, Ting Lei, Tao Zhou", "title": "A robust ranking algorithm to spamming", "comments": "4 pages, 4 figures, 3 Tables", "journal-ref": "EPL 94 (2011) 48002", "doi": "10.1209/0295-5075/94/48002", "report-no": null, "categories": "cs.IR physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking problem of web-based rating system has attracted many attentions. A\ngood ranking algorithm should be robust against spammer attack. Here we\nproposed a correlation based reputation algorithm to solve the ranking problem\nof such rating systems where user votes some objects with ratings. In this\nalgorithm, reputation of user is iteratively determined by the correlation\ncoefficient between his/her rating vector and the corresponding objects'\nweighted average rating vector. Comparing with iterative refinement (IR) and\nmean score algorithm, results for both artificial and real data indicate that,\nthe present algorithm shows a higher robustness against spammer attack.\n", "versions": [{"version": "v1", "created": "Fri, 17 Dec 2010 00:58:02 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Zhou", "Yanbo", ""], ["Lei", "Ting", ""], ["Zhou", "Tao", ""]]}, {"id": "1012.3805", "submitter": "Yang Wang", "authors": "Yang Wang, Zhikui Chen, Xiaodi Huang", "title": "Element Retrieval using Namespace Based on keyword search over XML\n  Documents", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Querying over XML elements using keyword search is steadily gaining\npopularity. The traditional similarity measure is widely employed in order to\neffectively retrieve various XML documents. A number of authors have already\nproposed different similarity-measure methods that take advantage of the\nstructure and content of XML documents. They do not, however, consider the\nsimilarity between latent semantic information of element texts and that of\nkeywords in a query. Although many algorithms on XML element search are\navailable, some of them have the high computational complexity due to searching\na huge number of elements. In this paper, we propose a new algorithm that makes\nuse of the semantic similarity between elements instead of between entire XML\ndocuments, considering not only the structure and content of an XML document,\nbut also semantic information of namespaces in elements. We compare our\nalgorithm with the three other algorithms by testing on the real datasets. The\nexperiments have demonstrated that our proposed method is able to improve the\nquery accuracy, as well as to reduce the running time.\n", "versions": [{"version": "v1", "created": "Fri, 17 Dec 2010 04:00:10 GMT"}], "update_date": "2010-12-20", "authors_parsed": [["Wang", "Yang", ""], ["Chen", "Zhikui", ""], ["Huang", "Xiaodi", ""]]}, {"id": "1012.4752", "submitter": "Ying Ding", "authors": "Ying Ding (School of Library and Information Science, Indiana\n  University Bloomington, IN, USA)", "title": "Semantic Web: Who is who in the field - A bibliometric analysis", "comments": "22 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Semantic Web is one of the main efforts aiming to enhance human and\nmachine interaction by representing data in an understandable way for machines\nto mediate data and services. It is a fast-moving and multidisciplinary field.\nThis study conducts a thorough bibliometric analysis of the field by collecting\ndata from Web of Science (WOS) and Scopus for the period of 1960-2009. It\nutilizes a total of 44,157 papers with 651,673 citations from Scopus, and\n22,951 papers with 571,911 citations from WOS. Based on these papers and\ncitations, it evaluates the research performance of the Semantic Web (SW) by\nidentifying the most productive players, major scholarly communication media,\nhighly cited authors, influential papers and emerging stars.\n", "versions": [{"version": "v1", "created": "Tue, 21 Dec 2010 18:07:45 GMT"}], "update_date": "2010-12-22", "authors_parsed": [["Ding", "Ying", "", "School of Library and Information Science, Indiana\n  University Bloomington, IN, USA"]]}, {"id": "1012.4759", "submitter": "Ying Ding", "authors": "Bin Chen (1), David J Wild (1), Qian Zhu (1), Ying Ding (2), Xiao Dong\n  (1), Madhuvanthi Sankaranarayanan (1), Huijun Wang (1), Yuyin Sun (2) ((1)\n  School of Informatics and Computing, Indiana University, Bloomington, IN,\n  USA, (2) School of Library and Information Science, Indiana University,\n  Bloomington, IN, USA)", "title": "Chem2Bio2RDF: A Linked Open Data Portal for Chemical Biology", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR q-bio.OT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Chem2Bio2RDF portal is a Linked Open Data (LOD) portal for systems\nchemical biology aiming for facilitating drug discovery. It converts around 25\ndifferent datasets on genes, compounds, drugs, pathways, side effects,\ndiseases, and MEDLINE/PubMed documents into RDF triples and links them to other\nLOD bubbles, such as Bio2RDF, LODD and DBPedia. The portal is based on D2R\nserver and provides a SPARQL endpoint, but adds on few unique features like RDF\nfaceted browser, user-friendly SPARQL query generator, MEDLINE/PubMed cross\nvalidation service, and Cytoscape visualization plugin. Three use cases\ndemonstrate the functionality and usability of this portal.\n", "versions": [{"version": "v1", "created": "Tue, 21 Dec 2010 18:29:54 GMT"}], "update_date": "2010-12-22", "authors_parsed": [["Chen", "Bin", ""], ["Wild", "David J", ""], ["Zhu", "Qian", ""], ["Ding", "Ying", ""], ["Dong", "Xiao", ""], ["Sankaranarayanan", "Madhuvanthi", ""], ["Wang", "Huijun", ""], ["Sun", "Yuyin", ""]]}, {"id": "1012.4875", "submitter": "Ying Ding", "authors": "Ying Ding (1), Elin K. Jacob (1), Michael Fried (2), Ioan Toma (2),\n  Erjia Yan (1), Schubert Foo (3) ((1) School of Library and Information\n  Science, Indiana University, Bloomington, IN, USA, (2) Institute of Computer\n  Science, University of Innsbruck, Innsbruck, Austria, (3) Division of\n  Information Studies, Nanyang Technological University, Singapore)", "title": "Upper Tag Ontology (UTO) For Integrating Social Tagging Data", "comments": "31 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data integration and mediation have become central concerns of information\ntechnology over the past few decades. With the advent of the Web and the rapid\nincreases in the amount of data and the number of Web documents and users,\nresearchers have focused on enhancing the interoperability of data through the\ndevelopment of metadata schemes. Other researchers have looked to the wealth of\nmetadata generated by bookmarking sites on the Social Web. While several\nexisting ontologies capitalize on the semantics of metadata created by tagging\nactivities, the Upper Tag Ontology (UTO) emphasizes the structure of tagging\nactivities to facilitate modeling of tagging data and the integration of data\nfrom different bookmarking sites as well as the alignment of tagging\nontologies. UTO is described and its utility in harvesting, modeling,\nintegrating, searching and analyzing data is demonstrated with metadata\nharvested from three major social tagging systems (Delicious, Flickr and\nYouTube).\n", "versions": [{"version": "v1", "created": "Wed, 22 Dec 2010 03:36:15 GMT"}], "update_date": "2010-12-23", "authors_parsed": [["Ding", "Ying", ""], ["Jacob", "Elin K.", ""], ["Fried", "Michael", ""], ["Toma", "Ioan", ""], ["Yan", "Erjia", ""], ["Foo", "Schubert", ""]]}, {"id": "1012.5208", "submitter": "Nadia Baaziz", "authors": "Nadia Baaziz, Omar Abahmane and Rokia Missaoui", "title": "Texture feature extraction in the spatial-frequency domain for\n  content-based image retrieval", "comments": "19 pages, 11 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of large scale multimedia databases has led to great challenges in\ncontent-based image retrieval (CBIR). Even though CBIR is considered an\nemerging field of research, however it constitutes a strong background for new\nmethodologies and systems implementations. Therefore, many research\ncontributions are focusing on techniques enabling higher image retrieval\naccuracy while preserving low level of computational complexity. Image\nretrieval based on texture features is receiving special attention because of\nthe omnipresence of this visual feature in most real-world images. This paper\nhighlights the state-of-the-art and current progress relevant to texture-based\nimage retrieval and spatial-frequency image representations. In particular, it\ngives an overview of statistical methodologies and techniques employed for\ntexture feature extraction using most popular spatial-frequency image\ntransforms, namely discrete wavelets, Gabor wavelets, dual-tree complex wavelet\nand contourlets. Indications are also given about used similarity measurement\nfunctions and most important achieved results.\n", "versions": [{"version": "v1", "created": "Thu, 23 Dec 2010 14:10:25 GMT"}], "update_date": "2010-12-24", "authors_parsed": [["Baaziz", "Nadia", ""], ["Abahmane", "Omar", ""], ["Missaoui", "Rokia", ""]]}, {"id": "1012.5506", "submitter": "Adrian Paschke", "authors": "Alejandra Gonzalez-Beltran, Ben Tagger, and Anthony Finkelstein", "title": "Ontology-based Queries over Cancer Data", "comments": "in Adrian Paschke, Albert Burger, Andrea Splendiani, M. Scott\n  Marshall, Paolo Romano: Proceedings of the 3rd International Workshop on\n  Semantic Web Applications and Tools for the Life Sciences, Berlin,Germany,\n  December 8-10, 2010", "journal-ref": null, "doi": null, "report-no": "SWAT4LS 2010", "categories": "cs.AI cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing amount of data in biomedical research, and in cancer\nresearch in particular, needs to be managed to support efficient data access,\nexchange and integration. Existing software infrastructures, such caGrid,\nsupport access to distributed information annotated with a domain ontology.\nHowever, caGrid's current querying functionality depends on the structure of\nindividual data resources without exploiting the semantic annotations. In this\npaper, we present the design and development of an ontology-based querying\nfunctionality that consists of: the generation of OWL2 ontologies from the\nunderlying data resources metadata and a query rewriting and translation\nprocess based on reasoning, which converts a query at the domain ontology level\ninto queries at the software infrastructure level. We present a detailed\nanalysis of our approach as well as an extensive performance evaluation. While\nthe implementation and evaluation was performed for the caGrid infrastructure,\nthe approach could be applicable to other model and metadata-driven\nenvironments for data sharing.\n", "versions": [{"version": "v1", "created": "Sun, 26 Dec 2010 10:49:52 GMT"}], "update_date": "2010-12-30", "authors_parsed": [["Gonzalez-Beltran", "Alejandra", ""], ["Tagger", "Ben", ""], ["Finkelstein", "Anthony", ""]]}]