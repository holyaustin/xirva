[{"id": "1112.0032", "submitter": "G\\'erald Kembellec", "authors": "G\\'erald Kembellec and Imad Saleh and Catherine Sauvaget", "title": "A model of Cross Language Retrieval for IT domain papers through a map\n  of ACM Computing Classification System", "comments": "7 pages, 3 figures, 1 table", "journal-ref": null, "doi": "10.1109/MMCS.2009.5256709", "report-no": null, "categories": "cs.DL cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a concept model, and the associated tool to help\nadvanced learners to find adapted bibliography. The purpose is the use of an IT\nrepresentation as educational research software for newcomers in research. We\nuse an ontology based on the ACM's Computing Classification System in order to\nfind scientific articles directly related to the new researcher's domain\nwithout any formal request. An ontology translation in French is automatically\nproposed and can be based on Web 2.0 enhanced by a community of users. A\nvisualization and navigation model is proposed to make it more accessible and\nexamples are given to show the interface of our tool: Ontology Navigator.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 21:18:44 GMT"}], "update_date": "2012-02-07", "authors_parsed": [["Kembellec", "G\u00e9rald", ""], ["Saleh", "Imad", ""], ["Sauvaget", "Catherine", ""]]}, {"id": "1112.0052", "submitter": "Mohammad Nassar", "authors": "Eman Al Mashagba, Feras Al Mashagba and Mohammad Othman Nassar", "title": "Query Optimization Using Genetic Algorithms in the Vector Space Model", "comments": "7 pages; ISSN (online): 1694-0814 This paper has been withdrawn by\n  the author due to a crucial errors in table: 2,3,4,5,6 and in the results", "journal-ref": "International Journal of Computer Science Issues (IJCSI), Volume\n  8, Issue 5, pp 450-457, September 2011", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In information retrieval research; Genetic Algorithms (GA) can be used to\nfind global solutions in many difficult problems. This study used different\nsimilarity measures (Dice, Inner Product) in the VSM, for each similarity\nmeasure we compared ten different GA approaches based on different fitness\nfunctions, different mutations and different crossover strategies to find the\nbest strategy and fitness function that can be used when the data collection is\nthe Arabic language. Our results shows that the GA approach which uses\none-point crossover operator, point mutation and Inner Product similarity as a\nfitness function is the best IR system in VSM.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 23:14:20 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2013 20:59:53 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Mashagba", "Eman Al", ""], ["Mashagba", "Feras Al", ""], ["Nassar", "Mohammad Othman", ""]]}, {"id": "1112.0054", "submitter": "Mohammad Nassar", "authors": "Mohammad Othman Nassar, Feras Al Mashagba, and Eman Al Mashagba", "title": "Improving the User Query for the Boolean Model Using Genetic Algorithms", "comments": "4 pages; ISSN (online): 1694-0814 this paper has been withdrawn by\n  the author due to a crucial errors in table 1 and 2. other errors are related\n  to the final results", "journal-ref": "International Journal of Computer Science Issues (IJCSI), Volume\n  8, Issue 5, pp 66-70, September 2011", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Use of genetic algorithms in the Information retrieval (IR) area,\nespecially in optimizing a user query in Arabic data collections is presented\nin this paper. Very little research has been carried out on Arabic text\ncollections. Boolean model have been used in this research. To optimize the\nquery using GA we used different fitness functions, different mutation\nstrategies to find which is the best strategy and fitness function that can be\nused with Boolean model when the data collection is the Arabic language. Our\nresults show that the best GA strategy for the Boolean model is the GA (M2,\nPrecision) method.\n", "versions": [{"version": "v1", "created": "Wed, 30 Nov 2011 23:20:06 GMT"}, {"version": "v2", "created": "Mon, 2 Dec 2013 20:56:27 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Nassar", "Mohammad Othman", ""], ["Mashagba", "Feras Al", ""], ["Mashagba", "Eman Al", ""]]}, {"id": "1112.2015", "submitter": "Anamika Bhargava", "authors": "Anamika Sharma", "title": "A Framework for Picture Extraction on Search Engine Improved and\n  Meaningful Result", "comments": "5 pages,1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Searching is an important tool of information gathering, if information is in\nthe form of picture than it play a major role to take quick action and easy to\nmemorize. This is a human tendency to retain more picture than text. The\ncomplexity and the occurrence of variety of query can give variation in result\nand provide the humans to learn something new or get confused. This paper\npresents a development of a framework that will focus on recourse\nidentification for the user so that they can get faster access with accurate &\nconcise results on time and analysis of the change that is evident as the\nscenario changes from text to picture retrieval. This paper also provides a\nglimpse how to get accurate picture information in advance and extended\ntechnologies searching framework. The new challenges and design techniques of\npicture retrieval systems are also suggested in this paper.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 04:26:47 GMT"}], "update_date": "2011-12-12", "authors_parsed": [["Sharma", "Anamika", ""]]}, {"id": "1112.2028", "submitter": "Bhawna Nigam", "authors": "Bhawna Nigam, Poorvi Ahirwal, Sonal Salve, Swati Vamney", "title": "Document Classification Using Expectation Maximization with Semi\n  Supervised Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the amount of online document increases, the demand for document\nclassification to aid the analysis and management of document is increasing.\nText is cheap, but information, in the form of knowing what classes a document\nbelongs to, is expensive. The main purpose of this paper is to explain the\nexpectation maximization technique of data mining to classify the document and\nto learn how to improve the accuracy while using semi-supervised approach.\nExpectation maximization algorithm is applied with both supervised and\nsemi-supervised approach. It is found that semi-supervised approach is more\naccurate and effective. The main advantage of semi supervised approach is\n\"Dynamically Generation of New Class\". The algorithm first trains a classifier\nusing the labeled document and probabilistically classifies the unlabeled\ndocuments. The car dataset for the evaluation purpose is collected from UCI\nrepository dataset in which some changes have been done from our side.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 07:09:21 GMT"}], "update_date": "2011-12-12", "authors_parsed": [["Nigam", "Bhawna", ""], ["Ahirwal", "Poorvi", ""], ["Salve", "Sonal", ""], ["Vamney", "Swati", ""]]}, {"id": "1112.2031", "submitter": "Yashodhara Haribhakta", "authors": "Y.V. Haribhakta and Dr. Parag Kulkarni", "title": "Learning Context for Text Categorization", "comments": "9 pages, selected in IJDKP (International Journal of Data Mining and\n  Knowledge Management Process)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes our work which is based on discovering context for text\ndocument categorization. The document categorization approach is derived from a\ncombination of a learning paradigm known as relation extraction and an\ntechnique known as context discovery. We demonstrate the effectiveness of our\ncategorization approach using reuters 21578 dataset and synthetic real world\ndata from sports domain. Our experimental results indicate that the learned\ncontext greatly improves the categorization performance as compared to\ntraditional categorization approaches.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 07:24:13 GMT"}], "update_date": "2011-12-12", "authors_parsed": [["Haribhakta", "Y. V.", ""], ["Kulkarni", "Dr. Parag", ""]]}, {"id": "1112.2071", "submitter": "Ferihane Kboubi", "authors": "Anja Habacha Chabi, Ferihane Kboubi, Mohamed Ben Ahmed", "title": "Thematic Analysis and Visualization of Textual Corpus", "comments": "16 pages,9 figures", "journal-ref": "International Journal of Computer Science & Engineering Survey\n  (IJCSES), November 2011, Volume 2 Number 4, ISSN : 0976-2760 (Online)\n  0976-3252 (Print) go", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The semantic analysis of documents is a domain of intense research at\npresent. The works in this domain can take several directions and touch several\nlevels of granularity. In the present work we are exactly interested in the\nthematic analysis of the textual documents. In our approach, we suggest\nstudying the variation of the theme relevance within a text to identify the\nmajor theme and all the minor themes evoked in the text. This allows us at the\nsecond level of analysis to identify the relations of thematic associations in\na textual corpus. Through the identification and the analysis of these\nassociation relations we suggest generating thematic paths allowing users,\nwithin the frame work of information search system, to explore the corpus\naccording to their themes of interest and to discover new knowledge by\nnavigating in the thematic association relations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Dec 2011 11:04:32 GMT"}], "update_date": "2011-12-12", "authors_parsed": [["Chabi", "Anja Habacha", ""], ["Kboubi", "Ferihane", ""], ["Ahmed", "Mohamed Ben", ""]]}, {"id": "1112.2251", "submitter": "Michalis Vafopoulos n", "authors": "Vafopoulos Michalis and Oikonomou Michael", "title": "Recommendation systems: a joint analysis of technical aspects with\n  marketing implications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In 2010, Web users ordered, only in Amazon, 73 items per second and massively\ncontribute reviews about their consuming experience. As the Web matures and\nbecomes social and participatory, collaborative filters are the basic\ncomplement in searching online information about people, events and products.\nIn Web 2.0, what connected consumers create is not simply content (e.g.\nreviews) but context. This new contextual framework of consumption emerges\nthrough the aggregation and collaborative filtering of personal preferences\nabout goods in the Web in massive scale. More importantly, facilitates\nconnected consumers to search and navigate the complex Web more effectively and\namplifies incentives for quality. The objective of the present article is to\njointly review the basic stylized facts of relevant research in recommendation\nsystems in computer and marketing studies in order to share some common\ninsights. After providing a comprehensive definition of goods and Users in the\nWeb, we describe a classification of recommendation systems based on two\nfamilies of criteria: how recommendations are formed and input data\navailability. The classification is presented under a common minimal matrix\nnotation and is used as a bridge to related issues in the business and\nmarketing literature. We focus our analysis in the fields of one-to-one\nmarketing, network-based marketing Web merchandising and atmospherics and their\nimplications in the processes of personalization and adaptation in the Web.\nMarket basket analysis is investigated in context of recommendation systems.\nDiscussion on further research refers to the business implications and\ntechnological challenges of recommendation systems.\n", "versions": [{"version": "v1", "created": "Sat, 10 Dec 2011 04:53:28 GMT"}], "update_date": "2011-12-13", "authors_parsed": [["Michalis", "Vafopoulos", ""], ["Michael", "Oikonomou", ""]]}, {"id": "1112.2388", "submitter": "Jianguo Liu", "authors": "Zhao-Guo Xuan, Zhan Li and Jian-Guo Liu", "title": "Information Filtering via Implicit Trust-based Network", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on the user-item bipartite network, collaborative filtering (CF)\nrecommender systems predict users' interests according to their history\ncollections, which is a promising way to solve the information exploration\nproblem. However, CF algorithm encounters cold start and sparsity problems. The\ntrust-based CF algorithm is implemented by collecting the users' trust\nstatements, which is time-consuming and must use users' private friendship\ninformation. In this paper, we present a novel measurement to calculate users'\nimplicit trust-based correlation by taking into account their average ratings,\nrating ranges, and the number of common rated items. By applying the similar\nidea to the items, a item-based CF algorithm is constructed. The simulation\nresults on three benchmark data sets show that the performances of both\nuser-based and item-based algorithms could be enhanced greatly. Finally, a\nhybrid algorithm is constructed by integrating the user-based and item-based\nalgorithms, the simulation results indicate that hybrid algorithm outperforms\nthe state-of-the-art methods. Specifically, it can not only provide more\naccurate recommendations, but also alleviate the cold start problem.\n", "versions": [{"version": "v1", "created": "Sun, 11 Dec 2011 19:37:24 GMT"}], "update_date": "2011-12-13", "authors_parsed": [["Xuan", "Zhao-Guo", ""], ["Li", "Zhan", ""], ["Liu", "Jian-Guo", ""]]}, {"id": "1112.2392", "submitter": "Jianguo Liu", "authors": "Jian-Guo Liu, Tao Zhou, Qiang Guo", "title": "Information filtering via biased heat conduction", "comments": "4 pages, 3 figures", "journal-ref": "Phys. Rev. E 87 (2011) 037101", "doi": "10.1103/PhysRevE.84.037101", "report-no": null, "categories": "physics.data-an cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heat conduction process has recently found its application in personalized\nrecommendation [T. Zhou \\emph{et al.}, PNAS 107, 4511 (2010)], which is of high\ndiversity but low accuracy. By decreasing the temperatures of small-degree\nobjects, we present an improved algorithm, called biased heat conduction (BHC),\nwhich could simultaneously enhance the accuracy and diversity. Extensive\nexperimental analyses demonstrate that the accuracy on MovieLens, Netflix and\nDelicious datasets could be improved by 43.5%, 55.4% and 19.2% compared with\nthe standard heat conduction algorithm, and the diversity is also increased or\napproximately unchanged. Further statistical analyses suggest that the present\nalgorithm could simultaneously identify users' mainstream and special tastes,\nresulting in better performance than the standard heat conduction algorithm.\nThis work provides a creditable way for highly efficient information filtering.\n", "versions": [{"version": "v1", "created": "Sun, 11 Dec 2011 20:18:22 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Liu", "Jian-Guo", ""], ["Zhou", "Tao", ""], ["Guo", "Qiang", ""]]}, {"id": "1112.2460", "submitter": "Alireza Abbasi", "authors": "Alireza Abbasi, Liaquat Hossain, Rolf Wigand", "title": "Social Capital and Individual Performance: A Study of Academic\n  Collaboration", "comments": "submitted to JASIST", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies on social networks highlight the importance of network structure or\nstructural properties of a given network and its impact on performance outcome.\nOne of the important properties of this network structure is referred as\n\"social capital\" which is the \"network of contacts\" and the associated values\nattached to these networks of contacts. In this study, our aim is to provide\nempirical evidence of the influence of social capital and performance within\nthe context of academic collaboration. We suggest that the collaborative\nprocess involves social capital embedded within relationships and network\nstructures among direct co-authors. Thus, we examine whether scholars' social\ncapital is associated with their citation-based performance, using\nco-authorship and citation data. In order to test and validate our proposed\nhypotheses, we extract publication records from Scopus having \"information\nscience\" in their title or keywords or abstracts during 2001 and 2010. To\novercome the limitations of traditional social network metrics for measuring\nthe influence of scholars' social capital within their co-authorship network,\nwe extend the traditional social network metrics by proposing a new measure\n(Power-Diversity Index). We then use Spearman's correlation rank test to\nexamine the association between scholars' social capital measures and their\ncitation-based performance. Results suggest that research performance of\nauthors is positively correlated with their social capital measures. This study\nhighlights that the Power-diversity Index, which is introduced as a new hybrid\ncentrality measure, serves as an indicator of power and influence of an\nindividual's ability to control communication and information.\n", "versions": [{"version": "v1", "created": "Mon, 12 Dec 2011 07:22:48 GMT"}], "update_date": "2011-12-13", "authors_parsed": [["Abbasi", "Alireza", ""], ["Hossain", "Liaquat", ""], ["Wigand", "Rolf", ""]]}, {"id": "1112.2807", "submitter": "Andri Mirzal", "authors": "Andri Mirzal", "title": "Design and Implementation of a Simple Web Search Engine", "comments": "8 pages, 5 figures", "journal-ref": "International Journal of Multimedia and Ubiquitous Engineering\n  International Journal of Multimedia and Ubiquitous Engineering International\n  Journal of Multimedia and Ubiquitous Engineering, Vol. 7, No. 1, January,\n  2012", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We present a simple web search engine for indexing and searching html\ndocuments using python programming language. Because python is well known for\nits simple syntax and strong support for main operating systems, we hope it\nwill be beneficial for learning information retrieval techniques, especially\nweb search engine technology.\n", "versions": [{"version": "v1", "created": "Tue, 13 Dec 2011 06:46:26 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2012 00:10:38 GMT"}], "update_date": "2012-02-10", "authors_parsed": [["Mirzal", "Andri", ""]]}, {"id": "1112.4456", "submitter": "Massimiliano Dal Mas", "authors": "Massimiliano Dal Mas", "title": "Cluster Analysis for a Scale-Free Folksodriven Structure Network", "comments": "9 pages, 4 figures; for details see: http://www.maxdalmas.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Folksonomy is said to provide a democratic tagging system that reflects the\nopinions of the general public, but it is not a classification system and it is\nhard to make sense of. It would be necessary to share a representation of\ncontexts by all the users to develop a social and collaborative matching. The\nsolution could be to help the users to choose proper tags thanks to a dynamical\ndriven system of folksonomy that could evolve during the time. This paper uses\na cluster analysis to measure a new concept of a structure called\n\"Folksodriven\", which consists of tags, source and time. Many approaches\ninclude in their goals the use of folksonomy that could evolve during time to\nevaluate characteristics. This paper describes an alternative where the goal is\nto develop a weighted network of tags where link strengths are based on the\nfrequencies of tag co-occurrence, and studied the weight distributions and\nconnectivity correlations among nodes in this network. The paper proposes and\nanalyzes the network structure of the Folksodriven tags thought as folksonomy\ntags suggestions for the user on a dataset built on chosen websites. It is\nobserved that the hypergraphs of the Folksodriven are highly connected and that\nthe relative path lengths are relatively low, facilitating thus the\nserendipitous discovery of interesting contents for the users. Then its\ncharacteristics, Clustering Coefficient, is compared with random networks. The\ngoal of this paper is a useful analysis of the use of folksonomies on some well\nknown and extensive web sites with real user involvement. The advantages of the\nnew tagging method using folksonomy are on a new interesting method to be\nemployed by a knowledge management system.\n  *** This paper has been accepted to the International Conference on Social\nComputing and its Applications (SCA 2011) - Sydney Australia, 12-14 December\n2011 ***\n", "versions": [{"version": "v1", "created": "Mon, 19 Dec 2011 20:31:00 GMT"}], "update_date": "2011-12-20", "authors_parsed": [["Mas", "Massimiliano Dal", ""]]}, {"id": "1112.5355", "submitter": "Imane Zaoui", "authors": "Imane Zaoui, Dalila Chiadmi, Laila Benhlima", "title": "2P-Med: Building a Personalization Platform for Mediation Systems", "comments": "In IJEST (International Journal of Engeneering Science and\n  Technologies) ISSN: 0975-5462 Vol. 3 No. 5 May 2011, 4488-4497", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, with the increasing number of integrated data sources, there is a\nreal trend to personalize mediation systems to improve user satisfaction. To\nmake these systems user sensitive, we propose a personalization platform called\n2P-Med. 2P-Med allows personalizing any mediation system used in any domain\nfollowing a cyclic process. The process includes building and managing adequate\nuser profiles and sources profiles, content and quality matching, source\nselection, adapting the mediator responses to user preferences and handling\nuser feedbacks. In this paper, we describe 2P-Med architecture and highlight\nits main functionalities. We also illustrate the operation of the platform\nthrough personalizing source selection in a travel planning assistant.\n", "versions": [{"version": "v1", "created": "Thu, 22 Dec 2011 15:38:17 GMT"}], "update_date": "2011-12-23", "authors_parsed": [["Zaoui", "Imane", ""], ["Chiadmi", "Dalila", ""], ["Benhlima", "Laila", ""]]}, {"id": "1112.6219", "submitter": "Rafi Muhammad", "authors": "Muhammad Rafi, M. Shahid Shaikh, Amir Farooq", "title": "Document Clustering based on Topic Maps", "comments": null, "journal-ref": "International Journal of Computer Applications 12(1):32-36,\n  December 2010", "doi": "10.5120/1640-2204", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Importance of document clustering is now widely acknowledged by researchers\nfor better management, smart navigation, efficient filtering, and concise\nsummarization of large collection of documents like World Wide Web (WWW). The\nnext challenge lies in semantically performing clustering based on the semantic\ncontents of the document. The problem of document clustering has two main\ncomponents: (1) to represent the document in such a form that inherently\ncaptures semantics of the text. This may also help to reduce dimensionality of\nthe document, and (2) to define a similarity measure based on the semantic\nrepresentation such that it assigns higher numerical values to document pairs\nwhich have higher semantic relationship. Feature space of the documents can be\nvery challenging for document clustering. A document may contain multiple\ntopics, it may contain a large set of class-independent general-words, and a\nhandful class-specific core-words. With these features in mind, traditional\nagglomerative clustering algorithms, which are based on either Document Vector\nmodel (DVM) or Suffix Tree model (STC), are less efficient in producing results\nwith high cluster quality. This paper introduces a new approach for document\nclustering based on the Topic Map representation of the documents. The document\nis being transformed into a compact form. A similarity measure is proposed\nbased upon the inferred information through topic maps data and structures. The\nsuggested method is implemented using agglomerative hierarchal clustering and\ntested on standard Information retrieval (IR) datasets. The comparative\nexperiment reveals that the proposed approach is effective in improving the\ncluster quality.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2011 04:15:48 GMT"}], "update_date": "2011-12-30", "authors_parsed": [["Rafi", "Muhammad", ""], ["Shaikh", "M. Shahid", ""], ["Farooq", "Amir", ""]]}, {"id": "1112.6222", "submitter": "Rafi Muhammad", "authors": "Muhammad Rafi, M. Maujood, M. M. Fazal, S. M. Ali", "title": "A comparison of two suffix tree-based document clustering algorithms", "comments": "Information and Emerging Technologies (ICIET), 2010 International\n  Conference", "journal-ref": null, "doi": "10.1109/2010.5625688", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document clustering as an unsupervised approach extensively used to navigate,\nfilter, summarize and manage large collection of document repositories like the\nWorld Wide Web (WWW). Recently, focuses in this domain shifted from traditional\nvector based document similarity for clustering to suffix tree based document\nsimilarity, as it offers more semantic representation of the text present in\nthe document. In this paper, we compare and contrast two recently introduced\napproaches to document clustering based on suffix tree data model. The first is\nan Efficient Phrase based document clustering, which extracts phrases from\ndocuments to form compact document representation and uses a similarity measure\nbased on common suffix tree to cluster the documents. The second approach is a\nfrequent word/word meaning sequence based document clustering, it similarly\nextracts the common word sequence from the document and uses the common\nsequence/ common word meaning sequence to perform the compact representation,\nand finally, it uses document clustering approach to cluster the compact\ndocuments. These algorithms are using agglomerative hierarchical document\nclustering to perform the actual clustering step, the difference in these\napproaches are mainly based on extraction of phrases, model representation as a\ncompact document, and the similarity measures used for clustering. This paper\ninvestigates the computational aspect of the two algorithms, and the quality of\nresults they produced.\n", "versions": [{"version": "v1", "created": "Thu, 29 Dec 2011 04:25:10 GMT"}, {"version": "v2", "created": "Tue, 10 Jan 2012 15:40:29 GMT"}], "update_date": "2012-01-11", "authors_parsed": [["Rafi", "Muhammad", ""], ["Maujood", "M.", ""], ["Fazal", "M. M.", ""], ["Ali", "S. M.", ""]]}]