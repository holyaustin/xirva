[{"id": "1103.1252", "submitter": "Emilio Ferrara", "authors": "Emilio Ferrara and Robert Baumgartner", "title": "Automatic Wrapper Adaptation by Tree Edit Distance Matching", "comments": "7 pages, 3 figures, In Proceedings of the 2nd International Workshop\n  on Combinations of Intelligent Methods and Applications (CIMA 2010)", "journal-ref": "Combinations of Intelligent Methods and Applications Smart\n  Innovation, Systems and Technologies Volume 8, 2011, pp 41-54", "doi": "10.1007/978-3-642-19618-8_3", "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information distributed through the Web keeps growing faster day by day, and\nfor this reason, several techniques for extracting Web data have been suggested\nduring last years. Often, extraction tasks are performed through so called\nwrappers, procedures extracting information from Web pages, e.g. implementing\nlogic-based techniques. Many fields of application today require a strong\ndegree of robustness of wrappers, in order not to compromise assets of\ninformation or reliability of data extracted. Unfortunately, wrappers may fail\nin the task of extracting data from a Web page, if its structure changes,\nsometimes even slightly, thus requiring the exploiting of new techniques to be\nautomatically held so as to adapt the wrapper to the new structure of the page,\nin case of failure. In this work we present a novel approach of automatic\nwrapper adaptation based on the measurement of similarity of trees through\nimproved tree edit distance matching techniques.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2011 11:27:30 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Ferrara", "Emilio", ""], ["Baumgartner", "Robert", ""]]}, {"id": "1103.1254", "submitter": "Emilio Ferrara", "authors": "Emilio Ferrara and Robert Baumgartner", "title": "Design of Automatically Adaptable Web Wrappers", "comments": "7 pages, 2 figures, In Proceedings of the 3rd International\n  Conference on Agents and Artificial Intelligence (ICAART 2011)", "journal-ref": "Proceedings of the 3rd International Conference on Agents and\n  Artificial Intelligence, pp 211-216, 2011", "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the huge amount of information distributed through the Web\nmotivates studying techniques to be adopted in order to extract relevant data\nin an efficient and reliable way. Both academia and enterprises developed\nseveral approaches of Web data extraction, for example using techniques of\nartificial intelligence or machine learning. Some commonly adopted procedures,\nnamely wrappers, ensure a high degree of precision of information extracted\nfrom Web pages, and, at the same time, have to prove robustness in order not to\ncompromise quality and reliability of data themselves. In this paper we focus\non some experimental aspects related to the robustness of the data extraction\nprocess and the possibility of automatically adapting wrappers. We discuss the\nimplementation of algorithms for finding similarities between two different\nversion of a Web page, in order to handle modifications, avoiding the failure\nof data extraction tasks and ensuring reliability of information extracted. Our\npurpose is to evaluate performances, advantages and draw-backs of our novel\nsystem of automatic wrapper adaptation.\n", "versions": [{"version": "v1", "created": "Mon, 7 Mar 2011 11:41:25 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Ferrara", "Emilio", ""], ["Baumgartner", "Robert", ""]]}, {"id": "1103.2635", "submitter": "Lawrence Cayton", "authors": "Lawrence Cayton", "title": "Accelerating Nearest Neighbor Search on Manycore Systems", "comments": null, "journal-ref": "In Proceedings of the 2012 IEEE 26th International Parallel and\n  Distributed Processing Symposium (IPDPS '12). IEEE Computer Society,\n  Washington, DC, USA, 402-413", "doi": "10.1109/IPDPS.2012.45", "report-no": null, "categories": "cs.DB cs.CG cs.DC cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop methods for accelerating metric similarity search that are\neffective on modern hardware. Our algorithms factor into easily parallelizable\ncomponents, making them simple to deploy and efficient on multicore CPUs and\nGPUs. Despite the simple structure of our algorithms, their search performance\nis provably sublinear in the size of the database, with a factor dependent only\non its intrinsic dimensionality. We demonstrate that our methods provide\nsubstantial speedups on a range of datasets and hardware platforms. In\nparticular, we present results on a 48-core server machine, on graphics\nhardware, and on a multicore desktop.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2011 11:39:23 GMT"}, {"version": "v2", "created": "Wed, 30 Mar 2011 18:26:44 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Cayton", "Lawrence", ""]]}, {"id": "1103.2651", "submitter": "Yanwei Xu", "authors": "Yanwei Xu", "title": "Efficient Continual Top-$k$ Keyword Search in Relational Databases", "comments": "This paper has been withdrawn by the author due to a crucial error of\n  the algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword search in relational databases has been widely studied in recent\nyears because it does not require users neither to master a certain structured\nquery language nor to know the complex underlying data schemas. Most of\nexisting methods focus on answering snapshot keyword queries in static\ndatabases. In practice, however, databases are updated frequently, and users\nmay have long-term interests on specific topics. To deal with such a situation,\nit is necessary to build effective and efficient facility in database systems\nto support continual keyword queries evaluation.\n  In this paper, we propose an efficient method for continual keyword queries\nanswering over relational databases. The proposed method consists of two core\nalgorithms. The first one computes a set of potential top-$k$ results by\nevaluating the ranges of the future relevance score for every query result and\ncreate a light-weight state for each keyword query. The second one uses these\nstates to maintain the top-$k$ results of keyword queries when the database is\ncontinually growing. Experimental results validate the effectiveness and\nefficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2011 12:50:48 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2011 18:28:41 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Xu", "Yanwei", ""]]}, {"id": "1103.2681", "submitter": "Sebastian Bernhardsson", "authors": "Sebastian Bernhardsson, Seung Ki Baek and Petter Minnhagen", "title": "A Paradoxical Property of the Monkey Book", "comments": "5 pages, 4 figures", "journal-ref": "J. Stat. Mech. (2011) P07013", "doi": "10.1088/1742-5468/2011/07/P07013", "report-no": null, "categories": "physics.data-an cond-mat.stat-mech cs.CL cs.IR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A \"monkey book\" is a book consisting of a random distribution of letters and\nblanks, where a group of letters surrounded by two blanks is defined as a word.\nWe compare the statistics of the word distribution for a monkey book with the\ncorresponding distribution for the general class of random books, where the\nlatter are books for which the words are randomly distributed. It is shown that\nthe word distribution statistics for the monkey book is different and quite\ndistinct from a typical sampled book or real book. In particular the monkey\nbook obeys Heaps' power law to an extraordinary good approximation, in contrast\nto the word distributions for sampled and real books, which deviate from Heaps'\nlaw in a characteristics way. The somewhat counter-intuitive conclusion is that\na \"monkey book\" obeys Heaps' power law precisely because its word-frequency\ndistribution is not a smooth power law, contrary to the expectation based on\nsimple mathematical arguments that if one is a power law, so is the other.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2011 14:54:10 GMT"}], "update_date": "2011-09-09", "authors_parsed": [["Bernhardsson", "Sebastian", ""], ["Baek", "Seung Ki", ""], ["Minnhagen", "Petter", ""]]}, {"id": "1103.2756", "submitter": "Xinmei Tian", "authors": "Xinmei Tian and Dacheng Tao and Yong Rui", "title": "Sparse Transfer Learning for Interactive Video Search Reranking", "comments": "17 pages", "journal-ref": null, "doi": "10.1145/0000000.0000000", "report-no": null, "categories": "cs.IR cs.CV cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual reranking is effective to improve the performance of the text-based\nvideo search. However, existing reranking algorithms can only achieve limited\nimprovement because of the well-known semantic gap between low level visual\nfeatures and high level semantic concepts. In this paper, we adopt interactive\nvideo search reranking to bridge the semantic gap by introducing user's\nlabeling effort. We propose a novel dimension reduction tool, termed sparse\ntransfer learning (STL), to effectively and efficiently encode user's labeling\ninformation. STL is particularly designed for interactive video search\nreranking. Technically, it a) considers the pair-wise discriminative\ninformation to maximally separate labeled query relevant samples from labeled\nquery irrelevant ones, b) achieves a sparse representation for the subspace to\nencodes user's intention by applying the elastic net penalty, and c) propagates\nuser's labeling information from labeled samples to unlabeled samples by using\nthe data distribution knowledge. We conducted extensive experiments on the\nTRECVID 2005, 2006 and 2007 benchmark datasets and compared STL with popular\ndimension reduction algorithms. We report superior performance by using the\nproposed STL based interactive video search reranking.\n", "versions": [{"version": "v1", "created": "Mon, 14 Mar 2011 19:48:20 GMT"}, {"version": "v2", "created": "Tue, 15 Mar 2011 03:49:33 GMT"}, {"version": "v3", "created": "Wed, 21 Dec 2011 00:12:42 GMT"}], "update_date": "2011-12-22", "authors_parsed": [["Tian", "Xinmei", ""], ["Tao", "Dacheng", ""], ["Rui", "Yong", ""]]}, {"id": "1103.2832", "submitter": "Yoshua Bengio", "authors": "Michael Mandel, Razvan Pascanu, Hugo Larochelle and Yoshua Bengio", "title": "Autotagging music with conditional restricted Boltzmann machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes two applications of conditional restricted Boltzmann\nmachines (CRBMs) to the task of autotagging music. The first consists of\ntraining a CRBM to predict tags that a user would apply to a clip of a song\nbased on tags already applied by other users. By learning the relationships\nbetween tags, this model is able to pre-process training data to significantly\nimprove the performance of a support vector machine (SVM) autotagging. The\nsecond is the use of a discriminative RBM, a type of CRBM, to autotag music. By\nsimultaneously exploiting the relationships among tags and between tags and\naudio-based features, this model is able to significantly outperform SVMs,\nlogistic regression, and multi-layer perceptrons. In order to be applied to\nthis problem, the discriminative RBM was generalized to the multi-label setting\nand four different learning algorithms for it were evaluated, the first such\nin-depth analysis of which we are aware.\n", "versions": [{"version": "v1", "created": "Tue, 15 Mar 2011 02:39:31 GMT"}], "update_date": "2011-03-16", "authors_parsed": [["Mandel", "Michael", ""], ["Pascanu", "Razvan", ""], ["Larochelle", "Hugo", ""], ["Bengio", "Yoshua", ""]]}, {"id": "1103.2886", "submitter": "Pavel Sirotkin", "authors": "Pavel Sirotkin", "title": "Predicting User Preferences", "comments": null, "journal-ref": "Information und Wissen: global, sozial und frei? Proceedings des\n  12. Internationalen Symposiums f\\\"ur Informationswissenschaft. Joachim\n  Griesbaum, Thomas Mandl, Christa Womser-Hacker (Editors). VWH, Boizenburg,\n  2011. Pages 24-35", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The many metrics employed for the evaluation of search engine results have\nnot themselves been conclusively evaluated. We propose a new measure for a\nmetric's ability to identify user preference of result lists. Using this\nmeasure, we evaluate the metrics Discounted Cumulated Gain, Mean Average\nPrecision and classical precision, finding that the former performs best. We\nalso show that considering more results for a given query can impair rather\nthan improve a metric's ability to predict user preferences.\n", "versions": [{"version": "v1", "created": "Tue, 15 Mar 2011 11:48:30 GMT"}], "update_date": "2011-03-16", "authors_parsed": [["Sirotkin", "Pavel", ""]]}, {"id": "1103.2903", "submitter": "Finn {\\AA}rup Nielsen", "authors": "Finn {\\AA}rup Nielsen", "title": "A new ANEW: Evaluation of a word list for sentiment analysis in\n  microblogs", "comments": "6 pages, 4 figures, 1 table, Submitted to \"Making Sense of Microposts\n  (#MSM2011)\"", "journal-ref": "Proceedings of the ESWC2011 Workshop on 'Making Sense of\n  Microposts': Big things come in small packages (2011) 93-98", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Sentiment analysis of microblogs such as Twitter has recently gained a fair\namount of attention. One of the simplest sentiment analysis approaches compares\nthe words of a posting against a labeled word list, where each word has been\nscored for valence, -- a 'sentiment lexicon' or 'affective word lists'. There\nexist several affective word lists, e.g., ANEW (Affective Norms for English\nWords) developed before the advent of microblogging and sentiment analysis. I\nwanted to examine how well ANEW and other word lists performs for the detection\nof sentiment strength in microblog posts in comparison with a new word list\nspecifically constructed for microblogs. I used manually labeled postings from\nTwitter scored for sentiment. Using a simple word matching I show that the new\nword list may perform better than ANEW, though not as good as the more\nelaborate approach found in SentiStrength.\n", "versions": [{"version": "v1", "created": "Tue, 15 Mar 2011 13:39:20 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Nielsen", "Finn \u00c5rup", ""]]}, {"id": "1103.3585", "submitter": "Fredrik Sandin", "authors": "Fredrik Sandin, Blerim Emruli, Magnus Sahlgren", "title": "Incremental dimension reduction of tensors with random index", "comments": "36 pages, 9 figures", "journal-ref": "Revised version published in Knowl. Inf. Syst. 2016 (Open Access)", "doi": "10.1007/s10115-016-1012-2", "report-no": null, "categories": "cs.DS cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an incremental, scalable and efficient dimension reduction\ntechnique for tensors that is based on sparse random linear coding. Data is\nstored in a compactified representation with fixed size, which makes memory\nrequirements low and predictable. Component encoding and decoding are performed\non-line without computationally expensive re-analysis of the data set. The\nrange of tensor indices can be extended dynamically without modifying the\ncomponent representation. This idea originates from a mathematical model of\nsemantic memory and a method known as random indexing in natural language\nprocessing. We generalize the random-indexing algorithm to tensors and present\nsignal-to-noise-ratio simulations for representations of vectors and matrices.\nWe present also a mathematical analysis of the approximate orthogonality of\nhigh-dimensional ternary vectors, which is a property that underpins this and\nother similar random-coding approaches to dimension reduction. To further\ndemonstrate the properties of random indexing we present results of a synonym\nidentification task. The method presented here has some similarities with\nrandom projection and Tucker decomposition, but it performs well at high\ndimensionality only (n>10^3). Random indexing is useful for a range of complex\npractical problems, e.g., in natural language processing, data mining, pattern\nrecognition, event detection, graph searching and search engines. Prototype\nsoftware is provided. It supports encoding and decoding of tensors of order >=\n1 in a unified framework, i.e., vectors, matrices and higher order tensors.\n", "versions": [{"version": "v1", "created": "Fri, 18 Mar 2011 10:07:13 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Sandin", "Fredrik", ""], ["Emruli", "Blerim", ""], ["Sahlgren", "Magnus", ""]]}, {"id": "1103.3735", "submitter": "Lihong Li", "authors": "Taesup Moon and Wei Chu and Lihong Li and Zhaohui Zheng and Yi Chang", "title": "Refining Recency Search Results with User Click Feedback", "comments": "22 pages, 9 figures, 1 table. A preliminary and shorter version\n  presented at CIKM-2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional machine-learned ranking systems for web search are often trained\nto capture stationary relevance of documents to queries, which has limited\nability to track non-stationary user intention in a timely manner. In recency\nsearch, for instance, the relevance of documents to a query on breaking news\noften changes significantly over time, requiring effective adaptation to user\nintention. In this paper, we focus on recency search and study a number of\nalgorithms to improve ranking results by leveraging user click feedback. Our\ncontributions are three-fold. First, we use real search sessions collected in a\nrandom exploration bucket for \\emph{reliable} offline evaluation of these\nalgorithms, which provides an unbiased comparison across algorithms without\nonline bucket tests. Second, we propose a re-ranking approach to improve search\nresults for recency queries using user clicks. Third, our empirical comparison\nof a dozen algorithms on real-life search data suggests importance of a few\nalgorithmic choices in these applications, including generalization across\ndifferent query-document pairs, specialization to popular queries, and\nreal-time adaptation of user clicks.\n", "versions": [{"version": "v1", "created": "Sat, 19 Mar 2011 00:08:45 GMT"}], "update_date": "2011-03-22", "authors_parsed": [["Moon", "Taesup", ""], ["Chu", "Wei", ""], ["Li", "Lihong", ""], ["Zheng", "Zhaohui", ""], ["Chang", "Yi", ""]]}, {"id": "1103.3872", "submitter": "Xing Wang", "authors": "Xing M. Wang", "title": "Probability Bracket Notation, Term Vector Space, Concept Fock Space and\n  Induced Probabilistic IR Models", "comments": "23 pages; added a simple example of Bayesian inference; added more\n  test scenarios (e.g., weight formulas); added more references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR math-ph math.MP math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  After a brief introduction to Probability Bracket Notation (PBN) for discrete\nrandom variables in time-independent probability spaces, we apply both PBN and\nDirac notation to investigate probabilistic modeling for information retrieval\n(IR). We derive the expressions of relevance of document to query (RDQ) for\nvarious probabilistic models, induced by Term Vector Space (TVS) and by Concept\nFock Space (CFS). The inference network model (INM) formula is symmetric and\ncan be used to evaluate relevance of document to document (RDD); the\nCFS-induced models contain ingredients of all three classical IR models. The\nrelevance formulas are tested and compared on different scenarios against a\nfamous textbook example.\n", "versions": [{"version": "v1", "created": "Sun, 20 Mar 2011 18:29:57 GMT"}, {"version": "v2", "created": "Sun, 19 Jun 2011 23:07:42 GMT"}], "update_date": "2011-06-21", "authors_parsed": [["Wang", "Xing M.", ""]]}, {"id": "1103.4090", "submitter": "Luis Rocha", "authors": "An\\'alia Louren\\c{c}o, Michael Conover, Andrew Wong, Azadeh\n  Nematzadeh, Fengxia Pan, Hagit Shatkay, Luis M. Rocha", "title": "A Linear Classifier Based on Entity Recognition Tools and a Statistical\n  Approach to Method Extraction in the Protein-Protein Interaction Literature", "comments": "BMC Bioinformatics. In Press", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We participated, in the Article Classification and the Interaction Method\nsubtasks (ACT and IMT, respectively) of the Protein-Protein Interaction task of\nthe BioCreative III Challenge. For the ACT, we pursued an extensive testing of\navailable Named Entity Recognition and dictionary tools, and used the most\npromising ones to extend our Variable Trigonometric Threshold linear\nclassifier. For the IMT, we experimented with a primarily statistical approach,\nas opposed to employing a deeper natural language processing strategy. Finally,\nwe also studied the benefits of integrating the method extraction approach that\nwe have used for the IMT into the ACT pipeline. For the ACT, our linear article\nclassifier leads to a ranking and classification performance significantly\nhigher than all the reported submissions. For the IMT, our results are\ncomparable to those of other systems, which took very different approaches. For\nthe ACT, we show that the use of named entity recognition tools leads to a\nsubstantial improvement in the ranking and classification of articles relevant\nto protein-protein interaction. Thus, we show that our substantially expanded\nlinear classifier is a very competitive classifier in this domain. Moreover,\nthis classifier produces interpretable surfaces that can be understood as\n\"rules\" for human understanding of the classification. In terms of the IMT\ntask, in contrast to other participants, our approach focused on identifying\nsentences that are likely to bear evidence for the application of a PPI\ndetection method, rather than on classifying a document as relevant to a\nmethod. As BioCreative III did not perform an evaluation of the evidence\nprovided by the system, we have conducted a separate assessment; the evaluators\nagree that our tool is indeed effective in detecting relevant evidence for PPI\ndetection methods.\n", "versions": [{"version": "v1", "created": "Mon, 21 Mar 2011 17:33:32 GMT"}, {"version": "v2", "created": "Fri, 22 Apr 2011 17:46:37 GMT"}], "update_date": "2011-04-25", "authors_parsed": [["Louren\u00e7o", "An\u00e1lia", ""], ["Conover", "Michael", ""], ["Wong", "Andrew", ""], ["Nematzadeh", "Azadeh", ""], ["Pan", "Fengxia", ""], ["Shatkay", "Hagit", ""], ["Rocha", "Luis M.", ""]]}, {"id": "1103.5002", "submitter": "David Vallet David Vallet", "authors": "Blaz Fortuna, Dunja Mladenic, Marko Grobelnik", "title": "User Modeling Combining Access Logs, Page Content and Semantics", "comments": "1st International Workshop on Usage Analysis and the Web of Data\n  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),\n  Hyderabad, India, March 28th, 2011", "journal-ref": null, "doi": null, "report-no": "WWW2011USEWOD/2011/formlagro", "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes an approach to modeling users of large Web sites based on\ncombining different data sources: access logs and content of the accessed pages\nare combined with semantic information about the Web pages, the users and the\naccesses of the users to the Web site. The assumption is that we are dealing\nwith a large Web site providing content to a large number of users accessing\nthe site. The proposed approach represents each user by a set of features\nderived from the different data sources, where some feature values may be\nmissing for some users. It further enables user modeling based on the provided\ncharacteristics of the targeted user subset. The approach is evaluated on\nreal-world data where we compare performance of the automatic assignment of a\nuser to a predefined user segment when different data sources are used to\nrepresent the users.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 15:49:03 GMT"}], "update_date": "2011-03-28", "authors_parsed": [["Fortuna", "Blaz", ""], ["Mladenic", "Dunja", ""], ["Grobelnik", "Marko", ""]]}, {"id": "1103.5043", "submitter": "David Vallet David Vallet", "authors": "Mario Arias, Javier D. Fern\\'andez, Miguel A. Mart\\'inez-Prieto, Pablo\n  de la Fuente", "title": "An Empirical Study of Real-World SPARQL Queries", "comments": "1st International Workshop on Usage Analysis and the Web of Data\n  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),\n  Hyderabad, India, March 28th, 2011", "journal-ref": null, "doi": null, "report-no": "WWW2011USEWOD/2011/arifermarfue", "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how users tailor their SPARQL queries is crucial when designing\nquery evaluation engines or fine-tuning RDF stores with performance in mind. In\nthis paper we analyze 3 million real-world SPARQL queries extracted from logs\nof the DBPedia and SWDF public endpoints. We aim at finding which are the most\nused language elements both from syntactical and structural perspectives,\npaying special attention to triple patterns and joins, since they are indeed\nsome of the most expensive SPARQL operations at evaluation phase. We have\ndetermined that most of the queries are simple and include few triple patterns\nand joins, being Subject-Subject, Subject-Object and Object-Object the most\ncommon join types. The graph patterns are usually star-shaped and despite\ntriple pattern chains exist, they are generally short.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 17:43:17 GMT"}], "update_date": "2011-03-28", "authors_parsed": [["Arias", "Mario", ""], ["Fern\u00e1ndez", "Javier D.", ""], ["Mart\u00ednez-Prieto", "Miguel A.", ""], ["de la Fuente", "Pablo", ""]]}, {"id": "1103.5044", "submitter": "David Vallet David Vallet", "authors": "Ashish Sureka", "title": "Mining User Comment Activity for Detecting Forum Spammers in YouTube", "comments": "1st International Workshop on Usage Analysis and the Web of Data\n  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),\n  Hyderabad, India, March 28th, 2011", "journal-ref": null, "doi": null, "report-no": "WWW2011USEWOD/2011/sur", "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research shows that comment spamming (comments which are unsolicited,\nunrelated, abusive, hateful, commercial advertisements etc) in online\ndiscussion forums has become a common phenomenon in Web 2.0 applications and\nthere is a strong need to counter or combat comment spamming. We present a\nmethod to automatically detect comment spammer in YouTube (largest and a\npopular video sharing website) forums. The proposed technique is based on\nmining comment activity log of a user and extracting patterns (such as time\ninterval between subsequent comments, presence of exactly same comment across\nmultiple unrelated videos) indicating spam behavior. We perform empirical\nanalysis on data crawled from YouTube and demonstrate that the proposed method\nis effective for the task of comment spammer detection.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 17:45:46 GMT"}], "update_date": "2011-03-28", "authors_parsed": [["Sureka", "Ashish", ""]]}, {"id": "1103.5046", "submitter": "David Vallet David Vallet", "authors": "Markus Kirchberg, Ryan K L Ko, Bu Sung Lee", "title": "From Linked Data to Relevant Data -- Time is the Essence", "comments": "1st International Workshop on Usage Analysis and the Web of Data\n  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),\n  Hyderabad, India, March 28th, 2011", "journal-ref": null, "doi": null, "report-no": "WWW2011USEWOD/2011/kirkolee", "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Semantic Web initiative puts emphasis not primarily on putting data on\nthe Web, but rather on creating links in a way that both humans and machines\ncan explore the Web of data. When such users access the Web, they leave a trail\nas Web servers maintain a history of requests. Web usage mining approaches have\nbeen studied since the beginning of the Web given the log's huge potential for\npurposes such as resource annotation, personalization, forecasting etc.\nHowever, the impact of any such efforts has not really gone beyond generating\nstatistics detailing who, when, and how Web pages maintained by a Web server\nwere visited.\n", "versions": [{"version": "v1", "created": "Fri, 25 Mar 2011 17:48:57 GMT"}], "update_date": "2011-04-07", "authors_parsed": [["Kirchberg", "Markus", ""], ["Ko", "Ryan K L", ""], ["Lee", "Bu Sung", ""]]}, {"id": "1103.5120", "submitter": "Zi-Ke Zhang Mr.", "authors": "Tao Zhou, Matus Medo, Giulio Cimini, Zi-Ke Zhang, Yi-Cheng Zhang", "title": "Emergence of scale-free leadership structure in social recommender\n  systems", "comments": null, "journal-ref": "PLoS ONE 6(7): e20648 (2011)", "doi": "10.1371/journal.pone.0020648", "report-no": null, "categories": "physics.soc-ph cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The study of the organization of social networks is important for\nunderstanding of opinion formation, rumor spreading, and the emergence of\ntrends and fashion. This paper reports empirical analysis of networks extracted\nfrom four leading sites with social functionality (Delicious, Flickr, Twitter\nand YouTube) and shows that they all display a scale-free leadership structure.\nTo reproduce this feature, we propose an adaptive network model driven by\nsocial recommending. Artificial agent-based simulations of this model highlight\na \"good get richer\" mechanism where users with broad interests and good\njudgments are likely to become popular leaders for the others. Simulations also\nindicate that the studied social recommendation mechanism can gradually improve\nthe user experience by adapting to tastes of its users. Finally we outline\nimplications for real online resource-sharing systems.\n", "versions": [{"version": "v1", "created": "Sat, 26 Mar 2011 11:03:21 GMT"}, {"version": "v2", "created": "Thu, 28 Apr 2011 05:35:51 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Zhou", "Tao", ""], ["Medo", "Matus", ""], ["Cimini", "Giulio", ""], ["Zhang", "Zi-Ke", ""], ["Zhang", "Yi-Cheng", ""]]}, {"id": "1103.5231", "submitter": "Yeung Chi Ho", "authors": "Linyuan Lu, Yi-Cheng Zhang, Chi Ho Yeung, Tao Zhou", "title": "Leaders in Social Networks, the Delicious Case", "comments": "14 pages, 6 figures, with supporting information", "journal-ref": "PLoS ONE 6(6): e21202 (2011)", "doi": "10.1371/journal.pone.0021202", "report-no": null, "categories": "physics.soc-ph cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding pertinent information is not limited to search engines. Online\ncommunities can amplify the influence of a small number of power users for the\nbenefit of all other users. Users' information foraging in depth and breadth\ncan be greatly enhanced by choosing suitable leaders. For instance in\ndelicious.com, users subscribe to leaders' collection which lead to a deeper\nand wider reach not achievable with search engines. To consolidate such\ncollective search, it is essential to utilize the leadership topology and\nidentify influential users. Google's PageRank, as a successful search algorithm\nin the World Wide Web, turns out to be less effective in networks of people. We\nthus devise an adaptive and parameter-free algorithm, the LeaderRank, to\nquantify user influence. We show that LeaderRank outperforms PageRank in terms\nof ranking effectiveness, as well as robustness against manipulations and noisy\ndata. These results suggest that leaders who are aware of their clout may\nreinforce the development of social networks, and thus the power of collective\nsearch.\n", "versions": [{"version": "v1", "created": "Sun, 27 Mar 2011 16:18:58 GMT"}], "update_date": "2011-07-01", "authors_parsed": [["Lu", "Linyuan", ""], ["Zhang", "Yi-Cheng", ""], ["Yeung", "Chi Ho", ""], ["Zhou", "Tao", ""]]}]