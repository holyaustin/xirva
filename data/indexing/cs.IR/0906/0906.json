[{"id": "0906.0080", "submitter": "L.T. Handoko", "authors": "Z. Akbar and L.T. Handoko", "title": "Reverse method for labeling the information from semi-structured web\n  pages", "comments": "5 pages, Proceeding of the 2009 International Conference on Signal\n  Processing Systems pp. 551-555", "journal-ref": null, "doi": "10.1109/ICSPS.2009.86", "report-no": "FISIKALIPI-09017", "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new technique to infer the structure and extract the tokens of\ndata from the semi-structured web sources which are generated using a\nconsistent template or layout with some implicit regularities. The attributes\nare extracted and labeled reversely from the region of interest of targeted\ncontents. This is in contrast with the existing techniques which always\ngenerate the trees from the root. We argue and show that our technique is\nsimpler, more accurate and effective especially to detect the changes of the\ntemplates of targeted web pages.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2009 14:22:04 GMT"}, {"version": "v2", "created": "Thu, 6 Aug 2009 17:36:09 GMT"}], "update_date": "2009-08-06", "authors_parsed": [["Akbar", "Z.", ""], ["Handoko", "L. T.", ""]]}, {"id": "0906.0231", "submitter": "Kimikazu Kato", "authors": "Kimikazu Kato and Tikara Hosino", "title": "Solving $k$-Nearest Neighbor Problem on Multiple Graphics Processors", "comments": "5 pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS cs.NE", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The recommendation system is a software system to predict customers' unknown\npreferences from known preferences. In the recommendation system, customers'\npreferences are encoded into vectors, and finding the nearest vectors to each\nvector is an essential part. This vector-searching part of the problem is\ncalled a $k$-nearest neighbor problem. We give an effective algorithm to solve\nthis problem on multiple graphics processor units (GPUs).\n  Our algorithm consists of two parts: an $N$-body problem and a partial sort.\nFor a algorithm of the $N$-body problem, we applied the idea of a known\nalgorithm for the $N$-body problem in physics, although another trick is need\nto overcome the problem of small sized shared memory. For the partial sort, we\ngive a novel GPU algorithm which is effective for small $k$. In our partial\nsort algorithm, a heap is accessed in parallel by threads with a low cost of\nsynchronization. Both of these two parts of our algorithm utilize maximal power\nof coalesced memory access, so that a full bandwidth is achieved.\n  By an experiment, we show that when the size of the problem is large, an\nimplementation of the algorithm on two GPUs runs more than 330 times faster\nthan a single core implementation on a latest CPU. We also show that our\nalgorithm scales well with respect to the number of GPUs.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2009 08:14:13 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2009 06:48:21 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2010 02:23:22 GMT"}], "update_date": "2010-07-16", "authors_parsed": [["Kato", "Kimikazu", ""], ["Hosino", "Tikara", ""]]}, {"id": "0906.0612", "submitter": "Santo Fortunato Dr", "authors": "Santo Fortunato", "title": "Community detection in graphs", "comments": "Review article. 103 pages, 42 figures, 2 tables. Two sections\n  expanded + minor modifications. Three figures + one table + references added.\n  Final version published in Physics Reports", "journal-ref": "Physics Reports 486, 75-174 (2010)", "doi": "10.1016/j.physrep.2009.11.002", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.IR physics.bio-ph physics.comp-ph q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modern science of networks has brought significant advances to our\nunderstanding of complex systems. One of the most relevant features of graphs\nrepresenting real systems is community structure, or clustering, i. e. the\norganization of vertices in clusters, with many edges joining vertices of the\nsame cluster and comparatively few edges joining vertices of different\nclusters. Such clusters, or communities, can be considered as fairly\nindependent compartments of a graph, playing a similar role like, e. g., the\ntissues or the organs in the human body. Detecting communities is of great\nimportance in sociology, biology and computer science, disciplines where\nsystems are often represented as graphs. This problem is very hard and not yet\nsatisfactorily solved, despite the huge effort of a large interdisciplinary\ncommunity of scientists working on it over the past few years. We will attempt\na thorough exposition of the topic, from the definition of the main elements of\nthe problem, to the presentation of most methods developed, with a special\nfocus on techniques designed by statistical physicists, from the discussion of\ncrucial issues like the significance of clustering and how methods should be\ntested and compared against each other, to the description of applications to\nreal networks.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2009 10:20:48 GMT"}, {"version": "v2", "created": "Mon, 25 Jan 2010 14:53:31 GMT"}], "update_date": "2010-09-17", "authors_parsed": [["Fortunato", "Santo", ""]]}, {"id": "0906.0684", "submitter": "Chris Giannella", "authors": "Chris Giannella", "title": "New Instability Results for High Dimensional Nearest Neighbor Search", "comments": null, "journal-ref": "Information Processing Letters 109(19), 2009.", "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a dataset of n(d) points generated independently from R^d according\nto a common p.d.f. f_d with support(f_d) = [0,1]^d and sup{f_d([0,1]^d)}\ngrowing sub-exponentially in d. We prove that: (i) if n(d) grows\nsub-exponentially in d, then, for any query point q^d in [0,1]^d and any\nepsilon>0, the ratio of the distance between any two dataset points and q^d is\nless that 1+epsilon with probability -->1 as d-->infinity; (ii) if\nn(d)>[4(1+epsilon)]^d for large d, then for all q^d in [0,1]^d (except a small\nsubset) and any epsilon>0, the distance ratio is less than 1+epsilon with\nlimiting probability strictly bounded away from one. Moreover, we provide\npreliminary results along the lines of (i) when f_d=N(mu_d,Sigma_d).\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2009 15:13:12 GMT"}], "update_date": "2009-09-01", "authors_parsed": [["Giannella", "Chris", ""]]}, {"id": "0906.1148", "submitter": "Tao Zhou", "authors": "Ming-Sheng Shang, Ci-Hang Jin, Tao Zhou, Yi-Cheng Zhang", "title": "Collaborative filtering based on multi-channel diffusion", "comments": "9 pages, 3 figures", "journal-ref": "Physica A 388 (2009) 4867-4871", "doi": "10.1016/j.physa.2009.08.011", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, by applying a diffusion process, we propose a new index to\nquantify the similarity between two users in a user-object bipartite graph. To\ndeal with the discrete ratings on objects, we use a multi-channel\nrepresentation where each object is mapped to several channels with the number\nof channels being equal to the number of different ratings. Each channel\nrepresents a certain rating and a user having voted an object will be connected\nto the channel corresponding to the rating. Diffusion process taking place on\nsuch a user-channel bipartite graph gives a new similarity measure of user\npairs, which is further demonstrated to be more accurate than the classical\nPearson correlation coefficient under the standard collaborative filtering\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2009 15:32:47 GMT"}], "update_date": "2009-09-05", "authors_parsed": [["Shang", "Ming-Sheng", ""], ["Jin", "Ci-Hang", ""], ["Zhou", "Tao", ""], ["Zhang", "Yi-Cheng", ""]]}, {"id": "0906.2459", "submitter": "Vit Niennattrakul", "authors": "Vit Niennattrakul, Pongsakorn Ruengronghirunya, Chotirat Ann\n  Ratanamahatana", "title": "Exact Indexing for Massive Time Series Databases under Time Warping\n  Distance", "comments": "Submitted to Data Mining and Knowledge Discovery (DMKD). 33 pages, 19\n  figures, and 8 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Among many existing distance measures for time series data, Dynamic Time\nWarping (DTW) distance has been recognized as one of the most accurate and\nsuitable distance measures due to its flexibility in sequence alignment.\nHowever, DTW distance calculation is computationally intensive. Especially in\nvery large time series databases, sequential scan through the entire database\nis definitely impractical, even with random access that exploits some index\nstructures since high dimensionality of time series data incurs extremely high\nI/O cost. More specifically, a sequential structure consumes high CPU but low\nI/O costs, while an index structure requires low CPU but high I/O costs. In\nthis work, we therefore propose a novel indexed sequential structure called\nTWIST (Time Warping in Indexed Sequential sTructure) which benefits from both\nsequential access and index structure. When a query sequence is issued, TWIST\ncalculates lower bounding distances between a group of candidate sequences and\nthe query sequence, and then identifies the data access order in advance, hence\nreducing a great number of both sequential and random accesses. Impressively,\nour indexed sequential structure achieves significant speedup in a querying\nprocess by a few orders of magnitude. In addition, our method shows superiority\nover existing rival methods in terms of query processing time, number of page\naccesses, and storage requirement with no false dismissal guaranteed.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2009 09:07:05 GMT"}], "update_date": "2009-06-16", "authors_parsed": [["Niennattrakul", "Vit", ""], ["Ruengronghirunya", "Pongsakorn", ""], ["Ratanamahatana", "Chotirat Ann", ""]]}, {"id": "0906.2835", "submitter": "Mikhail (Mike) Basilyan", "authors": "Mikhail Basilyan", "title": "Employing Wikipedia's Natural Intelligence For Cross Language\n  Information Retrieval", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a novel method for retrieving information in\nlanguages other than that of the query. We use this technique in combination\nwith existing traditional Cross Language Information Retrieval (CLIR)\ntechniques to improve their results. This method has a number of advantages\nover traditional techniques that rely on machine translation to translate the\nquery and then search the target document space using a machine translation.\nThis method is not limited to the availability of a machine translation\nalgorithm for the desired language and uses already existing sources of readily\navailable translated information on the internet as a \"middle-man\" approach. In\nthis paper we use Wikipedia; however, any similar multilingual, cross\nreferenced body of documents can be used. For evaluation and comparison\npurposes we also implemented a traditional machine translation approach\nseparately as well as the Wikipedia approach separately.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2009 02:09:27 GMT"}], "update_date": "2009-06-17", "authors_parsed": [["Basilyan", "Mikhail", ""]]}, {"id": "0906.3085", "submitter": "Christine Michel", "authors": "Christine Michel (LIESP, Ictt)", "title": "Poset representation and similarity comparisons os systems in IR", "comments": null, "journal-ref": "26eme conf\\'erence ACM SIGIR, Toronto - Ontario : Canada (2003)", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we are using the poset representation to describe the complex\nanswers given by IR systems after a clustering and ranking processes. The\nanswers considered may be given by cartographical representations or by\nthematic sub-lists of documents. The poset representation, with the graph\ntheory and the relational representation opens many perspectives in the\ndefinition of new similarity measures capable of taking into account both the\nclustering and ranking processes. We present a general method for constructing\nnew similarity measures and give several examples. These measures can be used\nfor semi-ordered partitions; moreover, in the comparison of two sets of\nanswers, the corresponding similarity indicator is an increasing function of\nthe ranks of presentation of common answers.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 07:04:44 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Michel", "Christine", "", "LIESP, Ictt"]]}, {"id": "0906.3112", "submitter": "Panagiotis Papadakos", "authors": "Panagiotis Papadakos, Yannis Theoharis, Yannis Marketakis, Nikos\n  Armenatzoglou and Yannis Tzitzikas", "title": "Object-Relational Database Representations for Text Indexing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the distinctive features of Information Retrieval systems comparing to\nDatabase Management systems, is that they offer better compression for posting\nlists, resulting in better I/O performance and thus faster query evaluation. In\nthis paper, we introduce database representations of the index that reduce the\nsize (and thus the disk I/Os) of the posting lists. This is not achieved by\nredesigning the DBMS, but by exploiting the non 1NF features that existing\nObject-Relational DBM systems (ORDBMS) already offer. Specifically, four\ndifferent database representations are described and detailed experimental\nresults for one million pages are reported. Three of these representations are\none order of magnitude more space efficient and faster (in query evaluation)\nthan the plain relational representation.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2009 13:32:09 GMT"}], "update_date": "2009-06-18", "authors_parsed": [["Papadakos", "Panagiotis", ""], ["Theoharis", "Yannis", ""], ["Marketakis", "Yannis", ""], ["Armenatzoglou", "Nikos", ""], ["Tzitzikas", "Yannis", ""]]}, {"id": "0906.3585", "submitter": "Arnab Bhattacharya", "authors": "Vishwakarma Singh, Arnab Bhattacharya, Ambuj K. Singh", "title": "Finding Significant Subregions in Large Image Databases", "comments": "16 pages, 48 figures", "journal-ref": "Extending Database Technology (EDBT) 2010", "doi": null, "report-no": null, "categories": "cs.DB cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Images have become an important data source in many scientific and commercial\ndomains. Analysis and exploration of image collections often requires the\nretrieval of the best subregions matching a given query. The support of such\ncontent-based retrieval requires not only the formulation of an appropriate\nscoring function for defining relevant subregions but also the design of new\naccess methods that can scale to large databases. In this paper, we propose a\nsolution to this problem of querying significant image subregions. We design a\nscoring scheme to measure the similarity of subregions. Our similarity measure\nextends to any image descriptor. All the images are tiled and each alignment of\nthe query and a database image produces a tile score matrix. We show that the\nproblem of finding the best connected subregion from this matrix is NP-hard and\ndevelop a dynamic programming heuristic. With this heuristic, we develop two\nindex based scalable search strategies, TARS and SPARS, to query patterns in a\nlarge image repository. These strategies are general enough to work with other\nscoring schemes and heuristics. Experimental results on real image datasets\nshow that TARS saves more than 87% query time on small queries, and SPARS saves\nup to 52% query time on large queries as compared to linear search. Qualitative\ntests on synthetic and real datasets achieve precision of more than 80%.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2009 06:57:51 GMT"}], "update_date": "2010-03-09", "authors_parsed": [["Singh", "Vishwakarma", ""], ["Bhattacharya", "Arnab", ""], ["Singh", "Ambuj K.", ""]]}, {"id": "0906.3741", "submitter": "Lillian Lee", "authors": "Cristian Danescu-Niculescu-Mizil, Gueorgi Kossinets, Jon Kleinberg,\n  Lillian Lee", "title": "How opinions are received by online communities: A case study on\n  Amazon.com helpfulness votes", "comments": null, "journal-ref": "Proceedings of WWW, pp. 141--150, 2009", "doi": null, "report-no": null, "categories": "cs.CL cs.IR physics.data-an physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many on-line settings in which users publicly express opinions. A\nnumber of these offer mechanisms for other users to evaluate these opinions; a\ncanonical example is Amazon.com, where reviews come with annotations like \"26\nof 32 people found the following review helpful.\" Opinion evaluation appears in\nmany off-line settings as well, including market research and political\ncampaigns. Reasoning about the evaluation of an opinion is fundamentally\ndifferent from reasoning about the opinion itself: rather than asking, \"What\ndid Y think of X?\", we are asking, \"What did Z think of Y's opinion of X?\" Here\nwe develop a framework for analyzing and modeling opinion evaluation, using a\nlarge-scale collection of Amazon book reviews as a dataset. We find that the\nperceived helpfulness of a review depends not just on its content but also but\nalso in subtle ways on how the expressed evaluation relates to other\nevaluations of the same product. As part of our approach, we develop novel\nmethods that take advantage of the phenomenon of review \"plagiarism\" to control\nfor the effects of text in opinion evaluation, and we provide a simple and\nnatural mathematical model consistent with our findings. Our analysis also\nallows us to distinguish among the predictions of competing theories from\nsociology and social psychology, and to discover unexpected differences in the\ncollective opinion-evaluation behavior of user populations from different\ncountries.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2009 01:59:21 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Danescu-Niculescu-Mizil", "Cristian", ""], ["Kossinets", "Gueorgi", ""], ["Kleinberg", "Jon", ""], ["Lee", "Lillian", ""]]}, {"id": "0906.4026", "submitter": "Benjamin Piwowarski", "authors": "B. Piwowarski, M. Lalmas", "title": "A Quantum-based Model for Interactive Information Retrieval (extended\n  version)", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even the best information retrieval model cannot always identify the most\nuseful answers to a user query. This is in particular the case with web search\nsystems, where it is known that users tend to minimise their effort to access\nrelevant information. It is, however, believed that the interaction between\nusers and a retrieval system, such as a web search engine, can be exploited to\nprovide better answers to users. Interactive Information Retrieval (IR)\nsystems, in which users access information through a series of interactions\nwith the search system, are concerned with building models for IR, where\ninteraction plays a central role. There are many possible interactions between\na user and a search system, ranging from query (re)formulation to relevance\nfeedback. However, capturing them within a single framework is difficult and\npreviously proposed approaches have mostly focused on relevance feedback. In\nthis paper, we propose a general framework for interactive IR that is able to\ncapture the full interaction process in a principled way. Our approach relies\nupon a generalisation of the probability framework of quantum physics, whose\nstrong geometric component can be a key towards a successful interactive IR\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2009 16:17:36 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2009 09:11:19 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["Piwowarski", "B.", ""], ["Lalmas", "M.", ""]]}, {"id": "0906.4044", "submitter": "Don Conry", "authors": "Don Conry, Yehuda Koren, Naren Ramakrishnan", "title": "Recommender Systems for the Conference Paper Assignment Problem", "comments": "8 pages, 5 figures, submitted to the ACM Conference on Recommender\n  Systems 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conference paper assignment, i.e., the task of assigning paper submissions to\nreviewers, presents multi-faceted issues for recommender systems research.\nBesides the traditional goal of predicting `who likes what?', a conference\nmanagement system must take into account aspects such as: reviewer capacity\nconstraints, adequate numbers of reviews for papers, expertise modeling,\nconflicts of interest, and an overall distribution of assignments that balances\nreviewer preferences with conference objectives. Among these, issues of\nmodeling preferences and tastes in reviewing have traditionally been studied\nseparately from the optimization of paper-reviewer assignment. In this paper,\nwe present an integrated study of both these aspects. First, due to the paucity\nof data per reviewer or per paper (relative to other recommender systems\napplications) we show how we can integrate multiple sources of information to\nlearn paper-reviewer preference models. Second, our models are evaluated not\njust in terms of prediction accuracy but in terms of the end-assignment\nquality. Using a linear programming-based assignment optimization formulation,\nwe show how our approach better explores the space of unsupplied assignments to\nmaximize the overall affinities of papers assigned to reviewers. We demonstrate\nour results on real reviewer preference data from the IEEE ICDM 2007\nconference.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2009 17:26:24 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["Conry", "Don", ""], ["Koren", "Yehuda", ""], ["Ramakrishnan", "Naren", ""]]}, {"id": "0906.4690", "submitter": "R Doomun", "authors": "Ladda Suanmali, Naomie Salim and Mohammed Salem Binwahlan", "title": "Fuzzy Logic Based Method for Improving Text Summarization", "comments": "6 pages, International Journal of Computer Science and Information\n  Security (IJCSIS)", "journal-ref": "IJCSIS June 2009 Issue, Vol. 2, No. 1", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text summarization can be classified into two approaches: extraction and\nabstraction. This paper focuses on extraction approach. The goal of text\nsummarization based on extraction approach is sentence selection. One of the\nmethods to obtain the suitable sentences is to assign some numerical measure of\na sentence for the summary called sentence weighting and then select the best\nones. The first step in summarization by extraction is the identification of\nimportant features. In our experiment, we used 125 test documents in DUC2002\ndata set. Each document is prepared by preprocessing process: sentence\nsegmentation, tokenization, removing stop word, and word stemming. Then, we use\n8 important features and calculate their score for each sentence. We propose\ntext summarization based on fuzzy logic to improve the quality of the summary\ncreated by the general statistic method. We compare our results with the\nbaseline summarizer and Microsoft Word 2007 summarizers. The results show that\nthe best average precision, recall, and f-measure for the summaries were\nobtained by fuzzy method.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2009 13:19:07 GMT"}], "update_date": "2009-06-26", "authors_parsed": [["Suanmali", "Ladda", ""], ["Salim", "Naomie", ""], ["Binwahlan", "Mohammed Salem", ""]]}, {"id": "0906.4982", "submitter": "Dmitry Ignatov", "authors": "Dmitry I. Ignatov, Sergei O. Kuznetsov", "title": "Concept-based Recommendations for Internet Advertisement", "comments": "D.I.Ignatov, S.O. Kuznetsov. Concept-based Recommendations for\n  Internet Advertisement//In proceedings of The Sixth International Conference\n  Concept Lattices and Their Applications (CLA'08), Olomouc, Czech Republic,\n  2008 ISBN 978-80-244-2111-7", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of detecting terms that can be interesting to the advertiser is\nconsidered. If a company has already bought some advertising terms which\ndescribe certain services, it is reasonable to find out the terms bought by\ncompeting companies. A part of them can be recommended as future advertising\nterms to the company. The goal of this work is to propose better interpretable\nrecommendations based on FCA and association rules.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2009 17:26:05 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Ignatov", "Dmitry I.", ""], ["Kuznetsov", "Sergei O.", ""]]}, {"id": "0906.5017", "submitter": "Tao Zhou", "authors": "Ming-Sheng Shang, Zi-Ke Zhang, Tao Zhou, Yi-Cheng Zhang", "title": "Collaborative filtering with diffusion-based similarity on tripartite\n  graphs", "comments": "8 pages, 4 figures, 1 table", "journal-ref": "Physica A 389 (2010) 1259-1264", "doi": "10.1016/j.physa.2009.11.041", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative tags are playing more and more important role for the\norganization of information systems. In this paper, we study a personalized\nrecommendation model making use of the ternary relations among users, objects\nand tags. We propose a measure of user similarity based on his preference and\ntagging information. Two kinds of similarities between users are calculated by\nusing a diffusion-based process, which are then integrated for recommendation.\nWe test the proposed method in a standard collaborative filtering framework\nwith three metrics: ranking score, Recall and Precision, and demonstrate that\nit performs better than the commonly used cosine similarity.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2009 23:01:47 GMT"}, {"version": "v2", "created": "Sat, 17 Oct 2009 14:50:14 GMT"}], "update_date": "2009-12-28", "authors_parsed": [["Shang", "Ming-Sheng", ""], ["Zhang", "Zi-Ke", ""], ["Zhou", "Tao", ""], ["Zhang", "Yi-Cheng", ""]]}, {"id": "0906.5034", "submitter": "R Doomun", "authors": "Anshika Pal, Deepak Singh Tomar, S.C. Shrivastava", "title": "Effective Focused Crawling Based on Content and Link Structure Analysis", "comments": "5 Pages, International Journal of Computer Science and Information\n  Security (IJCSIS)", "journal-ref": "IJCSIS June 2009 Issue, Vol. 2, No. 1", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A focused crawler traverses the web selecting out relevant pages to a\npredefined topic and neglecting those out of concern. While surfing the\ninternet it is difficult to deal with irrelevant pages and to predict which\nlinks lead to quality pages. In this paper a technique of effective focused\ncrawling is implemented to improve the quality of web navigation. To check the\nsimilarity of web pages w.r.t. topic keywords a similarity function is used and\nthe priorities of extracted out links are also calculated based on meta data\nand resultant pages generated from focused crawler. The proposed work also uses\na method for traversing the irrelevant pages that met during crawling to\nimprove the coverage of a specific topic.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2009 03:50:59 GMT"}], "update_date": "2009-06-30", "authors_parsed": [["Pal", "Anshika", ""], ["Tomar", "Deepak Singh", ""], ["Shrivastava", "S. C.", ""]]}, {"id": "0906.5286", "submitter": "Yifan Hu", "authors": "Emden Gansner, Yifan Hu, Stephen Kobourov, Chris Volinsky", "title": "Putting Recommendations on the Map -- Visualizing Clusters and Relations", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For users, recommendations can sometimes seem odd or counterintuitive.\nVisualizing recommendations can remove some of this mystery, showing how a\nrecommendation is grouped with other choices. A drawing can also lead a user's\neye to other options. Traditional 2D-embeddings of points can be used to create\na basic layout, but these methods, by themselves, do not illustrate clusters\nand neighborhoods very well. In this paper, we propose the use of geographic\nmaps to enhance the definition of clusters and neighborhoods, and consider the\neffectiveness of this approach in visualizing similarities and recommendations\narising from TV shows and music selections. All the maps referenced in this\npaper can be found in http://www.research.att.com/~volinsky/maps\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2009 15:00:43 GMT"}], "update_date": "2009-06-30", "authors_parsed": [["Gansner", "Emden", ""], ["Hu", "Yifan", ""], ["Kobourov", "Stephen", ""], ["Volinsky", "Chris", ""]]}, {"id": "0906.5608", "submitter": "Saqib Saeed", "authors": "Saqib Saeed, Christoph Kunz", "title": "Loading Arbitrary Knowledge Bases in Matrix Browser", "comments": "This paper was published in the proceedings of IEEE International\n  Multi Topic Conference (INMIC 2004) Lahore, Pakistan 24th- 26th December 2004", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the work done on Matrix Browser, which is a recently\ndeveloped graphical user interface to explore and navigate complex networked\ninformation spaces. This approach presents a new way of navigating information\nnets in windows explorer like widget. The problem on hand was how to export\narbitrary knowledge bases in Matrix Browser. This was achieved by identifying\nthe relationships present in knowledge bases and then by forming the\nhierarchies from this data and these hierarchies are being exported to matrix\nbrowser. This paper gives solution to this problem and informs about\nimplementation work.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2009 18:42:59 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Saeed", "Saqib", ""], ["Kunz", "Christoph", ""]]}]