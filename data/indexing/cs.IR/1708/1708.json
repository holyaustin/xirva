[{"id": "1708.00120", "submitter": "Himan Abdollahpouri", "authors": "Himan Abdollahpouri, Steve Essinger", "title": "Multiple Stakeholders in Music Recommender Systems", "comments": "Included in the 2017 Workshop on Value-Aware and Multistakeholder\n  Recommendation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music recommendation services collectively spin billions of songs for\nmillions of listeners on a daily basis. Users can typically listen to a variety\nof songs tailored to their personal tastes and preferences. Music is not the\nonly type of content encountered in these services, however. Advertisements are\ngenerally interspersed throughout the music stream to generate revenue for the\nbusiness. Additional content may include artist messaging, ticketing, sports,\nnews and weather. In this paper, we discuss issues that arise when multiple\ncontent providers are stakeholders in the recommendation process. These\nstakeholders each have their own objectives and must work in concert to sustain\na healthy music recommendation service.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 01:14:41 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Abdollahpouri", "Himan", ""], ["Essinger", "Steve", ""]]}, {"id": "1708.00130", "submitter": "Theodore Vasiloudis", "authors": "Theodore Vasiloudis, Hossein Vahabi, Ross Kravitz, Valery Rashkov", "title": "Predicting Session Length in Media Streaming", "comments": "4 pages, 3 figures", "journal-ref": "Proceedings of the 40th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR 2017). ACM, New\n  York, NY, USA, 977-980", "doi": "10.1145/3077136.3080695", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session length is a very important aspect in determining a user's\nsatisfaction with a media streaming service. Being able to predict how long a\nsession will last can be of great use for various downstream tasks, such as\nrecommendations and ad scheduling. Most of the related literature on user\ninteraction duration has focused on dwell time for websites, usually in the\ncontext of approximating post-click satisfaction either in search results, or\ndisplay ads. In this work we present the first analysis of session length in a\nmobile-focused online service, using a real world data-set from a major music\nstreaming service. We use survival analysis techniques to show that the\ncharacteristics of the length distributions can differ significantly between\nusers, and use gradient boosted trees with appropriate objectives to predict\nthe length of a session using only information available at its beginning. Our\nevaluation on real world data illustrates that our proposed technique\noutperforms the considered baseline.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 02:15:52 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Vasiloudis", "Theodore", ""], ["Vahabi", "Hossein", ""], ["Kravitz", "Ross", ""], ["Rashkov", "Valery", ""]]}, {"id": "1708.00154", "submitter": "Piji Li", "authors": "Piji Li, Zihao Wang, Zhaochun Ren, Lidong Bing, Wai Lam", "title": "Neural Rating Regression with Abstractive Tips Generation for\n  Recommendation", "comments": "SIGIR 2017", "journal-ref": null, "doi": "10.1145/3077136.3080822", "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, some E-commerce sites launch a new interaction box called Tips on\ntheir mobile apps. Users can express their experience and feelings or provide\nsuggestions using short texts typically several words or one sentence. In\nessence, writing some tips and giving a numerical rating are two facets of a\nuser's product assessment action, expressing the user experience and feelings.\nJointly modeling these two facets is helpful for designing a better\nrecommendation system. While some existing models integrate text information\nsuch as item specifications or user reviews into user and item latent factors\nfor improving the rating prediction, no existing works consider tips for\nimproving recommendation quality. We propose a deep learning based framework\nnamed NRT which can simultaneously predict precise ratings and generate\nabstractive tips with good linguistic quality simulating user experience and\nfeelings. For abstractive tips generation, gated recurrent neural networks are\nemployed to \"translate\" user and item latent representations into a concise\nsentence. Extensive experiments on benchmark datasets from different domains\nshow that NRT achieves significant improvements over the state-of-the-art\nmethods. Moreover, the generated tips can vividly predict the user experience\nand feelings.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 04:25:17 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Li", "Piji", ""], ["Wang", "Zihao", ""], ["Ren", "Zhaochun", ""], ["Bing", "Lidong", ""], ["Lam", "Wai", ""]]}, {"id": "1708.00192", "submitter": "Jorge Lloret-Gazo", "authors": "Jorge Lloret-Gazo", "title": "A Survey on Visual Query Systems in the Web Era (extended version)", "comments": "34 pages. 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more and more collections of data are becoming available on the web to\neveryone, non expert users demand easy ways to retrieve data from these\ncollections. One solution is the so called Visual Query Systems (VQS) where\nqueries are represented visually and users do not have to understand query\nlanguages such as SQL or XQuery. In 1996, a paper by Catarci reviewed the\nVisual Query Systems available until that year. In this paper, we review VQSs\nfrom 1997 until now and try to determine whether they have been the solution\nfor non expert users. The short answer is no because very few systems have in\nfact been used in real environments or as commercial tools. We have also\ngathered basic features of VQSs such as the visual representation adopted to\npresent the reality of interest or the visual representation adopted to express\nqueries.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 07:37:16 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Lloret-Gazo", "Jorge", ""]]}, {"id": "1708.00247", "submitter": "Hiteshwar Azad", "authors": "Hiteshwar Kumar Azad, Akshay Deepak", "title": "Query expansion techniques for information retrieval: A survey", "comments": "43 pages, 5 figures, 10 tables", "journal-ref": "Information Processing & Management, 2019", "doi": "10.1016/j.ipm.2019.05.009", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever increasing size of the web, relevant information extraction on\nthe Internet with a query formed by a few keywords has become a big challenge.\nQuery Expansion (QE) plays a crucial role in improving searches on the\nInternet. Here, the user's initial query is reformulated by adding additional\nmeaningful terms with similar significance. QE -- as part of information\nretrieval (IR) -- has long attracted researchers' attention. It has become very\ninfluential in the field of personalized social document, question answering,\ncross-language IR, information filtering and multimedia IR. Research in QE has\ngained further prominence because of IR dedicated conferences such as TREC\n(Text Information Retrieval Conference) and CLEF (Conference and Labs of the\nEvaluation Forum). This paper surveys QE techniques in IR from 1960 to 2017\nwith respect to core techniques, data sources used, weighting and ranking\nmethodologies, user participation and applications -- bringing out similarities\nand differences.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 11:04:53 GMT"}, {"version": "v2", "created": "Thu, 20 Jun 2019 10:51:03 GMT"}], "update_date": "2019-06-21", "authors_parsed": [["Azad", "Hiteshwar Kumar", ""], ["Deepak", "Akshay", ""]]}, {"id": "1708.00417", "submitter": "Elham Shahab", "authors": "Maryam Nayebzadeh, Akbar Moazzam, Amir Mohammad Saba, Hadi\n  Abdolrahimpour, Elham Shahab", "title": "An Investigation on Social Network Recommender Systems and Collaborative\n  Filtering Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, with the remarkable expansion of the information through the\ninternet, users prefer to receive the exact information that they need through\nsome suggestions from their friends or profiles to save their time and money.\nRecommend systems based on different algorithms as one of the basic ways to\nreach this goal through the internet have been proposed but each of them has\ntheir own advantages and disadvantages. In this study, we have selected and\nimplemented two approaches which are Collaborative Filtering (CF) and Social\nNetwork Recommendations System (SNRS). Based on some limitations to finding a\ndataset which covers friendship, rating and item categories we generated it for\n10 categories, 10 items, and 100 users and compared two approaches. We used\nMean Absolute Error (MAE) and accuracy to compare the result of two mentioned\napproaches and found that the SNRS method as it is claimed to be improved\nversion of CF works more efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 17:07:05 GMT"}], "update_date": "2017-08-02", "authors_parsed": [["Nayebzadeh", "Maryam", ""], ["Moazzam", "Akbar", ""], ["Saba", "Amir Mohammad", ""], ["Abdolrahimpour", "Hadi", ""], ["Shahab", "Elham", ""]]}, {"id": "1708.00481", "submitter": "Hidekazu Oiwa", "authors": "Hidekazu Oiwa, Yoshihiko Suhara, Jiyu Komiya, Andrei Lopatenko", "title": "A Lightweight Front-end Tool for Interactive Entity Population", "comments": "ICML Workshop on Interactive Machine Learning", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity population, a task of collecting entities that belong to a particular\ncategory, has attracted attention from vertical domains. There is still a high\ndemand for creating entity dictionaries in vertical domains, which are not\ncovered by existing knowledge bases. We develop a lightweight front-end tool\nfor facilitating interactive entity population. We implement key components\nnecessary for effective interactive entity population: 1) GUI-based dashboards\nto quickly modify an entity dictionary, and 2) entity highlighting on documents\nfor quickly viewing the current progress. We aim to reduce user cost from\nbeginning to end, including package installation and maintenance. The\nimplementation enables users to use this tool on their web browsers without any\nadditional packages --- users can focus on their missions to create entity\ndictionaries. Moreover, an entity expansion module is implemented as external\nAPIs. This design makes it easy to continuously improve interactive entity\npopulation pipelines. We are making our demo publicly available\n(http://bit.ly/luwak-demo).\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 19:27:02 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Oiwa", "Hidekazu", ""], ["Suhara", "Yoshihiko", ""], ["Komiya", "Jiyu", ""], ["Lopatenko", "Andrei", ""]]}, {"id": "1708.00651", "submitter": "Phong Nguyen", "authors": "Phong Nguyen, John Dines and Jan Krasnodebski", "title": "A Multi-Objective Learning to re-Rank Approach to Optimize Online\n  Marketplaces for Multiple Stakeholders", "comments": "Presented at the 2017 Workshop on Value-Aware and Multistakeholder\n  Recommendation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-objective recommender systems address the difficult task of\nrecommending items that are relevant to multiple, possibly conflicting,\ncriteria. However these systems are most often designed to address the\nobjective of one single stakeholder, typically, in online commerce, the\nconsumers whose input and purchasing decisions ultimately determine the success\nof the recommendation systems. In this work, we address the multi-objective,\nmulti-stakeholder, recommendation problem involving one or more objective(s)\nper stakeholder. In addition to the consumer stakeholder, we also consider two\nother stakeholders; the suppliers who provide the goods and services for sale\nand the intermediary who is responsible for helping connect consumers to\nsuppliers via its recommendation algorithms. We analyze the multi-objective,\nmulti-stakeholder, problem from the point of view of the online marketplace\nintermediary whose objective is to maximize its commission through its\nrecommender system. We define a multi-objective problem relating all our three\nstakeholders which we solve with a novel learning-to-re-rank approach that\nmakes use of a novel regularization function based on the Kendall tau\ncorrelation metric and its kernel version; given an initial ranking of item\nrecommendations built for the consumer, we aim to re-rank it such that the new\nranking is also optimized for the secondary objectives while staying close to\nthe initial ranking. We evaluate our approach on a real-world dataset of hotel\nrecommendations provided by Expedia where we show the effectiveness of our\napproach against a business-rules oriented baseline model.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 08:54:07 GMT"}, {"version": "v2", "created": "Thu, 3 Aug 2017 02:35:09 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Nguyen", "Phong", ""], ["Dines", "John", ""], ["Krasnodebski", "Jan", ""]]}, {"id": "1708.00733", "submitter": "Andreas Arzt", "authors": "Andreas Arzt and Gerhard Widmer", "title": "Piece Identification in Classical Piano Music Without Reference Scores", "comments": "In Proceedings of the 18th International Society for Music\n  Information Retrieval Conference (ISMIR 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe an approach to identify the name of a piece of\npiano music, based on a short audio excerpt of a performance. Given only a\ndescription of the pieces in text format (i.e. no score information is\nprovided), a reference database is automatically compiled by acquiring a number\nof audio representations (performances of the pieces) from internet sources.\nThese are transcribed, preprocessed, and used to build a reference database via\na robust symbolic fingerprinting algorithm, which in turn is used to identify\nnew, incoming queries. The main challenge is the amount of noise that is\nintroduced into the identification process by the music transcription algorithm\nand the automatic (but possibly suboptimal) choice of performances to represent\na piece in the reference database. In a number of experiments we show how to\nimprove the identification performance by increasing redundancy in the\nreference database and by using a preprocessing step to rate the reference\nperformances regarding their suitability as a representation of the pieces in\nquestion. As the results show this approach leads to a robust system that is\nable to identify piano music with high accuracy -- without any need for data\nannotation or manual data preparation.\n", "versions": [{"version": "v1", "created": "Wed, 2 Aug 2017 13:07:11 GMT"}], "update_date": "2017-08-03", "authors_parsed": [["Arzt", "Andreas", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1708.01060", "submitter": "Etienne Papegnies", "authors": "Etienne Papegnies (LIA), Vincent Labatut (LIA), Richard Dufour (LIA),\n  Georges Linares (LIA)", "title": "Graph-based Features for Automatic Online Abuse Detection", "comments": null, "journal-ref": "5th International Conference on Statistical Language and Speech\n  Processing (SLSP), 2017, Le Mans (FR), Lecture Notes in Artificial\n  Intelligence vol.10583, p.70-81", "doi": "10.1007/978-3-319-68456-7_6", "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While online communities have become increasingly important over the years,\nthe moderation of user-generated content is still performed mostly manually.\nAutomating this task is an important step in reducing the financial cost\nassociated with moderation, but the majority of automated approaches strictly\nbased on message content are highly vulnerable to intentional obfuscation. In\nthis paper, we discuss methods for extracting conversational networks based on\nraw multi-participant chat logs, and we study the contribution of graph\nfeatures to a classification system that aims to determine if a given message\nis abusive. The conversational graph-based system yields unexpectedly high\nperformance , with results comparable to those previously obtained with a\ncontent-based approach.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 09:06:25 GMT"}], "update_date": "2017-10-17", "authors_parsed": [["Papegnies", "Etienne", "", "LIA"], ["Labatut", "Vincent", "", "LIA"], ["Dufour", "Richard", "", "LIA"], ["Linares", "Georges", "", "LIA"]]}, {"id": "1708.01162", "submitter": "Alex Olieman", "authors": "Alex Olieman, Kaspar Beelen, Milan van Lange, Jaap Kamps, and Maarten\n  Marx", "title": "Good Applications for Crummy Entity Linkers? The Case of Corpus\n  Selection in Digital Humanities", "comments": "Accepted for presentation at SEMANTiCS '17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade we have made great progress in entity linking (EL)\nsystems, but performance may vary depending on the context and, arguably, there\nare even principled limitations preventing a \"perfect\" EL system. This also\nsuggests that there may be applications for which current \"imperfect\" EL is\nalready very useful, and makes finding the \"right\" application as important as\nbuilding the \"right\" EL system. We investigate the Digital Humanities use case,\nwhere scholars spend a considerable amount of time selecting relevant source\ntexts. We developed WideNet; a semantically-enhanced search tool which\nleverages the strengths of (imperfect) EL without getting in the way of its\nexpert users. We evaluate this tool in two historical case-studies aiming to\ncollect a set of references to historical periods in parliamentary debates from\nthe last two decades; the first targeted the Dutch Golden Age, and the second\nWorld War II. The case-studies conclude with a critical reflection on the\nutility of WideNet for this kind of research, after which we outline how such a\nreal-world application can help to improve EL technology in general.\n", "versions": [{"version": "v1", "created": "Thu, 3 Aug 2017 14:35:53 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Olieman", "Alex", ""], ["Beelen", "Kaspar", ""], ["van Lange", "Milan", ""], ["Kamps", "Jaap", ""], ["Marx", "Maarten", ""]]}, {"id": "1708.01856", "submitter": "Iman Tahamtan", "authors": "Shahram Sedghi, Zeinab Shourmeij, Iman Tahamtan", "title": "Exploring the context of visual information seeking", "comments": "18 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information seeking is an interactive behaviour of the end users with\ninformation systems, which occurs in a real environment known as context.\nContext affects information-seeking behaviour in many different ways. The\npurpose of this paper is to investigate the factors that potentially constitute\nthe context of visual information seeking. We used a Straussian version of\ngrounded theory, a qualitative approach, to conduct the study. Using a\npurposive sampling method, 28 subjects participated in the study. The data were\nanalysed using open, axial and selective coding in MAXQDA software. The\ncontextual factors influencing visual information seeking were classified into\nseven categories, including: user characteristics, general search features,\nvisual search features, display of results, accessibility of results, task type\nand environmental factors. This study contributes to a better understanding of\nhow people conduct searches in and interact with visual search interfaces.\nResults have important implications for the designers of information retrieval\nsystems. This paper is among the pioneer studies investigating contextual\nfactors influencing information seeking in visual information retrieval\nsystems.\n", "versions": [{"version": "v1", "created": "Sun, 6 Aug 2017 07:08:45 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 15:42:06 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Sedghi", "Shahram", ""], ["Shourmeij", "Zeinab", ""], ["Tahamtan", "Iman", ""]]}, {"id": "1708.02062", "submitter": "Naama Kraus", "authors": "Naama Kraus, David Carmel, Idit Keidar", "title": "Fishing in the Stream: Similarity Search over Endless Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity search is the task of retrieving data items that are similar to a\ngiven query. In this paper, we introduce the time-sensitive notion of\nsimilarity search over endless data-streams (SSDS), which takes into account\ndata quality and temporal characteristics in addition to similarity. SSDS is\nchallenging as it needs to process unbounded data, while computation resources\nare bounded. We propose Stream-LSH, a randomized SSDS algorithm that bounds the\nindex size by retaining items according to their freshness, quality, and\ndynamic popularity attributes. We analytically show that Stream-LSH increases\nthe probability to find similar items compared to alternative approaches using\nthe same space capacity. We further conduct an empirical study using real world\nstream datasets, which confirms our theoretical results.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 10:42:36 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Kraus", "Naama", ""], ["Carmel", "David", ""], ["Keidar", "Idit", ""]]}, {"id": "1708.02099", "submitter": "Chi Thang Duong", "authors": "Chi Thang Duong, Remi Lebret, Karl Aberer", "title": "Multimodal Classification for Analysing Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Classification of social media data is an important approach in understanding\nuser behavior on the Web. Although information on social media can be of\ndifferent modalities such as texts, images, audio or videos, traditional\napproaches in classification usually leverage only one prominent modality.\nTechniques that are able to leverage multiple modalities are often complex and\nsusceptible to the absence of some modalities. In this paper, we present simple\nmodels that combine information from different modalities to classify social\nmedia content and are able to handle the above problems with existing\ntechniques. Our models combine information from different modalities using a\npooling layer and an auxiliary learning task is used to learn a common feature\nspace. We demonstrate the performance of our models and their robustness to the\nmissing of some modalities in the emotion classification domain. Our\napproaches, although being simple, can not only achieve significantly higher\naccuracies than traditional fusion approaches but also have comparable results\nwhen only one modality is available.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 12:50:09 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Duong", "Chi Thang", ""], ["Lebret", "Remi", ""], ["Aberer", "Karl", ""]]}, {"id": "1708.02210", "submitter": "Qing Ping", "authors": "Qing Ping, Chaomei Chen", "title": "Video Highlights Detection and Summarization with Lag-Calibration based\n  on Concept-Emotion Mapping of Crowd-sourced Time-Sync Comments", "comments": "Accepted in EMNLP 2017 Workshop on New Frontiers in Summarization.\n  Please include \"EMNLP 2017 Workshop on New Frontiers in Summarization\" in any\n  citations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the prevalence of video sharing, there are increasing demands for\nautomatic video digestion such as highlight detection. Recently, platforms with\ncrowdsourced time-sync video comments have emerged worldwide, providing a good\nopportunity for highlight detection. However, this task is non-trivial: (1)\ntime-sync comments often lag behind their corresponding shot; (2) time-sync\ncomments are semantically sparse and noisy; (3) to determine which shots are\nhighlights is highly subjective. The present paper aims to tackle these\nchallenges by proposing a framework that (1) uses concept-mapped lexical-chains\nfor lag calibration; (2) models video highlights based on comment intensity and\ncombination of emotion and concept concentration of each shot; (3) summarize\neach detected highlight using improved SumBasic with emotion and concept\nmapping. Experiments on large real-world datasets show that our highlight\ndetection method and summarization method both outperform other benchmarks with\nconsiderable margins.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 17:21:20 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Ping", "Qing", ""], ["Chen", "Chaomei", ""]]}, {"id": "1708.02238", "submitter": "Hojjat Salehinejad", "authors": "Hojjat Salehinejad, Joseph Barfett, Parham Aarabi, Shahrokh Valaee,\n  Errol Colak, Bruce Gray and Tim Dowdell", "title": "A Convolutional Neural Network for Search Term Detection", "comments": "This paper is accepted for presentation at 2017 IEEE 28th Annual\n  International Symposium on Personal, Indoor, and Mobile Radio Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pathfinding in hospitals is challenging for patients, visitors, and even\nemployees. Many people have experienced getting lost due to lack of clear\nguidance, large footprint of hospitals, and confusing array of hospital wings.\nIn this paper, we propose Halo; An indoor navigation application based on\nvoice-user interaction to help provide directions for users without assistance\nof a localization system. The main challenge is accurate detection of origin\nand destination search terms. A custom convolutional neural network (CNN) is\nproposed to detect origin and destination search terms from transcription of a\nsubmitted speech query. The CNN is trained based on a set of queries tailored\nspecifically for hospital and clinic environments. Performance of the proposed\nmodel is studied and compared with Levenshtein distance-based word matching.\n", "versions": [{"version": "v1", "created": "Mon, 7 Aug 2017 03:37:33 GMT"}, {"version": "v2", "created": "Wed, 9 Aug 2017 05:50:51 GMT"}, {"version": "v3", "created": "Tue, 7 Nov 2017 15:54:20 GMT"}], "update_date": "2017-11-08", "authors_parsed": [["Salehinejad", "Hojjat", ""], ["Barfett", "Joseph", ""], ["Aarabi", "Parham", ""], ["Valaee", "Shahrokh", ""], ["Colak", "Errol", ""], ["Gray", "Bruce", ""], ["Dowdell", "Tim", ""]]}, {"id": "1708.02377", "submitter": "Chengxi Zang", "authors": "Chengxi Zang, Peng Cui, Chaoming Song, Christos Faloutsos and Wenwu\n  Zhu", "title": "Structural patterns of information cascades and their implications for\n  dynamics and semantics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information cascades are ubiquitous in both physical society and online\nsocial media, taking on large variations in structures, dynamics and semantics.\nAlthough the dynamics and semantics of information cascades have been studied,\nthe structural patterns and their correlations with dynamics and semantics are\nlargely unknown. Here we explore a large-scale dataset including $432$ million\ninformation cascades with explicit records of spreading traces, spreading\nbehaviors, information content as well as user profiles. We find that the\nstructural complexity of information cascades is far beyond the previous\nconjectures. We first propose a ten-dimensional metric to quantify the\nstructural characteristics of information cascades, reflecting cascade size,\nsilhouette, direction and activity aspects. We find that bimodal law governs\nmajority of the metrics, information flows in cascades have four directions,\nand the self-loop number and average activity of cascades follows power law. We\nthen analyze the high-order structural patterns of information cascades.\nFinally, we evaluate to what extent the structural features of information\ncascades can explain its dynamic patterns and semantics, and finally uncover\nsome notable implications of structural patterns in information cascades. Our\ndiscoveries also provide a foundation for the microscopic mechanisms for\ninformation spreading, potentially leading to implications for cascade\nprediction and outlier detection.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 05:42:46 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Zang", "Chengxi", ""], ["Cui", "Peng", ""], ["Song", "Chaoming", ""], ["Faloutsos", "Christos", ""], ["Zhu", "Wenwu", ""]]}, {"id": "1708.02417", "submitter": "Elad Yom-Tov", "authors": "Eitan Giat and Elad Yom-Tov", "title": "Evidence from web-based dietary search patterns to the role of B12\n  deficiency in chronic pain", "comments": null, "journal-ref": null, "doi": "10.2196/jmir.8667", "report-no": null, "categories": "cs.IR q-bio.TO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Profound vitamin B12 deficiency is a known cause of disease, but the role of\nlow or intermediate levels of B12 in the development of neuropathy and other\nneuropsychiatric symptoms as well as the relationship of eating meat and B12\nlevels is unclear. Here we use food-related internet search patterns from a\nsample of 8.5 million US-based people as a proxy to B12 intake and correlate\nthese searches with internet searches related to possible effects of B12\ndeficiency. Food-related search patterns are highly correlated with known\nconsumption and food-related searches (Spearman 0.69). Awareness of B12\ndeficiency was associated with a higher consumption of B12-rich foods and with\nqueries for B12 supplements. Searches for terms related to neurological\ndisorders were correlated with searches for B12-poor foods, in contrast with\ncontrol terms. Popular medicines, those having fewer indications, and those\nwhich are predominantly used to treat pain are more strongly correlated with\nthe ability to predict neuropathic pain queries using the B12 contents of food.\nOur findings provide evidence for the utility of using Internet search patterns\nto investigate health questions in large populations and suggest that low B12\nintake may be associated with a broader spectrum of neurological disorders than\ncurrently appreciated.\n", "versions": [{"version": "v1", "created": "Tue, 8 Aug 2017 09:21:11 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Giat", "Eitan", ""], ["Yom-Tov", "Elad", ""]]}, {"id": "1708.02702", "submitter": "Christophe Van Gysel", "authors": "Christophe Van Gysel, Maarten de Rijke and Evangelos Kanoulas", "title": "Neural Vector Spaces for Unsupervised Information Retrieval", "comments": "TOIS 2018", "journal-ref": null, "doi": "10.1145/3196826", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the Neural Vector Space Model (NVSM), a method that learns\nrepresentations of documents in an unsupervised manner for news article\nretrieval. In the NVSM paradigm, we learn low-dimensional representations of\nwords and documents from scratch using gradient descent and rank documents\naccording to their similarity with query representations that are composed from\nword representations. We show that NVSM performs better at document ranking\nthan existing latent semantic vector space methods. The addition of NVSM to a\nmixture of lexical language models and a state-of-the-art baseline vector space\nmodel yields a statistically significant increase in retrieval effectiveness.\nConsequently, NVSM adds a complementary relevance signal. Next to semantic\nmatching, we find that NVSM performs well in cases where lexical matching is\nneeded.\n  NVSM learns a notion of term specificity directly from the document\ncollection without feature engineering. We also show that NVSM learns\nregularities related to Luhn significance. Finally, we give advice on how to\ndeploy NVSM in situations where model selection (e.g., cross-validation) is\ninfeasible. We find that an unsupervised ensemble of multiple models trained\nwith different hyperparameter values performs better than a single\ncross-validated model. Therefore, NVSM can safely be used for ranking documents\nwithout supervised relevance judgments.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 03:21:20 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 14:26:58 GMT"}, {"version": "v3", "created": "Wed, 11 Apr 2018 07:51:23 GMT"}, {"version": "v4", "created": "Sat, 18 Aug 2018 13:44:56 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Van Gysel", "Christophe", ""], ["de Rijke", "Maarten", ""], ["Kanoulas", "Evangelos", ""]]}, {"id": "1708.02765", "submitter": "Pavel Kucherbaev", "authors": "Pavel Kucherbaev, Nava Tintarev, Carlos Rodriguez", "title": "Ephemeral Context to Support Robust and Diverse Music Recommendations", "comments": "3 pages, 1 figure, Machine Learning for Music Discovery workshop at\n  ICML2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While prior work on context-based music recommendation focused on fixed set\nof contexts (e.g. walking, driving, jogging), we propose to use multiple\nsensors and external data sources to describe momentary (ephemeral) context in\na rich way with a very large number of possible states (e.g. jogging fast along\nin downtown of Sydney under a heavy rain at night being tired and angry). With\nour approach, we address the problems which current approaches face: 1) a\nlimited ability to infer context from missing or faulty sensor data; 2) an\ninability to use contextual information to support novel content discovery.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 09:00:03 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Kucherbaev", "Pavel", ""], ["Tintarev", "Nava", ""], ["Rodriguez", "Carlos", ""]]}, {"id": "1708.02867", "submitter": "Mostafa Shehata", "authors": "Mostafa A. Shehata, Mohammad Nassef and Amr A. Badr", "title": "Simulated Annealing with Levy Distribution for Fast Matrix\n  Factorization-Based Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization is one of the best approaches for collaborative\nfiltering, because of its high accuracy in presenting users and items latent\nfactors. The main disadvantages of matrix factorization are its complexity, and\nbeing very hard to be parallelized, specially with very large matrices. In this\npaper, we introduce a new method for collaborative filtering based on Matrix\nFactorization by combining simulated annealing with levy distribution. By using\nthis method, good solutions are achieved in acceptable time with low\ncomputations, compared to other methods like stochastic gradient descent,\nalternating least squares, and weighted non-negative matrix factorization.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 15:14:54 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Shehata", "Mostafa A.", ""], ["Nassef", "Mohammad", ""], ["Badr", "Amr A.", ""]]}, {"id": "1708.02912", "submitter": "Tharindu Weerasooriya", "authors": "Tharindu Weerasooriya, Nandula Perera and S.R. Liyanage", "title": "KeyXtract Twitter Model - An Essential Keywords Extraction Model for\n  Twitter Designed using NLP Tools", "comments": "7 Pages, 5 Figures, Proceedings of the 10th KDU International\n  Research Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since a tweet is limited to 140 characters, it is ambiguous and difficult for\ntraditional Natural Language Processing (NLP) tools to analyse. This research\npresents KeyXtract which enhances the machine learning based Stanford CoreNLP\nPart-of-Speech (POS) tagger with the Twitter model to extract essential\nkeywords from a tweet. The system was developed using rule-based parsers and\ntwo corpora. The data for the research was obtained from a Twitter profile of a\ntelecommunication company. The system development consisted of two stages. At\nthe initial stage, a domain specific corpus was compiled after analysing the\ntweets. The POS tagger extracted the Noun Phrases and Verb Phrases while the\nparsers removed noise and extracted any other keywords missed by the POS\ntagger. The system was evaluated using the Turing Test. After it was tested and\ncompared against Stanford CoreNLP, the second stage of the system was developed\naddressing the shortcomings of the first stage. It was enhanced using Named\nEntity Recognition and Lemmatization. The second stage was also tested using\nthe Turing test and its pass rate increased from 50.00% to 83.33%. The\nperformance of the final system output was measured using the F1 score.\nStanford CoreNLP with the Twitter model had an average F1 of 0.69 while the\nimproved system had a F1 of 0.77. The accuracy of the system could be improved\nby using a complete domain specific corpus. Since the system used linguistic\nfeatures of a sentence, it could be applied to other NLP tools.\n", "versions": [{"version": "v1", "created": "Wed, 9 Aug 2017 17:04:34 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Weerasooriya", "Tharindu", ""], ["Perera", "Nandula", ""], ["Liyanage", "S. R.", ""]]}, {"id": "1708.03052", "submitter": "Lee Gao", "authors": "Lee Gao, Ronghuo Zheng", "title": "Communication-Free Parallel Supervised Topic Models", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embarrassingly (communication-free) parallel Markov chain Monte Carlo (MCMC)\nmethods are commonly used in learning graphical models. However, MCMC cannot be\ndirectly applied in learning topic models because of the quasi-ergodicity\nproblem caused by multimodal distribution of topics. In this paper, we develop\nan embarrassingly parallel MCMC algorithm for sLDA. Our algorithm works by\nswitching the order of sampled topics combination and labeling variable\nprediction in sLDA, in which it overcomes the quasi-ergodicity problem because\nhigh-dimension topics that follow a multimodal distribution are projected into\none-dimension document labels that follow a unimodal distribution. Our\nempirical experiments confirm that the out-of-sample prediction performance\nusing our embarrassingly parallel algorithm is comparable to non-parallel sLDA\nwhile the computation time is significantly reduced.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 02:03:52 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Gao", "Lee", ""], ["Zheng", "Ronghuo", ""]]}, {"id": "1708.03058", "submitter": "Qing Wang", "authors": "Qing Wang, Chunqiu Zeng, Wubai Zhou, Tao Li, Larisa Shwartz, Genady\n  Ya. Grabarnik", "title": "Online Interactive Collaborative Filtering Using Multi-Armed Bandit with\n  Dependent Arms", "comments": "Recommender systems; Interactive collaborative filtering; Topic\n  modeling; Cold-start problem; Particle learning; 10 pages", "journal-ref": null, "doi": "10.1109/TKDE.2018.2866041", "report-no": "18795315", "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online interactive recommender systems strive to promptly suggest to\nconsumers appropriate items (e.g., movies, news articles) according to the\ncurrent context including both the consumer and item content information.\nHowever, such context information is often unavailable in practice for the\nrecommendation, where only the users' interaction data on items can be\nutilized. Moreover, the lack of interaction records, especially for new users\nand items, worsens the performance of recommendation further. To address these\nissues, collaborative filtering (CF), one of the recommendation techniques\nrelying on the interaction data only, as well as the online multi-armed bandit\nmechanisms, capable of achieving the balance between exploitation and\nexploration, are adopted in the online interactive recommendation settings, by\nassuming independent items (i.e., arms). Nonetheless, the assumption rarely\nholds in reality, since the real-world items tend to be correlated with each\nother (e.g., two articles with similar topics). In this paper, we study online\ninteractive collaborative filtering problems by considering the dependencies\namong items. We explicitly formulate the item dependencies as the clusters on\narms, where the arms within a single cluster share the similar latent topics.\nIn light of the topic modeling techniques, we come up with a generative model\nto generate the items from their underlying topics. Furthermore, an efficient\nonline algorithm based on particle learning is developed for inferring both\nlatent parameters and states of our model. Additionally, our inferred model can\nbe naturally integrated with existing multi-armed selection strategies in the\nonline interactive collaborating setting. Empirical studies on two real-world\napplications, online recommendations of movies and news, demonstrate both the\neffectiveness and efficiency of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 02:52:57 GMT"}, {"version": "v2", "created": "Fri, 11 Aug 2017 23:13:10 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Qing", ""], ["Zeng", "Chunqiu", ""], ["Zhou", "Wubai", ""], ["Li", "Tao", ""], ["Shwartz", "Larisa", ""], ["Grabarnik", "Genady Ya.", ""]]}, {"id": "1708.03181", "submitter": "Ben He", "authors": "Chenhao Yang, Ben He, Yanhua Ran", "title": "Utilizing Embeddings for Ad-hoc Retrieval by Document-to-document\n  Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent semantic representations of words or paragraphs, namely the\nembeddings, have been widely applied to information retrieval (IR). One of the\ncommon approaches of utilizing embeddings for IR is to estimate the\ndocument-to-query (D2Q) similarity in their embeddings. As words with similar\nsyntactic usage are usually very close to each other in the embeddings space,\nalthough they are not semantically similar, the D2Q similarity approach may\nsuffer from the problem of \"multiple degrees of similarity\". To this end, this\npaper proposes a novel approach that estimates a semantic relevance score (SEM)\nbased on document-to-document (D2D) similarity of embeddings. As Word or\nPara2Vec generates embeddings by the context of words/paragraphs, the D2D\nsimilarity approach turns the task of document ranking into the estimation of\nsimilarity between content within different documents. Experimental results on\nstandard TREC test collections show that our proposed approach outperforms\nstrong baselines.\n", "versions": [{"version": "v1", "created": "Thu, 10 Aug 2017 12:33:25 GMT"}], "update_date": "2017-08-11", "authors_parsed": [["Yang", "Chenhao", ""], ["He", "Ben", ""], ["Ran", "Yanhua", ""]]}, {"id": "1708.03418", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Sascha Rothe, Enrique Alfonseca, Pascal Fleury", "title": "Learning to Attend, Copy, and Generate for Session-Based Query\n  Suggestion", "comments": "Accepted to be published at The 26th ACM International Conference on\n  Information and Knowledge Management (CIKM2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users try to articulate their complex information needs during search\nsessions by reformulating their queries. To make this process more effective,\nsearch engines provide related queries to help users in specifying the\ninformation need in their search process. In this paper, we propose a\ncustomized sequence-to-sequence model for session-based query suggestion. In\nour model, we employ a query-aware attention mechanism to capture the structure\nof the session context. is enables us to control the scope of the session from\nwhich we infer the suggested next query, which helps not only handle the noisy\ndata but also automatically detect session boundaries. Furthermore, we observe\nthat, based on the user query reformulation behavior, within a single session a\nlarge portion of query terms is retained from the previously submitted queries\nand consists of mostly infrequent or unseen terms that are usually not included\nin the vocabulary. We therefore empower the decoder of our model to access the\nsource words from the session context during decoding by incorporating a copy\nmechanism. Moreover, we propose evaluation metrics to assess the quality of the\ngenerative models for query suggestion. We conduct an extensive set of\nexperiments and analysis. e results suggest that our model outperforms the\nbaselines both in terms of the generating queries and scoring candidate queries\nfor the task of query suggestion.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 00:55:57 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 12:02:09 GMT"}, {"version": "v3", "created": "Tue, 19 Sep 2017 10:43:53 GMT"}, {"version": "v4", "created": "Mon, 13 Nov 2017 11:29:43 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Rothe", "Sascha", ""], ["Alfonseca", "Enrique", ""], ["Fleury", "Pascal", ""]]}, {"id": "1708.03436", "submitter": "Suthee Chaidaroon", "authors": "Suthee Chaidaroon and Yi Fang", "title": "Variational Deep Semantic Hashing for Text Documents", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the amount of textual data has been rapidly increasing over the past\ndecade, efficient similarity search methods have become a crucial component of\nlarge-scale information retrieval systems. A popular strategy is to represent\noriginal data samples by compact binary codes through hashing. A spectrum of\nmachine learning methods have been utilized, but they often lack expressiveness\nand flexibility in modeling to learn effective representations. The recent\nadvances of deep learning in a wide range of applications has demonstrated its\ncapability to learn robust and powerful feature representations for complex\ndata. Especially, deep generative models naturally combine the expressiveness\nof probabilistic generative models with the high capacity of deep neural\nnetworks, which is very suitable for text modeling. However, little work has\nleveraged the recent progress in deep learning for text hashing.\n  In this paper, we propose a series of novel deep document generative models\nfor text hashing. The first proposed model is unsupervised while the second one\nis supervised by utilizing document labels/tags for hashing. The third model\nfurther considers document-specific factors that affect the generation of\nwords. The probabilistic generative formulation of the proposed models provides\na principled framework for model extension, uncertainty estimation, simulation,\nand interpretability. Based on variational inference and reparameterization,\nthe proposed models can be interpreted as encoder-decoder deep neural networks\nand thus they are capable of learning complex nonlinear distributed\nrepresentations of the original documents. We conduct a comprehensive set of\nexperiments on four public testbeds. The experimental results have demonstrated\nthe effectiveness of the proposed supervised learning models for text hashing.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 05:19:04 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Chaidaroon", "Suthee", ""], ["Fang", "Yi", ""]]}, {"id": "1708.03569", "submitter": "Erich Schubert", "authors": "Erich Schubert and Andreas Spitz and Michael Weiler and Johanna\n  Gei{\\ss} and Michael Gertz", "title": "Semantic Word Clouds with Background Corpus Normalization and\n  t-distributed Stochastic Neighbor Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many word clouds provide no semantics to the word placement, but use a random\nlayout optimized solely for aesthetic purposes. We propose a novel approach to\nmodel word significance and word affinity within a document, and in comparison\nto a large background corpus. We demonstrate its usefulness for generating more\nmeaningful word clouds as a visual summary of a given document. We then select\nkeywords based on their significance and construct the word cloud based on the\nderived affinity. Based on a modified t-distributed stochastic neighbor\nembedding (t-SNE), we generate a semantic word placement. For words that\ncooccur significantly, we include edges, and cluster the words according to\ntheir cooccurrence. For this we designed a scalable and memory-efficient\nsketch-based approach usable on commodity hardware to aggregate the required\ncorpus statistics needed for normalization, and for identifying keywords as\nwell as significant cooccurences. We empirically validate our approch using a\nlarge Wikipedia corpus.\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 15:19:53 GMT"}], "update_date": "2017-08-14", "authors_parsed": [["Schubert", "Erich", ""], ["Spitz", "Andreas", ""], ["Weiler", "Michael", ""], ["Gei\u00df", "Johanna", ""], ["Gertz", "Michael", ""]]}, {"id": "1708.03658", "submitter": "Bin Liu", "authors": "Xu He, Bin Liu, Ke-Jia Chen", "title": "iTrace: An Implicit Trust Inference Method for Trust-aware Collaborative\n  Filtering", "comments": "6 pages, 4 figures, 1 table", "journal-ref": null, "doi": "10.1063/1.5033766", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of Internet commerce has stimulated the use of collaborative\nfiltering (CF) algorithms as recommender systems. A collaborative filtering\n(CF) algorithm recommends items of interest to the target user by leveraging\nthe votes given by other similar users. In a standard CF framework, it is\nassumed that the credibility of every voting user is exactly the same with\nrespect to the target user. This assumption is not satisfied and thus may lead\nto misleading recommendations in many practical applications. A natural\ncountermeasure is to design a trust-aware CF (TaCF) algorithm, which can take\naccount of the difference in the credibilities of the voting users when\nperforming CF. To this end, this paper presents a trust inference approach,\nwhich can predict the implicit trust of the target user on every voting user\nfrom a sparse explicit trust matrix. Then an improved CF algorithm termed\niTrace is proposed, which takes advantage of both the explicit and the\npredicted implicit trust to provide recommendations with the CF framework. An\nempirical evaluation on a public dataset demonstrates that the proposed\nalgorithm provides a significant improvement in recommendation quality in terms\nof mean absolute error (MAE).\n", "versions": [{"version": "v1", "created": "Fri, 11 Aug 2017 18:41:16 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 04:16:39 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["He", "Xu", ""], ["Liu", "Bin", ""], ["Chen", "Ke-Jia", ""]]}, {"id": "1708.03797", "submitter": "Zhenghua Xu", "authors": "Zhenghua Xu, Cheng Chen, Thomas Lukasiewicz, Yishu Miao", "title": "Hybrid Deep-Semantic Matrix Factorization for Tag-Aware Personalized\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization has now become a dominant solution for personalized\nrecommendation on the Social Web. To alleviate the cold start problem, previous\napproaches have incorporated various additional sources of information into\ntraditional matrix factorization models. These upgraded models, however,\nachieve only \"marginal\" enhancements on the performance of personalized\nrecommendation. Therefore, inspired by the recent development of deep-semantic\nmodeling, we propose a hybrid deep-semantic matrix factorization (HDMF) model\nto further improve the performance of tag-aware personalized recommendation by\nintegrating the techniques of deep-semantic modeling, hybrid learning, and\nmatrix factorization. Experimental results show that HDMF significantly\noutperforms the state-of-the-art baselines in tag-aware personalized\nrecommendation, in terms of all evaluation metrics, e.g., its mean reciprocal\nrank (resp., mean average precision) is 1.52 (resp., 1.66) times as high as\nthat of the best baseline.\n", "versions": [{"version": "v1", "created": "Sat, 12 Aug 2017 17:06:28 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Xu", "Zhenghua", ""], ["Chen", "Cheng", ""], ["Lukasiewicz", "Thomas", ""], ["Miao", "Yishu", ""]]}, {"id": "1708.03940", "submitter": "Tao Yu", "authors": "Tao Yu, Christopher Hidey, Owen Rambow and Kathleen McKeown", "title": "Leveraging Sparse and Dense Feature Combinations for Sentiment\n  Classification", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks are one of the most popular approaches for many natural\nlanguage processing tasks such as sentiment analysis. They often outperform\ntraditional machine learning models and achieve the state-of-art results on\nmost tasks. However, many existing deep learning models are complex, difficult\nto train and provide a limited improvement over simpler methods. We propose a\nsimple, robust and powerful model for sentiment classification. This model\noutperforms many deep learning models and achieves comparable results to other\ndeep learning models with complex architectures on sentiment analysis datasets.\nWe publish the code online.\n", "versions": [{"version": "v1", "created": "Sun, 13 Aug 2017 17:38:17 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Yu", "Tao", ""], ["Hidey", "Christopher", ""], ["Rambow", "Owen", ""], ["McKeown", "Kathleen", ""]]}, {"id": "1708.03993", "submitter": "Yan Yan", "authors": "Yan Yan, Wentao Guo, Meng Zhao, Jinghe Hu and Weipeng P. Yan", "title": "Optimizing Gross Merchandise Volume via DNN-MAB Dynamic Ranking Paradigm", "comments": "7 pages, 7 figures, accepted by 'IJCAI-17 Workshop AI Applications in\n  E-Commerce'", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the transition from people's traditional `brick-and-mortar' shopping to\nonline mobile shopping patterns in web 2.0 $\\mathit{era}$, the recommender\nsystem plays a critical role in E-Commerce and E-Retails. This is especially\ntrue when designing this system for more than $\\mathbf{236~million}$ daily\nactive users. Ranking strategy, the key module of the recommender system, needs\nto be precise, accurate, and responsive for estimating customers' intents. We\npropose a dynamic ranking paradigm, named as DNN-MAB, that is composed of a\npairwise deep neural network (DNN) $\\mathit{pre}$-ranker connecting a revised\nmulti-armed bandit (MAB) dynamic $\\mathit{post}$-ranker. By taking into account\nof explicit and implicit user feedbacks such as impressions, clicks,\nconversions, etc. DNN-MAB is able to adjust DNN $\\mathit{pre}$-ranking scores\nto assist customers locating items they are interested in most so that they can\nconverge quickly and frequently. To the best of our knowledge, frameworks like\nDNN-MAB have not been discussed in the previous literature to either E-Commerce\nor machine learning audiences. In practice, DNN-MAB has been deployed to\nproduction and it easily outperforms against other state-of-the-art models by\nsignificantly lifting the gross merchandise volume (GMV) which is the objective\nmetrics at JD.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 02:33:53 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Yan", "Yan", ""], ["Guo", "Wentao", ""], ["Zhao", "Meng", ""], ["Hu", "Jinghe", ""], ["Yan", "Weipeng P.", ""]]}, {"id": "1708.04120", "submitter": "Marc Szafraniec", "authors": "Marc Szafraniec, Gautier Marti, Philippe Donnat", "title": "Putting Self-Supervised Token Embedding on the Tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information distribution by electronic messages is a privileged means of\ntransmission for many businesses and individuals, often under the form of\nplain-text tables. As their number grows, it becomes necessary to use an\nalgorithm to extract text and numbers instead of a human. Usual methods are\nfocused on regular expressions or on a strict structure in the data, but are\nnot efficient when we have many variations, fuzzy structure or implicit labels.\nIn this paper we introduce SC2T, a totally self-supervised model for\nconstructing vector representations of tokens in semi-structured messages by\nusing characters and context levels that address these issues. It can then be\nused for an unsupervised labeling of tokens, or be the basis for a\nsemi-supervised information extraction system.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jul 2017 09:35:45 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 12:53:55 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Szafraniec", "Marc", ""], ["Marti", "Gautier", ""], ["Donnat", "Philippe", ""]]}, {"id": "1708.04326", "submitter": "Rishav Chakravarti", "authors": "Rishav Chakravarti, Jiri Navratil, Cicero Nogueira dos Santos", "title": "Improved Answer Selection with Pre-Trained Word Embeddings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper evaluates existing and newly proposed answer selection methods\nbased on pre-trained word embeddings. Word embeddings are highly effective in\nvarious natural language processing tasks and their integration into\ntraditional information retrieval (IR) systems allows for the capture of\nsemantic relatedness between questions and answers. Empirical results on three\npublicly available data sets show significant gains over traditional term\nfrequency based approaches in both supervised and unsupervised settings. We\nshow that combining these word embedding features with traditional\nlearning-to-rank techniques can achieve similar performance to state-of-the-art\nneural networks trained for the answer selection task.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 21:04:36 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Chakravarti", "Rishav", ""], ["Navratil", "Jiri", ""], ["Santos", "Cicero Nogueira dos", ""]]}, {"id": "1708.04358", "submitter": "Afshin Rahimi", "authors": "Afshin Rahimi, Timothy Baldwin and Trevor Cohn", "title": "Continuous Representation of Location for Geolocation and Lexical\n  Dialectology using Mixture Density Networks", "comments": "Conference on Empirical Methods in Natural Language Processing (EMNLP\n  2017) September 2017, Copenhagen, Denmark", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a method for embedding two-dimensional locations in a continuous\nvector space using a neural network-based model incorporating mixtures of\nGaussian distributions, presenting two model variants for text-based\ngeolocation and lexical dialectology. Evaluated over Twitter data, the proposed\nmodel outperforms conventional regression-based geolocation and provides a\nbetter estimate of uncertainty. We also show the effectiveness of the\nrepresentation for predicting words from location in lexical dialectology, and\nevaluate it using the DARE dataset.\n", "versions": [{"version": "v1", "created": "Mon, 14 Aug 2017 23:52:02 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Rahimi", "Afshin", ""], ["Baldwin", "Timothy", ""], ["Cohn", "Trevor", ""]]}, {"id": "1708.04378", "submitter": "Ziming Li", "authors": "Ziming Li, Julia Kiseleva, Maarten de Rijke, Artem Grotov", "title": "Towards Learning Reward Functions from User Interactions", "comments": "5 pages", "journal-ref": null, "doi": "10.1145/3121050.3121098", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the physical world, people have dynamic preferences, e.g., the same\nsituation can lead to satisfaction for some humans and to frustration for\nothers. Personalization is called for. The same observation holds for online\nbehavior with interactive systems. It is natural to represent the behavior of\nusers who are engaging with interactive systems such as a search engine or a\nrecommender system, as a sequence of actions where each next action depends on\nthe current situation and the user reward of taking a particular action. By and\nlarge, current online evaluation metrics for interactive systems such as search\nengines or recommender systems, are static and do not reflect differences in\nuser behavior. They rarely capture or model the reward experienced by a user\nwhile interacting with an interactive system. We argue that knowing a user's\nreward function is essential for an interactive system as both for learning and\nevaluation. We propose to learn users' reward functions directly from observed\ninteraction traces. In particular, we present how users' reward functions can\nbe uncovered directly using inverse reinforcement learning techniques. We also\nshow how to incorporate user features into the learning process. Our main\ncontribution is a novel and dynamic approach to restore a user's reward\nfunction. We present an analytic approach to this problem and complement it\nwith initial experiments using the interaction logs of a cultural heritage\ninstitution that demonstrate the feasibility of the approach by uncovering\ndifferent reward functions for different user groups.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 01:53:12 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Li", "Ziming", ""], ["Kiseleva", "Julia", ""], ["de Rijke", "Maarten", ""], ["Grotov", "Artem", ""]]}, {"id": "1708.04396", "submitter": "Xiangnan He", "authors": "Xiangnan He, Ming Gao, Min-Yen Kan, Dingxian Wang", "title": "BiRank: Towards Ranking on Bipartite Graphs", "comments": "15 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The bipartite graph is a ubiquitous data structure that can model the\nrelationship between two entity types: for instance, users and items, queries\nand webpages. In this paper, we study the problem of ranking vertices of a\nbipartite graph, based on the graph's link structure as well as prior\ninformation about vertices (which we term a query vector). We present a new\nsolution, BiRank, which iteratively assigns scores to vertices and finally\nconverges to a unique stationary ranking. In contrast to the traditional random\nwalk-based methods, BiRank iterates towards optimizing a regularization\nfunction, which smooths the graph under the guidance of the query vector.\nImportantly, we establish how BiRank relates to the Bayesian methodology,\nenabling the future extension in a probabilistic way. To show the rationale and\nextendability of the ranking methodology, we further extend it to rank for the\nmore generic n-partite graphs. BiRank's generic modeling of both the graph\nstructure and vertex features enables it to model various ranking hypotheses\nflexibly. To illustrate its functionality, we apply the BiRank and TriRank\n(ranking for tripartite graphs) algorithms to two real-world applications: a\ngeneral ranking scenario that predicts the future popularity of items, and a\npersonalized ranking scenario that recommends items of interest to users.\nExtensive experiments on both synthetic and real-world datasets demonstrate\nBiRank's soundness (fast convergence), efficiency (linear in the number of\ngraph edges) and effectiveness (achieving state-of-the-art in the two\nreal-world tasks).\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 05:09:44 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["He", "Xiangnan", ""], ["Gao", "Ming", ""], ["Kan", "Min-Yen", ""], ["Wang", "Dingxian", ""]]}, {"id": "1708.04439", "submitter": "Sukriti Verma", "authors": "Sukriti Verma and Vagisha Nidhi", "title": "Extractive Summarization using Deep Learning", "comments": "Accepted to 18th International Conference on Computational\n  Linguistics and Intelligent Text Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a text summarization approach for factual reports using a\ndeep learning model. This approach consists of three phases: feature\nextraction, feature enhancement, and summary generation, which work together to\nassimilate core information and generate a coherent, understandable summary. We\nare exploring various features to improve the set of sentences selected for the\nsummary, and are using a Restricted Boltzmann Machine to enhance and abstract\nthose features to improve resultant accuracy without losing any important\ninformation. The sentences are scored based on those enhanced features and an\nextractive summary is constructed. Experimentation carried out on several\narticles demonstrates the effectiveness of the proposed approach. Source code\navailable at: https://github.com/vagisha-nidhi/TextSummarizer\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 09:08:50 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2019 07:30:40 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Verma", "Sukriti", ""], ["Nidhi", "Vagisha", ""]]}, {"id": "1708.04479", "submitter": "Chen Wu", "authors": "Chen Wu, Ming Yan, Luo Si", "title": "Ensemble Methods for Personalized E-Commerce Search Challenge at CIKM\n  Cup 2016", "comments": "First Place Solution at CIKM Cup 2016 Track 2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized search has been a hot research topic for many years and has been\nwidely used in e-commerce. This paper describes our solution to tackle the\nchallenge of personalized e-commerce search at CIKM Cup 2016. The goal of this\ncompetition is to predict search relevance and re-rank the result items in SERP\naccording to the personalized search, browsing and purchasing preferences.\nBased on a detailed analysis of the provided data, we extract three different\ntypes of features, i.e., statistic features, query-item features and session\nfeatures. Different models are used on these features, including logistic\nregression, gradient boosted decision trees, rank svm and a novel deep match\nmodel. With the blending of multiple models, a stacking ensemble model is built\nto integrate the output of individual models and produce a more accurate\nprediction result. Based on these efforts, our solution won the champion of the\ncompetition on all the evaluation metrics.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 12:53:50 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Wu", "Chen", ""], ["Yan", "Ming", ""], ["Si", "Luo", ""]]}, {"id": "1708.04497", "submitter": "Chenwei Cai", "authors": "Chenwei Cai, Ruining He, Julian McAuley", "title": "SPMC: Socially-Aware Personalized Markov Chains for Sparse Sequential\n  Recommendation", "comments": "7 pages, 6 figures, 3 tables, accepted to IJCAI 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with sparse, long-tailed datasets, and cold-start problems is always\na challenge for recommender systems. These issues can partly be dealt with by\nmaking predictions not in isolation, but by leveraging information from related\nevents; such information could include signals from social relationships or\nfrom the sequence of recent activities. Both types of additional information\ncan be used to improve the performance of state-of-the-art matrix\nfactorization-based techniques. In this paper, we propose new methods to\ncombine both social and sequential information simultaneously, in order to\nfurther improve recommendation performance. We show these techniques to be\nparticularly effective when dealing with sparsity and cold-start issues in\nseveral large, real-world datasets.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 20:17:28 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Cai", "Chenwei", ""], ["He", "Ruining", ""], ["McAuley", "Julian", ""]]}, {"id": "1708.04531", "submitter": "Baichuan Zhang", "authors": "Baichuan Zhang, Murat Dundar, Mohammad Al Hasan", "title": "Bayesian Non-Exhaustive Classification for Active Online Name\n  Disambiguation", "comments": "arXiv admin note: text overlap with arXiv:1607.05746", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The name disambiguation task partitions a collection of records pertaining to\na given name, such that there is a one-to-one correspondence between the\npartitions and a group of people, all sharing that given name. Most existing\nsolutions for this task are proposed for static data. However, more realistic\nscenarios stipulate emergence of records in a streaming fashion where records\nmay belong to known as well as unknown persons all sharing the same name. This\nrequires a flexible name disambiguation algorithm that can not only classify\nrecords of known persons represented in the train- ing data by their existing\nrecords but can also identify records of new ambiguous persons with no existing\nrecords included in the initial training dataset. Toward achieving this\nobjective, in this paper we propose a Bayesian non-exhaustive classification\nframe- work for solving online name disambiguation. In particular, we present a\nDirichlet Process Gaussian Mixture Model (DPGMM) as a core engine for online\nname disambiguation task. Meanwhile, two online inference algorithms, namely\none-pass Gibbs sampler and Sequential Importance Sampling with Resampling (also\nknown as particle filtering), are proposed to simultaneously perform online\nclassification and new class discovery. As a case study we consider\nbibliographic data in a temporal stream format and disambiguate authors by\npartitioning their papers into homogeneous groups.Our experimental results\ndemonstrate that the proposed method is significantly better than existing\nmethods for performing online name disambiguation task. We also propose an\ninteractive version of our online name disambiguation method designed to\nleverage user feedback to improve prediction accuracy.\n", "versions": [{"version": "v1", "created": "Sat, 12 Aug 2017 00:04:58 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Zhang", "Baichuan", ""], ["Dundar", "Murat", ""], ["Hasan", "Mohammad Al", ""]]}, {"id": "1708.04587", "submitter": "Nattapong Sanchan", "authors": "Nattapong Sanchan, Ahmet Aker and Kalina Bontcheva", "title": "Automatic Summarization of Online Debates", "comments": "Accepted and to be published in Natural Language Processing and\n  Information Retrieval workshop, Recent Advances in Natural Language\n  Processing 2017 (RANLP 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Debate summarization is one of the novel and challenging research areas in\nautomatic text summarization which has been largely unexplored. In this paper,\nwe develop a debate summarization pipeline to summarize key topics which are\ndiscussed or argued in the two opposing sides of online debates. We view that\nthe generation of debate summaries can be achieved by clustering, cluster\nlabeling, and visualization. In our work, we investigate two different\nclustering approaches for the generation of the summaries. In the first\napproach, we generate the summaries by applying purely term-based clustering\nand cluster labeling. The second approach makes use of X-means for clustering\nand Mutual Information for labeling the clusters. Both approaches are driven by\nontologies. We visualize the results using bar charts. We think that our\nresults are a smooth entry for users aiming to receive the first impression\nabout what is discussed within a debate topic containing waste number of\nargumentations.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 16:44:28 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Sanchan", "Nattapong", ""], ["Aker", "Ahmet", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "1708.04592", "submitter": "Nattapong Sanchan", "authors": "Nattapong Sanchan, Ahmet Aker and Kalina Bontcheva", "title": "Gold Standard Online Debates Summaries and First Experiments Towards\n  Automatic Summarization of Online Debate Data", "comments": "accepted and presented at the CICLING 2017 - 18th International\n  Conference on Intelligent Text Processing and Computational Linguistics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Usage of online textual media is steadily increasing. Daily, more and more\nnews stories, blog posts and scientific articles are added to the online\nvolumes. These are all freely accessible and have been employed extensively in\nmultiple research areas, e.g. automatic text summarization, information\nretrieval, information extraction, etc. Meanwhile, online debate forums have\nrecently become popular, but have remained largely unexplored. For this reason,\nthere are no sufficient resources of annotated debate data available for\nconducting research in this genre. In this paper, we collected and annotated\ndebate data for an automatic summarization task. Similar to extractive gold\nstandard summary generation our data contains sentences worthy to include into\na summary. Five human annotators performed this task. Inter-annotator\nagreement, based on semantic similarity, is 36% for Cohen's kappa and 48% for\nKrippendorff's alpha. Moreover, we also implement an extractive summarization\nsystem for online debates and discuss prominent features for the task of\nsummarizing online debate data automatically.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 16:52:22 GMT"}], "update_date": "2017-08-16", "authors_parsed": [["Sanchan", "Nattapong", ""], ["Aker", "Ahmet", ""], ["Bontcheva", "Kalina", ""]]}, {"id": "1708.04681", "submitter": "Arman Cohan", "authors": "Arman Cohan, Allan Fong, Raj Ratwani, Nazli Goharian", "title": "Identifying Harm Events in Clinical Care through Medical Narratives", "comments": "ACM-BCB 2017", "journal-ref": null, "doi": "10.1145/3107411.3107485", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Preventable medical errors are estimated to be among the leading causes of\ninjury and death in the United States. To prevent such errors, healthcare\nsystems have implemented patient safety and incident reporting systems. These\nsystems enable clinicians to report unsafe conditions and cases where patients\nhave been harmed due to errors in medical care. These reports are narratives in\nnatural language and while they provide detailed information about the\nsituation, it is non-trivial to perform large scale analysis for identifying\ncommon causes of errors and harm to the patients. In this work, we present a\nmethod based on attentive convolutional and recurrent networks for identifying\nharm events in patient care and categorize the harm based on its severity\nlevel. We demonstrate that our methods can significantly improve the\nperformance over existing methods in identifying harm in clinical care.\n", "versions": [{"version": "v1", "created": "Tue, 15 Aug 2017 20:38:37 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Cohan", "Arman", ""], ["Fong", "Allan", ""], ["Ratwani", "Raj", ""], ["Goharian", "Nazli", ""]]}, {"id": "1708.04725", "submitter": "JungHun Kim", "authors": "Jung-Hun Kim, Aviv Segev", "title": "Hypotheses generation using link prediction in a bipartite graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large volume of scientific publications is likely to have hidden\nknowledge that can be used for suggesting new research topics. We propose an\nautomatic method that is helpful for generating research hypotheses in the\nfield of physics using the massive number of physics journal publications. We\nconvert the text data of titles and abstract sections in publications to a\nbipartite graph, extracting words of physical matter composed of chemical\nelements and extracting related keywords in the paper. The proposed method\npredicts the formation of new links between matter and keyword nodes based on\ncollaborative filtering and matter popularity. The formation of links\nrepresents research hypotheses, as it suggests the new possible relationships\nbetween physical matter and keywords for physical properties or phenomena. The\nsuggested method has better performance than existing methods for link\nprediction in the entire bipartite graph and the subgraph that contains only a\nspecific keyword, such as `antiferromagnetism' or `superconductivity.'\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 00:25:03 GMT"}, {"version": "v2", "created": "Tue, 26 Dec 2017 09:59:37 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Kim", "Jung-Hun", ""], ["Segev", "Aviv", ""]]}, {"id": "1708.04828", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Minh C. Phan, Siu Cheung Hui", "title": "Multi-task Neural Network for Non-discrete Attribute Prediction in\n  Knowledge Graphs", "comments": "Accepted at CIKM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many popular knowledge graphs such as Freebase, YAGO or DBPedia maintain a\nlist of non-discrete attributes for each entity. Intuitively, these attributes\nsuch as height, price or population count are able to richly characterize\nentities in knowledge graphs. This additional source of information may help to\nalleviate the inherent sparsity and incompleteness problem that are prevalent\nin knowledge graphs. Unfortunately, many state-of-the-art relational learning\nmodels ignore this information due to the challenging nature of dealing with\nnon-discrete data types in the inherently binary-natured knowledge graphs. In\nthis paper, we propose a novel multi-task neural network approach for both\nencoding and prediction of non-discrete attribute information in a relational\nsetting. Specifically, we train a neural network for triplet prediction along\nwith a separate network for attribute value regression. Via multi-task\nlearning, we are able to learn representations of entities, relations and\nattributes that encode information about both tasks. Moreover, such attributes\nare not only central to many predictive tasks as an information source but also\nas a prediction target. Therefore, models that are able to encode, incorporate\nand predict such information in a relational learning context are highly\nattractive as well. We show that our approach outperforms many state-of-the-art\nmethods for the tasks of relational triplet classification and attribute value\nprediction.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 09:55:15 GMT"}], "update_date": "2017-08-17", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Phan", "Minh C.", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1708.05024", "submitter": "Xiangnan He", "authors": "Xiangnan He, Hanwang Zhang, Min-Yen Kan, Tat-Seng Chua", "title": "Fast Matrix Factorization for Online Recommendation with Implicit\n  Feedback", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper contributes improvements on both the effectiveness and efficiency\nof Matrix Factorization (MF) methods for implicit feedback. We highlight two\ncritical issues of existing works. First, due to the large space of unobserved\nfeedback, most existing works resort to assign a uniform weight to the missing\ndata to reduce computational complexity. However, such a uniform assumption is\ninvalid in real-world settings. Second, most methods are also designed in an\noffline setting and fail to keep up with the dynamic nature of online data. We\naddress the above two issues in learning MF models from implicit feedback. We\nfirst propose to weight the missing data based on item popularity, which is\nmore effective and flexible than the uniform-weight assumption. However, such a\nnon-uniform weighting poses efficiency challenge in learning the model. To\naddress this, we specifically design a new learning algorithm based on the\nelement-wise Alternating Least Squares (eALS) technique, for efficiently\noptimizing a MF model with variably-weighted missing data. We exploit this\nefficiency to then seamlessly devise an incremental update strategy that\ninstantly refreshes a MF model given new feedback. Through comprehensive\nexperiments on two public datasets in both offline and online protocols, we\nshow that our eALS method consistently outperforms state-of-the-art implicit MF\nmethods. Our implementation is available at\nhttps://github.com/hexiangnan/sigir16-eals.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 18:22:49 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["He", "Xiangnan", ""], ["Zhang", "Hanwang", ""], ["Kan", "Min-Yen", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1708.05031", "submitter": "Xiangnan He", "authors": "Xiangnan He, Lizi Liao, Hanwang Zhang, Liqiang Nie, Xia Hu, Tat-Seng\n  Chua", "title": "Neural Collaborative Filtering", "comments": "10 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, deep neural networks have yielded immense success on speech\nrecognition, computer vision and natural language processing. However, the\nexploration of deep neural networks on recommender systems has received\nrelatively less scrutiny. In this work, we strive to develop techniques based\non neural networks to tackle the key problem in recommendation -- collaborative\nfiltering -- on the basis of implicit feedback. Although some recent work has\nemployed deep learning for recommendation, they primarily used it to model\nauxiliary information, such as textual descriptions of items and acoustic\nfeatures of musics. When it comes to model the key factor in collaborative\nfiltering -- the interaction between user and item features, they still\nresorted to matrix factorization and applied an inner product on the latent\nfeatures of users and items. By replacing the inner product with a neural\narchitecture that can learn an arbitrary function from data, we present a\ngeneral framework named NCF, short for Neural network-based Collaborative\nFiltering. NCF is generic and can express and generalize matrix factorization\nunder its framework. To supercharge NCF modelling with non-linearities, we\npropose to leverage a multi-layer perceptron to learn the user-item interaction\nfunction. Extensive experiments on two real-world datasets show significant\nimprovements of our proposed NCF framework over the state-of-the-art methods.\nEmpirical evidence shows that using deeper layers of neural networks offers\nbetter recommendation performance.\n", "versions": [{"version": "v1", "created": "Wed, 16 Aug 2017 18:30:09 GMT"}, {"version": "v2", "created": "Sat, 26 Aug 2017 01:37:09 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["He", "Xiangnan", ""], ["Liao", "Lizi", ""], ["Zhang", "Hanwang", ""], ["Nie", "Liqiang", ""], ["Hu", "Xia", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1708.05302", "submitter": "Gon\\c{c}alo Mordido", "authors": "Gon\\c{c}alo Mordido, Jo\\~ao Magalh\\~aes, Sofia Cavaco", "title": "Automatic Organisation, Segmentation, and Filtering of User-Generated\n  Audio Content", "comments": "MMSP 2017 - IEEE 19th International Workshop on Multimedia Signal\n  Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.IR cs.MM cs.SD", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using solely the information retrieved by audio fingerprinting techniques, we\npropose methods to treat a possibly large dataset of user-generated audio\ncontent, that (1) enable the grouping of several audio files that contain a\ncommon audio excerpt (i.e., are relative to the same event), and (2) give\ninformation about how those files are correlated in terms of time and quality\ninside each event. Furthermore, we use supervised learning to detect incorrect\nmatches that may arise from the audio fingerprinting algorithm itself, whilst\nensuring our model learns with previous predictions. All the presented methods\nwere further validated by user-generated recordings of several different\nconcerts manually crawled from YouTube.\n", "versions": [{"version": "v1", "created": "Thu, 17 Aug 2017 14:19:17 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Mordido", "Gon\u00e7alo", ""], ["Magalh\u00e3es", "Jo\u00e3o", ""], ["Cavaco", "Sofia", ""]]}, {"id": "1708.05517", "submitter": "Maram Hasanain", "authors": "Maram Hasanain, Reem Suwaileh, Tamer Elsayed, Mucahid Kutlu and Hind\n  Almerekhi", "title": "EveTAR: Building a Large-Scale Multi-Task Test Collection over Arabic\n  Tweets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article introduces a new language-independent approach for creating a\nlarge-scale high-quality test collection of tweets that supports multiple\ninformation retrieval (IR) tasks without running a shared-task campaign. The\nadopted approach (demonstrated over Arabic tweets) designs the collection\naround significant (i.e., popular) events, which enables the development of\ntopics that represent frequent information needs of Twitter users for which\nrich content exists. That inherently facilitates the support of multiple tasks\nthat generally revolve around events, namely event detection, ad-hoc search,\ntimeline generation, and real-time summarization. The key highlights of the\napproach include diversifying the judgment pool via interactive search and\nmultiple manually-crafted queries per topic, collecting high-quality\nannotations via crowd-workers for relevancy and in-house annotators for\nnovelty, filtering out low-agreement topics and inaccessible tweets, and\nproviding multiple subsets of the collection for better availability. Applying\nour methodology on Arabic tweets resulted in EveTAR , the first\nfreely-available tweet test collection for multiple IR tasks. EveTAR includes a\ncrawl of 355M Arabic tweets and covers 50 significant events for which about\n62K tweets were judged with substantial average inter-annotator agreement\n(Kappa value of 0.71). We demonstrate the usability of EveTAR by evaluating\nexisting algorithms in the respective tasks. Results indicate that the new\ncollection can support reliable ranking of IR systems that is comparable to\nsimilar TREC collections, while providing strong baseline results for future\nstudies over Arabic tweets.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 06:12:40 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 10:13:15 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Hasanain", "Maram", ""], ["Suwaileh", "Reem", ""], ["Elsayed", "Tamer", ""], ["Kutlu", "Mucahid", ""], ["Almerekhi", "Hind", ""]]}, {"id": "1708.05529", "submitter": "Ayan Kumar Bhunia", "authors": "Partha Pratim Roy, Ayan Kumar Bhunia, Avirup Bhattacharyya, Umapada\n  Pal", "title": "Word Searching in Scene Image and Video Frame in Multi-Script Scenario\n  using Dynamic Shape Coding", "comments": "Multimedia Tools and Applications, Springer", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieval of text information from natural scene images and video frames is a\nchallenging task due to its inherent problems like complex character shapes,\nlow resolution, background noise, etc. Available OCR systems often fail to\nretrieve such information in scene/video frames. Keyword spotting, an\nalternative way to retrieve information, performs efficient text searching in\nsuch scenarios. However, current word spotting techniques in scene/video images\nare script-specific and they are mainly developed for Latin script. This paper\npresents a novel word spotting framework using dynamic shape coding for text\nretrieval in natural scene image and video frames. The framework is designed to\nsearch query keyword from multiple scripts with the help of on-the-fly\nscript-wise keyword generation for the corresponding script. We have used a\ntwo-stage word spotting approach using Hidden Markov Model (HMM) to detect the\ntranslated keyword in a given text line by identifying the script of the line.\nA novel unsupervised dynamic shape coding based scheme has been used to group\nsimilar shape characters to avoid confusion and to improve text alignment.\nNext, the hypotheses locations are verified to improve retrieval performance.\nTo evaluate the proposed system for searching keyword from natural scene image\nand video frames, we have considered two popular Indic scripts such as Bangla\n(Bengali) and Devanagari along with English. Inspired by the zone-wise\nrecognition approach in Indic scripts[1], zone-wise text information has been\nused to improve the traditional word spotting performance in Indic scripts. For\nour experiment, a dataset consisting of images of different scenes and video\nframes of English, Bangla and Devanagari scripts were considered. The results\nobtained showed the effectiveness of our proposed word spotting approach.\n", "versions": [{"version": "v1", "created": "Fri, 18 Aug 2017 07:47:05 GMT"}, {"version": "v2", "created": "Wed, 30 Aug 2017 16:45:52 GMT"}, {"version": "v3", "created": "Thu, 31 May 2018 00:45:20 GMT"}, {"version": "v4", "created": "Tue, 19 Jun 2018 06:23:12 GMT"}, {"version": "v5", "created": "Wed, 27 Jun 2018 06:35:13 GMT"}, {"version": "v6", "created": "Mon, 30 Jul 2018 10:41:30 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Roy", "Partha Pratim", ""], ["Bhunia", "Ayan Kumar", ""], ["Bhattacharyya", "Avirup", ""], ["Pal", "Umapada", ""]]}, {"id": "1708.05851", "submitter": "Di Hu", "authors": "Xuelong Li and Di Hu and Xiaoqiang Lu", "title": "Image2song: Song Retrieval via Bridging Image Content and Lyric Words", "comments": "13 pages, 13 figures, accepted by ICCV 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image is usually taken for expressing some kinds of emotions or purposes,\nsuch as love, celebrating Christmas. There is another better way that combines\nthe image and relevant song to amplify the expression, which has drawn much\nattention in the social network recently. Hence, the automatic selection of\nsongs should be expected. In this paper, we propose to retrieve semantic\nrelevant songs just by an image query, which is named as the image2song\nproblem. Motivated by the requirements of establishing correlation in\nsemantic/content, we build a semantic-based song retrieval framework, which\nlearns the correlation between image content and lyric words. This model uses a\nconvolutional neural network to generate rich tags from image regions, a\nrecurrent neural network to model lyric, and then establishes correlation via a\nmulti-layer perceptron. To reduce the content gap between image and lyric, we\npropose to make the lyric modeling focus on the main image content via a tag\nattention. We collect a dataset from the social-sharing multimodal data to\nstudy the proposed problem, which consists of (image, music clip, lyric)\ntriplets. We demonstrate that our proposed model shows noticeable results in\nthe image2song retrieval task and provides suitable songs. Besides, the\nsong2image task is also performed.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 14:17:44 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Li", "Xuelong", ""], ["Hu", "Di", ""], ["Lu", "Xiaoqiang", ""]]}, {"id": "1708.05878", "submitter": "Sibo Zhang", "authors": "Sibo Zhang, Yuan Cheng, Deyuan Ke", "title": "Event-Radar: Real-time Local Event Detection System for Geo-Tagged Tweet\n  Streams", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The local event detection is to use posting messages with geotags on social\nnetworks to reveal the related ongoing events and their locations. Recent\nstudies have demonstrated that the geo-tagged tweet stream serves as an\nunprecedentedly valuable source for local event detection. Nevertheless, how to\neffectively extract local events from large geo-tagged tweet streams in real\ntime remains challenging. A robust and efficient cloud-based real-time local\nevent detection software system would benefit various aspects in the real-life\nsociety, from shopping recommendation for customer service providers to\ndisaster alarming for emergency departments. We use the preliminary research\nGeoBurst as a starting point, which proposed a novel method to detect local\nevents. GeoBurst+ leverages a novel cross-modal authority measure to identify\nseveral pivots in the query window. Such pivots reveal different geo-topical\nactivities and naturally attract related tweets to form candidate events. It\nfurther summarises the continuous stream and compares the candidates against\nthe historical summaries to pinpoint truly interesting local events. We mainly\nimplement a website demonstration system Event-Radar with an improved algorithm\nto show the real-time local events online for public interests. Better still,\nas the query window shifts, our method can update the event list with little\ntime cost, thus achieving continuous monitoring of the stream.\n", "versions": [{"version": "v1", "created": "Sat, 19 Aug 2017 17:32:24 GMT"}, {"version": "v2", "created": "Thu, 5 Oct 2017 14:07:23 GMT"}], "update_date": "2020-04-07", "authors_parsed": [["Zhang", "Sibo", ""], ["Cheng", "Yuan", ""], ["Ke", "Deyuan", ""]]}, {"id": "1708.06011", "submitter": "Ronan Cummins", "authors": "Ronan Cummins", "title": "Modelling Word Burstiness in Natural Language: A Generalised Polya\n  Process for Document Language Models in Information Retrieval", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a generalised multivariate Polya process for document language\nmodelling. The framework outlined here generalises a number of statistical\nlanguage models used in information retrieval for modelling document\ngeneration. In particular, we show that the choice of replacement matrix M\nultimately defines the type of random process and therefore defines a\nparticular type of document language model. We show that a particular variant\nof the general model is useful for modelling term-specific burstiness.\nFurthermore, via experimentation we show that this variant significantly\nimproves retrieval effectiveness over a strong baseline on a number of small\ntest collections.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 19:41:58 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Cummins", "Ronan", ""]]}, {"id": "1708.06409", "submitter": "Yongfeng Zhang", "authors": "Yongfeng Zhang", "title": "Explainable Recommendation: Theory and Applications", "comments": "169 pages, in Chinese, 3 main research chapters", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although personalized recommendation has been investigated for decades, the\nwide adoption of Latent Factor Models (LFM) has made the explainability of\nrecommendations a critical issue to both the research community and practical\napplication of recommender systems. For example, in many practical systems the\nalgorithm just provides a personalized item recommendation list to the users,\nwithout persuasive personalized explanation about why such an item is\nrecommended while another is not. Unexplainable recommendations introduce\nnegative effects to the trustworthiness of recommender systems, and thus affect\nthe effectiveness of recommendation engines. In this work, we investigate\nexplainable recommendation in aspects of data explainability, model\nexplainability, and result explainability, and the main contributions are as\nfollows:\n  1. Data Explainability: We propose Localized Matrix Factorization (LMF)\nframework based Bordered Block Diagonal Form (BBDF) matrices, and further\napplied this technique for parallelized matrix factorization.\n  2. Model Explainability: We propose Explicit Factor Models (EFM) based on\nphrase-level sentiment analysis, as well as dynamic user preference modeling\nbased on time series analysis. In this work, we extract product features and\nuser opinions towards different features from large-scale user textual reviews\nbased on phrase-level sentiment analysis techniques, and introduce the EFM\napproach for explainable model learning and recommendation.\n  3. Economic Explainability: We propose the Total Surplus Maximization (TSM)\nframework for personalized recommendation, as well as the model specification\nin different types of online applications. Based on basic economic concepts, we\nprovide the definitions of utility, cost, and surplus in the application\nscenario of Web services, and propose the general framework of web total\nsurplus calculation and maximization.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 20:26:48 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Zhang", "Yongfeng", ""]]}, {"id": "1708.06520", "submitter": "Cedric De Boom", "authors": "Cedric De Boom, Rohan Agrawal, Samantha Hansen, Esh Kumar, Romain Yon,\n  Ching-Wei Chen, Thomas Demeester, Bart Dhoedt", "title": "Large-Scale User Modeling with Recurrent Neural Networks for Music\n  Discovery on Multiple Time Scales", "comments": "Author pre-print version, 20 pages, 6 figures, 4 tables", "journal-ref": null, "doi": "10.1007/s11042-017-5121-z", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The amount of content on online music streaming platforms is immense, and\nmost users only access a tiny fraction of this content. Recommender systems are\nthe application of choice to open up the collection to these users.\nCollaborative filtering has the disadvantage that it relies on explicit\nratings, which are often unavailable, and generally disregards the temporal\nnature of music consumption. On the other hand, item co-occurrence algorithms,\nsuch as the recently introduced word2vec-based recommenders, are typically left\nwithout an effective user representation. In this paper, we present a new\napproach to model users through recurrent neural networks by sequentially\nprocessing consumed items, represented by any type of embeddings and other\ncontext features. This way we obtain semantically rich user representations,\nwhich capture a user's musical taste over time. Our experimental analysis on\nlarge-scale user data shows that our model can be used to predict future songs\na user will likely listen to, both in the short and long term.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 07:45:22 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["De Boom", "Cedric", ""], ["Agrawal", "Rohan", ""], ["Hansen", "Samantha", ""], ["Kumar", "Esh", ""], ["Yon", "Romain", ""], ["Chen", "Ching-Wei", ""], ["Demeester", "Thomas", ""], ["Dhoedt", "Bart", ""]]}, {"id": "1708.06828", "submitter": "Bonggun Shin", "authors": "Bonggun Shin, Falgun H. Chokshi, Timothy Lee and Jinho D. Choi", "title": "Classification of Radiology Reports Using Neural Attention Models", "comments": null, "journal-ref": "In Proceedings of the International Joint Conference on Neural\n  Networks, of IJCNN'17, pages 4363--4370, Anchorage, AK, 2017", "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The electronic health record (EHR) contains a large amount of\nmulti-dimensional and unstructured clinical data of significant operational and\nresearch value. Distinguished from previous studies, our approach embraces a\ndouble-annotated dataset and strays away from obscure \"black-box\" models to\ncomprehensive deep learning models. In this paper, we present a novel neural\nattention mechanism that not only classifies clinically important findings.\nSpecifically, convolutional neural networks (CNN) with attention analysis are\nused to classify radiology head computed tomography reports based on five\ncategories that radiologists would account for in assessing acute and\ncommunicable findings in daily practice. The experiments show that our CNN\nattention models outperform non-neural models, especially when trained on a\nlarger dataset. Our attention analysis demonstrates the intuition behind the\nclassifier's decision by generating a heatmap that highlights attended terms\nused by the CNN model; this is valuable when potential downstream medical\ndecisions are to be performed by human experts or the classifier information is\nto be used in cohort construction such as for epidemiological studies.\n", "versions": [{"version": "v1", "created": "Tue, 22 Aug 2017 21:30:23 GMT"}], "update_date": "2017-08-24", "authors_parsed": [["Shin", "Bonggun", ""], ["Chokshi", "Falgun H.", ""], ["Lee", "Timothy", ""], ["Choi", "Jinho D.", ""]]}, {"id": "1708.07157", "submitter": "Christina Lioma Assoc. Prof", "authors": "Christina Lioma and Jakob Grue Simonsen and Birger Larsen", "title": "Evaluation Measures for Relevance and Credibility in Ranked Lists", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent discussions on alternative facts, fake news, and post truth politics\nhave motivated research on creating technologies that allow people not only to\naccess information, but also to assess the credibility of the information\npresented to them by information retrieval systems. Whereas technology is in\nplace for filtering information according to relevance and/or credibility, no\nsingle measure currently exists for evaluating the accuracy or precision (and\nmore generally effectiveness) of both the relevance and the credibility of\nretrieved results. One obvious way of doing so is to measure relevance and\ncredibility effectiveness separately, and then consolidate the two measures\ninto one. There at least two problems with such an approach: (I) it is not\ncertain that the same criteria are applied to the evaluation of both relevance\nand credibility (and applying different criteria introduces bias to the\nevaluation); (II) many more and richer measures exist for assessing relevance\neffectiveness than for assessing credibility effectiveness (hence risking\nfurther bias).\n  Motivated by the above, we present two novel types of evaluation measures\nthat are designed to measure the effectiveness of both relevance and\ncredibility in ranked lists of retrieval results. Experimental evaluation on a\nsmall human-annotated dataset (that we make freely available to the research\ncommunity) shows that our measures are expressive and intuitive in their\ninterpretation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 19:18:11 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Lioma", "Christina", ""], ["Simonsen", "Jakob Grue", ""], ["Larsen", "Birger", ""]]}, {"id": "1708.07289", "submitter": "Jiacheng Xu", "authors": "Xu Jiacheng", "title": "Family Shopping Recommendation System Using User Profile and Behavior\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  With the arrival of the big data era, recommendation system has been a hot\ntechnology for enterprises to streamline their sales. Recommendation algorithms\nfor individual users have been extensively studied over the past decade. Most\nexisting recommendation systems also focus on individual user recommendations,\nhowever in many daily activities, items are recommended to the groups not one\nperson. As an effective means to solve the problem of group recommendation\nproblem,we extend the single user recommendation to group recommendation.\nSpecifically we propose a novel approach for family-based shopping\nrecommendation system. We use the dataset from the real shopping mall\nconsisting of shopping records table, client-profile table and family\nrelationship table. Our algorithm integrates user behavior similarity and user\nprofile similarity to build the user based collaborative filtering model. We\nevaluate our approach on a real-world shopping mall dataset.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 06:33:50 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Jiacheng", "Xu", ""]]}, {"id": "1708.07336", "submitter": "Hsuan-Tien Lin", "authors": "Wei-Yuan Shen and Hsuan-Tien Lin", "title": "Active Sampling of Pairs and Points for Large-scale Linear Bipartite\n  Ranking", "comments": "a shorter version was presented in ACML 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bipartite ranking is a fundamental ranking problem that learns to order\nrelevant instances ahead of irrelevant ones. The pair-wise approach for\nbi-partite ranking construct a quadratic number of pairs to solve the problem,\nwhich is infeasible for large-scale data sets. The point-wise approach, albeit\nmore efficient, often results in inferior performance. That is, it is difficult\nto conduct bipartite ranking accurately and efficiently at the same time. In\nthis paper, we develop a novel active sampling scheme within the pair-wise\napproach to conduct bipartite ranking efficiently. The scheme is inspired from\nactive learning and can reach a competitive ranking performance while focusing\nonly on a small subset of the many pairs during training. Moreover, we propose\na general Combined Ranking and Classification (CRC) framework to accurately\nconduct bipartite ranking. The framework unifies point-wise and pair-wise\napproaches and is simply based on the idea of treating each instance point as a\npseudo-pair. Experiments on 14 real-word large-scale data sets demonstrate that\nthe proposed algorithm of Active Sampling within CRC, when coupled with a\nlinear Support Vector Machine, usually outperforms state-of-the-art point-wise\nand pair-wise ranking approaches in terms of both accuracy and efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 09:43:17 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Shen", "Wei-Yuan", ""], ["Lin", "Hsuan-Tien", ""]]}, {"id": "1708.07347", "submitter": "Sebastian Heinz", "authors": "Sebastian Heinz, Christian Bracher, Roland Vollgraf", "title": "An LSTM-Based Dynamic Customer Model for Fashion Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online fashion sales present a challenging use case for personalized\nrecommendation: Stores offer a huge variety of items in multiple sizes. Small\nstocks, high return rates, seasonality, and changing trends cause continuous\nturnover of articles for sale on all time scales. Customers tend to shop\nrarely, but often buy multiple items at once. We report on backtest experiments\nwith sales data of 100k frequent shoppers at Zalando, Europe's leading online\nfashion platform. To model changing customer and store environments, our\nrecommendation method employs a pair of neural networks: To overcome the cold\nstart problem, a feedforward network generates article embeddings in \"fashion\nspace,\" which serve as input to a recurrent neural network that predicts a\nstyle vector in this space for each client, based on their past purchase\nsequence. We compare our results with a static collaborative filtering\napproach, and a popularity ranking baseline.\n", "versions": [{"version": "v1", "created": "Thu, 24 Aug 2017 10:35:24 GMT"}], "update_date": "2017-08-25", "authors_parsed": [["Heinz", "Sebastian", ""], ["Bracher", "Christian", ""], ["Vollgraf", "Roland", ""]]}, {"id": "1708.07689", "submitter": "Sebastian Lapuschkin", "authors": "Sebastian Lapuschkin, Alexander Binder, Klaus-Robert M\\\"uller,\n  Wojciech Samek", "title": "Understanding and Comparing Deep Neural Networks for Age and Gender\n  Classification", "comments": "8 pages, 5 figures, 5 tables. Presented at ICCV 2017 Workshop: 7th\n  IEEE International Workshop on Analysis and Modeling of Faces and Gestures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.AI cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, deep neural networks have demonstrated excellent performances in\nrecognizing the age and gender on human face images. However, these models were\napplied in a black-box manner with no information provided about which facial\nfeatures are actually used for prediction and how these features depend on\nimage preprocessing, model initialization and architecture choice. We present a\nstudy investigating these different effects.\n  In detail, our work compares four popular neural network architectures,\nstudies the effect of pretraining, evaluates the robustness of the considered\nalignment preprocessings via cross-method test set swapping and intuitively\nvisualizes the model's prediction strategies in given preprocessing conditions\nusing the recent Layer-wise Relevance Propagation (LRP) algorithm. Our\nevaluations on the challenging Adience benchmark show that suitable parameter\ninitialization leads to a holistic perception of the input, compensating\nartefactual data representations. With a combination of simple preprocessing\nsteps, we reach state of the art performance in gender recognition.\n", "versions": [{"version": "v1", "created": "Fri, 25 Aug 2017 11:08:38 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Lapuschkin", "Sebastian", ""], ["Binder", "Alexander", ""], ["M\u00fcller", "Klaus-Robert", ""], ["Samek", "Wojciech", ""]]}, {"id": "1708.07935", "submitter": "Kui Zhao", "authors": "Kui Zhao, Yi Wang, Xia Hu, Can Wang", "title": "Effective Blog Pages Extractor for Better UGC Accessing", "comments": "2016 3rd International Conference on Information Science and Control\n  Engineering (ICISCE)", "journal-ref": null, "doi": "10.1109/ICISCE.2016.86", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blog is becoming an increasingly popular media for information publishing.\nBesides the main content, most of blog pages nowadays also contain noisy\ninformation such as advertisements etc. Removing these unrelated elements can\nimproves user experience, but also can better adapt the content to various\ndevices such as mobile phones. Though template-based extractors are highly\naccurate, they may incur expensive cost in that a large number of template need\nto be developed and they will fail once the template is updated. To address\nthese issues, we present a novel template-independent content extractor for\nblog pages. First, we convert a blog page into a DOM-Tree, where all elements\nincluding the title and body blocks in a page correspond to subtrees. Then we\nconstruct subtree candidate set for the title and the body blocks respectively,\nand extract both spatial and content features for elements contained in the\nsubtree. SVM classifiers for the title and the body blocks are trained using\nthese features. Finally, the classifiers are used to extract the main content\nfrom blog pages. We test our extractor on 2,250 blog pages crawled from nine\nblog sites with obviously different styles and templates. Experimental results\nverify the effectiveness of our extractor.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 05:56:32 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Zhao", "Kui", ""], ["Wang", "Yi", ""], ["Hu", "Xia", ""], ["Wang", "Can", ""]]}, {"id": "1708.07940", "submitter": "Kui Zhao", "authors": "Kui Zhao, Bangpeng Li, Zilun Peng, Jiajun Bu, Can Wang", "title": "Navigation Objects Extraction for Better Content Structure Understanding", "comments": "2017 IEEE/WIC/ACM International Conference on Web Intelligence (WI)", "journal-ref": null, "doi": "10.1145/3106426.3106437", "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing works for extracting navigation objects from webpages focus on\nnavigation menus, so as to reveal the information architecture of the site.\nHowever, web 2.0 sites such as social networks, e-commerce portals etc. are\nmaking the understanding of the content structure in a web site increasingly\ndifficult. Dynamic and personalized elements such as top stories, recommended\nlist in a webpage are vital to the understanding of the dynamic nature of web\n2.0 sites. To better understand the content structure in web 2.0 sites, in this\npaper we propose a new extraction method for navigation objects in a webpage.\nOur method will extract not only the static navigation menus, but also the\ndynamic and personalized page-specific navigation lists. Since the navigation\nobjects in a webpage naturally come in blocks, we first cluster hyperlinks into\ndifferent blocks by exploiting spatial locations of hyperlinks, the\nhierarchical structure of the DOM-tree and the hyperlink density. Then we\nidentify navigation objects from those blocks using the SVM classifier with\nnovel features such as anchor text lengths etc. Experiments on real-world data\nsets with webpages from various domains and styles verified the effectiveness\nof our method.\n", "versions": [{"version": "v1", "created": "Sat, 26 Aug 2017 06:59:24 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Zhao", "Kui", ""], ["Li", "Bangpeng", ""], ["Peng", "Zilun", ""], ["Bu", "Jiajun", ""], ["Wang", "Can", ""]]}, {"id": "1708.08123", "submitter": "Ankit Vadehra", "authors": "Ankit Vadehra, Maura R. Grossman and Gordon V. Cormack", "title": "Impact of Feature Selection on Micro-Text Classification", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social media datasets, especially Twitter tweets, are popular in the field of\ntext classification. Tweets are a valuable source of micro-text (sometimes\nreferred to as \"micro-blogs\"), and have been studied in domains such as\nsentiment analysis, recommendation systems, spam detection, clustering, among\nothers. Tweets often include keywords referred to as \"Hashtags\" that can be\nused as labels for the tweet. Using tweets encompassing 50 labels, we studied\nthe impact of word versus character-level feature selection and extraction on\ndifferent learners to solve a multi-class classification task. We show that\nfeature extraction of simple character-level groups performs better than simple\nword groups and pre-processing methods like normalizing using Porter's Stemming\nand Part-of-Speech (\"POS\")-Lemmatization.\n", "versions": [{"version": "v1", "created": "Sun, 27 Aug 2017 18:50:48 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Vadehra", "Ankit", ""], ["Grossman", "Maura R.", ""], ["Cormack", "Gordon V.", ""]]}, {"id": "1708.08289", "submitter": "Dar\\'io Garigliotti", "authors": "Dar\\'io Garigliotti and Krisztian Balog", "title": "Generating Query Suggestions to Support Task-Based Search", "comments": "Proceedings of the 40th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR '17), 2017", "journal-ref": null, "doi": "10.1145/3077136.3080745", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of generating query suggestions to support users in\ncompleting their underlying tasks (which motivated them to search in the first\nplace). Given an initial query, these query suggestions should provide a\ncoverage of possible subtasks the user might be looking for. We propose a\nprobabilistic modeling framework that obtains keyphrases from multiple sources\nand generates query suggestions from these keyphrases. Using the test suites of\nthe TREC Tasks track, we evaluate and analyze each component of our model.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 12:44:14 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Garigliotti", "Dar\u00edo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1708.08291", "submitter": "Dar\\'io Garigliotti", "authors": "Dar\\'io Garigliotti and Krisztian Balog", "title": "On Type-Aware Entity Retrieval", "comments": "Proceedings of the 3rd ACM International Conference on the Theory of\n  Information Retrieval (ICTIR '17), 2017", "journal-ref": null, "doi": "10.1145/3121050.3121054", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, the practice of returning entities from a knowledge base in response\nto search queries has become widespread. One of the distinctive characteristics\nof entities is that they are typed, i.e., assigned to some hierarchically\norganized type system (type taxonomy). The primary objective of this paper is\nto gain a better understanding of how entity type information can be utilized\nin entity retrieval. We perform this investigation in an idealized \"oracle\"\nsetting, assuming that we know the distribution of target types of the relevant\nentities for a given query. We perform a thorough analysis of three main\naspects: (i) the choice of type taxonomy, (ii) the representation of\nhierarchical type information, and (iii) the combination of type-based and\nterm-based similarity in the retrieval model. Using a standard entity search\ntest collection based on DBpedia, we find that type information proves most\nuseful when using large type taxonomies that provide very specific types. We\nprovide further insights on the extensional coverage of entities and on the\nutility of target types.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 12:47:04 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Garigliotti", "Dar\u00edo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1708.08319", "submitter": "Jim Pivarski", "authors": "Jim Pivarski, Peter Elmer, Brian Bockelman, Zhe Zhang", "title": "Fast Access to Columnar, Hierarchically Nested Data via Code\n  Transformation", "comments": "10 pages, 2 figures, submitted to IEEE Big Data", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big Data query systems represent data in a columnar format for fast,\nselective access, and in some cases (e.g. Apache Drill), perform calculations\ndirectly on the columnar data without row materialization, avoiding runtime\ncosts.\n  However, many analysis procedures cannot be easily or efficiently expressed\nas SQL. In High Energy Physics, the majority of data processing requires nested\nloops with complex dependencies. When faced with tasks like these, the\nconventional approach is to convert the columnar data back into an object form,\nusually with a performance price.\n  This paper describes a new technique to transform procedural code so that it\noperates on hierarchically nested, columnar data natively, without row\nmaterialization. It can be viewed as a compiler pass on the typed abstract\nsyntax tree, rewriting references to objects as columnar array lookups.\n  We will also present performance comparisons between transformed code and\nconventional object-oriented code in a High Energy Physics context.\n", "versions": [{"version": "v1", "created": "Sun, 20 Aug 2017 23:41:13 GMT"}, {"version": "v2", "created": "Fri, 3 Nov 2017 16:02:33 GMT"}], "update_date": "2017-11-06", "authors_parsed": [["Pivarski", "Jim", ""], ["Elmer", "Peter", ""], ["Bockelman", "Brian", ""], ["Zhang", "Zhe", ""]]}, {"id": "1708.08447", "submitter": "Joeran Beel", "authors": "Joeran Beel", "title": "It's Time to Consider \"Time\" when Evaluating Recommender-System\n  Algorithms [Proposal]", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this position paper, we question the current practice of calculating\nevaluation metrics for recommender systems as single numbers (e.g. precision\np=.28 or mean absolute error MAE = 1.21). We argue that single numbers express\nonly average effectiveness over a usually rather long period (e.g. a year or\neven longer), which provides only a vague and static view of the data. We\npropose that recommender-system researchers should instead calculate metrics\nfor time-series such as weeks or months, and plot the results in e.g. a line\nchart. This way, results show how algorithms' effectiveness develops over time,\nand hence the results allow drawing more meaningful conclusions about how an\nalgorithm will perform in the future. In this paper, we explain our reasoning,\nprovide an example to illustrate our reasoning and present suggestions for what\nthe community should do next.\n", "versions": [{"version": "v1", "created": "Mon, 28 Aug 2017 09:58:25 GMT"}, {"version": "v2", "created": "Wed, 30 Aug 2017 08:49:44 GMT"}, {"version": "v3", "created": "Sun, 29 Oct 2017 14:45:48 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Beel", "Joeran", ""]]}, {"id": "1708.08715", "submitter": "Shuo Zhang", "authors": "Shuo Zhang and Krisztian Balog", "title": "Design Patterns for Fusion-Based Object Retrieval", "comments": "Proceedings of the 39th European conference on Advances in\n  Information Retrieval (ECIR '17), 2017", "journal-ref": null, "doi": "10.1007/978-3-319-56608-5_66", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the task of ranking objects (such as people, blogs, or verticals)\nthat, unlike documents, do not have direct term-based representations. To be\nable to match them against keyword queries, evidence needs to be amassed from\ndocuments that are associated with the given object. We present two design\npatterns, i.e., general reusable retrieval strategies, which are able to\nencompass most existing approaches from the past. One strategy combines\nevidence on the term level (early fusion), while the other does it on the\ndocument level (late fusion). We demonstrate the generality of these patterns\nby applying them to three different object retrieval tasks: expert finding,\nblog distillation, and vertical ranking.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 12:05:38 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Zhang", "Shuo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1708.08721", "submitter": "Shuo Zhang", "authors": "Shuo Zhang and Krisztian Balog", "title": "EntiTables: Smart Assistance for Entity-Focused Tables", "comments": "Proceedings of the 40th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR '17), 2017", "journal-ref": null, "doi": "10.1145/3077136.3080796", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tables are among the most powerful and practical tools for organizing and\nworking with data. Our motivation is to equip spreadsheet programs with smart\nassistance capabilities. We concentrate on one particular family of tables,\nnamely, tables with an entity focus. We introduce and focus on two specific\ntasks: populating rows with additional instances (entities) and populating\ncolumns with new headings. We develop generative probabilistic models for both\ntasks. For estimating the components of these models, we consider a knowledge\nbase as well as a large table corpus. Our experimental evaluation simulates the\nvarious stages of the user entering content into an actual table. A detailed\nanalysis of the results shows that the models' components are complimentary and\nthat our methods outperform existing approaches from the literature.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 12:14:26 GMT"}], "update_date": "2017-08-30", "authors_parsed": [["Zhang", "Shuo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1708.09025", "submitter": "Xiaofeng Zhu", "authors": "Xiaofeng Zhu, Diego Klabjan, Patrick Bless", "title": "Unsupervised Terminological Ontology Learning based on Hierarchical\n  Topic Modeling", "comments": null, "journal-ref": "IRI 2017", "doi": "10.1109/IRI.2017.18", "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present hierarchical relationbased latent Dirichlet\nallocation (hrLDA), a data-driven hierarchical topic model for extracting\nterminological ontologies from a large number of heterogeneous documents. In\ncontrast to traditional topic models, hrLDA relies on noun phrases instead of\nunigrams, considers syntax and document structures, and enriches topic\nhierarchies with topic relations. Through a series of experiments, we\ndemonstrate the superiority of hrLDA over existing topic models, especially for\nbuilding hierarchies. Furthermore, we illustrate the robustness of hrLDA in the\nsettings of noisy data sets, which are likely to occur in many practical\nscenarios. Our ontology evaluation results show that ontologies extracted from\nhrLDA are very competitive with the ontologies created by domain experts.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 21:04:11 GMT"}], "update_date": "2020-01-10", "authors_parsed": [["Zhu", "Xiaofeng", ""], ["Klabjan", "Diego", ""], ["Bless", "Patrick", ""]]}, {"id": "1708.09088", "submitter": "Haekyu Park", "authors": "Haekyu Park, Jinhong Jung, and U Kang", "title": "A Comparative Study of Matrix Factorization and Random Walk with Restart\n  in Recommender Systems", "comments": "10 pages, Appears in IEEE International Conference on Big Data 2017\n  (IEEE BigData 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Between matrix factorization or Random Walk with Restart (RWR), which method\nworks better for recommender systems? Which method handles explicit or implicit\nfeedback data better? Does additional information help recommendation?\nRecommender systems play an important role in many e-commerce services such as\nAmazon and Netflix to recommend new items to a user. Among various\nrecommendation strategies, collaborative filtering has shown good performance\nby using rating patterns of users. Matrix factorization and random walk with\nrestart are the most representative collaborative filtering methods. However,\nit is still unclear which method provides better recommendation performance\ndespite their extensive utility.\n  In this paper, we provide a comparative study of matrix factorization and RWR\nin recommender systems. We exactly formulate each correspondence of the two\nmethods according to various tasks in recommendation. Especially, we newly\ndevise an RWR method using global bias term which corresponds to a matrix\nfactorization method using biases. We describe details of the two methods in\nvarious aspects of recommendation quality such as how those methods handle\ncold-start problem which typically happens in collaborative filtering. We\nextensively perform experiments over real-world datasets to evaluate the\nperformance of each method in terms of various measures. We observe that matrix\nfactorization performs better with explicit feedback ratings while RWR is\nbetter with implicit ones. We also observe that exploiting global popularities\nof items is advantageous in the performance and that side information produces\npositive synergy with explicit feedback but gives negative effects with\nimplicit one.\n", "versions": [{"version": "v1", "created": "Wed, 30 Aug 2017 02:08:14 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 07:45:51 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Park", "Haekyu", ""], ["Jung", "Jinhong", ""], ["Kang", "U", ""]]}, {"id": "1708.09662", "submitter": "Malay Bhattacharyya", "authors": "Sujoy Chatterjee, Anirban Mukhopadhyay and Malay Bhattacharyya", "title": "Quality Enhancement by Weighted Rank Aggregation of Crowd Opinion", "comments": "Works-in-Progress, Fifth AAAI Conference on Human Computation and\n  Crowdsourcing (HCOMP 2017), Quebec City, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Expertise of annotators has a major role in crowdsourcing based opinion\naggregation models. In such frameworks, accuracy and biasness of annotators are\noccasionally taken as important features and based on them priority of the\nannotators are assigned. But instead of relying on a single feature, multiple\nfeatures can be considered and separate rankings can be produced to judge the\nannotators properly. Finally, the aggregation of those rankings with perfect\nweightage can be done with an aim to produce better ground truth prediction.\nHere, we propose a novel weighted rank aggregation method and its efficacy with\nrespect to other existing approaches is shown on artificial dataset. The\neffectiveness of weighted rank aggregation to enhance quality prediction is\nalso shown by applying it on an Amazon Mechanical Turk (AMT) dataset.\n", "versions": [{"version": "v1", "created": "Thu, 31 Aug 2017 11:04:22 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Chatterjee", "Sujoy", ""], ["Mukhopadhyay", "Anirban", ""], ["Bhattacharyya", "Malay", ""]]}, {"id": "1708.09719", "submitter": "Ruihui Zhao", "authors": "Ruihui Zhao, Mizuho Iwaihara", "title": "Lightweight Efficient Multi-keyword Ranked Search over Encrypted Cloud\n  Data using Dual Word Embeddings", "comments": "14pages. arXiv admin note: substantial text overlap with\n  arXiv:1705.11056", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is emerging as a revolutionary computing paradigm which\npro-vides a flexible and economic strategy for data management and resource\nsharing. Security and privacy become major concerns in the cloud scenario, for\nwhich Searchable Encryption (SE) technology is proposed to support efficient\nretrieval of encrypted data. However, the absence of lightweight ranked search\nis still a typical shortage in existing SE schemes. In this paper, we propose a\nLightweight Efficient Multi-keyword Ranked Search over Encrypted Cloud Data\nusing Dual Word Embeddings (LRSE) scheme that supports top-k retrieval in the\nknown background model. For the first time, we formulate the privacy issue and\ndesign goals for lightweight ranked search in SE. We employ word embedding\ntrained on the whole English Wikipedia using word2vec to replace the general\ndictionary, afterwards we make use of Dual Embedding Space Model (DESM) to\nsubstitute traditional Vector Space Model (VSM), based on which we achieve the\ngoal of lightweight ranked search with higher precision and solve the\nchallenging prob-lems caused by updating the traditional dictionary in existing\nSE schemes. In LRSE, we employ an improved secure kNN scheme to guarantee\nsufficient pri-vacy protection. Our security analysis shows that LRSE satisfies\nour formulated privacy requirements and extensive experiments performed on\nreal-world datasets demonstrate that LRSE indeed accords with our proposed\ndesign goals.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 04:34:40 GMT"}], "update_date": "2017-09-01", "authors_parsed": [["Zhao", "Ruihui", ""], ["Iwaihara", "Mizuho", ""]]}]