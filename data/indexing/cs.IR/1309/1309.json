[{"id": "1309.0129", "submitter": "An Zeng", "authors": "An Zeng, Alexandre Vidmer, Matus Medo and Yi-Cheng Zhang", "title": "Information filtering via hybridization of similarity preferential\n  diffusion processes", "comments": "6 pages, 4 figures, 2 tables", "journal-ref": null, "doi": "10.1209/0295-5075/105/58002", "report-no": null, "categories": "cs.IR cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recommender system is one of the most promising ways to address the\ninformation overload problem in online systems. Based on the personal\nhistorical record, the recommender system can find interesting and relevant\nobjects for the user within a huge information space. Many physical processes\nsuch as the mass diffusion and heat conduction have been applied to design the\nrecommendation algorithms. The hybridization of these two algorithms has been\nshown to provide both accurate and diverse recommendation results. In this\npaper, we proposed two similarity preferential diffusion processes. Extensive\nexperimental analyses on two benchmark data sets demonstrate that both\nrecommendation and accuracy and diversity are improved duet to the similarity\npreference in the diffusion. The hybridization of the similarity preferential\ndiffusion processes is shown to significantly outperform the state-of-art\nrecommendation algorithm. Finally, our analysis on network sparsity show that\nthere is significant difference between dense and sparse system, indicating\nthat all the former conclusions on recommendation in the literature should be\nreexamined in sparse system.\n", "versions": [{"version": "v1", "created": "Sat, 31 Aug 2013 16:17:26 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Zeng", "An", ""], ["Vidmer", "Alexandre", ""], ["Medo", "Matus", ""], ["Zhang", "Yi-Cheng", ""]]}, {"id": "1309.0337", "submitter": "Neil Houlsby", "authors": "Neil Houlsby, Massimiliano Ciaramita", "title": "Scalable Probabilistic Entity-Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an LDA approach to entity disambiguation. Each topic is associated\nwith a Wikipedia article and topics generate either content words or entity\nmentions. Training such models is challenging because of the topic and\nvocabulary size, both in the millions. We tackle these problems using a novel\ndistributed inference and representation framework based on a parallel Gibbs\nsampler guided by the Wikipedia link graph, and pipelines of MapReduce allowing\nfast and memory-frugal processing of large datasets. We report state-of-the-art\nperformance on a public dataset.\n", "versions": [{"version": "v1", "created": "Mon, 2 Sep 2013 09:34:50 GMT"}], "update_date": "2013-09-03", "authors_parsed": [["Houlsby", "Neil", ""], ["Ciaramita", "Massimiliano", ""]]}, {"id": "1309.0691", "submitter": "Zi-Ke Zhang Dr.", "authors": "Chu-Xu Zhang, Zi-Ke Zhang, Lu Yu, Chuang Liu, Hao Liu, Xiao-Yong Yan", "title": "Information Filtering via Collaborative User Clustering Modeling", "comments": null, "journal-ref": null, "doi": "10.1016/j.physa.2013.11.024", "report-no": null, "categories": "cs.IR cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have witnessed the great success of recommender systems,\nwhich can significantly help users find out personalized items for them from\nthe information era. One of the most widely applied recommendation methods is\nthe Matrix Factorization (MF). However, most of researches on this topic have\nfocused on mining the direct relationships between users and items. In this\npaper, we optimize the standard MF by integrating the user clustering\nregularization term. Our model considers not only the user-item rating\ninformation, but also takes into account the user interest. We compared the\nproposed model with three typical other methods: User-Mean (UM), Item-Mean (IM)\nand standard MF. Experimental results on a real-world dataset,\n\\emph{MovieLens}, show that our method performs much better than other three\nmethods in the accuracy of recommendation.\n", "versions": [{"version": "v1", "created": "Tue, 3 Sep 2013 14:20:00 GMT"}, {"version": "v2", "created": "Wed, 4 Sep 2013 09:20:30 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2013 16:29:26 GMT"}, {"version": "v4", "created": "Mon, 10 Feb 2014 08:40:21 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Zhang", "Chu-Xu", ""], ["Zhang", "Zi-Ke", ""], ["Yu", "Lu", ""], ["Liu", "Chuang", ""], ["Liu", "Hao", ""], ["Yan", "Xiao-Yong", ""]]}, {"id": "1309.2648", "submitter": "Hany SalahEldeen", "authors": "Hany M. SalahEldeen and Michael L. Nelson", "title": "Resurrecting My Revolution: Using Social Link Neighborhood in Bringing\n  Context to the Disappearing Web", "comments": "Published IN TPDL 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In previous work we reported that resources linked in tweets disappeared at\nthe rate of 11% in the first year followed by 7.3% each year afterwards. We\nalso found that in the first year 6.7%, and 14.6% in each subsequent year, of\nthe resources were archived in public web archives. In this paper we revisit\nthe same dataset of tweets and find that our prior model still holds and the\ncalculated error for estimating percentages missing was about 4%, but we found\nthe rate of archiving produced a higher error of about 11.5%. We also\ndiscovered that resources have disappeared from the archives themselves (7.89%)\nas well as reappeared on the live web after being declared missing (6.54%). We\nhave also tested the availability of the tweets themselves and found that\n10.34% have disappeared from the live web. To mitigate the loss of resources on\nthe live web, we propose the use of a \"tweet signature\". Using the Topsy API,\nwe extract the top five most frequent terms from the union of all tweets about\na resource, and use these five terms as a query to Google. We found that using\ntweet signatures results in discovering replacement resources with 70+% textual\nsimilarity to the missing resource 41% of the time.\n", "versions": [{"version": "v1", "created": "Tue, 10 Sep 2013 20:00:55 GMT"}], "update_date": "2013-09-12", "authors_parsed": [["SalahEldeen", "Hany M.", ""], ["Nelson", "Michael L.", ""]]}, {"id": "1309.3132", "submitter": "Xiao-Bo Jin", "authors": "Xiao-Bo Jin, Guang-Gang Geng, Dexian Zhang", "title": "Combination of Multiple Bipartite Ranking for Web Content Quality\n  Evaluation", "comments": "17 pages, 8 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web content quality estimation is crucial to various web content processing\napplications. Our previous work applied Bagging + C4.5 to achive the best\nresults on the ECML/PKDD Discovery Challenge 2010, which is the comibination of\nmany point-wise rankinig models. In this paper, we combine multiple pair-wise\nbipartite ranking learner to solve the multi-partite ranking problems for the\nweb quality estimation. In encoding stage, we present the ternary encoding and\nthe binary coding extending each rank value to $L - 1$ (L is the number of the\ndifferent ranking value). For the decoding, we discuss the combination of\nmultiple ranking results from multiple bipartite ranking models with the\npredefined weighting and the adaptive weighting. The experiments on ECML/PKDD\n2010 Discovery Challenge datasets show that \\textit{binary coding} +\n\\textit{predefined weighting} yields the highest performance in all four\ncombinations and furthermore it is better than the best results reported in\nECML/PKDD 2010 Discovery Challenge competition.\n", "versions": [{"version": "v1", "created": "Thu, 12 Sep 2013 12:15:51 GMT"}, {"version": "v2", "created": "Thu, 26 Jun 2014 03:01:13 GMT"}], "update_date": "2014-06-27", "authors_parsed": [["Jin", "Xiao-Bo", ""], ["Geng", "Guang-Gang", ""], ["Zhang", "Dexian", ""]]}, {"id": "1309.3421", "submitter": "Yanshan Wang", "authors": "Yanshan Wang, Jae-Sung Lee, In-Chan Choi", "title": "Indexing by Latent Dirichlet Allocation and Ensemble Model", "comments": "Accepted by the Journal of American Society for Information Science\n  and Technology (JASIST)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The contribution of this paper is two-fold. First, we present Indexing by\nLatent Dirichlet Allocation (LDI), an automatic document indexing method. The\nprobability distributions in LDI utilize those in Latent Dirichlet Allocation\n(LDA), a generative topic model that has been previously used in applications\nfor document retrieval tasks. However, the ad hoc applications, or their\nvariants with smoothing techniques as prompted by previous studies in LDA-based\nlanguage modeling, result in unsatisfactory performance as the document\nrepresentations do not accurately reflect concept space. To improve\nperformance, we introduce a new definition of document probability vectors in\nthe context of LDA and present a novel scheme for automatic document indexing\nbased on LDA. Second, we propose an Ensemble Model (EnM) for document\nretrieval. The EnM combines basis indexing models by assigning different\nweights and attempts to uncover the optimal weights to maximize the Mean\nAverage Precision (MAP). To solve the optimization problem, we propose an\nalgorithm, EnM.B, which is derived based on the boosting method. The results of\nour computational experiments on benchmark data sets indicate that both the\nproposed approaches are viable options for document retrieval.\n", "versions": [{"version": "v1", "created": "Fri, 13 Sep 2013 10:37:47 GMT"}, {"version": "v2", "created": "Thu, 28 Nov 2013 11:37:58 GMT"}, {"version": "v3", "created": "Tue, 14 Oct 2014 07:41:46 GMT"}, {"version": "v4", "created": "Tue, 21 Oct 2014 12:57:14 GMT"}, {"version": "v5", "created": "Mon, 8 Dec 2014 08:27:49 GMT"}, {"version": "v6", "created": "Thu, 11 Dec 2014 05:18:32 GMT"}], "update_date": "2014-12-12", "authors_parsed": [["Wang", "Yanshan", ""], ["Lee", "Jae-Sung", ""], ["Choi", "In-Chan", ""]]}, {"id": "1309.3946", "submitter": "Anuj Sharma Dr", "authors": "Anuj Sharma, Shubhamoy Dey", "title": "Using Self-Organizing Maps for Sentiment Analysis", "comments": "13 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web 2.0 services have enabled people to express their opinions, experience\nand feelings in the form of user-generated content. Sentiment analysis or\nopinion mining involves identifying, classifying and aggregating opinions as\nper their positive or negative polarity. This paper investigates the efficacy\nof different implementations of Self-Organizing Maps (SOM) for sentiment based\nvisualization and classification of online reviews. Specifically, this paper\nimplements the SOM algorithm for both supervised and unsupervised learning from\ntext documents. The unsupervised SOM algorithm is implemented for sentiment\nbased visualization and classification tasks. For supervised sentiment\nanalysis, a competitive learning algorithm known as Learning Vector\nQuantization is used. Both algorithms are also compared with their respective\nmulti-pass implementations where a quick rough ordering pass is followed by a\nfine tuning pass. The experimental results on the online movie review data set\nshow that SOMs are well suited for sentiment based classification and sentiment\npolarity visualization.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 13:21:45 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["Sharma", "Anuj", ""], ["Dey", "Shubhamoy", ""]]}, {"id": "1309.3949", "submitter": "Anuj Sharma Dr", "authors": "Anuj sharma, Shubhamoy Dey", "title": "Performance Investigation of Feature Selection Methods", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sentiment analysis or opinion mining has become an open research domain after\nproliferation of Internet and Web 2.0 social media. People express their\nattitudes and opinions on social media including blogs, discussion forums,\ntweets, etc. and, sentiment analysis concerns about detecting and extracting\nsentiment or opinion from online text. Sentiment based text classification is\ndifferent from topical text classification since it involves discrimination\nbased on expressed opinion on a topic. Feature selection is significant for\nsentiment analysis as the opinionated text may have high dimensions, which can\nadversely affect the performance of sentiment analysis classifier. This paper\nexplores applicability of feature selection methods for sentiment analysis and\ninvestigates their performance for classification in term of recall, precision\nand accuracy. Five feature selection methods (Document Frequency, Information\nGain, Gain Ratio, Chi Squared, and Relief-F) and three popular sentiment\nfeature lexicons (HM, GI and Opinion Lexicon) are investigated on movie reviews\ncorpus with a size of 2000 documents. The experimental results show that\nInformation Gain gave consistent results and Gain Ratio performs overall best\nfor sentimental feature selection while sentiment lexicons gave poor\nperformance. Furthermore, we found that performance of the classifier depends\non appropriate number of representative feature selected from text.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 13:27:04 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["sharma", "Anuj", ""], ["Dey", "Shubhamoy", ""]]}, {"id": "1309.4009", "submitter": "Yasmin AlNoamany", "authors": "Yasmin AlNoamany, Michele C. Weigle, Michael L. Nelson", "title": "Access Patterns for Robots and Humans in Web Archives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although user access patterns on the live web are well-understood, there has\nbeen no corresponding study of how users, both humans and robots, access web\narchives. Based on samples from the Internet Archive's public Wayback Machine,\nwe propose a set of basic usage patterns: Dip (a single access), Slide (the\nsame page at different archive times), Dive (different pages at approximately\nthe same archive time), and Skim (lists of what pages are archived, i.e.,\nTimeMaps). Robots are limited almost exclusively to Dips and Skims, but human\naccesses are more varied between all four types. Robots outnumber humans 10:1\nin terms of sessions, 5:4 in terms of raw HTTP accesses, and 4:1 in terms of\nmegabytes transferred. Robots almost always access TimeMaps (95% of accesses),\nbut humans predominately access the archived web pages themselves (82% of\naccesses). In terms of unique archived web pages, there is no overall\npreference for a particular time, but the recent past (within the last year)\nshows significant repeat accesses.\n", "versions": [{"version": "v1", "created": "Mon, 16 Sep 2013 15:40:16 GMT"}], "update_date": "2013-09-17", "authors_parsed": [["AlNoamany", "Yasmin", ""], ["Weigle", "Michele C.", ""], ["Nelson", "Michael L.", ""]]}, {"id": "1309.4345", "submitter": "Mateusz  Lis", "authors": "M. Brzezi\\'nski-Spiczak, K. Dobosz, M. Lis, M. Pintal", "title": "Music Files Search System", "comments": null, "journal-ref": "Information systems architecture and technology : information\n  systems and computer communication networks / eds Adam Grzech [i in.].\n  Wroc{\\l}aw : Oficyna Wydawnicza Politechniki Wroc{\\l}awskiej, 2008. s.\n  201-211", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper introduces a project of advanced system of music retrieval from\nthe Internet. The system uses combination of text search (by author, title and\nother information about the music file included in id3 tag description or\nsimilar for other file types) with more intuitive and novel method of melody\nsearch using query by humming. The patterns for storing text and melody\ninformation as well as improved clustering algorithm for the pattern space were\nproposed. The search engine is planned to optimise the query due to the data\ninput by user, thanks to the structure of text and melody index database. The\nsystem is planned to be a plug-in for popular digital music players or an\nindependent player. An advanced system of recommendation based on information\ngathered from user's profile and search history is an integral part of the\nsystem. The recommendation mechanism uses scrobbling methods and is responsible\nfor making suggestions of songs unknown to the user but similar to his\npreferred music styles and positioning search results.\n", "versions": [{"version": "v1", "created": "Tue, 17 Sep 2013 15:15:08 GMT"}], "update_date": "2013-09-18", "authors_parsed": [["Brzezi\u0144ski-Spiczak", "M.", ""], ["Dobosz", "K.", ""], ["Lis", "M.", ""], ["Pintal", "M.", ""]]}, {"id": "1309.4938", "submitter": "Dipasree Pal", "authors": "Dipasree Pal, Mandar Mitra and Kalyankumar Datta", "title": "Improving Query Expansion Using WordNet", "comments": "18 pages, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study proposes a new way of using WordNet for Query Expansion (QE). We\nchoose candidate expansion terms, as usual, from a set of pseudo relevant\ndocuments; however, the usefulness of these terms is measured based on their\ndefinitions provided in a hand-crafted lexical resource like WordNet.\nExperiments with a number of standard TREC collections show that this method\noutperforms existing WordNet based methods. It also compares favorably with\nestablished QE methods such as KLD and RM3. Leveraging earlier work in which a\ncombination of QE methods was found to outperform each individual method (as\nwell as other well-known QE methods), we next propose a combination-based QE\nmethod that takes into account three different aspects of a candidate expansion\nterm's usefulness: (i) its distribution in the pseudo relevant documents and in\nthe target corpus, (ii) its statistical association with query terms, and (iii)\nits semantic relation with the query, as determined by the overlap between the\nWordNet definitions of the term and query terms. This combination of diverse\nsources of information appears to work well on a number of test collections,\nviz., TREC123, TREC5, TREC678, TREC robust new and TREC910 collections, and\nyields significant improvements over competing methods on most of these\ncollections.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 11:38:51 GMT"}], "update_date": "2013-09-20", "authors_parsed": [["Pal", "Dipasree", ""], ["Mitra", "Mandar", ""], ["Datta", "Kalyankumar", ""]]}, {"id": "1309.5018", "submitter": "Naveen Ashish", "authors": "Ben Zamanzadeh, Naveen Ashish, Cartic Ramakrishnan and John Zimmerman", "title": "Semantic Advertising", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the concept of Semantic Advertising which we see as the future of\nonline advertising. Semantic Advertising is online advertising powered by\nsemantic technology which essentially enables us to represent and reason with\nconcepts and the meaning of things. This paper aims to 1) Define semantic\nadvertising, 2) Place it in the context of broader and more widely used\nconcepts such as the Semantic Web and Semantic Search, 3) Provide a survey of\nwork in related areas such as context matching, and 4) Provide a perspective on\nsuccessful emerging technologies and areas of future work. We base our work on\nour experience as a company developing semantic technologies aimed at realizing\nthe full potential of online advertising.\n", "versions": [{"version": "v1", "created": "Thu, 19 Sep 2013 15:23:24 GMT"}], "update_date": "2013-09-20", "authors_parsed": [["Zamanzadeh", "Ben", ""], ["Ashish", "Naveen", ""], ["Ramakrishnan", "Cartic", ""], ["Zimmerman", "John", ""]]}, {"id": "1309.5174", "submitter": "Andrei Barbu", "authors": "Andrei Barbu, N. Siddharth, Jeffrey Mark Siskind", "title": "Saying What You're Looking For: Linguistics Meets Video Search", "comments": "13 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an approach to searching large video corpora for video clips which\ndepict a natural-language query in the form of a sentence. This approach uses\ncompositional semantics to encode subtle meaning that is lost in other systems,\nsuch as the difference between two sentences which have identical words but\nentirely different meaning: \"The person rode the horse} vs. \\emph{The horse\nrode the person\". Given a video-sentence pair and a natural-language parser,\nalong with a grammar that describes the space of sentential queries, we produce\na score which indicates how well the video depicts the sentence. We produce\nsuch a score for each video clip in a corpus and return a ranked list of clips.\nFurthermore, this approach addresses two fundamental problems simultaneously:\ndetecting and tracking objects, and recognizing whether those tracks depict the\nquery. Because both tracking and object detection are unreliable, this uses\nknowledge about the intended sentential query to focus the tracker on the\nrelevant participants and ensures that the resulting tracks are described by\nthe sentential query. While earlier work was limited to single-word queries\nwhich correspond to either verbs or nouns, we show how one can search for\ncomplex queries which contain multiple phrases, such as prepositional phrases,\nand modifiers, such as adverbs. We demonstrate this approach by searching for\n141 queries involving people and horses interacting with each other in 10\nfull-length Hollywood movies.\n", "versions": [{"version": "v1", "created": "Fri, 20 Sep 2013 05:07:29 GMT"}], "update_date": "2013-09-23", "authors_parsed": [["Barbu", "Andrei", ""], ["Siddharth", "N.", ""], ["Siskind", "Jeffrey Mark", ""]]}, {"id": "1309.6527", "submitter": "Yordan Kalmukov", "authors": "Yordan Kalmukov", "title": "Describing Papers and Reviewers' Competences by Taxonomy of Keywords", "comments": null, "journal-ref": "Computer Science and Information Systems, Vol. 9(2), pp. 763-789,\n  2012, ISSN 1820-0214", "doi": "10.2298/CSIS110906012K", "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article focuses on the importance of the precise calculation of\nsimilarity factors between papers and reviewers for performing a fair and\naccurate automatic assignment of reviewers to papers. It suggests that papers\nand reviewers' competences should be described by taxonomy of keywords so that\nthe implied hierarchical structure allows similarity measures to take into\naccount not only the number of exactly matching keywords, but in case of\nnon-matching ones to calculate how semantically close they are. The paper also\nsuggests a similarity measure derived from the well-known and widely-used\nDice's coefficient, but adapted in a way it could be also applied between sets\nwhose elements are semantically related to each other (as concepts in taxonomy\nare). It allows a non-zero similarity factor to be accurately calculated\nbetween a paper and a reviewer even if they do not share any keyword in common.\n", "versions": [{"version": "v1", "created": "Wed, 25 Sep 2013 14:43:31 GMT"}], "update_date": "2013-09-26", "authors_parsed": [["Kalmukov", "Yordan", ""]]}, {"id": "1309.6852", "submitter": "Shuzi Niu", "authors": "Shuzi Niu, Yanyan Lan, Jiafeng Guo, Xueqi Cheng", "title": "Stochastic Rank Aggregation", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-478-487", "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of rank aggregation, which aims to find a\nconsensus ranking among multiple ranking inputs. Traditional rank aggregation\nmethods are deterministic, and can be categorized into explicit and implicit\nmethods depending on whether rank information is explicitly or implicitly\nutilized. Surprisingly, experimental results on real data sets show that\nexplicit rank aggregation methods would not work as well as implicit methods,\nalthough rank information is critical for the task. Our analysis indicates that\nthe major reason might be the unreliable rank information from incomplete\nranking inputs. To solve this problem, we propose to incorporate uncertainty\ninto rank aggregation and tackle the problem in both unsupervised and\nsupervised scenario. We call this novel framework {stochastic rank aggregation}\n(St.Agg for short). Specifically, we introduce a prior distribution on ranks,\nand transform the ranking functions or objectives in traditional explicit\nmethods to their expectations over this distribution. Our experiments on\nbenchmark data sets show that the proposed St.Agg outperforms the baselines in\nboth unsupervised and supervised scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:46:39 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Niu", "Shuzi", ""], ["Lan", "Yanyan", ""], ["Guo", "Jiafeng", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1309.6865", "submitter": "Nitish Srivastava", "authors": "Nitish Srivastava, Ruslan R Salakhutdinov, Geoffrey E. Hinton", "title": "Modeling Documents with Deep Boltzmann Machines", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-616-624", "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a Deep Boltzmann Machine model suitable for modeling and\nextracting latent semantic representations from a large unstructured collection\nof documents. We overcome the apparent difficulty of training a DBM with\njudicious parameter tying. This parameter tying enables an efficient\npretraining algorithm and a state initialization scheme that aids inference.\nThe model can be trained just as efficiently as a standard Restricted Boltzmann\nMachine. Our experiments show that the model assigns better log probability to\nunseen data than the Replicated Softmax model. Features extracted from our\nmodel outperform LDA, Replicated Softmax, and DocNADE models on document\nretrieval and document classification tasks.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:50:54 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Srivastava", "Nitish", ""], ["Salakhutdinov", "Ruslan R", ""], ["Hinton", "Geoffrey E.", ""]]}, {"id": "1309.6874", "submitter": "Pengtao Xie", "authors": "Pengtao Xie, Eric P. Xing", "title": "Integrating Document Clustering and Topic Modeling", "comments": "Appears in Proceedings of the Twenty-Ninth Conference on Uncertainty\n  in Artificial Intelligence (UAI2013)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2013-PG-694-703", "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document clustering and topic modeling are two closely related tasks which\ncan mutually benefit each other. Topic modeling can project documents into a\ntopic space which facilitates effective document clustering. Cluster labels\ndiscovered by document clustering can be incorporated into topic models to\nextract local topics specific to each cluster and global topics shared by all\nclusters. In this paper, we propose a multi-grain clustering topic model\n(MGCTM) which integrates document clustering and topic modeling into a unified\nframework and jointly performs the two tasks to achieve the overall best\nperformance. Our model tightly couples two components: a mixture component used\nfor discovering latent groups in document collection and a topic model\ncomponent used for mining multi-grain topics including local topics specific to\neach cluster and global topics shared across clusters.We employ variational\ninference to approximate the posterior of hidden variables and learn model\nparameters. Experiments on two datasets demonstrate the effectiveness of our\nmodel.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 12:54:02 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Xie", "Pengtao", ""], ["Xing", "Eric P.", ""]]}, {"id": "1309.6908", "submitter": "Anuj Sharma Dr", "authors": "Sanjog Ray, Anuj Sharma", "title": "A Collaborative Filtering Based Approach for Recommending Elective\n  Courses", "comments": "10 Pages, Ray, S., & Sharma, A. (2011). A Collaborative Filtering\n  Based Approach for Recommending Elective Courses. 5th International\n  Conference on Information Systems, Technology and Management (ICISTM-2011).\n  Gurgaon, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In management education programmes today, students face a difficult time in\nchoosing electives as the number of electives available are many. As the range\nand diversity of different elective courses available for selection have\nincreased, course recommendation systems that help students in making choices\nabout courses have become more relevant. In this paper we extend the concept of\ncollaborative filtering approach to develop a course recommendation system. The\nproposed approach provides student an accurate prediction of the grade they may\nget if they choose a particular course, which will be helpful when they decide\non selecting elective courses, as grade is an important parameter for a student\nwhile deciding on an elective course. We experimentally evaluate the\ncollaborative filtering approach on a real life data set and show that the\nproposed system is effective in terms of accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 26 Sep 2013 14:15:07 GMT"}], "update_date": "2013-09-27", "authors_parsed": [["Ray", "Sanjog", ""], ["Sharma", "Anuj", ""]]}, {"id": "1309.7270", "submitter": "Ahmed Abbasi", "authors": "Tianjun Fu, Ahmed Abbasi, Daniel Zeng and Hsinchun Chen", "title": "Evaluating the Usefulness of Sentiment Information for Focused Crawlers", "comments": "Fu, T., Abbasi, A., Zeng, D., and Chen, H. \"Evaluating the Usefulness\n  of Sentiment Information for Focused Crawlers,\" In Proceedings of the 20th\n  Annual Workshop on Information Technologies and Systems, St. Louis, MO,\n  December 11-12, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the prevalence of sentiment-related content on the Web, there has\nbeen limited work on focused crawlers capable of effectively collecting such\ncontent. In this study, we evaluated the efficacy of using sentiment-related\ninformation for enhanced focused crawling of opinion-rich web content regarding\na particular topic. We also assessed the impact of using sentiment-labeled web\ngraphs to further improve collection accuracy. Experimental results on a large\ntest bed encompassing over half a million web pages revealed that focused\ncrawlers utilizing sentiment information as well as sentiment-labeled web\ngraphs are capable of gathering more holistic collections of opinion-related\ncontent regarding a particular topic. The results have important implications\nfor business and marketing intelligence gathering efforts in the Web 2.0 era.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2013 15:14:34 GMT"}], "update_date": "2013-09-30", "authors_parsed": [["Fu", "Tianjun", ""], ["Abbasi", "Ahmed", ""], ["Zeng", "Daniel", ""], ["Chen", "Hsinchun", ""]]}, {"id": "1309.7313", "submitter": "Jiwei Li", "authors": "Jiwei Li and Claire Cardie", "title": "Timeline Generation: Tracking individuals on Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a unsupervised framework to reconstruct a person's\nlife history by creating a chronological list for {\\it personal important\nevents} (PIE) of individuals based on the tweets they published. By analyzing\nindividual tweet collections, we find that what are suitable for inclusion in\nthe personal timeline should be tweets talking about personal (as opposed to\npublic) and time-specific (as opposed to time-general) topics. To further\nextract these types of topics, we introduce a non-parametric multi-level\nDirichlet Process model to recognize four types of tweets: personal\ntime-specific (PersonTS), personal time-general (PersonTG), public\ntime-specific (PublicTS) and public time-general (PublicTG) topics, which, in\nturn, are used for further personal event extraction and timeline generation.\nTo the best of our knowledge, this is the first work focused on the generation\nof timeline for individuals from twitter data. For evaluation, we have built a\nnew golden standard Timelines based on Twitter and Wikipedia that contain PIE\nrelated events from 20 {\\it ordinary twitter users} and 20 {\\it celebrities}.\nExperiments on real Twitter data quantitatively demonstrate the effectiveness\nof our approach.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2013 17:56:35 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2013 00:16:14 GMT"}, {"version": "v3", "created": "Fri, 7 Feb 2014 19:10:58 GMT"}], "update_date": "2014-02-10", "authors_parsed": [["Li", "Jiwei", ""], ["Cardie", "Claire", ""]]}, {"id": "1309.7393", "submitter": "Chuan Shi", "authors": "Chuan Shi, Xiangnan Kong, Yue Huang, Philip S. Yu, Bin Wu", "title": "HeteSim: A General Framework for Relevance Measure in Heterogeneous\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity search is an important function in many applications, which\nusually focuses on measuring the similarity between objects with the same type.\nHowever, in many scenarios, we need to measure the relatedness between objects\nwith different types. With the surge of study on heterogeneous networks, the\nrelevance measure on objects with different types becomes increasingly\nimportant. In this paper, we study the relevance search problem in\nheterogeneous networks, where the task is to measure the relatedness of\nheterogeneous objects (including objects with the same type or different\ntypes). A novel measure HeteSim is proposed, which has the following\nattributes: (1) a uniform measure: it can measure the relatedness of objects\nwith the same or different types in a uniform framework; (2) a path-constrained\nmeasure: the relatedness of object pairs are defined based on the search path\nthat connect two objects through following a sequence of node types; (3) a\nsemi-metric measure: HeteSim has some good properties (e.g., self-maximum and\nsymmetric), that are crucial to many data mining tasks. Moreover, we analyze\nthe computation characteristics of HeteSim and propose the corresponding quick\ncomputation strategies. Empirical studies show that HeteSim can effectively and\nefficiently evaluate the relatedness of heterogeneous objects.\n", "versions": [{"version": "v1", "created": "Sat, 28 Sep 2013 00:31:30 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Shi", "Chuan", ""], ["Kong", "Xiangnan", ""], ["Huang", "Yue", ""], ["Yu", "Philip S.", ""], ["Wu", "Bin", ""]]}, {"id": "1309.7517", "submitter": "Modou Gueye M.", "authors": "Modou Gueye and Talel Abdessalem and Hubert Naacke", "title": "Improving tag recommendation by folding in more consistency", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tag recommendation is a major aspect of collaborative tagging systems. It\naims to recommend tags to a user for tagging an item. In this paper we present\na part of our work in progress which is a novel improvement of recommendations\nby re-ranking the output of a tag recommender. We mine association rules\nbetween candidates tags in order to determine a more consistent list of tags to\nrecommend.\n  Our method is an add-on one which leads to better recommendations as we show\nin this paper. It is easily parallelizable and morever it may be applied to a\nlot of tag recommenders. The experiments we did on five datasets with two kinds\nof tag recommender demonstrated the efficiency of our method.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2013 01:43:40 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Gueye", "Modou", ""], ["Abdessalem", "Talel", ""], ["Naacke", "Hubert", ""]]}, {"id": "1309.7611", "submitter": "Bal\\'azs Hidasi", "authors": "Bal\\'azs Hidasi, Domonkos Tikk", "title": "Context-aware recommendations from implicit data via scalable tensor\n  factorization", "comments": "Extended version of the ECML/PKDD 2012 paper of B. Hidasi & D. Tikk:\n  Fast ALS-based tensor factorization for context-aware recommendation from\n  implicit feedback [arXiv:1204.1259]", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Albeit the implicit feedback based recommendation problem - when only the\nuser history is available but there are no ratings - is the most typical\nsetting in real-world applications, it is much less researched than the\nexplicit feedback case. State-of-the-art algorithms that are efficient on the\nexplicit case cannot be automatically transformed to the implicit case if\nscalability should be maintained. There are few implicit feedback benchmark\ndata sets, therefore new ideas are usually experimented on explicit benchmarks.\nIn this paper, we propose a generic context-aware implicit feedback recommender\nalgorithm, coined iTALS. iTALS applies a fast, ALS-based tensor factorization\nlearning method that scales linearly with the number of non-zero elements in\nthe tensor. We also present two approximate and faster variants of iTALS using\ncoordinate descent and conjugate gradient methods at learning. The method also\nallows us to incorporate various contextual information into the model while\nmaintaining its computational efficiency. We present two context-aware variants\nof iTALS incorporating seasonality and item purchase sequentiality into the\nmodel to distinguish user behavior at different time intervals, and product\ntypes with different repetitiveness. Experiments run on six data sets shows\nthat iTALS clearly outperforms context-unaware models and context aware\nbaselines, while it is on par with factorization machines (beats 7 times out of\n12 cases) both in terms of recall and MAP.\n", "versions": [{"version": "v1", "created": "Sun, 29 Sep 2013 15:50:45 GMT"}], "update_date": "2013-10-01", "authors_parsed": [["Hidasi", "Bal\u00e1zs", ""], ["Tikk", "Domonkos", ""]]}]