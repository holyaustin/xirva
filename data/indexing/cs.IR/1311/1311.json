[{"id": "1311.0251", "submitter": "Andrew Mao", "authors": "Andrew Mao, Hossein Azari Soufiani, Yiling Chen, David C. Parkes", "title": "Capturing Variation and Uncertainty in Human Judgment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-studied problem of statistical rank aggregation has been applied to\ncomparing sports teams, information retrieval, and most recently to data\ngenerated by human judgment. Such human-generated rankings may be substantially\ndifferent from traditional statistical ranking data. In this work, we show that\na recently proposed generalized random utility model reveals distinctive\npatterns in human judgment across three different domains, and provides a\nsuccinct representation of variance in both population preferences and\nimperfect perception. In contrast, we also show that classical statistical\nranking models fail to capture important features from human-generated input.\nOur work motivates the use of more flexible ranking models for representing and\ndescribing the collective preferences or decision-making of human participants.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2013 21:30:59 GMT"}, {"version": "v2", "created": "Mon, 3 Nov 2014 22:10:36 GMT"}], "update_date": "2014-11-05", "authors_parsed": [["Mao", "Andrew", ""], ["Soufiani", "Hossein Azari", ""], ["Chen", "Yiling", ""], ["Parkes", "David C.", ""]]}, {"id": "1311.0339", "submitter": "Sonali Goyal", "authors": "Sonali Gupta, Komal Kumar Bhatia", "title": "A Novel Term Weighing Scheme Towards Efficient Crawl of Textual\n  Databases", "comments": "12 Pages. IJCEA, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hidden Web is the vast repository of informational databases available\nonly through search form interfaces, accessible by therein typing a set of\nkeywords in the search forms. Typically, a Hidden Web crawler is employed to\nautonomously discover and download pages from the Hidden Web. Traditional\nhidden web crawlers do not provide the search engines with an optimal search\nexperience because of the excessive number of search requests posed through the\nform interface so as to exhaustively crawl and retrieve the contents of the\ntarget hidden web database. Here in our work, we provide a framework to\ninvestigate the problem of optimal search and curtail it by proposing an\neffective query term selection approach based on the frequency & distribution\nof terms in the document database. The paper focuses on developing a\nterm-weighing scheme called VarDF (acronym for variable document frequency)\nthat can ease the identification of optimal terms to be used as queries on the\ninterface for maximizing the achieved coverage of the crawler which in turn\nwill facilitate the search engine to have a diversified and expanded index. We\nexperimentally evaluate the effectiveness of our approach on a manually created\ndatabase of documents in the area of Information Retrieval.\n", "versions": [{"version": "v1", "created": "Sat, 2 Nov 2013 04:45:36 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["Gupta", "Sonali", ""], ["Bhatia", "Komal Kumar", ""]]}, {"id": "1311.0667", "submitter": "Wilko van Hoek", "authors": "Wilko van Hoek", "title": "Developing a Visual Interactive Search History Exploration System", "comments": "KNOWeSCAPE 2013, 2 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As users advance in their search within a system, different queries are\nconducted and various results are examined by them. These objects form an\nimplicit individual library representing the acquired knowledge. In our\nresearch we aim to supply the user with visualizations of the search history\nand interaction methods to organize the history. The fundamental question is\nwhat role search history exploration can play in the users search process. In\nthis paper we want to introduce Ideas of a prototypical system for search\nhistory exploration and discuss methods to address the questions mentioned\nabove.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 12:13:50 GMT"}], "update_date": "2013-11-05", "authors_parsed": [["van Hoek", "Wilko", ""]]}, {"id": "1311.1082", "submitter": "Patrick Kenekayoro", "authors": "Patrick Kenekayoro, Kevan Buckley, Mike Thelwall", "title": "Motivation for hyperlink creation using inter-page relationships", "comments": "The 14th. Conference of the International Society for Scientometrics\n  and. Informetrics (ISSI), Vienna, Austria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using raw hyperlink counts for webometrics research has been shown to be\nunreliable and researchers have looked for alternatives. One alternative is\nclassifying hyperlinks in a website based on the motivation behind the\nhyperlink creation. The method used for this type of classification involves\nmanually visiting a webpage and then classifying individual links on the\nwebpage. This is time consuming, making it infeasible for large scale studies.\nThis paper speeds up the classification of hyperlinks in UK academic websites\nby using a machine learning technique, decision tree induction, to group web\npages found in UK academic websites into one of eight categories and then infer\nthe motivation for the creation of a hyperlink in a webpage based on the\nlinking pattern of the category the webpage belongs to.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 12:10:29 GMT"}], "update_date": "2013-11-06", "authors_parsed": [["Kenekayoro", "Patrick", ""], ["Buckley", "Kevan", ""], ["Thelwall", "Mike", ""]]}, {"id": "1311.1162", "submitter": "Bernardo Huberman", "authors": "Claudia Wagner, Philipp Singer, Markus Strohmaier and Bernardo A.\n  Huberman", "title": "Semantic Stability in Social Tagging Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One potential disadvantage of social tagging systems is that due to the lack\nof a centralized vocabulary, a crowd of users may never manage to reach a\nconsensus on the description of resources (e.g., books, users or songs) on the\nWeb. Yet, previous research has provided interesting evidence that the tag\ndistributions of resources may become semantically stable over time as more and\nmore users tag them. At the same time, previous work has raised an array of new\nquestions such as: (i) How can we assess the semantic stability of social\ntagging systems in a robust and methodical way? (ii) Does semantic\nstabilization of tags vary across different social tagging systems and\nultimately, (iii) what are the factors that can explain semantic stabilization\nin such systems? In this work we tackle these questions by (i) presenting a\nnovel and robust method which overcomes a number of limitations in existing\nmethods, (ii) empirically investigating semantic stabilization processes in a\nwide range of social tagging systems with distinct domains and properties and\n(iii) detecting potential causes for semantic stabilization, specifically\nimitation behavior, shared background knowledge and intrinsic properties of\nnatural language. Our results show that tagging streams which are generated by\na combination of imitation dynamics and shared background knowledge exhibit\nfaster and higher semantic stability than tagging streams which are generated\nvia imitation dynamics or natural language streams alone.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2013 19:00:02 GMT"}], "update_date": "2013-11-06", "authors_parsed": [["Wagner", "Claudia", ""], ["Singer", "Philipp", ""], ["Strohmaier", "Markus", ""], ["Huberman", "Bernardo A.", ""]]}, {"id": "1311.1247", "submitter": "Jeon-Hyung Kang", "authors": "Jeon-Hyung Kang, Kristina Lerman", "title": "LA-CTR: A Limited Attention Collaborative Topic Regression for Social\n  Media", "comments": "The Twenty-Seventh AAAI Conference on Artificial Intelligence (AAAI\n  2013)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic models can learn users' preferences from the history of their\nitem adoptions on a social media site, and in turn, recommend new items to\nusers based on learned preferences. However, current models ignore\npsychological factors that play an important role in shaping online social\nbehavior. One such factor is attention, the mechanism that integrates\nperceptual and cognitive features to select the items the user will consciously\nprocess and may eventually adopt. Recent research has shown that people have\nfinite attention, which constrains their online interactions, and that they\ndivide their limited attention non-uniformly over other people. We propose a\ncollaborative topic regression model that incorporates limited, non-uniformly\ndivided attention. We show that the proposed model is able to learn more\naccurate user preferences than state-of-art models, which do not take human\ncognitive factors into account. Specifically we analyze voting on news items on\nthe social news aggregator and show that our model is better able to predict\nheld out votes than alternate models. Our study demonstrates that\npsycho-socially motivated models are better able to describe and predict\nobserved behavior than models which only consider latent social structure and\ncontent.\n", "versions": [{"version": "v1", "created": "Tue, 5 Nov 2013 23:23:44 GMT"}], "update_date": "2013-11-07", "authors_parsed": [["Kang", "Jeon-Hyung", ""], ["Lerman", "Kristina", ""]]}, {"id": "1311.1406", "submitter": "Martin Takac", "authors": "Martin Tak\\'a\\v{c}, Selin Damla Ahipa\\c{s}ao\\u{g}lu, Ngai-Man Cheung,\n  Peter Richt\\'arik", "title": "TOP-SPIN: TOPic discovery via Sparse Principal component INterference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel topic discovery algorithm for unlabeled images based on\nthe bag-of-words (BoW) framework. We first extract a dictionary of visual words\nand subsequently for each image compute a visual word occurrence histogram. We\nview these histograms as rows of a large matrix from which we extract sparse\nprincipal components (PCs). Each PC identifies a sparse combination of visual\nwords which co-occur frequently in some images but seldom appear in others.\nEach sparse PC corresponds to a topic, and images whose interference with the\nPC is high belong to that topic, revealing the common parts possessed by the\nimages. We propose to solve the associated sparse PCA problems using an\nAlternating Maximization (AM) method, which we modify for purpose of\nefficiently extracting multiple PCs in a deflation scheme. Our approach attacks\nthe maximization problem in sparse PCA directly and is scalable to\nhigh-dimensional data. Experiments on automatic topic discovery and category\nprediction demonstrate encouraging performance of our approach.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 19:03:31 GMT"}], "update_date": "2013-11-07", "authors_parsed": [["Tak\u00e1\u010d", "Martin", ""], ["Ahipa\u015fao\u011flu", "Selin Damla", ""], ["Cheung", "Ngai-Man", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1311.1704", "submitter": "Prem Gopalan", "authors": "Prem Gopalan, Jake M. Hofman, David M. Blei", "title": "Scalable Recommendation with Poisson Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a Bayesian Poisson matrix factorization model for forming\nrecommendations from sparse user behavior data. These data are large user/item\nmatrices where each user has provided feedback on only a small subset of items,\neither explicitly (e.g., through star ratings) or implicitly (e.g., through\nviews or purchases). In contrast to traditional matrix factorization\napproaches, Poisson factorization implicitly models each user's limited\nattention to consume items. Moreover, because of the mathematical form of the\nPoisson likelihood, the model needs only to explicitly consider the observed\nentries in the matrix, leading to both scalable computation and good predictive\nperformance. We develop a variational inference algorithm for approximate\nposterior inference that scales up to massive data sets. This is an efficient\nalgorithm that iterates over the observed entries and adjusts an approximate\nposterior over the user/item representations. We apply our method to large\nreal-world user data containing users rating movies, users listening to songs,\nand users reading scientific papers. In all these settings, Bayesian Poisson\nfactorization outperforms state-of-the-art matrix factorization methods.\n", "versions": [{"version": "v1", "created": "Thu, 7 Nov 2013 14:58:40 GMT"}, {"version": "v2", "created": "Tue, 12 Nov 2013 17:23:05 GMT"}, {"version": "v3", "created": "Tue, 20 May 2014 19:19:30 GMT"}], "update_date": "2014-05-21", "authors_parsed": [["Gopalan", "Prem", ""], ["Hofman", "Jake M.", ""], ["Blei", "David M.", ""]]}, {"id": "1311.2103", "submitter": "Animesh Pandey Mr.", "authors": "Animesh Pandey", "title": "Idea of a new Personality-Type based Recommendation Engine", "comments": "7 Pages, 13 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Myers-Briggs Type Indicator (MBTI) types depict the psychological preferences\nby which a person perceives the world and make decisions. There are 4 principal\nfunctions through which the people see the world: sensation, intuition,\nfeeling, and thinking. These functions along with the Introverted\\Extroverted\nnature of the person, there are 16 personalities types, the humans are divided\ninto. Here an idea is presented where a user can get recommendations for books,\nweb media content, music and movies on the basis of the users' MBTI type. Only\nthings like books and other media content has been chosen because the\npreferences in such things are mostly subjective. Apart from the recommended\ncontent that is generally generated on the basis of the previous purchases,\nsearches can be enhanced by using the MBTI. A minimalist survey was designed\nfor collecting the data. This has a more than 100 features that show the\npreference of a personality type. Those include preferences in book genres,\nmusic genres, movie genres and even video games genres. After analyzing the\ndata that is collected from the survey, some inferences were drawn from it\nwhich can be used to design a new recommendation engine for recommending the\ncontent that coincides with the personality of the user.\n", "versions": [{"version": "v1", "created": "Fri, 8 Nov 2013 23:17:47 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Pandey", "Animesh", ""]]}, {"id": "1311.2349", "submitter": "Haleh Amintoosi", "authors": "Haleh Amintoosi, Salil S. Kanhere", "title": "Providing Trustworthy Contributions via a Reputation Framework in Social\n  Participatory Sensing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": "CSE-TR 201304", "categories": "cs.SI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social participatory sensing is a newly proposed paradigm that tries to\naddress the limitations of participatory sensing by leveraging online social\nnetworks as an infrastructure. A critical issue in the success of this paradigm\nis to assure the trustworthiness of contributions provided by participants. In\nthis paper, we propose an application-agnostic reputation framework for social\nparticipatory sensing systems. Our framework considers both the quality of\ncontribution and the trustworthiness level of participant within the social\nnetwork. These two aspects are then combined via a fuzzy inference system to\narrive at a final trust rating for a contribution. A reputation score is also\ncalculated for each participant as a resultant of the trust ratings assigned to\nhim. We adopt the utilization of PageRank algorithm as the building block for\nour reputation module. Extensive simulations demonstrate the efficacy of our\nframework in achieving high overall trust and assigning accurate reputation\nscores.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 04:10:50 GMT"}], "update_date": "2013-11-12", "authors_parsed": [["Amintoosi", "Haleh", ""], ["Kanhere", "Salil S.", ""]]}, {"id": "1311.2526", "submitter": "Kang Zhao", "authors": "Kang Zhao, Xi Wang, Mo Yu, and Bo Gao", "title": "User recommendation in reciprocal and bipartite social networks -- a\n  case study of online dating", "comments": "IEEE Intelligent Systems (2014 forthcoming)", "journal-ref": null, "doi": "10.1109/MIS.2013.104", "report-no": null, "categories": "cs.SI cs.IR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many social networks in our daily life are bipartite networks built on\nreciprocity. How can we recommend users/friends to a user, so that the user is\ninterested in and attractive to recommended users? In this research, we propose\na new collaborative filtering model to improve user recommendations in\nreciprocal and bipartite social networks. The model considers a user's \"taste\"\nin picking others and \"attractiveness\" in being picked by others. A case study\nof an online dating network shows that the new model has good performance in\nrecommending both initial and reciprocal contacts.\n", "versions": [{"version": "v1", "created": "Mon, 11 Nov 2013 18:46:16 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2014 23:03:48 GMT"}], "update_date": "2014-02-24", "authors_parsed": [["Zhao", "Kang", ""], ["Wang", "Xi", ""], ["Yu", "Mo", ""], ["Gao", "Bo", ""]]}, {"id": "1311.3064", "submitter": "Matus Medo", "authors": "Hao Liao, Rui Xiao, Giulio Cimini, Matus Medo", "title": "Ranking users, papers and authors in online scientific communities", "comments": "7 pages, 3 figures, 3 tables", "journal-ref": "PLoS ONE 9(12): e112022 (2014)", "doi": "10.1371/journal.pone.0112022", "report-no": null, "categories": "cs.SI cs.DL cs.IR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ever-increasing quantity and complexity of scientific production have\nmade it difficult for researchers to keep track of advances in their own\nfields. This, together with growing popularity of online scientific\ncommunities, calls for the development of effective information filtering\ntools. We propose here a method to simultaneously compute reputation of users\nand quality of scientific artifacts in an online scientific community.\nEvaluation on artificially-generated data and real data from the Econophysics\nForum is used to determine the method's best-performing variants. We show that\nwhen the method is extended by considering author credit, its performance\nimproves on multiple levels. In particular, top papers have higher citation\ncount and top authors have higher $h$-index than top papers and top authors\nchosen by other algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2013 10:02:47 GMT"}, {"version": "v2", "created": "Fri, 9 May 2014 09:34:12 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Liao", "Hao", ""], ["Xiao", "Rui", ""], ["Cimini", "Giulio", ""], ["Medo", "Matus", ""]]}, {"id": "1311.3175", "submitter": "Athira P M", "authors": "Athira P. M., Sreeja M. and P. C. Reghu Raj", "title": "Architecture of an Ontology-Based Domain-Specific Natural Language\n  Question Answering System", "comments": null, "journal-ref": "International Journal of Web & Semantic Technology (IJWesT) Vol.4,\n  No.4, October 2013", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question answering (QA) system aims at retrieving precise information from a\nlarge collection of documents against a query. This paper describes the\narchitecture of a Natural Language Question Answering (NLQA) system for a\nspecific domain based on the ontological information, a step towards semantic\nweb question answering. The proposed architecture defines four basic modules\nsuitable for enhancing current QA capabilities with the ability of processing\ncomplex questions. The first module was the question processing, which analyses\nand classifies the question and also reformulates the user query. The second\nmodule allows the process of retrieving the relevant documents. The next module\nprocesses the retrieved documents, and the last module performs the extraction\nand generation of a response. Natural language processing techniques are used\nfor processing the question and documents and also for answer extraction.\nOntology and domain knowledge are used for reformulating queries and\nidentifying the relations. The aim of the system is to generate short and\nspecific answer to the question that is asked in the natural language in a\nspecific domain. We have achieved 94 % accuracy of natural language question\nanswering in our implementation.\n", "versions": [{"version": "v1", "created": "Wed, 13 Nov 2013 15:36:12 GMT"}], "update_date": "2013-11-14", "authors_parsed": [["M.", "Athira P.", ""], ["M.", "Sreeja", ""], ["Raj", "P. C. Reghu", ""]]}, {"id": "1311.3394", "submitter": "Abeer Elkorany", "authors": "Abeer El-korany", "title": "Integrated Expert Recommendation Model for Online Communities", "comments": null, "journal-ref": "International Journal of Web & Semantic Technology (IJWesT),\n  October 2013, Volume 4, Number 4", "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online communities have become vital places for Web 2.0 users to share\nknowledge and experiences. Recently, finding expertise user in community has\nbecome an important research issue. This paper proposes a novel cascaded model\nfor expert recommendation using aggregated knowledge extracted from enormous\ncontents and social network features. Vector space model is used to compute the\nrelevance of published content with respect to a specific query while PageRank\nalgorithm is applied to rank candidate experts. The experimental results show\nthat the proposed model is an effective recommendation which can guarantee that\nthe most candidate experts are both highly relevant to the specific queries and\nhighly influential in corresponding areas.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 07:13:06 GMT"}], "update_date": "2013-11-15", "authors_parsed": [["El-korany", "Abeer", ""]]}, {"id": "1311.3732", "submitter": "Kien Nguyen", "authors": "Kien Duy Nguyen, Tuan Pham Minh, Quang Nhat Nguyen, Thanh Trung Nguyen", "title": "Exploiting Direct and Indirect Information for Friend Suggestion in\n  ZingMe", "comments": "NIPS workshop, 9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Friend suggestion is a fundamental problem in social networks with the goal\nof assisting users in creating more relationships, and thereby enhances\ninterest of users to the social networks. This problem is often considered to\nbe the link prediction problem in the network. ZingMe is one of the largest\nsocial networks in Vietnam. In this paper, we analyze the current approach for\nthe friend suggestion problem in ZingMe, showing its limitations and\ndisadvantages. We propose a new efficient approach for friend suggestion that\nuses information from the network structure, attributes and interactions of\nusers to create resources for the evaluation of friend connection amongst\nusers. Friend connection is evaluated exploiting both direct communication\nbetween the users and information from other ones in the network. The proposed\napproach has been implemented in a new system version of ZingMe. We conducted\nexperiments, exploiting a dataset derived from the users' real use of ZingMe,\nto compare the newly proposed approach to the current approach and some\nwell-known ones for the accuracy of friend suggestion. The experimental results\nshow that the newly proposed approach outperforms the current one, i.e., by an\nincrease of 7% to 98% on average in the friend suggestion accuracy. The\nproposed approach also outperforms other ones for users who have a small number\nof friends with improvements from 20% to 85% on average. In this paper, we also\ndiscuss a number of open issues and possible improvements for the proposed\napproach.\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2013 05:56:48 GMT"}], "update_date": "2013-11-18", "authors_parsed": [["Nguyen", "Kien Duy", ""], ["Minh", "Tuan Pham", ""], ["Nguyen", "Quang Nhat", ""], ["Nguyen", "Thanh Trung", ""]]}, {"id": "1311.3800", "submitter": "Mohammad Mehdi Keikha", "authors": "Mohammad Mehdi Keikha and Mohammad Ali Nematbakhsh and Behrouz Tork\n  Ladani", "title": "Structural Weights in Ontology Matching", "comments": null, "journal-ref": "2013-Vol 4- International Journal of Web & Semantic Technology\n  (IJWesT)", "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontology matching finds correspondences between similar entities of different\nontologies. Two ontologies may be similar in some aspects such as structure,\nsemantic etc. Most ontology matching systems integrate multiple matchers to\nextract all the similarities that two ontologies may have. Thus, we face a\nmajor problem to aggregate different similarities. Some matching systems use\nexperimental weights for aggregation of similarities among different matchers\nwhile others use machine learning approaches and optimization algorithms to\nfind optimal weights to assign to different matchers. However, both approaches\nhave their own deficiencies. In this paper, we will point out the problems and\nshortcomings of current similarity aggregation strategies. Then, we propose a\nnew strategy, which enables us to utilize the structural information of\nontologies to get weights of matchers, for the similarity aggregation task. For\nachieving this goal, we create a new Ontology Matching system which it uses\nthree available matchers, namely GMO, ISub and VDoc. We have tested our\nsimilarity aggregation strategy on the OAEI 2012 data set. Experimental results\nshow significant improvements in accuracies of several cases, especially in\nmatching the classes of ontologies. We will compare the performance of our\nsimilarity aggregation strategy with other well-known strategies\n", "versions": [{"version": "v1", "created": "Fri, 15 Nov 2013 10:34:31 GMT"}], "update_date": "2013-11-18", "authors_parsed": [["Keikha", "Mohammad Mehdi", ""], ["Nematbakhsh", "Mohammad Ali", ""], ["Ladani", "Behrouz Tork", ""]]}, {"id": "1311.3987", "submitter": "Seyed-Mehdi-Reza Beheshti", "authors": "Seyed-Mehdi-Reza Beheshti and Srikumar Venugopal and Seung Hwan Ryu\n  and Boualem Benatallah and Wei Wang", "title": "Big Data and Cross-Document Coreference Resolution: Current State and\n  Future Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.DC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Extraction (IE) is the task of automatically extracting\nstructured information from unstructured/semi-structured machine-readable\ndocuments. Among various IE tasks, extracting actionable intelligence from\never-increasing amount of data depends critically upon Cross-Document\nCoreference Resolution (CDCR) - the task of identifying entity mentions across\nmultiple documents that refer to the same underlying entity. Recently, document\ndatasets of the order of peta-/tera-bytes has raised many challenges for\nperforming effective CDCR such as scaling to large numbers of mentions and\nlimited representational power. The problem of analysing such datasets is\ncalled \"big data\". The aim of this paper is to provide readers with an\nunderstanding of the central concepts, subtasks, and the current\nstate-of-the-art in CDCR process. We provide assessment of existing\ntools/techniques for CDCR subtasks and highlight big data challenges in each of\nthem to help readers identify important and outstanding issues for further\ninvestigation. Finally, we provide concluding remarks and discuss possible\ndirections for future work.\n", "versions": [{"version": "v1", "created": "Thu, 14 Nov 2013 06:10:15 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Beheshti", "Seyed-Mehdi-Reza", ""], ["Venugopal", "Srikumar", ""], ["Ryu", "Seung Hwan", ""], ["Benatallah", "Boualem", ""], ["Wang", "Wei", ""]]}, {"id": "1311.4150", "submitter": "Jian-Feng Yan", "authors": "Jian-Feng Yan, Jia Zeng, Zhi-Qiang Liu, Yang Gao", "title": "Towards Big Topic Modeling", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To solve the big topic modeling problem, we need to reduce both time and\nspace complexities of batch latent Dirichlet allocation (LDA) algorithms.\nAlthough parallel LDA algorithms on the multi-processor architecture have low\ntime and space complexities, their communication costs among processors often\nscale linearly with the vocabulary size and the number of topics, leading to a\nserious scalability problem. To reduce the communication complexity among\nprocessors for a better scalability, we propose a novel communication-efficient\nparallel topic modeling architecture based on power law, which consumes orders\nof magnitude less communication time when the number of topics is large. We\ncombine the proposed communication-efficient parallel architecture with the\nonline belief propagation (OBP) algorithm referred to as POBP for big topic\nmodeling tasks. Extensive empirical results confirm that POBP has the following\nadvantages to solve the big topic modeling problem: 1) high accuracy, 2)\ncommunication-efficient, 3) fast speed, and 4) constant memory usage when\ncompared with recent state-of-the-art parallel LDA algorithms on the\nmulti-processor architecture.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2013 11:52:42 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Yan", "Jian-Feng", ""], ["Zeng", "Jia", ""], ["Liu", "Zhi-Qiang", ""], ["Gao", "Yang", ""]]}, {"id": "1311.4151", "submitter": "Hichem Benfriha BH", "authors": "Hichem Benfriha, Fatiha Barigou, Baghdad Atmani", "title": "Lattice-cell : Hybrid approach for text categorization", "comments": "Computer Science & Information Technology (CS & IT) 2013", "journal-ref": null, "doi": "10.5121/csit.2013.3817", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new text categorization framework based on\nConcepts Lattice and cellular automata. In this framework, concept structure\nare modeled by a Cellular Automaton for Symbolic Induction (CASI). Our\nobjective is to reduce time categorization caused by the Concept Lattice. We\nexamine, by experiments the performance of the proposed approach and compare it\nwith other algorithms such as Naive Bayes and k nearest neighbors. The results\nshow performance improvement while reducing time categorization.\n", "versions": [{"version": "v1", "created": "Sun, 17 Nov 2013 12:02:12 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Benfriha", "Hichem", ""], ["Barigou", "Fatiha", ""], ["Atmani", "Baghdad", ""]]}, {"id": "1311.4420", "submitter": "Kiran Sree Pokkuluri Prof", "authors": "P. Kiran Sree, Inampudi Ramesh Babu, SSSN Usha Devi N", "title": "CAVDM: Cellular Automata Based Video Cloud Mining Framework for\n  Information Retrieval", "comments": null, "journal-ref": "Parallel Computing and Cloud Computing Research (PCCR) Volume 1\n  Issue 1, April 2013", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Mining technique can be applied to various documents. Acquisition and\nstorage of video data is an easy task but retrieval of information from video\ndata is a challenging task. So video Cloud Mining plays an important role in\nefficient video data management for information retrieval. This paper proposes\na Cellular Automata based framework for video Cloud Mining to extract the\ninformation from video data. This includes developing the technique for shot\ndetection then key frame analysis is considered to compare the frames of each\nshot to each others to define the relationship between shots. Cellular automata\nbased hierarchical clustering technique is adopted to make a group of similar\nshots to detect the particular event on some requirement as per user demand.\n", "versions": [{"version": "v1", "created": "Mon, 18 Nov 2013 15:12:42 GMT"}], "update_date": "2013-11-19", "authors_parsed": [["Sree", "P. Kiran", ""], ["Babu", "Inampudi Ramesh", ""], ["N", "SSSN Usha Devi", ""]]}, {"id": "1311.4644", "submitter": "Yu Liu", "authors": "Yong Gao, Lei Liu, Xing Lin, Yu Liu", "title": "A Qualitative Representation and Similarity Measurement Method in\n  Geographic Information Retrieval", "comments": "17 Pages, 2 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modern geographic information retrieval technology is based on\nquantitative models and methods. The semantic information in web documents and\nqueries cannot be effectively represented, leading to information lost or\nmisunderstanding so that the results are either unreliable or inconsistent. A\nnew qualitative approach is thus proposed for supporting geographic information\nretrieval based on qualitative representation, semantic matching, and\nqualitative reasoning. A qualitative representation model and the corresponding\nsimilarity measurement method are defined. Information in documents and user\nqueries are represented using propositional logic, which considers the thematic\nand geographic semantics synthetically. Thematic information is represented as\nthematic propositions on the base of domain ontology. Similarly, spatial\ninformation is represented as geo-spatial propositions with the support of\ngeographic knowledge base. Then the similarity is divided into thematic\nsimilarity and spatial similarity. The former is calculated by the weighted\ndistance of proposition keywords in the domain ontology, and the latter\nsimilarity is further divided into conceptual similarity and spatial\nsimilarity. Represented by propositions and information units, the similarity\nmeasurement can take evidence theory and fuzzy logic to combine all sub\nsimilarities to get the final similarity between documents and queries. This\nnovel retrieval method is mainly used to retrieve the qualitative geographic\ninformation to support the semantic matching and results ranking. It does not\ndeal with geometric computation and is consistent with human commonsense\ncognition, and thus can improve the efficiency of geographic information\nretrieval technology.\n", "versions": [{"version": "v1", "created": "Tue, 19 Nov 2013 08:04:28 GMT"}], "update_date": "2013-11-20", "authors_parsed": [["Gao", "Yong", ""], ["Liu", "Lei", ""], ["Lin", "Xing", ""], ["Liu", "Yu", ""]]}, {"id": "1311.4900", "submitter": "Sonali Goyal", "authors": "Sudhakar Ranjan, Komal K. Bhatia", "title": "Query Interface Integrator For Domain Specific Hidden Web", "comments": "8 Pages. International Journal of Computer Engineering and\n  Applications, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web is title admittance today mainly relies on search engines. A large amount\nof data is hidden in the databases behind the search interfaces referred to as\nHidden web, which needs to be indexed so in order to serve user query. In this\npaper database and data mining techniques are used for query interface\nintegration. The query interface must resemble the look and feel of local\ninterface as much as possible despite being automatically generated without\nhuman support.This technique keeps the related documents in the same domain so\nthat searching of documents becomes more efficient in terms of time complexity.\n", "versions": [{"version": "v1", "created": "Sat, 16 Nov 2013 06:25:40 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Ranjan", "Sudhakar", ""], ["Bhatia", "Komal K.", ""]]}, {"id": "1311.5013", "submitter": "Srivatsan Sridharan", "authors": "Srivatsan Sridharan, Kausal Malladi, Yamini Muralitharan", "title": "Data Mining Model for the Data Retrieval from Central Server\n  Configuration", "comments": "9 Pages, 10 References, 6 Figures presented in ACITY 2013 Conference", "journal-ref": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 5, No 5, October 2013", "doi": "10.5121/ijcsit.2013.5514", "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A server, which is to keep track of heavy document traffic, is unable to\nfilter the documents that are most relevant and updated for continuous text\nsearch queries. This paper focuses on handling continuous text extraction\nsustaining high document traffic. The main objective is to retrieve recent\nupdated documents that are most relevant to the query by applying sliding\nwindow technique. Our solution indexes the streamed documents in the main\nmemory with structure based on the principles of inverted file, and processes\ndocument arrival and expiration events with incremental threshold-based method.\nIt also ensures elimination of duplicate document retrieval using unsupervised\nduplicate detection. The documents are ranked based on user feedback and given\nhigher priority for retrieval.\n", "versions": [{"version": "v1", "created": "Wed, 20 Nov 2013 11:14:58 GMT"}], "update_date": "2013-11-21", "authors_parsed": [["Sridharan", "Srivatsan", ""], ["Malladi", "Kausal", ""], ["Muralitharan", "Yamini", ""]]}, {"id": "1311.5401", "submitter": "Nicolas Turenne", "authors": "Nicolas Turenne", "title": "Clustering and Relational Ambiguity: from Text Data to Natural Data", "comments": null, "journal-ref": "Journal of Data Mining & Digital Humanities, 2014 (June 24, 2014)\n  jdmdh:13", "doi": "10.46298/jdmdh.4", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Text data is often seen as \"take-away\" materials with little noise and easy\nto process information. Main questions are how to get data and transform them\ninto a good document format. But data can be sensitive to noise oftenly called\nambiguities. Ambiguities are aware from a long time, mainly because polysemy is\nobvious in language and context is required to remove uncertainty. I claim in\nthis paper that syntactic context is not suffisant to improve interpretation.\nIn this paper I try to explain that firstly noise can come from natural data\nthemselves, even involving high technology, secondly texts, seen as verified\nbut meaningless, can spoil content of a corpus; it may lead to contradictions\nand background noise.\n", "versions": [{"version": "v1", "created": "Thu, 21 Nov 2013 13:47:21 GMT"}, {"version": "v2", "created": "Thu, 10 Apr 2014 17:49:51 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Turenne", "Nicolas", ""]]}, {"id": "1311.5765", "submitter": "Srikanth Bethu Mr", "authors": "Srikanth Bethu, G Charless Babu, J Vinoda, E Priyadarshini, M\n  Raghavendra rao", "title": "Text Classification and Distributional features techniques in Datamining\n  and Warehousing", "comments": "arXiv admin note: text overlap with arXiv:0912.1014, arXiv:1002.3985\n  by other authors without attribution", "journal-ref": "IJIP 2013, Volume 7 issue 3", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text Categorization is traditionally done by using the term frequency and\ninverse document frequency.This type of method is not very good because, some\nwords which are not so important may appear in the document .The term frequency\nof unimportant words may increase and document may be classified in the wrong\ncategory.For reducing the error of classifying of documents in wrong category.\nThe Distributional features are introduced. In the Distribuional Features, the\nDistribution of the words in the whole document is analyzed. Whole Document is\nvery closely analyzed for different measures like FirstAppearence, Last\nAppearance, Centriod, Count, etc.The measures are calculated and they are used\nin tf*idf equation and result is used in k- nearest neighbor and K-means\nalgorithm for classifying the documents.\n", "versions": [{"version": "v1", "created": "Fri, 22 Nov 2013 14:36:52 GMT"}], "update_date": "2016-11-25", "authors_parsed": [["Bethu", "Srikanth", ""], ["Babu", "G Charless", ""], ["Vinoda", "J", ""], ["Priyadarshini", "E", ""], ["rao", "M Raghavendra", ""]]}, {"id": "1311.6227", "submitter": "Debajyoti Mukhopadhyay Prof.", "authors": "Debajyoti Mukhopadhyay, Manoj Sharma, Gajanan Joshi, Trupti Pagare,\n  Adarsha Palwe", "title": "Experience of Developing a Meta-Semantic Search Engine", "comments": "4 pages, 9 figures, 1 table. CUBE 2013 International Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Thinking of todays web search scenario which is mainly keyword based, leads\nto the need of effective and meaningful search provided by Semantic Web.\nExisting search engines are vulnerable to provide relevant answers to users\nquery due to their dependency on simple data available in web pages. On other\nhand, semantic search engines provide efficient and relevant results as the\nsemantic web manages information with well defined meaning using ontology. A\nMeta-Search engine is a search tool that forwards users query to several\nexisting search engines and provides combined results by using their own page\nranking algorithm. SemanTelli is a meta semantic search engine that fetches\nresults from different semantic search engines such as Hakia, DuckDuckGo,\nSenseBot through intelligent agents. This paper proposes enhancement of\nSemanTelli with improved snippet analysis based page ranking algorithm and\nsupport for image and news search.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 08:27:35 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Mukhopadhyay", "Debajyoti", ""], ["Sharma", "Manoj", ""], ["Joshi", "Gajanan", ""], ["Pagare", "Trupti", ""], ["Palwe", "Adarsha", ""]]}, {"id": "1311.6240", "submitter": "Debajyoti Mukhopadhyay Prof.", "authors": "Shilpa Sonawani, Debajyoti Mukhopadhyay", "title": "A Decision Tree Approach to Classify Web Services using Quality\n  Parameters", "comments": "9 pages, 3 tables; ICWA 2013 International Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase in the number of web services, many web services are\navailable on internet providing the same functionality, making it difficult to\nchoose the best one, fulfilling users all requirements. This problem can be\nsolved by considering the quality of web services to distinguish functionally\nsimilar web services. Nine different quality parameters are considered. Web\nservices can be classified and ranked using decision tree approach since they\ndo not require long training period and can be easily interpreted. Various\ndecision tree and rules approaches available are applied and tested to find the\noptimal decision method to correctly classify functionally similar web services\nconsidering their quality parameters.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 09:12:15 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Sonawani", "Shilpa", ""], ["Mukhopadhyay", "Debajyoti", ""]]}, {"id": "1311.6243", "submitter": "Debajyoti Mukhopadhyay Prof.", "authors": "Sukanta Sinha, Rana Dattagupta, Debajyoti Mukhopadhyay", "title": "Web-page Indexing based on the Prioritize Ontology Terms", "comments": "9 pages, 3 figures, 2 tables. ICWA 2013 International Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this world, globalization has become a basic and most popular human trend.\nTo globalize information, people are going to publish the documents in the\ninternet. As a result, information volume of internet has become huge. To\nhandle that huge volume of information, Web searcher uses search engines. The\nWebpage indexing mechanism of a search engine plays a big role to retrieve Web\nsearch results in a faster way from the huge volume of Web resources. Web\nresearchers have introduced various types of Web-page indexing mechanism to\nretrieve Webpages from Webpage repository. In this paper, we have illustrated a\nnew approach of design and development of Webpage indexing. The proposed\nWebpage indexing mechanism has applied on domain specific Webpages and we have\nidentified the Webpage domain based on an Ontology. In our approach, first we\nprioritize the Ontology terms that exist in the Webpage content then apply our\nown indexing mechanism to index that Webpage. The main advantage of storing an\nindex is to optimize the speed and performance while finding relevant documents\nfrom the domain specific search engine storage area for a user given search\nquery.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 09:28:58 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Sinha", "Sukanta", ""], ["Dattagupta", "Rana", ""], ["Mukhopadhyay", "Debajyoti", ""]]}, {"id": "1311.6245", "submitter": "Debajyoti Mukhopadhyay Prof.", "authors": "Debajyoti Mukhopadhyay, Sajeeda Shikalgar", "title": "A Model Approach to Build Basic Ontology", "comments": "12 page, 3 fugures, 2 tables. ICWA 2013 International Conference.\n  arXiv admin note: text overlap with arXiv:1207.2606 by other authors without\n  attribution", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As todays world grows with the technology on the other hand it seems to be\nsmall with the World Wide Web. With the use of Internet more and more\ninformation can be search from the web. When Users fires a query they want\nrelevancy in obtained results. In general, search engines perform the ranking\nof web pages in an offline mode, which is after the web pages have been\nretrieved and stored in the database. But most of the time this method does not\nprovide relevant results as most of the search engines were using some ranking\nalgorithms like page Rank, HITS, SALSA and Hilltop. Where these algorithms does\nnot always provides the results based on the semantic web. So a concept of\nOntology is been introduced in search engines to get more meaningful and\nrelevant results with respect to the users query.Ontologies are used to capture\nknowledge about some domain of interest. Ontology describes the concepts in the\ndomain and also the relationships that hold between those concepts. Different\nontology languages provide different facilities. The most recent development in\nstandard ontology languages is OWL (Ontology Web Language) from the World Wide\nWeb Consortium. OWL makes it possible to describe concept to its full extent\nand enables the search engines to provide accurate results to the user.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 09:35:14 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Mukhopadhyay", "Debajyoti", ""], ["Shikalgar", "Sajeeda", ""]]}, {"id": "1311.6334", "submitter": "Charanpal Dhanjal", "authors": "Charanpal Dhanjal (LTCI), St\\'ephan Cl\\'emen\\c{c}on (LTCI)", "title": "Learning Reputation in an Authorship Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of searching for experts in a given academic field is hugely\nimportant in both industry and academia. We study exactly this issue with\nrespect to a database of authors and their publications. The idea is to use\nLatent Semantic Indexing (LSI) and Latent Dirichlet Allocation (LDA) to perform\ntopic modelling in order to find authors who have worked in a query field. We\nthen construct a coauthorship graph and motivate the use of influence\nmaximisation and a variety of graph centrality measures to obtain a ranked list\nof experts. The ranked lists are further improved using a Markov Chain-based\nrank aggregation approach. The complete method is readily scalable to large\ndatasets. To demonstrate the efficacy of the approach we report on an extensive\nset of computational simulations using the Arnetminer dataset. An improvement\nin mean average precision is demonstrated over the baseline case of simply\nusing the order of authors found by the topic models.\n", "versions": [{"version": "v1", "created": "Mon, 25 Nov 2013 15:25:28 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Dhanjal", "Charanpal", "", "LTCI"], ["Cl\u00e9men\u00e7on", "St\u00e9phan", "", "LTCI"]]}, {"id": "1311.6355", "submitter": "Xinxi Wang", "authors": "Xinxi Wang, Yi Wang, David Hsu, Ye Wang", "title": "Exploration in Interactive Personalized Music Recommendation: A\n  Reinforcement Learning Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current music recommender systems typically act in a greedy fashion by\nrecommending songs with the highest user ratings. Greedy recommendation,\nhowever, is suboptimal over the long term: it does not actively gather\ninformation on user preferences and fails to recommend novel songs that are\npotentially interesting. A successful recommender system must balance the needs\nto explore user preferences and to exploit this information for recommendation.\nThis paper presents a new approach to music recommendation by formulating this\nexploration-exploitation trade-off as a reinforcement learning task called the\nmulti-armed bandit. To learn user preferences, it uses a Bayesian model, which\naccounts for both audio content and the novelty of recommendations. A\npiecewise-linear approximation to the model and a variational inference\nalgorithm are employed to speed up Bayesian inference. One additional benefit\nof our approach is a single unified model for both music recommendation and\nplaylist generation. Both simulation results and a user study indicate strong\npotential for the new approach.\n", "versions": [{"version": "v1", "created": "Wed, 6 Nov 2013 12:20:35 GMT"}], "update_date": "2013-11-26", "authors_parsed": [["Wang", "Xinxi", ""], ["Wang", "Yi", ""], ["Hsu", "David", ""], ["Wang", "Ye", ""]]}, {"id": "1311.6876", "submitter": "Yuan Yao", "authors": "Yuan Yao, Hanghang Tong, Tao Xie, Leman Akoglu, Feng Xu, Jian Lu", "title": "Want a Good Answer? Ask a Good Question First!", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.IR cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community Question Answering (CQA) websites have become valuable repositories\nwhich host a massive volume of human knowledge. To maximize the utility of such\nknowledge, it is essential to evaluate the quality of an existing question or\nanswer, especially soon after it is posted on the CQA website.\n  In this paper, we study the problem of inferring the quality of questions and\nanswers through a case study of a software CQA (Stack Overflow). Our key\nfinding is that the quality of an answer is strongly positively correlated with\nthat of its question. Armed with this observation, we propose a family of\nalgorithms to jointly predict the quality of questions and answers, for both\nquantifying numerical quality scores and differentiating the high-quality\nquestions/answers from those of low quality. We conduct extensive experimental\nevaluations to demonstrate the effectiveness and efficiency of our methods.\n", "versions": [{"version": "v1", "created": "Wed, 27 Nov 2013 06:39:25 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Yao", "Yuan", ""], ["Tong", "Hanghang", ""], ["Xie", "Tao", ""], ["Akoglu", "Leman", ""], ["Xu", "Feng", ""], ["Lu", "Jian", ""]]}, {"id": "1311.7200", "submitter": "Debajyoti Mukhopadhyay Prof.", "authors": "Ayan Chakraborty, Shiladitya Munshi, Debajyoti Mukhopadhyay", "title": "Searching and Establishment of S-P-O Relationships for Linked RDF Graphs\n  : An Adaptive Approach", "comments": "5 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:1107.1104 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the coming era of semantic web linked data analysis is a very burning\nissue for efficient searching and retrieval of information. One way of\nestablishing this link is to implement subject predicate object relationship\nthrough Set Theory approach which is already done in our previous work. For\nanalyzing inter relationship between two RDF Graphs, RDF- Schema (RDFS) should\nalso be taken care of. In the present paper, an adaptive combination rule based\nframework has been proposed for establishment of S P O relationship and RDF\nGraph searching is reported. Hence the identification of criteria for\ninter-relationship of RDF Graphs opens up new road in semantic search.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2013 04:10:55 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Chakraborty", "Ayan", ""], ["Munshi", "Shiladitya", ""], ["Mukhopadhyay", "Debajyoti", ""]]}, {"id": "1311.7204", "submitter": "Debajyoti Mukhopadhyay Prof.", "authors": "Ujwala Wanaskar, Sheetal Vij, Debajyoti Mukhopadhyay", "title": "A Hybrid Web Recommendation System based on the Improved Association\n  Rule Mining Algorithm", "comments": "9 pages, 7 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the growing interest of web recommendation systems those are applied to\ndeliver customized data for their users, we started working on this system.\nGenerally the recommendation systems are divided into two major categories such\nas collaborative recommendation system and content based recommendation system.\nIn case of collaborative recommen-dation systems, these try to seek out users\nwho share same tastes that of given user as well as recommends the websites\naccording to the liking given user. Whereas the content based recommendation\nsystems tries to recommend web sites similar to those web sites the user has\nliked. In the recent research we found that the efficient technique based on\nasso-ciation rule mining algorithm is proposed in order to solve the problem of\nweb page recommendation. Major problem of the same is that the web pages are\ngiven equal importance. Here the importance of pages changes according to the\nfre-quency of visiting the web page as well as amount of time user spends on\nthat page. Also recommendation of newly added web pages or the pages those are\nnot yet visited by users are not included in the recommendation set. To\nover-come this problem, we have used the web usage log in the adaptive\nassociation rule based web mining where the asso-ciation rules were applied to\npersonalization. This algorithm was purely based on the Apriori data mining\nalgorithm in order to generate the association rules. However this method also\nsuffers from some unavoidable drawbacks. In this paper we are presenting and\ninvestigating the new approach based on weighted Association Rule Mining\nAlgorithm and text mining. This is improved algorithm which adds semantic\nknowledge to the results, has more efficiency and hence gives better quality\nand performances as compared to existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2013 04:22:55 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Wanaskar", "Ujwala", ""], ["Vij", "Sheetal", ""], ["Mukhopadhyay", "Debajyoti", ""]]}, {"id": "1311.7388", "submitter": "Ahmad Siddiqui Dr", "authors": "Ahmad Tasnim Siddiqui, Sultan Aljahdali", "title": "Web Mining Techniques in E-Commerce Applications", "comments": "arXiv admin note: text overlap with arXiv:1208.1926 by other authors", "journal-ref": "International Journal of Computer Applications, Volume 69 No.8,\n  May 2013", "doi": "10.5120/11864-7648", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today web is the best medium of communication in modern business. Many\ncompanies are redefining their business strategies to improve the business\noutput. Business over internet provides the opportunity to customers and\npartners where their products and specific business can be found. Nowadays\nonline business breaks the barrier of time and space as compared to the\nphysical office. Big companies around the world are realizing that e-commerce\nis not just buying and selling over Internet, rather it improves the efficiency\nto compete with other giants in the market. For this purpose data mining\nsometimes called as knowledge discovery is used. Web mining is data mining\ntechnique that is applied to the WWW. There are vast quantities of information\navailable over the Internet.\n", "versions": [{"version": "v1", "created": "Thu, 28 Nov 2013 17:57:20 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Siddiqui", "Ahmad Tasnim", ""], ["Aljahdali", "Sultan", ""]]}, {"id": "1311.7662", "submitter": "Behnam Neyshabur", "authors": "Behnam Neyshabur, Payman Yadollahpour, Yury Makarychev, Ruslan\n  Salakhutdinov, Nathan Srebro", "title": "The Power of Asymmetry in Binary Hashing", "comments": "Accepted to NIPS 2013, 9 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When approximating binary similarity using the hamming distance between short\nbinary hashes, we show that even if the similarity is symmetric, we can have\nshorter and more accurate hashes by using two distinct code maps. I.e. by\napproximating the similarity between $x$ and $x'$ as the hamming distance\nbetween $f(x)$ and $g(x')$, for two distinct binary codes $f,g$, rather than as\nthe hamming distance between $f(x)$ and $f(x')$.\n", "versions": [{"version": "v1", "created": "Fri, 29 Nov 2013 18:53:32 GMT"}], "update_date": "2013-12-02", "authors_parsed": [["Neyshabur", "Behnam", ""], ["Yadollahpour", "Payman", ""], ["Makarychev", "Yury", ""], ["Salakhutdinov", "Ruslan", ""], ["Srebro", "Nathan", ""]]}]