[{"id": "1811.00159", "submitter": "Gaurush Hiranandani", "authors": "Gaurush Hiranandani, Raghav Somani, Oluwasanmi Koyejo, Sreangsu\n  Acharyya", "title": "Clustered Monotone Transforms for Rating Factorization", "comments": "The first two authors contributed equally to the paper. The paper to\n  appear in WSDM 2019", "journal-ref": null, "doi": "10.1145/3289600.3291005", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exploiting low-rank structure of the user-item rating matrix has been the\ncrux of many recommendation engines. However, existing recommendation engines\nforce raters with heterogeneous behavior profiles to map their intrinsic rating\nscales to a common rating scale (e.g. 1-5). This non-linear transformation of\nthe rating scale shatters the low-rank structure of the rating matrix,\ntherefore resulting in a poor fit and consequentially, poor recommendations. In\nthis paper, we propose Clustered Monotone Transforms for Rating Factorization\n(CMTRF), a novel approach to perform regression up to unknown monotonic\ntransforms over unknown population segments. Essentially, for recommendation\nsystems, the technique searches for monotonic transformations of the rating\nscales resulting in a better fit. This is combined with an underlying matrix\nfactorization regression model that couples the user-wise ratings to exploit\nshared low dimensional structure. The rating scale transformations can be\ngenerated for each user, for a cluster of users, or for all the users at once,\nforming the basis of three simple and efficient algorithms proposed in this\npaper, all of which alternate between transformation of the rating scales and\nmatrix factorization regression. Despite the non-convexity, CMTRF is\ntheoretically shown to recover a unique solution under mild conditions.\nExperimental results on two synthetic and seven real-world datasets show that\nCMTRF outperforms other state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 23:53:24 GMT"}], "update_date": "2019-03-29", "authors_parsed": [["Hiranandani", "Gaurush", ""], ["Somani", "Raghav", ""], ["Koyejo", "Oluwasanmi", ""], ["Acharyya", "Sreangsu", ""]]}, {"id": "1811.00414", "submitter": "Ewin Tang", "authors": "Ewin Tang", "title": "Quantum-inspired classical algorithms for principal component analysis\n  and supervised clustering", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe classical analogues to Lloyd et al.'s quantum algorithms for\nprincipal component analysis and nearest-centroid clustering. We introduce a\nclassical algorithm model that assumes we can efficiently perform $\\ell^2$-norm\nsamples of input data, a natural analogue to quantum algorithms assuming\nefficient state preparation. In this model, our classical algorithms run in\ntime polylogarithmic in input size, matching the runtime of the quantum\nalgorithms with only polynomial slowdown. These algorithms indicate that their\ncorresponding problems do not yield exponential quantum speedups.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2018 03:23:52 GMT"}, {"version": "v2", "created": "Mon, 25 Nov 2019 10:22:32 GMT"}], "update_date": "2019-11-26", "authors_parsed": [["Tang", "Ewin", ""]]}, {"id": "1811.00606", "submitter": "Grace Hui Yang", "authors": "Zhiwen Tang and Grace Hui Yang", "title": "DeepTileBars: Visualizing Term Distribution for Neural Information\n  Retrieval", "comments": null, "journal-ref": "Proceedings of the AAAI 2019 Conference on Artificial\n  Intelligence, 33(01), 289-296", "doi": "10.1609/aaai.v33i01.3301289", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most neural Information Retrieval (Neu-IR) models derive query-to-document\nranking scores based on term-level matching. Inspired by TileBars, a classical\nterm distribution visualization method, in this paper, we propose a novel\nNeu-IR model that handles query-to-document matching at the subtopic and higher\nlevels. Our system first splits the documents into topical segments,\n\"visualizes\" the matchings between the query and the segments, and then feeds\nan interaction matrix into a Neu-IR model, DeepTileBars, to obtain the final\nranking scores. DeepTileBars models the relevance signals occurring at\ndifferent granularities in a document's topic hierarchy. It better captures the\ndiscourse structure of a document and thus the matching patterns. Although its\ndesign and implementation are light-weight, DeepTileBars outperforms other\nstate-of-the-art Neu-IR models on benchmark datasets including the Text\nREtrieval Conference (TREC) 2010-2012 Web Tracks and LETOR 4.0.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 19:39:14 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 21:44:21 GMT"}, {"version": "v3", "created": "Wed, 9 Jun 2021 13:58:39 GMT"}], "update_date": "2021-06-10", "authors_parsed": [["Tang", "Zhiwen", ""], ["Yang", "Grace Hui", ""]]}, {"id": "1811.00697", "submitter": "Ga Wu", "authors": "Ga Wu, Maksims Volkovs, Chee Loong Soon, Scott Sanner, Himanshu Rai", "title": "Noise Contrastive Estimation for Scalable Linear Models for One-Class\n  Collaborative Filtering", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous highly scalable one-class collaborative filtering methods such as\nProjected Linear Recommendation (PLRec) have advocated using fast randomized\nSVD to embed items into a latent space, followed by linear regression methods\nto learn personalized recommendation models per user. Unfortunately, naive SVD\nembedding methods often exhibit a popularity bias that skews the ability to\naccurately embed niche items. To address this, we leverage insights from Noise\nContrastive Estimation (NCE) to derive a closed-form, efficiently computable\n\"depopularized\" embedding. While this method is not ideal for direct\nrecommendation using methods like PureSVD since popularity still plays an\nimportant role in recommendation, we find that embedding followed by linear\nregression to learn personalized user models in a novel method we call\nNCE-PLRec leverages the improved item embedding of NCE while correcting for its\npopularity unbiasing in final recommendations. An analysis of the\nrecommendation popularity distribution demonstrates that NCE-PLRec uniformly\ndistributes its recommendations over the popularity spectrum while other\nmethods exhibit distinct biases towards specific popularity subranges, thus\nartificially restricting their recommendations. Empirically, NCE-PLRec\noutperforms state-of-the-art methods as well as various ablations of itself on\na variety of large-scale recommendation datasets.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 01:23:51 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Wu", "Ga", ""], ["Volkovs", "Maksims", ""], ["Soon", "Chee Loong", ""], ["Sanner", "Scott", ""], ["Rai", "Himanshu", ""]]}, {"id": "1811.00706", "submitter": "Luis Borges", "authors": "Lu\\'is Borges, Bruno Martins, P\\'avel Calado", "title": "Combining Similarity Features and Deep Representation Learning for\n  Stance Detection in the Context of Checking Fake News", "comments": "Accepted for publication in the special issue of the ACM Journal of\n  Data and Information Quality (ACM JDIQ) on Combating Digital Misinformation\n  and Disinformation", "journal-ref": "Journal of Data and Information Quality (JDIQ) 11 (3), 1-26, 2019", "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake news are nowadays an issue of pressing concern, given their recent rise\nas a potential threat to high-quality journalism and well-informed public\ndiscourse. The Fake News Challenge (FNC-1) was organized in 2017 to encourage\nthe development of machine learning-based classification systems for stance\ndetection (i.e., for identifying whether a particular news article agrees,\ndisagrees, discusses, or is unrelated to a particular news headline), thus\nhelping in the detection and analysis of possible instances of fake news. This\narticle presents a new approach to tackle this stance detection problem, based\non the combination of string similarity features with a deep neural\narchitecture that leverages ideas previously advanced in the context of\nlearning efficient text representations, document classification, and natural\nlanguage inference. Specifically, we use bi-directional Recurrent Neural\nNetworks, together with max-pooling over the temporal/sequential dimension and\nneural attention, for representing (i) the headline, (ii) the first two\nsentences of the news article, and (iii) the entire news article. These\nrepresentations are then combined/compared, complemented with similarity\nfeatures inspired on other FNC-1 approaches, and passed to a final layer that\npredicts the stance of the article towards the headline. We also explore the\nuse of external sources of information, specifically large datasets of sentence\npairs originally proposed for training and evaluating natural language\ninference methods, in order to pre-train specific components of the neural\nnetwork architecture (e.g., the RNNs used for encoding sentences). The obtained\nresults attest to the effectiveness of the proposed ideas and show that our\nmodel, particularly when considering pre-training and the combination of neural\nrepresentations together with similarity features, slightly outperforms the\nprevious state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 02:13:52 GMT"}], "update_date": "2021-01-22", "authors_parsed": [["Borges", "Lu\u00eds", ""], ["Martins", "Bruno", ""], ["Calado", "P\u00e1vel", ""]]}, {"id": "1811.00717", "submitter": "He Zhao", "authors": "He Zhao, Lan Du, Wray Buntine, Mingyuan Zhou", "title": "Dirichlet belief networks for topic structure learning", "comments": "accepted in NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, considerable research effort has been devoted to developing deep\narchitectures for topic models to learn topic structures. Although several deep\nmodels have been proposed to learn better topic proportions of documents, how\nto leverage the benefits of deep structures for learning word distributions of\ntopics has not yet been rigorously studied. Here we propose a new multi-layer\ngenerative process on word distributions of topics, where each layer consists\nof a set of topics and each topic is drawn from a mixture of the topics of the\nlayer above. As the topics in all layers can be directly interpreted by words,\nthe proposed model is able to discover interpretable topic hierarchies. As a\nself-contained module, our model can be flexibly adapted to different kinds of\ntopic models to improve their modelling accuracy and interpretability.\nExtensive experiments on text corpora demonstrate the advantages of the\nproposed model.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 02:54:39 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Zhao", "He", ""], ["Du", "Lan", ""], ["Buntine", "Wray", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "1811.00839", "submitter": "Jiankai Sun", "authors": "Jiankai Sun, Bortik Bandyopadhyay, Armin Bashizade, Jiongqian Liang,\n  P. Sadayappan and Srinivasan Parthasarathy", "title": "ATP: Directed Graph Embedding with Asymmetric Transitivity Preservation", "comments": "has been accepted to the Thirty-Third AAAI Conference on Artificial\n  Intelligence (AAAI 2019), acceptance rate: 1150/7095 = 16.2%", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Directed graphs have been widely used in Community Question Answering\nservices (CQAs) to model asymmetric relationships among different types of\nnodes in CQA graphs, e.g., question, answer, user. Asymmetric transitivity is\nan essential property of directed graphs, since it can play an important role\nin downstream graph inference and analysis. Question difficulty and user\nexpertise follow the characteristic of asymmetric transitivity. Maintaining\nsuch properties, while reducing the graph to a lower dimensional vector\nembedding space, has been the focus of much recent research. In this paper, we\ntackle the challenge of directed graph embedding with asymmetric transitivity\npreservation and then leverage the proposed embedding method to solve a\nfundamental task in CQAs: how to appropriately route and assign newly posted\nquestions to users with the suitable expertise and interest in CQAs. The\ntechnique incorporates graph hierarchy and reachability information naturally\nby relying on a non-linear transformation that operates on the core\nreachability and implicit hierarchy within such graphs. Subsequently, the\nmethodology levers a factorization-based approach to generate two embedding\nvectors for each node within the graph, to capture the asymmetric transitivity.\nExtensive experiments show that our framework consistently and significantly\noutperforms the state-of-the-art baselines on two diverse real-world tasks:\nlink prediction, and question difficulty estimation and expert finding in\nonline forums like Stack Exchange. Particularly, our framework can support\ninductive embedding learning for newly posted questions (unseen nodes during\ntraining), and therefore can properly route and assign these kinds of questions\nto experts in CQAs.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 12:45:16 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2018 14:25:49 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Sun", "Jiankai", ""], ["Bandyopadhyay", "Bortik", ""], ["Bashizade", "Armin", ""], ["Liang", "Jiongqian", ""], ["Sadayappan", "P.", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1811.00845", "submitter": "Angrosh Mandya Dr.", "authors": "Angrosh Mandya, Danushka Bollegala, Frans Coenen and Katie Atkinson", "title": "Combining Long Short Term Memory and Convolutional Neural Network for\n  Cross-Sentence n-ary Relation Extraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose in this paper a combined model of Long Short Term Memory and\nConvolutional Neural Networks (LSTM-CNN) that exploits word embeddings and\npositional embeddings for cross-sentence n-ary relation extraction. The\nproposed model brings together the properties of both LSTMs and CNNs, to\nsimultaneously exploit long-range sequential information and capture most\ninformative features, essential for cross-sentence n-ary relation extraction.\nThe LSTM-CNN model is evaluated on standard dataset on cross-sentence n-ary\nrelation extraction, where it significantly outperforms baselines such as CNNs,\nLSTMs and also a combined CNN-LSTM model. The paper also shows that the\nLSTM-CNN model outperforms the current state-of-the-art methods on\ncross-sentence n-ary relation extraction.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 13:22:19 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Mandya", "Angrosh", ""], ["Bollegala", "Danushka", ""], ["Coenen", "Frans", ""], ["Atkinson", "Katie", ""]]}, {"id": "1811.00854", "submitter": "Adel Rahimi", "authors": "Adel Rahimi, Mohammad Bahrani", "title": "Improving Information Retrieval Results for Persian Documents using\n  FarsNet", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new method for query expansion, which uses\nFarsNet (Persian WordNet) to find similar tokens related to the query and\nexpand the semantic meaning of the query. For this purpose, we use synonymy\nrelations in FarsNet and extract the related synonyms to query words. This\nalgorithm is used to enhance information retrieval systems and improve search\nresults. The overall evaluation of this system in comparison to the baseline\nmethod (without using query expansion) shows an improvement of about 9 percent\nin Mean Average Precision (MAP).\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 17:48:18 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Rahimi", "Adel", ""], ["Bahrani", "Mohammad", ""]]}, {"id": "1811.00855", "submitter": "Yanqiao Zhu", "authors": "Shu Wu, Yuyuan Tang, Yanqiao Zhu, Liang Wang, Xing Xie, Tieniu Tan", "title": "Session-based Recommendation with Graph Neural Networks", "comments": "9 pages, 4 figures, accepted by AAAI Conference on Artificial\n  Intelligence (AAAI-19)", "journal-ref": null, "doi": "10.1609/aaai.v33i01.3301346", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of session-based recommendation aims to predict user actions\nbased on anonymous sessions. Previous methods model a session as a sequence and\nestimate user representations besides item representations to make\nrecommendations. Though achieved promising results, they are insufficient to\nobtain accurate user vectors in sessions and neglect complex transitions of\nitems. To obtain accurate item embedding and take complex transitions of items\ninto account, we propose a novel method, i.e. Session-based Recommendation with\nGraph Neural Networks, SR-GNN for brevity. In the proposed method, session\nsequences are modeled as graph-structured data. Based on the session graph, GNN\ncan capture complex transitions of items, which are difficult to be revealed by\nprevious conventional sequential methods. Each session is then represented as\nthe composition of the global preference and the current interest of that\nsession using an attention network. Extensive experiments conducted on two real\ndatasets show that SR-GNN evidently outperforms the state-of-the-art\nsession-based recommendation methods consistently.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 02:44:16 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2018 04:47:18 GMT"}, {"version": "v3", "created": "Thu, 15 Nov 2018 04:41:34 GMT"}, {"version": "v4", "created": "Thu, 24 Jan 2019 08:12:19 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Wu", "Shu", ""], ["Tang", "Yuyuan", ""], ["Zhu", "Yanqiao", ""], ["Wang", "Liang", ""], ["Xie", "Xing", ""], ["Tan", "Tieniu", ""]]}, {"id": "1811.00869", "submitter": "Durmus Sahin", "authors": "Durmus Ozkan Sahin, Erdal Kilic", "title": "Comparison of Classification Algorithms Used Medical Documents\n  Categorization", "comments": "International Conference on Computer Science and Engineering 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volume of text based documents have been increasing day by day. Medical\ndocuments are located within this growing text documents. In this study, the\ntechniques used for text classification applied on medical documents and\nevaluated classification performance. Used data sets are multi class and multi\nlabelled. Chi Square (CHI) technique was used for feature selection also SMO,\nNB, C4.5, RF and KNN algorithms was used for classification. The aim of this\nstudy, success of various classifiers is evaluated on multi class and multi\nlabel data sets consisting of medical documents. The first 400 features, while\nthe most successful in the KNN classifier, feature number 400 and after the SMO\nhas become the most successful classifier.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 14:08:53 GMT"}], "update_date": "2018-11-05", "authors_parsed": [["Sahin", "Durmus Ozkan", ""], ["Kilic", "Erdal", ""]]}, {"id": "1811.00911", "submitter": "Gaurush Hiranandani", "authors": "Prakhar Gupta, Gaurush Hiranandani, Harvineet Singh, Branislav Kveton,\n  Zheng Wen, Iftikhar Ahamath Burhanuddin", "title": "Online Diverse Learning to Rank from Partial-Click Feedback", "comments": "The first three authors contributed equally to this work. 24 pages, 4\n  figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to rank is an important problem in machine learning and recommender\nsystems. In a recommender system, a user is typically recommended a list of\nitems. Since the user is unlikely to examine the entire recommended list,\npartial feedback arises naturally. At the same time, diverse recommendations\nare important because it is challenging to model all tastes of the user in\npractice. In this paper, we propose the first algorithm for online learning to\nrank diverse items from partial-click feedback. We assume that the user\nexamines the list of recommended items until the user is attracted by an item,\nwhich is clicked, and does not examine the rest of the items. This model of\nuser behavior is known as the cascade model. We propose an online learning\nalgorithm, cascadelsb, for solving our problem. The algorithm actively explores\nthe tastes of the user with the objective of learning to recommend the optimal\ndiverse list. We analyze the algorithm and prove a gap-free upper bound on its\nn-step regret. We evaluate cascadelsb on both synthetic and real-world\ndatasets, compare it to various baselines, and show that it learns even when\nour modeling assumptions do not hold exactly.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2018 03:10:00 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2018 17:36:49 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["Gupta", "Prakhar", ""], ["Hiranandani", "Gaurush", ""], ["Singh", "Harvineet", ""], ["Kveton", "Branislav", ""], ["Wen", "Zheng", ""], ["Burhanuddin", "Iftikhar Ahamath", ""]]}, {"id": "1811.01166", "submitter": "Binh Nguyen-Thai", "authors": "Binh Nguyen and Atsuhiro Takasu", "title": "Learning Representations from Product Titles for Modeling Shopping\n  Transactions", "comments": "RecNLP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shopping transaction analysis is important for understanding the shopping\nbehaviors of customers. Existing models such as association rules are poor at\nmodeling products that have short purchase histories and cannot be applied to\nnew products (the cold-start problem). In this paper, we propose BASTEXT, an\nefficient model of shopping baskets and the texts associated with the products\n(e.g., product titles). The model's goal is to learn the product\nrepresentations from the textual contents to capture the relationships between\nthe products in the baskets. Given the products already in a basket, a\nclassifier identifies whether a potential product is relevant to the basket\nbased on their vector representations. This relevancy enables us to learn\nhigh-quality representations of the products. The experiments demonstrate that\nBASTEXT can efficiently model millions of baskets and that it outperforms the\nstate-of-the-art methods in the next product recommendation task. We also show\nthat BASTEXT is a strong baseline for keyword-based product search.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 07:12:06 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 03:13:02 GMT"}, {"version": "v3", "created": "Tue, 11 May 2021 08:20:01 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Nguyen", "Binh", ""], ["Takasu", "Atsuhiro", ""]]}, {"id": "1811.01345", "submitter": "Bita Shams", "authors": "Bita Shams and Saman Haratizadeh", "title": "IteRank: An iterative network-oriented approach to neighbor-based\n  collaborative ranking", "comments": null, "journal-ref": "Knowledge-Based Systems 128 (2017): 102-114", "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neighbor-based collaborative ranking (NCR) techniques follow three\nconsecutive steps to recommend items to each target user: first they calculate\nthe similarities among users, then they estimate concordance of pairwise\npreferences to the target user based on the calculated similarities. Finally,\nthey use estimated pairwise preferences to infer the total ranking of items for\nthe target user. This general approach faces some problems as the rank data is\nusually sparse as users usually have compared only a few pairs of items and\nconsequently, the similarities among users is calculated based on limited\ninformation and is not accurate enough for inferring true values of preference\nconcordance and can lead to an invalid ranking of items. This article presents\na novel framework, called IteRank, that models the data as a bipartite network\ncontaining users and pairwise preferences. It then simultaneously refines\nusers' similarities and preferences' concordances using a random walk method on\nthis graph structure. It uses the information in this first step in another\nnetwork structure for simultaneously adjusting the concordances of preferences\nand rankings of items. Using this approach, IteRank can overcome some existing\nproblems caused by the sparsity of the data. Experimental results show that\nIteRank improves the performance of recommendation compared to the state of the\nart NCR techniques that use the traditional NCR framework for recommendation.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 10:08:08 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Shams", "Bita", ""], ["Haratizadeh", "Saman", ""]]}, {"id": "1811.01461", "submitter": "Virginia Tsintzou", "authors": "Virginia Tsintzou, Evaggelia Pitoura, Panayiotis Tsaparas", "title": "Bias Disparity in Recommendation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems have been applied successfully in a number of different\ndomains, such as, entertainment, commerce, and employment. Their success lies\nin their ability to exploit the collective behavior of users in order to\ndeliver highly targeted, personalized recommendations. Given that recommenders\nlearn from user preferences, they incorporate different biases that users\nexhibit in the input data. More importantly, there are cases where recommenders\nmay amplify such biases, leading to the phenomenon of bias disparity. In this\nshort paper, we present a preliminary experimental study on synthetic data,\nwhere we investigate different conditions under which a recommender exhibits\nbias disparity, and the long-term effect of recommendations on data bias. We\nalso consider a simple re-ranking algorithm for reducing bias disparity, and\npresent some observations for data disparity on real data.\n", "versions": [{"version": "v1", "created": "Sun, 4 Nov 2018 23:59:31 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Tsintzou", "Virginia", ""], ["Pitoura", "Evaggelia", ""], ["Tsaparas", "Panayiotis", ""]]}, {"id": "1811.01537", "submitter": "Simon Mauras", "authors": "Claire Mathieu and Simon Mauras", "title": "How to aggregate Top-lists: Approximation algorithms via scores and\n  average ranks", "comments": "To appear in SODA'20", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A top-list is a possibly incomplete ranking of elements: only a subset of the\nelements are ranked, with all unranked elements tied for last. Top-list\naggregation, a generalization of the well-known rank aggregation problem, takes\nas input a collection of top-lists and aggregates them into a single complete\nranking, aiming to minimize the number of upsets (pairs ranked in opposite\norder in the input and in the output). In this paper, we give simple\napproximation algorithms for top-list aggregation.\n  * We generalize the footrule algorithm for rank aggregation.\n  * Using inspiration from approval voting, we define the score of an element\nas the frequency with which it is ranked, i.e. appears in an input top-list. We\nreinterpret Ailon's RepeatChoice algorithm for top-list aggregation using the\nscore of an element and its average rank given that it is ranked.\n  * Using average ranks, we generalize and analyze Borda's algorithm for rank\naggregation.\n  * We design a simple 2-phase variant of the Generalized Borda's algorithm,\nroughly sorting by scores and breaking ties by average ranks.\n  * We then design another 2-phase variant in which in order to break ties we\nuse, as a black box, the Mathieu-Schudy PTAS for rank aggregation, yielding a\nPTAS for top-list aggregation.\n  * Finally, we discuss the special case in which all input lists have constant\nlength.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 07:24:14 GMT"}, {"version": "v2", "created": "Thu, 10 Oct 2019 12:47:33 GMT"}], "update_date": "2019-10-11", "authors_parsed": [["Mathieu", "Claire", ""], ["Mauras", "Simon", ""]]}, {"id": "1811.01686", "submitter": "Arash Khoeini", "authors": "Arash Khoeini, Bita Shams, Saman Haratizadeh", "title": "GEMRank: Global Entity Embedding For Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, word embedding algorithms have been applied to map the entities of\nrecommender systems, such as users and items, to new feature spaces using\ntextual element-context relations among them. Unlike many other domains, this\napproach has not achieved a desired performance in collaborative filtering\nproblems, probably due to unavailability of appropriate textual data. In this\npaper we propose a new recommendation framework, called GEMRank that can be\napplied when the user-item matrix is the sole available souce of information.\nIt uses the concept of profile co-occurrence for defining relations among\nentities and applies a factorization method for embedding the users and items.\nGEMRank then feeds the extracted representations to a neural network model to\npredict user-item like/dislike relations which the final recommendations are\nmade based on. We evaluated GEMRank in an extensive set of experiments against\nstate of the art recommendation methods. The results show that GEMRank\nsignificantly outperforms the baseline algorithms in a variety of data sets\nwith different degrees of density.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 13:54:20 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Khoeini", "Arash", ""], ["Shams", "Bita", ""], ["Haratizadeh", "Saman", ""]]}, {"id": "1811.01747", "submitter": "Ali Emami Mr.", "authors": "Ali Emami, Paul Trichelair, Adam Trischler, Kaheer Suleman, Hannes\n  Schulz and Jackie Chi Kit Cheung", "title": "The Knowref Coreference Corpus: Removing Gender and Number Cues for\n  Difficult Pronominal Anaphora Resolution", "comments": "9 pages (excluding references), accepted for ACL 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new benchmark for coreference resolution and NLI, Knowref,\nthat targets common-sense understanding and world knowledge. Previous\ncoreference resolution tasks can largely be solved by exploiting the number and\ngender of the antecedents, or have been handcrafted and do not reflect the\ndiversity of naturally occurring text. We present a corpus of over 8,000\nannotated text passages with ambiguous pronominal anaphora. These instances are\nboth challenging and realistic. We show that various coreference systems,\nwhether rule-based, feature-rich, or neural, perform significantly worse on the\ntask than humans, who display high inter-annotator agreement. To explain this\nperformance gap, we show empirically that state-of-the art models often fail to\ncapture context, instead relying on the gender or number of candidate\nantecedents to make a decision. We then use problem-specific insights to\npropose a data-augmentation trick called antecedent switching to alleviate this\ntendency in models. Finally, we show that antecedent switching yields promising\nresults on other tasks as well: we use it to achieve state-of-the-art results\non the GAP coreference task.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2018 16:41:26 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 22:16:35 GMT"}, {"version": "v3", "created": "Thu, 13 Jun 2019 20:06:32 GMT"}], "update_date": "2019-06-17", "authors_parsed": [["Emami", "Ali", ""], ["Trichelair", "Paul", ""], ["Trischler", "Adam", ""], ["Suleman", "Kaheer", ""], ["Schulz", "Hannes", ""], ["Cheung", "Jackie Chi Kit", ""]]}, {"id": "1811.01802", "submitter": "Zhichong Fang", "authors": "Zhichong Fang, Aman Agarwal, Thorsten Joachims", "title": "Intervention Harvesting for Context-Dependent Examination-Bias\n  Estimation", "comments": null, "journal-ref": null, "doi": "10.1145/3331184.3331238", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate estimates of examination bias are crucial for unbiased\nlearning-to-rank from implicit feedback in search engines and recommender\nsystems, since they enable the use of Inverse Propensity Score (IPS) weighting\ntechniques to address selection biases and missing data. Unfortunately,\nexisting examination-bias estimators are limited to the Position-Based Model\n(PBM), where the examination bias may only depend on the rank of the document.\nTo overcome this limitation, we propose a Contextual Position-Based Model\n(CPBM) where the examination bias may also depend on a context vector\ndescribing the query and the user. Furthermore, we propose an effective\nestimator for the CPBM based on intervention harvesting. A key feature of the\nestimator is that it does not require disruptive interventions but merely\nexploits natural variation resulting from the use of multiple historic ranking\nfunctions. Real-world experiments on the ArXiv search engine and semi-synthetic\nexperiments on the Yahoo Learning-To-Rank dataset demonstrate the superior\neffectiveness and robustness of the new approach.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 15:39:17 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 02:53:35 GMT"}, {"version": "v3", "created": "Fri, 24 May 2019 11:31:06 GMT"}], "update_date": "2019-05-27", "authors_parsed": [["Fang", "Zhichong", ""], ["Agarwal", "Aman", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1811.01833", "submitter": "Guofu Li", "authors": "Guofu Li, Pengjia Zhu, and Zhiyi Chen", "title": "Accelerating System Log Processing by Semi-supervised Learning: A\n  Technical Report", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing need for more automated system-log analysis tools for\nlarge scale online system in a timely manner. However, conventional way to\nmonitor and classify the log output based on keyword list does not scale well\nfor complex system in which codes contributed by a large group of developers,\nwith diverse ways of encoding the error messages, often with misleading pre-set\nlabels. In this paper, we propose that the design of a large scale online log\nanalysis should follow the \"Least Prior Knowledge Principle\", in which\nunsupervised or semi-supervised solution with the minimal prior knowledge of\nthe log should be encoded directly. Thereby, we report our experience in\ndesigning a two-stage machine learning based method, in which the system logs\nare regarded as the output of a quasi-natural language, pre-filtered by a\nperplexity score threshold, and then undergo a fine-grained classification\nprocedure. Tests on empirical data show that our method has obvious advantage\nregarding to the processing speed and classification accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2018 00:28:26 GMT"}], "update_date": "2018-11-06", "authors_parsed": [["Li", "Guofu", ""], ["Zhu", "Pengjia", ""], ["Chen", "Zhiyi", ""]]}, {"id": "1811.01905", "submitter": "Maurizio Ferrari Dacrema", "authors": "Maurizio Ferrari Dacrema, Alberto Gasparin and Paolo Cremonesi", "title": "Deriving item features relevance from collaborative domain knowledge", "comments": null, "journal-ref": "Proceedings of KaRS 2018 Workshop on Knowledge-aware and\n  Conversational Recommender Systems (KaRS @RecSys 2018)", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Item based recommender system works by computing a similarity between\nitems, which can exploit past user interactions (collaborative filtering) or\nitem features (content based filtering). Collaborative algorithms have been\nproven to achieve better recommendation quality then content based algorithms\nin a variety of scenarios, being more effective in modeling user behaviour.\nHowever, they can not be applied when items have no interactions at all, i.e.\ncold start items. Content based algorithms, which are applicable to cold start\nitems, often require a lot of feature engineering in order to generate useful\nrecommendations. This issue is specifically relevant as the content descriptors\nbecome large and heterogeneous. The focus of this paper is on how to use a\ncollaborative models domain-specific knowledge to build a wrapper feature\nweighting method which embeds collaborative knowledge in a content based\nalgorithm. We present a comparative study for different state of the art\nalgorithms and present a more general model. This machine learning approach to\nfeature weighting shows promising results and high flexibility.\n", "versions": [{"version": "v1", "created": "Mon, 5 Nov 2018 18:33:00 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Dacrema", "Maurizio Ferrari", ""], ["Gasparin", "Alberto", ""], ["Cremonesi", "Paolo", ""]]}, {"id": "1811.01931", "submitter": "Robert Giaquinto", "authors": "Robert Giaquinto and Arindam Banerjee", "title": "DAPPER: Scaling Dynamic Author Persona Topic Model to Billion Word\n  Corpora", "comments": "Published in IEEE International Conference on Data Mining, November\n  2018, Singapore", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting common narratives from multi-author dynamic text corpora requires\ncomplex models, such as the Dynamic Author Persona (DAP) topic model. However,\nsuch models are complex and can struggle to scale to large corpora, often\nbecause of challenging non-conjugate terms. To overcome such challenges, in\nthis paper we adapt new ideas in approximate inference to the DAP model,\nresulting in the DAP Performed Exceedingly Rapidly (DAPPER) topic model.\nSpecifically, we develop Conjugate-Computation Variational Inference (CVI)\nbased variational Expectation-Maximization (EM) for learning the model,\nyielding fast, closed form updates for each document, replacing iterative\noptimization in earlier work. Our results show significant improvements in\nmodel fit and training time without needing to compromise the model's temporal\nstructure or the application of Regularized Variation Inference (RVI). We\ndemonstrate the scalability and effectiveness of the DAPPER model by extracting\nhealth journeys from the CaringBridge corpus --- a collection of 9 million\njournals written by 200,000 authors during health crises.\n", "versions": [{"version": "v1", "created": "Sat, 3 Nov 2018 21:27:56 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Giaquinto", "Robert", ""], ["Banerjee", "Arindam", ""]]}, {"id": "1811.02198", "submitter": "Dongsheng Li", "authors": "Dongsheng Li and Chao Chen and Qin Lv and Junchi Yan and Li Shang and\n  Stephen M. Chu", "title": "Collaborative Filtering with Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering (CF) is a popular technique in today's recommender\nsystems, and matrix approximation-based CF methods have achieved great success\nin both rating prediction and top-N recommendation tasks. However, real-world\nuser-item rating matrices are typically sparse, incomplete and noisy, which\nintroduce challenges to the algorithm stability of matrix approximation, i.e.,\nsmall changes in the training data may significantly change the models. As a\nresult, existing matrix approximation solutions yield low generalization\nperformance, exhibiting high error variance on the training data, and\nminimizing the training error may not guarantee error reduction on the test\ndata. This paper investigates the algorithm stability problem of matrix\napproximation methods and how to achieve stable collaborative filtering via\nstable matrix approximation. We present a new algorithm design framework, which\n(1) introduces new optimization objectives to guide stable matrix approximation\nalgorithm design, and (2) solves the optimization problem to obtain stable\napproximation solutions with good generalization performance. Experimental\nresults on real-world datasets demonstrate that the proposed method can achieve\nbetter accuracy compared with state-of-the-art matrix approximation methods and\nensemble methods in both rating prediction and top-N recommendation tasks.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 07:13:23 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Li", "Dongsheng", ""], ["Chen", "Chao", ""], ["Lv", "Qin", ""], ["Yan", "Junchi", ""], ["Shang", "Li", ""], ["Chu", "Stephen M.", ""]]}, {"id": "1811.02516", "submitter": "Livia Ruback", "authors": "Livia Ruback, Claudio Lucchese, Alexander Arturo Mera Caraballo,\n  Grettel Monteagudo Garc\\'ia, Marco Antonio Casanova, Chiara Renso", "title": "Computing Entity Semantic Similarity by Features Ranking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a novel approach to estimate semantic entity similarity\nusing entity features available as Linked Data. The key idea is to exploit\nranked lists of features, extracted from Linked Data sources, as a\nrepresentation of the entities to be compared. The similarity between two\nentities is then estimated by comparing their ranked lists of features. The\narticle describes experiments with museum data from DBpedia, with datasets from\na LOD catalog, and with computer science conferences from the DBLP repository.\nThe experiments demonstrate that entity similarity, computed using ranked lists\nof features, achieves better accuracy than state-of-the-art measures.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 17:37:01 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Ruback", "Livia", ""], ["Lucchese", "Claudio", ""], ["Caraballo", "Alexander Arturo Mera", ""], ["Garc\u00eda", "Grettel Monteagudo", ""], ["Casanova", "Marco Antonio", ""], ["Renso", "Chiara", ""]]}, {"id": "1811.02746", "submitter": "Osman Tursun", "authors": "Osman Tursun, Simon Denman, Sabesan Sivapalan, Sridha Sridharan,\n  Clinton Fookes and Sandra Mau", "title": "Component-based Attention for Large-scale Trademark Retrieval", "comments": "Fix typos related to authors' information", "journal-ref": null, "doi": "10.1109/TIFS.2019.2959921", "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demand for large-scale trademark retrieval (TR) systems has significantly\nincreased to combat the rise in international trademark infringement.\nUnfortunately, the ranking accuracy of current approaches using either\nhand-crafted or pre-trained deep convolution neural network (DCNN) features is\ninadequate for large-scale deployments. We show in this paper that the ranking\naccuracy of TR systems can be significantly improved by incorporating hard and\nsoft attention mechanisms, which direct attention to critical information such\nas figurative elements and reduce attention given to distracting and\nuninformative elements such as text and background. Our proposed approach\nachieves state-of-the-art results on a challenging large-scale trademark\ndataset.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 03:33:28 GMT"}, {"version": "v2", "created": "Tue, 22 Oct 2019 06:25:55 GMT"}], "update_date": "2019-12-16", "authors_parsed": [["Tursun", "Osman", ""], ["Denman", "Simon", ""], ["Sivapalan", "Sabesan", ""], ["Sridharan", "Sridha", ""], ["Fookes", "Clinton", ""], ["Mau", "Sandra", ""]]}, {"id": "1811.02765", "submitter": "Xin Wang", "authors": "Xin Wang, Jiawei Wu, Da Zhang, Yu Su, William Yang Wang", "title": "Learning to Compose Topic-Aware Mixture of Experts for Zero-Shot Video\n  Captioning", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although promising results have been achieved in video captioning, existing\nmodels are limited to the fixed inventory of activities in the training corpus,\nand do not generalize to open vocabulary scenarios. Here we introduce a novel\ntask, zero-shot video captioning, that aims at describing out-of-domain videos\nof unseen activities. Videos of different activities usually require different\ncaptioning strategies in many aspects, i.e. word selection, semantic\nconstruction, and style expression etc, which poses a great challenge to depict\nnovel activities without paired training data. But meanwhile, similar\nactivities share some of those aspects in common. Therefore, We propose a\nprincipled Topic-Aware Mixture of Experts (TAMoE) model for zero-shot video\ncaptioning, which learns to compose different experts based on different topic\nembeddings, implicitly transferring the knowledge learned from seen activities\nto unseen ones. Besides, we leverage external topic-related text corpus to\nconstruct the topic embedding for each activity, which embodies the most\nrelevant semantic vectors within the topic. Empirical results not only validate\nthe effectiveness of our method in utilizing semantic knowledge for video\ncaptioning, but also show its strong generalization ability when describing\nnovel activities.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 05:33:07 GMT"}, {"version": "v2", "created": "Fri, 23 Nov 2018 23:22:19 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Wang", "Xin", ""], ["Wu", "Jiawei", ""], ["Zhang", "Da", ""], ["Su", "Yu", ""], ["Wang", "William Yang", ""]]}, {"id": "1811.02815", "submitter": "Peijie Sun", "authors": "Le Wu, Peijie Sun, Richang Hong, Yanjie Fu, Xiting Wang and Meng Wang", "title": "SocialGCN: An Efficient Graph Convolutional Network based Model for\n  Social Recommendation", "comments": "Our new version of this paper has been accepted by SIGIR 2019 and the\n  link to the new version is arXiv:1904.10322", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative Filtering (CF) is one of the most successful approaches for\nrecommender systems. With the emergence of online social networks, social\nrecommendation has become a popular research direction. Most of these social\nrecommendation models utilized each user's local neighbors' preferences to\nalleviate the data sparsity issue in CF. However, they only considered the\nlocal neighbors of each user and neglected the process that users' preferences\nare influenced as information diffuses in the social network. Recently, Graph\nConvolutional Networks~(GCN) have shown promising results by modeling the\ninformation diffusion process in graphs that leverage both graph structure and\nnode feature information. To this end, in this paper, we propose an effective\ngraph convolutional neural network based model for social recommendation. Based\non a classical CF model, the key idea of our proposed model is that we borrow\nthe strengths of GCNs to capture how users' preferences are influenced by the\nsocial diffusion process in social networks. The diffusion of users'\npreferences is built on a layer-wise diffusion manner, with the initial user\nembedding as a function of the current user's features and a free base user\nlatent vector that is not contained in the user feature. Similarly, each item's\nlatent vector is also a combination of the item's free latent vector, as well\nas its feature representation. Furthermore, we show that our proposed model is\nflexible when user and item features are not available. Finally, extensive\nexperimental results on two real-world datasets clearly show the effectiveness\nof our proposed model.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 10:07:52 GMT"}, {"version": "v2", "created": "Thu, 11 Jul 2019 03:06:02 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Wu", "Le", ""], ["Sun", "Peijie", ""], ["Hong", "Richang", ""], ["Fu", "Yanjie", ""], ["Wang", "Xiting", ""], ["Wang", "Meng", ""]]}, {"id": "1811.02820", "submitter": "Anton Belyy", "authors": "Anton Belyy", "title": "Construction and Quality Evaluation of Heterogeneous Hierarchical Topic\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In our work, we propose to represent HTM as a set of flat models, or layers,\nand a set of topical hierarchies, or edges. We suggest several quality measures\nfor edges of hierarchical models, resembling those proposed for flat models. We\nconduct an assessment experimentation and show strong correlation between the\nproposed measures and human judgement on topical edge quality. We also\nintroduce heterogeneous algorithm to build hierarchical topic models for\nheterogeneous data sources. We show how making certain adjustments to learning\nprocess helps to retain original structure of customized models while allowing\nfor slight coherent modifications for new documents. We evaluate this approach\nusing the proposed measures and show that the proposed heterogeneous algorithm\nsignificantly outperforms the baseline concat approach. Finally, we implement\nour own ESE called Rysearch, which demonstrates the potential of ARTM approach\nfor visualizing large heterogeneous document collections.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 10:32:50 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Belyy", "Anton", ""]]}, {"id": "1811.02964", "submitter": "Johannes Klinglmayr", "authors": "Bernhard Bergmair and Thomas Buchegger and Johann Hoffelner and Gerald\n  Schatz and Siegfried Silber and Johannes Klinglmayr", "title": "Instantly Deployable Expert Knowledge - Networks of Knowledge Engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge and information are becoming the primary resources of the emerging\ninformation society. To exploit the potential of available expert knowledge,\ncomprehension and application skills (i.e. expert competences) are necessary.\nThe ability to acquire these skills is limited for any individual human.\nConsequently, the capacities to solve problems based on human knowledge in a\nmanual (i.e. mental) way are strongly limited. We envision a new systemic\napproach to enable scalable knowledge deployment without expert competences.\nEventually, the system is meant to instantly deploy humanity's total knowledge\nin full depth for every individual challenge. To this end, we propose a\nsocio-technical framework that transforms expert knowledge into a solution\ncreation system. Knowledge is represented by automated algorithms (knowledge\nengines). Executable compositions of knowledge engines (networks of knowledge\nengines) generate requested individual information at runtime. We outline how\nthese knowledge representations could yield legal, ethical and social\nchallenges and nurture new business and remuneration models on knowledge. We\nidentify major technological and economic concepts that are already pushing the\nboundaries in knowledge utilisation: e.g. in artificial intelligence, knowledge\nbases, ontologies, advanced search tools, automation of knowledge work, the API\neconomy. We indicate impacts on society, economy and labour. Existing\ndevelopments are linked, including a specific use case in engineering design.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 16:30:08 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Bergmair", "Bernhard", ""], ["Buchegger", "Thomas", ""], ["Hoffelner", "Johann", ""], ["Schatz", "Gerald", ""], ["Silber", "Siegfried", ""], ["Klinglmayr", "Johannes", ""]]}, {"id": "1811.03030", "submitter": "Jinseok Kim", "authors": "Jinseok Kim", "title": "Scale-free collaboration networks: An author name disambiguation\n  perspective", "comments": "22 pages, 12 figures, 5 tables", "journal-ref": null, "doi": "10.1002/asi.24158", "report-no": null, "categories": "cs.DL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several studies have found that collaboration networks are scale-free,\nproposing that such networks can be modeled by specific network evolution\nmechanisms like preferential attachment. This study argues that collaboration\nnetworks can look more or less scale-free depending on the methods for\nresolving author name ambiguity in bibliographic data. Analyzing networks\nconstructed from multiple datasets containing 3.4M ~ 9.6M publication records,\nthis study shows that collaboration networks in which author names are\ndisambiguated by the commonly used heuristic, i.e., forename-initial-based name\nmatching, tend to produce degree distributions better fitted to power-law\nslopes with the typical scaling parameter (2 < {\\alpha} < 3) than networks\ndisambiguated by more accurate algorithm-based methods. Such tendency is\nobserved across collaboration networks generated under various conditions such\nas cumulative years, 5- & 1-year sliding windows, and random sampling, and\nthrough simulation, found to arise due mainly to artefactual entities created\nby inaccurate disambiguation. This cautionary study calls for special attention\nfrom scholars analyzing network data in which entities such as people,\norganization, and gene can be merged or split by improper disambiguation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2018 17:30:00 GMT"}], "update_date": "2018-11-08", "authors_parsed": [["Kim", "Jinseok", ""]]}, {"id": "1811.03275", "submitter": "EPTCS", "authors": "Francesco Galofaro (POLIMI, UNIBZ), Zeno Toffano (Centralesup\\'elec),\n  Bich-Li\\^en Doan (Centralesup\\'elec)", "title": "Quantum Semantic Correlations in Hate and Non-Hate Speeches", "comments": "In Proceedings CAPNS 2018, arXiv:1811.02701", "journal-ref": "EPTCS 283, 2018, pp. 62-74", "doi": "10.4204/EPTCS.283.5", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper aims to apply the notions of quantum geometry and correlation to\nthe typification of semantic relations between couples of keywords in different\ndocuments. In particular we analysed texts classified as hate / non hate\nspeeches, containing the keywords \"women\", \"white\", and \"black\". The paper\ncompares this approach to cosine similarity, a classical methodology, to cast\nlight on the notion of \"similar meaning\".\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 05:11:37 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Galofaro", "Francesco", "", "POLIMI, UNIBZ"], ["Toffano", "Zeno", "", "Centralesup\u00e9lec"], ["Doan", "Bich-Li\u00ean", "", "Centralesup\u00e9lec"]]}, {"id": "1811.03388", "submitter": "Jill-J\\^enn Vie", "authors": "Jill-J\\^enn Vie and Hisashi Kashima", "title": "Knowledge Tracing Machines: Factorization Machines for Knowledge Tracing", "comments": "8 pages, 3 figures, 7 tables, to appear at the 33th AAAI Conference\n  on Artificial Intelligence (AAAI-19)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge tracing is a sequence prediction problem where the goal is to\npredict the outcomes of students over questions as they are interacting with a\nlearning platform. By tracking the evolution of the knowledge of some student,\none can optimize instruction. Existing methods are either based on temporal\nlatent variable models, or factor analysis with temporal features. We here show\nthat factorization machines (FMs), a model for regression or classification,\nencompasses several existing models in the educational literature as special\ncases, notably additive factor model, performance factor model, and\nmultidimensional item response theory. We show, using several real datasets of\ntens of thousands of users and items, that FMs can estimate student knowledge\naccurately and fast even when student data is sparsely observed, and handle\nside information such as multiple knowledge components and number of attempts\nat item or skill level. Our approach allows to fit student models of higher\ndimension than existing models, and provides a testbed to try new combinations\nof features in order to improve existing models.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 13:02:09 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 05:41:18 GMT"}], "update_date": "2018-11-16", "authors_parsed": [["Vie", "Jill-J\u00eann", ""], ["Kashima", "Hisashi", ""]]}, {"id": "1811.03431", "submitter": "I\\~nigo Urteaga", "authors": "I\\~nigo Urteaga, Mollie McKillop, Sharon Lipsky-Gorman and No\\'emie\n  Elhadad", "title": "Phenotyping Endometriosis through Mixed Membership Models of\n  Self-Tracking Data", "comments": "As presented in Machine Learning for Healthcare 2018,\n  https://www.mlforhc.org/2018-conference/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the use of self-tracking data and unsupervised\nmixed-membership models to phenotype endometriosis. Endometriosis is a\nsystemic, chronic condition of women in reproductive age and, at the same time,\na highly enigmatic condition with no known biomarkers to monitor its\nprogression and no established staging. We leverage data collected through a\nself-tracking app in an observational research study of over 2,800 women with\nendometriosis tracking their condition over a year and a half (456,900\nobservations overall). We extend a classical mixed-membership model to\naccommodate the idiosyncrasies of the data at hand (i.e., the multimodality of\nthe tracked variables). Our experiments show that our approach identifies\npotential subtypes that are robust in terms of biases of self-tracked data\n(e.g., wide variations in tracking frequency amongst participants), as well as\nto variations in hyperparameters of the model. Jointly modeling a wide range of\nobservations about participants (symptoms, quality of life, treatments) yields\nclinically meaningful subtypes that both validate what is already known about\nendometriosis and suggest new findings.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2018 17:54:18 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Urteaga", "I\u00f1igo", ""], ["McKillop", "Mollie", ""], ["Lipsky-Gorman", "Sharon", ""], ["Elhadad", "No\u00e9mie", ""]]}, {"id": "1811.03514", "submitter": "Ayyoob Imani Googhari", "authors": "Ayyoob Imani, Amir Vakili, Ali Montazer and Azadeh Shakery", "title": "Deep Neural Networks for Query Expansion using Word Embeddings", "comments": "8 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query expansion is a method for alleviating the vocabulary mismatch problem\npresent in information retrieval tasks. Previous works have shown that terms\nselected for query expansion by traditional methods such as pseudo-relevance\nfeedback are not always helpful to the retrieval process. In this paper, we\nshow that this is also true for more recently proposed embedding-based query\nexpansion methods. We then introduce an artificial neural network classifier to\npredict the usefulness of query expansion terms. This classifier uses term word\nembeddings as inputs. We perform experiments on four TREC newswire and web\ncollections show that using terms selected by the classifier for expansion\nsignificantly improves retrieval performance when compared to competitive\nbaselines. The results are also shown to be more robust than the baselines.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 16:01:35 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Imani", "Ayyoob", ""], ["Vakili", "Amir", ""], ["Montazer", "Ali", ""], ["Shakery", "Azadeh", ""]]}, {"id": "1811.03569", "submitter": "Ayyoob Imani Googhari", "authors": "Ayyoob Imani, Amir Vakili, Ali Montazer and Azadeh Shakery", "title": "An Axiomatic Study of Query Terms Order in Ad-hoc Retrieval", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classic retrieval methods use simple bag-of-word representations for queries\nand documents. This representation fails to capture the full semantic richness\nof queries and documents. More recent retrieval models have tried to overcome\nthis deficiency by using approaches such as incorporating dependencies between\nquery terms, using bi-gram representations of documents, proximity heuristics,\nand passage retrieval. While some of these previous works have implicitly\naccounted for term order, to the best of our knowledge, term order has not been\nthe primary focus of any research. In this paper, we focus solely on the effect\nof term order in information retrieval. We will show that documents that have\ntwo query terms in the same order as in the query have a higher probability of\nbeing relevant than documents that have two query terms in the reverse order.\nUsing the axiomatic framework for information retrieval, we introduce a\nconstraint that retrieval models must adhere to in order to effectively utilize\nterm order dependency among query terms. We modify existing retrieval models\nbased on this constraint so that if the order of a pair of query terms is\nsemantically important, a document that includes these query terms in the same\norder as the query should receive a higher score compared to a document that\nincludes them in the reverse order. Our empirical evaluation using both TREC\nnewswire and web corpora demonstrates that the modified retrieval models\nsignificantly outperform their original counterparts.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 17:48:37 GMT"}], "update_date": "2018-11-09", "authors_parsed": [["Imani", "Ayyoob", ""], ["Vakili", "Amir", ""], ["Montazer", "Ali", ""], ["Shakery", "Azadeh", ""]]}, {"id": "1811.03661", "submitter": "Peter Snyder", "authors": "Mohammad Ghasemisharif and Peter Snyder and Andrius Aucinas and\n  Benjamin Livshits", "title": "SpeedReader: Reader Mode Made Fast and Private", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most popular web browsers include \"reader modes\" that improve the user\nexperience by removing un-useful page elements. Reader modes reformat the page\nto hide elements that are not related to the page's main content. Such page\nelements include site navigation, advertising related videos and images, and\nmost JavaScript. The intended end result is that users can enjoy the content\nthey are interested in, without distraction.\n  In this work, we consider whether the \"reader mode\" can be widened to also\nprovide performance and privacy improvements. Instead of its use as a\npost-render feature to clean up the clutter on a page we propose SpeedReader as\nan alternative multistep pipeline that is part of the rendering pipeline. Once\nthe tool decides during the initial phase of a page load that a page is\nsuitable for reader mode use, it directly applies document tree translation\nbefore the page is rendered.\n  Based on our measurements, we believe that SpeedReader can be continuously\nenabled in order to drastically improve end-user experience, especially on\nslower mobile connections. Combined with our approach to predicting which pages\nshould be rendered in reader mode with 91% accuracy, it achieves drastic\nspeedups and bandwidth reductions of up to 27x and 84x respectively on average.\nWe further find that our novel \"reader mode\" approach brings with it\nsignificant privacy improvements to users. Our approach effectively removes all\ncommonly recognized trackers, issuing 115 fewer requests to third parties, and\ninteracts with 64 fewer trackers on average, on transformed pages.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 20:01:50 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Ghasemisharif", "Mohammad", ""], ["Snyder", "Peter", ""], ["Aucinas", "Andrius", ""], ["Livshits", "Benjamin", ""]]}, {"id": "1811.03925", "submitter": "Ryuichi Takanobu", "authors": "Ryuichi Takanobu, Tianyang Zhang, Jiexi Liu, Minlie Huang", "title": "A Hierarchical Framework for Relation Extraction with Reinforcement\n  Learning", "comments": "To appear in AAAI 19", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing methods determine relation types only after all the entities\nhave been recognized, thus the interaction between relation types and entity\nmentions is not fully modeled. This paper presents a novel paradigm to deal\nwith relation extraction by regarding the related entities as the arguments of\na relation. We apply a hierarchical reinforcement learning (HRL) framework in\nthis paradigm to enhance the interaction between entity mentions and relation\ntypes. The whole extraction process is decomposed into a hierarchy of two-level\nRL policies for relation detection and entity extraction respectively, so that\nit is more feasible and natural to deal with overlapping relations. Our model\nwas evaluated on public datasets collected via distant supervision, and results\nshow that it gains better performance than existing methods and is more\npowerful for extracting overlapping relations.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 14:33:29 GMT"}], "update_date": "2018-11-12", "authors_parsed": [["Takanobu", "Ryuichi", ""], ["Zhang", "Tianyang", ""], ["Liu", "Jiexi", ""], ["Huang", "Minlie", ""]]}, {"id": "1811.03970", "submitter": "Iftitahu Ni'mah", "authors": "Wenting Xiong, Iftitahu Ni'mah, Juan M. G. Huesca, Werner van\n  Ipenburg, Jan Veldsink, and Mykola Pechenizkiy", "title": "Looking Deeper into Deep Learning Model: Attribution-based Explanations\n  of TextCNN", "comments": "NIPS 2018 Workshop on Challenges and Opportunities for AI in\n  Financial Services: the Impact of Fairness, Explainability, Accuracy, and\n  Privacy, Montr\\'eal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Layer-wise Relevance Propagation (LRP) and saliency maps have been recently\nused to explain the predictions of Deep Learning models, specifically in the\ndomain of text classification. Given different attribution-based explanations\nto highlight relevant words for a predicted class label, experiments based on\nword deleting perturbation is a common evaluation method. This word removal\napproach, however, disregards any linguistic dependencies that may exist\nbetween words or phrases in a sentence, which could semantically guide a\nclassifier to a particular prediction. In this paper, we present a\nfeature-based evaluation framework for comparing the two attribution methods on\ncustomer reviews (public data sets) and Customer Due Diligence (CDD) extracted\nreports (corporate data set). Instead of removing words based on the relevance\nscore, we investigate perturbations based on embedded features removal from\nintermediate layers of Convolutional Neural Networks. Our experimental study is\ncarried out on embedded-word, embedded-document, and embedded-ngrams\nexplanations. Using the proposed framework, we provide a visualization tool to\nassist analysts in reasoning toward the model's final prediction.\n", "versions": [{"version": "v1", "created": "Thu, 8 Nov 2018 18:23:48 GMT"}, {"version": "v2", "created": "Sun, 2 Dec 2018 23:18:23 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Xiong", "Wenting", ""], ["Ni'mah", "Iftitahu", ""], ["Huesca", "Juan M. G.", ""], ["van Ipenburg", "Werner", ""], ["Veldsink", "Jan", ""], ["Pechenizkiy", "Mykola", ""]]}, {"id": "1811.04155", "submitter": "Dae Hoon Park", "authors": "Dae Hoon Park and Yi Chang", "title": "Adversarial Sampling and Training for Semi-Supervised Information\n  Retrieval", "comments": "Published in WWW 2019", "journal-ref": null, "doi": "10.1145/3308558.3313416", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ad-hoc retrieval models with implicit feedback often have problems, e.g., the\nimbalanced classes in the data set. Too few clicked documents may hurt\ngeneralization ability of the models, whereas too many non-clicked documents\nmay harm effectiveness of the models and efficiency of training. In addition,\nrecent neural network-based models are vulnerable to adversarial examples due\nto the linear nature in them. To solve the problems at the same time, we\npropose an adversarial sampling and training framework to learn ad-hoc\nretrieval models with implicit feedback. Our key idea is (i) to augment clicked\nexamples by adversarial training for better generalization and (ii) to obtain\nvery informational non-clicked examples by adversarial sampling and training.\nExperiments are performed on benchmark data sets for common ad-hoc retrieval\ntasks such as Web search, item recommendation, and question answering.\nExperimental results indicate that the proposed approaches significantly\noutperform strong baselines especially for high-ranked documents, and they\noutperform IRGAN in NDCG@5 using only 5% of labeled data for the Web search\ntask.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2018 22:57:18 GMT"}, {"version": "v2", "created": "Fri, 18 Oct 2019 01:18:34 GMT"}], "update_date": "2019-10-21", "authors_parsed": [["Park", "Dae Hoon", ""], ["Chang", "Yi", ""]]}, {"id": "1811.04210", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui, Jian Su", "title": "Densely Connected Attention Propagation for Reading Comprehension", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose DecaProp (Densely Connected Attention Propagation), a new densely\nconnected neural architecture for reading comprehension (RC). There are two\ndistinct characteristics of our model. Firstly, our model densely connects all\npairwise layers of the network, modeling relationships between passage and\nquery across all hierarchical levels. Secondly, the dense connectors in our\nnetwork are learned via attention instead of standard residual skip-connectors.\nTo this end, we propose novel Bidirectional Attention Connectors (BAC) for\nefficiently forging connections throughout the network. We conduct extensive\nexperiments on four challenging RC benchmarks. Our proposed approach achieves\nstate-of-the-art results on all four, outperforming existing baselines by up to\n$2.6\\%-14.2\\%$ in absolute F1 score.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 07:54:13 GMT"}, {"version": "v2", "created": "Tue, 2 Apr 2019 11:19:54 GMT"}], "update_date": "2019-04-03", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""], ["Su", "Jian", ""]]}, {"id": "1811.04288", "submitter": "Ovidiu Dan", "authors": "Ovidiu Dan, Vaibhav Parikh, Brian D. Davison", "title": "IP Geolocation through Reverse DNS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  IP Geolocation databases are widely used in online services to map end user\nIP addresses to their geographical locations. However, they use proprietary\ngeolocation methods and in some cases they have poor accuracy. We propose a\nsystematic approach to use publicly accessible reverse DNS hostnames for\ngeolocating IP addresses. Our method is designed to be combined with other\ngeolocation data sources. We cast the task as a machine learning problem where\nfor a given hostname, we generate and rank a list of potential location\ncandidates. We evaluate our approach against three state of the art academic\nbaselines and two state of the art commercial IP geolocation databases. We show\nthat our work significantly outperforms the academic baselines, and is\ncomplementary and competitive with commercial databases. To aid\nreproducibility, we open source our entire approach.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2018 17:58:30 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Dan", "Ovidiu", ""], ["Parikh", "Vaibhav", ""], ["Davison", "Brian D.", ""]]}, {"id": "1811.04375", "submitter": "Xinyu Guan", "authors": "Xinyu Guan, Zhiyong Cheng, Xiangnan He, Yongfeng Zhang, Zhibo Zhu,\n  Qinke Peng, Tat-Seng Chua", "title": "Attentive Aspect Modeling for Review-aware Recommendation", "comments": "Camera-ready manuscript for TOIS", "journal-ref": "ACM Transactions on Information Systems (TOIS), 37(3), p.28 (2019)", "doi": "10.1145/3309546", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, many studies extract aspects from user reviews and integrate\nthem with ratings for improving the recommendation performance. The common\naspects mentioned in a user's reviews and a product's reviews indicate indirect\nconnections between the user and product. However, these aspect-based methods\nsuffer from two problems. First, the common aspects are usually very sparse,\nwhich is caused by the sparsity of user-product interactions and the diversity\nof individual users' vocabularies. Second, a user's interests on aspects could\nbe different with respect to different products, which are usually assumed to\nbe static in existing methods. In this paper, we propose an Attentive\nAspect-based Recommendation Model (AARM) to tackle these challenges. For the\nfirst problem, to enrich the aspect connections between user and product,\nbesides common aspects, AARM also models the interactions between synonymous\nand similar aspects. For the second problem, a neural attention network which\nsimultaneously considers user, product and aspect information is constructed to\ncapture a user's attention towards aspects when examining different products.\nExtensive quantitative and qualitative experiments show that AARM can\neffectively alleviate the two aforementioned problems and significantly\noutperforms several state-of-the-art recommendation methods on top-N\nrecommendation task.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 09:23:06 GMT"}, {"version": "v2", "created": "Fri, 25 Jan 2019 13:05:42 GMT"}, {"version": "v3", "created": "Wed, 17 Apr 2019 13:44:31 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Guan", "Xinyu", ""], ["Cheng", "Zhiyong", ""], ["He", "Xiangnan", ""], ["Zhang", "Yongfeng", ""], ["Zhu", "Zhibo", ""], ["Peng", "Qinke", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1811.04392", "submitter": "Feng Xue", "authors": "Feng Xue, Xiangnan He, Xiang Wang, Jiandong Xu, Kai Liu, Richang Hong", "title": "Deep Item-based Collaborative Filtering for Top-N Recommendation", "comments": "25 pages, submitted to TOIS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Item-based Collaborative Filtering(short for ICF) has been widely adopted in\nrecommender systems in industry, owing to its strength in user interest\nmodeling and ease in online personalization. By constructing a user's profile\nwith the items that the user has consumed, ICF recommends items that are\nsimilar to the user's profile. With the prevalence of machine learning in\nrecent years, significant processes have been made for ICF by learning item\nsimilarity (or representation) from data. Nevertheless, we argue that most\nexisting works have only considered linear and shallow relationship between\nitems, which are insufficient to capture the complicated decision-making\nprocess of users.\n  In this work, we propose a more expressive ICF solution by accounting for the\nnonlinear and higher-order relationship among items. Going beyond modeling only\nthe second-order interaction (e.g. similarity) between two items, we\nadditionally consider the interaction among all interacted item pairs by using\nnonlinear neural networks. Through this way, we can effectively model the\nhigher-order relationship among items, capturing more complicated effects in\nuser decision-making. For example, it can differentiate which historical\nitemsets in a user's profile are more important in affecting the user to make a\npurchase decision on an item. We treat this solution as a deep variant of ICF,\nthus term it as DeepICF. To justify our proposal, we perform empirical studies\non two public datasets from MovieLens and Pinterest. Extensive experiments\nverify the highly positive effect of higher-order item interaction modeling\nwith nonlinear neural networks. Moreover, we demonstrate that by more\nfine-grained second-order interaction modeling with attention network, the\nperformance of our DeepICF method can be further improved.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 11:06:01 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Xue", "Feng", ""], ["He", "Xiangnan", ""], ["Wang", "Xiang", ""], ["Xu", "Jiandong", ""], ["Liu", "Kai", ""], ["Hong", "Richang", ""]]}, {"id": "1811.04411", "submitter": "Xiaoyu Du", "authors": "Xiangnan He, Jinhui Tang, Xiaoyu Du, Richang Hong, Tongwei Ren and\n  Tat-Seng Chua", "title": "Fast Matrix Factorization with Non-Uniform Weights on Missing Data", "comments": "IEEE Transactions on Neural Networks and Learning Systems (TNNLS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Matrix factorization (MF) has been widely used to discover the low-rank\nstructure and to predict the missing entries of data matrix. In many real-world\nlearning systems, the data matrix can be very high-dimensional but sparse. This\nposes an imbalanced learning problem, since the scale of missing entries is\nusually much larger than that of observed entries, but they cannot be ignored\ndue to the valuable negative signal. For efficiency concern, existing work\ntypically applies a uniform weight on missing entries to allow a fast learning\nalgorithm. However, this simplification will decrease modeling fidelity,\nresulting in suboptimal performance for downstream applications.\n  In this work, we weight the missing data non-uniformly, and more generically,\nwe allow any weighting strategy on the missing data. To address the efficiency\nchallenge, we propose a fast learning method, for which the time complexity is\ndetermined by the number of observed entries in the data matrix, rather than\nthe matrix size. The key idea is two-fold: 1) we apply truncated SVD on the\nweight matrix to get a more compact representation of the weights, and 2) we\nlearn MF parameters with element-wise alternating least squares (eALS) and\nmemorize the key intermediate variables to avoid repeating computations that\nare unnecessary. We conduct extensive experiments on two recommendation\nbenchmarks, demonstrating the correctness, efficiency, and effectiveness of our\nfast eALS method.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 13:17:42 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 07:07:27 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["He", "Xiangnan", ""], ["Tang", "Jinhui", ""], ["Du", "Xiaoyu", ""], ["Hong", "Richang", ""], ["Ren", "Tongwei", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1811.04415", "submitter": "Qingyao Ai", "authors": "Qingyao Ai, Xuanhui Wang, Sebastian Bruch, Nadav Golbandi, Michael\n  Bendersky, Marc Najork", "title": "Learning Groupwise Multivariate Scoring Functions Using Deep Neural\n  Networks", "comments": null, "journal-ref": null, "doi": "10.1145/3341981.3344218", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While in a classification or a regression setting a label or a value is\nassigned to each individual document, in a ranking setting we determine the\nrelevance ordering of the entire input document list. This difference leads to\nthe notion of relative relevance between documents in ranking. The majority of\nthe existing learning-to-rank algorithms model such relativity at the loss\nlevel using pairwise or listwise loss functions. However, they are restricted\nto univariate scoring functions, i.e., the relevance score of a document is\ncomputed based on the document itself, regardless of other documents in the\nlist. To overcome this limitation, we propose a new framework for multivariate\nscoring functions, in which the relevance score of a document is determined\njointly by multiple documents in the list. We refer to this framework as GSFs\n-- groupwise scoring functions. We learn GSFs with a deep neural network\narchitecture, and demonstrate that several representative learning-to-rank\nalgorithms can be modeled as special cases in our framework. We conduct\nevaluation using click logs from one of the largest commercial email search\nengines, as well as a public benchmark dataset. In both cases, GSFs lead to\nsignificant performance improvements, especially in the presence of sparse\ntextual features.\n", "versions": [{"version": "v1", "created": "Sun, 11 Nov 2018 13:43:37 GMT"}, {"version": "v2", "created": "Tue, 4 Dec 2018 16:44:09 GMT"}, {"version": "v3", "created": "Sun, 4 Aug 2019 14:08:33 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Ai", "Qingyao", ""], ["Wang", "Xuanhui", ""], ["Bruch", "Sebastian", ""], ["Golbandi", "Nadav", ""], ["Bendersky", "Michael", ""], ["Najork", "Marc", ""]]}, {"id": "1811.04540", "submitter": "Xiang Wang", "authors": "Xiang Wang, Dingxian Wang, Canran Xu, Xiangnan He, Yixin Cao, Tat-Seng\n  Chua", "title": "Explainable Reasoning over Knowledge Graphs for Recommendation", "comments": "8 pages, 5 figures, AAAI-2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Incorporating knowledge graph into recommender systems has attracted\nincreasing attention in recent years. By exploring the interlinks within a\nknowledge graph, the connectivity between users and items can be discovered as\npaths, which provide rich and complementary information to user-item\ninteractions. Such connectivity not only reveals the semantics of entities and\nrelations, but also helps to comprehend a user's interest. However, existing\nefforts have not fully explored this connectivity to infer user preferences,\nespecially in terms of modeling the sequential dependencies within and holistic\nsemantics of a path. In this paper, we contribute a new model named\nKnowledge-aware Path Recurrent Network (KPRN) to exploit knowledge graph for\nrecommendation. KPRN can generate path representations by composing the\nsemantics of both entities and relations. By leveraging the sequential\ndependencies within a path, we allow effective reasoning on paths to infer the\nunderlying rationale of a user-item interaction. Furthermore, we design a new\nweighted pooling operation to discriminate the strengths of different paths in\nconnecting a user with an item, endowing our model with a certain level of\nexplainability. We conduct extensive experiments on two datasets about movie\nand music, demonstrating significant improvements over state-of-the-art\nsolutions Collaborative Knowledge Base Embedding and Neural Factorization\nMachine.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 03:36:14 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Wang", "Xiang", ""], ["Wang", "Dingxian", ""], ["Xu", "Canran", ""], ["He", "Xiangnan", ""], ["Cao", "Yixin", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "1811.04852", "submitter": "Chunhao Wang", "authors": "Nai-Hui Chia, Han-Hsuan Lin, Chunhao Wang", "title": "Quantum-inspired sublinear classical algorithms for solving low-rank\n  linear systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present classical sublinear-time algorithms for solving low-rank linear\nsystems of equations. Our algorithms are inspired by the HHL quantum algorithm\nfor solving linear systems and the recent breakthrough by Tang of dequantizing\nthe quantum algorithm for recommendation systems. Let $A \\in \\mathbb{C}^{m\n\\times n}$ be a rank-$k$ matrix, and $b \\in \\mathbb{C}^m$ be a vector. We\npresent two algorithms: a \"sampling\" algorithm that provides a sample from\n$A^{-1}b$ and a \"query\" algorithm that outputs an estimate of an entry of\n$A^{-1}b$, where $A^{-1}$ denotes the Moore-Penrose pseudo-inverse. Both of our\nalgorithms have query and time complexity $O(\\mathrm{poly}(k, \\kappa, \\|A\\|_F,\n1/\\epsilon)\\,\\mathrm{polylog}(m, n))$, where $\\kappa$ is the condition number\nof $A$ and $\\epsilon$ is the precision parameter. Note that the algorithms we\nconsider are sublinear time, so they cannot write and read the whole matrix or\nvectors. In this paper, we assume that $A$ and $b$ come with well-known\nlow-overhead data structures such that entries of $A$ and $b$ can be sampled\naccording to some natural probability distributions. Alternatively, when $A$ is\npositive semidefinite, our algorithms can be adapted so that the sampling\nassumption on $b$ is not required.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 16:57:33 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Chia", "Nai-Hui", ""], ["Lin", "Han-Hsuan", ""], ["Wang", "Chunhao", ""]]}, {"id": "1811.04860", "submitter": "Genevieve Gorrell", "authors": "Genevieve Gorrell, Xingyi Song, Angus Roberts", "title": "Bio-YODIE: A Named Entity Linking System for Biomedical Text", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Ever-expanding volumes of biomedical text require automated semantic\nannotation techniques to curate and put to best use. An established field of\nresearch seeks to link mentions in text to knowledge bases such as those\nincluded in the UMLS (Unified Medical Language System), in order to enable a\nmore sophisticated understanding. This work has yielded good results for tasks\nsuch as curating literature, but increasingly, annotation systems are more\nbroadly applied. Medical vocabularies are expanding in size, and with them the\nextent of term ambiguity. Document collections are increasing in size and\ncomplexity, creating a greater need for speed and robustness. Furthermore, as\nthe technologies are turned to new tasks, requirements change; for example\ngreater coverage of expressions may be required in order to annotate patient\nrecords, and greater accuracy may be needed for applications that affect\npatients. This places new demands on the approaches currently in use. In this\nwork, we present a new system, Bio-YODIE, and compare it to two other popular\nsystems in order to give guidance about suitable approaches in different\nscenarios and how systems might be designed to accommodate future needs.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 17:06:53 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Gorrell", "Genevieve", ""], ["Song", "Xingyi", ""], ["Roberts", "Angus", ""]]}, {"id": "1811.05063", "submitter": "Lewis Mitchell", "authors": "Peter Mathews, Caitlin Gray, Lewis Mitchell, Giang T. Nguyen, Nigel\n  G.Bean", "title": "SMERC: Social media event response clustering using textual and temporal\n  information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR physics.data-an stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tweet clustering for event detection is a powerful modern method to automate\nthe real-time detection of events. In this work we present a new tweet\nclustering approach, using a probabilistic approach to incorporate temporal\ninformation. By analysing the distribution of time gaps between tweets we show\nthat the gaps between pairs of related tweets exhibit exponential decay,\nwhereas the gaps between unrelated tweets are approximately uniform. Guided by\nthis insight, we use probabilistic arguments to estimate the likelihood that a\npair of tweets are related, and build an improved clustering method. Our method\nSocial Media Event Response Clustering (SMERC) creates clusters of tweets based\non their tendency to be related to a single event. We evaluate our method at\nthree levels: through traditional event prediction from tweet clustering, by\nmeasuring the improvement in quality of clusters created, and also comparing\nthe clustering precision and recall with other methods. By applying SMERC to\ntweets collected during a number of sporting events, we demonstrate that\nincorporating temporal information leads to state of the art clustering\nperformance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 01:58:36 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Mathews", "Peter", ""], ["Gray", "Caitlin", ""], ["Mitchell", "Lewis", ""], ["Nguyen", "Giang T.", ""], ["Bean", "Nigel G.", ""]]}, {"id": "1811.05318", "submitter": "Zhiyong Cheng", "authors": "Zhiyong Cheng, Xiaojun Chang, Lei Zhu, Rose C. Kanjirathinkal, Mohan\n  Kankanhalli", "title": "MMALFM: Explainable Recommendation by Leveraging Reviews and Images", "comments": "This paper has been accepted by Transactions on Information Systems.\n  arXiv admin note: substantial text overlap with arXiv:1802.07938", "journal-ref": null, "doi": "10.1145/3291060", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although the latent factor model achieves good accuracy in rating prediction,\nit suffers from many problems including cold-start, non-transparency, and\nsuboptimal results for individual user-item pairs. In this paper, we exploit\ntextual reviews and item images together with ratings to tackle these\nlimitations. Specifically, we first apply a proposed multi-modal aspect-aware\ntopic model (MATM) on text reviews and item images to model users' preferences\nand items' features from different aspects, and also estimate the aspect\nimportance of a user towards an item. Then the aspect importance is integrated\ninto a novel aspect-aware latent factor model (ALFM), which learns user's and\nitem's latent factors based on ratings. In particular, ALFM introduces a weight\nmatrix to associate those latent factors with the same set of aspects in MATM,\nsuch that the latent factors could be used to estimate aspect ratings. Finally,\nthe overall rating is computed via a linear combination of the aspect ratings,\nwhich are weighted by the corresponding aspect importance. To this end, our\nmodel could alleviate the data sparsity problem and gain good interpretability\nfor recommendation. Besides, every aspect rating is weighted by its aspect\nimportance, which is dependent on the targeted user's preferences and the\ntargeted item's features. Therefore, it is expected that the proposed method\ncan model a user's preferences on an item more accurately for each user-item\npair. Comprehensive experimental studies have been conducted on the Yelp 2017\nChallenge dataset and Amazon product datasets to demonstrate the effectiveness\nof our method.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2018 06:00:10 GMT"}, {"version": "v2", "created": "Sat, 24 Nov 2018 08:25:10 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Cheng", "Zhiyong", ""], ["Chang", "Xiaojun", ""], ["Zhu", "Lei", ""], ["Kanjirathinkal", "Rose C.", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "1811.05402", "submitter": "Carsten Eickhoff", "authors": "Xing Wei, Carsten Eickhoff", "title": "Embedding Electronic Health Records for Clinical Information Retrieval", "comments": "Published in AMIA Annual Symposium 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural network representation learning frameworks have recently shown to be\nhighly effective at a wide range of tasks ranging from radiography\ninterpretation via data-driven diagnostics to clinical decision support. This\noften superior performance comes at the price of dramatically increased\ntraining data requirements that cannot be satisfied in every given institution\nor scenario. As a means of countering such data sparsity effects, distant\nsupervision alleviates the need for scarce in-domain data by relying on a\nrelated, resource-rich, task for training.\n  This study presents an end-to-end neural clinical decision support system\nthat recommends relevant literature for individual patients (few available\nresources) via distant supervision on the well-known MIMIC-III collection\n(abundant resource). Our experiments show significant improvements in retrieval\neffectiveness over traditional statistical as well as purely locally supervised\nretrieval models.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 16:55:52 GMT"}], "update_date": "2018-11-14", "authors_parsed": [["Wei", "Xing", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "1811.05475", "submitter": "Jingcheng Du", "authors": "Jingcheng Du, Qingyu Chen, Yifan Peng, Yang Xiang, Cui Tao, Zhiyong Lu", "title": "ML-Net: multi-label classification of biomedical texts with deep neural\n  networks", "comments": null, "journal-ref": null, "doi": "10.1093/jamia/ocz085", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multi-label text classification, each textual document can be assigned\nwith one or more labels. Due to this nature, the multi-label text\nclassification task is often considered to be more challenging compared to the\nbinary or multi-class text classification problems. As an important task with\nbroad applications in biomedicine such as assigning diagnosis codes, a number\nof different computational methods (e.g. training and combining binary\nclassifiers for each label) have been proposed in recent years. However, many\nsuffered from modest accuracy and efficiency, with only limited success in\npractical use. We propose ML-Net, a novel deep learning framework, for\nmulti-label classification of biomedical texts. As an end-to-end system, ML-Net\ncombines a label prediction network with an automated label count prediction\nmechanism to output an optimal set of labels by leveraging both predicted\nconfidence score of each label and the contextual information in the target\ndocument. We evaluate ML-Net on three independent, publicly-available corpora\nin two kinds of text genres: biomedical literature and clinical notes. For\nevaluation, example-based measures such as precision, recall and f-measure are\nused. ML-Net is compared with several competitive machine learning baseline\nmodels. Our benchmarking results show that ML-Net compares favorably to the\nstate-of-the-art methods in multi-label classification of biomedical texts.\nML-NET is also shown to be robust when evaluated on different text genres in\nbiomedicine. Unlike traditional machine learning methods, ML-Net does not\nrequire human efforts in feature engineering and is highly efficient and\nscalable approach to tasks with a large set of labels (no need to build\nindividual classifiers for each separate label). Finally, ML-NET is able to\ndynamically estimate the label count based on the document context in a more\nsystematic and accurate manner.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 17:31:49 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2018 16:02:52 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Du", "Jingcheng", ""], ["Chen", "Qingyu", ""], ["Peng", "Yifan", ""], ["Xiang", "Yang", ""], ["Tao", "Cui", ""], ["Lu", "Zhiyong", ""]]}, {"id": "1811.05549", "submitter": "Michel Gagnon", "authors": "Gagnon Michel, Zouaq Amal, Aranha Francisco, Ensan Faezeh and\n  Jean-Louis Ludovic", "title": "An Analysis of the Semantic Annotation Task on the Linked Data Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic annotation, the process of identifying key-phrases in texts and\nlinking them to concepts in a knowledge base, is an important basis for\nsemantic information retrieval and the Semantic Web uptake. Despite the\nemergence of semantic annotation systems, very few comparative studies have\nbeen published on their performance. In this paper, we provide an evaluation of\nthe performance of existing systems over three tasks: full semantic annotation,\nnamed entity recognition, and keyword detection. More specifically, the\nspotting capability (recognition of relevant surface forms in text) is\nevaluated for all three tasks, whereas the disambiguation (correctly\nassociating an entity from Wikipedia or DBpedia to the spotted surface forms)\nis evaluated only for the first two tasks. Our evaluation is twofold: First, we\ncompute standard precision and recall on the output of semantic annotators on\ndiverse datasets, each best suited for one of the identified tasks. Second, we\nbuild a statistical model using logistic regression to identify significant\nperformance differences. Our results show that systems that provide full\nannotation perform better than named entities annotators and keyword\nextractors, for all three tasks. However, there is still much room for\nimprovement for the identification of the most relevant entities described in a\ntext.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 22:24:29 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Michel", "Gagnon", ""], ["Amal", "Zouaq", ""], ["Francisco", "Aranha", ""], ["Faezeh", "Ensan", ""], ["Ludovic", "Jean-Louis", ""]]}, {"id": "1811.05563", "submitter": "Liangchen Luo", "authors": "Qi Zeng, Liangchen Luo, Wenhao Huang, Yang Tang", "title": "Text Assisted Insight Ranking Using Context-Aware Memory Network", "comments": "Accepted to AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Extracting valuable facts or informative summaries from multi-dimensional\ntables, i.e. insight mining, is an important task in data analysis and business\nintelligence. However, ranking the importance of insights remains a challenging\nand unexplored task. The main challenge is that explicitly scoring an insight\nor giving it a rank requires a thorough understanding of the tables and costs a\nlot of manual efforts, which leads to the lack of available training data for\nthe insight ranking problem. In this paper, we propose an insight ranking model\nthat consists of two parts: A neural ranking model explores the data\ncharacteristics, such as the header semantics and the data statistical\nfeatures, and a memory network model introduces table structure and context\ninformation into the ranking process. We also build a dataset with text\nassistance. Experimental results show that our approach largely improves the\nranking precision as reported in multi evaluation metrics.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2018 23:11:26 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Zeng", "Qi", ""], ["Luo", "Liangchen", ""], ["Huang", "Wenhao", ""], ["Tang", "Yang", ""]]}, {"id": "1811.05711", "submitter": "Muhammed Tarik Altuncu", "authors": "M. Tarik Altuncu, Erik Mayer, Sophia N. Yaliraki, Mauricio Barahona", "title": "From Free Text to Clusters of Content in Health Records: An Unsupervised\n  Graph Partitioning Approach", "comments": "25 pages, 2 tables, 8 figures and 5 supplementary figures", "journal-ref": null, "doi": "10.1007/s41109-018-0109-9", "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Healthcare records contain large volumes of unstructured data in\ndifferent forms. Free text constitutes a large portion of such data, yet this\nsource of richly detailed information often remains under-used in practice\nbecause of a lack of suitable methodologies to extract interpretable content in\na timely manner. Here we apply network-theoretical tools to the analysis of\nfree text in Hospital Patient Incident reports in the English National Health\nService, to find clusters of reports in an unsupervised manner and at different\nlevels of resolution based directly on the free text descriptions contained\nwithin them. To do so, we combine recently developed deep neural network\ntext-embedding methodologies based on paragraph vectors with multi-scale Markov\nStability community detection applied to a similarity graph of documents\nobtained from sparsified text vector similarities. We showcase the approach\nwith the analysis of incident reports submitted in Imperial College Healthcare\nNHS Trust, London. The multiscale community structure reveals levels of meaning\nwith different resolution in the topics of the dataset, as shown by relevant\ndescriptive terms extracted from the groups of records, as well as by comparing\na posteriori against hand-coded categories assigned by healthcare personnel.\nOur content communities exhibit good correspondence with well-defined\nhand-coded categories, yet our results also provide further medical detail in\ncertain areas as well as revealing complementary descriptors of incidents\nbeyond the external classification. We also discuss how the method can be used\nto monitor reports over time and across different healthcare providers, and to\ndetect emerging trends that fall outside of pre-existing categories.\n", "versions": [{"version": "v1", "created": "Wed, 14 Nov 2018 10:08:19 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Altuncu", "M. Tarik", ""], ["Mayer", "Erik", ""], ["Yaliraki", "Sophia N.", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1811.05757", "submitter": "Tharindu Bandaragoda", "authors": "Tharindu Rukshan Bandaragoda, Daswin De Silva, Damminda Alahakoon", "title": "Automatic event detection in microblogs using incremental machine\n  learning", "comments": null, "journal-ref": "Journal of the Association for Information Science and Technology,\n  2017, 68(10), 2394-2411", "doi": "10.1002/asi.23896", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The global popularity of microblogs has led to an increasing accumulation of\nlarge volumes of text data on microblogging platforms such as Twitter. These\ncorpora are untapped resources to understand social expressions on diverse\nsubjects. Microblog analysis aims to unlock the value of such expressions by\ndiscovering insights and events of significance hidden among swathes of text.\nBesides velocity; diversity of content, brevity, absence of structure and\ntime-sensitivity are key challenges in microblog analysis. In this paper, we\npropose an unsupervised incremental machine learning and event detection\ntechnique to address these challenges. The proposed technique separates a\nmicroblog discussion into topics to address the key problem of diversity. It\nmaintains a record of the evolution of each topic over time. Brevity,\ntime-sensitivity and unstructured nature are addressed by these individual\ntopic pathways which contribute to generate a temporal, topic-driven structure\nof a microblog discussion. The proposed event detection method continuously\nmonitors these topic pathways using multiple domain-independent event\nindicators for events of significance. The autonomous nature of topic\nseparation, topic pathway generation, new topic identification and event\ndetection, appropriates the proposed technique for extensive applications in\nmicroblog analysis. We demonstrate these capabilities on tweets containing\n#microsoft and tweets containing #obama.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2018 21:56:25 GMT"}], "update_date": "2018-11-15", "authors_parsed": [["Bandaragoda", "Tharindu Rukshan", ""], ["De Silva", "Daswin", ""], ["Alahakoon", "Damminda", ""]]}, {"id": "1811.06147", "submitter": "Joel Mackenzie", "authors": "Rodger Benham, Joel Mackenzie, Alistair Moffat, and J. Shane Culpepper", "title": "Boosting Search Performance Using Query Variations", "comments": "Published in ACM TOIS, 2019", "journal-ref": null, "doi": "10.1145/3345001", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rank fusion is a powerful technique that allows multiple sources of\ninformation to be combined into a single result set. However, to date fusion\nhas not been regarded as being cost-effective in cases where strict per-query\nefficiency guarantees are required, such as in web search. In this work we\npropose a novel solution to rank fusion by splitting the computation into two\nparts -- one phase that is carried out offline to generate pre-computed\ncentroid answers for queries with broadly similar information needs, and then a\nsecond online phase that uses the corresponding topic centroid to compute a\nresult page for each query. We explore efficiency improvements to classic\nfusion algorithms whose costs can be amortized as a pre-processing step, and\ncan then be combined with re-ranking approaches to dramatically improve\neffectiveness in multi-stage retrieval systems with little efficiency overhead\nat query time. Experimental results using the ClueWeb12B collection and the\nUQV100 query variations demonstrate that centroid-based approaches allow\nimproved retrieval effectiveness at little or no loss in query throughput or\nlatency, and with reasonable pre-processing requirements. We additionally show\nthat queries that do not match any of the pre-computed clusters can be\naccurately identified and efficiently processed in our proposed ranking\npipeline.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 02:43:06 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2020 00:34:14 GMT"}], "update_date": "2020-11-11", "authors_parsed": [["Benham", "Rodger", ""], ["Mackenzie", "Joel", ""], ["Moffat", "Alistair", ""], ["Culpepper", "J. Shane", ""]]}, {"id": "1811.06567", "submitter": "Chandra Yadav Shekhar", "authors": "Chandra Shekhar Yadav", "title": "Automatic Text Document Summarization using Semantic-based Analysis", "comments": "six chapters, 32 figures, 25 tables, 167 pages, phd thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the advent of the web, the amount of data on wen has been increased\nseveral million folds. In recent years web data generated is more than data\nstored for years. One important data format is text. To answer user queries\nover the internet, and to overcome the problem of information overload one\npossible solution is text document summarization. This not only reduces query\naccess time, but also optimize the document results according to specific users\nrequirements. Summarization of text document can be categorized as abstractive\nand extractive. Most of the work has been done in the direction of Extractive\nsummarization. Extractive summarized result is a subset of original documents\nwith the objective of more content coverage and lea redundancy. Our work is\nbased on Extractive approaches. In the first approach, we are using some\nstatistical features and semantic-based features. To include sentiment as a\nfeature is an idea cached from a view that emotion plays an important role. It\neffectively conveys a message. So, it may play a vital role in text document\nsummarization.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 19:29:26 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Yadav", "Chandra Shekhar", ""]]}, {"id": "1811.06645", "submitter": "Sagar Uprety Mr.", "authors": "Sagar Uprety, Dimitris Gkoumas, Dawei Song", "title": "Investigating Bell Inequalities for Multidimensional Relevance Judgments\n  in Information Retrieval", "comments": "11th Quantum Interaction Conference, Nice, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Relevance judgment in Information Retrieval is influenced by multiple\nfactors. These include not only the topicality of the documents but also other\nuser oriented factors like trust, user interest, etc. Recent works have\nidentified these various factors into seven dimensions of relevance. In a\nprevious work, these relevance dimensions were quantified and user's cognitive\nstate with respect to a document was represented as a state vector in a Hilbert\nSpace, with each relevance dimension representing a basis. It was observed that\nrelevance dimensions are incompatible in some documents, when making a\njudgment. Incompatibility being a fundamental feature of Quantum Theory, this\nmotivated us to test the Quantum nature of relevance judgments using Bell type\ninequalities. However, none of the Bell-type inequalities tested have shown any\nviolation. We discuss our methodology to construct incompatible basis for\ndocuments from real world query log data, the experiments to test Bell\ninequalities on this dataset and possible reasons for the lack of violation.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 01:33:19 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 18:24:50 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Uprety", "Sagar", ""], ["Gkoumas", "Dimitris", ""], ["Song", "Dawei", ""]]}, {"id": "1811.06678", "submitter": "Harrie Oosterhuis", "authors": "Harrie Oosterhuis, J. Shane Culpepper, Maarten de Rijke", "title": "The Potential of Learned Index Structures for Index Compression", "comments": "Will appear in the proceedings of ADCS'18", "journal-ref": null, "doi": "10.1145/3291992.3291993", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inverted indexes are vital in providing fast key-word-based search. For every\nterm in the document collection, a list of identifiers of documents in which\nthe term appears is stored, along with auxiliary information such as term\nfrequency, and position offsets. While very effective, inverted indexes have\nlarge memory requirements for web-sized collections. Recently, the concept of\nlearned index structures was introduced, where machine learned models replace\ncommon index structures such as B-tree-indexes, hash-indexes, and\nbloom-filters. These learned index structures require less memory, and can be\ncomputationally much faster than their traditional counterparts. In this paper,\nwe consider whether such models may be applied to conjunctive Boolean querying.\nFirst, we investigate how a learned model can replace document postings of an\ninverted index, and then evaluate the compromises such an approach might have.\nSecond, we evaluate the potential gains that can be achieved in terms of memory\nrequirements. Our work shows that learned models have great potential in\ninverted indexing, and this direction seems to be a promising area for future\nresearch.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 05:12:28 GMT"}, {"version": "v2", "created": "Tue, 29 Jan 2019 15:07:16 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Oosterhuis", "Harrie", ""], ["Culpepper", "J. Shane", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1811.06773", "submitter": "Ashkan Esmaeili", "authors": "Ashkan Esmaeili and Farokh Marvasti", "title": "A Novel Approach to Sparse Inverse Covariance Estimation Using Transform\n  Domain Updates and Exponentially Adaptive Thresholding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Inverse Covariance Estimation (SICE) is useful in many practical data\nanalyses. Recovering the connectivity, non-connectivity graph of covariates is\nclassified amongst the most important data mining and learning problems. In\nthis paper, we introduce a novel SICE approach using adaptive thresholding. Our\nmethod is based on updates in a transformed domain of the desired matrix and\nexponentially decaying adaptive thresholding in the main domain (Inverse\nCovariance matrix domain). In addition to the proposed algorithm, the\nconvergence analysis is also provided. In the Numerical Experiments Section, we\nshow that the proposed method outperforms state-of-the-art methods in terms of\naccuracy.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 12:03:46 GMT"}, {"version": "v2", "created": "Thu, 4 Apr 2019 00:29:49 GMT"}], "update_date": "2019-04-05", "authors_parsed": [["Esmaeili", "Ashkan", ""], ["Marvasti", "Farokh", ""]]}, {"id": "1811.06859", "submitter": "Ishwarya Ananthabhotla", "authors": "Ishwarya Ananthabhotla, Joseph A. Paradiso", "title": "SoundSignaling: Realtime, Stylistic Modification of a Personal Music\n  Corpus for Information Delivery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Drawing inspiration from the notion of cognitive incongruence associated with\nStroop's famous experiment, from musical principles, and from the observation\nthat music consumption on an individual basis is becoming increasingly\nubiquitous, we present the SoundSignaling system -- a software platform\ndesigned to make real-time, stylistically relevant modifications to a personal\ncorpus of music as a means of conveying information or notifications. In this\nwork, we discuss in detail the system's technical implementation and its\nmotivation from a musical perspective, and validate these design choices\nthrough a crowd-sourced signal identification experiment consisting of 200\nindependent tasks performed by 50 online participants. We then qualitatively\ndiscuss the potential implications of such a system from the standpoint of\nswitch cost, cognitive load, and listening behavior by considering the\nanecdotal outcomes of a small-scale, in-the-wild experiment consisting of over\n180 hours of usage from 6 participants. Through this work, we suggest a\nre-evaluation of the age-old paradigm of binary audio notifications in favor of\na system designed to operate upon the relatively unexplored medium of a user's\nmusical preferences.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 15:32:28 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Ananthabhotla", "Ishwarya", ""], ["Paradiso", "Joseph A.", ""]]}, {"id": "1811.06884", "submitter": "Quoc Hung Ngo Mr", "authors": "Quoc Hung Ngo, Nhien-An Le-Khac and Tahar Kechadi", "title": "Ontology based Approach for Precision Agriculture", "comments": null, "journal-ref": "Kaenampornpan M., Malaka R., Nguyen D., Schwind N. (eds)\n  Multi-disciplinary Trends in Artificial Intelligence. MIWAI 2018. Lecture\n  Notes in Computer Science, vol 11248. Springer, Cham", "doi": "10.1007/978-3-030-03014-8_15", "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a framework of knowledge for an agriculture\nontology which can be used for the purpose of smart agriculture systems. This\nontology not only includes basic concepts in the agricultural domain but also\ncontains geographical, IoT, business subdomains, and other knowledge extracted\nfrom various datasets. With this ontology, any users can easily understand\nagricultural data links between them collected from many different data\nresources. In our experiment, we also import country, sub-country and disease\nentities into this ontology as basic entities for building agricultural linked\ndatasets later.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2018 16:03:32 GMT"}], "update_date": "2018-11-19", "authors_parsed": [["Ngo", "Quoc Hung", ""], ["Le-Khac", "Nhien-An", ""], ["Kechadi", "Tahar", ""]]}, {"id": "1811.07042", "submitter": "Anton Belyy", "authors": "Mariia Seleznova, Anton Belyy, Aleksei Sholokhov", "title": "Towards Large-Scale Exploratory Search over Heterogeneous Sources", "comments": "5 pages, 3 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Since time immemorial, people have been looking for ways to organize\nscientific knowledge into some systems to facilitate search and discovery of\nnew ideas. The problem was partially solved in the pre-Internet era using\nlibrary classifications, but nowadays it is nearly impossible to classify all\nscientific and popular scientific knowledge manually. There is a clear gap\nbetween the diversity and the amount of data available on the Internet and the\nalgorithms for automatic structuring of such data. In our preliminary study, we\napproach the problem of knowledge discovery on web-scale data with diverse text\nsources and propose an algorithm to aggregate multiple collections into a\nsingle hierarchical topic model. We implement a web service named Rysearch to\ndemonstrate the concept of topical exploratory search and make it available\nonline.\n", "versions": [{"version": "v1", "created": "Thu, 15 Nov 2018 01:48:48 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 10:13:59 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Seleznova", "Mariia", ""], ["Belyy", "Anton", ""], ["Sholokhov", "Aleksei", ""]]}, {"id": "1811.07174", "submitter": "Samuel Gomes Fadel", "authors": "Samuel G. Fadel and Ricardo da S. Torres", "title": "Link Prediction in Dynamic Graphs for Recommendation", "comments": "Workshop on Relational Representation Learning (R2L), NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in employing neural networks on graph domains helped push the\nstate of the art in link prediction tasks, particularly in recommendation\nservices. However, the use of temporal contextual information, often modeled as\ndynamic graphs that encode the evolution of user-item relationships over time,\nhas been overlooked in link prediction problems. In this paper, we consider the\nhypothesis that leveraging such information enables models to make better\npredictions, proposing a new neural network approach for this. Our experiments,\nperformed on the widely used ML-100k and ML-1M datasets, show that our approach\nproduces better predictions in scenarios where the pattern of user-item\nrelationships change over time. In addition, they suggest that existing\napproaches are significantly impacted by those changes.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2018 14:56:13 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Fadel", "Samuel G.", ""], ["Torres", "Ricardo da S.", ""]]}, {"id": "1811.07361", "submitter": "Alexander Veretennikov Borisovich", "authors": "Alexander B. Veretennikov", "title": "Proximity Full-Text Search with a Response Time Guarantee by Means of\n  Additional Indexes", "comments": "Alexander B. Veretennikov. Chair of Calculation Mathematics and\n  Computer Science, INSM. Ural Federal University", "journal-ref": "Intelligent Systems and Applications. IntelliSys 2018. Advances in\n  Intelligent Systems and Computing, vol 868, pp 936-954. Springer, Cham", "doi": "10.1007/978-3-030-01054-6_66", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Full-text search engines are important tools for information retrieval. Term\nproximity is an important factor in relevance score measurement. In a proximity\nfull-text search, we assume that a relevant document contains query terms near\neach other, especially if the query terms are frequently occurring words. A\nmethodology for high-performance full-text query execution is discussed. We\nbuild additional indexes to achieve better efficiency. For a word that occurs\nin the text, we include in the indexes some information about nearby words.\nWhat types of additional indexes do we use? How do we use them? These questions\nare discussed in this work. We present the results of experiments showing that\nthe average time of search query execution is 44-45 times less than that\nrequired when using ordinary inverted indexes.\n  This is a pre-print of a contribution \"Veretennikov A.B. Proximity Full-Text\nSearch with a Response Time Guarantee by Means of Additional Indexes\" published\nin \"Arai K., Kapoor S., Bhatia R. (eds) Intelligent Systems and Applications.\nIntelliSys 2018. Advances in Intelligent Systems and Computing, vol 868\"\npublished by Springer, Cham. The final authenticated version is available\nonline at: https://doi.org/10.1007/978-3-030-01054-6_66. The work was supported\nby Act 211 Government of the Russian Federation, contract no 02.A03.21.0006.\n", "versions": [{"version": "v1", "created": "Sun, 18 Nov 2018 17:23:41 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Veretennikov", "Alexander B.", ""]]}, {"id": "1811.07514", "submitter": "Shobeir Fakhraei", "authors": "Shobeir Fakhraei, Joel Mathew, Jose Luis Ambite", "title": "NSEEN: Neural Semantic Embedding for Entity Normalization", "comments": "Accepted for publication at ECML-PKDD 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DB cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much of human knowledge is encoded in text, available in scientific\npublications, books, and the web. Given the rapid growth of these resources, we\nneed automated methods to extract such knowledge into machine-processable\nstructures, such as knowledge graphs. An important task in this process is\nentity normalization, which consists of mapping noisy entity mentions in text\nto canonical entities in well-known reference sets. However, entity\nnormalization is a challenging problem; there often are many textual forms for\na canonical entity that may not be captured in the reference set, and entities\nmentioned in text may include many syntactic variations, or errors. The problem\nis particularly acute in scientific domains, such as biology. To address this\nproblem, we have developed a general, scalable solution based on a deep Siamese\nneural network model to embed the semantic information about the entities, as\nwell as their syntactic variations. We use these embeddings for fast mapping of\nnew entities to large reference sets, and empirically show the effectiveness of\nour framework in challenging bio-entity normalization datasets.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 06:04:13 GMT"}, {"version": "v2", "created": "Sat, 29 Jun 2019 07:19:08 GMT"}], "update_date": "2019-07-02", "authors_parsed": [["Fakhraei", "Shobeir", ""], ["Mathew", "Joel", ""], ["Ambite", "Jose Luis", ""]]}, {"id": "1811.08008", "submitter": "Daniel Gillick", "authors": "Daniel Gillick, Alessandro Presta, Gaurav Singh Tomar", "title": "End-to-End Retrieval in Continuous Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most text-based information retrieval (IR) systems index objects by words or\nphrases. These discrete systems have been augmented by models that use\nembeddings to measure similarity in continuous space. But continuous-space\nmodels are typically used just to re-rank the top candidates. We consider the\nproblem of end-to-end continuous retrieval, where standard approximate nearest\nneighbor (ANN) search replaces the usual discrete inverted index, and rely\nentirely on distances between learned embeddings. By training simple models\nspecifically for retrieval, with an appropriate model architecture, we improve\non a discrete baseline by 8% and 26% (MAP) on two similar-question retrieval\ntasks. We also discuss the problem of evaluation for retrieval systems, and\nshow how to modify existing pairwise similarity datasets for this purpose.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2018 22:23:59 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Gillick", "Daniel", ""], ["Presta", "Alessandro", ""], ["Tomar", "Gaurav Singh", ""]]}, {"id": "1811.08120", "submitter": "Weiyu Cheng", "authors": "Weiyu Cheng, Yanyan Shen, Yanmin Zhu, Linpeng Huang", "title": "Explaining Latent Factor Models for Recommendation with Influence\n  Functions", "comments": null, "journal-ref": null, "doi": "10.1145/3292500.3330857", "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent factor models (LFMs) such as matrix factorization achieve the\nstate-of-the-art performance among various Collaborative Filtering (CF)\napproaches for recommendation. Despite the high recommendation accuracy of\nLFMs, a critical issue to be resolved is the lack of explainability. Extensive\nefforts have been made in the literature to incorporate explainability into\nLFMs. However, they either rely on auxiliary information which may not be\navailable in practice, or fail to provide easy-to-understand explanations. In\nthis paper, we propose a fast influence analysis method named FIA, which\nsuccessfully enforces explicit neighbor-style explanations to LFMs with the\ntechnique of influence functions stemmed from robust statistics. We first\ndescribe how to employ influence functions to LFMs to deliver neighbor-style\nexplanations. Then we develop a novel influence computation algorithm for\nmatrix factorization with high efficiency. We further extend it to the more\ngeneral neural collaborative filtering and introduce an approximation algorithm\nto accelerate influence analysis over neural network models. Experimental\nresults on real datasets demonstrate the correctness, efficiency and usefulness\nof our proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 08:31:24 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Cheng", "Weiyu", ""], ["Shen", "Yanyan", ""], ["Zhu", "Yanmin", ""], ["Huang", "Linpeng", ""]]}, {"id": "1811.08129", "submitter": "Pranav A", "authors": "Pranav A", "title": "Alignment Analysis of Sequential Segmentation of Lexicons to Improve\n  Automatic Cognate Detection", "comments": "Published at ACL-SRW 2018", "journal-ref": "Proceedings of ACL 2018, Student Research Workshop. 2018", "doi": "10.18653/v1/P18-3019", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranking functions in information retrieval are often used in search engines\nto recommend the relevant answers to the query. This paper makes use of this\nnotion of information retrieval and applies onto the problem domain of cognate\ndetection. The main contributions of this paper are: (1) positional\nsegmentation, which incorporates the sequential notion; (2) graphical error\nmodelling, which deduces the transformations. The current research work focuses\non classification problem; which is distinguishing whether a pair of words are\ncognates. This paper focuses on a harder problem, whether we could predict a\npossible cognate from the given input. Our study shows that when language\nmodelling smoothing methods are applied as the retrieval functions and used in\nconjunction with positional segmentation and error modelling gives better\nresults than competing baselines, in both classification and prediction of\ncognates.\n  Source code is at: https://github.com/pranav-ust/cognates\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 08:59:53 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["A", "Pranav", ""]]}, {"id": "1811.08203", "submitter": "Noveen Sachdeva", "authors": "Noveen Sachdeva, Kartik Gupta, Vikram Pudi", "title": "Attentive Neural Architecture Incorporating Song Features For Music\n  Recommendation", "comments": "Accepted as a paper at the 12th ACM Conference on Recommender Systems\n  (RecSys 18)", "journal-ref": "12th ACM Conference on Recommender Systems (RecSys '18). ACM\n  (2018) 417-421", "doi": "10.1145/3240323.3240397", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender Systems are an integral part of music sharing platforms. Often\nthe aim of these systems is to increase the time, the user spends on the\nplatform and hence having a high commercial value. The systems which aim at\nincreasing the average time a user spends on the platform often need to\nrecommend songs which the user might want to listen to next at each point in\ntime. This is different from recommendation systems which try to predict the\nitem which might be of interest to the user at some point in the user lifetime\nbut not necessarily in the very near future. Prediction of the next song the\nuser might like requires some kind of modeling of the user interests at the\ngiven point of time. Attentive neural networks have been exploiting the\nsequence in which the items were selected by the user to model the implicit\nshort-term interests of the user for the task of next item prediction, however\nwe feel that the features of the songs occurring in the sequence could also\nconvey some important information about the short-term user interest which only\nthe items cannot. In this direction, we propose a novel attentive neural\narchitecture which in addition to the sequence of items selected by the user,\nuses the features of these items to better learn the user short-term\npreferences and recommend the next song to the user.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2018 12:10:06 GMT"}], "update_date": "2018-11-21", "authors_parsed": [["Sachdeva", "Noveen", ""], ["Gupta", "Kartik", ""], ["Pudi", "Vikram", ""]]}, {"id": "1811.08772", "submitter": "Sean MacAvaney", "authors": "Sean MacAvaney, Andrew Yates, Arman Cohan, Luca Soldaini, Kai Hui,\n  Nazli Goharian, Ophir Frieder", "title": "Overcoming low-utility facets for complex answer retrieval", "comments": "This is a pre-print of an article published in Information Retrieval\n  Journal. The final authenticated version (including additional experimental\n  results, analysis, etc.) is available online at:\n  https://doi.org/10.1007/s10791-018-9343-0", "journal-ref": "Information Retrieval Journal 2018", "doi": "10.1007/s10791-018-9343-0", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many questions cannot be answered simply; their answers must include numerous\nnuanced details and additional context. Complex Answer Retrieval (CAR) is the\nretrieval of answers to such questions. In their simplest form, these questions\nare constructed from a topic entity (e.g., `cheese') and a facet (e.g., `health\neffects'). While topic matching has been thoroughly explored, we observe that\nsome facets use general language that is unlikely to appear verbatim in\nanswers. We call these low-utility facets. In this work, we present an approach\nto CAR that identifies and addresses low-utility facets. We propose two\nestimators of facet utility. These include exploiting the hierarchical\nstructure of CAR queries and using facet frequency information from training\ndata. To improve the retrieval performance on low-utility headings, we also\ninclude entity similarity scores using knowledge graph embeddings. We apply our\napproaches to a leading neural ranking technique, and evaluate using the TREC\nCAR dataset. We find that our approach perform significantly better than the\nunmodified neural ranker and other leading CAR techniques. We also provide a\ndetailed analysis of our results, and verify that low-utility facets are indeed\nmore difficult to match, and that our approach improves the performance for\nthese difficult queries.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 15:09:00 GMT"}], "update_date": "2018-11-22", "authors_parsed": [["MacAvaney", "Sean", ""], ["Yates", "Andrew", ""], ["Cohan", "Arman", ""], ["Soldaini", "Luca", ""], ["Hui", "Kai", ""], ["Goharian", "Nazli", ""], ["Frieder", "Ophir", ""]]}, {"id": "1811.08853", "submitter": "Ya-Hui An", "authors": "Ya-Hui An, Liangming Pan, Min-Yen Kan, Qiang Dong, Yan Fu", "title": "Resource Mention Extraction for MOOC Discussion Forums", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In discussions hosted on discussion forums for MOOCs, references to online\nlearning resources are often of central importance. They contextualize the\ndiscussion, anchoring the discussion participants' presentation of the issues\nand their understanding. However they are usually mentioned in free text,\nwithout appropriate hyperlinking to their associated resource. Automated\nlearning resource mention hyperlinking and categorization will facilitate\ndiscussion and searching within MOOC forums, and also benefit the\ncontextualization of such resources across disparate views. We propose the\nnovel problem of learning resource mention identification in MOOC forums. As\nthis is a novel task with no publicly available data, we first contribute a\nlarge-scale labeled dataset, dubbed the Forum Resource Mention (FoRM) dataset,\nto facilitate our current research and future research on this task. We then\nformulate this task as a sequence tagging problem and investigate solution\narchitectures to address the problem. Importantly, we identify two major\nchallenges that hinder the application of sequence tagging models to the task:\n(1) the diversity of resource mention expression, and (2) long-range contextual\ndependencies. We address these challenges by incorporating character-level and\nthread context information into a LSTM-CRF model. First, we incorporate a\ncharacter encoder to address the out-of-vocabulary problem caused by the\ndiversity of mention expressions. Second, to address the context dependency\nchallenge, we encode thread contexts using an RNN-based context encoder, and\napply the attention mechanism to selectively leverage useful context\ninformation during sequence tagging. Experiments on FoRM show that the proposed\nmethod improves the baseline deep sequence tagging models notably,\nsignificantly bettering performance on instances that exemplify the two\nchallenges.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 17:59:56 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["An", "Ya-Hui", ""], ["Pan", "Liangming", ""], ["Kan", "Min-Yen", ""], ["Dong", "Qiang", ""], ["Fu", "Yan", ""]]}, {"id": "1811.09216", "submitter": "Meer Suri", "authors": "M. Suri and S. Rini", "title": "The Statistical Dictionary-based String Matching Problem", "comments": "8 pages, 2 figures, submitted to IEEE ICASSP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the Dictionary-based String Matching (DSM) problem, a retrieval system has\naccess to a source sequence and stores the position of a certain number of\nstrings in a posting table. When a user inquires the position of a string, the\nretrieval system, instead of searching in the source sequence directly, relies\non the the posting table to answer the query more efficiently. In this paper,\nthe Statistical DSM problem is a proposed as a statistical and\ninformation-theoretic formulation of the classic DSM problem in which both the\nsource and the query have a statistical description while the strings stored in\nthe posting sequence are described as a code. Through this formulation, we are\nable to define the efficiency of the retrieval system as the average cost in\nanswering a users' query in the limit of sufficiently long source sequence.\nThis formulation is used to study the retrieval performance for the case in\nwhich (i) all the strings of a given length, referred to as k-grams , and (ii)\nprefix-free codes.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 15:44:30 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Suri", "M.", ""], ["Rini", "S.", ""]]}, {"id": "1811.09292", "submitter": "Jan Trienes", "authors": "Jan Trienes, Andr\\'es Torres Cano, Djoerd Hiemstra", "title": "Recommending Users: Whom to Follow on Federated Social Networks", "comments": "4 pages, 1 figure", "journal-ref": "In Proceedings of the 17th Dutch-Belgian Information Retrieval\n  Workshop (DIR2018). Nov. 2018, Leiden, The Netherlands, 13-16", "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To foster an active and engaged community, social networks employ\nrecommendation algorithms that filter large amounts of contents and provide a\nuser with personalized views of the network. Popular social networks such as\nFacebook and Twitter generate follow recommendations by listing profiles a user\nmay be interested to connect with. Federated social networks aim to resolve\nissues associated with the popular social networks - such as large-scale\nuser-surveillance and the miss-use of user data to manipulate elections - by\ndecentralizing authority and promoting privacy. Due to their recent emergence,\nrecommender systems do not exist for federated social networks, yet. To make\nthese networks more attractive and promote community building, we investigate\nhow recommendation algorithms can be applied to decentralized social networks.\nWe present an offline and online evaluation of two recommendation strategies: a\ncollaborative filtering recommender based on BM25 and a topology-based\nrecommender using personalized PageRank. Our experiments on a large unbiased\nsample of the federated social network Mastodon shows that collaborative\nfiltering approaches outperform a topology-based approach, whereas both\napproaches significantly outperform a random recommender. A subsequent live\nuser experiment on Mastodon using balanced interleaving shows that the\ncollaborative filtering recommender performs on par with the topology-based\nrecommender.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2018 19:29:22 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Trienes", "Jan", ""], ["Cano", "Andr\u00e9s Torres", ""], ["Hiemstra", "Djoerd", ""]]}, {"id": "1811.09368", "submitter": "Riddhiman Dasgupta", "authors": "Riddhiman Dasgupta, Balaji Ganesan, Aswin Kannan, Berthold Reinwald,\n  Arun Kumar", "title": "Fine Grained Classification of Personal Data Entities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity Type Classification can be defined as the task of assigning category\nlabels to entity mentions in documents. While neural networks have recently\nimproved the classification of general entity mentions, pattern matching and\nother systems continue to be used for classifying personal data entities (e.g.\nclassifying an organization as a media company or a government institution for\nGDPR, and HIPAA compliance). We propose a neural model to expand the class of\npersonal data entities that can be classified at a fine grained level, using\nthe output of existing pattern matching systems as additional contextual\nfeatures. We introduce new resources, a personal data entities hierarchy with\n134 types, and two datasets from the Wikipedia pages of elected representatives\nand Enron emails. We hope these resource will aid research in the area of\npersonal data discovery, and to that effect, we provide baseline results on\nthese datasets, and compare our method with state of the art models on\nOntoNotes dataset.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2018 06:28:41 GMT"}], "update_date": "2018-11-26", "authors_parsed": [["Dasgupta", "Riddhiman", ""], ["Ganesan", "Balaji", ""], ["Kannan", "Aswin", ""], ["Reinwald", "Berthold", ""], ["Kumar", "Arun", ""]]}, {"id": "1811.09786", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui", "title": "Recurrently Controlled Recurrent Networks", "comments": "NIPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recurrent neural networks (RNNs) such as long short-term memory and gated\nrecurrent units are pivotal building blocks across a broad spectrum of sequence\nmodeling problems. This paper proposes a recurrently controlled recurrent\nnetwork (RCRN) for expressive and powerful sequence encoding. More concretely,\nthe key idea behind our approach is to learn the recurrent gating functions\nusing recurrent networks. Our architecture is split into two components - a\ncontroller cell and a listener cell whereby the recurrent controller actively\ninfluences the compositionality of the listener cell. We conduct extensive\nexperiments on a myriad of tasks in the NLP domain such as sentiment analysis\n(SST, IMDb, Amazon reviews, etc.), question classification (TREC), entailment\nclassification (SNLI, SciTail), answer selection (WikiQA, TrecQA) and reading\ncomprehension (NarrativeQA). Across all 26 datasets, our results demonstrate\nthat RCRN not only consistently outperforms BiLSTMs but also stacked BiLSTMs,\nsuggesting that our controller architecture might be a suitable replacement for\nthe widely adopted stacked architecture.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 08:15:50 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1811.09835", "submitter": "Simone Santini", "authors": "Alexandra Dumitrescu and Simone Santini", "title": "Novelty and Coverage in context-based information filtering", "comments": "26 pages, 16 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a collection of algorithms to filter a stream of documents in such\na way that the filtered documents will cover as well as possible the interest\nof a person, keeping in mind that, at any given time, the offered documents\nshould not only be relevant, but should also be diversified, in the sense not\nonly of avoiding nearly identical documents, but also of covering as well as\npossible all the interests of the person. We use a modification of the WEBSOM\nalgorithm, with limited architectural adaptation, to create a user model (which\nwe call the \"user context\" or simply the \"context\") based on a network of units\nlaid out in the word space and trained using a collection of documents\nrepresentative of the context.\n  We introduce the concepts of novelty and coverage. Novelty is related to, but\nnot identical to, the homonymous information retrieval concept: a document is\nnovel it it belongs to a semantic area of interest to a person for which no\ndocuments have been seen in the recent past. A group of documents has coverage\nto the extent to which it is a good representation of all the interests of a\nperson.\n  In order to increase coverage, we introduce an \"interest\" (or \"urgency\")\nfactor for each unit of the user model, modulated by the scores of the incoming\ndocuments: the interest of a unit is decreased drastically when a document\narrives that belongs to its semantic area and slowly recovers its initial value\nif no documents from that semantic area are displayed.\n  Our tests show that these algorithms can effectively increase the coverage of\nthe documents that are shown to the user without overly affecting precision.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 13:46:11 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Dumitrescu", "Alexandra", ""], ["Santini", "Simone", ""]]}, {"id": "1811.09975", "submitter": "Giuseppe Manco", "authors": "Noveen Sachdeva, Giuseppe Manco, Ettore Ritacco, Vikram Pudi", "title": "Sequential Variational Autoencoders for Collaborative Filtering", "comments": "9 pages, 6 figures, 2 tables, WSDM2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variational autoencoders were proven successful in domains such as computer\nvision and speech processing. Their adoption for modeling user preferences is\nstill unexplored, although recently it is starting to gain attention in the\ncurrent literature. In this work, we propose a model which extends variational\nautoencoders by exploiting the rich information present in the past preference\nhistory. We introduce a recurrent version of the VAE, where instead of passing\na subset of the whole history regardless of temporal dependencies, we rather\npass the consumption sequence subset through a recurrent neural network. At\neach time-step of the RNN, the sequence is fed through a series of\nfully-connected layers, the output of which models the probability distribution\nof the most likely future preferences. We show that handling temporal\ninformation is crucial for improving the accuracy of the VAE: In fact, our\nmodel beats the current state-of-the-art by valuable margins because of its\nability to capture temporal dependencies among the user-consumption sequence\nusing the recurrent encoder still keeping the fundamentals of variational\nautoencoders intact.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 09:19:18 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Sachdeva", "Noveen", ""], ["Manco", "Giuseppe", ""], ["Ritacco", "Ettore", ""], ["Pudi", "Vikram", ""]]}, {"id": "1811.10155", "submitter": "Yangyang Guo", "authors": "Yangyang Guo, Zhiyong Cheng, Liqiang Nie, Yinglong Wang, Jun Ma, Mohan\n  Kankanhalli", "title": "Attentive Long Short-Term Preference Modeling for Personalized Product\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  E-commerce users may expect different products even for the same query, due\nto their diverse personal preferences. It is well-known that there are two\ntypes of preferences: long-term ones and short-term ones. The former refers to\nuser' inherent purchasing bias and evolves slowly. By contrast, the latter\nreflects users' purchasing inclination in a relatively short period. They both\naffect users' current purchasing intentions. However, few research efforts have\nbeen dedicated to jointly model them for the personalized product search. To\nthis end, we propose a novel Attentive Long Short-Term Preference model, dubbed\nas ALSTP, for personalized product search. Our model adopts the neural networks\napproach to learn and integrate the long- and short-term user preferences with\nthe current query for the personalized product search. In particular, two\nattention networks are designed to distinguish which factors in the short-term\nas well as long-term user preferences are more relevant to the current query.\nThis unique design enables our model to capture users' current search\nintentions more accurately. Our work is the first to apply attention mechanisms\nto integrate both long- and short-term user preferences with the given query\nfor the personalized search. Extensive experiments over four Amazon product\ndatasets show that our model significantly outperforms several state-of-the-art\nproduct search methods in terms of different evaluation metrics.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 03:04:38 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Guo", "Yangyang", ""], ["Cheng", "Zhiyong", ""], ["Nie", "Liqiang", ""], ["Wang", "Yinglong", ""], ["Ma", "Jun", ""], ["Kankanhalli", "Mohan", ""]]}, {"id": "1811.10364", "submitter": "Joeran Beel", "authors": "Joeran Beel, Andrew Collins, Akiko Aizawa", "title": "The Architecture of Mr. DLib's Scientific Recommender-System API", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems in academia are not widely available. This may be in part\ndue to the difficulty and cost of developing and maintaining recommender\nsystems. Many operators of academic products such as digital libraries and\nreference managers avoid this effort, although a recommender system could\nprovide significant benefits to their users. In this paper, we introduce Mr.\nDLib's \"Recommendations as-a-Service\" (RaaS) API that allows operators of\nacademic products to easily integrate a scientific recommender system into\ntheir products. Mr. DLib generates recommendations for research articles but in\nthe future, recommendations may include call for papers, grants, etc. Operators\nof academic products can request recommendations from Mr. DLib and display\nthese recommendations to their users. Mr. DLib can be integrated in just a few\nhours or days; creating an equivalent recommender system from scratch would\nrequire several months for an academic operator. Mr. DLib has been used by\nGESIS Sowiport and by the reference manager JabRef. Mr. DLib is open source and\nits goal is to facilitate the application of, and research on, scientific\nrecommender systems. In this paper, we present the motivation for Mr. DLib, the\narchitecture and details about the effectiveness. Mr. DLib has delivered 94m\nrecommendations over a span of two years with an average click-through rate of\n0.12%.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 13:41:03 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Beel", "Joeran", ""], ["Collins", "Andrew", ""], ["Aizawa", "Akiko", ""]]}, {"id": "1811.10369", "submitter": "Joeran Beel", "authors": "Dominika Tkaczyk, Rohit Gupta, Riccardo Cinti, Joeran Beel", "title": "ParsRec: A Novel Meta-Learning Approach to Recommending Bibliographic\n  Reference Parsers", "comments": "Accepted at the 26th Irish Conference on Artificial Intelligence and\n  Cognitive Science. This paper is an extended version of a poster published at\n  the 12th ACM Conference on Recommender Systems, Proceedings of the 26th Irish\n  Conference on Artificial Intelligence and Cognitive Science (AICS). Dublin,\n  Ireland 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bibliographic reference parsers extract machine-readable metadata such as\nauthor names, title, journal, and year from bibliographic reference strings. To\nextract the metadata, the parsers apply heuristics or machine learning.\nHowever, no reference parser, and no algorithm, consistently gives the best\nresults in every scenario. For instance, one tool may be best in extracting\ntitles in ACM citation style, but only third best when APA is used. Another\ntool may be best in extracting English author names, while another one is best\nfor noisy data (i.e. inconsistent citation styles). In this paper, which is an\nextended version of our recent RecSys poster, we address the problem of\nreference parsing from a recommender-systems and meta-learning perspective. We\npropose ParsRec, a meta-learning based recommender-system that recommends the\npotentially most effective parser for a given reference string. ParsRec\nrecommends one out of 10 open-source parsers: Anystyle-Parser, Biblio, CERMINE,\nCitation, Citation-Parser, GROBID, ParsCit, PDFSSA4MET, Reference Tagger, and\nScience Parse. We evaluate ParsRec on 105k references from chemistry. We\npropose two approaches to meta-learning recommendations. The first approach\nlearns the best parser for an entire reference string. The second approach\nlearns the best parser for each metadata type in a reference string. The second\napproach achieved a 2.6% increase in F1 (0.909 vs. 0.886) over the best single\nparser (GROBID), reducing the false positive rate by 20.2% (0.075 vs. 0.094),\nand the false negative rate by 18.9% (0.107 vs. 0.132).\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 13:56:57 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Tkaczyk", "Dominika", ""], ["Gupta", "Rohit", ""], ["Cinti", "Riccardo", ""], ["Beel", "Joeran", ""]]}, {"id": "1811.10547", "submitter": "Sammy Khalife", "authors": "Sammy Khalife, Michalis Vazirgiannis", "title": "Scalable graph-based individual named entity identification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entity discovery (NED) is an important information retrieval problem\nthat can be decomposed into two sub-problems. The first sub-problem, named\nentity recognition (NER), aims to tag pre-defined sets of words in a vocabulary\n(called \"named entities\": names, places, locations, ...) when they appear in\nnatural language. The second subproblem, named entity linking/identification\n(NEL), considers these entity mentions as queries to be identified in a\npre-existing database. In this paper, we consider the NEL problem, and assume a\nset of queries (or mentions) that have to be identified within a knowledge\nbase. This knowledge base is represented by a text database paired with a\nsemantic graph. We present state-of-the-art methods in NEL, and propose a\n2-step method for individual identification of named entities. Our approach is\nwell-motivated by the limitations brought by recent deep learning approaches\nthat lack interpratability, and require lots of parameter tuning along with\nlarge volume of annotated data.\n  First of all, we propose a filtering algorithm designed with information\nretrieval and text mining techniques, aiming to maximize precision at K\n(typically for 5 <= K <=20). Then, we introduce two graph-based methods for\nnamed entity identification to maximize precision at 1 by re-ranking the\nremaining top entity candidates. The first identification method is using\nparametrized graph mining, and the second similarity with graph kernels. Our\napproach capitalizes on a fine-grained classification of entities from\nannotated web data. We present our algorithms in details, and show\nexperimentally on standard datasets (NIST TAC-KBP, CONLL/AIDA) their\nperformance in terms of precision are better than any graph-based method\nreported, and competitive with state-of-the-art systems. Finally, we conclude\non the advantages of our graph-based approach compared to recent deep learning\nmethods.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 17:50:40 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Khalife", "Sammy", ""], ["Vazirgiannis", "Michalis", ""]]}, {"id": "1811.10686", "submitter": "Mengting Wan", "authors": "Mengting Wan, Xin Chen", "title": "Beyond \"How may I help you?\": Assisting Customer Service Agents with\n  Proactive Responses", "comments": "7 pages, DEEP-DIAL 2019 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of providing recommended responses to customer service\nagents in live-chat dialogue systems. Smart-reply systems have been widely\napplied in real-world applications (e.g. Gmail, LinkedIn Messaging), where most\nof them can successfully recommend reactive responses. However, we observe a\nmajor limitation of current methods is that they generally have difficulties in\nsuggesting proactive investigation act (e.g. \"Do you perhaps have another\naccount with us?\") due to the lack of long-term context information, which\nindeed act as critical steps for customer service agents to collect information\nand resolve customers' issues. Thus in this work, we propose an end-to-end\nmethod with special focus on suggesting proactive investigative questions to\ncustomer agents in Airbnb's customer service live-chat system. Effectiveness of\nour proposed method can be validated through qualitative and quantitative\nresults.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 20:56:38 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Wan", "Mengting", ""], ["Chen", "Xin", ""]]}, {"id": "1811.10786", "submitter": "Zengjian Chen", "authors": "Zengjian Chen, Jiayi Liu, Yihe Deng, Kun He and John E. Hopcroft", "title": "Adaptive Wavelet Clustering for Highly Noisy Data", "comments": "11 pages,13 figures,ICDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we make progress on the unsupervised task of mining arbitrarily\nshaped clusters in highly noisy datasets, which is a task present in many\nreal-world applications. Based on the fundamental work that first applies a\nwavelet transform to data clustering, we propose an adaptive clustering\nalgorithm, denoted as AdaWave, which exhibits favorable characteristics for\nclustering. By a self-adaptive thresholding technique, AdaWave is parameter\nfree and can handle data in various situations. It is deterministic, fast in\nlinear time, order-insensitive, shape-insensitive, robust to highly noisy data,\nand requires no pre-knowledge on data models. Moreover, AdaWave inherits the\nability from the wavelet transform to cluster data in different resolutions. We\nadopt the \"grid labeling\" data structure to drastically reduce the memory\nconsumption of the wavelet transform so that AdaWave can be used for relatively\nhigh dimensional data. Experiments on synthetic as well as natural datasets\ndemonstrate the effectiveness and efficiency of our proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 03:05:26 GMT"}, {"version": "v2", "created": "Mon, 7 Jan 2019 06:22:23 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Chen", "Zengjian", ""], ["Liu", "Jiayi", ""], ["Deng", "Yihe", ""], ["He", "Kun", ""], ["Hopcroft", "John E.", ""]]}, {"id": "1811.10804", "submitter": "Shirsendu Halder", "authors": "Sudhanshu Kumar, Shirsendu Sukanta Halder, Kanjar De and Partha Pratim\n  Roy", "title": "Movie Recommendation System using Sentiment Analysis from Microblogging\n  Data", "comments": "19 pages, 7 tables, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems are important intelligent systems that play a vital\nrole in providing selective information to users. Traditional approaches in\nrecommendation systems include collaborative filtering and content-based\nfiltering. However, these approaches have certain limitations like the\nnecessity of prior user history and habits for performing the task of\nrecommendation. In order to reduce the effect of such dependencies, this paper\nproposes a hybrid recommendation system which combines the collaborative\nfiltering, content-based filtering with sentiment analysis of movie tweets. The\nmovie tweets have been collected from microblogging websites to understand the\ncurrent trends and user response of the movie. Experiments conducted on public\ndatabase produce promising results.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 04:42:06 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Kumar", "Sudhanshu", ""], ["Halder", "Shirsendu Sukanta", ""], ["De", "Kanjar", ""], ["Roy", "Partha Pratim", ""]]}, {"id": "1811.10810", "submitter": "Xiaoshuang Shi", "authors": "Xiaoshuang Shi, Fuyong Xing, Zizhao Zhang, Manish Sapkota, Zhenhua Guo\n  and Lin Yang", "title": "A Scalable Optimization Mechanism for Pairwise based Discrete Hashing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maintaining the pair similarity relationship among originally\nhigh-dimensional data into a low-dimensional binary space is a popular strategy\nto learn binary codes. One simiple and intutive method is to utilize two\nidentical code matrices produced by hash functions to approximate a pairwise\nreal label matrix. However, the resulting quartic problem is difficult to\ndirectly solve due to the non-convex and non-smooth nature of the objective. In\nthis paper, unlike previous optimization methods using various relaxation\nstrategies, we aim to directly solve the original quartic problem using a novel\nalternative optimization mechanism to linearize the quartic problem by\nintroducing a linear regression model. Additionally, we find that gradually\nlearning each batch of binary codes in a sequential mode, i.e. batch by batch,\nis greatly beneficial to the convergence of binary code learning. Based on this\nsignificant discovery and the proposed strategy, we introduce a scalable\nsymmetric discrete hashing algorithm that gradually and smoothly updates each\nbatch of binary codes. To further improve the smoothness, we also propose a\ngreedy symmetric discrete hashing algorithm to update each bit of batch binary\ncodes. Moreover, we extend the proposed optimization mechanism to solve the\nnon-convex optimization problems for binary code learning in many other\npairwise based hashing algorithms. Extensive experiments on benchmark\nsingle-label and multi-label databases demonstrate the superior performance of\nthe proposed mechanism over recent state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 04:50:30 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Shi", "Xiaoshuang", ""], ["Xing", "Fuyong", ""], ["Zhang", "Zizhao", ""], ["Sapkota", "Manish", ""], ["Guo", "Zhenhua", ""], ["Yang", "Lin", ""]]}, {"id": "1811.10812", "submitter": "Suwon Shon", "authors": "Suwon Shon, Younggun Lee, Taesu Kim", "title": "Large-scale Speaker Retrieval on Random Speaker Variability Subspace", "comments": "Interspeech 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.AS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a fast speaker search system to retrieve segments of the\nsame voice identity in the large-scale data. A recent study shows that Locality\nSensitive Hashing (LSH) enables quick retrieval of a relevant voice in the\nlarge-scale data in conjunction with i-vector while maintaining accuracy. In\nthis paper, we proposed Random Speaker-variability Subspace (RSS) projection to\nmap a data into LSH based hash tables. We hypothesized that rather than\nprojecting on completely random subspace without considering data, projecting\non randomly generated speaker variability space would give more chance to put\nthe same speaker representation into the same hash bins, so we can use less\nnumber of hash tables. Multiple RSS can be generated by randomly selecting a\nsubset of speakers from a large speaker cohort. From the experimental result,\nthe proposed approach shows 100 times and 7 times faster than the linear search\nand LSH, respectively\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 04:52:14 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 01:57:18 GMT"}], "update_date": "2019-06-19", "authors_parsed": [["Shon", "Suwon", ""], ["Lee", "Younggun", ""], ["Kim", "Taesu", ""]]}, {"id": "1811.10831", "submitter": "Swagata Duari", "authors": "Swagata Duari and Vasudha Bhatnagar", "title": "sCAKE: Semantic Connectivity Aware Keyword Extraction", "comments": "40 pages, 7 figures, 13 tables, submitted to Journal of Information\n  Sciences", "journal-ref": "Information Sciences 477C (2019) pp. 100-117", "doi": "10.1016/j.ins.2018.10.034", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword Extraction is an important task in several text analysis endeavors.\nIn this paper, we present a critical discussion of the issues and challenges\ningraph-based keyword extraction methods, along with comprehensive empirical\nanalysis. We propose a parameterless method for constructing graph of text that\ncaptures the contextual relation between words. A novel word scoring method is\nalso proposed based on the connection between concepts. We demonstrate that\nboth proposals are individually superior to those followed by the\nstate-of-the-art graph-based keyword extraction algorithms. Combination of the\nproposed graph construction and scoring methods leads to a novel, parameterless\nkeyword extraction method (sCAKE) based on semantic connectivity of words in\nthe document.\n  Motivated by limited availability of NLP tools for several languages, we also\ndesign and present a language-agnostic keyword extraction (LAKE) method. We\neliminate the need of NLP tools by using a statistical filter to identify\ncandidate keywords before constructing the graph. We show that the resulting\nmethod is a competent solution for extracting keywords from documents\noflanguages lacking sophisticated NLP support.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 06:22:33 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Duari", "Swagata", ""], ["Bhatnagar", "Vasudha", ""]]}, {"id": "1811.10907", "submitter": "Fan Yang", "authors": "Fan Yang, Ryota Hinami, Yusuke Matsui, Steven Ly, Shin'ichi Satoh", "title": "Efficient Image Retrieval via Decoupling Diffusion into Online and\n  Offline Processing", "comments": "Accepted by AAAI 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Diffusion is commonly used as a ranking or re-ranking method in retrieval\ntasks to achieve higher retrieval performance, and has attracted lots of\nattention in recent years. A downside to diffusion is that it performs slowly\nin comparison to the naive k-NN search, which causes a non-trivial online\ncomputational cost on large datasets. To overcome this weakness, we propose a\nnovel diffusion technique in this paper. In our work, instead of applying\ndiffusion to the query, we pre-compute the diffusion results of each element in\nthe database, making the online search a simple linear combination on top of\nthe k-NN search process. Our proposed method becomes 10~ times faster in terms\nof online search speed. Moreover, we propose to use late truncation instead of\nearly truncation in previous works to achieve better retrieval performance.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 10:52:26 GMT"}, {"version": "v2", "created": "Fri, 4 Jan 2019 11:12:31 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Yang", "Fan", ""], ["Hinami", "Ryota", ""], ["Matsui", "Yusuke", ""], ["Ly", "Steven", ""], ["Satoh", "Shin'ichi", ""]]}, {"id": "1811.10986", "submitter": "Somayeh Asadifar", "authors": "Somayeh Asadifar, Mohsen Kahani and Saeedeh Shekarpour", "title": "HCqa: Hybrid and Complex Question Answering on Textual Corpus and\n  Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Question Answering (QA) systems provide easy access to the vast amount of\nknowledge without having to know the underlying complex structure of the\nknowledge. The research community has provided ad hoc solutions to the key QA\ntasks, including named entity recognition and disambiguation, relation\nextraction and query building. Furthermore, some have integrated and composed\nthese components to implement many tasks automatically and efficiently.\nHowever, in general, the existing solutions are limited to simple and short\nquestions and still do not address complex questions composed of several\nsub-questions. Exploiting the answer to complex questions is further challenged\nif it requires integrating knowledge from unstructured data sources, i.e.,\ntextual corpus, as well as structured data sources, i.e., knowledge graphs. In\nthis paper, an approach (HCqa) is introduced for dealing with complex questions\nrequiring federating knowledge from a hybrid of heterogeneous data sources\n(structured and unstructured). We contribute in developing (i) a decomposition\nmechanism which extracts sub-questions from potentially long and complex input\nquestions, (ii) a novel comprehensive schema, first of its kind, for extracting\nand annotating relations, and (iii) an approach for executing and aggregating\nthe answers of sub-questions. The evaluation of HCqa showed a superior accuracy\nin the fundamental tasks, such as relation extraction, as well as the\nfederation task.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 07:03:53 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 08:19:45 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 09:42:23 GMT"}, {"version": "v4", "created": "Thu, 31 Jan 2019 06:39:48 GMT"}, {"version": "v5", "created": "Sun, 9 Jun 2019 04:56:51 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Asadifar", "Somayeh", ""], ["Kahani", "Mohsen", ""], ["Shekarpour", "Saeedeh", ""]]}, {"id": "1811.10988", "submitter": "Xavier Favory", "authors": "Xavier Favory, Eduardo Fonseca, Frederic Font, Xavier Serra", "title": "Facilitating the Manual Annotation of Sounds When Using Large Taxonomies", "comments": "5 pages, 5 figures, IEEE FRUCT International Workshop on Semantic\n  Audio and the Internet of Things", "journal-ref": "Proceedings of the 23rd Conference of Open Innovations Association\n  FRUCT, Bologna, Italy. 2018. ISSN 2305-7254, ISBN 978-952-68653-6-2, FRUCT\n  Oy, e-ISSN 2343-0737 (license CC BY-ND)", "doi": null, "report-no": null, "categories": "cs.IR cs.HC cs.LG cs.SD eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Properly annotated multimedia content is crucial for supporting advances in\nmany Information Retrieval applications. It enables, for instance, the\ndevelopment of automatic tools for the annotation of large and diverse\nmultimedia collections. In the context of everyday sounds and online\ncollections, the content to describe is very diverse and involves many\ndifferent types of concepts, often organised in large hierarchical structures\ncalled taxonomies. This makes the task of manually annotating content arduous.\nIn this paper, we present our user-centered development of two tools for the\nmanual annotation of audio content from a wide range of types. We conducted a\npreliminary evaluation of functional prototypes involving real users. The goal\nis to evaluate them in a real context, engage in discussions with users, and\ninspire new ideas. A qualitative analysis was carried out including usability\nquestionnaires and semi-structured interviews. This revealed interesting\naspects to consider when developing tools for the manual annotation of audio\ncontent with labels drawn from large hierarchical taxonomies.\n", "versions": [{"version": "v1", "created": "Wed, 21 Nov 2018 16:43:11 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Favory", "Xavier", ""], ["Fonseca", "Eduardo", ""], ["Font", "Frederic", ""], ["Serra", "Xavier", ""]]}, {"id": "1811.11008", "submitter": "Srikumar Krishnamoorthy", "authors": "Srikumar Krishnamoorthy", "title": "Sentiment Analysis of Financial News Articles using Performance\n  Indicators", "comments": "Knowledge and Information Systems Nov 2017", "journal-ref": null, "doi": "10.1007/s10115-017-1134-1", "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining financial text documents and understanding the sentiments of\nindividual investors, institutions and markets is an important and challenging\nproblem in the literature. Current approaches to mine sentiments from financial\ntexts largely rely on domain specific dictionaries. However, dictionary based\nmethods often fail to accurately predict the polarity of financial texts. This\npaper aims to improve the state-of-the-art and introduces a novel sentiment\nanalysis approach that employs the concept of financial and non-financial\nperformance indicators. It presents an association rule mining based\nhierarchical sentiment classifier model to predict the polarity of financial\ntexts as positive, neutral or negative. The performance of the proposed model\nis evaluated on a benchmark financial dataset. The model is also compared\nagainst other state-of-the-art dictionary and machine learning based approaches\nand the results are found to be quite promising. The novel use of performance\nindicators for financial sentiment analysis offers interesting and useful\ninsights.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2018 01:36:12 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Krishnamoorthy", "Srikumar", ""]]}, {"id": "1811.11017", "submitter": "Mohan Zhang", "authors": "Mohan Zhang, Zhichao Luo, Hai Lu", "title": "Latent Dirichlet Allocation with Residual Convolutional Neural Network\n  Applied in Evaluating Credibility of Chinese Listed Companies", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This project demonstrated a methodology to estimating cooperate credibility\nwith a Natural Language Processing approach. As cooperate transparency impacts\nboth the credibility and possible future earnings of the firm, it is an\nimportant factor to be considered by banks and investors on risk assessments of\nlisted firms. This approach of estimating cooperate credibility can bypass\nhuman bias and inconsistency in the risk assessment, the use of large\nquantitative data and neural network models provides more accurate estimation\nin a more efficient manner compare to manual assessment. At the beginning, the\nmodel will employs Latent Dirichlet Allocation and THU Open Chinese Lexicon\nfrom Tsinghua University to classify topics in articles which are potentially\nrelated to corporate credibility. Then with the keywords related to each\ntopics, we trained a residual convolutional neural network with data labeled\naccording to surveys of fund manager and accountant's opinion on corporate\ncredibility. After the training, we run the model with preprocessed news\nreports regarding to all of the 3065 listed companies, the model is supposed to\ngive back companies ranking based on the level of their transparency.\n", "versions": [{"version": "v1", "created": "Sat, 24 Nov 2018 17:50:41 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Zhang", "Mohan", ""], ["Luo", "Zhichao", ""], ["Lu", "Hai", ""]]}, {"id": "1811.11133", "submitter": "Stefano Marchesin", "authors": "Stefano Marchesin", "title": "A Concept-Centered Hypertext Approach to Case-Based Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of case-based retrieval is to assist physicians in the clinical\ndecision making process, by finding relevant medical literature in large\narchives. We propose a research that aims at improving the effectiveness of\ncase-based retrieval systems through the use of automatically created\ndocument-level semantic networks. The proposed research tackles different\naspects of information systems and leverages the recent advancements in\ninformation extraction and relational learning to revisit and advance the core\nideas of concept-centered hypertext models. We propose a two-step methodology\nthat in the first step addresses the automatic creation of document-level\nsemantic networks, then in the second step it designs methods that exploit such\ndocument representations to retrieve relevant cases from medical literature.\nFor the automatic creation of documents' semantic networks, we design a\ncombination of information extraction techniques and relational learning\nmodels. Mining concepts and relations from text, information extraction\ntechniques represent the core of the document-level semantic networks' building\nprocess. On the other hand, relational learning models have the task of\nenriching the graph with additional connections that have not been detected by\ninformation extraction algorithms and strengthening the confidence score of\nextracted relations. For the retrieval of relevant medical literature, we\ninvestigate methods that are capable of comparing the documents' semantic\nnetworks in terms of structure and semantics. The automatic extraction of\nsemantic relations from documents, and their centrality in the creation of the\ndocuments' semantic networks, represent our attempt to go one step further than\nprevious graph-based approaches.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 17:48:05 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Marchesin", "Stefano", ""]]}, {"id": "1811.11422", "submitter": "Dimitris Gkoumas", "authors": "Dimitris Gkoumas, Dawei Sogn", "title": "Exploiting \"Quantum-like Interference\" in Decision Fusion for Ranking\n  Multimodal Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fusing and ranking multimodal information remains always a challenging task.\nA robust decision-level fusion method should not only be dynamically adaptive\nfor assigning weights to each representation but also incorporate\ninter-relationships among different modalities. In this paper, we propose a\nquantum-inspired model for fusing and ranking visual and textual information\naccounting for the dependency between the aforementioned modalities. At first,\nwe calculate the text-based and image-based similarity individually. Two\ndifferent approaches have been applied for computing each unimodal similarity.\nThe first one makes use of the bag-of-words model. For the second one, a\npre-trained VGG19 model on ImageNet has been used for calculating the image\nsimilarity, while a query expansion approach has been applied to the text-based\nquery for improving the retrieval performance. Afterward, the local similarity\nscores fit the proposed quantum-inspired model. The inter-dependency between\nthe two modalities is captured implicitly through \"quantum interference\".\nFinally, the documents are ranked based on the proposed similarity measurement.\nWe test our approach on ImageCLEF2007photo data collection and show the\neffectiveness of the proposed approach. A series of interesting findings are\ndiscussed, which would provide theoretical and empirical foundations for future\ndevelopment of this direction.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 07:46:38 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Gkoumas", "Dimitris", ""], ["Sogn", "Dawei", ""]]}, {"id": "1811.11426", "submitter": "Maciej Zamorski", "authors": "Maciej Zamorski and Maciej Zi\\k{e}ba", "title": "Semi-supervised learning with Bidirectional GANs", "comments": "12 pages, 3 figures", "journal-ref": "Intelligent Information and Database Systems. ACIIDS 2019. Lecture\n  Notes in Computer Science, vol 11431 (2019) 649-660", "doi": "10.1007/978-3-030-14799-0_56", "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce a novel approach to train Bidirectional Generative\nAdversarial Model (BiGAN) in a semi-supervised manner. The presented method\nutilizes triplet loss function as an additional component of the objective\nfunction used to train discriminative data representation in the latent space\nof the BiGAN model. This representation can be further used as a seed for\ngenerating artificial images, but also as a good feature embedding for\nclassification and image retrieval tasks. We evaluate the quality of the\nproposed method in the two mentioned challenging tasks using two benchmark\ndatasets: CIFAR10 and SVHN.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 07:51:21 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Zamorski", "Maciej", ""], ["Zi\u0119ba", "Maciej", ""]]}, {"id": "1811.11523", "submitter": "Zulfat Miftahutdinov", "authors": "Elena Tutubalina, Zulfat Miftahutdinov, Sergey Nikolenko, Valentin\n  Malykh", "title": "Sequence Learning with RNNs for Medical Concept Normalization in\n  User-Generated Texts", "comments": "Machine Learning for Health (ML4H) Workshop at NeurIPS 2018\n  arXiv:1811.07216", "journal-ref": "Journal of Biomedical Informatics. - 2018. - Vol.84, Is.. -\n  P.93-102", "doi": "10.1016/j.jbi.2018.06.006", "report-no": "ML4H/2018/117", "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider the medical concept normalization problem, i.e.,\nthe problem of mapping a disease mention in free-form text to a concept in a\ncontrolled vocabulary, usually to the standard thesaurus in the Unified Medical\nLanguage System (UMLS). This task is challenging since medical terminology is\nvery different when coming from health care professionals or from the general\npublic in the form of social media texts. We approach it as a sequence learning\nproblem, with recurrent neural networks trained to obtain semantic\nrepresentations of one- and multi-word expressions. We develop end-to-end\nneural architectures tailored specifically to medical concept normalization,\nincluding bidirectional LSTM and GRU with an attention mechanism and additional\nsemantic similarity features based on UMLS. Our evaluation over a standard\nbenchmark shows that our model improves over a state of the art baseline for\nclassification based on CNNs.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 12:42:57 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2018 07:49:44 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Tutubalina", "Elena", ""], ["Miftahutdinov", "Zulfat", ""], ["Nikolenko", "Sergey", ""], ["Malykh", "Valentin", ""]]}, {"id": "1811.11569", "submitter": "Teofilo de Campos", "authors": "Fabricio Ataides Braz, Nilton Correia da Silva, Teofilo Emidio de\n  Campos, Felipe Borges S. Chaves, Marcelo H. S. Ferreira, Pedro Henrique\n  Inazawa, Victor H. D. Coelho, Bernardo Pablo Sukiennik, Ana Paula Goncalves\n  Soares de Almeida, Flavio Barros Vidal, Davi Alves Bezerra, Davi B. Gusmao,\n  Gabriel G. Ziegler, Ricardo V. C. Fernandes, Roberta Zumblick, Fabiano\n  Hartmann Peixoto", "title": "Document classification using a Bi-LSTM to unclog Brazil's supreme court", "comments": "This work was presented at NIPS 2018 Workshop on Machine Learning for\n  the Developing World (ML4D)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Brazilian court system is currently the most clogged up judiciary system\nin the world. Thousands of lawsuit cases reach the supreme court every day.\nThese cases need to be analyzed in order to be associated to relevant tags and\nallocated to the right team. Most of the cases reach the court as raster\nscanned documents with widely variable levels of quality. One of the first\nsteps for the analysis is to classify these documents. In this paper we present\na Bidirectional Long Short-Term Memory network (Bi-LSTM) to classify these\npieces of legal document.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2018 11:30:01 GMT"}], "update_date": "2018-11-29", "authors_parsed": [["Braz", "Fabricio Ataides", ""], ["da Silva", "Nilton Correia", ""], ["de Campos", "Teofilo Emidio", ""], ["Chaves", "Felipe Borges S.", ""], ["Ferreira", "Marcelo H. S.", ""], ["Inazawa", "Pedro Henrique", ""], ["Coelho", "Victor H. D.", ""], ["Sukiennik", "Bernardo Pablo", ""], ["de Almeida", "Ana Paula Goncalves Soares", ""], ["Vidal", "Flavio Barros", ""], ["Bezerra", "Davi Alves", ""], ["Gusmao", "Davi B.", ""], ["Ziegler", "Gabriel G.", ""], ["Fernandes", "Ricardo V. C.", ""], ["Zumblick", "Roberta", ""], ["Peixoto", "Fabiano Hartmann", ""]]}, {"id": "1811.11746", "submitter": "Rui Portocarrero Sarmento MSc", "authors": "Rui Portocarrero Sarmento and Pavel Brazdil", "title": "Incremental Sparse TFIDF & Incremental Similarity with Bipartite Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we experimented with several concepts regarding text streams\nanalysis.\n  We tested an implementation of Incremental Sparse TF-IDF (IS-TFIDF) and\nIncremental Cosine Similarity (ICS) with the use of bipartite graphs.\n  We are using bipartite graphs - one type of node are documents, and the other\ntype of nodes are words - to know what documents are affected with a word\narrival at the stream (the neighbors of the word in the graph). Thus, with this\ninformation, we leverage optimized algorithms used for graph-based\napplications. The concept is similar to, for example, the use of hash tables or\nother computer science concepts used for fast access to information in memory.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 15:20:32 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Sarmento", "Rui Portocarrero", ""], ["Brazdil", "Pavel", ""]]}, {"id": "1811.11833", "submitter": "Sebastin Santy", "authors": "Sebastin Santy, Wazeer Zulfikar, Rishabh Mehrotra, Emine Yilmaz", "title": "Towards Task Understanding in Visual Settings", "comments": "Accepted as Student Abstract at 33rd AAAI Conference on Artificial\n  Intelligence, 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of understanding real world tasks depicted in visual\nimages. While most existing image captioning methods excel in producing natural\nlanguage descriptions of visual scenes involving human tasks, there is often\nthe need for an understanding of the exact task being undertaken rather than a\nliteral description of the scene. We leverage insights from real world task\nunderstanding systems, and propose a framework composed of convolutional neural\nnetworks, and an external hierarchical task ontology to produce task\ndescriptions from input images. Detailed experiments highlight the efficacy of\nthe extracted descriptions, which could potentially find their way in many\napplications, including image alt text generation.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 21:06:27 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Santy", "Sebastin", ""], ["Zulfikar", "Wazeer", ""], ["Mehrotra", "Rishabh", ""], ["Yilmaz", "Emine", ""]]}, {"id": "1811.11866", "submitter": "Seyed Mohammad Mahdi Seyednezhad", "authors": "S.M. Mahdi Seyednezhad, Kailey Nobuko Cozart, John Anthony Bowllan,\n  and Anthony O. Smith", "title": "A Review on Recommendation Systems: Context-aware to Social-based", "comments": "44 pages without bibliography, 4 chapters, Slide presentation:\n  https://www.slideshare.net/MahdiSeyednejad/recommender-systems-97094937", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of Internet users had grown rapidly enticing companies and\ncooperations to make full use of recommendation infrastructures. Consequently,\nonline advertisement companies emerged to aid us in the presence of numerous\nitems and users. Even as a user, you may find yourself drowned in a set of\nitems that you think you might need, but you are not sure if you should try\nthem. Those items could be online services, products, places or even a person\nfor a friendship. Therefore, we need recommender systems that pave the way and\nhelp us making good decisions. This paper provides a review on traditional\nrecommendation systems, recommendation system evaluations and metrics,\ncontext-aware recommendation systems, and social-based recommendation systems.\nWhile it is hard to include all the information in a brief review paper, we try\nto have an introductory review over the essentials of recommendation systems.\nMore detailed information on each chapter will be found in the corresponding\nreferences. For the purpose of explaining the concept in a different way, we\nprovided slides available on\nhttps://www.slideshare.net/MahdiSeyednejad/recommender-systems-97094937.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2018 22:36:37 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Seyednezhad", "S. M. Mahdi", ""], ["Cozart", "Kailey Nobuko", ""], ["Bowllan", "John Anthony", ""], ["Smith", "Anthony O.", ""]]}, {"id": "1811.12181", "submitter": "Irene Li", "authors": "Irene Li, Alexander R. Fabbri, Robert R. Tung and Dragomir R. Radev", "title": "What Should I Learn First: Introducing LectureBank for NLP Education and\n  Prerequisite Chain Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have witnessed the rising popularity of Natural Language\nProcessing (NLP) and related fields such as Artificial Intelligence (AI) and\nMachine Learning (ML). Many online courses and resources are available even for\nthose without a strong background in the field. Often the student is curious\nabout a specific topic but does not quite know where to begin studying. To\nanswer the question of \"what should one learn first,\" we apply an\nembedding-based method to learn prerequisite relations for course concepts in\nthe domain of NLP. We introduce LectureBank, a dataset containing 1,352 English\nlecture files collected from university courses which are each classified\naccording to an existing taxonomy as well as 208 manually-labeled prerequisite\nrelation topics, which is publicly available. The dataset will be useful for\neducational purposes such as lecture preparation and organization as well as\napplications such as reading list generation. Additionally, we experiment with\nneural graph-based networks and non-neural classifiers to learn these\nprerequisite relations from our dataset.\n", "versions": [{"version": "v1", "created": "Mon, 26 Nov 2018 21:09:20 GMT"}], "update_date": "2018-11-30", "authors_parsed": [["Li", "Irene", ""], ["Fabbri", "Alexander R.", ""], ["Tung", "Robert R.", ""], ["Radev", "Dragomir R.", ""]]}, {"id": "1811.12408", "submitter": "Dorien Herremans", "authors": "Ching-Hua Chuan, Kat Agres, Dorien Herremans", "title": "From Context to Concept: Exploring Semantic Relationships in Music with\n  Word2Vec", "comments": "Accepted for publication in Neural Computing and Applications,\n  Springer. In Press", "journal-ref": "Neural Computing and Applications, Springer. 2019", "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the potential of a popular distributional semantics vector space\nmodel, word2vec, for capturing meaningful relationships in ecological (complex\npolyphonic) music. More precisely, the skip-gram version of word2vec is used to\nmodel slices of music from a large corpus spanning eight musical genres. In\nthis newly learned vector space, a metric based on cosine distance is able to\ndistinguish between functional chord relationships, as well as harmonic\nassociations in the music. Evidence, based on cosine distance between\nchord-pair vectors, suggests that an implicit circle-of-fifths exists in the\nvector space. In addition, a comparison between pieces in different keys\nreveals that key relationships are represented in word2vec space. These results\nsuggest that the newly learned embedded vector representation does in fact\ncapture tonal and harmonic characteristics of music, without receiving explicit\ninformation about the musical content of the constituent slices. In order to\ninvestigate whether proximity in the discovered space of embeddings is\nindicative of `semantically-related' slices, we explore a music generation\ntask, by automatically replacing existing slices from a given piece of music\nwith new slices. We propose an algorithm to find substitute slices based on\nspatial proximity and the pitch class distribution inferred in the chosen\nsubspace. The results indicate that the size of the subspace used has a\nsignificant effect on whether slices belonging to the same key are selected. In\nsum, the proposed word2vec model is able to learn music-vector embeddings that\ncapture meaningful tonal and harmonic relationships in music, thereby providing\na useful tool for exploring musical properties and comparisons across pieces,\nas a potential input representation for deep learning models, and as a music\ngeneration device.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 13:52:13 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Chuan", "Ching-Hua", ""], ["Agres", "Kat", ""], ["Herremans", "Dorien", ""]]}, {"id": "1811.12500", "submitter": "Tiehang Duan", "authors": "Tiehang Duan, Qi Lou, Sargur N. Srihari, Xiaohui Xie", "title": "Sequential Embedding Induced Text Clustering, a Non-parametric Bayesian\n  Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current state-of-the-art nonparametric Bayesian text clustering methods model\ndocuments through multinomial distribution on bags of words. Although these\nmethods can effectively utilize the word burstiness representation of documents\nand achieve decent performance, they do not explore the sequential information\nof text and relationships among synonyms. In this paper, the documents are\nmodeled as the joint of bags of words, sequential features and word embeddings.\nWe proposed Sequential Embedding induced Dirichlet Process Mixture Model\n(SiDPMM) to effectively exploit this joint document representation in text\nclustering. The sequential features are extracted by the encoder-decoder\ncomponent. Word embeddings produced by the continuous-bag-of-words (CBOW) model\nare introduced to handle synonyms. Experimental results demonstrate the\nbenefits of our model in two major aspects: 1) improved performance across\nmultiple diverse text datasets in terms of the normalized mutual information\n(NMI); 2) more accurate inference of ground truth cluster numbers with\nregularization effect on tiny outlier clusters.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 21:39:44 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Duan", "Tiehang", ""], ["Lou", "Qi", ""], ["Srihari", "Sargur N.", ""], ["Xie", "Xiaohui", ""]]}, {"id": "1811.12610", "submitter": "Vishal Sharma", "authors": "Vishal Sharma", "title": "An Energy-Efficient Transaction Model for the Blockchain-enabled\n  Internet of Vehicles (IoV)", "comments": "4 Pages, 4 Figures, IEEE Communications Letters", "journal-ref": null, "doi": "10.1109/LCOMM.2018.2883629", "report-no": null, "categories": "cs.NI cs.IR stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The blockchain is a safe, reliable and innovative mechanism for managing\nnumerous vehicles seeking connectivity. However, following the principles of\nthe blockchain, the number of transactions required to update ledgers pose\nserious issues for vehicles as these may consume the maximum available energy.\nTo resolve this, an efficient model is presented in this letter which is\ncapable of handling the energy demands of the blockchain-enabled Internet of\nVehicles (IoV) by optimally controlling the number of transactions through\ndistributed clustering. Numerical results suggest that the proposed approach is\n40.16% better in terms of energy conservation and 82.06% better in terms of the\nnumber of transactions required to share the entire blockchain-data compared\nwith the traditional blockchain.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 04:41:57 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Sharma", "Vishal", ""]]}, {"id": "1811.12776", "submitter": "Nikit Begwani", "authors": "Nikit Begwani, Shrutendra Harsola, Rahul Agrawal", "title": "Learning From Weights: A Cost-Sensitive Approach For Ad Retrieval", "comments": "7 pages, 5 figures, DAPA, WSDM Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieval models such as CLSM is trained on click-through data which treats\neach clicked query-document pair as equivalent. While training on click-through\ndata is reasonable, this paper argues that it is sub-optimal because of its\nnoisy and long-tail nature (especially for sponsored search). In this paper, we\ndiscuss the impact of incorporating or disregarding the long tail pairs in the\ntraining set. Also, we propose a weighing based strategy using which we can\nlearn semantic representations for tail pairs without compromising the quality\nof retrieval. We conducted our experiments on Bing sponsored search and also on\nAmazon product recommendation to demonstrate that the methodology is domain\nagnostic.\n  Online A/B testing on live search engine traffic showed improvements in\nclicks (11.8\\% higher CTR) and as well as improvement in quality (8.2\\% lower\nbounce rate) when compared to the unweighted model. We also conduct the\nexperiment on Amazon Product Recommendation data where we see slight\nimprovements in NDCG Scores calculated by retrieving among co-purchased\nproduct.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2018 13:13:38 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 06:21:36 GMT"}], "update_date": "2018-12-04", "authors_parsed": [["Begwani", "Nikit", ""], ["Harsola", "Shrutendra", ""], ["Agrawal", "Rahul", ""]]}, {"id": "1811.12802", "submitter": "Qiuyi Wu", "authors": "Qiuyi Wu, Ernest Fokoue", "title": "Naive Dictionary On Musical Corpora: From Knowledge Representation To\n  Pattern Recognition", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SD eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose and develop the novel idea of treating musical\nsheets as literary documents in the traditional text analytics parlance, to\nfully benefit from the vast amount of research already existing in statistical\ntext mining and topic modelling. We specifically introduce the idea of\nrepresenting any given piece of music as a collection of \"musical words\" that\nwe codenamed \"muselets\", which are essentially musical words of various\nlengths. Given the novelty and therefore the extremely difficulty of properly\nforming a complete version of a dictionary of muselets, the present paper\nfocuses on a simpler albeit naive version of the ultimate dictionary, which we\nrefer to as a Naive Dictionary because of the fact that all the words are of\nthe same length. We specifically herein construct a naive dictionary featuring\na corpus made up of African American, Chinese, Japanese and Arabic music, on\nwhich we perform both topic modelling and pattern recognition. Although some of\nthe results based on the Naive Dictionary are reasonably good, we anticipate\nphenomenal predictive performances once we get around to actually building a\nfull scale complete version of our intended dictionary of muselets.\n", "versions": [{"version": "v1", "created": "Thu, 29 Nov 2018 02:10:57 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Wu", "Qiuyi", ""], ["Fokoue", "Ernest", ""]]}]