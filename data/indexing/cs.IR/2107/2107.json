[{"id": "2107.00082", "submitter": "Nuno Oliveira", "authors": "Nuno Oliveira, Norberto Sousa, Isabel Pra\\c{c}a", "title": "A Search Engine for Scientific Publications: a Cybersecurity Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cybersecurity is a very challenging topic of research nowadays, as\ndigitalization increases the interaction of people, software and services on\nthe Internet by means of technology devices and networks connected to it. The\nfield is broad and has a lot of unexplored ground under numerous disciplines\nsuch as management, psychology, and data science. Its large disciplinary\nspectrum and many significant research topics generate a considerable amount of\ninformation, making it hard for us to find what we are looking for when\nresearching a particular subject. This work proposes a new search engine for\nscientific publications which combines both information retrieval and reading\ncomprehension algorithms to extract answers from a collection of\ndomain-specific documents. The proposed solution although being applied to the\ncontext of cybersecurity exhibited great generalization capabilities and can be\neasily adapted to perform under other distinct knowledge domains.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 20:10:04 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Oliveira", "Nuno", ""], ["Sousa", "Norberto", ""], ["Pra\u00e7a", "Isabel", ""]]}, {"id": "2107.00161", "submitter": "Qing Wang", "authors": "Qing Wang", "title": "The Use of Bandit Algorithms in Intelligent Interactive Recommender\n  Systems", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's business marketplace, many high-tech Internet enterprises\nconstantly explore innovative ways to provide optimal online user experiences\nfor gaining competitive advantages. The great needs of developing intelligent\ninteractive recommendation systems are indicated, which could sequentially\nsuggest users the most proper items by accurately predicting their preferences,\nwhile receiving the up-to-date feedback to refine the recommendation results,\ncontinuously. Multi-armed bandit algorithms, which have been widely applied\ninto various online systems, are quite capable of delivering such efficient\nrecommendation services. However, few existing bandit models are able to adapt\nto new changes introduced by the modern recommender systems.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 00:43:05 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wang", "Qing", ""]]}, {"id": "2107.00214", "submitter": "Kiran Sharma Dr.", "authors": "Parul Khurana, Geetha Ganesan, Gulshan Kumar, and Kiran Sharma", "title": "Proof of Reference(PoR): A unified informetrics based consensus\n  mechanism", "comments": "6 Pages, 3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Bibliometrics is useful to analyze the research impact for measuring the\nresearch quality. Different bibliographic databases like Scopus, Web of\nScience, Google Scholar etc. are accessed for evaluating the trend of\npublications and citations from time to time. Some of these databases are free\nand some are subscription based. Its always debatable that which bibliographic\ndatabase is better and in what terms. To provide an optimal solution to\navailability of multiple bibliographic databases, we have implemented a single\nauthentic database named as ``conflate'' which can be used for fetching\npublication and citation trend of an author. To further strengthen the\ngenerated database and to provide the transparent system to the stakeholders, a\nconsensus mechanism ``proof of reference (PoR)'' is proposed. Due to three\nconsent based checks implemented in PoR, we feel that it could be considered as\na authentic and honest citation data source for the calculation of unified\ninformetrics for an author.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 04:51:01 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Khurana", "Parul", ""], ["Ganesan", "Geetha", ""], ["Kumar", "Gulshan", ""], ["Sharma", "Kiran", ""]]}, {"id": "2107.00221", "submitter": "Jing Zhao", "authors": "Jing Zhao, Jingya Wang, Madhav Sigdel, Bopeng Zhang, Phuong Hoang,\n  Mengshu Liu and Mohammed Korayem", "title": "Embedding-based Recommender System for Job to Candidate Matching on\n  Scale", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The online recruitment matching system has been the core technology and\nservice platform in CareerBuilder. One of the major challenges in an online\nrecruitment scenario is to provide good matches between job posts and\ncandidates using a recommender system on the scale. In this paper, we discussed\nthe techniques for applying an embedding-based recommender system for the large\nscale of job to candidates matching. To learn the comprehensive and effective\nembedding for job posts and candidates, we have constructed a fused-embedding\nvia different levels of representation learning from raw text, semantic\nentities and location information. The clusters of fused-embedding of job and\ncandidates are then used to build and train the Faiss index that supports\nruntime approximate nearest neighbor search for candidate retrieval. After the\nfirst stage of candidate retrieval, a second stage reranking model that\nutilizes other contextual information was used to generate the final matching\nresult. Both offline and online evaluation results indicate a significant\nimprovement of our proposed two-staged embedding-based system in terms of\nclick-through rate (CTR), quality and normalized discounted accumulated gain\n(nDCG), compared to those obtained from our baseline system. We further\ndescribed the deployment of the system that supports the million-scale job and\ncandidate matching process at CareerBuilder. The overall improvement of our job\nto candidate matching system has demonstrated its feasibility and scalability\nat a major online recruitment site.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 05:18:32 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Zhao", "Jing", ""], ["Wang", "Jingya", ""], ["Sigdel", "Madhav", ""], ["Zhang", "Bopeng", ""], ["Hoang", "Phuong", ""], ["Liu", "Mengshu", ""], ["Korayem", "Mohammed", ""]]}, {"id": "2107.00525", "submitter": "Han Zhang", "authors": "Xinlin Xia, Shang Wang, Han Zhang, Songlin Wang, Sulong Xu, Yun Xiao,\n  Bo Long, Wen-Yun Yang", "title": "SearchGCN: Powering Embedding Retrieval by Graph Convolution Networks\n  for E-Commerce Search", "comments": "2 pages, 1 figure; accepted by SIGIR2021 industry track", "journal-ref": null, "doi": "10.1145/3404835.3464927", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graph convolution networks (GCN), which recently becomes new state-of-the-art\nmethod for graph node classification, recommendation and other applications,\nhas not been successfully applied to industrial-scale search engine yet. In\nthis proposal, we introduce our approach, namely SearchGCN, for embedding-based\ncandidate retrieval in one of the largest e-commerce search engine in the\nworld. Empirical studies demonstrate that SearchGCN learns better embedding\nrepresentations than existing methods, especially for long tail queries and\nitems. Thus, SearchGCN has been deployed into JD.com's search production since\nJuly 2020.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 15:11:00 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Xia", "Xinlin", ""], ["Wang", "Shang", ""], ["Zhang", "Han", ""], ["Wang", "Songlin", ""], ["Xu", "Sulong", ""], ["Xiao", "Yun", ""], ["Long", "Bo", ""], ["Yang", "Wen-Yun", ""]]}, {"id": "2107.00833", "submitter": "Sarah Dean", "authors": "Mihaela Curmei, Sarah Dean, Benjamin Recht", "title": "Quantifying Availability and Discovery in Recommender Systems via\n  Stochastic Reachability", "comments": "to appear ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider how preference models in interactive recommendation\nsystems determine the availability of content and users' opportunities for\ndiscovery. We propose an evaluation procedure based on stochastic reachability\nto quantify the maximum probability of recommending a target piece of content\nto an user for a set of allowable strategic modifications. This framework\nallows us to compute an upper bound on the likelihood of recommendation with\nminimal assumptions about user behavior. Stochastic reachability can be used to\ndetect biases in the availability of content and diagnose limitations in the\nopportunities for discovery granted to users. We show that this metric can be\ncomputed efficiently as a convex program for a variety of practical settings,\nand further argue that reachability is not inherently at odds with accuracy. We\ndemonstrate evaluations of recommendation algorithms trained on large datasets\nof explicit and implicit ratings. Our results illustrate how preference models,\nselection rules, and user interventions impact reachability and how these\neffects can be distributed unevenly.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 16:18:12 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Curmei", "Mihaela", ""], ["Dean", "Sarah", ""], ["Recht", "Benjamin", ""]]}, {"id": "2107.00846", "submitter": "Ruihong Qiu", "authors": "Ruihong Qiu, Zi Huang, Tong Chen and Hongzhi Yin", "title": "Exploiting Positional Information for Session-based Recommendation", "comments": null, "journal-ref": null, "doi": "10.1145/3473339", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For present e-commerce platforms, session-based recommender systems are\ndeveloped to predict users' preference for next-item recommendation. Although a\nsession can usually reflect a user's current preference, a local shift of the\nuser's intention within the session may still exist. Specifically, the\ninteractions that take place in the early positions within a session generally\nindicate the user's initial intention, while later interactions are more likely\nto represent the latest intention. Such positional information has been rarely\nconsidered in existing methods, which restricts their ability to capture the\nsignificance of interactions at different positions. To thoroughly exploit the\npositional information within a session, a theoretical framework is developed\nin this paper to provide an in-depth analysis of the positional information. We\nformally define the properties of forward-awareness and backward-awareness to\nevaluate the ability of positional encoding schemes in capturing the initial\nand the latest intention. According to our analysis, existing positional\nencoding schemes are generally forward-aware only, which can hardly represent\nthe dynamics of the intention in a session. To enhance the positional encoding\nscheme for the session-based recommendation, a dual positional encoding (DPE)\nis proposed to account for both forward-awareness and backward-awareness. Based\non DPE, we propose a novel Positional Recommender (PosRec) model with a\nwell-designed Position-aware Gated Graph Neural Network module to fully exploit\nthe positional information for session-based recommendation tasks. Extensive\nexperiments are conducted on two e-commerce benchmark datasets, Yoochoose and\nDiginetica and the experimental results show the superiority of the PosRec by\ncomparing it with the state-of-the-art session-based recommender models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 05:42:15 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 12:18:36 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Qiu", "Ruihong", ""], ["Huang", "Zi", ""], ["Chen", "Tong", ""], ["Yin", "Hongzhi", ""]]}, {"id": "2107.00852", "submitter": "Ruihong Qiu", "authors": "Ruihong Qiu, Zi Huang, Jingjing Li and Hongzhi Yin", "title": "Exploiting Cross-Session Information for Session-based Recommendation\n  with Graph Neural Networks", "comments": "arXiv admin note: substantial text overlap with arXiv:1911.11942", "journal-ref": null, "doi": "10.1145/3382764", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from the traditional recommender system, the session-based\nrecommender system introduces the concept of the session, i.e., a sequence of\ninteractions between a user and multiple items within a period, to preserve the\nuser's recent interest. The existing work on the session-based recommender\nsystem mainly relies on mining sequential patterns within individual sessions,\nwhich are not expressive enough to capture more complicated dependency\nrelationships among items. In addition, it does not consider the cross-session\ninformation due to the anonymity of the session data, where the linkage between\ndifferent sessions is prevented. In this paper, we solve these problems with\nthe graph neural networks technique. First, each session is represented as a\ngraph rather than a linear sequence structure, based on which a novel Full\nGraph Neural Network (FGNN) is proposed to learn complicated item dependency.\nTo exploit and incorporate cross-session information in the individual\nsession's representation learning, we further construct a Broadly Connected\nSession (BCS) graph to link different sessions and a novel Mask-Readout\nfunction to improve session embedding based on the BCS graph. Extensive\nexperiments have been conducted on two e-commerce benchmark datasets, i.e.,\nYoochoose and Diginetica, and the experimental results demonstrate the\nsuperiority of our proposal through comparisons with state-of-the-art\nsession-based recommender models.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 05:56:02 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 12:25:06 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Qiu", "Ruihong", ""], ["Huang", "Zi", ""], ["Li", "Jingjing", ""], ["Yin", "Hongzhi", ""]]}, {"id": "2107.00873", "submitter": "Heiko Paulheim", "authors": "Malte Brockmeier, Yawen Liu, Sunita Pateer, Sven Hertling and Heiko\n  Paulheim", "title": "On-Demand and Lightweight Knowledge Graph Generation -- a Demonstration\n  with DBpedia", "comments": "Accepted at Semantics 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern large-scale knowledge graphs, such as DBpedia, are datasets which\nrequire large computational resources to serve and process. Moreover, they\noften have longer release cycles, which leads to outdated information in those\ngraphs. In this paper, we present DBpedia on Demand -- a system which serves\nDBpedia resources on demand without the need to materialize and store the\nentire graph, and which even provides limited querying functionality.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jul 2021 07:15:27 GMT"}], "update_date": "2021-07-05", "authors_parsed": [["Brockmeier", "Malte", ""], ["Liu", "Yawen", ""], ["Pateer", "Sunita", ""], ["Hertling", "Sven", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2107.01516", "submitter": "Surya Kant Sahu", "authors": "Sai Mitheran, Abhinav Java, Surya Kant Sahu and Arshad Shaikh", "title": "Improved Representation Learning for Session-based Recommendation", "comments": "Submitted to AJCAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Session-based recommendation systems suggest relevant items to users by\nmodeling user behavior and preferences using short-term anonymous sessions.\nExisting methods leverage Graph Neural Networks (GNNs) that propagate and\naggregate information from neighboring nodes i.e., local message passing. Such\ngraph-based architectures have representational limits, as a single sub-graph\nis susceptible to overfit the sequential dependencies instead of accounting for\ncomplex transitions between items in different sessions. We propose using a\nTransformer in combination with a target attentive GNN, which allows richer\nRepresentation Learning. Our experimental results and ablation show that our\nproposed method outperforms the existing methods on real-world benchmark\ndatasets.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 00:57:28 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Mitheran", "Sai", ""], ["Java", "Abhinav", ""], ["Sahu", "Surya Kant", ""], ["Shaikh", "Arshad", ""]]}, {"id": "2107.01529", "submitter": "Shahpar Yakhchi", "authors": "Shahpar Yakhchi", "title": "Learning Complex Users' Preferences for Recommender Systems", "comments": "269 pages, 43 figures, 26 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommender systems (RSs) have emerged as very useful tools to help customers\nwith their decision-making process, find items of their interest, and alleviate\nthe information overload problem. There are two different lines of approaches\nin RSs: (1) general recommenders with the main goal of discovering long-term\nusers' preferences, and (2) sequential recommenders with the main focus of\ncapturing short-term users' preferences in a session of user-item interaction\n(here, a session refers to a record of purchasing multiple items in one\nshopping event). While considering short-term users' preferences may satisfy\ntheir current needs and interests, long-term users' preferences provide users\nwith the items that they may interact with, eventually. In this thesis, we\nfirst focus on improving the performance of general RSs. Most of the existing\ngeneral RSs tend to exploit the users' rating patterns on common items to\ndetect similar users. The data sparsity problem (i.e. the lack of available\ninformation) is one of the major challenges for the current general RSs, and\nthey may fail to have any recommendations when there are no common items of\ninterest among users. We call this problem data sparsity with no feedback on\ncommon items (DSW-n-FCI). To overcome this problem, we propose a\npersonality-based RS in which similar users are identified based on the\nsimilarity of their personality traits.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 03:25:15 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Yakhchi", "Shahpar", ""]]}, {"id": "2107.01655", "submitter": "Yang Li", "authors": "Yang Li, Tong Chen, Zi Huang", "title": "Attribute-aware Explainable Complementary Clothing Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modelling mix-and-match relationships among fashion items has become\nincreasingly demanding yet challenging for modern E-commerce recommender\nsystems. When performing clothes matching, most existing approaches leverage\nthe latent visual features extracted from fashion item images for compatibility\nmodelling, which lacks explainability of generated matching results and can\nhardly convince users of the recommendations. Though recent methods start to\nincorporate pre-defined attribute information (e.g., colour, style, length,\netc.) for learning item representations and improving the model\ninterpretability, their utilisation of attribute information is still mainly\nreserved for enhancing the learned item representations and generating\nexplanations via post-processing. As a result, this creates a severe bottleneck\nwhen we are trying to advance the recommendation accuracy and generating\nfine-grained explanations since the explicit attributes have only loose\nconnections to the actual recommendation process. This work aims to tackle the\nexplainability challenge in fashion recommendation tasks by proposing a novel\nAttribute-aware Fashion Recommender (AFRec). Specifically, AFRec recommender\nassesses the outfit compatibility by explicitly leveraging the extracted\nattribute-level representations from each item's visual feature. The attributes\nserve as the bridge between two fashion items, where we quantify the affinity\nof a pair of items through the learned compatibility between their attributes.\nExtensive experiments have demonstrated that, by making full use of the\nexplicit attributes in the recommendation process, AFRec is able to achieve\nstate-of-the-art recommendation accuracy and generate intuitive explanations at\nthe same time.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jul 2021 14:56:07 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Li", "Yang", ""], ["Chen", "Tong", ""], ["Huang", "Zi", ""]]}, {"id": "2107.01892", "submitter": "Weiyue Su", "authors": "Weiyue Su, Zeyang Fang, Hui Zhong, Huijuan Wang, Siming Dai, Zhengjie\n  Huang, Yunsheng Shi, Shikun Feng, Zeyu Chen", "title": "NOTE: Solution for KDD-CUP 2021 WikiKG90M-LSC", "comments": "The 1st solution for KDD-CUP 2021 WIKIKG90M-LSC. 7 pages, 2 figures,\n  1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WikiKG90M in KDD Cup 2021 is a large encyclopedic knowledge graph, which\ncould benefit various downstream applications such as question answering and\nrecommender systems. Participants are invited to complete the knowledge graph\nby predicting missing triplets. Recent representation learning methods have\nachieved great success on standard datasets like FB15k-237. Thus, we train the\nadvanced algorithms in different domains to learn the triplets, including OTE,\nQuatE, RotatE and TransE. Significantly, we modified OTE into NOTE (short for\nNorm-OTE) for better performance. Besides, we use both the DeepWalk and the\npost-smoothing technique to capture the graph structure for supplementation. In\naddition to the representations, we also use various statistical probabilities\namong the head entities, the relations and the tail entities for the final\nprediction. Experimental results show that the ensemble of state-of-the-art\nrepresentation learning methods could draw on each others strengths. And we\ndevelop feature engineering from validation candidates for further\nimprovements. Please note that we apply the same strategy on the test set for\nfinal inference. And these features may not be practical in the real world when\nconsidering ranking against all the entities.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 09:30:24 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Su", "Weiyue", ""], ["Fang", "Zeyang", ""], ["Zhong", "Hui", ""], ["Wang", "Huijuan", ""], ["Dai", "Siming", ""], ["Huang", "Zhengjie", ""], ["Shi", "Yunsheng", ""], ["Feng", "Shikun", ""], ["Chen", "Zeyu", ""]]}, {"id": "2107.01999", "submitter": "Kele Xu", "authors": "Zhishan Zhao, Sen Yang, Guohui Liu, Dawei Feng, Kele Xu", "title": "FINT: Field-aware INTeraction Neural Network For CTR Prediction", "comments": "5 pages, Submitted to CIKM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As a critical component for online advertising and marking, click-through\nrate (CTR) prediction has draw lots of attentions from both industry and\nacademia field. Recently, the deep learning has become the mainstream\nmethodological choice for CTR. Despite of sustainable efforts have been made,\nexisting approaches still pose several challenges. On the one hand, high-order\ninteraction between the features is under-explored. On the other hand,\nhigh-order interactions may neglect the semantic information from the low-order\nfields. In this paper, we proposed a novel prediction method, named FINT, that\nemploys the Field-aware INTeraction layer which captures high-order feature\ninteractions while retaining the low-order field information. To empirically\ninvestigate the effectiveness and robustness of the FINT, we perform extensive\nexperiments on the three realistic databases: KDD2012, Criteo and Avazu. The\nobtained results demonstrate that the FINT can significantly improve the\nperformance compared to the existing methods, without increasing the amount of\ncomputation required. Moreover, the proposed method brought about 2.72\\%\nincrease to the advertising revenue of a big online video app through A/B\ntesting. To better promote the research in CTR field, we will release our code\nas well as reference implementation of those baseline models in the final\nversion.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jul 2021 13:17:54 GMT"}], "update_date": "2021-07-06", "authors_parsed": [["Zhao", "Zhishan", ""], ["Yang", "Sen", ""], ["Liu", "Guohui", ""], ["Feng", "Dawei", ""], ["Xu", "Kele", ""]]}, {"id": "2107.02390", "submitter": "Ruihong Qiu", "authors": "Ruihong Qiu, Sen Wang, Zhi Chen, Hongzhi Yin and Zi Huang", "title": "CausalRec: Causal Inference for Visual Debiasing in Visually-Aware\n  Recommendation", "comments": null, "journal-ref": null, "doi": "10.1145/3474085.3475266", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visually-aware recommendation on E-commerce platforms aims to leverage visual\ninformation of items to predict a user's preference. It is commonly observed\nthat user's attention to visual features does not always reflect the real\npreference. Although a user may click and view an item in light of a visual\nsatisfaction of their expectations, a real purchase does not always occur due\nto the unsatisfaction of other essential features (e.g., brand, material,\nprice). We refer to the reason for such a visually related interaction\ndeviating from the real preference as a visual bias. Existing visually-aware\nmodels make use of the visual features as a separate collaborative signal\nsimilarly to other features to directly predict the user's preference without\nconsidering a potential bias, which gives rise to a visually biased\nrecommendation. In this paper, we derive a causal graph to identify and analyze\nthe visual bias of these existing methods. In this causal graph, the visual\nfeature of an item acts as a mediator, which could introduce a spurious\nrelationship between the user and the item. To eliminate this spurious\nrelationship that misleads the prediction of the user's real preference, an\nintervention and a counterfactual inference are developed over the mediator.\nParticularly, the Total Indirect Effect is applied for a debiased prediction\nduring the testing phase of the model. This causal inference framework is model\nagnostic such that it can be integrated into the existing methods. Furthermore,\nwe propose a debiased visually-aware recommender system, denoted as CausalRec\nto effectively retain the supportive significance of the visual information and\nremove the visual bias. Extensive experiments are conducted on eight benchmark\ndatasets, which shows the state-of-the-art performance of CausalRec and the\nefficacy of debiasing.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 05:09:38 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 12:31:01 GMT"}, {"version": "v3", "created": "Tue, 13 Jul 2021 02:04:00 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Qiu", "Ruihong", ""], ["Wang", "Sen", ""], ["Chen", "Zhi", ""], ["Yin", "Hongzhi", ""], ["Huang", "Zi", ""]]}, {"id": "2107.02757", "submitter": "Zhibin Duan", "authors": "Zhibin Duan, Dongsheng Wang, Bo Chen, Chaojie Wang, Wenchao Chen,\n  Yewen Li, Jie Ren, Mingyuan Zhou", "title": "Sawtooth Factorial Topic Embeddings Guided Gamma Belief Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical topic models such as the gamma belief network (GBN) have\ndelivered promising results in mining multi-layer document representations and\ndiscovering interpretable topic taxonomies. However, they often assume in the\nprior that the topics at each layer are independently drawn from the Dirichlet\ndistribution, ignoring the dependencies between the topics both at the same\nlayer and across different layers. To relax this assumption, we propose\nsawtooth factorial topic embedding guided GBN, a deep generative model of\ndocuments that captures the dependencies and semantic similarities between the\ntopics in the embedding space. Specifically, both the words and topics are\nrepresented as embedding vectors of the same dimension. The topic matrix at a\nlayer is factorized into the product of a factor loading matrix and a topic\nembedding matrix, the transpose of which is set as the factor loading matrix of\nthe layer above. Repeating this particular type of factorization, which shares\ncomponents between adjacent layers, leads to a structure referred to as\nsawtooth factorization. An auto-encoding variational inference network is\nconstructed to optimize the model parameter via stochastic gradient descent.\nExperiments on big corpora show that our models outperform other neural topic\nmodels on extracting deeper interpretable topics and deriving better document\nrepresentations.\n", "versions": [{"version": "v1", "created": "Wed, 30 Jun 2021 10:14:57 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Duan", "Zhibin", ""], ["Wang", "Dongsheng", ""], ["Chen", "Bo", ""], ["Wang", "Chaojie", ""], ["Chen", "Wenchao", ""], ["Li", "Yewen", ""], ["Ren", "Jie", ""], ["Zhou", "Mingyuan", ""]]}, {"id": "2107.02759", "submitter": "Juan Camilo V\\'asquez-Correa", "authors": "Daniel Escobar-Grisales, Juan Camilo Vasquez-Correa, Juan Rafael\n  Orozco-Arroyave", "title": "Gender Recognition in Informal and Formal Language Scenarios via\n  Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The interest in demographic information retrieval based on text data has\nincreased in the research community because applications have shown success in\ndifferent sectors such as security, marketing, heath-care, and others.\nRecognition and identification of demographic traits such as gender, age,\nlocation, or personality based on text data can help to improve different\nmarketing strategies. For instance it makes it possible to segment and to\npersonalize offers, thus products and services are exposed to the group of\ngreatest interest. This type of technology has been discussed widely in\ndocuments from social media. However, the methods have been poorly studied in\ndata with a more formal structure, where there is no access to emoticons,\nmentions, and other linguistic phenomena that are only present in social media.\nThis paper proposes the use of recurrent and convolutional neural networks, and\na transfer learning strategy for gender recognition in documents that are\nwritten in informal and formal languages. Models are tested in two different\ndatabases consisting of Tweets and call-center conversations. Accuracies of up\nto 75\\% are achieved for both databases. The results also indicate that it is\npossible to transfer the knowledge from a system trained on a specific type of\nexpressions or idioms such as those typically used in social media into a more\nformal type of text data, where the amount of data is more scarce and its\nstructure is completely different.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jun 2021 15:32:50 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Escobar-Grisales", "Daniel", ""], ["Vasquez-Correa", "Juan Camilo", ""], ["Orozco-Arroyave", "Juan Rafael", ""]]}, {"id": "2107.02765", "submitter": "Aaditeshwar Seth", "authors": "Mehak Gupta, Shayan Saifi, Konark Verma, Kumari Rekha, Aaditeshwar\n  Seth", "title": "Exploring the Scope of Using News Articles to Understand Development\n  Patterns of Districts in India", "comments": "11 pages of main text, 4 pages of supplementary material", "journal-ref": "The 3rd KDD Workshop on Data Science for Social Good, 2021", "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Understanding what factors bring about socio-economic development may often\nsuffer from the streetlight effect, of analyzing the effect of only those\nvariables that have been measured and are therefore available for analysis. How\ndo we check whether all worthwhile variables have been instrumented and\nconsidered when building an econometric development model? We attempt to\naddress this question by building unsupervised learning methods to identify and\nrank news articles about diverse events occurring in different districts of\nIndia, that can provide insights about what may have transpired in the\ndistricts. This can help determine whether variables related to these events\nare indeed available or not to model the development of these districts. We\nalso describe several other applications that emerge from this approach, such\nas to use news articles to understand why pairs of districts that may have had\nsimilar socio-economic indicators approximately ten years back ended up at\ndifferent levels of development currently, and another application that\ngenerates a newsfeed of unusual news articles that do not conform to news\narticles about typical districts with a similar socio-economic profile. These\napplications outline the need for qualitative data to augment models based on\nquantitative data, and are meant to open up research on new ways to mine\ninformation from unstructured qualitative data to understand development.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jul 2021 18:39:04 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Gupta", "Mehak", ""], ["Saifi", "Shayan", ""], ["Verma", "Konark", ""], ["Rekha", "Kumari", ""], ["Seth", "Aaditeshwar", ""]]}, {"id": "2107.03019", "submitter": "Xin Zhou", "authors": "Xin Zhou, Aixin Sun, Yong Liu, Jie Zhang, Chunyan Miao", "title": "SelfCF: A Simple Framework for Self-supervised Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collaborative filtering (CF) is widely used to learn an informative latent\nrepresentation of a user or item from observed interactions. Existing CF-based\nmethods commonly adopt negative sampling to discriminate different items. That\nis, observed user-item pairs are treated as positive instances; unobserved\npairs are considered as negative instances and are sampled under a defined\ndistribution for training. Training with negative sampling on large datasets is\ncomputationally expensive. Further, negative items should be carefully sampled\nunder the defined distribution, in order to avoid selecting an observed\npositive item in the training dataset. Unavoidably, some negative items sampled\nfrom the training dataset could be positive in the test set. Recently,\nself-supervised learning (SSL) has emerged as a powerful tool to learn a model\nwithout negative samples. In this paper, we propose a self-supervised\ncollaborative filtering framework (SelfCF), that is specially designed for\nrecommender scenario with implicit feedback. The main idea of SelfCF is to\naugment the output embeddings generated by backbone networks, because it is\ninfeasible to augment raw input of user/item ids. We propose and study three\noutput perturbation techniques that can be applied to different types of\nbackbone networks including both traditional CF models and graph-based models.\nBy encapsulating two popular recommendation models into the framework, our\nexperiments on three datasets show that the best performance of our framework\nis comparable or better than the supervised counterpart. We also show that\nSelfCF can boost up the performance by up to 8.93\\% on average, compared with\nanother self-supervised framework as the baseline. Source codes are available\nat: https://github.com/enoche/SelfCF.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 05:21:12 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Zhou", "Xin", ""], ["Sun", "Aixin", ""], ["Liu", "Yong", ""], ["Zhang", "Jie", ""], ["Miao", "Chunyan", ""]]}, {"id": "2107.03226", "submitter": "Andres Carvallo", "authors": "Iv\\'an Cantador, Andr\\'es Carvallo, Fernando Diez, Denis Parra", "title": "Graphing else matters: exploiting aspect opinions and ratings in\n  explainable graph-based recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG cs.SI", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The success of neural network embeddings has entailed a renewed interest in\nusing knowledge graphs for a wide variety of machine learning and information\nretrieval tasks. In particular, current recommendation methods based on graph\nembeddings have shown state-of-the-art performance. These methods commonly\nencode latent rating patterns and content features. Different from previous\nwork, in this paper, we propose to exploit embeddings extracted from graphs\nthat combine information from ratings and aspect-based opinions expressed in\ntextual reviews. We then adapt and evaluate state-of-the-art graph embedding\ntechniques over graphs generated from Amazon and Yelp reviews on six domains,\noutperforming baseline recommenders. Our approach has the advantage of\nproviding explanations which leverage aspect-based opinions given by users\nabout recommended items. Furthermore, we also provide examples of the\napplicability of recommendations utilizing aspect opinions as explanations in a\nvisualization dashboard, which allows obtaining information about the most and\nleast liked aspects of similar users obtained from the embeddings of an input\ngraph.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 13:57:28 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Cantador", "Iv\u00e1n", ""], ["Carvallo", "Andr\u00e9s", ""], ["Diez", "Fernando", ""], ["Parra", "Denis", ""]]}, {"id": "2107.03256", "submitter": "Patrick John Chia", "authors": "Patrick John Chia and Bingqing Yu and Jacopo Tagliabue", "title": "\"Are you sure?\": Preliminary Insights from Scaling Product Comparisons\n  to Multiple Shops", "comments": "Accepted for publication at SIGIR eCom 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large eCommerce players introduced comparison tables as a new type of\nrecommendations. However, building comparisons at scale without pre-existing\ntraining/taxonomy data remains an open challenge, especially within the\noperational constraints of shops in the long tail. We present preliminary\nresults from building a comparison pipeline designed to scale in a multi-shop\nscenario: we describe our design choices and run extensive benchmarks on\nmultiple shops to stress-test it. Finally, we run a small user study on\nproperty selection and conclude by discussing potential improvements and\nhighlighting the questions that remain to be addressed.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:39:52 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 13:24:22 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Chia", "Patrick John", ""], ["Yu", "Bingqing", ""], ["Tagliabue", "Jacopo", ""]]}, {"id": "2107.03272", "submitter": "Jesse David Dinneen", "authors": "Jesse David Dinneen and Ba Xuan Nguyen", "title": "How Big Are Peoples' Computer Files? File Size Distributions Among\n  User-managed Collections", "comments": "Final version to appear in ASIS&T `21: Proceedings of the 84th Annual\n  Meeting of the Association for Information Science & Technology, 58", "journal-ref": "ASIS&T 2021: Proceedings of the 84th Annual Meeting of the\n  Association for Information Science & Technology, 58", "doi": null, "report-no": null, "categories": "cs.HC cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Improving file management interfaces and optimising system performance\nrequires current data about users' digital collections and particularly about\nthe file size distributions of such collections. However, prior works have\nexamined only the sizes of system files and users' work files in varied\ncontexts, and there has been no such study since 2013; it therefore remains\nunclear how today's file sizes are distributed, particularly personal files,\nand further if distributions differ among the major operating systems or common\noccupations. Here we examine such differences among 49 million files in 348\nuser collections. We find that the average file size has grown more than\nten-fold since the mid-2000s, though most files are still under 8 MB, and that\nthere are demographic and technological influences in the size distributions.\nWe discuss the implications for user interfaces, system optimisation, and PIM\nresearch.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 15:05:35 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Dinneen", "Jesse David", ""], ["Nguyen", "Ba Xuan", ""]]}, {"id": "2107.03385", "submitter": "Andres Carvallo", "authors": "Iv\\'an Cantador, Andr\\'es Carvallo, Fernando Diez", "title": "Rating and aspect-based opinion graph embeddings for explainable\n  recommendations", "comments": "arXiv admin note: substantial text overlap with arXiv:2107.03226", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The success of neural network embeddings has entailed a renewed interest in\nusing knowledge graphs for a wide variety of machine learning and information\nretrieval tasks. In particular, recent recommendation methods based on graph\nembeddings have shown state-of-the-art performance. In general, these methods\nencode latent rating patterns and content features. Differently from previous\nwork, in this paper, we propose to exploit embeddings extracted from graphs\nthat combine information from ratings and aspect-based opinions expressed in\ntextual reviews. We then adapt and evaluate state-of-the-art graph embedding\ntechniques over graphs generated from Amazon and Yelp reviews on six domains,\noutperforming baseline recommenders. Additionally, our method has the advantage\nof providing explanations that involve the coverage of aspect-based opinions\ngiven by users about recommended items.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 14:07:07 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Cantador", "Iv\u00e1n", ""], ["Carvallo", "Andr\u00e9s", ""], ["Diez", "Fernando", ""]]}, {"id": "2107.03415", "submitter": "Masoud Mansoury", "authors": "Masoud Mansoury, Himan Abdollahpouri, Mykola Pechenizkiy, Bamshad\n  Mobasher, Robin Burke", "title": "A Graph-based Approach for Mitigating Multi-sided Exposure Bias in\n  Recommender Systems", "comments": "arXiv admin note: substantial text overlap with arXiv:2005.01148", "journal-ref": null, "doi": "10.1145/3470948", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is a critical system-level objective in recommender systems that has\nbeen the subject of extensive recent research. A specific form of fairness is\nsupplier exposure fairness where the objective is to ensure equitable coverage\nof items across all suppliers in recommendations provided to users. This is\nespecially important in multistakeholder recommendation scenarios where it may\nbe important to optimize utilities not just for the end-user, but also for\nother stakeholders such as item sellers or producers who desire a fair\nrepresentation of their items. This type of supplier fairness is sometimes\naccomplished by attempting to increasing aggregate diversity in order to\nmitigate popularity bias and to improve the coverage of long-tail items in\nrecommendations. In this paper, we introduce FairMatch, a general graph-based\nalgorithm that works as a post processing approach after recommendation\ngeneration to improve exposure fairness for items and suppliers. The algorithm\niteratively adds high quality items that have low visibility or items from\nsuppliers with low exposure to the users' final recommendation lists. A\ncomprehensive set of experiments on two datasets and comparison with\nstate-of-the-art baselines show that FairMatch, while significantly improves\nexposure fairness and aggregate diversity, maintains an acceptable level of\nrelevance of the recommendations.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 18:01:26 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Mansoury", "Masoud", ""], ["Abdollahpouri", "Himan", ""], ["Pechenizkiy", "Mykola", ""], ["Mobasher", "Bamshad", ""], ["Burke", "Robin", ""]]}, {"id": "2107.03564", "submitter": "Junsu Cho", "authors": "Junsu Cho, SeongKu Kang, Dongmin Hyun, Hwanjo Yu", "title": "Unsupervised Proxy Selection for Session-based Recommender Systems", "comments": "Accepted to SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462958", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session-based Recommender Systems (SRSs) have been actively developed to\nrecommend the next item of an anonymous short item sequence (i.e., session).\nUnlike sequence-aware recommender systems where the whole interaction sequence\nof each user can be used to model both the short-term interest and the general\ninterest of the user, the absence of user-dependent information in SRSs makes\nit difficult to directly derive the user's general interest from data.\nTherefore, existing SRSs have focused on how to effectively model the\ninformation about short-term interest within the sessions, but they are\ninsufficient to capture the general interest of users. To this end, we propose\na novel framework to overcome the limitation of SRSs, named ProxySR, which\nimitates the missing information in SRSs (i.e., general interest of users) by\nmodeling proxies of sessions. ProxySR selects a proxy for the input session in\nan unsupervised manner, and combines it with the encoded short-term interest of\nthe session. As a proxy is jointly learned with the short-term interest and\nselected by multiple sessions, a proxy learns to play the role of the general\ninterest of a user and ProxySR learns how to select a suitable proxy for an\ninput session. Moreover, we propose another real-world situation of SRSs where\na few users are logged-in and leave their identifiers in sessions, and a\nrevision of ProxySR for the situation. Our experiments on real-world datasets\nshow that ProxySR considerably outperforms the state-of-the-art competitors,\nand the proxies successfully imitate the general interest of the users without\nany user-dependent information.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 02:03:06 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Cho", "Junsu", ""], ["Kang", "SeongKu", ""], ["Hyun", "Dongmin", ""], ["Yu", "Hwanjo", ""]]}, {"id": "2107.03813", "submitter": "Yitong Pang", "authors": "Yitong Pang, Lingfei Wu, Qi Shen, Yiming Zhang, Zhihua Wei, Fangli Xu,\n  Ethan Chang, Bo Long", "title": "Heterogeneous Global Graph Neural Networks for Personalized\n  Session-based Recommendation", "comments": "11 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the next interaction of a short-term interaction session is a\nchallenging task in session-based recommendation. Almost all existing works\nrely on item transition patterns, and neglect the impact of user historical\nsessions while modeling user preference, which often leads to non-personalized\nrecommendation. Additionally, existing personalized session-based recommenders\ncapture user preference only based on the sessions of the current user, but\nignore the useful item-transition patterns from other user's historical\nsessions. To address these issues, we propose a novel Heterogeneous Global\nGraph Neural Networks (HG-GNN) to exploit the item transitions over all\nsessions in a subtle manner for better inferring user preference from the\ncurrent and historical sessions. To effectively exploit the item transitions\nover all sessions from users, we propose a novel heterogeneous global graph\nthat contains item transitions of sessions, user-item interactions and global\nco-occurrence items. Moreover, to capture user preference from sessions\ncomprehensively, we propose to learn two levels of user representations from\nthe global graph via two graph augmented preference encoders. Specifically, we\ndesign a novel heterogeneous graph neural network (HGNN) on the heterogeneous\nglobal graph to learn the long-term user preference and item representations\nwith rich semantics. Based on the HGNN, we propose the Current Preference\nEncoder and the Historical Preference Encoder to capture the different levels\nof user preference from the current and historical sessions, respectively. To\nachieve personalized recommendation, we integrate the representations of the\nuser current preference and historical interests to generate the final user\npreference representation. Extensive experimental results on three real-world\ndatasets show that our model outperforms other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 12:38:26 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Pang", "Yitong", ""], ["Wu", "Lingfei", ""], ["Shen", "Qi", ""], ["Zhang", "Yiming", ""], ["Wei", "Zhihua", ""], ["Xu", "Fangli", ""], ["Chang", "Ethan", ""], ["Long", "Bo", ""]]}, {"id": "2107.03844", "submitter": "Firoj Alam", "authors": "Firoj Alam, Arid Hasan, Tanvirul Alam, Akib Khan, Janntatul Tajrin,\n  Naira Khan, Shammur Absar Chowdhury", "title": "A Review of Bangla Natural Language Processing Tasks and the Utility of\n  Transformer Models", "comments": "Under Review, Bangla language processing, text classification,\n  sequence tagging, datasets, benchmarks, transformer models", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Bangla -- ranked as the 6th most widely spoken language across the world\n(https://www.ethnologue.com/guides/ethnologue200), with 230 million native\nspeakers -- is still considered as a low-resource language in the natural\nlanguage processing (NLP) community. With three decades of research, Bangla NLP\n(BNLP) is still lagging behind mainly due to the scarcity of resources and the\nchallenges that come with it. There is sparse work in different areas of BNLP;\nhowever, a thorough survey reporting previous work and recent advances is yet\nto be done. In this study, we first provide a review of Bangla NLP tasks,\nresources, and tools available to the research community; we benchmark datasets\ncollected from various platforms for nine NLP tasks using current\nstate-of-the-art algorithms (i.e., transformer-based models). We provide\ncomparative results for the studied NLP tasks by comparing monolingual vs.\nmultilingual models of varying sizes. We report our results using both\nindividual and consolidated datasets and provide data splits for future\nresearch. We reviewed a total of 108 papers and conducted 175 sets of\nexperiments. Our results show promising performance using transformer-based\nmodels while highlighting the trade-off with computational costs. We hope that\nsuch a comprehensive survey will motivate the community to build on and further\nadvance the research on Bangla NLP.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 13:49:46 GMT"}, {"version": "v2", "created": "Sun, 11 Jul 2021 06:43:33 GMT"}, {"version": "v3", "created": "Sun, 25 Jul 2021 05:41:15 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Alam", "Firoj", ""], ["Hasan", "Arid", ""], ["Alam", "Tanvirul", ""], ["Khan", "Akib", ""], ["Tajrin", "Janntatul", ""], ["Khan", "Naira", ""], ["Chowdhury", "Shammur Absar", ""]]}, {"id": "2107.03936", "submitter": "Siwei Liu", "authors": "Zaiqiao Meng and Siwei Liu and Craig Macdonald and Iadh Ounis", "title": "Graph Neural Pre-training for Enhancing Recommendations using Side\n  Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging the side information associated with entities (i.e. users and\nitems) to enhance the performance of recommendation systems has been widely\nrecognized as an important modelling dimension. While many existing approaches\nfocus on the integration scheme to incorporate entity side information -- by\ncombining the recommendation loss function with an extra side information-aware\nloss -- in this paper, we propose instead a novel pre-training scheme for\nleveraging the side information. In particular, we first pre-train a\nrepresentation model using the side information of the entities, and then\nfine-tune it using an existing general representation-based recommendation\nmodel. Specifically, we propose two pre-training models, named GCN-P and COM-P,\nby considering the entities and their relations constructed from side\ninformation as two different types of graphs respectively, to pre-train entity\nembeddings. For the GCN-P model, two single-relational graphs are constructed\nfrom all the users' and items' side information respectively, to pre-train\nentity representations by using the Graph Convolutional Networks. For the COM-P\nmodel, two multi-relational graphs are constructed to pre-train the entity\nrepresentations by using the Composition-based Graph Convolutional Networks. An\nextensive evaluation of our pre-training models fine-tuned under four general\nrepresentation-based recommender models, i.e. MF, NCF, NGCF and LightGCN, shows\nthat effectively pre-training embeddings with both the user's and item's side\ninformation can significantly improve these original models in terms of both\neffectiveness and stability.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 16:07:29 GMT"}, {"version": "v2", "created": "Fri, 9 Jul 2021 15:02:21 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Meng", "Zaiqiao", ""], ["Liu", "Siwei", ""], ["Macdonald", "Craig", ""], ["Ounis", "Iadh", ""]]}, {"id": "2107.04117", "submitter": "Evangelos Pournaras", "authors": "Evangelos Pournaras, Atif Nabi Ghulam, Renato Kunz, Regula H\\\"anggli", "title": "Crowd Sensing and Living Lab Outdoor Experimentation Made Easy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.DC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outdoor `living lab' experimentation using pervasive computing provides new\nopportunities: higher realism, external validity and large-scale\nsocio-spatio-temporal observations. However, experimentation `in the wild' is\nhighly complex and costly. Noise, biases, privacy concerns to comply with\nstandards of ethical review boards, remote moderation, control of experimental\nconditions and equipment perplex the collection of high-quality data for causal\ninference. This article introduces Smart Agora, a novel open-source software\nplatform for rigorous systematic outdoor experimentation. Without writing a\nsingle line of code, highly complex experimental scenarios are visually\ndesigned and automatically deployed to smart phones. Novel geolocated survey\nand sensor data are collected subject of participants verifying desired\nexperimental conditions, for instance. their presence at certain urban spots.\nThis new approach drastically improves the quality and purposefulness of crowd\nsensing, tailored to conditions that confirm/reject hypotheses. The features\nthat support this innovative functionality and the broad spectrum of its\napplicability are demonstrated.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jul 2021 21:49:32 GMT"}], "update_date": "2021-07-12", "authors_parsed": [["Pournaras", "Evangelos", ""], ["Ghulam", "Atif Nabi", ""], ["Kunz", "Renato", ""], ["H\u00e4nggli", "Regula", ""]]}, {"id": "2107.04846", "submitter": "Haodong Chang", "authors": "Haodong Chang and Yabo Chu", "title": "Propagation-aware Social Recommendation by Transfer Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Social-aware recommendation approaches have been recognized as an effective\nway to solve the data sparsity issue of traditional recommender systems. The\nassumption behind is that the knowledge in social user-user connections can be\nshared and transferred to the domain of user-item interactions, whereby to help\nlearn user preferences. However, most existing approaches merely adopt the\nfirst-order connections among users during transfer learning, ignoring those\nconnections in higher orders. We argue that better recommendation performance\ncan also benefit from high-order social relations. In this paper, we propose a\nnovel Propagation-aware Transfer Learning Network (PTLN) based on the\npropagation of social relations. We aim to better mine the sharing knowledge\nhidden in social networks and thus further improve recommendation performance.\nSpecifically, we explore social influence in two aspects: (a) higher-order\nfriends have been taken into consideration by order bias; (b) different friends\nin the same order will have distinct importance for recommendation by an\nattention mechanism. Besides, we design a novel regularization to bridge the\ngap between social relations and user-item interactions. We conduct extensive\nexperiments on two real-world datasets and beat other counterparts in terms of\nranking accuracy, especially for the cold-start users with few historical\ninteractions.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jul 2021 14:21:27 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Chang", "Haodong", ""], ["Chu", "Yabo", ""]]}, {"id": "2107.04953", "submitter": "Jonathan Stray", "authors": "Jonathan Stray", "title": "Designing Recommender Systems to Depolarize", "comments": "to appear in First Monday, September 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.SI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Polarization is implicated in the erosion of democracy and the progression to\nviolence, which makes the polarization properties of large algorithmic content\nselection systems (recommender systems) a matter of concern for peace and\nsecurity. While algorithm-driven social media does not seem to be a primary\ndriver of polarization at the country level, it could be a useful intervention\npoint in polarized societies. This paper examines algorithmic depolarization\ninterventions with the goal of conflict transformation: not suppressing or\neliminating conflict but moving towards more constructive conflict. Algorithmic\nintervention is considered at three stages: which content is available\n(moderation), how content is selected and personalized (ranking), and content\npresentation and controls (user interface). Empirical studies of online\nconflict suggest that the exposure diversity intervention proposed as an\nantidote to \"filter bubbles\" can be improved and can even worsen polarization\nunder some conditions. Using civility metrics in conjunction with diversity in\ncontent selection may be more effective. However, diversity-based interventions\nhave not been tested at scale and may not work in the diverse and dynamic\ncontexts of real platforms. Instead, intervening in platform polarization\ndynamics will likely require continuous monitoring of polarization metrics,\nsuch as the widely used \"feeling thermometer.\" These metrics can be used to\nevaluate product features, and potentially engineered as algorithmic\nobjectives. It may further prove necessary to include polarization measures in\nthe objective functions of recommender algorithms to prevent optimization\nprocesses from creating conflict as a side effect.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 03:23:42 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Stray", "Jonathan", ""]]}, {"id": "2107.04984", "submitter": "Noveen Sachdeva", "authors": "Noveen Sachdeva, Carole-Jean Wu, Julian McAuley", "title": "SVP-CF: Selection via Proxy for Collaborative Filtering Data", "comments": "11 pages, 3 figures, accepted at the SubSetML workshop at ICML '21\n  (Link: https://sites.google.com/view/icml-2021-subsetml/home)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the practical consequences of dataset sampling strategies on the\nperformance of recommendation algorithms. Recommender systems are generally\ntrained and evaluated on samples of larger datasets. Samples are often taken in\na naive or ad-hoc fashion: e.g. by sampling a dataset randomly or by selecting\nusers or items with many interactions. As we demonstrate, commonly-used data\nsampling schemes can have significant consequences on algorithm performance --\nmasking performance deficiencies in algorithms or altering the relative\nperformance of algorithms, as compared to models trained on the complete\ndataset. Following this observation, this paper makes the following main\ncontributions: (1) characterizing the effect of sampling on algorithm\nperformance, in terms of algorithm and dataset characteristics (e.g. sparsity\ncharacteristics, sequential dynamics, etc.); and (2) designing SVP-CF, which is\na data-specific sampling strategy, that aims to preserve the relative\nperformance of models after sampling, and is especially suited to long-tail\ninteraction data. Detailed experiments show that SVP-CF is more accurate than\ncommonly used sampling schemes in retaining the relative ranking of different\nrecommendation algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 07:00:19 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Sachdeva", "Noveen", ""], ["Wu", "Carole-Jean", ""], ["McAuley", "Julian", ""]]}, {"id": "2107.05005", "submitter": "Yi-Geng Hong", "authors": "Yi-Geng Hong, Hui-Chu Xiao, Wan-Lei Zhao", "title": "Towards Accurate Localization by Instance Search", "comments": "Accepted by ACM MM 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Visual object localization is the key step in a series of object detection\ntasks. In the literature, high localization accuracy is achieved with the\nmainstream strongly supervised frameworks. However, such methods require\nobject-level annotations and are unable to detect objects of unknown\ncategories. Weakly supervised methods face similar difficulties. In this paper,\na self-paced learning framework is proposed to achieve accurate object\nlocalization on the rank list returned by instance search. The proposed\nframework mines the target instance gradually from the queries and their\ncorresponding top-ranked search results. Since a common instance is shared\nbetween the query and the images in the rank list, the target visual instance\ncan be accurately localized even without knowing what the object category is.\nIn addition to performing localization on instance search, the issue of\nfew-shot object detection is also addressed under the same framework. Superior\nperformance over state-of-the-art methods is observed on both tasks.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 10:03:31 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Hong", "Yi-Geng", ""], ["Xiao", "Hui-Chu", ""], ["Zhao", "Wan-Lei", ""]]}, {"id": "2107.05025", "submitter": "Young Kyun Jang", "authors": "Young Kyun Jang, Nam Ik Cho", "title": "Similarity Guided Deep Face Image Retrieval", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Face image retrieval, which searches for images of the same identity from the\nquery input face image, is drawing more attention as the size of the image\ndatabase increases rapidly. In order to conduct fast and accurate retrieval, a\ncompact hash code-based methods have been proposed, and recently, deep face\nimage hashing methods with supervised classification training have shown\noutstanding performance. However, classification-based scheme has a\ndisadvantage in that it cannot reveal complex similarities between face images\ninto the hash code learning. In this paper, we attempt to improve the face\nimage retrieval quality by proposing a Similarity Guided Hashing (SGH) method,\nwhich gently considers self and pairwise-similarity simultaneously. SGH employs\nvarious data augmentations designed to explore elaborate similarities between\nface images, solving both intra and inter identity-wise difficulties. Extensive\nexperimental results on the protocols with existing benchmarks and an\nadditionally proposed large scale higher resolution face image dataset\ndemonstrate that our SGH delivers state-of-the-art retrieval performance.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 11:32:04 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Jang", "Young Kyun", ""], ["Cho", "Nam Ik", ""]]}, {"id": "2107.05124", "submitter": "Gabriel De Souza Pereira Moreira", "authors": "Gabriel de Souza P. Moreira and Sara Rabhi and Ronay Ak and Md Yasin\n  Kabir and Even Oldridge", "title": "Transformers with multi-modal features and post-fusion context for\n  e-commerce session-based recommendation", "comments": "In Proceedings of SIGIR eCom'21 - SIGIR eCommerce Workshop Data\n  Challenge 2021. https://sigir-ecom.github.io/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Session-based recommendation is an important task for e-commerce services,\nwhere a large number of users browse anonymously or may have very distinct\ninterests for different sessions. In this paper we present one of the winning\nsolutions for the Recommendation task of the SIGIR 2021 Workshop on E-commerce\nData Challenge. Our solution was inspired by NLP techniques and consists of an\nensemble of two Transformer architectures - Transformer-XL and XLNet - trained\nwith autoregressive and autoencoding approaches. To leverage most of the rich\ndataset made available for the competition, we describe how we prepared\nmulti-model features by combining tabular events with textual and image\nvectors. We also present a model prediction analysis to better understand the\neffectiveness of our architectures for the session-based recommendation.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jul 2021 20:02:59 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Moreira", "Gabriel de Souza P.", ""], ["Rabhi", "Sara", ""], ["Ak", "Ronay", ""], ["Kabir", "Md Yasin", ""], ["Oldridge", "Even", ""]]}, {"id": "2107.05204", "submitter": "Yanhua Huang", "authors": "Yanhua Huang, Weikun Wang, Lei Zhang, Ruiwen Xu", "title": "Sliding Spectrum Decomposition for Diversified Recommendation", "comments": "In Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD '21), August 14--18, 2021, Virtual Event,\n  Singapore", "journal-ref": null, "doi": "10.1145/3447548.3467108", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Content feed, a type of product that recommends a sequence of items for users\nto browse and engage with, has gained tremendous popularity among social media\nplatforms. In this paper, we propose to study the diversity problem in such a\nscenario from an item sequence perspective using time series analysis\ntechniques. We derive a method called sliding spectrum decomposition (SSD) that\ncaptures users' perception of diversity in browsing a long item sequence. We\nalso share our experiences in designing and implementing a suitable item\nembedding method for accurate similarity measurement under long tail effect.\nCombined together, they are now fully implemented and deployed in Xiaohongshu\nApp's production recommender system that serves the main Explore Feed product\nfor tens of millions of users every day. We demonstrate the effectiveness and\nefficiency of the method through theoretical analysis, offline experiments and\nonline A/B tests.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 05:41:54 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Huang", "Yanhua", ""], ["Wang", "Weikun", ""], ["Zhang", "Lei", ""], ["Xu", "Ruiwen", ""]]}, {"id": "2107.05235", "submitter": "Yutao Ma", "authors": "Liwei Huang, Yutao Ma, Yanbo Liu, Shuliang Wang, Deyi Li", "title": "Position-enhanced and Time-aware Graph Convolutional Network for\n  Sequential Recommendations", "comments": "25 pages, 5 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the existing deep learning-based sequential recommendation approaches\nutilize the recurrent neural network architecture or self-attention to model\nthe sequential patterns and temporal influence among a user's historical\nbehavior and learn the user's preference at a specific time. However, these\nmethods have two main drawbacks. First, they focus on modeling users' dynamic\nstates from a user-centric perspective and always neglect the dynamics of items\nover time. Second, most of them deal with only the first-order user-item\ninteractions and do not consider the high-order connectivity between users and\nitems, which has recently been proved helpful for the sequential\nrecommendation. To address the above problems, in this article, we attempt to\nmodel user-item interactions by a bipartite graph structure and propose a new\nrecommendation approach based on a Position-enhanced and Time-aware Graph\nConvolutional Network (PTGCN) for the sequential recommendation. PTGCN models\nthe sequential patterns and temporal dynamics between user-item interactions by\ndefining a position-enhanced and time-aware graph convolution operation and\nlearning the dynamic representations of users and items simultaneously on the\nbipartite graph with a self-attention aggregator. Also, it realizes the\nhigh-order connectivity between users and items by stacking multi-layer graph\nconvolutions. To demonstrate the effectiveness of PTGCN, we carried out a\ncomprehensive evaluation of PTGCN on three real-world datasets of different\nsizes compared with a few competitive baselines. Experimental results indicate\nthat PTGCN outperforms several state-of-the-art models in terms of two\ncommonly-used evaluation metrics for ranking.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 07:34:20 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Huang", "Liwei", ""], ["Ma", "Yutao", ""], ["Liu", "Yanbo", ""], ["Wang", "Shuliang", ""], ["Li", "Deyi", ""]]}, {"id": "2107.05247", "submitter": "Yunfan Wu", "authors": "Yunfan Wu, Qi Cao, Huawei Shen, Shuchang Tao, Xueqi Cheng", "title": "Inductive Representation Based Graph Convolution Network for\n  Collaborative Filtering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, graph neural networks (GNNs) have shown powerful ability in\ncollaborative filtering, which is a widely adopted recommendation scenario.\nWhile without any side information, existing graph neural network based methods\ngenerally learn a one-hot embedding for each user or item as the initial input\nrepresentation of GNNs. However, such one-hot embedding is intrinsically\ntransductive, making these methods with no inductive ability, i.e., failing to\ndeal with new users or new items that are unseen during training. Besides, the\nnumber of model parameters depends on the number of users and items, which is\nexpensive and not scalable. In this paper, we give a formal definition of\ninductive recommendation and solve the above problems by proposing Inductive\nrepresentation based Graph Convolutional Network (IGCN) for collaborative\nfiltering. Specifically, we design an inductive representation layer, which\nutilizes the interaction behavior with core users or items as the initial\nrepresentation, improving the general recommendation performance while bringing\ninductive ability. Note that, the number of parameters of IGCN only depends on\nthe number of core users or items, which is adjustable and scalable. Extensive\nexperiments on three public benchmarks demonstrate the state-of-the-art\nperformance of IGCN in both transductive and inductive recommendation\nscenarios, while with remarkably fewer model parameters. Our implementations\nare available here in PyTorch.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 08:12:06 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Wu", "Yunfan", ""], ["Cao", "Qi", ""], ["Shen", "Huawei", ""], ["Tao", "Shuchang", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2107.05315", "submitter": "Yinwei Wei", "authors": "Yinwei Wei, Xiang Wang, Qi Li, Liqiang Nie, Yan Li, Xuanping Li,\n  Tat-Seng Chua", "title": "Contrastive Learning for Cold-Start Recommendation", "comments": "Accepted by ACM Multimedia 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommending cold-start items is a long-standing and fundamental challenge in\nrecommender systems. Without any historical interaction on cold-start items, CF\nscheme fails to use collaborative signals to infer user preference on these\nitems. To solve this problem, extensive studies have been conducted to\nincorporate side information into the CF scheme. Specifically, they employ\nmodern neural network techniques (e.g., dropout, consistency constraint) to\ndiscover and exploit the coalition effect of content features and collaborative\nrepresentations. However, we argue that these works less explore the mutual\ndependencies between content features and collaborative representations and\nlack sufficient theoretical supports, thus resulting in unsatisfactory\nperformance. In this work, we reformulate the cold-start item representation\nlearning from an information-theoretic standpoint. It aims to maximize the\nmutual dependencies between item content and collaborative signals.\nSpecifically, the representation learning is theoretically lower-bounded by the\nintegration of two terms: mutual information between collaborative embeddings\nof users and items, and mutual information between collaborative embeddings and\nfeature representations of items. To model such a learning process, we devise a\nnew objective function founded upon contrastive learning and develop a simple\nyet effective Contrastive Learning-based Cold-start Recommendation\nframework(CLCRec). In particular, CLCRec consists of three components:\ncontrastive pair organization, contrastive embedding, and contrastive\noptimization modules. It allows us to preserve collaborative signals in the\ncontent representations for both warm and cold-start items. Through extensive\nexperiments on four publicly accessible datasets, we observe that CLCRec\nachieves significant improvements over state-of-the-art approaches in both\nwarm- and cold-start scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 11:00:20 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 01:41:24 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 07:29:52 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Wei", "Yinwei", ""], ["Wang", "Xiang", ""], ["Li", "Qi", ""], ["Nie", "Liqiang", ""], ["Li", "Yan", ""], ["Li", "Xuanping", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2107.05366", "submitter": "Xiaoleii Liu", "authors": "Naicheng Guo and Xiaolei Liu and Shaoshuai Li and Qiongxu Ma and Yunan\n  Zhao and Bing Han and Lin Zheng and Kaixin Gao and Xiaobo Guo", "title": "HCGR: Hyperbolic Contrastive Graph Representation Learning for\n  Session-based Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Session-based recommendation (SBR) learns users' preferences by capturing the\nshort-term and sequential patterns from the evolution of user behaviors. Among\nthe studies in the SBR field, graph-based approaches are a relatively powerful\nkind of way, which generally extract item information by message aggregation\nunder Euclidean space. However, such methods can't effectively extract the\nhierarchical information contained among consecutive items in a session, which\nis critical to represent users' preferences. In this paper, we present a\nhyperbolic contrastive graph recommender (HCGR), a principled session-based\nrecommendation framework involving Lorentz hyperbolic space to adequately\ncapture the coherence and hierarchical representations of the items. Within\nthis framework, we design a novel adaptive hyperbolic attention computation to\naggregate the graph message of each user's preference in a session-based\nbehavior sequence. In addition, contrastive learning is leveraged to optimize\nthe item representation by considering the geodesic distance between positive\nand negative samples in hyperbolic space. Extensive experiments on four\nreal-world datasets demonstrate that HCGR consistently outperforms\nstate-of-the-art baselines by 0.43$\\%$-28.84$\\%$ in terms of $HitRate$, $NDCG$\nand $MRR$.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 01:46:16 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Guo", "Naicheng", ""], ["Liu", "Xiaolei", ""], ["Li", "Shaoshuai", ""], ["Ma", "Qiongxu", ""], ["Zhao", "Yunan", ""], ["Han", "Bing", ""], ["Zheng", "Lin", ""], ["Gao", "Kaixin", ""], ["Guo", "Xiaobo", ""]]}, {"id": "2107.05368", "submitter": "Golsa Heidari", "authors": "Golsa Heidari, Kamran Zamanifar", "title": "A Three Phase Semantic Web Matchmaker", "comments": "14 pages, 1 figure, International Journal of Smart Home. arXiv admin\n  note: text overlap with arXiv:2107.02609", "journal-ref": "International Journal of Smart Home, Vol.4, No.3, July, 2010", "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Since using environments that are made according to the service oriented\narchitecture, we have more effective and dynamic applications. Semantic\nmatchmaking process is finding valuable service candidates for substitution. It\nis a very important aspect of using semantic Web Services. Our proposed\nmatchmaker algorithm performs semantic matching of Web Services on the basis of\ninput and output descriptions of semantic Web Services matching. This technique\ntakes advantages from a graph structure and flow networks. Our novel approach\nis assigning matchmaking scores to semantics of the inputs and outputs\nparameters and their types. It makes a flow network in which the weights of the\nedges are these scores, using FordFulkerson algorithm, we find matching rate of\ntwo web services. So, all services should be described in the same Ontology Web\nLanguage. Among these candidates, best one is chosen for substitution in the\ncase of an execution failure. Our approach uses the algorithm that has the\nleast running time among all others that can be used for bipartite matching.\nThe importance of problem is that in real systems, many fundamental problems\nwill occur by late answering. So system`s service should always be on and if\none of them crashes, it would be replaced fast. Semantic web matchmaker eases\nthis process.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 13:39:11 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Heidari", "Golsa", ""], ["Zamanifar", "Kamran", ""]]}, {"id": "2107.05381", "submitter": "Daniel Devatman Hromada", "authors": "Daniel Devatman Hromada", "title": "Can Evolutionary Computation Help us to Crib the Voynich Manuscript ?", "comments": "16 pages, 3 figures, 2 source code snippets", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Departing from the postulate that Voynich Manuscript is not a hoax but rather\nencodes authentic contents, our article presents an evolutionary algorithm\nwhich aims to find the most optimal mapping between voynichian glyphs and\ncandidate phonemic values. Core component of the decoding algorithm is a\nprocess of maximization of a fitness function which aims to find most optimal\nset of substitution rules allowing to transcribe the part of the manuscript --\nwhich we call the Calendar -- into lists of feminine names. This leads to sets\nof character subsitution rules which allow us to consistently transcribe dozens\namong three hundred calendar tokens into feminine names: a result far\nsurpassing both ``popular'' as well as \"state of the art\" tentatives to crack\nthe manuscript. What's more, by using name lists stemming from different\nlanguages as potential cribs, our ``adaptive'' method can also be useful in\nidentification of the language in which the manuscript is written.\n  As far as we can currently tell, results of our experiments indicate that the\nCalendar part of the manuscript contains names from baltoslavic, balkanic or\nhebrew language strata. Two further indications are also given: primo, highest\nfitness values were obtained when the crib list contains names with specific\ninfixes at token's penultimate position as is the case, for example, for slavic\n\\textbf{feminine diminutives} (i.e. names ending with -ka and not -a). In the\nmost successful scenario, 240 characters contained in 35 distinct Voynichese\ntokens were successfully transcribed. Secundo, in case of crib stemming from\nHebrew language, whole adaptation process converges to significantly better\nfitness values when transcribing voynichian tokens whose order of individual\ncharacters have been reversed, and when lists feminine and not masculine names\nare used as the crib.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 23:39:59 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Hromada", "Daniel Devatman", ""]]}, {"id": "2107.05385", "submitter": "Monika Daryani", "authors": "Monika Daryani and James Caverlee", "title": "Identifying Hijacked Reviews", "comments": "To be published in ACL-IJCNLP 2021 Workshop on e-Commerce and NLP\n  (ECNLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fake reviews and review manipulation are growing problems on online\nmarketplaces globally. Review Hijacking is a new review manipulation tactic in\nwhich unethical sellers \"hijack\" an existing product page (usually one with\nmany positive reviews), then update the product details like title, photo, and\ndescription with those of an entirely different product. With the earlier\nreviews still attached, the new item appears well-reviewed. However, there are\nno public datasets of review hijacking and little is known in the literature\nabout this tactic. Hence, this paper proposes a three-part study: (i) we\npropose a framework to generate synthetically labeled data for review hijacking\nby swapping products and reviews; (ii) then, we evaluate the potential of both\na Twin LSTM network and BERT sequence pair classifier to distinguish legitimate\nreviews from hijacked ones using this data; and (iii) we then deploy the best\nperforming model on a collection of 31K products (with 6.5 M reviews) in the\noriginal data, where we find 100s of previously unknown examples of review\nhijacking.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jul 2021 20:43:36 GMT"}], "update_date": "2021-07-13", "authors_parsed": [["Daryani", "Monika", ""], ["Caverlee", "James", ""]]}, {"id": "2107.05474", "submitter": "Hao Fu", "authors": "Zhi Bian, Shaojun Zhou, Hao Fu, Qihong Yang, Zhenqi Sun, Junjie Tang,\n  Guiquan Liu, Kaikui Liu, Xiaolong Li", "title": "Denoising User-aware Memory Network for Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For better user satisfaction and business effectiveness, more and more\nattention has been paid to the sequence-based recommendation system, which is\nused to infer the evolution of users' dynamic preferences, and recent studies\nhave noticed that the evolution of users' preferences can be better understood\nfrom the implicit and explicit feedback sequences. However, most of the\nexisting recommendation techniques do not consider the noise contained in\nimplicit feedback, which will lead to the biased representation of user\ninterest and a suboptimal recommendation performance. Meanwhile, the existing\nmethods utilize item sequence for capturing the evolution of user interest. The\nperformance of these methods is limited by the length of the sequence, and can\nnot effectively model the long-term interest in a long period of time. Based on\nthis observation, we propose a novel CTR model named denoising user-aware\nmemory network (DUMN). Specifically, the framework: (i) proposes a feature\npurification module based on orthogonal mapping, which use the representation\nof explicit feedback to purify the representation of implicit feedback, and\neffectively denoise the implicit feedback; (ii) designs a user memory network\nto model the long-term interests in a fine-grained way by improving the memory\nnetwork, which is ignored by the existing methods; and (iii) develops a\npreference-aware interactive representation component to fuse the long-term and\nshort-term interests of users based on gating to understand the evolution of\nunbiased preferences of users. Extensive experiments on two real e-commerce\nuser behavior datasets show that DUMN has a significant improvement over the\nstate-of-the-art baselines. The code of DUMN model has been uploaded as an\nadditional material.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 14:39:36 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Bian", "Zhi", ""], ["Zhou", "Shaojun", ""], ["Fu", "Hao", ""], ["Yang", "Qihong", ""], ["Sun", "Zhenqi", ""], ["Tang", "Junjie", ""], ["Liu", "Guiquan", ""], ["Liu", "Kaikui", ""], ["Li", "Xiaolong", ""]]}, {"id": "2107.05677", "submitter": "Chris Donahue", "authors": "Rodrigo Castellon and Chris Donahue and Percy Liang", "title": "Codified audio language modeling learns useful representations for music\n  information retrieval", "comments": "To appear in the proceedings of ISMIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG cs.MM eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We demonstrate that language models pre-trained on codified\n(discretely-encoded) music audio learn representations that are useful for\ndownstream MIR tasks. Specifically, we explore representations from Jukebox\n(Dhariwal et al. 2020): a music generation system containing a language model\ntrained on codified audio from 1M songs. To determine if Jukebox's\nrepresentations contain useful information for MIR, we use them as input\nfeatures to train shallow models on several MIR tasks. Relative to\nrepresentations from conventional MIR models which are pre-trained on tagging,\nwe find that using representations from Jukebox as input features yields 30%\nstronger performance on average across four MIR tasks: tagging, genre\nclassification, emotion recognition, and key detection. For key detection, we\nobserve that representations from Jukebox are considerably stronger than those\nfrom models pre-trained on tagging, suggesting that pre-training via codified\naudio language modeling may address blind spots in conventional approaches. We\ninterpret the strength of Jukebox's representations as evidence that modeling\naudio instead of tags provides richer representations for MIR.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:28:50 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Castellon", "Rodrigo", ""], ["Donahue", "Chris", ""], ["Liang", "Percy", ""]]}, {"id": "2107.05684", "submitter": "Paul Rodrigues", "authors": "Evan Williams, Paul Rodrigues, Sieu Tran", "title": "Accenture at CheckThat! 2021: Interesting claim identification and\n  ranking with contextually sensitive lexical training data augmentation", "comments": "To Appear As: Evan Williams, Paul Rodrigues, Sieu Tran. Accenture at\n  CheckThat! 2021: Interesting claim identification and ranking with\n  contextually sensitive lexical training data augmentation. In: Faggioli et\n  al. Working Notes of CLEF 2021-Conference and Labs of the Evaluation Forum.\n  Bucharest, Romania. 21-24 September 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper discusses the approach used by the Accenture Team for CLEF2021\nCheckThat! Lab, Task 1, to identify whether a claim made in social media would\nbe interesting to a wide audience and should be fact-checked. Twitter training\nand test data were provided in English, Arabic, Spanish, Turkish, and\nBulgarian. Claims were to be classified (check-worthy/not check-worthy) and\nranked in priority order for the fact-checker. Our method used deep neural\nnetwork transformer models with contextually sensitive lexical augmentation\napplied on the supplied training datasets to create additional training\nsamples. This augmentation approach improved the performance for all languages.\nOverall, our architecture and data augmentation pipeline produced the best\nsubmitted system for Arabic, and performance scales according to the quantity\nof provided training data for English, Spanish, Turkish, and Bulgarian. This\npaper investigates the deep neural network architectures for each language as\nwell as the provided data to examine why the approach worked so effectively for\nArabic, and discusses additional data augmentation measures that should could\nbe useful to this problem.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 18:46:47 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Williams", "Evan", ""], ["Rodrigues", "Paul", ""], ["Tran", "Sieu", ""]]}, {"id": "2107.05720", "submitter": "St\\'ephane Clinchant", "authors": "Thibault Formal, Benjamin Piwowarski, St\\'ephane Clinchant", "title": "SPLADE: Sparse Lexical and Expansion Model for First Stage Ranking", "comments": "5 pages, SIGIR'21 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In neural Information Retrieval, ongoing research is directed towards\nimproving the first retriever in ranking pipelines. Learning dense embeddings\nto conduct retrieval using efficient approximate nearest neighbors methods has\nproven to work well. Meanwhile, there has been a growing interest in learning\nsparse representations for documents and queries, that could inherit from the\ndesirable properties of bag-of-words models such as the exact matching of terms\nand the efficiency of inverted indexes. In this work, we present a new\nfirst-stage ranker based on explicit sparsity regularization and a\nlog-saturation effect on term weights, leading to highly sparse representations\nand competitive results with respect to state-of-the-art dense and sparse\nmethods. Our approach is simple, trained end-to-end in a single stage. We also\nexplore the trade-off between effectiveness and efficiency, by controlling the\ncontribution of the sparsity regularization.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 20:17:44 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Formal", "Thibault", ""], ["Piwowarski", "Benjamin", ""], ["Clinchant", "St\u00e9phane", ""]]}, {"id": "2107.05722", "submitter": "Reza Khanmohammadi", "authors": "Reza Khanmohammadi, Mitra Sadat Mirshafiee, Mehdi Allahyari", "title": "COPER: a Query-adaptable Semantics-based Search Engine for Persian\n  COVID-19 Articles", "comments": "7 pages", "journal-ref": null, "doi": "10.1109/ICWR51868.2021.9443151", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the surge of pretrained language models, a new pathway has been opened\nto incorporate Persian text contextual information. Meanwhile, as many other\ncountries, including Iran, are fighting against COVID-19, a plethora of\nCOVID-19 related articles has been published in Iranian Healthcare magazines to\nbetter inform the public of the situation. However, finding answers in this\nsheer volume of information is an extremely difficult task. In this paper, we\ncollected a large dataset of these articles, leveraged different BERT\nvariations as well as other keyword models such as BM25 and TF-IDF, and created\na search engine to sift through these documents and rank them, given a user's\nquery. Our final search engine consists of a ranker and a re-ranker, which\nadapts itself to the query. We fine-tune our models using Semantic Textual\nSimilarity and evaluate them with standard task metrics. Our final method\noutperforms the rest by a considerable margin.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 20:25:56 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 05:48:21 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Khanmohammadi", "Reza", ""], ["Mirshafiee", "Mitra Sadat", ""], ["Allahyari", "Mehdi", ""]]}, {"id": "2107.05760", "submitter": "Keping Bi", "authors": "Keping Bi, Qingyao Ai, W. Bruce Croft", "title": "Asking Clarifying Questions Based on Negative Feedback in Conversational\n  Search", "comments": "In the proceedings of ICTIR'21", "journal-ref": null, "doi": "10.1145/3471158.3472232", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users often need to look through multiple search result pages or reformulate\nqueries when they have complex information-seeking needs. Conversational search\nsystems make it possible to improve user satisfaction by asking questions to\nclarify users' search intents. This, however, can take significant effort to\nanswer a series of questions starting with \"what/why/how\". To quickly identify\nuser intent and reduce effort during interactions, we propose an intent\nclarification task based on yes/no questions where the system needs to ask the\ncorrect question about intents within the fewest conversation turns. In this\ntask, it is essential to use negative feedback about the previous questions in\nthe conversation history. To this end, we propose a Maximum-Marginal-Relevance\n(MMR) based BERT model (MMR-BERT) to leverage negative feedback based on the\nMMR principle for the next clarifying question selection. Experiments on the\nQulac dataset show that MMR-BERT outperforms state-of-the-art baselines\nsignificantly on the intent identification task and the selected questions also\nachieve significantly better performance in the associated document retrieval\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 22:12:29 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Bi", "Keping", ""], ["Ai", "Qingyao", ""], ["Croft", "W. Bruce", ""]]}, {"id": "2107.06083", "submitter": "Golsa Heidari", "authors": "Kamran Zamanifar, Golsa Heidari, Naser Nematbakhsh, Farhad Mardookhi", "title": "A New Approach for Semantic Web Matching", "comments": "9 pages, 6 figures, SUComS 2010", "journal-ref": null, "doi": "10.1007/978-3-642-16444-6_12", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this work we propose a new approach for semantic web matching to improve\nthe performance of Web Service replacement. Because in automatic systems we\nshould ensure the self-healing, self-configuration, self-optimization and\nself-management, all services should be always available and if one of them\ncrashes, it should be replaced with the most similar one. Candidate services\nare advertised in Universal Description, Discovery and Integration (UDDI) all\nin Web Ontology Language (OWL). By the help of bipartite graph, we did the\nmatching between the crashed service and a Candidate one. Then we chose the\nbest service, which had the maximum rate of matching. In fact we compare two\nservices` functionalities and capabilities to see how much they match. We found\nthat the best way for matching two web services, is comparing the\nfunctionalities of them.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jul 2021 13:47:12 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Zamanifar", "Kamran", ""], ["Heidari", "Golsa", ""], ["Nematbakhsh", "Naser", ""], ["Mardookhi", "Farhad", ""]]}, {"id": "2107.06400", "submitter": "Sergio Rojas-Galeano", "authors": "Sergio Rojas-Galeano", "title": "Using BERT Encoding to Tackle the Mad-lib Attack in SMS Spam Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  One of the stratagems used to deceive spam filters is to substitute vocables\nwith synonyms or similar words that turn the message unrecognisable by the\ndetection algorithms. In this paper we investigate whether the recent\ndevelopment of language models sensitive to the semantics and context of words,\nsuch as Google's BERT, may be useful to overcome this adversarial attack\n(called \"Mad-lib\" as per the word substitution game). Using a dataset of 5572\nSMS spam messages, we first established a baseline of detection performance\nusing widely known document representation models (BoW and TFIDF) and the novel\nBERT model, coupled with a variety of classification algorithms (Decision Tree,\nkNN, SVM, Logistic Regression, Naive Bayes, Multilayer Perceptron). Then, we\nbuilt a thesaurus of the vocabulary contained in these messages, and set up a\nMad-lib attack experiment in which we modified each message of a held out\nsubset of data (not used in the baseline experiment) with different rates of\nsubstitution of original words with synonyms from the thesaurus. Lastly, we\nevaluated the detection performance of the three representation models (BoW,\nTFIDF and BERT) coupled with the best classifier from the baseline experiment\n(SVM). We found that the classic models achieved a 94% Balanced Accuracy (BA)\nin the original dataset, whereas the BERT model obtained 96%. On the other\nhand, the Mad-lib attack experiment showed that BERT encodings manage to\nmaintain a similar BA performance of 96% with an average substitution rate of\n1.82 words per message, and 95% with 3.34 words substituted per message. In\ncontrast, the BA performance of the BoW and TFIDF encoders dropped to chance.\nThese results hint at the potential advantage of BERT models to combat these\ntype of ingenious attacks, offsetting to some extent for the inappropriate use\nof semantic relationships in language.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 21:17:57 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Rojas-Galeano", "Sergio", ""]]}, {"id": "2107.06416", "submitter": "Diego Antognini", "authors": "Diana Petrescu and Diego Antognini and Boi Faltings", "title": "Multi-Step Critiquing User Interface for Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendations with personalized explanations have been shown to increase\nuser trust and perceived quality and help users make better decisions.\nMoreover, such explanations allow users to provide feedback by critiquing them.\nSeveral algorithms for recommendation systems with multi-step critiquing have\ntherefore been developed. However, providing a user-friendly interface based on\npersonalized explanations and critiquing has not been addressed in the last\ndecade. In this paper, we introduce four different web interfaces (available\nunder https://lia.epfl.ch/critiquing/) helping users making decisions and\nfinding their ideal item. We have chosen the hotel recommendation domain as a\nuse case even though our approach is trivially adaptable for other domains.\nMoreover, our system is model-agnostic (for both recommender systems and\ncritiquing models) allowing a great flexibility and further extensions. Our\ninterfaces are above all a useful tool to help research in recommendation with\ncritiquing. They allow to test such systems on a real use case and also to\nhighlight some limitations of these approaches to find solutions to overcome\nthem.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 22:19:38 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Petrescu", "Diana", ""], ["Antognini", "Diego", ""], ["Faltings", "Boi", ""]]}, {"id": "2107.06423", "submitter": "Kholoud AlGhamdi", "authors": "Kholoud AlGhamdi, Miaojing Shi, and Elena Simperl", "title": "Learning to Recommend Items to Wikidata Editors", "comments": "The paper is accepted to appear in ISWC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Wikidata is an open knowledge graph built by a global community of\nvolunteers. As it advances in scale, it faces substantial challenges around\neditor engagement. These challenges are in terms of both attracting new editors\nto keep up with the sheer amount of work and retaining existing editors.\nExperience from other online communities and peer-production systems, including\nWikipedia, suggests that personalised recommendations could help, especially\nnewcomers, who are sometimes unsure about how to contribute best to an ongoing\neffort. For this reason, we propose a recommender system WikidataRec for\nWikidata items. The system uses a hybrid of content-based and collaborative\nfiltering techniques to rank items for editors relying on both item features\nand item-editor previous interaction. A neural network, named a neural mixture\nof representations, is designed to learn fine weights for the combination of\nitem-based representations and optimize them with editor-based representation\nby item-editor interaction. To facilitate further research in this space, we\nalso create two benchmark datasets, a general-purpose one with 220,000 editors\nresponsible for 14 million interactions with 4 million items and a second one\nfocusing on the contributions of more than 8,000 more active editors. We\nperform an offline evaluation of the system on both datasets with promising\nresults. Our code and datasets are available at\nhttps://github.com/WikidataRec-developer/Wikidata_Recommender.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 22:49:55 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 18:07:13 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["AlGhamdi", "Kholoud", ""], ["Shi", "Miaojing", ""], ["Simperl", "Elena", ""]]}, {"id": "2107.06427", "submitter": "Kaize Ding", "authors": "Jianling Wang, Kaize Ding and James Caverlee", "title": "Sequential Recommendation for Cold-start Users with Meta Transitional\n  Learning", "comments": "Accepted by SIGIR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A fundamental challenge for sequential recommenders is to capture the\nsequential patterns of users toward modeling how users transit among items. In\nmany practical scenarios, however, there are a great number of cold-start users\nwith only minimal logged interactions. As a result, existing sequential\nrecommendation models will lose their predictive power due to the difficulties\nin learning sequential patterns over users with only limited interactions. In\nthis work, we aim to improve sequential recommendation for cold-start users\nwith a novel framework named MetaTL, which learns to model the transition\npatterns of users through meta-learning. Specifically, the proposed MetaTL: (i)\nformulates sequential recommendation for cold-start users as a few-shot\nlearning problem; (ii) extracts the dynamic transition patterns among users\nwith a translation-based architecture; and (iii) adopts meta transitional\nlearning to enable fast learning for cold-start users with only limited\ninteractions, leading to accurate inference of sequential interactions.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jul 2021 23:22:57 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Wang", "Jianling", ""], ["Ding", "Kaize", ""], ["Caverlee", "James", ""]]}, {"id": "2107.06472", "submitter": "Bei Yu", "authors": "Jun Wang, Bei Yu", "title": "Linking Health News to Research Literature", "comments": "13 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurately linking news articles to scientific research works is a critical\ncomponent in a number of applications, such as measuring the social impact of a\nresearch work and detecting inaccuracies or distortions in science news.\nAlthough the lack of links between news and literature has been a challenge in\nthese applications, it is a relatively unexplored research problem. In this\npaper we designed and evaluated a new approach that consists of (1) augmenting\nlatest named-entity recognition techniques to extract various metadata, and (2)\ndesigning a new elastic search engine that can facilitate the use of enriched\nmetadata queries. To evaluate our approach, we constructed two datasets of\npaired news articles and research papers: one is used for training models to\nextract metadata, and the other for evaluation. Our experiments showed that the\nnew approach performed significantly better than a baseline approach used by\naltmetric.com (0.89 vs 0.32 in terms of top-1 accuracy). To further demonstrate\nthe effectiveness of the approach, we also conducted a study on 37,600\nhealth-related press releases published on EurekAlert!, which showed that our\napproach was able to identify the corresponding research papers with a top-1\naccuracy of at least 0.97.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 03:50:51 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Wang", "Jun", ""], ["Yu", "Bei", ""]]}, {"id": "2107.06720", "submitter": "Ashudeep Singh", "authors": "Ashudeep Singh, David Kempe, Thorsten Joachims", "title": "Fairness in Ranking under Uncertainty", "comments": "Preprint under submission. 19 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness has emerged as an important consideration in algorithmic\ndecision-making. Unfairness occurs when an agent with higher merit obtains a\nworse outcome than an agent with lower merit. Our central point is that a\nprimary cause of unfairness is uncertainty. A principal or algorithm making\ndecisions never has access to the agents' true merit, and instead uses proxy\nfeatures that only imperfectly predict merit (e.g., GPA, star ratings,\nrecommendation letters). None of these ever fully capture an agent's merit; yet\nexisting approaches have mostly been defining fairness notions directly based\non observed features and outcomes.\n  Our primary point is that it is more principled to acknowledge and model the\nuncertainty explicitly. The role of observed features is to give rise to a\nposterior distribution of the agents' merits. We use this viewpoint to define a\nnotion of approximate fairness in ranking. We call an algorithm $\\phi$-fair\n(for $\\phi \\in [0,1]$) if it has the following property for all agents $x$ and\nall $k$: if agent $x$ is among the top $k$ agents with respect to merit with\nprobability at least $\\rho$ (according to the posterior merit distribution),\nthen the algorithm places the agent among the top $k$ agents in its ranking\nwith probability at least $\\phi \\rho$.\n  We show how to compute rankings that optimally trade off approximate fairness\nagainst utility to the principal. In addition to the theoretical\ncharacterization, we present an empirical analysis of the potential impact of\nthe approach in simulation studies. For real-world validation, we applied the\napproach in the context of a paper recommendation system that we built and\nfielded at a large conference.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 14:10:16 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Singh", "Ashudeep", ""], ["Kempe", "David", ""], ["Joachims", "Thorsten", ""]]}, {"id": "2107.06751", "submitter": "Guillaume Cabanac", "authors": "Guillaume Cabanac and Cyril Labb\\'e and Alexander Magazinov", "title": "Tortured phrases: A dubious writing style emerging in science. Evidence\n  of critical issues affecting established journals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.CL cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic text generators have been used to produce fake scientific\npapers for more than a decade. Such nonsensical papers are easily detected by\nboth human and machine. Now more complex AI-powered generation techniques\nproduce texts indistinguishable from that of humans and the generation of\nscientific texts from a few keywords has been documented. Our study introduces\nthe concept of tortured phrases: unexpected weird phrases in lieu of\nestablished ones, such as 'counterfeit consciousness' instead of 'artificial\nintelligence.' We combed the literature for tortured phrases and study one\nreputable journal where these concentrated en masse. Hypothesising the use of\nadvanced language models we ran a detector on the abstracts of recent articles\nof this journal and on several control sets. The pairwise comparisons reveal a\nconcentration of abstracts flagged as 'synthetic' in the journal. We also\nhighlight irregularities in its operation, such as abrupt changes in editorial\ntimelines. We substantiate our call for investigation by analysing several\nindividual dubious articles, stressing questionable features: tortured writing\nstyle, citation of non-existent literature, and unacknowledged image reuse.\nSurprisingly, some websites offer to rewrite texts for free, generating\ngobbledegook full of tortured phrases. We believe some authors used rewritten\ntexts to pad their manuscripts. We wish to raise the awareness on publications\ncontaining such questionable AI-generated or rewritten texts that passed (poor)\npeer review. Deception with synthetic texts threatens the integrity of the\nscientific literature.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jul 2021 20:47:08 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Cabanac", "Guillaume", ""], ["Labb\u00e9", "Cyril", ""], ["Magazinov", "Alexander", ""]]}, {"id": "2107.06835", "submitter": "Ripon Patgiri", "authors": "Sabuzima Nayak, Ripon Patgiri, Lilapati Waikhom, Arif Ahmed", "title": "A Review on Edge Analytics: Issues, Challenges, Opportunities, Promises,\n  Future Directions, and Applications", "comments": "Submitted to Elsevier for possible publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.DB cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Edge technology aims to bring Cloud resources (specifically, the compute,\nstorage, and network) to the closed proximity of the Edge devices, i.e., smart\ndevices where the data are produced and consumed. Embedding computing and\napplication in Edge devices lead to emerging of two new concepts in Edge\ntechnology, namely, Edge computing and Edge analytics. Edge analytics uses some\ntechniques or algorithms to analyze the data generated by the Edge devices.\nWith the emerging of Edge analytics, the Edge devices have become a complete\nset. Currently, Edge analytics is unable to provide full support for the\nexecution of the analytic techniques. The Edge devices cannot execute advanced\nand sophisticated analytic algorithms following various constraints such as\nlimited power supply, small memory size, limited resources, etc. This article\naims to provide a detailed discussion on Edge analytics. A clear explanation to\ndistinguish between the three concepts of Edge technology, namely, Edge\ndevices, Edge computing, and Edge analytics, along with their issues.\nFurthermore, the article discusses the implementation of Edge analytics to\nsolve many problems in various areas such as retail, agriculture, industry, and\nhealthcare. In addition, the research papers of the state-of-the-art edge\nanalytics are rigorously reviewed in this article to explore the existing\nissues, emerging challenges, research opportunities and their directions, and\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jul 2021 21:48:20 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Nayak", "Sabuzima", ""], ["Patgiri", "Ripon", ""], ["Waikhom", "Lilapati", ""], ["Ahmed", "Arif", ""]]}, {"id": "2107.07002", "submitter": "Mostafa Dehghani", "authors": "Mostafa Dehghani, Yi Tay, Alexey A. Gritsenko, Zhe Zhao, Neil Houlsby,\n  Fernando Diaz, Donald Metzler, Oriol Vinyals", "title": "The Benchmark Lottery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The world of empirical machine learning (ML) strongly relies on benchmarks in\norder to determine the relative effectiveness of different algorithms and\nmethods. This paper proposes the notion of \"a benchmark lottery\" that describes\nthe overall fragility of the ML benchmarking process. The benchmark lottery\npostulates that many factors, other than fundamental algorithmic superiority,\nmay lead to a method being perceived as superior. On multiple benchmark setups\nthat are prevalent in the ML community, we show that the relative performance\nof algorithms may be altered significantly simply by choosing different\nbenchmark tasks, highlighting the fragility of the current paradigms and\npotential fallacious interpretation derived from benchmarking ML methods. Given\nthat every benchmark makes a statement about what it perceives to be important,\nwe argue that this might lead to biased progress in the community. We discuss\nthe implications of the observed phenomena and provide recommendations on\nmitigating them using multiple machine learning domains and communities as use\ncases, including natural language processing, computer vision, information\nretrieval, recommender systems, and reinforcement learning.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jul 2021 21:08:30 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Dehghani", "Mostafa", ""], ["Tay", "Yi", ""], ["Gritsenko", "Alexey A.", ""], ["Zhao", "Zhe", ""], ["Houlsby", "Neil", ""], ["Diaz", "Fernando", ""], ["Metzler", "Donald", ""], ["Vinyals", "Oriol", ""]]}, {"id": "2107.07106", "submitter": "Alex Egg", "authors": "Alex Egg", "title": "Online Learning for Recommendations at Grubhub", "comments": null, "journal-ref": null, "doi": "10.1145/3460231.3474599", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a method to easily modify existing offline Recommender Systems to\nrun online using Transfer Learning. Online Learning for Recommender Systems has\ntwo main advantages: quality and scale. Like many Machine Learning algorithms\nin production if not regularly retrained will suffer from Concept Drift. A\npolicy that is updated frequently online can adapt to drift faster than a batch\nsystem. This is especially true for user-interaction systems like recommenders\nwhere the underlying distribution can shift drastically to follow user\nbehaviour. As a platform grows rapidly like Grubhub, the cost of running batch\ntraining jobs becomes material. A shift from stateless batch learning offline\nto stateful incremental learning online can recover, for example, at Grubhub,\nup to a 45x cost savings and a +20% metrics increase. There are a few\nchallenges to overcome with the transition to online stateful learning, namely\nconvergence, non-stationary embeddings and off-policy evaluation, which we\nexplore from our experiences running this system in production.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 04:01:36 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Egg", "Alex", ""]]}, {"id": "2107.07173", "submitter": "Lei Chen", "authors": "Lei Chen, Fajie Yuan, Jiaxi Yang, Min Yang, and Chengming Li", "title": "Scene-adaptive Knowledge Distillation for Sequential Recommendation via\n  Differentiable Architecture Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sequential recommender systems (SRS) have become a research hotspot due to\nits power in modeling user dynamic interests and sequential behavioral\npatterns. To maximize model expressive ability, a default choice is to apply a\nlarger and deeper network architecture, which, however, often brings high\nnetwork latency when generating online recommendations. Naturally, we argue\nthat compressing the heavy recommendation models into middle- or light- weight\nneural networks is of great importance for practical production systems. To\nrealize such a goal, we propose AdaRec, a knowledge distillation (KD) framework\nwhich compresses knowledge of a teacher model into a student model adaptively\naccording to its recommendation scene by using differentiable Neural\nArchitecture Search (NAS). Specifically, we introduce a target-oriented\ndistillation loss to guide the structure search process for finding the student\nnetwork architecture, and a cost-sensitive loss as constraints for model size,\nwhich achieves a superior trade-off between recommendation effectiveness and\nefficiency. In addition, we leverage Earth Mover's Distance (EMD) to realize\nmany-to-many layer mapping during knowledge distillation, which enables each\nintermediate student layer to learn from other intermediate teacher layers\nadaptively. Extensive experiments on real-world recommendation datasets\ndemonstrate that our model achieves competitive or better accuracy with notable\ninference speedup comparing to strong counterparts, while discovering diverse\nneural architectures for sequential recommender models under different\nrecommendation scenes.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 07:47:46 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chen", "Lei", ""], ["Yuan", "Fajie", ""], ["Yang", "Jiaxi", ""], ["Yang", "Min", ""], ["Li", "Chengming", ""]]}, {"id": "2107.07268", "submitter": "Jing Yi", "authors": "Jing Yi and Yaochen Zhu and Jiayi Xie and Zhenzhong Chen", "title": "Cross-modal Variational Auto-encoder for Content-based Micro-video\n  Background Music Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we propose a cross-modal variational auto-encoder (CMVAE) for\ncontent-based micro-video background music recommendation. CMVAE is a\nhierarchical Bayesian generative model that matches relevant background music\nto a micro-video by projecting these two multimodal inputs into a shared\nlow-dimensional latent space, where the alignment of two corresponding\nembeddings of a matched video-music pair is achieved by cross-generation.\nMoreover, the multimodal information is fused by the product-of-experts (PoE)\nprinciple, where the semantic information in visual and textual modalities of\nthe micro-video are weighted according to their variance estimations such that\nthe modality with a lower noise level is given more weights. Therefore, the\nmicro-video latent variables contain less irrelevant information that results\nin a more robust model generalization. Furthermore, we establish a large-scale\ncontent-based micro-video background music recommendation dataset, TT-150k,\ncomposed of approximately 3,000 different background music clips associated to\n150,000 micro-videos from different users. Extensive experiments on the\nestablished TT-150k dataset demonstrate the effectiveness of the proposed\nmethod. A qualitative assessment of CMVAE by visualizing some recommendation\nresults is also included.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 11:47:43 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Yi", "Jing", ""], ["Zhu", "Yaochen", ""], ["Xie", "Jiayi", ""], ["Chen", "Zhenzhong", ""]]}, {"id": "2107.07284", "submitter": "Chintoo Kumar", "authors": "Chintoo Kumar, C. Ravindranath Chowdary", "title": "Auto-detecting groups based on textual similarity for group\n  recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In general, recommender systems are designed to provide personalized items to\na user. But in few cases, items are recommended for a group, and the challenge\nis to aggregate the individual user preferences to infer the recommendation to\na group. It is also important to consider the similarity of characteristics\namong the members of a group to generate a better recommendation. Members of an\nautomatically identified group will have similar characteristics, and reaching\na consensus with a decision-making process is preferable in this case. It\nrequires users-items and their rating interactions over a utility matrix to\nauto-detect the groups in group recommendations. We may not overlook other\nintrinsic information to form a group. The textual information also plays a\npivotal role in user clustering. In this paper, we auto-detect the groups based\non the textual similarity of the metadata (review texts). We consider the order\nin user preferences in our models. We have conducted extensive experiments over\ntwo real-world datasets to check the efficacy of the proposed models. We have\nalso conducted a competitive comparison with a baseline model to show the\nimprovements in the quality of recommendations.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 12:30:41 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Kumar", "Chintoo", ""], ["Chowdary", "C. Ravindranath", ""]]}, {"id": "2107.07453", "submitter": "Wenzhuo Song", "authors": "Wenzhuo Song, Shoujin Wang, Yan Wang, Shengsheng Wang", "title": "Next-item Recommendations in Short Sessions", "comments": "This paper has been accepted by ACM RecSys'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The changing preferences of users towards items trigger the emergence of\nsession-based recommender systems (SBRSs), which aim to model the dynamic\npreferences of users for next-item recommendations. However, most of the\nexisting studies on SBRSs are based on long sessions only for recommendations,\nignoring short sessions, though short sessions, in fact, account for a large\nproportion in most of the real-world datasets. As a result, the applicability\nof existing SBRSs solutions is greatly reduced. In a short session, quite\nlimited contextual information is available, making the next-item\nrecommendation very challenging. To this end, in this paper, inspired by the\nsuccess of few-shot learning (FSL) in effectively learning a model with limited\ninstances, we formulate the next-item recommendation as an FSL problem.\nAccordingly, following the basic idea of a representative approach for FSL,\ni.e., meta-learning, we devise an effective SBRS called INter-SEssion\ncollaborative Recommender netTwork (INSERT) for next-item recommendations in\nshort sessions. With the carefully devised local module and global module,\nINSERT is able to learn an optimal preference representation of the current\nuser in a given short session. In particular, in the global module, a similar\nsession retrieval network (SSRN) is designed to find out the sessions similar\nto the current short session from the historical sessions of both the current\nuser and other users, respectively. The obtained similar sessions are then\nutilized to complement and optimize the preference representation learned from\nthe current short session by the local module for more accurate next-item\nrecommendations in this short session. Extensive experiments conducted on two\nreal-world datasets demonstrate the superiority of our proposed INSERT over the\nstate-of-the-art SBRSs when making next-item recommendations in short sessions.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 16:56:33 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 10:22:28 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Song", "Wenzhuo", ""], ["Wang", "Shoujin", ""], ["Wang", "Yan", ""], ["Wang", "Shengsheng", ""]]}, {"id": "2107.07500", "submitter": "Narinder Singh Punn", "authors": "Sudhanshu, Narinder Singh Punn, Sanjay Kumar Sonbhadra, Sonali Agarwal", "title": "Recommending best course of treatment based on similarities of\n  prognostic markers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the advancement in the technology sector spanning over every field, a\nhuge influx of information is inevitable. Among all the opportunities that the\nadvancements in the technology have brought, one of them is to propose\nefficient solutions for data retrieval. This means that from an enormous pile\nof data, the retrieval methods should allow the users to fetch the relevant and\nrecent data over time. In the field of entertainment and e-commerce,\nrecommender systems have been functioning to provide the aforementioned.\nEmploying the same systems in the medical domain could definitely prove to be\nuseful in variety of ways. Following this context, the goal of this paper is to\npropose collaborative filtering based recommender system in the healthcare\nsector to recommend remedies based on the symptoms experienced by the patients.\nFurthermore, a new dataset is developed consisting of remedies concerning\nvarious diseases to address the limited availability of the data. The proposed\nrecommender system accepts the prognostic markers of a patient as the input and\ngenerates the best remedy course. With several experimental trials, the\nproposed model achieved promising results in recommending the possible remedy\nfor given prognostic markers.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 17:52:12 GMT"}, {"version": "v2", "created": "Mon, 19 Jul 2021 07:39:23 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Sudhanshu", "", ""], ["Punn", "Narinder Singh", ""], ["Sonbhadra", "Sanjay Kumar", ""], ["Agarwal", "Sonali", ""]]}, {"id": "2107.07705", "submitter": "Qin Ruan", "authors": "Qin Ruan, Brian Mac Namee, Ruihai Dong", "title": "Pseudo-labelling Enhanced Media Bias Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Leveraging unlabelled data through weak or distant supervision is a\ncompelling approach to developing more effective text classification models.\nThis paper proposes a simple but effective data augmentation method, which\nleverages the idea of pseudo-labelling to select samples from noisy distant\nsupervision annotation datasets. The result shows that the proposed method\nimproves the accuracy of biased news detection models.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 04:47:50 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Ruan", "Qin", ""], ["Mac Namee", "Brian", ""], ["Dong", "Ruihai", ""]]}, {"id": "2107.07773", "submitter": "Zhenghao Liu PhD.", "authors": "Yizhi Li, Zhenghao Liu, Chenyan Xiong, Zhiyuan Liu", "title": "More Robust Dense Retrieval with Contrastive Dual Learning", "comments": "Accepted by ICTIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense retrieval conducts text retrieval in the embedding space and has shown\nmany advantages compared to sparse retrieval. Existing dense retrievers\noptimize representations of queries and documents with contrastive training and\nmap them to the embedding space. The embedding space is optimized by aligning\nthe matched query-document pairs and pushing the negative documents away from\nthe query. However, in such training paradigm, the queries are only optimized\nto align to the documents and are coarsely positioned, leading to an\nanisotropic query embedding space. In this paper, we analyze the embedding\nspace distributions and propose an effective training paradigm, Contrastive\nDual Learning for Approximate Nearest Neighbor (DANCE) to learn fine-grained\nquery representations for dense retrieval. DANCE incorporates an additional\ndual training object of query retrieval, inspired by the classic information\nretrieval training axiom, query likelihood. With contrastive learning, the dual\ntraining object of DANCE learns more tailored representations for queries and\ndocuments to keep the embedding space smooth and uniform, thriving on the\nranking performance of DANCE on the MS MARCO document retrieval task. Different\nfrom ANCE that only optimized with the document retrieval task, DANCE\nconcentrates the query embeddings closer to document representations while\nmaking the document distribution more discriminative. Such concentrated query\nembedding distribution assigns more uniform negative sampling probabilities to\nqueries and helps to sufficiently optimize query representations in the query\nretrieval task. Our codes are released at https://github.com/thunlp/DANCE.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 08:59:36 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Li", "Yizhi", ""], ["Liu", "Zhenghao", ""], ["Xiong", "Chenyan", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "2107.07786", "submitter": "Elona Shatri Miss", "authors": "Elona Shatri and Gy\\\"orgy Fazekas", "title": "DoReMi: First glance at a universal OMR dataset", "comments": "7 pages, including 2 pages appendix. Accepted for publishing at the\n  3rd International Workshop on Reading Music Systems 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The main challenges of Optical Music Recognition (OMR) come from the nature\nof written music, its complexity and the difficulty of finding an appropriate\ndata representation. This paper provides a first look at DoReMi, an OMR dataset\nthat addresses these challenges, and a baseline object detection model to\nassess its utility. Researchers often approach OMR following a set of small\nstages, given that existing data often do not satisfy broader research. We\nexamine the possibility of changing this tendency by presenting more metadata.\nOur approach complements existing research; hence DoReMi allows harmonisation\nwith two existing datasets, DeepScores and MUSCIMA++. DoReMi was generated\nusing a music notation software and includes over 6400 printed sheet music\nimages with accompanying metadata useful in OMR research. Our dataset provides\nOMR metadata, MIDI, MEI, MusicXML and PNG files, each aiding a different stage\nof OMR. We obtain 64% mean average precision (mAP) in object detection using\nhalf of the data. Further work includes re-iterating through the creation\nprocess to satisfy custom OMR models. While we do not assume to have solved the\nmain challenges in OMR, this dataset opens a new course of discussions that\nwould ultimately aid that goal.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 09:24:58 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Shatri", "Elona", ""], ["Fazekas", "Gy\u00f6rgy", ""]]}, {"id": "2107.07831", "submitter": "Arpita Chaudhuri", "authors": "Arpita Chaudhuri, Debasis Samanta, Monalisa Sarma", "title": "Modeling User Behaviour in Research Paper Recommendation System", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  User intention which often changes dynamically is considered to be an\nimportant factor for modeling users in the design of recommendation systems.\nRecent studies are starting to focus on predicting user intention (what users\nwant) beyond user preference (what users like). In this work, a user intention\nmodel is proposed based on deep sequential topic analysis. The model predicts a\nuser's intention in terms of the topic of interest. The Hybrid Topic Model\n(HTM) comprising Latent Dirichlet Allocation (LDA) and Word2Vec is proposed to\nderive the topic of interest of users and the history of preferences. HTM finds\nthe true topics of papers estimating word-topic distribution which includes\nsyntactic and semantic correlations among words. Next, to model user intention,\na Long Short Term Memory (LSTM) based sequential deep learning model is\nproposed. This model takes into account temporal context, namely the time\ndifference between clicks of two consecutive papers seen by a user. Extensive\nexperiments with the real-world research paper dataset indicate that the\nproposed approach significantly outperforms the state-of-the-art methods.\nFurther, the proposed approach introduces a new road map to model a user\nactivity suitable for the design of a research paper recommendation system.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 11:31:03 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Chaudhuri", "Arpita", ""], ["Samanta", "Debasis", ""], ["Sarma", "Monalisa", ""]]}, {"id": "2107.07842", "submitter": "Shivani Choudhary", "authors": "Shivani Choudhary, Tarun Luthra, Ashima Mittal, Rajat Singh", "title": "A Survey of Knowledge Graph Embedding and Their Applications", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge Graph embedding provides a versatile technique for representing\nknowledge. These techniques can be used in a variety of applications such as\ncompletion of knowledge graph to predict missing information, recommender\nsystems, question answering, query expansion, etc. The information embedded in\nKnowledge graph though being structured is challenging to consume in a\nreal-world application. Knowledge graph embedding enables the real-world\napplication to consume information to improve performance. Knowledge graph\nembedding is an active research area. Most of the embedding methods focus on\nstructure-based information. Recent research has extended the boundary to\ninclude text-based information and image-based information in entity embedding.\nEfforts have been made to enhance the representation with context information.\nThis paper introduces growth in the field of KG embedding from simple\ntranslation-based models to enrichment-based models. This paper includes the\nutility of the Knowledge graph in real-world applications.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 12:07:53 GMT"}], "update_date": "2021-07-19", "authors_parsed": [["Choudhary", "Shivani", ""], ["Luthra", "Tarun", ""], ["Mittal", "Ashima", ""], ["Singh", "Rajat", ""]]}, {"id": "2107.08096", "submitter": "Divya Shanmugam", "authors": "Divya Shanmugam, Samira Shabanian, Fernando Diaz, Mich\\`ele Finck,\n  Asia Biega", "title": "Learning to Limit Data Collection via Scaling Laws: Data Minimization\n  Compliance in Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data minimization is a legal obligation defined in the European Union's\nGeneral Data Protection Regulation (GDPR) as the responsibility to process an\nadequate, relevant, and limited amount of personal data in relation to a\nprocessing purpose. However, unlike fairness or transparency, the principle has\nnot seen wide adoption for machine learning systems due to a lack of\ncomputational interpretation. In this paper, we build on literature in machine\nlearning and law to propose the first learning framework for limiting data\ncollection based on an interpretation that ties the data collection purpose to\nsystem performance. We formalize a data minimization criterion based on\nperformance curve derivatives and provide an effective and interpretable\npiecewise power law technique that models distinct stages of an algorithm's\nperformance throughout data collection. Results from our empirical\ninvestigation offer deeper insights into the relevant considerations when\ndesigning a data minimization framework, including the choice of feature\nacquisition algorithm, initialization conditions, as well as impacts on\nindividuals that hint at tensions between data minimization and fairness.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jul 2021 19:59:01 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Shanmugam", "Divya", ""], ["Shabanian", "Samira", ""], ["Diaz", "Fernando", ""], ["Finck", "Mich\u00e8le", ""], ["Biega", "Asia", ""]]}, {"id": "2107.08291", "submitter": "Lakshya Kumar", "authors": "Lakshya Kumar, Sagnik Sarkar", "title": "Neural Search: Learning Query and Product Representations in Fashion\n  E-commerce", "comments": "10 pages, accepted at SIGIR eCommerce 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Typical e-commerce platforms contain millions of products in the catalog.\nUsers visit these platforms and enter search queries to retrieve their desired\nproducts. Therefore, showing the relevant products at the top is essential for\nthe success of e-commerce platforms. We approach this problem by learning low\ndimension representations for queries and product descriptions by leveraging\nuser click-stream data as our main source of signal for product relevance.\nStarting from GRU-based architectures as our baseline model, we move towards a\nmore advanced transformer-based architecture. This helps the model to learn\ncontextual representations of queries and products to serve better search\nresults and understand the user intent in an efficient manner. We perform\nexperiments related to pre-training of the Transformer based RoBERTa model\nusing a fashion corpus and fine-tuning it over the triplet loss. Our\nexperiments on the product ranking task show that the RoBERTa model is able to\ngive an improvement of 7.8% in Mean Reciprocal Rank(MRR), 15.8% in Mean Average\nPrecision(MAP) and 8.8% in Normalized Discounted Cumulative Gain(NDCG), thus\noutperforming our GRU based baselines. For the product retrieval task, RoBERTa\nmodel is able to outperform other two models with an improvement of 164.7% in\nPrecision@50 and 145.3% in Recall@50. In order to highlight the importance of\npre-training RoBERTa for fashion domain, we qualitatively compare already\npre-trained RoBERTa on standard datasets with our custom pre-trained RoBERTa\nover a fashion corpus for the query token prediction task. Finally, we also\nshow a qualitative comparison between GRU and RoBERTa results for product\nretrieval task for some test queries.\n", "versions": [{"version": "v1", "created": "Sat, 17 Jul 2021 17:34:36 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Kumar", "Lakshya", ""], ["Sarkar", "Sagnik", ""]]}, {"id": "2107.08345", "submitter": "Yinqiong Cai", "authors": "Yinqiong Cai, Yixing Fan, Jiafeng Guo, Ruqing Zhang, Yanyan Lan and\n  Xueqi Cheng", "title": "A Discriminative Semantic Ranker for Question Retrieval", "comments": "ICTIR'21", "journal-ref": null, "doi": "10.1145/3471158.3472227", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Similar question retrieval is a core task in community-based question\nanswering (CQA) services. To balance the effectiveness and efficiency, the\nquestion retrieval system is typically implemented as multi-stage rankers: The\nfirst-stage ranker aims to recall potentially relevant questions from a large\nrepository, and the latter stages attempt to re-rank the retrieved results.\nMost existing works on question retrieval mainly focused on the re-ranking\nstages, leaving the first-stage ranker to some traditional term-based methods.\nHowever, term-based methods often suffer from the vocabulary mismatch problem,\nespecially on short texts, which may block the re-rankers from relevant\nquestions at the very beginning. An alternative is to employ embedding-based\nmethods for the first-stage ranker, which compress texts into dense vectors to\nenhance the semantic matching. However, these methods often lose the\ndiscriminative power as term-based methods, thus introduce noise during\nretrieval and hurt the recall performance. In this work, we aim to tackle the\ndilemma of the first-stage ranker, and propose a discriminative semantic\nranker, namely DenseTrans, for high-recall retrieval. Specifically, DenseTrans\nis a densely connected Transformer, which learns semantic embeddings for texts\nbased on Transformer layers. Meanwhile, DenseTrans promotes low-level features\nthrough dense connections to keep the discriminative power of the learned\nrepresentations. DenseTrans is inspired by DenseNet in computer vision (CV),\nbut poses a new way to use the dense connectivity which is totally different\nfrom its original design purpose. Experimental results over two question\nretrieval benchmark datasets show that our model can obtain significant gain on\nrecall against strong term-based methods as well as state-of-the-art\nembedding-based methods.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 02:23:34 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Cai", "Yinqiong", ""], ["Fan", "Yixing", ""], ["Guo", "Jiafeng", ""], ["Zhang", "Ruqing", ""], ["Lan", "Yanyan", ""], ["Cheng", "Xueqi", ""]]}, {"id": "2107.08383", "submitter": "Feiyang Pan", "authors": "Feiyang Pan, Haoming Li, Xiang Ao, Wei Wang, Yanrong Kang, Ao Tan and\n  Qing He", "title": "GuideBoot: Guided Bootstrap for Deep Contextual Bandits", "comments": "WWW-2021", "journal-ref": null, "doi": "10.1145/3442381.3449987", "report-no": null, "categories": "cs.LG cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The exploration/exploitation (E&E) dilemma lies at the core of interactive\nsystems such as online advertising, for which contextual bandit algorithms have\nbeen proposed. Bayesian approaches provide guided exploration with principled\nuncertainty estimation, but the applicability is often limited due to\nover-simplified assumptions. Non-Bayesian bootstrap methods, on the other hand,\ncan apply to complex problems by using deep reward models, but lacks clear\nguidance to the exploration behavior. It still remains largely unsolved to\ndevelop a practical method for complex deep contextual bandits.\n  In this paper, we introduce Guided Bootstrap (GuideBoot for short), combining\nthe best of both worlds. GuideBoot provides explicit guidance to the\nexploration behavior by training multiple models over both real samples and\nnoisy samples with fake labels, where the noise is added according to the\npredictive uncertainty. The proposed method is efficient as it can make\ndecisions on-the-fly by utilizing only one randomly chosen model, but is also\neffective as we show that it can be viewed as a non-Bayesian approximation of\nThompson sampling. Moreover, we extend it to an online version that can learn\nsolely from streaming data, which is favored in real applications. Extensive\nexperiments on both synthetic task and large-scale advertising environments\nshow that GuideBoot achieves significant improvements against previous\nstate-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jul 2021 07:53:04 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Pan", "Feiyang", ""], ["Li", "Haoming", ""], ["Ao", "Xiang", ""], ["Wang", "Wei", ""], ["Kang", "Yanrong", ""], ["Tan", "Ao", ""], ["He", "Qing", ""]]}, {"id": "2107.08868", "submitter": "Niloofar Yazdani", "authors": "Niloofar Yazdani, Nikolaos Kouvelas, R Venkatesha Prasad, Daniel E.\n  Lucani", "title": "Energy Efficient Data Recovery from Corrupted LoRa Frames", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.IR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High frame-corruption is widely observed in Long Range Wide Area Networks\n(LoRaWAN) due to the coexistence with other networks in ISM bands and an\nAloha-like MAC layer. LoRa's Forward Error Correction (FEC) mechanism is often\ninsufficient to retrieve corrupted data. In fact, real-life measurements show\nthat at least one-fourth of received transmissions are corrupted. When more\nframes are dropped, LoRa nodes usually switch over to higher spreading factors\n(SF), thus increasing transmission times and increasing the required energy.\nThis paper introduces ReDCoS, a novel coding technique at the application layer\nthat improves recovery of corrupted LoRa frames, thus reducing the overall\ntransmission time and energy invested by LoRa nodes by several-fold. ReDCoS\nutilizes lightweight coding techniques to pre-encode the transmitted data.\nTherefore, the inbuilt Cyclic Redundancy Check (CRC) that follows is computed\nbased on an already encoded data. At the receiver, we use both the CRC and the\ncoded data to recover data from a corrupted frame beyond the built-in Error\nCorrecting Code (ECC). We compare the performance of ReDCoS to (I) the standard\nFEC of vanilla-LoRaWAN, and to (ii) RS coding applied as ECC to the data of\nLoRaWAN. The results indicated a 54x and 13.5x improvement of decoding ratio,\nrespectively, when 20 data symbols were sent. Furthermore, we evaluated ReDCoS\non-field using LoRa SX1261 transceivers showing that it outperformed RS-coding\nby factor of at least 2x (and up to 6x) in terms of the decoding ratio while\nconsuming 38.5% less energy per correctly received transmission.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 13:34:46 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Yazdani", "Niloofar", ""], ["Kouvelas", "Nikolaos", ""], ["Prasad", "R Venkatesha", ""], ["Lucani", "Daniel E.", ""]]}, {"id": "2107.08927", "submitter": "Farzad Pourkamali", "authors": "Farzad Pourkamali and Nicolas Macris", "title": "Mismatched Estimation of rank-one symmetric matrices under Gaussian\n  noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.IR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the estimation of an n-dimensional vector s from the noisy\nelement-wise measurements of $\\mathbf{s}\\mathbf{s}^T$, a generic problem that\narises in statistics and machine learning. We study a mismatched Bayesian\ninference setting, where some of the parameters are not known to the\nstatistician. We derive the full exact analytic expression of the asymptotic\nmean squared error (MSE) in the large system size limit for the particular case\nof Gaussian priors and additive noise. From our formulas, we see that\nestimation is still possible in the mismatched case; and also that the minimum\nMSE (MMSE) can be achieved if the statistician chooses suitable parameters. Our\ntechnique relies on the asymptotics of the spherical integrals and can be\napplied as long as the statistician chooses a rotationally invariant prior.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 14:40:22 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Pourkamali", "Farzad", ""], ["Macris", "Nicolas", ""]]}, {"id": "2107.08957", "submitter": "Xi Yang", "authors": "Xi Yang, Zehao Yu, Yi Guo, Jiang Bian and Yonghui Wu", "title": "Clinical Relation Extraction Using Transformer-based Models", "comments": "1 Figure; 36 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The newly emerged transformer technology has a tremendous impact on NLP\nresearch. In the general English domain, transformer-based models have achieved\nstate-of-the-art performances on various NLP benchmarks. In the clinical\ndomain, researchers also have investigated transformer models for clinical\napplications. The goal of this study is to systematically explore three widely\nused transformer-based models (i.e., BERT, RoBERTa, and XLNet) for clinical\nrelation extraction and develop an open-source package with clinical\npre-trained transformer-based models to facilitate information extraction in\nthe clinical domain. We developed a series of clinical RE models based on three\ntransformer architectures, namely BERT, RoBERTa, and XLNet. We evaluated these\nmodels using 2 publicly available datasets from 2018 MADE1.0 and 2018 n2c2\nchallenges. We compared two classification strategies (binary vs. multi-class\nclassification) and investigated two approaches to generate candidate relations\nin different experimental settings. In this study, we compared three\ntransformer-based (BERT, RoBERTa, and XLNet) models for relation extraction. We\ndemonstrated that the RoBERTa-clinical RE model achieved the best performance\non the 2018 MADE1.0 dataset with an F1-score of 0.8958. On the 2018 n2c2\ndataset, the XLNet-clinical model achieved the best F1-score of 0.9610. Our\nresults indicated that the binary classification strategy consistently\noutperformed the multi-class classification strategy for clinical relation\nextraction. Our methods and models are publicly available at\nhttps://github.com/uf-hobi-informatics-lab/ClinicalTransformerRelationExtraction.\nWe believe this work will improve current practice on clinical relation\nextraction and other related NLP tasks in the biomedical domain.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:15:51 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Yang", "Xi", ""], ["Yu", "Zehao", ""], ["Guo", "Yi", ""], ["Bian", "Jiang", ""], ["Wu", "Yonghui", ""]]}, {"id": "2107.08973", "submitter": "Shivangi Bithel", "authors": "Shivangi Bithel, Sumitra S Malagi", "title": "Unsupervised Identification of Relevant Prior Cases", "comments": "Code: https://github.com/shivangibithel/Information-Retrieval-CS6370", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Document retrieval has taken its role in almost all domains of knowledge\nunderstanding, including the legal domain. Precedent refers to a court decision\nthat is considered as authority for deciding subsequent cases involving\nidentical or similar facts or similar legal issues. In this work, we propose\ndifferent unsupervised approaches to solve the task of identifying relevant\nprecedents to a given query case. Our proposed approaches are using word\nembeddings like word2vec, doc2vec, and sent2vec, finding cosine similarity\nusing TF-IDF, retrieving relevant documents using BM25 scores, using the\npre-trained model and SBERT to find the most similar document, and using the\nproduct of BM25 and TF-IDF scores to find the most relevant document for a\ngiven query. We compared all the methods based on precision@10, recall@10, and\nMRR. Based on the comparative analysis, we found that the TF-IDF score\nmultiplied by the BM25 score gives the best result. In this paper, we have also\npresented the analysis that we did to improve the BM25 score.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 15:41:49 GMT"}], "update_date": "2021-07-20", "authors_parsed": [["Bithel", "Shivangi", ""], ["Malagi", "Sumitra S", ""]]}, {"id": "2107.09480", "submitter": "Giosu\\'e Lo Bosco", "authors": "Domenico Amato and Raffaele Giancarlo and Giosu\\`e Lo Bosco", "title": "Learned Sorted Table Search and Static Indexes in Small Space:\n  Methodological and Practical Insights via an Experimental Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB cs.DS cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sorted Table Search Procedures are the quintessential query-answering tool,\nstill very useful, e.g, Search Engines (Google Chrome). Speeding them up, in\nsmall additional space with respect to the table being searched into, is still\na quite significant achievement. Static Learned Indexes have been very\nsuccessful in achieving such a speed-up, but leave open a major question: To\nwhat extent one can enjoy the speed-up of Learned Indexes while using constant\nor nearly constant additional space. By generalizing the experimental\nmethodology of a recent benchmarking study on Learned Indexes, we shed light on\nthis question, by considering two scenarios. The first, quite elementary, i.e.,\ntextbook code, and the second using advanced Learned Indexing algorithms and\nthe supporting sophisticated software platforms. Although in both cases one\nwould expect a positive answer, its achievement is not as simple as it seems.\nIndeed, our extensive set of experiments reveal a complex relationship between\nquery time and model space. The findings regarding this relationship and the\ncorresponding quantitative estimates, across memory levels, can be of interest\nto algorithm designers and of use to practitioners as well. As an essential\npart of our research, we introduce two new models that are of interest in their\nown right. The first is a constant space model that can be seen as a\ngeneralization of $k$-ary search, while the second is a synoptic {\\bf RMI}, in\nwhich we can control model space usage.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jul 2021 16:06:55 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 13:56:52 GMT"}, {"version": "v3", "created": "Fri, 23 Jul 2021 13:18:02 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Amato", "Domenico", ""], ["Giancarlo", "Raffaele", ""], ["Bosco", "Giosu\u00e8 Lo", ""]]}, {"id": "2107.09558", "submitter": "Hieu Tran", "authors": "Hieu Tran, Son Nguyen, I-Ling Yen, Farokh Bastani", "title": "Into Summarization Techniques for IoT Data Discovery Routing", "comments": "10 pages, 8 figures", "journal-ref": "IEEE International Conference on Cloud Computing 2021 (IEEE CLOUD\n  2021)", "doi": null, "report-no": null, "categories": "cs.NI cs.DB cs.DC cs.IR cs.NE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider the IoT data discovery problem in very large and\ngrowing scale networks. Specifically, we investigate in depth the routing table\nsummarization techniques to support effective and space-efficient IoT data\ndiscovery routing. Novel summarization algorithms, including alphabetical\nbased, hash based, and meaning based summarization and their corresponding\ncoding schemes are proposed. The issue of potentially misleading routing due to\nsummarization is also investigated. Subsequently, we analyze the strategy of\nwhen to summarize in order to balance the tradeoff between the routing table\ncompression rate and the chance of causing misleading routing. For experimental\nstudy, we have collected 100K IoT data streams from various IoT databases as\nthe input dataset. Experimental results show that our summarization solution\ncan reduce the routing table size by 20 to 30 folds with 2-5% increase in\nlatency when compared with similar peer-to-peer discovery routing algorithms\nwithout summarization. Also, our approach outperforms DHT based approaches by 2\nto 6 folds in terms of latency and traffic.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jul 2021 15:22:16 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 14:52:47 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Tran", "Hieu", ""], ["Nguyen", "Son", ""], ["Yen", "I-Ling", ""], ["Bastani", "Farokh", ""]]}, {"id": "2107.09966", "submitter": "Muhammad Aslam Jarwar", "authors": "Muhammad Aslam Jarwar, Adriane Chapman, Mark Elliot, Fatemeh Raji", "title": "Provenance, Anonymisation and Data Environments: a Unifying Construction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Anonymisation Decision-making Framework (ADF) operationalizes the risk\nmanagement of data exchange between organizations, referred to as \"data\nenvironments\". The second edition of ADF has increased its emphasis on modeling\ndata flows, highlighting a potential new use of provenance information to\nsupport anonymisation decision-making. In this paper, we provide a use case\nthat showcases this functionality more. Based on this use case, we identify how\nprovenance information could be utilized within the ADF framework, and identify\na currently un-met requirement which is the modeling of \\textit{data\nenvironments}. We show how data environments can be implemented within the W3C\nPROV in four different ways. We analyze the costs and benefits of each\napproach, and consider another use case as a partial check for completeness. We\nthen summarize our findings and suggest ways forward.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 09:25:33 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Jarwar", "Muhammad Aslam", ""], ["Chapman", "Adriane", ""], ["Elliot", "Mark", ""], ["Raji", "Fatemeh", ""]]}, {"id": "2107.09980", "submitter": "Jannik Fischbach", "authors": "Jannik Fischbach, Tobias Springer, Julian Frattini, Henning Femmer,\n  Andreas Vogelsang, and Daniel Mendez", "title": "Fine-Grained Causality Extraction From Natural Language Requirements\n  Using Recursive Neural Tensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  [Context:] Causal relations (e.g., If A, then B) are prevalent in functional\nrequirements. For various applications of AI4RE, e.g., the automatic derivation\nof suitable test cases from requirements, automatically extracting such causal\nstatements are a basic necessity. [Problem:] We lack an approach that is able\nto extract causal relations from natural language requirements in fine-grained\nform. Specifically, existing approaches do not consider the combinatorics\nbetween causes and effects. They also do not allow to split causes and effects\ninto more granular text fragments (e.g., variable and condition), making the\nextracted relations unsuitable for automatic test case derivation. [Objective &\nContributions:] We address this research gap and make the following\ncontributions: First, we present the Causality Treebank, which is the first\ncorpus of fully labeled binary parse trees representing the composition of\n1,571 causal requirements. Second, we propose a fine-grained causality\nextractor based on Recursive Neural Tensor Networks. Our approach is capable of\nrecovering the composition of causal statements written in natural language and\nachieves a F1 score of 74 % in the evaluation on the Causality Treebank. Third,\nwe disclose our open data sets as well as our code to foster the discourse on\nthe automatic extraction of causality in the RE community.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 09:52:10 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 07:43:30 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Fischbach", "Jannik", ""], ["Springer", "Tobias", ""], ["Frattini", "Julian", ""], ["Femmer", "Henning", ""], ["Vogelsang", "Andreas", ""], ["Mendez", "Daniel", ""]]}, {"id": "2107.10023", "submitter": "Jannik Fischbach", "authors": "Noah Jadallah, Jannik Fischbach, Julian Frattini, and Andreas\n  Vogelsang", "title": "CATE: CAusality Tree Extractor from Natural Language Requirements", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal relations (If A, then B) are prevalent in requirements artifacts.\nAutomatically extracting causal relations from requirements holds great\npotential for various RE activities (e.g., automatic derivation of suitable\ntest cases). However, we lack an approach capable of extracting causal\nrelations from natural language with reasonable performance. In this paper, we\npresent our tool CATE (CAusality Tree Extractor), which is able to parse the\ncomposition of a causal relation as a tree structure. CATE does not only\nprovide an overview of causes and effects in a sentence, but also reveals their\nsemantic coherence by translating the causal relation into a binary tree. We\nencourage fellow researchers and practitioners to use CATE at\nhttps://causalitytreeextractor.com/\n", "versions": [{"version": "v1", "created": "Wed, 21 Jul 2021 11:37:31 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 07:36:56 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Jadallah", "Noah", ""], ["Fischbach", "Jannik", ""], ["Frattini", "Julian", ""], ["Vogelsang", "Andreas", ""]]}, {"id": "2107.10457", "submitter": "Hao Li", "authors": "Fan Wu, Min Gao, Junliang Yu, Zongwei Wang, Kecheng Liu and Xu Wange", "title": "Ready for Emerging Threats to Recommender Systems? A Graph\n  Convolution-based Generative Shilling Attack", "comments": "16 pages, 21 figures, Information Sciences - Journal - Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To explore the robustness of recommender systems, researchers have proposed\nvarious shilling attack models and analyzed their adverse effects. Primitive\nattacks are highly feasible but less effective due to simplistic handcrafted\nrules, while upgraded attacks are more powerful but costly and difficult to\ndeploy because they require more knowledge from recommendations. In this paper,\nwe explore a novel shilling attack called Graph cOnvolution-based generative\nshilling ATtack (GOAT) to balance the attacks' feasibility and effectiveness.\nGOAT adopts the primitive attacks' paradigm that assigns items for fake users\nby sampling and the upgraded attacks' paradigm that generates fake ratings by a\ndeep learning-based model. It deploys a generative adversarial network (GAN)\nthat learns the real rating distribution to generate fake ratings.\nAdditionally, the generator combines a tailored graph convolution structure\nthat leverages the correlations between co-rated items to smoothen the fake\nratings and enhance their authenticity. The extensive experiments on two public\ndatasets evaluate GOAT's performance from multiple perspectives. Our study of\nthe GOAT demonstrates technical feasibility for building a more powerful and\nintelligent attack model with a much-reduced cost, enables analysis the threat\nof such an attack and guides for investigating necessary prevention measures.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 05:02:59 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Wu", "Fan", ""], ["Gao", "Min", ""], ["Yu", "Junliang", ""], ["Wang", "Zongwei", ""], ["Liu", "Kecheng", ""], ["Wange", "Xu", ""]]}, {"id": "2107.10939", "submitter": "Ivan Vendrov", "authors": "Jonathan Stray, Ivan Vendrov, Jeremy Nixon, Steven Adler, Dylan\n  Hadfield-Menell", "title": "What are you optimizing for? Aligning Recommender Systems with Human\n  Values", "comments": "Originally presented at the ICML 2020 Participatory Approaches to\n  Machine Learning workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe cases where real recommender systems were modified in the service\nof various human values such as diversity, fairness, well-being, time well\nspent, and factual accuracy. From this we identify the current practice of\nvalues engineering: the creation of classifiers from human-created data with\nvalue-based labels. This has worked in practice for a variety of issues, but\nproblems are addressed one at a time, and users and other stakeholders have\nseldom been involved. Instead, we look to AI alignment work for approaches that\ncould learn complex values directly from stakeholders, and identify four major\ndirections: useful measures of alignment, participatory design and operation,\ninteractive value learning, and informed deliberative judgments.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jul 2021 21:52:43 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Stray", "Jonathan", ""], ["Vendrov", "Ivan", ""], ["Nixon", "Jeremy", ""], ["Adler", "Steven", ""], ["Hadfield-Menell", "Dylan", ""]]}, {"id": "2107.11250", "submitter": "Axel Marmoret", "authors": "Axel Marmoret, Nancy Bertin, Jeremy Cohen", "title": "Multi-Channel Automatic Music Transcription Using Tensor Algebra", "comments": "40 pages, 14 figues, 5 tables, code can be found at:\n  https://gitlab.inria.fr/amarmore/nonnegative-factorization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Music is an art, perceived in unique ways by every listener, coming from\nacoustic signals. In the meantime, standards as musical scores exist to\ndescribe it. Even if humans can make this transcription, it is costly in terms\nof time and efforts, even more with the explosion of information consecutively\nto the rise of the Internet. In that sense, researches are driven in the\ndirection of Automatic Music Transcription. While this task is considered\nsolved in the case of single notes, it is still open when notes superpose\nthemselves, forming chords. This report aims at developing some of the existing\ntechniques towards Music Transcription, particularly matrix factorization, and\nintroducing the concept of multi-channel automatic music transcription. This\nconcept will be explored with mathematical objects called tensors.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jul 2021 14:07:40 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Marmoret", "Axel", ""], ["Bertin", "Nancy", ""], ["Cohen", "Jeremy", ""]]}, {"id": "2107.11755", "submitter": "Damiano Spina", "authors": "Kevin Roitero and Michael Soprano and Beatrice Portelli and\n  Massimiliano De Luise and Damiano Spina and Vincenzo Della Mea and Giuseppe\n  Serra and Stefano Mizzaro and Gianluca Demartini", "title": "Can the Crowd Judge Truthfulness? A Longitudinal Study on Recent\n  Misinformation about COVID-19", "comments": "31 pages; Preprint of an article accepted in Personal and Ubiquitous\n  Computing (Special Issue on Intelligent Systems for Tackling Online Harms).\n  arXiv admin note: substantial text overlap with arXiv:2008.05701", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the misinformation problem has been addressed with a\ncrowdsourcing-based approach: to assess the truthfulness of a statement,\ninstead of relying on a few experts, a crowd of non-expert is exploited. We\nstudy whether crowdsourcing is an effective and reliable method to assess\ntruthfulness during a pandemic, targeting statements related to COVID-19, thus\naddressing (mis)information that is both related to a sensitive and personal\nissue and very recent as compared to when the judgment is done. In our\nexperiments, crowd workers are asked to assess the truthfulness of statements,\nand to provide evidence for the assessments. Besides showing that the crowd is\nable to accurately judge the truthfulness of the statements, we report results\non workers behavior, agreement among workers, effect of aggregation functions,\nof scales transformations, and of workers background and bias. We perform a\nlongitudinal study by re-launching the task multiple times with both novice and\nexperienced workers, deriving important insights on how the behavior and\nquality change over time. Our results show that: workers are able to detect and\nobjectively categorize online (mis)information related to COVID-19; both\ncrowdsourced and expert judgments can be transformed and aggregated to improve\nquality; worker background and other signals (e.g., source of information,\nbehavior) impact the quality of the data. The longitudinal study demonstrates\nthat the time-span has a major effect on the quality of the judgments, for both\nnovice and experienced workers. Finally, we provide an extensive failure\nanalysis of the statements misjudged by the crowd-workers.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 08:37:09 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Roitero", "Kevin", ""], ["Soprano", "Michael", ""], ["Portelli", "Beatrice", ""], ["De Luise", "Massimiliano", ""], ["Spina", "Damiano", ""], ["Della Mea", "Vincenzo", ""], ["Serra", "Giuseppe", ""], ["Mizzaro", "Stefano", ""], ["Demartini", "Gianluca", ""]]}, {"id": "2107.11803", "submitter": "Yashar Deldjoo", "authors": "Yashar Deldjoo, Markus Schedl, Peter Knees", "title": "Content-driven Music Recommendation: Evolution, State of the Art, and\n  Challenges", "comments": "35 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The music domain is among the most important ones for adopting recommender\nsystems technology. In contrast to most other recommendation domains, which\npredominantly rely on collaborative filtering (CF) techniques, music\nrecommenders have traditionally embraced content-based (CB) approaches. In the\npast years, music recommendation models that leverage collaborative and content\ndata -- which we refer to as content-driven models -- have been replacing pure\nCF or CB models.\n  In this survey, we review 47 articles on content-driven music recommendation.\nBased on a thorough literature analysis, we first propose an onion model\ncomprising five layers, each of which corresponds to a category of music\ncontent we identified: signal, embedded metadata, expert-generated content,\nuser-generated content, and derivative content. We provide a detailed\ncharacterization of each category along several dimensions. Second, we identify\nsix overarching challenges, according to which we organize our main discussion:\nincreasing recommendation diversity and novelty, providing transparency and\nexplanations, accomplishing context-awareness, recommending sequences of music,\nimproving scalability and efficiency, and alleviating cold start. Each article\naddressing one or more of these challenges is categorized according to the\ncontent layers of our onion model, the article's goal(s), and main\nmethodological choices. Furthermore, articles are discussed in temporal order\nto shed light on the evolution of content-driven music recommendation\nstrategies. Finally, we provide our personal selection of the persisting grand\nchallenges, which are still waiting to be solved in future research endeavors.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 13:41:47 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Deldjoo", "Yashar", ""], ["Schedl", "Markus", ""], ["Knees", "Peter", ""]]}, {"id": "2107.11879", "submitter": "Marco Valentino", "authors": "Marco Valentino, Mokanarangan Thayaparan, Deborah Ferreira, Andr\\'e\n  Freitas", "title": "Hybrid Autoregressive Solver for Scalable Abductive Natural Language\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regenerating natural language explanations for science questions is a\nchallenging task for evaluating complex multi-hop and abductive inference\ncapabilities. In this setting, Transformers trained on human-annotated\nexplanations achieve state-of-the-art performance when adopted as cross-encoder\narchitectures. However, while much attention has been devoted to the quality of\nthe constructed explanations, the problem of performing abductive inference at\nscale is still under-studied. As intrinsically not scalable, the cross-encoder\narchitectural paradigm is not suitable for efficient multi-hop inference on\nmassive facts banks. To maximise both accuracy and inference time, we propose a\nhybrid abductive solver that autoregressively combines a dense bi-encoder with\na sparse model of explanatory power, computed leveraging explicit patterns in\nthe explanations. Our experiments demonstrate that the proposed framework can\nachieve performance comparable with the state-of-the-art cross-encoder while\nbeing $\\approx 50$ times faster and scalable to corpora of millions of facts.\nMoreover, we study the impact of the hybridisation on semantic drift and\nscience question answering without additional training, showing that it boosts\nthe quality of the explanations and contributes to improved downstream\ninference performance.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jul 2021 19:29:53 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Valentino", "Marco", ""], ["Thayaparan", "Mokanarangan", ""], ["Ferreira", "Deborah", ""], ["Freitas", "Andr\u00e9", ""]]}, {"id": "2107.12024", "submitter": "Zhang Junlin", "authors": "Qingyun She, Zhiqiang Wang, Junlin Zhang", "title": "Leaf-FM: A Learnable Feature Generation Factorization Machine for\n  Click-Through Rate Prediction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Click-through rate (CTR) prediction plays important role in personalized\nadvertising and recommender systems. Though many models have been proposed such\nas FM, FFM and DeepFM in recent years, feature engineering is still a very\nimportant way to improve the model performance in many applications because\nusing raw features can rarely lead to optimal results. For example, the\ncontinuous features are usually transformed to the power forms by adding a new\nfeature to allow it to easily form non-linear functions of the feature.\nHowever, this kind of feature engineering heavily relies on peoples experience\nand it is both time consuming and labor consuming. On the other side, concise\nCTR model with both fast online serving speed and good model performance is\ncritical for many real life applications. In this paper, we propose LeafFM\nmodel based on FM to generate new features from the original feature embedding\nby learning the transformation functions automatically. We also design three\nconcrete Leaf-FM models according to the different strategies of combing the\noriginal and the generated features. Extensive experiments are conducted on\nthree real-world datasets and the results show Leaf-FM model outperforms\nstandard FMs by a large margin. Compared with FFMs, Leaf-FM can achieve\nsignificantly better performance with much less parameters. In Avazu and\nMalware dataset, add version Leaf-FM achieves comparable performance with some\ndeep learning based models such as DNN and AutoInt. As an improved FM model,\nLeaf-FM has the same computation complexity with FM in online serving phase and\nit means Leaf-FM is applicable in many industry applications because of its\nbetter performance and high computation efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 08:29:18 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["She", "Qingyun", ""], ["Wang", "Zhiqiang", ""], ["Zhang", "Junlin", ""]]}, {"id": "2107.12025", "submitter": "Zhang Junlin", "authors": "Zhiqiang Wang, Qingyun She, PengTao Zhang, Junlin Zhang", "title": "ContextNet: A Click-Through Rate Prediction Framework Using Contextual\n  information to Refine Feature Embedding", "comments": "arXiv admin note: text overlap with arXiv:2102.07619", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Click-through rate (CTR) estimation is a fundamental task in personalized\nadvertising and recommender systems and it's important for ranking models to\neffectively capture complex high-order features.Inspired by the success of ELMO\nand Bert in NLP field, which dynamically refine word embedding according to the\ncontext sentence information where the word appears, we think it's also\nimportant to dynamically refine each feature's embedding layer by layer\naccording to the context information contained in input instance in CTR\nestimation tasks. We can effectively capture the useful feature interactions\nfor each feature in this way. In this paper, We propose a novel CTR Framework\nnamed ContextNet that implicitly models high-order feature interactions by\ndynamically refining each feature's embedding according to the input context.\nSpecifically, ContextNet consists of two key components: contextual embedding\nmodule and ContextNet block. Contextual embedding module aggregates contextual\ninformation for each feature from input instance and ContextNet block maintains\neach feature's embedding layer by layer and dynamically refines its\nrepresentation by merging contextual high-order interaction information into\nfeature embedding. To make the framework specific, we also propose two\nmodels(ContextNet-PFFN and ContextNet-SFFN) under this framework by introducing\nlinear contextual embedding network and two non-linear mapping sub-network in\nContextNet block. We conduct extensive experiments on four real-world datasets\nand the experiment results demonstrate that our proposed ContextNet-PFFN and\nContextNet-SFFN model outperform state-of-the-art models such as DeepFM and\nxDeepFM significantly.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 08:29:40 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Wang", "Zhiqiang", ""], ["She", "Qingyun", ""], ["Zhang", "PengTao", ""], ["Zhang", "Junlin", ""]]}, {"id": "2107.12079", "submitter": "Andrea Galassi", "authors": "Bettina Fazzinga, Andrea Galassi, Paolo Torroni", "title": "An Argumentative Dialogue System for COVID-19 Vaccine Information", "comments": "20 pages, 2 figures, currently under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Dialogue systems are widely used in AI to support timely and interactive\ncommunication with users. We propose a general-purpose dialogue system\narchitecture that leverages computational argumentation and state-of-the-art\nlanguage technologies. We illustrate and evaluate the system using a COVID-19\nvaccine information case study.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 09:58:39 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Fazzinga", "Bettina", ""], ["Galassi", "Andrea", ""], ["Torroni", "Paolo", ""]]}, {"id": "2107.12360", "submitter": "Deepak Uniyal", "authors": "Deepak Uniyal, Amit Agarwal", "title": "IRLCov19: A Large COVID-19 Multilingual Twitter Dataset of Indian\n  Regional Languages", "comments": "Accepted for presentation at the workshop SoGood 2021, held in\n  conjunction with ECML PKDD 2021, in September 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Emerged in Wuhan city of China in December 2019, COVID-19 continues to spread\nrapidly across the world despite authorities having made available a number of\nvaccines. While the coronavirus has been around for a significant period of\ntime, people and authorities still feel the need for awareness due to the\nmutating nature of the virus and therefore varying symptoms and prevention\nstrategies. People and authorities resort to social media platforms the most to\nshare awareness information and voice out their opinions due to their massive\noutreach in spreading the word in practically no time. People use a number of\nlanguages to communicate over social media platforms based on their\nfamiliarity, language outreach, and availability on social media platforms. The\nentire world has been hit by the coronavirus and India is the second worst-hit\ncountry in terms of the number of active coronavirus cases. India, being a\nmultilingual country, offers a great opportunity to study the outreach of\nvarious languages that have been actively used across social media platforms.\nIn this study, we aim to study the dataset related to COVID-19 collected in the\nperiod between February 2020 to July 2020 specifically for regional languages\nin India. This could be helpful for the Government of India, various state\ngovernments, NGOs, researchers, and policymakers in studying different issues\nrelated to the pandemic. We found that English has been the mode of\ncommunication in over 64% of tweets while as many as twelve regional languages\nin India account for approximately 4.77% of tweets.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 17:54:05 GMT"}], "update_date": "2021-07-27", "authors_parsed": [["Uniyal", "Deepak", ""], ["Agarwal", "Amit", ""]]}, {"id": "2107.12565", "submitter": "Juan Banda", "authors": "Luis Alberto Robles Hernandez, Tiffany J. Callahan, Juan M. Banda", "title": "A Biomedically oriented automatically annotated Twitter COVID-19 Dataset", "comments": "8 Pages, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The use of social media data, like Twitter, for biomedical research has been\ngradually increasing over the years. With the COVID-19 pandemic, researchers\nhave turned to more nontraditional sources of clinical data to characterize the\ndisease in near real-time, study the societal implications of interventions, as\nwell as the sequelae that recovered COVID-19 cases present (Long-COVID).\nHowever, manually curated social media datasets are difficult to come by due to\nthe expensive costs of manual annotation and the efforts needed to identify the\ncorrect texts. When datasets are available, they are usually very small and\ntheir annotations do not generalize well over time or to larger sets of\ndocuments. As part of the 2021 Biomedical Linked Annotation Hackathon, we\nrelease our dataset of over 120 million automatically annotated tweets for\nbiomedical research purposes. Incorporating best practices, we identify tweets\nwith potentially high clinical relevance. We evaluated our work by comparing\nseveral SpaCy-based annotation frameworks against a manually annotated\ngold-standard dataset. Selecting the best method to use for automatic\nannotation, we then annotated 120 million tweets and released them publicly for\nfuture downstream usage within the biomedical domain.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 02:58:34 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Hernandez", "Luis Alberto Robles", ""], ["Callahan", "Tiffany J.", ""], ["Banda", "Juan M.", ""]]}, {"id": "2107.12677", "submitter": "\\'Angel Gonz\\'alez-Prieto Dr.", "authors": "Jes\\'us Bobadilla, Fernando Ortega, Abraham Guti\\'errez, \\'Angel\n  Gonz\\'alez-Prieto", "title": "Deep Variational Models for Collaborative Filtering-based Recommender\n  Systems", "comments": "14 pages, 8 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning provides accurate collaborative filtering models to improve\nrecommender system results. Deep matrix factorization and their related\ncollaborative neural networks are the state-of-art in the field; nevertheless,\nboth models lack the necessary stochasticity to create the robust, continuous,\nand structured latent spaces that variational autoencoders exhibit. On the\nother hand, data augmentation through variational autoencoder does not provide\naccurate results in the collaborative filtering field due to the high sparsity\nof recommender systems. Our proposed models apply the variational concept to\ninject stochasticity in the latent space of the deep architecture, introducing\nthe variational technique in the neural collaborative filtering field. This\nmethod does not depend on the particular model used to generate the latent\nrepresentation. In this way, this approach can be applied as a plugin to any\ncurrent and future specific models. The proposed models have been tested using\nfour representative open datasets, three different quality measures, and\nstate-of-art baselines. The results show the superiority of the proposed\napproach in scenarios where the variational enrichment exceeds the injected\nnoise effect. Additionally, a framework is provided to enable the\nreproducibility of the conducted experiments.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 08:59:39 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Bobadilla", "Jes\u00fas", ""], ["Ortega", "Fernando", ""], ["Guti\u00e9rrez", "Abraham", ""], ["Gonz\u00e1lez-Prieto", "\u00c1ngel", ""]]}, {"id": "2107.13031", "submitter": "Martin Andrews", "authors": "Vivek Kalyan and Sam Witteveen and Martin Andrews", "title": "Red Dragon AI at TextGraphs 2021 Shared Task: Multi-Hop Inference\n  Explanation Regeneration by Matching Expert Ratings", "comments": "Accepted paper for TextGraphs-15 workshop at NAACL 2021. (5 pages\n  including references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Creating explanations for answers to science questions is a challenging task\nthat requires multi-hop inference over a large set of fact sentences. This\nyear, to refocus the Textgraphs Shared Task on the problem of gathering\nrelevant statements (rather than solely finding a single 'correct path'), the\nWorldTree dataset was augmented with expert ratings of 'relevance' of\nstatements to each overall explanation. Our system, which achieved second place\non the Shared Task leaderboard, combines initial statement retrieval; language\nmodels trained to predict the relevance scores; and ensembling of a number of\nthe resulting rankings. Our code implementation is made available at\nhttps://github.com/mdda/worldtree_corpus/tree/textgraphs_2021\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 18:29:51 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Kalyan", "Vivek", ""], ["Witteveen", "Sam", ""], ["Andrews", "Martin", ""]]}, {"id": "2107.13045", "submitter": "Alexander Dallmann", "authors": "Alexander Dallmann, Daniel Zoller, Andreas Hotho", "title": "A Case Study on Sampling Strategies for Evaluating Neural Sequential\n  Item Recommendation Models", "comments": null, "journal-ref": null, "doi": "10.1145/3460231.3475943", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At the present time, sequential item recommendation models are compared by\ncalculating metrics on a small item subset (target set) to speed up\ncomputation. The target set contains the relevant item and a set of negative\nitems that are sampled from the full item set. Two well-known strategies to\nsample negative items are uniform random sampling and sampling by popularity to\nbetter approximate the item frequency distribution in the dataset. Most\nrecently published papers on sequential item recommendation rely on sampling by\npopularity to compare the evaluated models. However, recent work has already\nshown that an evaluation with uniform random sampling may not be consistent\nwith the full ranking, that is, the model ranking obtained by evaluating a\nmetric using the full item set as target set, which raises the question whether\nthe ranking obtained by sampling by popularity is equal to the full ranking. In\nthis work, we re-evaluate current state-of-the-art sequential recommender\nmodels from the point of view, whether these sampling strategies have an impact\non the final ranking of the models. We therefore train four recently proposed\nsequential recommendation models on five widely known datasets. For each\ndataset and model, we employ three evaluation strategies. First, we compute the\nfull model ranking. Then we evaluate all models on a target set sampled by the\ntwo different sampling strategies, uniform random sampling and sampling by\npopularity with the commonly used target set size of 100, compute the model\nranking for each strategy and compare them with each other. Additionally, we\nvary the size of the sampled target set. Overall, we find that both sampling\nstrategies can produce inconsistent rankings compared with the full ranking of\nthe models. Furthermore, both sampling by popularity and uniform random\nsampling do not consistently produce the same ranking ...\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 19:06:03 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Dallmann", "Alexander", ""], ["Zoller", "Daniel", ""], ["Hotho", "Andreas", ""]]}, {"id": "2107.13052", "submitter": "Dantong Zhu", "authors": "Dantong Zhu, Minjia Zhang", "title": "Understanding and Generalizing Monotonic Proximity Graphs for\n  Approximate Nearest Neighbor Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph-based algorithms have shown great empirical potential for the\napproximate nearest neighbor (ANN) search problem. Currently, graph-based ANN\nsearch algorithms are designed mainly using heuristics, whereas theoretical\nanalysis of such algorithms is quite lacking. In this paper, we study a\nfundamental model of proximity graphs used in graph-based ANN search, called\nMonotonic Relative Neighborhood Graph (MRNG), from a theoretical perspective.\nWe use mathematical proofs to explain why proximity graphs that are built based\non MRNG tend to have good searching performance. We also run experiments on\nMRNG and graphs generalizing MRNG to obtain a deeper understanding of the\nmodel. Our experiments give guidance on how to approximate and generalize MRNG\nto build proximity graphs on a large scale. In addition, we discover and study\na hidden structure of MRNG called conflicting nodes, and we give theoretical\nevidence how conflicting nodes could be used to improve ANN search methods that\nare based on MRNG.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 19:37:31 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Zhu", "Dantong", ""], ["Zhang", "Minjia", ""]]}, {"id": "2107.13078", "submitter": "Muhammad Ammad-Ud-Din Ph.D.", "authors": "Farwa K. Khan, Adrian Flanagan, Kuan E. Tan, Zareen Alamgir, Muhammad\n  Ammad-Ud-Din", "title": "A Payload Optimization Method for Federated Recommender Systems", "comments": "15 pages, 3 figures, 4 tables", "journal-ref": "Fifteenth ACM Conference on Recommender Systems (RecSys 2021),\n  September 27-October 1, 2021, Amsterdam, Netherlands. ACM, New York, NY, USA", "doi": "10.1145/3460231.3474257", "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We introduce the payload optimization method for federated recommender\nsystems (FRS). In federated learning (FL), the global model payload that is\nmoved between the server and users depends on the number of items to recommend.\nThe model payload grows when there is an increasing number of items. This\nbecomes challenging for an FRS if it is running in production mode. To tackle\nthe payload challenge, we formulated a multi-arm bandit solution that selected\npart of the global model and transmitted it to all users. The selection process\nwas guided by a novel reward function suitable for FL systems. So far as we are\naware, this is the first optimization method that seeks to address item\ndependent payloads. The method was evaluated using three benchmark\nrecommendation datasets. The empirical validation confirmed that the proposed\nmethod outperforms the simpler methods that do not benefit from the bandits for\nthe purpose of item selection. In addition, we have demonstrated the usefulness\nof our proposed method by rigorously evaluating the effects of a payload\nreduction on the recommendation performance degradation. Our method achieved up\nto a 90\\% reduction in model payload, yielding only a $\\sim$4\\% - 8\\% loss in\nthe recommendation performance for highly sparse datasets\n", "versions": [{"version": "v1", "created": "Tue, 27 Jul 2021 20:44:30 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Khan", "Farwa K.", ""], ["Flanagan", "Adrian", ""], ["Tan", "Kuan E.", ""], ["Alamgir", "Zareen", ""], ["Ammad-Ud-Din", "Muhammad", ""]]}, {"id": "2107.13327", "submitter": "Giuseppe Di Benedetto", "authors": "Oriol Barbany Mayor, Vito Bellini, Alexander Buchholz, Giuseppe Di\n  Benedetto, Diego Marco Granziol, Matteo Ruffini, Yannik Stein", "title": "Ranker-agnostic Contextual Position Bias Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning-to-rank (LTR) algorithms are ubiquitous and necessary to explore the\nextensive catalogs of media providers. To avoid the user examining all the\nresults, its preferences are used to provide a subset of relatively small size.\nThe user preferences can be inferred from the interactions with the presented\ncontent if explicit ratings are unavailable. However, directly using implicit\nfeedback can lead to learning wrong relevance models and is known as biased\nLTR. The mismatch between implicit feedback and true relevances is due to\nvarious nuisances, with position bias one of the most relevant. Position bias\nmodels consider that the lack of interaction with a presented item is not only\nattributed to the item being irrelevant but because the item was not examined.\nThis paper introduces a method for modeling the probability of an item being\nseen in different contexts, e.g., for different users, with a single estimator.\nOur suggested method, denoted as contextual (EM)-based regression, is\nranker-agnostic and able to correctly learn the latent examination\nprobabilities while only using implicit feedback. Our empirical results\nindicate that the method introduced in this paper outperforms other existing\nposition bias estimators in terms of relative error when the examination\nprobability varies across queries. Moreover, the estimated values provide a\nranking performance boost when used to debias the implicit ranking data even if\nthere is no context dependency on the examination probabilities.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 12:50:21 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Mayor", "Oriol Barbany", ""], ["Bellini", "Vito", ""], ["Buchholz", "Alexander", ""], ["Di Benedetto", "Giuseppe", ""], ["Granziol", "Diego Marco", ""], ["Ruffini", "Matteo", ""], ["Stein", "Yannik", ""]]}, {"id": "2107.13472", "submitter": "Vito Walter Anelli Dr.", "authors": "Vito Walter Anelli, Alejandro Bellog\\'in, Tommaso Di Noia, Claudio\n  Pomo", "title": "Reenvisioning Collaborative Filtering vs Matrix Factorization", "comments": "Preprint, Accepted for publication at ACM RecSys 2021,9 pages", "journal-ref": null, "doi": "10.1145/3460231.3475944", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering models based on matrix factorization and learned\nsimilarities using Artificial Neural Networks (ANNs) have gained significant\nattention in recent years. This is, in part, because ANNs have demonstrated\ngood results in a wide variety of recommendation tasks. The introduction of\nANNs within the recommendation ecosystem has been recently questioned, raising\nseveral comparisons in terms of efficiency and effectiveness. One aspect most\nof these comparisons have in common is their focus on accuracy, neglecting\nother evaluation dimensions important for the recommendation, such as novelty,\ndiversity, or accounting for biases. We replicate experiments from three papers\nthat compare Neural Collaborative Filtering (NCF) and Matrix Factorization\n(MF), to extend the analysis to other evaluation dimensions. Our contribution\nshows that the experiments are entirely reproducible, and we extend the study\nincluding other accuracy metrics and two statistical hypothesis tests. We\ninvestigated the Diversity and Novelty of the recommendations, showing that MF\nprovides a better accuracy also on the long tail, although NCF provides a\nbetter item coverage and more diversified recommendations. We discuss the bias\neffect generated by the tested methods. They show a relatively small bias, but\nother recommendation baselines, with competitive accuracy performance,\nconsistently show to be less affected by this issue. This is the first work, to\nthe best of our knowledge, where several evaluation dimensions have been\nexplored for an array of SOTA algorithms covering recent adaptations of ANNs\nand MF. Hence, we show the potential these techniques may have on\nbeyond-accuracy evaluation while analyzing the effect on reproducibility these\ncomplementary dimensions may spark. Available at\ngithub.com/sisinflab/Reenvisioning-the-comparison-between-Neural-Collaborative-Filtering-and-Matrix-Factorization\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 16:29:38 GMT"}], "update_date": "2021-07-29", "authors_parsed": [["Anelli", "Vito Walter", ""], ["Bellog\u00edn", "Alejandro", ""], ["Di Noia", "Tommaso", ""], ["Pomo", "Claudio", ""]]}, {"id": "2107.13602", "submitter": "Barlas Oguz", "authors": "Barlas O\\u{g}uz, Kushal Lakhotia, Anchit Gupta, Patrick Lewis,\n  Vladimir Karpukhin, Aleksandra Piktus, Xilun Chen, Sebastian Riedel, Wen-tau\n  Yih, Sonal Gupta, Yashar Mehdad", "title": "Domain-matched Pre-training Tasks for Dense Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pre-training on larger datasets with ever increasing model size is now a\nproven recipe for increased performance across almost all NLP tasks. A notable\nexception is information retrieval, where additional pre-training has so far\nfailed to produce convincing results. We show that, with the right pre-training\nsetup, this barrier can be overcome. We demonstrate this by pre-training large\nbi-encoder models on 1) a recently released set of 65 million synthetically\ngenerated questions, and 2) 200 million post-comment pairs from a preexisting\ndataset of Reddit conversations made available by pushshift.io. We evaluate on\na set of information retrieval and dialogue retrieval benchmarks, showing\nsubstantial improvements over supervised baselines.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 19:13:00 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["O\u011fuz", "Barlas", ""], ["Lakhotia", "Kushal", ""], ["Gupta", "Anchit", ""], ["Lewis", "Patrick", ""], ["Karpukhin", "Vladimir", ""], ["Piktus", "Aleksandra", ""], ["Chen", "Xilun", ""], ["Riedel", "Sebastian", ""], ["Yih", "Wen-tau", ""], ["Gupta", "Sonal", ""], ["Mehdad", "Yashar", ""]]}, {"id": "2107.13617", "submitter": "Carlos Lordelo", "authors": "Carlos Lordelo, Emmanouil Benetos, Simon Dixon and Sven Ahlb\\\"ack", "title": "Pitch-Informed Instrument Assignment Using a Deep Convolutional Network\n  with Multiple Kernel Shapes", "comments": "4 figures, 4 tables and 7 pages. Accepted for publication at ISMIR\n  Conference 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG cs.NE eess.AS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper proposes a deep convolutional neural network for performing\nnote-level instrument assignment. Given a polyphonic multi-instrumental music\nsignal along with its ground truth or predicted notes, the objective is to\nassign an instrumental source for each note. This problem is addressed as a\npitch-informed classification task where each note is analysed individually. We\nalso propose to utilise several kernel shapes in the convolutional layers in\norder to facilitate learning of efficient timbre-discriminative feature maps.\nExperiments on the MusicNet dataset using 7 instrument classes show that our\napproach is able to achieve an average F-score of 0.904 when the original\nmulti-pitch annotations are used as the pitch information for the system, and\nthat it also excels if the note information is provided using third-party\nmulti-pitch estimation algorithms. We also include ablation studies\ninvestigating the effects of the use of multiple kernel shapes and comparing\ndifferent input representations for the audio and the note-related information.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 19:48:09 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Lordelo", "Carlos", ""], ["Benetos", "Emmanouil", ""], ["Dixon", "Simon", ""], ["Ahlb\u00e4ck", "Sven", ""]]}, {"id": "2107.13637", "submitter": "Peter Van Der Putten", "authors": "Manolis Fragkiadakis and Peter van der Putten", "title": "Sign and Search: Sign Search Functionality for Sign Language Lexica", "comments": "Accepted for the 1st International Workshop on Automatic Translation\n  for Signed and Spoken Languages (ATS4SSL), August 20, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.MM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sign language lexica are a useful resource for researchers and people\nlearning sign languages. Current implementations allow a user to search a sign\neither by its gloss or by selecting its primary features such as handshape and\nlocation. This study focuses on exploring a reverse search functionality where\na user can sign a query sign in front of a webcam and retrieve a set of\nmatching signs. By extracting different body joints combinations (upper body,\ndominant hand's arm and wrist) using the pose estimation framework OpenPose, we\ncompare four techniques (PCA, UMAP, DTW and Euclidean distance) as distance\nmetrics between 20 query signs, each performed by eight participants on a 1200\nsign lexicon. The results show that UMAP and DTW can predict a matching sign\nwith an 80\\% and 71\\% accuracy respectively at the top-20 retrieved signs using\nthe movement of the dominant hand arm. Using DTW and adding more sign instances\nfrom other participants in the lexicon, the accuracy can be raised to 90\\% at\nthe top-10 ranking. Our results suggest that our methodology can be used with\nno training in any sign language lexicon regardless of its size.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jul 2021 20:48:53 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Fragkiadakis", "Manolis", ""], ["van der Putten", "Peter", ""]]}, {"id": "2107.13751", "submitter": "Zhizhong Chen", "authors": "Zhizhong Chen, Carsten Eickhoff", "title": "The Cross-Lingual Arabic Information REtrieval (CLAIRE) System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite advances in neural machine translation, cross-lingual retrieval tasks\nin which queries and documents live in different natural language spaces remain\nchallenging. Although neural translation models may provide an intuitive\napproach to tackle the cross-lingual problem, their resource-consuming training\nand advanced model structures may complicate the overall retrieval pipeline and\nreduce users engagement. In this paper, we build our end-to-end Cross-Lingual\nArabic Information REtrieval (CLAIRE) system based on the cross-lingual word\nembedding where searchers are assumed to have a passable passive understanding\nof Arabic and various supporting information in English is provided to aid\nretrieval experience. The proposed system has three major advantages: (1) The\nusage of English-Arabic word embedding simplifies the overall pipeline and\navoids the potential mistakes caused by machine translation. (2) Our CLAIRE\nsystem can incorporate arbitrary word embedding-based neural retrieval models\nwithout structural modification. (3) Early empirical results on an Arabic news\ncollection show promising performance.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 05:28:00 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chen", "Zhizhong", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "2107.13752", "submitter": "Zhizhong Chen", "authors": "Zhizhong Chen, Carsten Eickhoff", "title": "ExpertRank: A Multi-level Coarse-grained Expert-based Listwise Ranking\n  Loss", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of information retrieval is to recommend a list of document\ncandidates that are most relevant to a given query. Listwise learning trains\nneural retrieval models by comparing various candidates simultaneously on a\nlarge scale, offering much more competitive performance than pairwise and\npointwise schemes. Existing listwise ranking losses treat the candidate\ndocument list as a whole unit without further inspection. Some candidates with\nmoderate semantic prominence may be ignored by the noisy similarity signals or\novershadowed by a few especially pronounced candidates. As a result, existing\nranking losses fail to exploit the full potential of neural retrieval models.\nTo address these concerns, we apply the classic pooling technique to conduct\nmulti-level coarse graining and propose ExpertRank, a novel expert-based\nlistwise ranking loss. The proposed scheme has three major advantages: (1)\nExpertRank introduces the profound physics concept of coarse graining to\ninformation retrieval by selecting prominent candidates at various local levels\nbased on model prediction and inter-document comparison. (2) ExpertRank applies\nthe mixture of experts (MoE) technique to combine different experts effectively\nby extending the traditional ListNet. (3) Compared to other existing listwise\nlearning approaches, ExpertRank produces much more reliable and competitive\nperformance for various neural retrieval models with different complexities,\nfrom traditional models, such as KNRM, ConvKNRM, MatchPyramid, to sophisticated\nBERT/ALBERT-based retrieval models.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 05:29:05 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Chen", "Zhizhong", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "2107.13876", "submitter": "Felice Antonio Merra", "authors": "Vito Walter Anelli, Yashar Deldjoo, Tommaso Di Noia, Felice Antonio\n  Merra", "title": "Understanding the Effects of Adversarial Personalized Ranking\n  Optimization Method on Recommendation Quality", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommender systems (RSs) employ user-item feedback, e.g., ratings, to match\ncustomers to personalized lists of products. Approaches to top-k recommendation\nmainly rely on Learning-To-Rank algorithms and, among them, the most widely\nadopted is Bayesian Personalized Ranking (BPR), which bases on a pair-wise\noptimization approach. Recently, BPR has been found vulnerable against\nadversarial perturbations of its model parameters. Adversarial Personalized\nRanking (APR) mitigates this issue by robustifying BPR via an adversarial\ntraining procedure. The empirical improvements of APR's accuracy performance on\nBPR have led to its wide use in several recommender models. However, a key\noverlooked aspect has been the beyond-accuracy performance of APR, i.e.,\nnovelty, coverage, and amplification of popularity bias, considering that\nrecent results suggest that BPR, the building block of APR, is sensitive to the\nintensification of biases and reduction of recommendation novelty. In this\nwork, we model the learning characteristics of the BPR and APR optimization\nframeworks to give mathematical evidence that, when the feedback data have a\ntailed distribution, APR amplifies the popularity bias more than BPR due to an\nunbalanced number of received positive updates from short-head items. Using\nmatrix factorization (MF), we empirically validate the theoretical results by\nperforming preliminary experiments on two public datasets to compare BPR-MF and\nAPR-MF performance on accuracy and beyond-accuracy metrics. The experimental\nresults consistently show the degradation of novelty and coverage measures and\na worrying amplification of bias.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 10:22:20 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Anelli", "Vito Walter", ""], ["Deldjoo", "Yashar", ""], ["Di Noia", "Tommaso", ""], ["Merra", "Felice Antonio", ""]]}, {"id": "2107.13943", "submitter": "Adam Elwood", "authors": "Adam Elwood, Alberto Gasparin, Alessandro Rozza", "title": "Ranking Micro-Influencers: a Novel Multi-Task Learning and Interpretable\n  Framework", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the rise in use of social media to promote branded products, the demand\nfor effective influencer marketing has increased. Brands are looking for\nimproved ways to identify valuable influencers among a vast catalogue; this is\neven more challenging with \"micro-influencers\", which are more affordable than\nmainstream ones but difficult to discover. In this paper, we propose a novel\nmulti-task learning framework to improve the state of the art in\nmicro-influencer ranking based on multimedia content. Moreover, since the\nvisual congruence between a brand and influencer has been shown to be good\nmeasure of compatibility, we provide an effective visual method for\ninterpreting our models' decisions, which can also be used to inform brands'\nmedia strategies. We compare with the current state-of-the-art on a recently\nconstructed public dataset and we show significant improvement both in terms of\naccuracy and model complexity. The techniques for ranking and interpretation\npresented in this work can be generalised to arbitrary multimedia ranking tasks\nthat have datasets with a similar structure.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jul 2021 13:04:25 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Elwood", "Adam", ""], ["Gasparin", "Alberto", ""], ["Rozza", "Alessandro", ""]]}, {"id": "2107.13983", "submitter": "Etienne-Victor Depasquale", "authors": "Etienne-Victor Depasquale, Humaira Abdul Salam, Franco Davoli", "title": "PAD: a graphical and numerical enhancement of structural coding to\n  facilitate thematic analysis of a literature corpus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We suggest an enhancement to structural coding through the use of (a)\ncausally bound codes, (b) basic constructs of graph theory and (c) statistics.\nAs is the norm with structural coding, the codes are collected into categories.\nThe categories are represented by nodes (graph theory). The causality is\nillustrated through links (graph theory) between the nodes and the entire set\nof linked nodes is collected into a single directed acyclic graph. The number\nof occurrences of the nodes and the links provide the input required to analyze\nrelative frequency of occurrence, as well as opening a scope for further\nstatistical analysis. While our raw data was a corpus of literature from a\nspecific discipline, this enhancement is accessible to any qualitative analysis\nthat recognizes causality in its structural codes.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jul 2021 07:59:34 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Depasquale", "Etienne-Victor", ""], ["Salam", "Humaira Abdul", ""], ["Davoli", "Franco", ""]]}, {"id": "2107.14041", "submitter": "Pankajeshwara Nand Sharma", "authors": "Fabrice Lartigou, Michael Govorov, Tofiga Aisake and Pankajeshwara N.\n  Sharma", "title": "Interactive GIS Web-Atlas for Twelve Pacific Islands Countries", "comments": "Project report article to Intergraph. (GeoMedia Research Laboratory\n  Initiative)", "journal-ref": null, "doi": "10.13140/RG.2.2.18883.73765", "report-no": null, "categories": "cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This article deals with the development of an interactive up-to-date Pacific\nIslands Web GIS Atlas. It focuses on the compilation of spatial data from the\ntwelve member countries of the University of the South Pacific (Cook Islands,\nFiji Islands, Kiribati Islands, Marshall Islands, Nauru, Niue, Tonga, Tuvalu,\nTokelau, Solomon Islands, Vanuatu, and Western Samoa). A previous bitmap web\nAtlas was created in 1996, and was a pilot activity investigating the potential\nfor using Geographical Information Systems (GIS) in the South Pacific. The\nobjective of the new atlas is to provide sets of spatial and attributive data\nand maps for use of educators, students, researchers, policy makers and other\nrelevant user groups and the public. GIS is a highly flexible and dynamic\ntechnology that allows the construction and analysis of maps and data sets from\na variety of sources and formats. Nowadays, GIS application has moved from\nlocal and client-server applications to a three-tier architecture: Client (Web\nBrowser) -- Application Web Map Server -- Spatial Data Warehouses. The\nobjective of this project is to produce an Atlas that will include interactive\nmaps and data on an Application Web Map Server. Intergraph products such as\nGeoMedia Professional, Web Map and Web Publisher have been selected for the web\natlas production and design. In an interactive environment, an atlas will be\ncomposed from a series of maps and data profiles, which will be based on legend\nentries, queries, hot spots and cartographic tools. Only the first stage of\ndevelopment of the atlas and related technological solutions are outlined in\nthis article.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jul 2021 13:41:01 GMT"}], "update_date": "2021-07-30", "authors_parsed": [["Lartigou", "Fabrice", ""], ["Govorov", "Michael", ""], ["Aisake", "Tofiga", ""], ["Sharma", "Pankajeshwara N.", ""]]}]