[{"id": "2105.00150", "submitter": "Yuta Koreeda", "authors": "Yuta Koreeda, Christopher D. Manning", "title": "Capturing Logical Structure of Visually Structured Documents with\n  Multimodal Transition Parser", "comments": "7 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While many NLP papers, tasks and pipelines assume raw, clean texts, many\ntexts we encounter in the wild are not so clean, with many of them being\nvisually structured documents (VSDs) such as PDFs. Conventional preprocessing\ntools for VSDs mainly focused on word segmentation and coarse layout analysis,\nwhile fine-grained logical structure analysis (such as identifying paragraph\nboundaries and their hierarchies) of VSDs is underexplored. To that end, we\nproposed to formulate the task as prediction of transition labels between text\nfragments that maps the fragments to a tree, and developed a feature-based\nmachine learning system that fuses visual, textual and semantic cues. Our\nsystem significantly outperformed baselines in identifying different structures\nin VSDs. For example, our system obtained a paragraph boundary detection F1\nscore of 0.951 which is significantly better than a popular PDF-to-text tool\nwith a F1 score of 0.739.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 02:33:50 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Koreeda", "Yuta", ""], ["Manning", "Christopher D.", ""]]}, {"id": "2105.00199", "submitter": "Shahab Saquib Sohail PhD", "authors": "Shahab Saquib Sohail, Jamshed Siddiqui, Rashid Ali, S. Hamid Hasan,\n  M.Afshar Alam", "title": "Can we aggregate human intelligence? an approach for human centric\n  aggregation using ordered weighted averaging operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The primary objective of this paper is to present an approach for recommender\nsystems that can assimilate ranking to the voters or rankers so that\nrecommendation can be made by giving priority to experts suggestion over usual\nrecommendation. To accomplish this, we have incorporated the concept of\nhuman-centric aggregation via Ordered Weighted Aggregation (OWA). Here, we are\nadvocating ranked recommendation where rankers are assigned weights according\nto their place in the ranking. Further, the recommendation process which is\npresented here for the recommendation of books to university students exploits\nlinguistic data summaries and Ordered Weighted Aggregation (OWA) technique. In\nthe suggested approach, the weights are assigned in a way that it associates\nhigher weights to best ranked university. The approach has been evaluated over\neight different parameters. The superiority of the proposed approach is evident\nfrom the evaluation results. We claim that proposed scheme saves storage spaces\nrequired in traditional recommender systems as well as it does not need users\nprior preferences and hence produce a solution for cold start problem. This\nenvisaged that the proposed scheme can be very useful in decision making\nproblems, especially for recommender systems. In addition, it emphasizes on how\nhuman-centric aggregation can be useful in recommendation researches, and also\nit gives a new direction about how various human specific tasks can be\nnumerically aggregated.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 09:05:59 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Sohail", "Shahab Saquib", ""], ["Siddiqui", "Jamshed", ""], ["Ali", "Rashid", ""], ["Hasan", "S. Hamid", ""], ["Alam", "M. Afshar", ""]]}, {"id": "2105.00309", "submitter": "Arman Malekzadeh Lashkaryani", "authors": "Arman Malekzadeh and Amin Gheibi and Ali Mohades", "title": "PREDICT: Persian Reverse Dictionary", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Finding the appropriate words to convey concepts (i.e., lexical access) is\nessential for effective communication. Reverse dictionaries fulfill this need\nby helping individuals to find the word(s) which could relate to a specific\nconcept or idea. To the best of our knowledge, this resource has not been\navailable for the Persian language. In this paper, we compare four different\narchitectures for implementing a Persian reverse dictionary (PREDICT).\n  We evaluate our models using (phrase,word) tuples extracted from the only\nPersian dictionaries available online, namely Amid, Moein, and Dehkhoda where\nthe phrase describes the word. Given the phrase, a model suggests the most\nrelevant word(s) in terms of the ability to convey the concept. The model is\nconsidered to perform well if the correct word is one of its top suggestions.\n  Our experiments show that a model consisting of Long Short-Term Memory (LSTM)\nunits enhanced by an additive attention mechanism is enough to produce\nsuggestions comparable to (or in some cases better than) the word in the\noriginal dictionary. The study also reveals that the model sometimes produces\nthe synonyms of the word as its output which led us to introduce a new metric\nfor the evaluation of reverse dictionaries called Synonym Accuracy accounting\nfor the percentage of times the event of producing the word or a synonym of it\noccurs. The assessment of the best model using this new metric also indicates\nthat at least 62% of the times, it produces an accurate result within the top\n100 suggestions.\n", "versions": [{"version": "v1", "created": "Sat, 1 May 2021 17:37:01 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Malekzadeh", "Arman", ""], ["Gheibi", "Amin", ""], ["Mohades", "Ali", ""]]}, {"id": "2105.00522", "submitter": "Zhiwei Liu", "authors": "Zhiwei Liu, Ziwei Fan, Yu Wang, Philip S. Yu", "title": "Augmenting Sequential Recommendation with Pseudo-Prior Items via\n  Reversely Pre-training Transformer", "comments": "Accepted by SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3463036", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Sequential Recommendation characterizes the evolving patterns by modeling\nitem sequences chronologically. The essential target of it is to capture the\nitem transition correlations. The recent developments of transformer inspire\nthe community to design effective sequence encoders, \\textit{e.g.,} SASRec and\nBERT4Rec. However, we observe that these transformer-based models suffer from\nthe cold-start issue, \\textit{i.e.,} performing poorly for short sequences.\nTherefore, we propose to augment short sequences while still preserving\noriginal sequential correlations. We introduce a new framework for\n\\textbf{A}ugmenting \\textbf{S}equential \\textbf{Re}commendation with\n\\textbf{P}seudo-prior items~(ASReP). We firstly pre-train a transformer with\nsequences in a reverse direction to predict prior items. Then, we use this\ntransformer to generate fabricated historical items at the beginning of short\nsequences. Finally, we fine-tune the transformer using these augmented\nsequences from the time order to predict the next item. Experiments on two\nreal-world datasets verify the effectiveness of ASReP. The code is available on\n\\url{https://github.com/DyGRec/ASReP}.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 18:06:23 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Liu", "Zhiwei", ""], ["Fan", "Ziwei", ""], ["Wang", "Yu", ""], ["Yu", "Philip S.", ""]]}, {"id": "2105.00574", "submitter": "Workneh Y. Ayele", "authors": "W. Y. Ayele", "title": "Adapting CRISP-DM for Idea Mining: A Data Mining Process for Generating\n  Ideas Using a Textual Dataset", "comments": "13 pages, 14 figures. International Journal of Advanced Computer\n  Science and Applications, 2020", "journal-ref": null, "doi": "10.14569/issn.2156-5570", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Data mining project managers can benefit from using standard data mining\nprocess models. The benefits of using standard process models for data mining,\nsuch as the de facto and the most popular, Cross-Industry-Standard-Process\nmodel for Data Mining (CRISP-DM) are reduced cost and time. Also, standard\nmodels facilitate knowledge transfer, reuse of best practices, and minimize\nknowledge requirements. On the other hand, to unlock the potential of\never-growing textual data such as publications, patents, social media data, and\ndocuments of various forms, digital innovation is increasingly needed.\nFurthermore, the introduction of cutting-edge machine learning tools and\ntechniques enable the elicitation of ideas. The processing of unstructured\ntextual data to generate new and useful ideas is referred to as idea mining.\nExisting literature about idea mining merely overlooks the utilization of\nstandard data mining process models. Therefore, the purpose of this paper is to\npropose a reusable model to generate ideas, CRISP-DM, for Idea Mining\n(CRISP-IM). The design and development of the CRISP-IM are done following the\ndesign science approach. The CRISP-IM facilitates idea generation, through the\nuse of Dynamic Topic Modeling (DTM), unsupervised machine learning, and\nsubsequent statistical analysis on a dataset of scholarly articles. The adapted\nCRISP-IM can be used to guide the process of identifying trends using scholarly\nliterature datasets or temporally organized patent or any other textual dataset\nof any domain to elicit ideas. The ex-post evaluation of the CRISP-IM is left\nfor future study.\n", "versions": [{"version": "v1", "created": "Sun, 2 May 2021 23:24:25 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Ayele", "W. Y.", ""]]}, {"id": "2105.00627", "submitter": "Zheng Gao", "authors": "Zheng Gao, Chun Guo, Xiaozhong Liu", "title": "Improving Community Detection Performance in Heterogeneous Music Network\n  by Learning Edge-type Usefulness Distribution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music is becoming an essential part of daily life. There is an urgent need to\ndevelop recommendation systems to assist people targeting better songs with\nfewer efforts. As the interactions between users and songs naturally construct\na complex network, community detection approaches can be applied to reveal\nusers' potential interests on songs by grouping relevant users \\& songs to the\nsame community. However, as the types of interaction are diverse, it challenges\nconventional community detection methods which are designed originally for\nhomogeneous networks. Although there are existing works focusing on\nheterogeneous community detection, they are mostly task-driven approaches and\nnot feasible for music retrieval and recommendation directly. In this paper, we\npropose a genetic based approach to learn an edge-type usefulness distribution\n(ETUD) for all edge-types in heterogeneous music networks. ETUD can be regarded\nas a linear function to project all edges to the same latent space and make\nthem comparable. Therefore a heterogeneous network can be converted to a\nhomogeneous one where those conventional methods are eligible to use. We\nvalidate the proposed model on a heterogeneous music network constructed from\nan online music streaming service. Results show that for conventional methods,\nETUD can help to detect communities significantly improving music\nrecommendation accuracy while reducing user searching cost simultaneously.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 04:43:25 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Gao", "Zheng", ""], ["Guo", "Chun", ""], ["Liu", "Xiaozhong", ""]]}, {"id": "2105.00650", "submitter": "Jaydip Sen", "authors": "Gourab Nath and Jaydip Sen", "title": "An Algorithm for Recommending Groceries Based on an Item Ranking Method", "comments": "This is the accepted version of our paper in the IEEE International\n  Conference on Intelligent Technologies (IEEE CONIT), June 25-27, 2021, which\n  will be conducted in Belgaum, INDIA. The paper consists of 7 pages, 1 figure\n  and 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research proposes a new recommender system algorithm for online grocery\nshopping. The algorithm is based on the perspective that, since the grocery\nitems are usually bought in bulk, a grocery recommender system should be\ncapable of recommending the items in bulk. The algorithm figures out the\npossible dishes a user may cook based on the items added to the basket and\nrecommends the ingredients accordingly. Our algorithm does not depend on the\nuser ratings. Customers usually do not have the patience to rate the groceries\nthey purchase. Therefore, algorithms that are not dependent on user ratings\nneed to be designed. Instead of using a brute force search, this algorithm\nlimits the search space to a set of only a few probably food categories. Each\nfood category consists of several food subcategories. For example, \"fried rice\"\nand \"biryani\" are food subcategories that belong to the food category \"rice\".\nFor each food category, items are ranked according to how well they can\ndifferentiate a food subcategory. To each food subcategory in the activated\nsearch space, this algorithm attaches a score. The score is calculated based on\nthe rank of the items added to the basket. Once the score exceeds a threshold\nvalue, its corresponding subcategory gets activated. The algorithm then uses a\nbasket-to-recipe similarity measure to identify the best recipe matches within\nthe activated subcategories only. This reduces the search space to a great\nextent. We may argue that this algorithm is similar to the content-based\nrecommender system in some sense, but it does not suffer from the limitations\nlike limited content, over-specialization, or the new user problem.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 06:52:33 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Nath", "Gourab", ""], ["Sen", "Jaydip", ""]]}, {"id": "2105.00666", "submitter": "Soyeong Jeong", "authors": "Soyeong Jeong, Jinheon Baek, ChaeHun Park, Jong C. Park", "title": "Unsupervised Document Expansion for Information Retrieval with\n  Stochastic Text Generation", "comments": "SDP@NAACL2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the challenges in information retrieval (IR) is the vocabulary\nmismatch problem, which happens when the terms between queries and documents\nare lexically different but semantically similar. While recent work has\nproposed to expand the queries or documents by enriching their representations\nwith additional relevant terms to address this challenge, they usually require\na large volume of query-document pairs to train an expansion model. In this\npaper, we propose an Unsupervised Document Expansion with Generation (UDEG)\nframework with a pre-trained language model, which generates diverse\nsupplementary sentences for the original document without using labels on\nquery-document pairs for training. For generating sentences, we further\nstochastically perturb their embeddings to generate more diverse sentences for\ndocument expansion. We validate our framework on two standard IR benchmark\ndatasets. The results show that our framework significantly outperforms\nrelevant expansion baselines for IR.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 07:52:05 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Jeong", "Soyeong", ""], ["Baek", "Jinheon", ""], ["Park", "ChaeHun", ""], ["Park", "Jong C.", ""]]}, {"id": "2105.00674", "submitter": "Heiko Paulheim", "authors": "Michael Matthias Voit and Heiko Paulheim", "title": "Bias in Knowledge Graphs -- an Empirical Study with Movie Recommendation\n  and Different Language Editions of DBpedia", "comments": "Accepted for publication at 3rd Conference on Language, Data and\n  Knowledge (LDK 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Public knowledge graphs such as DBpedia and Wikidata have been recognized as\ninteresting sources of background knowledge to build content-based recommender\nsystems. They can be used to add information about the items to be recommended\nand links between those. While quite a few approaches for exploiting knowledge\ngraphs have been proposed, most of them aim at optimizing the recommendation\nstrategy while using a fixed knowledge graph. In this paper, we take a\ndifferent approach, i.e., we fix the recommendation strategy and observe\nchanges when using different underlying knowledge graphs. Particularly, we use\ndifferent language editions of DBpedia. We show that the usage of different\nknowledge graphs does not only lead to differently biased recommender systems,\nbut also to recommender systems that differ in performance for particular\nfields of recommendations.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 08:07:30 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Voit", "Michael Matthias", ""], ["Paulheim", "Heiko", ""]]}, {"id": "2105.00774", "submitter": "Diego Antognini", "authors": "Diego Antognini and Boi Faltings", "title": "Fast Multi-Step Critiquing for VAE-based Recommender Systems", "comments": "Accepted at RecSys 2021. 19 pages, 7 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent studies have shown that providing personalized explanations alongside\nrecommendations increases trust and perceived quality. Furthermore, it gives\nusers an opportunity to refine the recommendations by critiquing parts of the\nexplanations. On one hand, current recommender systems model the\nrecommendation, explanation, and critiquing objectives jointly, but this\ncreates an inherent trade-off between their respective performance. On the\nother hand, although recent latent linear critiquing approaches are built upon\nan existing recommender system, they suffer from computational inefficiency at\ninference due to the objective optimized at each conversation's turn. We\naddress these deficiencies with M&Ms-VAE, a novel variational autoencoder for\nrecommendation and explanation that is based on multimodal modeling\nassumptions. We train the model under a weak supervision scheme to simulate\nboth fully and partially observed variables. Then, we leverage the\ngeneralization ability of a trained M&Ms-VAE model to embed the user preference\nand the critique separately. Our work's most important innovation is our\ncritiquing module, which is built upon and trained in a self-supervised manner\nwith a simple ranking objective. Experiments on four real-world datasets\ndemonstrate that among state-of-the-art models, our system is the first to\ndominate or match the performance in terms of recommendation, explanation, and\nmulti-step critiquing. Moreover, M&Ms-VAE processes the critiques up to 25.6x\nfaster than the best baselines. Finally, we show that our model infers coherent\njoint and cross generation, even under weak supervision, thanks to our\nmultimodal-based modeling and training scheme.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 12:26:09 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 18:22:16 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Antognini", "Diego", ""], ["Faltings", "Boi", ""]]}, {"id": "2105.00813", "submitter": "Preslav Nakov", "authors": "Anton Chernyavskiy, Dmitry Ilvovsky, Preslav Nakov", "title": "Transformers: \"The End of History\" for NLP?", "comments": "Transformers, NLP, BERT, RoBERTa, XLNet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in neural architectures, such as the Transformer, coupled\nwith the emergence of large-scale pre-trained models such as BERT, have\nrevolutionized the field of Natural Language Processing (NLP), pushing the\nstate-of-the-art for a number of NLP tasks. A rich family of variations of\nthese models has been proposed, such as RoBERTa, ALBERT, and XLNet, but\nfundamentally, they all remain limited in their ability to model certain kinds\nof information, and they cannot cope with certain information sources, which\nwas easy for pre-existing models. Thus, here we aim to shed some light on some\nimportant theoretical limitations of pre-trained BERT-style models that are\ninherent in the general Transformer architecture. First, we demonstrate in\npractice on two general types of tasks -- segmentation and segment labeling --\nand four datasets that these limitations are indeed harmful and that addressing\nthem, even in some very simple and naive ways, can yield sizable improvements\nover vanilla RoBERTa and XLNet. Then, we offer a more general discussion on\ndesiderata for future additions to the Transformer architecture that would\nincrease its expressiveness, which we hope could help in the design of the next\ngeneration of deep NLP architectures.\n", "versions": [{"version": "v1", "created": "Fri, 9 Apr 2021 08:29:42 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Chernyavskiy", "Anton", ""], ["Ilvovsky", "Dmitry", ""], ["Nakov", "Preslav", ""]]}, {"id": "2105.00822", "submitter": "Xiaocong Chen", "authors": "Xiaocong Chen, Lina Yao, Xianzhi Wang, Aixin Sun, Wenjie Zhang and\n  Quan Z. Sheng", "title": "Generative Adversarial Reward Learning for Generalized Behavior Tendency\n  Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in reinforcement learning have inspired increasing interest\nin learning user modeling adaptively through dynamic interactions, e.g., in\nreinforcement learning based recommender systems. Reward function is crucial\nfor most of reinforcement learning applications as it can provide the guideline\nabout the optimization. However, current reinforcement-learning-based methods\nrely on manually-defined reward functions, which cannot adapt to dynamic and\nnoisy environments. Besides, they generally use task-specific reward functions\nthat sacrifice generalization ability. We propose a generative inverse\nreinforcement learning for user behavioral preference modelling, to address the\nabove issues. Instead of using predefined reward functions, our model can\nautomatically learn the rewards from user's actions based on discriminative\nactor-critic network and Wasserstein GAN. Our model provides a general way of\ncharacterizing and explaining underlying behavioral tendencies, and our\nexperiments show our method outperforms state-of-the-art methods in a variety\nof scenarios, namely traffic signal control, online recommender systems, and\nscanpath prediction.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 13:14:25 GMT"}, {"version": "v2", "created": "Wed, 5 May 2021 13:01:28 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Chen", "Xiaocong", ""], ["Yao", "Lina", ""], ["Wang", "Xianzhi", ""], ["Sun", "Aixin", ""], ["Zhang", "Wenjie", ""], ["Sheng", "Quan Z.", ""]]}, {"id": "2105.00824", "submitter": "Diyah Puspitaningrum", "authors": "Diyah Puspitaningrum", "title": "A Survey of Recent Abstract Summarization Techniques", "comments": "6 tables, 1 figure, additionals (data):\n  https://drive.google.com/drive/folders/152XMSCU3ctshB2BvzEQHY0vo6xkZ9gOl?usp=sharing\n  ,\n  https://drive.google.com/drive/folders/1z09D2-4arE6aOQZxgxcwMVF41xMH4EEH?usp=sharing.\n  Awaiting at https://www.springer.com/gp/book/9789811621017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper surveys several recent abstract summarization methods: T5,\nPegasus, and ProphetNet. We implement the systems in two languages: English and\nIndonesian languages. We investigate the impact of pre-training models (one T5,\nthree Pegasuses, three ProphetNets) on several Wikipedia datasets in English\nand Indonesian language and compare the results to the Wikipedia systems'\nsummaries. The T5-Large, the Pegasus-XSum, and the ProphetNet-CNNDM provide the\nbest summarization. The most significant factors that influence ROUGE\nperformance are coverage, density, and compression. The higher the scores, the\nbetter the summary. Other factors that influence the ROUGE scores are the\npre-training goal, the dataset's characteristics, the dataset used for testing\nthe pre-trained model, and the cross-lingual function. Several suggestions to\nimprove this paper's limitation are: 1) assure that the dataset used for the\npre-training model must sufficiently large, contains adequate instances for\nhandling cross-lingual purpose; 2) Advanced process (finetuning) shall be\nreasonable. We recommend using the large dataset consists of comprehensive\ncoverage of topics from many languages before implementing advanced processes\nsuch as the train-infer-train procedure to the zero-shot translation in the\ntraining stage of the pre-training model.\n", "versions": [{"version": "v1", "created": "Thu, 15 Apr 2021 20:01:34 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Puspitaningrum", "Diyah", ""]]}, {"id": "2105.00826", "submitter": "Preslav Nakov", "authors": "Anton Chernyavskiy, Dmitry Ilvovsky, Preslav Nakov", "title": "WhatTheWikiFact: Fact-Checking Claims Against Wikipedia", "comments": "fact-checking, veracity, factuality, stance detection, evidence\n  retrieval, fake news, FEVER, Wikipedia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of Internet has made it a major source of information.\nUnfortunately, not all information online is true, and thus a number of\nfact-checking initiatives have been launched, both manual and automatic. Here,\nwe present our contribution in this regard: WhatTheWikiFact, a system for\nautomatic claim verification using Wikipedia. The system predicts the veracity\nof an input claim, and it further shows the evidence it has retrieved as part\nof the verification process. It shows confidence scores and a list of relevant\nWikipedia articles, together with detailed information about each article,\nincluding the phrase used to retrieve it, the most relevant sentences it\ncontains, and their stances with respect to the input claim, with associated\nprobabilities.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 12:23:56 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Chernyavskiy", "Anton", ""], ["Ilvovsky", "Dmitry", ""], ["Nakov", "Preslav", ""]]}, {"id": "2105.00855", "submitter": "Harrie Oosterhuis", "authors": "Harrie Oosterhuis", "title": "Computationally Efficient Optimization of Plackett-Luce Ranking Models\n  for Relevance and Fairness", "comments": "full paper in the SIGIR 2021 conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent work has proposed stochastic Plackett-Luce (PL) ranking models as a\nrobust choice for optimizing relevance and fairness metrics. Unlike their\ndeterministic counterparts that require heuristic optimization algorithms, PL\nmodels are fully differentiable. Theoretically, they can be used to optimize\nranking metrics via stochastic gradient descent. However, in practice, the\ncomputation of the gradient is infeasible because it requires one to iterate\nover all possible permutations of items. Consequently, actual applications rely\non approximating the gradient via sampling techniques. In this paper, we\nintroduce a novel algorithm: PL-Rank, that estimates the gradient of a PL\nranking model w.r.t. both relevance and fairness metrics. Unlike existing\napproaches that are based on policy gradients, PL-Rank makes use of the\nspecific structure of PL models and ranking metrics. Our experimental analysis\nshows that PL-Rank has a greater sample-efficiency and is computationally less\ncostly than existing policy gradients, resulting in faster convergence at\nhigher performance. PL-Rank further enables the industry to apply PL models for\nmore relevant and fairer real-world ranking systems.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 13:41:46 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 12:44:42 GMT"}], "update_date": "2021-07-08", "authors_parsed": [["Oosterhuis", "Harrie", ""]]}, {"id": "2105.00867", "submitter": "Mingming Guo", "authors": "Mingming Guo, Nian Yan, Xiquan Cui, Simon Hughes, Khalifeh Al Jadda", "title": "Online Product Feature Recommendations with Interpretable Machine\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Product feature recommendations are critical for online customers to purchase\nthe right products based on the right features. For a customer, selecting the\nproduct that has the best trade-off between price and functionality is a\ntime-consuming step in an online shopping experience, and customers can be\noverwhelmed by the available choices. However, determining the set of product\nfeatures that most differentiate a particular product is still an open question\nin online recommender systems. In this paper, we focus on using interpretable\nmachine learning methods to tackle this problem. First, we identify this unique\nproduct feature recommendation problem from a business perspective on a major\nUS e-commerce site. Second, we formulate the problem into a price-driven\nsupervised learning problem to discover the product features that could best\nexplain the price of a product in a given product category. We build machine\nlearning models with a model-agnostic method Shapley Values to understand the\nimportance of each feature, rank and recommend the most essential features.\nThird, we leverage human experts to evaluate its relevancy. The results show\nthat our method is superior to a strong baseline method based on customer\nbehavior and significantly boosts the coverage by 45%. Finally, our proposed\nmethod shows comparable conversion rate against the baseline in online A/B\ntests.\n", "versions": [{"version": "v1", "created": "Wed, 28 Apr 2021 16:40:51 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Guo", "Mingming", ""], ["Yan", "Nian", ""], ["Cui", "Xiquan", ""], ["Hughes", "Simon", ""], ["Jadda", "Khalifeh Al", ""]]}, {"id": "2105.00942", "submitter": "Eric Gaussier", "authors": "Thibaut Thonet, Yagmur Gizem Cinar, Eric Gaussier, Minghan Li,\n  Jean-Michel Renders", "title": "SmoothI: Smooth Rank Indicators for Differentiable IR Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information retrieval (IR) systems traditionally aim to maximize metrics\nbuilt on rankings, such as precision or NDCG. However, the\nnon-differentiability of the ranking operation prevents direct optimization of\nsuch metrics in state-of-the-art neural IR models, which rely entirely on the\nability to compute meaningful gradients. To address this shortcoming, we\npropose SmoothI, a smooth approximation of rank indicators that serves as a\nbasic building block to devise differentiable approximations of IR metrics. We\nfurther provide theoretical guarantees on SmoothI and derived approximations,\nshowing in particular that the approximation errors decrease exponentially with\nan inverse temperature-like hyperparameter that controls the quality of the\napproximations. Extensive experiments conducted on four standard\nlearning-to-rank datasets validate the efficacy of the listwise losses based on\nSmoothI, in comparison to previously proposed ones. Additional experiments with\na vanilla BERT ranking model on a text-based IR task also confirm the benefits\nof our listwise approach.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 15:16:58 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Thonet", "Thibaut", ""], ["Cinar", "Yagmur Gizem", ""], ["Gaussier", "Eric", ""], ["Li", "Minghan", ""], ["Renders", "Jean-Michel", ""]]}, {"id": "2105.00991", "submitter": "Yingwei Xin", "authors": "Yunwen Chen, Zuotao Liu, Daqi Ji, Yingwei Xin, Wenguang Wang, Lu Yao,\n  Yi Zou", "title": "Context-aware Ensemble of Multifaceted Factorization Models for\n  Recommendation Prediction in Social Networks", "comments": "KDD 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the solution of Shanda Innovations team to Task 1 of\nKDD-Cup 2012. A novel approach called Multifaceted Factorization Models is\nproposed to incorporate a great variety of features in social networks. Social\nrelationships and actions between users are integrated as implicit feedbacks to\nimprove the recommendation accuracy. Keywords, tags, profiles, time and some\nother features are also utilized for modeling user interests. In addition, user\nbehaviors are modeled from the durations of recommendation records. A\ncontext-aware ensemble framework is then applied to combine multiple predictors\nand produce final recommendation results. The proposed approach obtained\n0.43959 (public score) / 0.41874 (private score) on the testing dataset, which\nachieved the 2nd place in the KDD-Cup competition.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 16:42:50 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Chen", "Yunwen", ""], ["Liu", "Zuotao", ""], ["Ji", "Daqi", ""], ["Xin", "Yingwei", ""], ["Wang", "Wenguang", ""], ["Yao", "Lu", ""], ["Zou", "Yi", ""]]}, {"id": "2105.01004", "submitter": "Manjeet Dahiya", "authors": "Sanidhya Singal, Piyush Singh, Manjeet Dahiya", "title": "Automatic Collection Creation and Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a collection recommender system that can automatically create and\nrecommend collections of items at a user level. Unlike regular recommender\nsystems, which output top-N relevant items, a collection recommender system\noutputs collections of items such that the items in the collections are\nrelevant to a user, and the items within a collection follow a specific theme.\nOur system builds on top of the user-item representations learnt by item\nrecommender systems. We employ dimensionality reduction and clustering\ntechniques along with intuitive heuristics to create collections with their\nratings and titles.\n  We test these ideas in a real-world setting of music recommendation, within a\npopular music streaming service. We find that there is a 2.3x increase in\nrecommendation-driven consumption when recommending collections over items.\nFurther, it results in effective utilization of real estate and leads to\nrecommending a more and diverse set of items. To our knowledge, these are first\nof its kind experiments at such a large scale.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 16:51:21 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Singal", "Sanidhya", ""], ["Singh", "Piyush", ""], ["Dahiya", "Manjeet", ""]]}, {"id": "2105.01044", "submitter": "Eugene Yang", "authors": "Eugene Yang, Sean MacAvaney, David D. Lewis, Ophir Frieder", "title": "Goldilocks: Just-Right Tuning of BERT for Technology-Assisted Review", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Technology-assisted review (TAR) refers to iterative active learning\nworkflows for document review in high recall retrieval (HRR) tasks. TAR\nresearch and most commercial TAR software have applied linear models such as\nlogistic regression or support vector machines to lexical features.\nTransformer-based models with supervised tuning have been found to improve\neffectiveness on many text classification tasks, suggesting their use in TAR.\nWe indeed find that the pre-trained BERT model reduces review volume by 30% in\nTAR workflows simulated on the RCV1-v2 newswire collection. In contrast, we\nfind that linear models outperform BERT for simulated legal discovery topics on\nthe Jeb Bush e-mail collection. This suggests the match between transformer\npre-training corpora and the task domain is more important than generally\nappreciated. Additionally, we show that just-right language model fine-tuning\non the task collection before starting active learning is critical. Both too\nlittle or too much fine-tuning results in performance worse than that of linear\nmodels, even for RCV1-v2.\n", "versions": [{"version": "v1", "created": "Mon, 3 May 2021 17:41:18 GMT"}], "update_date": "2021-05-04", "authors_parsed": [["Yang", "Eugene", ""], ["MacAvaney", "Sean", ""], ["Lewis", "David D.", ""], ["Frieder", "Ophir", ""]]}, {"id": "2105.01064", "submitter": "Xiaocong Du", "authors": "Xiaocong Du, Bhargav Bhushanam, Jiecao Yu, Dhruv Choudhary, Tianxiang\n  Gao, Sherman Wong, Louis Feng, Jongsoo Park, Yu Cao, Arun Kejariwal", "title": "Alternate Model Growth and Pruning for Efficient Training of\n  Recommendation Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning recommendation systems at scale have provided remarkable gains\nthrough increasing model capacity (i.e. wider and deeper neural networks), but\nit comes at significant training cost and infrastructure cost. Model pruning is\nan effective technique to reduce computation overhead for deep neural networks\nby removing redundant parameters. However, modern recommendation systems are\nstill thirsty for model capacity due to the demand for handling big data. Thus,\npruning a recommendation model at scale results in a smaller model capacity and\nconsequently lower accuracy. To reduce computation cost without sacrificing\nmodel capacity, we propose a dynamic training scheme, namely alternate model\ngrowth and pruning, to alternatively construct and prune weights in the course\nof training. Our method leverages structured sparsification to reduce\ncomputational cost without hurting the model capacity at the end of offline\ntraining so that a full-size model is available in the recurring training stage\nto learn new data in real-time. To the best of our knowledge, this is the first\nwork to provide in-depth experiments and discussion of applying structural\ndynamics to recommendation systems at scale to reduce training cost. The\nproposed method is validated with an open-source deep-learning recommendation\nmodel (DLRM) and state-of-the-art industrial-scale production models.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 03:14:30 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Du", "Xiaocong", ""], ["Bhushanam", "Bhargav", ""], ["Yu", "Jiecao", ""], ["Choudhary", "Dhruv", ""], ["Gao", "Tianxiang", ""], ["Wong", "Sherman", ""], ["Feng", "Louis", ""], ["Park", "Jongsoo", ""], ["Cao", "Yu", ""], ["Kejariwal", "Arun", ""]]}, {"id": "2105.01331", "submitter": "Hasan Kemik", "authors": "Hasan Kemik, Nusret \\\"Ozate\\c{s}, Meysam Asgari-Chenaghlu, Erik\n  Cambria", "title": "BLM-17m: A Large-Scale Dataset for Black Lives Matter Topic Detection on\n  Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Protection of human rights is one of the most important problems of our\nworld. In this paper, our aim is to provide a dataset which covers one of the\nmost significant human rights contradiction in recent months affected the whole\nworld, George Floyd incident. We propose a labeled dataset for topic detection\nthat contains 17 million tweets. These Tweets are collected from 25 May 2020 to\n21 August 2020 that covers 89 days from start of this incident. We labeled the\ndataset by monitoring most trending news topics from global and local\nnewspapers. Apart from that, we present two baselines, TF-IDF and LDA. We\nevaluated the results of these two methods with three different k values for\nmetrics of precision, recall and f1-score. The collected dataset is available\nat https://github.com/MeysamAsgariC/BLMT.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 07:27:42 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Kemik", "Hasan", ""], ["\u00d6zate\u015f", "Nusret", ""], ["Asgari-Chenaghlu", "Meysam", ""], ["Cambria", "Erik", ""]]}, {"id": "2105.01541", "submitter": "Mingtian Gao", "authors": "Yichi Lu, Mingtian Gao, Ryosuke Saga", "title": "Apparel Recommender System based on Bilateral image shape features", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Probabilistic matrix factorization (PMF) is a well-known model of recommender\nsystems. With the development of image recognition technology, some PMF\nrecommender systems that combine images have emerged. Some of these systems use\nthe image shape features of the recommended products to achieve better results\ncompared to those of the traditional PMF. However, in the existing methods, no\nPMF recommender system can combine the image features of products previously\npurchased by customers and of recommended products. Thus, this study proposes a\nnovel probabilistic model that integrates double convolutional neural networks\n(CNNs) into PMF. For apparel goods, two trained CNNs from the image shape\nfeatures of users and items are combined, and the latent variables of users and\nitems are optimized based on the vectorized features of CNNs and ratings.\nExtensive experiments show that our model predicts outcome more accurately than\ndo other recommender models.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 14:48:38 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Lu", "Yichi", ""], ["Gao", "Mingtian", ""], ["Saga", "Ryosuke", ""]]}, {"id": "2105.01564", "submitter": "Haggai Roitman", "authors": "Yotam Eshel, Or Levi, Haggai Roitman, Alexander Nus", "title": "PreSizE: Predicting Size in E-Commerce using Transformers", "comments": "Accepted for publication in SIGIR'2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advances in the e-commerce fashion industry have led to an exploration\nof novel ways to enhance buyer experience via improved personalization.\nPredicting a proper size for an item to recommend is an important\npersonalization challenge, and is being studied in this work. Earlier works in\nthis field either focused on modeling explicit buyer fitment feedback or\nmodeling of only a single aspect of the problem (e.g., specific category,\nbrand, etc.). More recent works proposed richer models, either content-based or\nsequence-based, better accounting for content-based aspects of the problem or\nbetter modeling the buyer's online journey. However, both these approaches fail\nin certain scenarios: either when encountering unseen items (sequence-based\nmodels) or when encountering new users (content-based models).\n  To address the aforementioned gaps, we propose PreSizE - a novel deep\nlearning framework which utilizes Transformers for accurate size prediction.\nPreSizE models the effect of both content-based attributes, such as brand and\ncategory, and the buyer's purchase history on her size preferences. Using an\nextensive set of experiments on a large-scale e-commerce dataset, we\ndemonstrate that PreSizE is capable of achieving superior prediction\nperformance compared to previous state-of-the-art baselines. By encoding item\nattributes, PreSizE better handles cold-start cases with unseen items, and\ncases where buyers have little past purchase data. As a proof of concept, we\ndemonstrate that size predictions made by PreSizE can be effectively integrated\ninto an existing production recommender system yielding very effective features\nand significantly improving recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 15:23:59 GMT"}], "update_date": "2021-05-05", "authors_parsed": [["Eshel", "Yotam", ""], ["Levi", "Or", ""], ["Roitman", "Haggai", ""], ["Nus", "Alexander", ""]]}, {"id": "2105.01736", "submitter": "Fei Wang", "authors": "Fei Wang, Kexuan Sun, Muhao Chen, Jay Pujara, Pedro Szekely", "title": "Retrieving Complex Tables with Multi-Granular Graph Representation\n  Learning", "comments": "Accepted by SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462909", "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The task of natural language table retrieval (NLTR) seeks to retrieve\nsemantically relevant tables based on natural language queries. Existing\nlearning systems for this task often treat tables as plain text based on the\nassumption that tables are structured as dataframes. However, tables can have\ncomplex layouts which indicate diverse dependencies between subtable\nstructures, such as nested headers. As a result, queries may refer to different\nspans of relevant content that is distributed across these structures.\nMoreover, such systems fail to generalize to novel scenarios beyond those seen\nin the training set. Prior methods are still distant from a generalizable\nsolution to the NLTR problem, as they fall short in handling complex table\nlayouts or queries over multiple granularities. To address these issues, we\npropose Graph-based Table Retrieval (GTR), a generalizable NLTR framework with\nmulti-granular graph representation learning. In our framework, a table is\nfirst converted into a tabular graph, with cell nodes, row nodes and column\nnodes to capture content at different granularities. Then the tabular graph is\ninput to a Graph Transformer model that can capture both table cell content and\nthe layout structures. To enhance the robustness and generalizability of the\nmodel, we further incorporate a self-supervised pre-training task based on\ngraph-context matching. Experimental results on two benchmarks show that our\nmethod leads to significant improvements over the current state-of-the-art\nsystems. Further experiments demonstrate promising performance of our method on\ncross-dataset generalization, and enhanced capability of handling complex\ntables and fulfilling diverse query intents. Code and data are available at\nhttps://github.com/FeiWang96/GTR.\n", "versions": [{"version": "v1", "created": "Tue, 4 May 2021 20:19:03 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Wang", "Fei", ""], ["Sun", "Kexuan", ""], ["Chen", "Muhao", ""], ["Pujara", "Jay", ""], ["Szekely", "Pedro", ""]]}, {"id": "2105.02091", "submitter": "Avijit Ghosh", "authors": "Avijit Ghosh, Ritam Dutt, Christo Wilson", "title": "When Fair Ranking Meets Uncertain Inference", "comments": "Accepted as full paper at SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462850", "report-no": null, "categories": "cs.IR cs.CY cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing fair ranking systems, especially those designed to be\ndemographically fair, assume that accurate demographic information about\nindividuals is available to the ranking algorithm. In practice, however, this\nassumption may not hold -- in real-world contexts like ranking job applicants\nor credit seekers, social and legal barriers may prevent algorithm operators\nfrom collecting peoples' demographic information. In these cases, algorithm\noperators may attempt to infer peoples' demographics and then supply these\ninferences as inputs to the ranking algorithm.\n  In this study, we investigate how uncertainty and errors in demographic\ninference impact the fairness offered by fair ranking algorithms. Using\nsimulations and three case studies with real datasets, we show how demographic\ninferences drawn from real systems can lead to unfair rankings. Our results\nsuggest that developers should not use inferred demographic data as input to\nfair ranking algorithms, unless the inferences are extremely accurate.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 14:40:07 GMT"}], "update_date": "2021-05-06", "authors_parsed": [["Ghosh", "Avijit", ""], ["Dutt", "Ritam", ""], ["Wilson", "Christo", ""]]}, {"id": "2105.02192", "submitter": "Andreea-Maria Oncescu", "authors": "Andreea-Maria Oncescu, A. Sophia Koepke, Jo\\~ao F. Henriques, Zeynep\n  Akata, Samuel Albanie", "title": "Audio Retrieval with Natural Language Queries", "comments": "Accepted at INTERSPEECH 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SD eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the task of retrieving audio using free-form natural language\nqueries. To study this problem, which has received limited attention in the\nexisting literature, we introduce challenging new benchmarks for text-based\naudio retrieval using text annotations sourced from the Audiocaps and Clotho\ndatasets. We then employ these benchmarks to establish baselines for\ncross-modal audio retrieval, where we demonstrate the benefits of pre-training\non diverse audio tasks. We hope that our benchmarks will inspire further\nresearch into cross-modal text-based audio retrieval with free-form text\nqueries.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 17:04:56 GMT"}, {"version": "v2", "created": "Thu, 22 Jul 2021 15:56:19 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Oncescu", "Andreea-Maria", ""], ["Koepke", "A. Sophia", ""], ["Henriques", "Jo\u00e3o F.", ""], ["Akata", "Zeynep", ""], ["Albanie", "Samuel", ""]]}, {"id": "2105.02274", "submitter": "Donald Metzler", "authors": "Donald Metzler, Yi Tay, Dara Bahri, Marc Najork", "title": "Rethinking Search: Making Domain Experts out of Dilettantes", "comments": null, "journal-ref": "SIGIR Forum 55, 1, Article 13 (June 2021), 27 pages", "doi": "10.1145/3476415.3476428", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  When experiencing an information need, users want to engage with a domain\nexpert, but often turn to an information retrieval system, such as a search\nengine, instead. Classical information retrieval systems do not answer\ninformation needs directly, but instead provide references to (hopefully\nauthoritative) answers. Successful question answering systems offer a limited\ncorpus created on-demand by human experts, which is neither timely nor\nscalable. Pre-trained language models, by contrast, are capable of directly\ngenerating prose that may be responsive to an information need, but at present\nthey are dilettantes rather than domain experts -- they do not have a true\nunderstanding of the world, they are prone to hallucinating, and crucially they\nare incapable of justifying their utterances by referring to supporting\ndocuments in the corpus they were trained over. This paper examines how ideas\nfrom classical information retrieval and pre-trained language models can be\nsynthesized and evolved into systems that truly deliver on the promise of\ndomain expert advice.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 18:40:00 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 18:36:56 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Metzler", "Donald", ""], ["Tay", "Yi", ""], ["Bahri", "Dara", ""], ["Najork", "Marc", ""]]}, {"id": "2105.02354", "submitter": "Zhiyu Chen", "authors": "Zhiyu Chen, Shuo Zhang, Brian D. Davison", "title": "WTR: A Test Collection for Web Table Retrieval", "comments": "Accepted as a resource paper in SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3463260", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the development, characteristics and availability of a test\ncollection for the task of Web table retrieval, which uses a large-scale Web\nTable Corpora extracted from the Common Crawl. Since a Web table usually has\nrich context information such as the page title and surrounding paragraphs, we\nnot only provide relevance judgments of query-table pairs, but also the\nrelevance judgments of query-table context pairs with respect to a query, which\nare ignored by previous test collections. To facilitate future research with\nthis benchmark, we provide details about how the dataset is pre-processed and\nalso baseline results from both traditional and recently proposed table\nretrieval methods. Our experimental results show that proper usage of context\nlabels can benefit previous table retrieval methods.\n", "versions": [{"version": "v1", "created": "Wed, 5 May 2021 22:25:23 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Chen", "Zhiyu", ""], ["Zhang", "Shuo", ""], ["Davison", "Brian D.", ""]]}, {"id": "2105.02377", "submitter": "Ruohan Zhan", "authors": "Ruohan Zhan, Konstantina Christakopoulou, Ya Le, Jayden Ooi, Martin\n  Mladenov, Alex Beutel, Craig Boutilier, Ed H. Chi, Minmin Chen", "title": "Towards Content Provider Aware Recommender Systems: A Simulation Study\n  on the Interplay between User and Provider Utilities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing recommender systems focus primarily on matching users to\ncontent which maximizes user satisfaction on the platform. It is increasingly\nobvious, however, that content providers have a critical influence on user\nsatisfaction through content creation, largely determining the content pool\navailable for recommendation. A natural question thus arises: can we design\nrecommenders taking into account the long-term utility of both users and\ncontent providers? By doing so, we hope to sustain more providers and a more\ndiverse content pool for long-term user satisfaction. Understanding the full\nimpact of recommendations on both user and provider groups is challenging. This\npaper aims to serve as a research investigation of one approach toward building\na provider-aware recommender, and evaluating its impact in a simulated setup.\n  To characterize the user-recommender-provider interdependence, we complement\nuser modeling by formalizing provider dynamics as well. The resulting joint\ndynamical system gives rise to a weakly-coupled partially observable Markov\ndecision process driven by recommender actions and user feedback to providers.\nWe then build a REINFORCE recommender agent, coined EcoAgent, to optimize a\njoint objective of user utility and the counterfactual utility lift of the\nprovider associated with the recommended content, which we show to be\nequivalent to maximizing overall user utility and the utilities of all\nproviders on the platform under some mild assumptions. To evaluate our\napproach, we introduce a simulation environment capturing the key interactions\namong users, providers, and the recommender. We offer a number of simulated\nexperiments that shed light on both the benefits and the limitations of our\napproach. These results help understand how and when a provider-aware\nrecommender agent is of benefit in building multi-stakeholder recommender\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 00:02:58 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Zhan", "Ruohan", ""], ["Christakopoulou", "Konstantina", ""], ["Le", "Ya", ""], ["Ooi", "Jayden", ""], ["Mladenov", "Martin", ""], ["Beutel", "Alex", ""], ["Boutilier", "Craig", ""], ["Chi", "Ed H.", ""], ["Chen", "Minmin", ""]]}, {"id": "2105.02414", "submitter": "Mehul S. Raval", "authors": "Hiren Galiyawala, Mehul S Raval", "title": "Person Retrieval in Surveillance Using Textual Query: A Review", "comments": "45 pages, 17 figures, 6 Tables", "journal-ref": "Springer Multimedia Tools and Application, 2021", "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent advancement of research in biometrics, computer vision, and natural\nlanguage processing has discovered opportunities for person retrieval from\nsurveillance videos using textual query. The prime objective of a surveillance\nsystem is to locate a person using a description, e.g., a short woman with a\npink t-shirt and white skirt carrying a black purse. She has brown hair. Such a\ndescription contains attributes like gender, height, type of clothing, colour\nof clothing, hair colour, and accessories. Such attributes are formally known\nas soft biometrics. They help bridge the semantic gap between a human\ndescription and a machine as a textual query contains the person's soft\nbiometric attributes. It is also not feasible to manually search through huge\nvolumes of surveillance footage to retrieve a specific person. Hence, automatic\nperson retrieval using vision and language-based algorithms is becoming\npopular. In comparison to other state-of-the-art reviews, the contribution of\nthe paper is as follows: 1. Recommends most discriminative soft biometrics for\nspecifiic challenging conditions. 2. Integrates benchmark datasets and\nretrieval methods for objective performance evaluation. 3. A complete snapshot\nof techniques based on features, classifiers, number of soft biometric\nattributes, type of the deep neural networks, and performance measures. 4. The\ncomprehensive coverage of person retrieval from handcrafted features based\nmethods to end-to-end approaches based on natural language description.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 03:17:13 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Galiyawala", "Hiren", ""], ["Raval", "Mehul S", ""]]}, {"id": "2105.02568", "submitter": "Francesco Busolin", "authors": "Francesco Busolin, Claudio Lucchese, Franco Maria Nardini, Salvatore\n  Orlando, Raffaele Perego, Salvatore Trani", "title": "Learning Early Exit Strategies for Additive Ranking Ensembles", "comments": "5 pages, 3 figures, ACM SIGIR Conference on Research and Development\n  in Information Retrieval (SIGIR 21)", "journal-ref": null, "doi": "10.1145/3404835.346", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern search engine ranking pipelines are commonly based on large\nmachine-learned ensembles of regression trees. We propose LEAR, a novel -\nlearned - technique aimed to reduce the average number of trees traversed by\ndocuments to accumulate the scores, thus reducing the overall query response\ntime. LEAR exploits a classifier that predicts whether a document can early\nexit the ensemble because it is unlikely to be ranked among the final top-k\nresults. The early exit decision occurs at a sentinel point, i.e., after having\nevaluated a limited number of trees, and the partial scores are exploited to\nfilter out non-promising documents. We evaluate LEAR by deploying it in a\nproduction-like setting, adopting a state-of-the-art algorithm for ensembles\ntraversal. We provide a comprehensive experimental evaluation on two public\ndatasets. The experiments show that LEAR has a significant impact on the\nefficiency of the query processing without hindering its ranking quality. In\ndetail, on a first dataset, LEAR is able to achieve a speedup of 3x without any\nloss in NDCG1@0, while on a second dataset the speedup is larger than 5x with a\nnegligible NDCG@10 loss (< 0.05%).\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 10:25:50 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Busolin", "Francesco", ""], ["Lucchese", "Claudio", ""], ["Nardini", "Franco Maria", ""], ["Orlando", "Salvatore", ""], ["Perego", "Raffaele", ""], ["Trani", "Salvatore", ""]]}, {"id": "2105.02605", "submitter": "Junhan Yang", "authors": "Junhan Yang, Zheng Liu, Shitao Xiao, Chaozhuo Li, Guangzhong Sun, and\n  Xing Xie", "title": "GraphFormers: GNN-nested Language Models for Linked Text Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Linked text representation is critical for many intelligent web applications,\nsuch as online advertisement and recommender systems. Recent breakthroughs on\npretrained language models and graph neural networks facilitate the development\nof corresponding techniques. However, the existing works mainly rely on\ncascaded model structures: the texts are independently encoded by language\nmodels at first, and the textual embeddings are further aggregated by graph\nneural networks. We argue that the neighbourhood information is insufficiently\nutilized within the above process, which restricts the representation quality.\nIn this work, we propose GraphFormers, where graph neural networks are nested\nalongside each transformer layer of the language models. On top of the above\narchitecture, the linked texts will iteratively extract neighbourhood\ninformation for the enhancement of their own semantics. Such an iterative\nworkflow gives rise to more effective utilization of neighbourhood information,\nwhich contributes to the representation quality. We further introduce an\nadaptation called unidirectional GraphFormers, which is much more efficient and\ncomparably effective; and we leverage a pretraining strategy called the\nneighbourhood-aware masked language modeling to enhance the training effect. We\nperform extensive experiment studies with three large-scale linked text\ndatasets, whose results verify the effectiveness of our proposed methods.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 12:20:41 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Yang", "Junhan", ""], ["Liu", "Zheng", ""], ["Xiao", "Shitao", ""], ["Li", "Chaozhuo", ""], ["Sun", "Guangzhong", ""], ["Xie", "Xing", ""]]}, {"id": "2105.02697", "submitter": "Bryar Hassan Dr.", "authors": "Bryar A. Hassan, Aram M. Ahmed, Soran A. Saeed, Awin A. Saeed", "title": "Evaluating e-Government Services in Kurdistan Institution for Strategic\n  Studies and Scientific Research Using the EGOVSAT Model", "comments": null, "journal-ref": null, "doi": "10.24017/science.2016.1.2.2", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Office automation is an initiative used to digitally deliver services to\ncitizens, private and public sectors. It is used to digitally collect, store,\ncreate, and manipulate office information as a need of accomplishing basic\ntasks. Azya Office Automation has been implemented as a pilot project in\nKurdistan Institution for Strategic Studies and Scientific Research (KISSR)\nsince 2013. The efficiency of governance in Kurdistan Institution for Strategic\nStudies and Scientific Research has been improved, thanks to its\nimplementation. The aims of this research paper is to evaluate user\nsatisfaction of this software and identify its significant predictors using\nEGOVSAT Model. The user satisfaction of this model encompasses five main parts,\nwhich are utility, reliability, efficiency, customization, and flexibility. For\nthat purpose, a detailed survey is conducted to measure the level of user\nsatisfaction. A total of sixteen questions have distributed among forty one\nusers of the software in KISSR. In order to evaluate the software, three\nmeasurement have been used which are reliability test, regression analysis and\ncorrelation analysis. The results indicate that the software is successful to a\ndecent extent based on user satisfaction feedbacks obtained by using EGOVSAT\nModel.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 14:14:20 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Hassan", "Bryar A.", ""], ["Ahmed", "Aram M.", ""], ["Saeed", "Soran A.", ""], ["Saeed", "Awin A.", ""]]}, {"id": "2105.02746", "submitter": "Sanya Bathla Taneja", "authors": "Sanya B. Taneja, Richard D. Boyce, William T. Reynolds, Denis\n  Newman-Griffis", "title": "Introducing Information Retrieval for Biomedical Informatics Students", "comments": "To appear in the Proceedings of the Fifth Workshop on Teaching NLP @\n  NAACL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Introducing biomedical informatics (BMI) students to natural language\nprocessing (NLP) requires balancing technical depth with practical know-how to\naddress application-focused needs. We developed a set of three activities\nintroducing introductory BMI students to information retrieval with NLP,\ncovering document representation strategies and language models from TF-IDF to\nBERT. These activities provide students with hands-on experience targeted\ntowards common use cases, and introduce fundamental components of NLP workflows\nfor a wide variety of applications.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 15:15:54 GMT"}], "update_date": "2021-05-07", "authors_parsed": [["Taneja", "Sanya B.", ""], ["Boyce", "Richard D.", ""], ["Reynolds", "William T.", ""], ["Newman-Griffis", "Denis", ""]]}, {"id": "2105.02898", "submitter": "Bin Han", "authors": "Bin Han, Chirag Shah, Daniel Saelid", "title": "Users' Perception of Search Engine Biases and Satisfaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Search engines could consistently favor certain values over the others, which\nis considered as biased due to the built-in infrastructures. Many studies have\nbeen dedicated to detect, control, and mitigate the impacts of the biases from\nthe perspectives of search engines themselves. In our study, we take the\nperspective from end-users to analyze their perceptions of search engine biases\nand their satisfaction when the biases are regulated. In the study, we paired a\nreal search page from search engine Bing with a synthesized page that has more\ndiversities in the results (i.e. less biased). Both pages show the top-10\nsearch items given search queries and we asked participants which one do they\nprefer and why do they prefer the one selected. Statistical analyses revealed\nthat overall, participants prefer the original Bing pages and the locations\nwhere the diversities are introduced are also associated with users'\npreferences. We found out that users prefer results that are more consistent\nand relevant to the search queries. Introducing diversities undermines the\nrelevance of the search results and impairs users' satisfaction to some degree.\nAdditionally, we confirmed that users tend to pay more attention to the top\nportion of the results than the bottom ones.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 18:04:23 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Han", "Bin", ""], ["Shah", "Chirag", ""], ["Saelid", "Daniel", ""]]}, {"id": "2105.02935", "submitter": "Vedant Bahel", "authors": "Vedant Bahel and Achamma Thomas", "title": "Text similarity analysis for evaluation of descriptive answers", "comments": "7 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keeping in mind the necessity of intelligent system in educational sector,\nthis paper proposes a text analysis based automated approach for automatic\nevaluation of the descriptive answers in an examination. In particular, the\nresearch focuses on the use of intelligent concepts of Natural Language\nProcessing and Data Mining for computer aided examination evaluation system.\nThe paper present an architecture for fair evaluation of answer sheet. In this\narchitecture, the examiner creates a sample answer sheet for given sets of\nquestion. By using the concept of text summarization, text semantics and\nkeywords summarization, the final score for each answer is calculated. The text\nsimilarity model is based on Siamese Manhattan LSTM (MaLSTM). The results of\nthis research were compared to manually graded assignments and other existing\nsystem. This approach was found to be very efficient in order to be implemented\nin an institution or in an university.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 20:19:58 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Bahel", "Vedant", ""], ["Thomas", "Achamma", ""]]}, {"id": "2105.02951", "submitter": "Haolun Wu", "authors": "Haolun Wu, Chen Ma, Bhaskar Mitra, Fernando Diaz, Xue Liu", "title": "Multi-FR: A Multi-Objective Optimization Method for Achieving Two-sided\n  Fairness in E-commerce Recommendation", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two-sided marketplaces are an important component of many existing Internet\nservices like Airbnb and Amazon, which have both consumers (e.g. users) and\nproducers (e.g. retailers). Traditionally, the recommendation system in these\nplatforms mainly focuses on maximizing customer satisfaction by recommending\nthe most relevant items based on the learned user preference. However, it has\nbeen shown in previous works that solely optimizing the satisfaction of\ncustomers may lead to unfair exposure of items, which jeopardizes the benefits\nof producers. To tackle this problem, we propose a fairness-aware\nrecommendation framework by using multi-objective optimization, Multi-FR, to\nadaptively balance the objectives between consumers and producers. In\nparticular, Multi-FR adopts the multi-gradient descent to generate a Pareto set\nof solutions, where the most appropriate one is selected from the Pareto set.\nIn addition, four fairness metrics/constraints are applied to make the\nrecommendation results on both the consumer and producer side fair. We\nextensively evaluate our model on three real-world datasets, comparing with\ngrid-search methods and using a variety of performance metrics. The\nexperimental results demonstrate that Multi-FR can improve the recommendation\nfairness on both the consumer and producer side with little drop in\nrecommendation quality, also outperforming several state-of-the-art fair\nranking approaches.\n", "versions": [{"version": "v1", "created": "Thu, 6 May 2021 21:04:59 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 00:43:24 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Wu", "Haolun", ""], ["Ma", "Chen", ""], ["Mitra", "Bhaskar", ""], ["Diaz", "Fernando", ""], ["Liu", "Xue", ""]]}, {"id": "2105.03279", "submitter": "Mantas Luko\\v{s}evi\\v{c}ius", "authors": "Lukas Stankevi\\v{c}ius and Mantas Luko\\v{s}evi\\v{c}ius", "title": "Generating abstractive summaries of Lithuanian news articles using a\n  transformer model", "comments": "Accepted in ICIST 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this work, we train the first monolingual Lithuanian transformer model on\na relatively large corpus of Lithuanian news articles and compare various\noutput decoding algorithms for abstractive news summarization. We achieve an\naverage ROUGE-2 score 0.163, generated summaries are coherent and look\nimpressive at first glance. However, some of them contain misleading\ninformation that is not so easy to spot. We describe all the technical details\nand share our trained model and accompanying code in an online open-source\nrepository, as well as some characteristic samples of the generated summaries.\n", "versions": [{"version": "v1", "created": "Fri, 23 Apr 2021 20:10:42 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 13:36:37 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Stankevi\u010dius", "Lukas", ""], ["Luko\u0161evi\u010dius", "Mantas", ""]]}, {"id": "2105.03299", "submitter": "Yunshan Ma", "authors": "Yujuan Ding, Yunshan Ma, Lizi Liao, Wai Keung Wong, Tat-Seng Chua", "title": "Leveraging Multiple Relations for Fashion Trend Forecasting Based on\n  Social Media", "comments": "12 pages, 8 figures", "journal-ref": "IEEE Transaction on Multimedia, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fashion trend forecasting is of great research significance in providing\nuseful suggestions for both fashion companies and fashion lovers. Although\nvarious studies have been devoted to tackling this challenging task, they only\nstudied limited fashion elements with highly seasonal or simple patterns, which\ncould hardly reveal the real complex fashion trends. Moreover, the mainstream\nsolutions for this task are still statistical-based and solely focus on\ntime-series data modeling, which limit the forecast accuracy. Towards\ninsightful fashion trend forecasting, previous work [1] proposed to analyze\nmore fine-grained fashion elements which can informatively reveal fashion\ntrends. Specifically, it focused on detailed fashion element trend forecasting\nfor specific user groups based on social media data. In addition, it proposed a\nneural network-based method, namely KERN, to address the problem of fashion\ntrend modeling and forecasting. In this work, to extend the previous work, we\npropose an improved model named Relation Enhanced Attention Recurrent (REAR)\nnetwork. Compared to KERN, the REAR model leverages not only the relations\namong fashion elements but also those among user groups, thus capturing more\ntypes of correlations among various fashion trends. To further improve the\nperformance of long-range trend forecasting, the REAR method devises a sliding\ntemporal attention mechanism, which is able to capture temporal patterns on\nfuture horizons better. Extensive experiments and more analysis have been\nconducted on the FIT and GeoStyle datasets to evaluate the performance of REAR.\nExperimental and analytical results demonstrate the effectiveness of the\nproposed REAR model in fashion trend forecasting, which also show the\nimprovement of REAR compared to the KERN.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 14:52:03 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 07:41:25 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Ding", "Yujuan", ""], ["Ma", "Yunshan", ""], ["Liao", "Lizi", ""], ["Wong", "Wai Keung", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2105.03300", "submitter": "Lei Guo", "authors": "Lei Guo, Li Tang, Tong Chen, Lei Zhu, Quoc Viet Hung Nguyen, Hongzhi\n  Yin", "title": "DA-GCN: A Domain-aware Attentive Graph Convolution Network for\n  Shared-account Cross-domain Sequential Recommendation", "comments": null, "journal-ref": "The 30th International Joint Conference on Artificial\n  Intelligence, 2021", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shared-account Cross-domain Sequential recommendation (SCSR) is the task of\nrecommending the next item based on a sequence of recorded user behaviors,\nwhere multiple users share a single account, and their behaviours are available\nin multiple domains. Existing work on solving SCSR mainly relies on mining\nsequential patterns via RNN-based models, which are not expressive enough to\ncapture the relationships among multiple entities. Moreover, all existing\nalgorithms try to bridge two domains via knowledge transfer in the latent\nspace, and the explicit cross-domain graph structure is unexploited. In this\nwork, we propose a novel graph-based solution, namely DA-GCN, to address the\nabove challenges. Specifically, we first link users and items in each domain as\na graph. Then, we devise a domain-aware graph convolution network to learn\nuser-specific node representations. To fully account for users' domain-specific\npreferences on items, two novel attention mechanisms are further developed to\nselectively guide the message passing process. Extensive experiments on two\nreal-world datasets are conducted to demonstrate the superiority of our DA-GCN\nmethod.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 14:52:06 GMT"}], "update_date": "2021-05-10", "authors_parsed": [["Guo", "Lei", ""], ["Tang", "Li", ""], ["Chen", "Tong", ""], ["Zhu", "Lei", ""], ["Nguyen", "Quoc Viet Hung", ""], ["Yin", "Hongzhi", ""]]}, {"id": "2105.03456", "submitter": "Garrett Allen", "authors": "Garrett Allen, Katherine Landau Wright, Jerry Alan Fails, Casey\n  Kennington, Maria Soledad Pera", "title": "CASTing a Net: Supporting Teachers with Search Technology", "comments": "KidRec '21: 5th International and Interdisciplinary Perspectives on\n  Children & Recommender and Information Retrieval Systems (KidRec) Search and\n  Recommendation Technology through the Lens of a Teacher- Co-located with ACM\n  IDC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.HC cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Past and current research has typically focused on ensuring that search\ntechnology for the classroom serves children. In this paper, we argue for the\nneed to broaden the research focus to include teachers and how search\ntechnology can aid them. In particular, we share how furnishing a\nbehind-the-scenes portal for teachers can empower them by providing a window\ninto the spelling, writing, and concept connection skills of their students.\n", "versions": [{"version": "v1", "created": "Fri, 7 May 2021 18:13:49 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Allen", "Garrett", ""], ["Wright", "Katherine Landau", ""], ["Fails", "Jerry Alan", ""], ["Kennington", "Casey", ""], ["Pera", "Maria Soledad", ""]]}, {"id": "2105.03599", "submitter": "Hongyin Tang", "authors": "Hongyin Tang, Xingwu Sun, Beihong Jin, Jingang Wang, Fuzheng Zhang,\n  Wei Wu", "title": "Improving Document Representations by Generating Pseudo Query Embeddings\n  for Dense Retrieval", "comments": "11 pages, 2 figures, Accepted by ACL 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, the retrieval models based on dense representations have been\ngradually applied in the first stage of the document retrieval tasks, showing\nbetter performance than traditional sparse vector space models. To obtain high\nefficiency, the basic structure of these models is Bi-encoder in most cases.\nHowever, this simple structure may cause serious information loss during the\nencoding of documents since the queries are agnostic. To address this problem,\nwe design a method to mimic the queries on each of the documents by an\niterative clustering process and represent the documents by multiple pseudo\nqueries (i.e., the cluster centroids). To boost the retrieval process using\napproximate nearest neighbor search library, we also optimize the matching\nfunction with a two-step score calculation procedure. Experimental results on\nseveral popular ranking and QA datasets show that our model can achieve\nstate-of-the-art results.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 05:28:24 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Tang", "Hongyin", ""], ["Sun", "Xingwu", ""], ["Jin", "Beihong", ""], ["Wang", "Jingang", ""], ["Zhang", "Fuzheng", ""], ["Wu", "Wei", ""]]}, {"id": "2105.03686", "submitter": "Ruobing Xie", "authors": "Ruobing Xie, Yalong Wang, Rui Wang, Yuanfu Lu, Yuanhang Zou, Feng Xia,\n  Leyu Lin", "title": "Long Short-Term Temporal Meta-learning in Online Recommendation", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective online recommendation system should jointly capture user\nlong-term and short-term preferences in both user internal and external\nbehaviors. However, it is challenging to conduct fast adaptations to variable\nnew topics while making full use of all information in large-scale systems, due\nto the online efficiency limitation and complexity of real-world systems. To\naddress this, we propose a novel Long Short-Term Temporal Meta-learning\nframework (LSTTM) for online recommendation, which captures user preferences\nfrom a global long-term graph and an internal short-term graph. To improve\nonline learning for short-term interests, we propose a temporal MAML method\nwith asynchronous online updating for fast adaptation, which regards\nrecommendations at different time periods as different tasks. In experiments,\nLSTTM achieves significant improvements on both offline and online evaluations.\nLSTTM has also been deployed on a widely-used online system, affecting millions\nof users. The idea of temporal MAML can be easily transferred to other models\nand temporal tasks.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 12:27:37 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Xie", "Ruobing", ""], ["Wang", "Yalong", ""], ["Wang", "Rui", ""], ["Lu", "Yuanfu", ""], ["Zou", "Yuanhang", ""], ["Xia", "Feng", ""], ["Lin", "Leyu", ""]]}, {"id": "2105.03708", "submitter": "Maria Soledad Pera", "authors": "Emiliana Murgia, Monica Landoni, Theo Huibers, Maria Soledad Pera", "title": "All Together Now: Teachers as Research Partners in the Design of Search\n  Technology for the Classroom", "comments": "In KidRec '21: 5th International and Interdisciplinary Perspectives\n  on Children & Recommender and Information Retrieval Systems (KidRec) Search\n  and Recommendation Technology through the Lens of a Teacher- Co-located with\n  ACM IDC 2021; June 26, 2021; Online Event", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In the classroom environment, search tools are the means for students to\naccess Web resources. The perspectives of students, researchers, and industry\npractitioners lead the ongoing research debate in this area. In this article,\nwe argue in favor of incorporating a new voice into this debate: teachers. We\nshowcase the value of involving teachers in all aspects related to the design\nof search tools for the classroom; from the beginning till the end. Driven by\nour research experience designing, developing, and evaluating new tools to\nsupport children's information discovery in the classroom, we share insights on\nthe role of the experts-in-the-loop, i.e., teachers who provide the connection\nbetween search tools and students. And yes, in our case, always involving a\nteacher as a research partner.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 14:25:44 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Murgia", "Emiliana", ""], ["Landoni", "Monica", ""], ["Huibers", "Theo", ""], ["Pera", "Maria Soledad", ""]]}, {"id": "2105.03748", "submitter": "Shuo Zhang", "authors": "Weiwei Sun, Shuo Zhang, Krisztian Balog, Zhaochun Ren, Pengjie Ren,\n  Zhumin Chen and Maarten de Rijke", "title": "Simulating User Satisfaction for the Evaluation of Task-oriented\n  Dialogue Systems", "comments": "Proceedings of the 44th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR '21), 2021", "journal-ref": null, "doi": "10.1145/3404835.3463241", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation is crucial in the development process of task-oriented dialogue\nsystems. As an evaluation method, user simulation allows us to tackle issues\nsuch as scalability and cost-efficiency, making it a viable choice for\nlarge-scale automatic evaluation. To help build a human-like user simulator\nthat can measure the quality of a dialogue, we propose the following task:\nsimulating user satisfaction for the evaluation of task-oriented dialogue\nsystems. The purpose of the task is to increase the evaluation power of user\nsimulations and to make the simulation more human-like. To overcome a lack of\nannotated data, we propose a user satisfaction annotation dataset, USS, that\nincludes 6,800 dialogues sampled from multiple domains, spanning real-world\ne-commerce dialogues, task-oriented dialogues constructed through Wizard-of-Oz\nexperiments, and movie recommendation dialogues. All user utterances in those\ndialogues, as well as the dialogues themselves, have been labeled based on a\n5-level satisfaction scale. We also share three baseline methods for user\nsatisfaction prediction and action prediction tasks. Experiments conducted on\nthe USS dataset suggest that distributed representations outperform\nfeature-based methods. A model based on hierarchical GRUs achieves the best\nperformance in in-domain user satisfaction prediction, while a BERT-based model\nhas better cross-domain generalization ability.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 17:34:40 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Sun", "Weiwei", ""], ["Zhang", "Shuo", ""], ["Balog", "Krisztian", ""], ["Ren", "Zhaochun", ""], ["Ren", "Pengjie", ""], ["Chen", "Zhumin", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2105.03775", "submitter": "Hossein Basafa", "authors": "Hossein Basafa, Sajad Movahedi, Ali Ebrahimi, Azadeh Shakery and\n  Heshaam Faili", "title": "NLP-IIS@UT at SemEval-2021 Task 4: Machine Reading Comprehension using\n  the Long Document Transformer", "comments": "6 pages, 1 figure. Accepted in SemEval2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a technical report of our submission to the 4th task of\nSemEval-2021, titled: Reading Comprehension of Abstract Meaning. In this task,\nwe want to predict the correct answer based on a question given a context.\nUsually, contexts are very lengthy and require a large receptive field from the\nmodel. Thus, common contextualized language models like BERT miss fine\nrepresentation and performance due to the limited capacity of the input tokens.\nTo tackle this problem, we used the Longformer model to better process the\nsequences. Furthermore, we utilized the method proposed in the Longformer\nbenchmark on Wikihop dataset which improved the accuracy on our task data from\n23.01% and 22.95% achieved by the baselines for subtask 1 and 2, respectively,\nto 70.30% and 64.38%.\n", "versions": [{"version": "v1", "created": "Sat, 8 May 2021 20:48:32 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Basafa", "Hossein", ""], ["Movahedi", "Sajad", ""], ["Ebrahimi", "Ali", ""], ["Shakery", "Azadeh", ""], ["Faili", "Heshaam", ""]]}, {"id": "2105.03811", "submitter": "Farzaneh Rajabi", "authors": "Farzaneh Rajabi, Jack Siyuan He", "title": "Click-Through Rate Prediction Using Graph Neural Networks and Online\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommendation systems have been extensively studied by many literature in\nthe past and are ubiquitous in online advertisement, shopping\nindustry/e-commerce, query suggestions in search engines, and friend\nrecommendation in social networks. Moreover,\nrestaurant/music/product/movie/news/app recommendations are only a few of the\napplications of a recommender system. A small percent improvement on the CTR\nprediction accuracy has been mentioned to add millions of dollars of revenue to\nthe advertisement industry. Click-Through-Rate (CTR) prediction is a special\nversion of recommender system in which the goal is predicting whether or not a\nuser is going to click on a recommended item. A content-based recommendation\napproach takes into account the past history of the user's behavior, i.e. the\nrecommended products and the users reaction to them. So, a personalized model\nthat recommends the right item to the right user at the right time is the key\nto building such a model. On the other hand, the so-called collaborative\nfiltering approach incorporates the click history of the users who are very\nsimilar to a particular user, thereby helping the recommender to come up with a\nmore confident prediction for that particular user by leveraging the wider\nknowledge of users who share their taste in a connected network of users. In\nthis project, we are interested in building a CTR predictor using Graph Neural\nNetworks complemented by an online learning algorithm that models such dynamic\ninteractions. By framing the problem as a binary classification task, we have\nevaluated this system both on the offline models (GNN, Deep Factorization\nMachines) with test-AUC of 0.7417 and on the online learning model with\ntest-AUC of 0.7585 using a sub-sampled version of Criteo public dataset\nconsisting of 10,000 data points.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 01:35:49 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Rajabi", "Farzaneh", ""], ["He", "Jack Siyuan", ""]]}, {"id": "2105.03933", "submitter": "Han Zhang", "authors": "Han Zhang, Hongwei Shen, Yiming Qiu, Yunjiang Jiang, Songlin Wang,\n  Sulong Xu, Yun Xiao, Bo Long, Wen-Yun Yang", "title": "Joint Learning of Deep Retrieval Model and Product Quantization based\n  Embedding Index", "comments": "4 pages, 4 figures; accepted by SIGIR2021", "journal-ref": null, "doi": "10.1145/3404835.3462988", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Embedding index that enables fast approximate nearest neighbor(ANN) search,\nserves as an indispensable component for state-of-the-art deep retrieval\nsystems. Traditional approaches, often separating the two steps of embedding\nlearning and index building, incur additional indexing time and decayed\nretrieval accuracy. In this paper, we propose a novel method called Poeem,\nwhich stands for product quantization based embedding index jointly trained\nwith deep retrieval model, to unify the two separate steps within an end-to-end\ntraining, by utilizing a few techniques including the gradient straight-through\nestimator, warm start strategy, optimal space decomposition and Givens\nrotation. Extensive experimental results show that the proposed method not only\nimproves retrieval accuracy significantly but also reduces the indexing time to\nalmost none. We have open sourced our approach for the sake of comparison and\nreproducibility.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 13:17:31 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 13:09:21 GMT"}, {"version": "v3", "created": "Fri, 28 May 2021 08:32:08 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Zhang", "Han", ""], ["Shen", "Hongwei", ""], ["Qiu", "Yiming", ""], ["Jiang", "Yunjiang", ""], ["Wang", "Songlin", ""], ["Xu", "Sulong", ""], ["Xiao", "Yun", ""], ["Long", "Bo", ""], ["Yang", "Wen-Yun", ""]]}, {"id": "2105.03938", "submitter": "Chen Qu", "authors": "Chen Qu, Hamed Zamani, Liu Yang, W. Bruce Croft and Erik\n  Learned-Miller", "title": "Passage Retrieval for Outside-Knowledge Visual Question Answering", "comments": "Accepted to SIGIR'21 as a short paper", "journal-ref": null, "doi": "10.1145/3404835.3462987", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we address multi-modal information needs that contain text\nquestions and images by focusing on passage retrieval for outside-knowledge\nvisual question answering. This task requires access to outside knowledge,\nwhich in our case we define to be a large unstructured passage collection. We\nfirst conduct sparse retrieval with BM25 and study expanding the question with\nobject names and image captions. We verify that visual clues play an important\nrole and captions tend to be more informative than object names in sparse\nretrieval. We then construct a dual-encoder dense retriever, with the query\nencoder being LXMERT, a multi-modal pre-trained transformer. We further show\nthat dense retrieval significantly outperforms sparse retrieval that uses\nobject expansion. Moreover, dense retrieval matches the performance of sparse\nretrieval that leverages human-generated captions.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 13:27:22 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Qu", "Chen", ""], ["Zamani", "Hamed", ""], ["Yang", "Liu", ""], ["Croft", "W. Bruce", ""], ["Learned-Miller", "Erik", ""]]}, {"id": "2105.03983", "submitter": "Rajdeep Mukherjee", "authors": "Rajdeep Mukherjee, Atharva Naik, Sriyash Poddar, Soham Dasgupta, Niloy\n  Ganguly", "title": "Understanding the Role of Affect Dimensions in Detecting Emotions from\n  Tweets: A Multi-task Approach", "comments": "5 pages, Short Paper accepted at SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3463080", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose VADEC, a multi-task framework that exploits the correlation\nbetween the categorical and dimensional models of emotion representation for\nbetter subjectivity analysis. Focusing primarily on the effective detection of\nemotions from tweets, we jointly train multi-label emotion classification and\nmulti-dimensional emotion regression, thereby utilizing the inter-relatedness\nbetween the tasks. Co-training especially helps in improving the performance of\nthe classification task as we outperform the strongest baselines with 3.4%,\n11%, and 3.9% gains in Jaccard Accuracy, Macro-F1, and Micro-F1 scores\nrespectively on the AIT dataset. We also achieve state-of-the-art results with\n11.3% gains averaged over six different metrics on the SenWave dataset. For the\nregression task, VADEC, when trained with SenWave, achieves 7.6% and 16.5%\ngains in Pearson Correlation scores over the current state-of-the-art on the\nEMOBANK dataset for the Valence (V) and Dominance (D) affect dimensions\nrespectively. We conclude our work with a case study on COVID-19 tweets posted\nby Indians that further helps in establishing the efficacy of our proposed\nsolution.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 18:07:04 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Mukherjee", "Rajdeep", ""], ["Naik", "Atharva", ""], ["Poddar", "Sriyash", ""], ["Dasgupta", "Soham", ""], ["Ganguly", "Niloy", ""]]}, {"id": "2105.03986", "submitter": "Sarit Kraus", "authors": "Aviram Aviv, Yaniv Oshrat, Samuel A. Assefa, Tobi Mustapha, Daniel\n  Borrajo, Manuela Veloso, Sarit Kraus", "title": "Advising Agent for Service-Providing Live-Chat Operators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Call centers, in which human operators attend clients using textual chat, are\nvery common in modern e-commerce. Training enough skilled operators who are\nable to provide good service is a challenge. We suggest an algorithm and a\nmethod to train and implement an assisting agent that provides on-line advice\nto operators while they attend clients. The agent is domain-independent and can\nbe introduced to new domains without major efforts in design, training and\norganizing structured knowledge of the professional discipline. We demonstrate\nthe applicability of the system in an experiment that realizes its full\nlife-cycle on a specific domain and analyze its capabilities.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 18:10:54 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 13:46:48 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Aviv", "Aviram", ""], ["Oshrat", "Yaniv", ""], ["Assefa", "Samuel A.", ""], ["Mustapha", "Tobi", ""], ["Borrajo", "Daniel", ""], ["Veloso", "Manuela", ""], ["Kraus", "Sarit", ""]]}, {"id": "2105.04019", "submitter": "Felix Petersen", "authors": "Felix Petersen, Christian Borgelt, Hilde Kuehne, Oliver Deussen", "title": "Differentiable Sorting Networks for Scalable Sorting and Ranking\n  Supervision", "comments": "Published at ICML 2021, Code @\n  https://github.com/Felix-Petersen/diffsort, Video @\n  https://www.youtube.com/watch?v=38dvqdYEs1o", "journal-ref": "PMLR 139:8546-8555, 2021", "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sorting and ranking supervision is a method for training neural networks\nend-to-end based on ordering constraints. That is, the ground truth order of\nsets of samples is known, while their absolute values remain unsupervised. For\nthat, we propose differentiable sorting networks by relaxing their pairwise\nconditional swap operations. To address the problems of vanishing gradients and\nextensive blurring that arise with larger numbers of layers, we propose mapping\nactivations to regions with moderate gradients. We consider odd-even as well as\nbitonic sorting networks, which outperform existing relaxations of the sorting\noperation. We show that bitonic sorting networks can achieve stable training on\nlarge input sets of up to 1024 elements.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 20:39:03 GMT"}, {"version": "v2", "created": "Wed, 14 Jul 2021 10:16:01 GMT"}], "update_date": "2021-07-15", "authors_parsed": [["Petersen", "Felix", ""], ["Borgelt", "Christian", ""], ["Kuehne", "Hilde", ""], ["Deussen", "Oliver", ""]]}, {"id": "2105.04020", "submitter": "M. F. Mridha", "authors": "Farisa Benta Safir, Abu Quwsar Ohi, M.F. Mridha, Muhammad Mostafa\n  Monowar, Md. Abdul Hamid", "title": "End-to-End Optical Character Recognition for Bengali Handwritten Words", "comments": "Accepted in \"The 4th National Computing Colleges Conference\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optical character recognition (OCR) is a process of converting analogue\ndocuments into digital using document images. Currently, many commercial and\nnon-commercial OCR systems exist for both handwritten and printed copies for\ndifferent languages. Despite this, very few works are available in case of\nrecognising Bengali words. Among them, most of the works focused on OCR of\nprinted Bengali characters. This paper introduces an end-to-end OCR system for\nBengali language. The proposed architecture implements an end to end strategy\nthat recognises handwritten Bengali words from handwritten word images. We\nexperiment with popular convolutional neural network (CNN) architectures,\nincluding DenseNet, Xception, NASNet, and MobileNet to build the OCR\narchitecture. Further, we experiment with two different recurrent neural\nnetworks (RNN) methods, LSTM and GRU. We evaluate the proposed architecture\nusing BanglaWritting dataset, which is a peer-reviewed Bengali handwritten\nimage dataset. The proposed method achieves 0.091 character error rate and\n0.273 word error rate performed using DenseNet121 model with GRU recurrent\nlayer.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 20:48:56 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Safir", "Farisa Benta", ""], ["Ohi", "Abu Quwsar", ""], ["Mridha", "M. F.", ""], ["Monowar", "Muhammad Mostafa", ""], ["Hamid", "Md. Abdul", ""]]}, {"id": "2105.04021", "submitter": "Bhaskar Mitra", "authors": "Nick Craswell, Bhaskar Mitra, Emine Yilmaz, Daniel Campos and Jimmy\n  Lin", "title": "MS MARCO: Benchmarking Ranking Models in the Large-Data Regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Evaluation efforts such as TREC, CLEF, NTCIR and FIRE, alongside public\nleaderboard such as MS MARCO, are intended to encourage research and track our\nprogress, addressing big questions in our field. However, the goal is not\nsimply to identify which run is \"best\", achieving the top score. The goal is to\nmove the field forward by developing new robust techniques, that work in many\ndifferent settings, and are adopted in research and practice. This paper uses\nthe MS MARCO and TREC Deep Learning Track as our case study, comparing it to\nthe case of TREC ad hoc ranking in the 1990s. We show how the design of the\nevaluation effort can encourage or discourage certain outcomes, and raising\nquestions about internal and external validity of results. We provide some\nanalysis of certain pitfalls, and a statement of best practices for avoiding\nsuch pitfalls. We summarize the progress of the effort so far, and describe our\ndesired end state of \"robust usefulness\", along with steps that might be\nrequired to get us there.\n", "versions": [{"version": "v1", "created": "Sun, 9 May 2021 20:57:36 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Craswell", "Nick", ""], ["Mitra", "Bhaskar", ""], ["Yilmaz", "Emine", ""], ["Campos", "Daniel", ""], ["Lin", "Jimmy", ""]]}, {"id": "2105.04067", "submitter": "Yixin Su", "authors": "Yixin Su and Rui Zhang and Sarah Erfani and Junhao Gan", "title": "Neural Graph Matching based Collaborative Filtering", "comments": "10 pages, 6 figures, 4 tables, SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462833", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User and item attributes are essential side-information; their interactions\n(i.e., their co-occurrence in the sample data) can significantly enhance\nprediction accuracy in various recommender systems. We identify two different\ntypes of attribute interactions, inner interactions and cross interactions:\ninner interactions are those between only user attributes or those between only\nitem attributes; cross interactions are those between user attributes and item\nattributes. Existing models do not distinguish these two types of attribute\ninteractions, which may not be the most effective way to exploit the\ninformation carried by the interactions. To address this drawback, we propose a\nneural Graph Matching based Collaborative Filtering model (GMCF), which\neffectively captures the two types of attribute interactions through modeling\nand aggregating attribute interactions in a graph matching structure for\nrecommendation. In our model, the two essential recommendation procedures,\ncharacteristic learning and preference matching, are explicitly conducted\nthrough graph learning (based on inner interactions) and node matching (based\non cross interactions), respectively. Experimental results show that our model\noutperforms state-of-the-art models. Further studies verify the effectiveness\nof GMCF in improving the accuracy of recommendation.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 01:51:46 GMT"}, {"version": "v2", "created": "Fri, 23 Jul 2021 01:53:56 GMT"}], "update_date": "2021-07-26", "authors_parsed": [["Su", "Yixin", ""], ["Zhang", "Rui", ""], ["Erfani", "Sarah", ""], ["Gan", "Junhao", ""]]}, {"id": "2105.04117", "submitter": "KayYen Wong", "authors": "KayYen Wong, Miriam Redi, Diego Saez-Trumper", "title": "Wiki-Reliability: A Large Scale Dataset for Content Reliability on\n  Wikipedia", "comments": "Proceedings of the 44th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR '21), 2021", "journal-ref": null, "doi": "10.1145/3404835.3463253", "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Wikipedia is the largest online encyclopedia, used by algorithms and web\nusers as a central hub of reliable information on the web. The quality and\nreliability of Wikipedia content is maintained by a community of volunteer\neditors. Machine learning and information retrieval algorithms could help scale\nup editors' manual efforts around Wikipedia content reliability. However, there\nis a lack of large-scale data to support the development of such research. To\nfill this gap, in this paper, we propose Wiki-Reliability, the first dataset of\nEnglish Wikipedia articles annotated with a wide set of content reliability\nissues. To build this dataset, we rely on Wikipedia \"templates\". Templates are\ntags used by expert Wikipedia editors to indicate content issues, such as the\npresence of \"non-neutral point of view\" or \"contradictory articles\", and serve\nas a strong signal for detecting reliability issues in a revision. We select\nthe 10 most popular reliability-related templates on Wikipedia, and propose an\neffective method to label almost 1M samples of Wikipedia article revisions as\npositive or negative with respect to each template. Each positive/negative\nexample in the dataset comes with the full article text and 20 features from\nthe revision's metadata. We provide an overview of the possible downstream\ntasks enabled by such data, and show that Wiki-Reliability can be used to train\nlarge-scale models for content reliability prediction. We release all data and\ncode for public use.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 05:07:03 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 11:57:14 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Wong", "KayYen", ""], ["Redi", "Miriam", ""], ["Saez-Trumper", "Diego", ""]]}, {"id": "2105.04166", "submitter": "Shi Yu", "authors": "Shi Yu, Zhenghao Liu, Chenyan Xiong, Tao Feng and Zhiyuan Liu", "title": "Few-Shot Conversational Dense Retrieval", "comments": "Accepted by SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462856", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense retrieval (DR) has the potential to resolve the query understanding\nchallenge in conversational search by matching in the learned embedding space.\nHowever, this adaptation is challenging due to DR models' extra needs for\nsupervision signals and the long-tail nature of conversational search. In this\npaper, we present a Conversational Dense Retrieval system, ConvDR, that learns\ncontextualized embeddings for multi-turn conversational queries and retrieves\ndocuments solely using embedding dot products. In addition, we grant ConvDR\nfew-shot ability using a teacher-student framework, where we employ an ad hoc\ndense retriever as the teacher, inherit its document encodings, and learn a\nstudent query encoder to mimic the teacher embeddings on oracle reformulated\nqueries. Our experiments on TREC CAsT and OR-QuAC demonstrate ConvDR's\neffectiveness in both few-shot and fully-supervised settings. It outperforms\nprevious systems that operate in the sparse word space, matches the retrieval\naccuracy of oracle query reformulations, and is also more efficient thanks to\nits simplicity. Our analyses reveal that the advantages of ConvDR come from its\nability to capture informative context while ignoring the unrelated context in\nprevious conversation rounds. This makes ConvDR more effective as conversations\nevolve while previous systems may get confused by the increased noise from\nprevious turns. Our code is publicly available at\nhttps://github.com/thunlp/ConvDR.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 07:51:05 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 02:43:59 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 13:16:51 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Yu", "Shi", ""], ["Liu", "Zhenghao", ""], ["Xiong", "Chenyan", ""], ["Feng", "Tao", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "2105.04170", "submitter": "Hande Dong", "authors": "Jiawei Chen, Hande Dong, Yang Qiu, Xiangnan He, Xin Xin, Liang Chen,\n  Guli Lin, Keping Yang", "title": "AutoDebias: Learning to Debias for Recommendation", "comments": "Accepted by SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462919", "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems rely on user behavior data like ratings and clicks to\nbuild personalization model. However, the collected data is observational\nrather than experimental, causing various biases in the data which\nsignificantly affect the learned model. Most existing work for recommendation\ndebiasing, such as the inverse propensity scoring and imputation approaches,\nfocuses on one or two specific biases, lacking the universal capacity that can\naccount for mixed or even unknown biases in the data. Towards this research\ngap, we first analyze the origin of biases from the perspective of \\textit{risk\ndiscrepancy} that represents the difference between the expectation empirical\nrisk and the true risk. Remarkably, we derive a general learning framework that\nwell summarizes most existing debiasing strategies by specifying some\nparameters of the general framework. This provides a valuable opportunity to\ndevelop a universal solution for debiasing, e.g., by learning the debiasing\nparameters from data. However, the training data lacks important signal of how\nthe data is biased and what the unbiased data looks like. To move this idea\nforward, we propose \\textit{AotoDebias} that leverages another (small) set of\nuniform data to optimize the debiasing parameters by solving the bi-level\noptimization problem with meta-learning. Through theoretical analyses, we\nderive the generalization bound for AutoDebias and prove its ability to acquire\nthe appropriate debiasing strategy. Extensive experiments on two real datasets\nand a simulated dataset demonstrated effectiveness of AutoDebias. The code is\navailable at \\url{https://github.com/DongHande/AutoDebias}.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 08:03:48 GMT"}, {"version": "v2", "created": "Wed, 7 Jul 2021 07:46:00 GMT"}, {"version": "v3", "created": "Thu, 15 Jul 2021 07:35:19 GMT"}], "update_date": "2021-07-16", "authors_parsed": [["Chen", "Jiawei", ""], ["Dong", "Hande", ""], ["Qiu", "Yang", ""], ["He", "Xiangnan", ""], ["Xin", "Xin", ""], ["Chen", "Liang", ""], ["Lin", "Guli", ""], ["Yang", "Keping", ""]]}, {"id": "2105.04183", "submitter": "Zhiyong Cheng", "authors": "Xinxiao Zhao, Zhiyong Cheng, Lei Zhu, Jiecai Zheng, Xueqing Li", "title": "UGRec: Modeling Directed and Undirected Relations for Recommendation", "comments": "Accepted as a long paper in SIGIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recommender systems, which merely leverage user-item interactions for user\npreference prediction (such as the collaborative filtering-based ones), often\nface dramatic performance degradation when the interactions of users or items\nare insufficient. In recent years, various types of side information have been\nexplored to alleviate this problem. Among them, knowledge graph (KG) has\nattracted extensive research interests as it can encode users/items and their\nassociated attributes in the graph structure to preserve the relation\ninformation. In contrast, less attention has been paid to the item-item\nco-occurrence information (i.e., \\textit{co-view}), which contains rich\nitem-item similarity information. It provides information from a perspective\ndifferent from the user/item-attribute graph and is also valuable for the CF\nrecommendation models. In this work, we make an effort to study the potential\nof integrating both types of side information (i.e., KG and item-item\nco-occurrence data) for recommendation. To achieve the goal, we propose a\nunified graph-based recommendation model (UGRec), which integrates the\ntraditional directed relations in KG and the undirected item-item co-occurrence\nrelations simultaneously. In particular, for a directed relation, we transform\nthe head and tail entities into the corresponding relation space to model their\nrelation; and for an undirected co-occurrence relation, we project head and\ntail entities into a unique hyperplane in the entity space to minimize their\ndistance. In addition, a head-tail relation-aware attentive mechanism is\ndesigned for fine-grained relation modeling. Extensive experiments have been\nconducted on several publicly accessible datasets to evaluate the proposed\nmodel. Results show that our model outperforms several previous\nstate-of-the-art methods and demonstrate the effectiveness of our UGRec model.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 08:20:29 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Zhao", "Xinxiao", ""], ["Cheng", "Zhiyong", ""], ["Zhu", "Lei", ""], ["Zheng", "Jiecai", ""], ["Li", "Xueqing", ""]]}, {"id": "2105.04266", "submitter": "Esraa Ali", "authors": "Esraa Ali, Annalina Caputo, S\\'eamus Lawless, and Owen Conlan", "title": "A Probabilistic Approach to Personalize Type-based Facet Ranking for POI\n  Suggestion", "comments": "Accepted at ICWE 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Faceted Search Systems (FSS) have become one of the main search interfaces\nused in vertical search systems, offering users meaningful facets to refine\ntheir search query and narrow down the results quickly to find the intended\nsearch target. This work focuses on the problem of ranking type-based facets.\nIn a structured information space, type-based facets (t-facets) indicate the\ncategory to which each object belongs. When they belong to a large multi-level\ntaxonomy, it is desirable to rank them separately before ranking other facet\ngroups. This helps the searcher in filtering the results according to their\ntype first. This also makes it easier to rank the rest of the facets once the\ntype of the intended search target is selected. Existing research employs the\nsame ranking methods for different facet groups. In this research, we propose a\ntwo-step approach to personalize t-facet ranking. The first step assigns a\nrelevance score to each individual leaf-node t-facet. The score is generated\nusing probabilistic models and it reflects t-facet relevance to the query and\nthe user profile. In the second step, this score is used to re-order and select\nthe sub-tree to present to the user. We investigate the usefulness of the\nproposed method to a Point Of Interest (POI) suggestion task. Our evaluation\naims at capturing the user effort required to fulfil her search needs by using\nthe ranked facets. The proposed approach achieved better results than other\nexisting personalized baselines.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 11:06:02 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Ali", "Esraa", ""], ["Caputo", "Annalina", ""], ["Lawless", "S\u00e9amus", ""], ["Conlan", "Owen", ""]]}, {"id": "2105.04293", "submitter": "Giovanni Mauro", "authors": "Paolo Cintia, Giovanni Mauro, Luca Pappalardo, Paolo Ferragina", "title": "An interactive dashboard for searching and comparing soccer performance\n  scores", "comments": "4 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The performance of soccer players is one of most discussed aspects by many\nactors in the soccer industry: from supporters to journalists, from coaches to\ntalent scouts. Unfortunately, the dashboards available online provide no\neffective way to compare the evolution of the performance of players or to find\nplayers behaving similarly on the field. This paper describes the design of a\nweb dashboard that interacts via APIs with a performance evaluation algorithm\nand provides graphical tools that allow the user to perform many tasks, such as\nto search or compare players by age, role or trend of growth in their\nperformance, find similar players based on their pitching behavior, change the\nalgorithm's parameters to obtain customized performance scores. We also\ndescribe an example of how a talent scout can interact with the dashboard to\nfind young, promising talents.\n", "versions": [{"version": "v1", "created": "Fri, 16 Apr 2021 16:50:26 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 13:39:02 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Cintia", "Paolo", ""], ["Mauro", "Giovanni", ""], ["Pappalardo", "Luca", ""], ["Ferragina", "Paolo", ""]]}, {"id": "2105.04376", "submitter": "Iacopo Vagliano", "authors": "Iacopo Vagliano, Lukas Galke, Ansgar Scherp", "title": "Recommendations for Item Set Completion: On the Semantics of Item\n  Co-Occurrence With Data Sparsity, Input Size, and Input Modalities", "comments": "arXiv admin note: text overlap with arXiv:1907.12366", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of recommending relevant items to a user in order to\n\"complete\" a partial set of items already known. We consider the two scenarios\nof citation and subject label recommendation, which resemble different\nsemantics of item co-occurrence: relatedness for co-citations and diversity for\nsubject labels. We assess the influence of the completeness of an already known\npartial item set on the recommender performance. We also investigate data\nsparsity through a pruning parameter and the influence of using additional\nmetadata. As recommender models, we focus on different autoencoders, which are\nparticularly suited for reconstructing missing items in a set. We extend\nautoencoders to exploit a multi-modal input of text and structured data. Our\nexperiments on six real-world datasets show that supplying the partial item set\nas input is helpful when item co-occurrence resembles relatedness, while\nmetadata are effective when co-occurrence implies diversity. This outcome means\nthat the semantics of item co-occurrence is an important factor. The simple\nitem co-occurrence model is a strong baseline for citation recommendation.\nHowever, autoencoders have the advantage to enable exploiting additional\nmetadata besides the partial item set as input and achieve comparable\nperformance. For the subject label recommendation task, the title is the most\nimportant attribute. Adding more input modalities sometimes even harms the\nresult. In conclusion, it is crucial to consider the semantics of the item\nco-occurrence for the choice of an appropriate recommendation model and\ncarefully decide which metadata to exploit.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 13:56:00 GMT"}], "update_date": "2021-05-11", "authors_parsed": [["Vagliano", "Iacopo", ""], ["Galke", "Lukas", ""], ["Scherp", "Ansgar", ""]]}, {"id": "2105.04387", "submitter": "Jinjie Ni", "authors": "Jinjie Ni, Tom Young, Vlad Pandelea, Fuzhao Xue, Vinay Adiga, Erik\n  Cambria", "title": "Recent Advances in Deep Learning Based Dialogue Systems: A Systematic\n  Survey", "comments": "76 pages, 19 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dialogue systems are a popular Natural Language Processing (NLP) task as it\nis promising in real-life applications. It is also a complicated task since\nmany NLP tasks deserving study are involved. As a result, a multitude of novel\nworks on this task are carried out, and most of them are deep learning-based\ndue to the outstanding performance. In this survey, we mainly focus on the deep\nlearning-based dialogue systems. We comprehensively review state-of-the-art\nresearch outcomes in dialogue systems and analyze them from two angles: model\ntype and system type. Specifically, from the angle of model type, we discuss\nthe principles, characteristics, and applications of different models that are\nwidely used in dialogue systems. This will help researchers acquaint these\nmodels and see how they are applied in state-of-the-art frameworks, which is\nrather helpful when designing a new dialogue system. From the angle of system\ntype, we discuss task-oriented and open-domain dialogue systems as two streams\nof research, providing insight into the hot topics related. Furthermore, we\ncomprehensively review the evaluation methods and datasets for dialogue systems\nto pave the way for future research. Finally, some possible research trends are\nidentified based on the recent research outcomes. To the best of our knowledge,\nthis survey is the most comprehensive and up-to-date one at present in the area\nof dialogue systems and dialogue-related tasks, extensively covering the\npopular frameworks, topics, and datasets.\n  Keywords: Dialogue Systems, Chatbots, Conversational AI, Task-oriented, Open\nDomain, Chit-chat, Question Answering, Artificial Intelligence, Natural\nLanguage Processing, Information Retrieval, Deep Learning, Neural Networks,\nCNN, RNN, Hierarchical Recurrent Encoder-Decoder, Memory Networks, Attention,\nTransformer, Pointer Net, CopyNet, Reinforcement Learning, GANs, Knowledge\nGraph, Survey, Review\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 14:07:49 GMT"}, {"version": "v2", "created": "Thu, 13 May 2021 13:45:12 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 04:23:43 GMT"}, {"version": "v4", "created": "Tue, 1 Jun 2021 06:12:48 GMT"}], "update_date": "2021-06-02", "authors_parsed": [["Ni", "Jinjie", ""], ["Young", "Tom", ""], ["Pandelea", "Vlad", ""], ["Xue", "Fuzhao", ""], ["Adiga", "Vinay", ""], ["Cambria", "Erik", ""]]}, {"id": "2105.04651", "submitter": "Daniel Cohen", "authors": "Daniel Cohen, Bhaskar Mitra, Oleg Lesota, Navid Rekabsaz and Carsten\n  Eickhoff", "title": "Not All Relevance Scores are Equal: Efficient Uncertainty and\n  Calibration Modeling for Deep Retrieval Models", "comments": "ACM SIGIR preprint", "journal-ref": null, "doi": "10.1145/3404835.3462951", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In any ranking system, the retrieval model outputs a single score for a\ndocument based on its belief on how relevant it is to a given search query.\nWhile retrieval models have continued to improve with the introduction of\nincreasingly complex architectures, few works have investigated a retrieval\nmodel's belief in the score beyond the scope of a single value. We argue that\ncapturing the model's uncertainty with respect to its own scoring of a document\nis a critical aspect of retrieval that allows for greater use of current models\nacross new document distributions, collections, or even improving effectiveness\nfor down-stream tasks. In this paper, we address this problem via an efficient\nBayesian framework for retrieval models which captures the model's belief in\nthe relevance score through a stochastic process while adding only negligible\ncomputational overhead. We evaluate this belief via a ranking based calibration\nmetric showing that our approximate Bayesian framework significantly improves a\nretrieval model's ranking effectiveness through a risk aware reranking as well\nas its confidence calibration. Lastly, we demonstrate that this additional\nuncertainty information is actionable and reliable on down-stream tasks\nrepresented via cutoff prediction.\n", "versions": [{"version": "v1", "created": "Mon, 10 May 2021 20:15:53 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Cohen", "Daniel", ""], ["Mitra", "Bhaskar", ""], ["Lesota", "Oleg", ""], ["Rekabsaz", "Navid", ""], ["Eickhoff", "Carsten", ""]]}, {"id": "2105.04761", "submitter": "Chang Li", "authors": "Chang Li and Hua Ouyang", "title": "Federated Unbiased Learning to Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unbiased Learning to Rank (ULTR) studies the problem of learning a ranking\nfunction based on biased user interactions. In this framework, ULTR algorithms\nhave to rely on a large amount of user data that are collected, stored, and\naggregated by central servers.\n  In this paper, we consider an on-device search setting, where users search\nagainst their personal corpora on their local devices, and the goal is to learn\na ranking function from biased user interactions. Due to privacy constraints,\nusers' queries, personal documents, results lists, and raw interaction data\nwill not leave their devices, and ULTR has to be carried out via Federated\nLearning (FL).\n  Directly applying existing ULTR algorithms on users' devices could suffer\nfrom insufficient training data due to the limited amount of local\ninteractions. To address this problem, we propose the FedIPS algorithm, which\nlearns from user interactions on-device under the coordination of a central\nserver and uses click propensities to remove the position bias in user\ninteractions. Our evaluation of FedIPS on the Yahoo and Istella datasets shows\nthat FedIPS is robust over a range of position biases.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 03:01:14 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Li", "Chang", ""], ["Ouyang", "Hua", ""]]}, {"id": "2105.04769", "submitter": "Riku Togashi", "authors": "Riku Togashi, Masahiro Kato, Mayu Otani, Tetsuya Sakai, Shin'ichi\n  Satoh", "title": "Scalable Personalised Item Ranking through Parametric Density Estimation", "comments": "Accepted by SIGIR'21", "journal-ref": null, "doi": "10.1145/3404835.3462933", "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning from implicit feedback is challenging because of the difficult\nnature of the one-class problem: we can observe only positive examples. Most\nconventional methods use a pairwise ranking approach and negative samplers to\ncope with the one-class problem. However, such methods have two main drawbacks\nparticularly in large-scale applications; (1) the pairwise approach is severely\ninefficient due to the quadratic computational cost; and (2) even recent\nmodel-based samplers (e.g. IRGAN) cannot achieve practical efficiency due to\nthe training of an extra model.\n  In this paper, we propose a learning-to-rank approach, which achieves\nconvergence speed comparable to the pointwise counterpart while performing\nsimilarly to the pairwise counterpart in terms of ranking effectiveness. Our\napproach estimates the probability densities of positive items for each user\nwithin a rich class of distributions, viz. \\emph{exponential family}. In our\nformulation, we derive a loss function and the appropriate negative sampling\ndistribution based on maximum likelihood estimation. We also develop a\npractical technique for risk approximation and a regularisation scheme. We then\ndiscuss that our single-model approach is equivalent to an IRGAN variant under\na certain condition. Through experiments on real-world datasets, our approach\noutperforms the pointwise and pairwise counterparts in terms of effectiveness\nand efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 03:38:16 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Togashi", "Riku", ""], ["Kato", "Masahiro", ""], ["Otani", "Mayu", ""], ["Sakai", "Tetsuya", ""], ["Satoh", "Shin'ichi", ""]]}, {"id": "2105.04774", "submitter": "Xuhui Ren", "authors": "Xuhui Ren, Hongzhi Yin, Tong Chen, Hao Wang, Zi Huang, Kai Zheng", "title": "Learning to Ask Appropriate Questions in Conversational Recommendation", "comments": "to be published in SIGIR'2021", "journal-ref": null, "doi": "10.1145/3404835.3462839", "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conversational recommender systems (CRSs) have revolutionized the\nconventional recommendation paradigm by embracing dialogue agents to\ndynamically capture the fine-grained user preference. In a typical\nconversational recommendation scenario, a CRS firstly generates questions to\nlet the user clarify her/his demands and then makes suitable recommendations.\nHence, the ability to generate suitable clarifying questions is the key to\ntimely tracing users' dynamic preferences and achieving successful\nrecommendations. However, existing CRSs fall short in asking high-quality\nquestions because: (1) system-generated responses heavily depends on the\nperformance of the dialogue policy agent, which has to be trained with huge\nconversation corpus to cover all circumstances; and (2) current CRSs cannot\nfully utilize the learned latent user profiles for generating appropriate and\npersonalized responses.\n  To mitigate these issues, we propose the Knowledge-Based Question Generation\nSystem (KBQG), a novel framework for conversational recommendation. Distinct\nfrom previous conversational recommender systems, KBQG models a user's\npreference in a finer granularity by identifying the most relevant relations\nfrom a structured knowledge graph (KG). Conditioned on the varied importance of\ndifferent relations, the generated clarifying questions could perform better in\nimpelling users to provide more details on their preferences. Finially,\naccurate recommendations can be generated in fewer conversational turns.\nFurthermore, the proposed KBQG outperforms all baselines in our experiments on\ntwo real-world datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 03:58:10 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Ren", "Xuhui", ""], ["Yin", "Hongzhi", ""], ["Chen", "Tong", ""], ["Wang", "Hao", ""], ["Huang", "Zi", ""], ["Zheng", "Kai", ""]]}, {"id": "2105.04785", "submitter": "Yongchun Zhu", "authors": "Yongchun Zhu, Kaikai Ge, Fuzhen Zhuang, Ruobing Xie, Dongbo Xi, Xu\n  Zhang, Leyu Lin and Qing He", "title": "Transfer-Meta Framework for Cross-domain Recommendation to Cold-Start\n  Users", "comments": "5 pages, accepted by SIGIR2021", "journal-ref": null, "doi": "10.1145/3404835.3463010", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cold-start problems are enormous challenges in practical recommender systems.\nOne promising solution for this problem is cross-domain recommendation (CDR)\nwhich leverages rich information from an auxiliary (source) domain to improve\nthe performance of recommender system in the target domain. In these CDR\napproaches, the family of Embedding and Mapping methods for CDR (EMCDR) is very\neffective, which explicitly learn a mapping function from source embeddings to\ntarget embeddings with overlapping users. However, these approaches suffer from\none serious problem: the mapping function is only learned on limited\noverlapping users, and the function would be biased to the limited overlapping\nusers, which leads to unsatisfying generalization ability and degrades the\nperformance on cold-start users in the target domain. With the advantage of\nmeta learning which has good generalization ability to novel tasks, we propose\na transfer-meta framework for CDR (TMCDR) which has a transfer stage and a meta\nstage. In the transfer (pre-training) stage, a source model and a target model\nare trained on source and target domains, respectively. In the meta stage, a\ntask-oriented meta network is learned to implicitly transform the user\nembedding in the source domain to the target feature space. In addition, the\nTMCDR is a general framework that can be applied upon various base models,\ne.g., MF, BPR, CML. By utilizing data from Amazon and Douban, we conduct\nextensive experiments on 6 cross-domain tasks to demonstrate the superior\nperformance and compatibility of TMCDR.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 05:15:53 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Zhu", "Yongchun", ""], ["Ge", "Kaikai", ""], ["Zhuang", "Fuzhen", ""], ["Xie", "Ruobing", ""], ["Xi", "Dongbo", ""], ["Zhang", "Xu", ""], ["Lin", "Leyu", ""], ["He", "Qing", ""]]}, {"id": "2105.04790", "submitter": "Yongchun Zhu", "authors": "Yongchun Zhu, Ruobing Xie, Fuzhen Zhuang, Kaikai Ge, Ying Sun, Xu\n  Zhang, Leyu Lin and Juan Cao", "title": "Learning to Warm Up Cold Item Embeddings for Cold-start Recommendation\n  with Meta Scaling and Shifting Networks", "comments": "10 pages, accepted by SIGIR2021", "journal-ref": null, "doi": "10.1145/3404835.3462843", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, embedding techniques have achieved impressive success in\nrecommender systems. However, the embedding techniques are data demanding and\nsuffer from the cold-start problem. Especially, for the cold-start item which\nonly has limited interactions, it is hard to train a reasonable item ID\nembedding, called cold ID embedding, which is a major challenge for the\nembedding techniques. The cold item ID embedding has two main problems: (1) A\ngap is existing between the cold ID embedding and the deep model. (2) Cold ID\nembedding would be seriously affected by noisy interaction. However, most\nexisting methods do not consider both two issues in the cold-start problem,\nsimultaneously. To address these problems, we adopt two key ideas: (1) Speed up\nthe model fitting for the cold item ID embedding (fast adaptation). (2)\nAlleviate the influence of noise. Along this line, we propose Meta Scaling and\nShifting Networks to generate scaling and shifting functions for each item,\nrespectively. The scaling function can directly transform cold item ID\nembeddings into warm feature space which can fit the model better, and the\nshifting function is able to produce stable embeddings from the noisy\nembeddings. With the two meta networks, we propose Meta Warm Up Framework\n(MWUF) which learns to warm up cold ID embeddings. Moreover, MWUF is a general\nframework that can be applied upon various existing deep recommendation models.\nThe proposed model is evaluated on three popular benchmarks, including both\nrecommendation and advertising datasets. The evaluation results demonstrate its\nsuperior performance and compatibility.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 05:22:06 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Zhu", "Yongchun", ""], ["Xie", "Ruobing", ""], ["Zhuang", "Fuzhen", ""], ["Ge", "Kaikai", ""], ["Sun", "Ying", ""], ["Zhang", "Xu", ""], ["Lin", "Leyu", ""], ["Cao", "Juan", ""]]}, {"id": "2105.04850", "submitter": "Magdalena Kaiser", "authors": "Magdalena Kaiser, Rishiraj Saha Roy, Gerhard Weikum", "title": "Reinforcement Learning from Reformulations in Conversational Question\n  Answering over Knowledge Graphs", "comments": "SIGIR 2021 Long Paper, 11 pages", "journal-ref": null, "doi": "10.1145/3404835.3462859", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of personal assistants has made conversational question answering\n(ConvQA) a very popular mechanism for user-system interaction. State-of-the-art\nmethods for ConvQA over knowledge graphs (KGs) can only learn from crisp\nquestion-answer pairs found in popular benchmarks. In reality, however, such\ntraining data is hard to come by: users would rarely mark answers explicitly as\ncorrect or wrong. In this work, we take a step towards a more natural learning\nparadigm - from noisy and implicit feedback via question reformulations. A\nreformulation is likely to be triggered by an incorrect system response,\nwhereas a new follow-up question could be a positive signal on the previous\nturn's answer. We present a reinforcement learning model, termed CONQUER, that\ncan learn from a conversational stream of questions and reformulations. CONQUER\nmodels the answering process as multiple agents walking in parallel on the KG,\nwhere the walks are determined by actions sampled using a policy network. This\npolicy network takes the question along with the conversational context as\ninputs and is trained via noisy rewards obtained from the reformulation\nlikelihood. To evaluate CONQUER, we create and release ConvRef, a benchmark\nwith about 11k natural conversations containing around 205k reformulations.\nExperiments show that CONQUER successfully learns to answer conversational\nquestions from noisy reward signals, significantly improving over a\nstate-of-the-art baseline.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 08:08:35 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Kaiser", "Magdalena", ""], ["Roy", "Rishiraj Saha", ""], ["Weikum", "Gerhard", ""]]}, {"id": "2105.04903", "submitter": "Faegheh Hasibi", "authors": "Hideaki Joko, Faegheh Hasibi, Krisztian Balog, Arjen P. de Vries", "title": "Conversational Entity Linking: Problem Definition and Datasets", "comments": null, "journal-ref": null, "doi": "10.1145/3404835.3463258", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine understanding of user utterances in conversational systems is of\nutmost importance for enabling engaging and meaningful conversations with\nusers. Entity Linking (EL) is one of the means of text understanding, with\nproven efficacy for various downstream tasks in information retrieval. In this\npaper, we study entity linking for conversational systems. To develop a better\nunderstanding of what EL in a conversational setting entails, we analyze a\nlarge number of dialogues from existing conversational datasets and annotate\nreferences to concepts, named entities, and personal entities using\ncrowdsourcing. Based on the annotated dialogues, we identify the main\ncharacteristics of conversational entity linking. Further, we report on the\nperformance of traditional EL systems on our Conversational Entity Linking\ndataset, ConEL, and present an extension to these methods to better fit the\nconversational setting. The resources released with this paper include\nannotated datasets, detailed descriptions of crowdsourcing setups, as well as\nthe annotations produced by various EL systems. These new resources allow for\nan investigation of how the role of entities in conversations is different from\nthat in documents or isolated short text utterances like queries and tweets,\nand complement existing conversational datasets.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 09:44:27 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Joko", "Hideaki", ""], ["Hasibi", "Faegheh", ""], ["Balog", "Krisztian", ""], ["de Vries", "Arjen P.", ""]]}, {"id": "2105.04971", "submitter": "Mikhail Fain", "authors": "Mikhail Fain, Niall Twomey and Danushka Bollegala", "title": "Backretrieval: An Image-Pivoted Evaluation Metric for Cross-Lingual Text\n  Representations Without Parallel Corpora", "comments": "SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3463027", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-lingual text representations have gained popularity lately and act as\nthe backbone of many tasks such as unsupervised machine translation and\ncross-lingual information retrieval, to name a few. However, evaluation of such\nrepresentations is difficult in the domains beyond standard benchmarks due to\nthe necessity of obtaining domain-specific parallel language data across\ndifferent pairs of languages. In this paper, we propose an automatic metric for\nevaluating the quality of cross-lingual textual representations using images as\na proxy in a paired image-text evaluation dataset. Experimentally,\nBackretrieval is shown to highly correlate with ground truth metrics on\nannotated datasets, and our analysis shows statistically significant\nimprovements over baselines. Our experiments conclude with a case study on a\nrecipe dataset without parallel cross-lingual data. We illustrate how to judge\ncross-lingual embedding quality with Backretrieval, and validate the outcome\nwith a small human study.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 12:14:24 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Fain", "Mikhail", ""], ["Twomey", "Niall", ""], ["Bollegala", "Danushka", ""]]}, {"id": "2105.05008", "submitter": "Rishiraj Saha Roy", "authors": "Khanh Hiep Tran, Azin Ghazimatin, Rishiraj Saha Roy", "title": "Counterfactual Explanations for Neural Recommenders", "comments": "SIGIR 2021 Short Paper, 5 pages", "journal-ref": null, "doi": "10.1145/3404835.3463005", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding why specific items are recommended to users can significantly\nincrease their trust and satisfaction in the system. While neural recommenders\nhave become the state-of-the-art in recent years, the complexity of deep models\nstill makes the generation of tangible explanations for end users a challenging\nproblem. Existing methods are usually based on attention distributions over a\nvariety of features, which are still questionable regarding their suitability\nas explanations, and rather unwieldy to grasp for an end user. Counterfactual\nexplanations based on a small set of the user's own actions have been shown to\nbe an acceptable solution to the tangibility problem. However, current work on\nsuch counterfactuals cannot be readily applied to neural models. In this work,\nwe propose ACCENT, the first general framework for finding counterfactual\nexplanations for neural recommenders. It extends recently-proposed influence\nfunctions for identifying training points most relevant to a recommendation,\nfrom a single to a pair of items, while deducing a counterfactual set in an\niterative process. We use ACCENT to generate counterfactual explanations for\ntwo popular neural models, Neural Collaborative Filtering (NCF) and Relational\nCollaborative Filtering (RCF), and demonstrate its feasibility on a sample of\nthe popular MovieLens 100K dataset.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 13:16:18 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Tran", "Khanh Hiep", ""], ["Ghazimatin", "Azin", ""], ["Roy", "Rishiraj Saha", ""]]}, {"id": "2105.05037", "submitter": "Zhongping Ji", "authors": "Zhongping Ji", "title": "BikNN: Anomaly Estimation in Bilateral Domains with k-Nearest Neighbors", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, a novel framework for anomaly estimation is proposed. The\nbasic idea behind our method is to reduce the data into a two-dimensional space\nand then rank each data point in the reduced space. We attempt to estimate the\ndegree of anomaly in both spatial and density domains. Specifically, we\ntransform the data points into a density space and measure the distances in\ndensity domain between each point and its k-Nearest Neighbors in spatial\ndomain. Then, an anomaly coordinate system is built by collecting two\nunilateral anomalies from k-nearest neighbors of each point. Further more, we\nintroduce two schemes to model their correlation and combine them to get the\nfinal anomaly score. Experiments performed on the synthetic and real world\ndatasets demonstrate that the proposed method performs well and achieve highest\naverage performance. We also show that the proposed method can provide\nvisualization and classification of the anomalies in a simple manner. Due to\nthe complexity of the anomaly, none of the existing methods can perform best on\nall benchmark datasets. Our method takes into account both the spatial domain\nand the density domain and can be adapted to different datasets by adjusting a\nfew parameters manually.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 13:45:29 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Ji", "Zhongping", ""]]}, {"id": "2105.05076", "submitter": "Hasan Abu Rasheed", "authors": "H. Abu-Rasheed, C. Weber, J. Zenkert, P. Czerner, R. Krumm, M. Fathi", "title": "A Text Extraction-Based Smart Knowledge Graph Composition for\n  Integrating Lessons Learned during the Microchip Design", "comments": null, "journal-ref": "In: Arai K., Kapoor S., Bhatia R. (eds) Intelligent Systems and\n  Applications. IntelliSys 2020. Advances in Intelligent Systems and Computing,\n  vol 1251. Springer, Cham", "doi": "10.1007/978-3-030-55187-2_43", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The production of microchips is a complex and thus well documented process.\nTherefore, available textual data about the production can be overwhelming in\nterms of quantity. This affects the visibility and retrieval of a certain piece\nof information when it is most needed. In this paper, we propose a dynamic\napproach to interlink the information extracted from multisource\nproduction-relevant documents through the creation of a knowledge graph. This\ngraph is constructed in order to support searchability and enhance user's\naccess to large-scale production information. Text mining methods are firstly\nutilized to extract data from multiple documentation sources. Document\nrelations are then mined and extracted for the composition of the knowledge\ngraph. Graph search functionality is then supported with a recommendation\nuse-case to enhance users' access to information that is related to the initial\ndocuments. The proposed approach is tailored to and tested on microchip\ndesign-relevant documents. It enhances the visibility and findability of\nprevious design-failure-cases during the process of a new chip design.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 14:26:45 GMT"}], "update_date": "2021-05-12", "authors_parsed": [["Abu-Rasheed", "H.", ""], ["Weber", "C.", ""], ["Zenkert", "J.", ""], ["Czerner", "P.", ""], ["Krumm", "R.", ""], ["Fathi", "M.", ""]]}, {"id": "2105.05326", "submitter": "Cheng Qian", "authors": "Cheng Qian, Nikos Kargas, Cao Xiao, Lucas Glass, Nicholas\n  Sidiropoulos, Jimeng Sun", "title": "Multi-version Tensor Completion for Time-delayed Spatio-temporal Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Real-world spatio-temporal data is often incomplete or inaccurate due to\nvarious data loading delays. For example, a location-disease-time tensor of\ncase counts can have multiple delayed updates of recent temporal slices for\nsome locations or diseases. Recovering such missing or noisy (under-reported)\nelements of the input tensor can be viewed as a generalized tensor completion\nproblem. Existing tensor completion methods usually assume that i) missing\nelements are randomly distributed and ii) noise for each tensor element is\ni.i.d. zero-mean. Both assumptions can be violated for spatio-temporal tensor\ndata. We often observe multiple versions of the input tensor with different\nunder-reporting noise levels. The amount of noise can be time- or\nlocation-dependent as more updates are progressively introduced to the tensor.\nWe model such dynamic data as a multi-version tensor with an extra tensor mode\ncapturing the data updates. We propose a low-rank tensor model to predict the\nupdates over time. We demonstrate that our method can accurately predict the\nground-truth values of many real-world tensors. We obtain up to 27.2% lower\nroot mean-squared-error compared to the best baseline method. Finally, we\nextend our method to track the tensor data over time, leading to significant\ncomputational savings.\n", "versions": [{"version": "v1", "created": "Tue, 11 May 2021 19:55:56 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Qian", "Cheng", ""], ["Kargas", "Nikos", ""], ["Xiao", "Cao", ""], ["Glass", "Lucas", ""], ["Sidiropoulos", "Nicholas", ""], ["Sun", "Jimeng", ""]]}, {"id": "2105.05385", "submitter": "Tianxue Hu", "authors": "Tianxue Hu and Claire Arthur", "title": "A Statistical Model for Melody Reduction", "comments": "5 pages, 1 figure. Proceeding and presentation available at Future\n  Directions of Music Cognition but the conference has not yet officially\n  published until summer 2021. http://org.osu.edu/mascats/march-6-talks/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR eess.AS stat.AP", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A commonly-cited reason for the poor performance of automatic chord\nestimation (ACE) systems within music information retrieval (MIR) is that\nnon-chord tones (i.e., notes outside the supporting harmony) contribute to\nerror during the labeling process. Despite the prevalence of machine learning\napproaches in MIR, there are cases where alternative approaches provide a\nsimpler alternative while allowing for insights into musicological practices.\nIn this project, we present a statistical model for predicting chord tones\nbased on music theory rules. Our model is currently focused on predicting chord\ntones in classical music, since composition in this style is highly\nconstrained, theoretically making the placement of chord tones highly\npredictable. Indeed, music theorists have labeling systems for every variety of\nnon-chord tone, primarily classified by the note's metric position and\nintervals of approach and departure. Using metric position, duration, and\nmelodic intervals as predictors, we build a statistical model for predicting\nchord tones using the TAVERN dataset. While our probabilistic approach is\nsimilar to other efforts in the domain of automatic harmonic analysis, our\nfocus is on melodic reduction rather than predicting harmony. However, we hope\nto pursue applications for ACE in the future. Finally, we implement our melody\nreduction model using an existing symbolic visualization tool, to assist with\nmelody reduction and non-chord tone identification for computational musicology\nresearchers and music theorists.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 01:10:35 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Hu", "Tianxue", ""], ["Arthur", "Claire", ""]]}, {"id": "2105.05389", "submitter": "Binh Nguyen-Thai", "authors": "Binh Nguyen, Atsuhiro Takasu", "title": "Co-Factorization Model for Collaborative Filtering with Session-based\n  Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization (MF) is a common method for collaborative filtering. MF\nrepresents user preferences and item attributes by latent factors. Despite that\nMF is a powerful method, it suffers from not be able to identifying strong\nassociations of closely related items. In this work, we propose a method for\nmatrix factorization that can reflect the localized relationships between\nstrong related items into the latent representations of items. We do it by\ncombine two worlds: MF for collaborative filtering and item2vec for\nitem-embedding. The proposed method is able to exploit item-item relations. Our\nexperiments on several datasets demonstrates a better performance with the\nprevious work.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 01:24:28 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Nguyen", "Binh", ""], ["Takasu", "Atsuhiro", ""]]}, {"id": "2105.05435", "submitter": "Haoyang Liu", "authors": "Haoyang Liu, M. Janina Sarol and Halil Kilicoglu", "title": "UIUC_BioNLP at SemEval-2021 Task 11: A Cascade of Neural Models for\n  Structuring Scholarly NLP Contributions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a cascade of neural models that performs sentence classification,\nphrase recognition, and triple extraction to automatically structure the\nscholarly contributions of NLP publications. To identify the most important\ncontribution sentences in a paper, we used a BERT-based classifier with\npositional features (Subtask 1). A BERT-CRF model was used to recognize and\ncharacterize relevant phrases in contribution sentences (Subtask 2). We\ncategorized the triples into several types based on whether and how their\nelements were expressed in text, and addressed each type using separate\nBERT-based classifiers as well as rules (Subtask 3). Our system was officially\nranked second in Phase 1 evaluation and first in both parts of Phase 2\nevaluation. After fixing a submission error in Pharse 1, our approach yields\nthe best results overall. In this paper, in addition to a system description,\nwe also provide further analysis of our results, highlighting its strengths and\nlimitations. We make our code publicly available at\nhttps://github.com/Liu-Hy/nlp-contrib-graph.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 05:24:35 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Liu", "Haoyang", ""], ["Sarol", "M. Janina", ""], ["Kilicoglu", "Halil", ""]]}, {"id": "2105.05503", "submitter": "Oshan Mudannayake", "authors": "Oshan Mudannayake, Nalin Ranasinghe", "title": "kMatrix: A Space Efficient Streaming Graph Summarization Technique", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The amount of collected information on data repositories has vastly increased\nwith the advent of the internet. It has become increasingly complex to deal\nwith these massive data streams due to their sheer volume and the throughput of\nincoming data. Many of these data streams are mapped into graphs, which helps\ndiscover some of their properties. However, due to the difficulty in processing\nmassive streaming graphs, they are summarized such that their properties can be\napproximately evaluated using the summaries. gSketch, TCM, and gMatrix are some\nof the major streaming graph summarization techniques. Our primary contribution\nis devising kMatrix, which is much more memory efficient than existing\nstreaming graph summarization techniques. We achieved this by partitioning the\nallocated memory using a sample of the original graph stream. Through the\nexperiments, we show that kMatrix can achieve a significantly less error for\nthe queries using the same space as that of TCM and gMatrix.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 08:26:49 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Mudannayake", "Oshan", ""], ["Ranasinghe", "Nalin", ""]]}, {"id": "2105.05563", "submitter": "Yanbo Xue", "authors": "Yuan Cheng and Yanbo Xue", "title": "Looking at CTR Prediction Again: Is Attention All You Need?", "comments": "9 pages, 2 figures, 4 tables, SIGIR'21", "journal-ref": null, "doi": "10.1145/3404835.3462936", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Click-through rate (CTR) prediction is a critical problem in web search,\nrecommendation systems and online advertisement displaying. Learning good\nfeature interactions is essential to reflect user's preferences to items. Many\nCTR prediction models based on deep learning have been proposed, but\nresearchers usually only pay attention to whether state-of-the-art performance\nis achieved, and ignore whether the entire framework is reasonable. In this\nwork, we use the discrete choice model in economics to redefine the CTR\nprediction problem, and propose a general neural network framework built on\nself-attention mechanism. It is found that most existing CTR prediction models\nalign with our proposed general framework. We also examine the expressive power\nand model complexity of our proposed framework, along with potential extensions\nto some existing models. And finally we demonstrate and verify our insights\nthrough some experimental results on public datasets.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 10:27:14 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Cheng", "Yuan", ""], ["Xue", "Yanbo", ""]]}, {"id": "2105.05571", "submitter": "Chen Shani", "authors": "Chen Shani, Alexander Libov, Sofia Tolmach, Liane Lewin-Eytan, Yoelle\n  Maarek, Dafna Shahaf", "title": "\"Alexa, what do you do for fun?\" Characterizing playful requests with\n  virtual assistants", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual assistants such as Amazon's Alexa, Apple's Siri, Google Home, and\nMicrosoft's Cortana, are becoming ubiquitous in our daily lives and\nsuccessfully help users in various daily tasks, such as making phone calls or\nplaying music. Yet, they still struggle with playful utterances, which are not\nmeant to be interpreted literally. Examples include jokes or absurd requests or\nquestions such as, \"Are you afraid of the dark?\", \"Who let the dogs out?\", or\n\"Order a zillion gummy bears\". Today, virtual assistants often return\nirrelevant answers to such utterances, except for hard-coded ones addressed by\ncanned replies.\n  To address the challenge of automatically detecting playful utterances, we\nfirst characterize the different types of playful human-virtual assistant\ninteraction. We introduce a taxonomy of playful requests rooted in theories of\nhumor and refined by analyzing real-world traffic from Alexa. We then focus on\none node, personification, where users refer to the virtual assistant as a\nperson (\"What do you do for fun?\"). Our conjecture is that understanding such\nutterances will improve user experience with virtual assistants. We conducted a\nWizard-of-Oz user study and showed that endowing virtual assistant s with the\nability to identify humorous opportunities indeed has the potential to increase\nuser satisfaction. We hope this work will contribute to the understanding of\nthe landscape of the problem and inspire novel ideas and techniques towards the\nvision of giving virtual assistants a sense of humor.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 10:48:00 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Shani", "Chen", ""], ["Libov", "Alexander", ""], ["Tolmach", "Sofia", ""], ["Lewin-Eytan", "Liane", ""], ["Maarek", "Yoelle", ""], ["Shahaf", "Dafna", ""]]}, {"id": "2105.05686", "submitter": "Guilherme Rosa", "authors": "Guilherme Moraes Rosa, Ruan Chaves Rodrigues, Roberto Lotufo, Rodrigo\n  Nogueira", "title": "Yes, BM25 is a Strong Baseline for Legal Case Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe our single submission to task 1 of COLIEE 2021. Our vanilla BM25\ngot second place, well above the median of submissions. Code is available at\nhttps://github.com/neuralmind-ai/coliee.\n", "versions": [{"version": "v1", "created": "Mon, 26 Apr 2021 18:33:38 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Rosa", "Guilherme Moraes", ""], ["Rodrigues", "Ruan Chaves", ""], ["Lotufo", "Roberto", ""], ["Nogueira", "Rodrigo", ""]]}, {"id": "2105.05710", "submitter": "Niall Twomey", "authors": "Kentaro Takiguchi and Mikhail Fain and Niall Twomey and Luis M Vaquero", "title": "Evaluation of Field-Aware Neural Ranking Models for Recipe Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Explicitly modelling field interactions and correlations in complex document\nstructures has recently gained popularity in neural document embedding and\nretrieval tasks. Although this requires the specification of bespoke\ntask-dependent models, encouraging empirical results are beginning to emerge.\nWe present the first in-depth analyses of non-linear multi-field interaction\n(NL-MFI) ranking in the cooking domain in this work. Our results show that\nfield-weighted factorisation machines models provide a statistically\nsignificant improvement over baselines in recipe retrieval tasks. Additionally,\nwe show that sparsely capturing subsets of field interactions based on domain\nknowledge and feature selection heuristics offers significant advantages over\nbaselines and exhaustive alternatives. Although field-interaction aware models\nare more elaborate from an architectural basis, they are often more\ndata-efficient in optimisation and are better suited for explainability due to\nmirrored document and model factorisation.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 14:53:05 GMT"}, {"version": "v2", "created": "Thu, 8 Jul 2021 12:22:38 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Takiguchi", "Kentaro", ""], ["Fain", "Mikhail", ""], ["Twomey", "Niall", ""], ["Vaquero", "Luis M", ""]]}, {"id": "2105.05733", "submitter": "Mariano Beguerisse-D\\'iaz", "authors": "Mariano Beguerisse-D\\'iaz, Dimitrios Korkinof, Till Hoffmann", "title": "Thematic recommendations on knowledge graphs using multilayer networks", "comments": "20 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework to generate and evaluate thematic recommendations\nbased on multilayer network representations of knowledge graphs (KGs). In this\nrepresentation, each layer encodes a different type of relationship in the KG,\nand directed interlayer couplings connect the same entity in different roles.\nThe relative importance of different types of connections is captured by an\nintuitive salience matrix that can be estimated from data, tuned to incorporate\ndomain knowledge, address different use cases, or respect business logic.\n  We apply an adaptation of the personalised PageRank algorithm to multilayer\nmodels of KGs to generate item-item recommendations. These recommendations\nreflect the knowledge we hold about the content and are suitable for thematic\nand/or cold-start recommendation settings. Evaluating thematic recommendations\nfrom user data presents unique challenges that we address by developing a\nmethod to evaluate recommendations relying on user-item ratings, yet respecting\ntheir thematic nature. We also show that the salience matrix can be estimated\nfrom user data. We demonstrate the utility of our methods by significantly\nimproving consumption metrics in an AB test where collaborative filtering\ndelivered subpar performance. We also apply our approach to movie\nrecommendation using publicly-available data to ensure the reproducibility of\nour results. We demonstrate that our approach outperforms existing thematic\nrecommendation methods and is even competitive with collaborative filtering\napproaches.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 15:30:21 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Beguerisse-D\u00edaz", "Mariano", ""], ["Korkinof", "Dimitrios", ""], ["Hoffmann", "Till", ""]]}, {"id": "2105.05779", "submitter": "Michael Ekstrand", "authors": "Michael D. Ekstrand and Anubrata Das and Robin Burke and Fernando Diaz", "title": "Fairness and Discrimination in Information Access Systems", "comments": "Currently under review. Please send comments to the authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation, information retrieval, and other information access systems\npose unique challenges for investigating and applying the fairness and\nnon-discrimination concepts that have been developed for studying other machine\nlearning systems. While fair information access shares many commonalities with\nfair classification, the multistakeholder nature of information access\napplications, the rank-based problem setting, the centrality of personalization\nin many cases, and the role of user response complicate the problem of\nidentifying precisely what types and operationalizations of fairness may be\nrelevant, let alone measuring or promoting them.\n  In this monograph, we present a taxonomy of the various dimensions of fair\ninformation access and survey the literature to date on this new and\nrapidly-growing topic. We preface this with brief introductions to information\naccess and algorithmic fairness, to facilitate use of this work by scholars\nwith experience in one (or neither) of these fields who wish to learn about\ntheir intersection. We conclude with several open problems in fair information\naccess, along with some suggestions for how to approach research in this space.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 16:51:45 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Ekstrand", "Michael D.", ""], ["Das", "Anubrata", ""], ["Burke", "Robin", ""], ["Diaz", "Fernando", ""]]}, {"id": "2105.06067", "submitter": "Yang Zhang", "authors": "Yang Zhang, Fuli Feng, Xiangnan He, Tianxin Wei, Chonggang Song,\n  Guohui Ling, Yongdong Zhang", "title": "Causal Intervention for Leveraging Popularity Bias in Recommendation", "comments": "Appear in SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462875", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender system usually faces popularity bias issues: from the data\nperspective, items exhibit uneven (long-tail) distribution on the interaction\nfrequency; from the method perspective, collaborative filtering methods are\nprone to amplify the bias by over-recommending popular items. It is undoubtedly\ncritical to consider popularity bias in recommender systems, and existing work\nmainly eliminates the bias effect. However, we argue that not all biases in the\ndata are bad -- some items demonstrate higher popularity because of their\nbetter intrinsic quality. Blindly pursuing unbiased learning may remove the\nbeneficial patterns in the data, degrading the recommendation accuracy and user\nsatisfaction.\n  This work studies an unexplored problem in recommendation -- how to leverage\npopularity bias to improve the recommendation accuracy. The key lies in two\naspects: how to remove the bad impact of popularity bias during training, and\nhow to inject the desired popularity bias in the inference stage that generates\ntop-K recommendations. This questions the causal mechanism of the\nrecommendation generation process. Along this line, we find that item\npopularity plays the role of confounder between the exposed items and the\nobserved interactions, causing the bad effect of bias amplification. To achieve\nour goal, we propose a new training and inference paradigm for recommendation\nnamed Popularity-bias Deconfounding and Adjusting (PDA). It removes the\nconfounding popularity bias in model training and adjusts the recommendation\nscore with desired popularity bias via causal intervention. We demonstrate the\nnew paradigm on latent factor model and perform extensive experiments on three\nreal-world datasets. Empirical studies validate that the deconfounded training\nis helpful to discover user real interests and the inference adjustment with\npopularity bias could further improve the recommendation accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 04:02:51 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Zhang", "Yang", ""], ["Feng", "Fuli", ""], ["He", "Xiangnan", ""], ["Wei", "Tianxin", ""], ["Song", "Chonggang", ""], ["Ling", "Guohui", ""], ["Zhang", "Yongdong", ""]]}, {"id": "2105.06083", "submitter": "Zihan Wang", "authors": "Zihan Wang, Hongye Song, Zhaochun Ren, Pengjie Ren, Zhumin Chen,\n  Xiaozhong Liu, Hongsong Li, Maarten de Rijke", "title": "Cross-Domain Contract Element Extraction with a Bi-directional Feedback\n  Clause-Element Relation Network", "comments": "Accepted by SIGIR2021", "journal-ref": null, "doi": "10.1145/3404835.3462873", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contract element extraction (CEE) is the novel task of automatically\nidentifying and extracting legally relevant elements such as contract dates,\npayments, and legislation references from contracts. Automatic methods for this\ntask view it as a sequence labeling problem and dramatically reduce human\nlabor. However, as contract genres and element types may vary widely, a\nsignificant challenge for this sequence labeling task is how to transfer\nknowledge from one domain to another, i.e., cross-domain CEE. Cross-domain CEE\ndiffers from cross-domain named entity recognition (NER) in two important ways.\nFirst, contract elements are far more fine-grained than named entities, which\nhinders the transfer of extractors. Second, the extraction zones for\ncross-domain CEE are much larger than for cross-domain NER. As a result, the\ncontexts of elements from different domains can be more diverse. We propose a\nframework, the Bi-directional Feedback cLause-Element relaTion network\n(Bi-FLEET), for the cross-domain CEE task that addresses the above challenges.\nBi-FLEET has three main components: (1) a context encoder, (2) a clause-element\nrelation encoder, and (3) an inference layer. To incorporate invariant\nknowledge about element and clause types, a clause-element graph is constructed\nacross domains and a hierarchical graph neural network is adopted in the\nclause-element relation encoder. To reduce the influence of context variations,\na multi-task framework with a bi-directional feedback scheme is designed in the\ninference layer, conducting both clause classification and element extraction.\nThe experimental results over both cross-domain NER and CEE tasks show that\nBi-FLEET significantly outperforms state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 05:14:36 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Wang", "Zihan", ""], ["Song", "Hongye", ""], ["Ren", "Zhaochun", ""], ["Ren", "Pengjie", ""], ["Chen", "Zhumin", ""], ["Liu", "Xiaozhong", ""], ["Li", "Hongsong", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2105.06247", "submitter": "Hao Zhang", "authors": "Hao Zhang, Aixin Sun, Wei Jing, Guoshun Nan, Liangli Zhen, Joey Tianyi\n  Zhou, Rick Siow Mong Goh", "title": "Video Corpus Moment Retrieval with Contrastive Learning", "comments": "11 pages, 7 figures and 6 tables. Accepted by SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462874", "report-no": null, "categories": "cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a collection of untrimmed and unsegmented videos, video corpus moment\nretrieval (VCMR) is to retrieve a temporal moment (i.e., a fraction of a video)\nthat semantically corresponds to a given text query. As video and text are from\ntwo distinct feature spaces, there are two general approaches to address VCMR:\n(i) to separately encode each modality representations, then align the two\nmodality representations for query processing, and (ii) to adopt fine-grained\ncross-modal interaction to learn multi-modal representations for query\nprocessing. While the second approach often leads to better retrieval accuracy,\nthe first approach is far more efficient. In this paper, we propose a Retrieval\nand Localization Network with Contrastive Learning (ReLoCLNet) for VCMR. We\nadopt the first approach and introduce two contrastive learning objectives to\nrefine video encoder and text encoder to learn video and text representations\nseparately but with better alignment for VCMR. The video contrastive learning\n(VideoCL) is to maximize mutual information between query and candidate video\nat video-level. The frame contrastive learning (FrameCL) aims to highlight the\nmoment region corresponds to the query at frame-level, within a video.\nExperimental results show that, although ReLoCLNet encodes text and video\nseparately for efficiency, its retrieval accuracy is comparable with baselines\nadopting cross-modal interaction learning.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 12:54:39 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Zhang", "Hao", ""], ["Sun", "Aixin", ""], ["Jing", "Wei", ""], ["Nan", "Guoshun", ""], ["Zhen", "Liangli", ""], ["Zhou", "Joey Tianyi", ""], ["Goh", "Rick Siow Mong", ""]]}, {"id": "2105.06275", "submitter": "Nicol\\`o Felicioni", "authors": "Nicol\\`o Felicioni, Maurizio Ferrari Dacrema, Paolo Cremonesi", "title": "A Methodology for the Offline Evaluation of Recommender Systems in a\n  User Interface with Multiple Carousels", "comments": null, "journal-ref": "Adjunct Proceedings of the 29th ACM Conference on User Modeling,\n  Adaptation and Personalization (UMAP '21 Adjunct), June 21--25, 2021,\n  Utrecht, Netherlands", "doi": "10.1145/3450614.3461680", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many video-on-demand and music streaming services provide the user with a\npage consisting of several recommendation lists, i.e. widgets or swipeable\ncarousels, each built with a specific criterion (e.g. most recent, TV series,\netc.). Finding efficient strategies to select which carousels to display is an\nactive research topic of great industrial interest. In this setting, the\noverall quality of the recommendations of a new algorithm cannot be assessed by\nmeasuring solely its individual recommendation quality. Rather, it should be\nevaluated in a context where other recommendation lists are already available,\nto account for how they complement each other. This is not considered by\ntraditional offline evaluation protocols. Hence, we propose an offline\nevaluation protocol for a carousel setting in which the recommendation quality\nof a model is measured by how much it improves upon that of an already\navailable set of carousels. We report experiments on publicly available\ndatasets on the movie domain and notice that under a carousel setting the\nranking of the algorithms change. In particular, when a SLIM carousel is\navailable, matrix factorization models tend to be preferred, while item-based\nmodels are penalized. We also propose to extend ranking metrics to the\ntwo-dimensional carousel layout in order to account for a known position bias,\ni.e. users will not explore the lists sequentially, but rather concentrate on\nthe top-left corner of the screen.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 13:14:59 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Felicioni", "Nicol\u00f2", ""], ["Dacrema", "Maurizio Ferrari", ""], ["Cremonesi", "Paolo", ""]]}, {"id": "2105.06323", "submitter": "Dongha Lee", "authors": "Dongha Lee, SeongKu Kang, Hyunjun Ju, Chanyoung Park, Hwanjo Yu", "title": "Bootstrapping User and Item Representations for One-Class Collaborative\n  Filtering", "comments": "SIGIR 2021. 9 pages + references (1 page). 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The goal of one-class collaborative filtering (OCCF) is to identify the\nuser-item pairs that are positively-related but have not been interacted yet,\nwhere only a small portion of positive user-item interactions (e.g., users'\nimplicit feedback) are observed. For discriminative modeling between positive\nand negative interactions, most previous work relied on negative sampling to\nsome extent, which refers to considering unobserved user-item pairs as\nnegative, as actual negative ones are unknown. However, the negative sampling\nscheme has critical limitations because it may choose \"positive but unobserved\"\npairs as negative. This paper proposes a novel OCCF framework, named as BUIR,\nwhich does not require negative sampling. To make the representations of\npositively-related users and items similar to each other while avoiding a\ncollapsed solution, BUIR adopts two distinct encoder networks that learn from\neach other; the first encoder is trained to predict the output of the second\nencoder as its target, while the second encoder provides the consistent targets\nby slowly approximating the first encoder. In addition, BUIR effectively\nalleviates the data sparsity issue of OCCF, by applying stochastic data\naugmentation to encoder inputs. Based on the neighborhood information of users\nand items, BUIR randomly generates the augmented views of each positive\ninteraction each time it encodes, then further trains the model by this\nself-supervision. Our extensive experiments demonstrate that BUIR consistently\nand significantly outperforms all baseline methods by a large margin especially\nfor much sparse datasets in which any assumptions about negative interactions\nare less valid.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 14:24:13 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Lee", "Dongha", ""], ["Kang", "SeongKu", ""], ["Ju", "Hyunjun", ""], ["Park", "Chanyoung", ""], ["Yu", "Hwanjo", ""]]}, {"id": "2105.06339", "submitter": "Shoujin Wang", "authors": "Shoujin Wang, Liang Hu, Yan Wang, Xiangnan He, Quan Z. Sheng, Mehmet\n  A. Orgun, Longbing Cao, Francesco Ricci, Philip S. Yu", "title": "Graph Learning based Recommender Systems: A Review", "comments": "Accepted by IJCAI 2021 Survey Track, copyright is owned to IJCAI. The\n  first systematic survey on graph learning based recommender systems. arXiv\n  admin note: text overlap with arXiv:2004.11718", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent years have witnessed the fast development of the emerging topic of\nGraph Learning based Recommender Systems (GLRS). GLRS employ advanced graph\nlearning approaches to model users' preferences and intentions as well as\nitems' characteristics for recommendations. Differently from other RS\napproaches, including content-based filtering and collaborative filtering, GLRS\nare built on graphs where the important objects, e.g., users, items, and\nattributes, are either explicitly or implicitly connected. With the rapid\ndevelopment of graph learning techniques, exploring and exploiting homogeneous\nor heterogeneous relations in graphs are a promising direction for building\nmore effective RS. In this paper, we provide a systematic review of GLRS, by\ndiscussing how they extract important knowledge from graph-based\nrepresentations to improve the accuracy, reliability and explainability of the\nrecommendations. First, we characterize and formalize GLRS, and then summarize\nand categorize the key challenges and main progress in this novel research\narea. Finally, we share some new research directions in this vibrant area.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 14:50:45 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Wang", "Shoujin", ""], ["Hu", "Liang", ""], ["Wang", "Yan", ""], ["He", "Xiangnan", ""], ["Sheng", "Quan Z.", ""], ["Orgun", "Mehmet A.", ""], ["Cao", "Longbing", ""], ["Ricci", "Francesco", ""], ["Yu", "Philip S.", ""]]}, {"id": "2105.06365", "submitter": "Shuo Zhang", "authors": "Shuo Zhang and Krisztian Balog", "title": "Semantic Table Retrieval using Keyword and Table Queries", "comments": "ACM Transactions on the Web (TWEB). arXiv admin note: substantial\n  text overlap with arXiv:1802.06159", "journal-ref": null, "doi": "10.1145/3441690", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tables on the Web contain a vast amount of knowledge in a structured form. To\ntap into this valuable resource, we address the problem of table retrieval:\nanswering an information need with a ranked list of tables. We investigate this\nproblem in two different variants, based on how the information need is\nexpressed: as a keyword query or as an existing table (\"query-by-table\"). The\nmain novel contribution of this work is a semantic table retrieval framework\nfor matching information needs (keyword or table queries) against tables.\nSpecifically, we (i) represent queries and tables in multiple semantic spaces\n(both discrete sparse and continuous dense vector representations) and (ii)\nintroduce various similarity measures for matching those semantic\nrepresentations. We consider all possible combinations of semantic\nrepresentations and similarity measures and use these as features in a\nsupervised learning model. Using two purpose-built test collections based on\nWikipedia tables, we demonstrate significant and substantial improvements over\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 15:48:14 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Zhang", "Shuo", ""], ["Balog", "Krisztian", ""]]}, {"id": "2105.06398", "submitter": "Kaushik Roy", "authors": "Manas Gaur, Kaushik Roy, Aditya Sharma, Biplav Srivastava, and Amit\n  Sheth", "title": "\"Who can help me?\": Knowledge Infused Matching of Support Seekers and\n  Support Providers during COVID-19 on Reddit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the ongoing COVID-19 crisis, subreddits on Reddit, such as\nr/Coronavirus saw a rapid growth in user's requests for help (support seekers -\nSSs) including individuals with varying professions and experiences with\ndiverse perspectives on care (support providers - SPs). Currently,\nknowledgeable human moderators match an SS with a user with relevant\nexperience, i.e, an SP on these subreddits. This unscalable process defers\ntimely care. We present a medical knowledge-infused approach to efficient\nmatching of SS and SPs validated by experts for the users affected by anxiety\nand depression, in the context of with COVID-19. After matching, each SP to an\nSS labeled as either supportive, informative, or similar (sharing experiences)\nusing the principles of natural language inference. Evaluation by 21 domain\nexperts indicates the efficacy of incorporated knowledge and shows the efficacy\nthe matching system.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 02:34:33 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Gaur", "Manas", ""], ["Roy", "Kaushik", ""], ["Sharma", "Aditya", ""], ["Srivastava", "Biplav", ""], ["Sheth", "Amit", ""]]}, {"id": "2105.06400", "submitter": "Harsh Desai", "authors": "Harsh Desai, Pratik Kayal, Mayank Singh", "title": "TabLeX: A Benchmark Dataset for Structure and Content Information\n  Extraction from Scientific Tables", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Information Extraction (IE) from the tables present in scientific articles is\nchallenging due to complicated tabular representations and complex embedded\ntext. This paper presents TabLeX, a large-scale benchmark dataset comprising\ntable images generated from scientific articles. TabLeX consists of two\nsubsets, one for table structure extraction and the other for table content\nextraction. Each table image is accompanied by its corresponding LATEX source\ncode. To facilitate the development of robust table IE tools, TabLeX contains\nimages in different aspect ratios and in a variety of fonts. Our analysis sheds\nlight on the shortcomings of current state-of-the-art table extraction models\nand shows that they fail on even simple table images. Towards the end, we\nexperiment with a transformer-based existing baseline to report performance\nscores. In contrast to the static benchmarks, we plan to augment this dataset\nwith more complex and diverse tables at regular intervals.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 05:13:38 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Desai", "Harsh", ""], ["Kayal", "Pratik", ""], ["Singh", "Mayank", ""]]}, {"id": "2105.06441", "submitter": "Mona Zehni", "authors": "Safa Messaoud, Ismini Lourentzou, Assma Boughoula, Mona Zehni, Zhizhen\n  Zhao, Chengxiang Zhai, Alexander G. Schwing", "title": "DeepQAMVS: Query-Aware Hierarchical Pointer Networks for Multi-Video\n  Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent growth of web video sharing platforms has increased the demand for\nsystems that can efficiently browse, retrieve and summarize video content.\nQuery-aware multi-video summarization is a promising technique that caters to\nthis demand. In this work, we introduce a novel Query-Aware Hierarchical\nPointer Network for Multi-Video Summarization, termed DeepQAMVS, that jointly\noptimizes multiple criteria: (1) conciseness, (2) representativeness of\nimportant query-relevant events and (3) chronological soundness. We design a\nhierarchical attention model that factorizes over three distributions, each\ncollecting evidence from a different modality, followed by a pointer network\nthat selects frames to include in the summary. DeepQAMVS is trained with\nreinforcement learning, incorporating rewards that capture representativeness,\ndiversity, query-adaptability and temporal coherence. We achieve\nstate-of-the-art results on the MVS1K dataset, with inference time scaling\nlinearly with the number of input video frames.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 17:33:26 GMT"}], "update_date": "2021-05-14", "authors_parsed": [["Messaoud", "Safa", ""], ["Lourentzou", "Ismini", ""], ["Boughoula", "Assma", ""], ["Zehni", "Mona", ""], ["Zhao", "Zhizhen", ""], ["Zhai", "Chengxiang", ""], ["Schwing", "Alexander G.", ""]]}, {"id": "2105.06813", "submitter": "Guilherme Moraes Rosa", "authors": "Guilherme Moraes Rosa, Luiz Henrique Bonifacio, Leandro Rodrigues de\n  Souza, Roberto Lotufo and Rodrigo Nogueira", "title": "A cost-benefit analysis of cross-lingual transfer methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective method for cross-lingual transfer is to fine-tune a bilingual or\nmultilingual model on a supervised dataset in one language and evaluating it on\nanother language in a zero-shot manner. Translating examples at training time\nor inference time are also viable alternatives. However, there are costs\nassociated with these methods that are rarely addressed in the literature. In\nthis work, we analyze cross-lingual methods in terms of their effectiveness\n(e.g., accuracy), development and deployment costs, as well as their latencies\nat inference time. Our experiments on three tasks indicate that the best\ncross-lingual method is highly task-dependent. Finally, by combining zero-shot\nand translation methods, we achieve the state-of-the-art in two of the three\ndatasets used in this work. Based on these results, we question the need for\nmanually labeled training data in a target language. Code, models and\ntranslated datasets are available at\nhttps://github.com/unicamp-dl/cross-lingual-analysis\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 13:21:12 GMT"}, {"version": "v2", "created": "Sat, 29 May 2021 14:09:54 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Rosa", "Guilherme Moraes", ""], ["Bonifacio", "Luiz Henrique", ""], ["de Souza", "Leandro Rodrigues", ""], ["Lotufo", "Roberto", ""], ["Nogueira", "Rodrigo", ""]]}, {"id": "2105.06912", "submitter": "Chien-Sheng Wu", "authors": "Chien-Sheng Wu, Andrea Madotto, Wenhao Liu, Pascale Fung, Caiming\n  Xiong", "title": "QAConv: Question Answering on Informative Conversations", "comments": "Data and code are available at https://github.com/salesforce/QAConv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces QAConv, a new question answering (QA) dataset that uses\nconversations as a knowledge source. We focus on informative conversations\nincluding business emails, panel discussions, and work channels. Unlike\nopen-domain and task-oriented dialogues, these conversations are usually long,\ncomplex, asynchronous, and involve strong domain knowledge. In total, we\ncollect 34,204 QA pairs, including span-based, free-form, and unanswerable\nquestions, from 10,259 selected conversations with both human-written and\nmachine-generated questions. We segment long conversations into chunks, and use\na question generator and dialogue summarizer as auxiliary tools to collect\nmulti-hop questions. The dataset has two testing scenarios, chunk mode and full\nmode, depending on whether the grounded chunk is provided or retrieved from a\nlarge conversational pool. Experimental results show that state-of-the-art QA\nsystems trained on existing QA datasets have limited zero-shot ability and tend\nto predict our questions as unanswerable. Fine-tuning such systems on our\ncorpus can achieve significant improvement up to 23.6% and 13.6% in both chunk\nmode and full mode, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 15:53:05 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Wu", "Chien-Sheng", ""], ["Madotto", "Andrea", ""], ["Liu", "Wenhao", ""], ["Fung", "Pascale", ""], ["Xiong", "Caiming", ""]]}, {"id": "2105.07019", "submitter": "Riya Shah", "authors": "Shah Riya Chiragkumar", "title": "Chord Recognition- Music and Audio Information Retrieval", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Music Information Retrieval (MIR) is a collaborative scientific study that\nhelp to build innovative information research themes, novel frameworks, and\ndeveloping connected delivery mechanisms in addition to making the world's\nmassive collection of music open for everyone. Modern rock music proved to be\ndifficult to estimate tempo and chord recognition did not work. All of the\nfindings indicate that modern rock and metal music can be analysed, despite its\ncomplexity, but that further research is needed in this area to make it useful.\nUsing a neural network has been one of the simplest ways of dealing with it.\nThe pitch class profile vector is used in the neural network method. Because\nthe vector only contains 12 elements of semi-tone values, it is enough for\nchord recognition. Of course, there are other ways of achieving this work, most\nof them depend on pitch class profiling to transform the chord into a type that\ncan be recognised, but the recognition process is time-consuming centred on\nextremely complicated and memory-intensive methods.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 18:14:53 GMT"}], "update_date": "2021-06-11", "authors_parsed": [["Chiragkumar", "Shah Riya", ""]]}, {"id": "2105.07062", "submitter": "Nicol\\`o Felicioni", "authors": "Nicol\\`o Felicioni, Maurizio Ferrari Dacrema, Paolo Cremonesi", "title": "Measuring the User Satisfaction in a Recommendation Interface with\n  Multiple Carousels", "comments": null, "journal-ref": "ACM International Conference on Interactive Media Experiences (IMX\n  '21), June 21--23, 2021, Virtual Event, NY, USA", "doi": "10.1145/3452918.3465493", "report-no": null, "categories": "cs.IR cs.HC cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common for video-on-demand and music streaming services to adopt a user\ninterface composed of several recommendation lists, i.e. widgets or swipeable\ncarousels, each generated according to a specific criterion or algorithm (e.g.\nmost recent, top popular, recommended for you, editors' choice, etc.).\nSelecting the appropriate combination of carousel has significant impact on\nuser satisfaction. A crucial aspect of this user interface is that to measure\nthe relevance a new carousel for the user it is not sufficient to account\nsolely for its individual quality. Instead, it should be considered that other\ncarousels will already be present in the interface. This is not considered by\ntraditional evaluation protocols for recommenders systems, in which each\ncarousel is evaluated in isolation, regardless of (i) which other carousels are\ndisplayed to the user and (ii) the relative position of the carousel with\nrespect to other carousels. Hence, we propose a two-dimensional evaluation\nprotocol for a carousel setting that will measure the quality of a\nrecommendation carousel based on how much it improves upon the quality of an\nalready available set of carousels. Our evaluation protocol takes into account\nalso the position bias, i.e. users do not explore the carousels sequentially,\nbut rather concentrate on the top-left corner of the screen.\n  We report experiments on the movie domain and notice that under a carousel\nsetting the definition of which criteria has to be preferred to generate a list\nof recommended items changes with respect to what is commonly understood.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 20:33:51 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Felicioni", "Nicol\u00f2", ""], ["Dacrema", "Maurizio Ferrari", ""], ["Cremonesi", "Paolo", ""]]}, {"id": "2105.07377", "submitter": "Lei Chen", "authors": "Lei Chen, Le Wu, Kun Zhang, Richang Hong, Meng Wang", "title": "Set2setRank: Collaborative Set to Set Ranking for Implicit Feedback\n  based Recommendation", "comments": "The paper is accepted by SIGIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As users often express their preferences with binary behavior data~(implicit\nfeedback), such as clicking items or buying products, implicit feedback based\nCollaborative Filtering~(CF) models predict the top ranked items a user might\nlike by leveraging implicit user-item interaction data. For each user, the\nimplicit feedback is divided into two sets: an observed item set with limited\nobserved behaviors, and a large unobserved item set that is mixed with negative\nitem behaviors and unknown behaviors. Given any user preference prediction\nmodel, researchers either designed ranking based optimization goals or relied\non negative item mining techniques for better optimization. Despite the\nperformance gain of these implicit feedback based models, the recommendation\nresults are still far from satisfactory due to the sparsity of the observed\nitem set for each user. To this end, in this paper, we explore the unique\ncharacteristics of the implicit feedback and propose Set2setRank framework for\nrecommendation. The optimization criteria of Set2setRank are two folds: First,\nwe design an item to an item set comparison that encourages each observed item\nfrom the sampled observed set is ranked higher than any unobserved item from\nthe sampled unobserved set. Second, we model set level comparison that\nencourages a margin between the distance summarized from the observed item set\nand the most \"hard\" unobserved item from the sampled negative set. Further, an\nadaptive sampling technique is designed to implement these two goals. We have\nto note that our proposed framework is model-agnostic and can be easily applied\nto most recommendation prediction approaches, and is time efficient in\npractice. Finally, extensive experiments on three real-world datasets\ndemonstrate the superiority of our proposed approach.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 08:06:22 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 08:00:02 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Chen", "Lei", ""], ["Wu", "Le", ""], ["Zhang", "Kun", ""], ["Hong", "Richang", ""], ["Wang", "Meng", ""]]}, {"id": "2105.07542", "submitter": "Chang Lu", "authors": "Chang Lu, Chandan K. Reddy, Prithwish Chakraborty, Samantha Kleinberg,\n  Yue Ning", "title": "Collaborative Graph Learning with Auxiliary Text for Temporal Event\n  Prediction in Healthcare", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accurate and explainable health event predictions are becoming crucial for\nhealthcare providers to develop care plans for patients. The availability of\nelectronic health records (EHR) has enabled machine learning advances in\nproviding these predictions. However, many deep learning based methods are not\nsatisfactory in solving several key challenges: 1) effectively utilizing\ndisease domain knowledge; 2) collaboratively learning representations of\npatients and diseases; and 3) incorporating unstructured text. To address these\nissues, we propose a collaborative graph learning model to explore\npatient-disease interactions and medical domain knowledge. Our solution is able\nto capture structural features of both patients and diseases. The proposed\nmodel also utilizes unstructured text data by employing an attention regulation\nstrategy and then integrates attentive text features into a sequential learning\nprocess. We conduct extensive experiments on two important healthcare problems\nto show the competitive prediction performance of the proposed method compared\nwith various state-of-the-art models. We also confirm the effectiveness of\nlearned representations and model interpretability by a set of ablation and\ncase studies.\n", "versions": [{"version": "v1", "created": "Sun, 16 May 2021 23:11:11 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Lu", "Chang", ""], ["Reddy", "Chandan K.", ""], ["Chakraborty", "Prithwish", ""], ["Kleinberg", "Samantha", ""], ["Ning", "Yue", ""]]}, {"id": "2105.07585", "submitter": "Yujuan Ding", "authors": "Yujuan Ding, Yunshan Ma, Wai Keung Wong, Tat-Seng Chua", "title": "Leveraging Two Types of Global Graph for Sequential Fashion\n  Recommendation", "comments": null, "journal-ref": null, "doi": "10.1145/3460426.3463638", "report-no": null, "categories": "cs.IR cs.MM", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Sequential fashion recommendation is of great significance in online fashion\nshopping, which accounts for an increasing portion of either fashion retailing\nor online e-commerce. The key to building an effective sequential fashion\nrecommendation model lies in capturing two types of patterns: the personal\nfashion preference of users and the transitional relationships between adjacent\nitems. The two types of patterns are usually related to user-item interaction\nand item-item transition modeling respectively. However, due to the large sets\nof users and items as well as the sparse historical interactions, it is\ndifficult to train an effective and efficient sequential fashion recommendation\nmodel. To tackle these problems, we propose to leverage two types of global\ngraph, i.e., the user-item interaction graph and item-item transition graph, to\nobtain enhanced user and item representations by incorporating higher-order\nconnections over the graphs. In addition, we adopt the graph kernel of LightGCN\nfor the information propagation in both graphs and propose a new design for\nitem-item transition graph. Extensive experiments on two established sequential\nfashion recommendation datasets validate the effectiveness and efficiency of\nour approach.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 03:02:04 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 01:05:22 GMT"}, {"version": "v3", "created": "Sun, 30 May 2021 02:08:48 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ding", "Yujuan", ""], ["Ma", "Yunshan", ""], ["Wong", "Wai Keung", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2105.07597", "submitter": "Zhenzhong Chen", "authors": "Yaochen Zhu and Zhenzhong Chen", "title": "Collaborative Variational Bandwidth Auto-encoder for Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Collaborative filtering has been widely adopted by modern recommender systems\nto discover user preferences based on their past behaviors. However, the\nobserved interactions for different users are usually unbalanced, which leads\nto high uncertainty in the collaborative embeddings of users with sparse\nratings, thereby severely degenerating the recommendation performance.\nConsequently, more efforts have been dedicated to the hybrid recommendation\nstrategy where user/item features are utilized as auxiliary information to\naddress the sparsity problem. However, since these features contain rich\nmultimodal patterns and most of them are irrelevant to the recommendation\npurpose, excessive reliance on these features will make the model difficult to\ngeneralize. To address the above two challenges, we propose a VBAE for\nrecommendation. VBAE models both the collaborative and the user feature\nembeddings as Gaussian random variables inferred via deep neural networks to\ncapture non-linear similarities between users based on their ratings and\nfeatures. Furthermore, VBAE establishes an information regulation mechanism by\nintroducing a user-dependent channel variable where the bandwidth is determined\nby the information already contained in the observed ratings to dynamically\ncontrol the amount of information allowed to be accessed from the corresponding\nuser features. The user-dependent channel variable alleviates the uncertainty\nproblem when the ratings are sparse while avoids unnecessary dependence of the\nmodel on noisy user features simultaneously. Codes and datasets are released at\nhttps://github.com/yaochenzhu/vbae.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 04:00:33 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Zhu", "Yaochen", ""], ["Chen", "Zhenzhong", ""]]}, {"id": "2105.07706", "submitter": "Xu Ma", "authors": "Xu Ma, Pengjie Wang, Hui Zhao, Shaoguo Liu, Chuhan Zhao, Wei Lin,\n  Kuang-Chih Lee, Jian Xu, Bo Zheng", "title": "Towards a Better Tradeoff between Effectiveness and Efficiency in\n  Pre-Ranking: A Learnable Feature Selection based Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-world search, recommendation, and advertising systems, the\nmulti-stage ranking architecture is commonly adopted. Such architecture usually\nconsists of matching, pre-ranking, ranking, and re-ranking stages. In the\npre-ranking stage, vector-product based models with representation-focused\narchitecture are commonly adopted to account for system efficiency. However, it\nbrings a significant loss to the effectiveness of the system. In this paper, a\nnovel pre-ranking approach is proposed which supports complicated models with\ninteraction-focused architecture. It achieves a better tradeoff between\neffectiveness and efficiency by utilizing the proposed learnable Feature\nSelection method based on feature Complexity and variational Dropout (FSCD).\nEvaluations in a real-world e-commerce sponsored search system for a search\nengine demonstrate that utilizing the proposed pre-ranking, the effectiveness\nof the system is significantly improved. Moreover, compared to the systems with\nconventional pre-ranking models, an identical amount of computational resource\nis consumed.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 09:48:15 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Ma", "Xu", ""], ["Wang", "Pengjie", ""], ["Zhao", "Hui", ""], ["Liu", "Shaoguo", ""], ["Zhao", "Chuhan", ""], ["Lin", "Wei", ""], ["Lee", "Kuang-Chih", ""], ["Xu", "Jian", ""], ["Zheng", "Bo", ""]]}, {"id": "2105.07752", "submitter": "Bencheng Yan", "authors": "Feng Li, Bencheng Yan, Qingqing Long, Pengjie Wang, Wei Lin, Jian Xu\n  and Bo Zheng", "title": "Explicit Semantic Cross Feature Learning via Pre-trained Graph Neural\n  Networks for CTR Prediction", "comments": "SIGIR 2021, 5 pages; The first two authors contributed equally to\n  this work; Pengjie Wang gave a lot of guidance in this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross features play an important role in click-through rate (CTR) prediction.\nMost of the existing methods adopt a DNN-based model to capture the cross\nfeatures in an implicit manner. These implicit methods may lead to a\nsub-optimized performance due to the limitation in explicit semantic modeling.\nAlthough traditional statistical explicit semantic cross features can address\nthe problem in these implicit methods, it still suffers from some challenges,\nincluding lack of generalization and expensive memory cost. Few works focus on\ntackling these challenges. In this paper, we take the first step in learning\nthe explicit semantic cross features and propose Pre-trained Cross Feature\nlearning Graph Neural Networks (PCF-GNN), a GNN based pre-trained model aiming\nat generating cross features in an explicit fashion. Extensive experiments are\nconducted on both public and industrial datasets, where PCF-GNN shows\ncompetence in both performance and memory-efficiency in various tasks.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 11:56:04 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Li", "Feng", ""], ["Yan", "Bencheng", ""], ["Long", "Qingqing", ""], ["Wang", "Pengjie", ""], ["Lin", "Wei", ""], ["Xu", "Jian", ""], ["Zheng", "Bo", ""]]}, {"id": "2105.07826", "submitter": "Jamal Al Qundus", "authors": "Malik Yousef, Jamal Al Qundus, Silvio Peikert, and Adrian Paschke", "title": "TopicsRanksDC: Distance-based Topic Ranking applied on Two-Class Data", "comments": "10 pages, 5 figures", "journal-ref": "International Conference on Database and Expert Systems\n  Applications DEXA 2020: Database and Expert Systems Applications pp 11-21", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we introduce a novel approach named TopicsRanksDC for topics\nranking based on the distance between two clusters that are generated by each\ntopic. We assume that our data consists of text documents that are associated\nwith two-classes. Our approach ranks each topic contained in these text\ndocuments by its significance for separating the two-classes. Firstly, the\nalgorithm detects topics using Latent Dirichlet Allocation (LDA). The words\ndefining each topic are represented as two clusters, where each one is\nassociated with one of the classes. We compute four distance metrics, Single\nLinkage, Complete Linkage, Average Linkage and distance between the centroid.\nWe compare the results of LDA topics and random topics. The results show that\nthe rank for LDA topics is much higher than random topics. The results of\nTopicsRanksDC tool are promising for future work to enable search engines to\nsuggest related topics.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 13:34:45 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Yousef", "Malik", ""], ["Qundus", "Jamal Al", ""], ["Peikert", "Silvio", ""], ["Paschke", "Adrian", ""]]}, {"id": "2105.07975", "submitter": "Iain Mackie", "authors": "Iain Mackie and Jeffery Dalton and Andrew Yates", "title": "How Deep is your Learning: the DL-HARD Annotated Deep Learning Dataset", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning Hard (DL-HARD) is a new annotated dataset designed to more\neffectively evaluate neural ranking models on complex topics. It builds on TREC\nDeep Learning (DL) topics by extensively annotating them with question intent\ncategories, answer types, wikified entities, topic categories, and result type\nmetadata from a commercial web search engine. Based on this data, we introduce\na framework for identifying challenging queries. DL-HARD contains fifty topics\nfrom the official DL 2019/2020 evaluation benchmark, half of which are newly\nand independently assessed. We perform experiments using the official submitted\nruns to DL on DL-HARD and find substantial differences in metrics and the\nranking of participating systems. Overall, DL-HARD is a new resource that\npromotes research on neural ranking methods by focusing on challenging and\ncomplex topics.\n", "versions": [{"version": "v1", "created": "Mon, 17 May 2021 15:58:44 GMT"}], "update_date": "2021-05-18", "authors_parsed": [["Mackie", "Iain", ""], ["Dalton", "Jeffery", ""], ["Yates", "Andrew", ""]]}, {"id": "2105.08246", "submitter": "Zhihong Chen", "authors": "Houyi Li, Zhihong Chen, Chenliang Li, Rong Xiao, Hongbo Deng, Peng\n  Zhang, Yongchao Liu, Haihong Tang", "title": "Path-based Deep Network for Candidate Item Matching in Recommenders", "comments": "Accepted for publication in SIGIR2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The large-scale recommender system mainly consists of two stages: matching\nand ranking. The matching stage (also known as the retrieval step) identifies a\nsmall fraction of relevant items from billion-scale item corpus in low latency\nand computational cost. Item-to-item collaborative filter (item-based CF) and\nembedding-based retrieval (EBR) have been long used in the industrial matching\nstage owing to its efficiency. However, item-based CF is hard to meet\npersonalization, while EBR has difficulty in satisfying diversity. In this\npaper, we propose a novel matching architecture, Path-based Deep Network (named\nPDN), which can incorporate both personalization and diversity to enhance\nmatching performance. Specifically, PDN is comprised of two modules: Trigger\nNet and Similarity Net. PDN utilizes Trigger Net to capture the user's interest\nin each of his/her interacted item, and Similarity Net to evaluate the\nsimilarity between each interacted item and the target item based on these\nitems' profile and CF information. The final relevance between the user and the\ntarget item is calculated by explicitly considering user's diverse interests,\n\\ie aggregating the relevance weights of the related two-hop paths (one hop of\na path corresponds to user-item interaction and the other to item-item\nrelevance). Furthermore, we describe the architecture design of a matching\nsystem with the proposed PDN in a leading real-world E-Commerce service (Mobile\nTaobao App). Based on offline evaluations and online A/B test, we show that PDN\noutperforms the existing solutions for the same task. The online results also\ndemonstrate that PDN can retrieve more personalized and more diverse relevant\nitems to significantly improve user engagement. Currently, PDN system has been\nsuccessfully deployed at Mobile Taobao App and handling major online traffic.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 02:56:56 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Li", "Houyi", ""], ["Chen", "Zhihong", ""], ["Li", "Chenliang", ""], ["Xiao", "Rong", ""], ["Deng", "Hongbo", ""], ["Zhang", "Peng", ""], ["Liu", "Yongchao", ""], ["Tang", "Haihong", ""]]}, {"id": "2105.08279", "submitter": "Chang Liu", "authors": "Chang Liu, Guanjie Zheng, Zhenhui Li", "title": "Learning to Route via Theory-Guided Residual Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The heavy traffic and related issues have always been concerns for modern\ncities. With the help of deep learning and reinforcement learning, people have\nproposed various policies to solve these traffic-related problems, such as\nsmart traffic signal control systems and taxi dispatching systems. People\nusually validate these policies in a city simulator, since directly applying\nthem in the real city introduces real cost. However, these policies validated\nin the city simulator may fail in the real city if the simulator is\nsignificantly different from the real world. To tackle this problem, we need to\nbuild a real-like traffic simulation system. Therefore, in this paper, we\npropose to learn the human routing model, which is one of the most essential\npart in the traffic simulator. This problem has two major challenges. First,\nhuman routing decisions are determined by multiple factors, besides the common\ntime and distance factor. Second, current historical routes data usually covers\njust a small portion of vehicles, due to privacy and device availability\nissues. To address these problems, we propose a theory-guided residual network\nmodel, where the theoretical part can emphasize the general principles for\nhuman routing decisions (e.g., fastest route), and the residual part can\ncapture drivable condition preferences (e.g., local road or highway). Since the\ntheoretical part is composed of traditional shortest path algorithms that do\nnot need data to train, our residual network can learn human routing models\nfrom limited data. We have conducted extensive experiments on multiple\nreal-world datasets to show the superior performance of our model, especially\nwith small data. Besides, we have also illustrated why our model is better at\nrecovering real routes through case studies.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 05:07:34 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 09:08:57 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Liu", "Chang", ""], ["Zheng", "Guanjie", ""], ["Li", "Zhenhui", ""]]}, {"id": "2105.08281", "submitter": "Kiran Sharma Dr.", "authors": "Parul Khurana and Kiran Sharma", "title": "Impact of $h$-index on authors ranking: An improvement to the h-index\n  for lower-ranked author", "comments": "14 pages, 6 figures, 5 Tables. arXiv admin note: text overlap with\n  arXiv:2102.06964", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In academia, the research performance of a faculty is either evaluated by the\nnumber of publications or the number of citations. Most of the time h-index is\nwidely used during the hiring process or the faculty performance evaluation.\nThe calculation of the h-index is shown in various databases; however, there is\nno systematic evidence about the differences between them. Here we analyze the\npublication records of 385 authors from Monash University (Australia) to\ninvestigate (i) the impact of different databases like Scopus and WoS on the\nranking of authors within a discipline, and (ii) to complement the $h$-index,\nnamed $h_c$, by adding the weight of the highest cited paper to the $h$-index\nof the authors. The results show the positive impact of $h_c$ on the\nlower-ranked authors in every discipline. Also, Scopus provides an overall\nbetter ranking than WoS; however, the ranking varies among Scopus and WoS for\ndisciplines.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 05:10:19 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Khurana", "Parul", ""], ["Sharma", "Kiran", ""]]}, {"id": "2105.08301", "submitter": "Pengjie Ren", "authors": "Pengjie Ren, Zhongkun Liu, Xiaomeng Song, Hongtao Tian, Zhumin Chen,\n  Zhaochun Ren and Maarten de Rijke", "title": "Wizard of Search Engine: Access to Information Through Conversations\n  with Search Engines", "comments": "Published in SIGIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Conversational information seeking (CIS) is playing an increasingly important\nrole in connecting people to information. Due to the lack of suitable resource,\nprevious studies on CIS are limited to the study of theoretical/conceptual\nframeworks, laboratory-based user studies, or a particular aspect of CIS (e.g.,\nasking clarifying questions). In this work, we make efforts to facilitate\nresearch on CIS from three aspects. (1) We formulate a pipeline for CIS with\nsix sub-tasks: intent detection (ID), keyphrase extraction (KE), action\nprediction (AP), query selection (QS), passage selection (PS), and response\ngeneration (RG). (2) We release a benchmark dataset, called wizard of search\nengine (WISE), which allows for comprehensive and in-depth research on all\naspects of CIS. (3) We design a neural architecture capable of training and\nevaluating both jointly and separately on the six sub-tasks, and devise a\npre-train/fine-tune learning scheme, that can reduce the requirements of WISE\nin scale by making full use of available data. We report some useful\ncharacteristics of CIS based on statistics of WISE. We also show that our best\nperforming model variant isable to achieve effective CIS as indicated by\nseveral metrics. We release the dataset, the code, as well as the evaluation\nscripts to facilitate future research by measuring further improvements in this\nimportant research direction.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 06:35:36 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Ren", "Pengjie", ""], ["Liu", "Zhongkun", ""], ["Song", "Xiaomeng", ""], ["Tian", "Hongtao", ""], ["Chen", "Zhumin", ""], ["Ren", "Zhaochun", ""], ["de Rijke", "Maarten", ""]]}, {"id": "2105.08318", "submitter": "Hao Ding", "authors": "Hao Ding, Yifei Ma, Anoop Deoras, Yuyang Wang, Hao Wang", "title": "Zero-Shot Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance of recommender systems (RS) relies heavily on the amount of\ntraining data available. This poses a chicken-and-egg problem for early-stage\nproducts, whose amount of data, in turn, relies on the performance of their RS.\nOn the other hand, zero-shot learning promises some degree of generalization\nfrom an old dataset to an entirely new dataset. In this paper, we explore the\npossibility of zero-shot learning in RS. We develop an algorithm, dubbed\nZEro-Shot Recommenders (ZESRec), that is trained on an old dataset and\ngeneralize to a new one where there are neither overlapping users nor\noverlapping items, a setting that contrasts typical cross-domain RS that has\neither overlapping users or items. Different from categorical item indices,\ni.e., item ID, in previous methods, ZESRec uses items' natural-language\ndescriptions (or description embeddings) as their continuous indices, and\ntherefore naturally generalize to any unseen items. In terms of users, ZESRec\nbuilds upon recent advances on sequential RS to represent users using their\ninteractions with items, thereby generalizing to unseen users as well. We study\ntwo pairs of real-world RS datasets and demonstrate that ZESRec can\nsuccessfully enable recommendations in such a zero-shot setting, opening up new\nopportunities for resolving the chicken-and-egg problem for data-scarce\nstartups or early-stage products.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 07:17:37 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Ding", "Hao", ""], ["Ma", "Yifei", ""], ["Deoras", "Anoop", ""], ["Wang", "Yuyang", ""], ["Wang", "Hao", ""]]}, {"id": "2105.08442", "submitter": "Hasan Abu-Rasheed", "authors": "Hasan Abu-Rasheed, Christian Weber, Johannes Zenkert, Roland Krumm,\n  Madjid Fathi", "title": "Explainable Graph-based Search for Lessons-Learned Documents in the\n  Semiconductor Industry", "comments": "Accepted in the \"Computing2021\" conference, 15-16 July 2021, London,\n  UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Industrial processes produce a considerable volume of data and thus\ninformation. Whether it is structured sensory data or semi- to unstructured\ntextual data, the knowledge that can be derived from it is critical to the\nsustainable development of the industrial process. A key challenge of this\nsustainability is the intelligent management of the generated data, as well as\nthe knowledge extracted from it, in order to utilize this knowledge for\nimproving future procedures. This challenge is a result of the tailored\ndocumentation methods and domain-specific requirements, which include the need\nfor quick visibility of the documented knowledge. In this paper, we utilize the\nexpert knowledge documented in chip-design failure reports in supporting user\naccess to information that is relevant to a current chip design. Unstructured,\nfree, textual data in previous failure documentations provides a valuable\nsource of lessons-learned, which expert design-engineers have experienced,\nsolved and documented. To achieve a sustainable utilization of knowledge within\nthe company, not only the inherent knowledge has to be mined from unstructured\ntextual data, but also the relations between the lessons-learned, uncovering\npotentially unknown links. In this research, a knowledge graph is constructed,\nin order to represent and use the interconnections between reported design\nfailures. A search engine is developed and applied onto the graph to answer\nqueries. In contrast to mere keyword-based searching, the searchability of the\nknowledge graph offers enhanced search results beyond direct matches and acts\nas a mean for generating explainable results and result recommendations.\nResults are provided to the design engineer through an interactive search\ninterface, in which, the feedback from the user is used to further optimize\nrelations for future iterations of the knowledge graph.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 11:23:28 GMT"}, {"version": "v2", "created": "Sun, 20 Jun 2021 18:32:39 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Abu-Rasheed", "Hasan", ""], ["Weber", "Christian", ""], ["Zenkert", "Johannes", ""], ["Krumm", "Roland", ""], ["Fathi", "Madjid", ""]]}, {"id": "2105.08489", "submitter": "Dongbo Xi", "authors": "Dongbo Xi, Zhen Chen, Peng Yan, Yinger Zhang, Yongchun Zhu, Fuzhen\n  Zhuang, Yu Chen", "title": "Modeling the Sequential Dependence among Audience Multi-step Conversions\n  with Multi-task Learning in Targeted Display Advertising", "comments": "accepted by KDD21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In most real-world large-scale online applications (e.g., e-commerce or\nfinance), customer acquisition is usually a multi-step conversion process of\naudiences. For example, an impression->click->purchase process is usually\nperformed of audiences for e-commerce platforms. However, it is more difficult\nto acquire customers in financial advertising (e.g., credit card advertising)\nthan in traditional advertising. On the one hand, the audience multi-step\nconversion path is longer. On the other hand, the positive feedback is sparser\n(class imbalance) step by step, and it is difficult to obtain the final\npositive feedback due to the delayed feedback of activation. Multi-task\nlearning is a typical solution in this direction. While considerable multi-task\nefforts have been made in this direction, a long-standing challenge is how to\nexplicitly model the long-path sequential dependence among audience multi-step\nconversions for improving the end-to-end conversion. In this paper, we propose\nan Adaptive Information Transfer Multi-task (AITM) framework, which models the\nsequential dependence among audience multi-step conversions via the Adaptive\nInformation Transfer (AIT) module. The AIT module can adaptively learn what and\nhow much information to transfer for different conversion stages. Besides, by\ncombining the Behavioral Expectation Calibrator in the loss function, the AITM\nframework can yield more accurate end-to-end conversion identification. The\nproposed framework is deployed in Meituan app, which utilizes it to real-timely\nshow a banner to the audience with a high end-to-end conversion rate for\nMeituan Co-Branded Credit Cards. Offline experimental results on both\nindustrial and public real-world datasets clearly demonstrate that the proposed\nframework achieves significantly better performance compared with\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 13:07:12 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 02:46:16 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Xi", "Dongbo", ""], ["Chen", "Zhen", ""], ["Yan", "Peng", ""], ["Zhang", "Yinger", ""], ["Zhu", "Yongchun", ""], ["Zhuang", "Fuzhen", ""], ["Chen", "Yu", ""]]}, {"id": "2105.08581", "submitter": "Matthias Hagen", "authors": "Vaibhav Kasturia, Marcel Gohsen, Matthias Hagen", "title": "Entity-Based Query Interpretation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web search queries can be rather ambiguous: Is \"paris hilton\" meant to find\nthe latest news on the celebrity or to find a specific hotel in Paris? And in\nwhich of the worldwide more than 20 \"Parises\"? We propose to solve this\nambiguity problem by deriving entity-based query interpretations: given some\nquery, the task is to link suitable parts of the query to semantically\ncompatible entities in a background knowledge base. Our suggested approach to\nidentify the most reasonable interpretations of a query based on the contained\nentities focuses on effectiveness but also on efficiency since web search\nresponse times should not exceed some hundreds of milliseconds. In our\napproach, we propose to use query segmentation as a pre-processing step that\nfinds promising segment-based \"skeletons\". These skeletons are then enhanced to\n\"interpretations\" by linking the contained segments to entities from a\nknowledge base and then ranking the interpretations in a final step. An\nexperimental comparison on a corpus of 2,800 queries shows our approach to have\na better interpretation accuracy at a better run time than the previously most\neffective query entity linking methods.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 15:07:51 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Kasturia", "Vaibhav", ""], ["Gohsen", "Marcel", ""], ["Hagen", "Matthias", ""]]}, {"id": "2105.08649", "submitter": "Zekai Chen", "authors": "Zekai Chen, Fangtian Zhong, Zhumin Chen, Xiao Zhang, Robert Pless,\n  Xiuzhen Cheng", "title": "DCAP: Deep Cross Attentional Product Network for User Response\n  Prediction", "comments": "12 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User response prediction, which aims to predict the probability that a user\nwill provide a predefined positive response in a given context such as clicking\non an ad or purchasing an item, is crucial to many industrial applications such\nas online advertising, recommender systems, and search ranking. However, due to\nthe high dimensionality and super sparsity of the data collected in these\ntasks, handcrafting cross features is inevitably time expensive. Prior studies\nin predicting user response leveraged the feature interactions by enhancing\nfeature vectors with products of features to model second-order or high-order\ncross features, either explicitly or implicitly. Nevertheless, these existing\nmethods can be hindered by not learning sufficient cross features due to model\narchitecture limitations or modeling all high-order feature interactions with\nequal weights. This work aims to fill this gap by proposing a novel\narchitecture Deep Cross Attentional Product Network (DCAP), which keeps cross\nnetwork's benefits in modeling high-order feature interactions explicitly at\nthe vector-wise level. Beyond that, it can differentiate the importance of\ndifferent cross features in each network layer inspired by the multi-head\nattention mechanism and Product Neural Network (PNN), allowing practitioners to\nperform a more in-depth analysis of user behaviors. Additionally, our proposed\nmodel can be easily implemented and train in parallel. We conduct comprehensive\nexperiments on three real-world datasets. The results have robustly\ndemonstrated that our proposed model DCAP achieves superior prediction\nperformance compared with the state-of-the-art models.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 16:27:20 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Chen", "Zekai", ""], ["Zhong", "Fangtian", ""], ["Chen", "Zhumin", ""], ["Zhang", "Xiao", ""], ["Pless", "Robert", ""], ["Cheng", "Xiuzhen", ""]]}, {"id": "2105.08716", "submitter": "Henderik Alex Proper", "authors": "P. D. Bruza and H. A. Proper", "title": "Discovering the Information that is lost in our Databases -- Why bother\n  storing data if you can't find the information?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We are surrounded by an ever increasing amount of data that is stored in a\nvariety of databases. In this article we will use a very liberal definition of\n\\EM{database}. Basically any collection of data can be regarded as a database,\nranging from the files in a directory on a disk, to ftp and web servers,\nthrough to relational or object-oriented databases. The sole reason for storing\ndata in databases is that there is an anticipated need for the stored data at\nsome time in the future. This means that providing smooth access paths by which\nstored information can be retrieved is at least as important as ensuring\nintegrity of the stored information. In practice, however, providing users with\nadequate avenues by which to access stored information has received far less\nattention.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 17:56:32 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Bruza", "P. D.", ""], ["Proper", "H. A.", ""]]}, {"id": "2105.08872", "submitter": "Jiansheng Fang", "authors": "Jiansheng Fang, Huazhu Fu, Dan Zeng, Xiao Yan, Yuguang Yan, and Jiang\n  Liu", "title": "Combating Ambiguity for Hash-code Learning in Medical Instance Retrieval", "comments": "11 pages,8 figures, JBHI Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When encountering a dubious diagnostic case, medical instance retrieval can\nhelp radiologists make evidence-based diagnoses by finding images containing\ninstances similar to a query case from a large image database. The similarity\nbetween the query case and retrieved similar cases is determined by visual\nfeatures extracted from pathologically abnormal regions. However, the\nmanifestation of these regions often lacks specificity, i.e., different\ndiseases can have the same manifestation, and different manifestations may\noccur at different stages of the same disease. To combat the manifestation\nambiguity in medical instance retrieval, we propose a novel deep framework\ncalled Y-Net, encoding images into compact hash-codes generated from\nconvolutional features by feature aggregation. Y-Net can learn highly\ndiscriminative convolutional features by unifying the pixel-wise segmentation\nloss and classification loss. The segmentation loss allows exploring subtle\nspatial differences for good spatial-discriminability while the classification\nloss utilizes class-aware semantic information for good semantic-separability.\nAs a result, Y-Net can enhance the visual features in pathologically abnormal\nregions and suppress the disturbing of the background during model training,\nwhich could effectively embed discriminative features into the hash-codes in\nthe retrieval stage. Extensive experiments on two medical image datasets\ndemonstrate that Y-Net can alleviate the ambiguity of pathologically abnormal\nregions and its retrieval performance outperforms the state-of-the-art method\nby an average of 9.27\\% on the returned list of 10.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 01:13:05 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Fang", "Jiansheng", ""], ["Fu", "Huazhu", ""], ["Zeng", "Dan", ""], ["Yan", "Xiao", ""], ["Yan", "Yuguang", ""], ["Liu", "Jiang", ""]]}, {"id": "2105.08908", "submitter": "Sixiao Zhang", "authors": "Sixiao Zhang, Hongxu Chen, Xiao Ming, Lizhen Cui, Hongzhi Yin,\n  Guandong Xu", "title": "Where are we in embedding spaces? A Comprehensive Analysis on Network\n  Embedding Approaches for Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hyperbolic space and hyperbolic embeddings are becoming a popular research\nfield for recommender systems. However, it is not clear under what\ncircumstances the hyperbolic space should be considered. To fill this gap, This\npaper provides theoretical analysis and empirical results on when and where to\nuse hyperbolic space and hyperbolic embeddings in recommender systems.\nSpecifically, we answer the questions that which type of models and datasets\nare more suited for hyperbolic space, as well as which latent size to choose.\nWe evaluate our answers by comparing the performance of Euclidean space and\nhyperbolic space on different latent space models in both general item\nrecommendation domain and social recommendation domain, with 6 widely used\ndatasets and different latent sizes. Additionally, we propose a new metric\nlearning based recommendation method called SCML and its hyperbolic version\nHSCML. We evaluate our conclusions regarding hyperbolic space on SCML and show\nthe state-of-the-art performance of hyperbolic space by comparing HSCML with\nother baseline methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 03:46:41 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Zhang", "Sixiao", ""], ["Chen", "Hongxu", ""], ["Ming", "Xiao", ""], ["Cui", "Lizhen", ""], ["Yin", "Hongzhi", ""], ["Xu", "Guandong", ""]]}, {"id": "2105.08909", "submitter": "Wentao Ouyang", "authors": "Wentao Ouyang, Xiuwu Zhang, Shukui Ren, Li Li, Kun Zhang, Jinmei Luo,\n  Zhaojie Liu, Yanlong Du", "title": "Learning Graph Meta Embeddings for Cold-Start Ads in Click-Through Rate\n  Prediction", "comments": "SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462879", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Click-through rate (CTR) prediction is one of the most central tasks in\nonline advertising systems. Recent deep learning-based models that exploit\nfeature embedding and high-order data nonlinearity have shown dramatic\nsuccesses in CTR prediction. However, these models work poorly on cold-start\nads with new IDs, whose embeddings are not well learned yet. In this paper, we\npropose Graph Meta Embedding (GME) models that can rapidly learn how to\ngenerate desirable initial embeddings for new ad IDs based on graph neural\nnetworks and meta learning. Previous works address this problem from the new ad\nitself, but ignore possibly useful information contained in existing old ads.\nIn contrast, GMEs simultaneously consider two information sources: the new ad\nand existing old ads. For the new ad, GMEs exploit its associated attributes.\nFor existing old ads, GMEs first build a graph to connect them with new ads,\nand then adaptively distill useful information. We propose three specific GMEs\nfrom different perspectives to explore what kind of information to use and how\nto distill information. In particular, GME-P uses Pre-trained neighbor ID\nembeddings, GME-G uses Generated neighbor ID embeddings and GME-A uses neighbor\nAttributes. Experimental results on three real-world datasets show that GMEs\ncan significantly improve the prediction performance in both cold-start (i.e.,\nno training data is available) and warm-up (i.e., a small number of training\nsamples are collected) scenarios over five major deep learning-based CTR\nprediction models. GMEs can be applied to conversion rate (CVR) prediction as\nwell.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 03:46:56 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Ouyang", "Wentao", ""], ["Zhang", "Xiuwu", ""], ["Ren", "Shukui", ""], ["Li", "Li", ""], ["Zhang", "Kun", ""], ["Luo", "Jinmei", ""], ["Liu", "Zhaojie", ""], ["Du", "Yanlong", ""]]}, {"id": "2105.09009", "submitter": "Henderik Alex Proper", "authors": "H. A. Proper", "title": "An Overview of Computer Supported Query Formulation", "comments": "arXiv admin note: substantial text overlap with arXiv:2102.01411", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Most present day organisations make use of some automated information system.\nThis usually means that a large body of vital corporate information is stored\nin these information systems. As a result, an essential function of information\nsystems should be the support of disclosure of this information.\n  We purposely use the term {\\em information disclosure} in this context. When\nusing the term information disclosure we envision a computer supported\nmechanism that allows for an easy and intuitive formulation of queries in a\nlanguage that is as close to the user's perception of the universe of discourse\nas possible.\n  From this point of view, it is only obvious that we do not consider a simple\nquery mechanism where users have to enter complex queries manually and look up\nwhat information is stored in a set of relational tables. Without a set of\nadequate information disclosure avenues an information system becomes worthless\nsince there is no use in storing information that will never be retrieved.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 09:23:51 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Proper", "H. A.", ""]]}, {"id": "2105.09137", "submitter": "Saumya Banthia", "authors": "Saumya Banthia, Anantha Sharma, Ravi Mangipudi", "title": "TableZa -- A classical Computer Vision approach to Tabular Extraction", "comments": "14 pages, 16 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Computer aided Tabular Data Extraction has always been a very challenging and\nerror prone task because it demands both Spectral and Spatial Sanity of data.\nIn this paper we discuss an approach for Tabular Data Extraction in the realm\nof document comprehension. Given the different kinds of the Tabular formats\nthat are often found across various documents, we discuss a novel approach\nusing Computer Vision for extraction of tabular data from images or vector\npdf(s) converted to image(s).\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 13:55:33 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Banthia", "Saumya", ""], ["Sharma", "Anantha", ""], ["Mangipudi", "Ravi", ""]]}, {"id": "2105.09179", "submitter": "Krisztian Balog", "authors": "Krisztian Balog and Filip Radlinski and Alexandros Karatzoglou", "title": "On Interpretation and Measurement of Soft Attributes for Recommendation", "comments": "Proceedings of the 44th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR '21), 2021", "journal-ref": null, "doi": "10.1145/3404835.3462893", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We address how to robustly interpret natural language refinements (or\ncritiques) in recommender systems. In particular, in human-human recommendation\nsettings people frequently use soft attributes to express preferences about\nitems, including concepts like the originality of a movie plot, the noisiness\nof a venue, or the complexity of a recipe. While binary tagging is extensively\nstudied in the context of recommender systems, soft attributes often involve\nsubjective and contextual aspects, which cannot be captured reliably in this\nway, nor be represented as objective binary truth in a knowledge base. This\nalso adds important considerations when measuring soft attribute ranking. We\npropose a more natural representation as personalized relative statements,\nrather than as absolute item properties. We present novel data collection\ntechniques and evaluation approaches, and a new public dataset. We also propose\na set of scoring approaches, from unsupervised to weakly supervised to fully\nsupervised, as a step towards interpreting and acting upon soft attribute based\ncritiques.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 14:54:53 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Balog", "Krisztian", ""], ["Radlinski", "Filip", ""], ["Karatzoglou", "Alexandros", ""]]}, {"id": "2105.09204", "submitter": "Krisztian Balog", "authors": "Jafar Afzali and Aleksander Mark Drzewiecki and Krisztian Balog", "title": "POINTREC: A Test Collection for Narrative-driven Point of Interest\n  Recommendation", "comments": "Proceedings of the 44th International ACM SIGIR Conference on\n  Research and Development in Information Retrieval (SIGIR '21), 2021", "journal-ref": null, "doi": "10.1145/3404835.3463243", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a test collection for contextual point of interest (POI)\nrecommendation in a narrative-driven scenario. There, user history is not\navailable, instead, user requests are described in natural language. The\nrequests in our collection are manually collected from social sharing websites,\nand are annotated with various types of metadata, including location,\ncategories, constraints, and example POIs. These requests are to be resolved\nfrom a dataset of POIs, which are collected from a popular online directory,\nand are further linked to a geographical knowledge base and enriched with\nrelevant web snippets. Graded relevance assessments are collected using\ncrowdsourcing, by pooling both manual and automatic recommendations, where the\nlatter serve as baselines for future performance comparison. This resource\nsupports the development of novel approaches for end-to-end POI recommendation\nas well as for specific semantic annotation tasks on natural language requests.\n", "versions": [{"version": "v1", "created": "Wed, 19 May 2021 15:33:18 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Afzali", "Jafar", ""], ["Drzewiecki", "Aleksander Mark", ""], ["Balog", "Krisztian", ""]]}, {"id": "2105.09293", "submitter": "Dan Shiebler", "authors": "Alim Virani, Jay Baxter, Dan Shiebler, Philip Gautier, Shivam Verma,\n  Yan Xia, Apoorv Sharma, Sumit Binnani, Linlin Chen, Chenguang Yu", "title": "Lessons Learned Addressing Dataset Bias in Model-Based Candidate\n  Generation at Twitter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditionally, heuristic methods are used to generate candidates for large\nscale recommender systems. Model-based candidate generation promises multiple\npotential advantages, primarily that we can explicitly optimize the same\nobjective as the downstream ranking model. However, large scale model-based\ncandidate generation approaches suffer from dataset bias problems caused by the\ninfeasibility of obtaining representative data on very irrelevant candidates.\nPopular techniques to correct dataset bias, such as inverse propensity scoring,\ndo not work well in the context of candidate generation. We first explore the\ndynamics of the dataset bias problem and then demonstrate how to use random\nsampling techniques to mitigate it. Finally, in a novel application of\nfine-tuning, we show performance gains when applying our candidate generation\nsystem to Twitter's home timeline.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 23:18:41 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Virani", "Alim", ""], ["Baxter", "Jay", ""], ["Shiebler", "Dan", ""], ["Gautier", "Philip", ""], ["Verma", "Shivam", ""], ["Xia", "Yan", ""], ["Sharma", "Apoorv", ""], ["Binnani", "Sumit", ""], ["Chen", "Linlin", ""], ["Yu", "Chenguang", ""]]}, {"id": "2105.09296", "submitter": "Amifa Raj", "authors": "Amifa Raj, Ashlee Milton, Michael D. Ekstrand", "title": "Pink for Princesses, Blue for Superheroes: The Need to Examine Gender\n  Stereotypes in Kid's Products in Search and Recommendations", "comments": "KidRec '21: 5th International and Interdisciplinary Perspectives on\n  Children \\& Recommender and Information Retrieval Systems (KidRec) Search and\n  Recommendation Technology through the Lens of a Teacher- Co-located with ACM\n  IDC 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this position paper, we argue for the need to investigate if and how\ngender stereotypes manifest in search and recommender systems.As a starting\npoint, we particularly focus on how these systems may propagate and reinforce\ngender stereotypes through their results in learning environments, a context\nwhere teachers and children in their formative stage regularly interact with\nthese systems. We provide motivating examples supporting our concerns and\noutline an agenda to support future research addressing the phenomena.\n", "versions": [{"version": "v1", "created": "Thu, 13 May 2021 21:37:23 GMT"}], "update_date": "2021-05-20", "authors_parsed": [["Raj", "Amifa", ""], ["Milton", "Ashlee", ""], ["Ekstrand", "Michael D.", ""]]}, {"id": "2105.09297", "submitter": "Rongyu Cao Dr.", "authors": "Rongyu Cao and Yixuan Cao and Ganbin Zhou and Ping Luo", "title": "Extracting Variable-Depth Logical Document Hierarchy from Long\n  Documents: Method, Evaluation, and Application", "comments": "23 pages, 10 figures, Journal of computer science and technology", "journal-ref": "Journal of computer science and technology, 2021", "doi": "10.1007/s11390-021-1076-7", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of extracting variable-depth \"logical\ndocument hierarchy\" from long documents, namely organizing the recognized\n\"physical document objects\" into hierarchical structures. The discovery of\nlogical document hierarchy is the vital step to support many downstream\napplications. However, long documents, containing hundreds or even thousands of\npages and variable-depth hierarchy, challenge the existing methods. To address\nthese challenges, we develop a framework, namely Hierarchy Extraction from Long\nDocument (HELD), where we \"sequentially\" insert each physical object at the\nproper on of the current tree. Determining whether each possible position is\nproper or not can be formulated as a binary classification problem. To further\nimprove its effectiveness and efficiency, we study the design variants in HELD,\nincluding traversal orders of the insertion positions, heading extraction\nexplicitly or implicitly, tolerance to insertion errors in predecessor steps,\nand so on. The empirical experiments based on thousands of long documents from\nChinese, English financial market and English scientific publication show that\nthe HELD model with the \"root-to-leaf\" traversal order and explicit heading\nextraction is the best choice to achieve the tradeoff between effectiveness and\nefficiency with the accuracy of 0.9726, 0.7291 and 0.9578 in Chinese financial,\nEnglish financial and arXiv datasets, respectively. Finally, we show that\nlogical document hierarchy can be employed to significantly improve the\nperformance of the downstream passage retrieval task. In summary, we conduct a\nsystematic study on this task in terms of methods, evaluations, and\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 06:26:22 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Cao", "Rongyu", ""], ["Cao", "Yixuan", ""], ["Zhou", "Ganbin", ""], ["Luo", "Ping", ""]]}, {"id": "2105.09562", "submitter": "Henderik Alex Proper", "authors": "H. A. Proper", "title": "Interactive Query Formulation using Query By Navigation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Effective information disclosure in the context of databases with a large\nconceptual schema is known to be a non-trivial problem. In particular the\nformulation of ad-hoc queries is a major problem in such contexts. Existing\napproaches for tackling this problem include graphical query interfaces, query\nby navigation, query by construction, and point to point queries. In this\nreport we propose an adoption of the query by navigation mechanism that is\nespecially geared towards the InfoAssistant product. Query by navigation is\nbased on ideas from the information retrieval world, in particular on the\nstratified hypermedia architecture. When using our approach to the formulations\nof queries, a user will first formulate a number of simple queries\ncorresponding to linear paths through the information structure. The\nformulation of the linear paths is the result of the {\\em explorative phase} of\nthe query formulation. Once users have specified a number of these linear\npaths, they may combine them to form more complex queries. Examples of such\ncombinations are: concatenation, union, intersection and selection. This last\nprocess is referred to as {\\em query by construction}, and is the {\\em\nconstructive phase} of the query formulation process.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 07:30:41 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Proper", "H. A.", ""]]}, {"id": "2105.09592", "submitter": "Konstantinos Bountrogiannis", "authors": "Konstantinos Bountrogiannis, George Tzagkarakis, Panagiotis Tsakalides", "title": "Distribution Agnostic Symbolic Representations for Time Series\n  Dimensionality Reduction and Online Anomaly Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the importance of the lower bounding distances and the attractiveness\nof symbolic representations, the family of symbolic aggregate approximations\n(SAX) has been used extensively for encoding time series data. However, typical\nSAX-based methods rely on two restrictive assumptions; the Gaussian\ndistribution and equiprobable symbols. This paper proposes two novel\ndata-driven SAX-based symbolic representations, distinguished by their\ndiscretization steps. The first representation, oriented for general data\ncompaction and indexing scenarios, is based on the combination of kernel\ndensity estimation and Lloyd-Max quantization to minimize the information loss\nand mean squared error in the discretization step. The second method, oriented\nfor high-level mining tasks, employs the Mean-Shift clustering method and is\nshown to enhance anomaly detection in the lower-dimensional space. Besides, we\nverify on a theoretical basis a previously observed phenomenon of the intrinsic\nprocess that results in a lower than the expected variance of the intermediate\npiecewise aggregate approximation. This phenomenon causes an additional\ninformation loss but can be avoided with a simple modification. The proposed\nrepresentations possess all the attractive properties of the conventional SAX\nmethod. Furthermore, experimental evaluation on real-world datasets\ndemonstrates their superiority compared to the traditional SAX and an\nalternative data-driven SAX variant.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 08:35:50 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Bountrogiannis", "Konstantinos", ""], ["Tzagkarakis", "George", ""], ["Tsakalides", "Panagiotis", ""]]}, {"id": "2105.09605", "submitter": "Yu Wang", "authors": "Yu Wang, Xin Xin, Zaiqiao Meng, Xiangnan He, Joemon Jose, Fuli Feng", "title": "Probabilistic and Variational Recommendation Denoising", "comments": "13 pages, 17 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Learning from implicit feedback is one of the most common cases in the\napplication of recommender systems. Generally speaking, interacted examples are\nconsidered as positive while negative examples are sampled from uninteracted\nones. However, noisy examples are prevalent in real-world implicit feedback. A\nnoisy positive example could be interacted but it actually leads to negative\nuser preference. A noisy negative example which is uninteracted because of\nunawareness of the user could also denote potential positive user preference.\nConventional training methods overlook these noisy examples, leading to\nsub-optimal recommendation. In this work, we propose probabilistic and\nvariational recommendation denoising for implicit feedback. Through an\nempirical study, we find that different models make relatively similar\npredictions on clean examples which denote the real user preference, while the\npredictions on noisy examples vary much more across different models. Motivated\nby this observation, we propose denoising with probabilistic inference (DPI)\nwhich aims to minimize the KL-divergence between the real user preference\ndistributions parameterized by two recommendation models while maximize the\nlikelihood of data observation. We then show that DPI recovers the evidence\nlower bound of an variational auto-encoder when the real user preference is\nconsidered as the latent variables. This leads to our second learning framework\ndenoising with variational autoencoder (DVAE). We employ the proposed DPI and\nDVAE on four state-of-the-art recommendation models and conduct experiments on\nthree datasets. Experimental results demonstrate that DPI and DVAE\nsignificantly improve recommendation performance compared with normal training\nand other denoising methods. Codes will be open-sourced.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 08:59:44 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Wang", "Yu", ""], ["Xin", "Xin", ""], ["Meng", "Zaiqiao", ""], ["He", "Xiangnan", ""], ["Jose", "Joemon", ""], ["Feng", "Fuli", ""]]}, {"id": "2105.09613", "submitter": "Aditi Singh", "authors": "Aditi Singh, Suhas Jayaram Subramanya, Ravishankar Krishnaswamy,\n  Harsha Vardhan Simhadri", "title": "FreshDiskANN: A Fast and Accurate Graph-Based ANN Index for Streaming\n  Similarity Search", "comments": "19 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Approximate nearest neighbor search (ANNS) is a fundamental building block in\ninformation retrieval with graph-based indices being the current\nstate-of-the-art and widely used in the industry. Recent advances in\ngraph-based indices have made it possible to index and search billion-point\ndatasets with high recall and millisecond-level latency on a single commodity\nmachine with an SSD.\n  However, existing graph algorithms for ANNS support only static indices that\ncannot reflect real-time changes to the corpus required by many key real-world\nscenarios (e.g. index of sentences in documents, email, or a news index). To\novercome this drawback, the current industry practice for manifesting updates\ninto such indices is to periodically re-build these indices, which can be\nprohibitively expensive.\n  In this paper, we present the first graph-based ANNS index that reflects\ncorpus updates into the index in real-time without compromising on search\nperformance. Using update rules for this index, we design FreshDiskANN, a\nsystem that can index over a billion points on a workstation with an SSD and\nlimited memory, and support thousands of concurrent real-time inserts, deletes\nand searches per second each, while retaining $>95\\%$ 5-recall@5. This\nrepresents a 5-10x reduction in the cost of maintaining freshness in indices\nwhen compared to existing methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 09:17:13 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Singh", "Aditi", ""], ["Subramanya", "Suhas Jayaram", ""], ["Krishnaswamy", "Ravishankar", ""], ["Simhadri", "Harsha Vardhan", ""]]}, {"id": "2105.09710", "submitter": "Yang Deng", "authors": "Yang Deng, Yaliang Li, Fei Sun, Bolin Ding, Wai Lam", "title": "Unified Conversational Recommendation Policy Learning via Graph-based\n  Reinforcement Learning", "comments": "Accepted by SIGIR 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Conversational recommender systems (CRS) enable the traditional recommender\nsystems to explicitly acquire user preferences towards items and attributes\nthrough interactive conversations. Reinforcement learning (RL) is widely\nadopted to learn conversational recommendation policies to decide what\nattributes to ask, which items to recommend, and when to ask or recommend, at\neach conversation turn. However, existing methods mainly target at solving one\nor two of these three decision-making problems in CRS with separated\nconversation and recommendation components, which restrict the scalability and\ngenerality of CRS and fall short of preserving a stable training procedure. In\nthe light of these challenges, we propose to formulate these three\ndecision-making problems in CRS as a unified policy learning task. In order to\nsystematically integrate conversation and recommendation components, we develop\na dynamic weighted graph based RL method to learn a policy to select the action\nat each conversation turn, either asking an attribute or recommending items.\nFurther, to deal with the sample efficiency issue, we propose two action\nselection strategies for reducing the candidate action space according to the\npreference and entropy information. Experimental results on two benchmark CRS\ndatasets and a real-world E-Commerce application show that the proposed method\nnot only significantly outperforms state-of-the-art methods but also enhances\nthe scalability and stability of CRS.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 12:50:41 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Deng", "Yang", ""], ["Li", "Yaliang", ""], ["Sun", "Fei", ""], ["Ding", "Bolin", ""], ["Lam", "Wai", ""]]}, {"id": "2105.09816", "submitter": "Sebastian Hofst\\\"atter", "authors": "Sebastian Hofst\\\"atter, Bhaskar Mitra, Hamed Zamani, Nick Craswell,\n  Allan Hanbury", "title": "Intra-Document Cascading: Learning to Select Passages for Neural\n  Document Ranking", "comments": "Accepted at SIGIR 2021 (Full Paper Track)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An emerging recipe for achieving state-of-the-art effectiveness in neural\ndocument re-ranking involves utilizing large pre-trained language models -\ne.g., BERT - to evaluate all individual passages in the document and then\naggregating the outputs by pooling or additional Transformer layers. A major\ndrawback of this approach is high query latency due to the cost of evaluating\nevery passage in the document with BERT. To make matters worse, this high\ninference cost and latency varies based on the length of the document, with\nlonger documents requiring more time and computation. To address this\nchallenge, we adopt an intra-document cascading strategy, which prunes passages\nof a candidate document using a less expensive model, called ESM, before\nrunning a scoring model that is more expensive and effective, called ETM. We\nfound it best to train ESM (short for Efficient Student Model) via knowledge\ndistillation from the ETM (short for Effective Teacher Model) e.g., BERT. This\npruning allows us to only run the ETM model on a smaller set of passages whose\nsize does not vary by document length. Our experiments on the MS MARCO and TREC\nDeep Learning Track benchmarks suggest that the proposed Intra-Document\nCascaded Ranking Model (IDCM) leads to over 400% lower query latency by\nproviding essentially the same effectiveness as the state-of-the-art BERT-based\ndocument ranking models.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 15:10:13 GMT"}], "update_date": "2021-05-21", "authors_parsed": [["Hofst\u00e4tter", "Sebastian", ""], ["Mitra", "Bhaskar", ""], ["Zamani", "Hamed", ""], ["Craswell", "Nick", ""], ["Hanbury", "Allan", ""]]}, {"id": "2105.09829", "submitter": "Yongfeng Zhang", "authors": "Yunqi Li, Hanxiong Chen, Shuyuan Xu, Yingqiang Ge, Yongfeng Zhang", "title": "Personalized Counterfactual Fairness in Recommendation", "comments": "10 pages. Accepted to ACM SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462966", "report-no": null, "categories": "cs.IR cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are gaining increasing and critical impacts on human and\nsociety since a growing number of users use them for information seeking and\ndecision making. Therefore, it is crucial to address the potential unfairness\nproblems in recommendations. Just like users have personalized preferences on\nitems, users' demands for fairness are also personalized in many scenarios.\nTherefore, it is important to provide personalized fair recommendations for\nusers to satisfy their personalized fairness demands. Besides, previous works\non fair recommendation mainly focus on association-based fairness. However, it\nis important to advance from associative fairness notions to causal fairness\nnotions for assessing fairness more properly in recommender systems. Based on\nthe above considerations, this paper focuses on achieving personalized\ncounterfactual fairness for users in recommender systems. To this end, we\nintroduce a framework for achieving counterfactually fair recommendations\nthrough adversary learning by generating feature-independent user embeddings\nfor recommendation. The framework allows recommender systems to achieve\npersonalized fairness for users while also covering non-personalized\nsituations. Experiments on two real-world datasets with shallow and deep\nrecommendation algorithms show that our method can generate fairer\nrecommendations for users with a desirable recommendation performance.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 15:24:34 GMT"}, {"version": "v2", "created": "Wed, 21 Jul 2021 15:52:26 GMT"}], "update_date": "2021-07-22", "authors_parsed": [["Li", "Yunqi", ""], ["Chen", "Hanxiong", ""], ["Xu", "Shuyuan", ""], ["Ge", "Yingqiang", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "2105.09981", "submitter": "M. Mehdi Afsar", "authors": "Mehdi Afsar, Trafford Crump, Behrouz Far", "title": "A Load Balanced Recommendation Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems (RSs) are software tools and algorithms developed to\nalleviate the problem of information overload, which makes it difficult for a\nuser to make right decisions. Two main paradigms toward the recommendation\nproblem are collaborative filtering and content-based filtering, which try to\nrecommend the best items using ratings and content available. These methods\ntypically face infamous problems including cold-start, diversity, scalability,\nand great computational expense. We argue that the uptake of deep learning and\nreinforcement learning methods is also questionable due to their computational\ncomplexities and uninterpretability. In this paper, we approach the\nrecommendation problem from a new prospective. We borrow ideas from cluster\nhead selection algorithms in wireless sensor networks and adapt them to the\nrecommendation problem. In particular, we propose Load Balanced Recommender\nSystem (LBRS), which uses a probabilistic scheme for item recommendation.\nFurthermore, we factor in the importance of items in the recommendation\nprocess, which significantly improves the recommendation accuracy. We also\nintroduce a method that considers a heterogeneity among items, in order to\nbalance the similarity and diversity trade-off. Finally, we propose a new\nmetric for diversity, which emphasizes the importance of diversity not only\nfrom an intra-list perspective, but also from a between-list point of view.\nWith experiments in a simulation study performed on RecSim, we show that LBRS\nis effective and can outperform baseline methods.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 18:30:43 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Afsar", "Mehdi", ""], ["Crump", "Trafford", ""], ["Far", "Behrouz", ""]]}, {"id": "2105.10019", "submitter": "Daniel Poh", "authors": "Daniel Poh, Bryan Lim, Stefan Zohren and Stephen Roberts", "title": "Enhancing Cross-Sectional Currency Strategies by Ranking Refinement with\n  Transformer-based Architectures", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.IR cs.LG q-fin.TR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The performance of a cross-sectional currency strategy depends crucially on\naccurately ranking instruments prior to portfolio construction. While this\nranking step is traditionally performed using heuristics, or by sorting outputs\nproduced by pointwise regression or classification models, Learning to Rank\nalgorithms have recently presented themselves as competitive and viable\nalternatives. Despite improving ranking accuracy on average however, these\ntechniques do not account for the possibility that assets positioned at the\nextreme ends of the ranked list -- which are ultimately used to construct the\nlong/short portfolios -- can assume different distributions in the input space,\nand thus lead to sub-optimal strategy performance. Drawing from research in\nInformation Retrieval that demonstrates the utility of contextual information\nembedded within top-ranked documents to learn the query's characteristics to\nimprove ranking, we propose an analogous approach: exploiting the features of\nboth out- and under-performing instruments to learn a model for refining the\noriginal ranked list. Under a re-ranking framework, we adapt the Transformer\narchitecture to encode the features of extreme assets for refining our\nselection of long/short instruments obtained with an initial retrieval.\nBacktesting on a set of 31 currencies, our proposed methodology significantly\nboosts Sharpe ratios -- by approximately 20% over the original LTR algorithms\nand double that of traditional baselines.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 20:30:41 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Poh", "Daniel", ""], ["Lim", "Bryan", ""], ["Zohren", "Stefan", ""], ["Roberts", "Stephen", ""]]}, {"id": "2105.10072", "submitter": "Jianghong Zhou", "authors": "Jianghong Zhou, Sayyed M. Zahiri, Simon Hughes, Khalifeh Al Jadda,\n  Surya Kallumadi, Eugene Agichtein", "title": "De-Biased Modelling of Search Click Behavior with Reinforcement Learning", "comments": "SIGIR 2021 Short Paper", "journal-ref": null, "doi": "10.1145/3404835.3463228", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Users' clicks on Web search results are one of the key signals for evaluating\nand improving web search quality and have been widely used as part of current\nstate-of-the-art Learning-To-Rank(LTR) models. With a large volume of search\nlogs available for major search engines, effective models of searcher click\nbehavior have emerged to evaluate and train LTR models. However, when modeling\nthe users' click behavior, considering the bias of the behavior is imperative.\nIn particular, when a search result is not clicked, it is not necessarily\nchosen as not relevant by the user, but instead could have been simply missed,\nespecially for lower-ranked results. These kinds of biases in the click log\ndata can be incorporated into the click models, propagating the errors to the\nresulting LTR ranking models or evaluation metrics. In this paper, we propose\nthe De-biased Reinforcement Learning Click model (DRLC). The DRLC model relaxes\npreviously made assumptions about the users' examination behavior and resulting\nlatent states. To implement the DRLC model, convolutional neural networks are\nused as the value networks for reinforcement learning, trained to learn a\npolicy to reduce bias in the click logs. To demonstrate the effectiveness of\nthe DRLC model, we first compare performance with the previous state-of-art\napproaches using established click prediction metrics, including log-likelihood\nand perplexity. We further show that DRLC also leads to improvements in ranking\nperformance. Our experiments demonstrate the effectiveness of the DRLC model in\nlearning to reduce bias in click logs, leading to improved modeling performance\nand showing the potential for using DRLC for improving Web search quality.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 00:23:32 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Zhou", "Jianghong", ""], ["Zahiri", "Sayyed M.", ""], ["Hughes", "Simon", ""], ["Jadda", "Khalifeh Al", ""], ["Kallumadi", "Surya", ""], ["Agichtein", "Eugene", ""]]}, {"id": "2105.10075", "submitter": "Jianghong Zhou", "authors": "Jianghong Zhou, Eugene Agichtein, Surya Kallumadi", "title": "Diversifying Multi-aspect Search Results Using Simpson's Diversity Index", "comments": "Proceedings of the 29th ACM International Conference on Information\n  and Knowledge Management (CIKM '20), October 19--23, 2020, Virtual Event,\n  Ireland}", "journal-ref": "CIKM '20: Proceedings of the 29th ACM International Conference on\n  Information & Knowledge Management October 2020 Pages 2345-2348", "doi": "10.1145/3340531.3412163", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In search and recommendation, diversifying the multi-aspect search results\ncould help with reducing redundancy, and promoting results that might not be\nshown otherwise. Many previous methods have been proposed for this task.\nHowever, previous methods do not explicitly consider the uniformity of the\nnumber of the items' classes, or evenness, which could degrade the search and\nrecommendation quality. To address this problem, we introduce a novel method by\nadapting the Simpson's Diversity Index from biology, which enables a more\neffective and efficient quadratic search result diversification algorithm. We\nalso extend the method to balance the diversity between multiple aspects\nthrough weighted factors and further improve computational complexity by\ndeveloping a fast approximation algorithm. We demonstrate the feasibility of\nthe proposed method using the openly available Kaggle shoes competition\ndataset. Our experimental results show that our approach outperforms previous\nstate of the art diversification methods, while reducing computational\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 00:53:18 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Zhou", "Jianghong", ""], ["Agichtein", "Eugene", ""], ["Kallumadi", "Surya", ""]]}, {"id": "2105.10117", "submitter": "Kornraphop Kawintiranon", "authors": "Kornraphop Kawintiranon and Yaguang Liu", "title": "Towards Automatic Comparison of Data Privacy Documents: A Preliminary\n  Experiment on GDPR-like Laws", "comments": "This is a preliminary work, see repo at\n  https://github.com/kornosk/GDPR-similarity-comparison", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  General Data Protection Regulation (GDPR) becomes a standard law for data\nprotection in many countries. Currently, twelve countries adopt the regulation\nand establish their GDPR-like regulation. However, to evaluate the differences\nand similarities of these GDPR-like regulations is time-consuming and needs a\nlot of manual effort from legal experts. Moreover, GDPR-like regulations from\ndifferent countries are written in their languages leading to a more difficult\ntask since legal experts who know both languages are essential. In this paper,\nwe investigate a simple natural language processing (NLP) approach to tackle\nthe problem. We first extract chunks of information from GDPR-like documents\nand form structured data from natural language. Next, we use NLP methods to\ncompare documents to measure their similarity. Finally, we manually label a\nsmall set of data to evaluate our approach. The empirical result shows that the\nBERT model with cosine similarity outperforms other baselines. Our data and\ncode are publicly available.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 03:59:29 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Kawintiranon", "Kornraphop", ""], ["Liu", "Yaguang", ""]]}, {"id": "2105.10124", "submitter": "Jianghong Zhou", "authors": "Jianghong Zhou, Eugene Agichtein", "title": "RLIRank: Learning to Rank with Reinforcement Learning for Dynamic Search", "comments": "Proceedings of The Web Conference 2020 (WWW '20), April 20--24, 2020,\n  Taipei, Taiwan", "journal-ref": "WWW '20: Proceedings of The Web Conference 2020 April 2020 Pages\n  2842-2848", "doi": "10.1145/3366423.3380047", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  To support complex search tasks, where the initial information requirements\nare complex or may change during the search, a search engine must adapt the\ninformation delivery as the user's information requirements evolve. To support\nthis dynamic ranking paradigm effectively, search result ranking must\nincorporate both the user feedback received, and the information displayed so\nfar. To address this problem, we introduce a novel reinforcement learning-based\napproach, RLIrank. We first build an adapted reinforcement learning framework\nto integrate the key components of the dynamic search. Then, we implement a new\nLearning to Rank (LTR) model for each iteration of the dynamic search, using a\nrecurrent Long Short Term Memory neural network (LSTM), which estimates the\ngain for each next result, learning from each previously ranked document. To\nincorporate the user's feedback, we develop a word-embedding variation of the\nclassic Rocchio Algorithm, to help guide the ranking towards the high-value\ndocuments. Those innovations enable RLIrank to outperform the previously\nreported methods from the TREC Dynamic Domain Tracks 2017 and exceed all the\nmethods in 2016 TREC Dynamic Domain after multiple search iterations, advancing\nthe state of the art for dynamic search.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 04:30:17 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Zhou", "Jianghong", ""], ["Agichtein", "Eugene", ""]]}, {"id": "2105.10152", "submitter": "Harsh Kohli Mr.", "authors": "Harsh Kohli", "title": "Training Mixed-Objective Pointing Decoders for Block-Level Optimization\n  in Search Recommendation", "comments": "4 pages. Accepted at the 43rd International ACM SIGIR Conference on\n  Research and Development in Information Retrieval", "journal-ref": null, "doi": "10.1145/3397271.3401236", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Related or ideal follow-up suggestions to a web query in search engines are\noften optimized based on several different parameters -- relevance to the\noriginal query, diversity, click probability etc. One or many rankers may be\ntrained to score each suggestion from a candidate pool based on these factors.\nThese scorers are usually pairwise classification tasks where each training\nexample consists of a user query and a single suggestion from the list of\ncandidates. We propose an architecture that takes all candidate suggestions\nassociated with a given query and outputs a suggestion block. We discuss the\nbenefits of such an architecture over traditional approaches and experiment\nwith further enforcing each individual metric through mixed-objective training.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 06:34:19 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Kohli", "Harsh", ""]]}, {"id": "2105.10165", "submitter": "Dipendra Misra", "authors": "Andrew Bennett, Dipendra Misra, and Nga Than", "title": "Have you tried Neural Topic Models? Comparative Analysis of Neural and\n  Non-Neural Topic Models with Application to COVID-19 Twitter Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models are widely used in studying social phenomena. We conduct a\ncomparative study examining state-of-the-art neural versus non-neural topic\nmodels, performing a rigorous quantitative and qualitative assessment on a\ndataset of tweets about the COVID-19 pandemic. Our results show that not only\ndo neural topic models outperform their classical counterparts on standard\nevaluation metrics, but they also produce more coherent topics, which are of\ngreat benefit when studying complex social problems. We also propose a novel\nregularization term for neural topic models, which is designed to address the\nwell-documented problem of mode collapse, and demonstrate its effectiveness.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 07:24:09 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Bennett", "Andrew", ""], ["Misra", "Dipendra", ""], ["Than", "Nga", ""]]}, {"id": "2105.10216", "submitter": "Simon Walk", "authors": "Matthias W\\\"olbitsch, Thomas Hasler, Patrick Kasper, Denis Helic,\n  Simon Walk", "title": "RFID-based Article-to-Fixture Predictions in Real-World Fashion Stores", "comments": "Extended version of conference submission to IEEE RFID", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In recent years, Radio Frequency Identification (RFID) technology has been\napplied to improve numerous processes, such as inventory management in retail\nstores. However, automatic localization of RFID-tagged goods in stores is still\na challenging problem. To address this issue, we equip fixtures (e.g., shelves)\nwith reference tags and use data we collect during RFID-based stocktakes to map\narticles to fixtures. Knowing the location of goods enables the implementation\nof several practical applications, such as automated Money Mapping (i.e., a\nheat map of sales across fixtures). Specifically, we conduct controlled lab\nexperiments and a case-study in two fashion retail stores to evaluate our\narticle-to-fixture prediction approaches. The approaches are based on\ncalculating distances between read event time series using DTW, and clustering\nof read events using DBSCAN. We find that, read events collected during\nRFID-based stocktakes can be used to assign articles to fixtures with an\naccuracy of more than 90%. Additionally, we conduct a pilot to investigate the\nchallenges related to the integration of such a localization system in the\nday-to-day business of retail stores. Hence, in this paper we present an\nexploratory venture into novel and practical RFID-based applications in fashion\nretails stores, beyond the scope of stock management.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 09:12:36 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["W\u00f6lbitsch", "Matthias", ""], ["Hasler", "Thomas", ""], ["Kasper", "Patrick", ""], ["Helic", "Denis", ""], ["Walk", "Simon", ""]]}, {"id": "2105.10256", "submitter": "Andrea Fronzetti Colladon PhD", "authors": "A. Fronzetti Colladon and P. A. Gloor", "title": "Measuring the impact of spammers on e-mail and Twitter networks", "comments": null, "journal-ref": "International Journal of Information Management 48, 254-262 (2019)", "doi": "10.1016/j.ijinfomgt.2018.09.009", "report-no": null, "categories": "cs.SI cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper investigates the research question if senders of large amounts of\nirrelevant or unsolicited information - commonly called \"spammers\" - distort\nthe network structure of social networks. Two large social networks are\nanalyzed, the first extracted from the Twitter discourse about a big\ntelecommunication company, and the second obtained from three years of email\ncommunication of 200 managers working for a large multinational company. This\nwork compares network robustness and the stability of centrality and\ninteraction metrics, as well as the use of language, after removing spammers\nand the most and least connected nodes. The results show that spammers do not\nsignificantly alter the structure of the information-carrying network, for most\nof the social indicators. The authors additionally investigate the correlation\nbetween e-mail subject line and content by tracking language sentiment,\nemotionality, and complexity, addressing the cases where collecting email\nbodies is not permitted for privacy reasons. The findings extend the research\nabout robustness and stability of social networks metrics, after the\napplication of graph simplification strategies. The results have practical\nimplication for network analysts and for those company managers who rely on\nnetwork analytics (applied to company emails and social media data) to support\ntheir decision-making processes.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 10:13:11 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Colladon", "A. Fronzetti", ""], ["Gloor", "P. A.", ""]]}, {"id": "2105.10484", "submitter": "Jinnian Zhang", "authors": "Ze Meng, Jinnian Zhang, Yumeng Li, Jiancheng Li, Tanchao Zhu, Lifeng\n  Sun", "title": "A General Method For Automatic Discovery of Powerful Interactions In\n  Click-Through Rate Prediction", "comments": "Accepted by ACM SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462842", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling powerful interactions is a critical challenge in Click-through rate\n(CTR) prediction, which is one of the most typical machine learning tasks in\npersonalized advertising and recommender systems. Although developing\nhand-crafted interactions is effective for a small number of datasets, it\ngenerally requires laborious and tedious architecture engineering for extensive\nscenarios. In recent years, several neural architecture search (NAS) methods\nhave been proposed for designing interactions automatically. However, existing\nmethods only explore limited types and connections of operators for interaction\ngeneration, leading to low generalization ability. To address these problems,\nwe propose a more general automated method for building powerful interactions\nnamed AutoPI. The main contributions of this paper are as follows: AutoPI\nadopts a more general search space in which the computational graph is\ngeneralized from existing network connections, and the interactive operators in\nthe edges of the graph are extracted from representative hand-crafted works. It\nallows searching for various powerful feature interactions to produce higher\nAUC and lower Logloss in a wide variety of applications. Besides, AutoPI\nutilizes a gradient-based search strategy for exploration with a significantly\nlow computational cost. Experimentally, we evaluate AutoPI on a diverse suite\nof benchmark datasets, demonstrating the generalizability and efficiency of\nAutoPI over hand-crafted architectures and state-of-the-art NAS algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 17:48:28 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Meng", "Ze", ""], ["Zhang", "Jinnian", ""], ["Li", "Yumeng", ""], ["Li", "Jiancheng", ""], ["Zhu", "Tanchao", ""], ["Sun", "Lifeng", ""]]}, {"id": "2105.10587", "submitter": "Michael Tashman", "authors": "Michael Tashman, John Hoffman, Jiayi Xie, Fengdan Ye, Atefeh Morsali,\n  Lee Winikor, Rouzbeh Gerami", "title": "Techniques Toward Optimizing Viewability in RTB Ad Campaigns Using\n  Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reinforcement learning (RL) is an effective technique for training\ndecision-making agents through interactions with their environment. The advent\nof deep learning has been associated with highly notable successes with\nsequential decision making problems - such as defeating some of the\nhighest-ranked human players at Go. In digital advertising, real-time bidding\n(RTB) is a common method of allocating advertising inventory through real-time\nauctions. Bidding strategies need to incorporate logic for dynamically\nadjusting parameters in order to deliver pre-assigned campaign goals. Here we\ndiscuss techniques toward using RL to train bidding agents. As a campaign\nmetric we particularly focused on viewability: the percentage of inventory\nwhich goes on to be viewed by an end user.\n  This paper is presented as a survey of techniques and experiments which we\ndeveloped through the course of this research. We discuss expanding our\ntraining data to include edge cases by training on simulated interactions. We\ndiscuss the experimental results comparing the performance of several promising\nRL algorithms, and an approach to hyperparameter optimization of an\nactor/critic training pipeline through Bayesian optimization. Finally, we\npresent live-traffic tests of some of our RL agents against a rule-based\nfeedback-control approach, demonstrating the potential for this method as well\nas areas for further improvement. This paper therefore presents an arrangement\nof our findings in this quickly developing field, and ways that it can be\napplied to an RTB use case.\n", "versions": [{"version": "v1", "created": "Fri, 21 May 2021 21:56:12 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Tashman", "Michael", ""], ["Hoffman", "John", ""], ["Xie", "Jiayi", ""], ["Ye", "Fengdan", ""], ["Morsali", "Atefeh", ""], ["Winikor", "Lee", ""], ["Gerami", "Rouzbeh", ""]]}, {"id": "2105.10648", "submitter": "Wenjie Wang", "authors": "Wenjie Wang, Fuli Feng, Xiangnan He, Xiang Wang, and Tat-Seng Chua", "title": "Deconfounded Recommendation for Alleviating Bias Amplification", "comments": null, "journal-ref": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discoveryand Data Mining (KDD 2021)", "doi": "10.1145/3447548.3467249", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems usually amplify the biases in the data. The model learned\nfrom historical interactions with imbalanced item distribution will amplify the\nimbalance by over-recommending items from the major groups. Addressing this\nissue is essential for a healthy ecosystem of recommendation in the long run.\nExisting works apply bias control to the ranking targets (e.g., calibration,\nfairness, and diversity), but ignore the true reason for bias amplification and\ntrade-off the recommendation accuracy.\n  In this work, we scrutinize the cause-effect factors for bias amplification,\nidentifying the main reason lies in the confounder effect of imbalanced item\ndistribution on user representation and prediction score. The existence of such\nconfounder pushes us to go beyond merely modeling the conditional probability\nand embrace the causal modeling for recommendation. Towards this end, we\npropose a Deconfounded Recommender System (DecRS), which models the causal\neffect of user representation on the prediction score. The key to eliminating\nthe impact of the confounder lies in backdoor adjustment, which is however\ndifficult to do due to the infinite sample space of the confounder. For this\nchallenge, we contribute an approximation operator for backdoor adjustment\nwhich can be easily plugged into most recommender models. Lastly, we devise an\ninference strategy to dynamically regulate backdoor adjustment according to\nuser status. We instantiate DecRS on two representative models FM and NFM, and\nconduct extensive experiments over two benchmarks to validate the superiority\nof our proposed DecRS.\n", "versions": [{"version": "v1", "created": "Sat, 22 May 2021 06:20:39 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Wang", "Wenjie", ""], ["Feng", "Fuli", ""], ["He", "Xiangnan", ""], ["Wang", "Xiang", ""], ["Chua", "Tat-Seng", ""]]}, {"id": "2105.10866", "submitter": "Zeinab Rouhollahi", "authors": "Zeinab Rouhollahi", "title": "Towards Artificial Intelligence Enabled Financial Crime Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR q-fin.ST", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, financial institutes have been dealing with an increase in\nfinancial crimes. In this context, financial services firms started to improve\ntheir vigilance and use new technologies and approaches to identify and predict\nfinancial fraud and crime possibilities. This task is challenging as\ninstitutions need to upgrade their data and analytics capabilities to enable\nnew technologies such as Artificial Intelligence (AI) to predict and detect\nfinancial crimes. In this paper, we put a step towards AI-enabled financial\ncrime detection in general and money laundering detection in particular to\naddress this challenge. We study and analyse the recent works done in financial\ncrime detection and present a novel model to detect money laundering cases with\nminimum human intervention needs.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 06:57:25 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Rouhollahi", "Zeinab", ""]]}, {"id": "2105.10868", "submitter": "Seongwon Jang", "authors": "Seongwon Jang, Hoyeop Lee, Hyunsouk Cho, Sehee Chung", "title": "CITIES: Contextual Inference of Tail-Item Embeddings for Sequential\n  Recommendation", "comments": "Accepted as a full paper at IEEE ICDM 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Sequential recommendation techniques provide users with product\nrecommendations fitting their current preferences by handling dynamic user\npreferences over time. Previous studies have focused on modeling sequential\ndynamics without much regard to which of the best-selling products (i.e., head\nitems) or niche products (i.e., tail items) should be recommended. We\nscrutinize the structural reason for why tail items are barely served in the\ncurrent sequential recommendation model, which consists of an item-embedding\nlayer, a sequence-modeling layer, and a recommendation layer. Well-designed\nsequence-modeling and recommendation layers are expected to naturally learn\nsuitable item embeddings. However, tail items are likely to fall short of this\nexpectation because the current model structure is not suitable for learning\nhigh-quality embeddings with insufficient data. Thus, tail items are rarely\nrecommended. To eliminate this issue, we propose a framework called CITIES,\nwhich aims to enhance the quality of the tail-item embeddings by training an\nembedding-inference function using multiple contextual head items so that the\nrecommendation performance improves for not only the tail items but also for\nthe head items. Moreover, our framework can infer new-item embeddings without\nan additional learning process. Extensive experiments on two real-world\ndatasets show that applying CITIES to the state-of-the-art methods improves\nrecommendation performance for both tail and head items. We conduct an\nadditional experiment to verify that CITIES can infer suitable new-item\nembeddings as well.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 07:07:12 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Jang", "Seongwon", ""], ["Lee", "Hoyeop", ""], ["Cho", "Hyunsouk", ""], ["Chung", "Sehee", ""]]}, {"id": "2105.10880", "submitter": "Yang Li", "authors": "Yang Li, Hermawan Mulyono, Ying Chen, Zhiyin Lu, Desmond Chan", "title": "RtFPS: An Interactive Map that Visualizes and Predicts Wildfires in the\n  US", "comments": "Source code: https://github.com/yangland/rtfps", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.HC cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Climate change has largely impacted our daily lives. As one of its\nconsequences, we are experiencing more wildfires. In the year 2020, wildfires\nburned a record number of 8,888,297 acres in the US. To awaken people's\nattention to climate change, and to visualize the current risk of wildfires, We\ndeveloped RtFPS, \"Real-Time Fire Prediction System\". It provides a real-time\nprediction visualization of wildfire risk at specific locations base on a\nMachine Learning model. It also provides interactive map features that show the\nhistorical wildfire events with environmental info.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 08:07:01 GMT"}, {"version": "v2", "created": "Tue, 22 Jun 2021 01:58:27 GMT"}], "update_date": "2021-06-23", "authors_parsed": [["Li", "Yang", ""], ["Mulyono", "Hermawan", ""], ["Chen", "Ying", ""], ["Lu", "Zhiyin", ""], ["Chan", "Desmond", ""]]}, {"id": "2105.10922", "submitter": "Shumin Deng", "authors": "Shumin Deng, Ningyu Zhang, Luoqiu Li, Hui Chen, Huaixiao Tou, Mosha\n  Chen, Fei Huang, Huajun Chen", "title": "OntoED: Low-resource Event Detection with Ontology Embedding", "comments": "Accepted to appear at the ACL 2021 main conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Event Detection (ED) aims to identify event trigger words from a given text\nand classify it into an event type. Most of current methods to ED rely heavily\non training instances, and almost ignore the correlation of event types. Hence,\nthey tend to suffer from data scarcity and fail to handle new unseen event\ntypes. To address these problems, we formulate ED as a process of event\nontology population: linking event instances to pre-defined event types in\nevent ontology, and propose a novel ED framework entitled OntoED with ontology\nembedding. We enrich event ontology with linkages among event types, and\nfurther induce more event-event correlations. Based on the event ontology,\nOntoED can leverage and propagate correlation knowledge, particularly from\ndata-rich to data-poor event types. Furthermore, OntoED can be applied to new\nunseen event types, by establishing linkages to existing ones. Experiments\nindicate that OntoED is more predominant and robust than previous approaches to\nED, especially in data-scarce scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 23 May 2021 12:00:22 GMT"}, {"version": "v2", "created": "Wed, 26 May 2021 03:57:12 GMT"}, {"version": "v3", "created": "Thu, 27 May 2021 15:11:37 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Deng", "Shumin", ""], ["Zhang", "Ningyu", ""], ["Li", "Luoqiu", ""], ["Chen", "Hui", ""], ["Tou", "Huaixiao", ""], ["Chen", "Mosha", ""], ["Huang", "Fei", ""], ["Chen", "Huajun", ""]]}, {"id": "2105.11108", "submitter": "Lixin Zou", "authors": "Lixin Zou, Shengqiang Zhang, Hengyi Cai, Dehong Ma, Suqi Cheng,\n  Daiting Shi, Zhifan Zhu, Weiyue Su, Shuaiqiang Wang, Zhicong Cheng, Dawei Yin", "title": "Pre-trained Language Model based Ranking in Baidu Search", "comments": "9-pages, 3 figures, 7 tables, SIGKDD 2021 accepted paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the heart of a search engine, the ranking system plays a crucial role in\nsatisfying users' information demands. More recently, neural rankers fine-tuned\nfrom pre-trained language models (PLMs) establish state-of-the-art ranking\neffectiveness. However, it is nontrivial to directly apply these PLM-based\nrankers to the large-scale web search system due to the following challenging\nissues:(1) the prohibitively expensive computations of massive neural PLMs,\nespecially for long texts in the web-document, prohibit their deployments in an\nonline ranking system that demands extremely low latency;(2) the discrepancy\nbetween existing ranking-agnostic pre-training objectives and the ad-hoc\nretrieval scenarios that demand comprehensive relevance modeling is another\nmain barrier for improving the online ranking system;(3) a real-world search\nengine typically involves a committee of ranking components, and thus the\ncompatibility of the individually fine-tuned ranking model is critical for a\ncooperative ranking system. In this work, we contribute a series of\nsuccessfully applied techniques in tackling these exposed issues when deploying\nthe state-of-the-art Chinese pre-trained language model, i.e., ERNIE, in the\nonline search engine system. We first articulate a novel practice to\ncost-efficiently summarize the web document and contextualize the resultant\nsummary content with the query using a cheap yet powerful Pyramid-ERNIE\narchitecture. Then we endow an innovative paradigm to finely exploit the\nlarge-scale noisy and biased post-click behavioral data for relevance-oriented\npre-training. We also propose a human-anchored fine-tuning strategy tailored\nfor the online ranking system, aiming to stabilize the ranking signals across\nvarious online components. Extensive offline and online experimental results\nshow that the proposed techniques significantly boost the search engine's\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 06:12:06 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 16:03:00 GMT"}, {"version": "v3", "created": "Fri, 25 Jun 2021 09:11:00 GMT"}], "update_date": "2021-06-28", "authors_parsed": [["Zou", "Lixin", ""], ["Zhang", "Shengqiang", ""], ["Cai", "Hengyi", ""], ["Ma", "Dehong", ""], ["Cheng", "Suqi", ""], ["Shi", "Daiting", ""], ["Zhu", "Zhifan", ""], ["Su", "Weiyue", ""], ["Wang", "Shuaiqiang", ""], ["Cheng", "Zhicong", ""], ["Yin", "Dawei", ""]]}, {"id": "2105.11347", "submitter": "Baban Gain", "authors": "Baban Gain, Dibyanayan Bandyopadhyay, Arkadipta De, Tanik Saikh, Asif\n  Ekbal", "title": "IITP at AILA 2019: System Report for Artificial Intelligence for Legal\n  Assistance Shared Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this article, we present a description of our systems as a part of our\nparticipation in the shared task namely Artificial Intelligence for Legal\nAssistance (AILA 2019). This is an integral event of Forum for Information\nRetrieval Evaluation-2019. The outcomes of this track would be helpful for the\nautomation of the working process of the Indian Judiciary System. The manual\nworking procedures and documentation at any level (from lower to higher court)\nof the judiciary system are very complex in nature. The systems produced as a\npart of this track would assist the law practitioners. It would be helpful for\ncommon men too. This kind of track also opens the path of research of Natural\nLanguage Processing (NLP) in the judicial domain. This track defined two\nproblems such as Task 1: Identifying relevant prior cases for a given situation\nand Task 2: Identifying the most relevant statutes for a given situation. We\ntackled both of them. Our proposed approaches are based on BM25 and Doc2Vec. As\nper the results declared by the task organizers, we are in 3rd and a modest\nposition in Task 1 and Task 2 respectively.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 15:31:24 GMT"}, {"version": "v2", "created": "Sat, 26 Jun 2021 12:07:31 GMT"}], "update_date": "2021-06-29", "authors_parsed": [["Gain", "Baban", ""], ["Bandyopadhyay", "Dibyanayan", ""], ["De", "Arkadipta", ""], ["Saikh", "Tanik", ""], ["Ekbal", "Asif", ""]]}, {"id": "2105.11410", "submitter": "Abhishek Santra", "authors": "Abhishek Santra, Kanthi Komar, Sanjukta Bhowmick and Sharma\n  Chakravarthy", "title": "From Base Data To Knowledge Discovery -- A Life Cycle Approach -- Using\n  Multilayer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DB cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Any large complex data analysis to infer or discover meaningful\ninformation/knowledge involves the following steps (in addition to data\ncollection, cleaning, preparing the data for analysis such as attribute\nelimination): i) Modeling the data -- an approach for modeling and deriving a\ndata representation for analysis using that approach, ii) translating analysis\nobjectives into computations on the model generated; this can be as simple as a\nsingle computation (e.g., community detection) or may involve a sequence of\noperations (e.g., pair-wise community detection over multiple networks) using\nexpressions based on the model, iii) computation of the expressions generated\n-- efficiency and scalability come into picture here, and iv) drill-down of\nresults to interpret or understand them clearly. Beyond this, it is also\nmeaningful to visualize results for easier understanding. Covid-19\nvisualization dashboard presented in this paper is an example of this.\n  This paper covers all of the above steps of data analysis life cycle using a\ndata representation that is gaining importance for multi-entity, multi-feature\ndata sets - Multilayer Networks. We use several data sets to establish the\neffectiveness of modeling using MLNs and analyze them using the proposed\ndecoupling approach. For coverage, we use different types of MLNs for modeling,\nand community and centrality computations for analysis. The data sets used - US\ncommercial airlines, IMDb, DBLP, and Covid-19 data set. Our experimental\nanalyses using the identified steps validate modeling, breadth of objectives\nthat can be computed, and overall versatility of the life cycle approach.\nCorrectness of results is verified, where possible, using independently\navailable ground truth. We demonstrate drill-down that is afforded by this\napproach (due to structure and semantics preservation) for a better\nunderstanding and visualization of results.\n", "versions": [{"version": "v1", "created": "Mon, 24 May 2021 17:00:30 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Santra", "Abhishek", ""], ["Komar", "Kanthi", ""], ["Bhowmick", "Sanjukta", ""], ["Chakravarthy", "Sharma", ""]]}, {"id": "2105.11601", "submitter": "Lei Li", "authors": "Lei Li, Yongfeng Zhang, Li Chen", "title": "Personalized Transformer for Explainable Recommendation", "comments": "Published as a conference paper at ACL-IJCNLP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Personalization of natural language generation plays a vital role in a large\nspectrum of tasks, such as explainable recommendation, review summarization and\ndialog systems. In these tasks, user and item IDs are important identifiers for\npersonalization. Transformer, which is demonstrated with strong language\nmodeling capability, however, is not personalized and fails to make use of the\nuser and item IDs since the ID tokens are not even in the same semantic space\nas the words. To address this problem, we present a PErsonalized Transformer\nfor Explainable Recommendation (PETER), on which we design a simple and\neffective learning objective that utilizes the IDs to predict the words in the\ntarget explanation, so as to endow the IDs with linguistic meanings and to\nachieve personalized Transformer. Besides generating explanations, PETER can\nalso make recommendations, which makes it a unified model for the whole\nrecommendation-explanation pipeline. Extensive experiments show that our small\nunpretrained model outperforms fine-tuned BERT on the generation task, in terms\nof both effectiveness and efficiency, which highlights the importance and the\nnice utility of our design.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 01:42:47 GMT"}, {"version": "v2", "created": "Sat, 5 Jun 2021 01:19:31 GMT"}], "update_date": "2021-06-09", "authors_parsed": [["Li", "Lei", ""], ["Zhang", "Yongfeng", ""], ["Chen", "Li", ""]]}, {"id": "2105.11678", "submitter": "Mostafa Khalaji", "authors": "Mostafa Khalaji, Chitra Dadkhah, Joobin Gharibshah", "title": "Hybrid Movie Recommender System based on Resource Allocation", "comments": "8 pages, 4 figures", "journal-ref": "The CSI Journal on Computer Science and Engineering, vol. 17, no.\n  2, 2020", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recommender Systems are inevitable to personalize user's experiences on the\nInternet. They are using different approaches to recommend the Top-K items to\nusers according to their preferences. Nowadays recommender systems have become\none of the most important parts of largescale data mining techniques. In this\npaper, we propose a Hybrid Movie Recommender System (HMRS) based on Resource\nAllocation to improve the accuracy of recommendation and solve the cold start\nproblem for a new movie. HMRS-RA uses a self-organizing mapping neural network\nto clustering the users into N clusters. The users' preferences are different\naccording to their age and gender, therefore HMRS-RA is a combination of a\nContent-Based Method for solving the cold start problem for a new movie and a\nCollaborative Filtering model besides the demographic information of users. The\nexperimental results based on the MovieLens dataset show that the HMRS-RA\nincreases the accuracy of recommendation compared to the state-of-art and\nsimilar works.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 05:31:04 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Khalaji", "Mostafa", ""], ["Dadkhah", "Chitra", ""], ["Gharibshah", "Joobin", ""]]}, {"id": "2105.11734", "submitter": "Robin Brochier", "authors": "Robin Brochier, Fr\\'ed\\'eric B\\'echet", "title": "Predicting Links on Wikipedia with Anchor Text Information", "comments": "ACM SIGIR Conference on Research and Development in Information\n  Retrieval, Jul 2021, New York, France", "journal-ref": null, "doi": "10.1145/3404835.3462994", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wikipedia, the largest open-collaborative online encyclopedia, is a corpus of\ndocuments bound together by internal hyperlinks. These links form the building\nblocks of a large network whose structure contains important information on the\nconcepts covered in this encyclopedia. The presence of a link between two\narticles, materialised by an anchor text in the source page pointing to the\ntarget page, can increase readers' understanding of a topic. However, the\nprocess of linking follows specific editorial rules to avoid both under-linking\nand over-linking. In this paper, we study the transductive and the inductive\ntasks of link prediction on several subsets of the English Wikipedia and\nidentify some key challenges behind automatic linking based on anchor text\ninformation. We propose an appropriate evaluation sampling methodology and\ncompare several algorithms. Moreover, we propose baseline models that provide a\ngood estimation of the overall difficulty of the tasks.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 07:57:57 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Brochier", "Robin", ""], ["B\u00e9chet", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "2105.11826", "submitter": "Yunshan Ma", "authors": "Yunshan Ma, Yujuan Ding, Xun Yang, Lizi Liao, Wai Keung Wong, Tat-Seng\n  Chua, Jinyoung Moon, Hong-Han Shuai", "title": "Reproducibility Companion Paper: Knowledge Enhanced Neural Fashion Trend\n  Forecasting", "comments": null, "journal-ref": "ICMR 2021", "doi": "10.1145/3460426.3463598", "report-no": null, "categories": "cs.LG cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This companion paper supports the replication of the fashion trend\nforecasting experiments with the KERN (Knowledge Enhanced Recurrent Network)\nmethod that we presented in the ICMR 2020. We provide an artifact that allows\nthe replication of the experiments using a Python implementation. The artifact\nis easy to deploy with simple installation, training and evaluation. We\nreproduce the experiments conducted in the original paper and obtain similar\nperformance as previously reported. The replication results of the experiments\nsupport the main claims in the original paper.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 10:53:11 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Ma", "Yunshan", ""], ["Ding", "Yujuan", ""], ["Yang", "Xun", ""], ["Liao", "Lizi", ""], ["Wong", "Wai Keung", ""], ["Chua", "Tat-Seng", ""], ["Moon", "Jinyoung", ""], ["Shuai", "Hong-Han", ""]]}, {"id": "2105.11866", "submitter": "Zekun Li", "authors": "Zekun Li, Shu Wu, Zeyu Cui, Xiaoyu Zhang", "title": "GraphFM: Graph Factorization Machines for Feature Interaction Modeling", "comments": "submitted to tkde", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Factorization machine (FM) is a prevalent approach to modeling pairwise\n(second-order) feature interactions when dealing with high-dimensional sparse\ndata. However, on the one hand, FM fails to capture higher-order feature\ninteractions suffering from combinatorial expansion, on the other hand, taking\ninto account interaction between every pair of features may introduce noise and\ndegrade prediction accuracy. To solve the problems, we propose a novel approach\nGraph Factorization Machine (GraphFM) by naturally representing features in the\ngraph structure. In particular, a novel mechanism is designed to select the\nbeneficial feature interactions and formulate them as edges between features.\nThen our proposed model which integrates the interaction function of FM into\nthe feature aggregation strategy of Graph Neural Network (GNN), can model\narbitrary-order feature interactions on the graph-structured features by\nstacking layers. Experimental results on several real-world datasets has\ndemonstrated the rationality and effectiveness of our proposed approach.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 12:10:54 GMT"}, {"version": "v2", "created": "Wed, 30 Jun 2021 09:33:33 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Li", "Zekun", ""], ["Wu", "Shu", ""], ["Cui", "Zeyu", ""], ["Zhang", "Xiaoyu", ""]]}, {"id": "2105.11876", "submitter": "Xiao Luo", "authors": "Xiao Luo, Daqing Wu, Chong Chen, Jinwen Ma, Minghua Deng, Chen Shen,\n  Jianqiang Huang, Xian-Sheng Hua", "title": "Criterion-based Heterogeneous Collaborative Filtering for Multi-behavior\n  Implicit Recommendation", "comments": "25 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the increasing scale and diversification of interaction behaviors in\nE-commerce, more and more researchers pay attention to multi-behavior\nrecommender systems that utilize interaction data of other auxiliary behaviors\nsuch as view and cart. To address these challenges in heterogeneous scenarios,\nnon-sampling methods have shown superiority over negative sampling methods.\nHowever, two observations are usually ignored in existing state-of-the-art\nnon-sampling methods based on binary regression: (1) users have different\npreference strengths for different items, so they cannot be measured simply by\nbinary implicit data; (2) the dependency across multiple behaviors varies for\ndifferent users and items. To tackle the above issue, we propose a novel\nnon-sampling learning framework named \\underline{C}riterion-guided\n\\underline{H}eterogeneous \\underline{C}ollaborative \\underline{F}iltering\n(CHCF). CHCF introduces both upper and lower bounds to indicate selection\ncriteria, which will guide user preference learning. Besides, CHCF integrates\ncriterion learning and user preference learning into a unified framework, which\ncan be trained jointly for the interaction prediction on target behavior. We\nfurther theoretically demonstrate that the optimization of Collaborative Metric\nLearning can be approximately achieved by CHCF learning framework in a\nnon-sampling form effectively. Extensive experiments on two real-world datasets\nshow that CHCF outperforms the state-of-the-art methods in heterogeneous\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 12:23:24 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 05:25:48 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Luo", "Xiao", ""], ["Wu", "Daqing", ""], ["Chen", "Chong", ""], ["Ma", "Jinwen", ""], ["Deng", "Minghua", ""], ["Shen", "Chen", ""], ["Huang", "Jianqiang", ""], ["Hua", "Xian-Sheng", ""]]}, {"id": "2105.12190", "submitter": "Lukasz Golab", "authors": "Mohammad S. Parsa, Lukasz Golab, Srinivasan Keshav", "title": "Climate Action During COVID-19 Recovery and Beyond: A Twitter Text\n  Mining Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The Coronavirus pandemic created a global crisis that prompted immediate\nlarge-scale action, including economic shutdowns and mobility restrictions.\nThese actions have had devastating effects on the economy, but some positive\neffects on the environment. As the world recovers from the pandemic, we ask the\nfollowing question: What is the public attitude towards climate action during\nCOVID-19 recovery and beyond? We answer this question by analyzing discussions\non the Twitter social media platform. We find that most discussions support\nclimate action and point out lessons learned during pandemic response that can\nshape future climate policy, although skeptics continue to have a presence.\nAdditionally, concerns arise in the context of climate action during the\npandemic, such as mitigating the risk of COVID-19 transmission on public\ntransit.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 19:57:41 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Parsa", "Mohammad S.", ""], ["Golab", "Lukasz", ""], ["Keshav", "Srinivasan", ""]]}, {"id": "2105.12261", "submitter": "Simon \\v{S}uster", "authors": "Simon \\v{S}uster, Karin Verspoor, Timothy Baldwin, Jey Han Lau,\n  Antonio Jimeno Yepes, David Martinez, Yulia Otmakhova", "title": "Impact of detecting clinical trial elements in exploration of COVID-19\n  literature", "comments": "Accepted at HealthNLP'21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The COVID-19 pandemic has driven ever-greater demand for tools which enable\nefficient exploration of biomedical literature. Although semi-structured\ninformation resulting from concept recognition and detection of the defining\nelements of clinical trials (e.g. PICO criteria) has been commonly used to\nsupport literature search, the contributions of this abstraction remain poorly\nunderstood, especially in relation to text-based retrieval. In this study, we\ncompare the results retrieved by a standard search engine with those filtered\nusing clinically-relevant concepts and their relations. With analysis based on\nthe annotations from the TREC-COVID shared task, we obtain quantitative as well\nas qualitative insights into characteristics of relational and concept-based\nliterature exploration. Most importantly, we find that the relational concept\nselection filters the original retrieved collection in a way that decreases the\nproportion of unjudged documents and increases the precision, which means that\nthe user is likely to be exposed to a larger number of relevant documents.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 23:41:24 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["\u0160uster", "Simon", ""], ["Verspoor", "Karin", ""], ["Baldwin", "Timothy", ""], ["Lau", "Jey Han", ""], ["Yepes", "Antonio Jimeno", ""], ["Martinez", "David", ""], ["Otmakhova", "Yulia", ""]]}, {"id": "2105.12353", "submitter": "Ryoma Sato", "authors": "Ryoma Sato", "title": "Private Recommender Systems: How Can Users Build Their Own Fair\n  Recommender Systems without Log Data?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fairness is an important property in data-mining applications, including\nrecommender systems. In this work, we investigate a case where users of a\nrecommender system need (or want) to be fair to a protected group of items. For\nexample, in a job market, the user is the recruiter, an item is the job seeker,\nand the protected attribute is gender or race. Even if recruiters want to use a\nfair talent recommender system, the platform may not provide a fair recommender\nsystem, or recruiters may not be able to ascertain whether the recommender\nsystem's algorithm is fair. In this case, recruiters cannot utilize the\nrecommender system, or they may become unfair to job seekers. In this work, we\npropose methods to enable the users to build their own fair recommender\nsystems. Our methods can generate fair recommendations even when the platform\ndoes not (or cannot) provide fair recommender systems. The key challenge is\nthat a user does not have access to the log data of other users or the latent\nrepresentations of items. This restriction prohibits us from adopting existing\nmethods, which are designed for platforms. The main idea is that a user has\naccess to unfair recommendations provided by the platform. Our methods leverage\nthe outputs of an unfair recommender system to construct a new fair recommender\nsystem. We empirically validate that our proposed method improves fairness\nsubstantially without harming much performance of the original unfair system.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 06:31:02 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Sato", "Ryoma", ""]]}, {"id": "2105.12371", "submitter": "Yijiang Lian", "authors": "Yijiang Lian, Shuang Li, Chaobing Feng, YanFeng Zhu", "title": "Quotient Space-Based Keyword Retrieval in Sponsored Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Synonymous keyword retrieval has become an important problem for sponsored\nsearch ever since major search engines relax the exact match product's matching\nrequirement to a synonymous level. Since the synonymous relations between\nqueries and keywords are quite scarce, the traditional information retrieval\nframework is inefficient in this scenario. In this paper, we propose a novel\nquotient space-based retrieval framework to address this problem. Considering\nthe synonymy among keywords as a mathematical equivalence relation, we can\ncompress the synonymous keywords into one representative, and the corresponding\nquotient space would greatly reduce the size of the keyword repository. Then an\nembedding-based retrieval is directly conducted between queries and the keyword\nrepresentatives. To mitigate the semantic gap of the quotient space-based\nretrieval, a single semantic siamese model is utilized to detect both the\nkeyword--keyword and query-keyword synonymous relations. The experiments show\nthat with our quotient space-based retrieval method, the synonymous keyword\nretrieving performance can be greatly improved in terms of memory cost and\nrecall efficiency. This method has been successfully implemented in Baidu's\nonline sponsored search system and has yielded a significant improvement in\nrevenue.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 07:27:54 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Lian", "Yijiang", ""], ["Li", "Shuang", ""], ["Feng", "Chaobing", ""], ["Zhu", "YanFeng", ""]]}, {"id": "2105.12676", "submitter": "Zhaoxia Deng", "authors": "Zhaoxia (Summer) Deng, Jongsoo Park, Ping Tak Peter Tang, Haixin Liu,\n  Jie (Amy) Yang, Hector Yuen, Jianyu Huang, Daya Khudia, Xiaohan Wei, Ellie\n  Wen, Dhruv Choudhary, Raghuraman Krishnamoorthi, Carole-Jean Wu, Satish\n  Nadathur, Changkyu Kim, Maxim Naumov, Sam Naghshineh, Mikhail Smelyanskiy", "title": "Low-Precision Hardware Architectures Meet Recommendation Model Inference\n  at Scale", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.IR cs.NA cs.PF math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tremendous success of machine learning (ML) and the unabated growth in ML\nmodel complexity motivated many ML-specific designs in both CPU and accelerator\narchitectures to speed up the model inference. While these architectures are\ndiverse, highly optimized low-precision arithmetic is a component shared by\nmost. Impressive compute throughputs are indeed often exhibited by these\narchitectures on benchmark ML models. Nevertheless, production models such as\nrecommendation systems important to Facebook's personalization services are\ndemanding and complex: These systems must serve billions of users per month\nresponsively with low latency while maintaining high prediction accuracy,\nnotwithstanding computations with many tens of billions parameters per\ninference. Do these low-precision architectures work well with our production\nrecommendation systems? They do. But not without significant effort. We share\nin this paper our search strategies to adapt reference recommendation models to\nlow-precision hardware, our optimization of low-precision compute kernels, and\nthe design and development of tool chain so as to maintain our models' accuracy\nthroughout their lifespan during which topic trends and users' interests\ninevitably evolve. Practicing these low-precision technologies helped us save\ndatacenter capacities while deploying models with up to 5X complexity that\nwould otherwise not be deployed on traditional general-purpose CPUs. We believe\nthese lessons from the trenches promote better co-design between hardware\narchitecture and software engineering and advance the state of the art of ML in\nindustry.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 16:42:33 GMT"}], "update_date": "2021-05-27", "authors_parsed": [["Zhaoxia", "", "", "Summer"], ["Deng", "", "", "Amy"], ["Park", "Jongsoo", "", "Amy"], ["Tang", "Ping Tak Peter", "", "Amy"], ["Liu", "Haixin", "", "Amy"], ["Jie", "", "", "Amy"], ["Yang", "", ""], ["Yuen", "Hector", ""], ["Huang", "Jianyu", ""], ["Khudia", "Daya", ""], ["Wei", "Xiaohan", ""], ["Wen", "Ellie", ""], ["Choudhary", "Dhruv", ""], ["Krishnamoorthi", "Raghuraman", ""], ["Wu", "Carole-Jean", ""], ["Nadathur", "Satish", ""], ["Kim", "Changkyu", ""], ["Naumov", "Maxim", ""], ["Naghshineh", "Sam", ""], ["Smelyanskiy", "Mikhail", ""]]}, {"id": "2105.12788", "submitter": "Marcelo Mendoza Mr.", "authors": "Alfredo Silva and Marcelo Mendoza", "title": "A data-driven strategy to combine word embeddings in information\n  retrieval", "comments": null, "journal-ref": "8th International Conference on Artificial Intelligence and\n  Applications (AIAP 2021), January 23 ~ 24, 2021, Zurich, Switzerland", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word embeddings are vital descriptors of words in unigram representations of\ndocuments for many tasks in natural language processing and information\nretrieval. The representation of queries has been one of the most critical\nchallenges in this area because it consists of a few terms and has little\ndescriptive capacity. Strategies such as average word embeddings can enrich the\nqueries' descriptive capacity since they favor the identification of related\nterms from the continuous vector representations that characterize these\napproaches. We propose a data-driven strategy to combine word embeddings. We\nuse Idf combinations of embeddings to represent queries, showing that these\nrepresentations outperform the average word embeddings recently proposed in the\nliterature. Experimental results on benchmark data show that our proposal\nperforms well, suggesting that data-driven combinations of word embeddings are\na promising line of research in ad-hoc information retrieval.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 18:41:20 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Silva", "Alfredo", ""], ["Mendoza", "Marcelo", ""]]}, {"id": "2105.12876", "submitter": "Pratik K. Biswas", "authors": "Pratik K. Biswas, Songlin Liu", "title": "A Hybrid Recommender System for Recommending Smartphones to Prospective\n  Customers", "comments": "Journal Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender Systems are a subclass of machine learning systems that employ\nsophisticated information filtering strategies to reduce the search time and\nsuggest the most relevant items to any particular user. Hybrid recommender\nsystems combine multiple recommendation strategies in different ways to benefit\nfrom their complementary advantages. Some hybrid recommender systems have\ncombined collaborative filtering and content-based approaches to build systems\nthat are more robust. In this paper, we propose a hybrid recommender system,\nwhich combines Alternative Least Squares (ALS) based collaborative filtering\nwith deep learning to enhance recommendation performance as well as overcome\nthe limitations associated with the collaborative filtering approach,\nespecially concerning its cold start problem. In essence, we use the outputs\nfrom ALS (collaborative filtering) to influence the recommendations from a Deep\nNeural Network (DNN), which combines characteristic, contextual, structural and\nsequential information, in a big data processing framework. We have conducted\nseveral experiments in testing the efficacy of the proposed hybrid architecture\nin recommending smartphones to prospective customers and compared its\nperformance with other open-source recommenders. The results have shown that\nthe proposed system has outperformed several existing hybrid recommender\nsystems.\n", "versions": [{"version": "v1", "created": "Wed, 26 May 2021 23:10:51 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Biswas", "Pratik K.", ""], ["Liu", "Songlin", ""]]}, {"id": "2105.12932", "submitter": "Xiaofei Ma", "authors": "Xiaofei Ma, Cicero Nogueira dos Santos and Andrew O. Arnold", "title": "Contrastive Fine-tuning Improves Robustness for Neural Rankers", "comments": null, "journal-ref": "Findings of ACL 2021", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The performance of state-of-the-art neural rankers can deteriorate\nsubstantially when exposed to noisy inputs or applied to a new domain. In this\npaper, we present a novel method for fine-tuning neural rankers that can\nsignificantly improve their robustness to out-of-domain data and query\nperturbations. Specifically, a contrastive loss that compares data points in\nthe representation space is combined with the standard ranking loss during\nfine-tuning. We use relevance labels to denote similar/dissimilar pairs, which\nallows the model to learn the underlying matching semantics across different\nquery-document pairs and leads to improved robustness. In experiments with four\npassage ranking datasets, the proposed contrastive fine-tuning method obtains\nimprovements on robustness to query reformulations, noise perturbations, and\nzero-shot transfer for both BERT and BART based rankers. Additionally, our\nexperiments show that contrastive fine-tuning outperforms data augmentation for\nrobustifying neural rankers.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 04:00:22 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ma", "Xiaofei", ""], ["Santos", "Cicero Nogueira dos", ""], ["Arnold", "Andrew O.", ""]]}, {"id": "2105.12937", "submitter": "Dong Li", "authors": "Ruoming Jin and Dong Li and Jing Gao and Zhi Liu and Li Chen and Yang\n  Zhou", "title": "Towards a Better Understanding of Linear Models for Recommendation", "comments": null, "journal-ref": null, "doi": "10.1145/3447548.3467428", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently, linear regression models, such as EASE and SLIM, have shown to\noften produce rather competitive results against more sophisticated deep\nlearning models. On the other side, the (weighted) matrix factorization\napproaches have been popular choices for recommendation in the past and widely\nadopted in the industry. In this work, we aim to theoretically understand the\nrelationship between these two approaches, which are the cornerstones of\nmodel-based recommendations. Through the derivation and analysis of the\nclosed-form solutions for two basic regression and matrix factorization\napproaches, we found these two approaches are indeed inherently related but\nalso diverge in how they \"scale-down\" the singular values of the original\nuser-item interaction matrix. This analysis also helps resolve the questions\nrelated to the regularization parameter range and model complexities. We\nfurther introduce a new learning algorithm in searching (hyper)parameters for\nthe closed-form solution and utilize it to discover the nearby models of the\nexisting solutions. The experimental results demonstrate that the basic models\nand their closed-form solutions are indeed quite competitive against the\nstate-of-the-art models, thus, confirming the validity of studying the basic\nmodels. The effectiveness of exploring the nearby models are also\nexperimentally validated.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 04:17:04 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 03:38:09 GMT"}], "update_date": "2021-06-17", "authors_parsed": [["Jin", "Ruoming", ""], ["Li", "Dong", ""], ["Gao", "Jing", ""], ["Liu", "Zhi", ""], ["Chen", "Li", ""], ["Zhou", "Yang", ""]]}, {"id": "2105.12989", "submitter": "Henderik Alex Proper", "authors": "Rik D.T. Janssen and Henderik A. Proper", "title": "A functionality taxonomy for document search engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper a functionality taxonomy for document search engines is\nproposed. It can be used to assess the features of a search engine, to position\nsearch engines relative to each other, or to select which search engine 'fits'\na certain situation. One is able to identify areas for improvement. During\ndevelopment, we were guided by the viewpoint of the user. We use the word\n`search engine' in the broadest sense possible, including library and web based\n(meta) search engines. The taxonomy distinguishes seven functionality areas: an\nindexing service, user profiling, query composition, query execution, result\npresentation, result refinement, and history keeping. Each of these relates and\nprovides services to other functionality areas. It can be extended whenever\nnecessary. To illustrate the validity of our taxonomy, it has been used for\ncomparing various document search engines existing today (ACM Digital Library,\nPiCarta, Copernic, AltaVista, Google, and GuideBeam). It appears that the\nfunctionality aspects covered by our taxonomy can be used for describing these\nsearch engines.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 08:15:49 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Janssen", "Rik D. T.", ""], ["Proper", "Henderik A.", ""]]}, {"id": "2105.13003", "submitter": "Chuhan Wu", "authors": "Chuhan Wu, Fangzhao Wu, Yongfeng Huang", "title": "Rethinking InfoNCE: How Many Negative Samples Do You Need?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  InfoNCE loss is a widely used loss function for contrastive model training.\nIt aims to estimate the mutual information between a pair of variables by\ndiscriminating between each positive pair and its associated $K$ negative\npairs. It is proved that when the sample labels are clean, the lower bound of\nmutual information estimation is tighter when more negative samples are\nincorporated, which usually yields better model performance. However, in many\nreal-world tasks the labels often contain noise, and incorporating too many\nnoisy negative samples for model training may be suboptimal. In this paper, we\nstudy how many negative samples are optimal for InfoNCE in different scenarios\nvia a semi-quantitative theoretical framework. More specifically, we first\npropose a probabilistic model to analyze the influence of the negative sampling\nratio $K$ on training sample informativeness. Then, we design a training\neffectiveness function to measure the overall influence of training samples on\nmodel learning based on their informativeness. We estimate the optimal negative\nsampling ratio using the $K$ value that maximizes the training effectiveness\nfunction. Based on our framework, we further propose an adaptive negative\nsampling method that can dynamically adjust the negative sampling ratio to\nimprove InfoNCE based model training. Extensive experiments on different\nreal-world datasets show our framework can accurately predict the optimal\nnegative sampling ratio in different tasks, and our proposed adaptive negative\nsampling method can achieve better performance than the commonly used fixed\nnegative sampling ratio strategy.\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 08:38:29 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Wu", "Chuhan", ""], ["Wu", "Fangzhao", ""], ["Huang", "Yongfeng", ""]]}, {"id": "2105.13066", "submitter": "Zijing Ou", "authors": "Zijing Ou, Qinliang Su, Jianxing Yu, Bang Liu, Jingwen Wang, Ruihui\n  Zhao, Changyou Chen and Yefeng Zheng", "title": "Integrating Semantics and Neighborhood Information with Graph-Driven\n  Generative Models for Document Retrieval", "comments": null, "journal-ref": "ACL2021", "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the need of fast retrieval speed and small memory footprint, document\nhashing has been playing a crucial role in large-scale information retrieval.\nTo generate high-quality hashing code, both semantics and neighborhood\ninformation are crucial. However, most existing methods leverage only one of\nthem or simply combine them via some intuitive criteria, lacking a theoretical\nprinciple to guide the integration process. In this paper, we encode the\nneighborhood information with a graph-induced Gaussian distribution, and\npropose to integrate the two types of information with a graph-driven\ngenerative model. To deal with the complicated correlations among documents, we\nfurther propose a tree-structured approximation method for learning. Under the\napproximation, we prove that the training objective can be decomposed into\nterms involving only singleton or pairwise documents, enabling the model to be\ntrained as efficiently as uncorrelated ones. Extensive experimental results on\nthree benchmark datasets show that our method achieves superior performance\nover state-of-the-art methods, demonstrating the effectiveness of the proposed\nmodel for simultaneously preserving semantic and neighborhood information.\\\n", "versions": [{"version": "v1", "created": "Thu, 27 May 2021 11:29:03 GMT"}], "update_date": "2021-05-28", "authors_parsed": [["Ou", "Zijing", ""], ["Su", "Qinliang", ""], ["Yu", "Jianxing", ""], ["Liu", "Bang", ""], ["Wang", "Jingwen", ""], ["Zhao", "Ruihui", ""], ["Chen", "Changyou", ""], ["Zheng", "Yefeng", ""]]}, {"id": "2105.13623", "submitter": "Siyuan Guo", "authors": "Siyuan Guo, Lixin Zou, Yiding Liu, Wenwen Ye, Suqi Cheng, Shuaiqiang\n  Wang, Hechang Chen, Dawei Yin, Yi Chang", "title": "Enhanced Doubly Robust Learning for Debiasing Post-click Conversion Rate\n  Estimation", "comments": "10 pages, 3 figures, accepted by SIGIR 2021", "journal-ref": null, "doi": "10.1145/3404835.3462917", "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Post-click conversion, as a strong signal indicating the user preference, is\nsalutary for building recommender systems. However, accurately estimating the\npost-click conversion rate (CVR) is challenging due to the selection bias,\ni.e., the observed clicked events usually happen on users' preferred items.\nCurrently, most existing methods utilize counterfactual learning to debias\nrecommender systems. Among them, the doubly robust (DR) estimator has achieved\ncompetitive performance by combining the error imputation based (EIB) estimator\nand the inverse propensity score (IPS) estimator in a doubly robust way.\nHowever, inaccurate error imputation may result in its higher variance than the\nIPS estimator. Worse still, existing methods typically use simple\nmodel-agnostic methods to estimate the imputation error, which are not\nsufficient to approximate the dynamically changing model-correlated target\n(i.e., the gradient direction of the prediction model). To solve these\nproblems, we first derive the bias and variance of the DR estimator. Based on\nit, a more robust doubly robust (MRDR) estimator has been proposed to further\nreduce its variance while retaining its double robustness. Moreover, we propose\na novel double learning approach for the MRDR estimator, which can convert the\nerror imputation into the general CVR estimation. Besides, we empirically\nverify that the proposed learning scheme can further eliminate the high\nvariance problem of the imputation learning. To evaluate its effectiveness,\nextensive experiments are conducted on a semi-synthetic dataset and two\nreal-world datasets. The results demonstrate the superiority of the proposed\napproach over the state-of-the-art methods. The code is available at\nhttps://github.com/guosyjlu/MRDR-DL.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 06:59:49 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Guo", "Siyuan", ""], ["Zou", "Lixin", ""], ["Liu", "Yiding", ""], ["Ye", "Wenwen", ""], ["Cheng", "Suqi", ""], ["Wang", "Shuaiqiang", ""], ["Chen", "Hechang", ""], ["Yin", "Dawei", ""], ["Chang", "Yi", ""]]}, {"id": "2105.13868", "submitter": "Shuhuai Ren", "authors": "Shuhuai Ren, Junyang Lin, Guangxiang Zhao, Rui Men, An Yang, Jingren\n  Zhou, Xu Sun, Hongxia Yang", "title": "Learning Relation Alignment for Calibrated Cross-modal Retrieval", "comments": "Accepted by ACL-IJCNLP 2021 main conference (Long Paper)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the achievements of large-scale multimodal pre-training approaches,\ncross-modal retrieval, e.g., image-text retrieval, remains a challenging task.\nTo bridge the semantic gap between the two modalities, previous studies mainly\nfocus on word-region alignment at the object level, lacking the matching\nbetween the linguistic relation among the words and the visual relation among\nthe regions. The neglect of such relation consistency impairs the\ncontextualized representation of image-text pairs and hinders the model\nperformance and the interpretability. In this paper, we first propose a novel\nmetric, Intra-modal Self-attention Distance (ISD), to quantify the relation\nconsistency by measuring the semantic distance between linguistic and visual\nrelations. In response, we present Inter-modal Alignment on Intra-modal\nSelf-attentions (IAIS), a regularized training method to optimize the ISD and\ncalibrate intra-modal self-attentions from the two modalities mutually via\ninter-modal alignment. The IAIS regularizer boosts the performance of\nprevailing models on Flickr30k and MS COCO datasets by a considerable margin,\nwhich demonstrates the superiority of our approach.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 14:25:49 GMT"}, {"version": "v2", "created": "Tue, 1 Jun 2021 05:16:22 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Ren", "Shuhuai", ""], ["Lin", "Junyang", ""], ["Zhao", "Guangxiang", ""], ["Men", "Rui", ""], ["Yang", "An", ""], ["Zhou", "Jingren", ""], ["Sun", "Xu", ""], ["Yang", "Hongxia", ""]]}, {"id": "2105.13881", "submitter": "Xu Xie", "authors": "Xu Xie, Zhaoyang Liu, Shiwen Wu, Fei Sun, Cihang Liu, Jiawei Chen,\n  Jinyang Gao, Bin Cui, Bolin Ding", "title": "CausCF: Causal Collaborative Filtering for RecommendationEffect\n  Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  To improve user experience and profits of corporations, modern industrial\nrecommender systems usually aim to select the items that are most likely to be\ninteracted with (e.g., clicks and purchases). However, they overlook the fact\nthat users may purchase the items even without recommendations. To select these\neffective items, it is essential to estimate the causal effect of\nrecommendations. The real effective items are the ones which can contribute to\npurchase probability uplift. Nevertheless, it is difficult to obtain the real\ncausal effect since we can only recommend or not recommend an item to a user at\none time. Furthermore, previous works usually rely on the randomized controlled\ntrial~(RCT) experiment to evaluate their performance. However, it is usually\nnot practicable in the recommendation scenario due to its unavailable time\nconsuming. To tackle these problems, in this paper, we propose a causal\ncollaborative filtering~(CausCF) method inspired by the widely adopted\ncollaborative filtering~(CF) technique. It is based on the idea that similar\nusers not only have a similar taste on items, but also have similar treatment\neffect under recommendations. CausCF extends the classical matrix factorization\nto the tensor factorization with three dimensions -- user, item, and treatment.\nFurthermore, we also employs regression discontinuity design (RDD) to evaluate\nthe precision of the estimated causal effects from different models. With the\ntestable assumptions, RDD analysis can provide an unbiased causal conclusion\nwithout RCT experiments. Through dedicated experiments on both the public\ndatasets and the industrial application, we demonstrate the effectiveness of\nour proposed CausCF on the causal effect estimation and ranking performance\nimprovement.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 14:44:27 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Xie", "Xu", ""], ["Liu", "Zhaoyang", ""], ["Wu", "Shiwen", ""], ["Sun", "Fei", ""], ["Liu", "Cihang", ""], ["Chen", "Jiawei", ""], ["Gao", "Jinyang", ""], ["Cui", "Bin", ""], ["Ding", "Bolin", ""]]}, {"id": "2105.14060", "submitter": "Yongji Wu", "authors": "Yongji Wu, Lu Yin, Defu Lian, Mingyang Yin, Neil Zhenqiang Gong,\n  Jingren Zhou, Hongxia Yang", "title": "Rethinking Lifelong Sequential Recommendation with Incremental\n  Multi-Interest Attention", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential recommendation plays an increasingly important role in many\ne-commerce services such as display advertisement and online shopping. With the\nrapid development of these services in the last two decades, users have\naccumulated a massive amount of behavior data. Richer sequential behavior data\nhas been proven to be of great value for sequential recommendation. However,\ntraditional sequential models fail to handle users' lifelong sequences, as\ntheir linear computational and storage cost prohibits them from performing\nonline inference. Recently, lifelong sequential modeling methods that borrow\nthe idea of memory networks from NLP are proposed to address this issue.\nHowever, the RNN-based memory networks built upon intrinsically suffer from the\ninability to capture long-term dependencies and may instead be overwhelmed by\nthe noise on extremely long behavior sequences. In addition, as the user's\nbehavior sequence gets longer, more interests would be demonstrated in it. It\nis therefore crucial to model and capture the diverse interests of users. In\norder to tackle these issues, we propose a novel lifelong incremental\nmulti-interest self attention based sequential recommendation model, namely\nLimaRec. Our proposed method benefits from the carefully designed\nself-attention to identify relevant information from users' behavior sequences\nwith different interests. It is still able to incrementally update users'\nrepresentations for online inference, similarly to memory network based\napproaches. We extensively evaluate our method on four real-world datasets and\ndemonstrate its superior performances compared to the state-of-the-art\nbaselines.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 18:58:11 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wu", "Yongji", ""], ["Yin", "Lu", ""], ["Lian", "Defu", ""], ["Yin", "Mingyang", ""], ["Gong", "Neil Zhenqiang", ""], ["Zhou", "Jingren", ""], ["Yang", "Hongxia", ""]]}, {"id": "2105.14068", "submitter": "Yongji Wu", "authors": "Yongji Wu, Defu Lian, Neil Zhenqiang Gong, Lu Yin, Mingyang Yin,\n  Jingren Zhou, Hongxia Yang", "title": "Linear-Time Self Attention with Codeword Histogram for Efficient\n  Recommendation", "comments": "11 pages. Accepted by the Web Conference 2021 (WWW '21)", "journal-ref": null, "doi": "10.1145/3442381.3449946", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-attention has become increasingly popular in a variety of sequence\nmodeling tasks from natural language processing to recommendation, due to its\neffectiveness. However, self-attention suffers from quadratic computational and\nmemory complexities, prohibiting its applications on long sequences. Existing\napproaches that address this issue mainly rely on a sparse attention context,\neither using a local window, or a permuted bucket obtained by\nlocality-sensitive hashing (LSH) or sorting, while crucial information may be\nlost. Inspired by the idea of vector quantization that uses cluster centroids\nto approximate items, we propose LISA (LInear-time Self Attention), which\nenjoys both the effectiveness of vanilla self-attention and the efficiency of\nsparse attention. LISA scales linearly with the sequence length, while enabling\nfull contextual attention via computing differentiable histograms of codeword\ndistributions. Meanwhile, unlike some efficient attention methods, our method\nposes no restriction on casual masking or sequence length. We evaluate our\nmethod on four real-world datasets for sequential recommendation. The results\nshow that LISA outperforms the state-of-the-art efficient attention methods in\nboth performance and speed; and it is up to 57x faster and 78x more memory\nefficient than vanilla self-attention.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 19:16:51 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wu", "Yongji", ""], ["Lian", "Defu", ""], ["Gong", "Neil Zhenqiang", ""], ["Yin", "Lu", ""], ["Yin", "Mingyang", ""], ["Zhou", "Jingren", ""], ["Yang", "Hongxia", ""]]}, {"id": "2105.14069", "submitter": "Arman Dehpanah", "authors": "Arman Dehpanah, Muheeb Faizan Ghori, Jonathan Gemmell, Bamshad\n  Mobasher", "title": "The Evaluation of Rating Systems in Team-based Battle Royale Games", "comments": "Updated references -- 10 pages, 1 figure, Accepted in the 23rd\n  International Conference on Artificial Intelligence (ICAI'21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online competitive games have become a mainstream entertainment platform. To\ncreate a fair and exciting experience, these games use rating systems to match\nplayers with similar skills. While there has been an increasing amount of\nresearch on improving the performance of these systems, less attention has been\npaid to how their performance is evaluated. In this paper, we explore the\nutility of several metrics for evaluating three popular rating systems on a\nreal-world dataset of over 25,000 team battle royale matches. Our results\nsuggest considerable differences in their evaluation patterns. Some metrics\nwere highly impacted by the inclusion of new players. Many could not capture\nthe real differences between certain groups of players. Among all metrics\nstudied, normalized discounted cumulative gain (NDCG) demonstrated more\nreliable performance and more flexibility. It alleviated most of the challenges\nfaced by the other metrics while adding the freedom to adjust the focus of the\nevaluations on different groups of players.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 19:22:07 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 20:40:26 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Dehpanah", "Arman", ""], ["Ghori", "Muheeb Faizan", ""], ["Gemmell", "Jonathan", ""], ["Mobasher", "Bamshad", ""]]}, {"id": "2105.14134", "submitter": "Sudarshan Lamkhede", "authors": "Sudarshan Lamkhede and Christoph Kofler", "title": "Recommendations and Results Organization in Netflix Search", "comments": "Extended abstract submitted to RecSys 2021 Industry Track. 5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Personalized recommendations on the Netflix Homepage are based on a user's\nviewing habits and the behavior of similar users. These recommendations,\norganized for efficient browsing, enable users to discover the next great video\nto watch and enjoy without additional input or an explicit expression of their\nintents or goals. The Netflix Search experience, on the other hand, allows\nusers to take active control of discovering new videos by explicitly expressing\ntheir entertainment needs via search queries.\n  In this talk, we discuss the importance of producing search results that go\nbeyond traditional keyword-matches to effectively satisfy users' search needs\nin the Netflix entertainment setting. Motivated by users' various search\nintents, we highlight the necessity to improve Search by applying approaches\nthat have historically powered the Homepage. Specifically, we discuss our\napproach to leverage recommendations in the context of Search and to\neffectively organize search results to provide a product experience that\nmeaningfully adds value for our users.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 23:01:30 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Lamkhede", "Sudarshan", ""], ["Kofler", "Christoph", ""]]}, {"id": "2105.14188", "submitter": "Liyi Guo", "authors": "Liyi Guo, Junqi Jin, Haoqi Zhang, Zhenzhe Zheng, Zhiye Yang, Zhizhuang\n  Xing, Fei Pan, Lvyin Niu, Fan Wu, Haiyang Xu, Chuan Yu, Yuning Jiang,\n  Xiaoqiang Zhu", "title": "We Know What You Want: An Advertising Strategy Recommender System for\n  Online Advertising", "comments": null, "journal-ref": "Proceedings of the 27th ACM SIGKDD Conference on Knowledge\n  Discovery and Data Mining (KDD '21), August 14--18, 2021, Virtual Event,\n  Singapore", "doi": "10.1145/3447548.3467175", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advertising expenditures have become the major source of revenue for\ne-commerce platforms. Providing good advertising experiences for advertisers by\nreducing their costs of trial and error in discovering the optimal advertising\nstrategies is crucial for the long-term prosperity of online advertising. To\nachieve this goal, the advertising platform needs to identify the advertiser's\noptimization objectives, and then recommend the corresponding strategies to\nfulfill the objectives. In this work, we first deploy a prototype of strategy\nrecommender system on Taobao display advertising platform, which indeed\nincreases the advertisers' performance and the platform's revenue, indicating\nthe effectiveness of strategy recommendation for online advertising. We further\naugment this prototype system by explicitly learning the advertisers'\npreferences over various advertising performance indicators and then\noptimization objectives through their adoptions of different recommending\nadvertising strategies. We use contextual bandit algorithms to efficiently\nlearn the advertisers' preferences and maximize the recommendation adoption,\nsimultaneously. Simulation experiments based on Taobao online bidding data show\nthat the designed algorithms can effectively optimize the strategy adoption\nrate of advertisers.\n", "versions": [{"version": "v1", "created": "Tue, 25 May 2021 17:06:59 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 12:28:10 GMT"}, {"version": "v3", "created": "Sun, 13 Jun 2021 07:34:43 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Guo", "Liyi", ""], ["Jin", "Junqi", ""], ["Zhang", "Haoqi", ""], ["Zheng", "Zhenzhe", ""], ["Yang", "Zhiye", ""], ["Xing", "Zhizhuang", ""], ["Pan", "Fei", ""], ["Niu", "Lvyin", ""], ["Wu", "Fan", ""], ["Xu", "Haiyang", ""], ["Yu", "Chuan", ""], ["Jiang", "Yuning", ""], ["Zhu", "Xiaoqiang", ""]]}, {"id": "2105.14201", "submitter": "Qianren Mao", "authors": "Xi Li, Qianren Mao, Hao Peng, Hongdong Zhu, Jianxin Li, Zheng Wang", "title": "Automated Timeline Length Selection for Flexible Timeline Summarization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By producing summaries for long-running events, timeline summarization (TLS)\nunderpins many information retrieval tasks. Successful TLS requires identifying\nan appropriate set of key dates (the timeline length) to cover. However, doing\nso is challenging as the right length can change from one topic to another.\nExisting TLS solutions either rely on an event-agnostic fixed length or an\nexpert-supplied setting. Neither of the strategies is desired for real-life TLS\nscenarios. A fixed, event-agnostic setting ignores the diversity of events and\ntheir development and hence can lead to low-quality TLS. Relying on\nexpert-crafted settings is neither scalable nor sustainable for processing many\ndynamically changing events. This paper presents a better TLS approach for\nautomatically and dynamically determining the TLS timeline length. We achieve\nthis by employing the established elbow method from the machine learning\ncommunity to automatically find the minimum number of dates within the time\nseries to generate concise and informative summaries. We applied our approach\nto four TLS datasets of English and Chinese and compared them against three\nprior methods. Experimental results show that our approach delivers comparable\nor even better summaries over state-of-art TLS methods, but it achieves this\nwithout expert involvement.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 03:47:10 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Li", "Xi", ""], ["Mao", "Qianren", ""], ["Peng", "Hao", ""], ["Zhu", "Hongdong", ""], ["Li", "Jianxin", ""], ["Wang", "Zheng", ""]]}, {"id": "2105.14329", "submitter": "Gerrit Gro{\\ss}mann", "authors": "Gerrit Gro{\\ss}mann, Julian Zimmerlin, Michael Backenk\\\"ohler, Verena\n  Wolf", "title": "GINA: Neural Relational Inference From Independent Snapshots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR cs.MA physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Dynamical systems in which local interactions among agents give rise to\ncomplex emerging phenomena are ubiquitous in nature and society. This work\nexplores the problem of inferring the unknown interaction structure\n(represented as a graph) of such a system from measurements of its constituent\nagents or individual components (represented as nodes). We consider a setting\nwhere the underlying dynamical model is unknown and where different\nmeasurements (i.e., snapshots) may be independent (e.g., may stem from\ndifferent experiments). We propose GINA (Graph Inference Network Architecture),\na graph neural network (GNN) to simultaneously learn the latent interaction\ngraph and, conditioned on the interaction graph, the prediction of a node's\nobservable state based on adjacent vertices. GINA is based on the hypothesis\nthat the ground truth interaction graph -- among all other potential graphs --\nallows to predict the state of a node, given the states of its neighbors, with\nthe highest accuracy. We test this hypothesis and demonstrate GINA's\neffectiveness on a wide range of interaction graphs and dynamical processes.\n", "versions": [{"version": "v1", "created": "Sat, 29 May 2021 15:42:33 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Gro\u00dfmann", "Gerrit", ""], ["Zimmerlin", "Julian", ""], ["Backenk\u00f6hler", "Michael", ""], ["Wolf", "Verena", ""]]}, {"id": "2105.14403", "submitter": "Ryoma Sato", "authors": "Ryoma Sato, Makoto Yamada, Hisashi Kashima", "title": "Re-evaluating Word Mover's Distance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The word mover's distance (WMD) is a fundamental technique for measuring the\nsimilarity of two documents. As the crux of WMD, it can take advantage of the\nunderlying geometry of the word space by employing an optimal transport\nformulation. The original study on WMD reported that WMD outperforms classical\nbaselines such as bag-of-words (BOW) and TF-IDF by significant margins in\nvarious datasets. In this paper, we point out that the evaluation in the\noriginal study could be misleading. We re-evaluate the performances of WMD and\nthe classical baselines and find that the classical baselines are competitive\nwith WMD if we employ an appropriate preprocessing, i.e., L1 normalization.\nHowever, this result is not intuitive. WMD should be superior to BOW because\nWMD can take the underlying geometry into account, whereas BOW cannot. Our\nanalysis shows that this is due to the high-dimensional nature of the\nunderlying metric. We find that WMD in high-dimensional spaces behaves more\nsimilarly to BOW than in low-dimensional spaces due to the curse of\ndimensionality.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 01:35:03 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Sato", "Ryoma", ""], ["Yamada", "Makoto", ""], ["Kashima", "Hisashi", ""]]}, {"id": "2105.14423", "submitter": "Ryoma Sato", "authors": "Ryoma Sato", "title": "Enumerating Fair Packages for Group Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In package recommendations, a set of items is regarded as a unified package\ntowards a single common goal, whereas conventional recommender systems treat\nitems independently. For example, for music playlist recommendations, each\npackage (i.e., playlist) should be consistent with respect to the genres. In\ngroup recommendations, items are recommended to a group of users, whereas\nconventional recommender systems recommend items to an individual user.\nDifferent from the conventional settings, it is difficult to measure the\nutility of group recommendations because it involves more than one user. In\nparticular, fairness is crucial in group recommendations. Even if some members\nin a group are substantially satisfied with a recommendation, it is undesirable\nif other members are ignored to increase the total utility. Various methods for\nevaluating and applying the fairness of group recommendations have been\nproposed in the literature. However, all these methods maximize the score and\noutput only a single package. This is in contrast to conventional recommender\nsystems, which output several (e.g., top-$K$) candidates. This can be\nproblematic because a group can be dissatisfied with the recommended package\nowing to some unobserved reasons, even if the score is high. In particular,\neach fairness measure is not absolute, and users may call for different\nfairness criteria than the one adopted in the recommender system in operation.\nTo address this issue, we propose a method to enumerate fair packages so that a\ngroup can select their favorite packages from the list. Our proposed method can\nenumerate fair packages efficiently, and users can search their favorite\npackages by various filtering queries. We confirm that our algorithm scales to\nlarge datasets and can balance several aspects of the utility of the packages.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 04:06:03 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Sato", "Ryoma", ""]]}, {"id": "2105.14426", "submitter": "Pratik Kayal", "authors": "Pratik Kayal, Mrinal Anand, Harsh Desai, Mayank Singh", "title": "ICDAR 2021 Competition on Scientific Table Image Recognition to LaTeX", "comments": "This submission has been removed by arXiv administrators because the\n  submitter did not have the right to grant the license at the time of\n  submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Tables present important information concisely in many scientific documents.\nVisual features like mathematical symbols, equations, and spanning cells make\nstructure and content extraction from tables embedded in research documents\ndifficult. This paper discusses the dataset, tasks, participants' methods, and\nresults of the ICDAR 2021 Competition on Scientific Table Image Recognition to\nLaTeX. Specifically, the task of the competition is to convert a tabular image\nto its corresponding LaTeX source code. We proposed two subtasks. In Subtask 1,\nwe ask the participants to reconstruct the LaTeX structure code from an image.\nIn Subtask 2, we ask the participants to reconstruct the LaTeX content code\nfrom an image. This report describes the datasets and ground truth\nspecification, details the performance evaluation metrics used, presents the\nfinal results, and summarizes the participating methods. Submission by team\nVCGroup got the highest Exact Match accuracy score of 74% for Subtask 1 and 55%\nfor Subtask 2, beating previous baselines by 5% and 12%, respectively. Although\nimprovements can still be made to the recognition capabilities of models, this\ncompetition contributes to the development of fully automated table recognition\nsystems by challenging practitioners to solve problems under specific\nconstraints and sharing their approaches; the platform will remain available\nfor post-challenge submissions at\nhttps://competitions.codalab.org/competitions/26979 .\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 04:17:55 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Kayal", "Pratik", ""], ["Anand", "Mrinal", ""], ["Desai", "Harsh", ""], ["Singh", "Mayank", ""]]}, {"id": "2105.14428", "submitter": "Liqi Yang", "authors": "Liqi Yang, Linhan Luo, Lifeng Xin, Xiaofeng Zhang, Xinni Zhang", "title": "DAGNN: Demand-aware Graph Neural Networks for Session-based\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Session-based recommendations have been widely adopted for various online\nvideo and E-commerce Websites. Most existing approaches are intuitively\nproposed to discover underlying interests or preferences out of the anonymous\nsession data. This apparently ignores the fact these sequential behaviors\nusually reflect session user's potential demand, i.e., a semantic level factor,\nand therefore how to estimate underlying demands from a session is challenging.\nTo address aforementioned issue, this paper proposes a demand-aware graph\nneural networks (DAGNN). Particularly, a demand modeling component is designed\nto first extract session demand and the underlying multiple demands of each\nsession is estimated using the global demand matrix. Then, the demand-aware\ngraph neural network is designed to extract session demand graph to learn the\ndemand-aware item embedddings for the later recommendations. The mutual\ninformation loss is further designed to enhance the quality of the learnt\nembeddings. Extensive experiments are evaluated on several real-world datasets\nand the proposed model achieves the SOTA model performance.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 04:55:04 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Yang", "Liqi", ""], ["Luo", "Linhan", ""], ["Xin", "Lifeng", ""], ["Zhang", "Xiaofeng", ""], ["Zhang", "Xinni", ""]]}, {"id": "2105.14566", "submitter": "Hao Cheng", "authors": "Hao Cheng, Ping Wang, Chun Qi", "title": "CNN Retrieval based Unsupervised Metric Learning for Near-Duplicated\n  Video Retrieval", "comments": "This paper is submitted to ICIP 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As important data carriers, the drastically increasing number of multimedia\nvideos often brings many duplicate and near-duplicate videos in the top results\nof search. Near-duplicate video retrieval (NDVR) can cluster and filter out the\nredundant contents. In this paper, the proposed NDVR approach extracts the\nframe-level video representation based on convolutional neural network (CNN)\nfeatures from fully-connected layer and aggregated intermediate convolutional\nlayers. Unsupervised metric learning is used for similarity measurement and\nfeature matching. An efficient re-ranking algorithm combined with k-nearest\nneighborhood fuses the retrieval results from two levels of features and\nfurther improves the retrieval performance. Extensive experiments on the widely\nused CC\\_WEB\\_VIDEO dataset shows that the proposed approach exhibits superior\nperformance over the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 15:11:53 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Cheng", "Hao", ""], ["Wang", "Ping", ""], ["Qi", "Chun", ""]]}, {"id": "2105.14599", "submitter": "Franziska Scherpinski", "authors": "Franziska Scherpinski, Stefan Lessmann", "title": "Personalization in E-Grocery: Top-N versus Top-k Rankings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Business success in e-commerce depends on customer perceived value. A\ncustomer with high perceived value buys, returns, and recommends items. The\nperceived value is at risk whenever the information load harms users' shopping\nexperience. In e-grocery, shoppers face an overwhelming number of items, the\nmajority of which is irrelevant for the shopper. Recommender systems (RS)\nenable businesses to master information overload (IO) by providing users with\nan item ranking by relevance. Prior work proposes RS with short personalized\nrankings (top-k). Given large order sizes and high user heterogeneity in\ne-grocery, top-k RS are insufficient to diminish IO in this domain. To fill\nthis gap and raise business performance, this paper introduces an RS with a\npersonalized long ranking (top-N). Undertaking a randomized field experiment,\nthe paper establishes the merit of shifting from top-k to top-N rankings.\nSpecifically, the proposed RS reduces IO by 29.4% and lowers users' search time\nby 3.3 seconds per item. The field experiment also reveals a 7% uplift in\nrevenue due to the top-N ranking. Substantial benefits for the customer and the\ncompany highlight the business value of top-N rankings as a new design\nrequirement for recommender systems in e-grocery.\n", "versions": [{"version": "v1", "created": "Sun, 30 May 2021 18:40:07 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Scherpinski", "Franziska", ""], ["Lessmann", "Stefan", ""]]}, {"id": "2105.14688", "submitter": "Yongchun Zhu", "authors": "Yongchun Zhu, Yudan Liu, Ruobing Xie, Fuzhen Zhuang, Xiaobo Hao,\n  Kaikai Ge, Xu Zhang, Leyu Lin and Juan Cao", "title": "Learning to Expand Audience via Meta Hybrid Experts and Critics for\n  Recommendation and Advertising", "comments": "accepted by KDD2021", "journal-ref": null, "doi": "10.1145/3447548.3467093", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recommender systems and advertising platforms, marketers always want to\ndeliver products, contents, or advertisements to potential audiences over media\nchannels such as display, video, or social. Given a set of audiences or\ncustomers (seed users), the audience expansion technique (look-alike modeling)\nis a promising solution to identify more potential audiences, who are similar\nto the seed users and likely to finish the business goal of the target\ncampaign. However, look-alike modeling faces two challenges: (1) In practice, a\ncompany could run hundreds of marketing campaigns to promote various contents\nwithin completely different categories every day, e.g., sports, politics,\nsociety. Thus, it is difficult to utilize a common method to expand audiences\nfor all campaigns. (2) The seed set of a certain campaign could only cover\nlimited users. Therefore, a customized approach based on such a seed set is\nlikely to be overfitting.\n  In this paper, to address these challenges, we propose a novel two-stage\nframework named Meta Hybrid Experts and Critics (MetaHeac) which has been\ndeployed in WeChat Look-alike System. In the offline stage, a general model\nwhich can capture the relationships among various tasks is trained from a\nmeta-learning perspective on all existing campaign tasks. In the online stage,\nfor a new campaign, a customized model is learned with the given seed set based\non the general model. According to both offline and online experiments, the\nproposed MetaHeac shows superior effectiveness for both content marketing\ncampaigns in recommender systems and advertising campaigns in advertising\nplatforms. Besides, MetaHeac has been successfully deployed in WeChat for the\npromotion of both contents and advertisements, leading to great improvement in\nthe quality of marketing. The code has been available at\n\\url{https://github.com/easezyc/MetaHeac}.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 03:43:10 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Zhu", "Yongchun", ""], ["Liu", "Yudan", ""], ["Xie", "Ruobing", ""], ["Zhuang", "Fuzhen", ""], ["Hao", "Xiaobo", ""], ["Ge", "Kaikai", ""], ["Zhang", "Xu", ""], ["Lin", "Leyu", ""], ["Cao", "Juan", ""]]}, {"id": "2105.14909", "submitter": "Giovanni Gabbolini", "authors": "Giovanni Gabbolini and Derek Bridge", "title": "Generating Interesting Song-to-Song Segues With Dave", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a novel domain-independent algorithm for generating interesting\nitem-to-item textual connections, or segues. Pivotal to our contribution is the\nintroduction of a scoring function for segues, based on their\n\"interestingness\". We provide an implementation of our algorithm in the music\ndomain. We refer to our implementation as Dave. Dave is able to generate 1553\ndifferent types of segues, that can be broadly categorized as either\ninformative or funny. We evaluate Dave by comparing it against a curated source\nof song-to-song segues, called The Chain. In the case of informative segues, we\nfind that Dave can produce segues of the same quality, if not better, than\nthose to be found in The Chain. And, we report positive correlation between the\nvalues produced by our scoring function and human perceptions of segue quality.\nThe results highlight the validity of our method, and open future directions in\nthe application of segues to recommender systems research.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 12:23:16 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Gabbolini", "Giovanni", ""], ["Bridge", "Derek", ""]]}, {"id": "2105.14931", "submitter": "Jian Chen", "authors": "Meng Ling and Jian Chen and Torsten M\\\"oller and Petra Isenberg and\n  Tobias Isenberg and Michael Sedlmair and Robert S. Laramee and Han-Wei Shen\n  and Jian Wu and C. Lee Giles", "title": "Document Domain Randomization for Deep Learning Document Layout\n  Extraction", "comments": "Main paper to appear in ICDAR 2021 (16th International Conference on\n  Document Analysis and Recognition). This version contains additional\n  materials. The associated test data is hosted on IEEE Data Port:\n  http://doi.org/10.21227/326q-bf39", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present document domain randomization (DDR), the first successful transfer\nof convolutional neural networks (CNNs) trained only on graphically rendered\npseudo-paper pages to real-world document segmentation. DDR renders\npseudo-document pages by modeling randomized textual and non-textual contents\nof interest, with user-defined layout and font styles to support joint learning\nof fine-grained classes. We demonstrate competitive results using our DDR\napproach to extract nine document classes from the benchmark CS-150 and papers\npublished in two domains, namely annual meetings of Association for\nComputational Linguistics (ACL) and IEEE Visualization (VIS). We compare DDR to\nconditions of style mismatch, fewer or more noisy samples that are more easily\nobtained in the real world. We show that high-fidelity semantic information is\nnot necessary to label semantic classes but style mismatch between train and\ntest can lower model accuracy. Using smaller training samples had a slightly\ndetrimental effect. Finally, network models still achieved high test accuracy\nwhen correct labels are diluted towards confusing labels; this behavior hold\nacross several classes.\n", "versions": [{"version": "v1", "created": "Thu, 20 May 2021 19:16:04 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Ling", "Meng", ""], ["Chen", "Jian", ""], ["M\u00f6ller", "Torsten", ""], ["Isenberg", "Petra", ""], ["Isenberg", "Tobias", ""], ["Sedlmair", "Michael", ""], ["Laramee", "Robert S.", ""], ["Shen", "Han-Wei", ""], ["Wu", "Jian", ""], ["Giles", "C. Lee", ""]]}, {"id": "2105.14975", "submitter": "Shuai Wang", "authors": "Shuai Wang, Kun Zhang, Le Wu, Haiping Ma, Richang Hong, Meng Wang", "title": "Privileged Graph Distillation for Cold Start Recommendation", "comments": "10 pages,5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The cold start problem in recommender systems is a long-standing challenge,\nwhich requires recommending to new users (items) based on attributes without\nany historical interaction records. In these recommendation systems, warm users\n(items) have privileged collaborative signals of interaction records compared\nto cold start users (items), and these Collaborative Filtering (CF) signals are\nshown to have competing performance for recommendation. Many researchers\nproposed to learn the correlation between collaborative signal embedding space\nand the attribute embedding space to improve the cold start recommendation, in\nwhich user and item categorical attributes are available in many online\nplatforms. However, the cold start recommendation is still limited by two\nembedding spaces modeling and simple assumptions of space transformation. As\nuser-item interaction behaviors and user (item) attributes naturally form a\nheterogeneous graph structure, in this paper, we propose a privileged graph\ndistillation model~(PGD). The teacher model is composed of a heterogeneous\ngraph structure for warm users and items with privileged CF links. The student\nmodel is composed of an entity-attribute graph without CF links. Specifically,\nthe teacher model can learn better embeddings of each entity by injecting\ncomplex higher-order relationships from the constructed heterogeneous graph.\nThe student model can learn the distilled output with privileged CF embeddings\nfrom the teacher embeddings. Our proposed model is generally applicable to\ndifferent cold start scenarios with new user, new item, or new user-new item.\nFinally, extensive experimental results on the real-world datasets clearly show\nthe effectiveness of our proposed model on different types of cold start\nproblems, with average $6.6\\%, 5.6\\%, $ and $17.1\\%$ improvement over\nstate-of-the-art baselines on three datasets, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 14:05:27 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Wang", "Shuai", ""], ["Zhang", "Kun", ""], ["Wu", "Le", ""], ["Ma", "Haiping", ""], ["Hong", "Richang", ""], ["Wang", "Meng", ""]]}, {"id": "2105.15014", "submitter": "Lenny Renault", "authors": "Lenny Renault, Andrea Vaglio, Romain Hennequin", "title": "Singing Language Identification using a Deep Phonotactic Approach", "comments": "5 pages, 1 figure, ICASSP 2021", "journal-ref": "ICASSP 2021 - 2021 IEEE International Conference on Acoustics,\n  Speech and Signal Processing (ICASSP), pp. 271-275", "doi": "10.1109/ICASSP39728.2021.9414203", "report-no": null, "categories": "cs.SD cs.IR eess.AS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Extensive works have tackled Language Identification (LID) in the speech\ndomain, however their application to the singing voice trails and performances\non Singing Language Identification (SLID) can be improved leveraging recent\nprogresses made in other singing related tasks. This work presents a modernized\nphonotactic system for SLID on polyphonic music: phoneme recognition is\nperformed with a Connectionist Temporal Classification (CTC)-based acoustic\nmodel trained with multilingual data, before language classification with a\nrecurrent model based on the phonemes estimation. The full pipeline is trained\nand evaluated with a large and publicly available dataset, with unprecedented\nperformances. First results of SLID with out-of-set languages are also\npresented.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 14:53:12 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Renault", "Lenny", ""], ["Vaglio", "Andrea", ""], ["Hennequin", "Romain", ""]]}, {"id": "2105.15165", "submitter": "Armin Kirchknopf", "authors": "Armin Kirchknopf, Djordje Slijepcevic, Matthias Zeppelzauer", "title": "Multimodal Detection of Information Disorder from Social Media", "comments": "4 pages, 2 figures, 2 tables, PrePrint CBMI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Social media is accompanied by an increasing proportion of content that\nprovides fake information or misleading content, known as information disorder.\nIn this paper, we study the problem of multimodal fake news detection on a\nlargescale multimodal dataset. We propose a multimodal network architecture\nthat enables different levels and types of information fusion. In addition to\nthe textual and visual content of a posting, we further leverage secondary\ninformation, i.e. user comments and metadata. We fuse information at multiple\nlevels to account for the specific intrinsic structure of the modalities. Our\nresults show that multimodal analysis is highly effective for the task and all\nmodalities contribute positively when fused properly.\n", "versions": [{"version": "v1", "created": "Mon, 31 May 2021 17:13:47 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Kirchknopf", "Armin", ""], ["Slijepcevic", "Djordje", ""], ["Zeppelzauer", "Matthias", ""]]}]