[{"id": "0904.0016", "submitter": "Tad Hogg", "authors": "Tad Hogg and Kristina Lerman", "title": "Stochastic Models of User-Contributory Web Sites", "comments": null, "journal-ref": "Proc. of the 3rd Intl Conf on Weblogs and Social Media\n  (ICWSM2009), pp. 50-57 (2009)", "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a general stochastic processes-based approach to modeling\nuser-contributory web sites, where users create, rate and share content. These\nmodels describe aggregate measures of activity and how they arise from simple\nmodels of individual users. This approach provides a tractable method to\nunderstand user activity on the web site and how this activity depends on web\nsite design choices, especially the choice of what information about other\nusers' behaviors is shown to each user. We illustrate this modeling approach in\nthe context of user-created content on the news rating site Digg.\n", "versions": [{"version": "v1", "created": "Tue, 31 Mar 2009 20:32:42 GMT"}], "update_date": "2009-10-06", "authors_parsed": [["Hogg", "Tad", ""], ["Lerman", "Kristina", ""]]}, {"id": "0904.0313", "submitter": "Petar Kormushev", "authors": "Petar Kormushev", "title": "Visual approach for data mining on medical information databases using\n  Fastmap algorithm", "comments": "Master's Thesis in Bio- and Medical Informatics, 76 pages, in\n  Bulgarian. Submitted to Faculty of Mathematics and Informatics, Sofia\n  University, 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid development of tools for acquisition and storage of information has\nlead to the formation of enormous medical databases. The large quantity of data\ndefinitely surpasses the abilities of humans for efficient usage without\nspecialized tools for analysis. The situation is described as rich in data, but\npoor in information. In order to fill this growing gap, different approaches\nfrom the field of Data Mining are applied. These methods perform analysis of\nlarge sets of observed data in order to find new dependencies or concise\nrepresentation of the data, which is more meaningful to humans. One of the\npossible approaches for discovery of dependencies is the visual approach, in\nwhich data is processed and visualized in a way suitable for analysis by a\ndomain expert. This work proposes a visual approach, in which data is processed\nand visualized in a way suitable for analysis by a domain expert. We design and\nimplement a software solution for visualization of multi-dimensional,\nclassified medical data using the FastMap algorithm for graduate reduction of\ndimensions. The implementation of the graphical user interface is described in\ndetail since it is the most important factor for the ease of use of these tools\nby non-professionals in data mining.\n", "versions": [{"version": "v1", "created": "Thu, 2 Apr 2009 06:14:42 GMT"}], "update_date": "2009-04-03", "authors_parsed": [["Kormushev", "Petar", ""]]}, {"id": "0904.0682", "submitter": "Michaela Goetz", "authors": "Michaela Goetz, Ashwin Machanavajjhala, Guozhang Wang, Xiaokui Xiao,\n  Johannes Gehrke", "title": "Privacy in Search Logs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search engine companies collect the \"database of intentions\", the histories\nof their users' search queries. These search logs are a gold mine for\nresearchers. Search engine companies, however, are wary of publishing search\nlogs in order not to disclose sensitive information. In this paper we analyze\nalgorithms for publishing frequent keywords, queries and clicks of a search\nlog. We first show how methods that achieve variants of $k$-anonymity are\nvulnerable to active attacks. We then demonstrate that the stronger guarantee\nensured by $\\epsilon$-differential privacy unfortunately does not provide any\nutility for this problem. We then propose an algorithm ZEALOUS and show how to\nset its parameters to achieve $(\\epsilon,\\delta)$-probabilistic privacy. We\nalso contrast our analysis of ZEALOUS with an analysis by Korolova et al. [17]\nthat achieves $(\\epsilon',\\delta')$-indistinguishability. Our paper concludes\nwith a large experimental study using real applications where we compare\nZEALOUS and previous work that achieves $k$-anonymity in search log publishing.\nOur results show that ZEALOUS yields comparable utility to $k-$anonymity while\nat the same time achieving much stronger privacy guarantees.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2009 05:49:00 GMT"}, {"version": "v2", "created": "Tue, 15 Dec 2009 08:42:17 GMT"}, {"version": "v3", "created": "Sun, 29 Aug 2010 20:08:44 GMT"}, {"version": "v4", "created": "Wed, 11 May 2011 22:39:23 GMT"}], "update_date": "2011-05-13", "authors_parsed": [["Goetz", "Michaela", ""], ["Machanavajjhala", "Ashwin", ""], ["Wang", "Guozhang", ""], ["Xiao", "Xiaokui", ""], ["Gehrke", "Johannes", ""]]}, {"id": "0904.0986", "submitter": "Sahbi Sidhom", "authors": "Sahbi Sidhom (LORIA)", "title": "Approche conceptuelle par un processus d'annotation pour la\n  repr\\'esentation et la valorisation de contenus informationnels en\n  intelligence \\'economique (IE)", "comments": null, "journal-ref": "Syst\\`emes d'Information et Intelligence Economique (SIIE) 1 (\n  ISBN 9978-9973868-19-0) (2008) pp. 172-190", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of the information society, the impact of the information systems\non the economy of material and immaterial is certainly perceptible. With\nregards to the information resources of an organization, the annotation\ninvolved to enrich informational content, to track the intellectual activities\non a document and to set the added value on information for the benefit of\nsolving a decision-making problem in the context of economic intelligence. Our\ncontribution is distinguished by the representation of an annotation process\nand its inherent concepts to lead the decisionmaker to an anticipated decision:\nthe provision of relevant and annotated information. Such information in the\nsystem is made easy by taking into account the diversity of resources and those\nthat are well annotated so formally and informally by the EI actors. A capital\nresearch framework consist of integrating in the decision-making process the\nannotator activity, the software agent (or the reasoning mechanisms) and the\ninformation resources enhancement.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2009 18:56:12 GMT"}], "update_date": "2009-04-07", "authors_parsed": [["Sidhom", "Sahbi", "", "LORIA"]]}, {"id": "0904.1234", "submitter": "Mark Herrera", "authors": "Mark Herrera, David C. Roberts, Natali Gulbahce", "title": "Mapping the evolution of scientific fields", "comments": "v3: re-ran analysis with new noise parameter choice; 10 pages for\n  main paper; 11 pages for suppl. info", "journal-ref": "PLoS ONE 5(5): e10355. 2010", "doi": "10.1371/journal.pone.0010355", "report-no": null, "categories": "physics.soc-ph cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the apparent cross-disciplinary interactions among scientific fields,\na formal description of their evolution is lacking. Here we describe a novel\napproach to study the dynamics and evolution of scientific fields using a\nnetwork-based analysis. We build an idea network consisting of American\nPhysical Society Physics and Astronomy Classification Scheme (PACS) numbers as\nnodes representing scientific concepts. Two PACS numbers are linked if there\nexist publications that reference them simultaneously. We locate scientific\nfields using a community finding algorithm, and describe the time evolution of\nthese fields over the course of 1985-2006. The communities we identify map to\nknown scientific fields, and their age depends on their size and activity. We\nexpect our approach to quantifying the evolution of ideas to be relevant for\nmaking predictions about the future of science and thus help to guide its\ndevelopment.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2009 22:24:11 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2009 20:58:03 GMT"}, {"version": "v3", "created": "Fri, 23 Apr 2010 02:53:29 GMT"}], "update_date": "2011-02-03", "authors_parsed": [["Herrera", "Mark", ""], ["Roberts", "David C.", ""], ["Gulbahce", "Natali", ""]]}, {"id": "0904.1299", "submitter": "Andreas W. Liehr", "authors": "Moritz Riede, Rico Schueppel, Kristian O. Sylvester-Hvid, Martin\n  Kuehne, Michael C. Roettger, Klaus Zimmermann and Andreas W. Liehr", "title": "On the Communication of Scientific Results: The Full-Metadata Format", "comments": null, "journal-ref": "Comput.Phys.Commun.181:651-662,2010", "doi": "10.1016/j.cpc.2009.11.014", "report-no": "SI20090302a", "categories": "cs.DL cs.IR physics.comp-ph physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a scientific format for text-based data files,\nwhich facilitates storing and communicating tabular data sets. The so-called\nFull-Metadata Format builds on the widely used INI-standard and is based on\nfour principles: readable self-documentation, flexible structure, fail-safe\ncompatibility, and searchability. As a consequence, all metadata required to\ninterpret the tabular data are stored in the same file, allowing for the\nautomated generation of publication-ready tables and graphs and the semantic\nsearchability of data file collections. The Full-Metadata Format is introduced\non the basis of three comprehensive examples. The complete format and syntax is\ngiven in the appendix.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2009 10:07:02 GMT"}], "update_date": "2010-01-21", "authors_parsed": [["Riede", "Moritz", ""], ["Schueppel", "Rico", ""], ["Sylvester-Hvid", "Kristian O.", ""], ["Kuehne", "Martin", ""], ["Roettger", "Michael C.", ""], ["Zimmermann", "Klaus", ""], ["Liehr", "Andreas W.", ""]]}, {"id": "0904.1989", "submitter": "Tao Zhou", "authors": "Zi-Ke Zhang, Tao Zhou, Yi-Cheng Zhang", "title": "Personalized Recommendation via Integrated Diffusion on User-Item-Tag\n  Tripartite Graphs", "comments": "12 pages, 6 figures, 2 tables", "journal-ref": "Physica A 389 (2010) 179-186", "doi": "10.1016/j.physa.2009.08.036", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalized recommender systems are confronting great challenges of\naccuracy, diversification and novelty, especially when the data set is sparse\nand lacks accessorial information, such as user profiles, item attributes and\nexplicit ratings. Collaborative tags contain rich information about\npersonalized preferences and item contents, and are therefore potential to help\nin providing better recommendations. In this paper, we propose a recommendation\nalgorithm based on an integrated diffusion on user-item-tag tripartite graphs.\nWe use three benchmark data sets, Del.icio.us, MovieLens and BibSonomy, to\nevaluate our algorithm. Experimental results demonstrate that the usage of tag\ninformation can significantly improve accuracy, diversification and novelty of\nrecommendations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2009 19:13:03 GMT"}], "update_date": "2009-10-07", "authors_parsed": [["Zhang", "Zi-Ke", ""], ["Zhou", "Tao", ""], ["Zhang", "Yi-Cheng", ""]]}, {"id": "0904.2012", "submitter": "David Spivak", "authors": "David I. Spivak", "title": "Simplicial Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper, we define a category DB, called the category of simplicial\ndatabases, whose objects are databases and whose morphisms are data-preserving\nmaps. Along the way we give a precise formulation of the category of relational\ndatabases, and prove that it is a full subcategory of DB. We also prove that\nlimits and colimits always exist in DB and that they correspond to queries such\nas select, join, union, etc.\n  One feature of our construction is that the schema of a simplicial database\nhas a natural geometric structure: an underlying simplicial set. The geometry\nof a schema is a way of keeping track of relationships between distinct tables,\nand can be thought of as a system of foreign keys. The shape of a schema is\ngenerally intuitive (e.g. the schema for round-trip flights is a circle\nconsisting of an edge from $A$ to $B$ and an edge from $B$ to $A$), and as\nsuch, may be useful for analyzing data.\n  We give several applications of our approach, as well as possible advantages\nit has over the relational model. We also indicate some directions for further\nresearch.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2009 21:20:57 GMT"}], "update_date": "2009-04-15", "authors_parsed": [["Spivak", "David I.", ""]]}, {"id": "0904.4041", "submitter": "Mario Nascimento", "authors": "Jie Luo and Mario A. Nascimento", "title": "Content-Based Sub-Image Retrieval with Relevance Feedback", "comments": "A preliminary version of this paper appeared in the Proceedings of\n  the 1st ACM International Workshop on Multimedia Databases, p. 63-69. 2003", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The typical content-based image retrieval problem is to find images within a\ndatabase that are similar to a given query image. This paper presents a\nsolution to a different problem, namely that of content based sub-image\nretrieval, i.e., finding images from a database that contains another image.\nNote that this is different from finding a region in a (segmented) image that\nis similar to another image region given as a query. We present a technique for\nCBsIR that explores relevance feedback, i.e., the user's input on intermediary\nresults, in order to improve retrieval efficiency. Upon modeling images as a\nset of overlapping and recursive tiles, we use a tile re-weighting scheme that\nassigns penalties to each tile of the database images and updates the tile\npenalties for all relevant images retrieved at each iteration using both the\nrelevant and irrelevant images identified by the user. Each tile is modeled by\nmeans of its color content using a compact but very efficient method which can,\nindirectly, capture some notion of texture as well, despite the fact that only\ncolor information is maintained. Performance evaluation on a largely\nheterogeneous dataset of over 10,000 images shows that the system can achieve a\nstable average recall value of 70% within the top 20 retrieved (and presented)\nimages after only 5 iterations, with each such iteration taking about 2 seconds\non an off-the-shelf desktop computer.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2009 17:50:33 GMT"}], "update_date": "2009-04-28", "authors_parsed": [["Luo", "Jie", ""], ["Nascimento", "Mario A.", ""]]}]