[{"id": "1805.00065", "submitter": "Aman Agarwal", "authors": "Aman Agarwal, Kenta Takatsu, Ivan Zaitsev, Thorsten Joachims", "title": "A General Framework for Counterfactual Learning-to-Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Implicit feedback (e.g., click, dwell time) is an attractive source of\ntraining data for Learning-to-Rank, but its naive use leads to learning results\nthat are distorted by presentation bias. For the special case of optimizing\naverage rank for linear ranking functions, however, the recently developed\nSVM-PropRank method has shown that counterfactual inference techniques can be\nused to provably overcome the distorting effect of presentation bias. Going\nbeyond this special case, this paper provides a general and theoretically\nrigorous framework for counterfactual learning-to-rank that enables unbiased\ntraining for a broad class of additive ranking metrics (e.g., Discounted\nCumulative Gain (DCG)) as well as a broad class of models (e.g., deep\nnetworks). Specifically, we derive a relaxation for propensity-weighted\nrank-based metrics which is subdifferentiable and thus suitable for\ngradient-based optimization. We demonstrate the effectiveness of this general\napproach by instantiating two new learning methods. One is a new type of\nunbiased SVM that optimizes DCG -- called SVM PropDCG --, and we show how the\nresulting optimization problem can be solved via the Convex Concave Procedure\n(CCP). The other is Deep PropDCG, where the ranking function can be an\narbitrary deep network. In addition to the theoretical support, we empirically\nfind that SVM PropDCG significantly outperforms existing linear rankers in\nterms of DCG. Moreover, the ability to train non-linear ranking functions via\nDeep PropDCG further improves performance.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 19:12:37 GMT"}, {"version": "v2", "created": "Fri, 22 Jun 2018 03:32:49 GMT"}, {"version": "v3", "created": "Tue, 27 Aug 2019 13:58:07 GMT"}], "update_date": "2019-08-28", "authors_parsed": [["Agarwal", "Aman", ""], ["Takatsu", "Kenta", ""], ["Zaitsev", "Ivan", ""], ["Joachims", "Thorsten", ""]]}, {"id": "1805.00121", "submitter": "Juan Duque Rodriguez", "authors": "Juan Ar\\'evalo, Juan Ram\\'on Duque, Marco Creatura", "title": "A Missing Information Loss function for implicit feedback datasets", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent factor models for Recommender Systems with implicit feedback typically\ntreat unobserved user-item interactions (i.e. missing information) as negative\nfeedback. This is frequently done either through negative sampling (point--wise\nloss) or with a ranking loss function (pair-- or list--wise estimation). Since\na zero preference recommendation is a valid solution for most common objective\nfunctions, regarding unknown values as actual zeros results in users having a\nzero preference recommendation for most of the available items. In this paper\nwe propose a novel objective function, the \\emph{Missing Information Loss}\n(MIL), that explicitly forbids treating unobserved user-item interactions as\npositive or negative feedback. We apply this loss to both traditional Matrix\nFactorization and user--based Denoising Autoencoder, and compare it with other\nestablished objective functions such as cross-entropy (both point- and\npair-wise) or the recently proposed multinomial log-likelihood. MIL achieves\ncompetitive performance in ranking-aware metrics when applied to three\ndatasets. Furthermore, we show that such a relevance in the recommendation is\nobtained while displaying popular items less frequently (up to a $20 \\%$\ndecrease with respect to the best competing method). This debiasing from the\nrecommendation of popular items favours the appearance of infrequent items (up\nto a $50 \\%$ increase of long-tail recommendations), a valuable feature for\nRecommender Systems with a large catalogue of products.\n", "versions": [{"version": "v1", "created": "Mon, 30 Apr 2018 22:38:05 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2018 08:16:50 GMT"}], "update_date": "2018-08-17", "authors_parsed": [["Ar\u00e9valo", "Juan", ""], ["Duque", "Juan Ram\u00f3n", ""], ["Creatura", "Marco", ""]]}, {"id": "1805.00150", "submitter": "Zheng Zhang", "authors": "Zheng Zhang, Minlie Huang, Zhongzhou Zhao, Feng Ji, Haiqing Chen,\n  Xiaoyan Zhu", "title": "Memory-augmented Dialogue Management for Task-oriented Dialogue Systems", "comments": "25 pages, 9 figures, Under review of ACM Transactions on Information\n  Systems (TOIS)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dialogue management (DM) decides the next action of a dialogue system\naccording to the current dialogue state, and thus plays a central role in\ntask-oriented dialogue systems. Since dialogue management requires to have\naccess to not only local utterances, but also the global semantics of the\nentire dialogue session, modeling the long-range history information is a\ncritical issue. To this end, we propose a novel Memory-Augmented Dialogue\nmanagement model (MAD) which employs a memory controller and two additional\nmemory structures, i.e., a slot-value memory and an external memory. The\nslot-value memory tracks the dialogue state by memorizing and updating the\nvalues of semantic slots (for instance, cuisine, price, and location), and the\nexternal memory augments the representation of hidden states of traditional\nrecurrent neural networks through storing more context information. To update\nthe dialogue state efficiently, we also propose slot-level attention on user\nutterances to extract specific semantic information for each slot. Experiments\nshow that our model can obtain state-of-the-art performance and outperforms\nexisting baselines.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 02:14:00 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Zhang", "Zheng", ""], ["Huang", "Minlie", ""], ["Zhao", "Zhongzhou", ""], ["Ji", "Feng", ""], ["Chen", "Haiqing", ""], ["Zhu", "Xiaoyan", ""]]}, {"id": "1805.00152", "submitter": "Laura Dietz", "authors": "Laura Dietz and John Foley", "title": "On the Equivalence of Generative and Discriminative Formulations of the\n  Sequential Dependence Model", "comments": "SIGIR'17 Workshop on Axiomatic Thinking for Information Retrieval and\n  Related Tasks (ATIR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The sequential dependence model (SDM) is a popular retrieval model which is\nbased on the theory of probabilistic graphical models. While it was originally\nintroduced by Metzler and Croft as a Markov Random Field (aka discriminative\nprobabilistic model), in this paper we demonstrate that it is equivalent to a\ngenerative probabilistic model.\n  To build an foundation for future retrieval models, this paper details the\naxiomatic underpinning of the SDM model as discriminative and generative\nprobabilistic model. The only difference arises whether model parameters are\nestimated in log-space or Multinomial-space. We demonstrate that\nparameter-estimation with grid-tuning is negatively impacting the generative\nformulation, an effect that vanishes when parameters are estimated with\ncoordinate-gradient descent. This is concerning, since empirical differences\nmay be falsely attributed to improved models.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 02:16:29 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Dietz", "Laura", ""], ["Foley", "John", ""]]}, {"id": "1805.00188", "submitter": "Liu Yang", "authors": "Liu Yang, Minghui Qiu, Chen Qu, Jiafeng Guo, Yongfeng Zhang, W. Bruce\n  Croft, Jun Huang, Haiqing Chen", "title": "Response Ranking with Deep Matching Networks and External Knowledge in\n  Information-seeking Conversation Systems", "comments": "Accepted by the 41th International ACM SIGIR Conference on Research\n  and Development in Information Retrieval (SIGIR 2018), Ann Arbor, Michigan,\n  U.S.A. July 8-12, 2018 (Full Oral Paper)", "journal-ref": null, "doi": "10.1145/3209978.3210011", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intelligent personal assistant systems with either text-based or voice-based\nconversational interfaces are becoming increasingly popular around the world.\nRetrieval-based conversation models have the advantages of returning fluent and\ninformative responses. Most existing studies in this area are on open domain\n\"chit-chat\" conversations or task / transaction oriented conversations. More\nresearch is needed for information-seeking conversations. There is also a lack\nof modeling external knowledge beyond the dialog utterances among current\nconversational models. In this paper, we propose a learning framework on the\ntop of deep neural matching networks that leverages external knowledge for\nresponse ranking in information-seeking conversation systems. We incorporate\nexternal knowledge into deep neural models with pseudo-relevance feedback and\nQA correspondence knowledge distillation. Extensive experiments with three\ninformation-seeking conversation data sets including both open benchmarks and\ncommercial data show that, our methods outperform various baseline methods\nincluding several deep text matching models and the state-of-the-art method on\nresponse selection in multi-turn conversations. We also perform analysis over\ndifferent response types, model variations and ranking examples. Our models and\nresearch findings provide new insights on how to utilize external knowledge\nwith deep neural models for response selection and have implications for the\ndesign of the next generation of information-seeking conversation systems.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 05:05:05 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 00:28:53 GMT"}, {"version": "v3", "created": "Wed, 9 May 2018 05:09:40 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Yang", "Liu", ""], ["Qiu", "Minghui", ""], ["Qu", "Chen", ""], ["Guo", "Jiafeng", ""], ["Zhang", "Yongfeng", ""], ["Croft", "W. Bruce", ""], ["Huang", "Jun", ""], ["Chen", "Haiqing", ""]]}, {"id": "1805.00254", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Benjamin Roth and Hinrich Sch\\\"utze", "title": "Joint Bootstrapping Machines for High Confidence Relation Extraction", "comments": "In Proceedings of the 16th Annual Conference of the North American\n  Chapter of the Association for Computational Linguistics: Human Language\n  Technologies (NAACL-HLT 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semi-supervised bootstrapping techniques for relationship extraction from\ntext iteratively expand a set of initial seed instances. Due to the lack of\nlabeled data, a key challenge in bootstrapping is semantic drift: if a false\npositive instance is added during an iteration, then all following iterations\nare contaminated. We introduce BREX, a new bootstrapping method that protects\nagainst such contamination by highly effective confidence assessment. This is\nachieved by using entity and template seeds jointly (as opposed to just one as\nin previous work), by expanding entities and templates in parallel and in a\nmutually constraining fashion in each iteration and by introducing\nhigherquality similarity measures for templates. Experimental results show that\nBREX achieves an F1 that is 0.13 (0.87 vs. 0.74) better than the state of the\nart for four relationships.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 09:39:19 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Gupta", "Pankaj", ""], ["Roth", "Benjamin", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1805.00309", "submitter": "Ning Ma", "authors": "Ning Ma, Alexey Volkov, Aleksandr Livshits, Pawel Pietrusinski,\n  Houdong Hu, Mark Bolin", "title": "An Universal Image Attractiveness Ranking Framework", "comments": "Accepted by 2019 Winter Conference on Application of Computer Vision\n  (WACV)", "journal-ref": "2019 IEEE Winter Conference on Applications of Computer Vision\n  (WACV)", "doi": "10.1109/WACV.2019.00075", "report-no": null, "categories": "cs.CV cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new framework to rank image attractiveness using a novel\npairwise deep network trained with a large set of side-by-side multi-labeled\nimage pairs from a web image index. The judges only provide relative ranking\nbetween two images without the need to directly assign an absolute score, or\nrate any predefined image attribute, thus making the rating more intuitive and\naccurate. We investigate a deep attractiveness rank net (DARN), a combination\nof deep convolutional neural network and rank net, to directly learn an\nattractiveness score mean and variance for each image and the underlying\ncriteria the judges use to label each pair. The extension of this model\n(DARN-V2) is able to adapt to individual judge's personal preference. We also\nshow the attractiveness of search results are significantly improved by using\nthis attractiveness information in a real commercial search engine. We evaluate\nour model against other state-of-the-art models on our side-by-side web test\ndata and another public aesthetic data set. With much less judgments (1M vs\n50M), our model outperforms on side-by-side labeled data, and is comparable on\ndata labeled by absolute score.\n", "versions": [{"version": "v1", "created": "Thu, 12 Apr 2018 21:10:37 GMT"}, {"version": "v2", "created": "Wed, 19 Sep 2018 06:27:01 GMT"}, {"version": "v3", "created": "Mon, 14 Jan 2019 06:34:48 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Ma", "Ning", ""], ["Volkov", "Alexey", ""], ["Livshits", "Aleksandr", ""], ["Pietrusinski", "Pawel", ""], ["Hu", "Houdong", ""], ["Bolin", "Mark", ""]]}, {"id": "1805.00356", "submitter": "Jill-J\\^enn Vie", "authors": "Jill-J\\^enn Vie", "title": "Deep Factorization Machines for Knowledge Tracing", "comments": "4 pages, 1 table, accepted at the 13th BEA workshop, co-located with\n  NAACL HLT 2018 conference in New Orleans on June 5, 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces our solution to the 2018 Duolingo Shared Task on Second\nLanguage Acquisition Modeling (SLAM). We used deep factorization machines, a\nwide and deep learning model of pairwise relationships between users, items,\nskills, and other entities considered. Our solution (AUC 0.815) hopefully\nmanaged to beat the logistic regression baseline (AUC 0.774) but not the top\nperforming model (AUC 0.861) and reveals interesting strategies to build upon\nitem response theory models.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 14:13:56 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Vie", "Jill-J\u00eann", ""]]}, {"id": "1805.00432", "submitter": "Duc Le", "authors": "V.Duc Le, Sang Kyun Cha", "title": "Real-time Air Pollution prediction model based on Spatiotemporal Big\n  data", "comments": "6 pages", "journal-ref": "The International Conference on Big data, IoT, and Cloud Computing\n  (BIC 2018)", "doi": null, "report-no": null, "categories": "cs.CY cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Air pollution is one of the most concerns for urban areas. Many countries\nhave constructed monitoring stations to hourly collect pollution values.\nRecently, there is a research in Daegu city, Korea for real-time air quality\nmonitoring via sensors installed on taxis running across the whole city. The\ncollected data is huge (1-second interval) and in both Spatial and Temporal\nformat. In this paper, based on this spatiotemporal Big data, we propose a\nreal-time air pollution prediction model based on Convolutional Neural Network\n(CNN) algorithm for image-like Spatial distribution of air pollution. Regarding\nto Temporal information in the data, we introduce a combination of a Long\nShort-Term Memory (LSTM) unit for time series data and a Neural Network model\nfor other air pollution impact factors such as weather conditions to build a\nhybrid prediction model. This model is simple in architecture but still brings\ngood prediction ability.\n", "versions": [{"version": "v1", "created": "Thu, 5 Apr 2018 06:36:12 GMT"}, {"version": "v2", "created": "Thu, 3 May 2018 00:55:20 GMT"}, {"version": "v3", "created": "Fri, 10 Aug 2018 02:35:34 GMT"}], "update_date": "2018-10-18", "authors_parsed": [["Le", "V. Duc", ""], ["Cha", "Sang Kyun", ""]]}, {"id": "1805.00445", "submitter": "Geoffrey Fairchild", "authors": "Geoffrey Fairchild (1), Byron Tasseff (1), Hari Khalsa (1), Nicholas\n  Generous (2), Ashlynn R. Daughton (1), Nileena Velappan (3), Reid Priedhorsky\n  (4), Alina Deshpande (3) ((1) Analytics, Intelligence, and Technology\n  Division, Los Alamos National Laboratory, Los Alamos, New Mexico, USA, (2)\n  Intelligence and Emerging Threats Program Office, Los Alamos National\n  Laboratory, Los Alamos, New Mexico, USA, (3) Bioscience Division, Los Alamos\n  National Laboratory, Los Alamos, New Mexico, USA, (4) High Performance\n  Computing Division, Los Alamos National Laboratory, Los Alamos, New Mexico,\n  USA)", "title": "Epidemiological data challenges: planning for a more robust future\n  through data standards", "comments": "v2 includes several typo fixes; v3 adds a paragraph on backfill; v4\n  adds 2 new paragraphs to the conclusion that address Frontiers reviewer\n  comments; v5 adds some minor modifications that address additional reviewer\n  comments", "journal-ref": null, "doi": "10.3389/fpubh.2018.00336", "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accessible epidemiological data are of great value for emergency preparedness\nand response, understanding disease progression through a population, and\nbuilding statistical and mechanistic disease models that enable forecasting.\nThe status quo, however, renders acquiring and using such data difficult in\npractice. In many cases, a primary way of obtaining epidemiological data is\nthrough the internet, but the methods by which the data are presented to the\npublic often differ drastically among institutions. As a result, there is a\nstrong need for better data sharing practices. This paper identifies, in detail\nand with examples, the three key challenges one encounters when attempting to\nacquire and use epidemiological data: 1) interfaces, 2) data formatting, and 3)\nreporting. These challenges are used to provide suggestions and guidance for\nimprovement as these systems evolve in the future. If these suggested data and\ninterface recommendations were adhered to, epidemiological and public health\nanalysis, modeling, and informatics work would be significantly streamlined,\nwhich can in turn yield better public health decision-making capabilities.\n", "versions": [{"version": "v1", "created": "Fri, 20 Apr 2018 18:44:04 GMT"}, {"version": "v2", "created": "Wed, 2 May 2018 20:45:05 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2018 20:28:23 GMT"}, {"version": "v4", "created": "Fri, 17 Aug 2018 18:39:42 GMT"}, {"version": "v5", "created": "Wed, 14 Nov 2018 23:28:37 GMT"}, {"version": "v6", "created": "Sat, 24 Nov 2018 05:29:03 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Fairchild", "Geoffrey", ""], ["Tasseff", "Byron", ""], ["Khalsa", "Hari", ""], ["Generous", "Nicholas", ""], ["Daughton", "Ashlynn R.", ""], ["Velappan", "Nileena", ""], ["Priedhorsky", "Reid", ""], ["Deshpande", "Alina", ""]]}, {"id": "1805.00457", "submitter": "Marcelo Mendoza Mr.", "authors": "Ignacio Espinoza and Marcelo Mendoza and Pablo Ortega and Daniel\n  Rivera and Fernanda Weiss", "title": "Viscovery: Trend Tracking in Opinion Forums based on Dynamic Topic\n  Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Opinions in forums and social networks are released by millions of people due\nto the increasing number of users that use Web 2.0 platforms to opine about\nbrands and organizations. For enterprises or government agencies it is almost\nimpossible to track what people say producing a gap between user\nneeds/expectations and organizations actions. To bridge this gap we create\nViscovery, a platform for opinion summarization and trend tracking that is able\nto analyze a stream of opinions recovered from forums. To do this we use\ndynamic topic models, allowing to uncover the hidden structure of topics behind\nopinions, characterizing vocabulary dynamics. We extend dynamic topic models\nfor incremental learning, a key aspect needed in Viscovery for model updating\nin near-real time. In addition, we include in Viscovery sentiment analysis,\nallowing to separate positive/negative words for a specific topic at different\nlevels of granularity. Viscovery allows to visualize representative opinions\nand terms in each topic. At a coarse level of granularity, the dynamic of the\ntopics can be analyzed using a 2D topic embedding, suggesting longitudinal\ntopic merging or segmentation. In this paper we report our experience\ndeveloping this platform, sharing lessons learned and opportunities that arise\nfrom the use of sentiment analysis and topic modeling in real world\napplications.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2018 17:48:19 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Espinoza", "Ignacio", ""], ["Mendoza", "Marcelo", ""], ["Ortega", "Pablo", ""], ["Rivera", "Daniel", ""], ["Weiss", "Fernanda", ""]]}, {"id": "1805.00533", "submitter": "Ping Li", "authors": "Ping Li", "title": "Sign-Full Random Projections", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The method of 1-bit (\"sign-sign\") random projections has been a popular tool\nfor efficient search and machine learning on large datasets. Given two $D$-dim\ndata vectors $u$, $v\\in\\mathbb{R}^D$, one can generate $x = \\sum_{i=1}^D u_i\nr_i$, and $y = \\sum_{i=1}^D v_i r_i$, where $r_i\\sim N(0,1)$ iid. The\n\"collision probability\" is ${Pr}\\left(sgn(x)=sgn(y)\\right) =\n1-\\frac{\\cos^{-1}\\rho}{\\pi}$, where $\\rho = \\rho(u,v)$ is the cosine\nsimilarity.\n  We develop \"sign-full\" random projections by estimating $\\rho$ from (e.g.,)\nthe expectation $E(sgn(x)y)=\\sqrt{\\frac{2}{\\pi}} \\rho$, which can be further\nsubstantially improved by normalizing $y$. For nonnegative data, we recommend\nan interesting estimator based on $E\\left(y_- 1_{x\\geq 0} + y_+ 1_{x<0}\\right)$\nand its normalized version. The recommended estimator almost matches the\naccuracy of the (computationally expensive) maximum likelihood estimator. At\nhigh similarity ($\\rho\\rightarrow1$), the asymptotic variance of recommended\nestimator is only $\\frac{4}{3\\pi} \\approx 0.4$ of the estimator for sign-sign\nprojections. At small $k$ and high similarity, the improvement would be even\nmuch more substantial.\n", "versions": [{"version": "v1", "created": "Thu, 26 Apr 2018 08:41:21 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Li", "Ping", ""]]}, {"id": "1805.00791", "submitter": "Sean MacAvaney", "authors": "Sean MacAvaney, Andrew Yates, Arman Cohan, Luca Soldaini, Kai Hui,\n  Nazli Goharian, Ophir Frieder", "title": "Characterizing Question Facets for Complex Answer Retrieval", "comments": "4 pages; SIGIR 2018 Short Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex answer retrieval (CAR) is the process of retrieving answers to\nquestions that have multifaceted or nuanced answers. In this work, we present\ntwo novel approaches for CAR based on the observation that question facets can\nvary in utility: from structural (facets that can apply to many similar topics,\nsuch as 'History') to topical (facets that are specific to the question's\ntopic, such as the 'Westward expansion' of the United States). We first explore\na way to incorporate facet utility into ranking models during query term score\ncombination. We then explore a general approach to reform the structure of\nranking models to aid in learning of facet utility in the query-document term\nmatching phase. When we use our techniques with a leading neural ranker on the\nTREC CAR dataset, our methods rank first in the 2017 TREC CAR benchmark, and\nyield up to 26% higher performance than the next best method.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 13:24:20 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["MacAvaney", "Sean", ""], ["Yates", "Andrew", ""], ["Cohan", "Arman", ""], ["Soldaini", "Luca", ""], ["Hui", "Kai", ""], ["Goharian", "Nazli", ""], ["Frieder", "Ophir", ""]]}, {"id": "1805.00900", "submitter": "Micael Carvalho", "authors": "Micael Carvalho, R\\'emi Cad\\`ene, David Picard, Laure Soulier,\n  Matthieu Cord", "title": "Images & Recipes: Retrieval in the cooking context", "comments": "Published at DECOR / ICDE 2018. Extended version accepted at SIGIR\n  2018, available here: arXiv:1804.11146", "journal-ref": null, "doi": "10.1109/ICDEW.2018.00035", "report-no": null, "categories": "cs.AI cs.CL cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent advances in the machine learning community allowed different use cases\nto emerge, as its association to domains like cooking which created the\ncomputational cuisine. In this paper, we tackle the picture-recipe alignment\nproblem, having as target application the large-scale retrieval task (finding a\nrecipe given a picture, and vice versa). Our approach is validated on the\nRecipe1M dataset, composed of one million image-recipe pairs and additional\nclass information, for which we achieve state-of-the-art results.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 16:34:01 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Carvalho", "Micael", ""], ["Cad\u00e8ne", "R\u00e9mi", ""], ["Picard", "David", ""], ["Soulier", "Laure", ""], ["Cord", "Matthieu", ""]]}, {"id": "1805.00904", "submitter": "Benjamin Weggenmann", "authors": "Benjamin Weggenmann, Florian Kerschbaum", "title": "SynTF: Synthetic and Differentially Private Term Frequency Vectors for\n  Privacy-Preserving Text Mining", "comments": "This report is an extended version of our SIGIR'18 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text mining and information retrieval techniques have been developed to\nassist us with analyzing, organizing and retrieving documents with the help of\ncomputers. In many cases, it is desirable that the authors of such documents\nremain anonymous: Search logs can reveal sensitive details about a user,\ncritical articles or messages about a company or government might have severe\nor fatal consequences for a critic, and negative feedback in customer surveys\nmight negatively impact business relations if they are identified. Simply\nremoving personally identifying information from a document is, however,\ninsufficient to protect the writer's identity: Given some reference texts of\nsuspect authors, so-called authorship attribution methods can reidentfy the\nauthor from the text itself.\n  One of the most prominent models to represent documents in many common text\nmining and information retrieval tasks is the vector space model where each\ndocument is represented as a vector, typically containing its term frequencies\nor related quantities. We therefore propose an automated text anonymization\napproach that produces synthetic term frequency vectors for the input documents\nthat can be used in lieu of the original vectors. We evaluate our method on an\nexemplary text classification task and demonstrate that it only has a low\nimpact on its accuracy. In contrast, we show that our method strongly affects\nauthorship attribution techniques to the level that they become infeasible with\na much stronger decline in accuracy. Other than previous authorship obfuscation\nmethods, our approach is the first that fulfills differential privacy and hence\ncomes with a provable plausible deniability guarantee.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 16:55:38 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Weggenmann", "Benjamin", ""], ["Kerschbaum", "Florian", ""]]}, {"id": "1805.00977", "submitter": "Ludovik Coba <", "authors": "Ludovik Coba, Markus Zanker, Laurens Rook and Panagiotis Symeonidis", "title": "Exploring Users' Perception of Collaborative Explanation Styles", "comments": null, "journal-ref": null, "doi": "10.1109/CBI.2018.00017", "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering systems heavily depend on user feedback expressed in\nproduct ratings to select and rank items to recommend. In this study we explore\nhow users value different collaborative explanation styles following the\nuser-based or item-based paradigm. Furthermore, we explore how the\ncharacteristics of these rating summarizations, like the total number of\nratings and the mean rating value, influence the decisions of online users.\nResults, based on a choice-based conjoint experimental design, show that the\nmean indicator has a higher impact compared to the total number of ratings.\nFinally, we discuss how these empirical results can serve as an input to\ndeveloping algorithms that foster items with a, consequently, higher\nprobability of choice based on their rating summarizations or their\nexplainability due to these ratings when ranking recommendations.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 18:45:32 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Coba", "Ludovik", ""], ["Zanker", "Markus", ""], ["Rook", "Laurens", ""], ["Symeonidis", "Panagiotis", ""]]}, {"id": "1805.01138", "submitter": "Brit Youngmann", "authors": "Liron Allerhand, Brit Youngmann, Elad Yom-Tov and David Arkadir", "title": "Detecting Parkinson's Disease from interactions with a search engine: Is\n  expert knowledge sufficient?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parkinson's disease (PD) is a slowly progressing neurodegenerative disease\nwith early manifestation of motor signs. Recently, there has been a growing\ninterest in developing automatic tools that can assess motor function in PD\npatients. Here we show that mouse tracking data collected during people's\ninteraction with a search engine can be used to distinguish PD patients from\nsimilar, non-diseased users and present a methodology developed for the\ndiagnosis of PD from these data. A main challenge we address is the extraction\nof informative features from raw mouse tracking data. We do so in two\ncomplementary ways: First, we manually construct expert-recommended informative\nfeatures, aiming to identify abnormalities in motor behaviors. Second, we use\nan unsupervised representation learning technique to map these raw data to\nhigh-level features. Using all the extracted features, a Random Forest\nclassifier is then used to distinguish PD patients from controls, achieving an\nAUC of 0.92, while results using only expert-generated or auto-generated\nfeatures are 0.87 and 0.83, respectively. Our results indicate that mouse\ntracking data can help in detecting users at early stages of the disease, and\nthat both expert-generated features and unsupervised techniques for feature\ngeneration are required to achieve the best possible performance\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 06:54:45 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Allerhand", "Liron", ""], ["Youngmann", "Brit", ""], ["Yom-Tov", "Elad", ""], ["Arkadir", "David", ""]]}, {"id": "1805.01275", "submitter": "Diyah Puspitaningrum", "authors": "Diyah Puspitaningrum", "title": "cSELENE: Privacy Preserving Query Retrieval System on Heterogeneous\n  Cloud Data", "comments": "The First International Workshop on Learning From Limited or Noisy\n  Data for Information Retrieval (LND4IR), Ann Arbor, Michigan, USA, July 2018\n  (SIGIR 2018), 6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While working in collaborative team elsewhere sometimes the federated (huge)\ndata are from heterogeneous cloud vendors. It is not only about the data\nprivacy concern but also about how can those federated data can be querying\nfrom cloud directly in fast and securely way. Previous solution offered hybrid\ncloud between public and trusted private cloud. Another previous solution used\nencryption on MapReduce framework. But the challenge is we are working on\nheterogeneous clouds. In this paper, we present a novel technique for querying\nwith privacy concern.\n  Since we take execution time into account, our basic idea is to use the data\nmining model by partitioning the federated databases in order to reduce the\nsearch and query time. By using model of the database it means we use only the\nsummary or the very characteristic patterns of the database. Modeling is the\nPreserving Privacy Stage I, since by modeling the data is being symbolized. We\nimplement encryption on the database as preserving privacy Stage II. Our\nsystem, called \"cSELENE\" (stands for \"cloud SELENE\"), is designed to handle\nfederated data on heterogeneous clouds: AWS, Microsoft Azure, and Google Cloud\nPlatform with MapReduce technique.\n  In this paper we discuss preserving-privacy system and threat model, the\nformat of federated data, the parallel programming (GPU programming and\nshared/memory systems), the parallel and secure algorithm for data mining model\nin distributed cloud, the cloud infrastructure/architecture, and the UIX design\nof the cSELENE system. Other issues such as incremental method and the secure\ndesign of cloud architecture system (Virtual Machines across platform design)\nare still open to discuss. Our experiments should demonstrate the validity and\npracticality of the proposed high performance computing scheme.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 07:29:34 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Puspitaningrum", "Diyah", ""]]}, {"id": "1805.01334", "submitter": "Chenyan Xiong", "authors": "Chenyan Xiong and Zhengzhong Liu and Jamie Callan and Tie-Yan Liu", "title": "Towards Better Text Understanding and Retrieval through Kernel Entity\n  Salience Modeling", "comments": null, "journal-ref": "In proceedings of SIGIR 2018", "doi": "10.1145/3209978.3209982", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a Kernel Entity Salience Model (KESM) that improves text\nunderstanding and retrieval by better estimating entity salience (importance)\nin documents. KESM represents entities by knowledge enriched distributed\nrepresentations, models the interactions between entities and words by kernels,\nand combines the kernel scores to estimate entity salience. The whole model is\nlearned end-to-end using entity salience labels. The salience model also\nimproves ad hoc search accuracy, providing effective ranking features by\nmodeling the salience of query entities in candidate documents. Our experiments\non two entity salience corpora and two TREC ad hoc search datasets demonstrate\nthe effectiveness of KESM over frequency-based and feature-based methods. We\nalso provide examples showing how KESM conveys its text understanding ability\nlearned from entity salience to search.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 14:46:12 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Xiong", "Chenyan", ""], ["Liu", "Zhengzhong", ""], ["Callan", "Jamie", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1805.01359", "submitter": "Simon Gottschalk", "authors": "Simon Gottschalk, Elena Demidova", "title": "EventKG+TL: Creating Cross-Lingual Timelines from an Event-Centric\n  Knowledge Graph", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-98192-5_31", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The provision of multilingual event-centric temporal knowledge graphs such as\nEventKG enables structured access to representations of a large number of\nhistorical and contemporary events in a variety of language contexts. Timelines\nprovide an intuitive way to facilitate an overview of events related to a query\nentity - i.e., an entity or an event of user interest - over a certain period\nof time. In this paper, we present EventKG+TL - a novel system that generates\ncross-lingual event timelines using EventKG and facilitates an overview of the\nlanguage-specific event relevance and popularity along with the cross-lingual\ndifferences.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 15:12:35 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2020 12:54:08 GMT"}], "update_date": "2020-12-07", "authors_parsed": [["Gottschalk", "Simon", ""], ["Demidova", "Elena", ""]]}, {"id": "1805.01547", "submitter": "Kevin Buchin", "authors": "Kevin Buchin, Anne Driemel, Joachim Gudmundsson, Michael Horton, Irina\n  Kostitsyna, Maarten L\\\"offler and Martijn Struijs", "title": "Approximating $(k,\\ell)$-center clustering for curves", "comments": "24 pages; results on minimum-enclosing ball added, additional author\n  added, general revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Euclidean $k$-center problem is a classical problem that has been\nextensively studied in computer science. Given a set $\\mathcal{G}$ of $n$\npoints in Euclidean space, the problem is to determine a set $\\mathcal{C}$ of\n$k$ centers (not necessarily part of $\\mathcal{G}$) such that the maximum\ndistance between a point in $\\mathcal{G}$ and its nearest neighbor in\n$\\mathcal{C}$ is minimized. In this paper we study the corresponding\n$(k,\\ell)$-center problem for polygonal curves under the Fr\\'echet distance,\nthat is, given a set $\\mathcal{G}$ of $n$ polygonal curves in $\\mathbb{R}^d$,\neach of complexity $m$, determine a set $\\mathcal{C}$ of $k$ polygonal curves\nin $\\mathbb{R}^d$, each of complexity $\\ell$, such that the maximum Fr\\'echet\ndistance of a curve in $\\mathcal{G}$ to its closest curve in $\\mathcal{C}$ is\nminimized. In this paper, we substantially extend and improve the known\napproximation bounds for curves in dimension $2$ and higher. We show that, if\n$\\ell$ is part of the input, then there is no polynomial-time approximation\nscheme unless $\\mathsf{P}=\\mathsf{NP}$. Our constructions yield different\nbounds for one and two-dimensional curves and the discrete and continuous\nFr\\'echet distance. In the case of the discrete Fr\\'echet distance on\ntwo-dimensional curves, we show hardness of approximation within a factor close\nto $2.598$. This result also holds when $k=1$, and the $\\mathsf{NP}$-hardness\nextends to the case that $\\ell=\\infty$, i.e., for the problem of computing the\nminimum-enclosing ball under the Fr\\'echet distance. Finally, we observe that a\ncareful adaptation of Gonzalez' algorithm in combination with a curve\nsimplification yields a $3$-approximation in any dimension, provided that an\noptimal simplification can be computed exactly. We conclude that our\napproximation bounds are close to being tight.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 21:32:41 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 15:25:36 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Buchin", "Kevin", ""], ["Driemel", "Anne", ""], ["Gudmundsson", "Joachim", ""], ["Horton", "Michael", ""], ["Kostitsyna", "Irina", ""], ["L\u00f6ffler", "Maarten", ""], ["Struijs", "Martijn", ""]]}, {"id": "1805.01597", "submitter": "Christophe Van Gysel", "authors": "Christophe Van Gysel, Maarten de Rijke", "title": "Pytrec_eval: An Extremely Fast Python Interface to trec_eval", "comments": "SIGIR '18. The 41st International ACM SIGIR Conference on Research &\n  Development in Information Retrieval", "journal-ref": null, "doi": "10.1145/3209978.3210065", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce pytrec_eval, a Python interface to the tree_eval information\nretrieval evaluation toolkit. pytrec_eval exposes the reference implementations\nof trec_eval within Python as a native extension. We show that pytrec_eval is\naround one order of magnitude faster than invoking trec_eval as a sub process\nfrom within Python. Compared to a native Python implementation of NDCG,\npytrec_eval is twice as fast for practically-sized rankings. Finally, we\ndemonstrate its effectiveness in an application where pytrec_eval is combined\nwith Pyndri and the OpenAI Gym where query expansion is learned using\nQ-learning.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 03:37:03 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2018 08:50:30 GMT"}], "update_date": "2018-06-06", "authors_parsed": [["Van Gysel", "Christophe", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1805.01788", "submitter": "Asia Biega", "authors": "Asia J. Biega, Krishna P. Gummadi, Gerhard Weikum", "title": "Equity of Attention: Amortizing Individual Fairness in Rankings", "comments": "Accepted to SIGIR 2018", "journal-ref": null, "doi": "10.1145/3209978.3210063", "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rankings of people and items are at the heart of selection-making,\nmatch-making, and recommender systems, ranging from employment sites to sharing\neconomy platforms. As ranking positions influence the amount of attention the\nranked subjects receive, biases in rankings can lead to unfair distribution of\nopportunities and resources, such as jobs or income.\n  This paper proposes new measures and mechanisms to quantify and mitigate\nunfairness from a bias inherent to all rankings, namely, the position bias,\nwhich leads to disproportionately less attention being paid to low-ranked\nsubjects. Our approach differs from recent fair ranking approaches in two\nimportant ways. First, existing works measure unfairness at the level of\nsubject groups while our measures capture unfairness at the level of individual\nsubjects, and as such subsume group unfairness. Second, as no single ranking\ncan achieve individual attention fairness, we propose a novel mechanism that\nachieves amortized fairness, where attention accumulated across a series of\nrankings is proportional to accumulated relevance.\n  We formulate the challenge of achieving amortized individual fairness subject\nto constraints on ranking quality as an online optimization problem and show\nthat it can be solved as an integer linear program. Our experimental evaluation\nreveals that unfair attention distribution in rankings can be substantial, and\ndemonstrates that our method can improve individual fairness while retaining\nhigh ranking quality.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 13:58:48 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Biega", "Asia J.", ""], ["Gummadi", "Krishna P.", ""], ["Weikum", "Gerhard", ""]]}, {"id": "1805.01952", "submitter": "Ehsan Kamalloo", "authors": "Ehsan Kamalloo and Davood Rafiei", "title": "A Coherent Unsupervised Model for Toponym Resolution", "comments": "9 pages (+1 page reference), WWW '18 Proceedings of the 2018 World\n  Wide Web Conference", "journal-ref": null, "doi": "10.1145/3178876.3186027", "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Toponym Resolution, the task of assigning a location mention in a document to\na geographic referent (i.e., latitude/longitude), plays a pivotal role in\nanalyzing location-aware content. However, the ambiguities of natural language\nand a huge number of possible interpretations for toponyms constitute\ninsurmountable hurdles for this task. In this paper, we study the problem of\ntoponym resolution with no additional information other than a gazetteer and no\ntraining data. We demonstrate that a dearth of large enough annotated data\nmakes supervised methods less capable of generalizing. Our proposed method\nestimates the geographic scope of documents and leverages the connections\nbetween nearby place names as evidence to resolve toponyms. We explore the\ninteractions between multiple interpretations of mentions and the relationships\nbetween different toponyms in a document to build a model that finds the most\ncoherent resolution. Our model is evaluated on three news corpora, two from the\nliterature and one collected and annotated by us; then, we compare our methods\nto the state-of-the-art unsupervised and supervised techniques. We also examine\nthree commercial products including Reuters OpenCalais, Yahoo! YQL Placemaker,\nand Google Cloud Natural Language API. The evaluation shows that our method\noutperforms the unsupervised technique as well as Reuters OpenCalais and Google\nCloud Natural Language API on all three corpora; also, our method shows a\nperformance close to that of the state-of-the-art supervised method and\noutperforms it when the test data has 40% or more toponyms that are not seen in\nthe training data.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2018 22:31:33 GMT"}, {"version": "v2", "created": "Tue, 8 May 2018 22:21:53 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Kamalloo", "Ehsan", ""], ["Rafiei", "Davood", ""]]}, {"id": "1805.02184", "submitter": "Sagar Uprety Mr.", "authors": "Sagar Uprety and Yi Su and Dawei Song and Jingfei Li", "title": "Modeling Multidimensional User Relevance in IR using Vector Spaces", "comments": null, "journal-ref": null, "doi": "10.1145/3209978.3210130", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been shown that relevance judgment of documents is influenced by\nmultiple factors beyond topicality. Some multidimensional user relevance models\n(MURM) proposed in literature have investigated the impact of different\ndimensions of relevance on user judgment. Our hypothesis is that a user might\ngive more importance to certain relevance dimensions in a session which might\nchange dynamically as the session progresses. This motivates the need to\ncapture the weights of different relevance dimensions using feedback and build\na model to rank documents for subsequent queries according to these weights. We\npropose a geometric model inspired by the mathematical framework of Quantum\ntheory to capture the user's importance given to each dimension of relevance\nand test our hypothesis on data from a web search engine and TREC Session\ntrack.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 10:15:16 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Uprety", "Sagar", ""], ["Su", "Yi", ""], ["Song", "Dawei", ""], ["Li", "Jingfei", ""]]}, {"id": "1805.02211", "submitter": "Mohammad Aliannejadi", "authors": "Mohammad Aliannejadi and Hamed Zamani and Fabio Crestani and W. Bruce\n  Croft", "title": "Target Apps Selection: Towards a Unified Search Framework for Mobile\n  Devices", "comments": "To appear at SIGIR 2018", "journal-ref": null, "doi": "10.1145/3209978.3210039", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent growth of conversational systems and intelligent assistants\nsuch as Apple Siri and Google Assistant, mobile devices are becoming even more\npervasive in our lives. As a consequence, users are getting engaged with the\nmobile apps and frequently search for an information need in their apps.\nHowever, users cannot search within their apps through their intelligent\nassistants. This requires a unified mobile search framework that identifies the\ntarget app(s) for the user's query, submits the query to the app(s), and\npresents the results to the user. In this paper, we take the first step forward\ntowards developing unified mobile search. In more detail, we introduce and\nstudy the task of target apps selection, which has various potential real-world\napplications. To this aim, we analyze attributes of search queries as well as\nuser behaviors, while searching with different mobile apps. The analyses are\ndone based on thousands of queries that we collected through crowdsourcing. We\nfinally study the performance of state-of-the-art retrieval models for this\ntask and propose two simple yet effective neural models that significantly\noutperform the baselines. Our neural approaches are based on learning\nhigh-dimensional representations for mobile apps. Our analyses and experiments\nsuggest specific future directions in this research area.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 13:40:38 GMT"}, {"version": "v2", "created": "Mon, 14 May 2018 22:40:58 GMT"}, {"version": "v3", "created": "Fri, 13 Jul 2018 12:56:46 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Aliannejadi", "Mohammad", ""], ["Zamani", "Hamed", ""], ["Crestani", "Fabio", ""], ["Croft", "W. Bruce", ""]]}, {"id": "1805.02232", "submitter": "Han Liu", "authors": "Han Liu, Xiangnan He, Fuli Feng, Liqiang Nie, Rui Liu, Hanwang Zhang", "title": "Discrete Factorization Machines for Fast Feature-based Recommendation", "comments": "Appeared in IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User and item features of side information are crucial for accurate\nrecommendation. However, the large number of feature dimensions, e.g., usually\nlarger than 10^7, results in expensive storage and computational cost. This\nprohibits fast recommendation especially on mobile applications where the\ncomputational resource is very limited. In this paper, we develop a generic\nfeature-based recommendation model, called Discrete Factorization Machine\n(DFM), for fast and accurate recommendation. DFM binarizes the real-valued\nmodel parameters (e.g., float32) of every feature embedding into binary codes\n(e.g., boolean), and thus supports efficient storage and fast user-item score\ncomputation. To avoid the severe quantization loss of the binarization, we\npropose a convergent updating rule that resolves the challenging discrete\noptimization of DFM. Through extensive experiments on two real-world datasets,\nwe show that 1) DFM consistently outperforms state-of-the-art binarized\nrecommendation models, and 2) DFM shows very competitive performance compared\nto its real-valued version (FM), demonstrating the minimized quantization loss.\nThis work is accepted by IJCAI 2018.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 15:24:54 GMT"}, {"version": "v2", "created": "Sun, 13 May 2018 09:08:36 GMT"}, {"version": "v3", "created": "Wed, 19 Sep 2018 08:56:16 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Liu", "Han", ""], ["He", "Xiangnan", ""], ["Feng", "Fuli", ""], ["Nie", "Liqiang", ""], ["Liu", "Rui", ""], ["Zhang", "Hanwang", ""]]}, {"id": "1805.02276", "submitter": "Nikolaos Polatidis Dr", "authors": "Elias Pimenidis, Nikolaos Polatidis, Haralambos Mouratidis", "title": "Mobile recommender systems: Identifying the major concepts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper identifies the factors that have an impact on mobile recommender\nsystems. Recommender systems have become a technology that has been widely used\nby various online applications in situations where there is an information\noverload problem. Numerous applications such as e-Commerce, video platforms and\nsocial networks provide personalized recommendations to their users and this\nhas improved the user experience and vendor revenues. The development of\nrecommender systems has been focused mostly on the proposal of new algorithms\nthat provide more accurate recommendations. However, the use of mobile devices\nand the rapid growth of the internet and networking infrastructure has brought\nthe necessity of using mobile recommender systems. The links between web and\nmobile recommender systems are described along with how the recommendations in\nmobile environments can be improved. This work is focused on identifying the\nlinks between web and mobile recommender systems and to provide solid future\ndirections that aim to lead in a more integrated mobile recommendation domain.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2018 20:46:55 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Pimenidis", "Elias", ""], ["Polatidis", "Nikolaos", ""], ["Mouratidis", "Haralambos", ""]]}, {"id": "1805.02334", "submitter": "Damiano Spina", "authors": "Enrique Amig\\'o, Damiano Spina and Jorge Carrillo-de-Albornoz", "title": "An Axiomatic Analysis of Diversity Evaluation Metrics: Introducing the\n  Rank-Biased Utility Metric", "comments": "Original version: 10 pages. Preprint of full paper to appear at\n  SIGIR'18: The 41st International ACM SIGIR Conference on Research &\n  Development in Information Retrieval, July 8-12, 2018, Ann Arbor, MI, USA.\n  ACM, New York, NY, USA", "journal-ref": null, "doi": "10.1145/3209978.3210024", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many evaluation metrics have been defined to evaluate the effectiveness\nad-hoc retrieval and search result diversification systems. However, it is\noften unclear which evaluation metric should be used to analyze the performance\nof retrieval systems given a specific task. Axiomatic analysis is an\ninformative mechanism to understand the fundamentals of metrics and their\nsuitability for particular scenarios. In this paper, we define a\nconstraint-based axiomatic framework to study the suitability of existing\nmetrics in search result diversification scenarios. The analysis informed the\ndefinition of Rank-Biased Utility (RBU) -- an adaptation of the well-known\nRank-Biased Precision metric -- that takes into account redundancy and the user\neffort associated to the inspection of documents in the ranking. Our\nexperiments over standard diversity evaluation campaigns show that the proposed\nmetric captures quality criteria reflected by different metrics, being suitable\nin the absence of knowledge about particular features of the scenario under\nstudy.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 03:50:11 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 02:22:55 GMT"}, {"version": "v3", "created": "Sun, 19 Aug 2018 07:38:20 GMT"}], "update_date": "2018-08-21", "authors_parsed": [["Amig\u00f3", "Enrique", ""], ["Spina", "Damiano", ""], ["Carrillo-de-Albornoz", "Jorge", ""]]}, {"id": "1805.02343", "submitter": "Xiangyu Zhao", "authors": "Xiangyu Zhao, Long Xia, Liang Zhang, Zhuoye Ding, Dawei Yin, Jiliang\n  Tang", "title": "Deep Reinforcement Learning for Page-wise Recommendations", "comments": "arXiv admin note: text overlap with arXiv:1802.06501", "journal-ref": null, "doi": "10.1145/3240323.3240374", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems can mitigate the information overload problem by\nsuggesting users' personalized items. In real-world recommendations such as\ne-commerce, a typical interaction between the system and its users is -- users\nare recommended a page of items and provide feedback; and then the system\nrecommends a new page of items. To effectively capture such interaction for\nrecommendations, we need to solve two key problems -- (1) how to update\nrecommending strategy according to user's \\textit{real-time feedback}, and 2)\nhow to generate a page of items with proper display, which pose tremendous\nchallenges to traditional recommender systems. In this paper, we study the\nproblem of page-wise recommendations aiming to address aforementioned two\nchallenges simultaneously. In particular, we propose a principled approach to\njointly generate a set of complementary items and the corresponding strategy to\ndisplay them in a 2-D page; and propose a novel page-wise recommendation\nframework based on deep reinforcement learning, DeepPage, which can optimize a\npage of items with proper display based on real-time feedback from users. The\nexperimental results based on a real-world e-commerce dataset demonstrate the\neffectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 04:58:37 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2018 02:23:38 GMT"}], "update_date": "2018-08-13", "authors_parsed": [["Zhao", "Xiangyu", ""], ["Xia", "Long", ""], ["Zhang", "Liang", ""], ["Ding", "Zhuoye", ""], ["Yin", "Dawei", ""], ["Tang", "Jiliang", ""]]}, {"id": "1805.02356", "submitter": "Jieli Zhou", "authors": "Xin Qian, Ziyi Zhong, Jieli Zhou", "title": "Multimodal Machine Translation with Reinforcement Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.MA cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multimodal machine translation is one of the applications that integrates\ncomputer vision and language processing. It is a unique task given that in the\nfield of machine translation, many state-of-the-arts algorithms still only\nemploy textual information. In this work, we explore the effectiveness of\nreinforcement learning in multimodal machine translation. We present a novel\nalgorithm based on the Advantage Actor-Critic (A2C) algorithm that specifically\ncater to the multimodal machine translation task of the EMNLP 2018 Third\nConference on Machine Translation (WMT18). We experiment our proposed algorithm\non the Multi30K multilingual English-German image description dataset and the\nFlickr30K image entity dataset. Our model takes two channels of inputs, image\nand text, uses translation evaluation metrics as training rewards, and achieves\nbetter results than supervised learning MLE baseline models. Furthermore, we\ndiscuss the prospects and limitations of using reinforcement learning for\nmachine translation. Our experiment results suggest a promising reinforcement\nlearning solution to the general task of multimodal sequence to sequence\nlearning.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 06:12:32 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Qian", "Xin", ""], ["Zhong", "Ziyi", ""], ["Zhou", "Jieli", ""]]}, {"id": "1805.02393", "submitter": "Nikos Voskarides", "authors": "Nikos Voskarides, and Edgar Meij, and Ridho Reinanda, and Abhinav\n  Khaitan, and Miles Osborne, and Giorgio Stefanoni, and Prabhanjan Kambadur,\n  and Maarten de Rijke", "title": "Weakly-supervised Contextualization of Knowledge Graph Facts", "comments": "SIGIR 2018: 41st international ACM SIGIR conference on Research and\n  Development in Information Retrieval. July version: corrected typos", "journal-ref": null, "doi": "10.1145/3209978.3210031", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Knowledge graphs (KGs) model facts about the world, they consist of nodes\n(entities such as companies and people) that are connected by edges (relations\nsuch as founderOf). Facts encoded in KGs are frequently used by search\napplications to augment result pages. When presenting a KG fact to the user,\nproviding other facts that are pertinent to that main fact can enrich the user\nexperience and support exploratory information needs. KG fact contextualization\nis the task of augmenting a given KG fact with additional and useful KG facts.\nThe task is challenging because of the large size of KGs, discovering other\nrelevant facts even in a small neighborhood of the given fact results in an\nenormous amount of candidates. We introduce a neural fact contextualization\nmethod (NFCM) to address the KG fact contextualization task. NFCM first\ngenerates a set of candidate facts in the neighborhood of a given fact and then\nranks the candidate facts using a supervised learning to rank model. The\nranking model combines features that we automatically learn from data and that\nrepresent the query-candidate facts with a set of hand-crafted features we\ndevised or adjusted for this task. In order to obtain the annotations required\nto train the learning to rank model at scale, we generate training data\nautomatically using distant supervision on a large entity-tagged text corpus.\nWe show that ranking functions learned on this data are effective at\ncontextualizing KG facts. Evaluation using human assessors shows that it\nsignificantly outperforms several competitive baselines.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 08:22:57 GMT"}, {"version": "v2", "created": "Sun, 8 Jul 2018 21:04:52 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Voskarides", "Nikos", ""], ["Meij", "Edgar", ""], ["Reinanda", "Ridho", ""], ["Khaitan", "Abhinav", ""], ["Osborne", "Miles", ""], ["Stefanoni", "Giorgio", ""], ["Kambadur", "Prabhanjan", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1805.02399", "submitter": "Nilavra Bhattacharya", "authors": "Nilavra Bhattacharya, Jacek Gwizdka", "title": "Relating Eye-Tracking Measures With Changes In Knowledge on Search Tasks", "comments": "ACM Symposium on Eye Tracking Research and Applications (ETRA), June\n  14-17, 2018, Warsaw, Poland", "journal-ref": "Proceedings of the 2018 ACM Symposium on Eye Tracking Research &\n  Applications", "doi": "10.1145/3204493.3204579", "report-no": null, "categories": "cs.HC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We conducted an eye-tracking study where 30 participants performed searches\non the web. We measured their topical knowledge before and after each task.\nTheir eye-fixations were labelled as \"reading\" or \"scanning\". The series of\nreading fixations in a line, called \"reading-sequences\" were characterized by\ntheir length in pixels, fixation duration, and the number of fixations making\nup the sequence. We hypothesize that differences in knowledge-change of\nparticipants are reflected in their eye-tracking measures related to reading.\nOur results show that the participants with higher change in knowledge differ\nsignificantly in terms of their total reading-sequence-length,\nreading-sequence-duration, and number of reading fixations, when compared to\nparticipants with lower knowledge-change.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 08:33:59 GMT"}], "update_date": "2019-08-16", "authors_parsed": [["Bhattacharya", "Nilavra", ""], ["Gwizdka", "Jacek", ""]]}, {"id": "1805.02404", "submitter": "Harrie Oosterhuis", "authors": "Harrie Oosterhuis and Maarten de Rijke", "title": "Ranking for Relevance and Display Preferences in Complex Presentation\n  Layouts", "comments": null, "journal-ref": null, "doi": "10.1145/3209978.3209992", "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning to Rank has traditionally considered settings where given the\nrelevance information of objects, the desired order in which to rank the\nobjects is clear. However, with today's large variety of users and layouts this\nis not always the case. In this paper, we consider so-called complex ranking\nsettings where it is not clear what should be displayed, that is, what the\nrelevant items are, and how they should be displayed, that is, where the most\nrelevant items should be placed. These ranking settings are complex as they\ninvolve both traditional ranking and inferring the best display order. Existing\nlearning to rank methods cannot handle such complex ranking settings as they\nassume that the display order is known beforehand. To address this gap we\nintroduce a novel Deep Reinforcement Learning method that is capable of\nlearning complex rankings, both the layout and the best ranking given the\nlayout, from weak reward signals. Our proposed method does so by selecting\ndocuments and positions sequentially, hence it ranks both the documents and\npositions, which is why we call it the Double-Rank Model (DRM). Our experiments\nshow that DRM outperforms all existing methods in complex ranking settings,\nthus it leads to substantial ranking improvements in cases where the display\norder is not known a priori.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2018 08:48:18 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Oosterhuis", "Harrie", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1805.02811", "submitter": "Xiaohui Xie", "authors": "Xiaohui Xie, Jiaxin Mao, Maarten de Rijke, Ruizhe Zhang, Min Zhang,\n  Shaoping Ma", "title": "Constructing an Interaction Behavior Model for Web Image Search", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User interaction behavior is a valuable source of implicit relevance\nfeedback. In Web image search a different type of search result presentation is\nused than in general Web search, which leads to different interaction\nmechanisms and user behavior. For example, image search results are\nself-contained, so that users do not need to click the results to view the\nlanding page as in general Web search, which generates sparse click data. Also,\ntwo-dimensional result placement instead of a linear result list makes browsing\nbehaviors more complex. Thus, it is hard to apply standard user behavior models\n(e.g., click models) developed for general Web search to Web image search.\n  In this paper, we conduct a comprehensive image search user behavior analysis\nusing data from a lab-based user study as well as data from a commercial search\nlog. We then propose a novel interaction behavior model, called grid-based user\nbrowsing model (GUBM), whose design is motivated by observations from our data\nanalysis. GUBM can both capture users' interaction behavior, including cursor\nhovering, and alleviate position bias. The advantages of GUBM are two-fold: (1)\nIt is based on an unsupervised learning method and does not need manually\nannotated data for training. (2) It is based on user interaction features on\nsearch engine result pages (SERPs) and is easily transferable to other\nscenarios that have a grid-based interface such as video search engines. We\nconduct extensive experiments to test the performance of our model using a\nlarge-scale commercial image search log. Experimental results show that in\nterms of behavior prediction (perplexity), and topical relevance and image\nquality (normalized discounted cumulative gain (NDCG)), GUBM outperforms\nstate-of-the-art baseline models as well as the original ranking. We make the\nimplementation of GUBM and related datasets publicly available for future\nstudies.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 02:51:46 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Xie", "Xiaohui", ""], ["Mao", "Jiaxin", ""], ["de Rijke", "Maarten", ""], ["Zhang", "Ruizhe", ""], ["Zhang", "Min", ""], ["Ma", "Shaoping", ""]]}, {"id": "1805.02816", "submitter": "Wanyu Chen", "authors": "Wanyu Chen, Fei Cai, Honghui Chen, Maarten de Rijke", "title": "Attention-based Hierarchical Neural Query Suggestion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query suggestions help users of a search engine to refine their queries.\nPrevious work on query suggestion has mainly focused on incorporating directly\nobservable features such as query co-occurrence and semantic similarity. The\nstructure of such features is often set manually, as a result of which hidden\ndependencies between queries and users may be ignored. We propose an AHNQS\nmodel that combines a hierarchical structure with a session-level neural\nnetwork and a user-level neural network to model the short- and long-term\nsearch history of a user. An attention mechanism is used to capture user\npreferences. We quantify the improvements of AHNQS over state-of-the-art\nRNN-based query suggestion baselines on the AOL query log dataset, with\nimprovements of up to 21.86% and 22.99% in terms of MRR@10 and Recall@10,\nrespectively, over the state-of-the-art; improvements are especially large for\nshort sessions.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 03:15:05 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Chen", "Wanyu", ""], ["Cai", "Fei", ""], ["Chen", "Honghui", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1805.02856", "submitter": "Yi Tay", "authors": "Yi Tay, Luu Anh Tuan, Siu Cheung Hui, Jian Su", "title": "Reasoning with Sarcasm by Reading In-between", "comments": "Accepted to ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sarcasm is a sophisticated speech act which commonly manifests on social\ncommunities such as Twitter and Reddit. The prevalence of sarcasm on the social\nweb is highly disruptive to opinion mining systems due to not only its tendency\nof polarity flipping but also usage of figurative language. Sarcasm commonly\nmanifests with a contrastive theme either between positive-negative sentiments\nor between literal-figurative scenarios. In this paper, we revisit the notion\nof modeling contrast in order to reason with sarcasm. More specifically, we\npropose an attention-based neural model that looks in-between instead of\nacross, enabling it to explicitly model contrast and incongruity. We conduct\nextensive experiments on six benchmark datasets from Twitter, Reddit and the\nInternet Argument Corpus. Our proposed model not only achieves state-of-the-art\nperformance on all datasets but also enjoys improved interpretability.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 06:46:03 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Tay", "Yi", ""], ["Tuan", "Luu Anh", ""], ["Hui", "Siu Cheung", ""], ["Su", "Jian", ""]]}, {"id": "1805.02983", "submitter": "Younghun Song", "authors": "Younghun Song, Jae-Gil Lee", "title": "Augmenting Recurrent Neural Networks with High-Order User-Contextual\n  Preference for Session-Based Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The recent adoption of recurrent neural networks (RNNs) for session modeling\nhas yielded substantial performance gains compared to previous approaches. In\nterms of context-aware session modeling, however, the existing RNN-based models\nare limited in that they are not designed to explicitly model rich static\nuser-side contexts (e.g., age, gender, location). Therefore, in this paper, we\nexplore the utility of explicit user-side context modeling for RNN session\nmodels. Specifically, we propose an augmented RNN (ARNN) model that extracts\nhigh-order user-contextual preference using the product-based neural network\n(PNN) in order to augment any existing RNN session model. Evaluation results\nshow that our proposed model outperforms the baseline RNN session model by a\nlarge margin when rich user-side contexts are available.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 12:44:12 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Song", "Younghun", ""], ["Lee", "Jae-Gil", ""]]}, {"id": "1805.03002", "submitter": "Shuai Zhang", "authors": "Shuai Zhang, Lina Yao, Aixin Sun, Sen Wang, Guodong Long, Manqing Dong", "title": "NeuRec: On Nonlinear Transformation for Personalized Ranking", "comments": "Accepted at IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modeling user-item interaction patterns is an important task for personalized\nrecommendations. Many recommender systems are based on the assumption that\nthere exists a linear relationship between users and items while neglecting the\nintricacy and non-linearity of real-life historical interactions. In this\npaper, we propose a neural network based recommendation model (NeuRec) that\nuntangles the complexity of user-item interactions and establishes an\nintegrated network to combine non-linear transformation with latent factors. We\nfurther design two variants of NeuRec: user-based NeuRec and item-based NeuRec,\nby concentrating on different aspects of the interaction matrix. Extensive\nexperiments on four real-world datasets demonstrated their superior\nperformances on personalized ranking task.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 13:26:53 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 14:44:04 GMT"}, {"version": "v3", "created": "Wed, 11 Jul 2018 05:07:43 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Zhang", "Shuai", ""], ["Yao", "Lina", ""], ["Sun", "Aixin", ""], ["Wang", "Sen", ""], ["Long", "Guodong", ""], ["Dong", "Manqing", ""]]}, {"id": "1805.03067", "submitter": "Dominik Kowald PhD", "authors": "Dominik Kowald and Elisabeth Lex", "title": "Overcoming the Imbalance Between Tag Recommendation Approaches and\n  Real-World Folksonomy Structures with Cognitive-Inspired Algorithms", "comments": "Presented at the European Symposium for Computational Social Sciences", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study the imbalance between current state-of-the-art tag\nrecommendation algorithms and the folksonomy structures of real-world social\ntagging systems. While algorithms such as FolkRank are designed for dense\nfolksonomy structures, most social tagging systems exhibit a sparse nature. To\novercome this imbalance, we show that cognitive-inspired algorithms, which\nmodel the tag vocabulary of a user in a cognitive-plausible way, can be\nhelpful. Our present approach does this via implementing the activation\nequation of the cognitive architecture ACT-R, which determines the usefulness\nof units in human memory (e.g., tags). In this sense, our long-term research\ngoal is to design hybrid recommendation approaches, which combine the\nadvantages of both worlds in order to adapt to the current setting (i.e.,\nsparse vs. dense ones).\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2018 14:47:18 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Kowald", "Dominik", ""], ["Lex", "Elisabeth", ""]]}, {"id": "1805.03352", "submitter": "Yongfeng Zhang", "authors": "Qingyao Ai, Vahid Azizi, Xu Chen, Yongfeng Zhang", "title": "Learning Heterogeneous Knowledge Base Embeddings for Explainable\n  Recommendation", "comments": "Accepted in Algorithms 11(9):137, 2018, Special Issue on\n  Collaborative Filtering and Recommender Systems", "journal-ref": "Algorithms 11(9):137, 2018, Special Issue on Collaborative\n  Filtering and Recommender Systems (Code is available at\n  https://github.com/evison/KBE4ExplainableRecommendation)", "doi": "10.3390/a11090137", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Providing model-generated explanations in recommender systems is important to\nuser experience. State-of-the-art recommendation algorithms - especially\ncollaborative filtering (CF)-based approaches with shallow or deep models -\nusually work with various unstructured information sources for recommendation,\nsuch as textual reviews, visual images, and various implicit or explicit\nfeedbacks. Though structured knowledge bases were considered in content-based\napproaches, they have been largely ignored recently due to the research focus\non CF approaches. However, structured knowledge exhibit unique advantages in\npersonalized recommendation systems. When the explicit knowledge about users\nand items is considered for recommendation, the system could provide highly\ncustomized recommendations based on users' historical behaviors and the\nknowledge is helpful for providing informed explanations regarding the\nrecommended items. A great challenge for using knowledge bases for\nrecommendation is how to integrate large-scale structured data, while taking\nadvantage of collaborative filtering for highly accurate performance. Recent\nachievements in knowledge-base embedding (KBE) sheds light on this problem,\nwhich makes it possible to learn user and item representations while preserving\nthe structure of their relationship with external knowledge for explanation. In\nthis work, we propose to explain knowledge-base embeddings for explainable\nrecommendation. Specifically, we propose a knowledge-base representation\nlearning framework to embed heterogeneous entities for recommendation, and\nbased on the embedded knowledge base, a soft matching algorithm is proposed to\ngenerate personalized explanations for the recommended items. Experimental\nresults on real-world e-commerce datasets verified the superior recommendation\nperformance and the explainability power of our approach compared with\nstate-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 02:32:19 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2018 16:15:26 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Ai", "Qingyao", ""], ["Azizi", "Vahid", ""], ["Chen", "Xu", ""], ["Zhang", "Yongfeng", ""]]}, {"id": "1805.03403", "submitter": "Bhaskar Mitra", "authors": "Daniel Cohen, Bhaskar Mitra, Katja Hofmann and W. Bruce Croft", "title": "Cross Domain Regularization for Neural Ranking Models Using Adversarial\n  Learning", "comments": "SIGIR 2018 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlike traditional learning to rank models that depend on hand-crafted\nfeatures, neural representation learning models learn higher level features for\nthe ranking task by training on large datasets. Their ability to learn new\nfeatures directly from the data, however, may come at a price. Without any\nspecial supervision, these models learn relationships that may hold only in the\ndomain from which the training data is sampled, and generalize poorly to\ndomains not observed during training. We study the effectiveness of adversarial\nlearning as a cross domain regularizer in the context of the ranking task. We\nuse an adversarial discriminator and train our neural ranking model on a small\nset of domains. The discriminator provides a negative feedback signal to\ndiscourage the model from learning domain specific representations. Our\nexperiments show consistently better performance on held out domains in the\npresence of the adversarial discriminator---sometimes up to 30% on precision@1.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 08:08:54 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Cohen", "Daniel", ""], ["Mitra", "Bhaskar", ""], ["Hofmann", "Katja", ""], ["Croft", "W. Bruce", ""]]}, {"id": "1805.03411", "submitter": "Alexey Borisov", "authors": "Alexey Borisov, Martijn Wardenaar, Ilya Markov and Maarten de Rijke", "title": "A Click Sequence Model for Web Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Getting a better understanding of user behavior is important for advancing\ninformation retrieval systems. Existing work focuses on modeling and predicting\nsingle interaction events, such as clicks. In this paper, we for the first time\nfocus on modeling and predicting sequences of interaction events. And in\nparticular, sequences of clicks.\n  We formulate the problem of click sequence prediction and propose a click\nsequence model (CSM) that aims to predict the order in which a user will\ninteract with search engine results. CSM is based on a neural network that\nfollows the encoder-decoder architecture. The encoder computes contextual\nembeddings of the results. The decoder predicts the sequence of positions of\nthe clicked results. It uses an attention mechanism to extract necessary\ninformation about the results at each timestep. We optimize the parameters of\nCSM by maximizing the likelihood of observed click sequences.\n  We test the effectiveness of CSM on three new tasks: (i) predicting click\nsequences, (ii) predicting the number of clicks, and (iii) predicting whether\nor not a user will interact with the results in the order these results are\npresented on a search engine result page (SERP). Also, we show that CSM\nachieves state-of-the-art results on a standard click prediction task, where\nthe goal is to predict an unordered set of results a user will click on.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2018 08:27:05 GMT"}], "update_date": "2018-05-10", "authors_parsed": [["Borisov", "Alexey", ""], ["Wardenaar", "Martijn", ""], ["Markov", "Ilya", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1805.03797", "submitter": "Liu Yang", "authors": "Daniel Cohen, Liu Yang, W. Bruce Croft", "title": "WikiPassageQA: A Benchmark Collection for Research on Non-factoid Answer\n  Passage Retrieval", "comments": "Accepted by SIGIR18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise in mobile and voice search, answer passage retrieval acts as a\ncritical component of an effective information retrieval system for open domain\nquestion answering. Currently, there are no comparable collections that address\nnon-factoid question answering within larger documents while simultaneously\nproviding enough examples sufficient to train a deep neural network. In this\npaper, we introduce a new Wikipedia based collection specific for non-factoid\nanswer passage retrieval containing thousands of questions with annotated\nanswers and show benchmark results on a variety of state of the art neural\narchitectures and retrieval models. The experimental results demonstrate the\nunique challenges presented by answer passage retrieval within topically\nrelevant documents for future research.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 03:14:42 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Cohen", "Daniel", ""], ["Yang", "Liu", ""], ["Croft", "W. Bruce", ""]]}, {"id": "1805.03885", "submitter": "Niel Chah", "authors": "Niel Chah", "title": "OK Google, What Is Your Ontology? Or: Exploring Freebase Classification\n  to Understand Google's Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper reconstructs the Freebase data dumps to understand the underlying\nontology behind Google's semantic search feature. The Freebase knowledge base\nwas a major Semantic Web and linked data technology that was acquired by Google\nin 2010 to support the Google Knowledge Graph, the backend for Google search\nresults that include structured answers to queries instead of a series of links\nto external resources. After its shutdown in 2016, Freebase is contained in a\ndata dump of 1.9 billion Resource Description Format (RDF) triples. A\nrecomposition of the Freebase ontology will be analyzed in relation to concepts\nand insights from the literature on classification by Bowker and Star. This\npaper will explore how the Freebase ontology is shaped by many of the forces\nthat also shape classification systems through a deep dive into the ontology\nand a small correlational study. These findings will provide a glimpse into the\nproprietary blackbox Knowledge Graph and what is meant by Google's mission to\n\"organize the world's information and make it universally accessible and\nuseful\".\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 08:39:40 GMT"}, {"version": "v2", "created": "Tue, 22 May 2018 11:54:16 GMT"}], "update_date": "2018-05-23", "authors_parsed": [["Chah", "Niel", ""]]}, {"id": "1805.03947", "submitter": "Marco Ponza", "authors": "Paolo Cifariello, Paolo Ferragina, Marco Ponza", "title": "WISER: A Semantic Approach for Expert Finding in Academia based on\n  Entity Linking", "comments": null, "journal-ref": "Information Systems, Elsevier (2019)", "doi": "10.1016/j.is.2018.12.003", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present WISER, a new semantic search engine for expert finding in\nacademia. Our system is unsupervised and it jointly combines classical language\nmodeling techniques, based on text evidences, with the Wikipedia Knowledge\nGraph, via entity linking.\n  WISER indexes each academic author through a novel profiling technique which\nmodels her expertise with a small, labeled and weighted graph drawn from\nWikipedia. Nodes in this graph are the Wikipedia entities mentioned in the\nauthor's publications, whereas the weighted edges express the semantic\nrelatedness among these entities computed via textual and graph-based\nrelatedness functions. Every node is also labeled with a relevance score which\nmodels the pertinence of the corresponding entity to author's expertise, and is\ncomputed by means of a proper random-walk calculation over that graph; and with\na latent vector representation which is learned via entity and other kinds of\nstructural embeddings derived from Wikipedia.\n  At query time, experts are retrieved by combining classic document-centric\napproaches, which exploit the occurrences of query terms in the author's\ndocuments, with a novel set of profile-centric scoring strategies, which\ncompute the semantic relatedness between the author's expertise and the query\ntopic via the above graph-based profiles.\n  The effectiveness of our system is established over a large-scale\nexperimental test on a standard dataset for this task. We show that WISER\nachieves better performance than all the other competitors, thus proving the\neffectiveness of modelling author's profile via our \"semantic\" graph of\nentities. Finally, we comment on the use of WISER for indexing and profiling\nthe whole research community within the University of Pisa, and its application\nto technology transfer in our University.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 13:00:02 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 08:56:07 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Cifariello", "Paolo", ""], ["Ferragina", "Paolo", ""], ["Ponza", "Marco", ""]]}, {"id": "1805.04007", "submitter": "Yinhao Li", "authors": "Yinhao Li, Awa Alqahtani, Ellis Solaiman, Charith Perera, Prem Prakash\n  Jayaraman, Boualem Benatallah, and Rajiv Ranjan", "title": "A Unified Knowledge Representation and Context-aware Recommender System\n  in Internet of Things", "comments": "This paper is an incomplete draft. Therefore, I would like to\n  withdraw it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the rapidly developing Internet of Things (IoT), numerous and diverse\nphysical devices, Edge devices, Cloud infrastructure, and their quality of\nservice requirements (QoS), need to be represented within a unified\nspecification in order to enable rapid IoT application development, monitoring,\nand dynamic reconfiguration. But heterogeneities among different configuration\nknowledge representation models pose limitations for acquisition, discovery and\ncuration of configuration knowledge for coordinated IoT applications. This\npaper proposes a unified data model to represent IoT resource configuration\nknowledge artifacts. It also proposes IoT-CANE (Context-Aware recommendatioN\nsystEm) to facilitate incremental knowledge acquisition and declarative context\ndriven knowledge recommendation.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 14:42:00 GMT"}, {"version": "v2", "created": "Thu, 24 May 2018 13:59:41 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Li", "Yinhao", ""], ["Alqahtani", "Awa", ""], ["Solaiman", "Ellis", ""], ["Perera", "Charith", ""], ["Jayaraman", "Prem Prakash", ""], ["Benatallah", "Boualem", ""], ["Ranjan", "Rajiv", ""]]}, {"id": "1805.04104", "submitter": "Mohamed Attia", "authors": "Mohamed Adel Attia, Deepak Kumar, Ravi Tandon", "title": "The Capacity of Private Information Retrieval from Uncoded Storage\n  Constrained Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DB cs.IR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Private information retrieval (PIR) allows a user to retrieve a desired\nmessage from a set of databases without revealing the identity of the desired\nmessage. The replicated databases scenario was considered by Sun and Jafar,\n2016, where $N$ databases can store the same $K$ messages completely. A PIR\nscheme was developed to achieve the optimal download cost given by $\\left(1+\n\\frac{1}{N}+ \\frac{1}{N^{2}}+ \\cdots + \\frac{1}{N^{K-1}}\\right)$. In this work,\nwe consider the problem of PIR from storage constrained databases. Each\ndatabase has a storage capacity of $\\mu KL$ bits, where $L$ is the size of each\nmessage in bits, and $\\mu \\in [1/N, 1]$ is the normalized storage. On one\nextreme, $\\mu=1$ is the replicated databases case. On the other hand, when\n$\\mu= 1/N$, then in order to retrieve a message privately, the user has to\ndownload all the messages from the databases achieving a download cost of\n$1/K$. We aim to characterize the optimal download cost versus storage\ntrade-off for any storage capacity in the range $\\mu \\in [1/N, 1]$. For any\n$(N,K)$, we show that the optimal trade-off between storage, $\\mu$, and the\ndownload cost, $D(\\mu)$, is given by the lower convex hull of the $N$ pairs\n$\\left(\\mu= \\frac{t}{N},D(\\mu) = \\left(1+ \\frac{1}{t}+ \\frac{1}{t^{2}}+ \\cdots\n+ \\frac{1}{t^{K-1}}\\right)\\right)$ for $t=1,2,\\ldots, N$. To prove this result,\nwe first present the storage constrained PIR scheme for any $(N,K)$. We next\nobtain a general lower bound on the download cost for PIR, which is valid for\nthe following storage scenarios: replicated or storage constrained, coded or\nuncoded, and fixed or optimized. We then specialize this bound using the\nuncoded storage assumption to obtain lower bounds matching the achievable\ndownload cost of the storage constrained PIR scheme for any value of the\navailable storage.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 17:59:39 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 18:49:17 GMT"}], "update_date": "2018-10-25", "authors_parsed": [["Attia", "Mohamed Adel", ""], ["Kumar", "Deepak", ""], ["Tandon", "Ravi", ""]]}, {"id": "1805.04690", "submitter": "Soumen Chakrabarti", "authors": "Sandeep Subramanian and Soumen Chakrabarti", "title": "New Embedded Representations and Evaluation Protocols for Inferring\n  Transitive Relations", "comments": "Accepted at SIGIR 2018", "journal-ref": null, "doi": "10.1145/3209978.3210150", "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Beyond word embeddings, continuous representations of knowledge graph (KG)\ncomponents, such as entities, types and relations, are widely used for entity\nmention disambiguation, relation inference and deep question answering. Great\nstrides have been made in modeling general, asymmetric or antisymmetric KG\nrelations using Gaussian, holographic, and complex embeddings. None of these\ndirectly enforce transitivity inherent in the is-instance-of and is-subtype-of\nrelations. A recent proposal, called order embedding (OE), demands that the\nvector representing a subtype elementwise dominates the vector representing a\nsupertype. However, the manner in which such constraints are asserted and\nevaluated have some limitations. In this short research note, we make three\ncontributions specific to representing and inferring transitive relations.\nFirst, we propose and justify a significant improvement to the OE loss\nobjective. Second, we propose a new representation of types as\nhyper-rectangular regions, that generalize and improve on OE. Third, we show\nthat some current protocols to evaluate transitive relation inference can be\nmisleading, and offer a sound alternative. Rather than use black-box deep\nlearning modules off-the-shelf, we develop our training networks using\nelementary geometric considerations.\n", "versions": [{"version": "v1", "created": "Sat, 12 May 2018 09:36:56 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Subramanian", "Sandeep", ""], ["Chakrabarti", "Soumen", ""]]}, {"id": "1805.04875", "submitter": "Shuo Zhang", "authors": "Shuo Zhang and Krisztian Balog", "title": "On-the-fly Table Generation", "comments": "The 41st International ACM SIGIR Conference on Research and\n  Development in Information Retrieval", "journal-ref": null, "doi": "10.1145/3209978.3209988", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many information needs revolve around entities, which would be better\nanswered by summarizing results in a tabular format, rather than presenting\nthem as a ranked list. Unlike previous work, which is limited to retrieving\nexisting tables, we aim to answer queries by automatically compiling a table in\nresponse to a query. We introduce and address the task of on-the-fly table\ngeneration: given a query, generate a relational table that contains relevant\nentities (as rows) along with their key properties (as columns). This problem\nis decomposed into three specific subtasks: (i) core column entity ranking,\n(ii) schema determination, and (iii) value lookup. We employ a feature-based\napproach for entity ranking and schema determination, combining deep semantic\nfeatures with task-specific signals. We further show that these two subtasks\nare not independent of each other and can assist each other in an iterative\nmanner. For value lookup, we combine information from existing tables and a\nknowledge base. Using two sets of entity-oriented queries, we evaluate our\napproach both on the component level and on the end-to-end table generation\ntask.\n", "versions": [{"version": "v1", "created": "Sun, 13 May 2018 12:46:25 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Zhang", "Shuo", ""], ["Balog", "Krisztian", ""]]}, {"id": "1805.04992", "submitter": "Soyoung Jun", "authors": "So-Young Jun, Dinara Aliyeva, Ji-Min Lee, SangKeun Lee", "title": "Utilizing Probase in Open Directory Project-based Text Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Open Directory Project (ODP) has been successfully utilized in text\nclassification due to its representation ability of various categories.\nHowever, ODP includes a limited number of entities, which play an important\nrole in classification tasks. In this paper, we enrich the semantics of ODP\ncategories with Probase entities. To effectively incorporate Probase entities\nin ODP categories, we first represent each ODP category and Probase entity in\nterms of concepts. Next, we measure the semantic relevance between an ODP\ncategory and a Probase entity based on the concept vector. Finally, we use\nProbase entity to enrich the semantics of the ODP categories. Our experimental\nresults show that the proposed methodology exhibits a significant improvement\nover state-of-the-art techniques in the ODP-based text classification.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 02:48:16 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Jun", "So-Young", ""], ["Aliyeva", "Dinara", ""], ["Lee", "Ji-Min", ""], ["Lee", "SangKeun", ""]]}, {"id": "1805.05005", "submitter": "ThaiBinh Nguyen", "authors": "ThaiBinh Nguyen, Kenro Aihara, Atsuhiro Takasu", "title": "Collaborative Item Embedding Model for Implicit Feedback Data", "comments": null, "journal-ref": "In Proceedings of International Conference on Web Engineering\n  (ICWE), 2017, page 336-348", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering is the most popular approach for recommender systems.\nOne way to perform collaborative filtering is matrix factorization, which\ncharacterizes user preferences and item attributes using latent vectors. These\nlatent vectors are good at capturing global features of users and items but are\nnot strong in capturing local relationships between users or between items. In\nthis work, we propose a method to extract the relationships between items and\nembed them into the latent vectors of the factorization model. This combines\ntwo worlds: matrix factorization for collaborative filtering and item embed-\nding, a similar concept to word embedding in language processing. Our\nexperiments on three real-world datasets show that our proposed method\noutperforms competing methods on top-n recommendation tasks.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 03:55:03 GMT"}], "update_date": "2018-05-15", "authors_parsed": [["Nguyen", "ThaiBinh", ""], ["Aihara", "Kenro", ""], ["Takasu", "Atsuhiro", ""]]}, {"id": "1805.05008", "submitter": "Chengsheng Mao", "authors": "Yuan Luo, Chengsheng Mao, Yiben Yang, Fei Wang, Faraz S. Ahmad, Donna\n  Arnett, Marguerite R. Irvin and Sanjiv J. Shah", "title": "Integrating Hypertension Phenotype and Genotype with Hybrid Non-negative\n  Matrix Factorization", "comments": "fixed some presentation errors", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hypertension is a heterogeneous syndrome in need of improved subtyping using\nphenotypic and genetic measurements so that patients in different subtypes\nshare similar pathophysiologic mechanisms and respond more uniformly to\ntargeted treatments. Existing machine learning approaches often face challenges\nin integrating phenotype and genotype information and presenting to clinicians\nan interpretable model. We aim to provide informed patient stratification by\nintroducing Hybrid Non-negative Matrix Factorization (HNMF) on phenotype and\ngenotype matrices. HNMF simultaneously approximates the phenotypic and genetic\nmatrices using different appropriate loss functions, and generates patient\nsubtypes, phenotypic groups and genetic groups. Unlike previous methods, HNMF\napproximates phenotypic matrix under Frobenius loss, and genetic matrix under\nKullback-Leibler (KL) loss. We propose an alternating projected gradient method\nto solve the approximation problem. Simulation shows HNMF converges fast and\naccurately to the true factor matrices. On real-world clinical dataset, we used\nthe patient factor matrix as features to predict main cardiac mechanistic\noutcomes. We compared HNMF with six different models using phenotype or\ngenotype features alone, with or without NMF, or using joint NMF with only one\ntype of loss. HNMF significantly outperforms all comparison models. HNMF also\nreveals intuitive phenotype-genotype interactions that characterize cardiac\nabnormalities.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 04:19:45 GMT"}, {"version": "v2", "created": "Fri, 18 May 2018 21:36:48 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Luo", "Yuan", ""], ["Mao", "Chengsheng", ""], ["Yang", "Yiben", ""], ["Wang", "Fei", ""], ["Ahmad", "Faraz S.", ""], ["Arnett", "Donna", ""], ["Irvin", "Marguerite R.", ""], ["Shah", "Sanjiv J.", ""]]}, {"id": "1805.05361", "submitter": "Dinghan Shen", "authors": "Dinghan Shen, Qinliang Su, Paidamoyo Chapfuwa, Wenlin Wang, Guoyin\n  Wang, Lawrence Carin, Ricardo Henao", "title": "NASH: Toward End-to-End Neural Architecture for Generative Semantic\n  Hashing", "comments": "To appear at ACL 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Semantic hashing has become a powerful paradigm for fast similarity search in\nmany information retrieval systems. While fairly successful, previous\ntechniques generally require two-stage training, and the binary constraints are\nhandled ad-hoc. In this paper, we present an end-to-end Neural Architecture for\nSemantic Hashing (NASH), where the binary hashing codes are treated as\nBernoulli latent variables. A neural variational inference framework is\nproposed for training, where gradients are directly back-propagated through the\ndiscrete latent variable to optimize the hash function. We also draw\nconnections between proposed method and rate-distortion theory, which provides\na theoretical foundation for the effectiveness of the proposed framework.\nExperimental results on three public datasets demonstrate that our method\nsignificantly outperforms several state-of-the-art models on both unsupervised\nand supervised scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 18:04:28 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Shen", "Dinghan", ""], ["Su", "Qinliang", ""], ["Chapfuwa", "Paidamoyo", ""], ["Wang", "Wenlin", ""], ["Wang", "Guoyin", ""], ["Carin", "Lawrence", ""], ["Henao", "Ricardo", ""]]}, {"id": "1805.05479", "submitter": "Umutcan \\c{S}im\\c{s}ek", "authors": "Umutcan \\c{S}im\\c{s}ek, Elias K\\\"arle and Dieter Fensel", "title": "Machine Readable Web APIs with Schema.org Action Annotations", "comments": "Submitted to SEMANTICS 2018 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The schema.org initiative led by the four major search engines curates a\nvocabulary for describing web content. The number of semantic annotations on\nthe web are increasing, mostly due to the industrial incentives provided by\nthose search engines. The annotations are not only consumed by search engines,\nbut also by other automated agents like intelligent personal assistants (IPAs).\nHowever, only annotating data is not enough for automated agents to reach their\nfull potential. Web APIs should be also annotated for automating service\nconsumption, so the IPAs can complete tasks like booking a hotel room or buying\na ticket for an event on the fly. Although there has been a vast amount of\neffort in the semantic web services field, the approaches did not gain too much\nadoption outside of academia, mainly due to lack of concrete incentives and\nsteep learning curves. In this paper, we suggest a lightweight, bottom-up\napproach based on schema.org actions to annotate Web APIs. We analyse\nschema.org vocabulary in the scope of lightweight semantic web services\nliterature and propose extensions where necessary. We show that schema.org\nactions could be a suitable vocabulary for Web API description. We demonstrate\nour work by annotating existing Web APIs of accommodation service providers.\nAdditionally, we briefly demonstrate how these APIs can be used dynamically,\nfor example, by a dialogue system.\n", "versions": [{"version": "v1", "created": "Mon, 14 May 2018 22:05:22 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["\u015eim\u015fek", "Umutcan", ""], ["K\u00e4rle", "Elias", ""], ["Fensel", "Dieter", ""]]}, {"id": "1805.05737", "submitter": "Yixing Fan", "authors": "Yixing Fan, Jiafeng Guo, Yanyan Lan, Jun Xu, Chengxiang Zhai, Xueqi\n  Cheng", "title": "Modeling Diverse Relevance Patterns in Ad-hoc Retrieval", "comments": "The 41st International ACM SIGIR Conference on Research \\&\n  Development in Information Retrieval, SIGIR'18", "journal-ref": null, "doi": "10.1145/3209978.3209980", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assessing relevance between a query and a document is challenging in ad-hoc\nretrieval due to its diverse patterns, i.e., a document could be relevant to a\nquery as a whole or partially as long as it provides sufficient information for\nusers' need. Such diverse relevance patterns require an ideal retrieval model\nto be able to assess relevance in the right granularity adaptively.\nUnfortunately, most existing retrieval models compute relevance at a single\ngranularity, either document-wide or passage-level, or use fixed combination\nstrategy, restricting their ability in capturing diverse relevance patterns. In\nthis work, we propose a data-driven method to allow relevance signals at\ndifferent granularities to compete with each other for final relevance\nassessment. Specifically, we propose a HIerarchical Neural maTching model\n(HiNT) which consists of two stacked components, namely local matching layer\nand global decision layer. The local matching layer focuses on producing a set\nof local relevance signals by modeling the semantic matching between a query\nand each passage of a document. The global decision layer accumulates local\nsignals into different granularities and allows them to compete with each other\nto decide the final relevance score. Experimental results demonstrate that our\nHiNT model outperforms existing state-of-the-art retrieval models significantly\non benchmark ad-hoc retrieval datasets.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 12:50:45 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Fan", "Yixing", ""], ["Guo", "Jiafeng", ""], ["Lan", "Yanyan", ""], ["Xu", "Jun", ""], ["Zhai", "Chengxiang", ""], ["Cheng", "Xueqi", ""]]}, {"id": "1805.05744", "submitter": "Elias K\\\"arle", "authors": "Elias K\\\"arle, Umutcan \\c{S}im\\c{s}ek, Oleksandra Panasiuk and Dieter\n  Fensel", "title": "Building an Ecosystem for the Tyrolean Tourism Knowledge Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of the schema.org vocabulary was a big step towards making\nwebsites machine read- and understandable. Due to schema.org's RDF-like nature\nstoring annotations in a graph database is easy and efficient. In this paper\nthe authors show how they gather touristic data in the Austrian region of Tirol\nand provide this data publicly in a knowledge graph. The definition of subsets\nof the vocabulary is followed by providing means to map data sources\nefficiently to schema.org and then store the annotated content into the graph.\nTo showcase the consumption of the touristic data four scenarios are described\nwhich use the knowledge graph for real life applications and data analysis.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 13:11:12 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 08:45:14 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["K\u00e4rle", "Elias", ""], ["\u015eim\u015fek", "Umutcan", ""], ["Panasiuk", "Oleksandra", ""], ["Fensel", "Dieter", ""]]}, {"id": "1805.06051", "submitter": "Seyedamin Pouriyeh", "authors": "Seyedamin Pouriyeh, Mehdi Allahyari, Qingxia Liu, Gong Cheng, Hamid\n  Reza Arabnia, Yuzhong Qu, Krys Kochut", "title": "Graph-based Ontology Summarization: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ontologies have been widely used in numerous and varied applications, e.g.,\nto support data modeling, information integration, and knowledge management.\nWith the increasing size of ontologies, ontology understanding, which is\nplaying an important role in different tasks, is becoming more difficult.\nConsequently, ontology summarization, as a way to distill key information from\nan ontology and generate an abridged version to facilitate a better\nunderstanding, is getting growing attention. In this survey paper, we review\nexisting ontology summarization techniques and focus mainly on graph-based\nmethods, which represent an ontology as a graph and apply centrality-based and\nother measures to identify the most important elements of an ontology as its\nsummary. After analyzing their strengths and weaknesses, we highlight a few\npotential directions for future research.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 22:21:26 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Pouriyeh", "Seyedamin", ""], ["Allahyari", "Mehdi", ""], ["Liu", "Qingxia", ""], ["Cheng", "Gong", ""], ["Arabnia", "Hamid Reza", ""], ["Qu", "Yuzhong", ""], ["Kochut", "Krys", ""]]}, {"id": "1805.06289", "submitter": "Firoj Alam", "authors": "Firoj Alam, Shafiq Joty, Muhammad Imran", "title": "Graph Based Semi-supervised Learning with Convolution Neural Networks to\n  Classify Crisis Related Tweets", "comments": "5 pages. arXiv admin note: substantial text overlap with\n  arXiv:1805.05151", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.CL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During time-critical situations such as natural disasters, rapid\nclassification of data posted on social networks by affected people is useful\nfor humanitarian organizations to gain situational awareness and to plan\nresponse efforts. However, the scarcity of labeled data in the early hours of a\ncrisis hinders machine learning tasks thus delays crisis response. In this\nwork, we propose to use an inductive semi-supervised technique to utilize\nunlabeled data, which is often abundant at the onset of a crisis event, along\nwith fewer labeled data. Specif- ically, we adopt a graph-based deep learning\nframework to learn an inductive semi-supervised model. We use two real-world\ncrisis datasets from Twitter to evaluate the proposed approach. Our results\nshow significant improvements using unlabeled data as compared to only using\nlabeled data.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2018 10:38:57 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Alam", "Firoj", ""], ["Joty", "Shafiq", ""], ["Imran", "Muhammad", ""]]}, {"id": "1805.06353", "submitter": "Shuo Zhang", "authors": "Shuo Zhang and Vugar Abdul Zada and Krisztian Balog", "title": "SmartTable: A Spreadsheet Program with Intelligent Assistance", "comments": "The 41st International ACM SIGIR Conference on Research and\n  Development in Information Retrieval (SIGIR '18)", "journal-ref": null, "doi": "10.1145/3209978.3210171", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce SmartTable, an online spreadsheet application that is equipped\nwith intelligent assistance capabilities. With a focus on relational tables,\ndescribing entities along with their attributes, we offer assistance in two\nflavors: (i) for populating the table with additional entities (rows) and (ii)\nfor extending it with additional entity attributes (columns). We provide\ndetails of our implementation, which is also released as open source. The\napplication is available at http://smarttable.cc.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 14:54:00 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Zhang", "Shuo", ""], ["Zada", "Vugar Abdul", ""], ["Balog", "Krisztian", ""]]}, {"id": "1805.06524", "submitter": "Ming Li", "authors": "Ming Li, Peilun Xiao, and Ju Zhang", "title": "Hybrid Adaptive Fuzzy Extreme Learning Machine for text classification", "comments": "2 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In traditional ELM and its improved versions suffer from the problems of\noutliers or noises due to overfitting and imbalance due to distribution. We\npropose a novel hybrid adaptive fuzzy ELM(HA-FELM), which introduces a fuzzy\nmembership function to the traditional ELM method to deal with the above\nproblems. We define the fuzzy membership function not only basing on the\ndistance between each sample and the center of the class but also the density\namong samples which based on the quantum harmonic oscillator model. The\nproposed fuzzy membership function overcomes the shortcoming of the traditional\nfuzzy membership function and could make itself adjusted according to the\nspecific distribution of different samples adaptively. Experiments show the\nproposed HA-FELM can produce better performance than SVM, ELM, and RELM in text\nclassification.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 06:11:27 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Li", "Ming", ""], ["Xiao", "Peilun", ""], ["Zhang", "Ju", ""]]}, {"id": "1805.06525", "submitter": "Ming Li", "authors": "Ming Li, Peilun Xiao, and Ju Zhang", "title": "Text classification based on ensemble extreme learning machine", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a novel approach based on cost-sensitive ensemble\nweighted extreme learning machine; we call this approach AE1-WELM. We apply\nthis approach to text classification. AE1-WELM is an algorithm including\nbalanced and imbalanced multiclassification for text classification. Weighted\nELM assigning the different weights to the different samples improves the\nclassification accuracy to a certain extent, but weighted ELM considers the\ndifferences between samples in the different categories only and ignores the\ndifferences between samples within the same categories. We measure the\nimportance of the documents by the sample information entropy, and generate\ncost-sensitive matrix and factor based on the document importance, then embed\nthe cost-sensitive weighted ELM into the AdaBoost.M1 framework seamlessly.\nVector space model(VSM) text representation produces the high dimensions and\nsparse features which increase the burden of ELM. To overcome this problem, we\ndevelop a text classification framework combining the word vector and AE1-WELM.\nThe experimental results show that our method provides an accurate, reliable\nand effective solution for text classification.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2018 06:10:46 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Li", "Ming", ""], ["Xiao", "Peilun", ""], ["Zhang", "Ju", ""]]}, {"id": "1805.06563", "submitter": "ThaiBinh Nguyen", "authors": "ThaiBinh Nguyen and Atsuhiro Takasu", "title": "NPE: Neural Personalized Embedding for Collaborative Filtering", "comments": "IJCAI-ECAI 2018 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization is one of the most efficient approaches in recommender\nsystems. However, such algorithms, which rely on the interactions between users\nand items, perform poorly for \"cold-users\" (users with little history of such\ninteractions) and at capturing the relationships between closely related items.\nTo address these problems, we propose a neural personalized embedding (NPE)\nmodel, which improves the recommendation performance for cold-users and can\nlearn effective representations of items. It models a user's click to an item\nin two terms: the personal preference of the user for the item, and the\nrelationships between this item and other items clicked by the user. We show\nthat NPE outperforms competing methods for top-N recommendations, specially for\ncold-user recommendations. We also performed a qualitative analysis that shows\nthe effectiveness of the representations learned by the model.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 00:57:26 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Nguyen", "ThaiBinh", ""], ["Takasu", "Atsuhiro", ""]]}, {"id": "1805.06594", "submitter": "Ze Wang", "authors": "Ze Wang, Hong Li", "title": "Leveraging Social Signal to Improve Item Recommendation for Matrix\n  Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Recommender Systems have been comprehensively studied in the past\ndecade both in industry and academia, most of current recommender systems\nsuffer from the following issues: 1) The data sparsity of the user-item matrix\nseriously affect the recommender system quality. As a result, most of\ntraditional recommender system approaches are not able to deal with the users\nwho have rated few items, which is known as cold start problem in recommender\nsystem. 2) Traditional recommender systems assume that users are independently\nand identically distributed and ignore the social relation between users.\nHowever, in real life scenario, due to the exponential growth of social\nnetworking service, such as facebook and Twitter, social connections between\ndifferent users play an significant role for recommender system task. In this\nwork, aiming at providing a better recommender systems by incorporating user\nsocial network information, we propose a matrix factorization framework with\nuser social connection constraints. Experimental results on the real-life\ndataset shows that the proposed method performs significantly better than the\nstate-of-the-art approaches in terms of MAE and RMSE, especially for the cold\nstart users.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 03:43:04 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Wang", "Ze", ""], ["Li", "Hong", ""]]}, {"id": "1805.06632", "submitter": "Wenjie Huang", "authors": "William B. Haskell, Wenjie Huang, Huifu Xu", "title": "Preference Elicitation and Robust Optimization with Multi-Attribute\n  Quasi-Concave Choice Functions", "comments": "36 pages, 4 figures, submitted to Operations Research", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.RM cs.AI cs.IR math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision maker's preferences are often captured by some choice functions\nwhich are used to rank prospects. In this paper, we consider ambiguity in\nchoice functions over a multi-attribute prospect space. Our main result is a\nrobust preference model where the optimal decision is based on the worst-case\nchoice function from an ambiguity set constructed through preference\nelicitation with pairwise comparisons of prospects. Differing from existing\nworks in the area, our focus is on quasi-concave choice functions rather than\nconcave functions and this enables us to cover a wide range of utility/risk\npreference problems including multi-attribute expected utility and $S$-shaped\naspirational risk preferences. The robust choice function is increasing and\nquasi-concave but not necessarily translation invariant, a key property of\nmonetary risk measures. We propose two approaches based respectively on the\nsupport functions and level functions of quasi-concave functions to develop\ntractable formulations of the maximin preference robust optimization model. The\nformer gives rise to a mixed integer linear programming problem whereas the\nlatter is equivalent to solving a sequence of convex risk minimization\nproblems. To assess the effectiveness of the proposed robust preference\noptimization model and numerical schemes, we apply them to a security budget\nallocation problem and report some preliminary results from experiments.\n", "versions": [{"version": "v1", "created": "Thu, 17 May 2018 07:37:33 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Haskell", "William B.", ""], ["Huang", "Wenjie", ""], ["Xu", "Huifu", ""]]}, {"id": "1805.06745", "submitter": "Olegs Verhodubs", "authors": "Olegs Verhodubs", "title": "Web Resource for Storing Collective Experience", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experience is what makes our life more effective that is why it is necessary\nto share experience among people. The use of information technologies is the\nmost technological way to work with experience, and the use of the Web is the\nbest way for sharing it. This paper describes a web resource designed for\nstoring, sharing and using experience that is obtained from different people in\nthe Web. The main purpose of this paper is to present this web resource in\norder to evaluate the interest in such a web resource.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2018 13:28:51 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Verhodubs", "Olegs", ""]]}, {"id": "1805.07037", "submitter": "Lei Zheng", "authors": "Lei Zheng, Chun-Ta Lu, Lifang He, Sihong Xie, Vahid Noroozi, He Huang\n  and Philip S. Yu", "title": "MARS: Memory Attention-Aware Recommender System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of modeling users' diverse interests.\nPrevious methods usually learn a fixed user representation, which has a limited\nability to represent distinct interests of a user. In order to model users'\nvarious interests, we propose a Memory Attention-aware Recommender System\n(MARS). MARS utilizes a memory component and a novel attentional mechanism to\nlearn deep \\textit{adaptive user representations}. Trained in an end-to-end\nfashion, MARS adaptively summarizes users' interests. In the experiments, MARS\noutperforms seven state-of-the-art methods on three real-world datasets in\nterms of recall and mean average precision. We also demonstrate that MARS has a\ngreat interpretability to explain its recommendation results, which is\nimportant in many recommendation scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 03:32:13 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Zheng", "Lei", ""], ["Lu", "Chun-Ta", ""], ["He", "Lifang", ""], ["Xie", "Sihong", ""], ["Noroozi", "Vahid", ""], ["Huang", "He", ""], ["Yu", "Philip S.", ""]]}, {"id": "1805.07317", "submitter": "Huazheng Wang", "authors": "Huazheng Wang, Ramsey Langley, Sonwoo Kim, Eric McCord-Snook, Hongning\n  Wang", "title": "Efficient Exploration of Gradient Space for Online Learning to Rank", "comments": "To appear on SIGIR '18: The 41st International ACM SIGIR Conference\n  on Research & Development in Information Retrieval", "journal-ref": null, "doi": "10.1145/3209978.3210045", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online learning to rank (OL2R) optimizes the utility of returned search\nresults based on implicit feedback gathered directly from users. To improve the\nestimates, OL2R algorithms examine one or more exploratory gradient directions\nand update the current ranker if a proposed one is preferred by users via an\ninterleaved test. In this paper, we accelerate the online learning process by\nefficient exploration in the gradient space. Our algorithm, named as Null Space\nGradient Descent, reduces the exploration space to only the \\emph{null space}\nof recent poorly performing gradients. This prevents the algorithm from\nrepeatedly exploring directions that have been discouraged by the most recent\ninteractions with users. To improve sensitivity of the resulting interleaved\ntest, we selectively construct candidate rankers to maximize the chance that\nthey can be differentiated by candidate ranking documents in the current query;\nand we use historically difficult queries to identify the best ranker when tie\noccurs in comparing the rankers. Extensive experimental comparisons with the\nstate-of-the-art OL2R algorithms on several public benchmarks confirmed the\neffectiveness of our proposal algorithm, especially in its fast learning\nconvergence and promising ranking quality at an early stage.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 16:32:04 GMT"}], "update_date": "2018-11-28", "authors_parsed": [["Wang", "Huazheng", ""], ["Langley", "Ramsey", ""], ["Kim", "Sonwoo", ""], ["McCord-Snook", "Eric", ""], ["Wang", "Hongning", ""]]}, {"id": "1805.07479", "submitter": "Cheng Ju", "authors": "Cheng Ju, James Li, Bram Wasti, Shengbo Guo", "title": "Semisupervised Learning on Heterogeneous Graphs and its Applications to\n  Facebook News Feed", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph-based semi-supervised learning is a fundamental machine learning\nproblem, and has been well studied. Most studies focus on homogeneous networks\n(e.g. citation network, friend network). In the present paper, we propose the\nHeterogeneous Embedding Label Propagation (HELP) algorithm, a graph-based\nsemi-supervised deep learning algorithm, for graphs that are characterized by\nheterogeneous node types. Empirically, we demonstrate the effectiveness of this\nmethod in domain classification tasks with Facebook user-domain interaction\ngraph, and compare the performance of the proposed HELP algorithm with the\nstate of the art algorithms. We show that the HELP algorithm improves the\npredictive performance across multiple tasks, together with semantically\nmeaningful embedding that are discriminative for downstream classification or\nregression tasks.\n", "versions": [{"version": "v1", "created": "Fri, 18 May 2018 23:58:07 GMT"}, {"version": "v2", "created": "Thu, 5 Jul 2018 02:20:50 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Ju", "Cheng", ""], ["Li", "James", ""], ["Wasti", "Bram", ""], ["Guo", "Shengbo", ""]]}, {"id": "1805.07591", "submitter": "Zhenghao Liu PhD.", "authors": "Zhenghao Liu, Chenyan Xiong, Maosong Sun and Zhiyuan Liu", "title": "Entity-Duet Neural Ranking: Understanding the Role of Knowledge Graph\n  Semantics in Neural Information Retrieval", "comments": "9 pages, 6 figures, ACL2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the Entity-Duet Neural Ranking Model (EDRM), which\nintroduces knowledge graphs to neural search systems. EDRM represents queries\nand documents by their words and entity annotations. The semantics from\nknowledge graphs are integrated in the distributed representations of their\nentities, while the ranking is conducted by interaction-based neural ranking\nnetworks. The two components are learned end-to-end, making EDRM a natural\ncombination of entity-oriented search and neural information retrieval. Our\nexperiments on a commercial search log demonstrate the effectiveness of EDRM.\nOur analyses reveal that knowledge graph semantics significantly improve the\ngeneralization ability of neural ranking models.\n", "versions": [{"version": "v1", "created": "Sat, 19 May 2018 13:37:32 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 12:25:18 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Liu", "Zhenghao", ""], ["Xiong", "Chenyan", ""], ["Sun", "Maosong", ""], ["Liu", "Zhiyuan", ""]]}, {"id": "1805.07851", "submitter": "Harish Gandhi Ramachandran", "authors": "Harish Gandhi Ramachandran, Dan DeRose Jr", "title": "A Text Analysis of Federal Reserve meeting minutes", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Recent developments in monetary policy by the Federal Reserve has created a\nneed for an objective method of communication analysis.Using methods developed\nfor text analysis, we present a novel technique of analysis which creates a\nsemantic space defined by various policymakers public comments and places the\ncommittee consensus in the appropriate location. Its then possible to determine\nwhich member of the committee is most closely aligned with the committee\nconsensus over time and create a foundation for further actionable research.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 00:27:05 GMT"}], "update_date": "2018-05-22", "authors_parsed": [["Ramachandran", "Harish Gandhi", ""], ["DeRose", "Dan", "Jr"]]}, {"id": "1805.08159", "submitter": "Jinfeng Rao", "authors": "Jinfeng Rao, Wei Yang, Yuhao Zhang, Ferhan Ture, Jimmy Lin", "title": "Multi-Perspective Relevance Matching with Hierarchical ConvNets for\n  Social Media Search", "comments": "AAAI 2019, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite substantial interest in applications of neural networks to\ninformation retrieval, neural ranking models have only been applied to standard\nad hoc retrieval tasks over web pages and newswire documents. This paper\nproposes MP-HCNN (Multi-Perspective Hierarchical Convolutional Neural Network)\na novel neural ranking model specifically designed for ranking short social\nmedia posts. We identify document length, informal language, and heterogeneous\nrelevance signals as features that distinguish documents in our domain, and\npresent a model specifically designed with these characteristics in mind. Our\nmodel uses hierarchical convolutional layers to learn latent semantic\nsoft-match relevance signals at the character, word, and phrase levels. A\npooling-based similarity measurement layer integrates evidence from multiple\ntypes of matches between the query, the social media post, as well as URLs\ncontained in the post. Extensive experiments using Twitter data from the TREC\nMicroblog Tracks 2011--2014 show that our model significantly outperforms prior\nfeature-based as well and existing neural ranking models. To our best\nknowledge, this paper presents the first substantial work tackling search over\nsocial media posts using neural ranking models.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2018 16:25:15 GMT"}, {"version": "v2", "created": "Sat, 22 Jun 2019 00:14:49 GMT"}], "update_date": "2019-06-25", "authors_parsed": [["Rao", "Jinfeng", ""], ["Yang", "Wei", ""], ["Zhang", "Yuhao", ""], ["Ture", "Ferhan", ""], ["Lin", "Jimmy", ""]]}, {"id": "1805.08524", "submitter": "Tao Zhuang", "authors": "Tao Zhuang, Wenwu Ou, Zhirong Wang", "title": "Globally Optimized Mutual Influence Aware Ranking in E-Commerce Search", "comments": null, "journal-ref": "IJCAI 2018", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In web search, mutual influences between documents have been studied from the\nperspective of search result diversification. But the methods in web search is\nnot directly applicable to e-commerce search because of their differences. And\nlittle research has been done on the mutual influences between items in\ne-commerce search. We propose a global optimization framework for mutual\ninfluence aware ranking in e-commerce search. Our framework directly optimizes\nthe Gross Merchandise Volume (GMV) for ranking, and decomposes ranking into two\ntasks. The first task is mutual influence aware purchase probability\nestimation. We propose a global feature extension method to incorporate mutual\ninfluences into the features of an item. We also use Recurrent Neural Network\n(RNN) to capture influences related to ranking orders in purchase probability\nestimation. The second task is to find the best ranking order based on the\npurchase probability estimations. We treat the second task as a sequence\ngeneration problem and solved it using the beam search algorithm. We performed\nonline A/B test on a large e-commerce search engine. The results show that our\nmethod brings a 5% increase in GMV for the search engine over a strong\nbaseline.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 11:56:25 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Zhuang", "Tao", ""], ["Ou", "Wenwu", ""], ["Wang", "Zhirong", ""]]}, {"id": "1805.08587", "submitter": "Jihua Zhu", "authors": "Shanmin Pang and Jin Ma and Jianru Xue and Jihua Zhu and Vicente\n  Ordonez", "title": "Deep Feature Aggregation and Image Re-ranking with Heat Diffusion for\n  Image Retrieval", "comments": "The paper has been accepted to IEEE Transactions on Multimedia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image retrieval based on deep convolutional features has demonstrated\nstate-of-the-art performance in popular benchmarks. In this paper, we present a\nunified solution to address deep convolutional feature aggregation and image\nre-ranking by simulating the dynamics of heat diffusion. A distinctive problem\nin image retrieval is that repetitive or \\emph{bursty} features tend to\ndominate final image representations, resulting in representations less\ndistinguishable. We show that by considering each deep feature as a heat\nsource, our unsupervised aggregation method is able to avoid\nover-representation of \\emph{bursty} features. We additionally provide a\npractical solution for the proposed aggregation method and further show the\nefficiency of our method in experimental evaluation. Inspired by the\naforementioned deep feature aggregation method, we also propose a method to\nre-rank a number of top ranked images for a given query image by considering\nthe query as the heat source. Finally, we extensively evaluate the proposed\napproach with pre-trained and fine-tuned deep networks on common public\nbenchmarks and show superior performance compared to previous work.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 14:06:28 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 14:57:01 GMT"}, {"version": "v3", "created": "Wed, 30 May 2018 22:18:33 GMT"}, {"version": "v4", "created": "Sat, 2 Jun 2018 19:34:08 GMT"}, {"version": "v5", "created": "Tue, 9 Oct 2018 02:30:27 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Pang", "Shanmin", ""], ["Ma", "Jin", ""], ["Xue", "Jianru", ""], ["Zhu", "Jihua", ""], ["Ordonez", "Vicente", ""]]}, {"id": "1805.08716", "submitter": "Meike Zehlike", "authors": "Meike Zehlike and Carlos Castillo", "title": "Reducing Disparate Exposure in Ranking: A Learning To Rank Approach", "comments": "7 pages", "journal-ref": null, "doi": "10.1145/3366424.3383534", "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ranked search results have become the main mechanism by which we find\ncontent, products, places, and people online. Thus their ordering contributes\nnot only to the satisfaction of the searcher, but also to career and business\nopportunities, educational placement, and even social success of those being\nranked. Researchers have become increasingly concerned with systematic biases\nin data-driven ranking models, and various post-processing methods have been\nproposed to mitigate discrimination and inequality of opportunity. This\napproach, however, has the disadvantage that it still allows an unfair ranking\nmodel to be trained. In this paper we explore a new in-processing approach:\nDELTR, a learning-to-rank framework that addresses potential issues of\ndiscrimination and unequal opportunity in rankings at training time. We measure\nthese problems in terms of discrepancies in the average group exposure and\ndesign a ranker that optimizes search results in terms of relevance and in\nterms of reducing such discrepancies. We perform an extensive experimental\nstudy showing that being \"colorblind\" can be among the best or the worst\nchoices from the perspective of relevance and exposure, depending on how much\nand which kind of bias is present in the training set. We show that our\nin-processing method performs better in terms of relevance and exposure than a\npre-processing and a post-processing method across all tested scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2018 16:23:49 GMT"}, {"version": "v2", "created": "Thu, 30 Aug 2018 15:19:03 GMT"}, {"version": "v3", "created": "Mon, 27 May 2019 16:03:00 GMT"}, {"version": "v4", "created": "Tue, 28 May 2019 08:31:23 GMT"}, {"version": "v5", "created": "Wed, 27 May 2020 17:49:06 GMT"}], "update_date": "2020-05-28", "authors_parsed": [["Zehlike", "Meike", ""], ["Castillo", "Carlos", ""]]}, {"id": "1805.08958", "submitter": "Yu Zhu", "authors": "Yu Zhu, Junxiong Zhu, Jie Hou, Yongliang Li, Beidou Wang, Ziyu Guan,\n  Deng Cai", "title": "A Brand-level Ranking System with the Customized Attention-GRU Model", "comments": "7 pages, 6 figures, 3 tables. Published in IJCAI 2018. Make some\n  figures and tables more clear", "journal-ref": "International Joint Conferences on Artificial Intelligence, 2018:\n  3947-3953", "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In e-commerce websites like Taobao, brand is playing a more important role in\ninfluencing users' decision of click/purchase, partly because users are now\nattaching more importance to the quality of products and brand is an indicator\nof quality. However, existing ranking systems are not specifically designed to\nsatisfy this kind of demand. Some design tricks may partially alleviate this\nproblem, but still cannot provide satisfactory results or may create additional\ninteraction cost. In this paper, we design the first brand-level ranking system\nto address this problem. The key challenge of this system is how to\nsufficiently exploit users' rich behavior in e-commerce websites to rank the\nbrands. In our solution, we firstly conduct the feature engineering\nspecifically tailored for the personalized brand ranking problem and then rank\nthe brands by an adapted Attention-GRU model containing three important\nmodifications. Note that our proposed modifications can also apply to many\nother machine learning models on various tasks. We conduct a series of\nexperiments to evaluate the effectiveness of our proposed ranking model and\ntest the response to the brand-level ranking system from real users on a\nlarge-scale e-commerce platform, i.e. Taobao.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 04:30:48 GMT"}, {"version": "v2", "created": "Sat, 11 Aug 2018 10:59:42 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Zhu", "Yu", ""], ["Zhu", "Junxiong", ""], ["Hou", "Jie", ""], ["Li", "Yongliang", ""], ["Wang", "Beidou", ""], ["Guan", "Ziyu", ""], ["Cai", "Deng", ""]]}, {"id": "1805.09023", "submitter": "Yu Zhu", "authors": "Yu Zhu, Jinhao Lin, Shibi He, Beidou Wang, Ziyu Guan, Haifeng Liu and\n  Deng Cai", "title": "Addressing the Item Cold-start Problem by Attribute-driven Active\n  Learning", "comments": "14 pages, 7 figures, 9 tables. Submitted to TKDE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recommender systems, cold-start issues are situations where no previous\nevents, e.g. ratings, are known for certain users or items. In this paper, we\nfocus on the item cold-start problem. Both content information (e.g. item\nattributes) and initial user ratings are valuable for seizing users'\npreferences on a new item. However, previous methods for the item cold-start\nproblem either 1) incorporate content information into collaborative filtering\nto perform hybrid recommendation, or 2) actively select users to rate the new\nitem without considering content information and then do collaborative\nfiltering. In this paper, we propose a novel recommendation scheme for the item\ncold-start problem by leverage both active learning and items' attribute\ninformation. Specifically, we design useful user selection criteria based on\nitems' attributes and users' rating history, and combine the criteria in an\noptimization framework for selecting users. By exploiting the feedback ratings,\nusers' previous ratings and items' attributes, we then generate accurate rating\npredictions for the other unselected users. Experimental results on two\nreal-world datasets show the superiority of our proposed method over\ntraditional methods.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 09:21:53 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Zhu", "Yu", ""], ["Lin", "Jinhao", ""], ["He", "Shibi", ""], ["Wang", "Beidou", ""], ["Guan", "Ziyu", ""], ["Liu", "Haifeng", ""], ["Cai", "Deng", ""]]}, {"id": "1805.09120", "submitter": "Patrice Bellot", "authors": "Patrice Bellot (LSIS, DIMAG), Wided Bakari, Mahmoud Neji", "title": "A logical representation of Arabic questions toward automatic passage\n  extraction from the Web", "comments": null, "journal-ref": "International Journal of Speech Technology, Springer Verlag, 2017,\n  20 (2), pp.339 - 353", "doi": "10.1007/s10772-017-9411-7", "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the expanding growth of Arabic electronic data on the web, extracting\ninformation, which is actually one of the major challenges of the\nquestion-answering, is essentially used for building corpus of documents. In\nfact, building a corpus is a research topic that is currently referred to among\nsome other major themes of conferences, in Natural Language Processing (NLP),\nsuch as, Information Retrieval (IR), Question-Answering (QA), Automatic Summary\n(AS), etc. Generally, a question-answering system provides various passages to\nanswer the user questions. To make these passages truly informative, this\nsystem needs access to an underlying knowledge base; this requires the\nconstruction of a corpus. The aim of our research is to build an Arabic\nquestion-answering system. In addition, analyzing the question must be the\nfirst step. Next, it is essential to retrieve a passage from the web that can\nserve as an appropriate answer. In this paper, we propose a method to analysis\nthe question and retrieve the passage answer in the Arabic language. For the\nquestion analysis, five factual question types are processed. Additionally, our\npurpose is to experiment with the generation of a logic representation from the\ndeclarative form of each question. Several studies, deal with the logic\napproaches in question-answering, are discussed in other languages than the\nArabic language. This representation is very promising because it helps us\nlater in the selection of a justifiable answer. The accuracy of questions that\nare correctly analyzed and translated into the logic form achieved 64%. And\nthen, the results of passages of texts that are automatically generated\nachieved an 87% score for accuracy and a 98% score for c@1.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2018 13:21:40 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Bellot", "Patrice", "", "LSIS, DIMAG"], ["Bakari", "Wided", ""], ["Neji", "Mahmoud", ""]]}, {"id": "1805.09557", "submitter": "Andreu Vall", "authors": "Andreu Vall, Matthias Dorfer, Markus Schedl, Gerhard Widmer", "title": "A Hybrid Approach to Music Playlist Continuation Based on Playlist-Song\n  Membership", "comments": null, "journal-ref": "Proceedings SAC 2018: Symposium on Applied Computing, April\n  9-13,2018, Pau, France. ACM, New York, NY, USA", "doi": "10.1145/3167132.3167280", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated music playlist continuation is a common task of music recommender\nsystems, that generally consists in providing a fitting extension to a given\nplaylist. Collaborative filtering models, that extract abstract patterns from\ncurated music playlists, tend to provide better playlist continuations than\ncontent-based approaches. However, pure collaborative filtering models have at\nleast one of the following limitations: (1) they can only extend playlists\nprofiled at training time; (2) they misrepresent songs that occur in very few\nplaylists. We introduce a novel hybrid playlist continuation model based on\nwhat we name \"playlist-song membership\", that is, whether a given playlist and\na given song fit together. The proposed model regards any playlist-song pair\nexclusively in terms of feature vectors. In light of this information, and\nafter having been trained on a collection of labeled playlist-song pairs, the\nproposed model decides whether a playlist-song pair fits together or not.\nExperimental results on two datasets of curated music playlists show that the\nproposed playlist continuation model compares to a state-of-the-art\ncollaborative filtering model in the ideal situation of extending playlists\nprofiled at training time and where songs occurred frequently in training\nplaylists. In contrast to the collaborative filtering model, and as a result of\nits general understanding of the playlist-song pairs in terms of feature\nvectors, the proposed model is additionally able to (1) extend non-profiled\nplaylists and (2) recommend songs that occurred seldom or never in\ntraining~playlists.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 09:02:21 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Vall", "Andreu", ""], ["Dorfer", "Matthias", ""], ["Schedl", "Markus", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1805.09559", "submitter": "Alexander Kirillov", "authors": "Alexander Kirillov and Natalia Krizhanovsky and Andrew Krizhanovsky", "title": "WSD algorithm based on a new method of vector-word contexts proximity\n  calculation via epsilon-filtration", "comments": "15 pages, 1 table, 15 figures, accepted in the journal Transactions\n  of Karelian Research Centre of the Russian Academy of Sciences", "journal-ref": "Transactions of Karelian Research Centre RAS. No. 7. 2018. P.\n  149-163", "doi": "10.17076/mat829", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of word sense disambiguation (WSD) is considered in the article.\nGiven a set of synonyms (synsets) and sentences with these synonyms. It is\nnecessary to select the meaning of the word in the sentence automatically. 1285\nsentences were tagged by experts, namely, one of the dictionary meanings was\nselected by experts for target words. To solve the WSD-problem, an algorithm\nbased on a new method of vector-word contexts proximity calculation is\nproposed. In order to achieve higher accuracy, a preliminary epsilon-filtering\nof words is performed, both in the sentence and in the set of synonyms. An\nextensive program of experiments was carried out. Four algorithms are\nimplemented, including a new algorithm. Experiments have shown that in a number\nof cases the new algorithm shows better results. The developed software and the\ntagged corpus have an open license and are available online. Wiktionary and\nWikisource are used. A brief description of this work can be viewed in slides\n(https://goo.gl/9ak6Gt). Video lecture in Russian on this research is available\nonline (https://youtu.be/-DLmRkepf58).\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 09:04:44 GMT"}, {"version": "v2", "created": "Mon, 18 Jun 2018 09:53:08 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Kirillov", "Alexander", ""], ["Krizhanovsky", "Natalia", ""], ["Krizhanovsky", "Andrew", ""]]}, {"id": "1805.09644", "submitter": "Siamak Barzegar", "authors": "Siamak Barzegar, Juliano Efson Sales, Andre Freitas, Siegfried\n  Handschuh and Brian Davis", "title": "DINFRA: A One Stop Shop for Computing Multilingual Semantic Relatedness", "comments": "2 pages, 2 figures, SIGIR Conference", "journal-ref": null, "doi": "10.1145/2766462.2767870", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This demonstration presents an infrastructure for computing multilingual\nsemantic relatedness and correlation for twelve natural languages by using\nthree distributional semantic models (DSMs). Our demonsrator - DInfra\n(Distributional Infrastructure) provides researchers and developers with a\nhighly useful platform for processing large-scale corpora and conducting\nexperiments with distributional semantics. We integrate several multilingual\nDSMs in our webservice so the end user can obtain a result without worrying\nabout the complexities involved in building DSMs. Our webservice allows the\nusers to have easy access to a wide range of comparisons of DSMs with different\nparameters. In addition, users can configure and access DSM parameters using an\neasy to use API.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2018 21:06:59 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Barzegar", "Siamak", ""], ["Sales", "Juliano Efson", ""], ["Freitas", "Andre", ""], ["Handschuh", "Siegfried", ""], ["Davis", "Brian", ""]]}, {"id": "1805.09687", "submitter": "Michele Dolfi", "authors": "Peter W J Staar, Michele Dolfi, Christoph Auer, Costas Bekas", "title": "Corpus Conversion Service: A machine learning platform to ingest\n  documents at scale [Poster abstract]", "comments": "Accepted in SysML 2018 (www.sysml.cc)", "journal-ref": null, "doi": "10.13140/RG.2.2.10858.82888", "report-no": null, "categories": "cs.DL cs.CL cs.CV cs.DC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past few decades, the amount of scientific articles and technical\nliterature has increased exponentially in size. Consequently, there is a great\nneed for systems that can ingest these documents at scale and make their\ncontent discoverable. Unfortunately, both the format of these documents (e.g.\nthe PDF format or bitmap images) as well as the presentation of the data (e.g.\ncomplex tables) make the extraction of qualitative and quantitive data\nextremely challenging. We present a platform to ingest documents at scale which\nis powered by Machine Learning techniques and allows the user to train custom\nmodels on document collections. We show precision/recall results greater than\n97% with regard to conversion to structured formats, as well as scaling\nevidence for each of the microservices constituting the platform.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2018 07:05:52 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Staar", "Peter W J", ""], ["Dolfi", "Michele", ""], ["Auer", "Christoph", ""], ["Bekas", "Costas", ""]]}, {"id": "1805.09772", "submitter": "Hamid Tizhoosh", "authors": "Graham Bleaney, Matthew Kuzyk, Julian Man, Hossein Mayanloo,\n  H.R.Tizhoosh", "title": "Auto-Detection of Safety Issues in Baby Products", "comments": "To appear in proceedings of The 31st IEA-AIE 2018, June 25-28, 2018,\n  Montreal, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Every year, thousands of people receive consumer product related injuries.\nResearch indicates that online customer reviews can be processed to\nautonomously identify product safety issues. Early identification of safety\nissues can lead to earlier recalls, and thus fewer injuries and deaths. A\ndataset of product reviews from Amazon.com was compiled, along with\n\\emph{SaferProducts.gov} complaints and recall descriptions from the Consumer\nProduct Safety Commission (CPSC) and European Commission Rapid Alert system. A\nsystem was built to clean the collected text and to extract relevant features.\nDimensionality reduction was performed by computing feature relevance through a\nRandom Forest and discarding features with low information gain. Various\nclassifiers were analyzed, including Logistic Regression, SVMs,\nNa{\\\"i}ve-Bayes, Random Forests, and an Ensemble classifier. Experimentation\nwith various features and classifier combinations resulted in a logistic\nregression model with 66\\% precision in the top 50 reviews surfaced. This\nclassifier outperforms all benchmarks set by related literature and consumer\nproduct safety professionals.\n", "versions": [{"version": "v1", "created": "Fri, 27 Apr 2018 15:33:50 GMT"}, {"version": "v2", "created": "Sat, 21 Jul 2018 23:43:59 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Bleaney", "Graham", ""], ["Kuzyk", "Matthew", ""], ["Man", "Julian", ""], ["Mayanloo", "Hossein", ""], ["Tizhoosh", "H. R.", ""]]}, {"id": "1805.09776", "submitter": "Sergej Znamenskij", "authors": "Sergej V. Znamenskij", "title": "The parallel texts of books translations in the quality evaluation of\n  basic models and algorithms for the similarity of symbol strings", "comments": "5 pages, 16 figures. The paper has been withdrawn from the XX\n  International Conference \"Data Analytics and Management in Data Intensive\n  Domains\" (DAMDID/RCDL'2018), Moscow, Russia, October 9-12, 2018. Paper can\n  disorient reader due to mistake in script that produced illustrations.\n  Corrected full version has been published in\n  DOI:10.25209/2079-3316-2018-9-4-561-578", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This numeric evaluation of string metric accuracy is based on the following\nidea: taking the paragraph of text in one language sort all paragraphs of the\ndocument in other language by similarity with given paragraph string and\nconsider place of the right translation as the value of the evaluation score.\nSuch a search of proper translation provides an objective and reproducible\nquality assessment for known similarity metrics and shows the most accurate\nones.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 16:55:29 GMT"}, {"version": "v2", "created": "Wed, 13 Feb 2019 05:47:47 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 10:13:37 GMT"}], "update_date": "2019-02-22", "authors_parsed": [["Znamenskij", "Sergej V.", ""]]}, {"id": "1805.09780", "submitter": "Abhirut Gupta", "authors": "Abhirut Gupta, Abhay Khosla, Gautam Singh, Gargi Dasgupta", "title": "Mining Procedures from Technical Support Documents", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Guided troubleshooting is an inherent task in the domain of technical support\nservices. When a customer experiences an issue with the functioning of a\ntechnical service or a product, an expert user helps guide the customer through\na set of steps comprising a troubleshooting procedure. The objective is to\nidentify the source of the problem through a set of diagnostic steps and\nobservations, and arrive at a resolution. Procedures containing these set of\ndiagnostic steps and observations in response to different problems are common\nartifacts in the body of technical support documentation. The ability to use\nmachine learning and linguistics to understand and leverage these procedures\nfor applications like intelligent chatbots or robotic process automation, is\ncrucial. Existing research on question answering or intelligent chatbots does\nnot look within procedures or deep-understand them. In this paper, we outline a\nsystem for mining procedures from technical support documents. We create models\nfor solving important subproblems like extraction of procedures, identifying\ndecision points within procedures, identifying blocks of instructions\ncorresponding to these decision points and mapping instructions within a\ndecision block. We also release a dataset containing our manual annotations on\npublicly available support documents, to promote further research on the\nproblem.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 16:58:24 GMT"}], "update_date": "2018-05-25", "authors_parsed": [["Gupta", "Abhirut", ""], ["Khosla", "Abhay", ""], ["Singh", "Gautam", ""], ["Dasgupta", "Gargi", ""]]}, {"id": "1805.09912", "submitter": "Maria Fernanda Moura", "authors": "Maria Fernanda Moura, Fabiano Fernandes dos Santos, and Solange\n  Oliveira Rezende", "title": "An experimental comparison of label selection methods for hierarchical\n  document clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The focus of this paper is on the evaluation of sixteen labeling methods for\nhierarchical document clusters over five datasets. All of the methods are\nindependent from clustering algorithms, applied subsequently to the dendrogram\nconstruction and based on probabilistic dependence relations among labels and\nclusters. To reach a fair comparison as well as a standard benchmark, we\nrewrote and presented the labeling methods in a similar notation. The\nexperimental results were analyzed through a proposed evaluation methodology\nbased on: (i) data standardization before applying the cluster labeling methods\nand over the labeling results; (ii) a particular information retrieval process,\nusing the obtained labels and their hierarchical relations to construct the\nsearch queries; (iii) evaluation of the retrieval process through precision,\nrecall and F measure; (iv) variance analysis of the retrieval results to better\nunderstanding the differences among the labeling methods; and, (v) the\nemulation of a human judgment through the analysis of a topic observed\ncoherence measure - normalized Pointwise Mutual Information (PMI). Applying the\nmethodology, we are able to highlight the advantages of certain methods: to\ncapture specific information; for a better document hierarchy comprehension at\ndifferent levels of granularity; and, to capture the most coherent labels\nthrough the label selections. Finally, the experimental results demonstrated\nthat the label selection methods which hardly consider hierarchical relations\nhad the best results.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2018 21:46:24 GMT"}], "update_date": "2018-05-28", "authors_parsed": [["Moura", "Maria Fernanda", ""], ["Santos", "Fabiano Fernandes dos", ""], ["Rezende", "Solange Oliveira", ""]]}, {"id": "1805.10364", "submitter": "Hojjat Aghakhani", "authors": "Hojjat Aghakhani, Aravind Machiry, Shirin Nilizadeh, Christopher\n  Kruegel, and Giovanni Vigna", "title": "Detecting Deceptive Reviews using Generative Adversarial Networks", "comments": "accepted at 1st Deep Learning and Security Workshop co-located with\n  the 39th IEEE Symposium on Security and Privacy", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.CL cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past few years, consumer review sites have become the main target of\ndeceptive opinion spam, where fictitious opinions or reviews are deliberately\nwritten to sound authentic. Most of the existing work to detect the deceptive\nreviews focus on building supervised classifiers based on syntactic and lexical\npatterns of an opinion. With the successful use of Neural Networks on various\nclassification applications, in this paper, we propose FakeGAN a system that\nfor the first time augments and adopts Generative Adversarial Networks (GANs)\nfor a text classification task, in particular, detecting deceptive reviews.\nUnlike standard GAN models which have a single Generator and Discriminator\nmodel, FakeGAN uses two discriminator models and one generative model. The\ngenerator is modeled as a stochastic policy agent in reinforcement learning\n(RL), and the discriminators use Monte Carlo search algorithm to estimate and\npass the intermediate action-value as the RL reward to the generator. Providing\nthe generator model with two discriminator models avoids the mod collapse issue\nby learning from both distributions of truthful and deceptive reviews. Indeed,\nour experiments show that using two discriminators provides FakeGAN high\nstability, which is a known issue for GAN architectures. While FakeGAN is built\nupon a semi-supervised classifier, known for less accuracy, our evaluation\nresults on a dataset of TripAdvisor hotel reviews show the same performance in\nterms of accuracy as of the state-of-the-art approaches that apply supervised\nmachine learning. These results indicate that GANs can be effective for text\nclassification tasks. Specifically, FakeGAN is effective at detecting deceptive\nreviews.\n", "versions": [{"version": "v1", "created": "Fri, 25 May 2018 21:06:56 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Aghakhani", "Hojjat", ""], ["Machiry", "Aravind", ""], ["Nilizadeh", "Shirin", ""], ["Kruegel", "Christopher", ""], ["Vigna", "Giovanni", ""]]}, {"id": "1805.10505", "submitter": "Panagiotis Papadopoulos", "authors": "Panagiotis Papadopoulos, Nicolas Kourtellis, Evangelos P. Markatos", "title": "Cookie Synchronization: Everything You Always Wanted to Know But Were\n  Afraid to Ask", "comments": null, "journal-ref": "Proceedings of the 2018 World Wide Web Conference (WWW'19)", "doi": "10.1145/3308558.3313542", "report-no": null, "categories": "cs.IR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User data is the primary input of digital advertising, fueling the free\nInternet as we know it. As a result, web companies invest a lot in elaborate\ntracking mechanisms to acquire user data that can sell to data markets and\nadvertisers. However, with same-origin policy, and cookies as a primary\nidentification mechanism on the web, each tracker knows the same user with a\ndifferent ID. To mitigate this, Cookie Synchronization (CSync) came to the\nrescue, facilitating an information sharing channel between third parties that\nmay or not have direct access to the website the user visits. In the\nbackground, with CSync, they merge user data they own, but also reconstruct a\nuser's browsing history, bypassing the same origin policy. In this paper, we\nperform a first to our knowledge in-depth study of CSync in the wild, using a\nyear-long weblog from 850 real mobile users. Through our study, we aim to\nunderstand the characteristics of the CSync protocol and the impact it has on\nweb users' privacy. For this, we design and implement CONRAD, a holistic\nmechanism to detect CSync events at real time, and the privacy loss on the user\nside, even when the synced IDs are obfuscated. Using CONRAD, we find that 97%\nof the regular web users are exposed to CSync: most of them within the first\nweek of their browsing, and the median userID gets leaked, on average, to 3.5\ndifferent domains. Finally, we see that CSync increases the number of domains\nthat track the user by a factor of 6.75.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2018 17:00:07 GMT"}, {"version": "v2", "created": "Wed, 27 Mar 2019 21:58:48 GMT"}, {"version": "v3", "created": "Tue, 25 Feb 2020 17:13:54 GMT"}], "update_date": "2020-02-26", "authors_parsed": [["Papadopoulos", "Panagiotis", ""], ["Kourtellis", "Nicolas", ""], ["Markatos", "Evangelos P.", ""]]}, {"id": "1805.10685", "submitter": "Keet Sugathadasa Mr", "authors": "Keet Sugathadasa, Buddhi Ayesha, Nisansa de Silva, Amal Shehan Perera,\n  Vindula Jayawardana, Dimuthu Lakmal, Madhavi Perera", "title": "Legal Document Retrieval using Document Vector Embeddings and Deep\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domain specific information retrieval process has been a prominent and\nongoing research in the field of natural language processing. Many researchers\nhave incorporated different techniques to overcome the technical and domain\nspecificity and provide a mature model for various domains of interest. The\nmain bottleneck in these studies is the heavy coupling of domain experts, that\nmakes the entire process to be time consuming and cumbersome. In this study, we\nhave developed three novel models which are compared against a golden standard\ngenerated via the on line repositories provided, specifically for the legal\ndomain. The three different models incorporated vector space representations of\nthe legal domain, where document vector generation was done in two different\nmechanisms and as an ensemble of the above two. This study contains the\nresearch being carried out in the process of representing legal case documents\ninto different vector spaces, whilst incorporating semantic word measures and\nnatural language processing techniques. The ensemble model built in this study,\nshows a significantly higher accuracy level, which indeed proves the need for\nincorporation of domain specific semantic similarity measures into the\ninformation retrieval process. This study also shows, the impact of varying\ndistribution of the word similarity measures, against varying document vector\ndimensions, which can lead to improvements in the process of legal information\nretrieval.\n", "versions": [{"version": "v1", "created": "Sun, 27 May 2018 20:55:50 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Sugathadasa", "Keet", ""], ["Ayesha", "Buddhi", ""], ["de Silva", "Nisansa", ""], ["Perera", "Amal Shehan", ""], ["Jayawardana", "Vindula", ""], ["Lakmal", "Dimuthu", ""], ["Perera", "Madhavi", ""]]}, {"id": "1805.11008", "submitter": "Kuan Liu", "authors": "Kuan Liu and Xing Shi and Prem Natarajan", "title": "A Sequential Embedding Approach for Item Recommendation with\n  Heterogeneous Attributes", "comments": "A shorter version appeared in ICDM 2017 SERecsys workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Attributes, such as metadata and profile, carry useful information which in\nprinciple can help improve accuracy in recommender systems. However, existing\napproaches have difficulty in fully leveraging attribute information due to\npractical challenges such as heterogeneity and sparseness. These approaches\nalso fail to combine recurrent neural networks which have recently shown\neffectiveness in item recommendations in applications such as video and music\nbrowsing. To overcome the challenges and to harvest the advantages of sequence\nmodels, we present a novel approach, Heterogeneous Attribute Recurrent Neural\nNetworks (HA-RNN), which incorporates heterogeneous attributes and captures\nsequential dependencies in \\textit{both} items and attributes. HA-RNN extends\nrecurrent neural networks with 1) a hierarchical attribute combination input\nlayer and 2) an output attribute embedding layer. We conduct extensive\nexperiments on two large-scale datasets. The new approach show significant\nimprovements over the state-of-the-art models. Our ablation experiments\ndemonstrate the effectiveness of the two components to address heterogeneous\nattribute challenges including variable lengths and attribute sparseness. We\nfurther investigate why sequence modeling works well by conducting exploratory\nstudies and show sequence models are more effective when data scale increases.\n", "versions": [{"version": "v1", "created": "Mon, 28 May 2018 16:07:46 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Liu", "Kuan", ""], ["Shi", "Xing", ""], ["Natarajan", "Prem", ""]]}, {"id": "1805.11404", "submitter": "Arnim Bleier", "authors": "Andreas Niekler, Arnim Bleier, Christian Kahmann, Lisa Posch, Gregor\n  Wiedemann, Kenan Erdogan, Gerhard Heyer, Markus Strohmaier", "title": "iLCM - A Virtual Research Infrastructure for Large-Scale Qualitative\n  Data", "comments": "11th edition of the Language Resources and Evaluation Conference\n  (LREC)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The iLCM project pursues the development of an integrated research\nenvironment for the analysis of structured and unstructured data in a \"Software\nas a Service\" architecture (SaaS). The research environment addresses\nrequirements for the quantitative evaluation of large amounts of qualitative\ndata with text mining methods as well as requirements for the reproducibility\nof data-driven research designs in the social sciences. For this, the iLCM\nresearch environment comprises two central components. First, the Leipzig\nCorpus Miner (LCM), a decentralized SaaS application for the analysis of large\namounts of news texts developed in a previous Digital Humanities project.\nSecond, the text mining tools implemented in the LCM are extended by an \"Open\nResearch Computing\" (ORC) environment for executable script documents,\nso-called \"notebooks\". This novel integration allows to combine generic,\nhigh-performance methods to process large amounts of unstructured text data and\nwith individual program scripts to address specific research requirements in\ncomputational social science and digital humanities.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2018 10:24:11 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Niekler", "Andreas", ""], ["Bleier", "Arnim", ""], ["Kahmann", "Christian", ""], ["Posch", "Lisa", ""], ["Wiedemann", "Gregor", ""], ["Erdogan", "Kenan", ""], ["Heyer", "Gerhard", ""], ["Strohmaier", "Markus", ""]]}, {"id": "1805.11535", "submitter": "Yi Tay", "authors": "Yi Tay, Anh Tuan Luu, Siu Cheung Hui", "title": "CoupleNet: Paying Attention to Couples with Coupled Attention for\n  Relationship Recommendation", "comments": "Accepted at ICWSM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dating and romantic relationships not only play a huge role in our personal\nlives but also collectively influence and shape society. Today, many romantic\npartnerships originate from the Internet, signifying the importance of\ntechnology and the web in modern dating. In this paper, we present a text-based\ncomputational approach for estimating the relationship compatibility of two\nusers on social media. Unlike many previous works that propose reciprocal\nrecommender systems for online dating websites, we devise a distant supervision\nheuristic to obtain real world couples from social platforms such as Twitter.\nOur approach, the CoupleNet is an end-to-end deep learning based estimator that\nanalyzes the social profiles of two users and subsequently performs a\nsimilarity match between the users. Intuitively, our approach performs both\nuser profiling and match-making within a unified end-to-end framework.\nCoupleNet utilizes hierarchical recurrent neural models for learning\nrepresentations of user profiles and subsequently coupled attention mechanisms\nto fuse information aggregated from two users. To the best of our knowledge,\nour approach is the first data-driven deep learning approach for our novel\nrelationship recommendation problem. We benchmark our CoupleNet against several\nmachine learning and deep learning baselines. Experimental results show that\nour approach outperforms all approaches significantly in terms of precision.\nQualitative analysis shows that our model is capable of also producing\nexplainable results to users.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 15:14:41 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Tay", "Yi", ""], ["Luu", "Anh Tuan", ""], ["Hui", "Siu Cheung", ""]]}, {"id": "1805.11537", "submitter": "Ludovik Coba <", "authors": "Ludovik Coba, Markus Zanker, Laurens Rook, Panagiotis Symeonidis", "title": "Decision Making of Maximizers and Satisficers Based on Collaborative\n  Explanations", "comments": null, "journal-ref": null, "doi": "10.1145/3301275.3302304", "report-no": null, "categories": "cs.IR cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rating-based summary statistics are ubiquitous in e-commerce, and often are\ncrucial components in personalized recommendation mechanisms. Largely left\nunexplored, however, is the issue to what extent the descriptives of rating\ndistributions influence the decision making of online consumers. We conducted a\nconjoint experiment to explore how different summarizations of rating\ndistributions (i.e., in the form of the number of ratings, mean, variance,\nskewness or the origin of the ratings) impact users' decision making. Results\nfrom over 200 participants indicate that users are primarily guided by the mean\nand the number of ratings and to a lesser degree by the variance, and the\norigin of a rating. We also looked into the maximizing behavioral tendencies of\nour participants, and found that in particular participants scoring high on the\nDecision Difficulty subscale displayed other sensitivities regarding the way in\nwhich rating distributions were summarized than others.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2018 15:15:15 GMT"}], "update_date": "2019-05-31", "authors_parsed": [["Coba", "Ludovik", ""], ["Zanker", "Markus", ""], ["Rook", "Laurens", ""], ["Symeonidis", "Panagiotis", ""]]}, {"id": "1805.11814", "submitter": "Phuong Anh Nguyen Mr", "authors": "Phuong Anh Nguyen, Yi-Jie Lu, Hao Zhang, Chong-Wah Ngo", "title": "The VIREO KIS at VBS 2018", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper presents the video browsing tool of VIREO team which has\nbeen used in the Video Browser Showdown 2018. All added functions in the final\nversion are introduced and experiences gained from the benchmark are also\nshared.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 05:32:02 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Nguyen", "Phuong Anh", ""], ["Lu", "Yi-Jie", ""], ["Zhang", "Hao", ""], ["Ngo", "Chong-Wah", ""]]}, {"id": "1805.11878", "submitter": "Dominik Kowald PhD", "authors": "Dominik Kowald", "title": "Modeling Cognitive Processes in Social Tagging to Improve Tag\n  Recommendations", "comments": "PHD-Symposium paper @ WWW2015. Supervised by Prof. Stefanie\n  Lindstaedt, Prof. Tobias Ley and Ass-Prof. Elisabeth Lex", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.HC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the emergence of Web 2.0, tag recommenders have become important tools,\nwhich aim to support users in finding descriptive tags for their bookmarked\nresources. Although current algorithms provide good results in terms of tag\nprediction accuracy, they are often designed in a data-driven way and thus,\nlack a thorough understanding of the cognitive processes that play a role when\npeople assign tags to resources. This thesis aims at modeling these cognitive\ndynamics in social tagging in order to improve tag recommendations and to\nbetter understand the underlying processes.\n  As a first attempt in this direction, we have implemented an interplay\nbetween individual micro-level (e.g., categorizing resources or temporal\ndynamics) and collective macro-level (e.g., imitating other users' tags)\nprocesses in the form of a novel tag recommender algorithm. The preliminary\nresults for datasets gathered from BibSonomy, CiteULike and Delicious show that\nour proposed approach can outperform current state-of-the-art algorithms, such\nas Collaborative Filtering, FolkRank or Pairwise Interaction Tensor\nFactorization. We conclude that recommender systems can be improved by\nincorporating related principles of human cognition.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 09:33:29 GMT"}], "update_date": "2018-05-31", "authors_parsed": [["Kowald", "Dominik", ""]]}, {"id": "1805.12118", "submitter": "Andrew Collins Mr", "authors": "Andrew Collins, Dominika Tkaczyk, Joeran Beel", "title": "One-at-a-time: A Meta-Learning Recommender-System for\n  Recommendation-Algorithm Selection on Micro Level", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effectiveness of recommendation algorithms is typically assessed with\nevaluation metrics such as root mean square error, F1, or click through rates,\ncalculated over entire datasets. The best algorithm is typically chosen based\non these overall metrics. However, there is no single-best algorithm for all\nusers, items, and contexts. Choosing a single algorithm based on overall\nevaluation results is not optimal. In this paper, we propose a\nmeta-learning-based approach to recommendation, which aims to select the best\nalgorithm for each user-item pair. We evaluate our approach using the MovieLens\n100K and 1M datasets. Our approach (RMSE, 100K: 0.973; 1M: 0.908) did not\noutperform the single-best algorithm, SVD++ (RMSE, 100K: 0.942; 1M: 0.887). We\nalso develop a distinction between meta-learners that operate per-instance\n(micro-level), per-data subset (mid-level), and per-dataset (global level). Our\nevaluation shows that a hypothetically perfect micro-level meta-learner would\nimprove RMSE by 25.5% for the MovieLens 100K and 1M datasets, compared to the\noverall-best algorithms used.\n", "versions": [{"version": "v1", "created": "Wed, 30 May 2018 17:58:21 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 09:11:19 GMT"}, {"version": "v3", "created": "Fri, 30 Nov 2018 16:43:20 GMT"}], "update_date": "2018-12-03", "authors_parsed": [["Collins", "Andrew", ""], ["Tkaczyk", "Dominika", ""], ["Beel", "Joeran", ""]]}, {"id": "1805.12312", "submitter": "Lu Zheng", "authors": "Lu Zheng and Zhao Tan and Kun Han and Ren Mao", "title": "Collaborative Multi-modal deep learning for the personalized product\n  retrieval in Facebook Marketplace", "comments": "6 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Facebook Marketplace is quickly gaining momentum among consumers as a favored\ncustomer-to-customer (C2C) product trading platform. The recommendation system\nbehind it helps to significantly improve the user experience. Building the\nrecommendation system for Facebook Marketplace is challenging for two reasons:\n1) Scalability: the number of products in Facebook Marketplace is huge. Tens of\nthousands of products need to be scored and recommended within a couple hundred\nmilliseconds for millions of users every day; 2) Cold start: the life span of\nthe C2C products is very short and the user activities on the products are\nsparse. Thus it is difficult to accumulate enough product level signals for\nrecommendation and we are facing a significant cold start issue. In this paper,\nwe propose to address both the scalability and the cold-start issue by building\na collaborative multi-modal deep learning based retrieval system where the\ncompact embeddings for the users and the products are trained with the\nmulti-modal content information. This system shows significant improvement over\nthe benchmark in online and off-line experiments: In the online experiment, it\nincreases the number of messages initiated by the buyer to the seller by\n+26.95%; in the off-line experiment, it improves the prediction accuracy by\n+9.58%.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 03:41:41 GMT"}], "update_date": "2018-06-01", "authors_parsed": [["Zheng", "Lu", ""], ["Tan", "Zhao", ""], ["Han", "Kun", ""], ["Mao", "Ren", ""]]}, {"id": "1805.12505", "submitter": "Shilun Zhang", "authors": "Shilun Zhang, Mat\\'u\\v{s} Medo, Linyuan L\\\"u, Manuel Sebastian Mariani", "title": "The long-term impact of ranking algorithms in growing networks", "comments": "Main text (pp. 1-27) and Supplementary Material (pp. 28-49)", "journal-ref": "Information Sciences 488, 257-271 (2019)", "doi": "10.1016/j.ins.2019.03.021", "report-no": null, "categories": "physics.soc-ph cs.CY cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When we search online for content, we are constantly exposed to rankings. For\nexample, web search results are presented as a ranking, and online bookstores\noften show us lists of best-selling books. While popularity-based ranking\nalgorithms (like Google's PageRank) have been extensively studied in previous\nworks, we still lack a clear understanding of their potential systemic\nconsequences. In this work, we fill this gap by introducing a new model of\nnetwork growth that allows us to compare the properties of the networks\ngenerated under the influence of different ranking algorithms. We show that by\ncorrecting for the omnipresent age bias of popularity-based ranking algorithms,\nthe resulting networks exhibit a significantly larger agreement between the\nnodes' inherent quality and their long-term popularity, and a less concentrated\npopularity distribution. To further promote popularity diversity, we introduce\nand validate a perturbation of the original rankings where a small number of\nrandomly-selected nodes are promoted to the top of the ranking. Our findings\nmove the first steps toward a model-based understanding of the long-term impact\nof popularity-based ranking algorithms, and could be used as an informative\ntool for the design of improved information filtering tools.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2018 15:06:09 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2018 04:53:00 GMT"}], "update_date": "2019-03-28", "authors_parsed": [["Zhang", "Shilun", ""], ["Medo", "Mat\u00fa\u0161", ""], ["L\u00fc", "Linyuan", ""], ["Mariani", "Manuel Sebastian", ""]]}]