[{"id": "0710.0169", "submitter": "Andrew Krizhanovsky A", "authors": "A. A. Krizhanovsky", "title": "Evaluation experiments on related terms search in Wikipedia: Information\n  Content and Adapted HITS (In Russian)", "comments": "10 pages, 1 figure, 3 tables, in Russian, short version of the paper\n  to be published in Proceedings of the Wiki-Conference 2007, Russia, St.\n  Petersburg, October 27-28. http://tinyurl.com/2czd6e ; v3: +figure; v4: typo\n  in Table 3; v5: +desc (res_hypo formula); v6: typo", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": null, "abstract": "  The classification of metrics and algorithms search for related terms via\nWordNet, Roget's Thesaurus, and Wikipedia was extended to include adapted HITS\nalgorithm. Evaluation experiments on Information Content and adapted HITS\nalgorithm are described. The test collection of Russian word pairs with\nhuman-assigned similarity judgments is proposed.\n  -----\n  Klassifikacija metrik i algoritmov poiska semanticheski blizkih slov v\ntezaurusah WordNet, Rozhe i jenciklopedii Vikipedija rasshirena adaptirovannym\nHITS algoritmom. S pomow'ju jeksperimentov v Vikipedii oceneny metrika\nInformation Content i adaptirovannyj algoritm HITS. Predlozhen resurs dlja\nocenki semanticheskoj blizosti russkih slov.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2007 16:04:52 GMT"}, {"version": "v2", "created": "Wed, 3 Oct 2007 06:21:01 GMT"}, {"version": "v3", "created": "Sat, 6 Oct 2007 15:38:57 GMT"}, {"version": "v4", "created": "Sun, 14 Oct 2007 14:44:03 GMT"}, {"version": "v5", "created": "Sun, 4 Nov 2007 11:05:26 GMT"}, {"version": "v6", "created": "Wed, 16 Jan 2008 17:31:14 GMT"}], "update_date": "2008-01-16", "authors_parsed": [["Krizhanovsky", "A. A.", ""]]}, {"id": "0710.1404", "submitter": "M Sabu THAMPI", "authors": "Sabu M. Thampi, Ashwin a K", "title": "Performance Comparison of Persistence Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": null, "abstract": "  One of the essential and most complex components in the software development\nprocess is the database. The complexity increases when the \"orientation\" of the\ninteracting components differs. A persistence framework moves the program data\nin its most natural form to and from a permanent data store, the database. Thus\na persistence framework manages the database and the mapping between the\ndatabase and the objects. This paper compares the performance of two\npersistence frameworks ? Hibernate and iBatis?s SQLMaps using a banking\ndatabase. The performance of both of these tools in single and multi-user\nenvironments are evaluated.\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2007 08:22:53 GMT"}], "update_date": "2007-10-09", "authors_parsed": [["Thampi", "Sabu M.", ""], ["K", "Ashwin a", ""]]}, {"id": "0710.1525", "submitter": "Sebastiano Vigna", "authors": "Sebastiano Vigna, Paolo Boldi", "title": "Efficient Optimally Lazy Algorithms for Minimal-Interval Semantics", "comments": "24 pages, 4 figures. A preliminary (now outdated) version was\n  presented at SPIRE 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimal-interval semantics associates with each query over a document a set\nof intervals, called witnesses, that are incomparable with respect to inclusion\n(i.e., they form an antichain): witnesses define the minimal regions of the\ndocument satisfying the query. Minimal-interval semantics makes it easy to\ndefine and compute several sophisticated proximity operators, provides snippets\nfor user presentation, and can be used to rank documents. In this paper we\nprovide algorithms for computing conjunction and disjunction that are linear in\nthe number of intervals and logarithmic in the number of operands; for\nadditional operators, such as ordered conjunction and Brouwerian difference, we\nprovide linear algorithms. In all cases, space is linear in the number of\noperands. More importantly, we define a formal notion of optimal laziness, and\neither prove it, or prove its impossibility, for each algorithm. We cast our\nresults in a general framework of antichains of intervals on total orders,\nmaking our algorithms directly applicable to other domains.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2007 12:15:48 GMT"}, {"version": "v2", "created": "Thu, 11 Aug 2016 08:57:30 GMT"}], "update_date": "2016-08-12", "authors_parsed": [["Vigna", "Sebastiano", ""], ["Boldi", "Paolo", ""]]}, {"id": "0710.1962", "submitter": "Sebastiano Vigna", "authors": "Sebastiano Vigna", "title": "Stanford Matrix Considered Harmful", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": null, "abstract": "  This note argues about the validity of web-graph data used in the literature.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2007 10:03:03 GMT"}], "update_date": "2007-10-11", "authors_parsed": [["Vigna", "Sebastiano", ""]]}, {"id": "0710.2228", "submitter": "Matus Medo", "authors": "Yi-Cheng Zhang, Matus Medo, Jie Ren, Tao Zhou, Tao Li, and Fan Yang", "title": "Recommendation model based on opinion diffusion", "comments": "5 pages, 2 figures", "journal-ref": "Europhysics Letters 80 (2007) 68003", "doi": "10.1209/0295-5075/80/68003", "report-no": null, "categories": "physics.soc-ph cs.CY cs.IR physics.data-an", "license": null, "abstract": "  Information overload in the modern society calls for highly efficient\nrecommendation algorithms. In this letter we present a novel diffusion based\nrecommendation model, with users' ratings built into a transition matrix. To\nspeed up computation we introduce a Green function method. The numerical tests\non a benchmark database show that our prediction is superior to the standard\nrecommendation methods.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2007 12:54:07 GMT"}, {"version": "v2", "created": "Thu, 15 Nov 2007 13:01:50 GMT"}], "update_date": "2007-11-15", "authors_parsed": [["Zhang", "Yi-Cheng", ""], ["Medo", "Matus", ""], ["Ren", "Jie", ""], ["Zhou", "Tao", ""], ["Li", "Tao", ""], ["Yang", "Fan", ""]]}, {"id": "0710.2889", "submitter": "Nir Ailon", "authors": "Nir Ailon and Mehryar Mohri", "title": "An efficient reduction of ranking to classification", "comments": "Revised paper: Improved results: Upper bounds for regret (constant\n  down to 1 for bipartite case) and also lower bound on deterministic\n  algorithms for bipartite case. Total number of pages 22", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": null, "abstract": "  This paper describes an efficient reduction of the learning problem of\nranking to binary classification. The reduction guarantees an average pairwise\nmisranking regret of at most that of the binary classifier regret, improving a\nrecent result of Balcan et al which only guarantees a factor of 2. Moreover,\nour reduction applies to a broader class of ranking loss functions, admits a\nsimpler proof, and the expected running time complexity of our algorithm in\nterms of number of calls to a classifier or preference function is improved\nfrom $\\Omega(n^2)$ to $O(n \\log n)$. In addition, when the top $k$ ranked\nelements only are required ($k \\ll n$), as in many applications in information\nextraction or search engines, the time complexity of our algorithm can be\nfurther reduced to $O(k \\log k + n)$. Our reduction and algorithm are thus\npractical for realistic applications where the number of points to rank exceeds\nseveral thousands. Much of our results also extend beyond the bipartite case\npreviously studied.\n  Our rediction is a randomized one. To complement our result, we also derive\nlower bounds on any deterministic reduction from binary (preference)\nclassification to ranking, implying that our use of a randomized reduction is\nessentially necessary for the guarantees we provide.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2007 18:25:15 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2007 00:02:44 GMT"}], "update_date": "2007-12-07", "authors_parsed": [["Ailon", "Nir", ""], ["Mohri", "Mehryar", ""]]}, {"id": "0710.3502", "submitter": "Stergos Afantenos", "authors": "Stergos D. Afantenos, V. Karkaletsis, P. Stamatopoulos and C. Halatsis", "title": "Using Synchronic and Diachronic Relations for Summarizing Multiple\n  Documents Describing Evolving Events", "comments": "45 pages, 6 figures. To appear in the Journal of Intelligent\n  Information Systems", "journal-ref": null, "doi": "10.1007/s10844-006-0025-9", "report-no": null, "categories": "cs.CL cs.IR", "license": null, "abstract": "  In this paper we present a fresh look at the problem of summarizing evolving\nevents from multiple sources. After a discussion concerning the nature of\nevolving events we introduce a distinction between linearly and non-linearly\nevolving events. We present then a general methodology for the automatic\ncreation of summaries from evolving events. At its heart lie the notions of\nSynchronic and Diachronic cross-document Relations (SDRs), whose aim is the\nidentification of similarities and differences between sources, from a\nsynchronical and diachronical perspective. SDRs do not connect documents or\ntextual elements found therein, but structures one might call messages.\nApplying this methodology will yield a set of messages and relations, SDRs,\nconnecting them, that is a graph which we call grid. We will show how such a\ngrid can be considered as the starting point of a Natural Language Generation\nSystem. The methodology is evaluated in two case-studies, one for linearly\nevolving events (descriptions of football matches) and another one for\nnon-linearly evolving events (terrorist incidents involving hostages). In both\ncases we evaluate the results produced by our computational systems.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2007 13:24:26 GMT"}], "update_date": "2007-10-19", "authors_parsed": [["Afantenos", "Stergos D.", ""], ["Karkaletsis", "V.", ""], ["Stamatopoulos", "P.", ""], ["Halatsis", "C.", ""]]}]