[{"id": "1312.0182", "submitter": "Haocheng Wu", "authors": "Haocheng Wu, Yunhua Hu, Hang Li, Enhong Chen", "title": "Query Segmentation for Relevance Ranking in Web Search", "comments": "25 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we try to answer the question of how to improve the\nstate-of-the-art methods for relevance ranking in web search by query\nsegmentation. Here, by query segmentation it is meant to segment the input\nquery into segments, typically natural language phrases, so that the\nperformance of relevance ranking in search is increased. We propose employing\nthe re-ranking approach in query segmentation, which first employs a generative\nmodel to create top $k$ candidates and then employs a discriminative model to\nre-rank the candidates to obtain the final segmentation result. The method has\nbeen widely utilized for structure prediction in natural language processing,\nbut has not been applied to query segmentation, as far as we know. Furthermore,\nwe propose a new method for using the result of query segmentation in relevance\nranking, which takes both the original query words and the segmented query\nphrases as units of query representation. We investigate whether our method can\nimprove three relevance models, namely BM25, key n-gram model, and dependency\nmodel. Our experimental results on three large scale web search datasets show\nthat our method can indeed significantly improve relevance ranking in all the\nthree cases.\n", "versions": [{"version": "v1", "created": "Sun, 1 Dec 2013 07:23:12 GMT"}], "update_date": "2013-12-03", "authors_parsed": [["Wu", "Haocheng", ""], ["Hu", "Yunhua", ""], ["Li", "Hang", ""], ["Chen", "Enhong", ""]]}, {"id": "1312.1286", "submitter": "Istiadi", "authors": "Istiadi and Azhari", "title": "An Ontology Model for Organizing Information Resources Sharing on\n  Personal Web", "comments": null, "journal-ref": "The Fifth International Symposium on Computational Science (ISCS\n  2012) Yogyakarta, Indonesia, May 15-16, 2012", "doi": null, "report-no": null, "categories": "cs.DL cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Retrieve information resources made by the machine processing may refer to\nmultiple sources. A personal web as part of information resources in the\nInternet requires a feature that can be understood by computer machines.\nTherefore, in this paper an ontology semantic web approach is used to map the\nresources in a meaningful scheme. In the design of concept, resources on the\nweb are viewed as documents that have some property and ownership. Domain\ninterest or web scope is used to describe a classification of resources that\nnavigate into relevant documents. If instances are completed to the concept,\nthen the ontology file can be loaded and shared as annotation on personal web.\nThis allows computer machine to query multiple ontology from different personal\nwebs that use it.\n", "versions": [{"version": "v1", "created": "Mon, 4 Nov 2013 05:26:29 GMT"}], "update_date": "2013-12-23", "authors_parsed": [["Istiadi", "", ""], ["Azhari", "", ""]]}, {"id": "1312.1448", "submitter": "Mohammed El-Dosuky", "authors": "M. A. El-Dosuky, M. Z. Rashad, T. T. Hamza, A.H. EL-Bassiouny", "title": "Food Recommendation using Ontology and Heuristics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems are needed to find food items of ones interest. We review\nrecommender systems and recommendation methods. We propose a food\npersonalization framework based on adaptive hypermedia. We extend Hermes\nframework with food recommendation functionality. We combine TF-IDF term\nextraction method with cosine similarity measure. Healthy heuristics and\nstandard food database are incorporated into the knowledgebase. Based on the\nperformed evaluation, we conclude that semantic recommender systems in general\noutperform traditional recommenders systems with respect to accuracy,\nprecision, and recall, and that the proposed recommender has a better F-measure\nthan existing semantic recommenders.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 06:50:30 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["El-Dosuky", "M. A.", ""], ["Rashad", "M. Z.", ""], ["Hamza", "T. T.", ""], ["EL-Bassiouny", "A. H.", ""]]}, {"id": "1312.1611", "submitter": "Eugene Kharitonov", "authors": "Eugene Kharitonov and Craig Macdonald and Pavel Serdyukov and Iadh\n  Ounis", "title": "Intent Models for Contextualising and Diversifying Query Suggestions", "comments": "A short version of this paper was presented at CIKM 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The query suggestion or auto-completion mechanisms help users to type less\nwhile interacting with a search engine. A basic approach that ranks suggestions\naccording to their frequency in the query logs is suboptimal. Firstly, many\ncandidate queries with the same prefix can be removed as redundant. Secondly,\nthe suggestions can also be personalised based on the user's context. These two\ndirections to improve the aforementioned mechanisms' quality can be in\nopposition: while the latter aims to promote suggestions that address search\nintents that a user is likely to have, the former aims to diversify the\nsuggestions to cover as many intents as possible. We introduce a\ncontextualisation framework that utilises a short-term context using the user's\nbehaviour within the current search session, such as the previous query, the\ndocuments examined, and the candidate query suggestions that the user has\ndiscarded. This short-term context is used to contextualise and diversify the\nranking of query suggestions, by modelling the user's information need as a\nmixture of intent-specific user models. The evaluation is performed offline on\na set of approximately 1.0M test user sessions. Our results suggest that the\nproposed approach significantly improves query suggestions compared to the\nbaseline approach.\n", "versions": [{"version": "v1", "created": "Thu, 5 Dec 2013 16:47:41 GMT"}], "update_date": "2013-12-06", "authors_parsed": [["Kharitonov", "Eugene", ""], ["Macdonald", "Craig", ""], ["Serdyukov", "Pavel", ""], ["Ounis", "Iadh", ""]]}, {"id": "1312.1860", "submitter": "Minyar Sassi", "authors": "Olfa Arfaoui, Minyar Sassi-Hidri", "title": "Flexible queries in XML native databases", "comments": "5 Pages, 1 Figure", "journal-ref": "International Conference on Control, Engineering & Information\n  Technology (CEIT), Proceedings Engineering & Technology, Vol. 4, pp. 100-104,\n  2013", "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To date, most of the XML native databases (DB) flexible querying systems are\nbased on exploiting the tree structure of their semi structured data (SSD).\nHowever, it becomes important to test the efficiency of Formal Concept Analysis\n(FCA) formalism for this type of data since it has been proved a great\nperformance in the field of information retrieval (IR). So, the IR in XML\ndatabases based on FCA is mainly based on the use of the lattice structure.\nEach concept of this lattice can be interpreted as a pair (response, query). In\nthis work, we provide a new flexible modeling of XML DB based on fuzzy FCA as a\nfirst step towards flexible querying of SSD.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 13:42:07 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Arfaoui", "Olfa", ""], ["Sassi-Hidri", "Minyar", ""]]}, {"id": "1312.1897", "submitter": "Toni Gruetze", "authors": "Toni Gruetze, Gjergji Kasneci, Zhe Zuo, Felix Naumann", "title": "Bootstrapped Grouping of Results to Ambiguous Person Name Queries", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Some of the main ranking features of today's search engines reflect result\npopularity and are based on ranking models, such as PageRank, implicit feedback\naggregation, and more. While such features yield satisfactory results for a\nwide range of queries, they aggravate the problem of search for ambiguous\nentities: Searching for a person yields satisfactory results only if the person\nwe are looking for is represented by a high-ranked Web page and all required\ninformation are contained in this page. Otherwise, the user has to either\nreformulate/refine the query or manually inspect low-ranked results to find the\nperson in question. A possible approach to solve this problem is to cluster the\nresults, so that each cluster represents one of the persons occurring in the\nanswer set. However clustering search results has proven to be a difficult\nendeavor by itself, where the clusters are typically of moderate quality.\n  A wealth of useful information about persons occurs in Web 2.0 platforms,\nsuch as LinkedIn, Wikipedia, Facebook, etc. Being human-generated, the\ninformation on these platforms is clean, focused, and already disambiguated. We\nshow that when searching for ambiguous person names the information from such\nplatforms can be bootstrapped to group the results according to the individuals\noccurring in them. We have evaluated our methods on a hand-labeled dataset of\naround 5,000 Web pages retrieved from Google queries on 50 ambiguous person\nnames.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 15:50:54 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Gruetze", "Toni", ""], ["Kasneci", "Gjergji", ""], ["Zuo", "Zhe", ""], ["Naumann", "Felix", ""]]}, {"id": "1312.1913", "submitter": "Robin Aly", "authors": "Robin Aly and Maria Eskevich and Roeland Ordelman and Gareth J.F.\n  Jones", "title": "Adapting Binary Information Retrieval Evaluation Metrics for\n  Segment-based Retrieval Tasks", "comments": "Explanation of evaluation measures for the linking task of the\n  MediaEval Workshop 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report describes metrics for the evaluation of the effectiveness of\nsegment-based retrieval based on existing binary information retrieval metrics.\nThis metrics are described in the context of a task for the hyperlinking of\nvideo segments. This evaluation approach re-uses existing evaluation measures\nfrom the standard Cranfield evaluation paradigm. Our adaptation approach can in\nprinciple be used with any kind of effectiveness measure that uses binary\nrelevance, and for other segment-baed retrieval tasks. In our video\nhyperlinking setting, we use precision at a cut-off rank n and mean average\nprecision.\n", "versions": [{"version": "v1", "created": "Fri, 6 Dec 2013 16:34:14 GMT"}], "update_date": "2013-12-09", "authors_parsed": [["Aly", "Robin", ""], ["Eskevich", "Maria", ""], ["Ordelman", "Roeland", ""], ["Jones", "Gareth J. F.", ""]]}, {"id": "1312.2061", "submitter": "Krishna A N", "authors": "Krishna A N, B G Prasad", "title": "Region and Location Based Indexing and Retrieval of MR-T2 Brain Tumor\n  Images", "comments": "10 pages", "journal-ref": "International Journal of Information Processing, 7(3):16-25, 2013", "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, region based and location based retrieval systems have been\nimplemented for retrieval of MR-T2 axial 2-D brain images. This is done by\nextracting and characterizing the tumor portion of 2-D brain slices by use of a\nsuitable threshold computed over the entire image. Indexing and retrieval is\nthen performed by computing texture features based on gray-tone\nspatial-dependence matrix of segmented regions. A Hash structure is used to\nindex all images. A combined index is adopted to point to all similar images in\nterms of the texture features. At query time, only those images that are in the\nsame hash bucket as those of the queried image are compared for similarity,\nthus reducing the search space and time.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2013 05:40:59 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["N", "Krishna A", ""], ["Prasad", "B G", ""]]}, {"id": "1312.2063", "submitter": "Amir Ingber", "authors": "Amir Ingber and Tsachy Weissman", "title": "The Minimal Compression Rate for Similarity Identification", "comments": "45 pages, 6 figures. Submitted to IEEE Transactions on Information\n  Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DB cs.IR math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, data compression deals with the problem of concisely\nrepresenting a data source, e.g. a sequence of letters, for the purpose of\neventual reproduction (either exact or approximate). In this work we are\ninterested in the case where the goal is to answer similarity queries about the\ncompressed sequence, i.e. to identify whether or not the original sequence is\nsimilar to a given query sequence. We study the fundamental tradeoff between\nthe compression rate and the reliability of the queries performed on compressed\ndata. For i.i.d. sequences, we characterize the minimal compression rate that\nallows query answers, that are reliable in the sense of having a vanishing\nfalse-positive probability, when false negatives are not allowed. The result is\npartially based on a previous work by Ahlswede et al., and the inherently\ntypical subset lemma plays a key role in the converse proof. We then\ncharacterize the compression rate achievable by schemes that use lossy source\ncodes as a building block, and show that such schemes are, in general,\nsuboptimal. Finally, we tackle the problem of evaluating the minimal\ncompression rate, by converting the problem to a sequence of convex programs\nthat can be solved efficiently.\n", "versions": [{"version": "v1", "created": "Sat, 7 Dec 2013 06:40:55 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Ingber", "Amir", ""], ["Weissman", "Tsachy", ""]]}, {"id": "1312.2244", "submitter": "Tao Wang", "authors": "Rumeng Li, Tao Wang, Xun Wang", "title": "Time-dependent Hierarchical Dirichlet Model for Timeline Generation", "comments": null, "journal-ref": "SDM(2015)p550-558", "doi": "10.1137/1.9781611974010.62", "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timeline Generation aims at summarizing news from different epochs and\ntelling readers how an event evolves. It is a new challenge that combines\nsalience ranking with novelty detection. For long-term public events, the main\ntopic usually includes various aspects across different epochs and each aspect\nhas its own evolving pattern. Existing approaches neglect such hierarchical\ntopic structure involved in the news corpus in timeline generation. In this\npaper, we develop a novel time-dependent Hierarchical Dirichlet Model (HDM) for\ntimeline generation. Our model can aptly detect different levels of topic\ninformation across corpus and such structure is further used for sentence\nselection. Based on the topic mined fro HDM, sentences are selected by\nconsidering different aspects such as relevance, coherence and coverage. We\ndevelop experimental systems to evaluate 8 long-term events that public\nconcern. Performance comparison between different systems demonstrates the\neffectiveness of our model in terms of ROUGE metrics.\n", "versions": [{"version": "v1", "created": "Sun, 8 Dec 2013 19:15:15 GMT"}, {"version": "v2", "created": "Mon, 21 Apr 2014 11:44:47 GMT"}, {"version": "v3", "created": "Tue, 14 Mar 2017 01:34:50 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Li", "Rumeng", ""], ["Wang", "Tao", ""], ["Wang", "Xun", ""]]}, {"id": "1312.2375", "submitter": "Ramachandra Rao Kurada Mr.", "authors": "RamachandraRao Kurada, Dr. K Karteeka Pavan", "title": "Novel text categorization by amalgamation of augmented k-nearest\n  neighborhood classification and k-medoids clustering", "comments": "13 Pages", "journal-ref": "International Journal of Computational Science & Information\n  Technology(IJCSITY)Vol.1,No.4,Nov2013,ISSN: 2320-7442", "doi": "10.5121/ijcsity.2013.1406", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning for text classification is the underpinning of document\ncataloging, news filtering, document steering and exemplification. In text\nmining realm, effective feature selection is significant to make the learning\ntask more accurate and competent. One of the traditional lazy text classifier\nk-Nearest Neighborhood (kNN) has a major pitfall in calculating the similarity\nbetween all the objects in training and testing sets, there by leads to\nexaggeration of both computational complexity of the algorithm and massive\nconsumption of main memory. To diminish these shortcomings in viewpoint of a\ndata-mining practitioner an amalgamative technique is proposed in this paper\nusing a novel restructured version of kNN called AugmentedkNN(AkNN) and\nk-Medoids(kMdd) clustering.The proposed work comprises preprocesses on the\ninitial training set by imposing attribute feature selection for reduction of\nhigh dimensionality, also it detects and excludes the high-fliers samples in\nthe initial training set and restructures a constrictedtraining set. The kMdd\nclustering algorithm generates the cluster centers (as interior objects) for\neach category and restructures the constricted training set with centroids.\nThis technique is amalgamated with AkNNclassifier that was prearranged with\ntext mining similarity measures. Eventually, significantweights and ranks were\nassigned to each object in the new training set based upon their accessory\ntowards the object in testing set. Experiments conducted on Reuters-21578 a UCI\nbenchmark text mining data set, and comparisons with traditional kNNclassifier\ndesignates the referredmethod yieldspreeminentrecitalin both clustering and\nclassification.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2013 10:36:22 GMT"}], "update_date": "2013-12-10", "authors_parsed": [["Kurada", "RamachandraRao", ""], ["Pavan", "Dr. K Karteeka", ""]]}, {"id": "1312.2459", "submitter": "Tiago Simas", "authors": "Tiago Simas and Luis M Rocha", "title": "Distance Closures on Complex Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cond-mat.dis-nn cs.IR nlin.CG physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To expand the toolbox available to network science, we study the isomorphism\nbetween distance and Fuzzy (proximity or strength) graphs. Distinct transitive\nclosures in Fuzzy graphs lead to closures of their isomorphic distance graphs\nwith widely different structural properties. For instance, the All Pairs\nShortest Paths (APSP) problem, based on the Dijkstra algorithm, is equivalent\nto a metric closure, which is only one of the possible ways to calculate\nshortest paths. Understanding and mapping this isomorphism is necessary to\nanalyse models of complex networks based on weighted graphs. Any conclusions\nderived from such models should take into account the distortions imposed on\ngraph topology when converting proximity/strength into distance graphs, to\nsubsequently compute path length and shortest path measures. We characterise\nthe isomorphism using the max-min and Dombi disjunction/conjunction pairs. This\nallows us to: (1) study alternative distance closures, such as those based on\ndiffusion, metric, and ultra-metric distances; (2) identify the operators\nclosest to the metric closure of distance graphs (the APSP), but which are\nlogically consistent; and (3) propose a simple method to compute alternative\ndistance closures using existing algorithms for the APSP. In particular, we\nshow that a specific diffusion distance is promising for community detection in\ncomplex networks, and is based on desirable axioms for logical inference or\napproximate reasoning on networks; it also provides a simple algebraic means to\ncompute diffusion processes on networks. Based on these results, we argue that\nchoosing different distance closures can lead to different conclusions about\nindirect associations on network data, as well as the structure of complex\nnetworks, and are thus important to consider.\n", "versions": [{"version": "v1", "created": "Mon, 9 Dec 2013 15:18:57 GMT"}, {"version": "v2", "created": "Tue, 10 Dec 2013 22:06:52 GMT"}, {"version": "v3", "created": "Thu, 16 Oct 2014 18:03:52 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Simas", "Tiago", ""], ["Rocha", "Luis M", ""]]}, {"id": "1312.2844", "submitter": "Patrice Descourt", "authors": "Norbert Rimoux, Patrice Descourt", "title": "mARC: Memory by Association and Reinforcement of Contexts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL nlin.AO nlin.CD", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper introduces the memory by Association and Reinforcement of Contexts\n(mARC). mARC is a novel data modeling technology rooted in the second\nquantization formulation of quantum mechanics. It is an all-purpose incremental\nand unsupervised data storage and retrieval system which can be applied to all\ntypes of signal or data, structured or unstructured, textual or not. mARC can\nbe applied to a wide range of information clas-sification and retrieval\nproblems like e-Discovery or contextual navigation. It can also for-mulated in\nthe artificial life framework a.k.a Conway \"Game Of Life\" Theory. In contrast\nto Conway approach, the objects evolve in a massively multidimensional space.\nIn order to start evaluating the potential of mARC we have built a mARC-based\nInternet search en-gine demonstrator with contextual functionality. We compare\nthe behavior of the mARC demonstrator with Google search both in terms of\nperformance and relevance. In the study we find that the mARC search engine\ndemonstrator outperforms Google search by an order of magnitude in response\ntime while providing more relevant results for some classes of queries.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 15:56:53 GMT"}], "update_date": "2013-12-11", "authors_parsed": [["Rimoux", "Norbert", ""], ["Descourt", "Patrice", ""]]}, {"id": "1312.2986", "submitter": "Konrad Kulakowski", "authors": "Konrad Ku{\\l}akowski", "title": "Notes on discrepancy in the pairwise comparisons method", "comments": "8 pages", "journal-ref": "EJOR, Vol. 245, Issue 1, Pages 333 - 337, 2015", "doi": "10.1016/j.ejor.2015.03.010", "report-no": null, "categories": "cs.DM cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pairwise comparisons method is a convenient tool used when the relative\norder among different concepts (alternatives) needs to be determined. One\npopular implementation of the method is based on solving an eigenvalue problem\nfor the pairwise comparisons matrix. In such cases the ranking result the\nprincipal eigenvector of the pairwise comparison matrix is adopted, whilst the\neigenvalue is used to determine the index of inconsistency. A lot of research\nhas been devoted to the critical analysis of the eigenvalue based approach. One\nof them is the work (Bana e Costa and Vansnick, 2008). In their work authors\ndefine the conditions of order preservation (COP) and show that even for a\nsufficiently consistent pairwise comparisons matrices, this condition can not\nbe met. The present work defines a more precise criteria for determining when\nthe COP is met. To formulate the criteria a discrepancy factor is used\ndescribing how far the input to the ranking procedure is from the ranking\nresult.\n", "versions": [{"version": "v1", "created": "Tue, 10 Dec 2013 22:43:09 GMT"}, {"version": "v2", "created": "Wed, 15 Jan 2014 23:48:59 GMT"}, {"version": "v3", "created": "Fri, 20 Jun 2014 11:17:29 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Ku\u0142akowski", "Konrad", ""]]}, {"id": "1312.3248", "submitter": "Antoine Amarilli", "authors": "Antoine Amarilli, Yael Amsterdamer, Tova Milo", "title": "On the Complexity of Mining Itemsets from the Crowd Using Taxonomies", "comments": "18 pages, 2 figures. To be published to ICDT'13. Added missing\n  acknowledgement", "journal-ref": null, "doi": "10.5441/002/icdt.2014.06", "report-no": null, "categories": "cs.DB cs.CC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of frequent itemset mining in domains where data is not\nrecorded in a conventional database but only exists in human knowledge. We\nprovide examples of such scenarios, and present a crowdsourcing model for them.\nThe model uses the crowd as an oracle to find out whether an itemset is\nfrequent or not, and relies on a known taxonomy of the item domain to guide the\nsearch for frequent itemsets. In the spirit of data mining with oracles, we\nanalyze the complexity of this problem in terms of (i) crowd complexity, that\nmeasures the number of crowd questions required to identify the frequent\nitemsets; and (ii) computational complexity, that measures the computational\neffort required to choose the questions. We provide lower and upper complexity\nbounds in terms of the size and structure of the input taxonomy, as well as the\nsize of a concise description of the output itemsets. We also provide\nconstructive algorithms that achieve the upper bounds, and consider more\nefficient variants for practical situations.\n", "versions": [{"version": "v1", "created": "Wed, 11 Dec 2013 17:15:39 GMT"}, {"version": "v2", "created": "Mon, 16 Dec 2013 11:50:11 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Amarilli", "Antoine", ""], ["Amsterdamer", "Yael", ""], ["Milo", "Tova", ""]]}, {"id": "1312.3872", "submitter": "Stephen Bensman", "authors": "Stephen J. Bensman", "title": "Eugene Garfield, Francis Narin, and PageRank: The Theoretical Bases of\n  the Google Search Engine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a test of the validity of using Google Scholar to\nevaluate the publications of researchers by comparing the premises on which its\nsearch engine, PageRank, is based, to those of Garfield's theory of citation\nindexing. It finds that the premises are identical and that PageRank and\nGarfield's theory of citation indexing validate each other.\n", "versions": [{"version": "v1", "created": "Fri, 13 Dec 2013 16:52:07 GMT"}], "update_date": "2013-12-16", "authors_parsed": [["Bensman", "Stephen J.", ""]]}, {"id": "1312.4036", "submitter": "Apoorv Narang", "authors": "Apoorv Narang and Srikanta Bedathur", "title": "Mind Your Language: Effects of Spoken Query Formulation on Retrieval\n  Effectiveness", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Voice search is becoming a popular mode for interacting with search engines.\nAs a result, research has gone into building better voice transcription\nengines, interfaces, and search engines that better handle inherent verbosity\nof queries. However, when one considers its use by non- native speakers of\nEnglish, another aspect that becomes important is the formulation of the query\nby users. In this paper, we present the results of a preliminary study that we\nconducted with non-native English speakers who formulate queries for given\nretrieval tasks. Our results show that the current search engines are sensitive\nin their rankings to the query formulation, and thus highlights the need for\ndeveloping more robust ranking methods.\n", "versions": [{"version": "v1", "created": "Sat, 14 Dec 2013 12:13:58 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Narang", "Apoorv", ""], ["Bedathur", "Srikanta", ""]]}, {"id": "1312.4425", "submitter": "Winfried G\\\"odert", "authors": "Winfried G\\\"odert", "title": "An Ontology-based Model for Indexing and Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Starting from an unsolved problem of information retrieval this paper\npresents an ontology-based model for indexing and retrieval. The model combines\nthe methods and experiences of cognitive-to-interpret indexing languages with\nthe strengths and possibilities of formal knowledge representation. The core\ncomponent of the model uses inferences along the paths of typed relations\nbetween the entities of a knowledge representation for enabling the\ndetermination of hit quantities in the context of retrieval processes. The\nentities are arranged in aspect-oriented facets to ensure a consistent\nhierarchical structure. The possible consequences for indexing and retrieval\nare discussed.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2013 16:49:32 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["G\u00f6dert", "Winfried", ""]]}, {"id": "1312.4794", "submitter": "Thabet Slimani", "authors": "Thabet Slimani", "title": "Semantic Annotation: The Mainstay of Semantic Web", "comments": "8 pages, 3 figures", "journal-ref": "International Journal of Computer Applications Technology and\n  Research, Volume 2, Issue 6, 763-770, 2013", "doi": "10.7753/IJCATR0206.1025", "report-no": null, "categories": "cs.DL cs.AI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given that semantic Web realization is based on the critical mass of metadata\naccessibility and the representation of data with formal knowledge, it needs to\ngenerate metadata that is specific, easy to understand and well-defined.\nHowever, semantic annotation of the web documents is the successful way to make\nthe Semantic Web vision a reality. This paper introduces the Semantic Web and\nits vision (stack layers) with regard to some concept definitions that helps\nthe understanding of semantic annotation. Additionally, this paper introduces\nthe semantic annotation categories, tools, domains and models.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 14:12:51 GMT"}], "update_date": "2013-12-18", "authors_parsed": [["Slimani", "Thabet", ""]]}, {"id": "1312.4824", "submitter": "Bhagwati Pande", "authors": "B. P. Pande, Pawan Tamta, H. S. Dhami", "title": "Generation, Implementation and Appraisal of an N-gram based Stemming\n  Algorithm", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A language independent stemmer has always been looked for. Single N-gram\ntokenization technique works well, however, it often generates stems that start\nwith intermediate characters, rather than initial ones. We present a novel\ntechnique that takes the concept of N gram stemming one step ahead and compare\nour method with an established algorithm in the field, Porter's Stemmer.\nResults indicate that our N gram stemmer is not inferior to Porter's linguistic\nstemmer.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 15:32:56 GMT"}, {"version": "v2", "created": "Thu, 16 Jan 2014 04:05:36 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["Pande", "B. P.", ""], ["Tamta", "Pawan", ""], ["Dhami", "H. S.", ""]]}, {"id": "1312.5111", "submitter": "Christoph Trattner", "authors": "Dominik Kowald, Paul Seitlinger, Christoph Trattner, Tobias Ley", "title": "Long Time No See: The Probability of Reusing Tags as a Function of\n  Frequency and Recency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce a tag recommendation algorithm that mimics the\nway humans draw on items in their long-term memory. This approach uses the\nfrequency and recency of previous tag assignments to estimate the probability\nof reusing a particular tag. Using three real-world folksonomies gathered from\nbookmarks in BibSonomy, CiteULike and Flickr, we show how adding a\ntime-dependent component outperforms conventional \"most popular tags\"\napproaches and another existing and very effective but less theory-driven,\ntime-dependent recommendation mechanism. By combining our approach with a\nsimple resource-specific frequency analysis, our algorithm outperforms other\nwell-established algorithms, such as FolkRank, Pairwise Interaction Tensor\nFactorization and Collaborative Filtering. We conclude that our approach\nprovides an accurate and computationally efficient model of a user's temporal\ntagging behavior. We show how effective principles for information retrieval\ncan be designed and implemented if human memory processes are taken into\naccount.\n", "versions": [{"version": "v1", "created": "Wed, 18 Dec 2013 12:31:23 GMT"}], "update_date": "2013-12-19", "authors_parsed": [["Kowald", "Dominik", ""], ["Seitlinger", "Paul", ""], ["Trattner", "Christoph", ""], ["Ley", "Tobias", ""]]}, {"id": "1312.5457", "submitter": "Yonatan Vaizman", "authors": "Yonatan Vaizman, Brian McFee and Gert Lanckriet", "title": "Codebook based Audio Feature Representation for Music Information\n  Retrieval", "comments": "Journal paper. Submitted to IEEE transactions on Audio, Speech and\n  Language Processing. Submitted on Dec 18th, 2013", "journal-ref": null, "doi": "10.1109/TASLP.2014.2337842", "report-no": null, "categories": "cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital music has become prolific in the web in recent decades. Automated\nrecommendation systems are essential for users to discover music they love and\nfor artists to reach appropriate audience. When manual annotations and user\npreference data is lacking (e.g. for new artists) these systems must rely on\n\\emph{content based} methods. Besides powerful machine learning tools for\nclassification and retrieval, a key component for successful recommendation is\nthe \\emph{audio content representation}.\n  Good representations should capture informative musical patterns in the audio\nsignal of songs. These representations should be concise, to enable efficient\n(low storage, easy indexing, fast search) management of huge music\nrepositories, and should also be easy and fast to compute, to enable real-time\ninteraction with a user supplying new songs to the system.\n  Before designing new audio features, we explore the usage of traditional\nlocal features, while adding a stage of encoding with a pre-computed\n\\emph{codebook} and a stage of pooling to get compact vectorial\nrepresentations. We experiment with different encoding methods, namely\n\\emph{the LASSO}, \\emph{vector quantization (VQ)} and \\emph{cosine similarity\n(CS)}. We evaluate the representations' quality in two music information\nretrieval applications: query-by-tag and query-by-example. Our results show\nthat concise representations can be used for successful performance in both\napplications. We recommend using top-$\\tau$ VQ encoding, which consistently\nperforms well in both applications, and requires much less computation time\nthan the LASSO.\n", "versions": [{"version": "v1", "created": "Thu, 19 Dec 2013 09:40:03 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Vaizman", "Yonatan", ""], ["McFee", "Brian", ""], ["Lanckriet", "Gert", ""]]}, {"id": "1312.6565", "submitter": "Feng Xia", "authors": "Feng Xia, Nana Yaw Asabere, Ahmedin Mohammed Ahmed, Jing Li, Xiangjie\n  Kong", "title": "Mobile Multimedia Recommendation in Smart Communities: A Survey", "comments": null, "journal-ref": "IEEE Access, vol.1, pp.606-624, 2013", "doi": null, "report-no": null, "categories": "cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the rapid growth of internet broadband access and proliferation of\nmodern mobile devices, various types of multimedia (e.g. text, images, audios\nand videos) have become ubiquitously available anytime. Mobile device users\nusually store and use multimedia contents based on their personal interests and\npreferences. Mobile device challenges such as storage limitation have however\nintroduced the problem of mobile multimedia overload to users. In order to\ntackle this problem, researchers have developed various techniques that\nrecommend multimedia for mobile users. In this survey paper, we examine the\nimportance of mobile multimedia recommendation systems from the perspective of\nthree smart communities, namely, mobile social learning, mobile event guide and\ncontext-aware services. A cautious analysis of existing research reveals that\nthe implementation of proactive, sensor-based and hybrid recommender systems\ncan improve mobile multimedia recommendations. Nevertheless, there are still\nchallenges and open issues such as the incorporation of context and social\nproperties, which need to be tackled in order to generate accurate and\ntrustworthy mobile multimedia recommendations.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 15:01:35 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Xia", "Feng", ""], ["Asabere", "Nana Yaw", ""], ["Ahmed", "Ahmedin Mohammed", ""], ["Li", "Jing", ""], ["Kong", "Xiangjie", ""]]}, {"id": "1312.6597", "submitter": "Luis Marujo", "authors": "Luis Marujo, Anatole Gershman, Jaime Carbonell, David Martins de\n  Matos, Jo\\~ao P. Neto", "title": "Co-Multistage of Multiple Classifiers for Imbalanced Multiclass Learning", "comments": "Preliminary version of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose two stochastic architectural models (CMC and CMC-M)\nwith two layers of classifiers applicable to datasets with one and multiple\nskewed classes. This distinction becomes important when the datasets have a\nlarge number of classes. Therefore, we present a novel solution to imbalanced\nmulticlass learning with several skewed majority classes, which improves\nminority classes identification. This fact is particularly important for text\nclassification tasks, such as event detection. Our models combined with\npre-processing sampling techniques improved the classification results on six\nwell-known datasets. Finally, we have also introduced a new metric SG-Mean to\novercome the multiplication by zero limitation of G-Mean.\n", "versions": [{"version": "v1", "created": "Mon, 23 Dec 2013 16:52:56 GMT"}, {"version": "v2", "created": "Fri, 24 Jan 2014 23:09:17 GMT"}], "update_date": "2014-01-28", "authors_parsed": [["Marujo", "Luis", ""], ["Gershman", "Anatole", ""], ["Carbonell", "Jaime", ""], ["de Matos", "David Martins", ""], ["Neto", "Jo\u00e3o P.", ""]]}, {"id": "1312.6782", "submitter": "Avinash Bhute", "authors": "Avinash N Bhute, B. B. Meshram", "title": "IVSS Integration of Color Feature Extraction Techniques for Intelligent\n  Video Search Systems", "comments": "5 pages, 9 figures. 2012 4th International Conference on Electronics\n  Computer Technology - ICECT 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As large amount of visual Information is available on web in form of images,\ngraphics, animations and videos, so it is important in internet era to have an\neffective video search system. As there are number of video search engine\n(blinkx, Videosurf, Google, YouTube, etc.) which search for relevant videos\nbased on user keyword or term, But very less commercial video search engine are\navailable which search videos based on visual image/clip/video. In this paper\nwe are recommending a system that will search for relevant video using color\nfeature of video in response of user Query.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2013 09:28:08 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Bhute", "Avinash N", ""], ["Meshram", "B. B.", ""]]}, {"id": "1312.6802", "submitter": "Bhagwati Pande", "authors": "B. P. Pande, Pawan Tamta and H. S. Dhami", "title": "Suffix Stripping Problem as an Optimization Problem", "comments": "14 pages, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stemming or suffix stripping, an important part of the modern Information\nRetrieval systems, is to find the root word (stem) out of a given cluster of\nwords. Existing algorithms targeting this problem have been developed in a\nhaphazard manner. In this work, we model this problem as an optimization\nproblem. An Integer Program is being developed to overcome the shortcomings of\nthe existing approaches. The sample results of the proposed method are also\nbeing compared with an established technique in the field for English language.\nAn AMPL code for the same IP has also been given.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2013 12:06:48 GMT"}], "update_date": "2013-12-25", "authors_parsed": [["Pande", "B. P.", ""], ["Tamta", "Pawan", ""], ["Dhami", "H. S.", ""]]}, {"id": "1312.6808", "submitter": "Feng Xia", "authors": "Feng Xia, Nana Yaw Asabere, Joel J.P.C. Rodrigues, Filippo Basso,\n  Nakema Deonauth, Wei Wang", "title": "Socially-Aware Venue Recommendation for Conference Participants", "comments": null, "journal-ref": "The 10th IEEE International Conference on Ubiquitous Intelligence\n  and Computing (UIC), Vietri sul Mare, Italy, December 2013", "doi": "10.1109/UIC-ATC.2013.81", "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current research environments are witnessing high enormities of presentations\noccurring in different sessions at academic conferences. This situation makes\nit difficult for researchers (especially juniors) to attend the right\npresentation session(s) for effective collaboration. In this paper, we propose\nan innovative venue recommendation algorithm to enhance smart conference\nparticipation. Our proposed algorithm, Social Aware Recommendation of Venues\nand Environments (SARVE), computes the Pearson Correlation and social\ncharacteristic information of conference participants. SARVE further\nincorporates the current context of both the smart conference community and\nparticipants in order to model a recommendation process using distributed\ncommunity detection. Through the integration of the above computations and\ntechniques, we are able to recommend presentation sessions of active\nparticipant presenters that may be of high interest to a particular\nparticipant. We evaluate SARVE using a real world dataset. Our experimental\nresults demonstrate that SARVE outperforms other state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Dec 2013 12:33:30 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Xia", "Feng", ""], ["Asabere", "Nana Yaw", ""], ["Rodrigues", "Joel J. P. C.", ""], ["Basso", "Filippo", ""], ["Deonauth", "Nakema", ""], ["Wang", "Wei", ""]]}, {"id": "1312.6962", "submitter": "Ahmad Kamal", "authors": "Ahmad Kamal", "title": "Subjectivity Classification using Machine Learning Techniques for Mining\n  Feature-Opinion Pairs from Web Opinion Sources", "comments": "10 pages, 2 Color Photographs, 1 Diagram, 14 Charts, 2 Graphs,\n  International Journal of Computer Science Issues (IJCSI), Vol. 10, Issue 5,\n  No 1, September 2013", "journal-ref": "International Journal of Computer Science Issues (IJCSI), Volume\n  10 Issue 5, 2013, pp 191-200", "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to flourish of the Web 2.0, web opinion sources are rapidly emerging\ncontaining precious information useful for both customers and manufactures.\nRecently, feature based opinion mining techniques are gaining momentum in which\ncustomer reviews are processed automatically for mining product features and\nuser opinions expressed over them. However, customer reviews may contain both\nopinionated and factual sentences. Distillations of factual contents improve\nmining performance by preventing noisy and irrelevant extraction. In this\npaper, combination of both supervised machine learning and rule-based\napproaches are proposed for mining feasible feature-opinion pairs from\nsubjective review sentences. In the first phase of the proposed approach, a\nsupervised machine learning technique is applied for classifying subjective and\nobjective sentences from customer reviews. In the next phase, a rule based\nmethod is implemented which applies linguistic and semantic analysis of texts\nto mine feasible feature-opinion pairs from subjective sentences retained after\nthe first phase. The effectiveness of the proposed methods is established\nthrough experimentation over customer reviews on different electronic products.\n", "versions": [{"version": "v1", "created": "Wed, 25 Dec 2013 12:38:17 GMT"}], "update_date": "2015-04-27", "authors_parsed": [["Kamal", "Ahmad", ""]]}, {"id": "1312.7056", "submitter": "Izuddin Zainalabidin", "authors": "Izuddin Zainalabidin, Izyan Izzati A Halim, Faizal A Fadzil", "title": "Development of Display Ads Retrieval System to Match Publisher's\n  Contents", "comments": "14 pages, 3 figures, 1 table. arXiv admin note: text overlap with\n  arXiv:1206.1754 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The technological transformation and automation of digital content delivery\nhas revolutionized the media industry. Advertising landscape is gradually\nshifting its traditional media forms to the emergent of Internet advertising.\nIn this paper, the types of internet advertising to be discussed on are\ncontextual and sponsored search ads. These types of advertising have the\ncentral challenge of finding the best match between a given context and a\nsuitable advertisement, through a principled method. Furthermore, there are\nfour main players that exist in the Internet advertising ecosystem: users,\nadvertisers, ad exchange and publishers. Hence, to find ways to counter the\ncentral challenge, the paper addresses two objectives: how to successfully make\nthe best contextual ads selections to match to a web page content to ensure\nthat there is a valuable connection between the web page and the contextual\nads. All methods, discussions, conclusion and future recommendations are\npresented as per sections. Hence, in order to prove the working mechanism of\nmatching contextual ads and web pages, web pages together with the ads matching\nsystem are developed as a prototype.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2013 05:48:39 GMT"}], "update_date": "2013-12-30", "authors_parsed": [["Zainalabidin", "Izuddin", ""], ["Halim", "Izyan Izzati A", ""], ["Fadzil", "Faizal A", ""]]}, {"id": "1312.7076", "submitter": "Jinyun Yan", "authors": "Stratis Ioannidis, S. Muthukrishnan, Jinyun Yan", "title": "A Consensus-Focused Group Recommender System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many cases, recommendations are consumed by groups of users rather than\nindividuals. In this paper, we present a system which recommends social events\nto groups. The system helps groups to organize a joint activity and\ncollectively select which activity to perform among several possible options.\nWe also facilitate the consensus making, following the principle of group\nconsensus decision making. Our system allows users to asynchronously vote, add\nand comment on alternatives. We observe social influence within groups through\npost-recommendation feedback during the group decision making process. We\npropose a decision cascading model and estimate such social influence, which\ncan be used to improve the performance of group recommendation. We conduct\nexperiments to measure the prediction performance of our model. The result\nshows that the model achieves better results than that of independent decision\nmaking model.\n", "versions": [{"version": "v1", "created": "Thu, 26 Dec 2013 09:35:50 GMT"}, {"version": "v2", "created": "Tue, 25 Mar 2014 19:42:54 GMT"}], "update_date": "2014-03-26", "authors_parsed": [["Ioannidis", "Stratis", ""], ["Muthukrishnan", "S.", ""], ["Yan", "Jinyun", ""]]}]