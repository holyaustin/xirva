[{"id": "1302.0413", "submitter": "Catarina Moreira", "authors": "Catarina Moreira and P\\'avel Calado and Bruno Martins", "title": "Learning to Rank for Expert Search in Digital Libraries of Academic\n  Publications", "comments": null, "journal-ref": "Progress in Artificial Intelligence, Lecture Notes in Computer\n  Science, Springer Berlin Heidelberg. In Proceedings of the 15th Portuguese\n  Conference on Artificial Intelligence, 2011", "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The task of expert finding has been getting increasing attention in\ninformation retrieval literature. However, the current state-of-the-art is\nstill lacking in principled approaches for combining different sources of\nevidence in an optimal way. This paper explores the usage of learning to rank\nmethods as a principled approach for combining multiple estimators of\nexpertise, derived from the textual contents, from the graph-structure with the\ncitation patterns for the community of experts, and from profile information\nabout the experts. Experiments made over a dataset of academic publications,\nfor the area of Computer Science, attest for the adequacy of the proposed\napproaches.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2013 18:36:08 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["Moreira", "Catarina", ""], ["Calado", "P\u00e1vel", ""], ["Martins", "Bruno", ""]]}, {"id": "1302.0420", "submitter": "Francisco  Couto", "authors": "Francisco M Couto, Daniel Faria, Bruno Tavares, Pedro Gon\\c{c}alves,\n  Paulo Verissimo", "title": "Benchmarking some Portuguese S&T system research units: 2nd Edition", "comments": "26 pages, 20 figures F. Couto, D. Faria, B. Tavares, P.\n  Gon\\c{c}alves, and P. Verissimo, Benchmarking some portuguese S\\&T system\n  research units: 2nd edition, DI/FCUL TR 13-03, Department of Informatics,\n  University of Lisbon, February 2013", "journal-ref": null, "doi": null, "report-no": "DI--FCUL--TR--2013--03", "categories": "cs.DL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing use of productivity and impact metrics for evaluation and\ncomparison, not only of individual researchers but also of institutions,\nuniversities and even countries, has prompted the development of bibliometrics.\nCurrently, metrics are becoming widely accepted as an easy and balanced way to\nassist the peer review and evaluation of scientists and/or research units,\nprovided they have adequate precision and recall.\n  This paper presents a benchmarking study of a selected list of representative\nPortuguese research units, based on a fairly complete set of parameters:\nbibliometric parameters, number of competitive projects and number of PhDs\nproduced. The study aimed at collecting productivity and impact data from the\nselected research units in comparable conditions i.e., using objective metrics\nbased on public information, retrievable on-line and/or from official sources\nand thus verifiable and repeatable. The study has thus focused on the activity\nof the 2003-06 period, where such data was available from the latest official\nevaluation.\n  The main advantage of our study was the application of automatic tools,\nachieving relevant results at a reduced cost. Moreover, the results over the\nselected units suggest that this kind of analyses will be very useful to\nbenchmark scientific productivity and impact, and assist peer review.\n", "versions": [{"version": "v1", "created": "Sat, 2 Feb 2013 19:36:14 GMT"}, {"version": "v2", "created": "Wed, 20 Feb 2013 15:29:56 GMT"}, {"version": "v3", "created": "Wed, 16 Oct 2013 16:13:25 GMT"}], "update_date": "2013-10-17", "authors_parsed": [["Couto", "Francisco M", ""], ["Faria", "Daniel", ""], ["Tavares", "Bruno", ""], ["Gon\u00e7alves", "Pedro", ""], ["Verissimo", "Paulo", ""]]}, {"id": "1302.1178", "submitter": "Juli\\'an Urbano", "authors": "Juli\\'an Urbano, M\\'onica Marrero, Diego Mart\\'in, Jorge Morato", "title": "Overview of EIREX 2012: Social Media", "comments": "9 pages, 5 tables, 4 figures. arXiv admin note: substantial text\n  overlap with arXiv:1203.0518, arXiv:1201.0274", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The third Information Retrieval Education through EXperimentation track\n(EIREX 2012) was run at the University Carlos III of Madrid, during the 2012\nspring semester. EIREX 2012 is the third in a series of experiments designed to\nfoster new Information Retrieval (IR) education methodologies and resources,\nwith the specific goal of teaching undergraduate IR courses from an\nexperimental perspective. For an introduction to the motivation behind the\nEIREX experiments, see the first sections of [Urbano et al., 2011a]. For\ninformation on other editions of EIREX and related data, see the website at\nhttp://ir.kr.inf.uc3m.es/eirex/. The EIREX series have the following goals: a)\nto help students get a view of the Information Retrieval process as they would\nfind it in a real-world scenario, either industrial or academic; b) to make\nstudents realize the importance of laboratory experiments in Computer Science\nand have them initiated in their execution and analysis; c) to create a public\nrepository of resources to teach Information Retrieval courses; d) to seek the\ncollaboration and active participation of other Universities in this endeavor.\nThis overview paper summarizes the results of the EIREX 2012 track, focusing on\nthe creation of the test collection and the analysis to assess its reliability.\n", "versions": [{"version": "v1", "created": "Tue, 5 Feb 2013 20:20:30 GMT"}], "update_date": "2013-02-06", "authors_parsed": [["Urbano", "Juli\u00e1n", ""], ["Marrero", "M\u00f3nica", ""], ["Mart\u00edn", "Diego", ""], ["Morato", "Jorge", ""]]}, {"id": "1302.1335", "submitter": "Raghu Anantharangachar", "authors": "Raghu Anantharangachar, Srinivasan Ramani, S Rajagopalan", "title": "Ontology Guided Information Extraction from Unstructured Text", "comments": null, "journal-ref": "International Journal of Web & Semantic Technology (IJWesT) Vol.4,\n  No.1, January 2013", "doi": "10.5121/ijwest.2013.4102", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we describe an approach to populate an existing ontology with\ninstance information present in the natural language text provided as input. An\nontology is defined as an explicit conceptualization of a shared domain. This\napproach starts with a list of relevant domain ontologies created by human\nexperts, and techniques for identifying the most appropriate ontology to be\nextended with information from a given text. Then we demonstrate heuristics to\nextract information from the unstructured text and for adding it as structured\ninformation to the selected ontology. This identification of the relevant\nontology is critical, as it is used in identifying relevant information in the\ntext. We extract information in the form of semantic triples from the text,\nguided by the concepts in the ontology. We then convert the extracted\ninformation about the semantic class instances into Resource Description\nFramework (RDF3) and append it to the existing domain ontology. This enables us\nto perform more precise semantic queries over the semantic triple store thus\ncreated. We have achieved 95% accuracy of information extraction in our\nimplementation.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 12:19:43 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Anantharangachar", "Raghu", ""], ["Ramani", "Srinivasan", ""], ["Rajagopalan", "S", ""]]}, {"id": "1302.1596", "submitter": "Onur Y{\\i}lmaz", "authors": "Onur Y{\\i}lmaz", "title": "Tag-based Semantic Website Recommendation for Turkish Language", "comments": "7 pages, research and experiment about recommendation system for\n  Turkish", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the dramatic increase in the number of websites on the internet, tagging\nhas become popular for finding related, personal and important documents. When\nthe potentially increasing internet markets are analyzed, Turkey, in which most\nof the people use Turkish language on the internet, found to be exponentially\nincreasing. In this paper, a tag-based website recommendation method is\npresented, where similarity measures are combined with semantic relationships\nof tags. In order to evaluate the system, an experiment with 25 people from\nTurkey is undertaken and participants are firstly asked to provide websites and\ntags in Turkish and then they are asked to evaluate recommended websites.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 22:02:31 GMT"}, {"version": "v2", "created": "Fri, 8 Feb 2013 20:53:41 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2013 12:14:12 GMT"}], "update_date": "2013-08-07", "authors_parsed": [["Y\u0131lmaz", "Onur", ""]]}, {"id": "1302.1612", "submitter": "Hanane Froud", "authors": "Hanane Froud, Abdelmonaime Lachkar, Said Alaoui Ouatik", "title": "Arabic text summarization based on latent semantic analysis to enhance\n  arabic documents clustering", "comments": null, "journal-ref": "International Journal of Data Mining & Knowledge Management\n  Process (IJDKP)- 2013", "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arabic Documents Clustering is an important task for obtaining good results\nwith the traditional Information Retrieval (IR) systems especially with the\nrapid growth of the number of online documents present in Arabic language.\nDocuments clustering aim to automatically group similar documents in one\ncluster using different similarity/distance measures. This task is often\naffected by the documents length, useful information on the documents is often\naccompanied by a large amount of noise, and therefore it is necessary to\neliminate this noise while keeping useful information to boost the performance\nof Documents clustering. In this paper, we propose to evaluate the impact of\ntext summarization using the Latent Semantic Analysis Model on Arabic Documents\nClustering in order to solve problems cited above, using five\nsimilarity/distance measures: Euclidean Distance, Cosine Similarity, Jaccard\nCoefficient, Pearson Correlation Coefficient and Averaged Kullback-Leibler\nDivergence, for two times: without and with stemming. Our experimental results\nindicate that our proposed approach effectively solves the problems of noisy\ninformation and documents length, and thus significantly improve the clustering\nperformance.\n", "versions": [{"version": "v1", "created": "Wed, 6 Feb 2013 23:24:37 GMT"}], "update_date": "2013-02-08", "authors_parsed": [["Froud", "Hanane", ""], ["Lachkar", "Abdelmonaime", ""], ["Ouatik", "Said Alaoui", ""]]}, {"id": "1302.2131", "submitter": "Bohdan Pavlyshenko", "authors": "Bohdan Pavlyshenko", "title": "Data Mining of the Concept \"End of the World\" in Twitter Microblogs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.CL cs.IR physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the analysis of quantitative characteristics of frequent\nsets and association rules in the posts of Twitter microblogs, related to the\ndiscussion of \"end of the world\", which was allegedly predicted on December 21,\n2012 due to the Mayan calendar. Discovered frequent sets and association rules\ncharacterize semantic relations between the concepts of analyzed subjects.The\nsupport for some fequent sets reaches the global maximum before the expected\nevent with some time delay. Such frequent sets may be considered as predictive\nmarkers that characterize the significance of expected events for blogosphere\nusers. It was shown that time dynamics of confidence of some revealed\nassociation rules can also have predictive characteristics. Exceeding a certain\nthreshold, it may be a signal for the corresponding reaction in the society\nduring the time interval between the maximum and probable coming of an event.\n", "versions": [{"version": "v1", "created": "Fri, 8 Feb 2013 19:56:43 GMT"}], "update_date": "2013-02-11", "authors_parsed": [["Pavlyshenko", "Bohdan", ""]]}, {"id": "1302.2222", "submitter": "Marko Horvat", "authors": "Marko Horvat, Gordan Gledec, Nikola Bogunovi\\'c", "title": "Ontology-Based Administration of Web Directories", "comments": "22 pages, 9 figures", "journal-ref": "Lecture Notes in Computer Science, Transactions on Computational\n  Collective Intelligence I., 6220, pp. 101-120 (2010)", "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Administration of a Web directory and maintenance of its content and the\nassociated structure is a delicate and labor intensive task performed\nexclusively by human domain experts. Subsequently there is an imminent risk of\na directory structures becoming unbalanced, uneven and difficult to use to all\nexcept for a few users proficient with the particular Web directory and its\ndomain. These problems emphasize the need to establish two important issues: i)\ngeneric and objective measures of Web directories structure quality, and ii)\nmechanism for fully automated development of a Web directory's structure. In\nthis paper we demonstrate how to formally and fully integrate Web directories\nwith the Semantic Web vision. We propose a set of criteria for evaluation of a\nWeb directory's structure quality. Some criterion functions are based on\nheuristics while others require the application of ontologies. We also suggest\nan ontology-based algorithm for construction of Web directories. By using\nontologies to describe the semantics of Web resources and Web directories'\ncategories it is possible to define algorithms that can build or rearrange the\nstructure of a Web directory. Assessment procedures can provide feedback and\nhelp steer the ontology-based construction process. The issues raised in the\narticle can be equally applied to new and existing Web directories.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2013 11:43:52 GMT"}], "update_date": "2013-02-12", "authors_parsed": [["Horvat", "Marko", ""], ["Gledec", "Gordan", ""], ["Bogunovi\u0107", "Nikola", ""]]}, {"id": "1302.2223", "submitter": "Marko Horvat", "authors": "Marko Horvat, Anton Grbin, Gordan Gledec", "title": "WNtags: A Web-Based Tool For Image Labeling And Retrieval With Lexical\n  Ontologies", "comments": "10 pages, 3 figures, published in 16th International Conference on\n  Knowledge-Based and Intelligent Information & Engineering Systems, 10-12 Sep\n  2012, San Sebastian, Spain", "journal-ref": "Frontiers in artificial intelligence and applications, 243, pp.\n  585-594 (2012)", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ever growing number of image documents available on the Internet continuously\nmotivates research in better annotation models and more efficient retrieval\nmethods. Formal knowledge representation of objects and events in pictures,\ntheir interaction as well as context complexity becomes no longer an option for\na quality image repository, but a necessity. We present an ontology-based\nonline image annotation tool WNtags and demonstrate its usefulness in several\ntypical multimedia retrieval tasks using International Affective Picture System\nemotionally annotated image database. WNtags is built around WordNet lexical\nontology but considers Suggested Upper Merged Ontology as the preferred\nlabeling formalism. WNtags uses sets of weighted WordNet synsets as high-level\nimage semantic descriptors and query matching is performed with word stemming\nand node distance metrics. We also elaborate our near future plans to expand\nimage content description with induced affect as in stimuli for research of\nhuman emotion and attention.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2013 11:49:19 GMT"}, {"version": "v2", "created": "Tue, 5 Dec 2017 18:50:48 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Horvat", "Marko", ""], ["Grbin", "Anton", ""], ["Gledec", "Gordan", ""]]}, {"id": "1302.2318", "submitter": "Pavel Sirotkin", "authors": "Pavel Sirotkin", "title": "On Search Engine Evaluation Metrics", "comments": "Doctoral thesis. 192 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The search engine evaluation research has quite a lot metrics available to\nit. Only recently, the question of the significance of individual metrics\nstarted being raised, as these metrics' correlations to real-world user\nexperiences or performance have generally not been well-studied. The first part\nof this thesis provides an overview of previous literature on the evaluation of\nsearch engine evaluation metrics themselves, as well as critiques of and\ncomments on individual studies and approaches. The second part introduces a\nmeta-evaluation metric, the Preference Identification Ratio (PIR), that\nquantifies the capacity of an evaluation metric to capture users' preferences.\nAlso, a framework for simultaneously evaluating many metrics while varying\ntheir parameters and evaluation standards is introduced. Both PIR and the\nmeta-evaluation framework are tested in a study which shows some interesting\npreliminary results; in particular, the unquestioning adherence to metrics or\ntheir ad hoc parameters seems to be disadvantageous. Instead, evaluation\nmethods should themselves be rigorously evaluated with regard to goals set for\na particular study.\n", "versions": [{"version": "v1", "created": "Sun, 10 Feb 2013 10:50:56 GMT"}], "update_date": "2013-02-12", "authors_parsed": [["Sirotkin", "Pavel", ""]]}, {"id": "1302.2615", "submitter": "Marko Horvat", "authors": "Marko Horvat, Gordan Gledec, Nikola Bogunovi\\'c", "title": "Assessing Semantic Quality of Web Directory Structure", "comments": "12 pages, 6 figures. arXiv admin note: substantial text overlap with\n  arXiv:1302.2222", "journal-ref": "Lecture Notes in Computer Science, Lecture Notes in Artificial\n  Intelligence, 1, 5796, pp. 377-388 (2009)", "doi": "10.1007/978-3-642-15034-0_7", "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The administration of a Web directory content and associated structure is a\nlabor intensive task performed by human domain experts. Because of that there\nalways exists a realistic risk of the structure becoming unbalanced, uneven and\ndifficult to use to all except for a few users proficient in a particular Web\ndirectory. These problems emphasize the importance of generic and objective\nmeasures of Web directories structure quality. In this paper we demonstrate how\nto formally merge Web directories into the Semantic Web vision. We introduce a\nset of objective criterions for evaluation of a Web directory's structure\nquality. Some criteria functions are based on heuristics while others require\nthe application of ontologies.\n", "versions": [{"version": "v1", "created": "Sat, 9 Feb 2013 11:48:39 GMT"}], "update_date": "2015-06-15", "authors_parsed": [["Horvat", "Marko", ""], ["Gledec", "Gordan", ""], ["Bogunovi\u0107", "Nikola", ""]]}, {"id": "1302.4412", "submitter": "Folke Mitzlaff", "authors": "Folke Mitzlaff, Gerd Stumme", "title": "Recommending Given Names", "comments": "Baseline results for the ECML PKDD Discovery Challenge 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All over the world, future parents are facing the task of finding a suitable\ngiven name for their child. This choice is influenced by different factors,\nsuch as the social context, language, cultural background and especially\npersonal taste. Although this task is omnipresent, little research has been\nconducted on the analysis and application of interrelations among given names\nfrom a data mining perspective.\n  The present work tackles the problem of recommending given names, by firstly\nmining for inter-name relatedness in data from the Social Web. Based on these\nresults, the name search engine \"Nameling\" was built, which attracted more than\n35,000 users within less than six months, underpinning the relevance of the\nunderlying recommendation task. The accruing usage data is then used for\nevaluating different state-of-the-art recommendation systems, as well our new\nNameRank algorithm which we adopted from our previous work on folksonomies and\nwhich yields the best results, considering the trade-off between prediction\naccuracy and runtime performance as well as its ability to generate\npersonalized recommendations. We also show, how the gathered inter-name\nrelationships can be used for meaningful result diversification of\nPageRank-based recommendation systems.\n  As all of the considered usage data is made publicly available, the present\nwork establishes baseline results, encouraging other researchers to implement\nadvanced recommendation systems for given names.\n", "versions": [{"version": "v1", "created": "Mon, 18 Feb 2013 20:23:51 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2013 20:51:42 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Mitzlaff", "Folke", ""], ["Stumme", "Gerd", ""]]}, {"id": "1302.4504", "submitter": "Diego  Amancio Raphael", "authors": "Diego R. Amancio, Osvaldo N. Oliveira Jr. and Luciano da F. Costa", "title": "On the use of topological features and hierarchical characterization for\n  disambiguating names in collaborative networks", "comments": null, "journal-ref": "Europhysics Letters (2012) 99 48002", "doi": "10.1209/0295-5075/99/48002", "report-no": null, "categories": "physics.soc-ph cs.DL cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many features of complex systems can now be unveiled by applying statistical\nphysics methods to treat them as social networks. The power of the analysis may\nbe limited, however, by the presence of ambiguity in names, e.g., caused by\nhomonymy in collaborative networks. In this paper we show that the ability to\ndistinguish between homonymous authors is enhanced when longer-distance\nconnections are considered, rather than looking at only the immediate neighbors\nof a node in the collaborative network. Optimized results were obtained upon\nusing the 3rd hierarchy in connections. Furthermore, reasonable distinction\namong authors could also be achieved upon using pattern recognition strategies\nfor the data generated from the topology of the collaborative network. These\nresults were obtained with a network from papers in the arXiv repository, into\nwhich homonymy was deliberately introduced to test the methods with a\ncontrolled, reliable dataset. In all cases, several methods of supervised and\nunsupervised machine learning were used, leading to the same overall results.\nThe suitability of using deeper hierarchies and network topology was confirmed\nwith a real database of movie actors, with the additional finding that the\ndistinguishing ability can be further enhanced by combining topology features\nand long-range connections in the collaborative network.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 02:00:01 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Amancio", "Diego R.", ""], ["Oliveira", "Osvaldo N.", "Jr."], ["Costa", "Luciano da F.", ""]]}, {"id": "1302.4726", "submitter": "Khalil Riad Bouzidi", "authors": "Khalil Riad Bouzidi (INRIA Sophia Antipolis / Laboratoire I3S), Bruno\n  Fies (CSTB Sophia Antipolis), Marc Bourdeau (CSTB Sophia Antipolis),\n  Catherine Faron-Zucker (INRIA Sophia Antipolis / Laboratoire I3S), Nhan\n  Le-Thanh (I3S)", "title": "An Ontology for Modelling and Supporting the Process of Authoring\n  Technical Assessments", "comments": "In the International Council for Building Conference, CIB 2011 (2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a semantic web approach for modelling the process\nof creating new technical and regulatory documents related to the Building\nsector. This industry, among other industries, is currently experiencing a\nphenomenal growth in its technical and regulatory texts. Therefore, it is\nurgent and crucial to improve the process of creating regulations by automating\nit as much as possible. We focus on the creation of particular technical\ndocuments issued by the French Scientific and Technical Centre for Building\n(CSTB), called Technical Assessments, and we propose services based on Semantic\nWeb models and techniques for modelling the process of their creation.\n", "versions": [{"version": "v1", "created": "Tue, 19 Feb 2013 20:09:08 GMT"}], "update_date": "2013-02-20", "authors_parsed": [["Bouzidi", "Khalil Riad", "", "INRIA Sophia Antipolis / Laboratoire I3S"], ["Fies", "Bruno", "", "CSTB Sophia Antipolis"], ["Bourdeau", "Marc", "", "CSTB Sophia Antipolis"], ["Faron-Zucker", "Catherine", "", "INRIA Sophia Antipolis / Laboratoire I3S"], ["Le-Thanh", "Nhan", "", "I3S"]]}, {"id": "1302.4888", "submitter": "Yue Shi", "authors": "Yue Shi, Martha Larson, Alan Hanjalic", "title": "Exploiting Social Tags for Cross-Domain Collaborative Filtering", "comments": "Manuscript under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most challenging problems in recommender systems based on the\ncollaborative filtering (CF) concept is data sparseness, i.e., limited user\npreference data is available for making recommendations. Cross-domain\ncollaborative filtering (CDCF) has been studied as an effective mechanism to\nalleviate data sparseness of one domain using the knowledge about user\npreferences from other domains. A key question to be answered in the context of\nCDCF is what common characteristics can be deployed to link different domains\nfor effective knowledge transfer. In this paper, we assess the usefulness of\nuser-contributed (social) tags in this respect. We do so by means of the\nGeneralized Tag-induced Cross-domain Collaborative Filtering (GTagCDCF)\napproach that we propose in this paper and that we developed based on the\ngeneral collective matrix factorization framework. Assessment is done by a\nseries of experiments, using publicly available CF datasets that represent\nthree cross-domain cases, i.e., two two-domain cases and one three-domain case.\nA comparative analysis on two-domain cases involving GTagCDCF and several\nstate-of-the-art CDCF approaches indicates the increased benefit of using\nsocial tags as representatives of explicit links between domains for CDCF as\ncompared to the implicit links deployed by the existing CDCF methods. In\naddition, we show that users from different domains can already benefit from\nGTagCDCF if they only share a few common tags. Finally, we use the three-domain\ncase to validate the robustness of GTagCDCF with respect to the scale of\ndatasets and the varying number of domains.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 12:37:33 GMT"}, {"version": "v2", "created": "Tue, 24 Dec 2013 16:03:11 GMT"}], "update_date": "2013-12-25", "authors_parsed": [["Shi", "Yue", ""], ["Larson", "Martha", ""], ["Hanjalic", "Alan", ""]]}, {"id": "1302.4916", "submitter": "Arkaitz Zubiaga", "authors": "Arkaitz Zubiaga and Alberto P\\'erez Garc\\'ia-Plaza and V\\'ictor Fresno\n  and Raquel Mart\\'inez", "title": "Stacking from Tags: Clustering Bookmarks around a Theme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Since very recently, users on the social bookmarking service Delicious can\nstack web pages in addition to tagging them. Stacking enables users to group\nweb pages around specific themes with the aim of recommending to others.\nHowever, users still stack a small subset of what they tag, and thus many web\npages remain unstacked. This paper presents early research towards\nautomatically clustering web pages from tags to find stacks and extend\nrecommendations.\n", "versions": [{"version": "v1", "created": "Wed, 20 Feb 2013 14:38:38 GMT"}], "update_date": "2013-02-21", "authors_parsed": [["Zubiaga", "Arkaitz", ""], ["Garc\u00eda-Plaza", "Alberto P\u00e9rez", ""], ["Fresno", "V\u00edctor", ""], ["Mart\u00ednez", "Raquel", ""]]}, {"id": "1302.5302", "submitter": "Jimmy Lin", "authors": "Nima Asadi, Jimmy Lin, and Michael Busch", "title": "Dynamic Memory Allocation Policies for Postings in Real-Time Twitter\n  Search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore a real-time Twitter search application where tweets are arriving\nat a rate of several thousands per second. Real-time search demands that they\nbe indexed and searchable immediately, which leads to a number of\nimplementation challenges. In this paper, we focus on one aspect: dynamic\npostings allocation policies for index structures that are completely held in\nmain memory. The core issue can be characterized as a \"Goldilocks Problem\".\nBecause memory remains today a scare resource, an allocation policy that is too\naggressive leads to inefficient utilization, while a policy that is too\nconservative is slow and leads to fragmented postings lists. We present a\ndynamic postings allocation policy that allocates memory in increasingly-larger\n\"slices\" from a small number of large, fixed pools of memory. Through\nanalytical models and experiments, we explore different settings that balance\ntime (query evaluation speed) and space (memory utilization).\n", "versions": [{"version": "v1", "created": "Thu, 21 Feb 2013 15:24:53 GMT"}], "update_date": "2013-02-22", "authors_parsed": [["Asadi", "Nima", ""], ["Lin", "Jimmy", ""], ["Busch", "Michael", ""]]}, {"id": "1302.5675", "submitter": "Natheer Gharaibeh Dr", "authors": "Wafa N. Bdour, Natheer K. Gharaibeh", "title": "Development of Yes/No Arabic Question Answering System", "comments": "13 pages, 4 figures, 5 tables", "journal-ref": "International Journal of Artificial Intelligence & Applications\n  (IJAIA), Vol.4, No.1, January 2013", "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Developing Question Answering systems has been one of the important research\nissues because it requires insights from a variety of\ndisciplines,including,Artificial Intelligence,Information Retrieval,\nInformation Extraction,Natural Language Processing, and Psychology.In this\npaper we realize a formal model for a lightweight semantic based open domain\nyes/no Arabic question answering system based on paragraph retrieval with\nvariable length. We propose a constrained semantic representation. Using an\nexplicit unification framework based on semantic similarities and query\nexpansion synonyms and antonyms.This frequently improves the precision of the\nsystem. Employing the passage retrieval system achieves a better precision by\nretrieving more paragraphs that contain relevant answers to the question; It\nsignificantly reduces the amount of text to be processed by the system.\n", "versions": [{"version": "v1", "created": "Fri, 22 Feb 2013 18:59:06 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Bdour", "Wafa N.", ""], ["Gharaibeh", "Natheer K.", ""]]}, {"id": "1302.6340", "submitter": "Kanagavalli V R", "authors": "Kanagavalli.V.R and Raja. K", "title": "A Fuzzy Logic based Method for Efficient Retrieval of Vague and\n  Uncertain Spatial Expressions in Text Exploiting the Granulation of the\n  Spatial Event Queries", "comments": "National Conference on Future Computing,0975 8887,IJCA,February2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The arrangement of things in n-dimensional space is specified as Spatial.\nSpatial data consists of values that denote the location and shape of objects\nand areas on the earths surface. Spatial information includes facts such as\nlocation of features, the relationship of geographic features and measurements\nof geographic features. The spatial cognition is a primal area of study in\nvarious other fields such as Robotics, Psychology, Geosciences, Geography,\nPolitical Sciences, Geographic Economy, Environmental, Mining and Petroleum\nEngineering, Natural Resources, Epidemiology, Demography etc., Any text\ndocument which contains physical location specifications such as place names,\ngeographic coordinates, landmarks, country names etc., are supposed to contain\nthe spatial information. The spatial information may also be represented using\nvague or fuzzy descriptions involving linguistic terms such as near to, far\nfrom, to the east of, very close. Given a query involving events, the aim of\nthis ongoing research work is to extract the relevant information from multiple\ntext documents, resolve the uncertainty and vagueness and translate them in to\nlocations in a map. The input to the system would be a text Corpus and a\nSpatial Query event. The output of the system is a map showing the most\npossible, disambiguated location of the event queried. The author proposes\nFuzzy Logic Techniques for resolving the uncertainty in the spatial\nexpressions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 06:51:33 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["R", "Kanagavalli. V.", ""], ["K", "Raja.", ""]]}, {"id": "1302.6580", "submitter": "Kostas Stefanidis", "authors": "Kostas Stefanidis and Evaggelia Pitoura", "title": "Finding the Right Set of Users: Generalized Constraints for Group\n  Recommendations", "comments": "PersDB 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, group recommendations have attracted considerable attention. Rather\nthan recommending items to individual users, group recommenders recommend items\nto groups of users. In this position paper, we introduce the problem of forming\nan appropriate group of users to recommend an item when constraints apply to\nthe members of the group. We present a formal model of the problem and an\nalgorithm for its solution. Finally, we identify several directions for future\nwork.\n", "versions": [{"version": "v1", "created": "Tue, 26 Feb 2013 20:55:42 GMT"}], "update_date": "2013-02-27", "authors_parsed": [["Stefanidis", "Kostas", ""], ["Pitoura", "Evaggelia", ""]]}, {"id": "1302.7039", "submitter": "Mounira Taileb", "authors": "Mounira Taileb", "title": "Content Based Image Retrieval System Using NOHIS-tree", "comments": "6 pages, 10th International Conference on Advances in Mobile\n  Computing & Multimedia (MoMM2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content-based image retrieval (CBIR) has been one of the most important\nresearch areas in computer vision. It is a widely used method for searching\nimages in huge databases. In this paper we present a CBIR system called\nNOHIS-Search. The system is based on the indexing technique NOHIS-tree. The two\nphases of the system are described and the performance of the system is\nillustrated with the image database ImagEval. NOHIS-Search system was compared\nto other two CBIR systems; the first that using PDDP indexing algorithm and the\nsecond system is that using the sequential search. Results show that\nNOHIS-Search system outperforms the two other systems.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 00:21:38 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Taileb", "Mounira", ""]]}, {"id": "1302.7088", "submitter": "Wesam Elshamy", "authors": "Wesam Elshamy", "title": "Continuous-time Infinite Dynamic Topic Models", "comments": "Ph.D. dissertation, Kansas State University, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic models are probabilistic models for discovering topical themes in\ncollections of documents. In real world applications, these models provide us\nwith the means of organizing what would otherwise be unstructured collections.\nThey can help us cluster a huge collection into different topics or find a\nsubset of the collection that resembles the topical theme found in an article\nat hand.\n  The first wave of topic models developed were able to discover the prevailing\ntopics in a big collection of documents spanning a period of time. It was later\nrealized that these time-invariant models were not capable of modeling 1) the\ntime varying number of topics they discover and 2) the time changing structure\nof these topics. Few models were developed to address this two deficiencies.\nThe online-hierarchical Dirichlet process models the documents with a time\nvarying number of topics. It varies the structure of the topics over time as\nwell. However, it relies on document order, not timestamps to evolve the model\nover time. The continuous-time dynamic topic model evolves topic structure in\ncontinuous-time. However, it uses a fixed number of topics over time.\n  In this dissertation, I present a model, the continuous-time infinite dynamic\ntopic model, that combines the advantages of these two models 1) the\nonline-hierarchical Dirichlet process, and 2) the continuous-time dynamic topic\nmodel. More specifically, the model I present is a probabilistic topic model\nthat does the following: 1) it changes the number of topics over continuous\ntime, and 2) it changes the topic structure over continuous-time.\n  I compared the model I developed with the two other models with different\nsetting values. The results obtained were favorable to my model and showed the\nneed for having a model that has a continuous-time varying number of topics and\ntopic structure.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 05:30:41 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Elshamy", "Wesam", ""]]}, {"id": "1302.7131", "submitter": "Rosy Madaan", "authors": "Rosy Madaan, A.K. Sharma, Ashutosh Dixit", "title": "Presence Factor-Oriented Blog Summarization", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The research that has been carried out on blogs focused on blog posts only,\nignoring the title of the blog page. Also, in summarization only a set of\nrepresentative sentences are extracted. Some analysis has been done and it has\nbeen found that the blog post contains the content that is likely to be related\nto the topic of the blog post. Thus, proposed system of summarization makes use\nof title contained in a blog page. The approach makes use of the Presence\nfactor that indicates the presence of each term of the title in each sentence\nof the blog post. This is a key feature because it considers those sentences as\nmore relevant for summarization that contain each of the term present in the\ntitle. The system has been implemented and evaluated experimentally. The system\nhas shown promising results.\n", "versions": [{"version": "v1", "created": "Thu, 28 Feb 2013 09:59:54 GMT"}], "update_date": "2013-03-01", "authors_parsed": [["Madaan", "Rosy", ""], ["Sharma", "A. K.", ""], ["Dixit", "Ashutosh", ""]]}]