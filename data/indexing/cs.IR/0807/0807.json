[{"id": "0807.0023", "submitter": "Marko A. Rodriguez", "authors": "Marko A. Rodriguez, Johan Bollen, Herbert Van de Sompel", "title": "Automatic Metadata Generation using Associative Networks", "comments": null, "journal-ref": "ACM Transactions on Information Systems, volume 27, number 2,\n  pages 1-20, ISSN: 1046-8188, ACM Press, February 2009", "doi": "10.1145/1462198.1462199", "report-no": "LA-UR-06-3445", "categories": "cs.IR cs.DL", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In spite of its tremendous value, metadata is generally sparse and\nincomplete, thereby hampering the effectiveness of digital information\nservices. Many of the existing mechanisms for the automated creation of\nmetadata rely primarily on content analysis which can be costly and\ninefficient. The automatic metadata generation system proposed in this article\nleverages resource relationships generated from existing metadata as a medium\nfor propagation from metadata-rich to metadata-poor resources. Because of its\nindependence from content analysis, it can be applied to a wide variety of\nresource media types and is shown to be computationally inexpensive. The\nproposed method operates through two distinct phases. Occurrence and\nco-occurrence algorithms first generate an associative network of repository\nresources leveraging existing repository metadata. Second, using the\nassociative network as a substrate, metadata associated with metadata-rich\nresources is propagated to metadata-poor resources by means of a discrete-form\nspreading activation algorithm. This article discusses the general framework\nfor building associative networks, an algorithm for disseminating metadata\nthrough such networks, and the results of an experiment and validation of the\nproposed method using a standard bibliographic dataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jun 2008 21:23:28 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2009 01:20:48 GMT"}], "update_date": "2009-03-07", "authors_parsed": [["Rodriguez", "Marko A.", ""], ["Bollen", "Johan", ""], ["Van de Sompel", "Herbert", ""]]}, {"id": "0807.0070", "submitter": "Yuri Arkhipkin", "authors": "Yuri Arkhipkin", "title": "Quantitative Paradigm of Software Reliability as Content Relevance", "comments": "14 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a quantitative approach to software reliability and\ncontent relevance definitions validated by the systems' potential reliability\nlaw.Thus it is argued for the unified math nature or quantitative paradigm of\nsoftware reliability and content relevance.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2008 05:29:07 GMT"}], "update_date": "2008-07-02", "authors_parsed": [["Arkhipkin", "Yuri", ""]]}, {"id": "0807.0337", "submitter": "Emanuel Diamant", "authors": "Emanuel Diamant", "title": "Unveiling the mystery of visual information processing in human brain", "comments": "Accepted to be published in Brain Research (BRES-38102)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.IT math.IT q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is generally accepted that human vision is an extremely powerful\ninformation processing system that facilitates our interaction with the\nsurrounding world. However, despite extended and extensive research efforts,\nwhich encompass many exploration fields, the underlying fundamentals and\noperational principles of visual information processing in human brain remain\nunknown. We still are unable to figure out where and how along the path from\neyes to the cortex the sensory input perceived by the retina is converted into\na meaningful object representation, which can be consciously manipulated by the\nbrain. Studying the vast literature considering the various aspects of brain\ninformation processing, I was surprised to learn that the respected scholarly\ndiscussion is totally indifferent to the basic keynote question: \"What is\ninformation?\" in general or \"What is visual information?\" in particular. In the\nold days, it was assumed that any scientific research approach has first to\ndefine its basic departure points. Why was it overlooked in brain information\nprocessing research remains a conundrum. In this paper, I am trying to find a\nremedy for this bizarre situation. I propose an uncommon definition of\n\"information\", which can be derived from Kolmogorov's Complexity Theory and\nChaitin's notion of Algorithmic Information. Embracing this new definition\nleads to an inevitable revision of traditional dogmas that shape the state of\nthe art of brain information processing research. I hope this revision would\nbetter serve the challenging goal of human visual information processing\nmodeling.\n", "versions": [{"version": "v1", "created": "Wed, 2 Jul 2008 12:33:48 GMT"}], "update_date": "2008-07-07", "authors_parsed": [["Diamant", "Emanuel", ""]]}, {"id": "0807.1560", "submitter": "Vahed Qazvinian", "authors": "Vahed Qazvinian and Dragomir R. Radev", "title": "Scientific Paper Summarization Using Citation Summary Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Quickly moving to a new area of research is painful for researchers due to\nthe vast amount of scientific literature in each field of study. One possible\nway to overcome this problem is to summarize a scientific topic. In this paper,\nwe propose a model of summarizing a single article, which can be further used\nto summarize an entire topic. Our model is based on analyzing others' viewpoint\nof the target article's contributions and the study of its citation summary\nnetwork using a clustering approach.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2008 00:01:20 GMT"}], "update_date": "2008-07-11", "authors_parsed": [["Qazvinian", "Vahed", ""], ["Radev", "Dragomir R.", ""]]}, {"id": "0807.2496", "submitter": "Ashish Goel", "authors": "Ashish Goel and Kamesh Munagala", "title": "Hybrid Keyword Search Auctions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search auctions have become a dominant source of revenue generation on the\nInternet. Such auctions have typically used per-click bidding and pricing. We\npropose the use of hybrid auctions where an advertiser can make a\nper-impression as well as a per-click bid, and the auctioneer then chooses one\nof the two as the pricing mechanism. We assume that the advertiser and the\nauctioneer both have separate beliefs (called priors) on the click-probability\nof an advertisement. We first prove that the hybrid auction is truthful,\nassuming that the advertisers are risk-neutral. We then show that this auction\nis superior to the existing per-click auction in multiple ways: 1) It takes\ninto account the risk characteristics of the advertisers. 2) For obscure\nkeywords, the auctioneer is unlikely to have a very sharp prior on the\nclick-probabilities. In such situations, the hybrid auction can result in\nsignificantly higher revenue. 3) An advertiser who believes that its\nclick-probability is much higher than the auctioneer's estimate can use\nper-impression bids to correct the auctioneer's prior without incurring any\nextra cost. 4) The hybrid auction can allow the advertiser and auctioneer to\nimplement complex dynamic programming strategies. As Internet commerce matures,\nwe need more sophisticated pricing models to exploit all the information held\nby each of the participants. We believe that hybrid auctions could be an\nimportant step in this direction.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2008 04:04:32 GMT"}, {"version": "v2", "created": "Mon, 26 Jan 2009 01:00:16 GMT"}], "update_date": "2009-01-26", "authors_parsed": [["Goel", "Ashish", ""], ["Munagala", "Kamesh", ""]]}, {"id": "0807.2569", "submitter": "Jeffrey Solka", "authors": "Jeffrey Solka", "title": "Text Data Mining: Theory and Methods", "comments": "Published in at http://dx.doi.org/10.1214/07-SS016 the Statistics\n  Surveys (http://www.i-journals.org/ss/) by the Institute of Mathematical\n  Statistics (http://www.imstat.org)", "journal-ref": "Statistics Surveys 2008, Vol. 2, 94-112", "doi": "10.1214/07-SS016", "report-no": "IMS-SS-SS_2007_16", "categories": "stat.ML cs.IR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides the reader with a very brief introduction to some of the\ntheory and methods of text data mining. The intent of this article is to\nintroduce the reader to some of the current methodologies that are employed\nwithin this discipline area while at the same time making the reader aware of\nsome of the interesting challenges that remain to be solved within the area.\nFinally, the articles serves as a very rudimentary tutorial on some of\ntechniques while also providing the reader with a list of references for\nadditional study.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2008 13:39:32 GMT"}], "update_date": "2008-07-17", "authors_parsed": [["Solka", "Jeffrey", ""]]}, {"id": "0807.3006", "submitter": "Enoch Peserico", "authors": "Enoch Peserico and Luca Pretto", "title": "The rank convergence of HITS can be slow", "comments": "5 pages, 1 figure. Keywords: algorithm analysis, information\n  retrieval, rank convergence", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We prove that HITS, to \"get right\" h of the top k ranked nodes of an N>=2k\nnode graph, can require h^(Omega(N h/k)) iterations (i.e. a substantial Omega(N\nh log(h)/k) matrix multiplications even with a \"squaring trick\"). Our proof\nrequires no algebraic tools and is entirely self-contained.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jul 2008 16:42:57 GMT"}], "update_date": "2008-07-21", "authors_parsed": [["Peserico", "Enoch", ""], ["Pretto", "Luca", ""]]}, {"id": "0807.3755", "submitter": "Martin Klein", "authors": "Martin Klein, Michael L. Nelson", "title": "Approximating Document Frequency with Term Count Values", "comments": "11 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For bounded datasets such as the TREC Web Track (WT10g) the computation of\nterm frequency (TF) and inverse document frequency (IDF) is not difficult.\nHowever, when the corpus is the entire web, direct IDF calculation is\nimpossible and values must instead be estimated. Most available datasets\nprovide values for term count (TC) meaning the number of times a certain term\noccurs in the entire corpus. Intuitively this value is different from document\nfrequency (DF), the number of documents (e.g., web pages) a certain term occurs\nin. We conduct a comparison study between TC and DF values within the Web as\nCorpus (WaC). We found a very strong correlation with Spearman's rho >0.8\n(p<0.005) which makes us confident in claiming that for such recently created\ncorpora the TC and DF values can be used interchangeably to compute IDF values.\nThese results are useful for the generation of accurate lexical signatures\nbased on the TF-IDF scheme.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2008 21:44:46 GMT"}], "update_date": "2008-07-25", "authors_parsed": [["Klein", "Martin", ""], ["Nelson", "Michael L.", ""]]}, {"id": "0807.4325", "submitter": "Guido Caldarelli", "authors": "Nicola Perra (1,2), Vinko Zlatic (3,4), Alessandro Chessa (1,2),\n  Claudio Conti (5), Debora Donato (6), Guido Caldarelli (3,2) ((1) Dep of\n  Physics, SLACS-CNR University of Cagliari Italy, (2) Linkalab, Complex\n  Systems Computational Lab. Cagliari, Italy, (3) Centre SMC CNR-INFM, Dip.\n  Fisica, Universita' Sapienza Rome, Italy, (4) Theor. Physics Div., Rudjer\n  Boskovic Inst., Zagreb Croatia, (5) Centre SOFT CNR-INFM, Dip. Fisica,\n  Universita' Sapienza Rome, Italy, (6) Yahoo! Research Barcelona Spain)", "title": "Schroedinger-like PageRank equation and localization in the WWW", "comments": "5 pages", "journal-ref": null, "doi": "10.1209/0295-5075/88/48002", "report-no": null, "categories": "physics.soc-ph cond-mat.stat-mech cs.IR physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The WorldWide Web is one of the most important communication systems we use\nin our everyday life. Despite its central role, the growth and the development\nof the WWW is not controlled by any central authority. This situation has\ncreated a huge ensemble of connections whose complexity can be fruitfully\ndescribed and quantified by network theory. One important application that\nallows to sort out the information present in these connections is given by the\nPageRank alghorithm. Computation of this quantity is usually made iteratively\nwith a large use of computational time. In this paper we show that the PageRank\ncan be expressed in terms of a wave function obeying a Schroedinger-like\nequation. In particular the topological disorder given by the unbalance of\noutgoing and ingoing links between pages, induces wave function and potential\nstructuring. This allows to directly localize the pages with the largest score.\nThrough this new representation we can now compute the PageRank without\niterative techniques. For most of the cases of interest our method is faster\nthan the original one. Our results also clarify the role of topology in the\ndiffusion of information within complex networks. The whole approach opens the\npossibility to novel techniques inspired by quantum physics for the analysis of\nthe WWW properties.\n", "versions": [{"version": "v1", "created": "Mon, 28 Jul 2008 18:31:17 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Perra", "Nicola", ""], ["Zlatic", "Vinko", ""], ["Chessa", "Alessandro", ""], ["Conti", "Claudio", ""], ["Donato", "Debora", ""], ["Caldarelli", "Guido", ""]]}]