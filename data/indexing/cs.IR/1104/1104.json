[{"id": "1104.0126", "submitter": "David Vallet David Vallet", "authors": "Fabian Abel, Ilknur Celik, Claudia Hauff, Laura Hollink, Geert-Jan\n  Houben", "title": "U-Sem: Semantic Enrichment, User Modeling and Mining of Usage Data on\n  the Social Web", "comments": "1st International Workshop on Usage Analysis and the Web of Data\n  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),\n  Hyderabad, India, March 28th, 2011", "journal-ref": null, "doi": null, "report-no": "WWW2011USEWOD/2011/abecelhauholhou", "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the growing popularity of Social Web applications, more and more user\ndata is published on the Web everyday. Our research focuses on investigating\nways of mining data from such platforms that can be used for modeling users and\nfor semantically augmenting user profiles. This process can enhance adaptation\nand personalization in various adaptive Web-based systems. In this paper, we\npresent the U-Sem people modeling service, a framework for the semantic\nenrichment and mining of people's profiles from usage data on the Social Web.\nWe explain the architecture of our people modeling service and describe its\napplication in an adult e-learning context as an example. Versions: Mar 21,\n10:10, Mar 25, 09:37\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2011 09:59:10 GMT"}], "update_date": "2011-04-04", "authors_parsed": [["Abel", "Fabian", ""], ["Celik", "Ilknur", ""], ["Hauff", "Claudia", ""], ["Hollink", "Laura", ""], ["Houben", "Geert-Jan", ""]]}, {"id": "1104.0128", "submitter": "David Vallet David Vallet", "authors": "Vera Hollink, Arjen de Vries", "title": "Towards an automated query modification assistant", "comments": "1st International Workshop on Usage Analysis and the Web of Data\n  (USEWOD2011) in the 20th International World Wide Web Conference (WWW2011),\n  Hyderabad, India, March 28th, 2011", "journal-ref": null, "doi": null, "report-no": "WWW2011USEWOD/2011/holvri", "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users who need several queries before finding what they need can benefit from\nan automatic search assistant that provides feedback on their query\nmodification strategies. We present a method to learn from a search log which\ntypes of query modifications have and have not been effective in the past. The\nmethod analyses query modifications along two dimensions: a traditional\nterm-based dimension and a semantic dimension, for which queries are enriches\nwith linked data entities. Applying the method to the search logs of two search\nengines, we identify six opportunities for a query modification assistant to\nimprove search: modification strategies that are commonly used, but that often\ndo not lead to satisfactory results.\n", "versions": [{"version": "v1", "created": "Fri, 1 Apr 2011 10:03:45 GMT"}], "update_date": "2011-04-04", "authors_parsed": [["Hollink", "Vera", ""], ["de Vries", "Arjen", ""]]}, {"id": "1104.0395", "submitter": "Tao Zhou", "authors": "Yu-Xiao Zhu, Linyuan L\\\"u, Qian-Ming Zhang, Tao Zhou", "title": "Uncovering missing links with cold ends", "comments": "16 pages, 5 figures, 6 tables", "journal-ref": "Physica A 391 (2012) 5769-5778", "doi": "10.1016/j.physa.2012.06.003", "report-no": null, "categories": "physics.data-an cs.IR cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To evaluate the performance of prediction of missing links, the known data\nare randomly divided into two parts, the training set and the probe set. We\nargue that this straightforward and standard method may lead to terrible bias,\nsince in real biological and information networks, missing links are more\nlikely to be links connecting low-degree nodes. We therefore study how to\nuncover missing links with low-degree nodes, namely links in the probe set are\nof lower degree products than a random sampling. Experimental analysis on ten\nlocal similarity indices and four disparate real networks reveals a surprising\nresult that the Leicht-Holme-Newman index [E. A. Leicht, P. Holme, and M. E. J.\nNewman, Phys. Rev. E 73, 026120 (2006)] performs the best, although it was\nknown to be one of the worst indices if the probe set is a random sampling of\nall links. We further propose an parameter-dependent index, which considerably\nimproves the prediction accuracy. Finally, we show the relevance of the\nproposed index on three real sampling methods.\n", "versions": [{"version": "v1", "created": "Sun, 3 Apr 2011 15:51:36 GMT"}, {"version": "v2", "created": "Mon, 3 Oct 2011 03:33:49 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Zhu", "Yu-Xiao", ""], ["L\u00fc", "Linyuan", ""], ["Zhang", "Qian-Ming", ""], ["Zhou", "Tao", ""]]}, {"id": "1104.0871", "submitter": "Oleg Zaboronski V", "authors": "Joost van Honschoten, Henri de Jong, Wabe W. Koelmans, Thomas P.\n  Parnell and Oleg V. Zaboronski", "title": "Information Storage and Retrieval for Probe Storage using Optical\n  Diffraction Patterns", "comments": "14 pages, 11 figures. Version 2: minor misprints corrected,\n  experimental section expanded", "journal-ref": "Journal of Applied Physics, vol. 110, 104309 (2011)", "doi": "10.1063/1.3657945", "report-no": null, "categories": "cs.IT cs.IR math.IT physics.optics", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel method for fast information retrieval from a probe storage device is\nconsidered. It is shown that information can be stored and retrieved using the\noptical diffraction patterns obtained by the illumination of a large array of\ncantilevers by a monochromatic light source. In thermo-mechanical probe\nstorage, the information is stored as a sequence of indentations on the polymer\nmedium. To retrieve the information, the array of probes is actuated by\napplying a bending force to the cantilevers. Probes positioned over\nindentations experience deflection by the depth of the indentation, probes over\nthe flat media remain un-deflected. Thus the array of actuated probes can be\nviewed as an irregular optical grating, which creates a data-dependent\ndiffraction pattern when illuminated by laser light. We develop a low\ncomplexity modulation scheme, which allows the extraction of information stored\nin the pattern of indentations on the media from Fourier coefficients of the\nintensity of the diffraction pattern. We then derive a low-complexity maximum\nlikelihood sequence detection algorithm for retrieving the user information\nfrom the Fourier coefficients. The derivation of both the modulation and the\ndetection schemes is based on the Fraunhofer formula for data-dependent\ndiffraction patterns. We show that for as long as the Fresnel number F<0.1, the\noptimal channel detector derived from Fraunhofer diffraction theory does not\nsuffer any significant performance degradation.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2011 15:40:30 GMT"}, {"version": "v2", "created": "Mon, 9 Jan 2012 11:19:59 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["van Honschoten", "Joost", ""], ["de Jong", "Henri", ""], ["Koelmans", "Wabe W.", ""], ["Parnell", "Thomas P.", ""], ["Zaboronski", "Oleg V.", ""]]}, {"id": "1104.1605", "submitter": "Bogdan Cautis", "authors": "Silviu Maniu, Bogdan Cautis", "title": "Efficient Top-K Retrieval in Online Social Tagging Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider in this paper top-k query answering in social tagging systems,\nalso known as folksonomies. This problem requires a significant departure from\nexisting, socially agnostic techniques. In a network-aware context, one can\n(and should) exploit the social links, which can indicate how users relate to\nthe seeker and how much weight their tagging actions should have in the result\nbuild-up. We propose an algorithm that has the potential to scale to current\napplications. While the problem has already been considered in previous\nliterature, this was done either under strong simplifying assumptions or under\nchoices that cannot scale to even moderate-size real world applications. We\nfirst consider a key aspect of the problem, which is accessing the closest or\nmost relevant users for a given seeker. We describe how this can be done on the\nfly (without any pre-computations) for several possible choices - arguably the\nmost natural ones - of proximity computation in a user network. Based on this,\nour top-k algorithm is sound and complete, while addressing the scalability\nissues of the existing ones. Importantly, our technique is instance optimal in\nthe case when the search relies exclusively on the social weight of tagging\nactions. To further reduce response times, we then consider directions for\nefficiency by approximation. Extensive experiments on real world data show that\nour techniques can drastically improve the response time, without sacrificing\nprecision.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2011 16:33:16 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2011 13:32:57 GMT"}, {"version": "v3", "created": "Mon, 3 Oct 2011 16:07:51 GMT"}, {"version": "v4", "created": "Thu, 29 Mar 2012 10:10:08 GMT"}, {"version": "v5", "created": "Wed, 15 Aug 2012 20:36:09 GMT"}, {"version": "v6", "created": "Fri, 5 Oct 2012 15:59:20 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Maniu", "Silviu", ""], ["Cautis", "Bogdan", ""]]}, {"id": "1104.1892", "submitter": "Kallam Suresh", "authors": "K. Suresh", "title": "\"Improved FCM algorithm for Clustering on Web Usage Mining\"", "comments": "ISSN(Online):1694-0814.\n  http://www.ijcsi.org/papers/IJCSI-8-1-42-45.pdf", "journal-ref": "IJCSI International Journal of Computer Sciencec Issues, Vol.8\n  Issue 1, January 2011, p42-46", "doi": null, "report-no": null, "categories": "cs.IR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present clustering method is very sensitive to the initial\ncenter values, requirements on the data set too high, and cannot handle noisy\ndata the proposal method is using information entropy to initialize the cluster\ncenters and introduce weighting parameters to adjust the location of cluster\ncenters and noise problems.The navigation datasets which are sequential in\nnature, Clustering web data is finding the groups which share common interests\nand behavior by analyzing the data collected in the web servers, this improves\nclustering on web data efficiently using improved fuzzy c-means(FCM)\nclustering. Web usage mining is the application of data mining techniques to\nweb log data repositories. It is used in finding the user access patterns from\nweb access log. Web data Clusters are formed using on MSNBC web navigation\ndataset.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2011 09:38:47 GMT"}], "update_date": "2011-04-12", "authors_parsed": [["Suresh", "K.", ""]]}, {"id": "1104.2196", "submitter": "Georg Groh", "authors": "Georg Groh, Florian Straub, Andreas Donaubauer, Benjamin Koster", "title": "Space and Time as a Primary Classification Criterion for Information\n  Retrieval in Distributed Social Networking", "comments": "Short Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss in a compact way how the implicit relations between spatiotemporal\nrelatedness of information items, spatiotemporal relatedness of users, social\nrelatedness of users and semantic relatedness of information items may be\nexploited for an information retrieval architecture that operates along the\nlines of human ways of searching. The decentralized and agent oriented\narchitecture mirrors emerging trends such as upcoming mobile and decentralized\nsocial networking as a new paradigm in social computing and is targetted to\nsatisfy broader and more subtly interlinked information demands beyond\nimmediate information needs which can be readily satisfied with current IR\nservices. We briefly discuss why using spatio-temporal references as primary\ninformation criterion implicitly conserves other relations and is thus suitable\nfor such an architecture. We finally shortly point to results from a large\nevaluation study using Wikipedia articles.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2011 12:54:25 GMT"}], "update_date": "2011-04-13", "authors_parsed": [["Groh", "Georg", ""], ["Straub", "Florian", ""], ["Donaubauer", "Andreas", ""], ["Koster", "Benjamin", ""]]}, {"id": "1104.2824", "submitter": "L.T. Handoko", "authors": "Z. Akbar, L.T. Handoko", "title": "Pattern discovery for semi-structured web pages using bar-tree\n  representation", "comments": "9 pages", "journal-ref": "Int. J. Comput. Theor. Eng. 3 (2011) 261-269", "doi": "10.7763/IJCTE.2011.V3.314", "report-no": "FISIKALIPI-10040", "categories": "cs.IR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many websites with an underlying database containing structured data provide\nthe richest and most dense source of information relevant for topical data\nintegration. The real data integration requires sustainable and reliable\npattern discovery to enable accurate content retrieval and to recognize pattern\nchanges from time to time; yet, extracting the structured data from web\ndocuments is still lacking from its accuracy. This paper proposes the bar-tree\nrepresentation to describe the whole pattern of web pages in an efficient way\nbased on the reverse algorithm. While previous algorithms always trace the\npattern and extract the region of interest from \\textit{top root}, the reverse\nalgorithm recognizes the pattern from the region of interest to both top and\nbottom roots simultaneously. The attributes are then extracted and labeled\nreversely from the region of interest of targeted contents. Since using\nconventional representations for the algorithm should require more\ncomputational power, the bar-tree method is developed to represent the\ngenerated patterns using bar graphs characterized by the depths and widths from\nthe document roots. We show that this representation is suitable for extracting\nthe data from the semi-structured web sources, and for detecting the template\nchanges of targeted pages. The experimental results show perfect recognition\nrate for template changes in several web targets.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2011 16:27:35 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Akbar", "Z.", ""], ["Handoko", "L. T.", ""]]}, {"id": "1104.2982", "submitter": "Thierry Despeyroux", "authors": "Mireille Arnoux (LIMI), Thierry Despeyroux (INRIA Rocquencourt / INRIA\n  Sophia Antipolis)", "title": "Multi-representation d'une ontologie : OWL, bases de donnees, syst\\`emes\n  de types et d'objets", "comments": "ISBN: 978-1-60558-842-1", "journal-ref": "Journ\\'ees Francophones sur les Ontologies (2009)", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the emergence of the semantic Web and the increasing need to formalize\nhuman knowledge, ontologie engineering is now an important activity. But is\nthis activity very different from other ones like software engineering, for\nexample ? In this paper, we investigate analogies between ontologies on one\nhand, types, objects and data bases on the other one, taking into account the\nnotion of evolution of an ontology. We represent a unique ontology using\ndifferent paradigms, and observe that the distance between these different\nconcepts is small. We deduce from this constatation that ontologies and more\nspecifically ontology description languages can take advantage of beeing\nfertilizated with some other computer science domains and inherit important\ncharacteristics as modularity, for example.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2011 08:31:04 GMT"}], "update_date": "2011-04-18", "authors_parsed": [["Arnoux", "Mireille", "", "LIMI"], ["Despeyroux", "Thierry", "", "INRIA Rocquencourt / INRIA\n  Sophia Antipolis"]]}, {"id": "1104.3084", "submitter": "Rasmus Pagh", "authors": "Kasper Green Larsen and Rasmus Pagh", "title": "I/O-Efficient Data Structures for Colored Range and Prefix Reporting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by information retrieval applications, we consider the\none-dimensional colored range reporting problem in rank space. The goal is to\nbuild a static data structure for sets C_1,...,C_m \\subseteq {1,...,sigma} that\nsupports queries of the kind: Given indices a,b, report the set Union_{a <= i\n<= b} C_i.\n  We study the problem in the I/O model, and show that there exists an optimal\nlinear-space data structure that answers queries in O(1+k/B) I/Os, where k\ndenotes the output size and B the disk block size in words. In fact, we obtain\nthe same bound for the harder problem of three-sided orthogonal range\nreporting. In this problem, we are to preprocess a set of n two-dimensional\npoints in rank space, such that all points inside a query rectangle of the form\n[x_1,x_2] x (-infinity,y] can be reported. The best previous bounds for this\nproblem is either O(n lg^2_B n) space and O(1+k/B) query I/Os, or O(n) space\nand O(lg^(h)_B n +k/B) query I/Os, where lg^(h)_B n is the base B logarithm\niterated h times, for any constant integer h. The previous bounds are both\nachieved under the indivisibility assumption, while our solution exploits the\nfull capabilities of the underlying machine. Breaking the indivisibility\nassumption thus provides us with cleaner and optimal bounds.\n  Our results also imply an optimal solution to the following colored prefix\nreporting problem. Given a set S of strings, each O(1) disk blocks in length,\nand a function c: S -> 2^{1,...,sigma}, support queries of the kind: Given a\nstring p, report the set Union_{x in S intersection p*} c(x), where p* denotes\nthe set of strings with prefix p. Finally, we consider the possibility of top-k\nextensions of this result, and present a simple solution in a model that allows\nnon-blocked I/O.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2011 15:15:27 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Larsen", "Kasper Green", ""], ["Pagh", "Rasmus", ""]]}, {"id": "1104.3179", "submitter": "Lingfei Wu", "authors": "Lingfei Wu and Chengjun Wang", "title": "Heterogeneity and Allometric Growth of Human Collaborative Tagging\n  Behavior", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Allometric growth is found in many tagging systems online. That is, the\nnumber of new tags (T) is a power law function of the active population (P), or\nT P^gamma (gamma!=1). According to previous studies, it is the heterogeneity in\nindividual tagging behavior that gives rise to allometric growth. These studies\nconsider the power-law distribution model with an exponent beta, regarding\n1/beta as an index for heterogeneity. However, they did not discuss whether\npower-law is the only distribution that leads to allometric growth, or\nequivalently, whether the positive correlation between heterogeneity and\nallometric growth holds in systems of distributions other than power-law. In\nthis paper, the authors systematically examine the growth pattern of systems of\nsix different distributions, and find that both power-law distribution and\nlog-normal distribution lead to allometric growth. Furthermore, by introducing\nShannon entropy as an indicator for heterogeneity instead of 1/beta, the\nauthors confirm that the positive relationship between heterogeneity and\nallometric growth exists in both cases of power-law and log-normal\ndistributions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2011 23:51:16 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Wu", "Lingfei", ""], ["Wang", "Chengjun", ""]]}, {"id": "1104.3213", "submitter": "Ziyang Liu", "authors": "Ziyang Liu (Arizona State University), Sivaramakrishnan Natarajan\n  (Arizona State University), Yi Chen (ASU)", "title": "Query Expansion Based on Clustered Results", "comments": "VLDB2011", "journal-ref": "Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 6, pp.\n  350-361 (2011)", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query expansion is a functionality of search engines that suggests a set of\nrelated queries for a user-issued keyword query. Typical corpus-driven keyword\nquery expansion approaches return popular words in the results as expanded\nqueries. Using these approaches, the expanded queries may correspond to a\nsubset of possible query semantics, and thus miss relevant results. To handle\nambiguous queries and exploratory queries, whose result relevance is difficult\nto judge, we propose a new framework for keyword query expansion: we start with\nclustering the results according to user specified granularity, and then\ngenerate expanded queries, such that one expanded query is generated for each\ncluster whose result set should ideally be the corresponding cluster. We\nformalize this problem and show its APX-hardness. Then we propose two efficient\nalgorithms named iterative single-keyword refinement and partial elimination\nbased convergence, respectively, which effectively generate a set of expanded\nqueries from clustered results that provide a classification of the original\nquery results. We believe our study of generating an optimal query based on the\nground truth of the query results not only has applications in query expansion,\nbut has significance for studying keyword search quality in general.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2011 08:45:55 GMT"}], "update_date": "2011-04-19", "authors_parsed": [["Liu", "Ziyang", "", "Arizona State University"], ["Natarajan", "Sivaramakrishnan", "", "Arizona State University"], ["Chen", "Yi", "", "ASU"]]}, {"id": "1104.3344", "submitter": "Diederik Aerts", "authors": "Diederik Aerts, Liane Gabora, Sandro Sozzo and Tomas Veloz", "title": "Quantum Structure in Cognition: Fundamentals and Applications", "comments": "9 pages", "journal-ref": "In V. Privman and V. Ovchinnikov (Eds.), IARIA, Proceedings of the\n  Fifth International Conference on Quantum, Nano and Micro Technologies, pp.\n  57-62, 2011", "doi": null, "report-no": null, "categories": "cs.AI cs.IR quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experiments in cognitive science and decision theory show that the ways in\nwhich people combine concepts and make decisions cannot be described by\nclassical logic and probability theory. This has serious implications for\napplied disciplines such as information retrieval, artificial intelligence and\nrobotics. Inspired by a mathematical formalism that generalizes quantum\nmechanics the authors have constructed a contextual framework for both concept\nrepresentation and decision making, together with quantum models that are in\nstrong alignment with experimental data. The results can be interpreted by\nassuming the existence in human thought of a double-layered structure, a\n'classical logical thought' and a 'quantum conceptual thought', the latter\nbeing responsible of the above paradoxes and nonclassical effects. The presence\nof a quantum structure in cognition is relevant, for it shows that quantum\nmechanics provides not only a useful modeling tool for experimental data but\nalso supplies a structural model for human and artificial thought processes.\nThis approach has strong connections with theories formalizing meaning, such as\nsemantic analysis, and has also a deep impact on computer science, information\nretrieval and artificial intelligence. More specifically, the links with\ninformation retrieval are discussed in this paper.\n", "versions": [{"version": "v1", "created": "Sun, 17 Apr 2011 20:28:49 GMT"}], "update_date": "2013-01-08", "authors_parsed": [["Aerts", "Diederik", ""], ["Gabora", "Liane", ""], ["Sozzo", "Sandro", ""], ["Veloz", "Tomas", ""]]}, {"id": "1104.3810", "submitter": "Juha K\\\"arkk\\\"ainen", "authors": "Juha K\\\"arkk\\\"ainen and Simon J. Puglisi", "title": "Fixed Block Compression Boosting in FM-Indexes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A compressed full-text self-index occupies space close to that of the\ncompressed text and simultaneously allows fast pattern matching and random\naccess to the underlying text. Among the best compressed self-indexes, in\ntheory and in practice, are several members of the FM-index family. In this\npaper, we describe new FM-index variants that combine nice theoretical\nproperties, simple implementation and improved practical performance. Our main\nresult is a new technique called fixed block compression boosting, which is a\nsimpler and faster alternative to optimal compression boosting and implicit\ncompression boosting used in previous FM-indexes.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2011 17:26:46 GMT"}], "update_date": "2011-04-20", "authors_parsed": [["K\u00e4rkk\u00e4inen", "Juha", ""], ["Puglisi", "Simon J.", ""]]}, {"id": "1104.4063", "submitter": "Fionn Murtagh", "authors": "Fionn Murtagh and Pedro Contreras", "title": "Fast redshift clustering with the Baire (ultra) metric", "comments": "14 pages, 6 figures", "journal-ref": null, "doi": "10.1142/9789814383295_0005", "report-no": null, "categories": "cs.IR astro-ph.IM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Baire metric induces an ultrametric on a dataset and is of linear\ncomputational complexity, contrasted with the standard quadratic time\nagglomerative hierarchical clustering algorithm. We apply the Baire distance to\nspectrometric and photometric redshifts from the Sloan Digital Sky Survey\nusing, in this work, about half a million astronomical objects. We want to know\nhow well the (more cos\\ tly to determine) spectrometric redshifts can predict\nthe (more easily obtained) photometric redshifts, i.e. we seek to regress the\nspectrometric on the photometric redshifts, and we develop a clusterwise\nnearest neighbor regression procedure for this.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2011 15:51:50 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Murtagh", "Fionn", ""], ["Contreras", "Pedro", ""]]}, {"id": "1104.4163", "submitter": "Saurabh  Pal", "authors": "Umesh Kumar Pandey and Saurabh Pal", "title": "Data Mining : A prediction of performer or underperformer using\n  classification", "comments": "5 pages, 1 figure", "journal-ref": "(IJCSIT) International Journal of Computer Science and Information\n  Technology, Vol. 2(2), 2011, 686-690", "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Now a day's students have a large set of data having precious information\nhidden. Data mining technique can help to find this hidden information. In this\npaper, data mining techniques name Byes classification method is used on these\ndata to help an institution. Institutions can find those students who are\nconsistently perform well. This study will help to institution reduce the drop\nput ratio to a significant level and improve the performance level of the\ninstitution.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2011 03:50:34 GMT"}], "update_date": "2012-03-26", "authors_parsed": [["Pandey", "Umesh Kumar", ""], ["Pal", "Saurabh", ""]]}, {"id": "1104.4164", "submitter": "Saurabh  Pal", "authors": "Umesh Kumar Pandey and Saurabh Pal", "title": "A Data Mining view on Class Room Teaching Language", "comments": "6 pages, 3 figures", "journal-ref": "(IJCSI) International Journal of Computer Science Issue, Vol. 8,\n  Issue 2, March -2011, 277-282, ISSN:1694-0814", "doi": null, "report-no": null, "categories": "cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From ancient period in India, educational institution embarked to use class\nroom teaching. Where a teacher explains the material and students understand\nand learn the lesson. There is no absolute scale for measuring knowledge but\nexamination score is one scale which shows the performance indicator of\nstudents. So it is important that appropriate material is taught but it is\nvital that while teaching which language is chosen, class notes must be\nprepared and attendance. This study analyses the impact of language on the\npresence of students in class room. The main idea is to find out the support,\nconfidence and interestingness level for appropriate language and attendance in\nthe classroom. For this purpose association rule is used.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2011 03:54:49 GMT"}], "update_date": "2011-04-22", "authors_parsed": [["Pandey", "Umesh Kumar", ""], ["Pal", "Saurabh", ""]]}, {"id": "1104.4723", "submitter": "Lucas Bueno", "authors": "Lucas Moutinho Bueno, Eduardo Valle, Ricardo da Silva Torres", "title": "Bayesian approach for near-duplicate image detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a bayesian approach for near-duplicate image\ndetection, and investigate how different probabilistic models affect the\nperformance obtained. The task of identifying an image whose metadata are\nmissing is often demanded for a myriad of applications: metadata retrieval in\ncultural institutions, detection of copyright violations, investigation of\nlatent cross-links in archives and libraries, duplicate elimination in storage\nmanagement, etc. The majority of current solutions are based either on voting\nalgorithms, which are very precise, but expensive; either on the use of visual\ndictionaries, which are efficient, but less precise. Our approach, uses local\ndescriptors in a novel way, which by a careful application of decision theory,\nallows a very fine control of the compromise between precision and efficiency.\nIn addition, the method attains a great compromise between those two axes, with\nmore than 99% accuracy with less than 10 database operations.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2011 14:04:16 GMT"}], "update_date": "2011-04-26", "authors_parsed": [["Bueno", "Lucas Moutinho", ""], ["Valle", "Eduardo", ""], ["Torres", "Ricardo da Silva", ""]]}]