[{"id": "1807.00122", "submitter": "Sanaz Bahargam", "authors": "Sanaz Bahargam, Evangelos E. Papalexakis", "title": "A Constrained Coupled Matrix-Tensor Factorization for Learning\n  Time-evolving and Emerging Topics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topic discovery has witnessed a significant growth as a field of data mining\nat large. In particular, time-evolving topic discovery, where the evolution of\na topic is taken into account has been instrumental in understanding the\nhistorical context of an emerging topic in a dynamic corpus. Traditionally,\ntime-evolving topic discovery has focused on this notion of time. However,\nespecially in settings where content is contributed by a community or a crowd,\nan orthogonal notion of time is the one that pertains to the level of expertise\nof the content creator: the more experienced the creator, the more advanced the\ntopic. In this paper, we propose a novel time-evolving topic discovery method\nwhich, in addition to the extracted topics, is able to identify the evolution\nof that topic over time, as well as the level of difficulty of that topic, as\nit is inferred by the level of expertise of its main contributors. Our method\nis based on a novel formulation of Constrained Coupled Matrix-Tensor\nFactorization, which adopts constraints well-motivated for, and, as we\ndemonstrate, are essential for high-quality topic discovery. We qualitatively\nevaluate our approach using real data from the Physics and also Programming\nStack Exchange forum, and we were able to identify topics of varying levels of\ndifficulty which can be linked to external events, such as the announcement of\ngravitational waves by the LIGO lab in Physics forum. We provide a quantitative\nevaluation of our method by conducting a user study where experts were asked to\njudge the coherence and quality of the extracted topics. Finally, our proposed\nmethod has implications for automatic curriculum design using the extracted\ntopics, where the notion of the level of difficulty is necessary for the proper\nmodeling of prerequisites and advanced concepts.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 04:07:00 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Bahargam", "Sanaz", ""], ["Papalexakis", "Evangelos E.", ""]]}, {"id": "1807.00228", "submitter": "Yunpu Ma", "authors": "Yunpu Ma, Volker Tresp, Erik Daxberger", "title": "Embedding Models for Episodic Knowledge Graphs", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years a number of large-scale triple-oriented knowledge graphs have\nbeen generated and various models have been proposed to perform learning in\nthose graphs. Most knowledge graphs are static and reflect the world in its\ncurrent state. In reality, of course, the state of the world is changing: a\nhealthy person becomes diagnosed with a disease and a new president is\ninaugurated. In this paper, we extend models for static knowledge graphs to\ntemporal knowledge graphs. This enables us to store episodic data and to\ngeneralize to new facts (inductive learning). We generalize leading learning\nmodels for static knowledge graphs (i.e., Tucker, RESCAL, HolE, ComplEx,\nDistMult) to temporal knowledge graphs. In particular, we introduce a new\ntensor model, ConT, with superior generalization performance. The performances\nof all proposed models are analyzed on two different datasets: the Global\nDatabase of Events, Language, and Tone (GDELT) and the database for Integrated\nConflict Early Warning System (ICEWS). We argue that temporal knowledge graph\nembeddings might be models also for cognitive episodic memory (facts we\nremember and can recollect) and that a semantic memory (current facts we know)\ncan be generated from episodic memory by a marginalization operation. We\nvalidate this episodic-to-semantic projection hypothesis with the ICEWS\ndataset.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jun 2018 21:25:04 GMT"}, {"version": "v2", "created": "Mon, 3 Dec 2018 19:20:25 GMT"}], "update_date": "2018-12-05", "authors_parsed": [["Ma", "Yunpu", ""], ["Tresp", "Volker", ""], ["Daxberger", "Erik", ""]]}, {"id": "1807.00257", "submitter": "Jochen L. Leidner", "authors": "Jochen L. Leidner", "title": "Information Retrieval in the Cloud", "comments": "6 pages, 1 figure, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent trend to migrate IT infrastructure into the cloud. In\nthis paper, we discuss the impact of this trend on searching for textual and\nother data, i.e. the distributed indexing and retrieval of information, from an\norganizational context.\n  Keywords: information retrieval (IR); federated search; cloud search.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 02:36:24 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Leidner", "Jochen L.", ""]]}, {"id": "1807.00303", "submitter": "Vinicius Woloszyn", "authors": "Vinicius Woloszyn, Guilherme Medeiros Machado, Leandro Krug Wives,\n  Jos\\'e Palazzo Moreira de Oliveira", "title": "Modeling, comprehending and summarizing textual content by graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Automatic Text Summarization strategies have been successfully employed to\ndigest text collections and extract its essential content. Usually, summaries\nare generated using textual corpora that belongs to the same domain area where\nthe summary will be used. Nonetheless, there are special cases where it is not\nfound enough textual sources, and one possible alternative is to generate a\nsummary from a different domain. One manner to summarize texts consists of\nusing a graph model. This model allows giving more importance to words\ncorresponding to the main concepts from the target domain found in the\nsummarized text. This gives the reader an overview of the main text concepts as\nwell as their relationships. However, this kind of summarization presents a\nsignificant number of repeated terms when compared to human-generated\nsummaries. In this paper, we present an approach to produce graph-model\nextractive summaries of texts, meeting the target domain exigences and treating\nthe terms repetition problem. To evaluate the proposition, we performed a\nseries of experiments showing that the proposed approach statistically improves\nthe performance of a model based on Graph Centrality, achieving better\ncoverage, accuracy, and recall.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 09:42:10 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Woloszyn", "Vinicius", ""], ["Machado", "Guilherme Medeiros", ""], ["Wives", "Leandro Krug", ""], ["de Oliveira", "Jos\u00e9 Palazzo Moreira", ""]]}, {"id": "1807.00311", "submitter": "Yanru Qu", "authors": "Yanru Qu, Bohui Fang, Weinan Zhang, Ruiming Tang, Minzhe Niu, Huifeng\n  Guo, Yong Yu, Xiuqiang He", "title": "Product-based Neural Networks for User Response Prediction over\n  Multi-field Categorical Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User response prediction is a crucial component for personalized information\nretrieval and filtering scenarios, such as recommender system and web search.\nThe data in user response prediction is mostly in a multi-field categorical\nformat and transformed into sparse representations via one-hot encoding. Due to\nthe sparsity problems in representation and optimization, most research focuses\non feature engineering and shallow modeling. Recently, deep neural networks\nhave attracted research attention on such a problem for their high capacity and\nend-to-end training scheme. In this paper, we study user response prediction in\nthe scenario of click prediction. We first analyze a coupled gradient issue in\nlatent vector-based models and propose kernel product to learn field-aware\nfeature interactions. Then we discuss an insensitive gradient issue in\nDNN-based models and propose Product-based Neural Network (PNN) which adopts a\nfeature extractor to explore feature interactions. Generalizing the kernel\nproduct to a net-in-net architecture, we further propose Product-network In\nNetwork (PIN) which can generalize previous models. Extensive experiments on 4\nindustrial datasets and 1 contest dataset demonstrate that our models\nconsistently outperform 8 baselines on both AUC and log loss. Besides, PIN\nmakes great CTR improvement (relatively 34.67%) in online A/B test.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2018 11:02:50 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Qu", "Yanru", ""], ["Fang", "Bohui", ""], ["Zhang", "Weinan", ""], ["Tang", "Ruiming", ""], ["Niu", "Minzhe", ""], ["Guo", "Huifeng", ""], ["Yu", "Yong", ""], ["He", "Xiuqiang", ""]]}, {"id": "1807.00462", "submitter": "Jiankai Sun", "authors": "Jiankai Sun, Abhinav Vishnu, Aniket Chakrabarti, Charles Siegel, and\n  Srinivasan Parthasarathy", "title": "ColdRoute: Effective Routing of Cold Questions in Stack Exchange Sites", "comments": "Accepted to the Journal Track of The European Conference on Machine\n  Learning and Principles and Practice of Knowledge Discovery in Databases\n  (ECML PKDD 2018); Published by Springer:\n  https://link.springer.com/article/10.1007%2Fs10618-018-0577-7", "journal-ref": "@Article{Sun2018, author=\"Sun, Jiankai and Vishnu, A. and\n  Chakrabarti, A. and Siegel, C. and Parthasarathy, S.\", title=\"ColdRoute:\n  effective routing of cold questions in stack exchange sites\", journal=\"ECML\n  PKDD\", year=\"2018\"}", "doi": "10.1007/s10618-018-0577-7", "report-no": null, "categories": "cs.AI cs.HC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Routing questions in Community Question Answer services (CQAs) such as Stack\nExchange sites is a well-studied problem. Yet, cold-start -- a phenomena\nobserved when a new question is posted is not well addressed by existing\napproaches. Additionally, cold questions posted by new askers present\nsignificant challenges to state-of-the-art approaches. We propose ColdRoute to\naddress these challenges. ColdRoute is able to handle the task of routing cold\nquestions posted by new or existing askers to matching experts. Specifically,\nwe use Factorization Machines on the one-hot encoding of critical features such\nas question tags and compare our approach to well-studied techniques such as\nCQARank and semantic matching (LDA, BoW, and Doc2Vec). Using data from eight\nstack exchange sites, we are able to improve upon the routing metrics\n(Precision$@1$, Accuracy, MRR) over the state-of-the-art models such as\nsemantic matching by $159.5\\%$,$31.84\\%$, and $40.36\\%$ for cold questions\nposted by existing askers, and $123.1\\%$, $27.03\\%$, and $34.81\\%$ for cold\nquestions posted by new askers respectively.\n", "versions": [{"version": "v1", "created": "Mon, 2 Jul 2018 05:08:05 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Sun", "Jiankai", ""], ["Vishnu", "Abhinav", ""], ["Chakrabarti", "Aniket", ""], ["Siegel", "Charles", ""], ["Parthasarathy", "Srinivasan", ""]]}, {"id": "1807.00668", "submitter": "Andrew McMurry", "authors": "Andrew J McMurry (1), Richen Zhang (1), Alex Foxman (2), Lawrence\n  Reiter, (2) Ronny Schnel (2), DeLeys Brandman (1) ((1) Medal, Inc, (2)\n  NACORS, LLC - National Accountable Care Organization Research Services)", "title": "Using routinely collected patient data to support clinical trials\n  research in accountable care organizations", "comments": "11 pages including cover, 4 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Background: More than half (57%) of pharma clinical research spend is in\nsupport of clinical trials. One reason is that Electronic Health Record (EHR)\nsystems and HIPAA privacy rules often limit how broadly patient information can\nbe shared, resulting in laborious human efforts to manually collect,\nde-identify, and summarize patient information for use in clinical studies.\n  Purpose: Conduct feasibility study for a Rheumatoid Arthritis (RA) clinical\ntrial in an Accountable Care Organization. Measure prevalence of RA and related\nconditions matching study criteria. Evaluate automation of patient\nde-identification and summarization to support patient cohort development for\nclinical studies.\n  Methods: Collect original clinical documentation directly from the provider\nEHR system and extract clinical concepts necessary for matching study criteria.\nAutomatically de-identify Protected Health Information (PHI) protect patient\nprivacy and promote sharing. Leverage existing physician expert knowledge\nsources to enable analysis of patient populations.\n  Results: Prevalence of RA was four percent (4%) in the study population (mean\nage 53 years, 52% female, 48% male). Clinical documentation for 3500 patient\nwere extracted from three (3) EHR systems. Grouped diagnosis codes revealed\nhigh prevalence of diabetes and diseases of the circulatory system, as\nexpected. De-identification accurately removed 99% of PHI identifiers with 99%\nsensitivity and 99% specificity.\n  Conclusions: Results suggest the approach can improve automation and\naccelerate planning and construction of new clinical studies in the ACO\nsetting. De-identification accuracy was better than previously approved\nrequirements defined by four (4) hospital Institutional Review Boards.\n", "versions": [{"version": "v1", "created": "Mon, 25 Jun 2018 22:13:30 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["McMurry", "Andrew J", ""], ["Zhang", "Richen", ""], ["Foxman", "Alex", ""], ["Reiter", "Lawrence", ""], ["Schnel", "Ronny", ""], ["Brandman", "DeLeys", ""]]}, {"id": "1807.00692", "submitter": "Richard Diehl Martinez", "authors": "Richard Diehl Martinez, Geoffrey Angus, Rooz Mahdavian", "title": "Grapevine: A Wine Prediction Algorithm Using Multi-dimensional\n  Clustering Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for a wine recommendation system that employs\nmultidimensional clustering and unsupervised learning methods. Our algorithm\nfirst performs clustering on a large corpus of wine reviews. It then uses the\nresulting wine clusters as an approximation of the most common flavor palates,\nrecommending a user a wine by optimizing over a price-quality ratio within\nclusters that they demonstrated a preference for.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 13:55:44 GMT"}], "update_date": "2018-07-03", "authors_parsed": [["Martinez", "Richard Diehl", ""], ["Angus", "Geoffrey", ""], ["Mahdavian", "Rooz", ""]]}, {"id": "1807.01182", "submitter": "Ayushi Dalmia", "authors": "Ayushi Dalmia, Sachindra Joshi, Raghavendra Singh, Vikas Raykar", "title": "Styling with Attention to Details", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fashion as characterized by its nature, is driven by style. In this paper, we\npropose a method that takes into account the style information to complete a\ngiven set of selected fashion items with a complementary fashion item.\nComplementary items are those items that can be worn along with the selected\nitems according to the style. Addressing this problem facilitates in\nautomatically generating stylish fashion ensembles leading to a richer shopping\nexperience for users.\n  Recently, there has been a surge of online social websites where fashion\nenthusiasts post the outfit of the day and other users can like and comment on\nthem. These posts contain a gold-mine of information about style. In this\npaper, we exploit these posts to train a deep neural network which captures\nstyle in an automated manner. We pose the problem of predicting complementary\nfashion items as a sequence to sequence problem where the input is the selected\nset of fashion items and the output is a complementary fashion item based on\nthe style information learned by the model. We use the encoder decoder\narchitecture to solve this problem of completing the set of fashion items. We\nevaluate the goodness of the proposed model through a variety of experiments.\nWe empirically observe that our proposed model outperforms competitive baseline\nlike apriori algorithm by ~28 in terms of accuracy for top-1 recommendation to\ncomplete the fashion ensemble. We also perform retrieval based experiments to\nunderstand the ability of the model to learn style and rank the complementary\nfashion items and find that using attention in our encoder decoder model helps\nin improving the mean reciprocal rank by ~24. Qualitatively we find the\ncomplementary fashion items generated by our proposed model are richer than the\napriori algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 13:38:20 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Dalmia", "Ayushi", ""], ["Joshi", "Sachindra", ""], ["Singh", "Raghavendra", ""], ["Raykar", "Vikas", ""]]}, {"id": "1807.01227", "submitter": "Ariel Rosenfeld", "authors": "Akiva Kleinerman, Ariel Rosenfeld, Sarit Kraus", "title": "Providing Explanations for Recommendations in Reciprocal Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automated platforms which support users in finding a mutually beneficial\nmatch, such as online dating and job recruitment sites, are becoming\nincreasingly popular. These platforms often include recommender systems that\nassist users in finding a suitable match. While recommender systems which\nprovide explanations for their recommendations have shown many benefits,\nexplanation methods have yet to be adapted and tested in recommending suitable\nmatches. In this paper, we introduce and extensively evaluate the use of\n\"reciprocal explanations\" -- explanations which provide reasoning as to why\nboth parties are expected to benefit from the match. Through an extensive\nempirical evaluation, in both simulated and real-world dating platforms with\n287 human participants, we find that when the acceptance of a recommendation\ninvolves a significant cost (e.g., monetary or emotional), reciprocal\nexplanations outperform standard explanation methods which consider the\nrecommendation receiver alone. However, contrary to what one may expect, when\nthe cost of accepting a recommendation is negligible, reciprocal explanations\nare shown to be less effective than the traditional explanation methods.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 15:10:01 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Kleinerman", "Akiva", ""], ["Rosenfeld", "Ariel", ""], ["Kraus", "Sarit", ""]]}, {"id": "1807.01364", "submitter": "Michael Behrisch", "authors": "Michael Behrisch, Robert Krueger, Fritz Lekschas, Tobias Schreck, Nils\n  Gehlenborg, Hanspeter Pfister", "title": "Visual Pattern-Driven Exploration of Big Data", "comments": "Preprint - BDVA2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pattern extraction algorithms are enabling insights into the ever-growing\namount of today's datasets by translating reoccurring data properties into\ncompact representations. Yet, a practical problem arises: With increasing data\nvolumes and complexity also the number of patterns increases, leaving the\nanalyst with a vast result space. Current algorithmic and especially\nvisualization approaches often fail to answer central overview questions\nessential for a comprehensive understanding of pattern distributions and\nsupport, their quality, and relevance to the analysis task. To address these\nchallenges, we contribute a visual analytics pipeline targeted on the\npattern-driven exploration of result spaces in a semi-automatic fashion.\nSpecifically, we combine image feature analysis and unsupervised learning to\npartition the pattern space into interpretable, coherent chunks, which should\nbe given priority in a subsequent in-depth analysis. In our analysis scenarios,\nno ground-truth is given. Thus, we employ and evaluate novel quality metrics\nderived from the distance distributions of our image feature vectors and the\nderived cluster model to guide the feature selection process. We visualize our\nresults interactively, allowing the user to drill down from overview to detail\ninto the pattern space and demonstrate our techniques in a case study on\nbiomedical genomic data.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2018 20:34:39 GMT"}], "update_date": "2018-07-05", "authors_parsed": [["Behrisch", "Michael", ""], ["Krueger", "Robert", ""], ["Lekschas", "Fritz", ""], ["Schreck", "Tobias", ""], ["Gehlenborg", "Nils", ""], ["Pfister", "Hanspeter", ""]]}, {"id": "1807.01836", "submitter": "Vikas Yadav", "authors": "Vikas Yadav and Rebecca Sharp and Mihai Surdeanu", "title": "Sanity Check: A Strong Alignment and Information Retrieval Baseline for\n  Question Answering", "comments": "SIGIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While increasingly complex approaches to question answering (QA) have been\nproposed, the true gain of these systems, particularly with respect to their\nexpensive training requirements, can be inflated when they are not compared to\nadequate baselines. Here we propose an unsupervised, simple, and fast alignment\nand information retrieval baseline that incorporates two novel contributions: a\n\\textit{one-to-many alignment} between query and document terms and\n\\textit{negative alignment} as a proxy for discriminative information. Our\napproach not only outperforms all conventional baselines as well as many\nsupervised recurrent neural networks, but also approaches the state of the art\nfor supervised systems on three QA datasets. With only three hyperparameters,\nwe achieve 47\\% P@1 on an 8th grade Science QA dataset, 32.9\\% P@1 on a Yahoo!\nanswers QA dataset and 64\\% MAP on WikiQA. We also achieve 26.56\\% and 58.36\\%\non ARC challenge and easy dataset respectively. In addition to including the\nadditional ARC results in this version of the paper, for the ARC easy set only\nwe also experimented with one additional parameter -- number of justifications\nretrieved.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 03:33:53 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Yadav", "Vikas", ""], ["Sharp", "Rebecca", ""], ["Surdeanu", "Mihai", ""]]}, {"id": "1807.01857", "submitter": "Mohammad Masudur Rahman", "authors": "Mohammad Masudur Rahman, Shamima Yeasmin and Chanchal K. Roy", "title": "An IDE-Based Context-Aware Meta Search Engine", "comments": "20th Working Conference on Reverse Engineering (WCRE 2013), Koblenz,\n  Germany, October 2013, pp. 467--471", "journal-ref": null, "doi": "10.1109/WCRE.2013.6671324", "report-no": null, "categories": "cs.SE cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditional web search forces the developers to leave their working\nenvironments and look for solutions in the web browsers. It often does not\nconsider the context of their programming problems. The context-switching\nbetween the web browser and the working environment is time-consuming and\ndistracting, and the keyword-based traditional search often does not help much\nin problem solving. In this paper, we propose an Eclipse IDE-based web search\nsolution that collects the data from three web search APIs-- Google, Yahoo,\nBing and a programming Q & A site-- Stack Overflow. It then provides search\nresults within IDE taking not only the content of the selected error into\naccount but also the problem context, popularity and search engine\nrecommendation of the result links. Experiments with 25 run time errors and\nexceptions show that the proposed approach outperforms the keyword-based search\napproaches with a recommendation accuracy of 96%. We also validate the results\nwith a user study involving five prospective participants where we get a result\nagreement of 64.28%. While the preliminary results are promising, the approach\nneeds to be further validated with more errors and exceptions followed by a\nuser study with more participants to establish itself as a complete IDE-based\nweb search solution.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 06:05:46 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Rahman", "Mohammad Masudur", ""], ["Yeasmin", "Shamima", ""], ["Roy", "Chanchal K.", ""]]}, {"id": "1807.02039", "submitter": "Aliasgar Kutiyanawala", "authors": "Aliasgar Kutiyanawala, Prateek Verma, Zheng (John) Yan", "title": "Towards a simplified ontology for better e-commerce search", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Query Understanding is a semantic search method that can classify tokens in a\ncustomer's search query to entities such as Product, Brand, etc. This method\ncan overcome the limitations of bag-of-words methods but requires an ontology.\nWe show that current ontologies are not optimized for search and propose a\nsimplified ontology framework designed specifically for e-commerce search and\nretrieval. We also present three methods for automatically extracting product\nclasses for the proposed ontology and compare their performance relative to\neach other.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 14:58:32 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["Kutiyanawala", "Aliasgar", "", "John"], ["Verma", "Prateek", "", "John"], ["Zheng", "", "", "John"], ["Yan", "", ""]]}, {"id": "1807.02150", "submitter": "Kevin Luk", "authors": "Elias Tragas, Calvin Luo, Maxime Gazeau, Kevin Luk, David Duvenaud", "title": "Scalable Recommender Systems through Recursive Evidence Chains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems can be formulated as a matrix completion problem,\npredicting ratings from user and item parameter vectors. Optimizing these\nparameters by subsampling data becomes difficult as the number of users and\nitems grows. We develop a novel approach to generate all latent variables on\ndemand from the ratings matrix itself and a fixed pool of parameters. We\nestimate missing ratings using chains of evidence that link them to a small set\nof prototypical users and items. Our model automatically addresses the\ncold-start and online learning problems by combining information across both\nusers and items. We investigate the scaling behavior of this model, and\ndemonstrate competitive results with respect to current matrix factorization\ntechniques in terms of accuracy and convergence speed.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 18:48:56 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Tragas", "Elias", ""], ["Luo", "Calvin", ""], ["Gazeau", "Maxime", ""], ["Luk", "Kevin", ""], ["Duvenaud", "David", ""]]}, {"id": "1807.02162", "submitter": "Shweta Yadav Shweta", "authors": "Shweta Yadav, Ankit Kumar, Asif Ekbal, Sriparna Saha and Pushpak\n  Bhattacharyya", "title": "Feature Assisted bi-directional LSTM Model for Protein-Protein\n  Interaction Identification from Biomedical Texts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Knowledge about protein-protein interactions is essential in understanding\nthe biological processes such as metabolic pathways, DNA replication, and\ntranscription etc. However, a majority of the existing Protein-Protein\nInteraction (PPI) systems are dependent primarily on the scientific literature,\nwhich is yet not accessible as a structured database. Thus, efficient\ninformation extraction systems are required for identifying PPI information\nfrom the large collection of biomedical texts. Most of the existing systems\nmodel the PPI extraction task as a classification problem and are tailored to\nthe handcrafted feature set including domain dependent features. In this paper,\nwe present a novel method based on deep bidirectional long short-term memory\n(B-LSTM) technique that exploits word sequences and dependency path related\ninformation to identify PPI information from text. This model leverages joint\nmodeling of proteins and relations in a single unified framework, which we name\nas Shortest Dependency Path B-LSTM (sdpLSTM) model. We perform experiments on\ntwo popular benchmark PPI datasets, namely AiMed & BioInfer. The evaluation\nshows the F1-score values of 86.45% and 77.35% on AiMed and BioInfer,\nrespectively. Comparisons with the existing systems show that our proposed\napproach attains state-of-the-art performance.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 19:37:29 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Yadav", "Shweta", ""], ["Kumar", "Ankit", ""], ["Ekbal", "Asif", ""], ["Saha", "Sriparna", ""], ["Bhattacharyya", "Pushpak", ""]]}, {"id": "1807.02255", "submitter": "Mohammad Masudur Rahman", "authors": "Mohammad Masudur Rahman, Shamima Yeasmin and Chanchal K. Roy", "title": "Towards a Context-Aware IDE-Based Meta Search Engine for Recommendation\n  about Programming Errors and Exceptions", "comments": "IEEE CSMR-18/WCRE-21 Software Evolution Week (CSMR-WCRE 2014), pp.\n  194--203, Antwerp, Belgium, February 2014", "journal-ref": "Proc. CSMR-WCRE 2014, pp. 194--203", "doi": "10.1109/CSMR-WCRE.2014.6747170", "report-no": null, "categories": "cs.SE cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Study shows that software developers spend about 19% of their time looking\nfor information in the web during software development and maintenance.\nTraditional web search forces them to leave the working environment (e.g., IDE)\nand look for information in the web browser. It also does not consider the\ncontext of the problems that the developers search solutions for. The frequent\nswitching between web browser and the IDE is both time-consuming and\ndistracting, and the keyword-based traditional web search often does not help\nmuch in problem solving. In this paper, we propose an Eclipse IDE-based web\nsearch solution that exploits the APIs provided by three popular web search\nengines-- Google, Yahoo, Bing and a popular programming Q & A site, Stack\nOverflow, and captures the content-relevance, context-relevance, popularity and\nsearch engine confidence of each candidate result against the encountered\nprogramming problems. Experiments with 75 programming errors and exceptions\nusing the proposed approach show that inclusion of different types of context\ninformation associated with a given exception can enhance the recommendation\naccuracy of a given exception. Experiments both with two existing approaches\nand existing web search engines confirm that our approach can perform better\nthan them in terms of recall, mean precision and other performance measures\nwith little computational cost.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 05:08:10 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Rahman", "Mohammad Masudur", ""], ["Yeasmin", "Shamima", ""], ["Roy", "Chanchal K.", ""]]}, {"id": "1807.02263", "submitter": "Mohammad Masudur Rahman", "authors": "Mohammad Masudur Rahman and Chanchal K. Roy", "title": "TextRank Based Search Term Identification for Software Change Tasks", "comments": "The 22nd IEEE International Conference on Software Analysis,\n  Evolution, and Reengineering (SANER 2015), pp. 540--544, Montreal, Canada,\n  March 2015", "journal-ref": "Proc. SANER 2015, pp. 540--544", "doi": "10.1109/SANER.2015.7081873", "report-no": null, "categories": "cs.SE cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During maintenance, software developers deal with a number of software change\nrequests. Each of those requests is generally written using natural language\ntexts, and it involves one or more domain related concepts. A developer needs\nto map those concepts to exact source code locations within the project in\norder to implement the requested change. This mapping generally starts with a\nsearch within the project that requires one or more suitable search terms.\nStudies suggest that the developers often perform poorly in coming up with good\nsearch terms for a change task. In this paper, we propose and evaluate a novel\nTextRank-based technique that automatically identifies and suggests search\nterms for a software change task by analyzing its task description. Experiments\nwith 349 change tasks from two subject systems and comparison with one of the\nlatest and closely related state-of-the-art approaches show that our technique\nis highly promising in terms of suggestion accuracy, mean average precision and\nrecall.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 06:02:02 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Rahman", "Mohammad Masudur", ""], ["Roy", "Chanchal K.", ""]]}, {"id": "1807.02274", "submitter": "Mohammad Masudur Rahman", "authors": "Mohammad Masudur Rahman and Chanchal K. Roy", "title": "Recommending Relevant Sections from a Webpage about Programming Errors\n  and Exceptions", "comments": "25th Annual International Conference on Computer Science and Software\n  Engineering (CASCON 2015), pp. 181--190, Markham, Canada, November 2015", "journal-ref": "Proc. CASCON 2015, pp. 181--190", "doi": null, "report-no": null, "categories": "cs.SE cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Programming errors or exceptions are inherent in software development and\nmaintenance, and given today's Internet era, software developers often look at\nweb for finding working solutions. They make use of a search engine for\nretrieving relevant pages, and then look for the appropriate solutions by\nmanually going through the pages one by one. However, both the manual checking\nof a page's content against a given exception (and its context) and then\nworking an appropriate solution out are non-trivial tasks. They are even more\ncomplex and time-consuming with the bulk of irrelevant (i.e., off-topic) and\nnoisy (e.g., advertisements) content in the web page. In this paper, we propose\nan IDE-based and context-aware page content recommendation technique that\nlocates and recommends relevant sections from a given web page by exploiting\nthe technical details, in particular, the context of an encountered exception\nin the IDE. An evaluation with 250 web pages related to 80 programming\nexceptions, comparison with the only available closely related technique, and a\ncase study involving comparison with VSM and LSA techniques show that the\nproposed technique is highly promising in terms of precision, recall and\nF1-measure.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 06:28:49 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Rahman", "Mohammad Masudur", ""], ["Roy", "Chanchal K.", ""]]}, {"id": "1807.02299", "submitter": "Weinan Zhang", "authors": "Shihao Zou, Guanyu Tao, Jun Wang, Weinan Zhang, Dell Zhang", "title": "On the Equilibrium of Query Reformulation and Document Retrieval", "comments": "Accepted in ICTIR 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.GT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study jointly query reformulation and document relevance\nestimation, the two essential aspects of information retrieval (IR). Their\ninteractions are modelled as a two-player strategic game: one player, a query\nformulator, taking actions to produce the optimal query, is expected to\nmaximize its own utility with respect to the relevance estimation of documents\nproduced by the other player, a retrieval modeler; simultaneously, the\nretrieval modeler, taking actions to produce the document relevance scores,\nneeds to optimize its likelihood from the training data with respect to the\nrefined query produced by the query formulator. Their equilibrium or equilibria\nwill be reached when both are the best responses to each other. We derive our\nequilibrium theory of IR using normal-form representations: when a standard\nrelevance feedback algorithm is coupled with a retrieval model, they would\nshare the same objective function and thus form a partnership game; by\ncontrast, pseudo relevance feedback pursues a rather different objective than\nthat of retrieval models, therefore the interaction between them would lead to\na general-sum game (though implicitly collaborative). Our game-theoretical\nanalyses not only yield useful insights into the two major aspects of IR, but\nalso offer new practical algorithms for achieving the equilibrium state of\nretrieval which have been shown to bring consistent performance improvements in\nboth text retrieval and item recommendation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 08:06:22 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 11:17:04 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Zou", "Shihao", ""], ["Tao", "Guanyu", ""], ["Wang", "Jun", ""], ["Zhang", "Weinan", ""], ["Zhang", "Dell", ""]]}, {"id": "1807.02314", "submitter": "Xianggen Liu", "authors": "Xianggen Liu, Lili Mou, Haotian Cui, Zhengdong Lu, Sen Song", "title": "JUMPER: Learning When to Make Classification Decisions in Reading", "comments": "Accepted by IJCAI 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In early years, text classification is typically accomplished by\nfeature-based machine learning models; recently, deep neural networks, as a\npowerful learning machine, make it possible to work with raw input as the text\nstands. However, exiting end-to-end neural networks lack explicit\ninterpretation of the prediction. In this paper, we propose a novel framework,\nJUMPER, inspired by the cognitive process of text reading, that models text\nclassification as a sequential decision process. Basically, JUMPER is a neural\nsystem that scans a piece of text sequentially and makes classification\ndecisions at the time it wishes. Both the classification result and when to\nmake the classification are part of the decision process, which is controlled\nby a policy network and trained with reinforcement learning. Experimental\nresults show that a properly trained JUMPER has the following properties: (1)\nIt can make decisions whenever the evidence is enough, therefore reducing total\ntext reading by 30-40% and often finding the key rationale of prediction. (2)\nIt achieves classification accuracy better than or comparable to\nstate-of-the-art models in several benchmark and industrial datasets.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2018 08:49:56 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Liu", "Xianggen", ""], ["Mou", "Lili", ""], ["Cui", "Haotian", ""], ["Lu", "Zhengdong", ""], ["Song", "Sen", ""]]}, {"id": "1807.02391", "submitter": "Sudha Subramani", "authors": "Sudha Subramani, Manjula O'Connor", "title": "Extracting Actionable Knowledge from Domestic Violence Discourses on\n  Social Media", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Domestic Violence (DV) is considered as big social issue and there exists a\nstrong relationship between DV and health impacts of the public. Existing\nresearch studies have focused on social media to track and analyse real world\nevents like emerging trends, natural disasters, user sentiment analysis,\npolitical opinions, and health care. However there is less attention given on\nsocial welfare issues like DV and its impact on public health. Recently, the\nvictims of DV turned to social media platforms to express their feelings in the\nform of posts and seek the social and emotional support, for sympathetic\nencouragement, to show compassion and empathy among public. But, it is\ndifficult to mine the actionable knowledge from large conversational datasets\nfrom social media due to the characteristics of high dimensions, short, noisy,\nhuge volume, high velocity, and so on. Hence, this paper will propose a novel\nframework to model and discover the various themes related to DV from the\npublic domain. The proposed framework would possibly provide unprecedentedly\nvaluable information to the public health researchers, national family health\norganizations, government and public with data enrichment and consolidation to\nimprove the social welfare of the community. Thus provides actionable knowledge\nby monitoring and analysing continuous and rich user generated content.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 03:34:22 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Subramani", "Sudha", ""], ["O'Connor", "Manjula", ""]]}, {"id": "1807.02471", "submitter": "Debadri Dutta", "authors": "Debadri Dutta", "title": "A Review of Different Word Embeddings for Sentiment Classification using\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The web is loaded with textual content, and Natural Language Processing is a\nstandout amongst the most vital fields in Machine Learning. But when data is\nhuge simple Machine Learning algorithms are not able to handle it and that is\nwhen Deep Learning comes into play which based on Neural Networks. However\nsince neural networks cannot process raw text, we have to change over them\nthrough some diverse strategies of word embedding. This paper demonstrates\nthose distinctive word embedding strategies implemented on an Amazon Review\nDataset, which has two sentiments to be classified: Happy and Unhappy based on\nnumerous customer reviews. Moreover we demonstrate the distinction in accuracy\nwith a discourse about which word embedding to apply when.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2018 07:17:21 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Dutta", "Debadri", ""]]}, {"id": "1807.02599", "submitter": "Muhammed Tarik Altuncu", "authors": "M. Tarik Altuncu, Erik Mayer, Sophia N. Yaliraki, Mauricio Barahona", "title": "From Text to Topics in Healthcare Records: An Unsupervised Graph\n  Partitioning Methodology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG cs.SI math.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electronic Healthcare Records contain large volumes of unstructured data,\nincluding extensive free text. Yet this source of detailed information often\nremains under-used because of a lack of methodologies to extract interpretable\ncontent in a timely manner. Here we apply network-theoretical tools to analyse\nfree text in Hospital Patient Incident reports from the National Health\nService, to find clusters of documents with similar content in an unsupervised\nmanner at different levels of resolution. We combine deep neural network\nparagraph vector text-embedding with multiscale Markov Stability community\ndetection applied to a sparsified similarity graph of document vectors, and\nshowcase the approach on incident reports from Imperial College Healthcare NHS\nTrust, London. The multiscale community structure reveals different levels of\nmeaning in the topics of the dataset, as shown by descriptive terms extracted\nfrom the clusters of records. We also compare a posteriori against hand-coded\ncategories assigned by healthcare personnel, and show that our approach\noutperforms LDA-based models. Our content clusters exhibit good correspondence\nwith two levels of hand-coded categories, yet they also provide further medical\ndetail in certain areas and reveal complementary descriptors of incidents\nbeyond the external classification taxonomy.\n", "versions": [{"version": "v1", "created": "Sat, 7 Jul 2018 01:14:10 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Altuncu", "M. Tarik", ""], ["Mayer", "Erik", ""], ["Yaliraki", "Sophia N.", ""], ["Barahona", "Mauricio", ""]]}, {"id": "1807.02854", "submitter": "Pankaj Gupta", "authors": "Pankaj Gupta and Bernt Andrassy and Hinrich Sch\\\"utze", "title": "Replicated Siamese LSTM in Ticketing System for Similarity Learning and\n  Retrieval in Asymmetric Texts", "comments": "In the 27th International Conference on Computational Linguistics\n  (COLING 2018) workshop on Semantic Deep Learning (SemDeep-3)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of our industrial ticketing system is to retrieve a relevant\nsolution for an input query, by matching with historical tickets stored in\nknowledge base. A query is comprised of subject and description, while a\nhistorical ticket consists of subject, description and solution. To retrieve a\nrelevant solution, we use textual similarity paradigm to learn similarity in\nthe query and historical tickets. The task is challenging due to significant\nterm mismatch in the query and ticket pairs of asymmetric lengths, where\nsubject is a short text but description and solution are multi-sentence texts.\nWe present a novel Replicated Siamese LSTM model to learn similarity in\nasymmetric text pairs, that gives 22% and 7% gain (Accuracy@10) for retrieval\ntask, respectively over unsupervised and supervised baselines. We also show\nthat the topic and distributed semantic features for short and long texts\nimproved both similarity learning and retrieval.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 17:33:43 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Gupta", "Pankaj", ""], ["Andrassy", "Bernt", ""], ["Sch\u00fctze", "Hinrich", ""]]}, {"id": "1807.02892", "submitter": "Deon Nicholas", "authors": "Volodymyr Lyubinets, Taras Boiko, Deon Nicholas", "title": "Automated labeling of bugs and tickets using attention-based mechanisms\n  in recurrent neural networks", "comments": "Accepted to 2018 IEEE Second International Conference on Data Stream\n  Mining and Processing. Index Terms - text classification, recurrent neural\n  network, hierarchical attention, machine learning, natural language\n  processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore solutions for automated labeling of content in bug trackers and\ncustomer support systems. In order to do that, we classify content in terms of\nseveral criteria, such as priority or product area. In the first part of the\npaper, we provide an overview of existing methods used for text classification.\nThese methods fall into two categories - the ones that rely on neural networks\nand the ones that don't. We evaluate results of several solutions of both\nkinds. In the second part of the paper we present our own recurrent neural\nnetwork solution based on hierarchical attention paradigm. It consists of\nseveral Hierarchical Attention network blocks with varying Gated Recurrent Unit\ncell sizes and a complementary shallow network that goes alongside. Lastly, we\nevaluate above-mentioned methods when predicting fields from two datasets -\nArch Linux bug tracker and Chromium bug tracker. Our contributions include a\ncomprehensive benchmark between a variety of methods on relevant datasets; a\nnovel solution that outperforms previous generation methods; and two new\ndatasets that are made public for further research.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 22:33:51 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Lyubinets", "Volodymyr", ""], ["Boiko", "Taras", ""], ["Nicholas", "Deon", ""]]}, {"id": "1807.02895", "submitter": "Chengyuan Zhang", "authors": "Jun Long, Qunfeng Liu, Xinpan Yuan, Chengyuan Zhang, Junfeng Liu", "title": "A Filter of Minhash for Image Similarity Measures", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MM cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Image similarity measures play an important role in nearest neighbor search\nand duplicate detection for large-scale image datasets. Recently, Minwise\nHashing (or Minhash) and its related hashing algorithms have achieved great\nperformances in large-scale image retrieval systems. However, there are a large\nnumber of comparisons for image pairs in these applications, which may spend a\nlot of computation time and affect the performance. In order to quickly obtain\nthe pairwise images that theirs similarities are higher than the specific\nthreshold T (e.g., 0.5), we propose a dynamic threshold filter of Minwise\nHashing for image similarity measures. It greatly reduces the calculation time\nby terminating the unnecessary comparisons in advance. We also find that the\nfilter can be extended to other hashing algorithms, on when the estimator\nsatisfies the binomial distribution, such as b-Bit Minwise Hashing, One\nPermutation Hashing, etc. In this pager, we use the Bag-of-Visual-Words (BoVW)\nmodel based on the Scale Invariant Feature Transform (SIFT) to represent the\nimage features. We have proved that the filter is correct and effective through\nthe experiment on real image datasets.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2018 23:27:12 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Long", "Jun", ""], ["Liu", "Qunfeng", ""], ["Yuan", "Xinpan", ""], ["Zhang", "Chengyuan", ""], ["Liu", "Junfeng", ""]]}, {"id": "1807.02962", "submitter": "Chih-Yi Chiu", "authors": "Chih-Yi Chiu, Amorntip Prayoonwong, and Yin-Chih Liao", "title": "Learning to Index for Nearest Neighbor Search", "comments": "This paper was accepted by IEEE Transcations on Pattern Analysis and\n  Machine Intelligence in March 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we present a novel ranking model based on learning\nneighborhood relationships embedded in the index space. Given a query point,\nconventional approximate nearest neighbor search calculates the distances to\nthe cluster centroids, before ranking the clusters from near to far based on\nthe distances. The data indexed in the top-ranked clusters are retrieved and\ntreated as the nearest neighbor candidates for the query. However, the loss of\nquantization between the data and cluster centroids will inevitably harm the\nsearch accuracy. To address this problem, the proposed model ranks clusters\nbased on their nearest neighbor probabilities rather than the query-centroid\ndistances. The nearest neighbor probabilities are estimated by employing neural\nnetworks to characterize the neighborhood relationships, i.e., the density\nfunction of nearest neighbors with respect to the query. The proposed\nprobability-based ranking can replace the conventional distance-based ranking\nfor finding candidate clusters, and the predicted probability can be used to\ndetermine the data quantity to be retrieved from the candidate cluster. Our\nexperimental results demonstrated that the proposed ranking model could boost\nthe search performance effectively in billion-scale datasets.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 06:55:07 GMT"}, {"version": "v2", "created": "Thu, 7 Mar 2019 16:52:27 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 12:21:18 GMT"}], "update_date": "2019-05-01", "authors_parsed": [["Chiu", "Chih-Yi", ""], ["Prayoonwong", "Amorntip", ""], ["Liao", "Yin-Chih", ""]]}, {"id": "1807.03012", "submitter": "Miguel Feria", "authors": "Miguel Feria, Juan Paolo Balbin, Francis Michael Bautista", "title": "Constructing a Word Similarity Graph from Vector based Word\n  Representation for Named Entity Recognition", "comments": "Preprint for 14th International Conference On Web Information Systems\n  and Technologies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss a method for identifying a seed word that would\nbest represent a class of named entities in a graphical representation of words\nand their similarities. Word networks, or word graphs, are representations of\nvectorized text where nodes are the words encountered in a corpus, and the\nweighted edges incident on the nodes represent how similar the words are to\neach other. We intend to build a bilingual word graph and identify seed words\nthrough community analysis that would be best used to segment a graph according\nto its named entities, therefore providing an unsupervised way of tagging named\nentities for a bilingual language base.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 09:43:23 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Feria", "Miguel", ""], ["Balbin", "Juan Paolo", ""], ["Bautista", "Francis Michael", ""]]}, {"id": "1807.03046", "submitter": "Emilia Gomez", "authors": "Emilia G\\'omez and Merlijn Blaauw and Jordi Bonada and Pritish Chandna\n  and Helena Cuesta", "title": "Deep Learning for Singing Processing: Achievements, Challenges and\n  Impact on Singers and Listeners", "comments": "Keynote speech, 2018 Joint Workshop on Machine Learning for Music.\n  The Federated Artificial Intelligence Meeting (FAIM), a joint workshop\n  program of ICML, IJCAI/ECAI, and AAMAS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.IR cs.LG cs.MM eess.AS stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes some recent advances on a set of tasks related to the\nprocessing of singing using state-of-the-art deep learning techniques. We\ndiscuss their achievements in terms of accuracy and sound quality, and the\ncurrent challenges, such as availability of data and computing resources. We\nalso discuss the impact that these advances do and will have on listeners and\nsingers when they are integrated in commercial applications.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jul 2018 11:19:42 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["G\u00f3mez", "Emilia", ""], ["Blaauw", "Merlijn", ""], ["Bonada", "Jordi", ""], ["Chandna", "Pritish", ""], ["Cuesta", "Helena", ""]]}, {"id": "1807.03283", "submitter": "Ahmed I. Taloba", "authors": "Ahmed I. Taloba, D. A. Eisa, Safaa S. I. Ismail", "title": "A Comparative Study on using Principle Component Analysis with Different\n  Text Classifiers", "comments": null, "journal-ref": "International Journal of Computer Applications 180(31):1-6, April\n  2018", "doi": "10.5120/ijca2018916800", "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text categorization (TC) is the task of automatically organizing a set of\ndocuments into a set of pre-defined categories. Over the last few years,\nincreased attention has been paid to the use of documents in digital form and\nthis makes text categorization becomes a challenging issue. The most\nsignificant problem of text categorization is its huge number of features. Most\nof these features are redundant, noisy and irrelevant that cause over fitting\nwith most of the classifiers. Hence, feature extraction is an important step to\nimprove the overall accuracy and the performance of the text classifiers. In\nthis paper, we will provide an overview of using principle component analysis\n(PCA) as a feature extraction with various classifiers. It was observed that\nthe performance rate of the classifiers after using PCA to reduce the dimension\nof data improved. Experiments are conducted on three UCI data sets, Classic03,\nCNAE-9 and DBWorld e-mails. We compare the classification performance results\nof using PCA with popular and well-known text classifiers. Results show that\nusing PCA encouragingly enhances classification performance on most of the\nclassifiers.\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2018 08:50:35 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Taloba", "Ahmed I.", ""], ["Eisa", "D. A.", ""], ["Ismail", "Safaa S. I.", ""]]}, {"id": "1807.03492", "submitter": "Takumi Ichimura", "authors": "Takumi Ichimura, Takuya Uemoto, Shin Kamada", "title": "The Recommendation System to SNS Community for Tourists by Using\n  Altruistic Behaviors", "comments": "6 pages, 9 figures", "journal-ref": "Proc. of IEEE 9th International Workshop on Computational\n  Intelligence and Applications (IWCIA2016)", "doi": "10.1109/IWCIA.2016.7805747", "report-no": null, "categories": "cs.MA cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have already developed the recommendation system of sightseeing\ninformation on SNS by using smartphone based user participatory sensing system.\nThe system can post the attractive information for tourists to the specified\nFacebook page by our developed smartphone application. The users in Facebook,\nwho are interested in sightseeing, can come flocking through information space\nfrom far and near. However, the activities in the community on SNS are only\nsupported by the specified people called a hub. We proposed the method of\nvitalization of tourist behaviors to give a stimulus to the people. We\ndeveloped the simulation system for multi agent system with altruistic\nbehaviors inspired by the Army Ants. The army ant takes feeding action with\naltruistic behaviors to suppress selfish behavior to a common object used by a\nplurality of users in common. In this paper, we introduced the altruism\nbehavior determined by some simulation to vitalize the SNS community. The\nefficiency of the revitalization process of the community was investigated by\nsome experimental simulation results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 06:26:28 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 07:47:34 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Ichimura", "Takumi", ""], ["Uemoto", "Takuya", ""], ["Kamada", "Shin", ""]]}, {"id": "1807.03493", "submitter": "Takumi Ichimura", "authors": "Shin Kamada, Takumi Ichimura, Takanobu Watanabe", "title": "A Recommendation System of Grants to Acquire External Funds", "comments": null, "journal-ref": "Proc. of IEEE 9th International Workshop on Computational\n  Intelligence and Applications (IWCIA2016)", "doi": "10.1109/IWCIA.2016.7805760", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recommendation system of the competitive grants to university researchers\nby using the Grants-in-Aid for Scientific Research (KAKEN) keywords has been\ndeveloped. The system can determine the recommendation order of researchers to\neach grant by the using the association rules between KAKEN application and\nvarious information from the web site of the corresponding grant. However, our\ndeveloped previous system has some fatal errors in the retrieval algorithm. We\nmodify the algorithm and extend the retrieval data for web mining. If the grant\ninformation is not enough to determine the relation, the system investigates\nthe past KAKEN records in the database for the researcher who acquired the past\ngrant. Moreover, the system retrieves the papers of the researchers to search\ntheir interests. As a result, the agreement degree of the researcher's interest\nto the grant increases. This paper discusses some simulation results.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 06:27:15 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 07:59:58 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Kamada", "Shin", ""], ["Ichimura", "Takumi", ""], ["Watanabe", "Takanobu", ""]]}, {"id": "1807.03521", "submitter": "Yehezkel Resheff", "authors": "Yehezkel S. Resheff, Yanai Elazar, Moni Shahar, Oren Sar Shalom", "title": "Privacy and Fairness in Recommender Systems via Adversarial Training of\n  User Representations", "comments": "International Conference on Pattern Recognition and Methods", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent factor models for recommender systems represent users and items as low\ndimensional vectors. Privacy risks of such systems have previously been studied\nmostly in the context of recovery of personal information in the form of usage\nrecords from the training data. However, the user representations themselves\nmay be used together with external data to recover private user information\nsuch as gender and age. In this paper we show that user vectors calculated by a\ncommon recommender system can be exploited in this way. We propose the\nprivacy-adversarial framework to eliminate such leakage of private information,\nand study the trade-off between recommender performance and leakage both\ntheoretically and empirically using a benchmark dataset. An advantage of the\nproposed method is that it also helps guarantee fairness of results, since all\nimplicit knowledge of a set of attributes is scrubbed from the representations\nused by the model, and thus can't enter into the decision making. We discuss\nfurther applications of this method towards the generation of deeper and more\ninsightful recommendations.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 08:33:20 GMT"}, {"version": "v2", "created": "Mon, 10 Dec 2018 19:47:46 GMT"}, {"version": "v3", "created": "Tue, 18 Dec 2018 06:21:43 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Resheff", "Yehezkel S.", ""], ["Elazar", "Yanai", ""], ["Shahar", "Moni", ""], ["Shalom", "Oren Sar", ""]]}, {"id": "1807.03719", "submitter": "Robin Brochier", "authors": "Robin Brochier, Adrien Guille (ERIC), Julien Velcin (ERIC), Benjamin\n  Rothan, Di Cioccio", "title": "Peerus Review: a tool for scientific experts finding", "comments": "in French", "journal-ref": "EGC 2018, Jan 2018, Paris, France", "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a tool for experts finding applied to academic data generated by\nthe start-up DSRT in the context of its application Peerus. A user may submit\nthe title, the abstract and optionnally the authors and the journal of\npublication of a scientific article and the application then returns a list of\nexperts, potential reviewers of the submitted article. The retrieval algorithm\nis a voting system based on a language modeling technique trained on several\nmillions of scientific papers.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jun 2018 14:20:30 GMT"}], "update_date": "2018-07-11", "authors_parsed": [["Brochier", "Robin", "", "ERIC"], ["Guille", "Adrien", "", "ERIC"], ["Velcin", "Julien", "", "ERIC"], ["Rothan", "Benjamin", ""], ["Cioccio", "Di", ""]]}, {"id": "1807.03905", "submitter": "Andre Lima", "authors": "Andre Paulino de Lima, Sarajane Marques Peres", "title": "Limits to Surprise in Recommender Systems", "comments": "9 pages, conference format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we address the challenge of measuring the ability of a\nrecommender system to make surprising recommendations. Although current\nevaluation methods make it possible to determine if two algorithms can make\nrecommendations with a significant difference in their average surprise\nmeasure, it could be of interest to our community to know how competent an\nalgorithm is at embedding surprise in its recommendations, without having to\nresort to making a direct comparison with another algorithm. We argue that a)\nsurprise is a finite resource in a recommender system, b) there is a limit to\nhow much surprise any algorithm can embed in a recommendation, and c) this\nlimit can provide us with a scale against which the performance of any\nalgorithm can be measured. By exploring these ideas, it is possible to define\nthe concepts of maximum and minimum potential surprise and design a surprise\nmetric called \"normalised surprise\" that employs these limits to potential\nsurprise. Two experiments were conducted to test the proposed metric. The aim\nof the first was to validate the quality of the estimates of minimum and\nmaximum potential surprise produced by a greedy algorithm. The purpose of the\nsecond experiment was to analyse the behaviour of the proposed metric using the\nMovieLens dataset. The results confirmed the behaviour that was expected, and\nshowed that the proposed surprise metric is both effective and consistent for\ndiffering choices of recommendation algorithms, data representations and\ndistance functions.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 23:57:40 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["de Lima", "Andre Paulino", ""], ["Peres", "Sarajane Marques", ""]]}, {"id": "1807.04098", "submitter": "C. H. Bryan Liu", "authors": "Georg L. Grob, \\^Angelo Cardoso, C. H. Bryan Liu, Duncan A. Little,\n  Benjamin Paul Chamberlain", "title": "A Recurrent Neural Network Survival Model: Predicting Web User Return\n  Time", "comments": "Accepted into ECML PKDD 2018; 8 figures and 1 table", "journal-ref": "Machine Learning and Knowledge Discovery in Databases. ECML PKDD\n  2018. Lecture Notes in Computer Science, vol 11053. pp 152-168", "doi": "10.1007/978-3-030-10997-4_10", "report-no": null, "categories": "cs.LG cs.CY cs.IR cs.NE stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The size of a website's active user base directly affects its value. Thus, it\nis important to monitor and influence a user's likelihood to return to a site.\nEssential to this is predicting when a user will return. Current state of the\nart approaches to solve this problem come in two flavors: (1) Recurrent Neural\nNetwork (RNN) based solutions and (2) survival analysis methods. We observe\nthat both techniques are severely limited when applied to this problem.\nSurvival models can only incorporate aggregate representations of users instead\nof automatically learning a representation directly from a raw time series of\nuser actions. RNNs can automatically learn features, but can not be directly\ntrained with examples of non-returning users who have no target value for their\nreturn time. We develop a novel RNN survival model that removes the limitations\nof the state of the art methods. We demonstrate that this model can\nsuccessfully be applied to return time prediction on a large e-commerce dataset\nwith a superior ability to discriminate between returning and non-returning\nusers than either method applied in isolation.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 12:12:48 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Grob", "Georg L.", ""], ["Cardoso", "\u00c2ngelo", ""], ["Liu", "C. H. Bryan", ""], ["Little", "Duncan A.", ""], ["Chamberlain", "Benjamin Paul", ""]]}, {"id": "1807.04204", "submitter": "Vito Walter Anelli", "authors": "Vito Walter Anelli, Tommaso Di Noia, Eugenio Di Sciascio, Azzurra\n  Ragone, and Joseph Trotta", "title": "Local Popularity and Time in top-N Recommendation", "comments": "ECIR short paper, 7 pages", "journal-ref": "Advances in Information Retrieval - 41st European Conference on IR\n  Research, ECIR 2019, Cologne, Germany, April 14-18, 2019, Proceedings, Part I", "doi": "10.1007/978-3-030-15712-8_63", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Items popularity is a strong signal in recommendation algorithms. It strongly\naffects collaborative filtering approaches and it has been proven to be a very\ngood baseline in terms of results accuracy. Even though we miss an actual\npersonalization, global popularity can be effectively used to recommend items\nto users. In this paper we introduce the idea of a time-aware personalized\npopularity in recommender systems by considering both items popularity among\nneighbors and how it changes over time. An experimental evaluation shows a\nhighly competitive behavior of the proposed approach, compared to state of the\nart model-based collaborative approaches, in terms of results accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 15:43:19 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 12:42:18 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Anelli", "Vito Walter", ""], ["Di Noia", "Tommaso", ""], ["Di Sciascio", "Eugenio", ""], ["Ragone", "Azzurra", ""], ["Trotta", "Joseph", ""]]}, {"id": "1807.04207", "submitter": "Vito Walter Anelli", "authors": "Vito Walter Anelli, Joseph Trotta, Tommaso Di Noia, Eugenio Di\n  Sciascio, Azzurra Ragone", "title": "The importance of being dissimilar in Recommendation", "comments": "Short Version, 5 pages", "journal-ref": "Proceedings of the 34th ACM/SIGAPP Symposium on Applied Computing,\n  SAC 2019, Limassol, Cyprus, April 8-12, 2019", "doi": "10.1145/3297280.3297360", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity measures play a fundamental role in memory-based nearest neighbors\napproaches. They recommend items to a user based on the similarity of either\nitems or users in a neighborhood. In this paper we argue that, although it\nkeeps a leading importance in computing recommendations, similarity between\nusers or items should be paired with a value of dissimilarity (computed not\njust as the complement of the similarity one). We formally modeled and injected\nthis notion in some of the most used similarity measures and evaluated our\napproach showing its effectiveness in terms of accuracy results.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 15:51:31 GMT"}, {"version": "v2", "created": "Thu, 4 Jul 2019 12:49:13 GMT"}], "update_date": "2019-07-05", "authors_parsed": [["Anelli", "Vito Walter", ""], ["Trotta", "Joseph", ""], ["Di Noia", "Tommaso", ""], ["Di Sciascio", "Eugenio", ""], ["Ragone", "Azzurra", ""]]}, {"id": "1807.04210", "submitter": "Mohammad Aliannejadi", "authors": "Mohammad Aliannejadi and Dimitrios Rafailidis and Fabio Crestani", "title": "A Collaborative Ranking Model with Multiple Location-based Similarities\n  for Venue Suggestion", "comments": "To appear at ICTIR 2018", "journal-ref": null, "doi": "10.1145/3234944.3234945", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommending venues plays a critical rule in satisfying users' needs on\nlocation-based social networks. Recent studies have explored the idea of\nadopting collaborative ranking (CR) for recommendation, combining the idea of\nlearning to rank and collaborative filtering. However, CR suffers from the\nsparsity problem, mainly because it associates similar users based on exact\nmatching of the venues in their check-in history. Even though research in\ncollaborative filtering has shown that considering auxiliary information such\nas geographical influence, helps the model to alleviate the sparsity problem,\nthe same direction still needs to be explored in CR. In this work, we present a\nCR framework that focuses on the top of the ranked list while integrating an\narbitrary number of similarity functions between venues as it learns the\nmodel's parameters. We further introduce three example similarity measures\nbased on venues' contents and locations. Incorporating cross-venue similarity\nmeasures into the model enhances the latent associations between users as\nsimilar venues are also taken into account while associating users with each\nother. Our experiments on the TREC Contextual Suggestion dataset show that our\nproposed CR model beats other state-of-the-art venue suggestion methods.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 15:53:54 GMT"}, {"version": "v2", "created": "Fri, 13 Jul 2018 12:57:42 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Aliannejadi", "Mohammad", ""], ["Rafailidis", "Dimitrios", ""], ["Crestani", "Fabio", ""]]}, {"id": "1807.04271", "submitter": "Ewin Tang", "authors": "Ewin Tang", "title": "A quantum-inspired classical algorithm for recommendation systems", "comments": "32 pages; revised structure of document, improved runtime, simplified\n  algorithm and notation", "journal-ref": null, "doi": "10.1145/3313276.3316310", "report-no": null, "categories": "cs.IR cs.DS cs.LG quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a classical analogue to Kerenidis and Prakash's quantum\nrecommendation system, previously believed to be one of the strongest\ncandidates for provably exponential speedups in quantum machine learning. Our\nmain result is an algorithm that, given an $m \\times n$ matrix in a data\nstructure supporting certain $\\ell^2$-norm sampling operations, outputs an\n$\\ell^2$-norm sample from a rank-$k$ approximation of that matrix in time\n$O(\\text{poly}(k)\\log(mn))$, only polynomially slower than the quantum\nalgorithm. As a consequence, Kerenidis and Prakash's algorithm does not in fact\ngive an exponential speedup over classical algorithms. Further, under strong\ninput assumptions, the classical recommendation system resulting from our\nalgorithm produces recommendations exponentially faster than previous classical\nsystems, which run in time linear in $m$ and $n$.\n  The main insight of this work is the use of simple routines to manipulate\n$\\ell^2$-norm sampling distributions, which play the role of quantum\nsuperpositions in the classical setting. This correspondence indicates a\npotentially fruitful framework for formally comparing quantum machine learning\nalgorithms to classical machine learning algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2018 20:57:24 GMT"}, {"version": "v2", "created": "Mon, 22 Apr 2019 02:49:30 GMT"}, {"version": "v3", "created": "Thu, 9 May 2019 05:03:18 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Tang", "Ewin", ""]]}, {"id": "1807.04317", "submitter": "Damiano Spina", "authors": "Enrique Amig\\'o, Fernando Giner, Stefano Mizzaro, Damiano Spina", "title": "A Formal Account of Effectiveness Evaluation and Ranking Fusion", "comments": "ICTIR'18 paper, extended version with formal proofs (10 pages)", "journal-ref": null, "doi": "10.1145/3234944.3234958", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a theoretical framework which models the information\nprovided by retrieval systems in terms of Information Theory. The proposed\nframework allows to formalize: (i) system effectiveness as an information\ntheoretic similarity between system outputs and human assessments, and (ii)\nranking fusion as an information quantity measure. As a result, the proposed\neffectiveness metric improves popular metrics in terms of formal constraints.\nIn addition, our empirical experiments suggest that it captures quality aspects\nfrom traditional metrics, while the reverse is not true. Our work also advances\nthe understanding of theoretical foundations of the empirically known\nphenomenon of effectiveness increase when combining retrieval system outputs in\nan unsupervised manner.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 19:22:24 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2018 23:37:52 GMT"}, {"version": "v3", "created": "Fri, 14 Sep 2018 10:13:33 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Amig\u00f3", "Enrique", ""], ["Giner", "Fernando", ""], ["Mizzaro", "Stefano", ""], ["Spina", "Damiano", ""]]}, {"id": "1807.04386", "submitter": "Yihuang Kang", "authors": "Yihuang Kang, Keng-Pei Lin, I-Ling Cheng", "title": "Topic Diffusion Discovery based on Sparseness-constrained Non-negative\n  Matrix Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to recent explosion of text data, researchers have been overwhelmed by\never-increasing volume of articles produced by different research communities.\nVarious scholarly search websites, citation recommendation engines, and\nresearch databases have been created to simplify the text search tasks.\nHowever, it is still difficult for researchers to be able to identify potential\nresearch topics without doing intensive reviews on a tremendous number of\narticles published by journals, conferences, meetings, and workshops. In this\npaper, we consider a novel topic diffusion discovery technique that\nincorporates sparseness-constrained Non-negative Matrix Factorization with\ngeneralized Jensen-Shannon divergence to help understand term-topic evolutions\nand identify topic diffusions. Our experimental result shows that this approach\ncan extract more prominent topics from large article databases, visualize\nrelationships between terms of interest and abstract topics, and further help\nresearchers understand whether given terms/topics have been widely explored or\nwhether new topics are emerging from literature.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 00:31:43 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Kang", "Yihuang", ""], ["Lin", "Keng-Pei", ""], ["Cheng", "I-Ling", ""]]}, {"id": "1807.04441", "submitter": "Roberto Camacho Barranco", "authors": "Roberto Camacho Barranco, Raimundo F. Dos Santos, M. Shahriar Hossain", "title": "Tracking the Evolution of Words with Time-reflective Text\n  Representations", "comments": "10 pages, 8 figures, presented at the 4th Special Session on\n  Intelligent Data Mining special session of the 2018 IEEE International\n  Conference on Big Data 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  More than 80% of today's data is unstructured in nature, and these\nunstructured datasets evolve over time. A large part of these datasets are text\ndocuments generated by media outlets, scholarly articles in digital libraries,\nfindings from scientific and professional communities, and social media. Vector\nspace models were developed to analyze text data using data mining and machine\nlearning algorithms. While ample vector space models exist for text data, the\nevolutionary aspect of ever-changing text corpora is still missing in\nvector-based representations. The advent of word embeddings has enabled us to\ncreate a contextual vector space, but the embeddings fail to consider the\ntemporal aspects of the feature space successfully. This paper presents an\napproach to include temporal aspects in feature spaces. The inclusion of the\ntime aspect in the feature space provides vectors for every natural language\nelement, such as words or entities, at every timestamp. Such temporal word\nvectors allow us to track how the meaning of a word changes over time, by\nstudying the changes in its neighborhood. Moreover, a time-reflective text\nrepresentation will pave the way to a new set of text analytic abilities\ninvolving time series for text collections. In this paper, we present a\ntime-reflective vector space model for temporal text data that is able to\ncapture short and long-term changes in the meaning of words. We compare our\napproach with the limited literature on dynamic embeddings. We present\nqualitative and quantitative evaluations using the tracking of semantic\nevolution as the target application.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 06:47:15 GMT"}, {"version": "v2", "created": "Wed, 20 Mar 2019 02:20:04 GMT"}], "update_date": "2019-03-21", "authors_parsed": [["Barranco", "Roberto Camacho", ""], ["Santos", "Raimundo F. Dos", ""], ["Hossain", "M. Shahriar", ""]]}, {"id": "1807.04465", "submitter": "Cheng Kang Hsieh", "authors": "Miguel Campo, Cheng-Kang Hsieh, Matt Nickens, JJ Espinoza, Abhinav\n  Taliyan, Julie Rieger, Jean Ho, Bettina Sherick", "title": "Competitive Analysis System for Theatrical Movie Releases Based on Movie\n  Trailer Deep Video Representation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CV cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Audience discovery is an important activity at major movie studios. Deep\nmodels that use convolutional networks to extract frame-by-frame features of a\nmovie trailer and represent it in a form that is suitable for prediction are\nnow possible thanks to the availability of pre-built feature extractors trained\non large image datasets. Using these pre-built feature extractors, we are able\nto process hundreds of publicly available movie trailers, extract\nframe-by-frame low level features (e.g., a face, an object, etc) and create\nvideo-level representations. We use the video-level representations to train a\nhybrid Collaborative Filtering model that combines video features with\nhistorical movie attendance records. The trained model not only makes accurate\nattendance and audience prediction for existing movies, but also successfully\nprofiles new movies six to eight months prior to their release.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 08:24:56 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Campo", "Miguel", ""], ["Hsieh", "Cheng-Kang", ""], ["Nickens", "Matt", ""], ["Espinoza", "JJ", ""], ["Taliyan", "Abhinav", ""], ["Rieger", "Julie", ""], ["Ho", "Jean", ""], ["Sherick", "Bettina", ""]]}, {"id": "1807.04639", "submitter": "Harris Georgiou", "authors": "Harris Georgiou, Sophia Karagiorgou, Yannis Kontoulis, Nikos Pelekis,\n  Petros Petrou, David Scarlatti, Yannis Theodoridis", "title": "Moving Objects Analytics: Survey on Future Location & Trajectory\n  Prediction Methods", "comments": "45 pages, 11 figures, 2 tables, 127 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The tremendous growth of positioning technologies and GPS enabled devices has\nproduced huge volumes of tracking data during the recent years. This source of\ninformation constitutes a rich input for data analytics processes, either\noffline (e.g. cluster analysis, hot motion discovery) or online (e.g.\nshort-term forecasting of forthcoming positions). This paper focuses on\npredictive analytics for moving objects (could be pedestrians, cars, vessels,\nplanes, animals, etc.) and surveys the state-of-the-art in the context of\nfuture location and trajectory prediction. We provide an extensive review of\nover 50 works, also proposing a novel taxonomy of predictive algorithms over\nmoving objects. We also list the properties of several real datasets used in\nthe past for validation purposes of those works and, motivated by this, we\ndiscuss challenges that arise in the transition from conventional to Big Data\napplications.\n  CCS Concepts: Information systems > Spatial-temporal systems; Information\nsystems > Data analytics; Information systems > Data mining; Computing\nmethodologies > Machine learning Additional Key Words and Phrases: mobility\ndata, moving object trajectories, trajectory prediction, future location\nprediction.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2018 08:01:38 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Georgiou", "Harris", ""], ["Karagiorgou", "Sophia", ""], ["Kontoulis", "Yannis", ""], ["Pelekis", "Nikos", ""], ["Petrou", "Petros", ""], ["Scarlatti", "David", ""], ["Theodoridis", "Yannis", ""]]}, {"id": "1807.04690", "submitter": "Andreu Vall", "authors": "Andreu Vall, Massimo Quadrana, Markus Schedl, Gerhard Widmer", "title": "The Importance of Song Context and Song Order in Automated Music\n  Playlist Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The automated generation of music playlists can be naturally regarded as a\nsequential task, where a recommender system suggests a stream of songs that\nconstitute a listening session. In order to predict the next song in a\nplaylist, some of the playlist models proposed so far consider the current and\nprevious songs in the playlist (i.e., the song context) and possibly the order\nof the songs in the playlist. We investigate the impact of the song context and\nthe song order on next-song recommendations by conducting dedicated off-line\nexperiments on two datasets of hand-curated music playlists. Firstly, we\ncompare three playlist models, each able to consider a different song context\nlength: a popularity-based model, a song-based Collaborative Filtering (CF)\nmodel and a Recurrent-Neural-Network-based model (RNN). We also consider a\nmodel that predicts next songs at random as a reference. Secondly, we challenge\nthe RNN model (the only model from the first experiment able to consider the\nsong order) by manipulating the order of songs within playlists. Our results\nindicate that the song context has a positive impact on the quality of\nnext-song recommendations, even though this effect can be masked by the bias\ntowards very popular songs. Furthermore, in our experiments the song order does\nnot appear as a crucial variable to predict better next-song recommendations.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 15:56:58 GMT"}], "update_date": "2018-07-13", "authors_parsed": [["Vall", "Andreu", ""], ["Quadrana", "Massimo", ""], ["Schedl", "Markus", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1807.04923", "submitter": "Suhas Ranganath", "authors": "Suhas Ranganath", "title": "Leveraging Catalog Knowledge Graphs for Query Attribute Identification\n  in E-Commerce Sites", "comments": "in ACM SIGIR Ecom 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Millions of people use online e-commerce platforms to search and buy\nproducts. Identifying attributes in a query is a critical component in\nconnecting users to relevant items. However, in many cases, the queries have\nmultiple attributes, and some of them will be in conflict with each other. For\nexample, the query \"maroon 5 dvds\" has two candidate attributes, the color\n\"maroon\" or the band \"maroon 5\", where only one of the attributes can be\npresent. In this paper, we address the problem of resolving conflicting\nattributes in e-commerce queries. A challenge in this problem is that knowledge\nbases like Wikipedia that are used to understand web queries are not focused on\nthe e-commerce domain. E-commerce search engines, however, have access to the\ncatalog which contains detailed information about the items and its attributes.\nWe propose a framework that constructs knowledge graphs from catalog to resolve\nconflicting attributes in e-commerce queries. Our experiments on real-world\nqueries on e-commerce platforms demonstrate that resolving conflicting\nattributes by leveraging catalog information significantly improves attribute\nidentification, and also gives out more relevant search results.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 05:35:36 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Ranganath", "Suhas", ""]]}, {"id": "1807.05006", "submitter": "Vito Bellini", "authors": "Vito Bellini, Angelo Schiavone, Tommaso Di Noia, Azzurra Ragone,\n  Eugenio Di Sciascio", "title": "Computing recommendations via a Knowledge Graph-aware Autoencoder", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last years, deep learning has shown to be a game-changing technology\nin artificial intelligence thanks to the numerous successes it reached in\ndiverse application fields. Among others, the use of deep learning for the\nrecommendation problem, although new, looks quite promising due to its positive\nperformances in terms of accuracy of recommendation results. In a\nrecommendation setting, in order to predict user ratings on unknown items a\npossible configuration of a deep neural network is that of autoencoders\ntipically used to produce a lower dimensionality representation of the original\ndata. In this paper we present KG-AUTOENCODER, an autoencoder that bases the\nstructure of its neural network on the semanticsaware topology of a knowledge\ngraph thus providing a label for neurons in the hidden layer that are\neventually used to build a user profile and then compute recommendations. We\nshow the effectiveness of KG-AUTOENCODER in terms of accuracy, diversity and\nnovelty by comparing with state of the art recommendation algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 11:08:42 GMT"}], "update_date": "2018-07-16", "authors_parsed": [["Bellini", "Vito", ""], ["Schiavone", "Angelo", ""], ["Di Noia", "Tommaso", ""], ["Ragone", "Azzurra", ""], ["Di Sciascio", "Eugenio", ""]]}, {"id": "1807.05151", "submitter": "Seid Muhie Yimam", "authors": "Gregor Wiedemann and Seid Muhie Yimam and Chris Biemann", "title": "New/s/leak 2.0 - Multilingual Information Extraction and Visualization\n  for Investigative Journalism", "comments": "Social Informatics 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Investigative journalism in recent years is confronted with two major\nchallenges: 1) vast amounts of unstructured data originating from large text\ncollections such as leaks or answers to Freedom of Information requests, and 2)\nmulti-lingual data due to intensified global cooperation and communication in\npolitics, business and civil society. Faced with these challenges, journalists\nare increasingly cooperating in international networks. To support such\ncollaborations, we present the new version of new/s/leak 2.0, our open-source\nsoftware for content-based searching of leaks. It includes three novel main\nfeatures: 1) automatic language detection and language-dependent information\nextraction for 40 languages, 2) entity and keyword visualization for efficient\nexploration, and 3) decentral deployment for analysis of confidential data from\nvarious formats. We illustrate the new analysis capabilities with an exemplary\ncase study.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jul 2018 15:51:31 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Wiedemann", "Gregor", ""], ["Yimam", "Seid Muhie", ""], ["Biemann", "Chris", ""]]}, {"id": "1807.05324", "submitter": "Heng Ding", "authors": "Heng Ding, Krisztian Balog", "title": "Generating Synthetic Data for Neural Keyword-to-Question Models", "comments": "Extended version of ICTIR'18 full paper, 11 pages", "journal-ref": null, "doi": "10.1145/3234944.3234964", "report-no": null, "categories": "cs.IR cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Search typically relies on keyword queries, but these are often semantically\nambiguous. We propose to overcome this by offering users natural language\nquestions, based on their keyword queries, to disambiguate their intent. This\nkeyword-to-question task may be addressed using neural machine translation\ntechniques. Neural translation models, however, require massive amounts of\ntraining data (keyword-question pairs), which is unavailable for this task. The\nmain idea of this paper is to generate large amounts of synthetic training data\nfrom a small seed set of hand-labeled keyword-question pairs. Since natural\nlanguage questions are available in large quantities, we develop models to\nautomatically generate the corresponding keyword queries. Further, we introduce\nvarious filtering mechanisms to ensure that synthetic training data is of high\nquality. We demonstrate the feasibility of our approach using both automatic\nand manual evaluation. This is an extended version of the article published\nwith the same title in the Proceedings of ICTIR'18.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 03:24:31 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Ding", "Heng", ""], ["Balog", "Krisztian", ""]]}, {"id": "1807.05351", "submitter": "Gustavo Publio", "authors": "Gustavo Correa Publio, Diego Esteves, Agnieszka {\\L}awrynowicz,\n  Pan\\v{c}e Panov, Larisa Soldatova, Tommaso Soru, Joaquin Vanschoren, Hamid\n  Zafar", "title": "ML-Schema: Exposing the Semantics of Machine Learning with Schemas and\n  Ontologies", "comments": "Poster, selected for the 2nd Reproducibility in Machine Learning\n  Workshop at ICML 2018, Stockholm, Sweden", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DB cs.IR stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The ML-Schema, proposed by the W3C Machine Learning Schema Community Group,\nis a top-level ontology that provides a set of classes, properties, and\nrestrictions for representing and interchanging information on machine learning\nalgorithms, datasets, and experiments. It can be easily extended and\nspecialized and it is also mapped to other more domain-specific ontologies\ndeveloped in the area of machine learning and data mining. In this paper we\noverview existing state-of-the-art machine learning interchange formats and\npresent the first release of ML-Schema, a canonical format resulted of more\nthan seven years of experience among different research institutions. We argue\nthat exposing semantics of machine learning algorithms, models, and experiments\nthrough a canonical format may pave the way to better interpretability and to\nrealistically achieve the full interoperability of experiments regardless of\nplatform or adopted workflow solution.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 08:07:31 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Publio", "Gustavo Correa", ""], ["Esteves", "Diego", ""], ["\u0141awrynowicz", "Agnieszka", ""], ["Panov", "Pan\u010de", ""], ["Soldatova", "Larisa", ""], ["Soru", "Tommaso", ""], ["Vanschoren", "Joaquin", ""], ["Zafar", "Hamid", ""]]}, {"id": "1807.05355", "submitter": "Sagar Uprety Mr.", "authors": "Sagar Uprety and Dawei Song", "title": "Investigating Order Effects in Multidimensional Relevance Judgment using\n  Query Logs", "comments": "Published at ACM ICTIR 2018", "journal-ref": null, "doi": "10.1145/3234944.3234972", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a growing body of research which has investigated relevance judgment\nin IR being influenced by multiple factors or dimensions. At the same time, the\nOrder Effects in sequential decision making have been quantitatively detected\nand studied in Mathematical Psychology. Combining the two phenomena, there have\nbeen some user studies carried out which investigate the Order Effects and thus\nincompatibility in different dimensions of relevance. In this work, we propose\na methodology for carrying out such an investigation in large scale and real\nworld data using query logs of a web search engine, and device a test to detect\nthe presence of an irrational user behavior in relevance judgment of documents.\nWe further validate this behavior through a Quantum Cognitive explanation of\nthe Order and Context effects.\n", "versions": [{"version": "v1", "created": "Sat, 14 Jul 2018 08:25:14 GMT"}, {"version": "v2", "created": "Wed, 13 Mar 2019 18:24:28 GMT"}], "update_date": "2019-03-15", "authors_parsed": [["Uprety", "Sagar", ""], ["Song", "Dawei", ""]]}, {"id": "1807.05540", "submitter": "Chaoran Huang", "authors": "Xianzhi Wang, Chaoran Huang, Lina Yao, Boualem Benatallah and Manqing\n  Dong", "title": "A Survey on Expert Recommendation in Community Question Answering", "comments": "29 pages, Journal of Computer Science and Technology, January 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Community question answering (CQA) represents the type of Web applications\nwhere people can exchange knowledge via asking and answering questions. One\nsignificant challenge of most real-world CQA systems is the lack of effective\nmatching between questions and the potential good answerers, which adversely\naffects the efficient knowledge acquisition and circulation. On the one hand, a\nrequester might experience many low-quality answers without receiving a quality\nresponse in a brief time, on the other hand, an answerer might face numerous\nnew questions without being able to identify their questions of interest\nquickly. Under this situation, expert recommendation emerges as a promising\ntechnique to address the above issues. Instead of passively waiting for users\nto browse and find their questions of interest, an expert recommendation method\nraises the attention of users to the appropriate questions actively and\npromptly. The past few years have witnessed considerable efforts that address\nthe expert recommendation problem from different perspectives. These methods\nall have their issues that need to be resolved before the advantages of expert\nrecommendation can be fully embraced. In this survey, we first present an\noverview of the research efforts and state-of-the-art techniques for the expert\nrecommendation in CQA. We next summarize and compare the existing methods\nconcerning their advantages and shortcomings, followed by discussing the open\nissues and future research directions.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 12:42:28 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Wang", "Xianzhi", ""], ["Huang", "Chaoran", ""], ["Yao", "Lina", ""], ["Benatallah", "Boualem", ""], ["Dong", "Manqing", ""]]}, {"id": "1807.05574", "submitter": "Vuong M. Ngo", "authors": "Vuong M. Ngo, Tru H. Cao and Tuan M. V. Le", "title": "WordNet-Based Information Retrieval Using Common Hypernyms and Combined\n  Features", "comments": "6pages, Will be in proceedings of the 5th International Conference on\n  Intelligent Computing and Information Systems (ICICIS-2011), in cooperation\n  with ACM. 30 June to 3 July, 2011, Cairo, Egypt", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Text search based on lexical matching of keywords is not satisfactory due to\npolysemous and synonymous words. Semantic search that exploits word meanings,\nin general, improves search performance. In this paper, we survey WordNet-based\ninformation retrieval systems, which employ a word sense disambiguation method\nto process queries and documents. The problem is that in many cases a word has\nmore than one possible direct sense, and picking only one of them may give a\nwrong sense for the word. Moreover, the previous systems use only word forms to\nrepresent word senses and their hypernyms. We propose a novel approach that\nuses the most specific common hypernym of the remaining undisambiguated\nmulti-senses of a word, as well as combined WordNet features to represent word\nmeanings. Experiments on a benchmark dataset show that, in terms of the MAP\nmeasure, our search engine is 17.7% better than the lexical search, and at\nleast 9.4% better than all surveyed search systems using WordNet.\n  Keywords Ontology, word sense disambiguation, semantic annotation, semantic\nsearch.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 16:49:06 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Ngo", "Vuong M.", ""], ["Cao", "Tru H.", ""], ["Le", "Tuan M. V.", ""]]}, {"id": "1807.05576", "submitter": "Vuong M. Ngo", "authors": "Tru H. Cao and Vuong M. Ngo", "title": "Semantic Search by Latent Ontological Features", "comments": "17 pages, Accept by New Generation Computing (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both named entities and keywords are important in defining the content of a\ntext in which they occur. In particular, people often use named entities in\ninformation search. However, named entities have ontological features, namely,\ntheir aliases, classes, and identifiers, which are hidden from their textual\nappearance. We propose ontology-based extensions of the traditional Vector\nSpace Model that explore different combinations of those latent ontological\nfeatures with keywords for text retrieval. Our experiments on benchmark\ndatasets show better search quality of the proposed models as compared to the\npurely keyword-based model, and their advantages for both text retrieval and\nrepresentation of documents and queries.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 17:08:45 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Cao", "Tru H.", ""], ["Ngo", "Vuong M.", ""]]}, {"id": "1807.05578", "submitter": "Vuong M. Ngo", "authors": "Vuong M. Ngo and Tru H. Cao", "title": "Discovering Latent Concepts and Exploiting Ontological Features for\n  Semantic Text Search", "comments": "9 pages - accpted by the 5th International Joint Conference on\n  Natural Language Processing (IJCNLP-2011). arXiv admin note: text overlap\n  with arXiv:1807.05574", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entities and WordNet words are important in defining the content of a\ntext in which they occur. Named entities have ontological features, namely,\ntheir aliases, classes, and identifiers. WordNet words also have ontological\nfeatures, namely, their synonyms, hypernyms, hyponyms, and senses. Those\nfeatures of concepts may be hidden from their textual appearance. Besides,\nthere are related concepts that do not appear in a query, but can bring out the\nmeaning of the query if they are added. The traditional constrained spreading\nactivation algorithms use all relations of a node in the network that will add\nunsuitable information into the query. Meanwhile, we only use relations\nrepresented in the query. We propose an ontology-based generalized Vector Space\nModel to semantic text search. It discovers relevant latent concepts in a query\nby relation constrained spreading activation. Besides, to represent a word\nhaving more than one possible direct sense, it combines the most specific\ncommon hypernym of the remaining undisambiguated multi-senses with the form of\nthe word. Experiments on a benchmark dataset in terms of the MAP measure for\nthe retrieval performance show that our model is 41.9% and 29.3% better than\nthe purely keyword-based model and the traditional constrained spreading\nactivation model, respectively.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 17:19:03 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Ngo", "Vuong M.", ""], ["Cao", "Tru H.", ""]]}, {"id": "1807.05579", "submitter": "Vuong M. Ngo", "authors": "Vuong M. Ngo and Tru H. Cao", "title": "Ontology-Based Query Expansion with Latently Related Named Entities for\n  Semantic Text Search", "comments": "12 pages - accepted by Advances in Intelligent Information and\n  Database Systems, Book of series SCI, Springer-Verlag (2010)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional information retrieval systems represent documents and queries by\nkeyword sets. However, the content of a document or a query is mainly defined\nby both keywords and named entities occurring in it. Named entities have\nontological features, namely, their aliases, classes, and identifiers, which\nare hidden from their textual appearance. Besides, the meaning of a query may\nimply latent named entities that are related to the apparent ones in the query.\nWe propose an ontology-based generalized vector space model to semantic text\nsearch. It exploits ontological features of named entities and their latently\nrelated ones to reveal the semantics of documents and queries. We also propose\na framework to combine different ontologies to take their complementary\nadvantages for semantic annotation and searching. Experiments on a benchmark\ndataset show better search quality of our model to other ones.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 17:20:54 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Ngo", "Vuong M.", ""], ["Cao", "Tru H.", ""]]}, {"id": "1807.05614", "submitter": "Martin Aum\\\"uller", "authors": "Martin Aum\\\"uller, Erik Bernhardsson, Alexander Faithfull", "title": "ANN-Benchmarks: A Benchmarking Tool for Approximate Nearest Neighbor\n  Algorithms", "comments": "Full version of the SISAP 2017 conference paper. v2: Updated the\n  abstract to avoid arXiv linking to the wrong URL", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper describes ANN-Benchmarks, a tool for evaluating the performance of\nin-memory approximate nearest neighbor algorithms. It provides a standard\ninterface for measuring the performance and quality achieved by nearest\nneighbor algorithms on different standard data sets. It supports several\ndifferent ways of integrating $k$-NN algorithms, and its configuration system\nautomatically tests a range of parameter settings for each algorithm.\nAlgorithms are compared with respect to many different (approximate) quality\nmeasures, and adding more is easy and fast; the included plotting front-ends\ncan visualise these as images, $\\LaTeX$ plots, and websites with interactive\nplots. ANN-Benchmarks aims to provide a constantly updated overview of the\ncurrent state of the art of $k$-NN algorithms. In the short term, this overview\nallows users to choose the correct $k$-NN algorithm and parameters for their\nsimilarity search task; in the longer term, algorithm designers will be able to\nuse this overview to test and refine automatic parameter tuning. The paper\ngives an overview of the system, evaluates the results of the benchmark, and\npoints out directions for future work. Interestingly, very different approaches\nto $k$-NN search yield comparable quality-performance trade-offs. The system is\navailable at http://ann-benchmarks.com .\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 21:25:55 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2018 20:45:47 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Aum\u00fcller", "Martin", ""], ["Bernhardsson", "Erik", ""], ["Faithfull", "Alexander", ""]]}, {"id": "1807.05631", "submitter": "Hamed Zamani", "authors": "Hamed Zamani and W. Bruce Croft", "title": "Joint Modeling and Optimization of Search and Recommendation", "comments": "In Proceedings of Design of Experimental Search & Information\n  REtrieval Systems (DESIRES 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the somewhat different techniques used in developing search engines\nand recommender systems, they both follow the same goal: helping people to get\nthe information they need at the right time. Due to this common goal, search\nand recommendation models can potentially benefit from each other. The recent\nadvances in neural network technologies make them effective and easily\nextendable for various tasks, including retrieval and recommendation. This\nraises the possibility of jointly modeling and optimizing search ranking and\nrecommendation algorithms, with potential benefits to both. In this paper, we\npresent theoretical and practical reasons to motivate joint modeling of search\nand recommendation as a research direction. We propose a general framework that\nsimultaneously learns a retrieval model and a recommendation model by\noptimizing a joint loss function. Our preliminary results on a dataset of\nproduct data indicate that the proposed joint modeling substantially\noutperforms the retrieval and recommendation models trained independently. We\nlist a number of future directions for this line of research that can\npotentially lead to development of state-of-the-art search and recommendation\nmodels.\n", "versions": [{"version": "v1", "created": "Sun, 15 Jul 2018 23:34:54 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Zamani", "Hamed", ""], ["Croft", "W. Bruce", ""]]}, {"id": "1807.05730", "submitter": "Yifan Chen", "authors": "Yifan Chen, Maarten de Rijke", "title": "A Collective Variational Autoencoder for Top-$N$ Recommendation with\n  Side Information", "comments": "7 pages, 3 figures, DLRS workshop 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems have been studied extensively due to their practical use\nin many real-world scenarios. Despite this, generating effective\nrecommendations with sparse user ratings remains a challenge. Side information\nassociated with items has been widely utilized to address rating sparsity.\nExisting recommendation models that use side information are linear and, hence,\nhave restricted expressiveness. Deep learning has been used to capture\nnon-linearities by learning deep item representations from side information but\nas side information is high-dimensional existing deep models tend to have large\ninput dimensionality, which dominates their overall size. This makes them\ndifficult to train, especially with small numbers of inputs.\n  Rather than learning item representations, which is problematic with\nhigh-dimensional side information, in this paper, we propose to learn feature\nrepresentation through deep learning from side information. Learning feature\nrepresentations, on the other hand, ensures a sufficient number of inputs to\ntrain a deep network. To achieve this, we propose to simultaneously recover\nuser ratings and side information, by using a Variational Autoencoder (VAE).\nSpecifically, user ratings and side information are encoded and decoded\ncollectively through the same inference network and generation network. This is\npossible as both user ratings and side information are data associated with\nitems. To account for the heterogeneity of user rating and side information,\nthe final layer of the generation network follows different distributions\ndepending on the type of information. The proposed model is easy to implement\nand efficient to optimize and is shown to outperform state-of-the-art top-$N$\nrecommendation methods that use side information.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 08:45:44 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Chen", "Yifan", ""], ["de Rijke", "Maarten", ""]]}, {"id": "1807.05739", "submitter": "Ruiming Tang", "authors": "Huifeng Guo, Ruiming Tang, Yunming Ye, Feng Liu, Yuzhou Zhang", "title": "An Adjustable Heat Conduction based KNN Approach for Session-based\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The KNN approach, which is widely used in recommender systems because of its\nefficiency, robustness and interpretability, is proposed for session-based\nrecommendation recently and outperforms recurrent neural network models. It\ncaptures the most recent co-occurrence information of items by considering the\ninteraction time. However, it neglects the co-occurrence information of items\nin the historical behavior which is interacted earlier and cannot discriminate\nthe impact of items and sessions with different popularity. Due to these\nobservations, this paper presents a new contextual KNN approach to address\nthese issues for session-based recommendation. Specifically, a diffusion-based\nsimilarity method is proposed for considering the popularity of vertices in\nsession-item bipartite network, and a candidate selection method is proposed to\ncapture the items that are co-occurred with different historical clicked items\nin the same session efficiently. Comprehensive experiments are conducted to\ndemonstrate the effectiveness of our KNN approach over the state-of-the-art KNN\napproach for session-based recommendation on three benchmark datasets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 09:05:36 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Guo", "Huifeng", ""], ["Tang", "Ruiming", ""], ["Ye", "Yunming", ""], ["Liu", "Feng", ""], ["Zhang", "Yuzhou", ""]]}, {"id": "1807.05798", "submitter": "Jimmy Lin", "authors": "Jimmy Lin and Peilin Yang", "title": "Repeatability Corner Cases in Document Ranking: The Impact of Score Ties", "comments": "Published in the Proceedings of the 42nd Annual International ACM\n  SIGIR Conference on Research and Development in Information Retrieval (SIGIR\n  2019)", "journal-ref": null, "doi": "10.1145/3331184.3331339", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Document ranking experiments should be repeatable. However, the interaction\nbetween multi-threaded indexing and score ties during retrieval may yield\nnon-deterministic rankings, making repeatability not as trivial as one might\nimagine. In the context of the open-source Lucene search engine, score ties are\nbroken by internal document ids, which are assigned at index time. Due to\nmulti-threaded indexing, which makes experimentation with large modern document\ncollections practical, internal document ids are not assigned consistently\nbetween different index instances of the same collection, and thus score ties\nare broken unpredictably. This short paper examines the effectiveness impact of\nsuch score ties, quantifying the variability that can be attributed to this\nphenomenon. The obvious solution to this non-determinism and to ensure\nrepeatable document ranking is to break score ties using external collection\ndocument ids. This approach, however, comes with measurable efficiency costs\ndue to the necessity of consulting external identifiers during query\nevaluation.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 11:32:52 GMT"}, {"version": "v2", "created": "Mon, 2 Sep 2019 20:16:41 GMT"}], "update_date": "2019-09-04", "authors_parsed": [["Lin", "Jimmy", ""], ["Yang", "Peilin", ""]]}, {"id": "1807.05853", "submitter": "Mohamed Reda Bouadjenek", "authors": "Mohamed Reda Bouadjenek, Esther Pacitti, Maximilien Servajean, Florent\n  Masseglia, Amr El Abbadi", "title": "A Distributed Collaborative Filtering Algorithm Using Multiple Data\n  Sources", "comments": "The Tenth International Conference on Advances in Databases,\n  Knowledge, and Data Applications, DBKDA 2018 May 20, 2018 to May 24, 2018 -\n  Nice, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative Filtering (CF) is one of the most commonly used recommendation\nmethods. CF consists in predicting whether, or how much, a user will like (or\ndislike) an item by leveraging the knowledge of the user's preferences as well\nas that of other users. In practice, users interact and express their opinion\non only a small subset of items, which makes the corresponding user-item rating\nmatrix very sparse. Such data sparsity yields two main problems for recommender\nsystems: (1) the lack of data to effectively model users' preferences, and (2)\nthe lack of data to effectively model item characteristics. However, there are\noften many other data sources that are available to a recommender system\nprovider, which can describe user interests and item characteristics (e.g.,\nusers' social network, tags associated to items, etc.). These valuable data\nsources may supply useful information to enhance a recommendation system in\nmodeling users' preferences and item characteristics more accurately and thus,\nhopefully, to make recommenders more precise. For various reasons, these data\nsources may be managed by clusters of different data centers, thus requiring\nthe development of distributed solutions. In this paper, we propose a new\ndistributed collaborative filtering algorithm, which exploits and combines\nmultiple and diverse data sources to improve recommendation quality. Our\nexperimental evaluation using real datasets shows the effectiveness of our\nalgorithm compared to state-of-the-art recommendation algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 13:35:58 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Bouadjenek", "Mohamed Reda", ""], ["Pacitti", "Esther", ""], ["Servajean", "Maximilien", ""], ["Masseglia", "Florent", ""], ["Abbadi", "Amr El", ""]]}, {"id": "1807.05858", "submitter": "Andreu Vall", "authors": "Andreu Vall, Gerhard Widmer", "title": "Machine Learning Approaches to Hybrid Music Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Music recommender systems have become a key technology supporting the access\nto increasingly larger music catalogs in on-line music streaming services,\non-line music shops, and private collections. The interaction of users with\nlarge music catalogs is a complex phenomenon researched from different\ndisciplines. We survey our works investigating the machine learning and data\nmining aspects of hybrid music recommender systems (i.e., systems that\nintegrate different recommendation techniques). We proposed hybrid music\nrecommender systems based solely on data and robust to the so-called\n\"cold-start problem\" for new music items, favoring the discovery of relevant\nbut non-popular music. We thoroughly studied the specific task of music\nplaylist continuation, by analyzing fundamental playlist characteristics, song\nfeature representations, and the relationship between playlists and the songs\ntherein.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 13:44:35 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Vall", "Andreu", ""], ["Widmer", "Gerhard", ""]]}, {"id": "1807.05906", "submitter": "Nalin Chhibber", "authors": "Nalin Chhibber, Rohail Syed, Mengqiu Teng, Joslin Goh, Kevyn\n  Collins-Thompson, Edith Law", "title": "Human Perception of Surprise: A User Study", "comments": "4 pages. Presented at Computational Surprise Workshop, SIGIR 2018\n  (Michigan)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding how to engage users is a critical question in many\napplications. Previous research has shown that unexpected or astonishing events\ncan attract user attention, leading to positive outcomes such as engagement and\nlearning. In this work, we investigate the similarity and differences in how\npeople and algorithms rank the surprisingness of facts. Our crowdsourcing\nstudy, involving 106 participants, shows that computational models of surprise\ncan be used to artificially induce surprise in humans.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 15:02:38 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Chhibber", "Nalin", ""], ["Syed", "Rohail", ""], ["Teng", "Mengqiu", ""], ["Goh", "Joslin", ""], ["Collins-Thompson", "Kevyn", ""], ["Law", "Edith", ""]]}, {"id": "1807.06036", "submitter": "Michael Conover", "authors": "Michael Conover, Matthew Hayes, Scott Blackburn, Pete Skomoroch, Sam\n  Shah", "title": "Pangloss: Fast Entity Linking in Noisy Text Environments", "comments": "KDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Entity linking is the task of mapping potentially ambiguous terms in text to\ntheir constituent entities in a knowledge base like Wikipedia. This is useful\nfor organizing content, extracting structured data from textual documents, and\nin machine learning relevance applications like semantic search, knowledge\ngraph construction, and question answering. Traditionally, this work has\nfocused on text that has been well-formed, like news articles, but in common\nreal world datasets such as messaging, resumes, or short-form social media,\nnon-grammatical, loosely-structured text adds a new dimension to this problem.\n  This paper presents Pangloss, a production system for entity disambiguation\non noisy text. Pangloss combines a probabilistic linear-time key phrase\nidentification algorithm with a semantic similarity engine based on\ncontext-dependent document embeddings to achieve better than state-of-the-art\nresults (>5% in F1) compared to other research or commercially available\nsystems. In addition, Pangloss leverages a local embedded database with a\ntiered architecture to house its statistics and metadata, which allows rapid\ndisambiguation in streaming contexts and on-device disambiguation in low-memory\nenvironments such as mobile phones.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 18:04:08 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Conover", "Michael", ""], ["Hayes", "Matthew", ""], ["Blackburn", "Scott", ""], ["Skomoroch", "Pete", ""], ["Shah", "Sam", ""]]}, {"id": "1807.06060", "submitter": "Atom Sonoda", "authors": "Atom Sonoda, Fujio Toriumi, Hiroto Nakajima, Miyabi Gouji", "title": "Analysis and Modeling of Behavioral Changes in a News Service", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information is transmitted through websites, and immediate reactions to\nvarious kinds of information are required. Hence, efforts by users to select\ninformation themselves have increased, which is fueling further improvements in\nrecommendation services that can reduce such burdens. On the other hand, filter\nbubbles that only provide biased information to users are generated due to\nredundant recommendations. In this research, we analyzed behavioral changes\nprior to recommendation by clustering, and we found that user attributes and\ncluster contents are different among users with different behavioral changes.\nThe proportion of users under forty and women was relatively large in the\ndiversity-increasing group. We also proposed an article selection model to\nclarify the influence of recommendation systems on behavioral changes. We\ncompared our proposed model with the target data, verified it, and evaluated\nthe effect of recommendation systems on user behavior. Our simulation results\nshowed that diversity usually decreases, but collaborative filtering can\nsuppress the diversity decrease more effectively than non-recommendations. We\nalso found that the category that users are interested in the most is easily\nstrengthened and is one factor that leads to less diversity, and a\nrecommendation method that can suppress the strengthening of the category that\nusers are interested in the most will be effective for developing a\nrecommendation system that can suppress diversity decreasing.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 18:54:59 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Sonoda", "Atom", ""], ["Toriumi", "Fujio", ""], ["Nakajima", "Hiroto", ""], ["Gouji", "Miyabi", ""]]}, {"id": "1807.06160", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj", "title": "Layer-wise Relevance Propagation for Explainable Recommendations", "comments": "Accepted in Proceedings of the EARS Workshop at SIGIR 2018", "journal-ref": "Homanga Bharadhwaj. 2018. Layer-wise Relevance Propagation for\n  Explainable Recommendations. In Proceedings of SIGIR 2018 Workshop on\n  ExplainAble Recommendation and Search (EARS'18). ACM, New York, NY, USA", "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.IR cs.MM stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we tackle the problem of explanations in a deep-learning based\nmodel for recommendations by leveraging the technique of layer-wise relevance\npropagation. We use a Deep Convolutional Neural Network to extract relevant\nfeatures from the input images before identifying similarity between the images\nin feature space. Relationships between the images are identified by the model\nand layer-wise relevance propagation is used to infer pixel-level details of\nthe images that may have significantly informed the model's choice. We evaluate\nour method on an Amazon products dataset and demonstrate the efficacy of our\napproach.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 00:38:31 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Bharadhwaj", "Homanga", ""]]}, {"id": "1807.06161", "submitter": "Homanga Bharadhwaj", "authors": "Homanga Bharadhwaj, Shruti Joshi", "title": "Explanations for Temporal Recommendations", "comments": "Accepted at the XAI Workshop in IJCAI/ECAI 2018", "journal-ref": "Homanga Bharadhwaj and Shruti Joshi. \"Explanations for Temporal\n  Recommendations\" IJCAI-18 Workshop on Explainable AI (XAI). 2018", "doi": null, "report-no": null, "categories": "cs.AI cs.HC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommendation systems are an integral part of Artificial Intelligence (AI)\nand have become increasingly important in the growing age of commercialization\nin AI. Deep learning (DL) techniques for recommendation systems (RS) provide\npowerful latent-feature models for effective recommendation but suffer from the\nmajor drawback of being non-interpretable. In this paper we describe a\nframework for explainable temporal recommendations in a DL model. We consider\nan LSTM based Recurrent Neural Network (RNN) architecture for recommendation\nand a neighbourhood-based scheme for generating explanations in the model. We\ndemonstrate the effectiveness of our approach through experiments on the\nNetflix dataset by jointly optimizing for both prediction accuracy and\nexplainability.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 00:38:40 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Bharadhwaj", "Homanga", ""], ["Joshi", "Shruti", ""]]}, {"id": "1807.06300", "submitter": "Vito Bellini", "authors": "Vito Bellini, Angelo Schiavone, Tommaso Di Noia, Azzurra Ragone,\n  Eugenio Di Sciascio", "title": "Knowledge-aware Autoencoders for Explainable Recommender Sytems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender Systems have been widely used to help users in finding what they\nare looking for thus tackling the information overload problem. After several\nyears of research and industrial findings looking after better algorithms to\nimprove accuracy and diversity metrics, explanation services for recommendation\nare gaining momentum as a tool to provide a human-understandable feedback to\nresults computed, in most of the cases, by black-box machine learning\ntechniques. As a matter of fact, explanations may guarantee users satisfaction,\ntrust, and loyalty in a system. In this paper, we evaluate how different\ninformation encoded in a Knowledge Graph are perceived by users when they are\nadopted to show them an explanation. More precisely, we compare how the use of\ncategorical information, factual one or a mixture of them both in building\nexplanations, affect explanatory criteria for a recommender system.\nExperimental results are validated through an A/B testing platform which uses a\nrecommendation engine based on a Semantics-Aware Autoencoder to build users\nprofiles which are in turn exploited to compute recommendation lists and to\nprovide an explanation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 09:40:21 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Bellini", "Vito", ""], ["Schiavone", "Angelo", ""], ["Di Noia", "Tommaso", ""], ["Ragone", "Azzurra", ""], ["Di Sciascio", "Eugenio", ""]]}, {"id": "1807.06349", "submitter": "Jurek Leonhardt", "authors": "Jurek Leonhardt, Avishek Anand, Megha Khosla", "title": "User Fairness in Recommender Systems", "comments": null, "journal-ref": null, "doi": "10.1145/3184558.3186949", "report-no": null, "categories": "cs.CY cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recent works in recommendation systems have focused on diversity in\nrecommendations as an important aspect of recommendation quality. In this work\nwe argue that the post-processing algorithms aimed at only improving diversity\namong recommendations lead to discrimination among the users. We introduce the\nnotion of user fairness which has been overlooked in literature so far and\npropose measures to quantify it. Our experiments on two diversification\nalgorithms show that an increase in aggregate diversity results in increased\ndisparity among the users.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 11:19:42 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Leonhardt", "Jurek", ""], ["Anand", "Avishek", ""], ["Khosla", "Megha", ""]]}, {"id": "1807.06373", "submitter": "Sofiane Abbar", "authors": "Sofiane Abbar, Carlos Castillo, Antonio Sanfilippo", "title": "To Post or Not to Post: Using Online Trends to Predict Popularity of\n  Offline Content", "comments": null, "journal-ref": "Sofiane Abbar, Carlos Castillo, and Antonio Sanfilippo. 2018. To\n  Post or Not to Post: Using Online Trends to Predict Popularity of Offline\n  Content. In Proceedings of the 29th on Hypertext and Social Media (HT '18)", "doi": "10.1145/3209542.3209575", "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Predicting the popularity of online content has attracted much attention in\nthe past few years. In news rooms, for instance, journalists and editors are\nkeen to know, as soon as possible, the articles that will bring the most\ntraffic into their website. The relevant literature includes a number of\napproaches and algorithms to perform this forecasting. Most of the proposed\nmethods require monitoring the popularity of content during some time after it\nis posted, before making any longer-term prediction. In this paper, we propose\na new approach for predicting the popularity of news articles before they go\nonline. Our approach complements existing content-based methods, and is based\non a number of observations regarding article similarity and topicality. First,\nthe popularity of a new article is correlated with the popularity of similar\narticles of recent publication. Second, the popularity of the new article is\nrelated to the recent historical popularity of its main topic. Based on these\nobservations, we use time series forecasting to predict the number of visits an\narticle will receive. Our experiments, conducted on a real data collection of\narticles in an international news website, demonstrate the effectiveness and\nefficiency of the proposed method.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 12:09:36 GMT"}], "update_date": "2018-07-18", "authors_parsed": [["Abbar", "Sofiane", ""], ["Castillo", "Carlos", ""], ["Sanfilippo", "Antonio", ""]]}, {"id": "1807.06414", "submitter": "Mehdi Ben Lazreg", "authors": "Mehdi Ben Lazreg, Morten Goodwin", "title": "Combining a Context Aware Neural Network with a Denoising Autoencoder\n  for Measuring String Similarities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Measuring similarities between strings is central for many established and\nfast growing research areas including information retrieval, biology, and\nnatural language processing. The traditional approach for string similarity\nmeasurements is to define a metric over a word space that quantifies and sums\nup the differences between characters in two strings. The state-of-the-art in\nthe area has, surprisingly, not evolved much during the last few decades. The\nmajority of the metrics are based on a simple comparison between character and\ncharacter distributions without consideration for the context of the words.\nThis paper proposes a string metric that encompasses similarities between\nstrings based on (1) the character similarities between the words including.\nNon-Standard and standard spellings of the same words, and (2) the context of\nthe words. Our proposal is a neural network composed of a denoising autoencoder\nand what we call a context encoder specifically designed to find similarities\nbetween the words based on their context. The experimental results show that\nthe resulting metrics succeeds in 85.4\\% of the cases in finding the correct\nversion of a non-standard spelling among the closest words, compared to 63.2\\%\nwith the established Normalised-Levenshtein distance. Besides, we show that\nwords used in similar context are with our approach calculated to be similar\nthan words with different contexts, which is a desirable property missing in\nestablished string metrics.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2018 12:29:23 GMT"}], "update_date": "2018-08-20", "authors_parsed": [["Lazreg", "Mehdi Ben", ""], ["Goodwin", "Morten", ""]]}, {"id": "1807.06638", "submitter": "Chengsheng Mao", "authors": "Himanshu Sharma, Chengsheng Mao, Yizhen Zhang, Haleh Vatani, Liang\n  Yao, Yizhen Zhong, Luke Rasmussen, Guoqian Jiang, Jyotishman Pathak and Yuan\n  Luo", "title": "Developing a Portable Natural Language Processing Based Phenotyping\n  System", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a portable phenotyping system that is capable of\nintegrating both rule-based and statistical machine learning based approaches.\nOur system utilizes UMLS to extract clinically relevant features from the\nunstructured text and then facilitates portability across different\ninstitutions and data systems by incorporating OHDSI's OMOP Common Data Model\n(CDM) to standardize necessary data elements. Our system can also store the key\ncomponents of rule-based systems (e.g., regular expression matches) in the\nformat of OMOP CDM, thus enabling the reuse, adaptation and extension of many\nexisting rule-based clinical NLP systems. We experimented with our system on\nthe corpus from i2b2's Obesity Challenge as a pilot study. Our system\nfacilitates portable phenotyping of obesity and its 15 comorbidities based on\nthe unstructured patient discharge summaries, while achieving a performance\nthat often ranked among the top 10 of the challenge participants. This\nstandardization enables a consistent application of numerous rule-based and\nmachine learning based classification techniques downstream.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 19:40:28 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Sharma", "Himanshu", ""], ["Mao", "Chengsheng", ""], ["Zhang", "Yizhen", ""], ["Vatani", "Haleh", ""], ["Yao", "Liang", ""], ["Zhong", "Yizhen", ""], ["Rasmussen", "Luke", ""], ["Jiang", "Guoqian", ""], ["Pathak", "Jyotishman", ""], ["Luo", "Yuan", ""]]}, {"id": "1807.06651", "submitter": "Giannis Karamanolakis", "authors": "Giannis Karamanolakis, Kevin Raji Cherian, Ananth Ravi Narayan, Jie\n  Yuan, Da Tang, Tony Jebara", "title": "Item Recommendation with Variational Autoencoders and Heterogenous\n  Priors", "comments": "Accepted for the 3rd Workshop on Deep Learning for Recommender\n  Systems (DLRS 2018), held in conjunction with the 12th ACM Conference on\n  Recommender Systems (RecSys 2018) in Vancouver, Canada", "journal-ref": null, "doi": "10.1145/3270323.327032", "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Variational Autoencoders (VAEs) have been shown to be highly\neffective in both standard collaborative filtering applications and extensions\nsuch as incorporation of implicit feedback. We extend VAEs to collaborative\nfiltering with side information, for instance when ratings are combined with\nexplicit text feedback from the user. Instead of using a user-agnostic standard\nGaussian prior, we incorporate user-dependent priors in the latent VAE space to\nencode users' preferences as functions of the review text. Taking into account\nboth the rating and the text information to represent users in this multimodal\nlatent space is promising to improve recommendation quality. Our proposed model\nis shown to outperform the existing VAE models for collaborative filtering (up\nto 29.41% relative improvement in ranking metric) along with other baselines\nthat incorporate both user ratings and text for item recommendation.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2018 20:14:02 GMT"}, {"version": "v2", "created": "Sun, 7 Oct 2018 03:54:31 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Karamanolakis", "Giannis", ""], ["Cherian", "Kevin Raji", ""], ["Narayan", "Ananth Ravi", ""], ["Yuan", "Jie", ""], ["Tang", "Da", ""], ["Jebara", "Tony", ""]]}, {"id": "1807.06786", "submitter": "Jongpil Lee", "authors": "Jongpil Lee, Kyungyun Lee, Jiyoung Park, Jangyeon Park, Juhan Nam", "title": "Deep Content-User Embedding Model for Music Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently deep learning based recommendation systems have been actively\nexplored to solve the cold-start problem using a hybrid approach. However, the\nmajority of previous studies proposed a hybrid model where collaborative\nfiltering and content-based filtering modules are independently trained. The\nend-to-end approach that takes different modality data as input and jointly\ntrains the model can provide better optimization but it has not been fully\nexplored yet. In this work, we propose deep content-user embedding model, a\nsimple and intuitive architecture that combines the user-item interaction and\nmusic audio content. We evaluate the model on music recommendation and music\nauto-tagging tasks. The results show that the proposed model significantly\noutperforms the previous work. We also discuss various directions to improve\nthe proposed model further.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 06:13:15 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Lee", "Jongpil", ""], ["Lee", "Kyungyun", ""], ["Park", "Jiyoung", ""], ["Park", "Jangyeon", ""], ["Nam", "Juhan", ""]]}, {"id": "1807.06839", "submitter": "Tomislav Duricic", "authors": "Tomislav Duricic, Emanuel Lacic, Dominik Kowald, Elisabeth Lex", "title": "Trust-Based Collaborative Filtering: Tackling the Cold Start Problem\n  Using Regular Equivalence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  User-based Collaborative Filtering (CF) is one of the most popular approaches\nto create recommender systems. This approach is based on finding the most\nrelevant k users from whose rating history we can extract items to recommend.\nCF, however, suffers from data sparsity and the cold-start problem since users\noften rate only a small fraction of available items. One solution is to\nincorporate additional information into the recommendation process such as\nexplicit trust scores that are assigned by users to others or implicit trust\nrelationships that result from social connections between users. Such\nrelationships typically form a very sparse trust network, which can be utilized\nto generate recommendations for users based on people they trust. In our work,\nwe explore the use of a measure from network science, i.e. regular equivalence,\napplied to a trust network to generate a similarity matrix that is used to\nselect the k-nearest neighbors for recommending items. We evaluate our approach\non Epinions and we find that we can outperform related methods for tackling\ncold-start users in terms of recommendation accuracy.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 10:05:44 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Duricic", "Tomislav", ""], ["Lacic", "Emanuel", ""], ["Kowald", "Dominik", ""], ["Lex", "Elisabeth", ""]]}, {"id": "1807.06918", "submitter": "Joeran Beel", "authors": "Joeran Beel and Barry Smyth and Andrew Collins", "title": "RARD II: The 94 Million Related-Article Recommendation Dataset", "comments": null, "journal-ref": "1st Workshop on Algorithm Selection and Meta-Learning in\n  Information Retrieval (AMIR). 2019", "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main contribution of this paper is to introduce and describe a new\nrecommender-systems dataset (RARD II). It is based on data from Mr. DLib, a\nrecommender-system as-a-service in the digital library and\nreference-management-software domain. As such, RARD II complements datasets\nfrom other domains such as books, movies, and music. The dataset encompasses\n94m recommendations, delivered in the two years from September 2016 to\nSeptember 2018. The dataset covers an item-space of 24m unique items. RARD II\nprovides a range of rich recommendation data, beyond conventional ratings. For\nexample, in addition to the usual (implicit) ratings matrices, RARD II includes\nthe original recommendation logs, which provide a unique insight into many\naspects of the algorithms that generated the recommendations. The logs enable\nresearchers to conduct various analyses about a real-world recommender system.\nThis includes the evaluation of meta-learning approaches for predicting\nalgorithm performance. In this paper, we summarise the key features of this\ndataset release, describe how it was generated and discuss some of its unique\nfeatures. Compared to its predecessor RARD, RARD II contains 64% more\nrecommendations, 187% more features (algorithms, parameters, and statistics),\n50% more clicks, 140% more documents, and one additional service partner\n(JabRef).\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 13:27:33 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2018 08:46:06 GMT"}, {"version": "v3", "created": "Wed, 21 Aug 2019 10:47:36 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Beel", "Joeran", ""], ["Smyth", "Barry", ""], ["Collins", "Andrew", ""]]}, {"id": "1807.06928", "submitter": "Kenta Iida", "authors": "Kenta Iida, Hitoshi Kiya", "title": "Robust Image Identification for Double-Compressed JPEG Images", "comments": "This paper was presented at International Conference on\n  Communications 2018", "journal-ref": null, "doi": "10.1587/transinf.2018MUP0007", "report-no": null, "categories": "eess.IV cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is known that JPEG images uploaded to social networks (SNs) are mostly\nre-compressed by the social network providers. Because of such a situation, a\nnew image identification scheme for double-compressed JPEG images is proposed\nin this paper. The aim is to detect single-compressed images that have the same\noriginal image as that of a double-compressed one. In the proposed scheme, the\nsigns of only DC coefficients in DCT coefficients and one threshold value are\nused for the identification. The use of them allows us to robustly avoid errors\ncaused by double-compression, which are not considered in conventional schemes.\nThe proposed scheme has applications not only to find uploaded images\ncorresponding to double-compressed ones, but also to detect some image\nintegrity. The simulation results demonstrate that the proposed one outperforms\nconventional ones including state-of-art image hashing one in terms of the\nquerying performance.\n", "versions": [{"version": "v1", "created": "Sat, 23 Jun 2018 09:50:42 GMT"}], "update_date": "2019-01-30", "authors_parsed": [["Iida", "Kenta", ""], ["Kiya", "Hitoshi", ""]]}, {"id": "1807.06978", "submitter": "Sixun Ouyang", "authors": "Sixun Ouyang and Aonghus Lawlor and Felipe Costa and Peter Dolog", "title": "Improving Explainable Recommendations with Synthetic Reviews", "comments": "Recsys DLRS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An important task for a recommender system to provide interpretable\nexplanations for the user. This is important for the credibility of the system.\nCurrent interpretable recommender systems tend to focus on certain features\nknown to be important to the user and offer their explanations in a structured\nform. It is well known that user generated reviews and feedback from reviewers\nhave strong leverage over the users' decisions. On the other hand, recent text\ngeneration works have been shown to generate text of similar quality to human\nwritten text, and we aim to show that generated text can be successfully used\nto explain recommendations.\n  In this paper, we propose a framework consisting of popular review-oriented\ngeneration models aiming to create personalised explanations for\nrecommendations. The interpretations are generated at both character and word\nlevels. We build a dataset containing reviewers' feedback from the Amazon books\nreview dataset. Our cross-domain experiments are designed to bridge from\nnatural language processing to the recommender system domain. Besides language\nmodel evaluation methods, we employ DeepCoNN, a novel review-oriented\nrecommender system using a deep neural network, to evaluate the recommendation\nperformance of generated reviews by root mean square error (RMSE). We\ndemonstrate that the synthetic personalised reviews have better recommendation\nperformance than human written reviews. To our knowledge, this presents the\nfirst machine-generated natural language explanations for rating prediction.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 14:42:35 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Ouyang", "Sixun", ""], ["Lawlor", "Aonghus", ""], ["Costa", "Felipe", ""], ["Dolog", "Peter", ""]]}, {"id": "1807.07298", "submitter": "Joeran Beel", "authors": "Joeran Beel and Andrew Collins and Oliver Kopp and Linus W. Dietz and\n  Petr Knoth", "title": "Online Evaluations for Everyone: Mr. DLib's Living Lab for Scholarly\n  Recommendations", "comments": "Published at the 41st European Conference on Information Retrieval\n  (ECIR) 2019", "journal-ref": null, "doi": "10.1007/978-3-030-15719-7_27", "report-no": null, "categories": "cs.IR cs.DL cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the first 'living lab' for scholarly recommender systems. This\nlab allows recommender-system researchers to conduct online evaluations of\ntheir novel algorithms for scholarly recommendations, i.e., recommendations for\nresearch papers, citations, conferences, research grants, etc. Recommendations\nare delivered through the living lab's API to platforms such as reference\nmanagement software and digital libraries. The living lab is built on top of\nthe recommender-system as-a-service Mr. DLib. Current partners are the\nreference management software JabRef and the CORE research team. We present the\narchitecture of Mr. DLib's living lab as well as usage statistics on the first\nsixteen months of operating it. During this time, 1,826,643 recommendations\nwere delivered with an average click-through rate of 0.21%.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 08:55:09 GMT"}, {"version": "v2", "created": "Wed, 22 May 2019 08:42:02 GMT"}], "update_date": "2019-05-23", "authors_parsed": [["Beel", "Joeran", ""], ["Collins", "Andrew", ""], ["Kopp", "Oliver", ""], ["Dietz", "Linus W.", ""], ["Knoth", "Petr", ""]]}, {"id": "1807.07346", "submitter": "Esteban Garc\\'ia-Cuesta Dr.", "authors": "Esteban Garc\\'ia-Cuesta (Data Science Laboratory, School of\n  Arquitecture, Engineering and Design, Universidad Europea de Madrid, Spain),\n  Jos\\'e M. G\\'omez-P\\'erez (Expert System, Spain)", "title": "Indexing Execution Patterns in Workflow Provenance Graphs through\n  Generalized Trie Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last years, scientific workflows have become mature enough to be\nused in a production style. However, despite the increasing maturity, there is\nstill a shortage of tools for searching, adapting, and reusing workflows that\nhinders a more generalized adoption by the scientific communities. Indeed, due\nto the limited availability of machine-readable scientific metadata and the\nheterogeneity of workflow specification formats and representations, new ways\nto leverage alternative sources of information that complement existing\napproaches are needed. In this paper we address such limitations by applying\nstatistically enriched generalized trie structures to exploit workflow\nexecution provenance information in order to assist the analysis, indexing and\nsearch of scientific workflows. Our method bridges the gap between the\ndescription of what a workflow is supposed to do according to its specification\nand related metadata and what it actually does as recorded in its provenance\nexecution trace. In doing so, we also prove that the proposed method\noutperforms SPARQL 1.1 Property Paths for querying provenance graphs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2018 11:29:40 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Garc\u00eda-Cuesta", "Esteban", "", "Data Science Laboratory, School of\n  Arquitecture, Engineering and Design, Universidad Europea de Madrid, Spain"], ["G\u00f3mez-P\u00e9rez", "Jos\u00e9 M.", "", "Expert System, Spain"]]}, {"id": "1807.07468", "submitter": "Kaveh Bastani", "authors": "Kaveh Bastani, Hamed Namavari, Jeffry Shaffer", "title": "Latent Dirichlet Allocation (LDA) for Topic Modeling of the CFPB\n  Consumer Complaints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A text mining approach is proposed based on latent Dirichlet allocation (LDA)\nto analyze the Consumer Financial Protection Bureau (CFPB) consumer complaints.\nThe proposed approach aims to extract latent topics in the CFPB complaint\nnarratives, and explores their associated trends over time. The time trends\nwill then be used to evaluate the effectiveness of the CFPB regulations and\nexpectations on financial institutions in creating a consumer oriented culture\nthat treats consumers fairly and prioritizes consumer protection in their\ndecision making processes. The proposed approach can be easily operationalized\nas a decision support system to automate detection of emerging topics in\nconsumer complaints. Hence, the technology-human partnership between the\nproposed approach and the CFPB team could certainly improve consumer\nprotections from unfair, deceptive or abusive practices in the financial\nmarkets by providing more efficient and effective investigations of consumer\ncomplaint narratives.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2018 17:26:57 GMT"}], "update_date": "2018-07-20", "authors_parsed": [["Bastani", "Kaveh", ""], ["Namavari", "Hamed", ""], ["Shaffer", "Jeffry", ""]]}, {"id": "1807.07777", "submitter": "Vuong M. Ngo", "authors": "Tru H. Cao, Vuong M. Ngo, Dung T. Hong, and Tho T. Quan", "title": "Semantic Document Clustering on Named Entity Features", "comments": "7 papes, PAKDD workshops", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Keyword-based information processing has limitations due to simple treatment\nof words. In this paper, we introduce named entities as objectives into\ndocument clustering, which are the key elements defining document semantics and\nin many cases are of user concerns. First, the traditional keyword-based vector\nspace model is adapted with vectors defined over spaces of entity names, types,\nname-type pairs, and identifiers, instead of keywords. Then, hierarchical\ndocument clustering can be performed using the similarity measure defined as\nthe cosines of the vectors representing documents. Experimental results are\npresented and discussed. Clustering documents by information of named entities\ncould be useful for managing web-based learning materials with respect to\nrelated objects.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 10:24:09 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Cao", "Tru H.", ""], ["Ngo", "Vuong M.", ""], ["Hong", "Dung T.", ""], ["Quan", "Tho T.", ""]]}, {"id": "1807.07779", "submitter": "Vuong M. Ngo", "authors": "Vuong M. Ngo and Tru H. Cao", "title": "A Generalized Vector Space Model for Ontology-Based Information\n  Retrieval", "comments": "5 pages, in Vietnamese. information retrieval, vector space model,\n  ontology, named entity, keyword. Accepted by Vietnamese Journal on\n  Information Technologies and Communications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entities (NE) are objects that are referred to by names such as people,\norganizations and locations. Named entities and keywords are important to the\nmeaning of a document. We propose a generalized vector space model that\ncombines named entities and keywords. In the model, we take into account\ndifferent ontological features of named entities, namely, aliases, classes and\nidentifiers. Moreover, we use entity classes to represent the latent\ninformation of interrogative words in Wh-queries, which are ignored in\ntraditional keyword-based searching. We have implemented and tested the\nproposed model on a TREC dataset, as presented and discussed in the paper.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 10:37:31 GMT"}], "update_date": "2018-07-23", "authors_parsed": [["Ngo", "Vuong M.", ""], ["Cao", "Tru H.", ""]]}, {"id": "1807.07966", "submitter": "Vuong M. Ngo", "authors": "Tru H. Cao, Khanh C. Le and Vuong M. Ngo", "title": "Exploring Combinations of Ontological Features and Keywords for Text\n  Retrieval", "comments": "10 pages, will be in PRICAI. arXiv admin note: substantial text\n  overlap with arXiv:1807.05576", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Named entities have been considered and combined with keywords to enhance\ninformation retrieval performance. However, there is not yet a formal and\ncomplete model that takes into account entity names, classes, and identifiers\ntogether. Our work explores various adaptations of the traditional Vector Space\nModel that combine different ontological features with keywords, and in\ndifferent ways. It shows better performance of the proposed models as compared\nto the keyword-based Lucene, and their advantages for both text retrieval and\nrepresentation of documents and queries.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 10:30:26 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Cao", "Tru H.", ""], ["Le", "Khanh C.", ""], ["Ngo", "Vuong M.", ""]]}, {"id": "1807.07967", "submitter": "Vuong M. Ngo", "authors": "Vuong M. Ngo, Tru H. Cao and Tuan M.V. Le", "title": "Combining Named Entities with WordNet and Using Query-Oriented Spreading\n  Activation for Semantic Text Search", "comments": "6 papes, Accepted by RIVF. arXiv admin note: substantial text overlap\n  with arXiv:1807.05579; text overlap with arXiv:1807.05578", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Purely keyword-based text search is not satisfactory because named entities\nand WordNet words are also important elements to define the content of a\ndocument or a query in which they occur. Named entities have ontological\nfeatures, namely, their aliases, classes, and identifiers. Words in WordNet\nalso have ontological features, namely, their synonyms, hypernyms, hyponyms,\nand senses. Those features of concepts may be hidden from their textual\nappearance. Besides, there are related concepts that do not appear in a query,\nbut can bring out the meaning of the query if they are added. We propose an\nontology-based generalized Vector Space Model to semantic text search. It\nexploits ontological features of named entities and WordNet words, and develops\na query-oriented spreading activation algorithm to expand queries. In addition,\nit combines and utilizes advantages of different ontologies for semantic\nannotation and searching. Experiments on a benchmark dataset show that, in\nterms of the MAP measure, our model is 42.5% better than the purely\nkeyword-based model, and 32.3% and 15.9% respectively better than the ones\nusing only WordNet or named entities.\n  Keywords: semantic search, spreading activation, ontology, named entity,\nWordNet.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2018 10:43:55 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Ngo", "Vuong M.", ""], ["Cao", "Tru H.", ""], ["Le", "Tuan M. V.", ""]]}, {"id": "1807.08061", "submitter": "Bhaskar Mitra", "authors": "Surya Kallumadi, Bhaskar Mitra and Tereza Iofciu", "title": "A Line in the Sand: Recommendation or Ad-hoc Retrieval?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The popular approaches to recommendation and ad-hoc retrieval tasks are\nlargely distinct in the literature. In this work, we argue that many\nrecommendation problems can also be cast as ad-hoc retrieval tasks. To\ndemonstrate this, we build a solution for the RecSys 2018 Spotify challenge by\ncombining standard ad-hoc retrieval models and using popular retrieval tools\nsets. We draw a parallel between the playlist continuation task and the task of\nfinding good expansion terms for queries in ad-hoc retrieval, and show that\nstandard pseudo-relevance feedback can be effective as a collaborative\nfiltering approach. We also use ad-hoc retrieval for content-based\nrecommendation by treating the input playlist title as a query and associating\nall candidate tracks with meta-descriptions extracted from the background data.\nThe recommendations from these two approaches are further supplemented by a\nnearest neighbor search based on track embeddings learned by a popular neural\nmodel. Our final ranked list of recommendations is produced by a learning to\nrank model. Our proposed solution using ad-hoc retrieval models achieved a\ncompetitive performance on the music recommendation task at RecSys 2018\nchallenge---finishing at rank 7 out of 112 participating teams and at rank 5\nout of 31 teams for the main and the creative tracks, respectively.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jul 2018 00:45:13 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Kallumadi", "Surya", ""], ["Mitra", "Bhaskar", ""], ["Iofciu", "Tereza", ""]]}, {"id": "1807.08484", "submitter": "Wang Ruijie", "authors": "Ruijie Wang, Yuchen Yan, Jialu Wang, Yuting Jia, Ye Zhang, Weinan\n  Zhang, Xinbing Wang", "title": "AceKG: A Large-scale Knowledge Graph for Academic Data Mining", "comments": "CIKM 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most existing knowledge graphs (KGs) in academic domains suffer from problems\nof insufficient multi-relational information, name ambiguity and improper data\nformat for large-scale machine processing. In this paper, we present AceKG, a\nnew large-scale KG in academic domain. AceKG not only provides clean academic\ninformation, but also offers a large-scale benchmark dataset for researchers to\nconduct challenging data mining projects including link prediction, community\ndetection and scholar classification. Specifically, AceKG describes 3.13\nbillion triples of academic facts based on a consistent ontology, including\nnecessary properties of papers, authors, fields of study, venues and\ninstitutes, as well as the relations among them. To enrich the proposed\nknowledge graph, we also perform entity alignment with existing databases and\nrule-based inference. Based on AceKG, we conduct experiments of three typical\nacademic data mining tasks and evaluate several state-of- the-art knowledge\nembedding and network representation learning approaches on the benchmark\ndatasets built from AceKG. Finally, we discuss several promising research\ndirections that benefit from AceKG.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 08:57:44 GMT"}, {"version": "v2", "created": "Tue, 7 Aug 2018 07:46:48 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Wang", "Ruijie", ""], ["Yan", "Yuchen", ""], ["Wang", "Jialu", ""], ["Jia", "Yuting", ""], ["Zhang", "Ye", ""], ["Zhang", "Weinan", ""], ["Wang", "Xinbing", ""]]}, {"id": "1807.09009", "submitter": "Jahongir Azimjonov", "authors": "Jahongir Azimjonov and Jumabek Alikhanov", "title": "Rule Based Metadata Extraction Framework from Academic Articles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Metadata of scientific articles such as title, abstract, keywords or index\nterms, body text, conclusion, reference and others play a decisive role in\ncollecting, managing and storing academic data in scientific databases,\nacademic journals and digital libraries. An accurate extraction of these kinds\nof data from scientific papers is crucial to organize and retrieve important\nscientific information for researchers as well as librarians. Research social\nnetwork systems and academic digital library systems provide academic data\nextracting, organizing and retrieving services. Mostly these types of services\nare not free or open source. They also have some performance problems and\nextracting limitations in the number of PDF (Portable Document Format) files\nthat you can upload to the extraction systems. In this paper, a completely free\nand open source Java based high performance metadata extraction framework is\nproposed. This frameworks extraction speed is 9-10 times faster than existing\nmetadata extraction systems. It is also flexible in that it allows uploading of\nunlimited number of PDF files. In this approach, titles of papers are extracted\nusing layout features, font and size characteristics of text. Other metadata\nfields such as abstracts, body text, keywords, conclusions and references are\nextracted from PDF files using fixed rule sets. Extracted metadata are stored\nin both Oracle database and XML (Extensible Markup Language) file. This\nframework can be used to make scientific collections in digital libraries,\nonline journals, online and offline scientific databases, government research\nagencies and research centers.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 10:13:00 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Azimjonov", "Jahongir", ""], ["Alikhanov", "Jumabek", ""]]}, {"id": "1807.09097", "submitter": "Tiago Cunha", "authors": "Tiago Cunha, Carlos Soares, Andr\\'e C.P.L.F. de Carvalho", "title": "Algorithm Selection for Collaborative Filtering: the influence of graph\n  metafeatures and multicriteria metatargets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To select the best algorithm for a new problem is an expensive and difficult\ntask. However, there are automatic solutions to address this problem: using\nMetalearning, which takes advantage of problem characteristics (i.e.\nmetafeatures), one is able to predict the relative performance of algorithms.\nIn the Collaborative Filtering scope, recent works have proposed diverse\nmetafeatures describing several dimensions of this problem. Despite interesting\nand effective findings, it is still unknown whether these are the most\neffective metafeatures. Hence, this work proposes a new set of graph\nmetafeatures, which approach the Collaborative Filtering problem from a Graph\nTheory perspective. Furthermore, in order to understand whether metafeatures\nfrom multiple dimensions are a better fit, we investigate the effects of\ncomprehensive metafeatures. These metafeatures are a selection of the best\nmetafeatures from all existing Collaborative Filtering metafeatures. The impact\nof the most representative metafeatures is investigated in a controlled\nexperimental setup. Another contribution we present is the use of a\nPareto-Efficient ranking procedure to create multicriteria metatargets. These\nnew rankings of algorithms, which take into account multiple evaluation\nmeasures, allow to explore the algorithm selection problem in a fairer and more\ndetailed way. According to the experimental results, the graph metafeatures are\na good alternative to related work metafeatures. However, the results have\nshown that the feature selection procedure used to create the comprehensive\nmetafeatures is is not effective, since there is no gain in predictive\nperformance. Finally, an extensive metaknowledge analysis was conducted to\nidentify the most influential metafeatures.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 13:37:52 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Cunha", "Tiago", ""], ["Soares", "Carlos", ""], ["de Carvalho", "Andr\u00e9 C. P. L. F.", ""]]}, {"id": "1807.09142", "submitter": "Kiewan Villatel", "authors": "Kiewan Villatel (SEQUEL), Elena Smirnova, J\\'er\\'emie Mary, Philippe\n  Preux (SEQUEL)", "title": "Recurrent Neural Networks for Long and Short-Term Sequential\n  Recommendation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recommender systems objectives can be broadly characterized as modeling user\npreferences over short-or long-term time horizon. A large body of previous\nresearch studied long-term recommendation through dimensionality reduction\ntechniques applied to the historical user-item interactions. A recently\nintroduced session-based recommendation setting highlighted the importance of\nmodeling short-term user preferences. In this task, Recurrent Neural Networks\n(RNN) have shown to be successful at capturing the nuances of user's\ninteractions within a short time window. In this paper, we evaluate RNN-based\nmodels on both short-term and long-term recommendation tasks. Our experimental\nresults suggest that RNNs are capable of predicting immediate as well as\ndistant user interactions. We also find the best performing configuration to be\na stacked RNN with layer normalization and tied item embeddings.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2018 11:38:04 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Villatel", "Kiewan", "", "SEQUEL"], ["Smirnova", "Elena", "", "SEQUEL"], ["Mary", "J\u00e9r\u00e9mie", "", "SEQUEL"], ["Preux", "Philippe", "", "SEQUEL"]]}, {"id": "1807.09320", "submitter": "Antoine Amarilli", "authors": "Antoine Amarilli, Pierre Bourhis, Stefan Mengel, Matthias Niewerth", "title": "Constant-Delay Enumeration for Nondeterministic Document Spanners", "comments": "25 pages including 17 pages of main material. Integrates all reviewer\n  feedback. T paper is exactly the same as the ICDT'19 paper except that it\n  contains 6 pages of technical appendix, and except that we corrected some\n  additional minor mistakes following reviews of the journal version\n  (arXiv:2003.02576). We recommend reading the journal version instead of this\n  paper", "journal-ref": null, "doi": "10.4230/LIPIcs.ICDT.2019.19", "report-no": null, "categories": "cs.DB cs.IR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider the information extraction framework known as document spanners,\nand study the problem of efficiently computing the results of the extraction\nfrom an input document, where the extraction task is described as a sequential\nvariable-set automaton (VA). We pose this problem in the setting of enumeration\nalgorithms, where we can first run a preprocessing phase and must then produce\nthe results with a small delay between any two consecutive results. Our goal is\nto have an algorithm which is tractable in combined complexity, i.e., in the\nsizes of the input document and the VA; while ensuring the best possible data\ncomplexity bounds in the input document size, i.e., constant delay in the\ndocument size. Several recent works at PODS'18 proposed such algorithms but\nwith linear delay in the document size or with an exponential dependency in\nsize of the (generally nondeterministic) input VA. In particular, Florenzano et\nal. suggest that our desired runtime guarantees cannot be met for general\nsequential VAs. We refute this and show that, given a nondeterministic\nsequential VA and an input document, we can enumerate the mappings of the VA on\nthe document with the following bounds: the preprocessing is linear in the\ndocument size and polynomial in the size of the VA, and the delay is\nindependent of the document and polynomial in the size of the VA. The resulting\nalgorithm thus achieves tractability in combined complexity and the best\npossible data complexity bounds. Moreover, it is rather easy to describe, in\nparticular for the restricted case of so-called extended VAs.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 19:49:14 GMT"}, {"version": "v2", "created": "Fri, 28 Sep 2018 13:23:00 GMT"}, {"version": "v3", "created": "Sat, 2 Mar 2019 14:53:12 GMT"}, {"version": "v4", "created": "Fri, 25 Sep 2020 07:54:45 GMT"}, {"version": "v5", "created": "Mon, 7 Dec 2020 13:43:35 GMT"}], "update_date": "2020-12-08", "authors_parsed": [["Amarilli", "Antoine", ""], ["Bourhis", "Pierre", ""], ["Mengel", "Stefan", ""], ["Niewerth", "Matthias", ""]]}, {"id": "1807.09751", "submitter": "Han Xiao", "authors": "Han Xiao, Yidong Chen, Xiaodong Shi", "title": "Multi-Perspective Neural Architecture for Recommendation System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, there starts a research trend to leverage neural architecture for\nrecommendation systems. Though several deep recommender models are proposed,\nmost methods are too simple to characterize users' complex preference. In this\npaper, for a fine-grain analysis, users' ratings are explained from multiple\nperspectives, based on which, we propose our neural architecture. Specifically,\nour model employs several sequential stages to encode the user and item into\nhidden representations. In one stage, the user and item are represented from\nmultiple perspectives and in each perspective, the representations of user and\nitem put attentions to each other. Last, we metric the output representations\nof final stage to approach the users' rating. Extensive experiments demonstrate\nthat our method achieves substantial improvements against baselines.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 05:06:39 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Xiao", "Han", ""], ["Chen", "Yidong", ""], ["Shi", "Xiaodong", ""]]}, {"id": "1807.09754", "submitter": "Sarathkrishna Swaminathan", "authors": "Stephen Boyer, Thomas Griffin, Sarath Swaminathan, Kenneth L.\n  Clarkson, Dmitry Zubarev", "title": "Data Infrastructure and Approaches for Ontology-Based Drug Repurposing", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report development of a data infrastructure for drug repurposing that\ntakes advantage of two currently available chemical ontologies. The data\ninfrastructure includes a database of compound- target associations augmented\nwith molecular ontological labels. It also contains two computational tools for\nprediction of new associations. We describe two drug-repurposing systems: one,\nNascent Ontological Information Retrieval for Drug Repurposing (NOIR-DR), based\non an information retrieval strategy, and another, based on non-negative matrix\nfactorization together with compound similarity, that was inspired by\nrecommender systems. We report the performance of both tools on a\ndrug-repurposing task.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2018 23:17:05 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Boyer", "Stephen", ""], ["Griffin", "Thomas", ""], ["Swaminathan", "Sarath", ""], ["Clarkson", "Kenneth L.", ""], ["Zubarev", "Dmitry", ""]]}, {"id": "1807.09842", "submitter": "Muhammad Mahbubur Rahman", "authors": "Muhammad Mahbubur Rahman, Tim Finin", "title": "Understanding and representing the semantics of large structured\n  documents", "comments": "10 pages, 6 figures, 28 references and 2 tables", "journal-ref": "Semantic Deep Learning at ISWC 2018", "doi": null, "report-no": null, "categories": "cs.CL cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding large, structured documents like scholarly articles, requests\nfor proposals or business reports is a complex and difficult task. It involves\ndiscovering a document's overall purpose and subject(s), understanding the\nfunction and meaning of its sections and subsections, and extracting low level\nentities and facts about them. In this research, we present a deep learning\nbased document ontology to capture the general purpose semantic structure and\ndomain specific semantic concepts from a large number of academic articles and\nbusiness documents. The ontology is able to describe different functional parts\nof a document, which can be used to enhance semantic indexing for a better\nunderstanding by human beings and machines. We evaluate our models through\nextensive experiments on datasets of scholarly articles from arXiv and Request\nfor Proposal documents.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2018 04:14:51 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Rahman", "Muhammad Mahbubur", ""], ["Finin", "Tim", ""]]}, {"id": "1807.09870", "submitter": "Felipe del Rio", "authors": "Felipe del Rio and Pablo Messina and Vicente Dominguez and Denis Parra", "title": "Do Better ImageNet Models Transfer Better... for Image Recommendation?", "comments": "Submitted to KTL Workshop co-located at RecSys", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visual embeddings from Convolutional Neural Networks (CNN) trained on the\nImageNet dataset for the ILSVRC challenge have shown consistently good\nperformance for transfer learning and are widely used in several tasks,\nincluding image recommendation. However, some important questions have not yet\nbeen answered in order to use these embeddings for a larger scope of\nrecommendation domains: a) Do CNNs that perform better in ImageNet are also\nbetter for transfer learning in content-based image recommendation?, b) Does\nfine-tuning help to improve performance? and c) Which is the best way to\nperform the fine-tuning?\n  In this paper we compare several CNN models pre-trained with ImageNet to\nevaluate their transfer learning performance to an artwork image recommendation\ntask. Our results indicate that models with better performance in the ImageNet\nchallenge do not always imply better transfer learning for recommendation tasks\n(e.g. NASNet vs. ResNet). Our results also show that fine-tuning can be helpful\neven with a small dataset, but not every fine-tuning works. Our results can\ninform other researchers and practitioners on how to train their CNNs for\nbetter transfer learning towards image recommendation systems.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 21:34:55 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2018 16:56:52 GMT"}, {"version": "v3", "created": "Tue, 25 Sep 2018 11:52:52 GMT"}], "update_date": "2018-09-26", "authors_parsed": [["del Rio", "Felipe", ""], ["Messina", "Pablo", ""], ["Dominguez", "Vicente", ""], ["Parra", "Denis", ""]]}, {"id": "1807.09967", "submitter": "Artit Wangperawong", "authors": "Xinyi Liu and Artit Wangperawong", "title": "A Collaborative Approach to Angel and Venture Capital Investment\n  Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-fin.PM cs.IR cs.LG q-fin.GN stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization was used to generate investment recommendations for\ninvestors. An iterative conjugate gradient method was used to optimize the\nregularized squared-error loss function. The number of latent factors, number\nof iterations, and regularization values were explored. Overfitting can be\naddressed by either early stopping or regularization parameter tuning. The\nmodel achieved the highest average prediction accuracy of 13.3%. With a similar\nmodel, the same dataset was used to generate investor recommendations for\ncompanies undergoing fundraising, which achieved highest prediction accuracy of\n11.1%.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 06:14:08 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Liu", "Xinyi", ""], ["Wangperawong", "Artit", ""]]}, {"id": "1807.10009", "submitter": "Dejan Lavbi\\v{c}", "authors": "Slavko \\v{Z}itnik, Lovro \\v{S}ubelj, Dejan Lavbi\\v{c}, Olegas\n  Vasilecas, Marko Bajec", "title": "General Context-Aware Data Matching and Merging Framework", "comments": "29 pages, 12 figures, 2 tables", "journal-ref": "Informatica 24 (2013) 119-152", "doi": null, "report-no": null, "categories": "cs.IR cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to numerous public information sources and services, many methods to\ncombine heterogeneous data were proposed recently. However, general end-to-end\nsolutions are still rare, especially systems taking into account different\ncontext dimensions. Therefore, the techniques often prove insufficient or are\nlimited to a certain domain. In this paper we briefly review and rigorously\nevaluate a general framework for data matching and merging. The framework\nemploys collective entity resolution and redundancy elimination using three\ndimensions of context types. In order to achieve domain independent results,\ndata is enriched with semantics and trust. However, the main contribution of\nthe paper is evaluation on five public domain-incompatible datasets.\nFurthermore, we introduce additional attribute, relationship, semantic and\ntrust metrics, which allow complete framework management. Besides overall\nresults improvement within the framework, metrics could be of independent\ninterest.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 08:30:25 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["\u017ditnik", "Slavko", ""], ["\u0160ubelj", "Lovro", ""], ["Lavbi\u010d", "Dejan", ""], ["Vasilecas", "Olegas", ""], ["Bajec", "Marko", ""]]}, {"id": "1807.10147", "submitter": "Christophe Dumora", "authors": "Christophe Dumora (LaBRI, IMB), David Auber (LaBRI), J\\'er\\'emie Bigot\n  (IMB), Vincent Couallier (IMB), Cyril Leclerc (LyRE)", "title": "Data-Oriented Algorithm for Real-Time Estimation of Flow Rates and Flow\n  Directions in a Water Distribution Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DS cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to present how data collected from a water\ndistribution network (WDN) can be used to reconstruct flow rate and flow\ndirection all over the network to enhance knowledge and detection of unforeseen\nevents. The methodological approach consists in modeling the WDN and all\navailable sensor data related to the management of such a network in the form\nof a flow network graph G = (V, E, s, t, c), with V a set of nodes, E a set of\nedges whose elements are ordered pairs of distinct nodes, s a source node, t a\nsink node and c a capacity function on edges. Our objective is to reconstruct a\nreal-valued function f(u,v): VxV => R on all the edges E in VxV from partial\nobservations on a small number of nodes V = {1, ..., n}. This reconstruction\nmethod consists in a data-driven Ford-Fulkerson maximum-flow problem in a\nmulti-source, multi-sink context using a constrained bidirectional\nbreadth-first search based on Edmonds-Karp method. The innovative approach is\nits application in the context of smart cities to operate from sensor data,\nstructural data from a geographical information system (GIS) and consumption\nestimates.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2018 07:10:18 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Dumora", "Christophe", "", "LaBRI, IMB"], ["Auber", "David", "", "LaBRI"], ["Bigot", "J\u00e9r\u00e9mie", "", "IMB"], ["Couallier", "Vincent", "", "IMB"], ["Leclerc", "Cyril", "", "LyRE"]]}, {"id": "1807.10204", "submitter": "Rafael Valle", "authors": "Rafael Valle", "title": "Visual Display and Retrieval of Music Information", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes computational methods for the visual display and\nanalysis of music information. We provide a concise description of software,\nmusic descriptors and data visualization techniques commonly used in music\ninformation retrieval. Finally, we provide use cases where the described\nsoftware, descriptors and visualizations are showcased.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 15:41:35 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Valle", "Rafael", ""]]}, {"id": "1807.10623", "submitter": "Ashutosh Maurya", "authors": "Ashutosh K. Maurya", "title": "Learning low dimensional word based linear classifiers using Data Shared\n  Adaptive Bootstrap Aggregated Lasso with application to IMDb data", "comments": "arXiv admin note: text overlap with arXiv:1204.1177 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we propose a new supervised ensemble learning method called\nData Shared Adaptive Bootstrap Aggregated (AdaBag) Lasso for capturing low\ndimensional useful features for word based sentiment analysis and mining\nproblems. The literature on ensemble methods is very rich in both statistics\nand machine learning. The algorithm is a substantial upgrade of the Data Shared\nLasso uplift algorithm. The most significant conceptual addition to the\nexisting literature lies in the final selection of bag of predictors through a\nspecial bootstrap aggregation scheme. We apply the algorithm to one simulated\ndata and perform dimension reduction in grouped IMDb data (drama, comedy and\nhorror) to extract reduced set of word features for predicting sentiment\nratings of movie reviews demonstrating different aspects. We also compare the\nperformance of the present method with the classical Principal Components with\nassociated Linear Discrimination (PCA-LD) as baseline. There are few\nlimitations in the algorithm. Firstly, the algorithm workflow does not\nincorporate online sequential data acquisition and it does not use sentence\nbased models which are common in ANN algorithms . Our results produce slightly\nhigher error rate compare to the reported state-of-the-art as a consequence.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2018 17:55:35 GMT"}, {"version": "v2", "created": "Mon, 30 Jul 2018 05:58:00 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Maurya", "Ashutosh K.", ""]]}, {"id": "1807.10634", "submitter": "Evgeny Frolov", "authors": "Evgeny Frolov and Ivan Oseledets", "title": "Revealing the Unobserved by Linking Collaborative Behavior and Side\n  Knowledge", "comments": "9 pages, 1 figure, draft", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a tensor-based model that fuses a more granular representation of\nuser preferences with the ability to take additional side information into\naccount. The model relies on the concept of ordinal nature of utility, which\nbetter corresponds to actual user perception. In addition to that, unlike the\nmajority of hybrid recommenders, the model ties side information directly to\ncollaborative data, which not only addresses the problem of extreme data\nsparsity, but also allows to naturally exploit patterns in the observed\nbehavior for a more meaningful representation of user intents. We demonstrate\nthe effectiveness of the proposed model on several standard benchmark datasets.\nThe general formulation of the approach imposes no restrictions on the type of\nobserved interactions and makes it potentially applicable for joint modelling\nof context information along with side data.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2018 14:02:25 GMT"}], "update_date": "2018-07-30", "authors_parsed": [["Frolov", "Evgeny", ""], ["Oseledets", "Ivan", ""]]}, {"id": "1807.11024", "submitter": "Vuong M. Ngo", "authors": "L.H. Nguyen, N.T.H. Pham, V.M. Ngo", "title": "Opinion Spam Recognition Method for Online Reviews using Ontological\n  Features", "comments": "15 pages, In Journal of Science, Special Issue: Natural Science and\n  Technology, Ho Chi Minh City University of Education", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.AI cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, there are a lot of people using social media opinions to make their\ndecision on buying products or services. Opinion spam detection is a hard\nproblem because fake reviews can be made by organizations as well as\nindividuals for different purposes. They write fake reviews to mislead readers\nor automated detection system by promoting or demoting target products to\npromote them or to damage their reputations. In this paper, we pro-pose a new\napproach using knowledge-based Ontology to detect opinion spam with high\naccuracy (higher than 75%). Keywords: Opinion spam, Fake review, E-commercial,\nOntology.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2018 09:05:21 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Nguyen", "L. H.", ""], ["Pham", "N. T. H.", ""], ["Ngo", "V. M.", ""]]}, {"id": "1807.11141", "submitter": "Gaole He", "authors": "Wayne Xin Zhao, Gaole He, Hongjian Dou, Jin Huang, Siqi Ouyang and\n  Ji-Rong Wen", "title": "KB4Rec: A Dataset for Linking Knowledge Bases with Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To develop a knowledge-aware recommender system, a key data problem is how we\ncan obtain rich and structured knowledge information for recommender system\n(RS) items. Existing datasets or methods either use side information from\noriginal recommender systems (containing very few kinds of useful information)\nor utilize private knowledge base (KB). In this paper, we present the first\npublic linked KB dataset for recommender systems, named KB4Rec v1.0, which has\nlinked three widely used RS datasets with the popular KB Freebase. Based on our\nlinked dataset, we first preform some interesting qualitative analysis\nexperiments, in which we discuss the effect of two important factors (i.e.\npopularity and recency) on whether a RS item can be linked to a KB entity.\nFinally, we present the comparison of several knowledge-aware recommendation\nalgorithms on our linked dataset.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2018 01:57:16 GMT"}, {"version": "v2", "created": "Tue, 31 Jul 2018 11:01:06 GMT"}, {"version": "v3", "created": "Mon, 20 Aug 2018 02:16:05 GMT"}, {"version": "v4", "created": "Wed, 17 Oct 2018 06:41:21 GMT"}, {"version": "v5", "created": "Thu, 18 Oct 2018 02:36:47 GMT"}, {"version": "v6", "created": "Sun, 30 Dec 2018 12:50:49 GMT"}, {"version": "v7", "created": "Mon, 28 Dec 2020 03:35:57 GMT"}], "update_date": "2020-12-29", "authors_parsed": [["Zhao", "Wayne Xin", ""], ["He", "Gaole", ""], ["Dou", "Hongjian", ""], ["Huang", "Jin", ""], ["Ouyang", "Siqi", ""], ["Wen", "Ji-Rong", ""]]}, {"id": "1807.11689", "submitter": "Muhao Chen", "authors": "Muhao Chen, Changping Meng, Gang Huang and Carlo Zaniolo", "title": "Neural Article Pair Modeling for Wikipedia Sub-article Matching", "comments": "ECML-PKDD 2018. 16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.CL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, editors tend to separate different subtopics of a long Wiki-pedia\narticle into multiple sub-articles. This separation seeks to improve human\nreadability. However, it also has a deleterious effect on many Wikipedia-based\ntasks that rely on the article-as-concept assumption, which requires each\nentity (or concept) to be described solely by one article. This underlying\nassumption significantly simplifies knowledge representation and extraction,\nand it is vital to many existing technologies such as automated knowledge base\nconstruction, cross-lingual knowledge alignment, semantic search and data\nlineage of Wikipedia entities. In this paper we provide an approach to match\nthe scattered sub-articles back to their corresponding main-articles, with the\nintent of facilitating automated Wikipedia curation and processing. The\nproposed model adopts a hierarchical learning structure that combines multiple\nvariants of neural document pair encoders with a comprehensive set of explicit\nfeatures. A large crowdsourced dataset is created to support the evaluation and\nfeature extraction for the task. Based on the large dataset, the proposed model\nachieves promising results of cross-validation and significantly outperforms\nprevious approaches. Large-scale serving on the entire English Wikipedia also\nproves the practicability and scalability of the proposed model by effectively\nextracting a vast collection of newly paired main and sub-articles.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 07:19:36 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2018 21:30:17 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Chen", "Muhao", ""], ["Meng", "Changping", ""], ["Huang", "Gang", ""], ["Zaniolo", "Carlo", ""]]}, {"id": "1807.11698", "submitter": "Guy Hadash", "authors": "Guy Hadash, Oren Sar Shalom, Rita Osadchy", "title": "Rank and Rate: Multi-task Learning for Recommender Systems", "comments": null, "journal-ref": null, "doi": "10.1145/3240323.3240406", "report-no": null, "categories": "cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The two main tasks in the Recommender Systems domain are the ranking and\nrating prediction tasks. The rating prediction task aims at predicting to what\nextent a user would like any given item, which would enable to recommend the\nitems with the highest predicted scores. The ranking task on the other hand\ndirectly aims at recommending the most valuable items for the user. Several\nprevious approaches proposed learning user and item representations to optimize\nboth tasks simultaneously in a multi-task framework. In this work we propose a\nnovel multi-task framework that exploits the fact that a user does a two-phase\ndecision process - first decides to interact with an item (ranking task) and\nonly afterward to rate it (rating prediction task). We evaluated our framework\non two benchmark datasets, on two different configurations and showed its\nsuperiority over state-of-the-art methods.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2018 08:16:08 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Hadash", "Guy", ""], ["Shalom", "Oren Sar", ""], ["Osadchy", "Rita", ""]]}]