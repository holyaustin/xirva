[{"id": "1705.00138", "submitter": "Monowar Hasan", "authors": "Monowar Hasan, Sibin Mohan, Rodolfo Pellizzoni, Rakesh B. Bobba", "title": "Contego: An Adaptive Framework for Integrating Security Tasks in\n  Real-Time Systems", "comments": "Accepted for publication, 29th Euromicro Conference on Real-Time\n  Systems (ECRTS17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded real-time systems (RTS) are pervasive. Many modern RTS are exposed\nto unknown security flaws, and threats to RTS are growing in both number and\nsophistication. However, until recently, cyber-security considerations were an\nafterthought in the design of such systems. Any security mechanisms integrated\ninto RTS must (a) co-exist with the real- time tasks in the system and (b)\noperate without impacting the timing and safety constraints of the control\nlogic. We introduce Contego, an approach to integrating security tasks into RTS\nwithout affecting temporal requirements. Contego is specifically designed for\nlegacy systems, viz., the real-time control systems in which major alterations\nof the system parameters for constituent tasks is not always feasible. Contego\ncombines the concept of opportunistic execution with hierarchical scheduling to\nmaintain compatibility with legacy systems while still providing flexibility by\nallowing security tasks to operate in different modes. We also define a metric\nto measure the effectiveness of such integration. We evaluate Contego using\nsynthetic workloads as well as with an implementation on a realistic embedded\nplatform (an open- source ARM CPU running real-time Linux).\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 06:22:32 GMT"}, {"version": "v2", "created": "Tue, 2 May 2017 05:44:38 GMT"}, {"version": "v3", "created": "Tue, 23 May 2017 19:00:17 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Hasan", "Monowar", ""], ["Mohan", "Sibin", ""], ["Pellizzoni", "Rodolfo", ""], ["Bobba", "Rakesh B.", ""]]}, {"id": "1705.02561", "submitter": "Chien-Ying Chen", "authors": "Chien-Ying Chen, AmirEmad Ghassami, Sibin Mohan, Negar Kiyavash,\n  Rakesh B. Bobba, Rodolfo Pellizzoni, Man-Ki Yoon", "title": "A Reconnaissance Attack Mechanism for Fixed-Priority Real-Time Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real-time embedded systems (RTS), failures due to security breaches can\ncause serious damage to the system, the environment and/or injury to humans.\nTherefore, it is very important to understand the potential threats and attacks\nagainst these systems. In this paper we present a novel reconnaissance attack\nthat extracts the exact schedule of real-time systems designed using fixed\npriority scheduling algorithms. The attack is demonstrated on both a real\nhardware platform and a simulator, with a high success rate. Our evaluation\nresults show that the algorithm is robust even in the presence of execution\ntime variation.\n", "versions": [{"version": "v1", "created": "Sun, 7 May 2017 04:07:10 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Chen", "Chien-Ying", ""], ["Ghassami", "AmirEmad", ""], ["Mohan", "Sibin", ""], ["Kiyavash", "Negar", ""], ["Bobba", "Rakesh B.", ""], ["Pellizzoni", "Rodolfo", ""], ["Yoon", "Man-Ki", ""]]}, {"id": "1705.03591", "submitter": "Tao Lu", "authors": "Tao Lu, Ping Huang, Xubin He, Matthew Welch, Steven Gonzales, Ming\n  Zhang", "title": "IOTune: A G-states Driver for Elastic Performance of Block Storage", "comments": "15 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Imagining a disk which provides baseline performance at a relatively low\nprice during low-load periods, but when workloads demand more resources, the\ndisk performance is automatically promoted in situ and in real time. In a\nhardware era, this is hardly achievable. However, this imagined disk is\nbecoming reality due to the technical advances of software-defined storage,\nwhich enable volume performance to be adjusted on the fly. We propose IOTune, a\nresource management middleware which employs software-defined storage\nprimitives to implement G-states of virtual block devices. G-states enable\nvirtual block devices to serve at multiple performance gears, getting rid of\nconflicts between immutable resource reservation and dynamic resource demands,\nand always achieving resource right-provisioning for workloads. Accompanying\nG-states, we also propose a new block storage pricing policy for cloud\nproviders. Our case study for applying G-states to cloud block storage verifies\nthe effectiveness of the IOTune framework. Trace-replay based evaluations\ndemonstrate that storage volumes with G-states adapt to workload fluctuations.\nFor tenants, G-states enable volumes to provide much better QoS with a same\ncost of ownership, comparing with static IOPS provisioning and the I/O credit\nmechanism. G-states also reduce I/O tail latencies by one to two orders of\nmagnitude. From the standpoint of cloud providers, G-states promote storage\nutilization, creating values and benefiting competitiveness. G-states supported\nby IOTune provide a new paradigm for storage resource management and pricing in\nmulti-tenant clouds.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 02:30:06 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Lu", "Tao", ""], ["Huang", "Ping", ""], ["He", "Xubin", ""], ["Welch", "Matthew", ""], ["Gonzales", "Steven", ""], ["Zhang", "Ming", ""]]}, {"id": "1705.03623", "submitter": "Youyou Lu", "authors": "Youyou Lu, Jiwu Shu, Long Sun, Onur Mutlu", "title": "Improving the Performance and Endurance of Persistent Memory with\n  Loose-Ordering Consistency", "comments": "This paper has been accepted by IEEE Transactions on Parallel and\n  Distributed Systems", "journal-ref": null, "doi": "10.1109/TPDS.2017.2701364", "report-no": null, "categories": "cs.AR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent memory provides high-performance data persistence at main memory.\nMemory writes need to be performed in strict order to satisfy storage\nconsistency requirements and enable correct recovery from system crashes.\nUnfortunately, adhering to such a strict order significantly degrades system\nperformance and persistent memory endurance. This paper introduces a new\nmechanism, Loose-Ordering Consistency (LOC), that satisfies the ordering\nrequirements at significantly lower performance and endurance loss. LOC\nconsists of two key techniques. First, Eager Commit eliminates the need to\nperform a persistent commit record write within a transaction. We do so by\nensuring that we can determine the status of all committed transactions during\nrecovery by storing necessary metadata information statically with blocks of\ndata written to memory. Second, Speculative Persistence relaxes the write\nordering between transactions by allowing writes to be speculatively written to\npersistent memory. A speculative write is made visible to software only after\nits associated transaction commits. To enable this, our mechanism supports the\ntracking of committed transaction ID and multi-versioning in the CPU cache. Our\nevaluations show that LOC reduces the average performance overhead of memory\npersistence from 66.9% to 34.9% and the memory write traffic overhead from\n17.1% to 3.4% on a variety of workloads.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 06:47:40 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Lu", "Youyou", ""], ["Shu", "Jiwu", ""], ["Sun", "Long", ""], ["Mutlu", "Onur", ""]]}, {"id": "1705.05798", "submitter": "Jo\\\"el Goossens", "authors": "Pascal Richard, Jo\\\"el Goossens and Shinpei Kato", "title": "Comments on \"Gang EDF Schedulability Analysis\"", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short report raises a correctness issue in the schedulability test\npresented in Kato et al., \"Gang EDF Scheduling of Parallel Task Systems\", 30th\nIEEE Real-Time Systems Symposium, 2009, pp. 459-468.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 16:41:43 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Richard", "Pascal", ""], ["Goossens", "Jo\u00ebl", ""], ["Kato", "Shinpei", ""]]}, {"id": "1705.06932", "submitter": "Ralf Ramsauer", "authors": "Ralf Ramsauer, Jan Kiszka, Daniel Lohmann, Wolfgang Mauerer", "title": "Look Mum, no VM Exits! (Almost)", "comments": null, "journal-ref": "Proceedings of the 13th Workshop on Operating Systems Platforms\n  for Embedded Real-Time Applications (OSPERT 2017)", "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-core CPUs are a standard component in many modern embedded systems.\nTheir virtualisation extensions enable the isolation of services, and gain\npopularity to implement mixed-criticality or otherwise split systems. We\npresent Jailhouse, a Linux-based, OS-agnostic partitioning hypervisor that uses\nnovel architectural approaches to combine Linux, a powerful general-purpose\nsystem, with strictly isolated special-purpose components. Our design goals\nfavour simplicity over features, establish a minimal code base, and minimise\nhypervisor activity.\n  Direct assignment of hardware to guests, together with a deferred\ninitialisation scheme, offloads any complex hardware handling and bootstrapping\nissues from the hypervisor to the general purpose OS. The hypervisor\nestablishes isolated domains that directly access physical resources without\nthe need for emulation or paravirtualisation. This retains, with negligible\nsystem overhead, Linux's feature-richness in uncritical parts, while frugal\nsafety and real-time critical workloads execute in isolated, safe domains.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 11:01:54 GMT"}], "update_date": "2020-09-03", "authors_parsed": [["Ramsauer", "Ralf", ""], ["Kiszka", "Jan", ""], ["Lohmann", "Daniel", ""], ["Mauerer", "Wolfgang", ""]]}, {"id": "1705.06965", "submitter": "J\\'an Vesel\\'y", "authors": "J\\'an Vesel\\'y, Arkaprava Basu, Abhishek Bhattacharjee, Gabriel Loh,\n  Mark Oskin, Steven K. Reinhardt", "title": "GPU System Calls", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPUs are becoming first-class compute citizens and are being tasked to\nperform increasingly complex work. Modern GPUs increasingly support\nprogrammability- enhancing features such as shared virtual memory and hardware\ncache coherence, enabling them to run a wider variety of programs. But a key\naspect of general-purpose programming where GPUs are still found lacking is the\nability to invoke system calls. We explore how to directly invoke generic\nsystem calls in GPU programs. We examine how system calls should be meshed with\nprevailing GPGPU programming models where thousands of threads are organized in\na hierarchy of execution groups: Should a system call be invoked at the\nindividual GPU task, or at different execution group levels? What are\nreasonable ordering semantics for GPU system calls across these hierarchy of\nexecution groups? To study these questions, we implemented GENESYS -- a\nmechanism to allow GPU pro- grams to invoke system calls in the Linux operating\nsystem. Numerous subtle changes to Linux were necessary, as the existing kernel\nassumes that only CPUs invoke system calls. We analyze the performance of\nGENESYS using micro-benchmarks and three applications that exercise the\nfilesystem, networking, and memory allocation subsystems of the kernel. We\nconclude by analyzing the suitability of all of Linux's system calls for the\nGPU.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 12:48:50 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 20:48:00 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Vesel\u00fd", "J\u00e1n", ""], ["Basu", "Arkaprava", ""], ["Bhattacharjee", "Abhishek", ""], ["Loh", "Gabriel", ""], ["Oskin", "Mark", ""], ["Reinhardt", "Steven K.", ""]]}, {"id": "1705.07400", "submitter": "Juncheng Yang", "authors": "Juncheng Yang, Reza Karimi, Trausti S{\\ae}mundsson, Avani Wildani,\n  Ymir Vigfusson", "title": "MITHRIL: Mining Sporadic Associations for Cache Prefetching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing pressure on cloud application scalability has accentuated storage\nperformance as a critical bottle- neck. Although cache replacement algorithms\nhave been extensively studied, cache prefetching - reducing latency by\nretrieving items before they are actually requested remains an underexplored\narea. Existing approaches to history-based prefetching, in particular, provide\ntoo few benefits for real systems for the resources they cost. We propose\nMITHRIL, a prefetching layer that efficiently exploits historical patterns in\ncache request associations. MITHRIL is inspired by sporadic association rule\nmining and only relies on the timestamps of requests. Through evaluation of 135\nblock-storage traces, we show that MITHRIL is effective, giving an average of a\n55% hit ratio increase over LRU and PROBABILITY GRAPH, a 36% hit ratio gain\nover AMP at reasonable cost. We further show that MITHRIL can supplement any\ncache replacement algorithm and be readily integrated into existing systems.\nFurthermore, we demonstrate the improvement comes from MITHRIL being able to\ncapture mid-frequency blocks.\n", "versions": [{"version": "v1", "created": "Sun, 21 May 2017 05:51:21 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Yang", "Juncheng", ""], ["Karimi", "Reza", ""], ["S\u00e6mundsson", "Trausti", ""], ["Wildani", "Avani", ""], ["Vigfusson", "Ymir", ""]]}, {"id": "1705.09701", "submitter": "Keith Smith", "authors": "Peter Macko, Xiongzi Ge, John Haskins Jr., James Kelley, David Slik,\n  Keith A. Smith, Maxim G. Smith", "title": "SMORE: A Cold Data Object Store for SMR Drives (Extended Version)", "comments": "13 pages, 8 figures, full version of 6 page paper published at MSST\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shingled magnetic recording (SMR) increases the capacity of magnetic hard\ndrives, but it requires that each zone of a disk be written sequentially and\nerased in bulk. This makes SMR a good fit for workloads dominated by large data\nobjects with limited churn. To explore this possibility, we have developed\nSMORE, an object storage system designed to reliably and efficiently store\nlarge, seldom-changing data objects on an array of host-managed or host-aware\nSMR disks.\n  SMORE uses a log-structured approach to accommodate the constraint that all\nwrites to an SMR drive must be sequential within large shingled zones. It\nstripes data across zones on separate disks, using erasure coding to protect\nagainst drive failure. A separate garbage collection thread reclaims space by\nmigrating live data out of the emptiest zones so that they can be trimmed and\nreused. An index stored on flash and backed up to the SMR drives maps object\nidentifiers to on-disk locations. SMORE interleaves log records with object\ndata within SMR zones to enable index recovery after a system crash (or failure\nof the flash device) without any additional logging mechanism.\n  SMORE achieves full disk bandwidth when ingesting data---with a variety of\nobject sizes---and when reading large objects. Read performance declines for\nsmaller object sizes where inter- object seek time dominates. With a worst-case\npattern of random deletions, SMORE has a write amplification (not counting RAID\nparity) of less than 2.0 at 80% occupancy. By taking an index snapshot every\ntwo hours, SMORE recovers from crashes in less than a minute. More frequent\nsnapshots allow faster recovery.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 20:03:18 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Macko", "Peter", ""], ["Ge", "Xiongzi", ""], ["Haskins", "John", "Jr."], ["Kelley", "James", ""], ["Slik", "David", ""], ["Smith", "Keith A.", ""], ["Smith", "Maxim G.", ""]]}]