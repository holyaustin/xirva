[{"id": "1901.00825", "submitter": "Chen Zheng", "authors": "Chen Zheng, Lei Wang, Sally A. McKee, Lixin Zhang, Hainan Ye, Jianfeng\n  Zhan", "title": "XOS: An Application-Defined Operating System for Data Center Servers", "comments": "Accepted for publication in IEEE BigData 2018. 10 pages, 6 figures, 3\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid growth of datacenter (DC) scale, urgency of cost control, increasing\nworkload diversity, and huge software investment protection place unprecedented\ndemands on the operating system (OS) efficiency, scalability, performance\nisolation, and backward-compatibility. The traditional OSes are not built to\nwork with deep-hierarchy software stacks, large numbers of cores, tail latency\nguarantee, and increasingly rich variety of applications seen in modern DCs,\nand thus they struggle to meet the demands of such workloads.\n  This paper presents XOS, an application-defined OS for modern DC servers. Our\ndesign moves resource management out of the OS kernel, supports customizable\nkernel subsystems in user space, and enables elastic partitioning of hardware\nresources. Specifically, XOS leverages modern hardware support for\nvirtualization to move resource management functionality out of the\nconventional kernel and into user space, which lets applications achieve near\nbare-metal performance. We implement XOS on top of Linux to provide backward\ncompatibility. XOS speeds up a set of DC workloads by up to 1.6X over our\nbaseline Linux on a 24-core server, and outperforms the state-of-the-art Dune\nby up to 3.3X in terms of virtual memory management. In addition, XOS\ndemonstrates good scalability and strong performance isolation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Jan 2019 17:27:14 GMT"}], "update_date": "2019-01-04", "authors_parsed": [["Zheng", "Chen", ""], ["Wang", "Lei", ""], ["McKee", "Sally A.", ""], ["Zhang", "Lixin", ""], ["Ye", "Hainan", ""], ["Zhan", "Jianfeng", ""]]}, {"id": "1901.01222", "submitter": "Vlad Nitu", "authors": "Yuxin Ren, Vlad Nitu, Guyue Liu, Gabriel Parmer, Timothy Wood, Alain\n  Tchana, Riley Kennedy", "title": "Efficient, Dynamic Multi-tenant Edge Computation in EdgeOS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the future, computing will be immersed in the world around us -- from\naugmented reality to autonomous vehicles to the Internet of Things. Many of\nthese smart devices will offer services that respond in real time to their\nphysical surroundings, requiring complex processing with strict performance\nguarantees. Edge clouds promise a pervasive computational infrastructure a\nshort network hop away from end devices, but today's operating systems are a\npoor fit to meet the goals of scalable isolation, dense multi-tenancy, and\npredictable performance required by these emerging applications. In this paper\nwe present EdgeOS, a micro-kernel based operating system that meets these goals\nby blending recent advances in real-time systems and network function\nvirtualization. EdgeOS introduces a Featherweight Process model that offers\nlightweight isolation and supports extreme scalability even under high churn.\nOur architecture provides efficient communication mechanisms, and low-overhead\nper-client isolation. To achieve high performance networking, EdgeOS employs\nkernel bypass paired with the isolation properties of Featherweight Processes.\nWe have evaluated our EdgeOS prototype for running high scale network\nmiddleboxes using the Click software router and endpoint applications using\nmemcached. EdgeOS reduces startup latency by 170X compared to Linux processes\nand over five orders of magnitude compared to containers, while providing three\norders of magnitude latency improvement when running 300 to 1000 edge-cloud\nmemcached instances on one server.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 17:31:56 GMT"}], "update_date": "2019-01-07", "authors_parsed": [["Ren", "Yuxin", ""], ["Nitu", "Vlad", ""], ["Liu", "Guyue", ""], ["Parmer", "Gabriel", ""], ["Wood", "Timothy", ""], ["Tchana", "Alain", ""], ["Kennedy", "Riley", ""]]}, {"id": "1901.01340", "submitter": "Viacheslav Dubeyko", "authors": "Viacheslav Dubeyko", "title": "File System in Data-Centric Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The moving computation on the edge or near to data is the new trend that can\nbreak the bandwidth wall and to unleash the power of next generation NVM or SCM\nmemory. File system is the important OS subsystem that plays the role of\nmediator between the user-space application and storage device. The key goal of\nthe file system is to represent the file abstraction and to build the files'\nnamespace. In the current paradigm the file system needs to copy the metadata\nand user data in the DRAM of the host with the goal to access and to modify the\nuser data on the host side. The DAX approach doesn't change the concept but to\nbuild the way to bypass the page cache via the direct access to file's content\nin persistent memory. Generally speaking, for the case of data-centric\ncomputing, the file system needs to solve the opposite task not to copy data\ninto page cache but to deliver the processing activity near data on the storage\ndevice side.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jan 2019 23:10:05 GMT"}], "update_date": "2019-01-08", "authors_parsed": [["Dubeyko", "Viacheslav", ""]]}, {"id": "1901.02450", "submitter": "Houssam-Eddine Zahaf", "authors": "Houssam-Eddine Zahaf (UNIMORE), Nicola Capodieci (UNIMORE), Roberto\n  Cavicchioli (UNIMORE), Marko Bertogna (UNIMORE), Giuseppe Lipari", "title": "A C-DAG task model for scheduling complex real-time tasks on\n  heterogeneous platforms: preemption matters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent commercial hardware platforms for embedded real-time systems feature\nheterogeneous processing units and computing accelerators on the same\nSystem-on-Chip. When designing complex real-time application for such\narchitectures, the designer needs to make a number of difficult choices: on\nwhich processor should a certain task be implemented? Should a component be\nimplemented in parallel or sequentially? These choices may have a great impact\non feasibility, as the difference in the processor internal architectures\nimpact on the tasks' execution time and preemption cost. To help the designer\nexplore the wide space of design choices and tune the scheduling parameters, in\nthis paper we propose a novel real-time application model, called C-DAG,\nspecifically conceived for heterogeneous platforms. A C-DAG allows to specify\nalternative implementations of the same component of an application for\ndifferent processing engines to be selected off-line, as well as conditional\nbranches to model if-then-else statements to be selected at run-time. We also\npropose a schedulability analysis for the C-DAG model and a heuristic\nallocation algorithm so that all deadlines are respected. Our analysis takes\ninto account the cost of preempting a task, which can be non-negligible on\ncertain processors. We demonstrate the effectiveness of our approach on a large\nset of synthetic experiments by comparing with state of the art algorithms in\nthe literature.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jan 2019 08:37:23 GMT"}], "update_date": "2019-01-10", "authors_parsed": [["Zahaf", "Houssam-Eddine", "", "UNIMORE"], ["Capodieci", "Nicola", "", "UNIMORE"], ["Cavicchioli", "Roberto", "", "UNIMORE"], ["Bertogna", "Marko", "", "UNIMORE"], ["Lipari", "Giuseppe", ""]]}, {"id": "1901.06360", "submitter": "Kyle Hale", "authors": "Kyle C. Hale, Conor Hetland, and Peter Dinda", "title": "Multiverse: Easy Conversion of Runtime Systems into OS Kernels via\n  Automatic Hybridization", "comments": "Published in the Proceedings of the 14th International Conference on\n  Autonomic Computing (ICAC '17)", "journal-ref": null, "doi": "10.1109/ICAC.2017.24", "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hybrid runtime (HRT) model offers a path towards high performance and\nefficiency. By integrating the OS kernel, runtime, and application, an HRT\nallows the runtime developer to leverage the full feature set of the hardware\nand specialize OS services to the runtime's needs. However, conforming to the\nHRT model currently requires a port of the runtime to the kernel level, for\nexample to the Nautilus kernel framework, and this requires knowledge of kernel\ninternals. In response, we developed Multiverse, a system that bridges the gap\nbetween a built-from-scratch HRT and a legacy runtime system. Multiverse allows\nunmodified applications and runtimes to be brought into the HRT model without\nany porting effort whatsoever by splitting the execution of the application\nbetween the domains of a legacy OS and an HRT environment. We describe the\ndesign and implementation of Multiverse and illustrate its capabilities using\nthe massive, widely-used Racket runtime system.\n", "versions": [{"version": "v1", "created": "Fri, 18 Jan 2019 18:01:38 GMT"}], "update_date": "2019-01-21", "authors_parsed": [["Hale", "Kyle C.", ""], ["Hetland", "Conor", ""], ["Dinda", "Peter", ""]]}, {"id": "1901.07732", "submitter": "Paul Ratazzi", "authors": "Paul Ratazzi, Ashok Bommisetti, Nian Ji and Wenliang Du", "title": "PINPOINT: Efficient and Effective Resource Isolation for Mobile Security\n  and Privacy", "comments": "Mobile Security Technologies (MoST) Workshop, May 21, 2015,\n  http://www.ieee-security.org/TC/SPW2015/MoST/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualization is frequently used to isolate untrusted processes and control\ntheir access to sensitive resources. However, isolation usually carries a price\nin terms of less resource sharing and reduced inter-process communication. In\nan open architecture such as Android, this price and its impact on performance,\nusability, and transparency must be carefully considered. Although previous\nefforts in developing general-purpose isolation solutions have shown that some\nof these negative side effects can be mitigated, doing so involves overcoming\nsignificant design challenges by incorporating numerous additional platform\ncomplexities not directly related to improved security. Thus, the general\npurpose solutions become inefficient and burdensome if the end-user has only\nspecific security goals. In this paper, we present PINPOINT, a resource\nisolation strategy that forgoes general-purpose solutions in favor of a\n\"building block\" approach that addresses specific end-user security goals.\nPINPOINT embodies the concept of Linux Namespace lightweight isolation, but\ndoes so in the Android Framework by guiding the security designer towards\nisolation points that are contextually close to the resource(s) that need to be\nisolated. This strategy allows the rest of the Framework to function fully as\nintended, transparently. We demonstrate our strategy with a case study on\nAndroid System Services, and show four applications of PINPOINTed system\nservices functioning with unmodified market apps. Our evaluation results show\nthat practical security and privacy advantages can be gained using our\napproach, without inducing the problematic side-effects that other\ngeneral-purpose designs must address.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jan 2019 05:41:42 GMT"}], "update_date": "2019-01-24", "authors_parsed": [["Ratazzi", "Paul", ""], ["Bommisetti", "Ashok", ""], ["Ji", "Nian", ""], ["Du", "Wenliang", ""]]}, {"id": "1901.08338", "submitter": "Gernot Heiser", "authors": "Gernot Heiser and Gerwin Klein and Toby Murray", "title": "Can We Prove Time Protection?", "comments": "6 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Timing channels are a significant and growing security threat in computer\nsystems, with no established solution. We have recently argued that the OS must\nprovide time protection, in analogy to the established memory protection, to\nprotect applications from information leakage through timing channels. Based on\na recently-proposed implementation of time protection in the seL4 microkernel,\nwe investigate how such an implementation could be formally proved to prevent\ntiming channels. We postulate that this should be possible by reasoning about a\nhighly abstracted representation of the shared hardware resources that cause\ntiming channels.\n", "versions": [{"version": "v1", "created": "Thu, 24 Jan 2019 10:44:31 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Heiser", "Gernot", ""], ["Klein", "Gerwin", ""], ["Murray", "Toby", ""]]}, {"id": "1901.10664", "submitter": "Paul Emmerich", "authors": "Paul Emmerich, Maximilian Pudelko, Simon Bauer, Stefan Huber, Thomas\n  Zwickl, Georg Carle", "title": "User Space Network Drivers", "comments": "in ACM/IEEE Symposium on Architectures for Networking and\n  Communications Systems (ANCS 2019), 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of user space packet processing frameworks like DPDK and netmap\nmakes low-level code more accessible to developers and researchers. Previously,\ndriver code was hidden in the kernel and rarely modified, or even looked at, by\ndevelopers working at higher layers. These barriers are gone nowadays, yet\ndevelopers still treat user space drivers as black-boxes magically accelerating\napplications. We want to change this: every researcher building high-speed\nnetwork applications should understand the intricacies of the underlying\ndrivers, especially if they impact performance. We present ixy, a user space\nnetwork driver designed for simplicity and educational purposes to show that\nfast packet IO is not black magic but careful engineering. ixy focuses on the\nbare essentials of user space packet processing: a packet forwarder including\nthe whole NIC driver uses less than 1,000 lines of C code.\n  This paper is partially written in tutorial style on the case study of our\nimplementations of drivers for both the Intel 82599 family and for virtual\nVirtIO NICs. The former allows us to reason about driver and framework\nperformance on a stripped-down implementation to assess individual\noptimizations in isolation. VirtIO support ensures that everyone can run it in\na virtual machine.\n  Our code is available as free and open source under the BSD license at\nhttps://github.com/emmericp/ixy\n", "versions": [{"version": "v1", "created": "Wed, 30 Jan 2019 04:10:01 GMT"}, {"version": "v2", "created": "Sun, 8 Sep 2019 15:33:45 GMT"}], "update_date": "2019-09-10", "authors_parsed": [["Emmerich", "Paul", ""], ["Pudelko", "Maximilian", ""], ["Bauer", "Simon", ""], ["Huber", "Stefan", ""], ["Zwickl", "Thomas", ""], ["Carle", "Georg", ""]]}]