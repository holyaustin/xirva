[{"id": "1708.00544", "submitter": "Jeremy Kepner", "authors": "Michael Jones, Jeremy Kepner, William Arcand, David Bestor, Bill\n  Bergeron, Vijay Gadepally, Michael Houle, Matthew Hubbell, Peter Michaleas,\n  Andrew Prout, Albert Reuther, Siddharth Samsi, Paul Monticiollo", "title": "Performance Measurements of Supercomputing and Cloud Storage Solutions", "comments": "5 pages, 4 figures, to appear in IEEE HPEC 2017", "journal-ref": null, "doi": "10.1109/HPEC.2017.8091073", "report-no": null, "categories": "cs.DC astro-ph.IM cs.NI cs.OS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing amounts of data from varied sources, particularly in the fields of\nmachine learning and graph analytics, are causing storage requirements to grow\nrapidly. A variety of technologies exist for storing and sharing these data,\nranging from parallel file systems used by supercomputers to distributed block\nstorage systems found in clouds. Relatively few comparative measurements exist\nto inform decisions about which storage systems are best suited for particular\ntasks. This work provides these measurements for two of the most popular\nstorage technologies: Lustre and Amazon S3. Lustre is an open-source, high\nperformance, parallel file system used by many of the largest supercomputers in\nthe world. Amazon's Simple Storage Service, or S3, is part of the Amazon Web\nServices offering, and offers a scalable, distributed option to store and\nretrieve data from anywhere on the Internet. Parallel processing is essential\nfor achieving high performance on modern storage systems. The performance tests\nused span the gamut of parallel I/O scenarios, ranging from single-client,\nsingle-node Amazon S3 and Lustre performance to a large-scale, multi-client\ntest designed to demonstrate the capabilities of a modern storage appliance\nunder heavy load. These results show that, when parallel I/O is used correctly\n(i.e., many simultaneous read or write processes), full network bandwidth\nperformance is achievable and ranged from 10 gigabits/s over a 10 GigE S3\nconnection to 0.35 terabits/s using Lustre on a 1200 port 10 GigE switch. These\nresults demonstrate that S3 is well-suited to sharing vast quantities of data\nover the Internet, while Lustre is well-suited to processing large quantities\nof data locally.\n", "versions": [{"version": "v1", "created": "Tue, 1 Aug 2017 22:48:06 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Jones", "Michael", ""], ["Kepner", "Jeremy", ""], ["Arcand", "William", ""], ["Bestor", "David", ""], ["Bergeron", "Bill", ""], ["Gadepally", "Vijay", ""], ["Houle", "Michael", ""], ["Hubbell", "Matthew", ""], ["Michaleas", "Peter", ""], ["Prout", "Andrew", ""], ["Reuther", "Albert", ""], ["Samsi", "Siddharth", ""], ["Monticiollo", "Paul", ""]]}, {"id": "1708.06450", "submitter": "Mahoukp\\'ego Parfait Tokponnon", "authors": "Mahoukp\\'ego Parfait Tokponnon, Marc Lobelle, Eugene C. Ezin", "title": "Entirely protecting operating systems against transient errors in space\n  environment", "comments": "2 pages, 4 figures, Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we propose a mainly-software hardening technique to totally\nprotect unmodified running operating systems on COTS hardware against transient\nerrors in heavily radiation - flooded environment like high altitude space. The\ntechnique is currently being implemented in a hypervisor and allows to control\nthe upper layers of the software stack (operating system and applications). The\nrest of the system, the hypervisor, will be protected by other means, thus\nresulting in a completely protected system against transient errors. The\ninduced overhead turns around 200% but this is expected to decrease with future\nimprovements.\n", "versions": [{"version": "v1", "created": "Mon, 21 Aug 2017 23:10:59 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Tokponnon", "Mahoukp\u00e9go Parfait", ""], ["Lobelle", "Marc", ""], ["Ezin", "Eugene C.", ""]]}, {"id": "1708.06931", "submitter": "Christian M. Fuchs", "authors": "Christian M. Fuchs, Todor Stefanov, Nadia Murillo, Aske Plaat", "title": "Bringing Fault-Tolerant GigaHertz-Computing to Space: A Multi-Stage\n  Software-Side Fault-Tolerance Approach for Miniaturized Spacecraft", "comments": "26th IEEE Asian Test Symposium 2017, 27-30 Nov 2017, Taipei City,\n  Taiwan", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern embedded technology is a driving factor in satellite miniaturization,\ncontributing to a massive boom in satellite launches and a rapidly evolving new\nspace industry. Miniaturized satellites, however, suffer from low reliability,\nas traditional hardware-based fault-tolerance (FT) concepts are ineffective for\non-board computers (OBCs) utilizing modern systems-on-a-chip (SoC). Therefore,\nlarger satellites continue to rely on proven processors with large feature\nsizes. Software-based concepts have largely been ignored by the space industry\nas they were researched only in theory, and have not yet reached the level of\nmaturity necessary for implementation. We present the first integral,\nreal-world solution to enable fault-tolerant general-purpose computing with\nmodern multiprocessor-SoCs (MPSoCs) for spaceflight, thereby enabling their use\nin future high-priority space missions. The presented multi-stage approach\nconsists of three FT stages, combining coarse-grained thread-level distributed\nself-validation, FPGA reconfiguration, and mixed criticality to assure\nlong-term FT and excellent scalability for both resource constrained and\ncritical high-priority space missions. Early benchmark results indicate a\ndrastic performance increase over state-of-the-art radiation-hard OBC designs\nand considerably lower software- and hardware development costs. This approach\nwas developed for a 4-year European Space Agency (ESA) project, and we are\nimplementing a tiled MPSoC prototype jointly with two industrial partners.\n", "versions": [{"version": "v1", "created": "Wed, 23 Aug 2017 09:31:28 GMT"}], "update_date": "2019-02-26", "authors_parsed": [["Fuchs", "Christian M.", ""], ["Stefanov", "Todor", ""], ["Murillo", "Nadia", ""], ["Plaat", "Aske", ""]]}, {"id": "1708.09334", "submitter": "Theofilos Petsios", "authors": "Theofilos Petsios, Adrian Tang, Dimitris Mitropoulos, Salvatore\n  Stolfo, Angelos D. Keromytis, and Suman Jana", "title": "Tug-of-War: Observations on Unified Content Handling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern applications and Operating Systems vary greatly with respect to how\nthey register and identify different types of content. These discrepancies lead\nto exploits and inconsistencies in user experience. In this paper, we highlight\nthe issues arising in the modern content handling ecosystem, and examine how\nthe operating system can be used to achieve unified and consistent content\nidentification.\n", "versions": [{"version": "v1", "created": "Tue, 29 Aug 2017 10:24:40 GMT"}], "update_date": "2017-08-31", "authors_parsed": [["Petsios", "Theofilos", ""], ["Tang", "Adrian", ""], ["Mitropoulos", "Dimitris", ""], ["Stolfo", "Salvatore", ""], ["Keromytis", "Angelos D.", ""], ["Jana", "Suman", ""]]}]