[{"id": "1801.02833", "submitter": "Matthias W\\\"ahlisch", "authors": "Martine Lenders, Peter Kietzmann, Oliver Hahm, Hauke Petersen, Cenk\n  G\\\"undo\\u{g}an, Emmanuel Baccelli, Kaspar Schleiser, Thomas C. Schmidt,\n  Matthias W\\\"ahlisch", "title": "Connecting the World of Embedded Mobiles: The RIOT Approach to\n  Ubiquitous Networking for the Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is rapidly evolving based on low-power compliant\nprotocol standards that extend the Internet into the embedded world. Pioneering\nimplementations have proven it is feasible to inter-network very constrained\ndevices, but had to rely on peculiar cross-layered designs and offer a\nminimalistic set of features. In the long run, however, professional use and\nmassive deployment of IoT devices require full-featured, cleanly composed, and\nflexible network stacks.\n  This paper introduces the networking architecture that turns RIOT into a\npowerful IoT system, to enable low-power wireless scenarios. RIOT networking\noffers (i) a modular architecture with generic interfaces for plugging in\ndrivers, protocols, or entire stacks, (ii) support for multiple heterogeneous\ninterfaces and stacks that can concurrently operate, and (iii) GNRC, its\ncleanly layered, recursively composed default network stack. We contribute an\nin-depth analysis of the communication performance and resource efficiency of\nRIOT, both on a micro-benchmarking level as well as by comparing IoT\ncommunication across different platforms. Our findings show that, though it is\nbased on significantly different design trade-offs, the networking subsystem of\nRIOT achieves a performance equivalent to that of Contiki and TinyOS, the two\noperating systems which pioneered IoT software platforms.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 08:28:11 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Lenders", "Martine", ""], ["Kietzmann", "Peter", ""], ["Hahm", "Oliver", ""], ["Petersen", "Hauke", ""], ["G\u00fcndo\u011fan", "Cenk", ""], ["Baccelli", "Emmanuel", ""], ["Schleiser", "Kaspar", ""], ["Schmidt", "Thomas C.", ""], ["W\u00e4hlisch", "Matthias", ""]]}, {"id": "1801.04565", "submitter": "Deepak Garg", "authors": "Eslam Elnikety, Deepak Garg, Peter Druschel", "title": "Shai: Enforcing Data-Specific Policies with Near-Zero Runtime Overhead", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data retrieval systems such as online search engines and online social\nnetworks must comply with the privacy policies of personal and selectively\nshared data items, regulatory policies regarding data retention and censorship,\nand the provider's own policies regarding data use. Enforcing these policies is\ndifficult and error-prone. Systematic techniques to enforce policies are either\nlimited to type-based policies that apply uniformly to all data of the same\ntype, or incur significant runtime overhead.\n  This paper presents Shai, the first system that systematically enforces\ndata-specific policies with near-zero overhead in the common case. Shai's key\nidea is to push as many policy checks as possible to an offline, ahead-of-time\nanalysis phase, often relying on predicted values of runtime parameters such as\nthe state of access control lists or connected users' attributes. Runtime\ninterception is used sparingly, only to verify these predictions and to make\nany remaining policy checks. Our prototype implementation relies on efficient,\nmodern OS primitives for sandboxing and isolation. We present the design of\nShai and quantify its overheads on an experimental data indexing and search\npipeline based on the popular search engine Apache Lucene.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 14:31:46 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Elnikety", "Eslam", ""], ["Garg", "Deepak", ""], ["Druschel", "Peter", ""]]}, {"id": "1801.05637", "submitter": "Nikolas Ioannou", "authors": "Nikolas Ioannou, Kornilios Kourtis, and Ioannis Koltsidas", "title": "Elevating commodity storage with the SALSA host translation layer", "comments": "Presented at 2018 IEEE 26th International Symposium on Modeling,\n  Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS)", "journal-ref": null, "doi": "10.1109/MASCOTS.2018.00035", "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To satisfy increasing storage demands in both capacity and performance,\nindustry has turned to multiple storage technologies, including Flash SSDs and\nSMR disks. These devices employ a translation layer that conceals the\nidiosyncrasies of their mediums and enables random access. Device translation\nlayers are, however, inherently constrained: resources on the drive are scarce,\nthey cannot be adapted to application requirements, and lack visibility across\nmultiple devices. As a result, performance and durability of many storage\ndevices is severely degraded.\n  In this paper, we present SALSA: a translation layer that executes on the\nhost and allows unmodified applications to better utilize commodity storage.\nSALSA supports a wide range of single- and multi-device optimizations and,\nbecause is implemented in software, can adapt to specific workloads. We\ndescribe SALSA's design, and demonstrate its significant benefits using\nmicrobenchmarks and case studies based on three applications: MySQL, the Swift\nobject store, and a video server.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 12:28:30 GMT"}, {"version": "v2", "created": "Thu, 10 Jan 2019 12:39:27 GMT"}], "update_date": "2019-01-11", "authors_parsed": [["Ioannou", "Nikolas", ""], ["Kourtis", "Kornilios", ""], ["Koltsidas", "Ioannis", ""]]}, {"id": "1801.07880", "submitter": "Ying Ye", "authors": "Ying Ye, Zhuoqun Cheng, Soham Sinha, Richard West", "title": "vLibOS: Babysitting OS Evolution with a Virtualized Library OS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many applications have service requirements that are not easily met by\nexisting operating systems. Real-time and security-critical tasks, for example,\noften require custom OSes to meet their needs. However, development of special\npurpose OSes is a time-consuming and difficult exercise. Drivers, libraries and\napplications have to be written from scratch or ported from existing sources.\nMany researchers have tackled this problem by developing ways to extend\nexisting systems with application-specific services. However, it is often\ndifficult to ensure an adequate degree of separation between legacy and new\nservices, especially when security and timing requirements are at stake.\nVirtualization, for example, supports logical isolation of separate guest\nservices, but suffers from inadequate temporal isolation of time-critical code\nrequired for real-time systems. This paper presents vLibOS, a master-slave\nparadigm for new systems, whose services are built on legacy code that is\ntemporally and spatially isolated in separate VM domains. Existing OSes are\ntreated as sandboxed libraries, providing legacy services that are requested by\ninter-VM calls, which execute with the time budget of the caller. We evaluate a\nreal-time implementation of vLibOS. Empirical results show that vLibOS achieves\nas much as a 50\\% reduction in performance slowdown for real-time threads, when\ncompeting for a shared memory bus with a Linux VM.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 07:11:22 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Ye", "Ying", ""], ["Cheng", "Zhuoqun", ""], ["Sinha", "Soham", ""], ["West", "Richard", ""]]}, {"id": "1801.08873", "submitter": "Alexander Thomasian", "authors": "Alexander Thomasian", "title": "Mirrored and Hybrid Disk Arrays: Organization, Scheduling, Reliability,\n  and Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Basic mirroring (BM) classified as RAID level 1 replicates data on two disks,\nthus doubling disk access bandwidth for read requests. RAID1/0 is an array of\nBM pairs with balanced loads due to striping. When a disk fails the read load\non its pair is doubled, which results in halving the maximum attainable\nbandwidth. We review RAID1 organizations which attain a balanced load upon disk\nfailure, but as shown by reliability analysis tend to be less reliable than\nRAID1/0. Hybrid disk arrays which store XORed instead of replicated data tend\nto have a higher reliability than mirrored disks, but incur a higher overhead\nin updating data. Read request response time can be improved by processing them\nat a higher priority than writes, since they have a direct effect on\napplication response time. Shortest seek distance and affinity based routing\nboth shorten seek time. Anticipatory arm placement places arms optimally to\nminimize the seek distance. The analysis of RAID1 in normal, degraded, and\nrebuild mode is provided to quantify RAID1/0 performance. We compare the\nreliability of mirrored disk organizations against each other and hybrid disks\nand erasure coded disk arrays.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 15:59:51 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Thomasian", "Alexander", ""]]}, {"id": "1801.09250", "submitter": "Gregory Price", "authors": "Gregory Michael Price", "title": "Virtual Breakpoints for x86/64", "comments": "12 Pages, Presented at BSides Las Vegas 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Efficient, reliable trapping of execution in a program at the desired\nlocation is a linchpin technique for dynamic malware analysis. The progression\nof debuggers and malware is akin to a game of cat and mouse - each are\nconstantly in a state of trying to thwart one another. At the core of most\nefficient debuggers today is a combination of virtual machines and traditional\nbinary modification breakpoints (int3). In this paper, we present a design for\nVirtual Breakpoints. a modification to the x86 MMU which brings breakpoint\nmanagement into hardware alongside page tables. In this paper we demonstrate\nthe fundamental abstraction failures of current trapping methods, and design a\nnew mechanism from the hardware up. This design incorporates lessons learned\nfrom 50 years of virtualization and debugger design to deliver fast, reliable\ntrapping without the pitfalls of traditional binary modification.\n", "versions": [{"version": "v1", "created": "Sun, 28 Jan 2018 17:09:14 GMT"}, {"version": "v2", "created": "Fri, 5 Apr 2019 03:34:15 GMT"}, {"version": "v3", "created": "Tue, 20 Aug 2019 18:53:28 GMT"}], "update_date": "2019-08-22", "authors_parsed": [["Price", "Gregory Michael", ""]]}]