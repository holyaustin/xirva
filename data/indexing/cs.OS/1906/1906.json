[{"id": "1906.00834", "submitter": "Maruthi Rohit Ayyagari", "authors": "Maruthi Rohit Ayyagari", "title": "Cache Contention on Multicore Systems: An Ontology-based Approach", "comments": "6 pages, 3 figures. International Journal of Engineering Trends and\n  Technology 2019", "journal-ref": null, "doi": "10.14445/22312803/IJCTT-V67I5P110", "report-no": null, "categories": "cs.OS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multicore processors have proved to be the right choice for both desktop and\nserver systems because it can support high performance with an acceptable\nbudget expenditure. In this work, we have compared several works in cache\ncontention and found that such works have identified several techniques for\ncache contention other than cache size including FSB, Memory Controller and\nprefetching hardware. We found that Distributed Intensity Online (DIO) is a\nvery promising cache contention algorithm since it can achieve up to 2% from\nthe optimal technique. Moreover, we propose a new framework for cache\ncontention based on resource ontologies. In which ontologies instances will be\nused for communication between diverse processes instead of grasping schedules\nbased on hardware.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jun 2019 14:32:03 GMT"}], "update_date": "2019-06-04", "authors_parsed": [["Ayyagari", "Maruthi Rohit", ""]]}, {"id": "1906.03724", "submitter": "Tegg Sung", "authors": "Tegg Taekyong Sung, Valliappa Chockalingam, Alex Yahja, Bo Ryu", "title": "Neural Heterogeneous Scheduler", "comments": "7 pages. The first two authors contributed equally. ICML 2019\n  Real-world Sequential Decision Making Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access to parallel and distributed computation has enabled researchers and\ndevelopers to improve algorithms and performance in many applications. Recent\nresearch has focused on next generation special purpose systems with multiple\nkinds of coprocessors, known as heterogeneous system-on-chips (SoC). In this\npaper, we introduce a method to intelligently schedule--and learn to\nschedule--a stream of tasks to available processing elements in such a system.\nWe use deep reinforcement learning enabling complex sequential decision making\nand empirically show that our reinforcement learning system provides for a\nviable, better alternative to conventional scheduling heuristics with respect\nto minimizing execution time.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jun 2019 22:15:19 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Sung", "Tegg Taekyong", ""], ["Chockalingam", "Valliappa", ""], ["Yahja", "Alex", ""], ["Ryu", "Bo", ""]]}, {"id": "1906.07124", "submitter": "GangUk Lee", "authors": "Ganguk Lee, Yeaseul Park, Jeongseob Ahn, Youngjin Kwon", "title": "Slicing the IO execution with ReLayTracer", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Analyzing IO performance anomalies is a crucial task in various computing\nenvironments, ranging from large-scale cloud applications to desktop\napplications. However, the IO stack of modern operating systems is complicated,\nmaking it hard to understand the performance anomalies with existing tools.\nKernel IO executions are frequently interrupted by internal kernel activities,\nrequiring a sophisticated IO profile tool to deal with the noises. Furthermore,\ncomplicated interactions of concurrent IO requests cause different sources of\ntail latencies in kernel IO stack. As a consequence, developers want to know\nfine-grained latency profile across IO layers, which may differ in each IO\nrequests. To meet the requirements, this paper suggests ReLayTracer, a\nper-request, per-layer IO profiler. ReLayTracer enables a detailed analysis to\nidentify root causes of IO performance anomalies by providing per-layer latency\ndistributions of each IO request, hardware performance behavior, and time spent\nby kernel activities such as an interrupt.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jun 2019 16:49:56 GMT"}], "update_date": "2019-06-18", "authors_parsed": [["Lee", "Ganguk", ""], ["Park", "Yeaseul", ""], ["Ahn", "Jeongseob", ""], ["Kwon", "Youngjin", ""]]}, {"id": "1906.09799", "submitter": "Valerio Schiavoni Dr", "authors": "Julien Amacher and Valerio Schiavoni", "title": "On The Performance of ARM TrustZone", "comments": "25 pages, extended version for version appeared in IFIP DAIS 2019.\n  European Commission Project: LEGaTO - Low Energy Toolset for Heterogeneous\n  Computing (EC-H2020-780681)", "journal-ref": null, "doi": "10.1007/978-3-030-22496-7_9", "report-no": null, "categories": "cs.OS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The TrustZone technology, available in the vast majority of recent ARM\nprocessors, allows the execution of code inside a so-called secure world. It\neffectively provides hardware-isolated areas of the processor for sensitive\ndata and code, i.e., a trusted execution environment (TEE). The OP-TEE\nframework provides a collection of toolchain, open-source libraries and secure\nkernel specifically geared to develop applications for TrustZone. This paper\npresents an in-depth performance- and energy-wise study of TrustZone using the\nOP-TEE framework, including secure storage and the cost of switching between\nsecure and unsecure worlds, using emulated and hardware measurements.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 09:11:18 GMT"}, {"version": "v2", "created": "Wed, 26 Jun 2019 15:24:10 GMT"}], "update_date": "2019-06-27", "authors_parsed": [["Amacher", "Julien", ""], ["Schiavoni", "Valerio", ""]]}, {"id": "1906.10239", "submitter": "Jan S. Rellermeyer", "authors": "Jan S. Rellermeyer, Maher Amer, Richard Smutzer, Karthick Rajamani", "title": "Container Density Improvements with Dynamic Memory Extension using NAND\n  Flash", "comments": "APSys 2018", "journal-ref": null, "doi": "10.1145/3265723.3265740", "report-no": null, "categories": "cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While containers efficiently implement the idea of operating-system-level\napplication virtualization, they are often insufficient to increase the server\nutilization to a desirable level. The reason is that in practice many\ncontainerized applications experience a limited amount of load while there are\nfew containers with a high load. In such a scenario, the virtual memory\nmanagement system can become the limiting factor to container density even\nthough the working set of active containers would fit into main memory. In this\npaper, we describe and evaluate a system for transparently moving memory pages\nin and out of DRAM and to a NAND Flash medium which is attached through the\nmemory bus. This technique, called Diablo Memory Expansion (DMX), operates on a\nprediction model and is able to relieve the pressure on the memory system. We\npresent a benchmark for container density and show that even under an overall\nconstant workload, adding additional containers adversely affects\nperformance-critical applications in Docker. When using the DMX technology of\nthe Memory1 system, however, the performance of the critical workload remains\nstable.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jun 2019 21:23:18 GMT"}], "update_date": "2019-06-26", "authors_parsed": [["Rellermeyer", "Jan S.", ""], ["Amer", "Maher", ""], ["Smutzer", "Richard", ""], ["Rajamani", "Karthick", ""]]}, {"id": "1906.10860", "submitter": "Adam Lev-Libfeld", "authors": "Adam Lev-Libfeld", "title": "Lawn: an Unbound Low Latency Timer Data Structure for Large Scale, High\n  Throughput Systems", "comments": "6 pages, 2 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As demand for Real-Time applications rises among the general public, the\nimportance of enabling large-scale, unbound algorithms to solve conventional\nproblems with low to no latency is critical for product viability. Timer\nalgorithms are prevalent in the core mechanisms behind operating systems,\nnetwork protocol implementation, stream processing, and several database\ncapabilities. This paper presents a field-tested algorithm for low latency,\nunbound range timer structure, based upon the well excepted Timing Wheel\nalgorithm. Using a set of queues hashed by TTL, the algorithm allows for a\nsimpler implementation, minimal overhead no overflow and no performance\ndegradation in comparison to the current state of the algorithms under typical\nuse cases.\n", "versions": [{"version": "v1", "created": "Wed, 26 Jun 2019 06:16:13 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2019 09:50:24 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Lev-Libfeld", "Adam", ""]]}]