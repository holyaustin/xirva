[{"id": "1810.01139", "submitter": "Javier Verdu", "authors": "Javier Verdu, Juan Jose Costa, Beatriz Otero, Eva Rodriguez, Alex\n  Pajuelo, Ramon Canal", "title": "Platform-Agnostic Steal-Time Measurement in a Guest Operating System", "comments": "4 pages, 6 figures, technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Steal time is a key performance metric for applications executed in a\nvirtualized environment. Steal time measures the amount of time the processor\nis preempted by code outside the virtualized environment. This, in turn, allows\nto compute accurately the execution time of an application inside a virtual\nmachine (i.e. it eliminates the time the virtual machine is suspended).\nUnfortunately, this metric is only available in particular scenarios in which\nthe host and the guest OS are tightly coupled. Typical examples are the Xen\nhypervisor and Linux-based guest OSes. In contrast, in scenarios where the\nsteal time is not available inside the virtualized environment, performance\nmeasurements are, most often, incorrect.\n  In this paper, we introduce a novel and platform agnostic approach to\ncalculate this steal time within the virtualized environment and without the\ncooperation of the host OS. The theoretical execution time of a deterministic\nmicrobenchmark is compared to its execution time in a virtualized environment.\nWhen factoring in the virtual machine load, this solution -as simple as it is-\ncan compute the steal time. The preliminary results show that we are able to\ncompute the load of the physical processor within the virtual machine with high\naccuracy.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2018 09:44:32 GMT"}], "update_date": "2018-10-03", "authors_parsed": [["Verdu", "Javier", ""], ["Costa", "Juan Jose", ""], ["Otero", "Beatriz", ""], ["Rodriguez", "Eva", ""], ["Pajuelo", "Alex", ""], ["Canal", "Ramon", ""]]}, {"id": "1810.01553", "submitter": "David Dice", "authors": "David Dice, Alex Kogan", "title": "BRAVO -- Biased Locking for Reader-Writer Locks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designers of modern reader-writer locks confront a difficult trade-off\nrelated to reader scalability. Locks that have a compact memory representation\nfor active readers will typically suffer under high intensity read-dominated\nworkloads when the \"reader indicator\"' state is updated frequently by a diverse\nset of threads, causing cache invalidation and coherence traffic. Other\ndesigns, such as cohort reader-writer locks, use distributed reader indicators,\none per NUMA node. This improves reader-reader scalability, but also increases\nthe size of each lock instance. We propose a simple transformation BRAVO, that\naugments any existing reader-writer lock, adding just two integer fields to the\nlock instance. Readers make their presence known to writers by hashing their\nthread's identity with the lock address, forming an index into a visible\nreaders table. Readers attempt to install the lock address into that element in\nthe table, making their existence known to potential writers. All locks and\nthreads in an address space can share the visible readers table. Updates by\nreaders tend to be diffused over the table, resulting in a NUMA-friendly\ndesign. Crucially, readers of the same lock tend to write to different\nlocations in the array, reducing coherence traffic. Specifically, BRAVO allows\na simple compact lock to be augmented so as to provide scalable concurrent\nreading but with only a modest increase in footprint.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 00:56:10 GMT"}, {"version": "v2", "created": "Thu, 21 Feb 2019 22:15:12 GMT"}, {"version": "v3", "created": "Wed, 10 Jul 2019 15:52:16 GMT"}], "update_date": "2019-07-11", "authors_parsed": [["Dice", "David", ""], ["Kogan", "Alex", ""]]}, {"id": "1810.01573", "submitter": "David Dice", "authors": "Dave Dice, Alex Kogan", "title": "TWA -- Ticket Locks Augmented with a Waiting Array", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The classic ticket lock consists of ticket and grant fields. Arriving threads\natomically fetch-and-increment ticket and then wait for grant to become equal\nto the value returned by the fetch-and-increment primitive, at which point the\nthread holds the lock. The corresponding unlock operation simply increments\ngrant. This simple design has short code paths and fast handover (transfer of\nownership) under light contention, but may suffer degraded scalability under\nhigh contention when multiple threads busy wait on the grant field -- so-called\nglobal spinning. We propose a variation on ticket locks where long-term waiting\nthreads wait on locations in a waiting array instead of busy waiting on the\ngrant field. The single waiting array is shared among all locks. Short-term\nwaiting is accomplished in the usual manner on the grant field. The resulting\nalgorithm, TWA, improves on ticket locks by limiting the number of threads\nspinning on the grant field at any given time, reducing the number of remote\ncaches requiring invalidation from the store that releases the lock. In turn,\nthis accelerates handover, and since the lock is held throughout the handover\noperation, scalability improves. Under light or no contention, TWA yields\nperformance comparable to the classic ticket lock, avoiding the complexity and\nextra accesses incurred by MCS locks in the handover path, but providing\nperformance above or beyond that of MCS at high contention.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2018 03:27:51 GMT"}, {"version": "v2", "created": "Wed, 7 Nov 2018 22:42:02 GMT"}, {"version": "v3", "created": "Thu, 21 Feb 2019 22:22:04 GMT"}, {"version": "v4", "created": "Wed, 10 Jul 2019 21:59:00 GMT"}], "update_date": "2019-07-12", "authors_parsed": [["Dice", "Dave", ""], ["Kogan", "Alex", ""]]}, {"id": "1810.02904", "submitter": "Jayashree Mohan", "authors": "Jayashree Mohan, Ashlie Martinez, Soujanya Ponnapalli, Pandian Raju,\n  Vijay Chidambaram", "title": "Finding Crash-Consistency Bugs with Bounded Black-Box Crash Testing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to testing file-system crash consistency: bounded\nblack-box crash testing (B3). B3 tests the file system in a black-box manner\nusing workloads of file-system operations. Since the space of possible\nworkloads is infinite, B3 bounds this space based on parameters such as the\nnumber of file-system operations or which operations to include, and\nexhaustively generates workloads within this bounded space. Each workload is\ntested on the target file system by simulating power-loss crashes while the\nworkload is being executed, and checking if the file system recovers to a\ncorrect state after each crash. B3 builds upon insights derived from our study\nof crash-consistency bugs reported in Linux file systems in the last five\nyears. We observed that most reported bugs can be reproduced using small\nworkloads of three or fewer file-system operations on a newly-created file\nsystem, and that all reported bugs result from crashes after fsync() related\nsystem calls. We build two tools, CrashMonkey and ACE, to demonstrate the\neffectiveness of this approach. Our tools are able to find 24 out of the 26\ncrash-consistency bugs reported in the last five years. Our tools also revealed\n10 new crash-consistency bugs in widely-used, mature Linux file systems, seven\nof which existed in the kernel since 2014. Our tools also found a\ncrash-consistency bug in a verified file system, FSCQ. The new bugs result in\nsevere consequences like broken rename atomicity and loss of persisted files.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2018 23:04:23 GMT"}], "update_date": "2018-10-09", "authors_parsed": [["Mohan", "Jayashree", ""], ["Martinez", "Ashlie", ""], ["Ponnapalli", "Soujanya", ""], ["Raju", "Pandian", ""], ["Chidambaram", "Vijay", ""]]}, {"id": "1810.04309", "submitter": "EPTCS", "authors": "Mihir Parang Mehta (UT Austin)", "title": "Formalising Filesystems in the ACL2 Theorem Prover: an Application to\n  FAT32", "comments": "In Proceedings ACL2 2018, arXiv:1810.03762", "journal-ref": "EPTCS 280, 2018, pp. 18-29", "doi": "10.4204/EPTCS.280.2", "report-no": null, "categories": "cs.LO cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an approach towards constructing executable\nspecifications of existing filesystems and verifying their functional\nproperties in a theorem proving environment. We detail an application of this\napproach to the FAT32 filesystem.\n  We also detail the methodology used to build up this type of executable\nspecification through a series of models which incrementally add features of\nthe target filesystem. This methodology has the benefit of allowing the\nverification effort to start from simple models which encapsulate features\ncommon to many filesystems and which are thus suitable for reuse.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 00:35:05 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Mehta", "Mihir Parang", "", "UT Austin"]]}, {"id": "1810.04603", "submitter": "Duwon Hong", "authors": "Duwon Hong, Myungsuk Kim, Jisung Park, Myoungsoo Jung and Jihong Kim", "title": "Revitalizing Copybacks in Modern SSDs: Why and How", "comments": "5 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For modern flash-based SSDs, the performance overhead of internal data\nmigrations is dominated by the data transfer time, not by the flash program\ntime as in old SSDs. In order to mitigate the performance impact of data\nmigrations, we propose rCopyback, a restricted version of copyback. Rcopyback\nworks like the original copyback except that only n consecutive copybacks are\nallowed. By limiting the number of successive copybacks, it guarantees that no\ndata reliability problem occurs when data is internally migrated using\nrCopyback. In order to take a full advantage of rCopyback, we developed a\nrCopyback-aware FTL, rcFTL, which intelligently decides whether rCopyback\nshould be used or not by exploiting varying host workloads. Our evaluation\nresults show that rcFTL can improve the overall I/O throughput by 54% on\naverage over an existing FTL which does not use copybacks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2018 15:49:52 GMT"}], "update_date": "2018-10-11", "authors_parsed": [["Hong", "Duwon", ""], ["Kim", "Myungsuk", ""], ["Park", "Jisung", ""], ["Jung", "Myoungsoo", ""], ["Kim", "Jihong", ""]]}, {"id": "1810.05068", "submitter": "Takumi Shimada", "authors": "Takumi Shimada, Takeshi Yashiro, Ken Sakamura", "title": "T-Visor: A Hypervisor for Mixed Criticality Embedded Real-time System\n  with Hardware Virtualization Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Recently, embedded systems have not only requirements for hard real-time\nbehavior and reliability, but also diversified functional demands, such as\nnetwork functions. To satisfy these requirements, virtualization using\nhypervisors is promising for embedded systems. However, as most of existing\nhypervisors are designed for general-purpose information processing systems,\nthey rely on large system stacks, so that they are not suitable for mixed\ncriticality embedded real-time systems. Even in hypervisors designed for\nembedded systems, their schedulers do not consider the diversity of real-time\nrequirements and rapid change in scheduling theory.\n  We present the design and implementation of T-Visor, a hypervisor specialized\nfor mixed criticality embedded real-time systems. T-Visor supports ARM\narchitecture and realizes full virtualization using ARM Virtualization\nExtensions. To guarantee real-time behavior, T-Visor provides a flexible\nscheduling framework so that developers can select the most suitable scheduling\nalgorithm for their systems. Our evaluation showed that it performed better\ncompared to Xen/ARM. From these results, we conclude that our design and\nimplementation are more suitable for embedded real-time systems than the\nexisting hypervisors.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2018 15:05:44 GMT"}], "update_date": "2018-10-12", "authors_parsed": [["Shimada", "Takumi", ""], ["Yashiro", "Takeshi", ""], ["Sakamura", "Ken", ""]]}, {"id": "1810.05345", "submitter": "Qian Ge", "authors": "Qian Ge, Yuval Yarom, Tom Chothia, Gernot Heiser", "title": "Time Protection: the Missing OS Abstraction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Timing channels enable data leakage that threatens the security of computer\nsystems, from cloud platforms to smartphones and browsers executing untrusted\nthird-party code. Preventing unauthorised information flow is a core duty of\nthe operating system, however, present OSes are unable to prevent timing\nchannels. We argue that OSes must provide time protection in addition to the\nestablished memory protection. We examine the requirements of time protection,\npresent a design and its implementation in the seL4 microkernel, and evaluate\nits efficacy as well as performance overhead on Arm and x86 processors.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 03:54:52 GMT"}, {"version": "v2", "created": "Mon, 15 Oct 2018 23:38:53 GMT"}], "update_date": "2018-10-17", "authors_parsed": [["Ge", "Qian", ""], ["Yarom", "Yuval", ""], ["Chothia", "Tom", ""], ["Heiser", "Gernot", ""]]}, {"id": "1810.05600", "submitter": "David Dice", "authors": "Dave Dice, Alex Kogan", "title": "Compact NUMA-Aware Locks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern multi-socket architectures exhibit non-uniform memory access (NUMA)\nbehavior, where access by a core to data cached locally on a socket is much\nfaster than access to data cached on a remote socket. Prior work offers several\nefficient NUMA-aware locks that exploit this behavior by keeping the lock\nownership on the same socket, thus reducing remote cache misses and\ninter-socket communication. Virtually all those locks, however, are\nhierarchical in their nature, thus requiring space proportional to the number\nof sockets. The increased memory cost renders NUMA-aware locks unsuitable for\nsystems that are conscious to space requirements of their synchronization\nconstructs, with the Linux kernel being the chief example.\n  In this work, we present a compact NUMA-aware lock that requires only one\nword of memory, regardless of the number of sockets in the underlying machine.\nThe new lock is a variant of an efficient (NUMA-oblivious) MCS lock, and\ninherits its performant features, such as local spinning and a single atomic\ninstruction in the acquisition path. Unlike MCS, the new lock organizes waiting\nthreads in two queues, one composed of threads running on the same socket as\nthe current lock holder, and another composed of threads running on a different\nsocket(s).\n  We integrated the new lock in the Linux kernel's qspinlock, one of the major\nsynchronization constructs in the kernel. Our evaluation using both user-space\nand kernel benchmarks shows that the new lock has a single-thread performance\nof MCS, but significantly outperforms the latter under contention, achieving a\nsimilar level of performance when compared to other, state-of-the-art\nNUMA-aware locks that require substantially more space.\n", "versions": [{"version": "v1", "created": "Fri, 12 Oct 2018 16:42:49 GMT"}, {"version": "v2", "created": "Fri, 1 Mar 2019 05:13:22 GMT"}], "update_date": "2019-03-04", "authors_parsed": [["Dice", "Dave", ""], ["Kogan", "Alex", ""]]}]