[{"id": "2105.05590", "submitter": "Jan Staschulat", "authors": "Jan Staschulat (1), Ralph Lange (1), Dakshina Narahari Dasari (1) ((1)\n  Robert Bosch GmbH, Stuttgart, Germany)", "title": "Budget-based real-time Executor for Micro-ROS", "comments": "4 pages, 5 figures, submitted to RTAS conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Robot Operating System (ROS) is a popular robotics middleware framework.\nIn the last years, it underwent a redesign and reimplementation under the name\nROS~2. It now features QoS-configurable communication and a flexible layered\narchitecture. Micro-ROS is a variant developed specifically for\nresource-constrained microcontrollers (MCU). Such MCUs are commonly used in\nrobotics for sensors and actuators, for time-critical control functions, and\nfor safety. While the execution management of ROS 2 has been addressed by an\nExecutor concept, its lack of real-time capabilities make it unsuitable for\nindustrial use. Neither defining an execution order nor the assignment of\nscheduling parameters to tasks is possible, despite the fact that advanced\nreal-time scheduling algorithms are well-known and available in modern RTOS's.\nFor example, the NuttX RTOS supports a variant of the reservation-based\nscheduling which is very attractive for industrial applications: It allows to\nassign execution time budgets to software components so that a system\nintegrator can thereby guarantee the real-time requirements of the entire\nsystem. This paper presents for the first time a ROS~2 Executor design which\nenables the real-time scheduling capabilities of the operating system. In\nparticular, we successfully demonstrate the budget-based scheduling of the\nNuttX RTOS with a micro-ROS application on an STM32 microcontroller.\n", "versions": [{"version": "v1", "created": "Wed, 12 May 2021 11:09:47 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 10:40:07 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Staschulat", "Jan", ""], ["Lange", "Ralph", ""], ["Dasari", "Dakshina Narahari", ""]]}, {"id": "2105.08770", "submitter": "Roy Friedman", "authors": "Gil Einziger and Ohad Eytan and Roy Friedman and Benjamin Manes", "title": "Lightweight Robust Size Aware Cache Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern key-value stores, object stores, Internet proxy caches, as well as\nContent Delivery Networks (CDN) often manage objects of diverse sizes, e.g.,\nblobs, video files of different lengths, images with varying resolution, and\nsmall documents. In such workloads, size-aware cache policies outperform\nsize-oblivious algorithms. Unfortunately, existing size-aware algorithms tend\nto be overly complicated and computationally~expensive.\n  Our work follows a more approachable pattern; we extend the prevalent\n(size-oblivious) TinyLFU cache admission policy to handle variable sized items.\nImplementing our approach inside two popular caching libraries only requires\nminor changes. We show that our algorithms yield competitive or better\nhit-ratios and byte hit-ratios compared to the state of the art size-aware\nalgorithms such as AdaptSize, LHD, LRB, and GDSF. Further, a runtime comparison\nindicates that our implementation is faster by up to x3 compared to the best\nalternative, i.e., it imposes much lower CPU overhead.\n", "versions": [{"version": "v1", "created": "Tue, 18 May 2021 18:35:40 GMT"}, {"version": "v2", "created": "Sun, 23 May 2021 18:41:00 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Einziger", "Gil", ""], ["Eytan", "Ohad", ""], ["Friedman", "Roy", ""], ["Manes", "Benjamin", ""]]}, {"id": "2105.10397", "submitter": "R\\'emi Dulong", "authors": "R\\'emi Dulong, Rafael Pires, Andreia Correia, Valerio Schiavoni, Pedro\n  Ramalhete, Pascal Felber, Ga\\\"el Thomas", "title": "NVCache: A Plug-and-Play NVMM-based I/O Booster for Legacy Systems", "comments": "13 pages, 7 figures, to be published in the 51th IEEE/IFIP\n  International Conference on Dependable Systems and Networks (DSN 21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.OS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces NVCache, an approach that uses a non-volatile main\nmemory (NVMM) as a write cache to improve the write performance of legacy\napplications. We compare NVCache against file systems tailored for NVMM\n(Ext4-DAX and NOVA) and with I/O-heavy applications (SQLite, RocksDB). Our\nevaluation shows that NVCache reaches the performance level of the existing\nstate-of-the-art systems for NVMM, but without their limitations: NVCache does\nnot limit the size of the stored data to the size of the NVMM, and works\ntransparently with unmodified legacy applications, providing additional\npersistence guarantees even when their source code is not available.\n", "versions": [{"version": "v1", "created": "Fri, 14 May 2021 14:08:10 GMT"}], "update_date": "2021-05-24", "authors_parsed": [["Dulong", "R\u00e9mi", ""], ["Pires", "Rafael", ""], ["Correia", "Andreia", ""], ["Schiavoni", "Valerio", ""], ["Ramalhete", "Pedro", ""], ["Felber", "Pascal", ""], ["Thomas", "Ga\u00ebl", ""]]}, {"id": "2105.13894", "submitter": "Paulo Silva Feitosa", "authors": "Paulo Silva, Thiago Emmanuel Pereira", "title": "Performance Evaluation of Snapshot Methods to Warm the Serverless Cold\n  Start", "comments": "in Portuguese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The serverless computing model strengthens the cloud computing tendency to\nabstract resource management. Serverless platforms are responsible for\ndeploying and scaling the developer's applications. Serverless also\nincorporated the pay-as-you-go billing model, which only considers the time\nspent processing client requests. Such a decision created a natural incentive\nfor improving the platform's efficient resource usage. This search for\nefficiency can lead to the cold start problem, which represents a delay to\nexecute serverless applications. Among the solutions proposed to deal with the\ncold start, those based on the snapshot method stand out. Despite the rich\nexploration of the technique, there is a lack of research that evaluates the\nsolution's trade-offs. In this direction, this work compares two solutions to\nmitigate the cold start: Prebaking and SEUSS. We analyzed the solution's\nperformance with functions of different levels of complexity: NoOp, a function\nthat renders Markdown to HTML, and a function that loads 41 MB of dependencies.\nPreliminary results indicated that Prebaking showed a 33% and 25% superior\nperformance to startup the NoOp and Markdown functions, respectively. Further\nanalysis also revealed that Prebaking's warmup mechanism reduced the Markdown\nfirst request processing time by 69%.\n", "versions": [{"version": "v1", "created": "Fri, 28 May 2021 14:57:49 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Silva", "Paulo", ""], ["Pereira", "Thiago Emmanuel", ""]]}]