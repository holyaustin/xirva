[{"id": "1903.01314", "submitter": "Michael Bechtel", "authors": "Michael G Bechtel and Heechul Yun", "title": "Denial-of-Service Attacks on Shared Cache in Multicore: Analysis and\n  Prevention", "comments": "To be published as a conference paper at RTAS 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the feasibility of denial-of-service (DoS)\nattacks on shared caches in multicore platforms. With carefully engineered\nattacker tasks, we are able to cause more than 300X execution time increases on\na victim task running on a dedicated core on a popular embedded multicore\nplatform, regardless of whether we partition its shared cache or not. Based on\ncareful experimentation on real and simulated multicore platforms, we identify\nan internal hardware structure of a non-blocking cache, namely the cache\nwriteback buffer, as a potential target of shared cache DoS attacks. We propose\nan OS-level solution to prevent such DoS attacks by extending a\nstate-of-the-art memory bandwidth regulation mechanism. We implement the\nproposed mechanism in Linux on a real multicore platform and show its\neffectiveness in protecting against cache DoS attacks.\n", "versions": [{"version": "v1", "created": "Mon, 4 Mar 2019 15:48:00 GMT"}], "update_date": "2019-03-05", "authors_parsed": [["Bechtel", "Michael G", ""], ["Yun", "Heechul", ""]]}, {"id": "1903.01950", "submitter": "Marcela Melara", "authors": "Marcela S. Melara, David H. Liu, and Michael J. Freedman", "title": "Pyronia: Intra-Process Access Control for IoT Applications", "comments": "19 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Third-party code plays a critical role in IoT applications, which generate\nand analyze highly privacy-sensitive data. Unlike traditional desktop and\nserver settings, IoT devices mostly run a dedicated, single application. As a\nresult, vulnerabilities in third-party libraries within a process pose a much\nbigger threat than on traditional platforms.\n  We present Pyronia, a fine-grained access control system for IoT applications\nwritten in high-level languages. Pyronia exploits developers' coarse-grained\nexpectations about how imported third-party code operates to restrict access to\nfiles, devices, and specific network destinations, at the granularity of\nindividual functions. To efficiently protect such sensitive OS resources,\nPyronia combines three techniques: system call interposition, stack inspection,\nand memory domains. This design avoids the need for application refactoring, or\nunintuitive data flow analysis, while enforcing the developer's access policy\nat run time. Our Pyronia prototype for Python runs on a custom Linux kernel,\nand incurs moderate performance overhead on unmodified Python applications.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 17:35:03 GMT"}, {"version": "v2", "created": "Wed, 20 Nov 2019 21:28:47 GMT"}], "update_date": "2019-11-22", "authors_parsed": [["Melara", "Marcela S.", ""], ["Liu", "David H.", ""], ["Freedman", "Michael J.", ""]]}, {"id": "1903.01955", "submitter": "Peter Braam", "authors": "Peter Braam", "title": "The Lustre Storage Architecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This lengthy document often referred to as the \"Lustre Book\", contains a\ndetailed outline of Lustre file system architecture, as it was created between\n2001 and 2005, in accordance with the requirements from various users. Now, in\n2019, most features have been implemented, but some only recently, and some\nalong different lines of thought.\n", "versions": [{"version": "v1", "created": "Tue, 5 Mar 2019 17:40:38 GMT"}], "update_date": "2019-03-06", "authors_parsed": [["Braam", "Peter", ""]]}, {"id": "1903.03701", "submitter": "Viacheslav Dubeyko", "authors": "Viacheslav Dubeyko", "title": "Processor in Non-Volatile Memory (PiNVSM): Towards to Data-centric\n  Computing in Decentralized Environment", "comments": "arXiv admin note: text overlap with arXiv:1805.09612 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AI problem has no solution in the environment of existing hardware stack\nand OS architecture. CPU-centric model of computation has a huge number of\ndrawbacks that originate from memory hierarchy and obsolete architecture of the\ncomputing core. The concept of mixing memory and logic has been around since\n1960s. However, the concept of Processor-In-Memory (PIM) is unable to resolve\nthe critical issues of the CPU-centric computing model because of inevitable\nreplication of von Neumann architecture's drawbacks. The next generation of\nNVM/SCM memory is able to give the second birth to the data-centric computing\nparadigm. This paper presents a concept of Processor in Non-Volatile Memory\n(PiNVSM) architecture. The basis of PiNVSM architecture is the concept of DPU\nthat contains the NVM memory and dedicated PU. All necessary PU's registers can\nbe implemented in the space of NVM memory. NVM memory of DPU is the single\nspace for storing and transformation of data. In the basis of PiNVSM\narchitecture lies the DPU array is able to overcome the limitations as Turing\nmachine model as von Neumann architecture. The DPU array hasn't a centralized\ncomputing core. Every data portion has dedicated computing core that excludes\nthe necessity to transfer data to the place of data processing. Every DPU\ncontains data portion that is associated with the set of keywords. Any complex\ndata structure can be split on elementary items that can be stored into\nindependent DPU with dedicated computing core(s). One DPU is able to apply the\nelementary transformation on one item. But the DPU array is able to make the\ntransformation of complex structure by means of concurrent execution of\nelementary transformations in different DPUs. The PiNVSM architecture suggests\na principally new architecture of the computing core that creates a new\nopportunity for data self-organization, data and code synthesis.\n", "versions": [{"version": "v1", "created": "Fri, 8 Mar 2019 23:58:52 GMT"}], "update_date": "2019-03-20", "authors_parsed": [["Dubeyko", "Viacheslav", ""]]}, {"id": "1903.04075", "submitter": "Viacheslav Dubeyko", "authors": "Viacheslav Dubeyko, Om Rameshwar Gatla, Mai Zheng", "title": "Nature of System Calls in CPU-centric Computing Paradigm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern operating systems are typically POSIX-compliant with major system\ncalls specified decades ago. The next generation of non-volatile memory (NVM)\ntechnologies raise concerns about the efficiency of the traditional POSIX-based\nsystems. As one step toward building high performance NVM systems, we explore\nthe potential dependencies between system call performance and major hardware\ncomponents (e.g., CPU, memory, storage) under typical user cases (e.g.,\nsoftware compilation, installation, web browser, office suite) in this paper.\nWe build histograms for the most frequent and time-consuming system calls with\nthe goal to understand the nature of distribution on different platforms. We\nfind that there is a strong dependency between the system call performance and\nthe CPU architecture. On the other hand, the type of persistent storage plays a\nless important role in affecting the performance.\n", "versions": [{"version": "v1", "created": "Sun, 10 Mar 2019 23:34:14 GMT"}], "update_date": "2019-03-12", "authors_parsed": [["Dubeyko", "Viacheslav", ""], ["Gatla", "Om Rameshwar", ""], ["Zheng", "Mai", ""]]}, {"id": "1903.06889", "submitter": "Hsuan-Chi Kuo", "authors": "Hsuan-Chi Kuo, Akshith Gunasekaran, Yeongjin Jang, Sibin Mohan, Rakesh\n  B. Bobba, David Lie and Jesse Walker", "title": "MultiK: A Framework for Orchestrating Multiple Specialized Kernels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present, MultiK, a Linux-based framework 1 that reduces the attack surface\nfor operating system kernels by reducing code bloat. MultiK \"orchestrates\"\nmultiple kernels that are specialized for individual applications in a\ntransparent manner. This framework is flexible to accommodate different kernel\ncode reduction techniques and, most importantly, run the specialized kernels\nwith near-zero additional runtime overheads. MultiK avoids the overheads of\nvirtualization and runs natively on the system. For instance, an Apache\ninstance is shown to run on a kernel that has (a) 93.68% of its code reduced,\n(b) 19 of 23 known kernel vulnerabilities eliminated and (c) with negligible\nperformance overheads (0.19%). MultiK is a framework that can integrate with\nexisting code reduction and OS security techniques. We demonstrate this by\nusing D-KUT and S-KUT -- two methods to profile and eliminate unwanted kernel\ncode. The whole process is transparent to the user applications because MultiK\ndoes not require a recompilation of the application.\n", "versions": [{"version": "v1", "created": "Sat, 16 Mar 2019 07:17:47 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Kuo", "Hsuan-Chi", ""], ["Gunasekaran", "Akshith", ""], ["Jang", "Yeongjin", ""], ["Mohan", "Sibin", ""], ["Bobba", "Rakesh B.", ""], ["Lie", "David", ""], ["Walker", "Jesse", ""]]}, {"id": "1903.09310", "submitter": "Fabien Bouquillon", "authors": "Fabien Bouquillon, Cl\\'ement Ballabriga, Giuseppe Lipari, Smail Niar", "title": "A WCET-aware cache coloring technique for reducing interference in\n  real-time systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The predictability of a system is the condition to give saferbound on worst\ncase execution timeof real-time tasks which are running on it. Commercial\noff-the-shelf(COTS) processors are in-creasingly used in embedded systems and\ncontain shared cache memory. This component hasa hard predictable behavior\nbecause its state depends of theexecution history of the systems.To increase\npredictability of COTS component we use cache coloring, a technique widely\nusedto partition cache memory. Our main contribution is a WCET aware heuristic\nwhich parti-tion task according to the needs of each task. Our experiments are\nmade with CPLEX an ILPsolver with random tasks set generated running on\npreemptive system scheduled with earliestdeadline first(EDF).\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 13:08:13 GMT"}, {"version": "v2", "created": "Tue, 26 Mar 2019 15:56:22 GMT"}, {"version": "v3", "created": "Wed, 27 Mar 2019 16:00:02 GMT"}, {"version": "v4", "created": "Mon, 20 May 2019 16:35:52 GMT"}], "update_date": "2019-05-21", "authors_parsed": [["Bouquillon", "Fabien", ""], ["Ballabriga", "Cl\u00e9ment", ""], ["Lipari", "Giuseppe", ""], ["Niar", "Smail", ""]]}, {"id": "1903.09347", "submitter": "Maria F. Borge", "authors": "Mar\\'ia F. Borge, Florin Dinu, Willy Zwaenepoel", "title": "Understanding and taming SSD read performance variability: HDFS case\n  study", "comments": "13 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we analyze the influence that lower layers (file system, OS,\nSSD) have on HDFS' ability to extract maximum performance from SSDs on the read\npath. We uncover and analyze three surprising performance slowdowns induced by\nlower layers that result in HDFS read throughput loss. First, intrinsic\nslowdown affects reads from every new file system extent for a variable amount\nof time. Second, temporal slowdown appears temporarily and periodically and is\nworkload-agnostic. Third, in permanent slowdown, some files can individually\nand permanently become slower after a period of time. We analyze the impact of\nthese slowdowns on HDFS and show significant throughput loss. Individually,\neach of the slowdowns can cause a read throughput loss of 10-15%. However,\ntheir effect is cumulative. When all slowdowns happen concurrently, read\nthroughput drops by as much as 30%. We further analyze mitigation techniques\nand show that two of the three slowdowns could be addressed via increased IO\nrequest parallelism in the lower layers. Unfortunately, HDFS cannot\nautomatically adapt to use such additional parallelism. Our results point to a\nneed for adaptability in storage stacks. The reason is that an access pattern\nthat maximizes performance in the common case is not necessarily the same one\nthat can mask performance fluctuations.\n", "versions": [{"version": "v1", "created": "Fri, 22 Mar 2019 03:46:22 GMT"}], "update_date": "2019-03-25", "authors_parsed": [["Borge", "Mar\u00eda F.", ""], ["Dinu", "Florin", ""], ["Zwaenepoel", "Willy", ""]]}]