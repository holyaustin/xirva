[{"id": "1703.00897", "submitter": "Gene Cooperman", "authors": "Rohan Garg and Kapil Arya and Jiajun Cao and Gene Cooperman and Jeff\n  Evans and Ankit Garg and Neil A. Rosenberg and K. Suresh", "title": "Adapting the DMTCP Plugin Model for Checkpointing of Hardware Emulation", "comments": "5 pages, 11 figure, 1 listing; SELSE '17, March 21--22, 2017, Boston,\n  MA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Checkpoint-restart is now a mature technology. It allows a user to save and\nlater restore the state of a running process. The new plugin model for the\nupcoming version 3.0 of DMTCP (Distributed MultiThreaded Checkpointing) is\ndescribed here. This plugin model allows a target application to disconnect\nfrom the hardware emulator at checkpoint time and then re-connect to a possibly\ndifferent hardware emulator at the time of restart. The DMTCP plugin model is\nimportant in allowing three distinct parties to seamlessly inter-operate. The\nthree parties are: the EDA designer, who is concerned with formal verification\nof a circuit design; the DMTCP developers, who are concerned with providing\ntransparent checkpointing during the circuit emulation; and the hardware\nemulator vendor, who provides a plugin library that responds to checkpoint,\nrestart, and other events.\n  The new plugin model is an example of process-level virtualization:\nvirtualization of external abstractions from within a process. This capability\nis motivated by scenarios for testing circuit models with the help of a\nhardware emulator. The plugin model enables a three-way collaboration: allowing\na circuit designer and emulator vendor to each contribute separate proprietary\nplugins while sharing an open source software framework from the DMTCP\ndevelopers. This provides a more flexible platform, where different fault\ninjection models based on plugins can be designed within the DMTCP\ncheckpointing framework. After initialization, one restarts from a checkpointed\nstate under the control of the desired plugin. This restart saves the time\nspent in simulating the initialization phase, while enabling fault injection\nexactly at the region of interest. Upon restart, one can inject faults or\notherwise modify the remainder of the simulation. The work concludes with a\nbrief survey of checkpointing and process-level virtualization.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 18:52:45 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Garg", "Rohan", ""], ["Arya", "Kapil", ""], ["Cao", "Jiajun", ""], ["Cooperman", "Gene", ""], ["Evans", "Jeff", ""], ["Garg", "Ankit", ""], ["Rosenberg", "Neil A.", ""], ["Suresh", "K.", ""]]}, {"id": "1703.02925", "submitter": "Marco Tulio Valente", "authors": "Guilherme Avelino, Leonardo Passos, Andre Hora, Marco Tulio Valente", "title": "Assessing Code Authorship: The Case of the Linux Kernel", "comments": "Accepted at 13th International Conference on Open Source Systems\n  (OSS). 12 pages", "journal-ref": null, "doi": "10.1007/978-3-319-57735-7_15", "report-no": null, "categories": "cs.SE cs.OS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code authorship is a key information in large-scale open source systems.\nAmong others, it allows maintainers to assess division of work and identify key\ncollaborators. Interestingly, open-source communities lack guidelines on how to\nmanage authorship. This could be mitigated by setting to build an empirical\nbody of knowledge on how authorship-related measures evolve in successful\nopen-source communities. Towards that direction, we perform a case study on the\nLinux kernel. Our results show that: (a) only a small portion of developers (26\n%) makes significant contributions to the code base; (b) the distribution of\nthe number of files per author is highly skewed --- a small group of top\nauthors (3 %) is responsible for hundreds of files, while most authors (75 %)\nare responsible for at most 11 files; (c) most authors (62 %) have a specialist\nprofile; (d) authors with a high number of co-authorship connections tend to\ncollaborate with others with less connections.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 17:26:02 GMT"}], "update_date": "2018-08-07", "authors_parsed": [["Avelino", "Guilherme", ""], ["Passos", "Leonardo", ""], ["Hora", "Andre", ""], ["Valente", "Marco Tulio", ""]]}, {"id": "1703.06571", "submitter": "EPTCS", "authors": "Reto Achermann (Systems Group, Department of Computer Science, ETH\n  Zurich), Lukas Humbel (Systems Group, Department of Computer Science, ETH\n  Zurich), David Cock (Systems Group, Department of Computer Science, ETH\n  Zurich), Timothy Roscoe (Systems Group, Department of Computer Science, ETH\n  Zurich)", "title": "Formalizing Memory Accesses and Interrupts", "comments": "In Proceedings MARS 2017, arXiv:1703.05812", "journal-ref": "EPTCS 244, 2017, pp. 66-116", "doi": "10.4204/EPTCS.244.4", "report-no": null, "categories": "cs.OS cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The hardware/software boundary in modern heterogeneous multicore computers is\nincreasingly complex, and diverse across different platforms. A single memory\naccess by a core or DMA engine traverses multiple hardware translation and\ncaching steps, and the destination memory cell or register often appears at\ndifferent physical addresses for different cores. Interrupts pass through a\ncomplex topology of interrupt controllers and remappers before delivery to one\nor more cores, each with specific constraints on their configurations. System\nsoftware must not only correctly understand the specific hardware at hand, but\nalso configure it appropriately at runtime. We propose a formal model of\naddress spaces and resources in a system that allows us to express and verify\ninvariants of the system's runtime configuration, and illustrate (and motivate)\nit with several real platforms we have encountered in the process of OS\nimplementation.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 02:47:57 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Achermann", "Reto", "", "Systems Group, Department of Computer Science, ETH\n  Zurich"], ["Humbel", "Lukas", "", "Systems Group, Department of Computer Science, ETH\n  Zurich"], ["Cock", "David", "", "Systems Group, Department of Computer Science, ETH\n  Zurich"], ["Roscoe", "Timothy", "", "Systems Group, Department of Computer Science, ETH\n  Zurich"]]}, {"id": "1703.07725", "submitter": "Lei Liu", "authors": "Lei Liu, Mengyao Xie and Hao Yang", "title": "Memos: Revisiting Hybrid Memory Management in Modern Operating System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging hybrid DRAM-NVM architecture is challenging the existing memory\nmanagement mechanism in operating system. In this paper, we introduce memos,\nwhich can schedule memory resources over the entire memory hierarchy including\ncache, channels, main memory comprising DRAM and NVM simultaneously. Powered by\nour newly designed kernel-level monitoring module and page migration engine,\nmemos can dynamically optimize the data placement at the memory hierarchy in\nterms of the on-line memory patterns, current resource utilization and feature\nof memory medium. Our experimental results show that memos can achieve high\nmemory utilization, contributing to system throughput by 19.1% and QoS by 23.6%\non average. Moreover, memos can reduce the NVM side memory latency by 3~83.3%,\nenergy consumption by 25.1~99%, and benefit the NVM lifetime significantly (40X\nimprovement on average).\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 16:07:11 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Liu", "Lei", ""], ["Xie", "Mengyao", ""], ["Yang", "Hao", ""]]}, {"id": "1703.08469", "submitter": "Carlos Antonio Perea G\\'omez", "authors": "Carlos Antonio Perea-G\\'omez", "title": "Virtualization technology for distributed time sensitive domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on the state of the art of virtualization technology for\nboth general purpose domains as well as real-time domains. There exits no\nentirely instantaneous data transmission/transfer. There always exist a delay\nwhile transmitting data, either in the processing or in the medium itself.\nHowever most systems are designed to function appropriately with a delay\ntolerance. This delay, inevitably, is affected when operating with an extra\nlayer, the virtualization. For real time systems it is crucial to know the\ntemporal limits in order not to surpass them. Introducing virtualization in the\nreal-time domain therefore requires deeper analysis by making use of techniques\nthat will offer results with deterministic execution times. The study of time\nin systems and its behaviour under various possible circumstances is hence a\nkey for properly assessing this technology applied to both domains, especially\nthe real-time domain.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 15:38:17 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Perea-G\u00f3mez", "Carlos Antonio", ""]]}]