[{"id": "1506.01449", "submitter": "Riad Wahby", "authors": "Sebastian Angel and Riad S. Wahby and Max Howald and Joshua B. Leners\n  and Michael Spilo and Zhen Sun and Andrew J. Blumberg and Michael Walfish", "title": "Defending against malicious peripherals with Cinch", "comments": "18 pages, 7 figures", "journal-ref": "Proc. USENIX Security (2016), 397--414", "doi": null, "report-no": null, "categories": "cs.OS cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Malicious peripherals designed to attack their host computers are a growing\nproblem. Inexpensive and powerful peripherals that attach to plug-and-play\nbuses have made such attacks easy to mount. Making matters worse, commodity\noperating systems lack coherent defenses, and users are often unaware of the\nscope of the problem. We present Cinch, a pragmatic response to this threat.\nCinch uses virtualization to attach peripheral devices to a logically separate,\nuntrusted machine, and includes an interposition layer between the untrusted\nmachine and the protected one. This layer regulates interaction with devices\naccording to user-configured policies. Cinch integrates with existing OSes,\nenforces policies that thwart real-world attacks, and has low overhead.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 02:11:27 GMT"}, {"version": "v2", "created": "Sat, 11 Jul 2015 02:03:44 GMT"}, {"version": "v3", "created": "Wed, 2 Mar 2016 14:17:15 GMT"}, {"version": "v4", "created": "Wed, 29 Jun 2016 20:42:04 GMT"}], "update_date": "2016-08-19", "authors_parsed": [["Angel", "Sebastian", ""], ["Wahby", "Riad S.", ""], ["Howald", "Max", ""], ["Leners", "Joshua B.", ""], ["Spilo", "Michael", ""], ["Sun", "Zhen", ""], ["Blumberg", "Andrew J.", ""], ["Walfish", "Michael", ""]]}, {"id": "1506.02822", "submitter": "Ludovic Courtes", "authors": "Ludovic Court\\`es (INRIA Bordeaux - Sud-Ouest), Ricardo Wurmus", "title": "Reproducible and User-Controlled Software Environments in HPC with Guix", "comments": "2nd International Workshop on Reproducibility in Parallel Computing\n  (RepPar), Aug 2015, Vienne, Austria. http://reppar.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support teams of high-performance computing (HPC) systems often find\nthemselves between a rock and a hard place: on one hand, they understandably\nadministrate these large systems in a conservative way, but on the other hand,\nthey try to satisfy their users by deploying up-to-date tool chains as well as\nlibraries and scientific software. HPC system users often have no guarantee\nthat they will be able to reproduce results at a later point in time, even on\nthe same system-software may have been upgraded, removed, or recompiled under\ntheir feet, and they have little hope of being able to reproduce the same\nsoftware environment elsewhere. We present GNU Guix and the functional package\nmanagement paradigm and show how it can improve reproducibility and sharing\namong researchers with representative use cases.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 08:30:23 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2015 18:50:32 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Court\u00e8s", "Ludovic", "", "INRIA Bordeaux - Sud-Ouest"], ["Wurmus", "Ricardo", ""]]}, {"id": "1506.07566", "submitter": "Da Zheng", "authors": "Da Zheng, Randal Burns, Alexander S. Szalay", "title": "Optimize Unsynchronized Garbage Collection in an SSD Array", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solid state disks (SSDs) have advanced to outperform traditional hard drives\nsignificantly in both random reads and writes. However, heavy random writes\ntrigger fre- quent garbage collection and decrease the performance of SSDs. In\nan SSD array, garbage collection of individ- ual SSDs is not synchronized,\nleading to underutilization of some of the SSDs.\n  We propose a software solution to tackle the unsyn- chronized garbage\ncollection in an SSD array installed in a host bus adaptor (HBA), where\nindividual SSDs are exposed to an operating system. We maintain a long I/O\nqueue for each SSD and flush dirty pages intelligently to fill the long I/O\nqueues so that we hide the performance imbalance among SSDs even when there are\nfew parallel application writes. We further define a policy of select- ing\ndirty pages to flush and a policy of taking out stale flush requests to reduce\nthe amount of data written to SSDs. We evaluate our solution in a real system.\nExperi- ments show that our solution fully utilizes all SSDs in an array under\nrandom write-heavy workloads. It improves I/O throughput by up to 62% under\nrandom workloads of mixed reads and writes when SSDs are under active garbage\ncollection. It causes little extra data writeback and increases the cache hit\nrate.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 21:14:27 GMT"}], "update_date": "2015-06-26", "authors_parsed": [["Zheng", "Da", ""], ["Burns", "Randal", ""], ["Szalay", "Alexander S.", ""]]}]