[{"id": "2001.01442", "submitter": "Denis Efremov", "authors": "Denis Efremov and Ilya Shchepetkov", "title": "Runtime Verification of Linux Kernel Security Module", "comments": "15 pages, 4 figures, 3 listings, OpenCERT 2019", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Linux kernel is one of the most important Free/Libre Open Source Software\n(FLOSS) projects. It is installed on billions of devices all over the world,\nwhich process various sensitive, confidential or simply private data. It is\ncrucial to establish and prove its security properties. This work-in-progress\npaper presents a method to verify the Linux kernel for conformance with an\nabstract security policy model written in the Event-B specification language.\nThe method is based on system call tracing and aims at checking that the\nresults of system call execution do not lead to accesses that violate security\npolicy requirements. As a basis for it, we use an additional Event-B\nspecification of the Linux system call interface that is formally proved to\nsatisfy all the requirements of the security policy model. In order to perform\nthe conformance checks we use it to reproduce intercepted system calls and\nverify accesses.\n", "versions": [{"version": "v1", "created": "Mon, 6 Jan 2020 09:04:59 GMT"}], "update_date": "2020-01-07", "authors_parsed": [["Efremov", "Denis", ""], ["Shchepetkov", "Ilya", ""]]}, {"id": "2001.04698", "submitter": "Rakesh Mohanty", "authors": "Debasis Dwibedy, Rakesh Mohanty", "title": "Online Scheduling with Makespan Minimization: State of the Art Results,\n  Research Challenges and Open Problems", "comments": "37 pages, 13 Tables, Submitted to Computer Science Review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online scheduling has been a well studied and challenging research problem\nover the last five decades since the pioneering work of Graham with immense\npractical significance in various applications such as interactive parallel\nprocessing, routing in communication networks, distributed data management,\nclient-server communications, traffic management in transportation, industrial\nmanufacturing and production. In this problem, a sequence of jobs is received\none by one in order by the scheduler for scheduling over a number of machines.\nOn arrival of a job, the scheduler assigns the job irrevocably to a machine\nbefore the availability of the next job with an objective to minimize the\ncompletion time of the scheduled jobs. This paper highlights the state of the\nart contributions for online scheduling of a sequence of independent jobs on\nidentical and uniform related machines with a special focus on preemptive and\nnon-preemptive processing formats by considering makespan minimization as the\noptimality criterion. We present the fundamental aspects of online scheduling\nfrom a beginner's perspective along with a background of general scheduling\nframework. Important competitive analysis results obtained by well-known\ndeterministic and randomized online scheduling algorithms in the literature are\npresented along with research challenges and open problems. Two of the emerging\nrecent trends such as resource augmentation and semi-online scheduling are\ndiscussed as a motivation for future research work.\n", "versions": [{"version": "v1", "created": "Tue, 14 Jan 2020 10:19:15 GMT"}], "update_date": "2020-01-15", "authors_parsed": [["Dwibedy", "Debasis", ""], ["Mohanty", "Rakesh", ""]]}, {"id": "2001.05747", "submitter": "Mario Guenzel", "authors": "Mario G\\\"unzel and Jian-Jia Chen", "title": "On Schedulability Analysis of EDF Scheduling by Considering Suspension\n  as Blocking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the execution of a job, it may suspend itself, i.e., its computation\nceases to process until certain activities are complete to be resumed. This\npaper provides a counterexample of the schedulability analysis by Devi in\nEuromicro Conference on Real-Time Systems (ECRTS) in 2003, which is the only\nexisting suspension-aware analysis specialized for uniprocessor systems when\npreemptive earliest-deadline-first (EDF) is applied for scheduling dynamic\nselfsuspending tasks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2020 11:40:57 GMT"}, {"version": "v2", "created": "Tue, 11 Feb 2020 08:51:14 GMT"}], "update_date": "2020-02-12", "authors_parsed": [["G\u00fcnzel", "Mario", ""], ["Chen", "Jian-Jia", ""]]}, {"id": "2001.06159", "submitter": "Debasis Dwibedy", "authors": "Debasis Dwibedy, Rakesh Mohanty", "title": "A New Fairness Model based on User's Objective for Multi-user\n  Multi-processor Online Scheduling", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resources of a multi-user system in multi-processor online scheduling are\nshared by competing users in which fairness is a major performance criterion\nfor resource allocation. Fairness ensures equality in resource sharing among\nthe users. According to our knowledge, fairness based on the user's objective\nhas neither been comprehensively studied nor a formal fairness model has been\nwell defined in the literature. This motivates us to explore and define a new\nmodel to ensure algorithmic fairness with quantitative performance measures\nbased on optimization of the user's objective. In this paper, we propose a new\nmodel for fairness in Multi-user Multi-processor Online Scheduling\nProblem(MUMPOSP). We introduce and formally define quantitative fairness\nmeasures based on user's objective by optimizing makespan for individual user\nin our proposed fairness model. We also define the unfairness of deprived users\nand absolute fairness of an algorithm. We obtain lower bound results for the\nabsolute fairness for m identical machines with equal length jobs. We show that\nour proposed fairness model can serve as a framework for measuring algorithmic\nfairness by considering various optimality criteria such as flow time and sum\nof completion times.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2020 05:11:55 GMT"}], "update_date": "2020-01-20", "authors_parsed": [["Dwibedy", "Debasis", ""], ["Mohanty", "Rakesh", ""]]}, {"id": "2001.07045", "submitter": "Djordje Jevdjic", "authors": "Javier Picorel, Seyed Alireza Sanaee Kohroudi, Zi Yan, Abhishek\n  Bhattacharjee, Babak Falsafi, Djordje Jevdjic", "title": "SPARTA: A Divide and Conquer Approach to Address Translation for\n  Accelerators", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual memory (VM) is critical to the usability and programmability of\nhardware accelerators. Unfortunately, implementing accelerator VM efficiently\nis challenging because the area and power constraints make it difficult to\nemploy the large multi-level TLBs used in general-purpose CPUs. Recent research\nproposals advocate a number of restrictions on virtual-to-physical address\nmappings in order to reduce the TLB size or increase its reach. However, such\nrestrictions are unattractive because they forgo many of the original benefits\nof traditional VM, such as demand paging and copy-on-write.\n  We propose SPARTA, a divide and conquer approach to address translation.\nSPARTA splits the address translation into accelerator-side and memory-side\nparts. The accelerator-side translation hardware consists of a tiny TLB\ncovering only the accelerator's cache hierarchy (if any), while the translation\nfor main memory accesses is performed by shared memory-side TLBs. Performing\nthe translation for memory accesses on the memory side allows SPARTA to overlap\ndata fetch with translation, and avoids the replication of TLB entries for data\nshared among accelerators. To further improve the performance and efficiency of\nthe memory-side translation, SPARTA logically partitions the memory space,\ndelegating translation to small and efficient per-partition translation\nhardware. Our evaluation on index-traversal accelerators shows that SPARTA\nvirtually eliminates translation overhead, reducing it by over 30x on average\n(up to 47x) and improving performance by 57%. At the same time, SPARTA requires\nminimal accelerator-side translation hardware, reduces the total number of TLB\nentries in the system, gracefully scales with memory size, and preserves all\nkey VM functionalities.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2020 10:23:12 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Picorel", "Javier", ""], ["Kohroudi", "Seyed Alireza Sanaee", ""], ["Yan", "Zi", ""], ["Bhattacharjee", "Abhishek", ""], ["Falsafi", "Babak", ""], ["Jevdjic", "Djordje", ""]]}, {"id": "2001.07450", "submitter": "Hongliang Tian", "authors": "Youren Shen, Hongliang Tian, Yu Chen, Kang Chen, Runji Wang, Yi Xu,\n  and Yubin Xia", "title": "Occlum: Secure and Efficient Multitasking Inside a Single Enclave of\n  Intel SGX", "comments": null, "journal-ref": null, "doi": "10.1145/3373376.3378469", "report-no": null, "categories": "cs.OS cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intel Software Guard Extensions (SGX) enables user-level code to create\nprivate memory regions called enclaves, whose code and data are protected by\nthe CPU from software and hardware attacks outside the enclaves. Recent work\nintroduces library operating systems (LibOSes) to SGX so that legacy\napplications can run inside enclaves with few or even no modifications. As\nvirtually any non-trivial application demands multiple processes, it is\nessential for LibOSes to support multitasking. However, none of the existing\nSGX LibOSes support multitasking both securely and efficiently.\n  This paper presents Occlum, a system that enables secure and efficient\nmultitasking on SGX. We implement the LibOS processes as SFI-Isolated Processes\n(SIPs). SFI is a software instrumentation technique for sandboxing untrusted\nmodules (called domains). We design a novel SFI scheme named MPX-based,\nMulti-Domain SFI (MMDSFI) and leverage MMDSFI to enforce the isolation of SIPs.\nWe also design an independent verifier to ensure the security guarantees of\nMMDSFI. With SIPs safely sharing the single address space of an enclave, the\nLibOS can implement multitasking efficiently. The Occlum LibOS outperforms the\nstate-of-the-art SGX LibOS on multitasking-heavy workloads by up to 6,600X on\nmicro-benchmarks and up to 500X on application benchmarks.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2020 11:42:17 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Shen", "Youren", ""], ["Tian", "Hongliang", ""], ["Chen", "Yu", ""], ["Chen", "Kang", ""], ["Wang", "Runji", ""], ["Xu", "Yi", ""], ["Xia", "Yubin", ""]]}, {"id": "2001.08169", "submitter": "Nawanol Theera-Ampornpunt", "authors": "Nawanol Theera-Ampornpunt, Shikhar Suryavansh, Sameer Manchanda,\n  Rajesh Panta, Kaustubh Joshi, Mostafa Ammar, Mung Chiang, Saurabh Bagchi", "title": "AppStreamer: Reducing Storage Requirements of Mobile Games through\n  Predictive Streaming", "comments": "12 pages; EWSN 2020", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Storage has become a constrained resource on smartphones. Gaming is a popular\nactivity on mobile devices and the explosive growth in the number of games\ncoupled with their growing size contributes to the storage crunch. Even where\nstorage is plentiful, it takes a long time to download and install a heavy app\nbefore it can be launched. This paper presents AppStreamer, a novel technique\nfor reducing the storage requirements or startup delay of mobile games, and\nheavy mobile apps in general. AppStreamer is based on the intuition that most\napps do not need the entirety of its files (images, audio and video clips,\netc.) at any one time. AppStreamer can, therefore, keep only a small part of\nthe files on the device, akin to a \"cache\", and download the remainder from a\ncloud storage server or a nearby edge server when it predicts that the app will\nneed them in the near future. AppStreamer continuously predicts file blocks for\nthe near future as the user uses the app, and fetches them from the storage\nserver before the user sees a stall due to missing resources. We implement\nAppStreamer at the Android file system layer. This ensures that the apps\nrequire no source code or modification, and the approach generalizes across\napps. We evaluate AppStreamer using two popular games: Dead Effect 2, a 3D\nfirst-person shooter, and Fire Emblem Heroes, a 2D turn-based strategy\nrole-playing game. Through a user study, 75% and 87% of the users respectively\nfind that AppStreamer provides the same quality of user experience as the\nbaseline where all files are stored on the device. AppStreamer cuts down the\nstorage requirement by 87% for Dead Effect 2 and 86% for Fire Emblem Heroes.\n", "versions": [{"version": "v1", "created": "Mon, 16 Dec 2019 08:42:59 GMT"}], "update_date": "2020-01-23", "authors_parsed": [["Theera-Ampornpunt", "Nawanol", ""], ["Suryavansh", "Shikhar", ""], ["Manchanda", "Sameer", ""], ["Panta", "Rajesh", ""], ["Joshi", "Kaustubh", ""], ["Ammar", "Mostafa", ""], ["Chiang", "Mung", ""], ["Bagchi", "Saurabh", ""]]}, {"id": "2001.09991", "submitter": "Stella Bitchebe", "authors": "Stella Bitchebe, Djob Mvondo, Alain Tchana, Laurent R\\'eveill\\`ere,\n  No\\\"el De Palma", "title": "Intel Page Modification Logging, a hardware virtualization feature:\n  study and improvement for virtual machine working set estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Intel Page Modification Logging (PML) is a novel hardware feature for\ntracking virtual machine (VM) accessed memory pages. This task is essential in\ntoday's data centers since it allows, among others, checkpointing, live\nmigration and working set size (WSS) estimation. Relying on the Xen hypervisor,\nthis paper studies PML from three angles: power consumption, efficiency, and\nperformance impact on user applications. Our findings are as follows. First,\nPML does not incur any power consumption overhead. Second, PML reduces by up to\n10.18% both VM live migration and checkpointing time. Third, PML slightly\nreduces by up to 0.95% the performance degradation on applications incurred by\nlive migration and checkpointing. Fourth, PML however does not allow accurate\nWSS estimation because read accesses are not tracked and hot pages cannot be\nidentified. A naive extension of PML for addressing these limitations could\nlead to severe performance degradation (up to 34.8%) for the VM whose WSS is\ncomputed.\n  This paper presents Page Reference Logging (PRL), a smart extension of PML\nfor allowing both read and write accesses to be tracked. It does this without\nimpacting user VMs. The paper also presents a WSS estimation system which\nleverages PRL and shows how this algorithm can be integrated into a data center\nwhich implements memory overcommitment. We implement PRL and the WSS estimation\nsystem under Gem5, a very popular hardware simulator. The evaluation results\nvalidate the accuracy of PRL in the estimation of WSS. They also show that PRL\nincurs no performance degradation for user VMs.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2020 16:24:08 GMT"}], "update_date": "2020-01-29", "authors_parsed": [["Bitchebe", "Stella", ""], ["Mvondo", "Djob", ""], ["Tchana", "Alain", ""], ["R\u00e9veill\u00e8re", "Laurent", ""], ["De Palma", "No\u00ebl", ""]]}]