[{"id": "1806.00680", "submitter": "Anuj Kalia", "authors": "Anuj Kalia, Michael Kaminsky, David G. Andersen", "title": "Datacenter RPCs can be General and Fast", "comments": "Updated to NSDI 2019 version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is commonly believed that datacenter networking software must sacrifice\ngenerality to attain high performance. The popularity of specialized\ndistributed systems designed specifically for niche technologies such as RDMA,\nlossless networks, FPGAs, and programmable switches testifies to this belief.\nIn this paper, we show that such specialization is not necessary. eRPC is a new\ngeneral-purpose remote procedure call (RPC) library that offers performance\ncomparable to specialized systems, while running on commodity CPUs in\ntraditional datacenter networks based on either lossy Ethernet or lossless\nfabrics. eRPC performs well in three key metrics: message rate for small\nmessages; bandwidth for large messages; and scalability to a large number of\nnodes and CPU cores. It handles packet loss, congestion, and background request\nexecution. In microbenchmarks, one CPU core can handle up to 10 million small\nRPCs per second, or send large messages at 75 Gbps. We port a production-grade\nimplementation of Raft state machine replication to eRPC without modifying the\ncore Raft source code. We achieve 5.5 microseconds of replication latency on\nlossy Ethernet, which is faster than or comparable to specialized replication\nsystems that use programmable switches, FPGAs, or RDMA.\n", "versions": [{"version": "v1", "created": "Sat, 2 Jun 2018 18:05:28 GMT"}, {"version": "v2", "created": "Tue, 15 Jan 2019 01:47:04 GMT"}], "update_date": "2019-01-16", "authors_parsed": [["Kalia", "Anuj", ""], ["Kaminsky", "Michael", ""], ["Andersen", "David G.", ""]]}, {"id": "1806.01147", "submitter": "Michael Peter", "authors": "Janis Danisevskis and Michael Peter and Jan Nordholz", "title": "Minimizing Event-Handling Latencies in Secure Virtual Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualization, after having found widespread adoption in the server and\ndesktop arena, is poised to change the architecture of embedded systems as\nwell. The benefits afforded by virtualization - enhanced isolation,\nmanageability, flexibility, and security - could be instrumental for developers\nof embedded systems as an answer to the rampant increase in complexity.\n  While mature desktop and server solutions exist, they cannot be easily reused\non embedded systems because of markedly different requirements. Unfortunately,\noptimizations aimed at throughput, important for servers, often compromise on\naspects like predictable real-time behavior, which are crucial to many embedded\nsystems. In a similar vein, the requirements for small trusted computing bases,\nlightweight inter-VM communication, and small footprints are often not\naccommodated. This observation suggests that virtual machines for embedded\nsystems should be constructed from scratch with particular attention paid to\nthe specific requirements.\n  In this paper, we set out with a virtual machine designed for\nsecurity-conscious workloads and describe the steps necessary to achieve good\nevent-handling latencies. That evolution is possible because the underlying\nmicrokernel is well suited to satisfy real-time requirements. As the guest\nsystem we chose Linux with the PREEMPT_RT configuration, which itself was\ndeveloped in an effort to bring down event-handling latencies in a general\npurpose system. Our results indicate that the increase of event-handling\nlatencies of a guest running in a virtual machine does not, compared to native\nexecution, exceed a factor of two.\n", "versions": [{"version": "v1", "created": "Mon, 4 Jun 2018 14:29:41 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Danisevskis", "Janis", ""], ["Peter", "Michael", ""], ["Nordholz", "Jan", ""]]}, {"id": "1806.01589", "submitter": "Paolo Torroni", "authors": "Paolo Torroni and Zeynep Kiziltan and Eugenio Faldella", "title": "Blocking time under basic priority inheritance: Polynomial bound and\n  exact computation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Priority Inheritance Protocol (PIP) is arguably the best-known protocol\nfor resource sharing under real-time constraints. Its importance in modern\napplications is undisputed. Nevertheless, because jobs may be blocked under PIP\nfor a variety of reasons, determining a job's maximum blocking time could be\ndifficult, and thus far no exact method has been proposed that does it.\nExisting analysis methods are inefficient, inaccurate, and of limited\napplicability. This article proposes a new characterization of the problem,\nthus allowing a polynomial method for bounding the blocking time, and an exact,\noptimally efficient method for blocking time computation under priority\ninheritance that have a general applicability.\n", "versions": [{"version": "v1", "created": "Tue, 5 Jun 2018 10:03:40 GMT"}, {"version": "v2", "created": "Mon, 11 Jun 2018 14:25:54 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Torroni", "Paolo", ""], ["Kiziltan", "Zeynep", ""], ["Faldella", "Eugenio", ""]]}, {"id": "1806.07480", "submitter": "Julian Stecklina", "authors": "Julian Stecklina and Thomas Prescher", "title": "LazyFP: Leaking FPU Register State using Microarchitectural\n  Side-Channels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.AR cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern processors utilize an increasingly large register set to facilitate\nefficient floating point and SIMD computation. This large register set is a\nburden for operating systems, as its content needs to be saved and restored\nwhen the operating system context switches between tasks. As an optimization,\nthe operating system can defer the context switch of the FPU and SIMD register\nset until the first instruction is executed that needs access to these\nregisters. Meanwhile, the old content is left in place with the hope that the\ncurrent task might not use these registers at all. This optimization is\ncommonly called lazy FPU context switching. To make it possible, a processor\noffers the ability to toggle the availability of instructions utilizing\nfloating point and SIMD registers. If the instructions are turned off, any\nattempt of executing them will generate a fault.\n  In this paper, we present an attack that exploits lazy FPU context switching\nand allows an adversary to recover the FPU and SIMD register set of arbitrary\nprocesses or VMs. The attack works on processors that transiently execute FPU\nor SIMD instructions that follow an instruction generating the fault indicating\nthe first use of FPU or SIMD instructions. On operating systems using lazy FPU\ncontext switching, the FPU and SIMD register content of other processes or\nvirtual machines can then be reconstructed via cache side effects.\n  With SIMD registers not only being used for cryptographic computation, but\nalso increasingly for simple operations, such as copying memory, we argue that\nlazy FPU context switching is a dangerous optimization that needs to be turned\noff in all operating systems, if there is a chance that they run on affected\nprocessors.\n", "versions": [{"version": "v1", "created": "Tue, 19 Jun 2018 21:59:59 GMT"}], "update_date": "2018-06-21", "authors_parsed": [["Stecklina", "Julian", ""], ["Prescher", "Thomas", ""]]}, {"id": "1806.11431", "submitter": "Flavio Rubens Massaro Jr.", "authors": "Flavio R Massaro Jr., Paulo S. Martins, Edson L. Ursini", "title": "Integrating Proactive Mode Changes in Mixed Criticality Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose to integrate prediction algorithms to the scheduling\nof mode changes under the Earliest-Deadline-First and Fixed-priority scheduling\nin mixed-criticality real-time systems. The method proactively schedules a mode\nchange in the system based on state variables such as laxity, to the percentage\ndifference in the temporal distance between the completion time of the instance\nof a task and its respective deadline, by the deadline (D) stipulated for the\ntask, in order to minimize deadline misses. The simulation model was validated\nagainst an analytical model prior to the logical integration of the\nKalman-based prediction algorithm. Two study cases were presented, one covering\nearliest-deadline first and the other the fixed-priority scheduling approach.\nThe results showed the gains in the adoption of the prediction approach for\nboth scheduling paradigms by presenting a significant reduction of the number\nof missed deadlines for low-criticality tasks.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jun 2018 14:19:12 GMT"}], "update_date": "2018-07-02", "authors_parsed": [["Massaro", "Flavio R", "Jr."], ["Martins", "Paulo S.", ""], ["Ursini", "Edson L.", ""]]}]