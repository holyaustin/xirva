[{"id": "1610.03052", "submitter": "Lihao Liang", "authors": "Lihao Liang, Paul E. McKenney, Daniel Kroening, Tom Melham", "title": "Verification of the Tree-Based Hierarchical Read-Copy Update in the\n  Linux Kernel", "comments": "This is a long version of a conference paper published in the 2018\n  Design, Automation and Test in Europe Conference (DATE)", "journal-ref": "Design, Automation and Test in Europe Conference (2018): 61-66", "doi": "10.23919/DATE.2018.8341980", "report-no": null, "categories": "cs.LO cs.DC cs.OS cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Read-Copy Update (RCU) is a scalable, high-performance Linux-kernel\nsynchronization mechanism that runs low-overhead readers concurrently with\nupdaters. Production-quality RCU implementations for multi-core systems are\ndecidedly non-trivial. Giving the ubiquity of Linux, a rare \"million-year\" bug\ncan occur several times per day across the installed base. Stringent validation\nof RCU's complex behaviors is thus critically important. Exhaustive testing is\ninfeasible due to the exponential number of possible executions, which suggests\nuse of formal verification.\n  Previous verification efforts on RCU either focus on simple implementations\nor use modeling languages, the latter requiring error-prone manual translation\nthat must be repeated frequently due to regular changes in the Linux kernel's\nRCU implementation. In this paper, we first describe the implementation of Tree\nRCU in the Linux kernel. We then discuss how to construct a model directly from\nTree RCU's source code in C, and use the CBMC model checker to verify its\nsafety and liveness properties. To our best knowledge, this is the first\nverification of a significant part of RCU's source code, and is an important\nstep towards integration of formal verification into the Linux kernel's\nregression test suite.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 19:59:32 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 17:15:33 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 17:40:49 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Liang", "Lihao", ""], ["McKenney", "Paul E.", ""], ["Kroening", "Daniel", ""], ["Melham", "Tom", ""]]}, {"id": "1610.08129", "submitter": "Asaf Cidon", "authors": "Asaf Cidon, Daniel Rushton, Stephen M. Rumble and Ryan Stutsman", "title": "Memshare: a Dynamic Multi-tenant Memory Key-value Cache", "comments": "14 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web application performance is heavily reliant on the hit rate of\nmemory-based caches. Current DRAM-based web caches statically partition their\nmemory across multiple applications sharing the cache. This causes under\nutilization of memory which negatively impacts cache hit rates. We present\nMemshare, a novel web memory cache that dynamically manages memory across\napplications. Memshare provides a resource sharing model that guarantees\nprivate memory to different applications while dynamically allocating the\nremaining shared memory to optimize overall hit rate. Today's high cost of DRAM\nstorage and the availability of high performance CPU and memory bandwidth, make\nweb caches memory capacity bound. Memshare's log-structured design allows it to\nprovide significantly higher hit rates and dynamically partition memory among\napplications at the expense of increased CPU and memory bandwidth consumption.\nIn addition, Memshare allows applications to use their own eviction policy for\ntheir objects, independent of other applications. We implemented Memshare and\nran it on a week-long trace from a commercial memcached provider. We\ndemonstrate that Memshare increases the combined hit rate of the applications\nin the trace by an 6.1% (from 84.7% hit rate to 90.8% hit rate) and reduces the\ntotal number of misses by 39.7% without affecting system throughput or latency.\nEven for single-tenant applications, Memshare increases the average hit rate of\nthe current state-of-the-art memory cache by an additional 2.7% on our\nreal-world trace.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 00:37:34 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Cidon", "Asaf", ""], ["Rushton", "Daniel", ""], ["Rumble", "Stephen M.", ""], ["Stutsman", "Ryan", ""]]}]