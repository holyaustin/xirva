[{"id": "1604.00478", "submitter": "Bin Liu", "authors": "Bin Liu, Shi Cheng", "title": "State Space Model based Trust Evaluation over Wireless Sensor Networks:\n  An Iterative Particle Filter Approach", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": "10.1049/joe.2016.0373", "report-no": null, "categories": "cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a state space modeling approach for trust evaluation\nin wireless sensor networks. In our state space trust model (SSTM), each sensor\nnode is associated with a trust metric, which measures to what extent the data\ntransmitted from this node would better be trusted by the server node. Given\nthe SSTM, we translate the trust evaluation problem to be a nonlinear state\nfiltering problem. To estimate the state based on the SSTM, a component-wise\niterative state inference procedure is proposed to work in tandem with the\nparticle filter, and thus the resulting algorithm is termed as iterative\nparticle filter (IPF). The computational complexity of the IPF algorithm is\ntheoretically linearly related with the dimension of the state. This property\nis desirable especially for high dimensional trust evaluation and state\nfiltering problems. The performance of the proposed algorithm is evaluated by\nboth simulations and real data analysis.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 09:02:27 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 22:22:33 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Liu", "Bin", ""], ["Cheng", "Shi", ""]]}, {"id": "1604.00500", "submitter": "Dmitrii Kuvaiskii", "authors": "Dmitrii Kuvaiskii, Oleksii Oleksenko, Pramod Bhatotia, Pascal Felber,\n  Christof Fetzer", "title": "Elzar: Triple Modular Redundancy using Intel Advanced Vector Extensions\n  (technical report)", "comments": "Short version of this report appeared in the 46th IEEE/IFIP\n  International Conference on Dependable Systems and Networks (DSN'2016) under\n  the title \"ELZAR: Triple Modular Redundancy using Intel Advanced Vector\n  Extensions (practical experience report)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Instruction-Level Redundancy (ILR) is a well-known approach to tolerate\ntransient CPU faults. It replicates instructions in a program and inserts\nperiodic checks to detect and correct CPU faults using majority voting, which\nessentially requires three copies of each instruction and leads to high\nperformance overheads. As SIMD technology can operate simultaneously on several\ncopies of the data, it appears to be a good candidate for decreasing these\noverheads. To verify this hypothesis, we propose Elzar, a compiler framework\nthat transforms unmodified multithreaded applications to support triple modular\nredundancy using Intel AVX extensions for vectorization. Our experience with\nseveral benchmark suites and real-world case-studies yields mixed results:\nwhile SIMD may be beneficial for some workloads, e.g., CPU-intensive ones with\nmany floating-point operations, it exhibits higher overhead than ILR in many\napplications we tested. We study the sources of overheads and discuss possible\nimprovements to Intel AVX that would lead to better performance.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 13:23:35 GMT"}, {"version": "v2", "created": "Wed, 24 Aug 2016 09:02:57 GMT"}], "update_date": "2016-08-25", "authors_parsed": [["Kuvaiskii", "Dmitrii", ""], ["Oleksenko", "Oleksii", ""], ["Bhatotia", "Pramod", ""], ["Felber", "Pascal", ""], ["Fetzer", "Christof", ""]]}, {"id": "1604.00554", "submitter": "{\\L}ukasz Olech Piotr", "authors": "{\\L}ukasz P. Olech and Jan Kwiatkowski", "title": "Scalability Model Based on the Concept of Granularity", "comments": "This article was presented at PPAM 2015 conference\n  http://www.ppam.pl/ and will be published in Springer Proceedengs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the recent years it can be observed increasing popularity of parallel\nprocessing using multi-core processors, local clusters, GPU and others.\nMoreover, currently one of the main requirements the IT users is the reduction\nof maintaining cost of the computer infrastructure. It causes that the\nperformance evaluation of the parallel applications becomes one of the most\nimportant problem. Then obtained results allows efficient use of available\nresources. In traditional methods of performance evaluation the results are\nbased on wall-clock time measurements. This approach requires consecutive\napplication executions and includes a time-consuming data analysis. In the\npaper an alternative approach is proposed. The decomposition of parallel\napplication execution time onto computation time and overheads related to\nparallel execution is use to calculate the granularity of application and then\ndetermine its efficiency. Finally the application scalability can be evaluates.\n", "versions": [{"version": "v1", "created": "Sat, 2 Apr 2016 20:16:49 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Olech", "\u0141ukasz P.", ""], ["Kwiatkowski", "Jan", ""]]}, {"id": "1604.00641", "submitter": "Roy Friedman", "authors": "Roy Friedman and Nir Hauser", "title": "COARA: Code Offloading on Android with AspectJ", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones suffer from limited computational capabilities and battery life.\nA method to mitigate these problems is code offloading: executing application\ncode on a remote server. We introduce COARA, a middleware platform for code\noffloading on Android that uses aspect-oriented programming (AOP) with AspectJ.\nAOP allows COARA to intercept code for offloading without a customized compiler\nor modification of the operating system. COARA requires minimal changes to\napplication source code, and does not require the application developer to be\naware of AOP. Since state transfer to the server is often a bottleneck that\nhinders performance, COARA uses AOP to intercept the transmission of large\nobjects from the client and replaces them with object proxies. The server can\nbegin execution of the offloaded application code, regardless of whether all\nrequired objects been transferred to the server. We run COARA with Android\napplications from the Google Play store on a Nexus 4 running unmodified Android\n4.3 to prove that our platform improves performance and reduces energy\nconsumption. Our approach yields speedups of 24x and 6x over WiFi and 3G\nrespectively.\n", "versions": [{"version": "v1", "created": "Sun, 3 Apr 2016 14:31:24 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Friedman", "Roy", ""], ["Hauser", "Nir", ""]]}, {"id": "1604.00739", "submitter": "Qiaoni Han", "authors": "Bo Yang, Yanyan Shen, Qiaoni Han, Cailian Chen, Xinping Guan, and\n  Weidong Zhang", "title": "Energy Efficient Resource Allocation for Time-Varying OFDMA Relay\n  Systems with Hybrid Energy Supplies", "comments": "12 pages, 9 figures, IEEE System Journal", "journal-ref": null, "doi": "10.1109/JSYST.2016.2551319", "report-no": null, "categories": "cs.DC cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the energy efficient resource allocation for\northogonal frequency division multiple access (OFDMA) relay systems, where the\nsystem is supplied by the conventional utility grid and a renewable energy\ngenerator equipped with a storage device. The optimal usage of radio resource\ndepends on the characteristics of the renewable energy generation and the\nmobile traffic, which exhibit both temporal and spatial diversities. Lyapunov\noptimization method is used to decompose the problem into the joint flow\ncontrol, radio resource allocation and energy management without knowing a\npriori knowledge of system statistics. It is proven that the proposed algorithm\ncan result in close-to-optimal performance with capacity limited data buffer\nand storage device. Simulation results show that the flexible tradeoff between\nthe system utility and the conventional energy consumption can be achieved.\nCompared with other schemes, the proposed algorithm demonstrates better\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 04:33:29 GMT"}, {"version": "v2", "created": "Wed, 6 Apr 2016 01:27:39 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Yang", "Bo", ""], ["Shen", "Yanyan", ""], ["Han", "Qiaoni", ""], ["Chen", "Cailian", ""], ["Guan", "Xinping", ""], ["Zhang", "Weidong", ""]]}, {"id": "1604.00794", "submitter": "Pramod Bhatotia", "authors": "Pramod Bhatotia", "title": "Asymptotic Analysis of Self-Adjusting Contraction Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present asymptotic analysis of self-adjusting contraction\ntrees for incremental sliding window analytics.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 09:55:06 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Bhatotia", "Pramod", ""]]}, {"id": "1604.00981", "submitter": "Jianmin Chen", "authors": "Jianmin Chen, Xinghao Pan, Rajat Monga, Samy Bengio and Rafal\n  Jozefowicz", "title": "Revisiting Distributed Synchronous SGD", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed training of deep learning models on large-scale training data is\ntypically conducted with asynchronous stochastic optimization to maximize the\nrate of updates, at the cost of additional noise introduced from asynchrony. In\ncontrast, the synchronous approach is often thought to be impractical due to\nidle time wasted on waiting for straggling workers. We revisit these\nconventional beliefs in this paper, and examine the weaknesses of both\napproaches. We demonstrate that a third approach, synchronous optimization with\nbackup workers, can avoid asynchronous noise while mitigating for the worst\nstragglers. Our approach is empirically validated and shown to converge faster\nand to better test accuracies.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 18:40:05 GMT"}, {"version": "v2", "created": "Fri, 15 Apr 2016 18:49:12 GMT"}, {"version": "v3", "created": "Tue, 21 Mar 2017 07:44:39 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Chen", "Jianmin", ""], ["Pan", "Xinghao", ""], ["Monga", "Rajat", ""], ["Bengio", "Samy", ""], ["Jozefowicz", "Rafal", ""]]}, {"id": "1604.00997", "submitter": "David Tolpin", "authors": "David Tolpin", "title": "Progressive Temporal Window Widening", "comments": "15 pages, 5 figures, LNCS format", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a scheme for data stream processing which is robust to\nbatch duration. Streaming frameworks process streams in batches retrieved at\nfixed time intervals. In a common setting a pattern recognition algorithm is\napplied independently to each batch. Choosing the right time interval is tough\n--- a pattern may not fit in an interval which is too short, but detection will\nbe delayed and memory may be exhausted if the interval is too long. We propose\nhere Progressive Window Widening, an algorithm for increasing the interval\ngradually so that patterns are caught at any pace without unnecessary delays or\nmemory overflow.\n  This algorithm is relevant to computer security, system monitoring, user\nbehavior tracking, and other applications where patterns of unknown or varying\nduration must be recognized online in data streams. Modern data stream\nprocessing frameworks are ubiquitously used to process high volumes of data,\nand adaptive memory and CPU allocation, facilitated by Progressive Window\nWidening, is crucial for their performance.\n", "versions": [{"version": "v1", "created": "Mon, 4 Apr 2016 19:33:00 GMT"}, {"version": "v2", "created": "Sun, 3 Jul 2016 15:41:38 GMT"}, {"version": "v3", "created": "Fri, 17 Feb 2017 10:16:01 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Tolpin", "David", ""]]}, {"id": "1604.01416", "submitter": "Steven Eliuk", "authors": "Steven Eliuk, Cameron Upright, Anthony Skjellum", "title": "dMath: A Scalable Linear Algebra and Math Library for Heterogeneous\n  GP-GPU Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new scalable parallel math library, dMath, is presented in this paper that\ndemonstrates leading scaling when using intranode, or internode,\nhybrid-parallelism for deep-learning. dMath provides easy-to-use distributed\nbase primitives and a variety of domain-specific algorithms. These include\nmatrix multiplication, convolutions, and others allowing for rapid development\nof highly scalable applications, including Deep Neural Networks (DNN), whereas\npreviously one was restricted to libraries that provided effective primitives\nfor only a single GPU, like Nvidia cublas and cudnn or DNN primitives from\nNervana neon framework. Development of HPC software is difficult,\nlabor-intensive work, requiring a unique skill set. dMath allows a wide range\nof developers to utilize parallel and distributed hardware easily. One\ncontribution of this approach is that data is stored persistently on the GPU\nhardware, avoiding costly transfers between host and device. Advanced memory\nmanagement techniques are utilized, including caching of transferred data and\nmemory reuse through pooling. A key contribution of dMath is that it delivers\nperformance, portability, and productivity to its specific domain of support.\nIt enables algorithm and application programmers to quickly solve problems\nwithout managing the significant complexity associated with multi-level\nparallelism.\n", "versions": [{"version": "v1", "created": "Tue, 5 Apr 2016 20:28:26 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Eliuk", "Steven", ""], ["Upright", "Cameron", ""], ["Skjellum", "Anthony", ""]]}, {"id": "1604.01890", "submitter": "Georg Hager", "authors": "Johannes Hofmann, Dietmar Fey, Michael Riedmann, Jan Eitzinger, Georg\n  Hager, Gerhard Wellein", "title": "Performance analysis of the Kahan-enhanced scalar product on current\n  multi- and manycore processors", "comments": "15 pages, 10 figures", "journal-ref": "Concurrency Computat.: Pract. Exper., 29: e3921 (2016)", "doi": "10.1002/cpe.3921", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the performance characteristics of a numerically enhanced\nscalar product (dot) kernel loop that uses the Kahan algorithm to compensate\nfor numerical errors, and describe efficient SIMD-vectorized implementations on\nrecent multi- and manycore processors. Using low-level instruction analysis and\nthe execution-cache-memory (ECM) performance model we pinpoint the relevant\nperformance bottlenecks for single-core and thread-parallel execution, and\npredict performance and saturation behavior. We show that the Kahan-enhanced\nscalar product comes at almost no additional cost compared to the naive\n(non-Kahan) scalar product if appropriate low-level optimizations, notably SIMD\nvectorization and unrolling, are applied. The ECM model is extended\nappropriately to accommodate not only modern Intel multicore chips but also the\nIntel Xeon Phi \"Knights Corner\" coprocessor and an IBM POWER8 CPU. This allows\nus to discuss the impact of processor features on the performance across four\nmodern architectures that are relevant for high performance computing.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 07:04:19 GMT"}], "update_date": "2018-07-09", "authors_parsed": [["Hofmann", "Johannes", ""], ["Fey", "Dietmar", ""], ["Riedmann", "Michael", ""], ["Eitzinger", "Jan", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1604.01950", "submitter": "Yong Zhan", "authors": "Yong Zhan, Du Xu, Hongfang Yu, Shui Yu", "title": "Incentivizing Users of Data Centers Participate in The Demand Response\n  Programs via Time-Varying Monetary Rewards", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Demand response is widely employed by today's data centers to reduce energy\nconsumption in response to the increasing of electricity cost. To incentivize\nusers of data centers participate in the demand response programs, i.e.,\nbreaking the \"split incentive\" hurdle, some prior researches propose\nmarket-based mechanisms such as dynamic pricing and static monetary rewards.\nHowever, these mechanisms are either intrusive or unfair. In this paper, we use\ntime-varying rewards to incentivize users, who have flexible deadlines and are\nwilling to trading performance degradation for monetary rewards, grant\ntime-shifting of their requests. With a game-theoretic framework, we model the\ngame between a single data center and its users. Further, we extend our design\nvia integrating it with two other emerging practical demand response\nstrategies: server shutdown and local renewable energy generation. With\nreal-world data traces, we show that a DC with our design can effectively shed\nits peak electricity load and overall electricity cost without reducing its\nprofit, when comparing it with the current practice where no incentive\nmechanism is established.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 10:45:44 GMT"}], "update_date": "2016-04-08", "authors_parsed": [["Zhan", "Yong", ""], ["Xu", "Du", ""], ["Yu", "Hongfang", ""], ["Yu", "Shui", ""]]}, {"id": "1604.02006", "submitter": "Ann Drobnis", "authors": "Vasant G. Honavar, Mark D. Hill, and Katherine Yelick", "title": "Accelerating Science: A Computing Research Agenda", "comments": "Computing Community Consortium (CCC) white paper, 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.AI cs.DC cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of \"big data\" offers unprecedented opportunities for not only\naccelerating scientific advances but also enabling new modes of discovery.\nScientific progress in many disciplines is increasingly enabled by our ability\nto examine natural phenomena through the computational lens, i.e., using\nalgorithmic or information processing abstractions of the underlying processes;\nand our ability to acquire, share, integrate and analyze disparate types of\ndata. However, there is a huge gap between our ability to acquire, store, and\nprocess data and our ability to make effective use of the data to advance\ndiscovery. Despite successful automation of routine aspects of data management\nand analytics, most elements of the scientific process currently require\nconsiderable human expertise and effort. Accelerating science to keep pace with\nthe rate of data acquisition and data processing calls for the development of\nalgorithmic or information processing abstractions, coupled with formal methods\nand tools for modeling and simulation of natural processes as well as major\ninnovations in cognitive tools for scientists, i.e., computational tools that\nleverage and extend the reach of human intellect, and partner with humans on a\nbroad range of tasks in scientific discovery (e.g., identifying, prioritizing\nformulating questions, designing, prioritizing and executing experiments\ndesigned to answer a chosen question, drawing inferences and evaluating the\nresults, and formulating new questions, in a closed-loop fashion). This calls\nfor concerted research agenda aimed at: Development, analysis, integration,\nsharing, and simulation of algorithmic or information processing abstractions\nof natural processes, coupled with formal methods and tools for their analyses\nand simulation; Innovations in cognitive tools that augment and extend human\nintellect and partner with humans in all aspects of science.\n", "versions": [{"version": "v1", "created": "Wed, 6 Apr 2016 18:43:00 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Honavar", "Vasant G.", ""], ["Hill", "Mark D.", ""], ["Yelick", "Katherine", ""]]}, {"id": "1604.02113", "submitter": "Simon Pintarelli", "authors": "M. Kranj\\v{c}evi\\'c, D. Palossi, S. Pintarelli", "title": "Parallel Delta-Stepping Algorithm for Shared Memory Architectures", "comments": "Measurements in section 4 are incorrect", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a shared memory implementation of a parallel algorithm, called\ndelta-stepping, for solving the single source shortest path problem for\ndirected and undirected graphs. In order to reduce synchronization costs we\nmake some deviations from the algorithm and discuss the consequences. We study\nthe behaviour of our implementation on small-world and scale-free graphs, and\ngraphs arising from game maps. We collect performance data on multi-core CPUs\nand Intel Xeon Phi. When run in sequential mode, our implementation outperforms\nthe implementation of Dijkstra's algorithm from Boost Graph Library on graphs\nwith a small diameter. Both on the CPU and the co-processor we achieve an\noverall performance of at least 50% parallel efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 19:04:53 GMT"}, {"version": "v2", "created": "Mon, 20 Feb 2017 16:20:48 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Kranj\u010devi\u0107", "M.", ""], ["Palossi", "D.", ""], ["Pintarelli", "S.", ""]]}, {"id": "1604.02114", "submitter": "Mohsen Mosleh", "authors": "Mohsen Mosleh, Peter Ludlow, and Babak Heydari", "title": "Distributed Resource Management in Systems of Systems: An Architecture\n  Perspective", "comments": "19 pages. To appear in Systems Engineering Journal 2016", "journal-ref": "Systems Engineering, 2016", "doi": "10.1002/sys.21342", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a framework for studying the interactions of autonomous\nsystem components and the design of the connectivity structure in Systems of\nSystems (SoSs). This framework, which uses complex network models, is also used\nto study the connectivity structure's impact on resource management. We discuss\nresource sharing as a mechanism that adds a level of flexibility to distributed\nsystems and describe the connectivity structures that enhance components'\naccess to the resources available within the system. The framework introduced\nin this paper explicitly incorporates costs of connection and the benefits that\nare received by direct and indirect access to resources and provides measures\nof the optimality of connectivity structures. We discuss central and a\ndistributed schemes that, respectively, represent systems in which a central\nplanner determines the connectivity structure and systems in which distributed\ncomponents are allowed to add and sever connections to improve their own\nresource access. Furthermore, we identify optimal connectivity structures for\nsystems with various heterogeneity conditions.\n", "versions": [{"version": "v1", "created": "Thu, 7 Apr 2016 19:06:55 GMT"}, {"version": "v2", "created": "Mon, 25 Jul 2016 13:38:01 GMT"}, {"version": "v3", "created": "Thu, 4 Aug 2016 13:51:56 GMT"}], "update_date": "2016-08-05", "authors_parsed": [["Mosleh", "Mohsen", ""], ["Ludlow", "Peter", ""], ["Heydari", "Babak", ""]]}, {"id": "1604.02216", "submitter": "Hao Yu", "authors": "Hao Yu and Michael J. Neely", "title": "A Primal-Dual Type Algorithm with the $O(1/t)$ Convergence Rate for\n  Large Scale Constrained Convex Programs", "comments": "18 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:1512.08370", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers large scale constrained convex programs, which are\nusually not solvable by interior point methods or other Newton-type methods due\nto the prohibitive computation and storage complexity for Hessians and matrix\ninversions. Instead, large scale constrained convex programs are often solved\nby gradient based methods or decomposition based methods. The conventional\nprimal-dual subgradient method, aka, Arrow-Hurwicz-Uzawa subgradient method, is\na low complexity algorithm with the $O(1/\\sqrt{t})$ convergence rate, where $t$\nis the number of iterations. If the objective and constraint functions are\nseparable, the Lagrangian dual type method can decompose a large scale convex\nprogram into multiple parallel small scale convex programs. The classical dual\ngradient algorithm is an example of Lagrangian dual type methods and has\nconvergence rate $O(1/\\sqrt{t})$. Recently, a new Lagrangian dual type\nalgorithm with faster $O(1/t)$ convergence is proposed in Yu and Neely (2015).\nHowever, if the objective or constraint functions are not separable, each\niteration of the Lagrangian dual type method in Yu and Neely (2015) requires to\nsolve a large scale unconstrained convex program, which can have huge\ncomplexity. This paper proposes a new primal-dual type algorithm, which only\ninvolves simple gradient updates at each iteration and has the $O(1/t)$\nconvergence rate.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 03:25:32 GMT"}], "update_date": "2016-08-02", "authors_parsed": [["Yu", "Hao", ""], ["Neely", "Michael J.", ""]]}, {"id": "1604.02334", "submitter": "Uldis Locans", "authors": "Uldis Locans, Andreas Adelmann, Andreas Suter, Jannis Fischer, Werner\n  Lustermann, Gunther Dissertori, Qiulin Wang", "title": "Real-Time Computation of Parameter Fitting and Image Reconstruction\n  Using Graphical Processing Units", "comments": null, "journal-ref": null, "doi": "10.1016/j.cpc.2017.02.007", "report-no": null, "categories": "cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years graphical processing units (GPUs) have become a powerful tool\nin scientific computing. Their potential to speed up highly parallel\napplications brings the power of high performance computing to a wider range of\nusers. However, programming these devices and integrating their use in existing\napplications is still a challenging task.\n  In this paper we examined the potential of GPUs for two different\napplications. The first application, created at Paul Scherrer Institut (PSI),\nis used for parameter fitting during data analysis of muSR (muon spin rotation,\nrelaxation and resonance) experiments. The second application, developed at\nETH, is used for PET (Positron Emission Tomography) image reconstruction and\nanalysis. Applications currently in use were examined to identify parts of the\nalgorithms in need of optimization. Efficient GPU kernels were created in order\nto allow applications to use a GPU, to speed up the previously identified\nparts. Benchmarking tests were performed in order to measure the achieved\nspeedup\n  During this work, we focused on single GPU systems to show that real time\ndata analysis of these problems can be achieved without the need for large\ncomputing clusters. The results show that the currently used application for\nparameter fitting, which uses OpenMP to parallelize calculations over multiple\nCPU cores, can be accelerated around 40 times through the use of a GPU. The\nspeedup may vary depending on the size and complexity of the problem. For PET\nimage analysis, the obtained speedups of the GPU version was more than x40\nlarger compared to a single core CPU implementation. The achieved results show\nthat it is possible to improve the execution time by orders of magnitude.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 12:47:47 GMT"}, {"version": "v2", "created": "Tue, 22 Nov 2016 14:49:44 GMT"}], "update_date": "2017-04-26", "authors_parsed": [["Locans", "Uldis", ""], ["Adelmann", "Andreas", ""], ["Suter", "Andreas", ""], ["Fischer", "Jannis", ""], ["Lustermann", "Werner", ""], ["Dissertori", "Gunther", ""], ["Wang", "Qiulin", ""]]}, {"id": "1604.02475", "submitter": "Junan Zhu", "authors": "Junan Zhu, Dror Baron, Florent Krzakala", "title": "Performance Limits for Noisy Multi-Measurement Vector Problems", "comments": "11 pages, 6 figures", "journal-ref": "IEEE Transactions on Signal Processing, Volume: 65, Issue: 9\n  Pages: 2444 - 2454 (2017)", "doi": "10.1109/TSP.2016.2646663", "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressed sensing (CS) demonstrates that sparse signals can be estimated\nfrom under-determined linear systems. Distributed CS (DCS) further reduces the\nnumber of measurements by considering joint sparsity within signal ensembles.\nDCS with jointly sparse signals has applications in multi-sensor acoustic\nsensing, magnetic resonance imaging with multiple coils, remote sensing, and\narray signal processing. Multi-measurement vector (MMV) problems consider the\nestimation of jointly sparse signals under the DCS framework. Two related MMV\nsettings are studied. In the first setting, each signal vector is measured by a\ndifferent independent and identically distributed (i.i.d.) measurement matrix,\nwhile in the second setting, all signal vectors are measured by the same i.i.d.\nmatrix. Replica analysis is performed for these two MMV settings, and the\nminimum mean squared error (MMSE), which turns out to be identical for both\nsettings, is obtained as a function of the noise variance and number of\nmeasurements. To showcase the application of MMV models, the MMSE's of complex\nCS problems with both real and complex measurement matrices are also analyzed.\nMultiple performance regions for MMV are identified where the MMSE behaves\ndifferently as a function of the noise variance and the number of measurements.\n  Belief propagation (BP) is a CS signal estimation framework that often\nachieves the MMSE asymptotically. A phase transition for BP is identified. This\nphase transition, verified by numerical results, separates the regions where BP\nachieves the MMSE and where it is suboptimal. Numerical results also illustrate\nthat more signal vectors in the jointly sparse signal ensemble lead to a better\nphase transition.\n", "versions": [{"version": "v1", "created": "Fri, 8 Apr 2016 20:30:51 GMT"}, {"version": "v2", "created": "Wed, 17 Aug 2016 02:17:59 GMT"}], "update_date": "2017-03-24", "authors_parsed": [["Zhu", "Junan", ""], ["Baron", "Dror", ""], ["Krzakala", "Florent", ""]]}, {"id": "1604.02504", "submitter": "Camille Coti", "authors": "Camille Coti", "title": "Fault Tolerant QR Factorization for General Matrices", "comments": "arXiv admin note: text overlap with arXiv:1511.00212", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a fault-tolerant algorithm for the QR factorization of\ngeneral matrices. It relies on the communication-avoiding algorithm, and uses\nthe structure of the reduction of each part of the computation to introduce\nredundancies that are sufficient to recover the state of a failed process.\nAfter a process has failed, its state can be recovered based on the data held\nby one process only. Besides, it does not add any significant operation in the\ncritical path during failure-free execution.\n", "versions": [{"version": "v1", "created": "Sat, 9 Apr 2016 00:25:10 GMT"}, {"version": "v2", "created": "Thu, 14 Apr 2016 13:10:14 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Coti", "Camille", ""]]}, {"id": "1604.02533", "submitter": "Xiaoqi Ren", "authors": "Xiaoqi Ren, Palma London, Juba Ziani, Adam Wierman", "title": "Joint Data Purchasing and Data Placement in a Geo-Distributed Data\n  Market", "comments": "35 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies two design tasks faced by a geo-distributed cloud data\nmarket: which data to purchase (data purchasing) and where to place/replicate\nthe data for delivery (data placement). We show that the joint problem of data\npurchasing and data placement within a cloud data market can be viewed as a\nfacility location problem, and is thus NP-hard. However, we give a provably\noptimal algorithm for the case of a data market made up of a single data\ncenter, and then generalize the structure from the single data center setting\nin order to develop a near-optimal, polynomial-time algorithm for a\ngeo-distributed data market. The resulting design, Datum, decomposes the joint\npurchasing and placement problem into two subproblems, one for data purchasing\nand one for data placement, using a transformation of the underlying bandwidth\ncosts. We show, via a case study, that Datum is near-optimal (within 1.6%) in\npractical settings.\n", "versions": [{"version": "v1", "created": "Sat, 9 Apr 2016 07:16:39 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Ren", "Xiaoqi", ""], ["London", "Palma", ""], ["Ziani", "Juba", ""], ["Wierman", "Adam", ""]]}, {"id": "1604.02608", "submitter": "Robert Grossman", "authors": "Robert L. Grossman, Allison Heath, Mark Murphy, Maria Patterson and\n  Walt Wells", "title": "A Case for Data Commons: Towards Data Science as a Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the amount of scientific data continues to grow at ever faster rates, the\nresearch community is increasingly in need of flexible computational\ninfrastructure that can support the entirety of the data science lifecycle,\nincluding long-term data storage, data exploration and discovery services, and\ncompute capabilities to support data analysis and re-analysis, as new data are\nadded and as scientific pipelines are refined. We describe our experience\ndeveloping data commons-- interoperable infrastructure that co-locates data,\nstorage, and compute with common analysis tools--and present several cases\nstudies. Across these case studies, several common requirements emerge,\nincluding the need for persistent digital identifier and metadata services,\nAPIs, data portability, pay for compute capabilities, and data peering\nagreements between data commons. Though many challenges, including\nsustainability and developing appropriate standards remain, interoperable data\ncommons bring us one step closer to effective Data Science as Service for the\nscientific research community.\n", "versions": [{"version": "v1", "created": "Sat, 9 Apr 2016 20:46:01 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Grossman", "Robert L.", ""], ["Heath", "Allison", ""], ["Murphy", "Mark", ""], ["Patterson", "Maria", ""], ["Wells", "Walt", ""]]}, {"id": "1604.02700", "submitter": "Gustavo Lacerda gustavolacerdas", "authors": "Gustavo R.L Silva, Rafael R. Medeiros, Antonio P. Braga, Douglas A.G.\n  Vieira", "title": "GPIC - GPU Power Iteration Cluster", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a new clustering algorithm, the GPIC, a Graphics\nProcessing Unit (GPU) accelerated algorithm for Power Iteration Clustering\n(PIC). Our algorithm is based on the original PIC proposal, adapted to take\nadvantage of the GPU architecture, maintining the algorith original properties.\nThe proposed method was compared against the serial and parallel Spark\nimplementation, achieving a considerable speed-up in the test problems.\n", "versions": [{"version": "v1", "created": "Sun, 10 Apr 2016 14:59:25 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Silva", "Gustavo R. L", ""], ["Medeiros", "Rafael R.", ""], ["Braga", "Antonio P.", ""], ["Vieira", "Douglas A. G.", ""]]}, {"id": "1604.02752", "submitter": "Junan Zhu", "authors": "Junan Zhu, Ahmad Beirami, Dror Baron", "title": "Performance Trade-Offs in Multi-Processor Approximate Message Passing", "comments": "5 pages, 2 figures, to appear at 2016 IEEE International Symposium on\n  Information Theory (ISIT2016)", "journal-ref": null, "doi": "10.1109/ISIT.2016.7541385", "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider large-scale linear inverse problems in Bayesian settings. Our\ngeneral approach follows a recent line of work that applies the approximate\nmessage passing (AMP) framework in multi-processor (MP) computational systems\nby storing and processing a subset of rows of the measurement matrix along with\ncorresponding measurements at each MP node. In each MP-AMP iteration, nodes of\nthe MP system and its fusion center exchange lossily compressed messages\npertaining to their estimates of the input. There is a trade-off between the\nphysical costs of the reconstruction process including computation time,\ncommunication loads, and the reconstruction quality, and it is impossible to\nsimultaneously minimize all the costs. We pose this minimization as a\nmulti-objective optimization problem (MOP), and study the properties of the\nbest trade-offs (Pareto optimality) in this MOP. We prove that the achievable\nregion of this MOP is convex, and conjecture how the combined cost of\ncomputation and communication scales with the desired mean squared error. These\nproperties are verified numerically.\n", "versions": [{"version": "v1", "created": "Sun, 10 Apr 2016 22:28:10 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Zhu", "Junan", ""], ["Beirami", "Ahmad", ""], ["Baron", "Dror", ""]]}, {"id": "1604.02765", "submitter": "Rodrigo de Lamare", "authors": "R. C. de Lamare", "title": "Study of Distributed Spectrum Estimation Using Alternating Mixed\n  Discrete-Continuous Adaptation", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a distributed alternating mixed discrete-continuous\n(DAMDC) algorithm to approach the oracle algorithm based on the diffusion\nstrategy for parameter and spectrum estimation over sensor networks. A least\nmean squares (LMS) type algorithm that obtains the oracle matrix adaptively is\ndeveloped and compared with the existing sparsity-aware and conventional\nalgorithms. The proposed algorithm exhibits improved performance in terms of\nmean square deviation and power spectrum estimation accuracy. Numerical results\nshow that the DAMDC algorithm achieves excellent performance.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 00:40:49 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["de Lamare", "R. C.", ""]]}, {"id": "1604.02844", "submitter": "Mireya Paredes Ms.", "authors": "Mireya Paredes, Graham Riley and Mikel Lujan", "title": "Breadth First Search Vectorization on the Intel Xeon Phi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Breadth First Search (BFS) is a building block for graph algorithms and has\nrecently been used for large scale analysis of information in a variety of\napplications including social networks, graph databases and web searching. Due\nto its importance, a number of different parallel programming models and\narchitectures have been exploited to optimize the BFS. However, due to the\nirregular memory access patterns and the unstructured nature of the large\ngraphs, its efficient parallelization is a challenge. The Xeon Phi is a\nmassively parallel architecture available as an off-the-shelf accelerator,\nwhich includes a powerful 512 bit vector unit with optimized scatter and gather\nfunctions. Given its potential benefits, work related to graph traversing on\nthis architecture is an active area of research.\n  We present a set of experiments in which we explore architectural features of\nthe Xeon Phi and how best to exploit them in a top-down BFS algorithm but the\ntechniques can be applied to the current state-of-the-art hybrid, top-down plus\nbottom-up, algorithms.\n  We focus on the exploitation of the vector unit by developing an improved\nhighly vectorized OpenMP parallel algorithm, using vector intrinsics, and\nunderstanding the use of data alignment and prefetching. In addition, we\ninvestigate the impact of hyperthreading and thread affinity on performance, a\ntopic that appears under researched in the literature. As a result, we achieve\nwhat we believe is the fastest published top-down BFS algorithm on the version\nof Xeon Phi used in our experiments. The vectorized BFS top-down source code\npresented in this paper can be available on request as free-to-use software.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 09:02:17 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Paredes", "Mireya", ""], ["Riley", "Graham", ""], ["Lujan", "Mikel", ""]]}, {"id": "1604.02971", "submitter": "Lin Wang", "authors": "Lin Wang, Lei Jiao, Mateusz Guzek, Dzmitry Kliazovich, Pascal Bouvry", "title": "Achieving Energy Efficiency in Cloud Brokering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of cloud providers has brought substantial interoperability\ncomplexity to the public cloud market, in which cloud brokering has been\nplaying an important role. However, energy-related issues for public clouds\nhave not been well addressed in the literature. In this paper, we claim that\nthe broker is also situated in a perfect position where necessary actions can\nbe taken to achieve energy efficiency for public cloud systems, particularly\nthrough job assignment and scheduling. We formulate the problem by a mixed\ninteger program and prove its NP-hardness. Based on the complexity analysis, we\nsimplify the problem by introducing admission control on jobs. In the sequel,\noptimal job assignment can be done straightforwardly and the problem is\ntransformed into improving job admission rate by scheduling on two coupled\nphases: data transfer and job execution. The two scheduling phases are further\ndecoupled and we develop efficient scheduling algorithm for each of them.\nExperimental results show that the proposed solution can achieve significant\nreduction on energy consumption with admission rates improved as well, even in\nlarge-scale public cloud systems.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 14:21:00 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Wang", "Lin", ""], ["Jiao", "Lei", ""], ["Guzek", "Mateusz", ""], ["Kliazovich", "Dzmitry", ""], ["Bouvry", "Pascal", ""]]}, {"id": "1604.03034", "submitter": "Dezhi Fang", "authors": "Dezhi Fang, Duen Horng Chau", "title": "M3: Scaling Up Machine Learning via Memory Mapping", "comments": "2 pages, 1 figure, 1 table", "journal-ref": null, "doi": "10.1145/1235", "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To process data that do not fit in RAM, conventional wisdom would suggest\nusing distributed approaches. However, recent research has demonstrated virtual\nmemory's strong potential in scaling up graph mining algorithms on a single\nmachine. We propose to use a similar approach for general machine learning. We\ncontribute: (1) our latest finding that memory mapping is also a feasible\ntechnique for scaling up general machine learning algorithms like logistic\nregression and k-means, when data fits in or exceeds RAM (we tested datasets up\nto 190GB); (2) an approach, called M3, that enables existing machine learning\nalgorithms to work with out-of-core datasets through memory mapping, achieving\na speed that is significantly faster than a 4-instance Spark cluster, and\ncomparable to an 8-instance cluster.\n", "versions": [{"version": "v1", "created": "Mon, 11 Apr 2016 17:12:14 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Fang", "Dezhi", ""], ["Chau", "Duen Horng", ""]]}, {"id": "1604.03228", "submitter": "Jessica McClintock", "authors": "Jessica McClintock, Anthony Wirth", "title": "Efficient Parallel Algorithms for k-Center Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-center problem is one of several classic NP-hard clustering questions.\nFor contemporary massive data sets, RAM-based algorithms become impractical.\nAnd although there exist good sequential algorithms for k-center, they are not\neasily parallelizable.\n  In this paper, we design and implement parallel approximation algorithms for\nthis problem. We observe that Gonzalez's greedy algorithm can be efficiently\nparallelized in several MapReduce rounds; in practice, we find that two rounds\nare sufficient, leading to a 4-approximation. We contrast this with an existing\nparallel algorithm for k-center that runs in a constant number of rounds, and\noffers a 10-approximation. In depth runtime analysis reveals that this scheme\nis often slow, and that its sampling procedure only runs if k is sufficiently\nsmall, relative to the input size. To trade off runtime for approximation\nguarantee, we parameterize this sampling algorithm, and find in our experiments\nthat the algorithm is not only faster, but sometimes more effective. Yet the\nparallel version of Gonzalez is about 100 times faster than both its sequential\nversion and the parallel sampling algorithm, barely compromising solution\nquality.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 03:04:11 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["McClintock", "Jessica", ""], ["Wirth", "Anthony", ""]]}, {"id": "1604.03356", "submitter": "Francois Taiani", "authors": "Hicham Lakhlef (ASAP), Michel Raynal (ASAP), Fran\\c{c}ois Ta\\\"iani\n  (ASAP)", "title": "Vertex Coloring with Communication and Local Memory Constraints in\n  Synchronous Broadcast Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vertex coloring problem has received a lot of attention in the context of\nsynchronous round-based systems where, at each round, a process can send a\nmessage to all its neighbors, and receive a message from each of them. Hence,\nthis communication model is particularly suited to point-to-point communication\nchannels. Several vertex coloring algorithms suited to these systems have been\nproposed. They differ mainly in the number of rounds they require and the\nnumber of colors they use. This paper considers a broadcast/receive\ncommunication model in which message collisions and message conflicts can occur\n(a collision occurs when, during the same round, messages are sent to the same\nprocess by too many neighbors; a conflict occurs when a process and one of its\nneighbors broadcast during the same round). This communication model is suited\nto systems where processes share communication bandwidths. More precisely,the\npaper considers the case where, during a round, a process may either broadcast\na message to its neighbors or receive a message from at most $m$ of them. This\ncaptures communication-related constraints or a local memory constraint stating\nthat, whatever the number of neighbors of a process, its local memory allows it\nto receive and store at most $m$ messages during each round. The paper defines\nfirst the corresponding generic vertex multi-coloring problem (a vertex can\nhave several colors). It focuses then on tree networks, for which it presents a\nlower bound on the number of colors $K$ that are necessary (namely,\n$K=\\lceil\\frac{\\Delta}{m}\\rceil+1$, where $\\Delta$ is the maximal degree of the\ncommunication graph), and an ssociated coloring algorithm, which is optimal\nwith respect to $K$.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 11:56:07 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Lakhlef", "Hicham", "", "ASAP"], ["Raynal", "Michel", "", "ASAP"], ["Ta\u00efani", "Fran\u00e7ois", "", "ASAP"]]}, {"id": "1604.03410", "submitter": "Tim Besard", "authors": "Tim Besard, Pieter Verstraete and Bjorn De Sutter", "title": "High-level GPU programming in Julia", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GPUs are popular devices for accelerating scientific calculations. However,\nas GPU code is usually written in low-level languages, it breaks the\nabstractions of high-level languages popular with scientific programmers. To\novercome this, we present a framework for CUDA GPU programming in the\nhigh-level Julia programming language. This framework compiles Julia source\ncode for GPU execution, and takes care of the necessary low-level interactions\nusing modern code generation techniques to avoid run-time overhead.\n  Evaluating the framework and its APIs on a case study comprising the trace\ntransform from the field of image processing, we find that the impact on\nperformance is minimal, while greatly increasing programmer productivity. The\nmetaprogramming capabilities of the Julia language proved invaluable for\nenabling this. Our framework significantly improves usability of GPUs, making\nthem accessible for a wide range of programmers. It is available as free and\nopen-source software licensed under the MIT License.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 13:52:17 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Besard", "Tim", ""], ["Verstraete", "Pieter", ""], ["De Sutter", "Bjorn", ""]]}, {"id": "1604.03470", "submitter": "Nikolas Herbst", "authors": "Nikolas Herbst, Rouven Krebs, Giorgos Oikonomou, George Kousiouris,\n  Athanasia Evangelinou, Alexandru Iosup, and Samuel Kounev", "title": "Ready for Rain? A View from SPEC Research on the Future of Cloud Metrics", "comments": "SPEC Research Group - Cloud Working Group, Standard Performance\n  Evaluation Corporation (SPEC)", "journal-ref": null, "doi": null, "report-no": "Technical Report SPEC-RG-2016-01", "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past decade, cloud computing has emerged from a pursuit for a\nservice-driven information and communication technology (ICT), into a\nsignifcant fraction of the ICT market. Responding to the growth of the market,\nmany alternative cloud services and their underlying systems are currently\nvying for the attention of cloud users and providers. Thus, benchmarking them\nis needed, to enable cloud users to make an informed choice, and to enable\nsystem DevOps to tune, design, and evaluate their systems. This requires\nfocusing on old and new system properties, possibly leading to the re-design of\nclassic benchmarking metrics, such as expressing performance as throughput and\nlatency (response time), and the design of new, cloud-specififc metrics.\nAddressing this requirement, in this work we focus on four system properties:\n(i) elasticity of the cloud service, to accommodate large variations in the\namount of service requested, (ii) performance isolation between the tenants of\nshared cloud systems, (iii) availability of cloud services and systems, and the\n(iv) operational risk of running a production system in a cloud\nenvironment.Focusing on key metrics, for each of these properties we review the\nstate-of-the-art, then select or propose new metrics together with measurement\napproaches. We see the presented metrics as a foundation towards upcoming,\nindustry-standard, cloud benchmarks.\n  Keywords: Cloud Computing; Metrics; Measurement; Benchmarking; Elasticity;\nIsolation; Performance; Service Level Objective; Availability; Operational\nRisk.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 16:23:15 GMT"}], "update_date": "2016-04-13", "authors_parsed": [["Herbst", "Nikolas", ""], ["Krebs", "Rouven", ""], ["Oikonomou", "Giorgos", ""], ["Kousiouris", "George", ""], ["Evangelinou", "Athanasia", ""], ["Iosup", "Alexandru", ""], ["Kounev", "Samuel", ""]]}, {"id": "1604.03687", "submitter": "Robert Brijder", "authors": "Robert Brijder and David Doty and David Soloveichik", "title": "Democratic, Existential, and Consensus-Based Output Conventions in\n  Stable Computation by Chemical Reaction Networks", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.DC cs.LO q-bio.MN", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that some natural output conventions for error-free computation in\nchemical reaction networks (CRN) lead to a common level of computational\nexpressivity. Our main results are that the standard consensus-based output\nconvention have equivalent computational power to (1) existence-based and (2)\ndemocracy-based output conventions. The CRNs using the former output convention\nhave only \"yes\" voters, with the interpretation that the CRN's output is yes if\nany voters are present and no otherwise. The CRNs using the latter output\nconvention define output by majority vote among \"yes\" and \"no\" voters.\n  Both results are proven via a generalized framework that simultaneously\ncaptures several definitions, directly inspired by a Petri net result of\nEsparza, Ganty, Leroux, and Majumder [CONCUR 2015]. These results support the\nthesis that the computational expressivity of error-free CRNs is intrinsic, not\nsensitive to arbitrary definitional choices.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 08:28:42 GMT"}, {"version": "v2", "created": "Mon, 10 Jul 2017 12:11:14 GMT"}], "update_date": "2017-07-11", "authors_parsed": [["Brijder", "Robert", ""], ["Doty", "David", ""], ["Soloveichik", "David", ""]]}, {"id": "1604.03703", "submitter": "Edgar Solomonik", "authors": "Edgar Solomonik, Grey Ballard, James Demmel, and Torsten Hoefler", "title": "A communication-avoiding parallel algorithm for the symmetric eigenvalue\n  problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many large-scale scientific computations require eigenvalue solvers in a\nscaling regime where efficiency is limited by data movement. We introduce a\nparallel algorithm for computing the eigenvalues of a dense symmetric matrix,\nwhich performs asymptotically less communication than previously known\napproaches. We provide analysis in the Bulk Synchronous Parallel (BSP) model\nwith additional consideration for communication between a local memory and\ncache. Given sufficient memory to store $c$ copies of the symmetric matrix, our\nalgorithm requires $\\Theta(\\sqrt{c})$ less interprocessor communication than\npreviously known algorithms, for any $c\\leq p^{1/3}$ when using $p$ processors.\nThe algorithm first reduces the dense symmetric matrix to a banded matrix with\nthe same eigenvalues. Subsequently, the algorithm employs successive reduction\nto $O(\\log p)$ thinner banded matrices. We employ two new parallel algorithms\nthat achieve lower communication costs for the full-to-band and band-to-band\nreductions. Both of these algorithms leverage a novel QR factorization\nalgorithm for rectangular matrices.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 09:36:02 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Solomonik", "Edgar", ""], ["Ballard", "Grey", ""], ["Demmel", "James", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1604.03763", "submitter": "Shun Zheng", "authors": "Shun Zheng, Jialei Wang, Fen Xia, Wei Xu, Tong Zhang", "title": "A General Distributed Dual Coordinate Optimization Framework for\n  Regularized Loss Minimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In modern large-scale machine learning applications, the training data are\noften partitioned and stored on multiple machines. It is customary to employ\nthe \"data parallelism\" approach, where the aggregated training loss is\nminimized without moving data across machines. In this paper, we introduce a\nnovel distributed dual formulation for regularized loss minimization problems\nthat can directly handle data parallelism in the distributed setting. This\nformulation allows us to systematically derive dual coordinate optimization\nprocedures, which we refer to as Distributed Alternating Dual Maximization\n(DADM). The framework extends earlier studies described in (Boyd et al., 2011;\nMa et al., 2015a; Jaggi et al., 2014; Yang, 2013) and has rigorous theoretical\nanalyses. Moreover with the help of the new formulation, we develop the\naccelerated version of DADM (Acc-DADM) by generalizing the acceleration\ntechnique from (Shalev-Shwartz and Zhang, 2014) to the distributed setting. We\nalso provide theoretical results for the proposed accelerated version and the\nnew result improves previous ones (Yang, 2013; Ma et al., 2015a) whose runtimes\ngrow linearly on the condition number. Our empirical studies validate our\ntheory and show that our accelerated approach significantly improves the\nprevious state-of-the-art distributed dual coordinate optimization algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 13:33:32 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 15:00:24 GMT"}, {"version": "v3", "created": "Fri, 25 Aug 2017 02:42:32 GMT"}], "update_date": "2017-08-28", "authors_parsed": [["Zheng", "Shun", ""], ["Wang", "Jialei", ""], ["Xia", "Fen", ""], ["Xu", "Wei", ""], ["Zhang", "Tong", ""]]}, {"id": "1604.03821", "submitter": "Bilal Habib", "authors": "Bilal Habib, Ahmed Anber and Sultan Daud Khan", "title": "The Effect of Multi-core Communication Architecture on System\n  Performance", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MPSoCs are gaining popularity because of its potential to solve\ncomputationally expensive applications. A multi-core processor combines two or\nmore independent cores (normally a CPU) into a single package composed of a\nsingle integrated circuit (Chip). However, as the number of components on a\nsingle chip and their performance continue to increase, a shift from\ncomputation-based to communication-based design becomes mandatory. As a result,\nthe communication architecture plays a major role in the area, performance, and\nenergy consumption of the overall system. In this paper, multiple soft-cores\n(IPs) such as Micro Blaze in an FPGA is used to study the effect of different\nconnection topologies on the performance of a parallel program.\n", "versions": [{"version": "v1", "created": "Wed, 13 Apr 2016 15:09:38 GMT"}], "update_date": "2016-04-14", "authors_parsed": [["Habib", "Bilal", ""], ["Anber", "Ahmed", ""], ["Khan", "Sultan Daud", ""]]}, {"id": "1604.03871", "submitter": "Maria Potop-Butucaru", "authors": "Silvia Bonomi (DIAG), Antonella Del Pozzo (NPA, DIAG), Maria\n  Potop-Butucaru (NPA), S\\'ebastien Tixeuil (NPA)", "title": "Approximate Agreement under Mobile Byzantine Faults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address Approximate Agreement problem in the Mobile\nByzantine faults model. Our contribution is threefold. First, we propose the\nthe first mapping from the existing variants of Mobile Byzantine models to the\nMixed-Mode faults model.This mapping further help us to prove the correctness\nof class MSR (Mean-Subsequence-Reduce) Approximate Agreement algorithms in the\nMobile Byzantine fault model, and is of independent interest. Secondly, we\nprove lower bounds for solving Approximate Agreement under all existing Mobile\nByzantine faults models. Interestingly, these lower bounds are different from\nthe static bounds. Finally, we propose matching upper bounds. Our paper is the\nfirst to link the Mobile Byzantine Faults models and the Mixed-Mode Faults\nmodels, and we advocate that a similar approach can be adopted in order to\nprove the correctness of other classical distributed building blocks (e.g.\nagreement, clock synchronization, interactive consistency etc) under Mobile\nByzantine Faults model.\n", "versions": [{"version": "v1", "created": "Tue, 12 Apr 2016 14:50:55 GMT"}], "update_date": "2016-04-14", "authors_parsed": [["Bonomi", "Silvia", "", "DIAG"], ["Del Pozzo", "Antonella", "", "NPA, DIAG"], ["Potop-Butucaru", "Maria", "", "NPA"], ["Tixeuil", "S\u00e9bastien", "", "NPA"]]}, {"id": "1604.04103", "submitter": "Espen Robertsen", "authors": "Espen Mikal Robertsen, Tim Kahlke, Inge Alexander Raknes, Edvard\n  Pedersen, Erik Kj{\\ae}rner Semb, Martin Ernstsen, Lars Ailo Bongo, Nils Peder\n  Willassen", "title": "META-pipe - Pipeline Annotation, Analysis and Visualization of Marine\n  Metagenomic Sequence Data", "comments": "22 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The marine environment is one of the most important sources for microbial\nbiodiversity on the planet. These microbes are drivers for many biogeochemical\nprocesses, and their enormous genetic potential is still not fully explored or\nexploited. Marine metagenomics (DNA shotgun sequencing), not only offers\nopportunities for studying structure and function of microbial communities, but\nalso identification of novel biocatalysts and bioactive compounds. However,\ndata analysis, management, storage, processing and interpretation are\nsignificant challenges in marine metagenomics due to the high diversity in\nsamples and the size of the marine flagship projects. We provide a new\npipeline, META-pipe, for marine metagenomics analysis. It offers pre-\nprocessing, assembly, taxonomic classification and functional analysis. To\nreduce the effort to develop and deploy it, we have integrated existing\nbiological analysis frameworks, and compute and storage infrastructure\nresources. Our current META-pipe web service provides integration with identity\nprovider services, distributed storage, computation on a Supercomputer, Galaxy\nworkflows, and interactive data visualizations. We have evaluated the\nscalability and performance of the analysis pipeline. Our results demonstrate\nhow to develop and deploy a pipeline on distributed compute and storage\nresources, and discusses important challenges related to this process.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 10:33:55 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Robertsen", "Espen Mikal", ""], ["Kahlke", "Tim", ""], ["Raknes", "Inge Alexander", ""], ["Pedersen", "Edvard", ""], ["Semb", "Erik Kj\u00e6rner", ""], ["Ernstsen", "Martin", ""], ["Bongo", "Lars Ailo", ""], ["Willassen", "Nils Peder", ""]]}, {"id": "1604.04197", "submitter": "Christina Rickmann", "authors": "Christina Rickmann", "title": "Topological Self-Stabilization with Name-Passing Process Calculi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Topological self-stabilization describes the ability of a distributed system\nto let the nodes themselves establish a meaningful overlay network. Independent\nfrom the initial network topology, the system converges to the desired topology\nvia forwarding, inserting, and deleting links to neighboring nodes.\nName-passing process calculi, like the pi-calculus, are a well-known and widely\nused method to model concurrent and distributed algorithms. The pi-calculus is\ndesigned to naturally express processes with a changing link infrastructure, as\nthe communication between processes may carry information that can be used for\na change in the linkage between the processes. We redesign a simple local\nlinearization algorithm with asynchronous message-passing that was originally\ndesigned for a shared memory model. We use an extended localized pi-calculus, a\nvariant of the pi-calculus, to model the algorithm. Subsequently, we formally\nprove the self-stabilizing properties closure, weak convergence for every\narbitrary initial configuration, and strong convergence for two special cases.\nIn our proofs we utilize rather an assertional reasoning than an action-based\nstyle. Furthermore, we describe the challenges in proving (strong) convergence\nin the general case. Additionally, we give strong arguments for strong\nconvergence, supported by further proven lemmata, and discuss different\napproaches for a formal proof.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 15:58:16 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Rickmann", "Christina", ""]]}, {"id": "1604.04205", "submitter": "James Ross", "authors": "James A. Ross, David A. Richie", "title": "Implementing OpenSHMEM for the Adapteva Epiphany RISC Array Processor", "comments": "4 pages, 1 figure, accepted to ICCS'16 ALCHEMY workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The energy-efficient Adapteva Epiphany architecture exhibits massive\nmany-core scalability in a physically compact 2D array of RISC cores with a\nfast network-on-chip (NoC). With fully divergent cores capable of MIMD\nexecution, the physical topology and memory-mapped capabilities of the core and\nnetwork translate well to partitioned global address space (PGAS) parallel\nprogramming models. Following an investigation into the use of two-sided\ncommunication using threaded MPI, one-sided communication using SHMEM is being\nexplored. Here we present work in progress on the development of an OpenSHMEM\n1.2 implementation for the Epiphany architecture.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 16:20:55 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Ross", "James A.", ""], ["Richie", "David A.", ""]]}, {"id": "1604.04206", "submitter": "K\\'evin Atighehchi", "authors": "Kevin Atighehchi", "title": "Note on Optimal Trees for Parallel Hash Functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent work shows how we can optimize a tree based mode of operation for a\nrate 1 hash function. In particular, an algorithm and a theorem are presented\nfor selecting a good tree topology in order to optimize both the running time\nand the number of processors at each step of the computation. Because this\npaper deals only with trees having their leaves at the same depth, the number\nof saved computing resources is perfectly optimal only for this category of\ntrees. In this note, we address the more general case and describe a simple\nalgorithm which, starting from such a tree topology, reworks it to further\nreduce the number of processors and the total amount of work done to hash a\nmessage.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 16:23:59 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Atighehchi", "Kevin", ""]]}, {"id": "1604.04207", "submitter": "James Ross", "authors": "David A. Richie, James A. Ross", "title": "Advances in Run-Time Performance and Interoperability for the Adapteva\n  Epiphany Coprocessor", "comments": "11 pages, 3 figures, accepted to ICCS'16 ALCHEMY workshop", "journal-ref": null, "doi": "10.1016/j.procs.2016.05.478", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The energy-efficient Adapteva Epiphany architecture exhibits massive\nmany-core scalability in a physically compact 2D array of RISC cores with a\nfast network-on-chip (NoC). The architecture presents many features and\nconstraints which contribute to software design challenges for the application\ndeveloper. Addressing these challenges within the software stack that supports\napplication development is critical to improving productivity and expanding the\nrange of applications for the architecture. We report here on advances that\nhave been made in the COPRTHR-2 software stack targeting the Epiphany\narchitecture that address critical issues identified in previous work.\nSpecifically, we describe improvements that bring greater control and precision\nto the design of compact compiled binary programs in the context of the limited\nper-core local memory of the architecture. We describe a new design for\nrun-time support that has been implemented to dramatically improve the program\nload and execute performance and capabilities. Finally, we describe\ndevelopments that advance host-coprocessor interoperability to expand the\nfunctionality available to the application developer.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 16:24:10 GMT"}], "update_date": "2017-01-18", "authors_parsed": [["Richie", "David A.", ""], ["Ross", "James A.", ""]]}, {"id": "1604.04217", "submitter": "Ioannis Lamprou", "authors": "Ioannis Lamprou, Russell Martin, Sven Schewe", "title": "Fast Two-Robot Disk Evacuation with Wireless Communication", "comments": "18 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the fast evacuation problem, we study the path planning problem for two\nrobots who want to minimize the worst-case evacuation time on the unit disk.\nThe robots are initially placed at the center of the disk. In order to\nevacuate, they need to reach an unknown point, the exit, on the boundary of the\ndisk. Once one of the robots finds the exit, it will instantaneously notify the\nother agent, who will make a beeline to it.\n  The problem has been studied for robots with the same speed~\\cite{s1}. We\nstudy a more general case where one robot has speed $1$ and the other has speed\n$s \\geq 1$. We provide optimal evacuation strategies in the case that $s \\geq\nc_{2.75} \\approx 2.75$ by showing matching upper and lower bounds on the\nworst-case evacuation time. For $1\\leq s < c_{2.75}$, we show (non-matching)\nupper and lower bounds on the evacuation time with a ratio less than $1.22$.\nMoreover, we demonstrate that a generalization of the two-robot search strategy\nfrom~\\cite{s1} is outperformed by our proposed strategies for any $s \\geq\nc_{1.71} \\approx 1.71$.\n", "versions": [{"version": "v1", "created": "Thu, 14 Apr 2016 16:58:07 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Lamprou", "Ioannis", ""], ["Martin", "Russell", ""], ["Schewe", "Sven", ""]]}, {"id": "1604.04320", "submitter": "Aryan Azimzadeh", "authors": "Aryan Azimzadeh, Nasseh Tabrizi", "title": "A Dynamic Power Management Schema for Multi-Tier Data Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An issue of great concern as it relates to global warming is power\nconsumption and efficient use of computers especially in large data centers.\nData centers have an important role in IT infrastructures because of their huge\npower consumption.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 00:32:24 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Azimzadeh", "Aryan", ""], ["Tabrizi", "Nasseh", ""]]}, {"id": "1604.04471", "submitter": "David Tian", "authors": "Wenhong Tian, Guangchun Luo, Ling Tian, and Aiguo Chen", "title": "On Dynamic Job Ordering and Slot Configurations for Minimizing the\n  Makespan Of Multiple MapReduce Jobs", "comments": "Under Review of IEEE Trans. on Service Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  MapReduce is a popular parallel computing paradigm for Big Data processing in\nclusters and data centers. It is observed that different job execution orders\nand MapReduce slot configurations for a MapReduce workload have significantly\ndifferent performance with regarding to the makespan, total completion time,\nsystem utilization and other performance metrics. There are quite a few\nalgorithms on minimizing makespan of multiple MapReduce jobs. However, these\nalgorithms are heuristic or suboptimal. The best known algorithm for minimizing\nthe makespan is 3-approximation by applying Johnson rule. In this paper, we\npropose an approach called UAAS algorithm to meet the conditions of classical\nJohnson model. Then we can still use Johnson model for an optimal solution. We\nexplain how to adapt to Johnson model and provide a few key features of our\nproposed method.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 12:54:09 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Tian", "Wenhong", ""], ["Luo", "Guangchun", ""], ["Tian", "Ling", ""], ["Chen", "Aiguo", ""]]}, {"id": "1604.04482", "submitter": "David Tian", "authors": "Guozhong Li, Yaqiu Jiang, Wutong Yang, Chaojie Huang, Wenhong Tian", "title": "Self-Adaptive Consolidation of Virtual Machines For Energy-Efficiency in\n  the Cloud", "comments": "Under Review of GlobalCom", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In virtualized data centers, consolidation of Virtual Machines (VMs) on\nminimizing the number of total physical machines (PMs) has been recognized as a\nvery efficient approach. This paper considers the energy-efficient\nconsolidation of VMs in a Cloud Data center. Concentrating on CPU-intensive\napplications, the objective is to schedule all requests non-preemptively,\nsubjecting to constraints of PM capacities and running time interval spans,\nsuch that the total energy consumption of all PMs is minimized (called MinTE\nfor abbreviation). The MinTE problem is NP-complete in general. We propose a\nself-adaptive approached called SAVE. The approach makes decisions of the\nassignment and migration of VMs by probabilistic processes and is based\nexclusively on local information, therefore it is very simple to implement.\nBoth simulation and real environment test show that our proposed method SAVE\ncan reduce energy consumption about 30% against VMWare DRS and 10-20% against\nEcoCloud on average.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 13:05:03 GMT"}], "update_date": "2016-04-18", "authors_parsed": [["Li", "Guozhong", ""], ["Jiang", "Yaqiu", ""], ["Yang", "Wutong", ""], ["Huang", "Chaojie", ""], ["Tian", "Wenhong", ""]]}, {"id": "1604.04575", "submitter": "Roly Perera", "authors": "Roly Perera, James Cheney", "title": "Proof-relevant $\\pi$-calculus: a constructive account of concurrency and\n  causality", "comments": "Under consideration for publication in Mathematical Structures in\n  Computer Science. arXiv admin note: text overlap with arXiv:1507.08054", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formalisation in Agda of the theory of concurrent transitions,\nresiduation, and causal equivalence of traces for the pi-calculus. Our\nformalisation employs de Bruijn indices and dependently-typed syntax, and\naligns the \"proved transitions\" proposed by Boudol and Castellani in the\ncontext of CCS with the proof terms naturally present in Agda's representation\nof the labelled transition relation. Our main contributions are proofs of the\n\"diamond lemma\" for the residuals of concurrent transitions and a formal\ndefinition of equivalence of traces up to permutation of transitions.\n  In the pi-calculus transitions represent propagating binders whenever their\nactions involve bound names. To accommodate these cases, we require a more\ngeneral diamond lemma where the target states of equivalent traces are no\nlonger identical, but are related by a braiding that rewires the bound and free\nnames to reflect the particular interleaving of events involving binders. Our\napproach may be useful for modelling concurrency in other languages where\ntransitions carry metadata sensitive to particular interleavings, such as\ndynamically allocated memory addresses.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 17:26:22 GMT"}, {"version": "v2", "created": "Sun, 5 Feb 2017 12:13:09 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Perera", "Roly", ""], ["Cheney", "James", ""]]}, {"id": "1604.04591", "submitter": "Christopher M. Poskitt", "authors": "Mischael Schill, Christopher M. Poskitt, Bertrand Meyer", "title": "An Interference-Free Programming Model for Network Objects", "comments": null, "journal-ref": "In Proc. International Conference on Coordination Models and\n  Languages (COORDINATION 2016), volume 9686 of LNCS, pages 227-244. Springer,\n  2016", "doi": "10.1007/978-3-319-39519-7_14", "report-no": null, "categories": "cs.DC cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network objects are a simple and natural abstraction for distributed\nobject-oriented programming. Languages that support network objects, however,\noften leave synchronization to the user, along with its associated pitfalls,\nsuch as data races and the possibility of failure. In this paper, we present\nD-SCOOP, a distributed programming model that allows for interference-free and\ntransaction-like reasoning on (potentially multiple) network objects, with\nsynchronization handled automatically, and network failures managed by a\ncompensation mechanism. We achieve this by leveraging the runtime semantics of\na multi-threaded object-oriented concurrency model, directly generalizing it\nwith a message-based protocol for efficiently coordinating remote objects. We\npresent our pathway to fusing these contrasting but complementary ideas, and\nevaluate the performance overhead of the automatic synchronization in D-SCOOP,\nfinding that it comes close to---or outperforms---explicit locking-based\nsynchronization in Java RMI.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 18:32:52 GMT"}], "update_date": "2016-05-25", "authors_parsed": [["Schill", "Mischael", ""], ["Poskitt", "Christopher M.", ""], ["Meyer", "Bertrand", ""]]}, {"id": "1604.04638", "submitter": "Haipeng Cai", "authors": "Haipeng Cai and Douglas Thain", "title": "DISTEA: Efficient Dynamic Impact Analysis for Distributed Systems", "comments": "12 pages, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamic impact analysis is a fundamental technique for understanding the\nimpact of specific program entities, or changes to them, on the rest of the\nprogram for concrete executions. However, existing techniques are either\ninapplicable or of very limited utility for distributed programs running in\nmultiple concurrent processes. This paper presents DISTEA, a technique and tool\nfor dynamic impact analysis of distributed systems. By partially ordering\ndistributed method-execution events and inferring causality from the ordered\nevents, DISTEA can predict impacts propagated both within and across process\nboundaries. We implemented DISTEA for Java and applied it to four distributed\nprograms of various types and sizes, including two enterprise systems. We also\nevaluated the precision and practical usefulness of DISTEA, and demonstrated\nits application in program comprehension, through two case studies. The results\nshow that DISTEA is highly scalable, more effective than existing alternatives,\nand instrumental to understanding distributed systems and their executions.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 20:40:12 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Cai", "Haipeng", ""], ["Thain", "Douglas", ""]]}, {"id": "1604.04661", "submitter": "Shihao Ji", "authors": "Shihao Ji, Nadathur Satish, Sheng Li, and Pradeep Dubey", "title": "Parallelizing Word2Vec in Shared and Distributed Memory", "comments": "Added more results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CL stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Word2Vec is a widely used algorithm for extracting low-dimensional vector\nrepresentations of words. It generated considerable excitement in the machine\nlearning and natural language processing (NLP) communities recently due to its\nexceptional performance in many NLP applications such as named entity\nrecognition, sentiment analysis, machine translation and question answering.\nState-of-the-art algorithms including those by Mikolov et al. have been\nparallelized for multi-core CPU architectures but are based on vector-vector\noperations that are memory-bandwidth intensive and do not efficiently use\ncomputational resources. In this paper, we improve reuse of various data\nstructures in the algorithm through the use of minibatching, hence allowing us\nto express the problem using matrix multiply operations. We also explore\ndifferent techniques to distribute word2vec computation across nodes in a\ncompute cluster, and demonstrate good strong scalability up to 32 nodes. In\ncombination, these techniques allow us to scale up the computation near\nlinearly across cores and nodes, and process hundreds of millions of words per\nsecond, which is the fastest word2vec implementation to the best of our\nknowledge.\n", "versions": [{"version": "v1", "created": "Fri, 15 Apr 2016 23:40:04 GMT"}, {"version": "v2", "created": "Mon, 8 Aug 2016 17:45:00 GMT"}], "update_date": "2016-08-09", "authors_parsed": [["Ji", "Shihao", ""], ["Satish", "Nadathur", ""], ["Li", "Sheng", ""], ["Dubey", "Pradeep", ""]]}, {"id": "1604.04689", "submitter": "Gang Mei", "authors": "Gang Mei, Nengxiong Xu, Hong Tian, Shengwei Li", "title": "A Parallel Solution to Finding Nodal Neighbors in Generic Meshes", "comments": "Short paper. 6 pages, 4 figures, 1 table. Authors' information has\n  been corrected", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we specifically present a parallel solution to finding the\none-ring neighboring nodes and elements for each vertex in generic meshes. The\nfinding of nodal neighbors is computationally straightforward but expensive for\nlarge meshes. To improve the efficiency, the parallelism is adopted by\nutilizing the modern Graphics Processing Unit (GPU). The presented parallel\nsolution is heavily dependent on the parallel sorting, scan, and reduction, and\ncan be applied to determine both the neighboring nodes and elements. To\nevaluate the performance, the parallel solution is compared to the\ncorresponding serial solution. Experimental results show that: our parallel\nsolution can achieve the speedups of approximately 55 and 90 over the\ncorresponding serial solution for finding neighboring nodes and elements,\nrespectively. Our parallel solution is efficient and easy to implement, but\nrequires the allocation of large device memory.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 04:43:25 GMT"}, {"version": "v2", "created": "Mon, 2 May 2016 02:03:29 GMT"}, {"version": "v3", "created": "Thu, 5 May 2016 13:38:36 GMT"}], "update_date": "2016-05-06", "authors_parsed": [["Mei", "Gang", ""], ["Xu", "Nengxiong", ""], ["Tian", "Hong", ""], ["Li", "Shengwei", ""]]}, {"id": "1604.04740", "submitter": "Yiannis Andreopoulos", "authors": "Mohammad Ashraful Anam and Yiannis Andreopoulos", "title": "Reliable Linear, Sesquilinear and Bijective Operations On Integer Data\n  Streams Via Numerical Entanglement", "comments": "to appear in IEEE Trans. on Signal Processing, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new technique is proposed for fault-tolerant linear, sesquilinear and\nbijective (LSB) operations on $M$ integer data streams ($M\\geq3$), such as:\nscaling, additions/subtractions, inner or outer vector products, permutations\nand convolutions. In the proposed method, the $M$ input integer data streams\nare linearly superimposed to form $M$ numerically-entangled integer data\nstreams that are stored in-place of the original inputs. A series of LSB\noperations can then be performed directly using these entangled data streams.\nThe results are extracted from the $M$ entangled output streams by additions\nand arithmetic shifts. Any soft errors affecting any single disentangled output\nstream are guaranteed to be detectable via a specific post-computation\nreliability check. In addition, when utilizing a separate processor core for\neach of the $M$ streams, the proposed approach can recover all outputs after\nany single fail-stop failure. Importantly, unlike algorithm-based fault\ntolerance (ABFT) methods, the number of operations required for the\nentanglement, extraction and validation of the results is linearly related to\nthe number of the inputs and does not depend on the complexity of the performed\nLSB operations. We have validated our proposal in an Intel processor (Haswell\narchitecture with AVX2 support) via fast Fourier transforms, circular\nconvolutions, and matrix multiplication operations. Our analysis and\nexperiments reveal that the proposed approach incurs between $0.03\\%$ to $7\\%$\nreduction in processing throughput for a wide variety of LSB operations. This\noverhead is 5 to 1000 times smaller than that of the equivalent ABFT method\nthat uses a checksum stream. Thus, our proposal can be used in fault-generating\nprocessor hardware or safety-critical applications, where high reliability is\nrequired without the cost of ABFT or modular redundancy.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 12:30:12 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Anam", "Mohammad Ashraful", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "1604.04772", "submitter": "Thejaka Kanewala", "authors": "Thejaka Amila Kanewala, Marcin Zalewski and Andrew Lumsdaine", "title": "Abstract Graph Machine", "comments": "10 pages, including Appendix and References", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An Abstract Graph Machine(AGM) is an abstract model for distributed memory\nparallel stabilizing graph algorithms. A stabilizing algorithm starts from a\nparticular initial state and goes through series of different state changes\nuntil it converges. The AGM adds work dependency to the stabilizing algorithm.\nThe work is processed within the processing function. All processes in the\nsystem execute the same processing function. Before feeding work into the\nprocessing function, work is ordered using a strict weak ordering relation. The\nstrict weak ordering relation divides work into equivalence classes, hence work\nwithin a single equivalence class can be processed in parallel, but work in\ndifferent equivalence classes must be executed in the order they appear in\nequivalence classes. The paper presents the AGM model, semantics and AGM models\nfor several existing distributed memory parallel graph algorithms.\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 16:26:29 GMT"}, {"version": "v2", "created": "Thu, 28 Apr 2016 19:13:02 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Kanewala", "Thejaka Amila", ""], ["Zalewski", "Marcin", ""], ["Lumsdaine", "Andrew", ""]]}, {"id": "1604.04804", "submitter": "Yiannis Andreopoulos", "authors": "Joseph Doyle, Vasileios Giotsas, Mohammad Ashraful Anam and Yiannis\n  Andreopoulos", "title": "Cloud Instance Management and Resource Prediction For\n  Computation-as-a-Service Platforms", "comments": "Proc. IEEE Int. Conf. on Cloud Engineering, IC2E 2016, April 2016,\n  Berlin, Germany", "journal-ref": null, "doi": "10.1109/IC2E.2016.36", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computation-as-a-Service (CaaS) offerings have gained traction in the last\nfew years due to their effectiveness in balancing between the scalability of\nSoftware-as-a-Service and the customisation possibilities of\nInfrastructure-as-a-Service platforms. To function effectively, a CaaS platform\nmust have three key properties: (i) reactive assignment of individual\nprocessing tasks to available cloud instances (compute units) according to\navailability and predetermined time-to-completion (TTC) constraints; (ii)\naccurate resource prediction; (iii) efficient control of the number of cloud\ninstances servicing workloads, in order to optimize between completing\nworkloads in a timely fashion and reducing resource utilization costs. In this\npaper, we propose three approaches that satisfy these properties\n(respectively): (i) a service rate allocation mechanism based on proportional\nfairness and TTC constraints; (ii) Kalman-filter estimates for resource\nprediction; and (iii) the use of additive increase multiplicative decrease\n(AIMD) algorithms (famous for being the resource management in the transport\ncontrol protocol) for the control of the number of compute units servicing\nworkloads. The integration of our three proposals\\ into a single CaaS platform\nis shown to provide for more than 27% reduction in Amazon EC2 spot instance\ncost against methods based on reactive resource prediction and 38% to 60%\nreduction of the billing cost against the current state-of-the-art in CaaS\nplatforms (Amazon Lambda and Autoscale).\n", "versions": [{"version": "v1", "created": "Sat, 16 Apr 2016 22:03:27 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Doyle", "Joseph", ""], ["Giotsas", "Vasileios", ""], ["Anam", "Mohammad Ashraful", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "1604.04815", "submitter": "Yongchao Liu", "authors": "Yongchao Liu, Srinivas Aluru", "title": "LightScan: Faster Scan Primitive on CUDA Compatible Manycore Processors", "comments": "21 pages, 6 figures, submitted to Journal of Parallel and Distributed\n  Computing on Jan 09, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scan (or prefix sum) is a fundamental and widely used primitive in parallel\ncomputing. In this paper, we present LightScan, a faster parallel scan\nprimitive for CUDA-enabled GPUs, which investigates a hybrid model combining\nintra-block computation and inter-block communication to perform a scan. Our\nalgorithm employs warp shuffle functions to implement fast intra-block\ncomputation and takes advantage of globally coherent L2 cache and the\nassociated parallel thread execution (PTX) assembly instructions to realize\nlightweight inter-block communication. Performance evaluation using a single\nTesla K40c GPU shows that LightScan outperforms existing GPU algorithms and\nimplementations, and yields a speedup of up to 2.1, 2.4, 1.5 and 1.2 over the\nleading CUDPP, Thrust, ModernGPU and CUB implementations running on the same\nGPU, respectively. Furthermore, LightScan runs up to 8.9 and 257.3 times faster\nthan Intel TBB running on 16 CPU cores and an Intel Xeon Phi 5110P coprocessor,\nrespectively. Source code of LightScan is available at\nhttp://cupbb.sourceforge.net.\n", "versions": [{"version": "v1", "created": "Sun, 17 Apr 2016 01:22:58 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Liu", "Yongchao", ""], ["Aluru", "Srinivas", ""]]}, {"id": "1604.04951", "submitter": "Junchul Choi", "authors": "Junchul Choi, Hyunok Oh, Soonhoi Ha", "title": "A Hybrid Performance Analysis Technique for Distributed Real-Time\n  Embedded Systems", "comments": "29 pages (25 page paper, 4 page appendix), 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It remains a challenging problem to tightly estimate the worst case response\ntime of an application in a distributed embedded system, especially when there\nare dependencies between tasks. We discovered that the state-of-the art\ntechniques considering task dependencies either fail to obtain a conservative\nbound or produce a loose upper bound. We propose a novel conservative\nperformance analysis, called hybrid performance analysis, combining the\nresponse time analysis technique and the scheduling time bound analysis\ntechnique to compute a tighter bound fast. Through extensive experiments with\nrandomly generated graphs, superior performance of our proposed approach\ncompared with previous methods is confirmed.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 01:24:48 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Choi", "Junchul", ""], ["Oh", "Hyunok", ""], ["Ha", "Soonhoi", ""]]}, {"id": "1604.04997", "submitter": "James Stevens", "authors": "James Stevens and Andreas Kl\\\"ockner", "title": "A Unified, Hardware-Fitted, Cross-GPU Performance Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a mechanism to symbolically gather performance-relevant operation\ncounts from numerically-oriented subprograms (`kernels') expressed in the Loopy\nprogramming system, and apply these counts in a simple, linear model of kernel\nrun time. We use a series of `performance-instructive' kernels to fit the\nparameters of a unified model to the performance characteristics of GPU\nhardware from multiple hardware generations and vendors. We evaluate the\npredictive power of the model on a broad array of computational kernels\nrelevant to scientific computing. In terms of the geometric mean, our simple,\nvendor- and GPU-type-independent model achieves relative accuracy comparable to\nthat of previously published work using hardware specific models.\n", "versions": [{"version": "v1", "created": "Mon, 18 Apr 2016 05:49:56 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Stevens", "James", ""], ["Kl\u00f6ckner", "Andreas", ""]]}, {"id": "1604.05428", "submitter": "Sudipta Saha", "authors": "Sudipta Saha, Animesh Mukherjee and Niloy Ganguly", "title": "Coverage analysis of information dissemination in throwbox-augmented DTN", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper uses a bipartite network model to calculate the coverage achieved\nby a delay-tolerant information dissemination algorithm in a specialized\nsetting. The specialized Delay Tolerant Network (DTN) system comprises static\nmessage buffers or throwboxes kept in popular places besides the mobile agents\nhopping from one place to another. We identify that an information\ndissemination technique that exploits the throwbox infrastructure can cover\nonly a fixed number of popular places irrespective of the time spent. We notice\nthat such DTN system has a natural bipartite network correspondence where two\nsets are the popular places and people visiting those places. This helps\nleveraging the theories of evolving bipartite networks (BNW) to provide an\nappropriate explanation of the observed temporal invariance of information\ncoverage over the DTN. In this work, we first show that information coverage\ncan be estimated by the size of the largest component in the thresholded\none-mode projection of BNW. Next, we also show that exploiting a special\nproperty of BNW, the size of the largest component size can be calculated from\nthe degree distribution. Combining these two, we derive a closed form simple\nequation to accurately predict the amount of information coverage in DTN which\nis almost impossible to achieve using the traditional techniques such as\nepidemic or Markov modeling. The equation shows that full coverage quickly\nbecomes extremely difficult to achieve if the number of places increases while\nvariation in agent's activity helps in covering more places.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 04:31:47 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Saha", "Sudipta", ""], ["Mukherjee", "Animesh", ""], ["Ganguly", "Niloy", ""]]}, {"id": "1604.05442", "submitter": "Binqi Zhang", "authors": "Binqi Zhang, Chen Wang, Bing Bing Zhou, Albert Y. Zomaya", "title": "Improving Raw Image Storage Efficiency by Exploiting Similarity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the temporal and spatial storage efficiency, researchers have\nintensively studied various techniques, including compression and\ndeduplication. Through our evaluation, we find that methods such as photo tags\nor local features help to identify the content-based similar- ity between raw\nimages. The images can then be com- pressed more efficiently to get better\nstorage space sav- ings. Furthermore, storing similar raw images together\nenables rapid data sorting, searching and retrieval if the images are stored in\na distributed and large-scale envi- ronment by reducing fragmentation. In this\npaper, we evaluated the compressibility by designing experiments and observing\nthe results. We found that on a statistical basis the higher similarity photos\nhave, the better com- pression results are. This research helps provide a clue\nfor future large-scale storage system design.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 06:29:36 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Zhang", "Binqi", ""], ["Wang", "Chen", ""], ["Zhou", "Bing Bing", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "1604.05676", "submitter": "Ramses van Zon", "authors": "Marcelo Ponce, Erik Spence, Daniel Gruner, Ramses van Zon", "title": "Scientific Computing, High-Performance Computing and Data Science in\n  Higher Education", "comments": "Updated discussion and title", "journal-ref": "Journal of Computational Science Education vol 10 (2019)", "doi": "10.22369/issn.2153-4136/10/1/5", "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an overview of current academic curricula for Scientific\nComputing, High-Performance Computing and Data Science. After a survey of\ncurrent academic and non-academic programs across the globe, we focus on\nCanadian programs and specifically on the education program of the SciNet HPC\nConsortium, using its detailed enrollment and course statistics for the past\nfour to five years. Not only do these data display a steady and rapid increase\nin the demand for research-computing instruction, they also show a clear shift\nfrom traditional (high performance) computing to data-oriented methods. It is\nargued that this growing demand warrants specialized research computing\ndegrees. The possible curricula of such degrees are described next, taking\nexisting programs as an example, and adding SciNet's experiences of student\ndesires as well as trends in advanced research computing.\n", "versions": [{"version": "v1", "created": "Tue, 19 Apr 2016 18:06:37 GMT"}, {"version": "v2", "created": "Thu, 16 Jun 2016 15:27:46 GMT"}], "update_date": "2019-01-17", "authors_parsed": [["Ponce", "Marcelo", ""], ["Spence", "Erik", ""], ["Gruner", "Daniel", ""], ["van Zon", "Ramses", ""]]}, {"id": "1604.05897", "submitter": "Valentin Puente", "authors": "Valentin Puente, Jos\\'e \\'Angel Gregorio", "title": "CLAASIC: a Cortex-Inspired Hardware Accelerator", "comments": "Submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.ET cs.AR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work explores the feasibility of specialized hardware implementing the\nCortical Learning Algorithm (CLA) in order to fully exploit its inherent\nadvantages. This algorithm, which is inspired in the current understanding of\nthe mammalian neo-cortex, is the basis of the Hierarchical Temporal Memory\n(HTM). In contrast to other machine learning (ML) approaches, the structure is\nnot application dependent and relies on fully unsupervised continuous learning.\nWe hypothesize that a hardware implementation will be able not only to extend\nthe already practical uses of these ideas to broader scenarios but also to\nexploit the hardware-friendly CLA characteristics. The architecture proposed\nwill enable an unfeasible scalability for software solutions and will fully\ncapitalize on one of the many CLA advantages: low computational requirements\nand reduced storage utilization. Compared to a state-of-the-art CLA software\nimplementation it could be possible to improve by 4 orders of magnitude in\nperformance and up to 8 orders of magnitude in energy efficiency. We propose to\nuse a packet-switched network to tackle this. The paper addresses the\nfundamental issues of such an approach, proposing solutions to achieve scalable\nsolutions. We will analyze cost and performance when using well-known\narchitecture techniques and tools. The results obtained suggest that even with\nCMOS technology, under constrained cost, it might be possible to implement a\nlarge-scale system. We found that the proposed solutions enable a saving of 90%\nof the original communication costs running either synthetic or realistic\nworkloads.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 11:18:06 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2016 14:28:28 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Puente", "Valentin", ""], ["Gregorio", "Jos\u00e9 \u00c1ngel", ""]]}, {"id": "1604.05915", "submitter": "Antoine Naudin", "authors": "J\\'er\\'emie Chalopin, Emmanuel Godard and Antoine Naudin", "title": "Using Binoculars for Fast Exploration and Map Construction in Chordal\n  Graphs and Extensions", "comments": "arXiv admin note: text overlap with arXiv:1505.00599", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the exploration and mapping of anonymous graphs by a mobile\nagent. It is long known that, without global information about the graph, it is\nnot possible to make the agent halt after the exploration except if the graph\nis a tree. We therefore endow the agent with binoculars, a sensing device that\ncan show the local structure of the environment at a constant distance of the\nagent's current location and investigate networks that can be efficiently\nexplored in this setting.\n  In the case of trees, the exploration without binoculars is fast (i.e. using\na DFS traversal of the graph, there is a number of moves linear in the number\nof nodes). We consider here the family of Weetman graphs that is a\ngeneralization of the standard family of chordal graphs and present a new\ndeterministic algorithm that realizes Exploration of any Weetman graph, without\nknowledge of size or diameter and for any port numbering. The number of moves\nis linear in the number of nodes, despite the fact that Weetman graphs are not\nsparse, some having a number of edges that is quadratic in the number of nodes.\n  At the end of the Exploration, the agent has also computed a map of the\nanonymous graph.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 12:29:30 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Chalopin", "J\u00e9r\u00e9mie", ""], ["Godard", "Emmanuel", ""], ["Naudin", "Antoine", ""]]}, {"id": "1604.05959", "submitter": "Gregory Chockler", "authors": "Vita Bortnikov, Gregory Chockler, Dmitri Perelman, Alexey Roytman,\n  Shlomit Shachor, lya Shnayderman", "title": "FRAPPE: Fast Replication Platform for Elastic Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elasticity is critical for today's cloud services, which must be able to\nquickly adapt to dynamically changing load conditions and resource\navailability. We introduce FRAPPE, a new consistent replication platform aiming\nat improving elasticity of the replicated services hosted in clouds or large\ndata centers. In the core of FRAPPE is a novel replicated state machine\nprotocol, which employs speculative executions to ensure continuous operation\nduring the reconfiguration periods as well as in situations where failures\nprevent the agreement on the next stable configuration from being reached in a\ntimely fashion. We present the FRAPPE's architecture and describe the basic\ntechniques underlying the implementation of our speculative state machine\nprotocol.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 13:52:16 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Bortnikov", "Vita", ""], ["Chockler", "Gregory", ""], ["Perelman", "Dmitri", ""], ["Roytman", "Alexey", ""], ["Shachor", "Shlomit", ""], ["Shnayderman", "lya", ""]]}, {"id": "1604.06030", "submitter": "Paul Attie", "authors": "Paul C. Attie and Nancy A. Lynch", "title": "Dynamic Input/Output Automata: a Formal and Compositional Model for\n  Dynamic Systems", "comments": "65 pages, 11 figures, Information and Computation, Available online\n  21 March 2016", "journal-ref": null, "doi": "10.1016/j.ic.2016.03.008", "report-no": null, "categories": "cs.DC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present dynamic I/O automata (DIOA), a compositional model of dynamic\nsystems. In DIOA, automata can be created and destroyed dynamically, as\ncomputation proceeds, and an automaton can dynamically change its signature,\ni.e., the set of actions in which it can participate.\n  DIOA features operators for parallel composition, action hiding, action\nrenaming, a notion of automaton creation, and a notion of behavioral subtyping\nby means of trace inclusion. DIOA can model mobility, using signature\nmodification, and is hierarchical: a dynamically changing system of interacting\nautomata is itself modeled as a single automaton.\n  We also show that parallel composition, action hiding, action renaming, and\n(subject to some technical conditions) automaton creation are all monotonic\nwith respect to trace inclusion: if one component is replaced by another whose\ntraces are a subset of the former, then the set of traces of the system as a\nwhole can only be reduced.\n", "versions": [{"version": "v1", "created": "Wed, 20 Apr 2016 16:49:32 GMT"}], "update_date": "2016-04-21", "authors_parsed": [["Attie", "Paul C.", ""], ["Lynch", "Nancy A.", ""]]}, {"id": "1604.06414", "submitter": "Da Zheng", "authors": "Da Zheng, Disa Mhembere, Joshua T. Vogelstein, Carey E. Priebe, Randal\n  Burns", "title": "FlashR: R-Programmed Parallel and Scalable Machine Learning using SSDs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  R is one of the most popular programming languages for statistics and machine\nlearning, but the R framework is relatively slow and unable to scale to large\ndatasets. The general approach for speeding up an implementation in R is to\nimplement the algorithms in C or FORTRAN and provide an R wrapper. FlashR takes\na different approach: it executes R code in parallel and scales the code beyond\nmemory capacity by utilizing solid-state drives (SSDs) automatically. It\nprovides a small number of generalized operations (GenOps) upon which we\nreimplement a large number of matrix functions in the R base package. As such,\nFlashR parallelizes and scales existing R code with little/no modification. To\nreduce data movement between CPU and SSDs, FlashR evaluates matrix operations\nlazily, fuses operations at runtime, and uses cache-aware, two-level matrix\npartitioning. We evaluate FlashR on a variety of machine learning and\nstatistics algorithms on inputs of up to four billion data points. FlashR\nout-of-core tracks closely the performance of FlashR in-memory. The R code for\nmachine learning algorithms executed in FlashR outperforms the in-memory\nexecution of H2O and Spark MLlib by a factor of 2-10 and outperforms Revolution\nR Open by more than an order of magnitude.\n", "versions": [{"version": "v1", "created": "Thu, 21 Apr 2016 18:43:38 GMT"}, {"version": "v2", "created": "Sat, 30 Apr 2016 00:43:50 GMT"}, {"version": "v3", "created": "Wed, 18 May 2016 13:42:30 GMT"}, {"version": "v4", "created": "Thu, 18 May 2017 23:28:01 GMT"}], "update_date": "2017-05-22", "authors_parsed": [["Zheng", "Da", ""], ["Mhembere", "Disa", ""], ["Vogelstein", "Joshua T.", ""], ["Priebe", "Carey E.", ""], ["Burns", "Randal", ""]]}, {"id": "1604.06581", "submitter": "Gabor Kecskemeti", "authors": "Gabor Kecskemeti", "title": "DISSECT-CF: a simulator to foster energy-aware scheduling in\n  infrastructure clouds", "comments": "28 pages, 17 figures, preprint version of the paper accepted by\n  Simulation Modelling Practice and Theory", "journal-ref": "Simulation Modelling Practice and Theory, Volume 58, Part 2,\n  November 2015, Pages 188-218, ISSN 1569-190X", "doi": "10.1016/j.simpat.2015.05.009", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infrastructure as a service (IaaS) systems offer on demand virtual\ninfrastructures so reliably and flexibly that users expect a high service\nlevel. Therefore, even with regards to internal IaaS behaviour, production\nclouds only adopt novel ideas that are proven not to hinder established service\nlevels. To analyse their expected behaviour, new ideas are often evaluated with\nsimulators in production IaaS system-like scenarios. For instance, new research\ncould enable collaboration amongst several layers of schedulers or could\nconsider new optimisation objectives such as energy consumption. Unfortunately,\ncurrent cloud simulators are hard to employ and they often have performance\nissues when several layers of schedulers interact in them. To target these\nissues, a new IaaS simulation framework (called DISSECT-CF) was designed. The\nnew simulator's foundation has the following goals: easy extensibility, support\nenergy evaluation of IaaSs and to enable fast evaluation of many scheduling and\nIaaS internal behaviour related scenarios. In response to the requirements of\nsuch scenarios, the new simulator introduces concepts such as: a unified model\nfor resource sharing and a new energy metering framework with hierarchical and\nindirect metering options. Then, the comparison of several simulated situations\nto real-life IaaS behaviour is used to validate the simulator's functionality.\nFinally, a performance comparison is presented between DISSECT-CF and some\ncurrently available simulators.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 09:14:56 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Kecskemeti", "Gabor", ""]]}, {"id": "1604.06734", "submitter": "Simon Doherty", "authors": "Simon Doherty, John Derrick", "title": "Causal Linearizability", "comments": "Full version of submission to SEFM 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work on the verification of concurrent objects for shared memory assumes\nsequential consistency, but most multicore processors support only weak memory\nmodels that do not provide sequential consistency. Furthermore, most\nverification efforts focus on the linearizability of concurrent objects, but\nthere are existing implementations optimized to run on weak memory models that\nare not linearizable.\n  In this paper, we address these problems by introducing causal\nlinearizability, a correctness condition for concurrent objects running on weak\nmemory models. Like linearizability itself, causal linearizability enables\nconcurrent objects to be composed, under weak constraints on the client's\nbehaviour. We specify these constraints by introducing a notion of\noperation-race freedom, where programs that satisfy this property are\nguaranteed to behave as if their shared objects were in fact linearizable.\n  We apply these ideas to objects from the Linux kernel, optimized to run on\nTSO, the memory model of the x86 processor family.\n", "versions": [{"version": "v1", "created": "Fri, 22 Apr 2016 16:29:26 GMT"}], "update_date": "2016-04-25", "authors_parsed": [["Doherty", "Simon", ""], ["Derrick", "John", ""]]}, {"id": "1604.06853", "submitter": "Muhammad Shafique", "authors": "Muhammad Shafique", "title": "Adaptive Content-based Routing using Subscription Subgrouping in\n  Structured Overlays", "comments": "arXiv admin note: substantial text overlap with arXiv:1512.06425", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cyclic or general overlays may provide multiple paths between publishers and\nsubscribers. However, an advertisement tree and a matching subscription\nactivates only one path for notifications routing in publish/subscribe systems.\nThis poses serious challenges in handling network conditions like congestion,\nand link or broker failures. Further, content-based dynamic routing of\nnotifications requires instantaneous updates in routing paths, which is not a\nscalable option. This paper introduces a clustering approach with a bit-vector\ntechnique for inter-cluster dynamic routing of notifications in a structured\ncyclic topology that provides multiple paths between publishers and interested\nsubscribers. The advertisement forwarding process exploits the structured\nnature of the overlay topology to generate advertisement trees of length 1\nwithout generating duplicate messages in the advertisement forwarding process.\nIssued subscriptions are divided into multiple disjoint subgropus, where each\nsubscription is broadcast to a cluster, which is a limited part of the\nstructured cyclic overlay network. We implemented novel static and\nintra-cluster dynamic routing algorithms in the proposed overlay topology for\nour advertisement-based publish/subscribe system, called OctopiA. We also\nperformed a pragmatic comparison of our two algorithms with the\nstate-of-the-art. Experiments on a cluster testbed show that our approach\ngenerates fewer inter-broker messages, and is scalable.\n", "versions": [{"version": "v1", "created": "Sat, 23 Apr 2016 03:02:40 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Shafique", "Muhammad", ""]]}, {"id": "1604.06984", "submitter": "Nan Zhu", "authors": "Nan Zhu, Wenbo He, Xue Liu, Yu Hua", "title": "PFO: A Parallel Friendly High Performance System for Online Query and\n  Update of Nearest Neighbors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nearest Neighbor(s) search is the fundamental computational primitive to\ntackle massive dataset. Locality Sensitive Hashing (LSH) has been a bracing\ntool for Nearest Neighbor(s) search in high dimensional spaces. However,\ntraditional LSH systems cannot be applied in online big data systems to handle\na large volume of query/update requests, because most of the systems optimize\nthe query efficiency with the assumption of infrequent updates and missing the\nparallel-friendly design. As a result, the state-of-the-art LSH systems cannot\nadapt the system response to the user behavior interactively.\n  In this paper, we propose a new LSH system called PFO. It handles\nquery/update requests in RAM and scales the system capacity by using flash\nmemory. To achieve high streaming data throughput, PFO adopts a\nparallel-friendly indexing structure while preserving the distance between data\npoints. Further, it accommodates inbound data in real-time and dispatches\nupdate requests intelligently to eliminate the cross-threads synchronization.\nWe carried out extensive evaluations with large synthetic and standard\nbenchmark datasets. Results demonstrate that PFO delivers shorter latency and\noffers scalable capacity compared with the existing LSH systems. PFO serves\nwith higher throughput than the state-of-the-art LSH indexing structure when\ndealing with online query/update requests to nearest neighbors. Meanwhile, PFO\nreturns neighbors with much better quality, thus being efficient to handle\nonline big data applications, e.g. streaming recommendation system, interactive\nmachine learning systems.\n", "versions": [{"version": "v1", "created": "Sun, 24 Apr 2016 05:08:27 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 23:16:52 GMT"}, {"version": "v3", "created": "Sun, 22 May 2016 21:20:32 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Zhu", "Nan", ""], ["He", "Wenbo", ""], ["Liu", "Xue", ""], ["Hua", "Yu", ""]]}, {"id": "1604.07086", "submitter": "Songze Li", "authors": "Songze Li, Mohammad Ali Maddah-Ali, Qian Yu, A. Salman Avestimehr", "title": "A Fundamental Tradeoff between Computation and Communication in\n  Distributed Computing", "comments": "To appear in IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can we optimally trade extra computing power to reduce the communication\nload in distributed computing? We answer this question by characterizing a\nfundamental tradeoff between computation and communication in distributed\ncomputing, i.e., the two are inversely proportional to each other.\n  More specifically, a general distributed computing framework, motivated by\ncommonly used structures like MapReduce, is considered, where the overall\ncomputation is decomposed into computing a set of \"Map\" and \"Reduce\" functions\ndistributedly across multiple computing nodes. A coded scheme, named \"Coded\nDistributed Computing\" (CDC), is proposed to demonstrate that increasing the\ncomputation load of the Map functions by a factor of $r$ (i.e., evaluating each\nfunction at $r$ carefully chosen nodes) can create novel coding opportunities\nthat reduce the communication load by the same factor.\n  An information-theoretic lower bound on the communication load is also\nprovided, which matches the communication load achieved by the CDC scheme. As a\nresult, the optimal computation-communication tradeoff in distributed computing\nis exactly characterized.\n  Finally, the coding techniques of CDC is applied to the Hadoop TeraSort\nbenchmark to develop a novel CodedTeraSort algorithm, which is empirically\ndemonstrated to speed up the overall job execution by $1.97\\times$ -\n$3.39\\times$, for typical settings of interest.\n", "versions": [{"version": "v1", "created": "Sun, 24 Apr 2016 22:10:44 GMT"}, {"version": "v2", "created": "Sat, 23 Sep 2017 02:47:20 GMT"}], "update_date": "2017-09-26", "authors_parsed": [["Li", "Songze", ""], ["Maddah-Ali", "Mohammad Ali", ""], ["Yu", "Qian", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "1604.07182", "submitter": "Dongxiao Yu", "authors": "Magnus M. Halldorsson and Yuexuan Wang and Dongxiao Yu", "title": "Leveraging Multiple Channels in Ad Hoc Networks", "comments": "20 pages, appeared in PODC'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the utility of multiple channels of communication in wireless\nnetworks under the SINR model of interference. The central question is whether\nthe use of multiple channels can result in linear speedup, up to some\nfundamental limit. We answer this question affirmatively for the data\naggregation problem, perhaps the most fundamental problem in sensor networks.\nTo achieve this, we form a hierarchical structure of independent interest, and\nillustrate its versatility by obtaining a new algorithm with linear speedup for\nthe node coloring problem.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 09:42:16 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Halldorsson", "Magnus M.", ""], ["Wang", "Yuexuan", ""], ["Yu", "Dongxiao", ""]]}, {"id": "1604.07187", "submitter": "Othon Michail", "authors": "Othon Michail, Paul G. Spirakis", "title": "How Many Cooks Spoil the Soup?", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the following basic question: \"How much parallelism\ndoes a distributed task permit?\" Our definition of parallelism (or symmetry)\nhere is not in terms of speed, but in terms of identical roles that processes\nhave at the same time in the execution. We initiate this study in population\nprotocols, a very simple model that not only allows for a straightforward\ndefinition of what a role is, but also encloses the challenge of isolating the\nproperties that are due to the protocol from those that are due to the\nadversary scheduler, who controls the interactions between the processes. We\n(i) give a partial characterization of the set of predicates on input\nassignments that can be stably computed with maximum symmetry, i.e.,\n$\\Theta(N_{min})$, where $N_{min}$ is the minimum multiplicity of a state in\nthe initial configuration, and (ii) we turn our attention to the remaining\npredicates and prove a strong impossibility result for the parity predicate:\nthe inherent symmetry of any protocol that stably computes it is upper bounded\nby a constant that depends on the size of the protocol.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 09:55:56 GMT"}, {"version": "v2", "created": "Wed, 17 Aug 2016 23:32:59 GMT"}], "update_date": "2016-08-19", "authors_parsed": [["Michail", "Othon", ""], ["Spirakis", "Paul G.", ""]]}, {"id": "1604.07371", "submitter": "Srikanth Kandula", "authors": "Robert Grandl, Srikanth Kandula, Sriram Rao, Aditya Akella and\n  Janardhan Kulkarni", "title": "Do the Hard Stuff First: Scheduling Dependent Computations in\n  Data-Analytics Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": "MSR-TR-2016-19", "categories": "cs.DC cs.DB cs.OS cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a scheduler that improves cluster utilization and job completion\ntimes by packing tasks having multi-resource requirements and\ninter-dependencies. While the problem is algorithmically very hard, we achieve\nnear-optimality on the job DAGs that appear in production clusters at a large\nenterprise and in benchmarks such as TPC-DS. A key insight is that carefully\nhandling the long-running tasks and those with tough-to-pack resource needs\nwill produce good-enough schedules. However, which subset of tasks to treat\ncarefully is not clear (and intractable to discover). Hence, we offer a search\nprocedure that evaluates various possibilities and outputs a preferred schedule\norder over tasks. An online component enforces the schedule orders desired by\nthe various jobs running on the cluster. In addition, it packs tasks, overbooks\nthe fungible resources and guarantees bounded unfairness for a variety of\ndesirable fairness schemes. Relative to the state-of-the art schedulers, we\nspeed up 50% of the jobs by over 30% each.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 19:20:18 GMT"}], "update_date": "2016-04-26", "authors_parsed": [["Grandl", "Robert", ""], ["Kandula", "Srikanth", ""], ["Rao", "Sriram", ""], ["Akella", "Aditya", ""], ["Kulkarni", "Janardhan", ""]]}, {"id": "1604.07515", "submitter": "Julian Shun", "authors": "Julian Shun, Farbod Roosta-Khorasani, Kimon Fountoulakis, Michael W.\n  Mahoney", "title": "Parallel Local Graph Clustering", "comments": "Fixed typo in Figure 5", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph clustering has many important applications in computing, but due to\ngrowing sizes of graphs, even traditionally fast clustering methods such as\nspectral partitioning can be computationally expensive for real-world graphs of\ninterest. Motivated partly by this, so-called local algorithms for graph\nclustering have received significant interest due to the fact that they can\nfind good clusters in a graph with work proportional to the size of the cluster\nrather than that of the entire graph. This feature has proven to be crucial in\nmaking such graph clustering and many of its downstream applications efficient\nin practice. While local clustering algorithms are already faster than\ntraditional algorithms that touch the entire graph, they are sequential and\nthere is an opportunity to make them even more efficient via parallelization.\nIn this paper, we show how to parallelize many of these algorithms in the\nshared-memory multicore setting, and we analyze the parallel complexity of\nthese algorithms. We present comprehensive experiments on large-scale graphs\nshowing that our parallel algorithms achieve good parallel speedups on a modern\nmulticore machine, thus significantly speeding up the analysis of local graph\nclusters in the very large-scale setting.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 04:35:51 GMT"}, {"version": "v2", "created": "Sat, 30 Jul 2016 06:35:12 GMT"}, {"version": "v3", "created": "Sat, 8 Jun 2019 06:24:11 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Shun", "Julian", ""], ["Roosta-Khorasani", "Farbod", ""], ["Fountoulakis", "Kimon", ""], ["Mahoney", "Michael W.", ""]]}, {"id": "1604.07564", "submitter": "Dietmar Berwanger", "authors": "Dietmar Berwanger, Anup Basil Mathew, R. Ramanujam", "title": "A Retraction Theorem for Distributed Synthesis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.FL cs.GT cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a general theorem for distributed synthesis problems in\ncoordination games with $\\omega$-regular objectives of the form: If there\nexists a winning strategy for the coalition, then there exists an \"essential\"\nwinning strategy, that is obtained by a retraction of the given one. In\ngeneral, this does not lead to finite-state winning strategies, but when the\nknowledge of agents remains bounded, we can solve the synthesis problem. Our\nstudy is carried out in a setting where objectives are expressed in terms of\nevents that may \\emph{not} be observable. This is natural in games of imperfect\ninformation, rather than the common assumption that objectives are expressed in\nterms of events that are observable to all agents. We characterise decidable\ndistributed synthesis problems in terms of finiteness of knowledge states and\nfinite congruence classes induced by them.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 08:32:29 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Berwanger", "Dietmar", ""], ["Mathew", "Anup Basil", ""], ["Ramanujam", "R.", ""]]}, {"id": "1604.07642", "submitter": "Tim Weninger PhD", "authors": "Glenn Osborne, Tim Weninger", "title": "Ozy: A General Orchestration Container", "comments": "8 pages, 8 figures, accepted at IEEE Intl Conf. on Web Services\n  (ICWS), San Francisco, CA, 2016", "journal-ref": null, "doi": "10.1109/ICWS.2016.84", "report-no": null, "categories": "cs.SE cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Service-Oriented Computing is a paradigm that uses services as building\nblocks for building distributed applications. The primary motivation for\norchestrating services in the cloud used to be distributed business processes,\nwhich drove the standardization of the Business Process Execution Language\n(BPEL) and its central notion that a service is a business process. In recent\nyears, there has been a transition towards other motivations for orchestrating\nservices in the cloud, {\\em e.g.}, XaaS, RMAD. Although it is theoretically\npossible to make all of those services into WSDL/SOAP services, it would be too\ncomplicated and costly for industry adoption. Therefore, the central notion\nthat a service is a business process is too restrictive. Instead, we view a\nservice as a technology neutral, loosely coupled, location transparent\nprocedure. With these ideas in mind, we introduce a new approach to services\norchestration: Ozy, a general orchestration container. We define this new\napproach in terms of existing technology, and we show that the Ozy container\nrelaxes many traditional constraints and allows for simpler, more feature-rich\napplications.\n", "versions": [{"version": "v1", "created": "Mon, 25 Apr 2016 15:23:27 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Osborne", "Glenn", ""], ["Weninger", "Tim", ""]]}, {"id": "1604.07805", "submitter": "Mohammad Roohitavaf", "authors": "Mohammad Roohitavaf", "title": "Consistency in Distributed Data Stores", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the problem of consistency in distributed data\nstores.We define strong consistency model which provides a simple semantics for\napplication programmers, but impossible to achieve with availability and\npartition-tolerance. We also define weaker consistency models including causal\nand eventual consistency. We review COPS and GentleRain as two causally\nconsistent data stores as well as Dynamo as an eventually consistent data\nstore. We provide insights about scenarios where each of these methods is\nsuitable, and some future research directions.\n", "versions": [{"version": "v1", "created": "Tue, 26 Apr 2016 19:23:52 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Roohitavaf", "Mohammad", ""]]}, {"id": "1604.07928", "submitter": "Shandian Zhe", "authors": "Shandian Zhe, Kai Zhang, Pengyuan Wang, Kuang-chih Lee, Zenglin Xu,\n  Yuan Qi, Zoubin Ghahramani", "title": "Distributed Flexible Nonlinear Tensor Factorization", "comments": "Gaussian process, tensor factorization, multidimensional arrays,\n  large scale, spark, map-reduce", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor factorization is a powerful tool to analyse multi-way data. Compared\nwith traditional multi-linear methods, nonlinear tensor factorization models\nare capable of capturing more complex relationships in the data. However, they\nare computationally expensive and may suffer severe learning bias in case of\nextreme data sparsity. To overcome these limitations, in this paper we propose\na distributed, flexible nonlinear tensor factorization model. Our model can\neffectively avoid the expensive computations and structural restrictions of the\nKronecker-product in existing TGP formulations, allowing an arbitrary subset of\ntensorial entries to be selected to contribute to the training. At the same\ntime, we derive a tractable and tight variational evidence lower bound (ELBO)\nthat enables highly decoupled, parallel computations and high-quality\ninference. Based on the new bound, we develop a distributed inference algorithm\nin the MapReduce framework, which is key-value-free and can fully exploit the\nmemory cache mechanism in fast MapReduce systems such as SPARK. Experimental\nresults fully demonstrate the advantages of our method over several\nstate-of-the-art approaches, in terms of both predictive performance and\ncomputational efficiency. Moreover, our approach shows a promising potential in\nthe application of Click-Through-Rate (CTR) prediction for online advertising.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 04:18:32 GMT"}, {"version": "v2", "created": "Sun, 22 May 2016 00:00:23 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Zhe", "Shandian", ""], ["Zhang", "Kai", ""], ["Wang", "Pengyuan", ""], ["Lee", "Kuang-chih", ""], ["Xu", "Zenglin", ""], ["Qi", "Yuan", ""], ["Ghahramani", "Zoubin", ""]]}, {"id": "1604.07990", "submitter": "Andres Masegosa R", "authors": "Andres R. Masegosa, Ana M. Martinez, Hanen Borchani", "title": "Probabilistic Graphical Models on Multi-Core CPUs using Java 8", "comments": "Pre-print version of the paper presented in the special issue on\n  Computational Intelligence Software at IEEE Computational Intelligence\n  Magazine journal", "journal-ref": "IEEE Computational Intelligence Magazine, 11(2), 41-54. 2016", "doi": "10.1109/MCI.2016.2532267", "report-no": null, "categories": "cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss software design issues related to the development\nof parallel computational intelligence algorithms on multi-core CPUs, using the\nnew Java 8 functional programming features. In particular, we focus on\nprobabilistic graphical models (PGMs) and present the parallelisation of a\ncollection of algorithms that deal with inference and learning of PGMs from\ndata. Namely, maximum likelihood estimation, importance sampling, and greedy\nsearch for solving combinatorial optimisation problems. Through these concrete\nexamples, we tackle the problem of defining efficient data structures for PGMs\nand parallel processing of same-size batches of data sets using Java 8\nfeatures. We also provide straightforward techniques to code parallel\nalgorithms that seamlessly exploit multi-core processors. The experimental\nanalysis, carried out using our open source AMIDST (Analysis of MassIve Data\nSTreams) Java toolbox, shows the merits of the proposed solutions.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 09:28:27 GMT"}], "update_date": "2017-07-10", "authors_parsed": [["Masegosa", "Andres R.", ""], ["Martinez", "Ana M.", ""], ["Borchani", "Hanen", ""]]}, {"id": "1604.08004", "submitter": "Luigi Palopoli", "authors": "Luigi Palopoli and Daniele Fontanelli and Luca Abeni and Bernardo\n  Villalba Fr\\'ias", "title": "An Analytical Solution for Probabilistic Guarantees of Reservation Based\n  Soft Real-Time Systems", "comments": "IEEE Transactions on Parallel and Distributed Systems, Volume:27,\n  Issue: 3, March 2016", "journal-ref": null, "doi": "10.1109/TPDS.2015.2416732", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show a methodology for the computation of the probability of deadline miss\nfor a periodic real-time task scheduled by a resource reservation algorithm. We\npropose a modelling technique for the system that reduces the computation of\nsuch a probability to that of the steady state probability of an infinite state\nDiscrete Time Markov Chain with a periodic structure. This structure is\nexploited to develop an efficient numeric solution where different\naccuracy/computation time trade-offs can be obtained by operating on the\ngranularity of the model. More importantly we offer a closed form conservative\nbound for the probability of a deadline miss. Our experiments reveal that the\nbound remains reasonably close to the experimental probability in one real-time\napplication of practical interest. When this bound is used for the optimisation\nof the overall Quality of Service for a set of tasks sharing the CPU, it\nproduces a good sub-optimal solution in a small amount of time.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 10:08:53 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Palopoli", "Luigi", ""], ["Fontanelli", "Daniele", ""], ["Abeni", "Luca", ""], ["Fr\u00edas", "Bernardo Villalba", ""]]}, {"id": "1604.08066", "submitter": "Johanne Cohen", "authors": "Johanne Cohen, Jonas Lef\\`evre, Khaled Ma\\^amra, George Manoussakis,\n  Laurence Pilard", "title": "The Manne et al. self-stabilizing 2/3-approximation matching algorithm\n  is sub-exponential", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Manne et al. designed the first algorithm computing a maximal matching that\nis a 2/3 -approximation of the maximum matching in $O(^2n)$ moves. However, the\ncomplexity tightness was not proved. In this paper, we exhibit a\nsub-exponential execution of this matching algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 13:40:55 GMT"}, {"version": "v2", "created": "Thu, 21 Jul 2016 10:29:52 GMT"}, {"version": "v3", "created": "Tue, 18 Apr 2017 13:06:49 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Cohen", "Johanne", ""], ["Lef\u00e8vre", "Jonas", ""], ["Ma\u00e2mra", "Khaled", ""], ["Manoussakis", "George", ""], ["Pilard", "Laurence", ""]]}, {"id": "1604.08080", "submitter": "Germ\\'an Andr\\'es Delbianco", "authors": "Germ\\'an Andr\\'es Delbianco, Ilya Sergey, Aleksandar Nanevski and\n  Anindya Banerjee", "title": "Concurrent Data Structures Linked in Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Arguments about correctness of a concurrent data structure are typically\ncarried out by using the notion of linearizability and specifying the\nlinearization points of the data structure's procedures. Such arguments are\noften cumbersome as the linearization points' position in time can be dynamic\n(depend on the interference, run-time values and events from the past, or even\nfuture), non-local (appear in procedures other than the one considered), and\nwhose position in the execution trace may only be determined after the\nconsidered procedure has already terminated.\n  In this paper we propose a new method, based on a separation-style logic, for\nreasoning about concurrent objects with such linearization points. We embrace\nthe dynamic nature of linearization points, and encode it as part of the data\nstructure's auxiliary state, so that it can be dynamically modified in place by\nauxiliary code, as needed when some appropriate run-time event occurs. We name\nthe idea linking-in-time, because it reduces temporal reasoning to spatial\nreasoning. For example, modifying a temporal position of a linearization point\ncan be modeled similarly to a pointer update in separation logic. Furthermore,\nthe auxiliary state provides a convenient way to concisely express the\nproperties essential for reasoning about clients of such concurrent objects. We\nillustrate the method by verifying (mechanically in Coq) an intricate optimal\nsnapshot algorithm due to Jayanti, as well as some clients.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 14:13:46 GMT"}, {"version": "v2", "created": "Tue, 3 May 2016 00:08:37 GMT"}, {"version": "v3", "created": "Mon, 24 Oct 2016 17:22:22 GMT"}, {"version": "v4", "created": "Wed, 18 Jan 2017 13:23:29 GMT"}], "update_date": "2017-01-19", "authors_parsed": [["Delbianco", "Germ\u00e1n Andr\u00e9s", ""], ["Sergey", "Ilya", ""], ["Nanevski", "Aleksandar", ""], ["Banerjee", "Anindya", ""]]}, {"id": "1604.08137", "submitter": "Valmir C. Barbosa", "authors": "Fabiano de S. Oliveira, Valmir C. Barbosa", "title": "On the mediation of program allocation in high-demand environments", "comments": "This version addresses a few minor issues and fixes a derivative", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we challenge the widely accepted premise that, in order to\ncarry out a distributed computation, say on the cloud, users have to inform,\nalong with all the inputs that the algorithm in use requires, the number of\nprocessors to be used. We discuss the complicated nature of deciding the value\nof such parameter, should it be chosen optimally, and propose the alternative\nscenario in which this choice is passed on to the server side for automatic\ndetermination. We show that the allocation problem arising from this\nalternative is NP-hard only weakly, being therefore solvable in\npseudo-polynomial time. In our proposal, one key component on which the\nautomatic determination of the number of processors is based is the cost model.\nThe one we use, which is being increasingly adopted in the wake of the\ncloud-computing movement, posits that each single execution of a program is to\nbe subject to current circumstances on both user and server side, and as such\nbe priced independently of all others. Running through our proposal is thus a\ncritique of the established common sense that sizing a set of processors to\nhandle a submission to some provider is entirely up to the user.\n", "versions": [{"version": "v1", "created": "Wed, 27 Apr 2016 16:48:45 GMT"}, {"version": "v2", "created": "Thu, 28 Apr 2016 17:43:43 GMT"}, {"version": "v3", "created": "Mon, 6 May 2019 17:48:56 GMT"}, {"version": "v4", "created": "Fri, 20 Sep 2019 17:22:17 GMT"}], "update_date": "2019-09-23", "authors_parsed": [["Oliveira", "Fabiano de S.", ""], ["Barbosa", "Valmir C.", ""]]}, {"id": "1604.08161", "submitter": "Michel Raynal", "authors": "Achour Mosteafoui, Matoula Petrolia, Michel Raynal, and Claude Jard", "title": "Atomic Read/Write Memory in Signature-free Byzantine Asynchronous\n  Message-passing Systems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a signature-free distributed algorithm which builds an\natomic read/write shared memory on top of an $n$-process asynchronous\nmessage-passing system in which up to $t<n/3$ processes may commit Byzantine\nfailures. From a conceptual point of view, this algorithm is designed to be as\nclose as possible to the algorithm proposed by Attiya, Bar-Noy and Dolev (JACM\n1995), which builds an atomic register in an $n$-process asynchronous\nmessage-passing system where up to $t<n/2$ processes may crash. The proposed\nalgorithm is particularly simple. It does not use cryptography to cope with\nByzantine processes, and is optimal from a $t$-resilience point of view\n($t<n/3$). A read operation requires $O(n)$ messages, and a write operation\nrequires $O(n^2)$ messages.\n", "versions": [{"version": "v1", "created": "Mon, 7 Dec 2015 08:53:28 GMT"}], "update_date": "2016-04-28", "authors_parsed": [["Mosteafoui", "Achour", ""], ["Petrolia", "Matoula", ""], ["Raynal", "Michel", ""], ["Jard", "Claude", ""]]}, {"id": "1604.08330", "submitter": "Bo Wang", "authors": "Bo Wang, Ying Song, Yuzhong Sun, Jun Liu", "title": "Server Consolidation for Internet Applications in Virtualized Data\n  Centers", "comments": "8 pages, 6 figures, In Proceedings of the Symposium on High\n  Performance Computing (HPC '16). Society for Computer Simulation\n  International, Pasadena, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Server consolidation based on virtualization technology simplifies system\nadministration and improves energy efficiency by improving resource\nutilizations and reducing the physical machine (PM) number in contemporary\nservice-oriented data centers. The elasticity of Internet applications changes\nthe consolidation technologies from addressing virtual machines (VMs) to PMs\nmapping schemes which must know the VMs statuses, i.e. the number of VMs and\nthe profiling data of each VM, into providing the application-to-VM-to-PM\nmapping. In this paper, we study on the consolidation of multiple Internet\napplications, minimizing the number of PMs with required performance. We first\nmodel the consolidation providing the application-to-VM-to-PM mapping to\nminimize the number of PMs as an integer linear programming problem, and then\npresent a heuristic algorithm to solve the problem in polynomial time.\nExtensive experimental results show that our heuristic algorithm consumes less\nthan 4.3% more resources than the optimal amounts with few overheads. Existing\nconsolidation technologies using the input of the VM statuses output by our\nheuristic algorithm consume 1.06% more PMs.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 07:33:40 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Wang", "Bo", ""], ["Song", "Ying", ""], ["Sun", "Yuzhong", ""], ["Liu", "Jun", ""]]}, {"id": "1604.08335", "submitter": "Bo Wang", "authors": "Bo Wang, Ying Song, Yuzhong Sun, Jun Liu", "title": "Managing Deadline-constrained Bag-of-Tasks Jobs on Hybrid Clouds", "comments": "8 pages, 9 figures, In Proceedings of the Symposium on High\n  Performance Computing (HPC '16). Society for Computer Simulation\n  International, Pasadena, CA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outsourcing jobs to a public cloud is a cost-effective way to address the\nproblem of satisfying the peak resource demand when the local cloud has\ninsufficient resources. In this paper, we study on managing\ndeadline-constrained bag-of-tasks jobs on hybrid clouds. We present a binary\nnonlinear programming (BNP) problem to model the hybrid cloud management where\nthe utilization of physical machines (PMs) in the local cloud/cluster is\nmaximized when the local resources are enough to satisfy the deadline\nconstraints of jobs, while when not, the rent cost from the public cloud is\nminimized. To solve this BNP problem in polynomial time, we proposed a\nheuristic algorithm. Its main idea is assigning the task closest to its\ndeadline to current core until the core cannot finish any task within its\ndeadline. When there is no available core, the algorithm adds an available PM\nwith most capacity or rents a new VM with highest cost-performance ratio.\nExtensive experimental results show that our heuristic algorithm saves\n16.2%-76% rent cost and improves 47.3%-182.8% resource utilizations satisfying\ndeadline constraints, compared with first fit decreasing algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 07:48:42 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Wang", "Bo", ""], ["Song", "Ying", ""], ["Sun", "Yuzhong", ""], ["Liu", "Jun", ""]]}, {"id": "1604.08340", "submitter": "Altti Ilari Maarala", "authors": "Altti Ilari Maarala, Xiang Su, and Jukka Riekki", "title": "Semantic Reasoning for Context-aware Internet of Things Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in ICT are bringing into reality the vision of a large number of\nuniquely identifiable, interconnected objects and things that gather\ninformation from diverse physical environments and deliver the information to a\nvariety of innovative applications and services. These sensing objects and\nthings form the Internet of Things (IoT) that can improve energy and cost\nefficiency and automation in many different industry fields such as\ntransportation and logistics, health care and manufacturing, and facilitate our\neveryday lives as well. IoT applications rely on real-time context data and\nallow sending information for driving the behaviors of users in intelligent\nenvironments.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 08:17:56 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Maarala", "Altti Ilari", ""], ["Su", "Xiang", ""], ["Riekki", "Jukka", ""]]}, {"id": "1604.08420", "submitter": "Wenjie Zheng", "authors": "Wenjie Zheng", "title": "Matrix Factorization Method for Decentralized Recommender Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decentralized recommender system does not rely on the central service\nprovider, and the users can keep the ownership of their ratings. This article\nbrings the theoretically well-studied matrix factorization method into the\ndecentralized recommender system, where the formerly prevalent algorithms are\nheuristic and hence lack of theoretical guarantee. Our preliminary simulation\nresults show that this method is promising.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 14:01:54 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Zheng", "Wenjie", ""]]}, {"id": "1604.08484", "submitter": "Ahsan Javed Awan", "authors": "Ahsan Javed Awan, Mats Brorsson, Vladimir Vlassov and Eduard Ayguade", "title": "Architectural Impact on Performance of In-memory Data Analytics: Apache\n  Spark Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While cluster computing frameworks are continuously evolving to provide\nreal-time data analysis capabilities, Apache Spark has managed to be at the\nforefront of big data analytics for being a unified framework for both, batch\nand stream data processing. However, recent studies on micro-architectural\ncharacterization of in-memory data analytics are limited to only batch\nprocessing workloads. We compare micro-architectural performance of batch\nprocessing and stream processing workloads in Apache Spark using hardware\nperformance counters on a dual socket server. In our evaluation experiments, we\nhave found that batch processing are stream processing workloads have similar\nmicro-architectural characteristics and are bounded by the latency of frequent\ndata access to DRAM. For data accesses we have found that simultaneous\nmulti-threading is effective in hiding the data latencies. We have also\nobserved that (i) data locality on NUMA nodes can improve the performance by\n10% on average and(ii) disabling next-line L1-D prefetchers can reduce the\nexecution time by up-to 14\\% and (iii) multiple small executors can provide\nup-to 36\\% speedup over single large executor.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 16:00:38 GMT"}], "update_date": "2016-04-29", "authors_parsed": [["Awan", "Ahsan Javed", ""], ["Brorsson", "Mats", ""], ["Vlassov", "Vladimir", ""], ["Ayguade", "Eduard", ""]]}, {"id": "1604.08618", "submitter": "Freddy C. Chua", "authors": "Freddy C. Chua, Julie Ward, Ying Zhang, Puneet Sharma, Bernardo A.\n  Huberman", "title": "Stringer: Balancing Latency and Resource Usage in Service Function Chain\n  Provisioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Functions Virtualization, or NFV, enables telecommunications\ninfrastructure providers to replace special-purpose networking equipment with\ncommodity servers running virtualized network functions (VNFs). A service\nprovider utilizing NFV technology faces the SFC provisioning problem of\nassigning VNF instances to nodes in the physical infrastructure (e.g., a\ndatacenter), and routing Service Function Chains (sequences of functions\nrequired by customers, a.k.a. SFCs) in the physical network. In doing so, the\nprovider must balance between various competing goals of performance and\nresource usage. We present an approach for SFC provisioning, consisting of\nthree elements. The first element is a fast, scalable round-robin heuristic.\nThe second element is a Mixed Integer Programming (MIP) based approach. The\nthird element is a queueing-theoretic model to estimate the average latency\nassociated with any SFC provisioning solution. Combined, these elements create\nan approach that generates a set of SFC provisioning solutions, reflecting\ndifferent tradeoffs between resource usage and performance.\n", "versions": [{"version": "v1", "created": "Thu, 28 Apr 2016 21:05:54 GMT"}, {"version": "v2", "created": "Thu, 9 Jun 2016 21:51:57 GMT"}], "update_date": "2016-06-13", "authors_parsed": [["Chua", "Freddy C.", ""], ["Ward", "Julie", ""], ["Zhang", "Ying", ""], ["Sharma", "Puneet", ""], ["Huberman", "Bernardo A.", ""]]}, {"id": "1604.08738", "submitter": "Manuel Penschuck", "authors": "Michael Hamann, Ulrich Meyer, Manuel Penschuck, Hung Tran and Dorothea\n  Wagner", "title": "I/O-Efficient Generation of Massive Graphs Following the LFR Benchmark", "comments": "25 pages, 11 figures. We add the sampling of simple graphs using the\n  Configuration Model followed by rewiring steps and experimental results\n  regarding the mixing time of the sampling schemes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LFR is a popular benchmark graph generator used to evaluate community\ndetection algorithms. We present EM-LFR, the first external memory algorithm\nable to generate massive complex networks following the LFR benchmark. Its most\nexpensive component is the generation of random graphs with prescribed degree\nsequences which can be divided into two steps: the graphs are first\nmaterialized deterministically using the Havel-Hakimi algorithm, and then\nrandomized. Our main contributions are EM-HH and EM-ES, two I/O-efficient\nexternal memory algorithms for these two steps. We also propose EM-CM/ES, an\nalternative sampling scheme using the Configuration Model and rewiring steps to\nobtain a random simple graph. In an experimental evaluation we demonstrate\ntheir performance; our implementation is able to handle graphs with more than\n37 billion edges on a single machine, is competitive with a massive parallel\ndistributed algorithm, and is faster than a state-of-the-art internal memory\nimplementation even on instances fitting in main memory. EM-LFR's\nimplementation is capable of generating large graph instances orders of\nmagnitude faster than the original implementation. We give evidence that both\nimplementations yield graphs with matching properties by applying clustering\nalgorithms to generated instances. Similarly, we analyse the evolution of graph\nproperties as EM-ES is executed on networks obtained with EM-CM/ES and find\nthat the alternative approach can accelerate the sampling process.\n", "versions": [{"version": "v1", "created": "Fri, 29 Apr 2016 08:56:11 GMT"}, {"version": "v2", "created": "Fri, 2 Sep 2016 15:45:31 GMT"}, {"version": "v3", "created": "Wed, 14 Jun 2017 09:23:34 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Hamann", "Michael", ""], ["Meyer", "Ulrich", ""], ["Penschuck", "Manuel", ""], ["Tran", "Hung", ""], ["Wagner", "Dorothea", ""]]}]