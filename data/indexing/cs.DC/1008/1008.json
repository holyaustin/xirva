[{"id": "1008.0011", "submitter": "Heinz Kredel", "authors": "Heinz Kredel", "title": "Parallel and distributed Gr\\\"obner bases computation in JAS", "comments": "14 pages, 8 tables, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers parallel Gr\\\"obner bases algorithms on distributed\nmemory parallel computers with multi-core compute nodes. We summarize three\ndifferent Gr\\\"obner bases implementations: shared memory parallel, pure\ndistributed memory parallel and distributed memory combined with shared memory\nparallelism. The last algorithm, called distributed hybrid, uses only one\ncontrol communication channel between the master node and the worker nodes and\nkeeps polynomials in shared memory on a node. The polynomials are transported\nasynchronous to the control-flow of the algorithm in a separate distributed\ndata structure. The implementation is generic and works for all implemented\n(exact) fields. We present new performance measurements and discuss the\nperformance of the algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jul 2010 20:38:38 GMT"}], "update_date": "2010-08-03", "authors_parsed": [["Kredel", "Heinz", ""]]}, {"id": "1008.0064", "submitter": "Anwitaman Datta", "authors": "Frederique Oggier and Anwitaman Datta", "title": "Self-repairing Homomorphic Codes for Distributed Storage Systems", "comments": null, "journal-ref": "Infocom 2011, The 30th IEEE International Conference on Computer\n  Communications", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Erasure codes provide a storage efficient alternative to replication based\nredundancy in (networked) storage systems. They however entail high\ncommunication overhead for maintenance, when some of the encoded fragments are\nlost and need to be replenished. Such overheads arise from the fundamental need\nto recreate (or keep separately) first a copy of the whole object before any\nindividual encoded fragment can be generated and replenished. There has been\nrecently intense interest to explore alternatives, most prominent ones being\nregenerating codes (RGC) and hierarchical codes (HC). We propose as an\nalternative a new family of codes to improve the maintenance process, which we\ncall self-repairing codes (SRC), with the following salient features: (a)\nencoded fragments can be repaired directly from other subsets of encoded\nfragments without having to reconstruct first the original data, ensuring that\n(b) a fragment is repaired from a fixed number of encoded fragments, the number\ndepending only on how many encoded blocks are missing and independent of which\nspecific blocks are missing. These properties allow for not only low\ncommunication overhead to recreate a missing fragment, but also independent\nreconstruction of different missing fragments in parallel, possibly in\ndifferent parts of the network. We analyze the static resilience of SRCs with\nrespect to traditional erasure codes, and observe that SRCs incur marginally\nlarger storage overhead in order to achieve the aforementioned properties. The\nsalient SRC properties naturally translate to low communication overheads for\nreconstruction of lost fragments, and allow reconstruction with lower latency\nby facilitating repairs in parallel. These desirable properties make\nself-repairing codes a good and practical candidate for networked distributed\nstorage systems.\n", "versions": [{"version": "v1", "created": "Sat, 31 Jul 2010 07:37:26 GMT"}], "update_date": "2010-11-24", "authors_parsed": [["Oggier", "Frederique", ""], ["Datta", "Anwitaman", ""]]}, {"id": "1008.0135", "submitter": "Amr Hassan", "authors": "A.H. Hassan, C.J. Fluke, D.G. Barnes", "title": "Interactive Visualization of the Largest Radioastronomy Cubes", "comments": "15 pages, 12 figures, Accepted New Astronomy July 2010", "journal-ref": "New Astronomy 16 (2011), pp. 100-109", "doi": "10.1016/j.newast.2010.07.009", "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  3D visualization is an important data analysis and knowledge discovery tool,\nhowever, interactive visualization of large 3D astronomical datasets poses a\nchallenge for many existing data visualization packages. We present a solution\nto interactively visualize larger-than-memory 3D astronomical data cubes by\nutilizing a heterogeneous cluster of CPUs and GPUs. The system partitions the\ndata volume into smaller sub-volumes that are distributed over the rendering\nworkstations. A GPU-based ray casting volume rendering is performed to generate\nimages for each sub-volume, which are composited to generate the whole volume\noutput, and returned to the user. Datasets including the HI Parkes All Sky\nSurvey (HIPASS - 12 GB) southern sky and the Galactic All Sky Survey (GASS - 26\nGB) data cubes were used to demonstrate our framework's performance. The\nframework can render the GASS data cube with a maximum render time < 0.3 second\nwith 1024 x 1024 pixels output resolution using 3 rendering workstations and 8\nGPUs. Our framework will scale to visualize larger datasets, even of Terabyte\norder, if proper hardware infrastructure is available.\n", "versions": [{"version": "v1", "created": "Sun, 1 Aug 2010 00:55:23 GMT"}], "update_date": "2010-09-21", "authors_parsed": [["Hassan", "A. H.", ""], ["Fluke", "C. J.", ""], ["Barnes", "D. G.", ""]]}, {"id": "1008.0451", "submitter": "Yibei Ling", "authors": "Yibei Ling, Shigang Chen, and Cho-Yu Jason Chiang", "title": "On Optimal Deadlock Detection Scheduling", "comments": null, "journal-ref": "IEEE Transactions on Computers, 55(9), 1178-1187 (2006)", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deadlock detection scheduling is an important, yet often overlooked problem\nthat can significantly affect the overall performance of deadlock handling.\nExcessive initiation of deadlock detection increases overall message usage,\nresulting in degraded system performance in the absence of deadlocks; while\ninsufficient initiation of deadlock detection increases the deadlock\npersistence time, resulting in an increased deadlock resolution cost in the\npresence of deadlocks. The investigation of this performance tradeoff, however,\nis missing in the literature. This paper studies the impact of deadlock\ndetection scheduling on the overall performance of deadlock handling. In\nparticular, we show that there exists an optimal deadlock detection frequency\nthat yields the minimum long-run mean average cost, which is determined by the\nmessage complexities of the deadlock detection and resolution algorithms being\nused, as well as the rate of deadlock formation, denoted as $\\lambda$. For the\nbest known deadlock detection and resolution algorithms, we show that the\nasymptotically optimal frequency of deadlock detection scheduling that\nminimizes the overall message overhead is ${\\cal O}((\\lambda n)^{1/3})$, when\nthe total number $n$ of processes is sufficiently large. Furthermore, we show\nthat in general fully distributed (uncoordinated) deadlock detection scheduling\ncannot be performed as efficiently as centralized (coordinated) deadlock\ndetection scheduling.\n", "versions": [{"version": "v1", "created": "Tue, 3 Aug 2010 03:46:56 GMT"}], "update_date": "2010-08-04", "authors_parsed": [["Ling", "Yibei", ""], ["Chen", "Shigang", ""], ["Chiang", "Cho-Yu Jason", ""]]}, {"id": "1008.1380", "submitter": "Soumya Banerjee", "authors": "Soumya Banerjee and Melanie Moses", "title": "Scale Invariance of Immune System Response Rates and Times: Perspectives\n  on Immune System Architecture and Implications for Artificial Immune Systems", "comments": "23 pages, 4 figures, Swarm Intelligence journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most biological rates and times decrease systematically with organism body\nsize. We use an ordinary differential equation (ODE) model of West Nile Virus\nin birds to show that pathogen replication rates decline with host body size,\nbut natural immune system (NIS) response rates do not change systematically\nwith body size. This is surprising since the NIS has to search for small\nquantities of pathogens through larger physical spaces in larger organisms, and\nalso respond by producing larger absolute quantities of antibody in larger\norganisms. We call this scale-invariant detection and response. We hypothesize\nthat the NIS has evolved an architecture to efficiently neutralize pathogens.\nWe investigate a range of architectures using an Agent Based Model (ABM). We\nfind that a sub-modular NIS architecture, in which lymph node number and size\nboth increase sublinearly with body size, efficiently balances the tradeoff\nbetween local pathogen detection and global response using antibodies. This\nleads to nearly scale-invariant detection and response, consistent with\nexperimental data. Similar to the NIS, physical space and resources are also\nimportant constraints on Artificial Immune Systems (AIS), especially\ndistributed systems applications used to connect low-powered sensors using\nshort-range wireless communication. We show that AIS problems, like distributed\nrobot control, will also require a sub-modular architecture to efficiently\nbalance the tradeoff between local search for a solution and global response or\nproliferation of the solution between different components. This research has\nwide applicability in other distributed systems AIS applications.\n", "versions": [{"version": "v1", "created": "Sun, 8 Aug 2010 04:47:36 GMT"}], "update_date": "2010-08-10", "authors_parsed": [["Banerjee", "Soumya", ""], ["Moses", "Melanie", ""]]}, {"id": "1008.1459", "submitter": "Carl Hewitt", "authors": "Carl Hewitt", "title": "Actor Model of Computation: Scalable Robust Information Systems", "comments": "Relationship to Internet of Things. arXiv admin note: text overlap\n  with arXiv:0812.4852, arXiv:0901.4934", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Actor model is a mathematical theory that treats \"Actors\" as the\nuniversal primitives of concurrent digital computation. The model has been used\nboth as a framework for a theoretical understanding of concurrency, and as the\ntheoretical basis for several practical implementations of concurrent systems.\nUnlike previous models of computation, the Actor model was inspired by physical\nlaws. It was also influenced by the programming languages Lisp, Simula 67 and\nSmalltalk-72, as well as ideas for Petri Nets, capability-based systems and\npacket switching. The advent of massive concurrency through client-cloud\ncomputing and many-core computer architectures has galvanized interest in the\nActor model.\n  Actor technology will see significant application for integrating all kinds\nof digital information for individuals, groups, and organizations so their\ninformation usefully links together. Information integration needs to make use\nof the following information system principles:\n  * Persistence. Information is collected and indexed.\n  * Concurrency: Work proceeds interactively and concurrently, overlapping in\ntime.\n  * Quasi-commutativity: Information can be used regardless of whether it\ninitiates new work or become relevant to ongoing work.\n  * Sponsorship: Sponsors provide resources for computation, i.e., processing,\nstorage, and communications.\n  * Pluralism: Information is heterogeneous, overlapping and often\ninconsistent.\n  * Provenance: The provenance of information is carefully tracked and recorded\n  The Actor Model is intended to provide a foundation for inconsistency robust\ninformation integration\n", "versions": [{"version": "v1", "created": "Mon, 9 Aug 2010 06:52:55 GMT"}, {"version": "v10", "created": "Wed, 29 Dec 2010 13:33:01 GMT"}, {"version": "v11", "created": "Sun, 6 Mar 2011 23:56:37 GMT"}, {"version": "v12", "created": "Mon, 4 Apr 2011 23:42:07 GMT"}, {"version": "v13", "created": "Sun, 17 Apr 2011 21:46:50 GMT"}, {"version": "v14", "created": "Mon, 25 Apr 2011 14:05:47 GMT"}, {"version": "v15", "created": "Mon, 2 May 2011 14:12:40 GMT"}, {"version": "v16", "created": "Tue, 17 May 2011 14:33:28 GMT"}, {"version": "v17", "created": "Sat, 18 Jun 2011 07:44:44 GMT"}, {"version": "v18", "created": "Wed, 6 Jul 2011 14:10:59 GMT"}, {"version": "v19", "created": "Mon, 1 Aug 2011 19:32:05 GMT"}, {"version": "v2", "created": "Thu, 12 Aug 2010 17:53:51 GMT"}, {"version": "v20", "created": "Mon, 22 Aug 2011 06:42:08 GMT"}, {"version": "v21", "created": "Tue, 30 Aug 2011 16:07:18 GMT"}, {"version": "v22", "created": "Wed, 16 Nov 2011 21:14:21 GMT"}, {"version": "v23", "created": "Sun, 1 Jan 2012 01:22:28 GMT"}, {"version": "v24", "created": "Mon, 2 Jul 2012 14:51:27 GMT"}, {"version": "v25", "created": "Fri, 31 Aug 2012 20:16:41 GMT"}, {"version": "v26", "created": "Thu, 11 Oct 2012 17:04:44 GMT"}, {"version": "v27", "created": "Wed, 7 Nov 2012 18:07:19 GMT"}, {"version": "v28", "created": "Sun, 30 Dec 2012 16:58:43 GMT"}, {"version": "v29", "created": "Thu, 28 Mar 2013 20:47:40 GMT"}, {"version": "v3", "created": "Tue, 17 Aug 2010 11:38:39 GMT"}, {"version": "v30", "created": "Mon, 2 Dec 2013 12:58:35 GMT"}, {"version": "v31", "created": "Mon, 30 Dec 2013 22:07:42 GMT"}, {"version": "v32", "created": "Wed, 26 Mar 2014 00:03:15 GMT"}, {"version": "v33", "created": "Wed, 13 Aug 2014 21:08:33 GMT"}, {"version": "v34", "created": "Thu, 11 Sep 2014 15:08:31 GMT"}, {"version": "v35", "created": "Mon, 3 Nov 2014 18:41:22 GMT"}, {"version": "v36", "created": "Mon, 29 Dec 2014 17:00:36 GMT"}, {"version": "v37", "created": "Mon, 5 Jan 2015 16:57:16 GMT"}, {"version": "v38", "created": "Wed, 21 Jan 2015 18:38:30 GMT"}, {"version": "v4", "created": "Sun, 22 Aug 2010 14:17:37 GMT"}, {"version": "v5", "created": "Tue, 31 Aug 2010 14:51:58 GMT"}, {"version": "v6", "created": "Mon, 6 Sep 2010 13:39:42 GMT"}, {"version": "v7", "created": "Wed, 8 Sep 2010 19:33:43 GMT"}, {"version": "v8", "created": "Mon, 8 Nov 2010 01:08:39 GMT"}, {"version": "v9", "created": "Mon, 29 Nov 2010 22:17:07 GMT"}], "update_date": "2015-01-22", "authors_parsed": [["Hewitt", "Carl", ""]]}, {"id": "1008.1900", "submitter": "Ali Khajeh-Hosseini", "authors": "Ali Khajeh-Hosseini, David Greenwood, James W. Smith, Ian Sommerville", "title": "The Cloud Adoption Toolkit: Supporting Cloud Adoption Decisions in the\n  Enterprise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing promises a radical shift in the provisioning of computing\nresource within the enterprise. This paper describes the challenges that\ndecision makers face when assessing the feasibility of the adoption of cloud\ncomputing in their organisations, and describes our Cloud Adoption Toolkit,\nwhich has been developed to support this process. The toolkit provides a\nframework to support decision makers in identifying their concerns, and\nmatching these concerns to appropriate tools/techniques that can be used to\naddress them. Cost Modeling is the most mature tool in the toolkit, and this\npaper shows its effectiveness by demonstrating how practitioners can use it to\nexamine the costs of deploying their IT systems on the cloud. The Cost Modeling\ntool is evaluated using a case study of an organization that is considering the\nmigration of some of its IT systems to the cloud. The case study shows that\nrunning systems on the cloud using a traditional \"always on\" approach can be\nless cost effective, and the elastic nature of the cloud has to be used to\nreduce costs. Therefore, decision makers have to be able to model the\nvariations in resource usage and their systems deployment options to obtain\naccurate cost estimates.\n", "versions": [{"version": "v1", "created": "Wed, 11 Aug 2010 12:56:32 GMT"}], "update_date": "2010-08-12", "authors_parsed": [["Khajeh-Hosseini", "Ali", ""], ["Greenwood", "David", ""], ["Smith", "James W.", ""], ["Sommerville", "Ian", ""]]}, {"id": "1008.2748", "submitter": "Carl Hewitt", "authors": "Carl Hewitt", "title": "ActorScript(TM) extension of C sharp (TM), Java(TM), and Objective\n  C(TM): iAdaptive(TM) concurrency for antiCloud(TM) privacy and security", "comments": "Added explanation of facets of an Actor. Admin note: text overlap\n  with arXiv:1008.1459", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ActorScript(TM) is a general purpose programming language for implementing\ndiscretionary, adaptive concurrency that manages resources and demand.\n  It is differentiated from previous languages by the following:\n  - Universality\n  *** Ability to specify what Actors can do\n  *** Specify interface between hardware and software\n  *** Everything in the language is accomplished using message passing\nincluding the very definition of ActorScript itself\n  *** Functional, Imperative, Logic, and Concurrent programming are integrated.\n  *** Concurrency dynamically adapts to resources available and current load.\n  *** Programs do not expose low-level implementation mechanisms such as\nthreads, tasks, locks, cores, etc.\n  *** Messages can be directly communicated without requiring indirection\nthrough brokers, channels, class hierarchies, mailboxes, pipes, ports, queues\netc.\n  *** Variable races are eliminated.\n  *** Binary XML and JSON are data types.\n  *** Application binary interfaces are afforded so that no identifier symbol\nneed be looked up at runtime.\n  - Safety and Security\n  *** Programs are extension invariant, i.e., extending a program does not\nchange its meaning.\n  *** Applications cannot directly harm each other.\n  - Performance\n  *** Impose no overhead on implementation of Actor systems\n  *** Message passing has essentially same overhead as procedure calling and\nlooping.\n  *** Allow execution to be dynamically adjusted for system load and capacity\n(e.g. cores)\n  *** Locality because execution is not bound by a sequential global memory\nmodel\n  *** Inherent concurrency because execution is not bound by communicating\nsequential processes\n  *** Minimize latency along critical paths\n", "versions": [{"version": "v1", "created": "Mon, 16 Aug 2010 19:45:20 GMT"}, {"version": "v10", "created": "Wed, 29 Dec 2010 13:23:33 GMT"}, {"version": "v11", "created": "Wed, 16 Feb 2011 18:58:22 GMT"}, {"version": "v12", "created": "Sun, 6 Mar 2011 23:51:16 GMT"}, {"version": "v13", "created": "Mon, 2 May 2011 14:11:43 GMT"}, {"version": "v14", "created": "Sat, 18 Jun 2011 08:36:20 GMT"}, {"version": "v15", "created": "Wed, 6 Jul 2011 14:09:24 GMT"}, {"version": "v16", "created": "Mon, 18 Jul 2011 10:39:23 GMT"}, {"version": "v17", "created": "Mon, 1 Aug 2011 19:28:08 GMT"}, {"version": "v18", "created": "Mon, 7 Nov 2011 12:08:56 GMT"}, {"version": "v19", "created": "Tue, 15 Nov 2011 14:29:38 GMT"}, {"version": "v2", "created": "Wed, 18 Aug 2010 17:24:47 GMT"}, {"version": "v20", "created": "Mon, 21 Nov 2011 17:26:53 GMT"}, {"version": "v21", "created": "Tue, 13 Dec 2011 23:20:19 GMT"}, {"version": "v22", "created": "Tue, 3 Jan 2012 15:49:33 GMT"}, {"version": "v23", "created": "Wed, 11 Jan 2012 14:16:14 GMT"}, {"version": "v24", "created": "Sat, 14 Jan 2012 19:18:33 GMT"}, {"version": "v25", "created": "Fri, 9 Mar 2012 18:12:55 GMT"}, {"version": "v26", "created": "Mon, 25 Jun 2012 16:22:05 GMT"}, {"version": "v27", "created": "Thu, 2 Aug 2012 18:56:07 GMT"}, {"version": "v28", "created": "Tue, 28 Aug 2012 05:28:57 GMT"}, {"version": "v29", "created": "Fri, 19 Oct 2012 05:40:28 GMT"}, {"version": "v3", "created": "Mon, 23 Aug 2010 14:45:26 GMT"}, {"version": "v30", "created": "Wed, 7 Nov 2012 18:03:34 GMT"}, {"version": "v31", "created": "Tue, 4 Dec 2012 18:24:08 GMT"}, {"version": "v32", "created": "Tue, 8 Jan 2013 18:36:23 GMT"}, {"version": "v33", "created": "Wed, 27 Feb 2013 19:45:06 GMT"}, {"version": "v34", "created": "Tue, 26 Mar 2013 15:36:01 GMT"}, {"version": "v35", "created": "Tue, 23 Apr 2013 05:42:37 GMT"}, {"version": "v36", "created": "Mon, 29 Apr 2013 16:05:46 GMT"}, {"version": "v37", "created": "Tue, 7 May 2013 17:40:13 GMT"}, {"version": "v38", "created": "Tue, 25 Jun 2013 18:43:01 GMT"}, {"version": "v39", "created": "Mon, 15 Jul 2013 16:17:05 GMT"}, {"version": "v4", "created": "Tue, 31 Aug 2010 17:25:04 GMT"}, {"version": "v40", "created": "Mon, 19 Aug 2013 16:41:30 GMT"}, {"version": "v41", "created": "Tue, 24 Sep 2013 19:03:29 GMT"}, {"version": "v42", "created": "Tue, 15 Oct 2013 23:52:45 GMT"}, {"version": "v43", "created": "Mon, 16 Dec 2013 20:23:22 GMT"}, {"version": "v44", "created": "Wed, 1 Jan 2014 02:22:43 GMT"}, {"version": "v45", "created": "Fri, 14 Feb 2014 20:49:29 GMT"}, {"version": "v46", "created": "Mon, 21 Apr 2014 13:58:04 GMT"}, {"version": "v47", "created": "Wed, 14 May 2014 15:55:52 GMT"}, {"version": "v48", "created": "Wed, 11 Jun 2014 06:39:04 GMT"}, {"version": "v49", "created": "Mon, 16 Jun 2014 19:33:48 GMT"}, {"version": "v5", "created": "Thu, 9 Sep 2010 18:41:02 GMT"}, {"version": "v50", "created": "Tue, 14 Oct 2014 15:10:41 GMT"}, {"version": "v51", "created": "Wed, 15 Oct 2014 16:52:06 GMT"}, {"version": "v52", "created": "Wed, 5 Nov 2014 15:03:16 GMT"}, {"version": "v53", "created": "Mon, 24 Nov 2014 00:33:38 GMT"}, {"version": "v54", "created": "Mon, 29 Dec 2014 19:30:07 GMT"}, {"version": "v55", "created": "Sun, 11 Jan 2015 00:03:38 GMT"}, {"version": "v56", "created": "Mon, 19 Jan 2015 17:13:01 GMT"}, {"version": "v57", "created": "Sun, 25 Jan 2015 23:31:03 GMT"}, {"version": "v58", "created": "Mon, 9 Feb 2015 18:06:24 GMT"}, {"version": "v59", "created": "Tue, 17 Feb 2015 18:23:20 GMT"}, {"version": "v6", "created": "Mon, 4 Oct 2010 19:15:10 GMT"}, {"version": "v60", "created": "Wed, 4 Mar 2015 21:46:30 GMT"}, {"version": "v7", "created": "Sat, 6 Nov 2010 21:38:29 GMT"}, {"version": "v8", "created": "Mon, 29 Nov 2010 15:58:31 GMT"}, {"version": "v9", "created": "Mon, 6 Dec 2010 20:50:18 GMT"}], "update_date": "2015-03-26", "authors_parsed": [["Hewitt", "Carl", ""]]}, {"id": "1008.2767", "submitter": "Derek Groen", "authors": "Derek Groen (Leiden), Steven Rieder (Leiden), Paola Grosso\n  (Amsterdam), Cees de Laat (Amsterdam), Simon Portegies Zwart (Leiden)", "title": "A Light-Weight Communication Library for Distributed Computing", "comments": "17 pages, 10 figures, published in Computational Science & Discovery", "journal-ref": "Derek Groen et al 2010 Comput. Sci. Disc. 3 015002", "doi": "10.1088/1749-4699/3/1/015002", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MPWide, a platform independent communication library for\nperforming message passing between computers. Our library allows coupling of\nseveral local MPI applications through a long distance network and is\nspecifically optimized for such communications. The implementation is\ndeliberately kept light-weight, platform independent and the library can be\ninstalled and used without administrative privileges. The only requirements are\na C++ compiler and at least one open port to a wide area network on each site.\nIn this paper we present the library, describe the user interface, present\nperformance tests and apply MPWide in a large scale cosmological N-body\nsimulation on a network of two computers, one in Amsterdam and the other in\nTokyo.\n", "versions": [{"version": "v1", "created": "Mon, 16 Aug 2010 20:14:11 GMT"}], "update_date": "2010-08-18", "authors_parsed": [["Groen", "Derek", "", "Leiden"], ["Rieder", "Steven", "", "Leiden"], ["Grosso", "Paola", "", "Amsterdam"], ["de Laat", "Cees", "", "Amsterdam"], ["Zwart", "Simon Portegies", "", "Leiden"]]}, {"id": "1008.2799", "submitter": "Soumya Banerjee", "authors": "Soumya Banerjee and Melanie Moses", "title": "Immune System Inspired Strategies for Distributed Systems", "comments": "5 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC q-bio.CB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many components of the IS are constructed as modular units which do not need\nto communicate with each other such that the number of components increases but\nthe size remains constant. However, a sub-modular IS architecture in which\nlymph node number and size both increase sublinearly with body size is shown to\nefficiently balance the requirements of communication and migration, consistent\nwith experimental data. We hypothesize that the IS architecture optimizes the\ntradeoff between local search for pathogens and global response using\nantibodies. Similar to natural immune systems, physical space and resource are\nalso important constraints on Artificial Immune Systems (AIS), especially\ndistributed systems applications used to connect low-powered sensors using\nshort-range wireless communication. AIS problems like distributed robot control\nwill also require a sub-modular architecture to efficiently balance the\ntradeoff between local search for a solution and global response or\nproliferation of the solution between different components.\n", "versions": [{"version": "v1", "created": "Tue, 17 Aug 2010 01:06:44 GMT"}], "update_date": "2010-08-18", "authors_parsed": [["Banerjee", "Soumya", ""], ["Moses", "Melanie", ""]]}, {"id": "1008.3171", "submitter": "Tsz-Wo Sze", "authors": "Tsz-Wo Sze", "title": "The Two Quadrillionth Bit of Pi is 0! Distributed Computation of Pi with\n  Apache Hadoop", "comments": "9 pages, 2 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.NT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new record on computing specific bits of Pi, the mathematical\nconstant, and discuss performing such computations on Apache Hadoop clusters.\nThe specific bits represented in hexadecimal are 0E6C1294 AED40403 F56D2D76\n4026265B CA98511D 0FCFFAA1 0F4D28B1 BB5392B8. These 256 bits end at the\n2,000,000,000,000,252nd bit position, which doubles the position and quadruples\nthe precision of the previous known record. The position of the first bit is\n1,999,999,999,999,997 and the value of the two quadrillionth bit is 0. The\ncomputation is carried out by a MapReduce program called DistBbp. To\neffectively utilize available cluster resources without monopolizing the whole\ncluster, we develop an elastic computation framework that automatically\nschedules computation slices, each a DistBbp job, as either map-side or\nreduce-side computation based on changing cluster load condition. We have\ncalculated Pi at varying bit positions and precisions, and one of the largest\ncomputations took 23 days of wall clock time and 503 years of CPU time on a\n1000-node cluster.\n", "versions": [{"version": "v1", "created": "Wed, 18 Aug 2010 20:17:09 GMT"}, {"version": "v2", "created": "Thu, 7 Oct 2010 03:30:14 GMT"}], "update_date": "2010-10-08", "authors_parsed": [["Sze", "Tsz-Wo", ""]]}, {"id": "1008.4551", "submitter": "Guanfeng Liang", "authors": "Guanfeng Liang and Nitin Vaidya", "title": "Deterministic Consensus Algorithm with Linear Per-Bit Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, building on the deterministic multi-valued one-to-many\nByzantine agreement (broadcast) algorithm in our recent technical report [2],\nwe introduce a deterministic multi-valued all-to-all Byzantine agreement\nalgorithm (consensus), with linear complexity per bit agreed upon. The\ndiscussion in this note is not self-contained, and relies heavily on the\nmaterial in [2] - please refer to [2] for the necessary background.\n", "versions": [{"version": "v1", "created": "Thu, 26 Aug 2010 17:29:31 GMT"}], "update_date": "2010-08-27", "authors_parsed": [["Liang", "Guanfeng", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1008.4571", "submitter": "Michael Thomas", "authors": "Michael W. Thomas and Erik Schnetter", "title": "Simulation Factory: Taming Application Configuration and Workflow on\n  High-End Resources", "comments": "10 pages, accepted by CBHPC 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational Science on large high performance computing resources is\nhampered by the complexity of these systems. Much of this complexity is due to\nlow-level details on these resources that are exposed to the application and\nthe end user. This includes (but is not limited to) mechanisms for remote\naccess, configuring and building applications from source code, and managing\nsimulations and their output files via batch queue systems. These challenges\nmultiply in a modern research environment, where a research collaboration spans\nmultiple groups, often in loosely defined international collaborations, where\nthere is a constant influx of new students into multi-year projects, and where\nsimulations are performed on several different resources. The Simulation\nFactory addresses these challenges by significantly simplifying remote access,\nbuilding executables, and managing simulations. By abstracting out the\nlow-level differences between different resources, it offers a uniform\ninterface to these resources. At the same time, it can enforce certain\nstandards for performing simulations that encapsulate best practices from\nexperienced users. Furthermore, SimFactory's automation avoids many possible\nuser errors that can in the worst case render month-long simulations worthless.\n", "versions": [{"version": "v1", "created": "Thu, 26 Aug 2010 19:34:14 GMT"}], "update_date": "2010-09-13", "authors_parsed": [["Thomas", "Michael W.", ""], ["Schnetter", "Erik", ""]]}, {"id": "1008.4900", "submitter": "Kamal Ahmat", "authors": "Kamal A. Ahmat and Hassan Gobjuka", "title": "Managing Clouds in Cloud Platforms", "comments": "NSDI '10: 7th USENIX Symposium on Networked Systems Design and\n  Implementation, San Jose, California", "journal-ref": "NSDI '10: 7th USENIX Symposium on Networked Systems Design and\n  Implementation, San Jose, California, April 2010", "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Managing cloud services is a fundamental challenge in todays virtualized\nenvironments. These challenges equally face both providers and consumers of\ncloud services. The issue becomes even more challenging in virtualized\nenvironments that support mobile clouds. Cloud computing platforms such as\nAmazon EC2 provide customers with flexible, on demand resources at low cost.\nHowever, they fail to provide seamless infrastructure management and monitoring\ncapabilities that many customers may need. For instance, Amazon EC2 doesn't\nfully support cloud services automated discovery and it requires a private set\nof authentication credentials. Salesforce.com, on the other hand, do not\nprovide monitoring access to their underlying systems. Moreover, these systems\nfail to provide infrastructure monitoring of heterogenous and legacy systems\nthat don't support agents. In this work, we explore how to build a cloud\nmanagement system that combines heterogeneous management of virtual resources\nwith comprehensive management of physical devices. We propose an initial\nprototype for automated cloud management and monitoring framework. Our ultimate\ngoal is to develop a framework that have the capability of automatically\ntracking configuration and relationships while providing full event management,\nmeasuring performance and testing thresholds, and measuring availability\nconsistently. Armed with such a framework, operators can make better decisions\nquickly and more efficiently.\n", "versions": [{"version": "v1", "created": "Sun, 29 Aug 2010 03:35:24 GMT"}], "update_date": "2010-08-31", "authors_parsed": [["Ahmat", "Kamal A.", ""], ["Gobjuka", "Hassan", ""]]}, {"id": "1008.4990", "submitter": "Karl Obermeyer", "authors": "Karl J. Obermeyer, Anurag Ganguli, Francesco Bullo", "title": "Multi-Agent Deployment for Visibility Coverage in Polygonal Environments\n  with Holes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents a distributed algorithm for a group of robotic agents\nwith omnidirectional vision to deploy into nonconvex polygonal environments\nwith holes. Agents begin deployment from a common point, possess no prior\nknowledge of the environment, and operate only under line-of-sight sensing and\ncommunication. The objective of the deployment is for the agents to achieve\nfull visibility coverage of the environment while maintaining line-of-sight\nconnectivity with each other. This is achieved by incrementally partitioning\nthe environment into distinct regions, each completely visible from some agent.\nProofs are given of (i) convergence, (ii) upper bounds on the time and number\nof agents required, and (iii) bounds on the memory and communication\ncomplexity. Simulation results and description of robust extensions are also\nincluded.\n", "versions": [{"version": "v1", "created": "Mon, 30 Aug 2010 03:05:50 GMT"}, {"version": "v2", "created": "Wed, 15 Sep 2010 02:32:51 GMT"}, {"version": "v3", "created": "Wed, 22 Sep 2010 17:18:06 GMT"}, {"version": "v4", "created": "Thu, 2 Dec 2010 17:12:26 GMT"}], "update_date": "2010-12-03", "authors_parsed": [["Obermeyer", "Karl J.", ""], ["Ganguli", "Anurag", ""], ["Bullo", "Francesco", ""]]}, {"id": "1008.5391", "submitter": "Hesam Dashti", "authors": "Hesam T. Dashti, Alireza F. Siahpirani, Liya Wang, Mary Kloc and Amir\n  H. Assadi", "title": "Parallel Evolutionary Computation in Very Large Scale Eigenvalue\n  Problems", "comments": "Proceedings of the 2008 International Conference on Scientific\n  Computing, CSC 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NA", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The history of research on eigenvalue problems is rich with many outstanding\ncontributions. Nonetheless, the rapidly increasing size of data sets requires\nnew algorithms for old problems in the context of extremely large matrix\ndimensions. This paper reports on a new method for finding eigenvalues of very\nlarge matrices by a synthesis of evolutionary computation, parallel\nprogramming, and empirical stochastic search. The direct design of our method\nhas the added advantage that it could be adapted to extend many algorithmic\nvariants of solutions of generalized eigenvalue problems to improve the\naccuracy of our algorithms. The preliminary evaluation results are encouraging\nand demonstrate the method's efficiency and practicality.\n", "versions": [{"version": "v1", "created": "Tue, 31 Aug 2010 18:56:04 GMT"}, {"version": "v2", "created": "Sun, 15 Dec 2013 19:24:23 GMT"}], "update_date": "2013-12-17", "authors_parsed": [["Dashti", "Hesam T.", ""], ["Siahpirani", "Alireza F.", ""], ["Wang", "Liya", ""], ["Kloc", "Mary", ""], ["Assadi", "Amir H.", ""]]}]