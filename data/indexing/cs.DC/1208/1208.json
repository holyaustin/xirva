[{"id": "1208.0055", "submitter": "Sutanay Choudhury Sutanay Choudhury", "authors": "Sutanay Choudhury, Lawrence Holder, George Chin, John Feo", "title": "Large-scale continuous subgraph queries on streams", "comments": null, "journal-ref": "In Proceedings of the first annual workshop on High performance\n  computing meets databases (HPCDB 2011). ACM, New York, NY, USA, 29-32", "doi": "10.1145/2125636.2125647", "report-no": null, "categories": "cs.DB cs.DC", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Graph pattern matching involves finding exact or approximate matches for a\nquery subgraph in a larger graph. It has been studied extensively and has\nstrong applications in domains such as computer vision, computational biology,\nsocial networks, security and finance. The problem of exact graph pattern\nmatching is often described in terms of subgraph isomorphism which is\nNP-complete. The exponential growth in streaming data from online social\nnetworks, news and video streams and the continual need for situational\nawareness motivates a solution for finding patterns in streaming updates. This\nis also the prime driver for the real-time analytics market. Development of\nincremental algorithms for graph pattern matching on streaming inputs to a\ncontinually evolving graph is a nascent area of research. Some of the\nchallenges associated with this problem are the same as found in continuous\nquery (CQ) evaluation on streaming databases. This paper reviews some of the\nrepresentative work from the exhaustively researched field of CQ systems and\nidentifies important semantics, constraints and architectural features that are\nalso appropriate for HPC systems performing real-time graph analytics. For each\nof these features we present a brief discussion of the challenge encountered in\nthe database realm, the approach to the solution and state their relevance in a\nhigh-performance, streaming graph processing framework.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jul 2012 23:40:03 GMT"}], "update_date": "2012-08-02", "authors_parsed": [["Choudhury", "Sutanay", ""], ["Holder", "Lawrence", ""], ["Chin", "George", ""], ["Feo", "John", ""]]}, {"id": "1208.0180", "submitter": "Othon Michail", "authors": "Othon Michail and Ioannis Chatzigiannakis and Paul G. Spirakis", "title": "Naming and Counting in Anonymous Unknown Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the fundamental naming and counting problems (and some\nvariations) in networks that are anonymous, unknown, and possibly dynamic. In\ncounting, nodes must determine the size of the network n and in naming they\nmust end up with unique identities. By anonymous we mean that all nodes begin\nfrom identical states apart possibly from a unique leader node and by unknown\nthat nodes have no a priori knowledge of the network (apart from some minimal\nknowledge when necessary) including ignorance of n. Network dynamicity is\nmodeled by the 1-interval connectivity model, in which communication is\nsynchronous and a worst-case adversary chooses the edges of every round subject\nto the condition that each instance is connected. We first focus on static\nnetworks with broadcast where we prove that, without a leader, counting is\nimpossible to solve and that naming is impossible to solve even with a leader\nand even if nodes know n. These impossibilities carry over to dynamic networks\nas well. We also show that a unique leader suffices in order to solve counting\nin linear time. Then we focus on dynamic networks with broadcast. We conjecture\nthat dynamicity renders nontrivial computation impossible. In view of this, we\nlet the nodes know an upper bound on the maximum degree that will ever appear\nand show that in this case the nodes can obtain an upper bound on n. Finally,\nwe replace broadcast with one-to-each, in which a node may send a different\nmessage to each of its neighbors. Interestingly, this natural variation is\nproved to be computationally equivalent to a full-knowledge model, in which\nunique names exist and the size of the network is known.\n", "versions": [{"version": "v1", "created": "Wed, 1 Aug 2012 12:00:17 GMT"}], "update_date": "2012-08-02", "authors_parsed": [["Michail", "Othon", ""], ["Chatzigiannakis", "Ioannis", ""], ["Spirakis", "Paul G.", ""]]}, {"id": "1208.0593", "submitter": "Partha Pratim Ray", "authors": "Partha Pratim Ray", "title": "The green grid saga - a green initiative to data centers: a review", "comments": "ISSN 0976-5166", "journal-ref": "Indian Journal of Computer Science and Engineering (IJCSE) 1(4),\n  2010, 333-339", "doi": null, "report-no": null, "categories": "cs.SY cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Information Technology (IT) significantly impacts the environment throughout\nits life cycle. Most enterprises have not paid enough attention to this until\nrecently. IT's environmental impact can be significantly reduced by behavioral\nchanges, as well as technology changes. Given the relative energy and materials\ninefficiency of most IT infrastructures today, many green IT initiatives can be\neasily tackled at no incremental cost. The Green Grid - a non-profit trade\norganization of IT professionals is such an initiative, formed to initiate the\nissues of power and cooling in data centers, scattered world-wide. The Green\nGrid seeks to define best practices for optimizing the efficient consumption of\npower at IT equipment and facility levels, as well as the manner in which\ncooling is delivered at these levels hence, providing promising attitude in\nbringing down the environmental hazards, as well as proceeding to the new era\nof green computing. In this paper we review the various analytical aspects of\nThe Green Grid upon the data centers and found green facts.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2012 17:03:15 GMT"}], "update_date": "2012-08-06", "authors_parsed": [["Ray", "Partha Pratim", ""]]}, {"id": "1208.0615", "submitter": "Dimitris Fotakis", "authors": "Foto N. Afrati, Dimitris Fotakis, Jeffrey D. Ullman", "title": "Enumerating Subgraph Instances Using Map-Reduce", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The theme of this paper is how to find all instances of a given \"sample\"\ngraph in a larger \"data graph,\" using a single round of map-reduce. For the\nsimplest sample graph, the triangle, we improve upon the best known such\nalgorithm. We then examine the general case, considering both the communication\ncost between mappers and reducers and the total computation cost at the\nreducers. To minimize communication cost, we exploit the techniques of (Afrati\nand Ullman, TKDE 2011)for computing multiway joins (evaluating conjunctive\nqueries) in a single map-reduce round. Several methods are shown for\ntranslating sample graphs into a union of conjunctive queries with as few\nqueries as possible. We also address the matter of optimizing computation cost.\nMany serial algorithms are shown to be \"convertible,\" in the sense that it is\npossible to partition the data graph, explore each partition in a separate\nreducer, and have the total computation cost at the reducers be of the same\norder as the computation cost of the serial algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 2 Aug 2012 20:56:39 GMT"}, {"version": "v2", "created": "Wed, 21 Nov 2012 20:03:05 GMT"}], "update_date": "2012-11-22", "authors_parsed": [["Afrati", "Foto N.", ""], ["Fotakis", "Dimitris", ""], ["Ullman", "Jeffrey D.", ""]]}, {"id": "1208.0664", "submitter": "Yin Wang", "authors": "Yin Wang, Yuan He, Dapeng Cheng, Yunhao Liu, Xiang-yang Li", "title": "Triggercast: Enabling Wireless Collisions Constructive", "comments": "10 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is generally considered that concurrent transmissions should be avoided in\norder to reduce collisions in wireless sensor networks. Constructive\ninterference (CI) envisions concurrent transmissions to positively interfere at\nthe receiver. CI potentially allows orders of magnitude reductions in energy\nconsumptions and improvements on link quality. In this paper, we theoretically\nintroduce a sufficient condition to construct CI with IEEE 802.15.4 radio for\nthe first time. Moreover, we propose Triggercast, a distributed middleware, and\nshow it is feasible to generate CI in TMote Sky sensor nodes. To synchronize\ntransmissions of multiple senders at the chip level, Triggercast effectively\ncompensates propagation and radio processing delays, and has $95^{th}$\npercentile synchronization errors of at most 250ns. Triggercast also\nintelligently decides which co-senders to participate in simultaneous\ntransmissions, and aligns their transmission time to maximize the overall link\nPRR, under the condition of maximal system robustness. Extensive experiments in\nreal testbeds reveal that Triggercast significantly improves PRR from 5% to 70%\nwith 7 concurrent senders. We also demonstrate that Triggercast provides on\naverage $1.3\\times$ PRR performance gains, when integrated with existing data\nforwarding protocols.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2012 06:34:25 GMT"}], "update_date": "2012-08-06", "authors_parsed": [["Wang", "Yin", ""], ["He", "Yuan", ""], ["Cheng", "Dapeng", ""], ["Liu", "Yunhao", ""], ["Li", "Xiang-yang", ""]]}, {"id": "1208.0712", "submitter": "Bojan Marinkovi\\'c", "authors": "Bojan Marinkovi\\'c, Paola Glavan, Zoran Ognjanovi\\'c", "title": "Description of the Chord Protocol using ASMs Formalism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the overlay protocol Chord using the formalism of\nAbstract State Machines. The formalization concerns Chord actions that maintain\nring topology and manipulate distributed keys. We define a class of runs and\nprove the correctness of our formalization with respect to it.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2012 11:17:57 GMT"}, {"version": "v2", "created": "Mon, 23 Sep 2013 13:23:08 GMT"}], "update_date": "2013-09-24", "authors_parsed": [["Marinkovi\u0107", "Bojan", ""], ["Glavan", "Paola", ""], ["Ognjanovi\u0107", "Zoran", ""]]}, {"id": "1208.0788", "submitter": "Shang Shang", "authors": "Shang Shang and Paul W. Cuff and Pan Hui and Sanjeev R. Kulkarni", "title": "An Upper Bound on the Convergence Time for Quantized Consensus", "comments": "submitted to IEEE Transactions on Automatic Control, 23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.DC cs.PF math.OC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We analyze a class of distributed quantized consen- sus algorithms for\narbitrary networks. In the initial setting, each node in the network has an\ninteger value. Nodes exchange their current estimate of the mean value in the\nnetwork, and then update their estimation by communicating with their neighbors\nin a limited capacity channel in an asynchronous clock setting. Eventually, all\nnodes reach consensus with quantized precision. We start the analysis with a\nspecial case of a distributed binary voting algorithm, then proceed to the\nexpected convergence time for the general quantized consensus algorithm\nproposed by Kashyap et al. We use the theory of electric networks, random\nwalks, and couplings of Markov chains to derive an O(N^3log N) upper bound for\nthe expected convergence time on an arbitrary graph of size N, improving on the\nstate of art bound of O(N^4logN) for binary consensus and O(N^5) for quantized\nconsensus algorithms. Our result is not dependent on graph topology.\nSimulations on special graphs such as star networks, line graphs, lollipop\ngraphs, and Erd\\\"os-R\\'enyi random graphs are performed to validate the\nanalysis. This work has applications to load balancing, coordination of\nautonomous agents, estimation and detection, decision-making networks,\npeer-to-peer systems, etc.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2012 16:16:13 GMT"}, {"version": "v2", "created": "Fri, 17 May 2013 21:49:10 GMT"}], "update_date": "2013-05-21", "authors_parsed": [["Shang", "Shang", ""], ["Cuff", "Paul W.", ""], ["Hui", "Pan", ""], ["Kulkarni", "Sanjeev R.", ""]]}, {"id": "1208.0811", "submitter": "Guanhong Pei", "authors": "Guanhong Pei and Anil Kumar S. Vullikanti", "title": "Efficient Algorithms for Maximum Link Scheduling in Distributed\n  Computing Models with SINR Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A fundamental problem in wireless networks is the maximum link scheduling\nproblem: given a set $L$ of links, compute the largest possible subset\n$L'\\subseteq L$ of links that can be scheduled simultaneously without\ninterference. This problem is particularly challenging in the physical\ninterference model based on SINR constraints (referred to as the SINR model),\nwhich has gained a lot of interest in recent years. Constant factor\napproximation algorithms have been developed for this problem, but low\ncomplexity distributed algorithms that give the same approximation guarantee in\nthe SINR model are not known. Distributed algorithms are especially challenging\nin this model, because of its non-locality.\n  In this paper, we develop a set of fast distributed algorithms in the SINR\nmodel, providing constant approximation for the maximum link scheduling problem\nunder uniform power assignment. We find that different aspects of available\ntechnology, such as full/half-duplex communication, and non-adaptive/adaptive\npower control, have a significant impact on the performance of the algorithm;\nthese issues have not been explored in the context of distributed algorithms in\nthe SINR model before. Our algorithms' running time is $O(g(L) \\log^c m)$,\nwhere $c=1,2,3$ for different problem instances, and $g(L)$ is the \"link\ndiversity\" determined by the logarithmic scale of a communication link length.\nSince $g(L)$ is small and remains in a constant range in most cases, our\nalgorithms serve as the first set of \"sublinear\" time distributed solution. The\nalgorithms are randomized and crucially use physical carrier sensing in\ndistributed communication steps.\n", "versions": [{"version": "v1", "created": "Fri, 3 Aug 2012 18:26:06 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2012 15:46:26 GMT"}], "update_date": "2012-11-19", "authors_parsed": [["Pei", "Guanhong", ""], ["Vullikanti", "Anil Kumar S.", ""]]}, {"id": "1208.1157", "submitter": "Saleh Dindar", "authors": "Saleh Dindar, Eric B. Ford, Mario Juric, Young In Yeo, Jianwei Gao,\n  Aaron C. Boley, Benjamin Nelson, Jorg Peters", "title": "Swarm-NG: a CUDA Library for Parallel n-body Integrations with focus on\n  Simulations of Planetary Systems", "comments": "Submitted to New Astronomy", "journal-ref": null, "doi": "10.1016/j.newast.2013.01.002", "report-no": null, "categories": "astro-ph.EP astro-ph.IM cs.DC cs.MS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Swarm-NG, a C++ library for the efficient direct integration of\nmany n-body systems using highly-parallel Graphics Processing Unit (GPU), such\nas NVIDIA's Tesla T10 and M2070 GPUs. While previous studies have demonstrated\nthe benefit of GPUs for n-body simulations with thousands to millions of\nbodies, Swarm-NG focuses on many few-body systems, e.g., thousands of systems\nwith 3...15 bodies each, as is typical for the study of planetary systems.\nSwarm-NG parallelizes the simulation, including both the numerical integration\nof the equations of motion and the evaluation of forces using NVIDIA's \"Compute\nUnified Device Architecture\" (CUDA) on the GPU. Swarm-NG includes optimized\nimplementations of 4th order time-symmetrized Hermite integration and mixed\nvariable symplectic integration, as well as several sample codes for other\nalgorithms to illustrate how non-CUDA-savvy users may themselves introduce\ncustomized integrators into the Swarm-NG framework. To optimize performance, we\nanalyze the effect of GPU-specific parameters on performance under double\nprecision.\n  Applications of Swarm-NG include studying the late stages of planet\nformation, testing the stability of planetary systems and evaluating the\ngoodness-of-fit between many planetary system models and observations of\nextrasolar planet host stars (e.g., radial velocity, astrometry, transit\ntiming). While Swarm-NG focuses on the parallel integration of many planetary\nsystems,the underlying integrators could be applied to a wide variety of\nproblems that require repeatedly integrating a set of ordinary differential\nequations many times using different initial conditions and/or parameter\nvalues.\n", "versions": [{"version": "v1", "created": "Mon, 6 Aug 2012 13:11:28 GMT"}, {"version": "v2", "created": "Tue, 25 Sep 2012 00:22:46 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Dindar", "Saleh", ""], ["Ford", "Eric B.", ""], ["Juric", "Mario", ""], ["Yeo", "Young In", ""], ["Gao", "Jianwei", ""], ["Boley", "Aaron C.", ""], ["Nelson", "Benjamin", ""], ["Peters", "Jorg", ""]]}, {"id": "1208.1454", "submitter": "Danupon Nanongkai", "authors": "Atish Das Sarma, Ashwin Lall, Danupon Nanongkai, Amitabh Trehan", "title": "Dense Subgraphs on Dynamic Networks", "comments": "To appear in the 26th International Symposium on Distributed\n  Computing (DISC 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed networks, it is often useful for the nodes to be aware of\ndense subgraphs, e.g., such a dense subgraph could reveal dense subtructures in\notherwise sparse graphs (e.g. the World Wide Web or social networks); these\nmight reveal community clusters or dense regions for possibly maintaining good\ncommunication infrastructure. In this work, we address the problem of\nself-awareness of nodes in a dynamic network with regards to graph density,\ni.e., we give distributed algorithms for maintaining dense subgraphs that the\nmember nodes are aware of. The only knowledge that the nodes need is that of\nthe dynamic diameter $D$, i.e., the maximum number of rounds it takes for a\nmessage to traverse the dynamic network. For our work, we consider a model\nwhere the number of nodes are fixed, but a powerful adversary can add or remove\na limited number of edges from the network at each time step. The communication\nis by broadcast only and follows the CONGEST model. Our algorithms are\ncontinuously executed on the network, and at any time (after some\ninitialization) each node will be aware if it is part (or not) of a particular\ndense subgraph. We give algorithms that ($2 + \\epsilon$)-approximate the\ndensest subgraph and ($3 + \\epsilon$)-approximate the at-least-$k$-densest\nsubgraph (for a given parameter $k$). Our algorithms work for a wide range of\nparameter values and run in $O(D\\log_{1+\\epsilon} n)$ time. Further, a special\ncase of our results also gives the first fully decentralized approximation\nalgorithms for densest and at-least-$k$-densest subgraph problems for static\ndistributed graphs.\n", "versions": [{"version": "v1", "created": "Tue, 7 Aug 2012 15:54:28 GMT"}], "update_date": "2012-08-08", "authors_parsed": [["Sarma", "Atish Das", ""], ["Lall", "Ashwin", ""], ["Nanongkai", "Danupon", ""], ["Trehan", "Amitabh", ""]]}, {"id": "1208.1723", "submitter": "Philipp Woelfel", "authors": "Abhijeet Pareek and Philipp Woelfel", "title": "RMR-Efficient Randomized Abortable Mutual Exclusion", "comments": "Extended abstract will appear at DISC 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research on mutual exclusion for shared-memory systems has focused on\n\"local spin\" algorithms. Performance is measured using the \"remote memory\nreferences\" (RMRs) metric. As common in recent literature, we consider a\nstandard asynchronous shared memory model with N processes, which allows atomic\nread, write and compare-and-swap (short: CAS) operations.\n  In such a model, the asymptotically tight upper and lower bound on the number\nof RMRs per passage through the Critical Section is Theta(log N) for the\noptimal deterministic algorithms (see Yang and Anderson,1995, and Attiya,\nHendler and Woelfel, 2008). Recently, several randomized algorithms have been\ndevised that break the Omega(log N) barrier and need only o(log N) RMRs per\npassage in expectation (see Hendler and Woelfel, 2010, Hendler and Woelfel,\n2011, and Bender and Gilbert, 2011). In this paper we present the first\nrandomized \"abortable\" mutual exclusion algorithm that achieves a\nsub-logarithmic expected RMR complexity. More precisely, against a weak\nadversary (which can make scheduling decisions based on the entire past\nhistory, but not the latest coin-flips of each process) every process needs an\nexpected number of O(log N/ log log N) RMRs to enter end exit the critical\nsection. If a process receives an abort-signal, it can abort an attempt to\nenter the critical section within a finite number of its own steps and by\nincurring O(log N/ log log N) RMRs.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2012 17:51:24 GMT"}], "update_date": "2012-08-09", "authors_parsed": [["Pareek", "Abhijeet", ""], ["Woelfel", "Philipp", ""]]}, {"id": "1208.1793", "submitter": "Xiaohua Xu", "authors": "Xiaohua Xu, Xiang-Yang Li, Min Song", "title": "Real-time Data Collection Scheduling in Multi-hop Wireless Sensor\n  Networks", "comments": "7 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We study real time periodic query scheduling for data collection in multihop\nWireless Sensor Networks (WSNs). Given a set of heterogenous data collection\nqueries in WSNs, each query requires the data from the source sensor nodes to\nbe collected to the control center within a certain end-to-end delay. We first\npropose almost-tight necessary conditions for a set of different queries to be\nschedulable by a WSN. We then develop a family of efficient and effective data\ncollection algorithms that can meet the real-time requirement under resource\nconstraints by addressing three tightly coupled tasks: (1) routing tree\nconstruction for data collection, (2) link activity scheduling, and (3)\npacket-level scheduling. Our theoretical analysis for the schedulability of\nthese algorithms show that they can achieve a constant fraction of the maximum\nschedulable load. For the case of overloaded networks where not all queries can\nbe possibly satisfied, we propose an efficient approximation algorithm to\nselect queries to maximize the total weight of selected schedulable queries.\nThe simulations corroborate our theoretical analysis.\n", "versions": [{"version": "v1", "created": "Wed, 8 Aug 2012 22:47:10 GMT"}, {"version": "v2", "created": "Fri, 2 Aug 2013 18:58:34 GMT"}], "update_date": "2013-08-05", "authors_parsed": [["Xu", "Xiaohua", ""], ["Li", "Xiang-Yang", ""], ["Song", "Min", ""]]}, {"id": "1208.1842", "submitter": "Simon Kramer", "authors": "Simon Kramer", "title": "Logic of Non-Monotonic Interactive Proofs (Formal Theory of Temporary\n  Knowledge Transfer)", "comments": "continuation of arXiv:1201.3667 ; published extended abstract:\n  DOI:10.1007/978-3-642-36039-8_16 ; related to arXiv:1208.5913", "journal-ref": null, "doi": "10.1007/978-3-642-36039-8_16", "report-no": null, "categories": "cs.LO cs.CR cs.DC cs.MA math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a monotonic logic of internalised non-monotonic or instant\ninteractive proofs (LiiP) and reconstruct an existing monotonic logic of\ninternalised monotonic or persistent interactive proofs (LiP) as a minimal\nconservative extension of LiiP. Instant interactive proofs effect a fragile\nepistemic impact in their intended communities of peer reviewers that consists\nin the impermanent induction of the knowledge of their proof goal by means of\nthe knowledge of the proof with the interpreting reviewer: If my peer reviewer\nknew my proof then she would at least then (in that instant) know that its\nproof goal is true. Their impact is fragile and their induction of knowledge\nimpermanent in the sense of being the case possibly only at the instant of\nlearning the proof. This accounts for the important possibility of\ninternalising proofs of statements whose truth value can vary, which, as\nopposed to invariant statements, cannot have persistent proofs. So instant\ninteractive proofs effect a temporary transfer of certain propositional\nknowledge (knowable ephemeral facts) via the transmission of certain individual\nknowledge (knowable non-monotonic proofs) in distributed systems of multiple\ninteracting agents.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2012 08:30:48 GMT"}, {"version": "v2", "created": "Thu, 31 Jan 2013 05:21:06 GMT"}], "update_date": "2013-02-07", "authors_parsed": [["Kramer", "Simon", ""]]}, {"id": "1208.1922", "submitter": "Probir Roy", "authors": "Probir Roy, Md. Mejbah Ul Alam and Nishita Das", "title": "Heuristic based task scheduling in multiprocessor systems with genetic\n  algorithm by choosing the eligible processor", "comments": null, "journal-ref": "IJDPS, Vol.3, No.4, (July 2012) 111-121", "doi": "10.5121/ijdps.2012.3412", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In multiprocessor systems, one of the main factors of systems' performance is\ntask scheduling. The well the task be distributed among the processors the well\nbe the performance. Again finding the optimal solution of scheduling the tasks\ninto the processors is NP-complete, that is, it will take a lot of time to find\nthe optimal solution. Many evolutionary algorithms (e.g. Genetic Algorithm,\nSimulated annealing) are used to reach the near optimal solution in linear\ntime. In this paper we propose a heuristic for genetic algorithm based task\nscheduling in multiprocessor systems by choosing the eligible processor on\neducated guess. From comparison it is found that this new heuristic based GA\ntakes less computation time to reach the suboptimal solution.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2012 14:34:20 GMT"}], "update_date": "2012-08-10", "authors_parsed": [["Roy", "Probir", ""], ["Alam", "Md. Mejbah Ul", ""], ["Das", "Nishita", ""]]}, {"id": "1208.1942", "submitter": "Thirumala Rao B", "authors": "B. Thirumala Rao, L. S. S. Reddy", "title": "Scheduling Data Intensive Workloads through Virtualization on MapReduce\n  based Clouds", "comments": null, "journal-ref": "International Journal of Distributed and Parallel Systems\n  (IJDPS)Vol.3, No.4, Pages 99-110, July 2012", "doi": "10.5121/ijdps.2012.3411", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  MapReduce has become a popular programming model for running data intensive\napplications on the cloud. Completion time goals or deadlines of MapReduce jobs\nset by users are becoming crucial in existing cloud-based data processing\nenvironments like Hadoop. There is a conflict between the scheduling MR jobs to\nmeet deadlines and \"data locality\" (assigning tasks to nodes that contain their\ninput data). To meet the deadline a task may be scheduled on a node without\nlocal input data for that task causing expensive data transfer from a remote\nnode. In this paper, a novel scheduler is proposed to address the above problem\nwhich is primarily based on the dynamic resource reconfiguration approach. It\nhas two components: 1) Resource Predictor: which dynamically determines the\nrequired number of Map/Reduce slots for every job to meet completion time\nguarantee; 2) Resource Reconfigurator: that adjusts the CPU resources while not\nviolating completion time goals of the users by dynamically increasing or\ndecreasing individual VMs to maximize data locality and also to maximize the\nuse of resources within the system among the active jobs. The proposed\nscheduler has been evaluated against Fair Scheduler on virtual cluster built on\na physical cluster of 20 machines. The results demonstrate a gain of about 12%\nincrease in throughput of Jobs\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2012 15:07:43 GMT"}], "update_date": "2012-08-10", "authors_parsed": [["Rao", "B. Thirumala", ""], ["Reddy", "L. S. S.", ""]]}, {"id": "1208.1975", "submitter": "Manuel Birke", "authors": "Manuel Birke, Bobby Philip, Zhen Wang, Mark Berrill", "title": "Block-Relaxation Methods for 3D Constant-Coefficient Stencils on GPUs\n  and Multicore CPUs", "comments": "Submitted to Journal of Parallel and Distributed Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Block iterative methods are extremely important as smoothers for multigrid\nmethods, as preconditioners for Krylov methods, and as solvers for diagonally\ndominant linear systems. Developing robust and efficient algorithms suitable\nfor current and evolving GPU and multicore CPU systems is a significant\nchallenge. We address this issue in the case of constant-coefficient stencils\narising in the solution of elliptic partial differential equations on\nstructured 3D uniform and adaptively refined grids. Robust, highly parallel\nimplementations of block Jacobi and chaotic block Gauss-Seidel algorithms with\nexact inversion of the blocks are developed using different parallelization\ntechniques. Experimental results for NVIDIA Fermi GPUs and AMD multicore\nsystems are presented.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2012 17:29:16 GMT"}, {"version": "v2", "created": "Mon, 11 Feb 2013 09:12:16 GMT"}, {"version": "v3", "created": "Mon, 15 Jul 2019 16:56:18 GMT"}], "update_date": "2019-07-16", "authors_parsed": [["Birke", "Manuel", ""], ["Philip", "Bobby", ""], ["Wang", "Zhen", ""], ["Berrill", "Mark", ""]]}, {"id": "1208.1982", "submitter": "Ravi Tandon", "authors": "Ravi Tandon", "title": "Determination Of Optimal Number Of Clusters In Wireless Sensor Networks", "comments": "18 pages, 14 figures", "journal-ref": "International Journal of Computer Networks & Communications\n  (IJCNC) Vol.4, No.4, July 2012, 235-249", "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Prolonged network lifetime, scalability and efficient load balancing are\nessential for optimal performance of a wireless sensor network. Clustering\nprovides an effective way of extending the lifetime of a sensor network.\nClustering is the process that divides sensor networks into smaller localized\ngroup (called clusters) of members with a cluster head. Clustering protocols\nneed to elect optimal number of clusters in hierarchically structured wireless\nsensor networks. Any clustering scheme that elects clusters uniformly\n(irrespective of the distance from Base Station) incurs excessive energy usage\non clusters proximal and distant to Base Station. In single hop networks a\ngradual increment in the energy depletion rate is observed as the distance from\nthe cluster head increases. This work focuses on the analysis of wasteful\nenergy consumption within a uniform cluster head election model (EPEM) and\nprovides an analytic solution to reduce the overall consumption of energy usage\namongst the clusters elected in a wireless sensor network. A circular model of\nsensor network is considered, where the sensor nodes are deployed around a\ncentrally located Base Station. The sensor network is divided into several\nconcentric rings centred at the Base Station. A model, Unequal Probability\nElection Model (UEPEM), which elects cluster heads non-uniformly is proposed.\nThe probability of cluster head election depends on the distance from the Base\nStation. UEPEM reduces the overall energy usage by about 21% over EPEM. The\nperformance of UEPEM improves as the number of rings is increased.\n", "versions": [{"version": "v1", "created": "Thu, 9 Aug 2012 17:46:24 GMT"}], "update_date": "2012-08-10", "authors_parsed": [["Tandon", "Ravi", ""]]}, {"id": "1208.2115", "submitter": "Ismael Etxeberria-Agiriano", "authors": "Ismael Etxeberria-Agiriano, Isidro Calvo, Liliana Montero and Ivan\n  Alonso", "title": "A DDS-Based Scalable and Reconfigurable Framework for Cyber-Physical\n  Systems", "comments": "13 pages, 6 figures", "journal-ref": "International Journal of Software Engineering & Applications\n  (IJSEA), vol. 3, no. 4 (2012) 25-37", "doi": "10.5121/ijsea.2012.3403", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Cyber-Physical Systems (CPSs) involve the interconnection of heterogeneous\ncomputing devices which are closely integrated with the physical processes\nunder control. Often, these systems are resource-constrained and require\nspecific features such as the ability to adapt in a timeliness and efficient\nfashion to dynamic environments. Also, they must support fault tolerance and\navoid single points of failure. This paper describes a scalable framework for\nCPSs based on the OMG DDS standard. The proposed solution allows reconfiguring\nthis kind of systems at run-time and managing efficiently their resources.\n", "versions": [{"version": "v1", "created": "Fri, 10 Aug 2012 08:47:10 GMT"}], "update_date": "2012-08-13", "authors_parsed": [["Etxeberria-Agiriano", "Ismael", ""], ["Calvo", "Isidro", ""], ["Montero", "Liliana", ""], ["Alonso", "Ivan", ""]]}, {"id": "1208.2407", "submitter": "Peter Wittek", "authors": "Peter Wittek, Fernando M. Cucchietti", "title": "A Second-Order Distributed Trotter-Suzuki Solver with a Hybrid Kernel", "comments": "11 pages, 10 figures", "journal-ref": "Computer Physics Communications 184, 1165-1171 (2013)", "doi": "10.1016/j.cpc.2012.12.008", "report-no": null, "categories": "physics.comp-ph cs.DC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Trotter-Suzuki approximation leads to an efficient algorithm for solving\nthe time-dependent Schr\\\"odinger equation. Using existing highly optimized CPU\nand GPU kernels, we developed a distributed version of the algorithm that runs\nefficiently on a cluster. Our implementation also improves single node\nperformance, and is able to use multiple GPUs within a node. The scaling is\nclose to linear using the CPU kernels, whereas the efficiency of GPU kernels\nimprove with larger matrices. We also introduce a hybrid kernel that\nsimultaneously uses multicore CPUs and GPUs in a distributed system. This\nkernel is shown to be efficient when the matrix size would not fit in the GPU\nmemory. Larger quantum systems scale especially well with a high number nodes.\nThe code is available under an open source license.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2012 07:22:24 GMT"}], "update_date": "2013-03-06", "authors_parsed": [["Wittek", "Peter", ""], ["Cucchietti", "Fernando M.", ""]]}, {"id": "1208.2428", "submitter": "Sebastian Szkoda", "authors": "Sebastian Szkoda, Zbigniew Koza, Mateusz Tykierko", "title": "Accelerating cellular automata simulations using AVX and CUDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigated various methods of parallelization of the\nFrish-Hasslacher-Pomeau (FHP) cellular automata algorithm for modeling fluid\nflow. These methods include SSE, AVX, and POSIX Threads for central processing\nunits (CPUs) and CUDA for graphics processing units (GPUs). We present\nimplementation details of the FHP algorithm based on AVX/SSE and CUDA\ntechnologies. We found that (a) using AVX or SSE is necessary to fully utilize\nthe potential of modern CPUs; (b) CPUs and GPUs are comparable in terms of\ncomputational and economic efficiency only if the CPU code uses AVX or SSE\ninstructions; (c) AVX does not offer any substantial improvement relative to\nSSE.\n", "versions": [{"version": "v1", "created": "Sun, 12 Aug 2012 13:34:11 GMT"}], "update_date": "2012-08-14", "authors_parsed": [["Szkoda", "Sebastian", ""], ["Koza", "Zbigniew", ""], ["Tykierko", "Mateusz", ""]]}, {"id": "1208.2649", "submitter": "Daniel S. Katz", "authors": "Daniel S. Katz, Shantenu Jha, Manish Parashar, Omer Rana, Jon Weissman", "title": "Survey and Analysis of Production Distributed Computing Infrastructures", "comments": null, "journal-ref": null, "doi": null, "report-no": "Computation Institute, University of Chicago, Technical Report\n  CI-TR-7-0811", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report has two objectives. First, we describe a set of the production\ndistributed infrastructures currently available, so that the reader has a basic\nunderstanding of them. This includes explaining why each infrastructure was\ncreated and made available and how it has succeeded and failed. The set is not\ncomplete, but we believe it is representative.\n  Second, we describe the infrastructures in terms of their use, which is a\ncombination of how they were designed to be used and how users have found ways\nto use them. Applications are often designed and created with specific\ninfrastructures in mind, with both an appreciation of the existing capabilities\nprovided by those infrastructures and an anticipation of their future\ncapabilities. Here, the infrastructures we discuss were often designed and\ncreated with specific applications in mind, or at least specific types of\napplications. The reader should understand how the interplay between the\ninfrastructure providers and the users leads to such usages, which we call\nusage modalities. These usage modalities are really abstractions that exist\nbetween the infrastructures and the applications; they influence the\ninfrastructures by representing the applications, and they influence the ap-\nplications by representing the infrastructures.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2012 18:00:09 GMT"}], "update_date": "2012-08-14", "authors_parsed": [["Katz", "Daniel S.", ""], ["Jha", "Shantenu", ""], ["Parashar", "Manish", ""], ["Rana", "Omer", ""], ["Weissman", "Jon", ""]]}, {"id": "1208.2654", "submitter": "Jan Hidders", "authors": "Jacek Sroka and Jan Hidders", "title": "On Generating *-Sound Nets with Substitution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a method for hierarchically generating sound workflow nets by\nsubstitution of nets with multiple inputs and outputs. We show that this method\nis correct and generalizes the class of nets generated by other hierarchical\napproaches. The method involves a new notion of soundness which is preserved by\nthe generalized type of substitution that is presented in this paper. We show\nthat this notion is better suited than *-soundness for use with the presented\ntype of generalized substitution, since {*}-soundness is not preserved by it.\nIt is moreover shown that it is in some sense the optimal notion of soundness\nfor the purpose of generating sound nets by the presented type of substitution.\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2012 18:19:36 GMT"}, {"version": "v2", "created": "Fri, 24 May 2013 10:57:29 GMT"}, {"version": "v3", "created": "Wed, 28 Aug 2013 20:49:04 GMT"}, {"version": "v4", "created": "Tue, 1 Oct 2013 14:57:49 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Sroka", "Jacek", ""], ["Hidders", "Jan", ""]]}, {"id": "1208.2675", "submitter": "Gerald Paul", "authors": "Gerald Paul", "title": "A GPU implementation of the Simulated Annealing Heuristic for the\n  Quadratic Assignment Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The quadratic assignment problem (QAP) is one of the most difficult\ncombinatorial optimization problems. An effective heuristic for obtaining\napproximate solutions to the QAP is simulated annealing (SA). Here we describe\nan SA implementation for the QAP which runs on a graphics processing unit\n(GPU). GPUs are composed of low cost commodity graphics chips which in\ncombination provide a powerful platform for general purpose parallel computing.\nFor SA runs with large numbers of iterations, we find performance 50-100 times\nbetter than that of a recent non-parallel but very efficient implementation of\nSA for the QAP\n", "versions": [{"version": "v1", "created": "Mon, 13 Aug 2012 19:30:44 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Paul", "Gerald", ""]]}, {"id": "1208.2849", "submitter": "Venkatesan Chakaravarthy", "authors": "Venkatesan T. Chakaravarthy and Naga Praveen Kumar Katta and Monu\n  Kedia and Ramakrishnan Rajamony and Aruna Ramanan and Yogish Sabharwal", "title": "Mapping Strategies for the PERCS Architecture", "comments": "Full version of paper at HiPC 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The PERCS system was designed by IBM in response to a DARPA challenge that\ncalled for a high-productivity high-performance computing system. The IBM PERCS\narchitecture is a two level direct network having low diameter and high\nbisection bandwidth. Mapping and routing strategies play an important role in\nthe performance of applications on such a topology. In this paper, we study\nmapping strategies for PERCS architecture, that examine how to map tasks of a\ngiven job on to the physical processing nodes. We develop and present\nfundamental principles for designing good mapping strategies that minimize\ncongestion. This is achieved via a theoretical study of some common\ncommunication patterns under both direct and indirect routing mechanisms\nsupported by the architecture.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2012 12:53:24 GMT"}], "update_date": "2012-08-15", "authors_parsed": [["Chakaravarthy", "Venkatesan T.", ""], ["Katta", "Naga Praveen Kumar", ""], ["Kedia", "Monu", ""], ["Rajamony", "Ramakrishnan", ""], ["Ramanan", "Aruna", ""], ["Sabharwal", "Yogish", ""]]}, {"id": "1208.2908", "submitter": "Georg Hager", "authors": "Georg Hager, Jan Treibig, Johannes Habich and Gerhard Wellein", "title": "Exploring performance and power properties of modern multicore chips via\n  simple machine models", "comments": "23 pages, 10 figures. Typos corrected, DOI added", "journal-ref": null, "doi": "10.1002/cpe.3180", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern multicore chips show complex behavior with respect to performance and\npower. Starting with the Intel Sandy Bridge processor, it has become possible\nto directly measure the power dissipation of a CPU chip and correlate this data\nwith the performance properties of the running code. Going beyond a simple\nbottleneck analysis, we employ the recently published Execution-Cache-Memory\n(ECM) model to describe the single- and multi-core performance of streaming\nkernels. The model refines the well-known roofline model, since it can predict\nthe scaling and the saturation behavior of bandwidth-limited loop kernels on a\nmulticore chip. The saturation point is especially relevant for considerations\nof energy consumption. From power dissipation measurements of benchmark\nprograms with vastly different requirements to the hardware, we derive a\nsimple, phenomenological power model for the Sandy Bridge processor. Together\nwith the ECM model, we are able to explain many peculiarities in the\nperformance and power behavior of multicore processors, and derive guidelines\nfor energy-efficient execution of parallel programs. Finally, we show that the\nECM and power models can be successfully used to describe the scaling and power\nbehavior of a lattice-Boltzmann flow solver code.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2012 15:51:43 GMT"}, {"version": "v2", "created": "Thu, 16 Aug 2012 19:12:39 GMT"}, {"version": "v3", "created": "Tue, 10 Sep 2013 10:17:43 GMT"}, {"version": "v4", "created": "Wed, 19 Mar 2014 13:55:47 GMT"}], "update_date": "2014-03-20", "authors_parsed": [["Hager", "Georg", ""], ["Treibig", "Jan", ""], ["Habich", "Johannes", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1208.2936", "submitter": "Vitaly Skachek", "authors": "Vincent Gripon, Vitaly Skachek, and Michael Rabbat", "title": "Forwarding Without Repeating: Efficient Rumor Spreading in\n  Bounded-Degree Graphs", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a gossip protocol called forwarding without repeating (FWR). The\nobjective is to spread multiple rumors over a graph as efficiently as possible.\nFWR accomplishes this by having nodes record which messages they have forwarded\nto each neighbor, so that each message is forwarded at most once to each\nneighbor. We prove that FWR spreads a rumor over a strongly connected digraph,\nwith high probability, in time which is within a constant factor of optimal for\ndigraphs with bounded out-degree. Moreover, on digraphs with bounded out-degree\nand bounded number of rumors, the number of transmissions required by FWR is\narbitrarily better than that of existing approaches. Specifically, FWR requires\nO(n) messages on bounded-degree graphs with n nodes, whereas classical\nforwarding and an approach based on network coding both require {\\omega}(n)\nmessages. Our results are obtained using combinatorial and probabilistic\narguments. Notably, they do not depend on expansion properties of the\nunderlying graph, and consequently the message complexity of FWR is arbitrarily\nbetter than classical forwarding even on constant-degree expander graphs, as n\n\\rightarrow \\infty. In resource-constrained applications, where each\ntransmission consumes battery power and bandwidth, our results suggest that\nusing a small amount of memory at each node leads to a significant savings.\n", "versions": [{"version": "v1", "created": "Tue, 14 Aug 2012 18:16:36 GMT"}], "update_date": "2012-08-15", "authors_parsed": [["Gripon", "Vincent", ""], ["Skachek", "Vitaly", ""], ["Rabbat", "Michael", ""]]}, {"id": "1208.3047", "submitter": "Edi Winarko", "authors": "Arif Nurwidyantoro and Edi Winarko", "title": "Parallelization of Maximum Entropy POS Tagging for Bahasa Indonesia with\n  MapReduce", "comments": "International Journal of Computer Science Issues (IJCSI), Vol. 9,\n  Issue 4, No 2, July 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, MapReduce programming model is used to parallelize training\nand tagging proceess in Maximum Entropy part of speech tagging for Bahasa\nIndonesia. In training process, MapReduce model is implemented dictionary,\ntagtoken, and feature creation. In tagging process, MapReduce is implemented to\ntag lines of document in parallel. The training experiments showed that total\ntraining time using MapReduce is faster, but its result reading time inside the\nprocess slow down the total training time. The tagging experiments using\ndifferent number of map and reduce process showed that MapReduce implementation\ncould speedup the tagging process. The fastest tagging result is showed by\ntagging process using 1,000,000 word corpus and 30 map process.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2012 07:16:14 GMT"}], "update_date": "2012-08-16", "authors_parsed": [["Nurwidyantoro", "Arif", ""], ["Winarko", "Edi", ""]]}, {"id": "1208.3071", "submitter": "Anisur Molla Rahaman", "authors": "Atish Das Sarma, Anisur Rahaman Molla, Gopal Pandurangan, Eli Upfal", "title": "Fast Distributed PageRank Computation", "comments": "14 pages", "journal-ref": "Theoretical Computer Science, Volume 561, Pages 113-121, 2015", "doi": "10.1016/j.tcs.2014.04.003", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade, PageRank has gained importance in a wide range of\napplications and domains, ever since it first proved to be effective in\ndetermining node importance in large graphs (and was a pioneering idea behind\nGoogle's search engine). In distributed computing alone, PageRank vector, or\nmore generally random walk based quantities have been used for several\ndifferent applications ranging from determining important nodes, load\nbalancing, search, and identifying connectivity structures. Surprisingly,\nhowever, there has been little work towards designing provably efficient\nfully-distributed algorithms for computing PageRank. The difficulty is that\ntraditional matrix-vector multiplication style iterative methods may not always\nadapt well to the distributed setting owing to communication bandwidth\nrestrictions and convergence rates.\n  In this paper, we present fast random walk-based distributed algorithms for\ncomputing PageRanks in general graphs and prove strong bounds on the round\ncomplexity. We first present a distributed algorithm that takes $O\\big(\\log\nn/\\eps \\big)$ rounds with high probability on any graph (directed or\nundirected), where $n$ is the network size and $\\eps$ is the reset probability\nused in the PageRank computation (typically $\\eps$ is a fixed constant). We\nthen present a faster algorithm that takes $O\\big(\\sqrt{\\log n}/\\eps \\big)$\nrounds in undirected graphs. Both of the above algorithms are scalable, as each\nnode sends only small ($\\polylog n$) number of bits over each edge per round.\nTo the best of our knowledge, these are the first fully distributed algorithms\nfor computing PageRank vector with provably efficient running time.\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2012 09:36:02 GMT"}, {"version": "v2", "created": "Wed, 25 Nov 2015 10:55:10 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Sarma", "Atish Das", ""], ["Molla", "Anisur Rahaman", ""], ["Pandurangan", "Gopal", ""], ["Upfal", "Eli", ""]]}, {"id": "1208.3773", "submitter": "Francisco Carvalho-Junior Dr", "authors": "Francisco Heron de Carvalho Junior, Rafael Dueire Lins", "title": "Haskell_#: Coordinating Functional Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Haskell#, a coordination language targeted at the\nefficient implementation of parallel scientific applications on loosely coupled\nparallel architectures, using the functional language Haskell. Examples of\napplications, their implementation details and performance figures are\npresented.\n", "versions": [{"version": "v1", "created": "Sat, 18 Aug 2012 18:29:00 GMT"}], "update_date": "2012-08-21", "authors_parsed": [["Junior", "Francisco Heron de Carvalho", ""], ["Lins", "Rafael Dueire", ""]]}, {"id": "1208.3836", "submitter": "Vishnuvardhan Mannava M.E", "authors": "Vishnuvardhan Mannava and T. Ramesh", "title": "Composite Design Pattern for Feature Oriented Service Injection and\n  Composition of Web Services for Distributed Computing Systems with Service\n  Oriented Architecture", "comments": "12 pages, 7 figures, International Journal of Web & Semantic\n  Technology (IJWesT)", "journal-ref": "Volume 3, Number 3, Page Number 73--84, July 2012", "doi": "10.5121/ijwest", "report-no": null, "categories": "cs.SE cs.DC cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  With the advent of newly introduced programming models like Feature-Oriented\nProgramming (FOP), we feel that it will be more flexible to include the new\nservice invocation function into the service providing server as a Feature\nModule for the self-adaptive distributed systems. A composite design patterns\nshows a synergy that makes the composition more than just the sum of its parts\nwhich leads to ready-made software architectures. In this paper we describe the\namalgamation of Visitor and Case-Based Reasoning Design Patterns to the\ndevelopment of the Service Invocation and Web Services Composition through SOA\nwith the help of JWS technologies and FOP. As far as we know, there are no\nstudies on composition of design patterns for self adaptive distributed\ncomputing domain. We have provided with the sample code developed for the\napplication and simple UML class diagram is used to describe the architecture.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2012 13:57:10 GMT"}], "update_date": "2012-08-21", "authors_parsed": [["Mannava", "Vishnuvardhan", ""], ["Ramesh", "T.", ""]]}, {"id": "1208.3882", "submitter": "Francisco Carvalho-Junior Dr", "authors": "Francisco Heron de Carvalho-Junior, Rafael Dueire Lins", "title": "Coordination Level Modeling and Analysis of Parallel Programs using\n  Petri Nets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last fifteen years, the high performance computing (HPC) community has\nclaimed for parallel programming environments that reconciles generality,\nhigher level of abstraction, portability, and efficiency for distributed-memory\nparallel computing platforms. The Hash component model appears as an\nalternative for addressing HPC community claims for fitting these requirements.\nThis paper presents foundations that will enable a parallel programming\nenvironment based on the Hash model to address the problems of \"debugging\",\nperformance evaluation and verification of formal properties of parallel\nprogram by means of a powerful, simple, and widely adopted formalism: Petri\nnets.\n", "versions": [{"version": "v1", "created": "Sun, 19 Aug 2012 19:31:40 GMT"}], "update_date": "2012-08-21", "authors_parsed": [["de Carvalho-Junior", "Francisco Heron", ""], ["Lins", "Rafael Dueire", ""]]}, {"id": "1208.3933", "submitter": "Imen Chakroun", "authors": "Melab Nouredine (LIFL), Imen Chakroun (INRIA Lille - Nord Europe),\n  Mezmaz Mohand, Daniel Tuyttens", "title": "A GPU-accelerated Branch-and-Bound Algorithm for the Flow-Shop\n  Scheduling Problem", "comments": null, "journal-ref": "14th IEEE International Conference on Cluster Computing,\n  Cluster'12 (2012)", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Branch-and-Bound (B&B) algorithms are time intensive tree-based exploration\nmethods for solving to optimality combinatorial optimization problems. In this\npaper, we investigate the use of GPU computing as a major complementary way to\nspeed up those methods. The focus is put on the bounding mechanism of B&B\nalgorithms, which is the most time consuming part of their exploration process.\nWe propose a parallel B&B algorithm based on a GPU-accelerated bounding model.\nThe proposed approach concentrate on optimizing data access management to\nfurther improve the performance of the bounding mechanism which uses large and\nintermediate data sets that do not completely fit in GPU memory. Extensive\nexperiments of the contribution have been carried out on well known FSP\nbenchmarks using an Nvidia Tesla C2050 GPU card. We compared the obtained\nperformances to a single and a multithreaded CPU-based execution. Accelerations\nup to x100 are achieved for large problem instances.\n", "versions": [{"version": "v1", "created": "Mon, 20 Aug 2012 08:06:58 GMT"}], "update_date": "2012-08-21", "authors_parsed": [["Nouredine", "Melab", "", "LIFL"], ["Chakroun", "Imen", "", "INRIA Lille - Nord Europe"], ["Mohand", "Mezmaz", ""], ["Tuyttens", "Daniel", ""]]}, {"id": "1208.4327", "submitter": "EPTCS", "authors": "Natallia Kokash, Ant\\'onio Ravara", "title": "Proceedings 11th International Workshop on Foundations of Coordination\n  Languages and Self Adaptation", "comments": null, "journal-ref": "EPTCS 91, 2012", "doi": "10.4204/EPTCS.91", "report-no": null, "categories": "cs.DC cs.LO cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Welcome to the proceedings of FOCLASA 2012, the 11th International Workshop\non the Foundations of Coordination Languages and Self-Adaptation. FOCLASA 2012\nwas held in Newcastle upon Tyne, UK, on September 8, 2012 as a satellite event\nof CONCUR 2012, the 23rd International Conference on Concurrency Theory. The\nworkshop provides a venue where researchers and practitioners could meet,\nexchange ideas, identify common problems, determine some of the key and\nfundamental issues related to coordination languages and self adaptation, and\nexplore together and disseminate solutions. Indeed, a number of hot research\ntopics are currently sharing the common problem of combining concurrent,\ndistributed, mobile and heterogeneous components, trying to harness the\nintrinsic complexity of the resulting systems. Computation nowadays is becoming\ninherently concurrent, either because of characteristics of the hardware (with\nmulticore processors becoming omnipresent) or due to the ubiquitous presence of\ndistributed systems (incarnated in the Internet). Computational systems are\ntherefore typically distributed, concurrent, mobile, and often involve\ncomposition of heterogeneous components. To specify and reason about such\nsystems and go beyond the functional correctness proofs, e.g., by supporting\nreusability and improving maintainability, approaches such as coordination\nlanguages and self adaptation are recognised as fundamental.\n  This year, we received 13 submissions involving 35 authors from 10 different\ncountries. Papers underwent a rigorous review process, and all accepted papers\nreceived 3 review reports. After the review process, the international Program\nCommittee of FOCLASA 2012 decided to select 8 papers for presentation during\nthe workshop and inclusion in these proceedings. These papers tackle different\nissues that are currently central to our community, self-adaptation and\ncoordination, processes and coordination, and type systems. The workshop\nfeatures an invited talk by Sebastian Uchitel from Imperial College London\n(UK).\n", "versions": [{"version": "v1", "created": "Wed, 15 Aug 2012 15:38:34 GMT"}], "update_date": "2012-08-22", "authors_parsed": [["Kokash", "Natallia", ""], ["Ravara", "Ant\u00f3nio", ""]]}, {"id": "1208.4484", "submitter": "Sruti  Gan Chaudhuri SGC", "authors": "Sruti Gan Chaudhuri and Krishnendu Mukhopadhyaya", "title": "Leader Election and Gathering for Asynchronous Transparent Fat Robots\n  without Chirality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a distributed algorithm which deterministically gathers n\n(n > 4) asynchronous, fat robots. The robots are assumed to be transparent and\nthey have full visibility. The robots are initially considered to be\nstationary. A robot is visible in its motion. The robots do not store past\nactions. They are anonymous and can not be distinguished by their appearances\nand do not have common coordinate system or chirality. The robots do not\ncommunicate through message passing. In the proposed gathering algorithm one\nrobot moves at a time towards its destination. The robot which moves, is\nselected in such a way that, it will be the only robot eligible to move, until\nit reaches its destination. In case of a tie, this paper proposes a leader\nelection algorithm which produces an ordering of the robots and the first robot\nin the ordering becomes the leader. The ordering is unique in the sense that,\neach robot, characterized by its location, agrees on the same ordering. We show\nthat if a set of robots can be ordered then they can gather deterministically.\nThe paper also characterizes the cases, where ordering is not possible. This\npaper also presents an important fact that, if leader election is possible then\ngathering pattern formation is possible even with no chirality.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2012 12:10:15 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Chaudhuri", "Sruti Gan", ""], ["Mukhopadhyaya", "Krishnendu", ""]]}, {"id": "1208.4572", "submitter": "Raphael Poss", "authors": "Raphael Poss", "title": "SL: a \"quick and dirty\" but working intermediate language for SVP\n  systems", "comments": "22 pages, 3 figures, 18 listings, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CSA group at the University of Amsterdam has developed SVP, a framework\nto manage and program many-core and hardware multithreaded processors. In this\narticle, we introduce the intermediate language SL, a common vehicle to program\nSVP platforms. SL is designed as an extension to the standard C language (ISO\nC99/C11). It includes primitive constructs to bulk create threads, bulk\nsynchronize on termination of threads, and communicate using word-sized\ndataflow channels between threads. It is intended for use as target language\nfor higher-level parallelizing compilers. SL is a research vehicle; as of this\nwriting, it is the only interface language to program a main SVP platform, the\nnew Microgrid chip architecture. This article provides an overview of the\nlanguage, to complement a detailed specification available separately.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2012 18:49:33 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Poss", "Raphael", ""]]}, {"id": "1208.4632", "submitter": "EPTCS", "authors": "Minas Charalambides (University of Illinois at Urbana-Champaign),\n  Peter Dinges (University of Illinois at Urbana-Champaign), Gul Agha\n  (University of Illinois at Urbana-Champaign)", "title": "Parameterized Concurrent Multi-Party Session Types", "comments": "In Proceedings FOCLASA 2012, arXiv:1208.4327", "journal-ref": "EPTCS 91, 2012, pp. 16-30", "doi": "10.4204/EPTCS.91.2", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Session types have been proposed as a means of statically verifying\nimplementations of communication protocols. Although prior work has been\nsuccessful in verifying some classes of protocols, it does not cope well with\nparameterized, multi-actor scenarios with inherent asynchrony. For example, the\nsliding window protocol is inexpressible in previously proposed session type\nsystems. This paper describes System-A, a new typing language which overcomes\nmany of the expressiveness limitations of prior work. System-A explicitly\nsupports asynchrony and parallelism, as well as multiple forms of\nparameterization. We define System-A and show how it can be used for the static\nverification of a large class of asynchronous communication protocols.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2012 21:58:46 GMT"}], "update_date": "2012-08-24", "authors_parsed": [["Charalambides", "Minas", "", "University of Illinois at Urbana-Champaign"], ["Dinges", "Peter", "", "University of Illinois at Urbana-Champaign"], ["Agha", "Gul", "", "University of Illinois at Urbana-Champaign"]]}, {"id": "1208.4634", "submitter": "EPTCS", "authors": "Gabriel Ciobanu (Romanian Academy, Institute of Computer Science),\n  Ross Horne (Romanian Academy, Institute of Computer Science)", "title": "A Provenance Tracking Model for Data Updates", "comments": "In Proceedings FOCLASA 2012, arXiv:1208.4327", "journal-ref": "EPTCS 91, 2012, pp. 31-44", "doi": "10.4204/EPTCS.91.3", "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For data-centric systems, provenance tracking is particularly important when\nthe system is open and decentralised, such as the Web of Linked Data. In this\npaper, a concise but expressive calculus which models data updates is\npresented. The calculus is used to provide an operational semantics for a\nsystem where data and updates interact concurrently. The operational semantics\nof the calculus also tracks the provenance of data with respect to updates.\nThis provides a new formal semantics extending provenance diagrams which takes\ninto account the execution of processes in a concurrent setting. Moreover, a\nsound and complete model for the calculus based on ideals of series-parallel\nDAGs is provided. The notion of provenance introduced can be used as a\nsubjective indicator of the quality of data in concurrent interacting systems.\n", "versions": [{"version": "v1", "created": "Wed, 22 Aug 2012 22:00:51 GMT"}], "update_date": "2012-08-24", "authors_parsed": [["Ciobanu", "Gabriel", "", "Romanian Academy, Institute of Computer Science"], ["Horne", "Ross", "", "Romanian Academy, Institute of Computer Science"]]}, {"id": "1208.4867", "submitter": "Lewis Tseng", "authors": "Lewis Tseng and Nitin H. Vaidya", "title": "Parameter-independent Iterative Approximate Byzantine Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we explore iterative approximate Byzantine consensus algorithms\nthat do not make explicit use of the global parameter of the graph, i.e., the\nupper-bound on the number of faults, f.\n", "versions": [{"version": "v1", "created": "Thu, 23 Aug 2012 21:44:08 GMT"}], "update_date": "2012-08-27", "authors_parsed": [["Tseng", "Lewis", ""], ["Vaidya", "Nitin H.", ""]]}, {"id": "1208.4895", "submitter": "Michael Rabbat", "authors": "Wu Shaochuan and Michael G. Rabbat", "title": "Broadcast Gossip Algorithms for Consensus on Strongly Connected Digraphs", "comments": "30 pages, submitted", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a general framework for broadcast gossip algorithms which use\ncompanion variables to solve the average consensus problem. Each node maintains\nan initial state and a companion variable. Iterative updates are performed\nasynchronously whereby one random node broadcasts its current state and\ncompanion variable and all other nodes receiving the broadcast update their\nstate and companion variable. We provide conditions under which this scheme is\nguaranteed to converge to a consensus solution, where all nodes have the same\nlimiting values, on any strongly connected directed graph. Under stronger\nconditions, which are reasonable when the underlying communication graph is\nundirected, we guarantee that the consensus value is equal to the average, both\nin expectation and in the mean-squared sense. Our analysis uses tools from\nnon-negative matrix theory and perturbation theory. The perturbation results\nrely on a parameter being sufficiently small. We characterize the allowable\nupper bound as well as the optimal setting for the perturbation parameter as a\nfunction of the network topology, and this allows us to characterize the\nworst-case rate of convergence. Simulations illustrate that, in comparison to\nexisting broadcast gossip algorithms, the approaches proposed in this paper\nhave the advantage that they simultaneously can be guaranteed to converge to\nthe average consensus and they converge in a small number of broadcasts.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2012 02:39:20 GMT"}, {"version": "v2", "created": "Fri, 31 Aug 2012 17:25:09 GMT"}], "update_date": "2012-09-03", "authors_parsed": [["Shaochuan", "Wu", ""], ["Rabbat", "Michael G.", ""]]}, {"id": "1208.4909", "submitter": "Yelena Yuditsky", "authors": "Shlomi Dolev, Juan Garay, Niv Gilboa, Vladimir Kolesnikov, and Yelena\n  Yuditsky", "title": "Efficient Private Distributed Computation on Unbounded Input Streams", "comments": "18 pages, 2 figures. A brief announcement will be presented in DISC\n  2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the problem of swarm computing, $n$ agents wish to securely and\ndistributively perform a computation on common inputs, in such a way that even\nif the entire memory contents of some of them are exposed, no information is\nrevealed about the state of the computation. Recently, Dolev, Garay, Gilboa and\nKolesnikov [ICS 2011] considered this problem in the setting of\ninformation-theoretic security, showing how to perform such computations on\ninput streams of unbounded length. The cost of their solution, however, is\nexponential in the size of the Finite State Automaton (FSA) computing the\nfunction.\n  In this work we are interested in efficient computation in the above model,\nat the expense of minimal additional assumptions. Relying on the existence of\none-way functions, we show how to process a priori unbounded inputs (but of\ncourse, polynomial in the security parameter) at a cost linear in $m$, the\nnumber of FSA states. In particular, our algorithms achieve the following:\n  * In the case of $(n,n)$-reconstruction (i.e. in which all $n$ agents\nparticipate in reconstruction of the distributed computation) and at most $n-1$\nagents are corrupted, the agent storage, the time required to process each\ninput symbol and the time complexity for reconstruction are all $O(mn)$.\n  * In the case of $(t+1,n)$-reconstruction (where only $t+1$ agents take part\nin the reconstruction) and at most $t$ agents are corrupted, the agents'\nstorage and time required to process each input symbol are $O(m{n-1 \\choose\nt-1})$. The complexity of reconstruction is $O(m(t+1))$.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2012 06:38:35 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Dolev", "Shlomi", ""], ["Garay", "Juan", ""], ["Gilboa", "Niv", ""], ["Kolesnikov", "Vladimir", ""], ["Yuditsky", "Yelena", ""]]}, {"id": "1208.5075", "submitter": "Lewis Tseng", "authors": "Lewis Tseng and Nitin Vaidya", "title": "Exact Byzantine Consensus in Directed Graphs", "comments": "Revised on February 18, 2014 to make major improvements to the\n  presentation and related work. Revised September 4, 2012 to add Section 8 on\n  example networks. Revised October 10, 2012 to make minor improvements to the\n  presentation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a synchronous point-to-point network of n nodes connected by\ndirected links, wherein each node has a binary input. This paper proves a tight\nnecessary and sufficient condition on the underlying communication topology for\nachieving Byzantine consensus among these nodes in the presence of up to f\nByzantine faults. We derive a necessary condition, and then we provide a\nconstructive proof of sufficiency by presenting a Byzantine consensus algorithm\nfor directed graphs that satisfy the necessary condition.\n  Prior work has developed analogous necessary and sufficient conditions for\nundirected graphs. It is known that, for undirected graphs, the following two\nconditions are together necessary and sufficient [8, 2, 6]: (i) n ? 3f + 1, and\n(ii) network connectivity greater than 2f. However, these conditions are not\nadequate to completely characterize Byzantine consensus in directed graphs.\n", "versions": [{"version": "v1", "created": "Fri, 24 Aug 2012 22:17:23 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2012 16:06:42 GMT"}, {"version": "v3", "created": "Wed, 10 Oct 2012 20:49:26 GMT"}, {"version": "v4", "created": "Wed, 19 Feb 2014 23:00:32 GMT"}], "update_date": "2014-02-21", "authors_parsed": [["Tseng", "Lewis", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1208.5542", "submitter": "Huiwei Lv", "authors": "Huiwei Lv, Guangming Tan, Mingyu Chen, Ninghui Sun", "title": "Compression and Sieve: Reducing Communication in Parallel Breadth First\n  Search on Distributed Memory Systems", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For parallel breadth first search (BFS) algorithm on large-scale distributed\nmemory systems, communication often costs significantly more than arithmetic\nand limits the scalability of the algorithm. In this paper we sufficiently\nreduce the communication cost in distributed BFS by compressing and sieving the\nmessages. First, we leverage a bitmap compression algorithm to reduce the size\nof messages before communication. Second, we propose a novel distributed\ndirectory algorithm, cross directory, to sieve the redundant data in messages.\nExperiments on a 6,144-core SMP cluster show our algorithm outperforms the\nbaseline implementation in Graph500 by 2.2 times, reduces its communication\ntime by 79.0%, and achieves a performance rate of 12.1 GTEPS (billion edge\nvisits per second)\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2012 02:59:38 GMT"}], "update_date": "2012-08-29", "authors_parsed": [["Lv", "Huiwei", ""], ["Tan", "Guangming", ""], ["Chen", "Mingyu", ""], ["Sun", "Ninghui", ""]]}, {"id": "1208.5620", "submitter": "Omri Liba", "authors": "Shlomi Dolev and Omri Liba and Elad M. Schiller", "title": "Self-Stabilizing Byzantine Resilient Topology Discovery and Message\n  Delivery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional Byzantine resilient algorithms use 2f+1 vertex disjoint paths to\nensure message delivery in the presence of up to f Byzantine nodes. The\nquestion of how these paths are identified is related to the fundamental\nproblem of topology discovery. Distributed algorithms for topology discovery\ncope with a never ending task, dealing with frequent changes in the network\ntopology and unpredictable transient faults. Therefore, algorithms for topology\ndiscovery should be self-stabilizing to ensure convergence of the topology\ninformation following any such unpredictable sequence of events. We present the\nfirst such algorithm that can cope with Byzantine nodes. Starting in an\narbitrary global state, and in the presence of f Byzantine nodes, each node is\neventually aware of all the other non-Byzantine nodes and their connecting\ncommunication links. Using the topology information, nodes can, for example,\nroute messages across the network and deliver messages from one end user to\nanother. We present the first deterministic, cryptographicassumptions- free,\nself-stabilizing, Byzantine-resilient algorithms for network topology discovery\nand end-to-end message delivery. We also consider the task of r-neighborhood\ndiscovery for the case in which r and the degree of nodes are bounded by\nconstants. The use of r-neighborhood discovery facilitates polynomial time,\ncommunication and space solutions for the above tasks. The obtained algorithms\ncan be used to authenticate parties, in particular during the establishment of\nprivate secrets, thus forming public key schemes that are resistant to\nman-in-the-middle attacks of the compromised Byzantine nodes. A polynomial and\nefficient end-to-end algorithm that is based on the established private secrets\ncan be employed in between periodical re-establishments of the secrets.\n", "versions": [{"version": "v1", "created": "Tue, 28 Aug 2012 11:03:07 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2012 08:25:00 GMT"}, {"version": "v3", "created": "Wed, 30 Jan 2013 07:25:41 GMT"}], "update_date": "2013-01-31", "authors_parsed": [["Dolev", "Shlomi", ""], ["Liba", "Omri", ""], ["Schiller", "Elad M.", ""]]}, {"id": "1208.5913", "submitter": "Simon Kramer", "authors": "Simon Kramer", "title": "Logic of Negation-Complete Interactive Proofs (Formal Theory of\n  Epistemic Deciders)", "comments": "Expanded Introduction. Added Footnote 4. Corrected Corollary 3 and 4.\n  Continuation of arXiv:1208.1842", "journal-ref": "Electronic Notes in Theoretical Computer Science, Volume 300, 21\n  January 2014, Pages 47-70", "doi": "10.1016/j.entcs.2013.12.011", "report-no": null, "categories": "math.LO cs.CR cs.DC cs.LO cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We produce a decidable classical normal modal logic of internalised\nnegation-complete and thus disjunctive non-monotonic interactive proofs (LDiiP)\nfrom an existing logical counterpart of non-monotonic or instant interactive\nproofs (LiiP). LDiiP internalises agent-centric proof theories that are\nnegation-complete (maximal) and consistent (and hence strictly weaker than, for\nexample, Peano Arithmetic) and enjoy the disjunction property (like\nIntuitionistic Logic). In other words, internalised proof theories are\nultrafilters and all internalised proof goals are definite in the sense of\nbeing either provable or disprovable to an agent by means of disjunctive\ninternalised proofs (thus also called epistemic deciders). Still, LDiiP itself\nis classical (monotonic, non-constructive), negation-incomplete, and does not\nhave the disjunction property. The price to pay for the negation completeness\nof our interactive proofs is their non-monotonicity and non-communality (for\nsingleton agent communities only). As a normal modal logic, LDiiP enjoys a\nstandard Kripke-semantics, which we justify by invoking the Axiom of Choice on\nLiiP's and then construct in terms of a concrete oracle-computable function.\nLDiiP's agent-centric internalised notion of proof can also be viewed as a\nnegation-complete disjunctive explicit refinement of standard KD45-belief, and\nyields a disjunctive but negation-incomplete explicit refinement of\nS4-provability.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2012 13:41:31 GMT"}, {"version": "v2", "created": "Fri, 30 Nov 2012 09:35:22 GMT"}, {"version": "v3", "created": "Wed, 29 May 2013 08:55:43 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Kramer", "Simon", ""]]}, {"id": "1208.6051", "submitter": "Bernhard Haeupler", "authors": "Bernhard Haeupler, Fabian Kuhn", "title": "Lower Bounds on Information Dissemination in Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study lower bounds on information dissemination in adversarial dynamic\nnetworks. Initially, k pieces of information (henceforth called tokens) are\ndistributed among n nodes. The tokens need to be broadcast to all nodes through\na synchronous network in which the topology can change arbitrarily from round\nto round provided that some connectivity requirements are satisfied.\n  If the network is guaranteed to be connected in every round and each node can\nbroadcast a single token per round to its neighbors, there is a simple token\ndissemination algorithm that manages to deliver all k tokens to all the nodes\nin O(nk) rounds. Interestingly, in a recent paper, Dutta et al. proved an\nalmost matching Omega(n + nk/log n) lower bound for deterministic\ntoken-forwarding algorithms that are not allowed to combine, split, or change\ntokens in any way. In the present paper, we extend this bound in different\nways.\n  If nodes are allowed to forward b < k tokens instead of only one token in\nevery round, a straight-forward extension of the O(nk) algorithm disseminates\nall k tokens in time O(nk/b). We show that for any randomized token-forwarding\nalgorithm, Omega(n + nk/(b^2 log n log log n)) rounds are necessary. If nodes\ncan only send a single token per round, but we are guaranteed that the network\ngraph is c-vertex connected in every round, we show a lower bound of\nOmega(nk/(c log^{3/2} n)), which almost matches the currently best O(nk/c)\nupper bound. Further, if the network is T-interval connected, a notion that\ncaptures connection stability over time, we prove that Omega(n + nk/(T^2 log\nn)) rounds are needed. The best known upper bound in this case manages to solve\nthe problem in O(n + nk/T) rounds. Finally, we show that even if each node only\nneeds to obtain a delta-fraction of all the tokens for some delta in [0,1],\nOmega(nk delta^3 log n) are still required.\n", "versions": [{"version": "v1", "created": "Wed, 29 Aug 2012 23:12:20 GMT"}], "update_date": "2012-08-31", "authors_parsed": [["Haeupler", "Bernhard", ""], ["Kuhn", "Fabian", ""]]}, {"id": "1208.6125", "submitter": "Bernhard Haeupler", "authors": "Keren Censor-Hillel, Bernhard Haeupler, Nancy Lynch, Muriel M\\'edard", "title": "Bounded-Contention Coding for Wireless Networks in the High SNR Regime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient communication in wireless networks is typically challenged by the\npossibility of interference among several transmitting nodes. Much important\nresearch has been invested in decreasing the number of collisions in order to\nobtain faster algorithms for communication in such networks.\n  This paper proposes a novel approach for wireless communication, which\nembraces collisions rather than avoiding them, over an additive channel. It\nintroduces a coding technique called Bounded-Contention Coding (BCC) that\nallows collisions to be successfully decoded by the receiving nodes into the\noriginal transmissions and whose complexity depends on a bound on the\ncontention among the transmitters.\n  BCC enables deterministic local broadcast in a network with n nodes and at\nmost a transmitters with information of l bits each within O(a log n + al) bits\nof communication with full-duplex radios, and O((a log n + al)(log n)) bits,\nwith high probability, with half-duplex radios. When combined with random\nlinear network coding, BCC gives global broadcast within O((D + a + log n)(a\nlog n + l)) bits, with high probability. This also holds in dynamic networks\nthat can change arbitrarily over time by a worst-case adversary. When no bound\non the contention is given, it is shown how to probabilistically estimate it\nand obtain global broadcast that is adaptive to the true contention in the\nnetwork.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2012 10:08:29 GMT"}], "update_date": "2012-08-31", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Haeupler", "Bernhard", ""], ["Lynch", "Nancy", ""], ["M\u00e9dard", "Muriel", ""]]}, {"id": "1208.6308", "submitter": "Jia Liu", "authors": "Jia Liu, Cathy H. Xia, Ness B. Shroff, and Hanif D. Sherali", "title": "Distributed Cross-Layer Optimization in Wireless Networks: A\n  Second-Order Approach", "comments": "This paper is going to appear in IEEE INFOCOM 2013, Turin, Italy", "journal-ref": null, "doi": "10.1109/INFCOM.2013.6567012", "report-no": null, "categories": "cs.NI cs.DC cs.IT cs.SY math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the rapidly growing scale and heterogeneity of wireless networks, the\ndesign of distributed cross-layer optimization algorithms have received\nsignificant interest from the networking research community. So far, the\nstandard distributed cross-layer approach in the literature is based on\nfirst-order Lagrangian dual decomposition and the subgradient method, which\nsuffers a slow convergence rate. In this paper, we make the first known attempt\nto develop a distributed Newton's method, which is second-order and enjoys a\nquadratic convergence rate. However, due to interference in wireless networks,\nthe Hessian matrix of the cross-layer problem has an non-separable structure.\nAs a result, developing a distributed second-order algorithm is far more\nchallenging than its counterpart for wireline networks. Our main results in\nthis paper are two-fold: i) For a special network setting where all links\nmutually interfere, we derive decentralized closed-form expressions to compute\nthe Hessian inverse; ii) For general wireless networks where the interference\nrelationships are arbitrary, we propose a distributed iterative matrix\nsplitting scheme for the Hessian inverse. These results successfully lead to a\nnew theoretical framework for cross-layer optimization in wireless networks.\nMore importantly, our work contributes to an exciting second-order paradigm\nshift in wireless networks optimization theory.\n", "versions": [{"version": "v1", "created": "Thu, 30 Aug 2012 20:35:26 GMT"}, {"version": "v2", "created": "Tue, 4 Sep 2012 16:08:18 GMT"}, {"version": "v3", "created": "Tue, 11 Sep 2012 18:46:56 GMT"}, {"version": "v4", "created": "Thu, 29 Nov 2012 21:58:20 GMT"}, {"version": "v5", "created": "Sat, 16 Feb 2013 00:11:31 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Liu", "Jia", ""], ["Xia", "Cathy H.", ""], ["Shroff", "Ness B.", ""], ["Sherali", "Hanif D.", ""]]}, {"id": "1208.6406", "submitter": "Sorav Bansal", "authors": "Piyus Kedia, Sorav Bansal, Deepak Deshpande, Sreekanth Iyer", "title": "Building Resilient Cloud Over Unreliable Commodity Infrastructure", "comments": "Oral presentation at IEEE \"Cloud Computing for Emerging Markets\",\n  Oct. 11-12, 2012, Bangalore, India", "journal-ref": null, "doi": "10.1109/CCEM.2012.6354601", "report-no": null, "categories": "cs.OS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Computing has emerged as a successful computing paradigm for\nefficiently utilizing managed compute infrastructure such as high speed\nrack-mounted servers, connected with high speed networking, and reliable\nstorage. Usually such infrastructure is dedicated, physically secured and has\nreliable power and networking infrastructure. However, much of our idle compute\ncapacity is present in unmanaged infrastructure like idle desktops, lab\nmachines, physically distant server machines, and laptops. We present a scheme\nto utilize this idle compute capacity on a best-effort basis and provide high\navailability even in face of failure of individual components or facilities.\n  We run virtual machines on the commodity infrastructure and present a cloud\ninterface to our end users. The primary challenge is to maintain availability\nin the presence of node failures, network failures, and power failures. We run\nmultiple copies of a Virtual Machine (VM) redundantly on geographically\ndispersed physical machines to achieve availability. If one of the running\ncopies of a VM fails, we seamlessly switchover to another running copy. We use\nVirtual Machine Record/Replay capability to implement this redundancy and\nswitchover. In current progress, we have implemented VM Record/Replay for\nuniprocessor machines over Linux/KVM and are currently working on VM\nRecord/Replay on shared-memory multiprocessor machines. We report initial\nexperimental results based on our implementation.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2012 06:53:14 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Kedia", "Piyus", ""], ["Bansal", "Sorav", ""], ["Deshpande", "Deepak", ""], ["Iyer", "Sreekanth", ""]]}, {"id": "1208.6465", "submitter": "Lev Kazakovtsev", "authors": "Lev Kazakovtsev", "title": "Parallel Random Search Algorithm of Constrained Pseudo-Boolean\n  Optimization for Some Distinctive Large-Scale Problems", "comments": "In: Advanced School in High Performance and GRID Computing - Concepts\n  and Applications, 2009 (ICTP, Trieste, Italy); ICTP Open Access Archive,\n  2009, http://eprints.ictp.it/508/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider an approach to the parallelizing of the algorithms\nrealizing the modified probability changigng method with adaptation and partial\nrollback procedure for constrained pseudo-Boolean optimization problems.\nExisting optimization algorithms are adapted for the shared memory and clusters\n(PVM library). The parallel efficiency is estimated for the lagre-scale\nnon-linear pseudo-Boolean optimization problems with linear constraints.\nInitially designed for unconstrained optimization, the probability changing\nmethod (MIVER) allows us finding the approximate solution of different linear\nand non-linear pseudo-Boolean optimization problems with constraints. Although,\nin case of large-scale problems, the computational demands are also very high\nand the precision of the result depends on the time spent. In case of the\nconstrained optimization problem, even the search of any permissibly solution\ncan take very large computational resources. The rapid development of the\nparallel processor systems which are often implemented even in the computer\nsystems designed for home use allows to reduce significantly the time spent to\nfind the acceptable solution with a speed-up close to ideal.\n", "versions": [{"version": "v1", "created": "Fri, 31 Aug 2012 11:32:31 GMT"}], "update_date": "2012-09-03", "authors_parsed": [["Kazakovtsev", "Lev", ""]]}]