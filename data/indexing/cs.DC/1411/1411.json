[{"id": "1411.0168", "submitter": "Jerry Li", "authors": "Rati Gelashvili, Mohsen Ghaffari, Jerry Li, Nir Shavit", "title": "On the Importance of Registers for Computability", "comments": "12 pages, 0 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All consensus hierarchies in the literature assume that we have, in addition\nto copies of a given object, an unbounded number of registers. But why do we\nreally need these registers?\n  This paper considers what would happen if one attempts to solve consensus\nusing various objects but without any registers. We show that under a\nreasonable assumption, objects like queues and stacks cannot emulate the\nmissing registers. We also show that, perhaps surprisingly, initialization,\nshown to have no computational consequences when registers are readily\navailable, is crucial in determining the synchronization power of objects when\nno registers are allowed. Finally, we show that without registers, the number\nof available objects affects the level of consensus that can be solved.\n  Our work thus raises the question of whether consensus hierarchies which\nassume an unbounded number of registers truly capture synchronization power,\nand begins a line of research aimed at better understanding the interaction\nbetween read-write memory and the powerful synchronization operations available\non modern architectures.\n", "versions": [{"version": "v1", "created": "Sat, 1 Nov 2014 21:01:07 GMT"}], "update_date": "2014-11-04", "authors_parsed": [["Gelashvili", "Rati", ""], ["Ghaffari", "Mohsen", ""], ["Li", "Jerry", ""], ["Shavit", "Nir", ""]]}, {"id": "1411.0541", "submitter": "Baharan Mirzasoleiman", "authors": "Baharan Mirzasoleiman, Amin Karbasi, Rik Sarkar, and Andreas Krause", "title": "Distributed Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many large-scale machine learning problems--clustering, non-parametric\nlearning, kernel machines, etc.--require selecting a small yet representative\nsubset from a large dataset. Such problems can often be reduced to maximizing a\nsubmodular set function subject to various constraints. Classical approaches to\nsubmodular optimization require centralized access to the full dataset, which\nis impractical for truly large-scale problems. In this paper, we consider the\nproblem of submodular function maximization in a distributed fashion. We\ndevelop a simple, two-stage protocol GreeDi, that is easily implemented using\nMapReduce style computations. We theoretically analyze our approach, and show\nthat under certain natural conditions, performance close to the centralized\napproach can be achieved. We begin with monotone submodular maximization\nsubject to a cardinality constraint, and then extend this approach to obtain\napproximation guarantees for (not necessarily monotone) submodular maximization\nsubject to more general constraints including matroid or knapsack constraints.\nIn our extensive experiments, we demonstrate the effectiveness of our approach\non several applications, including sparse Gaussian process inference and\nexemplar based clustering on tens of millions of examples using Hadoop.\n", "versions": [{"version": "v1", "created": "Mon, 3 Nov 2014 16:03:05 GMT"}, {"version": "v2", "created": "Mon, 27 Jun 2016 16:32:35 GMT"}], "update_date": "2016-06-28", "authors_parsed": [["Mirzasoleiman", "Baharan", ""], ["Karbasi", "Amin", ""], ["Sarkar", "Rik", ""], ["Krause", "Andreas", ""]]}, {"id": "1411.0912", "submitter": "Blesson Varghese", "authors": "Blesson Varghese, Ozgur Akgun, Ian Miguel, Long Thai and Adam Barker", "title": "Cloud Benchmarking for Performance", "comments": "6 pages, 6th IEEE International Conference on Cloud Computing\n  Technology and Science (IEEE CloudCom) 2014, Singapore", "journal-ref": null, "doi": "10.1109/CloudCom.2014.28", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  How can applications be deployed on the cloud to achieve maximum performance?\nThis question has become significant and challenging with the availability of a\nwide variety of Virtual Machines (VMs) with different performance capabilities\nin the cloud. The above question is addressed by proposing a six step\nbenchmarking methodology in which a user provides a set of four weights that\nindicate how important each of the following groups: memory, processor,\ncomputation and storage are to the application that needs to be executed on the\ncloud. The weights along with cloud benchmarking data are used to generate a\nranking of VMs that can maximise performance of the application. The rankings\nare validated through an empirical analysis using two case study applications;\nthe first is a financial risk application and the second is a molecular\ndynamics simulation, which are both representative of workloads that can\nbenefit from execution on the cloud. Both case studies validate the feasibility\nof the methodology and highlight that maximum performance can be achieved on\nthe cloud by selecting the top ranked VMs produced by the methodology.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 13:57:24 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Varghese", "Blesson", ""], ["Akgun", "Ozgur", ""], ["Miguel", "Ian", ""], ["Thai", "Long", ""], ["Barker", "Adam", ""]]}, {"id": "1411.0948", "submitter": "Abbas Mehrabian", "authors": "Huseyin Acan and Andrea Collevecchio and Abbas Mehrabian and Nick\n  Wormald", "title": "On the push&pull protocol for rumour spreading", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asynchronous push&pull protocol, a randomized distributed algorithm for\nspreading a rumour in a graph $G$, works as follows. Independent Poisson clocks\nof rate 1 are associated with the vertices of $G$. Initially, one vertex of $G$\nknows the rumour. Whenever the clock of a vertex $x$ rings, it calls a random\nneighbour $y$: if $x$ knows the rumour and $y$ does not, then $x$ tells $y$ the\nrumour (a push operation), and if $x$ does not know the rumour and $y$ knows\nit, $y$ tells $x$ the rumour (a pull operation). The average spread time of $G$\nis the expected time it takes for all vertices to know the rumour, and the\nguaranteed spread time of $G$ is the smallest time $t$ such that with\nprobability at least $1-1/n$, after time $t$ all vertices know the rumour. The\nsynchronous variant of this protocol, in which each clock rings precisely at\ntimes $1,2,\\dots$, has been studied extensively. We prove the following results\nfor any $n$-vertex graph: In either version, the average spread time is at most\nlinear even if only the pull operation is used, and the guaranteed spread time\nis within a logarithmic factor of the average spread time, so it is $O(n\\log\nn)$. In the asynchronous version, both the average and guaranteed spread times\nare $\\Omega(\\log n)$. We give examples of graphs illustrating that these bounds\nare best possible up to constant factors. We also prove theoretical\nrelationships between the guaranteed spread times in the two versions. Firstly,\nin all graphs the guaranteed spread time in the asynchronous version is within\nan $O(\\log n)$ factor of that in the synchronous version, and this is tight.\nNext, we find examples of graphs whose asynchronous spread times are\nlogarithmic, but the synchronous versions are polynomially large. Finally, we\nshow for any graph that the ratio of the synchronous spread time to the\nasynchronous spread time is $O(n^{2/3})$.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 15:53:11 GMT"}, {"version": "v2", "created": "Wed, 16 Sep 2015 03:52:26 GMT"}], "update_date": "2015-09-17", "authors_parsed": [["Acan", "Huseyin", ""], ["Collevecchio", "Andrea", ""], ["Mehrabian", "Abbas", ""], ["Wormald", "Nick", ""]]}, {"id": "1411.0968", "submitter": "Sateeshkrishna Dhuli", "authors": "Sateeshkrishna Dhuli, Kumar Gaurav, Y.N.Singh", "title": "Convergence Analysis for Regular Wireless Consensus Networks", "comments": "10 pages, 19 figures", "journal-ref": "IEEE Sensors Journal, 2015, Volume: 15 Issue: 8, Page(s):\n  4522-4531", "doi": "10.1109/JSEN.2015.2420952", "report-no": null, "categories": "cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Average consensus algorithms can be implemented over wireless sensor networks\n(WSN), where global statistics can be computed using communications among\nsensor nodes locally. Simple execution, robustness to global topology changes\ndue to frequent node failures and underlying distributed philosophy has made\nconsensus algorithms more suitable to WSNs. Since these algorithms are\niterative in nature, their performance is characterized by convergence speed.\nWe study the convergence of the average consensus algorithms for WSNs using\nregular graphs. We obtained the analytical expressions for optimal consensus\nand convergence parameters which decides the convergence time for r-nearest\nneighbor cycle and torus networks. We have also derived the generalized\nexpression for optimal consensus and convergence parameters for m-dimensional\nr-nearest neighbor torus networks. The obtained analytical results agree with\nthe simulation results and shown the effect of network dimension, number of\nnodes and transmission radius on convergence time. This work provides the basic\nanalytical tools for managing and controlling the performance of average\nconsensus algorithm in the finite sized practical networks.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 17:07:29 GMT"}, {"version": "v2", "created": "Thu, 22 Sep 2016 09:53:45 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Dhuli", "Sateeshkrishna", ""], ["Gaurav", "Kumar", ""], ["Singh", "Y. N.", ""]]}, {"id": "1411.1001", "submitter": "Rati Gelashvili", "authors": "Dan Alistarh, Rati Gelashvili, Adrian Vladu", "title": "How to Elect a Leader Faster than a Tournament", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of electing a leader from among $n$ contenders is one of the\nfundamental questions in distributed computing. In its simplest formulation,\nthe task is as follows: given $n$ processors, all participants must eventually\nreturn a win or lose indication, such that a single contender may win. Despite\na considerable amount of work on leader election, the following question is\nstill open: can we elect a leader in an asynchronous fault-prone system faster\nthan just running a $\\Theta(\\log n)$-time tournament, against a strong adaptive\nadversary?\n  In this paper, we answer this question in the affirmative, improving on a\ndecades-old upper bound. We introduce two new algorithmic ideas to reduce the\ntime complexity of electing a leader to $O(\\log^* n)$, using $O(n^2)$\npoint-to-point messages. A non-trivial application of our algorithm is a new\nupper bound for the tight renaming problem, assigning $n$ items to the $n$\nparticipants in expected $O(\\log^2 n)$ time and $O(n^2)$ messages. We\ncomplement our results with lower bound of $\\Omega(n^2)$ messages for solving\nthese two problems, closing the question of their message complexity.\n", "versions": [{"version": "v1", "created": "Tue, 4 Nov 2014 18:57:28 GMT"}, {"version": "v2", "created": "Sun, 15 Feb 2015 17:50:51 GMT"}], "update_date": "2015-02-17", "authors_parsed": [["Alistarh", "Dan", ""], ["Gelashvili", "Rati", ""], ["Vladu", "Adrian", ""]]}, {"id": "1411.1215", "submitter": "Blesson Varghese", "authors": "Muhammed Asif Saleem, Blesson Varghese and Adam Barker", "title": "BigExcel: A Web-Based Framework for Exploring Big Data in Social\n  Sciences", "comments": "8 pages", "journal-ref": "Workshop of Big Humanities Data at the IEEE International\n  Conference on Big Data (IEEE BigData) 2014, Washington D. C., USA", "doi": "10.1109/BigData.2014.7004458", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper argues that there are three fundamental challenges that need to be\novercome in order to foster the adoption of big data technologies in\nnon-computer science related disciplines: addressing issues of accessibility of\nsuch technologies for non-computer scientists, supporting the ad hoc\nexploration of large data sets with minimal effort and the availability of\nlightweight web-based frameworks for quick and easy analytics. In this paper,\nwe address the above three challenges through the development of 'BigExcel', a\nthree tier web-based framework for exploring big data to facilitate the\nmanagement of user interactions with large data sets, the construction of\nqueries to explore the data set and the management of the infrastructure. The\nfeasibility of BigExcel is demonstrated through two Yahoo Sandbox datasets. The\nfirst dataset is the Yahoo Buzz Score data set we use for quantitatively\npredicting trending technologies and the second is the Yahoo n-gram corpus we\nuse for qualitatively inferring the coverage of important events. A\ndemonstration of the BigExcel framework and source code is available at\nhttp://bigdata.cs.st-andrews.ac.uk/projects/bigexcel-exploring-big-data-for-social-sciences/.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 10:22:27 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Saleem", "Muhammed Asif", ""], ["Varghese", "Blesson", ""], ["Barker", "Adam", ""]]}, {"id": "1411.1293", "submitter": "Yu-Hang Tang", "authors": "Yu-Hang Tang, Shuhei Kudo, Xin Bian, Zhen Li and George E. Karniadakis", "title": "Multiscale Universal Interface: A Concurrent Framework for Coupling\n  Heterogeneous Solvers", "comments": "The library source code is freely available under the GPLv3 license\n  at http://www.cfm.brown.edu/repo/release/MUI/", "journal-ref": null, "doi": "10.1016/j.jcp.2015.05.004", "report-no": null, "categories": "physics.comp-ph cs.CE cs.DC physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrently coupled numerical simulations using heterogeneous solvers are\npowerful tools for modeling multiscale phenomena. However, major modifications\nto existing codes are often required to enable such simulations, posing\nsignificant difficulties in practice. In this paper we present a C++ library,\ni.e. the Multiscale Universal Interface (MUI), which is capable of facilitating\nthe coupling effort for a wide range of multiscale simulations. The library\nadopts a header-only form with minimal external dependency and hence can be\neasily dropped into existing codes. A data sampler concept is introduced,\ncombined with a hybrid dynamic/static typing mechanism, to create an easily\ncustomizable framework for solver-independent data interpretation. The library\nintegrates MPI MPMD support and an asynchronous communication protocol to\nhandle inter-solver information exchange irrespective of the solvers' own MPI\nawareness. Template metaprogramming is heavily employed to simultaneously\nimprove runtime performance and code flexibility. We validated the library by\nsolving three different multiscale problems, which also serve to demonstrate\nthe flexibility of the framework in handling heterogeneous models and solvers.\nIn the first example, a Couette flow was simulated using two concurrently\ncoupled Smoothed Particle Hydrodynamics (SPH) simulations of different spatial\nresolutions. In the second example, we coupled the deterministic SPH method\nwith the stochastic Dissipative Particle Dynamics (DPD) method to study the\neffect of surface grafting on the hydrodynamics properties on the surface. In\nthe third example, we consider conjugate heat transfer between a solid domain\nand a fluid domain by coupling the particle-based energy-conserving DPD (eDPD)\nmethod with the Finite Element Method (FEM).\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 15:20:18 GMT"}, {"version": "v2", "created": "Sat, 7 Mar 2015 05:28:38 GMT"}], "update_date": "2015-05-18", "authors_parsed": [["Tang", "Yu-Hang", ""], ["Kudo", "Shuhei", ""], ["Bian", "Xin", ""], ["Li", "Zhen", ""], ["Karniadakis", "George E.", ""]]}, {"id": "1411.1319", "submitter": "Avery Miller", "authors": "Avery Miller, Andrzej Pelc", "title": "Election vs. Selection: Two Ways of Finding the Largest Node in a Graph", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding the node with the largest label in a network, modeled as an\nundirected connected graph, is one of the fundamental problems in distributed\ncomputing. This is the way in which $\\textit{leader election}$ is usually\nsolved. We consider two distinct tasks in which the largest-labeled node is\nfound deterministically. In $\\textit{selection}$, this node must output 1 and\nall other nodes must output 0. In $\\textit{election}$, the other nodes must\nadditionally learn the largest label. Our aim is to compare the difficulty of\nthese two tasks executed under stringent running time constraints. The measure\nof difficulty is the amount of information that nodes of the network must\ninitially possess in order to solve the given task in an imposed amount of\ntime. Following the standard framework of $\\textit{algorithms with advice}$,\nthis information (a single binary string) is provided to all nodes at the start\nby an oracle knowing the entire graph. The length of this string is called the\n$\\textit{size of advice}$. Consider the class of $n$-node graphs with any\ndiameter $diam \\leq D$. If time is larger than $diam$, then both tasks can be\nsolved without advice. For the task of $\\textit{election}$, we show that if\ntime is smaller than $diam$, then the optimal size of advice is $\\Theta(\\log\nn)$, and if time is exactly $diam$, then the optimal size of advice is\n$\\Theta(\\log D)$. For the task of $\\textit{selection}$, the situation changes\ndramatically, even within the class of rings. Indeed, for the class of rings,\nwe show that, if time is $O(diam^{\\epsilon})$, for any $\\epsilon <1$, then the\noptimal size of advice is $\\Theta(\\log D)$, and, if time is $\\Theta(diam)$ (and\nat most $diam$) then this optimal size is $\\Theta(\\log \\log D)$.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 16:48:34 GMT"}], "update_date": "2014-11-06", "authors_parsed": [["Miller", "Avery", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1411.1432", "submitter": "Adrian Q.T. Ngo", "authors": "A.Q.T. Ngo, P. Bastian, O. Ippisch", "title": "Numerical solution of steady-state groundwater flow and solute transport\n  problems: Discontinuous Galerkin based methods compared to the Streamline\n  Diffusion approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this study, we consider the simulation of subsurface flow and solute\ntransport processes in the stationary limit. In the convection-dominant case,\nthe numerical solution of the transport problem may exhibit non-physical\ndiffusion and under- and overshoots. For an interior penalty discontinuous\nGalerkin (DG) discretization, we present a $h$-adaptive refinement strategy\nand, alternatively, a new efficient approach for reducing numerical under- and\novershoots using a diffusive $L^2$-projection. Furthermore, we illustrate an\nefficient way of solving the linear system arising from the DG discretization.\nIn $2$-D and $3$-D examples, we compare the DG-based methods to the streamline\ndiffusion approach with respect to computing time and their ability to resolve\nsteep fronts.\n", "versions": [{"version": "v1", "created": "Wed, 5 Nov 2014 22:24:12 GMT"}], "update_date": "2014-11-07", "authors_parsed": [["Ngo", "A. Q. T.", ""], ["Bastian", "P.", ""], ["Ippisch", "O.", ""]]}, {"id": "1411.1460", "submitter": "Oded Green", "authors": "Oded Green and Marat Dukhan and Richard Vuduc", "title": "Branch-Avoiding Graph Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper quantifies the impact of branches and branch mispredictions on the\nsingle-core performance for two classes of graph problems. Specifically, we\nconsider classical algorithms for computing connected components and\nbreadth-first search (BFS). We show that branch mispredictions are costly and\ncan reduce performance by as much as 30%-50%. This insight suggests that one\nshould seek graph algorithms and implementations that avoid branches.\n  As a proof-of-concept, we devise such implementations for both the classic\ntop-down algorithm for BFS and the Shiloach-Vishkin algorithm for connected\ncomponents. We evaluate these implementations on current x86 and ARM-based\nprocessors to show the efficacy of the approach. Our results suggest how both\ncompiler writers and architects might exploit this insight to improve graph\nprocessing systems more broadly and create better systems for such problems.\n", "versions": [{"version": "v1", "created": "Thu, 6 Nov 2014 00:36:24 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Green", "Oded", ""], ["Dukhan", "Marat", ""], ["Vuduc", "Richard", ""]]}, {"id": "1411.1507", "submitter": "Daisuke Ishii", "authors": "Daisuke Ishii, Kazuki Yoshizoe, Toyotaro Suzumura", "title": "Scalable Parallel Numerical CSP Solver", "comments": "The final publication is available at Springer", "journal-ref": null, "doi": "10.1007/978-3-319-10428-7_30", "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a parallel solver for numerical constraint satisfaction problems\n(NCSPs) that can scale on a number of cores. Our proposed method runs worker\nsolvers on the available cores and simultaneously the workers cooperate for the\nsearch space distribution and balancing. In the experiments, we attained up to\n119-fold speedup using 256 cores of a parallel computer.\n", "versions": [{"version": "v1", "created": "Thu, 6 Nov 2014 06:33:17 GMT"}], "update_date": "2014-11-07", "authors_parsed": [["Ishii", "Daisuke", ""], ["Yoshizoe", "Kazuki", ""], ["Suzumura", "Toyotaro", ""]]}, {"id": "1411.1931", "submitter": "Muralikrishnan Ramane MR", "authors": "Muralikrishnan Ramane, Sharmila Krishnamoorthy and Sasikala Gowtham", "title": "An Experimental Evaluation of Performance of A Hadoop Cluster on Replica\n  Management", "comments": "October 2014, Volume 4, Number 5, PAGE 88-97", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hadoop is an open source implementation of the MapReduce Framework in the\nrealm of distributed processing. A Hadoop cluster is a unique type of\ncomputational cluster designed for storing and analyzing large data sets across\ncluster of workstations. To handle massive scale data, Hadoop exploits the\nHadoop Distributed File System termed as HDFS. The HDFS similar to most\ndistributed file systems share a familiar problem on data sharing and\navailability among compute nodes, often which leads to decrease in performance.\nThis paper is an experimental evaluation of Hadoop's computing performance\nwhich is made by designing a rack aware cluster that utilizes the Hadoop's\ndefault block placement policy to improve data availability. Additionally, an\nadaptive data replication scheme that relies on access count prediction using\nLangrange's interpolation is adapted to fit the scenario. To prove, experiments\nwere conducted on a rack aware cluster setup which significantly reduced the\ntask completion time, but once the volume of the data being processed increases\nthere is a considerable cutback in computational speeds due to update cost.\nFurther the threshold level for balance between the update cost and replication\nfactor is identified and presented graphically.\n", "versions": [{"version": "v1", "created": "Fri, 7 Nov 2014 14:29:07 GMT"}], "update_date": "2014-11-10", "authors_parsed": [["Ramane", "Muralikrishnan", ""], ["Krishnamoorthy", "Sharmila", ""], ["Gowtham", "Sasikala", ""]]}, {"id": "1411.1951", "submitter": "Manuel P\\\"oter", "authors": "Manuel P\\\"oter", "title": "Pheet meets C++11", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pheet is a C++ task-scheduling framework that allows for easy customization\nof internal data-structures. The implementation was started before the C++11\nstandard was committed and therefore did not use the new standardized memory\nmodel but compiler/platform specific intrinsics for atomic memory operations.\nThis not only makes the implementation harder to port to other compilers or\narchitectures but also suffers from the fact that prior C++ versions did not\nspecify any memory model.\n  In this report I discuss the porting of one of the internal Pheet data\nstructures to the new memory model and provide reasoning about the correctness\nbased on the semantics of the memory consistency model. Using two benchmarks\nfrom the Pheet benchmark suite I compare the performance of the original\nagainst the new implementation which shows a significant speedup under certain\nconditions on one of the two test machines.\n", "versions": [{"version": "v1", "created": "Fri, 7 Nov 2014 15:40:48 GMT"}], "update_date": "2014-11-10", "authors_parsed": [["P\u00f6ter", "Manuel", ""]]}, {"id": "1411.1958", "submitter": "Jiajun Cao", "authors": "Jiajun Cao, Matthieu Simonin, Gene Cooperman, Christine Morin", "title": "Checkpointing as a Service in Heterogeneous Cloud Environments", "comments": "20 pages, 11 figures, appears in CCGrid, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A non-invasive, cloud-agnostic approach is demonstrated for extending\nexisting cloud platforms to include checkpoint-restart capability. Most cloud\nplatforms currently rely on each application to provide its own fault\ntolerance. A uniform mechanism within the cloud itself serves two purposes: (a)\ndirect support for long-running jobs, which would otherwise require a custom\nfault-tolerant mechanism for each application; and (b) the administrative\ncapability to manage an over-subscribed cloud by temporarily swapping out jobs\nwhen higher priority jobs arrive. An advantage of this uniform approach is that\nit also supports parallel and distributed computations, over both TCP and\nInfiniBand, thus allowing traditional HPC applications to take advantage of an\nexisting cloud infrastructure. Additionally, an integrated health-monitoring\nmechanism detects when long-running jobs either fail or incur exceptionally low\nperformance, perhaps due to resource starvation, and proactively suspends the\njob. The cloud-agnostic feature is demonstrated by applying the implementation\nto two very different cloud platforms: Snooze and OpenStack. The use of a\ncloud-agnostic architecture also enables, for the first time, migration of\napplications from one cloud platform to another.\n", "versions": [{"version": "v1", "created": "Fri, 7 Nov 2014 15:59:47 GMT"}, {"version": "v2", "created": "Sat, 21 Mar 2015 01:21:20 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Cao", "Jiajun", ""], ["Simonin", "Matthieu", ""], ["Cooperman", "Gene", ""], ["Morin", "Christine", ""]]}, {"id": "1411.2160", "submitter": "Marcos Aguilera", "authors": "Marcos K. Aguilera, Joshua B. Leners, Ramakrishna Kotla, Michael\n  Walfish", "title": "Yesquel: scalable SQL storage for Web applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Based on a brief history of the storage systems for Web applications, we\nmotivate the need for a new storage system. We then describe the architecture\nof such a system, called Yesquel. Yesquel supports the SQL query language and\noffers performance similar to NOSQL storage systems.\n", "versions": [{"version": "v1", "created": "Sat, 8 Nov 2014 20:32:17 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Aguilera", "Marcos K.", ""], ["Leners", "Joshua B.", ""], ["Kotla", "Ramakrishna", ""], ["Walfish", "Michael", ""]]}, {"id": "1411.2222", "submitter": "Neha Karanjkar", "authors": "Neha V. Karanjkar, Madhav P. Desai", "title": "Optimization of Discrete-parameter Multiprocessor Systems using a Novel\n  Ergodic Interpolation Technique", "comments": "A short version of this paper will be published in the proceedings of\n  IEEE MASCOTS 2015 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern multi-core systems have a large number of design parameters, most of\nwhich are discrete-valued, and this number is likely to keep increasing as chip\ncomplexity rises. Further, the accurate evaluation of a potential design choice\nis computationally expensive because it requires detailed cycle-accurate system\nsimulation. If the discrete parameter space can be embedded into a larger\ncontinuous parameter space, then continuous space techniques can, in principle,\nbe applied to the system optimization problem. Such continuous space techniques\noften scale well with the number of parameters.\n  We propose a novel technique for embedding the discrete parameter space into\nan extended continuous space so that continuous space techniques can be applied\nto the embedded problem using cycle accurate simulation for evaluating the\nobjective function. This embedding is implemented using simulation-based\nergodic interpolation, which, unlike spatial interpolation, produces the\ninterpolated value within a single simulation run irrespective of the number of\nparameters. We have implemented this interpolation scheme in a cycle-based\nsystem simulator. In a characterization study, we observe that the interpolated\nperformance curves are continuous, piece-wise smooth, and have low statistical\nerror. We use the ergodic interpolation-based approach to solve a large\nmulti-core design optimization problem with 31 design parameters. Our results\nindicate that continuous space optimization using ergodic interpolation-based\nembedding can be a viable approach for large multi-core design optimization\nproblems.\n", "versions": [{"version": "v1", "created": "Sun, 9 Nov 2014 12:21:23 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2015 07:24:53 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Karanjkar", "Neha V.", ""], ["Desai", "Madhav P.", ""]]}, {"id": "1411.2223", "submitter": "Weonjong Lee", "authors": "Yong-Chull Jang, Hwancheol Jeong, Jangho Kim, Weonjong Lee, Jeonghwan\n  Pak, Yuree Chung (SWME Collaboration)", "title": "Code Optimization on Kepler GPUs and Xeon Phi", "comments": "7 pages, 4 figures, Lattice 2014 proceeding", "journal-ref": "PoS (LATTICE 2014) 035", "doi": null, "report-no": null, "categories": "hep-lat cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kepler GTX Titan Black and Kepler Tesla K40 are still the best GPUs for high\nperformance computing, although Maxwell GPUs such as GTX 980 are available in\nthe market. Hence, we measure the performance of our lattice QCD codes using\nthe Kepler GPUs. We also upgrade our code to use the latest CPS (Columbia\nPhysics System) library along with the most recent QUDA (QCD CUDA) library for\nlattice QCD. These new libraries improve the performance of our conjugate\ngradient (CG) inverter so that it runs twice faster than before. We also\ninvestigate the performance of Xeon Phi 7120P coprocessor. It has similar\ncomputing power with the Kepler GPUs in principle. However, its performance for\nour CG code is significantly inferior to that of the GTX Titan Black GPUs at\npresent.\n", "versions": [{"version": "v1", "created": "Sun, 9 Nov 2014 12:29:01 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Jang", "Yong-Chull", "", "SWME Collaboration"], ["Jeong", "Hwancheol", "", "SWME Collaboration"], ["Kim", "Jangho", "", "SWME Collaboration"], ["Lee", "Weonjong", "", "SWME Collaboration"], ["Pak", "Jeonghwan", "", "SWME Collaboration"], ["Chung", "Yuree", "", "SWME Collaboration"]]}, {"id": "1411.2305", "submitter": "Xun Zheng", "authors": "Xun Zheng, Jin Kyu Kim, Qirong Ho, Eric P. Xing", "title": "Model-Parallel Inference for Big Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In real world industrial applications of topic modeling, the ability to\ncapture gigantic conceptual space by learning an ultra-high dimensional topical\nrepresentation, i.e., the so-called \"big model\", is becoming the next\ndesideratum after enthusiasms on \"big data\", especially for fine-grained\ndownstream tasks such as online advertising, where good performances are\nusually achieved by regression-based predictors built on millions if not\nbillions of input features. The conventional data-parallel approach for\ntraining gigantic topic models turns out to be rather inefficient in utilizing\nthe power of parallelism, due to the heavy dependency on a centralized image of\n\"model\". Big model size also poses another challenge on the storage, where\navailable model size is bounded by the smallest RAM of nodes. To address these\nissues, we explore another type of parallelism, namely model-parallelism, which\nenables training of disjoint blocks of a big topic model in parallel. By\nintegrating data-parallelism with model-parallelism, we show that dependencies\nbetween distributed elements can be handled seamlessly, achieving not only\nfaster convergence but also an ability to tackle significantly bigger model\nsize. We describe an architecture for model-parallel inference of LDA, and\npresent a variant of collapsed Gibbs sampling algorithm tailored for it.\nExperimental results demonstrate the ability of this system to handle topic\nmodeling with unprecedented amount of 200 billion model variables only on a\nlow-end cluster with very limited computational resources and bandwidth.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 01:25:30 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Zheng", "Xun", ""], ["Kim", "Jin Kyu", ""], ["Ho", "Qirong", ""], ["Xing", "Eric P.", ""]]}, {"id": "1411.2392", "submitter": "Philipp Leitner", "authors": "Rostyslav Zabolotnyi and Philipp Leitner and Waldemar Hummer and\n  Schahram Dustdar", "title": "JCloudScale: Closing the Gap Between IaaS and PaaS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Infrastructure-as-a-Service (IaaS) model of cloud computing is a\npromising approach towards building elastically scaling systems. Unfortunately,\nbuilding such applications today is a complex, repetitive and error-prone\nendeavor, as IaaS does not provide any abstraction on top of naked virtual\nmachines. Hence, all functionality related to elasticity needs to be\nimplemented anew for each application. In this paper, we present JCloudScale, a\nJava-based middleware that supports building elastic applications on top of a\npublic or private IaaS cloud. JCloudScale allows to easily bring applications\nto the cloud, with minimal changes to the application code. We discuss the\ngeneral architecture of the middleware as well as its technical features, and\nevaluate our system with regard to both, user acceptance (based on a user\nstudy) and performance overhead. Our results indicate that JCloudScale indeed\nallowed many participants to build IaaS applications more efficiently,\ncomparable to the convenience features provided by industrial\nPlatform-as-a-Service (PaaS) solutions. However, unlike PaaS, using JCloudScale\ndoes not lead to a loss of control and vendor lock-in for the developer.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 11:58:30 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Zabolotnyi", "Rostyslav", ""], ["Leitner", "Philipp", ""], ["Hummer", "Waldemar", ""], ["Dustdar", "Schahram", ""]]}, {"id": "1411.2406", "submitter": "Vladimir Khlevnoy", "authors": "Vladimir A. Khlevnoy, Andrey A. Shchurov", "title": "A Formal Approach to Distributed System Security Test Generation", "comments": "7 pages, 6 figures, 3 tables, Published with International Journal of\n  Computer Trends and Technology (IJCTT). arXiv admin note: text overlap with\n  arXiv:1410.1747", "journal-ref": "International Journal of Computer Trends and Technology (IJCTT)\n  V16(3), 2014 pg 121-127", "doi": "10.14445/22312803/IJCTT-V16P130", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of distributed systems sets high requirements for procedures for\nthe security testing of these systems. This work introduces: (1) a list of\ntypical threats based on standards and actual practices; (2) an extended\nsix-layered model for test generation mission on the basis of technical\nspecifications and end-user requirements. Based on the list of typical threats\nand the multilayer model, we describe a formal approach to the automated design\nand generation of security mechanisms checklists for complex distributed\nsystems.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 13:01:19 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Khlevnoy", "Vladimir A.", ""], ["Shchurov", "Andrey A.", ""]]}, {"id": "1411.2429", "submitter": "Philipp Leitner", "authors": "Philipp Leitner and Juergen Cito", "title": "Patterns in the Chaos - a Study of Performance Variation and\n  Predictability in Public IaaS Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Benchmarking the performance of public cloud providers is a common research\ntopic. Previous research has already extensively evaluated the performance of\ndifferent cloud platforms for different use cases, and under different\nconstraints and experiment setups. In this paper, we present a principled,\nlarge-scale literature review to collect and codify existing research regarding\nthe predictability of performance in public Infrastructure-as-a-Service (IaaS)\nclouds. We formulate 15 hypotheses relating to the nature of performance\nvariations in IaaS systems, to the factors of influence of performance\nvariations, and how to compare different instance types. In a second step, we\nconduct extensive real-life experimentation on Amazon EC2 and Google Compute\nEngine to empirically validate those hypotheses. At the time of our research,\nperformance in EC2 was substantially less predictable than in GCE. Further, we\nshow that hardware heterogeneity is in practice less prevalent than anticipated\nby earlier research, while multi-tenancy has a dramatic impact on performance\nand predictability.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 13:58:58 GMT"}, {"version": "v2", "created": "Tue, 19 Jan 2016 14:09:15 GMT"}], "update_date": "2016-01-20", "authors_parsed": [["Leitner", "Philipp", ""], ["Cito", "Juergen", ""]]}, {"id": "1411.2528", "submitter": "Lin Jianbiao", "authors": "Jianbiao Lin, Yukun Zhong, Xiaowei Lin, Hui Lin, Qiang Zeng", "title": "Hybrid Ant Colony Algorithm Clonal Selection in the Application of the\n  Cloud's Resource Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, thinking over characteristics of ant colony optimization\nAlgorithm, taking into account the characteristics of cloud computing, combined\nwith clonal selection algorithm (CSA) global optimum advantage of the\nconvergence of the clonal selection algorithm (CSA) into every ACO iteration,\nspeeding up the convergence rate, and the introduction of reverse mutation\nstrategy, ant colony optimization algorithm avoids local optimum. Depth study\nof the cloud environment ant colony clonal selection algorithm resource\nscheduling policy, clonal selection algorithm converges to solve optimization\nproblems when sufficient condition for global optimal solution based on clonal\nselection algorithm for various applications such as BCA and CLONALG algorithm,\nusing these sufficient condition to meet and simulation platform CloudSim\nachieve a simulation by extending the cloud. Experimental results show that\nthis task can be shortened fusion algorithm running time cloud environment,\nimprove resource utilization. Demonstrate the effectiveness of the method.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 18:42:11 GMT"}], "update_date": "2014-11-11", "authors_parsed": [["Lin", "Jianbiao", ""], ["Zhong", "Yukun", ""], ["Lin", "Xiaowei", ""], ["Lin", "Hui", ""], ["Zeng", "Qiang", ""]]}, {"id": "1411.2536", "submitter": "Li Tan", "authors": "Li Tan and Zizhong Chen", "title": "Algorithmic Energy Saving for Parallel Cholesky, LU, and QR\n  Factorizations", "comments": "35 pages, incorporating two short papers (one to be replaced) with\n  some updates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The pressing demands of improving energy efficiency for high performance\nscientific computing have motivated a large body of software-controlled hard-\nware solutions using Dynamic Voltage and Frequency Scaling (DVFS) that\nstrategically switch processors to low-power states, when the peak processor\nperformance is not necessary. Although OS level solutions have demonstrated the\neffectiveness of saving energy in a black-box fashion, for applications with\nvariable execution characteristics, the optimal energy efficiency can be\nblundered away due to defective prediction mechanism and untapped load\nimbalance. In this paper, we propose TX, a library level race-to-halt DVFS\nscheduling approach that analyzes Task Dependency Set of each task in parallel\nCholesky, LU, and QR factorizations to achieve substantial energy savings OS\nlevel solutions cannot fulfill. Partially giving up the generality of OS level\nsolutions per requiring library level source modification, TX lever- ages\nalgorithmic characteristics of the applications to gain greater energy savings.\nExperimental results on two power-aware clusters indicate that TX can save up\nto 17.8% more energy than state-of-the-art OS level solutions with negligible\n3.5% on average performance loss.\n", "versions": [{"version": "v1", "created": "Mon, 10 Nov 2014 18:59:19 GMT"}, {"version": "v2", "created": "Wed, 1 Apr 2015 20:48:28 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Tan", "Li", ""], ["Chen", "Zizhong", ""]]}, {"id": "1411.2800", "submitter": "Federico Cerutti", "authors": "Federico Cerutti, Ilias Tachmazidis, Mauro Vallati, Sotirios Batsakis,\n  Massimiliano Giacomin, Grigoris Antoniou", "title": "Exploiting Parallelism for Hard Problems in Abstract Argumentation:\n  Technical Report", "comments": "Technical report of an accepted AAAI-2015 Paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Abstract argumentation framework (\\AFname) is a unifying framework able to\nencompass a variety of nonmonotonic reasoning approaches, logic programming and\ncomputational argumentation. Yet, efficient approaches for most of the decision\nand enumeration problems associated to \\AFname s are missing, thus potentially\nlimiting the efficacy of argumentation-based approaches in real domains. In\nthis paper, we present an algorithm for enumerating the preferred extensions of\nabstract argumentation frameworks which exploits parallel computation. To this\npurpose, the SCC-recursive semantics definition schema is adopted, where\nextensions are defined at the level of specific sub-frameworks. The algorithm\nshows significant performance improvements in large frameworks, in terms of\nnumber of solutions found and speedup.\n", "versions": [{"version": "v1", "created": "Tue, 11 Nov 2014 13:33:33 GMT"}, {"version": "v2", "created": "Tue, 18 Nov 2014 14:31:12 GMT"}], "update_date": "2014-11-19", "authors_parsed": [["Cerutti", "Federico", ""], ["Tachmazidis", "Ilias", ""], ["Vallati", "Mauro", ""], ["Batsakis", "Sotirios", ""], ["Giacomin", "Massimiliano", ""], ["Antoniou", "Grigoris", ""]]}, {"id": "1411.3201", "submitter": "Swetha P T Srinivasan", "authors": "Swetha P.T. Srinivasan, Umesh Bellur", "title": "Novel Power and Completion Time Models for Virtualized Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power consumption costs takes upto half of operational expenses of\ndatacenters making power management a critical concern. Advances in processor\ntechnology provide fine-grained control over operating frequency and voltage of\nprocessors and this control can be used to tradeoff power for performance.\nAlthough many power and performance models exist, they have a significant error\nmargin while predicting the performance of memory or file-intensive tasks and\nHPC applications. Our investigations reveal that the prediction error is due in\npart to the fact that they do not take frequency AND CPU variations account,\nrather they just depend on the CPU by itself.\n  In this paper, we empirically derive power and completion time models using\nlinear regression with CPU utilization and operating frequency as parameters.\nWe validate our power model on several Intel and AMD processors by predicting\nwithin 2-7% of measured power. We validate our completion time model using five\nkernels of NASA Parallel Benchmark suite and five CPU, memory and\nfile-intensive benchmarks on four heterogeneous systems and predicting within\n1-6% of observed performance. We then show how these models can be employed to\nrealize as much as 15% savings in power while delivering 44% better performance\nfor applications deployed in a virtualized environment.\n", "versions": [{"version": "v1", "created": "Wed, 12 Nov 2014 15:16:51 GMT"}], "update_date": "2014-11-13", "authors_parsed": [["Srinivasan", "Swetha P. T.", ""], ["Bellur", "Umesh", ""]]}, {"id": "1411.3212", "submitter": "Francesco Lettich", "authors": "Francesco Lettich, Salvatore Orlando, Claudio Silvestri and Christian\n  S. Jensen", "title": "Manycore processing of repeated range queries over massive moving\n  objects observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to timely process significant amounts of continuously updated\nspatial data is mandatory for an increasing number of applications. Parallelism\nenables such applications to face this data-intensive challenge and allows the\ndevised systems to feature low latency and high scalability. In this paper we\nfocus on a specific data-intensive problem, concerning the repeated processing\nof huge amounts of range queries over massive sets of moving objects, where the\nspatial extents of queries and objects are continuously modified over time. To\ntackle this problem and significantly accelerate query processing we devise a\nhybrid CPU/GPU pipeline that compresses data output and save query processing\nwork. The devised system relies on an ad-hoc spatial index leading to a problem\ndecomposition that results in a set of independent data-parallel tasks. The\nindex is based on a point-region quadtree space decomposition and allows to\ntackle effectively a broad range of spatial object distributions, even those\nvery skewed. Also, to deal with the architectural peculiarities and limitations\nof the GPUs, we adopt non-trivial GPU data structures that avoid the need of\nlocked memory accesses and favour coalesced memory accesses, thus enhancing the\noverall memory throughput. To the best of our knowledge this is the first work\nthat exploits GPUs to efficiently solve repeated range queries over massive\nsets of continuously moving objects, characterized by highly skewed spatial\ndistributions. In comparison with state-of-the-art CPU-based implementations,\nour method highlights significant speedups in the order of 14x-20x, depending\non the datasets, even when considering very cheap GPUs.\n", "versions": [{"version": "v1", "created": "Wed, 12 Nov 2014 15:46:39 GMT"}], "update_date": "2014-11-13", "authors_parsed": [["Lettich", "Francesco", ""], ["Orlando", "Salvatore", ""], ["Silvestri", "Claudio", ""], ["Jensen", "Christian S.", ""]]}, {"id": "1411.3273", "submitter": "Subhash Kak", "authors": "Subhash Kak", "title": "Efficiency of Matrix Multiplication on the Cross-Wired Mesh Array", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This note looks at the efficiency of the cross-wired mesh array in the\ncontext of matrix multiplication. It is shown that in case of repeated\noperations, the average number of steps to multiply sets of nxn matrices on a\n2D cross-wired mesh array approaches n.\n", "versions": [{"version": "v1", "created": "Wed, 12 Nov 2014 18:35:49 GMT"}], "update_date": "2014-11-13", "authors_parsed": [["Kak", "Subhash", ""]]}, {"id": "1411.3622", "submitter": "Robert Piro", "authors": "Boris Motik, Yavor Nenov, Robert Piro, Ian Horrocks", "title": "Handling owl:sameAs via Rewriting", "comments": "This is the technical report supporting the AAAI 2015 Conference\n  submission with the same title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rewriting is widely used to optimise owl:sameAs reasoning in materialisation\nbased OWL 2 RL systems. We investigate issues related to both the correctness\nand efficiency of rewriting, and present an algorithm that guarantees\ncorrectness, improves efficiency, and can be effectively parallelised. Our\nevaluation shows that our approach can reduce reasoning times on practical data\nsets by orders of magnitude.\n", "versions": [{"version": "v1", "created": "Thu, 13 Nov 2014 17:30:03 GMT"}], "update_date": "2014-11-14", "authors_parsed": [["Motik", "Boris", ""], ["Nenov", "Yavor", ""], ["Piro", "Robert", ""], ["Horrocks", "Ian", ""]]}, {"id": "1411.3656", "submitter": "Karel Ad\\'amek", "authors": "Karel Ad\\'amek, Jan Novotn\\'y and Wes Armour", "title": "The Implementation of a Real-Time Polyphase Filter", "comments": "Proceedings of WDS 2014, Charles University in Prague, Faculty of\n  Mathematics and Physics Troja, Prague", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we study the suitability of dierent computational\naccelerators for the task of real-time data processing. The algorithm used for\ncomparison is the polyphase filter, a standard tool in signal processing and a\nwell established algorithm. We measure performance in FLOPs and execution time,\nwhich is a critical factor for real-time systems. For our real-time studies we\nhave chosen a data rate of 6.5GB/s, which is the estimated data rate for a\nsingle channel on the SKAs Low Frequency Aperture Array. Our findings how that\nGPUs are the most likely candidate for real-time data processing. GPUs are\nbetter in both performance and power consumption.\n", "versions": [{"version": "v1", "created": "Wed, 12 Nov 2014 18:33:21 GMT"}], "update_date": "2014-11-14", "authors_parsed": [["Ad\u00e1mek", "Karel", ""], ["Novotn\u00fd", "Jan", ""], ["Armour", "Wes", ""]]}, {"id": "1411.3771", "submitter": "Yasir Shoaib", "authors": "Yasir Shoaib, Olivia Das", "title": "Pouring Cloud Virtualization Security Inside Out", "comments": "13 pages, 2 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, virtualization security concerns in the cloud computing\ndomain are reviewed. The focus is toward virtual machine (VM) security where\nattacks and vulnerabilities such as VM escape, VM hopping, cross-VM\nside-channel, VM-based rootkits (VMBRs), VM mobility, and VM remote are\nmentioned and discussed according to their relevance in the clouds. For each\nattack we outline how they affect the security of cloud systems.\nCountermeasures and security measures to detect or prevent them through\ntechniques such as VM detection, GuardHype, VM introspection, VM image\nscanning, etc. are also discussed. Through the surveyed work we present a\nclassification of VM threats within the clouds. Finally, we include our\nobservations and those of other researchers on this matter of cloud\nvirtualization security.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 01:14:58 GMT"}], "update_date": "2014-11-17", "authors_parsed": [["Shoaib", "Yasir", ""], ["Das", "Olivia", ""]]}, {"id": "1411.3811", "submitter": "Todor Ivanov", "authors": "Todor Ivanov, Roberto V. Zicari, Sead Izberovic, Karsten Tolle", "title": "Performance Evaluation of Virtualized Hadoop Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": "Technical Report No. 2014-1", "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we investigate the performance of Hadoop clusters, deployed\nwith separated storage and compute layers, on top of a hypervisor managing a\nsingle physical host. We have analyzed and evaluated the different Hadoop\ncluster configurations by running CPU bound and I/O bound workloads. The report\nis structured as follows: Section 2 provides a brief description of the\ntechnologies involved in our study. An overview of the experimental platform,\nsetup test and configurations are presented in Section 3. Our benchmark\nmethodology is defined in Section 4. The performed experiments together with\nthe evaluation of the results are presented in Section 5. Finally, Section 6\nconcludes with lessons learned.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 07:14:05 GMT"}], "update_date": "2014-11-17", "authors_parsed": [["Ivanov", "Todor", ""], ["Zicari", "Roberto V.", ""], ["Izberovic", "Sead", ""], ["Tolle", "Karsten", ""]]}, {"id": "1411.4044", "submitter": "Todor Ivanov", "authors": "Todor Ivanov, Raik Niemann, Sead Izberovic, Marten Rosselli, Karsten\n  Tolle, Roberto V. Zicari", "title": "Benchmarking DataStax Enterprise/Cassandra with HiBench", "comments": "arXiv admin note: substantial text overlap with arXiv:1411.3811", "journal-ref": null, "doi": null, "report-no": "Technical Report No. 2014-2", "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report evaluates the new analytical capabilities of DataStax Enterprise\n(DSE) [1] through the use of standard Hadoop workloads. In particular, we run\nexperiments with CPU and I/O bound micro-benchmarks as well as OLAP-style\nanalytical query workloads. The performed tests should show that DSE is capable\nof successfully executing Hadoop applications without the need to adapt them\nfor the underlying Cassandra distributed storage system [2]. Due to the\nCassandra File System (CFS) [3], which supports the Hadoop Distributed File\nSystem API, Hadoop stack applications should seamlessly run in DSE. The report\nis structured as follows: Section 2 provides a brief description of the\ntechnologies involved in our study. An overview of our used hardware and\nsoftware components of the experimental environment is given in Section 3. Our\nbenchmark methodology is defined in Section 4. The performed experiments\ntogether with the evaluation of the results are presented in Section 5.\nFinally, Section 6 concludes with lessons learned.\n", "versions": [{"version": "v1", "created": "Fri, 14 Nov 2014 07:17:54 GMT"}, {"version": "v2", "created": "Tue, 16 Dec 2014 14:34:47 GMT"}], "update_date": "2014-12-17", "authors_parsed": [["Ivanov", "Todor", ""], ["Niemann", "Raik", ""], ["Izberovic", "Sead", ""], ["Rosselli", "Marten", ""], ["Tolle", "Karsten", ""], ["Zicari", "Roberto V.", ""]]}, {"id": "1411.4186", "submitter": "Alexander Olshevsky", "authors": "Alex Olshevsky", "title": "Linear Time Average Consensus on Fixed Graphs and Implications for\n  Decentralized Optimization and Multi-Agent Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a protocol for the average consensus problem on any fixed\nundirected graph whose convergence time scales linearly in the total number\nnodes $n$. The protocol is completely distributed, with the exception of\nrequiring all nodes to know the same upper bound $U$ on the total number of\nnodes which is correct within a constant multiplicative factor.\n  We next discuss applications of this protocol to problems in multi-agent\ncontrol connected to the consensus problem. In particular, we describe\nprotocols for formation maintenance and leader-following with convergence times\nwhich also scale linearly with the number of nodes.\n  Finally, we develop a distributed protocol for minimizing an average of\n(possibly nondifferentiable) convex functions $ (1/n) \\sum_{i=1}^n\nf_i(\\theta)$, in the setting where only node $i$ in an undirected, connected\ngraph knows the function $f_i(\\theta)$. Under the same assumption about all\nnodes knowing $U$, and additionally assuming that the subgradients of each\n$f_i(\\theta)$ have absolute values upper bounded by some constant $L$ known to\nthe nodes, we show that after $T$ iterations our protocol has error which is\n$O(L \\sqrt{n/T})$.\n", "versions": [{"version": "v1", "created": "Sat, 15 Nov 2014 21:02:08 GMT"}, {"version": "v2", "created": "Wed, 19 Nov 2014 20:26:38 GMT"}, {"version": "v3", "created": "Thu, 4 Dec 2014 07:48:19 GMT"}, {"version": "v4", "created": "Sun, 28 Dec 2014 06:02:03 GMT"}, {"version": "v5", "created": "Sat, 3 Jan 2015 23:36:47 GMT"}, {"version": "v6", "created": "Mon, 23 May 2016 00:40:59 GMT"}, {"version": "v7", "created": "Fri, 4 Aug 2017 00:13:59 GMT"}], "update_date": "2017-08-07", "authors_parsed": [["Olshevsky", "Alex", ""]]}, {"id": "1411.4379", "submitter": "Md Lisul Islam", "authors": "Md. Lisul Islam, Novia Nurain, Swakkhar Shatabda and M Sohel Rahman", "title": "FGPGA: An Efficient Genetic Approach for Producing Feasible Graph\n  Partitions", "comments": "Accepted in the 1st International Conference on Networking Systems\n  and Security 2015 (NSysS 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph partitioning, a well studied problem of parallel computing has many\napplications in diversified fields such as distributed computing, social\nnetwork analysis, data mining and many other domains. In this paper, we\nintroduce FGPGA, an efficient genetic approach for producing feasible graph\npartitions. Our method takes into account the heterogeneity and capacity\nconstraints of the partitions to ensure balanced partitioning. Such approach\nhas various applications in mobile cloud computing that include feasible\ndeployment of software applications on the more resourceful infrastructure in\nthe cloud instead of mobile hand set. Our proposed approach is light weight and\nhence suitable for use in cloud architecture. We ensure feasibility of the\npartitions generated by not allowing over-sized partitions to be generated\nduring the initialization and search. Our proposed method tested on standard\nbenchmark datasets significantly outperforms the state-of-the-art methods in\nterms of quality of partitions and feasibility of the solutions.\n", "versions": [{"version": "v1", "created": "Mon, 17 Nov 2014 06:51:50 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Islam", "Md. Lisul", ""], ["Nurain", "Novia", ""], ["Shatabda", "Swakkhar", ""], ["Rahman", "M Sohel", ""]]}, {"id": "1411.4510", "submitter": "Kian Hsiang Low", "authors": "Kian Hsiang Low, Jiangbo Yu, Jie Chen, Patrick Jaillet", "title": "Parallel Gaussian Process Regression for Big Data: Low-Rank\n  Representation Meets Markov Approximation", "comments": "29th AAAI Conference on Artificial Intelligence (AAAI 2015), Extended\n  version with proofs, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The expressive power of a Gaussian process (GP) model comes at a cost of poor\nscalability in the data size. To improve its scalability, this paper presents a\nlow-rank-cum-Markov approximation (LMA) of the GP model that is novel in\nleveraging the dual computational advantages stemming from complementing a\nlow-rank approximate representation of the full-rank GP based on a support set\nof inputs with a Markov approximation of the resulting residual process; the\nlatter approximation is guaranteed to be closest in the Kullback-Leibler\ndistance criterion subject to some constraint and is considerably more refined\nthan that of existing sparse GP models utilizing low-rank representations due\nto its more relaxed conditional independence assumption (especially with larger\ndata). As a result, our LMA method can trade off between the size of the\nsupport set and the order of the Markov property to (a) incur lower\ncomputational cost than such sparse GP models while achieving predictive\nperformance comparable to them and (b) accurately represent features/patterns\nof any scale. Interestingly, varying the Markov order produces a spectrum of\nLMAs with PIC approximation and full-rank GP at the two extremes. An advantage\nof our LMA method is that it is amenable to parallelization on multiple\nmachines/cores, thereby gaining greater scalability. Empirical evaluation on\nthree real-world datasets in clusters of up to 32 computing nodes shows that\nour centralized and parallel LMA methods are significantly more time-efficient\nand scalable than state-of-the-art sparse and full-rank GP regression methods\nwhile achieving comparable predictive performances.\n", "versions": [{"version": "v1", "created": "Mon, 17 Nov 2014 15:31:04 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Low", "Kian Hsiang", ""], ["Yu", "Jiangbo", ""], ["Chen", "Jie", ""], ["Jaillet", "Patrick", ""]]}, {"id": "1411.4565", "submitter": "Drona Pratap Chandu", "authors": "Drona Pratap Chandu", "title": "A Parallel Genetic Algorithm for Three Dimensional Bin Packing with\n  Heterogeneous Bins", "comments": "6 pages, 4 figures", "journal-ref": "International Journal of Computer Trends and Technology (IJCTT)\n  V17(1):33-38, Nov 2014", "doi": "10.14445/22312803/IJCTT-V17P108", "report-no": null, "categories": "cs.DC cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper presents a parallel genetic algorithm for three dimensional bin\npacking with heterogeneous bins using Hadoop Map-Reduce framework. The most\ncommon three dimensional bin packing problem which packs given set of boxes\ninto minimum number of equal sized bins is proven to be NP Hard. The variation\nof three dimensional bin packing problem that allows heterogeneous bin sizes\nand rotation of boxes is computationally more harder than common three\ndimensional bin packing problem. The proposed Map-Reduce implementation helps\nto run the genetic algorithm for three dimensional bin packing with\nheterogeneous bins on multiple machines parallely and computes the solution in\nrelatively short time.\n", "versions": [{"version": "v1", "created": "Mon, 17 Nov 2014 17:35:02 GMT"}], "update_date": "2014-11-18", "authors_parsed": [["Chandu", "Drona Pratap", ""]]}, {"id": "1411.4762", "submitter": "Harshan Jagadeesh", "authors": "J. Harshan, Fr\\'ed\\'erique Oggier and Anwitaman Datta", "title": "Sparsity Exploiting Erasure Coding for Resilient Storage and Efficient\n  I/O Access in Delta based Versioning Systems", "comments": "10 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the problem of storing reliably an archive of\nversioned data. Specifically, we focus on systems where the differences\n(deltas) between subsequent versions rather than the whole objects are stored -\na typical model for storing versioned data. For reliability, we propose erasure\nencoding techniques that exploit the sparsity of information in the deltas\nwhile storing them reliably in a distributed back-end storage system, resulting\nin improved I/O read performance to retrieve the whole versioned archive. Along\nwith the basic techniques, we propose a few optimization heuristics, and\nevaluate the techniques' efficacy analytically and with numerical simulations.\n", "versions": [{"version": "v1", "created": "Tue, 18 Nov 2014 08:34:17 GMT"}], "update_date": "2014-11-19", "authors_parsed": [["Harshan", "J.", ""], ["Oggier", "Fr\u00e9d\u00e9rique", ""], ["Datta", "Anwitaman", ""]]}, {"id": "1411.5077", "submitter": "Yasir Shoaib", "authors": "Yasir Shoaib, Olivia Das", "title": "Performance-oriented Cloud Provisioning: Taxonomy and Survey", "comments": "14 pages, 3 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is being viewed as the technology of today and the future.\nThrough this paradigm, the customers gain access to shared computing resources\nlocated in remote data centers that are hosted by cloud providers (CP). This\ntechnology allows for provisioning of various resources such as virtual\nmachines (VM), physical machines, processors, memory, network, storage and\nsoftware as per the needs of customers. Application providers (AP), who are\ncustomers of the CP, deploy applications on the cloud infrastructure and then\nthese applications are used by the end-users. To meet the fluctuating\napplication workload demands, dynamic provisioning is essential and this\narticle provides a detailed literature survey of dynamic provisioning within\ncloud systems with focus on application performance. The well-known types of\nprovisioning and the associated problems are clearly and pictorially explained\nand the provisioning terminology is clarified. A very detailed and general\ncloud provisioning classification is presented, which views provisioning from\ndifferent perspectives, aiding in understanding the process inside-out. Cloud\ndynamic provisioning is explained by considering resources, stakeholders,\ntechniques, technologies, algorithms, problems, goals and more.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 00:04:52 GMT"}], "update_date": "2014-11-20", "authors_parsed": [["Shoaib", "Yasir", ""], ["Das", "Olivia", ""]]}, {"id": "1411.5213", "submitter": "Atul Vaibhav", "authors": "Atul Vaibhav", "title": "Security in Monitoring Schemes: A Survey", "comments": "Attacks, Monitoring Schemes, Aggregation, Analysis, Dissemination,\n  Gossip, Tree, Hybrid, Distributed Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With our growing reliability on distributed networks, the security aspect of\nsuch networks becomes of prime importance. In large scale distributed networks\nit becomes cardinal to have an efficient and effective monitoring scheme. The\nmonitoring schemes supervise the node behaviour in the network and look out for\nany discrepancy. Monitoring schemes comprise of monitoring components that work\ntogether to help schemes in meeting various security requirement parameters for\nthe networks. These security parameters are breached via various attacks by\nmanipulation of monitoring components of particular monitoring schemes to\nproduce faulty results and thereby reducing efficiency of networks, reliability\nand security. In this paper we have discussed these components of monitoring,\nmultiple monitoring schemes, their security parameters and various types of\nattacks possible on these monitoring components by manipulating assumptions of\nmonitoring schemes.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 13:23:02 GMT"}], "update_date": "2014-11-20", "authors_parsed": [["Vaibhav", "Atul", ""]]}, {"id": "1411.5282", "submitter": "Lili Su", "authors": "Lili Su, Nitin Vaidya", "title": "Reaching Approximate Byzantine Consensus with Multi-hop Communication", "comments": "24 pages, 1 figure. arXiv admin note: text overlap with\n  arXiv:1203.1888", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We address the problem of reaching consensus in the presence of Byzantine\nfaults. In particular, we are interested in investigating the impact of\nmessages relay on the network connectivity for a correct iterative approximate\nByzantine consensus algorithm to exist. The network is modeled by a simple\ndirected graph. We assume a node can send messages to another node that is up\nto $l$ hops away via forwarding by the intermediate nodes on the routes, where\n$l\\in \\mathbb{N}$ is a natural number. We characterize the necessary and\nsufficient topological conditions on the network structure. The tight\nconditions we found are consistent with the tight conditions identified for\n$l=1$, where only local communication is allowed, and are strictly weaker for\n$l>1$. Let $l^*$ denote the length of a longest path in the given network. For\n$l\\ge l^*$ and undirected graphs, our conditions hold if and only if $n\\ge\n3f+1$ and the node-connectivity of the given graph is at least $2f+1$ , where\n$n$ is the total number of nodes and $f$ is the maximal number of Byzantine\nnodes; and for $l\\ge l^*$ and directed graphs, our conditions is equivalent to\nthe tight condition found for exact Byzantine consensus.\n  Our sufficiency is shown by constructing a correct algorithm, wherein the\ntrim function is constructed based on investigating a newly introduced minimal\nmessages cover property. The trim function proposed also works over\nmulti-graphs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 16:32:24 GMT"}, {"version": "v2", "created": "Wed, 15 Apr 2015 23:45:42 GMT"}], "update_date": "2015-04-17", "authors_parsed": [["Su", "Lili", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1411.5283", "submitter": "Zaid Alyasseri", "authors": "Zaid Abdi Alkareem Alyasseri, Kadhim Al-Attar, Mazin Nasser", "title": "Parallelize Bubble and Merge Sort Algorithms Using Message Passing\n  Interface (MPI)", "comments": "5 pages, 5 figures. arXiv admin note: substantial text overlap with\n  arXiv:1407.6603", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sorting has been a profound area for the algorithmic researchers and many\nresources are invested to suggest more works for sorting algorithms. For this\npurpose, many existing sorting algorithms were observed in terms of the\nefficiency of the algorithmic complexity. In this paper we implemented the\nbubble and merge sort algorithms using Message Passing Interface (MPI)\napproach. The proposed work tested on two standard datasets (text file) with\ndifferent size. The main idea of the proposed algorithm is distributing the\nelements of the input datasets into many additional temporary sub-arrays\naccording to a number of characters in each word. The sizes of each of these\nsub-arrays are decided depending on a number of elements with the same number\nof characters in the input array. We implemented MPI using Intel core i7-3610QM\n,(8 CPUs),using two approaches (vectors of string and array 3D) . Finally, we\nget the data structure effects on the performance of the algorithm for that we\nchoice the second approach.\n", "versions": [{"version": "v1", "created": "Wed, 19 Nov 2014 16:35:16 GMT"}], "update_date": "2014-11-20", "authors_parsed": [["Alyasseri", "Zaid Abdi Alkareem", ""], ["Al-Attar", "Kadhim", ""], ["Nasser", "Mazin", ""]]}, {"id": "1411.5433", "submitter": "Alexander Semenov", "authors": "Alexander Semenov, Oleg Zaikin and Ilya Otpuschennikov", "title": "Using Volunteer Computing for Mounting SAT-based Cryptographic Attacks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe the volunteer computing project SAT@home, developed\nand maintained by us. This project is aimed at solving hard instances of the\nBoolean satisfiability problem (SAT). We believe that this project can be a\nuseful tool for computational study of inversion problems of some cryptographic\nfunctions. In particular we describe a series of experiments performed in\nSAT@home on the cryptanalysis of the widely known keystream generator A5/1. In\nall experiments we analyzed one known burst (114 bits) of keystream produced by\nA5/1. Before the cryptanalysis itself there is a stage on which the\npartitioning of the original problem to a family of subproblems is carried out.\nEach of subproblems should be easy enough so that it could be solved in\nrelatively small amount of time by volunteer's PC. We construct such\npartitioning using the special technique based on the Monte Carlo method and\ndiscrete optimization algorithms for special predictive functions. Besides this\nin the paper we describe the technique for reducing inversion problems of\ncryptographic functions to SAT.\n", "versions": [{"version": "v1", "created": "Thu, 20 Nov 2014 03:42:13 GMT"}], "update_date": "2014-11-21", "authors_parsed": [["Semenov", "Alexander", ""], ["Zaikin", "Oleg", ""], ["Otpuschennikov", "Ilya", ""]]}, {"id": "1411.5943", "submitter": "Krzysztof Nienartowicz", "authors": "Krzysztof Nienartowicz, Diego Ord\\'o\\~nez Blanco, Leanne Guy, Berry\n  Holl, Isabelle Lecoeur-Ta\\\"ibi, Nami Mowlavi, Lorenzo Rimoldini, Idoia Ruiz,\n  Maria S\\\"uveges, Laurent Eyer", "title": "Time series data mining for the Gaia variability analysis", "comments": "4 pages, 3 figures. appears in the Proc. of the 2014 conference on\n  Big Data from Space (BiDS14), European Commission, Joint Research Centre, P.\n  Soille, P. G. Marchetti (eds)", "journal-ref": null, "doi": "10.2788/1823", "report-no": null, "categories": "astro-ph.IM cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gaia is an ESA cornerstone mission, which was successfully launched December\n2013 and commenced operations in July 2014. Within the Gaia Data Processing and\nAnalysis consortium, Coordination Unit 7 (CU7) is responsible for the\nvariability analysis of over a billion celestial sources and nearly 4 billion\nassociated time series (photometric, spectrophotometric, and spectroscopic),\nencoding information in over 800 billion observations during the 5 years of the\nmission, resulting in a petabyte scale analytical problem. In this article, we\nbriefly describe the solutions we developed to address the challenges of time\nseries variability analysis: from the structure for a distributed data-oriented\nscientific collaboration to architectural choices and specific components used.\nOur approach is based on Open Source components with a distributed, partitioned\ndatabase as the core to handle incrementally: ingestion, distributed\nprocessing, analysis, results and export in a constrained time window.\n", "versions": [{"version": "v1", "created": "Fri, 21 Nov 2014 16:32:19 GMT"}], "update_date": "2014-11-24", "authors_parsed": [["Nienartowicz", "Krzysztof", ""], ["Blanco", "Diego Ord\u00f3\u00f1ez", ""], ["Guy", "Leanne", ""], ["Holl", "Berry", ""], ["Lecoeur-Ta\u00efbi", "Isabelle", ""], ["Mowlavi", "Nami", ""], ["Rimoldini", "Lorenzo", ""], ["Ruiz", "Idoia", ""], ["S\u00fcveges", "Maria", ""], ["Eyer", "Laurent", ""]]}, {"id": "1411.6114", "submitter": "Dharmesh Kakadia", "authors": "Radheshyam Nanduri, Dharmesh Kakadia, Vasudeva Varma", "title": "Energy and SLA aware VM Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of Cloud Computing over the past few years, there has\nbeen a massive shift from traditional data centers to cloud enabled data\ncenters. The enterprises with cloud data centers are focusing their attention\non energy savings through effective utilization of resources. In this work, we\npropose algorithms which try to minimize the energy consumption in the data\ncenter duly maintaining the SLA guarantees. The algorithms try to utilize least\nnumber of physical machines in the data center by dynamically rebalancing the\nphysical machines based on their resource utilization. The algorithms also\nperform an optimal consolidation of virtual machines on a physical machine,\nminimizing SLA violations. In extensive simulation, our algorithms achieve\nsavings of about 21% in terms of energy consumption and in terms of maintaining\nthe SLAs, it performs 60% better than Single Threshold algorithm.\n", "versions": [{"version": "v1", "created": "Sat, 22 Nov 2014 11:21:01 GMT"}], "update_date": "2014-11-25", "authors_parsed": [["Nanduri", "Radheshyam", ""], ["Kakadia", "Dharmesh", ""], ["Varma", "Vasudeva", ""]]}, {"id": "1411.6358", "submitter": "Chenxu Zhao", "authors": "Junxiong Wang, Hongzhi Wang and Chenxu Zhao", "title": "A Hybrid Solution to improve Iteration Efficiency in the Distributed\n  Learning", "comments": "This paper has been withdrawn by the author due to a definition error", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Currently, many machine learning algorithms contain lots of iterations. When\nit comes to existing large-scale distributed systems, some slave nodes may\nbreak down or have lower efficiency. Therefore traditional machine learning\nalgorithm may fail because of the instability of distributed system.We presents\na hybrid approach which not only own a high fault-tolerant but also achieve a\nbalance of performance and efficiency.For each iteration, the result of slow\nmachines will be abandoned. Then, we discuss the relationship between accuracy\nand abandon rate. Next we debate the convergence speed of this process.\nFinally, our experiments demonstrate our idea can dramatically reduce\ncalculation time and be used in many platforms.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 06:42:03 GMT"}, {"version": "v2", "created": "Sun, 20 Dec 2020 11:20:04 GMT"}], "update_date": "2020-12-22", "authors_parsed": [["Wang", "Junxiong", ""], ["Wang", "Hongzhi", ""], ["Zhao", "Chenxu", ""]]}, {"id": "1411.6478", "submitter": "Francois Taiani", "authors": "Roy Friedman, Michel Raynal (IUF, UR1, ASAP), Fran\\c{c}ois Ta\\\"iani\n  (UR1, ASAP)", "title": "Fisheye Consistency: Keeping Data in Synch in a Georeplicated World", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last thirty years, numerous consistency conditions for replicated\ndata have been proposed and implemented. Popular examples of such conditions\ninclude linearizability (or atomicity), sequential consistency, causal\nconsistency, and eventual consistency. These consistency conditions are usually\ndefined independently from the computing entities (nodes) that manipulate the\nreplicated data; i.e., they do not take into account how computing entities\nmight be linked to one another, or geographically distributed. To address this\nlack, as a first contribution, this paper introduces the notion of proximity\ngraph between computing nodes. If two nodes are connected in this graph, their\noperations must satisfy a strong consistency condition, while the operations\ninvoked by other nodes are allowed to satisfy a weaker condition. The second\ncontribution is the use of such a graph to provide a generic approach to the\nhybridization of data consistency conditions into the same system. We\nillustrate this approach on sequential consistency and causal consistency, and\npresent a model in which all data operations are causally consistent, while\noperations by neighboring processes in the proximity graph are sequentially\nconsistent. The third contribution of the paper is the design and the proof of\na distributed algorithm based on this proximity graph, which combines\nsequential consistency and causal consistency (the resulting condition is\ncalled fisheye consistency). In doing so the paper not only extends the domain\nof consistency conditions, but provides a generic provably correct solution of\ndirect relevance to modern georeplicated systems.\n", "versions": [{"version": "v1", "created": "Mon, 24 Nov 2014 15:12:39 GMT"}, {"version": "v2", "created": "Thu, 22 Oct 2015 10:03:58 GMT"}], "update_date": "2015-10-23", "authors_parsed": [["Friedman", "Roy", "", "IUF, UR1, ASAP"], ["Raynal", "Michel", "", "IUF, UR1, ASAP"], ["Ta\u00efani", "Fran\u00e7ois", "", "UR1, ASAP"]]}, {"id": "1411.6721", "submitter": "Marc Solanas Tarre", "authors": "Marc Solanas, Julio Hernandez-Castro, Debojyoti Dutta", "title": "Detecting fraudulent activity in a cloud using privacy-friendly data\n  aggregates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  More users and companies make use of cloud services every day. They all\nexpect a perfect performance and any issue to remain transparent to them. This\nlast statement is very challenging to perform. A user's activities in our cloud\ncan affect the overall performance of our servers, having an impact on other\nresources. We can consider these kind of activities as fraudulent. They can be\neither illegal activities, such as launching a DDoS attack or just activities\nwhich are undesired by the cloud provider, such as Bitcoin mining, which uses\nsubstantial power, reduces the life of the hardware and can possibly slow down\nother user's activities. This article discusses a method to detect such\nactivities by using non-intrusive, privacy-friendly data: billing data. We use\nOpenStack as an example with data provided by Telemetry, the component in\ncharge of measuring resource usage for billing purposes. Results will be shown\nproving the efficiency of this method and ways to improve it will be provided\nas well as its advantages and disadvantages.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 03:56:43 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Solanas", "Marc", ""], ["Hernandez-Castro", "Julio", ""], ["Dutta", "Debojyoti", ""]]}, {"id": "1411.6753", "submitter": "Sukhpal  Singh Gill", "authors": "Sukhpal Singh and Inderveer Chana", "title": "Metrics based Workload Analysis Technique for IaaS Cloud", "comments": "Including 5 Tables and 3 Figures, Presented in the International\n  Conference on Next Generation Computing and Communication Technologies\n  (ICNGCCT 2014), Dubai, UAE on 23-24 April, 2014", "journal-ref": null, "doi": null, "report-no": "CCT0036", "categories": "cs.DC", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  The Dynamic Scalability of resources, a problem in Infrastructure as a\nService (IaaS) has been the hotspot for research and industry communities. The\nheterogeneous and dynamic nature of the Cloud workloads depends on the Quality\nof Service (QoS) allocation of appropriate workloads to appropriate resources.\nA workload is an abstraction of work that instance or set of instances that are\ngoing to perform. Running a web service or being a Hadoop data node is valid\nworkloads. The efficient management of dynamic nature resources can be done\nwith the help of workloads. Until workload is considered a fundamental\ncapability, the Cloud resources cannot be utilized in an efficient manner. In\nthis paper, different workloads have been identified and categorized along with\ntheir characteristics and constraints. The metrics based on Quality of Service\n(QoS) requirements have been identified for each workload and have been\nanalyzed for creating better application design.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 07:27:49 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Singh", "Sukhpal", ""], ["Chana", "Inderveer", ""]]}, {"id": "1411.6763", "submitter": "Peng Peng", "authors": "Peng Peng, Lei Zou, M. Tamer \\\"Ozsu, Lei Chen, Dongyan Zhao", "title": "Processing SPARQL Queries Over Distributed RDF Graphs", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose techniques for processing SPARQL queries over a large RDF graph in\na distributed environment. We adopt a \"partial evaluation and assembly\"\nframework. Answering a SPARQL query Q is equivalent to finding subgraph matches\nof the query graph Q over RDF graph G. Based on properties of subgraph matching\nover a distributed graph, we introduce local partial match as partial answers\nin each fragment of RDF graph G. For assembly, we propose two methods:\ncentralized and distributed assembly. We analyze our algorithms from both\ntheoretically and experimentally. Extensive experiments over both real and\nbenchmark RDF repositories of billions of triples confirm that our method is\nsuperior to the state-of-the-art methods in both the system's performance and\nscalability.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 08:36:58 GMT"}, {"version": "v2", "created": "Wed, 9 Dec 2015 07:20:19 GMT"}, {"version": "v3", "created": "Sat, 27 Feb 2016 03:00:53 GMT"}, {"version": "v4", "created": "Mon, 21 Mar 2016 13:58:00 GMT"}], "update_date": "2016-03-22", "authors_parsed": [["Peng", "Peng", ""], ["Zou", "Lei", ""], ["\u00d6zsu", "M. Tamer", ""], ["Chen", "Lei", ""], ["Zhao", "Dongyan", ""]]}, {"id": "1411.6767", "submitter": "Debajyoti Mukhopadhyay Prof.", "authors": "Vijayata Waghmare, Debajyoti Mukhopadhyay", "title": "Mobile Agent based Market Basket Analysis on Cloud", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the design and development of a location-based mobile\nshopping application for bakery product shops. Whole application is deployed on\ncloud. The three-tier architecture consists of, front-end, middle-ware and\nback-end. The front-end level is a location-based mobile shopping application\nfor android mobile devices, for purchasing bakery products of nearby places.\nFront-end level also displays association among the purchased products. The\nmiddle-ware level provides a web service to generate JSON (JavaScript Object\nNotation) output from the relational database. It exchanges information and\ndata between mobile application and servers in cloud. The back-end level\nprovides the Apache Tomcat Web server and MySQL database. The application also\nuses the Google Cloud Messaging for generating and sending notification of\norders to shopkeeper.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 08:51:45 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Waghmare", "Vijayata", ""], ["Mukhopadhyay", "Debajyoti", ""]]}, {"id": "1411.6775", "submitter": "Debajyoti Mukhopadhyay Prof.", "authors": "Debajyoti Mukhopadhyay, Chetan Agrawal, Devesh Maru, Pooja Yedale,\n  Pranav Gadekar", "title": "Addressing NameNode Scalability Issue in Hadoop Distributed File System\n  using Cache Approach", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hadoop is a distributed batch processing infrastructure which is currently\nbeing used for big data management. The foundation of Hadoop consists of Hadoop\nDistributed File System or HDFS. HDFS presents a client server architecture\ncomprised of a NameNode and many DataNodes. The NameNode stores the metadata\nfor the DataNodes and DataNode stores application data. The NameNode holds file\nsystem metadata in memory, and thus the limit to the number of files in a file\nsystem is governed by the amount of memory on the NameNode. Thus when the\nmemory on NameNode is full there is no further chance of increasing the cluster\ncapacity. In this paper we have used the concept of cache memory for handling\nthe issue of NameNode scalability. The focus of this paper is to highlight our\napproach that tries to enhance the current architecture and ensure that\nNameNode does not reach its threshold value soon.\n", "versions": [{"version": "v1", "created": "Tue, 25 Nov 2014 09:10:29 GMT"}], "update_date": "2014-11-26", "authors_parsed": [["Mukhopadhyay", "Debajyoti", ""], ["Agrawal", "Chetan", ""], ["Maru", "Devesh", ""], ["Yedale", "Pooja", ""], ["Gadekar", "Pranav", ""]]}, {"id": "1411.7131", "submitter": "Oussama Tahan PhD", "authors": "Oussama Tahan", "title": "Towards Efficient OpenMP Strategies for Non-Uniform Architectures", "comments": "International Journal of Advanced Studies in Computer Science and\n  Engineering (IJASCSE)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel processing is considered as todays and future trend for improving\nperformance of computers. Computing devices ranging from small embedded systems\nto big clusters of computers rely on parallelizing applications to reduce\nexecution time. Many of current computing systems rely on Non-Uniform Memory\nAccess (NUMA) based processors architectures. In these architectures, analyzing\nand considering the non-uniformity is of high importance for improving\nscalability of systems. In this paper, we analyze and develop a NUMA based\napproach for the OpenMP parallel programming model. Our technique applies a\nsmart threads allocation method and an advanced tasks scheduling strategy for\nreducing remote memory accesses and consequently their extra time consumption.\nWe implemented our approach within the NANOS runtime system. A set of tests was\nconducted using the BOTS benchmarks and results showed the capacity of our\ntechnique in improving the performance of OpenMP applications especially those\ndealing with a large amount of data.\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 08:15:52 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Tahan", "Oussama", ""]]}, {"id": "1411.7344", "submitter": "Abm Moniruzzaman", "authors": "A B M Moniruzzaman", "title": "Analysis of Memory Ballooning Technique for Dynamic Memory Management of\n  Virtual Machines (VMs)", "comments": "11 pages and 07 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Memory ballooning is dynamic memory management technique for virtual machines\n(VMs). Ballooning is a part of memory reclamation technique operations used by\na hypervisor to allow the physical host system to retrieve unused memory from\ncertain guest virtual machines (VMs) and share it with others. Memory\nballooning allows the total amount ofRAM required by guest VMs to exceed the\namount ofphysical RAM available on the host. Memory overcommitment enables a\nhigher consolidation ratio in a hypervisor. Using memory overcommitment, users\ncan consolidate VMs on a physical machine such that physical resources are\nutilized in an optimal manner while delivering good performance. Hence memory\nreclamation is an integral component ofmemory overcommitment. In this paper, we\naddress that the basic cause of memory that ballooning is memory overcommitment\nfrom using memory-intensive virtual machines. We compared to others reclamation\ntechnique and identify Cost Associate with Memory Ballooning in state of Memory\nOvercommitment. The objective of this paper is to analyse memory ballooning\ntechnique for dynamic memory management of VMs. For this analysis, VMware based\nvirtualization software e.g ESXi Server, vCenter Server, vSphere Client are\ninstalled and configured on the Centre for Innovation and Technology (CIT) Lab,\nDIU; for monitor and analyze VM performance for memory ballooning technique.\nThe performance ofmemory ballooning technique is evaluated with two different\ntest cases. The purpose is to help users understand, how this technique impact\nthe performance. Finally, we presents the throughput ofheavy workload with\ndifferent memory limits when using ballooning or swapping; and analyse VM\nperformance issue for this technique.\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 19:33:13 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Moniruzzaman", "A B M", ""]]}, {"id": "1411.7359", "submitter": "Alejandro Salinger", "authors": "Arash Farzan, Alejandro L\\'opez-Ortiz, Patrick K. Nicholson, Alejandro\n  Salinger", "title": "Algorithms in the Ultra-Wide Word Model", "comments": "28 pages, 5 figures; minor changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effective use of parallel computing resources to speed up algorithms in\ncurrent multi-core parallel architectures remains a difficult challenge, with\nease of programming playing a key role in the eventual success of various\nparallel architectures. In this paper we consider an alternative view of\nparallelism in the form of an ultra-wide word processor. We introduce the\nUltra-Wide Word architecture and model, an extension of the word-RAM model that\nallows for constant time operations on thousands of bits in parallel. Word\nparallelism as exploited by the word-RAM model does not suffer from the more\ndifficult aspects of parallel programming, namely synchronization and\nconcurrency. For the standard word-RAM algorithms, the speedups obtained are\nmoderate, as they are limited by the word size. We argue that a large class of\nword-RAM algorithms can be implemented in the Ultra-Wide Word model, obtaining\nspeedups comparable to multi-threaded computations while keeping the simplicity\nof programming of the sequential RAM model. We show that this is the case by\ndescribing implementations of Ultra-Wide Word algorithms for dynamic\nprogramming and string searching. In addition, we show that the Ultra-Wide Word\nmodel can be used to implement a nonstandard memory architecture, which enables\nthe sidestepping of lower bounds of important data structure problems such as\npriority queues and dynamic prefix sums. While similar ideas about operating on\nlarge words have been mentioned before in the context of multimedia processors\n[Thorup 2003], it is only recently that an architecture like the one we propose\nhas become feasible and that details can be worked out.\n", "versions": [{"version": "v1", "created": "Wed, 26 Nov 2014 20:25:27 GMT"}, {"version": "v2", "created": "Sun, 7 Dec 2014 17:36:42 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["Farzan", "Arash", ""], ["L\u00f3pez-Ortiz", "Alejandro", ""], ["Nicholson", "Patrick K.", ""], ["Salinger", "Alejandro", ""]]}, {"id": "1411.7507", "submitter": "Akshay  M S Mr", "authors": "Akshay MS, Suhas Mohan, Vincent Kuri, Dinkar Sitaram, H. L.\n  Phalachandra", "title": "Efficient Support of Big Data Storage Systems on the Cloud", "comments": "Presented at 2nd International Workshop on Cloud Computing\n  Applications (ICWA) during IEEE International Conference on High Performance\n  Computing (HiPC) 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its advantages over traditional data centers, there has been a rapid\ngrowth in the usage of cloud infrastructures. These include public clouds\n(e.g., Amazon EC2), or private clouds, such as clouds deployed using OpenStack.\nA common factor in many of the well known infrastructures, for example\nOpenStack and CloudStack, is that networked storage is used for storage of\npersistent data. However, traditional Big Data systems, including Hadoop, store\ndata in commodity local storage for reasons of high performance and low cost.\nWe present an architecture for supporting Hadoop on Openstack using local\nstorage. Subsequently, we use benchmarks on Openstack and Amazon to show that\nfor supporting Hadoop, local storage has better performance and lower cost. We\nconclude that cloud systems should support local storage for persistent data\n(in addition to networked storage) so as to provide efficient support for\nHadoop and other Big Data systems\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 09:25:54 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["MS", "Akshay", ""], ["Mohan", "Suhas", ""], ["Kuri", "Vincent", ""], ["Sitaram", "Dinkar", ""], ["Phalachandra", "H. L.", ""]]}, {"id": "1411.7612", "submitter": "Drona Pratap Chandu", "authors": "Drona Pratap Chandu", "title": "A Parallel Genetic Algorithm for Generalized Vertex Cover Problem", "comments": "4 pages, 3 figures, ISSN: 0975-9646. arXiv admin note: substantial\n  text overlap with arXiv:1411.4565", "journal-ref": "International Journal of Computer Science and Information\n  Technologies (IJCSIT), Vol. 5 (6) , 2014, 7686-7689", "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper presents a parallel genetic algorithm for generalised vertex cover\nproblem (GVCP) using Hadoop Map-Reduce framework. The proposed Map-Reduce\nimplementation helps to run the genetic algorithm for generalized vertex cover\nproblem (GVCP) on multiple machines parallely and computes the solution in\nrelatively short time.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 14:39:43 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Chandu", "Drona Pratap", ""]]}, {"id": "1411.7639", "submitter": "Debajyoti Mukhopadhyay Prof.", "authors": "Sayalee Narkhede, Trupti Baraskar, Debajyoti Mukhopadhyay", "title": "Analyzing Web Application Log Files to Find Hit Count Through the\n  Utilization of Hadoop MapReduce in Cloud Computing Environment", "comments": "6 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MapReduce has been widely applied in various fields of data and compute\nintensive applications and also it is important programming model for cloud\ncomputing. Hadoop is an open-source implementation of MapReduce which operates\non terabytes of data using commodity hardware. We have applied this Hadoop\nMapReduce programming model for analyzing web log files so that we could get\nhit count of specific web application. This system uses Hadoop file system to\nstore log file and results are evaluated using Map and Reduce function.\nExperimental results show hit count for each field in log file. Also due to\nMapReduce runtime parallelization response time is reduced.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 16:42:44 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Narkhede", "Sayalee", ""], ["Baraskar", "Trupti", ""], ["Mukhopadhyay", "Debajyoti", ""]]}, {"id": "1411.7658", "submitter": "Abm Moniruzzaman", "authors": "A B M Moniruzzaman, Md. Waliullah, Md. Sadekur Rahman", "title": "A High Availability Clusters Model Combined with Load Balancing and\n  Shared Storage Technologies for Web Servers", "comments": "6 pages. arXiv admin note: text overlap with arXiv:1311.3070 by other\n  authors", "journal-ref": "International Journal of Scientific & Engineering Research, Volume\n  5, Issue 12, December-2014", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper designs and implements a high availability clusters and\nincorporated with load balance infrastructure of web servers. The paper\ndescribed system can provide full facilities to the website hosting provider\nand large business organizations. This system can provide continuous service\nthough any system components fail uncertainly with the help of Linux Virtual\nServer (LVS) loadbalancing cluster technology and combined with virtualization\nas well as shared storage technology to achieve the three-tier architecture of\nWeb server clusters. This technology not only improves availability, but also\naffects the security and performance of the application services being\nrequested. Benefits of the system include node failover overcome; network\nfailover overcome; storage limitation overcome and load distribution.\n", "versions": [{"version": "v1", "created": "Thu, 27 Nov 2014 17:29:28 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Moniruzzaman", "A B M", ""], ["Waliullah", "Md.", ""], ["Rahman", "Md. Sadekur", ""]]}, {"id": "1411.7910", "submitter": "Diego Didona Mr", "authors": "Pierangelo Di Sanzo, Francesco Quaglia, Bruno Ciciani, Alessandro\n  Pellegrini, Diego Didona, Paolo Romano, Roberto Palmieri, Sebastiano Peluso", "title": "A Flexible Framework for Accurate Simulation of Cloud In-Memory Data\n  Stores", "comments": "34 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-memory (transactional) data stores are recognized as a first-class data\nmanagement technology for cloud platforms, thanks to their ability to match the\nelasticity requirements imposed by the pay-as-you-go cost model. On the other\nhand, defining the well-suited amount of cache servers to be deployed, and the\ndegree of in-memory replication of slices of data, in order to optimize\nreliability/availability and performance tradeoffs, is far from being a trivial\ntask. Yet, it is an essential aspect of the provisioning process of cloud\nplatforms, given that it has an impact on how well cloud resources are actually\nexploited. To cope with the issue of determining optimized configurations of\ncloud in-memory data stores, in this article we present a flexible simulation\nframework offering skeleton simulation models that can be easily specialized in\norder to capture the dynamics of diverse data grid systems, such as those\nrelated to the specific protocol used to provide data consistency and/or\ntransactional guarantees. Besides its flexibility, another peculiar aspect of\nthe framework lies in that it integrates simulation and machine-learning\n(black-box) techniques, the latter being essentially used to capture the\ndynamics of the data-exchange layer (e.g. the message passing layer) across the\ncache servers. This is a relevant aspect when considering that the actual\ndata-transport/networking infrastructure on top of which the data grid is\ndeployed might be unknown, hence being not feasible to be modeled via white-box\n(namely purely simulative) approaches. We also provide an extended experimental\nstudy aimed at validating instances of simulation models supported by our\nframework against execution dynamics of real data grid systems deployed on top\nof either private or public cloud infrastructures.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2014 15:38:23 GMT"}], "update_date": "2014-12-01", "authors_parsed": [["Di Sanzo", "Pierangelo", ""], ["Quaglia", "Francesco", ""], ["Ciciani", "Bruno", ""], ["Pellegrini", "Alessandro", ""], ["Didona", "Diego", ""], ["Romano", "Paolo", ""], ["Palmieri", "Roberto", ""], ["Peluso", "Sebastiano", ""]]}]