[{"id": "1412.0041", "submitter": "Liang Wang", "authors": "Liang Wang and Gareth Tyson and Jussi Kangasharju and Jon Crowcroft", "title": "FairCache: Introducing Fairness to ICN Caching - Technical Report", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.GT cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information-centric networking extensively uses universal in-network caching.\nHowever, developing an efficient and fair collaborative caching algorithm for\nselfish caches is still an open question. In addition, the communication\noverhead induced by collaboration is especially poorly understood in a general\nnetwork setting such as realistic ISP and Autonomous System networks. In this\npaper, we address these two problems by modeling the in-network caching problem\nas a Nash bargaining game. We show that the game is a convex optimization\nproblem and further derive the corresponding distributed algorithm. We\nanalytically investigate the collaboration overhead on general graph\ntopologies, and theoretically show that collaboration has to be constrained\nwithin a small neighborhood due to its cost growing exponentially. Our proposed\nalgorithm achieves at least 16% performance gain over its competitors on\ndifferent network topologies in the evaluation, and guarantees provable\nconvergence, Pareto efficiency and proportional fairness.\n", "versions": [{"version": "v1", "created": "Fri, 28 Nov 2014 22:16:00 GMT"}, {"version": "v2", "created": "Wed, 30 Sep 2015 16:13:40 GMT"}, {"version": "v3", "created": "Thu, 28 Jan 2016 11:32:49 GMT"}, {"version": "v4", "created": "Tue, 2 May 2017 11:40:24 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Wang", "Liang", ""], ["Tyson", "Gareth", ""], ["Kangasharju", "Jussi", ""], ["Crowcroft", "Jon", ""]]}, {"id": "1412.0595", "submitter": "Naresh Balaji", "authors": "Naresh Balaji, Esin Yavuz, Thomas Nowotny", "title": "Scalability and Optimization Strategies for GPU Enhanced Neural Networks\n  (GeNN)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation of spiking neural networks has been traditionally done on\nhigh-performance supercomputers or large-scale clusters. Utilizing the parallel\nnature of neural network computation algorithms, GeNN (GPU Enhanced Neural\nNetwork) provides a simulation environment that performs on General Purpose\nNVIDIA GPUs with a code generation based approach. GeNN allows the users to\ndesign and simulate neural networks by specifying the populations of neurons at\ndifferent stages, their synapse connection densities and the model of\nindividual neurons. In this report we describe work on how to scale synaptic\nweights based on the configuration of the user-defined network to ensure\nsufficient spiking and subsequent effective learning. We also discuss\noptimization strategies particular to GPU computing: sparse representation of\nsynapse connections and occupancy based block-size determination.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2014 19:12:54 GMT"}], "update_date": "2014-12-02", "authors_parsed": [["Balaji", "Naresh", ""], ["Yavuz", "Esin", ""], ["Nowotny", "Thomas", ""]]}, {"id": "1412.0659", "submitter": "Jeroen B\\'edorf", "authors": "Jeroen B\\'edorf, Evghenii Gaburov, Michiko S. Fujii, Keigo Nitadori,\n  Tomoaki Ishiyama and Simon Portegies Zwart", "title": "24.77 Pflops on a Gravitational Tree-Code to Simulate the Milky Way\n  Galaxy with 18600 GPUs", "comments": "12 pages, 4 figures, Published in: 'Proceeding SC '14 Proceedings of\n  the International Conference for High Performance Computing, Networking,\n  Storage and Analysis'. Gordon Bell Prize 2014 finalist", "journal-ref": null, "doi": "10.1109/SC.2014.10", "report-no": null, "categories": "astro-ph.GA astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have simulated, for the first time, the long term evolution of the Milky\nWay Galaxy using 51 billion particles on the Swiss Piz Daint supercomputer with\nour $N$-body gravitational tree-code Bonsai. Herein, we describe the scientific\nmotivation and numerical algorithms. The Milky Way model was simulated for 6\nbillion years, during which the bar structure and spiral arms were fully\nformed. This improves upon previous simulations by using 1000 times more\nparticles, and provides a wealth of new data that can be directly compared with\nobservations. We also report the scalability on both the Swiss Piz Daint and\nthe US ORNL Titan. On Piz Daint the parallel efficiency of Bonsai was above\n95%. The highest performance was achieved with a 242 billion particle Milky Way\nmodel using 18600 GPUs on Titan, thereby reaching a sustained GPU and\napplication performance of 33.49 Pflops and 24.77 Pflops respectively.\n", "versions": [{"version": "v1", "created": "Mon, 1 Dec 2014 21:00:06 GMT"}], "update_date": "2014-12-03", "authors_parsed": [["B\u00e9dorf", "Jeroen", ""], ["Gaburov", "Evghenii", ""], ["Fujii", "Michiko S.", ""], ["Nitadori", "Keigo", ""], ["Ishiyama", "Tomoaki", ""], ["Zwart", "Simon Portegies", ""]]}, {"id": "1412.0981", "submitter": "Sergey Vostokin", "authors": "Sergey Vostokin", "title": "Templet: a Markup Language for Concurrent Programming", "comments": "13 pages", "journal-ref": null, "doi": "10.18287/1613-0073-2016-1638-460-468", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a new approach to the description of a network of\ninteracting processes in a traditional programming language. Special\nprogramming languages or extensions to sequential languages are usually\ndesigned to express the semantics of concurrent execution. Using libraries in\nC++, Java, C#, and other languages is more practical way of concurrent\nprogramming. However, this method leads to an increase in workload of a manual\ncoding. Besides, stock compilers can not detect semantic errors related to the\nprogramming model in such libraries. The new markup language and a special\ntechnique of automatic programming based on the marked code can solve these\nproblems. The article provides a detailed specification of the markup language\nwithout discussing its implementation details. The language is used for\nprogramming of current and prospective multi-core and many-core systems.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 17:06:28 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Vostokin", "Sergey", ""]]}, {"id": "1412.1127", "submitter": "Ahmad Lashgar", "authors": "Ahmad Lashgar and Alireza Majidi and Amirali Baniasadi", "title": "IPMACC: Open Source OpenACC to CUDA/OpenCL Translator", "comments": "14 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce IPMACC, a framework for translating OpenACC\napplications to CUDA or OpenCL. IPMACC is composed of set of translators\ntranslating OpenACC for C applications to CUDA or OpenCL. The framework uses\nthe system compiler (e.g. nvcc) for generating final accelerator's binary. The\nframework can be used for extending the OpenACC API, executing OpenACC\napplications, or obtaining CUDA or OpenCL code which is equivalent to OpenACC\ncode. We verify correctness of our framework under several benchmarks included\nfrom Rodinia Benchmark Suit and CUDA SDK. We also compare the performance of\nCUDA version of the benchmarks to OpenACC version which is compiled by our\nframework. By comparing CUDA and OpenACC versions, we discuss the limitations\nof OpenACC in achieving a performance near to highly-optimized CUDA version.\n", "versions": [{"version": "v1", "created": "Tue, 2 Dec 2014 22:49:14 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Lashgar", "Ahmad", ""], ["Majidi", "Alireza", ""], ["Baniasadi", "Amirali", ""]]}, {"id": "1412.1297", "submitter": "Mariza Ferro", "authors": "Mariza Ferro and Antonio R. Mury and Laion F. Manfroi and Bruno Schlze", "title": "High Performance Computing Evaluation A methodology based on Scientific\n  Application Requirements", "comments": "29 pages, 2 tables and 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High Performance Distributed Computing is essential to boost scientific\nprogress in many areas of science and to efficiently deploy a number of complex\nscientific applications. These applications have different characteristics that\nrequire distinct computational resources too. In this work we propose a\nsystematic performance evaluation methodology. The focus of our methodology\nbegins on scientific application characteristics, and then considers how these\ncharacteristics interact with the problem size, with the programming language\nand finally with a specific computational architecture. The computational\nexperiments developed highlight this model of evaluation and indicate that\noptimal performance is found when we evaluate a combination of application\nclass, program language, problem size and architecture model.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 12:25:27 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Ferro", "Mariza", ""], ["Mury", "Antonio R.", ""], ["Manfroi", "Laion F.", ""], ["Schlze", "Bruno", ""]]}, {"id": "1412.1419", "submitter": "John Allen", "authors": "John Allen, David Scott, Malcolm Illingworth, Bartek Dobrzelecki, Davy\n  Virdee, Steve Thorn, Sara Knott", "title": "CloudQTL: Evolving a Bioinformatics Application to the Cloud", "comments": "12 pages, 3 figures, EGI conference Madrid 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A timeline is presented which shows the stages involved in converting a\nbioinformatics software application from a set of standalone algorithms through\nto a simple web based tool then to a web based portal harnessing Grid\ntechnologies and on to its latest inception as a Cloud based bioinformatics web\ntool. The nature of the software is discussed together with a description of\nits development at various stages including a detailed account of the Cloud\nservice. An outline of user results is also included.\n", "versions": [{"version": "v1", "created": "Wed, 3 Dec 2014 18:06:08 GMT"}], "update_date": "2014-12-04", "authors_parsed": [["Allen", "John", ""], ["Scott", "David", ""], ["Illingworth", "Malcolm", ""], ["Dobrzelecki", "Bartek", ""], ["Virdee", "Davy", ""], ["Thorn", "Steve", ""], ["Knott", "Sara", ""]]}, {"id": "1412.1576", "submitter": "Xun Zheng", "authors": "Jinhui Yuan, Fei Gao, Qirong Ho, Wei Dai, Jinliang Wei, Xun Zheng,\n  Eric P. Xing, Tie-Yan Liu, Wei-Ying Ma", "title": "LightLDA: Big Topic Models on Modest Compute Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When building large-scale machine learning (ML) programs, such as big topic\nmodels or deep neural nets, one usually assumes such tasks can only be\nattempted with industrial-sized clusters with thousands of nodes, which are out\nof reach for most practitioners or academic researchers. We consider this\nchallenge in the context of topic modeling on web-scale corpora, and show that\nwith a modest cluster of as few as 8 machines, we can train a topic model with\n1 million topics and a 1-million-word vocabulary (for a total of 1 trillion\nparameters), on a document collection with 200 billion tokens -- a scale not\nyet reported even with thousands of machines. Our major contributions include:\n1) a new, highly efficient O(1) Metropolis-Hastings sampling algorithm, whose\nrunning cost is (surprisingly) agnostic of model size, and empirically\nconverges nearly an order of magnitude faster than current state-of-the-art\nGibbs samplers; 2) a structure-aware model-parallel scheme, which leverages\ndependencies within the topic model, yielding a sampling strategy that is\nfrugal on machine memory and network communication; 3) a differential\ndata-structure for model storage, which uses separate data structures for high-\nand low-frequency words to allow extremely large models to fit in memory, while\nmaintaining high inference speed; and 4) a bounded asynchronous data-parallel\nscheme, which allows efficient distributed processing of massive data via a\nparameter server. Our distribution strategy is an instance of the\nmodel-and-data-parallel programming model underlying the Petuum framework for\ngeneral distributed ML, and was implemented on top of the Petuum open-source\nsystem. We provide experimental evidence showing how this development puts\nmassive models within reach on a small cluster while still enjoying\nproportional time cost reductions with increasing cluster size, in comparison\nwith alternative options.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 07:49:12 GMT"}], "update_date": "2014-12-05", "authors_parsed": [["Yuan", "Jinhui", ""], ["Gao", "Fei", ""], ["Ho", "Qirong", ""], ["Dai", "Wei", ""], ["Wei", "Jinliang", ""], ["Zheng", "Xun", ""], ["Xing", "Eric P.", ""], ["Liu", "Tie-Yan", ""], ["Ma", "Wei-Ying", ""]]}, {"id": "1412.1741", "submitter": "Sabri Pllana", "authors": "Suejb Memeti and Sabri Pllana", "title": "PaREM: A Novel Approach for Parallel Regular Expression Matching", "comments": "CSE-2014, Dec. 19th - 21st, 2014, Chengdu, Sichuan, China", "journal-ref": null, "doi": "10.1109/CSE.2014.146", "report-no": null, "categories": "cs.FL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regular expression matching is essential for many applications, such as\nfinding patterns in text, exploring substrings in large DNA sequences, or\nlexical analysis. However, sequential regular expression matching may be\ntime-prohibitive for large problem sizes. In this paper, we describe a novel\nalgorithm for parallel regular expression matching via deterministic finite\nautomata. Furthermore, we present our tool PaREM that accepts regular\nexpressions and finite automata as input and automatically generates the\ncorresponding code for our algorithm that is amenable for parallel execution on\nshared-memory systems. We evaluate our parallel algorithm empirically by\ncomparing it with a commonly used algorithm for sequential regular expression\nmatching. Experiments on a dual-socket shared-memory system with 24 physical\ncores show speed-ups of up to 21x for 48 threads.\n", "versions": [{"version": "v1", "created": "Thu, 4 Dec 2014 17:39:34 GMT"}, {"version": "v2", "created": "Mon, 29 Jun 2015 13:46:26 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Memeti", "Suejb", ""], ["Pllana", "Sabri", ""]]}, {"id": "1412.1885", "submitter": "Guoxu Zhou", "authors": "Guoxu Zhou and Andrzej Cichocki and Shengli Xie", "title": "Decomposition of Big Tensors With Low Multilinear Rank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tensor decompositions are promising tools for big data analytics as they\nbring multiple modes and aspects of data to a unified framework, which allows\nus to discover complex internal structures and correlations of data.\nUnfortunately most existing approaches are not designed to meet the major\nchallenges posed by big data analytics. This paper attempts to improve the\nscalability of tensor decompositions and provides two contributions: A flexible\nand fast algorithm for the CP decomposition (FFCP) of tensors based on their\nTucker compression; A distributed randomized Tucker decomposition approach for\narbitrarily big tensors but with relatively low multilinear rank. These two\nalgorithms can deal with huge tensors, even if they are dense. Extensive\nsimulations provide empirical evidence of the validity and efficiency of the\nproposed algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 5 Dec 2014 03:04:32 GMT"}, {"version": "v2", "created": "Mon, 29 Dec 2014 02:39:53 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Zhou", "Guoxu", ""], ["Cichocki", "Andrzej", ""], ["Xie", "Shengli", ""]]}, {"id": "1412.2109", "submitter": "Janne H. Korhonen", "authors": "Petteri Kaski, Janne H. Korhonen, Christoph Lenzen, Jukka Suomela", "title": "Algebrisation in Distributed Graph Algorithms: Fast Matrix\n  Multiplication in the Congested Clique", "comments": "This paper has been withdrawn by the authors. This paper has been\n  superseded by arXiv:1503.04963 (merged from arXiv:1412.2109 and\n  arXiv:1412.2667)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While algebrisation constitutes a powerful technique in the design and\nanalysis of centralised algorithms, to date there have been hardly any\napplications of algebraic techniques in the context of distributed graph\nalgorithms. This work is a case study that demonstrates the potential of\nalgebrisation in the distributed context. We will focus on distributed graph\nalgorithms in the congested clique model; the graph problems that we will\nconsider include, e.g., the triangle detection problem and the all-pairs\nshortest path problem (APSP). There is plenty of prior work on combinatorial\nalgorithms in the congested clique model: for example, Dolev et al. (DISC 2012)\ngave an algorithm for triangle detection with a running time of $\\tilde\nO(n^{1/3})$, and Nanongkai (STOC 2014) gave an approximation algorithm for APSP\nwith a running time of $\\tilde O(n^{1/2})$. In this work, we will use algebraic\ntechniques -- in particular, algorithms based on fast matrix multiplication --\nto solve both triangle detection and the unweighted APSP in time\n$O(n^{0.15715})$; for weighted APSP, we give a $(1+o(1))$-approximation with\nthis running time, as well as an exact $\\tilde O(n^{1/3})$ solution.\n", "versions": [{"version": "v1", "created": "Fri, 5 Dec 2014 19:33:46 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2015 09:52:27 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Kaski", "Petteri", ""], ["Korhonen", "Janne H.", ""], ["Lenzen", "Christoph", ""], ["Suomela", "Jukka", ""]]}, {"id": "1412.2123", "submitter": "Dawsen Hwang", "authors": "Dawsen Hwang, Patrick Jaillet, Zhengyuan Zhou", "title": "Distributed Multi-Depot Routing without Communications", "comments": "10 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider and formulate a class of distributed multi-depot routing\nproblems, where servers are to visit a set of requests, with the aim of\nminimizing the total distance travelled by all servers. These problems fall\ninto two categories: distributed offline routing problems where all the\nrequests that need to be visited are known from the start; distributed online\nrouting problems where the requests come to be known incrementally. A critical\nand novel feature of our formulations is that communications are not allowed\namong the servers, hence posing an interesting and challenging question: what\nperformance can be achieved in comparison to the best possible solution\nobtained from an omniscience planner with perfect communication capabilities?\nThe worst-case (over all possible request-set instances) performance metrics\nare given by the approximation ratio (offline case) and the competitive ratio\n(online case).\n  Our first result indicates that the online and offline problems are\neffectively equivalent: for the same request-set instance, the approximation\nratio and the competitive ratio differ by at most an additive factor of 2,\nirrespective of the release dates in the online case. Therefore, we can\nrestrict our attention to the offline problem. For the offline problem, we show\nthat the approximation ratio given by the Voronoi partition is m (the number of\nservers). For two classes of depot configurations, when the depots form a line\nand when the ratios between the distances of pairs of depots are upper bounded\nby a sublinear function f(m) (i.e., f(m) = o(m)), we give partition schemes\nwith sublinear approximation ratios O(log m) and {\\Theta}(f(m)) respectively.\nWe also discuss several interesting open problems in our formulations: in\nparticular, how our initial results (on the two deliberately chosen classes of\ndepots) shape our conjecture on the open problems.\n", "versions": [{"version": "v1", "created": "Fri, 5 Dec 2014 20:14:58 GMT"}], "update_date": "2014-12-08", "authors_parsed": [["Hwang", "Dawsen", ""], ["Jaillet", "Patrick", ""], ["Zhou", "Zhengyuan", ""]]}, {"id": "1412.2333", "submitter": "Vivek B. Sardeshmukh", "authors": "Sriram V. Pemmaraju and Vivek B. Sardeshmukh", "title": "Minimum-weight Spanning Tree Construction in $O(\\log \\log \\log n)$\n  Rounds on the Congested Clique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the \\textit{minimum spanning tree (MST)} problem in the\nCongested Clique model and presents an algorithm that runs in $O(\\log \\log \\log\nn)$ rounds, with high probability. Prior to this, the fastest MST algorithm in\nthis model was a deterministic algorithm due to Lotker et al.~(SIAM J on Comp,\n2005) from about a decade ago. A key step along the way to designing this MST\nalgorithm is a \\textit{connectivity verification} algorithm that not only runs\nin $O(\\log \\log \\log n)$ rounds with high probability, but also has low message\ncomplexity. This allows the fast computation of an MST by running multiple\ninstances of the connectivity verification algorithm in parallel. These results\ndepend on a new edge-sampling theorem, developed in the paper, that says that\nif each edge $e = \\{u, v\\}$ is sampled independently with probability $c \\log^2\nn/\\min\\{\\mbox{degree}(u), \\mbox{degree}(v)\\}$ (for a large enough constant $c$)\nthen all cuts of size at least $n$ are approximated in the sampled graph. This\nsampling theorem is inspired by series of papers on graph sparsification via\nrandom edge sampling due to Karger~(STOC 1994), Bencz\\'ur and Karger~(STOC\n1996, arxiv 2002), and Fung et al.~(STOC 2011). The edge sampling techniques in\nthese papers use probabilities that are functions of edge-connectivity or a\nrelated measure called edge-strength. For the purposes of this paper, these\nedge-connectivity measures seem too costly to compute and the main technical\ncontribution of this paper is to show that degree-based edge-sampling suffices\nto approximate large cuts.\n", "versions": [{"version": "v1", "created": "Sun, 7 Dec 2014 09:29:42 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["Pemmaraju", "Sriram V.", ""], ["Sardeshmukh", "Vivek B.", ""]]}, {"id": "1412.2385", "submitter": "Alexey Finogeev Prof.", "authors": "Valery Kamaev, Alexey Finogeev, Anton Finogeev, Sergey Shevchenko", "title": "Knowledge Discovery in the SCADA Databases Used for the Municipal Power\n  Supply System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This scientific paper delves into the problems related to the develop-ment of\nintellectual data analysis system that could support decision making to manage\nmunicipal power supply services. The management problems of mu-nicipal power\nsupply system have been specified taking into consideration modern tendencies\nshown by new technologies that allow for an increase in the energy efficiency.\nThe analysis findings of the system problems related to the integrated\ncomputer-aided control of the power supply for the city have been given. The\nconsideration was given to the hierarchy-level management decom-position model.\nThe objective task targeted at an increase in the energy effi-ciency to\nminimize expenditures and energy losses during the generation and\ntransportation of energy carriers to the Consumer, the optimization of power\nconsumption at the prescribed level of the reliability of pipelines and\nnetworks and the satisfaction of Consumers has been defined. To optimize the\nsupport of the decision making a new approach to the monitoring of engineering\nsystems and technological processes related to the energy consumption and\ntransporta-tion using the technologies of geospatial analysis and Knowledge\nDiscovery in databases (KDD) has been proposed. The data acquisition for\nanalytical prob-lems is realized in the wireless heterogeneous medium, which\nincludes soft-touch VPN segments of ZigBee technology realizing the 6LoWPAN\nstandard over the IEEE 802.15.4 standard and also the segments of the networks\nof cellu-lar communications. JBoss Application Server is used as a server-based\nplat-form for the operation of the tools used for the retrieval of data\ncollected from sensor nodes, PLC and energy consumption record devices. The KDD\ntools are developed using Java Enterprise Edition platform and Spring and ORM\nHiber-nate technologies.\n", "versions": [{"version": "v1", "created": "Sun, 7 Dec 2014 18:57:36 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["Kamaev", "Valery", ""], ["Finogeev", "Alexey", ""], ["Finogeev", "Anton", ""], ["Shevchenko", "Sergey", ""]]}, {"id": "1412.2432", "submitter": "Edward Meeds", "authors": "Edward Meeds and Remco Hendriks and Said Al Faraby and Magiel Bruntink\n  and Max Welling", "title": "MLitB: Machine Learning in the Browser", "comments": "Revised for PeerJ Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With few exceptions, the field of Machine Learning (ML) research has largely\nignored the browser as a computational engine. Beyond an educational resource\nfor ML, the browser has vast potential to not only improve the state-of-the-art\nin ML research, but also, inexpensively and on a massive scale, to bring\nsophisticated ML learning and prediction to the public at large. This paper\nintroduces MLitB, a prototype ML framework written entirely in JavaScript,\ncapable of performing large-scale distributed computing with heterogeneous\nclasses of devices. The development of MLitB has been driven by several\nunderlying objectives whose aim is to make ML learning and usage ubiquitous (by\nusing ubiquitous compute devices), cheap and effortlessly distributed, and\ncollaborative. This is achieved by allowing every internet capable device to\nrun training algorithms and predictive models with no software installation and\nby saving models in universally readable formats. Our prototype library is\ncapable of training deep neural networks with synchronized, distributed\nstochastic gradient descent. MLitB offers several important opportunities for\nnovel ML research, including: development of distributed learning algorithms,\nadvancement of web GPU algorithms, novel field and mobile applications, privacy\npreserving computing, and green grid-computing. MLitB is available as open\nsource software.\n", "versions": [{"version": "v1", "created": "Mon, 8 Dec 2014 02:23:40 GMT"}, {"version": "v2", "created": "Wed, 17 Jun 2015 13:11:41 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Meeds", "Edward", ""], ["Hendriks", "Remco", ""], ["Faraby", "Said Al", ""], ["Bruntink", "Magiel", ""], ["Welling", "Max", ""]]}, {"id": "1412.2667", "submitter": "Ami Paz", "authors": "Keren Censor-Hillel and Ami Paz", "title": "Computing Exact Distances in the Congested Clique", "comments": "This paper has been withdrawn by the authors. This paper has been\n  superseded by arXiv:1503.04963 (merged from arXiv:1412.2109 and\n  arXiv:1412.2667)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper gives simple distributed algorithms for the fundamental problem of\ncomputing graph distances in the Congested Clique model. One of the main\ncomponents of our algorithms is fast matrix multiplication, for which we show\nan $O(n^{1/3})$-round algorithm when the multiplication needs to be performed\nover a semi-ring, and an $O(n^{0.157})$-round algorithm when the computation\ncan be performed over a field. We propose to denote by $\\kappa$ the exponent of\nmatrix multiplication in this model, which gives $\\kappa < 0.157$.\n  We show how to compute all-pairs-shortest-paths (APSP) in $O(n^{1/3}\\log{n})$\nrounds in weighted graphs of $n$ nodes, implying also the computation of the\ngraph diameter $D$. In unweighted graphs, APSP can be computed in\n$O(\\min\\{n^{1/3}\\log{D},n^{\\kappa} D\\})$ rounds, and the diameter can be\ncomputed in $O(n^{\\kappa}\\log{D})$ rounds. Furthermore, we show how to compute\nthe girth of a graph in $O(n^{1/3})$ rounds, and provide triangle detection and\n4-cycle detection algorithms that complete in $O(n^{\\kappa})$ rounds.\n  All our algorithms are deterministic. Our triangle detection and 4-cycle\ndetection algorithms improve upon the previously best known algorithms in this\nmodel, and refute a conjecture that $\\tilde \\Omega (n^{1/3})$ rounds are\nrequired for detecting triangles by any deterministic oblivious algorithm. Our\ndistance computation algorithms are exact, and improve upon the previously best\nknown $\\tilde O(n^{1/2})$ algorithm of Nanongkai [STOC 2014] for computing a\n$(2+o(1))$-approximation of APSP.\n  Finally, we give lower bounds that match the above for natural families of\nalgorithms. For the Congested Clique Broadcast model, we derive unconditioned\nlower bounds for matrix multiplication and APSP. The matrix multiplication\nalgorithms and lower bounds are adapted from parallel computations, which is a\nconnection of independent interest.\n", "versions": [{"version": "v1", "created": "Mon, 8 Dec 2014 17:08:11 GMT"}, {"version": "v2", "created": "Sun, 22 Mar 2015 21:25:56 GMT"}], "update_date": "2015-03-24", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Paz", "Ami", ""]]}, {"id": "1412.2673", "submitter": "Marco Guazzone", "authors": "Marco Guazzone", "title": "Mining the Workload of Real Grid Computing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Since the mid 1990s, grid computing systems have emerged as an analogy for\nmaking computing power as pervasive an easily accessible as an electric power\ngrid. Since then, grid computing systems have been shown to be able to provide\nvery large amounts of storage and computing power to mainly support the\nscientific and engineering research on a wide geographic scale. Understanding\nthe workload characteristics incoming to such systems is a milestone for the\ndesign and the tuning of effective resource management strategies. This is\naccomplished through the workload characterization, where workload\ncharacteristics are analyzed and a possibly realistic model for those is\nobtained. In this paper, we study the workload of some real grid systems by\nusing a data mining approach to build a workload model for job interarrival\ntime and runtime, and a Bayesian approach to capture user correlations and\nusage patterns. The final model is then validated against the workload coming\nfrom a real grid system.\n", "versions": [{"version": "v1", "created": "Mon, 8 Dec 2014 17:26:14 GMT"}, {"version": "v2", "created": "Wed, 28 Jan 2015 09:50:07 GMT"}], "update_date": "2015-01-29", "authors_parsed": [["Guazzone", "Marco", ""]]}, {"id": "1412.3022", "submitter": "Nicolas Le Scouarnec", "authors": "Nicolas Le Scouarnec", "title": "Fast Product-Matrix Regenerating Codes", "comments": "6 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed storage systems support failures of individual devices by the use\nof replication or erasure correcting codes. While erasure correcting codes\noffer a better storage efficiency than replication for similar fault tolerance,\nthey incur higher CPU consumption, higher network consumption and higher disk\nI/Os. To address these issues, codes specific to storage systems have been\ndesigned. Their main feature is the ability to repair a single lost disk\nefficiently. In this paper, we focus on one such class of codes that minimize\nnetwork consumption during repair, namely regenerating codes. We implement the\noriginal Product-Matrix Regenerating codes as well as a new optimization we\npropose and show that the resulting optimized codes allow achieving 790 MB/s\nfor encoding in typical settings. Reported speeds are significantly higher than\nprevious studies, highlighting that regenerating codes can be used with little\nCPU penalty.\n", "versions": [{"version": "v1", "created": "Tue, 9 Dec 2014 17:07:52 GMT"}], "update_date": "2014-12-10", "authors_parsed": [["Scouarnec", "Nicolas Le", ""]]}, {"id": "1412.3136", "submitter": "Isaac Sheff", "authors": "Isaac C. Sheff, Robbert van Renesse, Andrew C. Myers", "title": "Distributed Protocols and Heterogeneous Trust: Technical Report", "comments": "This is the technical report of a submission for EuroSys 2015. 26\n  Pages 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.DB cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The robustness of distributed systems is usually phrased in terms of the\nnumber of failures of certain types that they can withstand. However, these\nfailure models are too crude to describe the different kinds of trust and\nexpectations of participants in the modern world of complex, integrated systems\nextending across different owners, networks, and administrative domains. Modern\nsystems often exist in an environment of heterogeneous trust, in which\ndifferent participants may have different opinions about the trustworthiness of\nother nodes, and a single participant may consider other nodes to differ in\ntheir trustworthiness. We explore how to construct distributed protocols that\nmeet the requirements of all participants, even in heterogeneous trust\nenvironments. The key to our approach is using lattice-based information flow\nto analyse and prove protocol properties. To demonstrate this approach, we show\nhow two earlier distributed algorithms can be generalized to work in the\npresence of heterogeneous trust: first, Heterogeneous Fast Consensus, an\nadaptation of the earlier Bosco Fast Consensus protocol; and second, Nysiad, an\nalgorithm for converting crash-tolerant protocols to be Byzantine-tolerant.\nThrough simulations, we show that customizing a protocol to a heterogeneous\ntrust configuration yields performance improvements over the conventional\nprotocol designed for homogeneous trust.\n", "versions": [{"version": "v1", "created": "Tue, 9 Dec 2014 22:09:48 GMT"}], "update_date": "2014-12-11", "authors_parsed": [["Sheff", "Isaac C.", ""], ["van Renesse", "Robbert", ""], ["Myers", "Andrew C.", ""]]}, {"id": "1412.3260", "submitter": "Angelo Furfaro", "authors": "Luciano Argento and Angelo Furfaro", "title": "A multi-protocol framework for the development of collaborative virtual\n  environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative virtual environments (CVEs) are used for collaboration and\ninteraction of possibly many participants that may be spread over large\ndistances. Both commercial and freely available CVEs exist today. Currently,\nCVEs are used already in a variety of different fields: gaming, business,\neducation, social communication, and cooperative development. In this paper, a\ngeneral framework is proposed for the development of a cooperative environment\nwhich is able to exploit a multi protocol network infrastructure. The framework\noffers support to concerns such as communication security and inter-protocol\ninteroperability and let software engineers to focus on the specific business\nof the CVE under development. To show the framework effectiveness we consider,\nas a case of study, the design of a reusable software layer for the development\nof distributed card games built on top of it. This layer is, in turn, used for\nthe implementation of a specific card game.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2014 11:13:18 GMT"}, {"version": "v2", "created": "Wed, 4 Mar 2015 21:02:16 GMT"}], "update_date": "2015-03-06", "authors_parsed": [["Argento", "Luciano", ""], ["Furfaro", "Angelo", ""]]}, {"id": "1412.3367", "submitter": "Arokia Paul Rajan", "authors": "R. Arokia Paul Rajan, F. Sagayaraj Francis", "title": "Experimenting with Request Assignment Simulator (RAS)", "comments": "November 2014, IJCSE", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is no existence of dedicated simulators on the Internet that studies\nthe impact of load balancing principles of the cloud architectures. Request\nAssignment Simulator (RAS) is a customizable, visual tool that helps to\nunderstand the request assignment to the resources based on the load balancing\nprinciples. We have designed this simulator to fit into Infrastructure as a\nService (IaaS) cloud model. In this paper, we present a working manual useful\nfor the conduct of experiment with RAS. The objective of this paper is to\ninstill the user to understand the pertinent parameters in the cloud, their\nmetrics, load balancing principles, and their impact on the performance.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2014 16:54:44 GMT"}], "update_date": "2014-12-11", "authors_parsed": [["Rajan", "R. Arokia Paul", ""], ["Francis", "F. Sagayaraj", ""]]}, {"id": "1412.3445", "submitter": "Stephan Holzer", "authors": "Stephan Holzer, Nathan Pinsker", "title": "Approximation of Distances and Shortest Paths in the Broadcast Congest\n  Clique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the broadcast version of the CONGEST CLIQUE model of distributed\ncomputing. In this model, in each round, any node in a network of size $n$ can\nsend the same message (i.e. broadcast a message) of limited size to every other\nnode in the network. Nanongkai presented in [STOC'14] a randomized\n$(2+o(1))$-approximation algorithm to compute all pairs shortest paths (APSP)\nin time $\\tilde{O}(\\sqrt{n})$ on weighted graphs, where we use the convention\nthat $\\tilde{\\Omega}(f(n))$ is essentially $\\Omega(f(n)/$polylog$f(n))$ and\n$\\tilde{O}(f(n))$ is essentially $O(f(n) $polylog$f(n))$. We complement this\nresult by proving that any randomized $(2-o(1))$-approximation of APSP and\n$(2-o(1))$-approximation of the diameter of a graph takes $\\tilde\\Omega(n)$\ntime in the worst case. This demonstrates that getting a negligible improvement\nin the approximation factor requires significantly more time. Furthermore this\nbound implies that already computing a $(2-o(1))$-approximation of all pairs\nshortest paths is among the hardest graph-problems in the broadcast-version of\nthe CONGEST CLIQUE model and contrasts a recent $(1+o(1))$-approximation for\nAPSP that runs in time $O(n^{0.15715})$ in the unicast version of the CONGEST\nCLIQUE model. On the positive side we provide a deterministic version of\nNanongkai's $(2+o(1))$-approximation algorithm for APSP. To do so we present a\nfast deterministic construction of small hitting sets. We also show how to\nreplace another randomized part within Nanongkai's algorithm with a\ndeterministic source-detection algorithm designed for the CONGEST model\npresented by Lenzen and Peleg at PODC'13.\n", "versions": [{"version": "v1", "created": "Wed, 10 Dec 2014 20:59:11 GMT"}, {"version": "v2", "created": "Fri, 12 Dec 2014 19:27:40 GMT"}], "update_date": "2014-12-15", "authors_parsed": [["Holzer", "Stephan", ""], ["Pinsker", "Nathan", ""]]}, {"id": "1412.3507", "submitter": "Ilan Cohen", "authors": "Yossi Azar and Ilan Reuven Cohen and Debmalya Panigrahi", "title": "Online Covering with Convex Objectives and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give an algorithmic framework for minimizing general convex objectives\n(that are differentiable and monotone non-decreasing) over a set of covering\nconstraints that arrive online. This substantially extends previous work on\nonline covering for linear objectives (Alon {\\em et al.}, STOC 2003) and online\ncovering with offline packing constraints (Azar {\\em et al.}, SODA 2013). To\nthe best of our knowledge, this is the first result in online optimization for\ngeneric non-linear objectives; special cases of such objectives have previously\nbeen considered, particularly for energy minimization.\n  As a specific problem in this genre, we consider the unrelated machine\nscheduling problem with startup costs and arbitrary $\\ell_p$ norms on machine\nloads (including the surprisingly non-trivial $\\ell_1$ norm representing total\nmachine load). This problem was studied earlier for the makespan norm in both\nthe offline (Khuller~{\\em et al.}, SODA 2010; Li and Khuller, SODA 2011) and\nonline settings (Azar {\\em et al.}, SODA 2013). We adapt the two-phase approach\nof obtaining a fractional solution and then rounding it online (used\nsuccessfully to many linear objectives) to the non-linear objective. The\nfractional algorithm uses ideas from our general framework that we described\nabove (but does not fit the framework exactly because of non-positive entries\nin the constraint matrix). The rounding algorithm uses ideas from offline\nrounding of LPs with non-linear objectives (Azar and Epstein, STOC 2005; Kumar\n{\\em et al.}, FOCS 2005). Our competitive ratio is tight up to a logarithmic\nfactor. Finally, for the important special case of total load ($\\ell_1$ norm),\nwe give a different rounding algorithm that obtains a better competitive ratio\nthan the generic rounding algorithm for $\\ell_p$ norms. We show that this\ncompetitive ratio is asymptotically tight.\n", "versions": [{"version": "v1", "created": "Thu, 11 Dec 2014 00:35:03 GMT"}], "update_date": "2014-12-12", "authors_parsed": [["Azar", "Yossi", ""], ["Cohen", "Ilan Reuven", ""], ["Panigrahi", "Debmalya", ""]]}, {"id": "1412.3906", "submitter": "Christian Plessl", "authors": "Marvin Damschen and Christian Plessl", "title": "Easy-to-Use On-the-Fly Binary Program Acceleration on Many-Cores", "comments": "Part of ADAPT Workshop proceedings, 2015 (arXiv:1412.2347)", "journal-ref": null, "doi": null, "report-no": "ADAPT/2015/05", "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces Binary Acceleration At Runtime (BAAR), an easy-to-use\non-the-fly binary acceleration mechanism which aims to tackle the problem of\nenabling existent software to automatically utilize accelerators at runtime.\nBAAR is based on the LLVM Compiler Infrastructure and has a client-server\narchitecture. The client runs the program to be accelerated in an environment\nwhich allows program analysis and profiling. Program parts which are identified\nas suitable for the available accelerator are exported and sent to the server.\nThe server optimizes these program parts for the accelerator and provides RPC\nexecution for the client. The client transforms its program to utilize\naccelerated execution on the server for offloaded program parts.\n  We evaluate our work with a proof-of-concept implementation of BAAR that uses\nan Intel Xeon Phi 5110P as the acceleration target and performs automatic\noffloading, parallelization and vectorization of suitable program parts. The\npracticality of BAAR for real-world examples is shown based on a study of\nstencil codes. Our results show a speedup of up to 4x without any\ndeveloper-provided hints and 5.77x with hints over the same code compiled with\nthe Intel Compiler at optimization level O2 and running on an Intel Xeon\nE5-2670 machine. Based on our insights gained during implementation and\nevaluation we outline future directions of research, e.g., offloading more\nfine-granular program parts than functions, a more sophisticated communication\nmechanism or introducing on-stack-replacement.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2014 07:44:52 GMT"}], "update_date": "2014-12-15", "authors_parsed": [["Damschen", "Marvin", ""], ["Plessl", "Christian", ""]]}, {"id": "1412.4054", "submitter": "Filipe Campos", "authors": "Filipe Campos and Jos\\'e Pereira", "title": "An Experimental Evaluation of Machine-to-Machine Coordination\n  Middleware: Extended Version", "comments": "24 pages, Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The vision of the Internet-of-Things (IoT) embodies the seam- less discovery,\nconfiguration, and interoperability of networked devices in various settings,\nranging from home automation and multimedia to autonomous vehicles and\nmanufacturing equipment. As these ap- plications become increasingly critical,\nthe middleware coping with Machine-to-Machine (M2M) communication and\ncoordination has to deal with fault tolerance and increasing complexity, while\nstill abiding to resource constraints of target devices. In this report, we\nfocus on configuration management and coordi- nation of services in a M2M\nscenario. On one hand, we consider Zoo- Keeper, originally developed for cloud\ndata centers, offering a simple file-system abstraction, and embodying\nreplication for fault-tolerance and scalability based on a consensus protocol.\nOn the other hand, we consider the Devices Profile for Web Services (DPWS)\nstack with replicated services based on our implementation of the Raft\nconsensus protocol. We show that the latter offers adequate performance for the\ntargeted applications while providing increasing flexibility.\n", "versions": [{"version": "v1", "created": "Fri, 12 Dec 2014 16:59:16 GMT"}], "update_date": "2014-12-15", "authors_parsed": [["Campos", "Filipe", ""], ["Pereira", "Jos\u00e9", ""]]}, {"id": "1412.4213", "submitter": "Hongyang Sun", "authors": "Yangjie Cao, Hongyang Sun, Depei Qian, Weiguo Wu", "title": "Scalable Hierarchical Scheduling for Malleable Parallel Jobs on\n  Multiprocessor-based Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of multi-core and multiprocessor-based computer systems has\nled to explosive development of parallel applications and hence the need for\nefficient schedulers. In this paper, we study hierarchical scheduling for\nmalleable parallel jobs on multiprocessor-based systems, which appears in many\ndistributed and multilayered computing environments. We propose a hierarchical\nscheduling algorithm, named AC-DS, that consists of a feedback-driven adaptive\nscheduler, a desire aggregation scheme and an efficient resource allocation\npolicy. From theoretical perspective, we show that AC-DS has scalable\nperformance regardless of the number of hierarchical levels. In particular, we\nprove that AC-DS achieves $O(1)$-competitiveness with respect to the overall\ncompletion time of the jobs, or the makespan. A detailed malleable job model is\ndeveloped to experimentally evaluate the effectiveness of the proposed\nscheduling algorithm. The results verify the scalability of AC-DS and\ndemonstrate that AC-DS outperforms other strategies for a wide range of\nparallel workloads.\n", "versions": [{"version": "v1", "created": "Sat, 13 Dec 2014 09:44:32 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Cao", "Yangjie", ""], ["Sun", "Hongyang", ""], ["Qian", "Depei", ""], ["Wu", "Weiguo", ""]]}, {"id": "1412.4353", "submitter": "Aridj Mohamed", "authors": "Aridj Mohamed", "title": "LH*TH: New fast Scalable Distributed Data Structures (SDDS)", "comments": null, "journal-ref": "International Journal of Computer Science Issues,(IJCSI) Volume\n  11, Issue 6, No 2, pp 123-128 November 2014", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proposed in 1993 the Scalable Distributed Data Structures (SDDSs) became a\nprofile of basis for the data management on Multi computer. In this paper we\npropose an organization of a LH* bucket based on the trie hashing in order to\nimprove times of different access request.\n", "versions": [{"version": "v1", "created": "Sun, 14 Dec 2014 13:01:39 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Mohamed", "Aridj", ""]]}, {"id": "1412.4556", "submitter": "Blesson Varghese", "authors": "Blesson Varghese and Adam Barker", "title": "Are Clouds Ready to Accelerate Ad hoc Financial Simulations?", "comments": "Best paper nominee at the International Symposium on Big Data\n  Computing (BDC 2014) in conjunction with IEEE/ACM Utility and Cloud Computing\n  (UCC), 2014 London, UK", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications employed in the financial services industry to capture and\nestimate a variety of risk metrics are underpinned by stochastic simulations\nwhich are data, memory and computationally intensive. Many of these simulations\nare routinely performed on production-based computing systems. Ad hoc\nsimulations in addition to routine simulations are required to obtain\nup-to-date views of risk metrics. Such simulations are currently not performed\nas they cannot be accommodated on production clusters, which are typically over\ncommitted resources. Scalable, on-demand and pay-as-you go Virtual Machines\n(VMs) offered by the cloud are a potential platform to satisfy the data, memory\nand computational constraints of the simulation. However, \"Are clouds ready to\naccelerate ad hoc financial simulations?\"\n  The research reported in this paper aims to experimentally verify this\nquestion by developing and deploying an important financial simulation,\nreferred to as 'Aggregate Risk Analysis' on the cloud. Parallel techniques to\nimprove efficiency and performance of the simulations are explored. Challenges\nsuch as accommodating large input data on limited memory VMs and rapidly\nprocessing data for real-time use are surmounted. The key result of this\ninvestigation is that Aggregate Risk Analysis can be accommodated on cloud VMs.\nAcceleration of up to 24x using multiple hardware accelerators over the\nimplementation on a single accelerator, 6x over a multiple core implementation\nand approximately 60x over a baseline implementation was achieved on the cloud.\nHowever, computational time is wasted for every dollar spent on the cloud due\nto poor acceleration over multiple virtual cores. Interestingly, private VMs\ncan offer better performance than public VMs on comparable underlying hardware.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 12:03:13 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Varghese", "Blesson", ""], ["Barker", "Adam", ""]]}, {"id": "1412.4582", "submitter": "Bashir Mohammed", "authors": "Bashir Mohammed and Mariam Kiran", "title": "Experimental Report on Setting up a Cloud Computing Environment at the\n  University of Bradford", "comments": "19 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Cloud computing is increasingly attracting large attention in computing both\nin academic research and in industrial initiatives. Emerging as a popular\nparadigm and an attractive model of providing computing, information technology\n(IT) infrastructure, network and storage to large and small enterprises both in\nprivate and public sectors. This project was initiated and aimed at designing\nand Setting up a basic Cloud lab Testbed running on Open stack under Virtual\nbox for experiments and Hosting Cloud Platforms in the networking laboratory at\nthe University of Bradford. This report presents the methodology of setting up\na cloud lab testbed for experiment running on open stack. Current resources, in\nthe Networking lab at the university were used and turned into virtual\nplatforms for cloud computing testing. This report serves as a practical\nguideline, concentrating on the practical infrastructure related questions and\nissues, on setting up a cloud lab for testing and proof of concept. Finally the\nreport proposes an experimental validation showing feasibility of migrating to\ncloud.\n  The primary focus of this report is to provide a brief background on\ndifferent theoretical concepts of cloud computing, particularly virtualisation,\nand then it elaborates on the practical aspects concerning the setup and\nimplementation of a Cloud lab test bed using open source solutions. This\nreports serves as a reference for institutions looking at the possibilities of\nimplementing cloud solutions, in order to benefit from getting the basics and a\nview on the different aspects of cloud migration concepts.\n", "versions": [{"version": "v1", "created": "Mon, 15 Dec 2014 13:38:45 GMT"}], "update_date": "2014-12-16", "authors_parsed": [["Mohammed", "Bashir", ""], ["Kiran", "Mariam", ""]]}, {"id": "1412.4933", "submitter": "Sankha Dutta", "authors": "Sankha Baran Dutta, Robert McLeod, and Marcia Friesen", "title": "GPU accelerated Nature Inspired Methods for Modelling Large Scale\n  Bi-Directional Pedestrian Movement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Pedestrian movement, although ubiquitous and well-studied, is still not that\nwell understood due to the complicating nature of the embedded social dynamics.\nInterest among researchers in simulating pedestrian movement and interactions\nhas grown significantly in part due to increased computational and\nvisualization capabilities afforded by high power computing. Different\napproaches have been adopted to simulate pedestrian movement under various\ncircumstances and interactions. In the present work, bi-directional crowd\nmovement is simulated where an equal numbers of individuals try to reach the\nopposite sides of an environment. Two movement methods are considered. First a\nLeast Effort Model (LEM) is investigated where agents try to take an optimal\npath with as minimal changes from their intended path as possible. Following\nthis, a modified form of Ant Colony Optimization (ACO) is proposed, where\nindividuals are guided by a goal of reaching the other side in a least effort\nmode as well as a pheromone trail left by predecessors. The basic idea is to\nincrease agent interaction, thereby more closely reflecting a real world\nscenario. The methodology utilizes Graphics Processing Units (GPUs) for general\npurpose computing using the CUDA platform. Because of the inherent parallel\nproperties associated with pedestrian movement such as proximate interactions\nof individuals on a 2D grid, GPUs are well suited. The main feature of the\nimplementation undertaken here is that the parallelism is data driven. The data\ndriven implementation leads to a speedup up to 18x compared to its sequential\ncounterpart running on a single threaded CPU. The numbers of pedestrians\nconsidered in the model ranged from 2K to 100K representing numbers typical of\nmass gathering events. A detailed discussion addresses implementation\nchallenges faced and averted.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 10:03:30 GMT"}], "update_date": "2014-12-17", "authors_parsed": [["Dutta", "Sankha Baran", ""], ["McLeod", "Robert", ""], ["Friesen", "Marcia", ""]]}, {"id": "1412.4944", "submitter": "Paul Irofti", "authors": "Paul Irofti", "title": "Efficient GPU Implementation for Single Block Orthogonal Dictionary\n  Learning", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dictionary training for sparse representations involves dealing with large\nchunks of data and complex algorithms that determine time consuming\nimplementations. SBO is an iterative dictionary learning algorithm based on\nconstructing unions of orthonormal bases via singular value decomposition, that\nrepresents each data item through a single best fit orthobase. In this paper we\npresent a GPGPU approach of implementing SBO in OpenCL. We provide a lock-free\nsolution that ensures full-occupancy of the GPU by following the map-reduce\nmodel for the sparse-coding stage and by making use of the Partitioned Global\nAddress Space (PGAS) model for developing parallel dictionary updates. The\nresulting implementation achieves a favourable trade-off between algorithm\ncomplexity and data representation quality compared to PAK-SVD which is the\nstandard overcomplete dictionary learning approach. We present and discuss\nnumerical results showing a significant acceleration of the execution time for\nthe dictionary learning process.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 10:39:23 GMT"}], "update_date": "2014-12-17", "authors_parsed": [["Irofti", "Paul", ""]]}, {"id": "1412.4986", "submitter": "Hsiang-Fu Yu", "authors": "Hsiang-Fu Yu and Cho-Jui Hsieh and Hyokun Yun and S.V.N Vishwanathan\n  and Inderjit S. Dhillon", "title": "A Scalable Asynchronous Distributed Algorithm for Topic Modeling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Learning meaningful topic models with massive document collections which\ncontain millions of documents and billions of tokens is challenging because of\ntwo reasons: First, one needs to deal with a large number of topics (typically\nin the order of thousands). Second, one needs a scalable and efficient way of\ndistributing the computation across multiple machines. In this paper we present\na novel algorithm F+Nomad LDA which simultaneously tackles both these problems.\nIn order to handle large number of topics we use an appropriately modified\nFenwick tree. This data structure allows us to sample from a multinomial\ndistribution over $T$ items in $O(\\log T)$ time. Moreover, when topic counts\nchange the data structure can be updated in $O(\\log T)$ time. In order to\ndistribute the computation across multiple processor we present a novel\nasynchronous framework inspired by the Nomad algorithm of\n\\cite{YunYuHsietal13}. We show that F+Nomad LDA significantly outperform\nstate-of-the-art on massive problems which involve millions of documents,\nbillions of words, and thousands of topics.\n", "versions": [{"version": "v1", "created": "Tue, 16 Dec 2014 12:52:50 GMT"}], "update_date": "2014-12-17", "authors_parsed": [["Yu", "Hsiang-Fu", ""], ["Hsieh", "Cho-Jui", ""], ["Yun", "Hyokun", ""], ["Vishwanathan", "S. V. N", ""], ["Dhillon", "Inderjit S.", ""]]}, {"id": "1412.5384", "submitter": "Paulo Matias", "authors": "Andre B. Perina, Marcilyanne M. Gois, Paulo Matias, Joao M. P.\n  Cardoso, Alexandre C. B. Delbem, Vanderlei Bonato", "title": "Representation of Evolutionary Algorithms in FPGA Cluster for Project of\n  Large-Scale Networks", "comments": "Preprint of a short paper published in the proceedings of ERAD-SP\n  2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many problems are related to network projects, such as electric distribution,\ntelecommunication and others. Most of them can be represented by graphs, which\nmanipulate thousands or millions of nodes, becoming almost an impossible task\nto obtain real-time solutions. Many efficient solutions use Evolutionary\nAlgorithms (EA), where researches show that performance of EAs can be\nsubstantially raised by using an appropriate representation, such as the\nNode-Depth Encoding (NDE). The objective of this work was to partition an\nimplementation on single-FPGA (Field-Programmable Gate Array) based on NDE from\n512 nodes to a multi-FPGAs approach, expanding the system to 4096 nodes.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 13:37:29 GMT"}], "update_date": "2014-12-18", "authors_parsed": [["Perina", "Andre B.", ""], ["Gois", "Marcilyanne M.", ""], ["Matias", "Paulo", ""], ["Cardoso", "Joao M. P.", ""], ["Delbem", "Alexandre C. B.", ""], ["Bonato", "Vanderlei", ""]]}, {"id": "1412.5538", "submitter": "Andreas Olofsson", "authors": "Andreas Olofsson, Tomas Nordstr\\\"om, Zain Ul-Abdin", "title": "Kickstarting High-performance Energy-efficient Manycore Architectures\n  with Epiphany", "comments": "(to appear in Asilomar Conference on signals, systems, and computers\n  2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce Epiphany as a high-performance energy-efficient\nmanycore architecture suitable for real-time embedded systems. This scalable\narchitecture supports floating point operations in hardware and achieves 50\nGFLOPS/W in 28 nm technology, making it suitable for high performance streaming\napplications like radio base stations and radar signal processing. Through an\nefficient 2D mesh Network-on-Chip and a distributed shared memory model, the\narchitecture is scalable to thousands of cores on a single chip. An\nEpiphany-based open source computer named Parallella was launched in 2012\nthrough Kickstarter crowd funding and has now shipped to thousands of customers\naround the world.\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 19:39:56 GMT"}], "update_date": "2014-12-18", "authors_parsed": [["Olofsson", "Andreas", ""], ["Nordstr\u00f6m", "Tomas", ""], ["Ul-Abdin", "Zain", ""]]}, {"id": "1412.5557", "submitter": "Daniel S. Katz", "authors": "Doug James, Nancy Wilkins-Diehr, Victoria Stodden, Dirk Colbry, Carlos\n  Rosales, Mark Fahey, Justin Shi, Rafael F. Silva, Kyo Lee, Ralph Roskies,\n  Laurence Loewe, Susan Lindsey, Rob Kooper, Lorena Barba, David Bailey,\n  Jonathan Borwein, Oscar Corcho, Ewa Deelman, Michael Dietze, Benjamin\n  Gilbert, Jan Harkes, Seth Keele, Praveen Kumar, Jong Lee, Erika Linke,\n  Richard Marciano, Luigi Marini, Chris Mattman, Dave Mattson, Kenton McHenry,\n  Robert McLay, Sheila Miguez, Barbara Minsker, Maria Perez-Hernandez, Dan\n  Ryan, Mats Rynge, Idafen Santana-Perez, Mahadev Satyanarayanan, Gloriana St.\n  Clair, Keith Webster, Elvind Hovig, Daniel S. Katz, Sophie Kay, Geir Sandve,\n  David Skinner, Gabrielle Allen, John Cazes, Kym Won Cho, Jim Fonseca,\n  Lorraine Hwang, Lars Koesterke, Pragnesh Patel, Line Pouchard, Ed Seidel,\n  Isuru Suriarachchi", "title": "Standing Together for Reproducibility in Large-Scale Computing: Report\n  on reproducibility@XSEDE", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is the final report on reproducibility@xsede, a one-day workshop held in\nconjunction with XSEDE14, the annual conference of the Extreme Science and\nEngineering Discovery Environment (XSEDE). The workshop's discussion-oriented\nagenda focused on reproducibility in large-scale computational research. Two\nimportant themes capture the spirit of the workshop submissions and\ndiscussions: (1) organizational stakeholders, especially supercomputer centers,\nare in a unique position to promote, enable, and support reproducible research;\nand (2) individual researchers should conduct each experiment as though someone\nwill replicate that experiment. Participants documented numerous issues,\nquestions, technologies, practices, and potentially promising initiatives\nemerging from the discussion, but also highlighted four areas of particular\ninterest to XSEDE: (1) documentation and training that promotes reproducible\nresearch; (2) system-level tools that provide build- and run-time information\nat the level of the individual job; (3) the need to model best practices in\nresearch collaborations involving XSEDE staff; and (4) continued work on\ngateways and related technologies. In addition, an intriguing question emerged\nfrom the day's interactions: would there be value in establishing an annual\naward for excellence in reproducible research?\n", "versions": [{"version": "v1", "created": "Wed, 17 Dec 2014 20:05:51 GMT"}, {"version": "v2", "created": "Fri, 2 Jan 2015 17:54:03 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["James", "Doug", ""], ["Wilkins-Diehr", "Nancy", ""], ["Stodden", "Victoria", ""], ["Colbry", "Dirk", ""], ["Rosales", "Carlos", ""], ["Fahey", "Mark", ""], ["Shi", "Justin", ""], ["Silva", "Rafael F.", ""], ["Lee", "Kyo", ""], ["Roskies", "Ralph", ""], ["Loewe", "Laurence", ""], ["Lindsey", "Susan", ""], ["Kooper", "Rob", ""], ["Barba", "Lorena", ""], ["Bailey", "David", ""], ["Borwein", "Jonathan", ""], ["Corcho", "Oscar", ""], ["Deelman", "Ewa", ""], ["Dietze", "Michael", ""], ["Gilbert", "Benjamin", ""], ["Harkes", "Jan", ""], ["Keele", "Seth", ""], ["Kumar", "Praveen", ""], ["Lee", "Jong", ""], ["Linke", "Erika", ""], ["Marciano", "Richard", ""], ["Marini", "Luigi", ""], ["Mattman", "Chris", ""], ["Mattson", "Dave", ""], ["McHenry", "Kenton", ""], ["McLay", "Robert", ""], ["Miguez", "Sheila", ""], ["Minsker", "Barbara", ""], ["Perez-Hernandez", "Maria", ""], ["Ryan", "Dan", ""], ["Rynge", "Mats", ""], ["Santana-Perez", "Idafen", ""], ["Satyanarayanan", "Mahadev", ""], ["Clair", "Gloriana St.", ""], ["Webster", "Keith", ""], ["Hovig", "Elvind", ""], ["Katz", "Daniel S.", ""], ["Kay", "Sophie", ""], ["Sandve", "Geir", ""], ["Skinner", "David", ""], ["Allen", "Gabrielle", ""], ["Cazes", "John", ""], ["Cho", "Kym Won", ""], ["Fonseca", "Jim", ""], ["Hwang", "Lorraine", ""], ["Koesterke", "Lars", ""], ["Patel", "Pragnesh", ""], ["Pouchard", "Line", ""], ["Seidel", "Ed", ""], ["Suriarachchi", "Isuru", ""]]}, {"id": "1412.5711", "submitter": "David Budden", "authors": "David M Budden, Peter Wang, Oliver Obst and Mikhail Prokopenko", "title": "Simulation leagues: Enabling replicable and robust investigation of\n  complex robotic systems", "comments": "9 pages, 4 figures. arXiv admin note: text overlap with\n  arXiv:1403.4023", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Physically-realistic simulated environments are powerful platforms for\nenabling measurable, replicable and statistically-robust investigation of\ncomplex robotic systems. Such environments are epitomised by the RoboCup\nsimulation leagues, which have been successfully utilised to conduct\nmassively-parallel experiments in topics including: optimisation of bipedal\nlocomotion, self-localisation from noisy perception data and planning complex\nmulti-agent strategies without direct agent-to-agent communication. Many of\nthese systems are later transferred to physical robots, making the simulation\nleagues invaluable well-beyond the scope of simulated soccer matches. In this\nstudy, we provide an overview of the RoboCup simulation leagues and describe\ntheir properties as they pertain to replicable and robust robotics research. To\ndemonstrate their utility directly, we leverage the ability to run parallelised\nexperiments to evaluate different competition formats (e.g. round robin) for\nthe RoboCup 2D simulation league. Our results demonstrate that a\npreviously-proposed hybrid format minimises fluctuations from 'true'\n(statistically-significant) team performance rankings within the time\nconstraints of the RoboCup world finals. Our experimental analysis would be\nimpossible with physical robots alone, and we encourage other researchers to\nexplore the potential for enriching their experimental pipelines with simulated\ncomponents, both to minimise experimental costsand enable others to replicate\nand expand upon their results in a hardware-independent manner.\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2014 03:09:03 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Budden", "David M", ""], ["Wang", "Peter", ""], ["Obst", "Oliver", ""], ["Prokopenko", "Mikhail", ""]]}, {"id": "1412.5847", "submitter": "Nicola Caon", "authors": "Antonio Dorta, Nicola Caon, Jorge Andres Perez Prieto", "title": "ConGUSTo: (HT)Condor Graphical Unified Supervising Tool", "comments": "8 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HTCondor is a distributed job scheduler developed by the University of\nWisconsin-Madison, which allows users to run their applications in other users'\nmachines when they are not being used, thus providing a considerably increase\nin the overall computational power and a more efficient use of the computing\nresources. Our institution has been successfully using HTCondor for more than\nten years, and HTCondor is nowadays the most used Supercomputing resource we\nhave. Although HTCondor provides a wide range of tools and options for its\nmanagement and administration, there are currently no tools that can show\ndetailed usage information and statistics in a clear, easy to interpret,\ninteractive set of graphics displays. For this reason, we have developed\nConGUSTo, a web-based tool that allows to collect HTCondor usage and statistics\ndata in an easy way, and present them using a variety of tabular and graphics\ncharts.\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2014 13:17:41 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Dorta", "Antonio", ""], ["Caon", "Nicola", ""], ["Prieto", "Jorge Andres Perez", ""]]}, {"id": "1412.6007", "submitter": "Swan Dubois", "authors": "Nicolas Braud-Santoni (TU Graz), Swan Dubois (INRIA), Mohamed-Hamza\n  Kaaouachi (INRIA), Franck Petit (INRIA)", "title": "The Next 700 Impossibility Results in Time-Varying Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address highly dynamic distributed systems modeled by time-varying graphs\n(TVGs). We interest in proof of impossibility results that often use informal\narguments about convergence. First, we provide a distance among TVGs to define\ncorrectly the convergence of TVG sequences. Next, we provide a general\nframework that formally proves the convergence of the sequence of executions of\nany deterministic algorithm over TVGs of any convergent sequence of TVGs.\nFinally, we illustrate the relevance of the above result by proving that no\ndeterministic algorithm exists to compute the underlying graph of any\nconnected-over-time TVG, i.e., any TVG of the weakest class of long-lived TVGs.\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2014 19:10:35 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Braud-Santoni", "Nicolas", "", "TU Graz"], ["Dubois", "Swan", "", "INRIA"], ["Kaaouachi", "Mohamed-Hamza", "", "INRIA"], ["Petit", "Franck", "", "INRIA"]]}, {"id": "1412.6170", "submitter": "Francesco Lettich", "authors": "Francesco Lettich, Salvatore Orlando and Claudio Silvestri", "title": "Manycore processing of repeated k-NN queries over massive moving objects\n  observations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to timely process significant amounts of continuously updated\nspatial data is mandatory for an increasing number of applications. In this\npaper we focus on a specific data-intensive problem concerning the repeated\nprocessing of huge amounts of k nearest neighbours (k-NN) queries over massive\nsets of moving objects, where the spatial extents of queries and the position\nof objects are continuously modified over time. In particular, we propose a\nnovel hybrid CPU/GPU pipeline that significantly accelerate query processing\nthanks to a combination of ad-hoc data structures and non-trivial memory access\npatterns. To the best of our knowledge this is the first work that exploits\nGPUs to efficiently solve repeated k-NN queries over massive sets of\ncontinuously moving objects, even characterized by highly skewed spatial\ndistributions. In comparison with state-of-the-art sequential CPU-based\nimplementations, our method highlights significant speedups in the order of\n10x-20x, depending on the datasets, even when considering cheap GPUs.\n", "versions": [{"version": "v1", "created": "Thu, 18 Dec 2014 22:43:28 GMT"}], "update_date": "2014-12-22", "authors_parsed": [["Lettich", "Francesco", ""], ["Orlando", "Salvatore", ""], ["Silvestri", "Claudio", ""]]}, {"id": "1412.6367", "submitter": "Pierre de Buyl", "authors": "J\\'er\\^ome Kieffer, Giannis Ashiotis", "title": "PyFAI: a Python library for high performance azimuthal integration on\n  GPU", "comments": "Part of the Proceedings of the 7th European Conference on Python in\n  Science (EuroSciPy 2014), Pierre de Buyl and Nelle Varoquaux editors, (2014)", "journal-ref": null, "doi": null, "report-no": "euroscipy-proceedings2014-02", "categories": "astro-ph.IM cs.DC cs.MS", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The pyFAI package has been designed to reduce X-ray diffraction images into\npowder diffraction curves to be further processed by scientists. This\ncontribution describes how to convert an image into a radial profile using the\nNumpy package, how the process was accelerated using Cython. The algorithm was\nparallelised, needing a complete re-design to benefit from massively parallel\ndevices like graphical processing units or accelerators like the Intel Xeon Phi\nusing the PyOpenCL library.\n", "versions": [{"version": "v1", "created": "Fri, 19 Dec 2014 15:06:50 GMT"}], "update_date": "2014-12-22", "authors_parsed": [["Kieffer", "J\u00e9r\u00f4me", ""], ["Ashiotis", "Giannis", ""]]}, {"id": "1412.6382", "submitter": "Liang Wang", "authors": "Julien Mineraud, Liang Wang, Sasitharan Balasubramaniam, Jussi\n  Kangasharju", "title": "Renewable Energy-Aware Information-Centric Networking", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ICT industry today is placed as one of the major consumers of energy,\nwhere recent reports have also shown that the industry is a major contributor\nto global carbon emissions. While renewable energy-aware data centers have been\nproposed, these solutions have certain limitations. The primary limitation is\ndue to the design of data centers which focus on large-size facilities located\nin selected locations. This paper addresses this problem, by utilizing\nin-network caching with each router having storage and being powered by\nrenewable energy sources (wind and solar). Besides placing contents closer to\nend users, utilizing in-network caching could potentially increase probability\nof capturing renewable energy in diverse geographical locations. Our proposed\nsolution is dual- layered: on the first layer a distributed gradient-based\nrouting protocol is used to discover the paths along routers that are powered\nby the highest renewable energy, and on the second layer, a caching mechanism\nwill pull the contents from the data centre and place them on routers of the\npaths that are discovered by our routing protocol. Through our experiments on a\ntestbed utilizing real meteorological data, our proposed solution has\ndemonstrated increased quantity of renewable energy consumption, while reducing\nthe workload on the data centers.\n", "versions": [{"version": "v1", "created": "Fri, 19 Dec 2014 15:36:16 GMT"}], "update_date": "2014-12-22", "authors_parsed": [["Mineraud", "Julien", ""], ["Wang", "Liang", ""], ["Balasubramaniam", "Sasitharan", ""], ["Kangasharju", "Jussi", ""]]}, {"id": "1412.6392", "submitter": "Leonardo Tizzei", "authors": "Kiran Mantripragada and Alecio Binotto and Leonardo P. Tizzei", "title": "A Self-adaptive Auto-scaling Method for Scientific Applications on HPC\n  Environments and Clouds", "comments": "Part of ADAPT Workshop proceedings, 2015 (arXiv:1412.2347)", "journal-ref": null, "doi": null, "report-no": "ADAPT/2015/01", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High intensive computation applications can usually take days to months to\nfinish an execution. During this time, it is common to have variations of the\navailable resources when considering that such hardware is usually shared among\na plurality of researchers/departments within an organization. On the other\nhand, High Performance Clusters can take advantage of Cloud Computing bursting\ntechniques for the execution of applications together with the on-premise\nresources. In order to meet deadlines, high intensive computational\napplications can use the Cloud to boost their performance when they are data\nand task parallel. This article presents an ongoing work towards the use of\nextended resources of an HPC execution platform together with Cloud. We propose\nan unified view of such heterogeneous environments and a method that monitors,\npredicts the application execution time, and dynamically shifts part of the\ndomain -- previously running in local HPC hardware -- to be computed on the\nCloud, meeting then a specific deadline. The method is exemplified along with a\nseismic application that, at runtime, adapts itself to move part of the\nprocessing to the Cloud (in a movement called bursting) and also auto-scales\n(the moved part) over cloud nodes. Our preliminary results show that there is\nan expected overhead for performing this movement and for synchronizing\nresults, but our outcomes demonstrate it is an important feature for meeting\ndeadlines in the case an on-premise cluster is overloaded or cannot provide the\ncapacity needed for a particular project.\n", "versions": [{"version": "v1", "created": "Fri, 19 Dec 2014 15:48:42 GMT"}, {"version": "v2", "created": "Wed, 14 Jan 2015 18:15:46 GMT"}, {"version": "v3", "created": "Mon, 26 Jan 2015 18:09:33 GMT"}], "update_date": "2015-01-27", "authors_parsed": [["Mantripragada", "Kiran", ""], ["Binotto", "Alecio", ""], ["Tizzei", "Leonardo P.", ""]]}, {"id": "1412.6765", "submitter": "Nassim Halli", "authors": "Nassim A. Halli, Henri-Pierre Charles and Jean-Fran\\c{c}ois Mehaut", "title": "Performance comparison between Java and JNI for optimal implementation\n  of computational micro-kernels", "comments": "Part of ADAPT Workshop proceedings, 2015 (arXiv:1412.2347)", "journal-ref": null, "doi": null, "report-no": "ADAPT/2015/06", "categories": "cs.PF cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General purpose CPUs used in high performance computing (HPC) support a\nvector instruction set and an out-of-order engine dedicated to increase the\ninstruction level parallelism. Hence, related optimizations are currently\ncritical to improve the performance of applications requiring numerical\ncomputation. Moreover, the use of a Java run-time environment such as the\nHotSpot Java Virtual Machine (JVM) in high performance computing is a promising\nalternative. It benefits from its programming flexibility, productivity and the\nperformance is ensured by the Just-In-Time (JIT) compiler. Though, the JIT\ncompiler suffers from two main drawbacks. First, the JIT is a black box for\ndevelopers. We have no control over the generated code nor any feedback from\nits optimization phases like vectorization. Secondly, the time constraint\nnarrows down the degree of optimization compared to static compilers like GCC\nor LLVM. So, it is compelling to use statically compiled code since it benefits\nfrom additional optimization reducing performance bottlenecks. Java enables to\ncall native code from dynamic libraries through the Java Native Interface\n(JNI). Nevertheless, JNI methods are not inlined and require an additional cost\nto be invoked compared to Java ones. Therefore, to benefit from better static\noptimization, this call overhead must be leveraged by the amount of computation\nperformed at each JNI invocation. In this paper we tackle this problem and we\npropose to do this analysis for a set of micro-kernels. Our goal is to select\nthe most efficient implementation considering the amount of computation defined\nby the calling context. We also investigate the impact on performance of\nseveral different optimization schemes which are vectorization, out-of-order\noptimization, data alignment, method inlining and the use of native memory for\nJNI methods.\n", "versions": [{"version": "v1", "created": "Sun, 21 Dec 2014 11:26:39 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Halli", "Nassim A.", ""], ["Charles", "Henri-Pierre", ""], ["Mehaut", "Jean-Fran\u00e7ois", ""]]}, {"id": "1412.6862", "submitter": "Jongmyon Kim", "authors": "Shohidul Islam, Cheol-Hong Kim, and Jong-Myon Kim", "title": "Computationally Efficient Implementation of a Hamming Code Decoder using\n  a Graphics Processing Unit", "comments": "6 pages, 8 figures, Journal of Communications and Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a computationally efficient implementation of a Hamming\ncode decoder on a graphics processing unit (GPU) to support real-time\nsoftware-defined radio (SDR), which is a software alternative for realizing\nwireless communication. The Hamming code algorithm is challenging to\nparallelize effectively on a GPU because it works on sparsely located data\nitems with several conditional statements, leading to non-coalesced, long\nlatency, global memory access, and huge thread divergence. To address these\nissues, we propose an optimized implementation of the Hamming code on the GPU\nto exploit the higher parallelism inherent in the algorithm. Experimental\nresults using a compute unified device architecture (CUDA)-enabled NVIDIA\nGeForce GTX 560, including 335 cores, revealed that the proposed approach\nachieved a 99x speedup versus the equivalent CPU-based implementation.\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2014 03:00:38 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Islam", "Shohidul", ""], ["Kim", "Cheol-Hong", ""], ["Kim", "Jong-Myon", ""]]}, {"id": "1412.6986", "submitter": "Tarek Abdelrahman", "authors": "Tianyi David Han, Tarek S. Abdelrahman", "title": "Automatic Tuning of Local Memory Use on GPGPUs", "comments": "Part of ADAPT Workshop proceedings, 2015 (arXiv:1412.2347)", "journal-ref": null, "doi": null, "report-no": "ADAPT/2015/04", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of local memory is important to improve the performance of OpenCL\nprograms. However, its use may not always benefit performance, depending on\nvarious application characteristics, and there is no simple heuristic for\ndeciding when to use it. We develop a machine learning model to decide if the\noptimization is beneficial or not. We train the model with millions of\nsynthetic benchmarks and show that it can predict if the optimization should be\napplied for a single array, in both synthetic and real benchmarks, with high\naccuracy.\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2014 14:06:37 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Han", "Tianyi David", ""], ["Abdelrahman", "Tarek S.", ""]]}, {"id": "1412.7018", "submitter": "Dominik Kaaser", "authors": "Hoda Akbari and Petra Berenbrink and Robert Els\\\"asser and Dominik\n  Kaaser", "title": "Discrete Load Balancing in Heterogeneous Networks with a Focus on\n  Second-Order Diffusion", "comments": "Full version of paper submitted to ICDCS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a wide class of discrete diffusion load balancing\nalgorithms. The problem is defined as follows. We are given an interconnection\nnetwork and a number of load items, which are arbitrarily distributed among the\nnodes of the network. The goal is to redistribute the load in iterative\ndiscrete steps such that at the end each node has (almost) the same number of\nitems. In diffusion load balancing nodes are only allowed to balance their load\nwith their direct neighbors.\n  We show three main results. Firstly, we present a general framework for\nrandomly rounding the flow generated by continuous diffusion schemes over the\nedges of a graph in order to obtain corresponding discrete schemes. Compared to\nthe results of Rabani, Sinclair, and Wanka, FOCS'98, which are only valid\nw.r.t. the class of homogeneous first order schemes, our framework can be used\nto analyze a larger class of diffusion algorithms, such as algorithms for\nheterogeneous networks and second order schemes. Secondly, we bound the\ndeviation between randomized second order schemes and their continuous\ncounterparts. Finally, we provide a bound for the minimum initial load in a\nnetwork that is sufficient to prevent the occurrence of negative load at a node\nduring the execution of second order diffusion schemes.\n  Our theoretical results are complemented with extensive simulations on\ndifferent graph classes. We show empirically that second order schemes, which\nare usually much faster than first order schemes, will not balance the load\ncompletely on a number of networks within reasonable time. However, the maximum\nload difference at the end seems to be bounded by a constant value, which can\nbe further decreased if first order scheme is applied once this value is\nachieved by second order scheme.\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2014 15:12:38 GMT"}], "update_date": "2014-12-23", "authors_parsed": [["Akbari", "Hoda", ""], ["Berenbrink", "Petra", ""], ["Els\u00e4sser", "Robert", ""], ["Kaaser", "Dominik", ""]]}, {"id": "1412.7116", "submitter": "Saghar Hosseini", "authors": "Saghar Hosseini, Airlie Chapman, and Mehran Mesbahi", "title": "Online Distributed ADMM on Networks", "comments": "Submitted to The IEEE Transactions on Control of Network Systems,\n  2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper examines online distributed Alternating Direction Method of\nMultipliers (ADMM). The goal is to distributively optimize a global objective\nfunction over a network of decision makers under linear constraints. The global\nobjective function is composed of convex cost functions associated with each\nagent. The local cost functions, on the other hand, are assumed to have been\ndecomposed into two distinct convex functions, one of which is revealed to the\ndecision makers over time and one known a priori. In addition, the agents must\nachieve consensus on the global variable that relates to the private local\nvariables via linear constraints. In this work, we extend online ADMM to a\ndistributed setting based on dual-averaging and distributed gradient descent.\nWe then propose a performance metric for such online distributed algorithms and\nexplore the performance of the sequence of decisions generated by the algorithm\nas compared with the best fixed decision in hindsight. This performance metric\nis called the social regret. A sub-linear upper bound on the social regret of\nthe proposed algorithm is then obtained that underscores the role of the\nunderlying network topology and certain condition measures associated with the\nlinear constraints. The online distributed ADMM algorithm is then applied to a\nformation acquisition problem demonstrating the application of the proposed\nsetup in distributed robotics.\n", "versions": [{"version": "v1", "created": "Mon, 22 Dec 2014 19:55:56 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2015 19:59:48 GMT"}], "update_date": "2015-10-05", "authors_parsed": [["Hosseini", "Saghar", ""], ["Chapman", "Airlie", ""], ["Mesbahi", "Mehran", ""]]}, {"id": "1412.7281", "submitter": "Shanying Zhu", "authors": "Shanying Zhu, Yeng Chai Soh, Lihua Xie", "title": "Distributed Parameter Estimation with Quantized Communication via\n  Running Average", "comments": "13 pages, 6 figures; IEEE Transactions on Signal Processing, 2015", "journal-ref": null, "doi": "10.1109/TSP.2015.2441034", "report-no": null, "categories": "cs.SY cs.DC cs.MA math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the parameter estimation problem over sensor\nnetworks in the presence of quantized data and directed communication links. We\npropose a two-stage algorithm aiming at achieving the centralized sample mean\nestimate in a distributed manner. Different from the existing algorithms, a\nrunning average technique is utilized in the proposed algorithm to smear out\nthe randomness caused by the probabilistic quantization scheme. With the\nrunning average technique, it is shown that the centralized sample mean\nestimate can be achieved both in the mean square and almost sure senses, which\nis not observed in the conventional consensus algorithms. In addition, the\nrates of convergence are given to quantify the mean square and almost sure\nperformances. Finally, simulation results are presented to illustrate the\neffectiveness of the proposed algorithm and highlight the improvements by using\nrunning average technique.\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2014 07:56:44 GMT"}, {"version": "v2", "created": "Fri, 24 Jul 2015 06:08:35 GMT"}], "update_date": "2015-07-27", "authors_parsed": [["Zhu", "Shanying", ""], ["Soh", "Yeng Chai", ""], ["Xie", "Lihua", ""]]}, {"id": "1412.7364", "submitter": "David Gleich", "authors": "David F. Gleich and Ananth Grama and Yao Zhu", "title": "Erasure coding for fault oblivious linear system solvers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with hardware and software faults is an important problem as parallel\nand distributed systems scale to millions of processing cores and wide area\nnetworks. Traditional methods for dealing with faults include\ncheckpoint-restart, active replicas, and deterministic replay. Each of these\ntechniques has associated resource overheads and constraints. In this paper, we\npropose an alternate approach to dealing with faults, based on input\naugmentation. This approach, which is an algorithmic analog of erasure coded\nstorage, applies a minimally modified algorithm on the augmented input to\nproduce an augmented output. The execution of such an algorithm proceeds\ncompletely oblivious to faults in the system. In the event of one or more\nfaults, the real solution is recovered using a rapid reconstruction method from\nthe augmented output. We demonstrate this approach on the problem of solving\nsparse linear systems using a conjugate gradient solver. We present input\naugmentation and output recovery techniques. Through detailed experiments, we\nshow that our approach can be made oblivious to a large number of faults with\nlow computational overhead. Specifically, we demonstrate cases where a single\nfault can be corrected with less than 10% overhead in time, and even in extreme\ncases (fault rates of 20%), our approach is able to compute a solution with\nreasonable overhead. These results represent a significant improvement over the\nstate of the art.\n", "versions": [{"version": "v1", "created": "Tue, 23 Dec 2014 14:04:34 GMT"}], "update_date": "2014-12-24", "authors_parsed": [["Gleich", "David F.", ""], ["Grama", "Ananth", ""], ["Zhu", "Yao", ""]]}, {"id": "1412.7580", "submitter": "Nicolas Vasilache", "authors": "Nicolas Vasilache, Jeff Johnson, Michael Mathieu, Soumith Chintala,\n  Serkan Piantino, Yann LeCun", "title": "Fast Convolutional Nets With fbfft: A GPU Performance Evaluation", "comments": "Camera ready for ICLR2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the performance profile of Convolutional Neural Network training\non the current generation of NVIDIA Graphics Processing Units. We introduce two\nnew Fast Fourier Transform convolution implementations: one based on NVIDIA's\ncuFFT library, and another based on a Facebook authored FFT implementation,\nfbfft, that provides significant speedups over cuFFT (over 1.5x) for whole\nCNNs. Both of these convolution implementations are available in open source,\nand are faster than NVIDIA's cuDNN implementation for many common convolutional\nlayers (up to 23.5x for some synthetic kernel configurations). We discuss\ndifferent performance regimes of convolutions, comparing areas where\nstraightforward time domain convolutions outperform Fourier frequency domain\nconvolutions. Details on algorithmic applications of NVIDIA GPU hardware\nspecifics in the implementation of fbfft are also provided.\n", "versions": [{"version": "v1", "created": "Wed, 24 Dec 2014 01:31:36 GMT"}, {"version": "v2", "created": "Tue, 30 Dec 2014 16:55:04 GMT"}, {"version": "v3", "created": "Fri, 10 Apr 2015 20:01:00 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["Vasilache", "Nicolas", ""], ["Johnson", "Jeff", ""], ["Mathieu", "Michael", ""], ["Chintala", "Soumith", ""], ["Piantino", "Serkan", ""], ["LeCun", "Yann", ""]]}, {"id": "1412.7653", "submitter": "Bao-Thien Hoang", "authors": "Bao-Thien Hoang, Abdessamad Imine", "title": "Efficient Polling Protocol for Decentralized Social Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the polling problem in social networks where individuals\ncollaborate to choose the most favorite choice amongst some options, without\ndivulging their vote and publicly exposing their potentially malicious actions.\nGiven this social interaction model, Guerraoui et al. recently proposed polling\nprotocols that do not rely on any central authority or cryptography system,\nusing a simple secret sharing scheme along with verification procedures to\naccurately compute the poll's final result. However, these protocols can be\ndeployed safely and efficiently provided that, inter alia, the social graph\nstructure should be transformed into a ring structure-based overlay and the\nnumber of participating users is perfect square. Consequently, designing\n\\emph{secure} and \\emph{efficient} polling protocols regardless these\nconstraints remains a challenging issue.\n  In this paper, we present EPol, a simple decentralized polling protocol that\nrelies on the current state of social graphs. More explicitly, we define one\nfamily of social graphs that satisfy what we call the $m$-broadcasting property\n(where $m$ is less than or equal to the minimum node degree) and show their\nstructures enable low communication cost and constitute necessary and\nsufficient condition to ensure vote privacy and limit the impact of dishonest\nusers on the accuracy of the polling output. Our protocol is effective to\ncompute more precisely the final result. Furthermore, despite the use of richer\nsocial graph structures, the communication and spatial complexities of EPol are\nclose to be linear.\n", "versions": [{"version": "v1", "created": "Wed, 24 Dec 2014 12:35:08 GMT"}], "update_date": "2014-12-25", "authors_parsed": [["Hoang", "Bao-Thien", ""], ["Imine", "Abdessamad", ""]]}, {"id": "1412.7789", "submitter": "Roshan Ragel", "authors": "Vajira Thambawita, Roshan Ragel and Dhammika Elkaduwe", "title": "To Use or Not to Use: Graphics Processing Units for Pattern Matching\n  Algorithms", "comments": "appears in The 7th International Conference on Information and\n  Automation for Sustainability (ICIAfS) 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  String matching is an important part in today's computer applications and\nAho-Corasick algorithm is one of the main string matching algorithms used to\naccomplish this. This paper discusses that when can the GPUs be used for string\nmatching applications using the Aho-Corasick algorithm as a benchmark. We have\nto identify the best unit to run our string matching algorithm according to the\nperformance of our devices and the applications. Sometimes CPU gives better\nperformance than GPU and sometimes GPU gives better performance than CPU.\nTherefore, identifying this critical point is significant task for researchers\nwho are using GPUs to improve the performance of their string matching\napplications based on string matching algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 25 Dec 2014 05:27:49 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Thambawita", "Vajira", ""], ["Ragel", "Roshan", ""], ["Elkaduwe", "Dhammika", ""]]}, {"id": "1412.7922", "submitter": "Boaz Patt-Shamir", "authors": "Christoph Lenzen and Boaz Patt-Shamir", "title": "Fast Partial Distance Estimation and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study approximate distributed solutions to the weighted {\\it\nall-pairs-shortest-paths} (APSP) problem in the CONGEST model. We obtain the\nfollowing results.\n  $1.$ A deterministic $(1+o(1))$-approximation to APSP in $\\tilde{O}(n)$\nrounds. This improves over the best previously known algorithm, by both\nderandomizing it and by reducing the running time by a $\\Theta(\\log n)$ factor.\n  In many cases, routing schemes involve relabeling, i.e., assigning new names\nto nodes and require that these names are used in distance and routing queries.\nIt is known that relabeling is necessary to achieve running times of $o(n/\\log\nn)$. In the relabeling model, we obtain the following results.\n  $2.$ A randomized $O(k)$-approximation to APSP, for any integer $k>1$,\nrunning in $\\tilde{O}(n^{1/2+1/k}+D)$ rounds, where $D$ is the hop diameter of\nthe network. This algorithm simplifies the best previously known result and\nreduces its approximation ratio from $O(k\\log k)$ to $O(k)$. Also, the new\nalgorithm uses uses labels of asymptotically optimal size, namely $O(\\log n)$\nbits.\n  $3.$ A randomized $O(k)$-approximation to APSP, for any integer $k>1$,\nrunning in time $\\tilde{O}((nD)^{1/2}\\cdot n^{1/k}+D)$ and producing {\\it\ncompact routing tables} of size $\\tilde{O}(n^{1/k})$. The node lables consist\nof $O(k\\log n)$ bits. This improves on the approximation ratio of $\\Theta(k^2)$\nfor tables of that size achieved by the best previously known algorithm, which\nterminates faster, in $\\tilde{O}(n^{1/2+1/k}+D)$ rounds.\n", "versions": [{"version": "v1", "created": "Fri, 26 Dec 2014 10:10:18 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Lenzen", "Christoph", ""], ["Patt-Shamir", "Boaz", ""]]}, {"id": "1412.7935", "submitter": "Christian Decker", "authors": "Christian Decker and Jochen Seidel and Roger Wattenhofer", "title": "Bitcoin Meets Strong Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bitcoin system only provides eventual consistency. For everyday life, the\ntime to confirm a Bitcoin transaction is prohibitively slow. In this paper we\npropose a new system, built on the Bitcoin blockchain, which enables strong\nconsistency. Our system, PeerCensus, acts as a certification authority, manages\npeer identities in a peer-to-peer network, and ultimately enhances Bitcoin and\nsimilar systems with strong consistency. Our extensive analysis shows that\nPeerCensus is in a secure state with high probability. We also show how\nDiscoin, a Bitcoin variant that decouples block creation and transaction\nconfirmation, can be built on top of PeerCensus, enabling real-time payments.\nUnlike Bitcoin, once transactions in Discoin are committed, they stay\ncommitted.\n", "versions": [{"version": "v1", "created": "Fri, 26 Dec 2014 12:58:13 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Decker", "Christian", ""], ["Seidel", "Jochen", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1412.8028", "submitter": "Mansaf  Alam", "authors": "Mansaf Alam and Kashish Ara Shakil", "title": "An NBDMMM Algorithm Based Framework for Allocation of Resources in Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is a technological advancement in the arena of computing and\nhas taken the utility vision of computing a step further by providing computing\nresources such as network, storage, compute capacity and servers, as a service\nvia an internet connection. These services are provided to the users in a pay\nper use manner subjected to the amount of usage of these resources by the cloud\nusers. Since the usage of these resources is done in an elastic manner thus an\non demand provisioning of these resources is the driving force behind the\nentire cloud computing infrastructure therefore the maintenance of these\nresources is a decisive task that must be taken into account. Eventually,\ninfrastructure level performance monitoring and enhancement is also important.\nThis paper proposes a framework for allocation of resources in a cloud based\nenvironment thereby leading to an infrastructure level enhancement of\nperformance in a cloud environment. The framework is divided into four stages\nStage 1: Cloud service provider monitors the infrastructure level pattern of\nusage of resources and behavior of the cloud users. Stage 2: Report the\nmonitoring activities about the usage to cloud service providers. Stage 3:\nApply proposed Network Bandwidth Dependent DMMM algorithm .Stage 4: Allocate\nresources or provide services to cloud users, thereby leading to infrastructure\nlevel performance enhancement and efficient management of resources. Analysis\nof resource usage pattern is considered as an important factor for proper\nallocation of resources by the service providers, in this paper Google cluster\ntrace has been used for accessing the resource usage pattern in cloud.\nExperiments have been conducted on cloudsim simulation framework and the\nresults reveal that NBDMMM algorithm improvises allocation of resources in a\nvirtualized cloud.\n", "versions": [{"version": "v1", "created": "Sat, 27 Dec 2014 08:49:32 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Alam", "Mansaf", ""], ["Shakil", "Kashish Ara", ""]]}, {"id": "1412.8029", "submitter": "Mansaf  Alam", "authors": "Mansaf Alam, Kashish Ara Shakil", "title": "A Decision Matrix and Monitoring based Framework for Infrastructure\n  Performance Enhancement in A Cloud based Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud environment is very different from traditional computing environment\nand therefore tracking the performance of cloud leverages additional\nrequirements. The movement of data in cloud is very fast. Hence, it requires\nthat resources and infrastructure available at disposal must be equally\ncompetent. Infrastructure level performance in cloud involves the performance\nof servers, network and storage which act as the heart and soul for driving the\nentire cloud business. Thus a constant improvement and enhancement of\ninfrastructure level performance is an important task that needs to be taken\ninto account. This paper proposes a framework for infrastructure performance\nenhancement in a cloud based environment. The framework is broadly divided into\nfour steps: a) Infrastructure level monitoring of usage pattern and behaviour\nof the cloud end users, b) Reporting of the monitoring activities to the cloud\nservice provider c) Cloud service provider assigns priority according to our\ndecision matrix based max-min algorithm (DMMM) d) Providing services to cloud\nusers leading to infrastructure performance enhancement. Our framework is based\non decision matrix and monitoring in cloud using our proposed decision matrix\nbased max-min algorithm, which draws its inspiration from the original min-min\nalgorithm. This algorithm makes use of decision matrix to make decisions\nregarding distribution of resources among the cloud users.\n", "versions": [{"version": "v1", "created": "Sat, 27 Dec 2014 08:54:53 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Alam", "Mansaf", ""], ["Shakil", "Kashish Ara", ""]]}, {"id": "1412.8097", "submitter": "William Hoza", "authors": "William M. Hoza and Leonard J. Schulman", "title": "The Adversarial Noise Threshold for Distributed Protocols", "comments": "23 pages, 2 figures. Fixes mistake in theorem 6 and various typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of implementing distributed protocols, despite\nadversarial channel errors, on synchronous-messaging networks with arbitrary\ntopology.\n  In our first result we show that any $n$-party $T$-round protocol on an\nundirected communication network $G$ can be compiled into a robust simulation\nprotocol on a sparse ($\\mathcal{O}(n)$ edges) subnetwork so that the simulation\ntolerates an adversarial error rate of $\\Omega\\left(\\frac{1}{n}\\right)$; the\nsimulation has a round complexity of $\\mathcal{O}\\left(\\frac{m \\log n}{n}\nT\\right)$, where $m$ is the number of edges in $G$. (So the simulation is\nwork-preserving up to a $\\log$ factor.) The adversary's error rate is within a\nconstant factor of optimal. Given the error rate, the round complexity blowup\nis within a factor of $\\mathcal{O}(k \\log n)$ of optimal, where $k$ is the edge\nconnectivity of $G$. We also determine that the maximum tolerable error rate on\ndirected communication networks is $\\Theta(1/s)$ where $s$ is the number of\nedges in a minimum equivalent digraph.\n  Next we investigate adversarial per-edge error rates, where the adversary is\ngiven an error budget on each edge of the network. We determine the exact limit\nfor tolerable per-edge error rates on an arbitrary directed graph. However, the\nconstruction that approaches this limit has exponential round complexity, so we\ngive another compiler, which transforms $T$-round protocols into\n$\\mathcal{O}(mT)$-round simulations, and prove that for polynomial-query black\nbox compilers, the per-edge error rate tolerated by this last compiler is\nwithin a constant factor of optimal.\n", "versions": [{"version": "v1", "created": "Sun, 28 Dec 2014 02:02:03 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2015 21:38:35 GMT"}], "update_date": "2015-04-30", "authors_parsed": [["Hoza", "William M.", ""], ["Schulman", "Leonard J.", ""]]}, {"id": "1412.8266", "submitter": "Jonathan Passerat-Palmbach", "authors": "Jonathan Passerat-Palmbach (ISIMA, UBP, LIMOS), David Hill (LIMOS,\n  UBP, ISIMA)", "title": "How to Correctly Deal With Pseudorandom Numbers in Manycore Environments\n  - Application to GPU programming with Shoverand", "comments": null, "journal-ref": "IEEE High Performance Computing and Simulation conference 2012,\n  Jul 2012, Madrid, Spain. pp.25 - 31", "doi": "10.1109/HPCSim.2012.6266887", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic simulations are often sensitive to the source of randomness that\ncharacter-izes the statistical quality of their results. Consequently, we need\nhighly reliable Random Number Generators (RNGs) to feed such applications.\nRecent developments try to shrink the computa-tion time by relying more and\nmore General Purpose Graphics Processing Units (GP-GPUs) to speed-up stochastic\nsimulations. Such devices bring new parallelization possibilities, but they\nalso introduce new programming difficulties. Since RNGs are at the base of any\nstochastic simulation, they also need to be ported to GP-GPU. There is still a\nlack of well-designed implementations of quality-proven RNGs on GP-GPU\nplatforms. In this paper, we introduce ShoveRand, a frame-work defining common\nrules to generate random numbers uniformly on GP-GPU. Our framework is designed\nto cope with any GPU-enabled development platform and to expose a\nstraightfor-ward interface to users. We also provide an existing RNG\nimplementation with this framework to demonstrate its efficiency in both\ndevelopment and ease of use.\n", "versions": [{"version": "v1", "created": "Mon, 29 Dec 2014 06:35:00 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Passerat-Palmbach", "Jonathan", "", "ISIMA, UBP, LIMOS"], ["Hill", "David", "", "LIMOS,\n  UBP, ISIMA"]]}, {"id": "1412.8299", "submitter": "Daniel Langr", "authors": "Daniel Langr and Ivan \\v{S}ime\\v{c}ek and Pavel Tvrd\\'ik", "title": "Loading Large Sparse Matrices Stored in Files in the Adaptive-Blocking\n  Hierarchical Storage Format", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The parallel algorithm for loading large sparse matrices from files into\ndistributed memories of high performance computing (HPC) systems is presented.\nThis algorithm was designed specially for matrices stored in files in the\nspace-effcient adaptive-blocking hierarchical storage format (ABHSF). The\nalgorithm can be used even if matrix storing and loading procedures use a\ndifferent number of processes, different matrix-processes mapping, or different\nin-memory storage format. The file format based on the utilization of the HDF5\nlibrary is described as well. Finally, the presented experimental study\nevaluates the proposed algorithm empirically.\n", "versions": [{"version": "v1", "created": "Mon, 29 Dec 2014 10:38:42 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Langr", "Daniel", ""], ["\u0160ime\u010dek", "Ivan", ""], ["Tvrd\u00edk", "Pavel", ""]]}, {"id": "1412.8324", "submitter": "Haoxiang Lin", "authors": "Haoxiang Lin", "title": "A Constructive Proof on the Compositionality of Linearizability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linearizability is the strongest correctness property for both shared memory\nand message passing systems. One of its useful features is the\ncompositionality: a history (execution) is linearizable if and only if each\nobject (component) subhistory is linearizable. In this paper, we propose a new\nhierarchical system model to address challenges in modular development of cloud\nsystems. Object are defined by induction from the most fundamental atomic\nBoolean registers, and histories are represented as countable well-ordered\nstructures of events to deal with both finite and infinite executions. Then, we\npresent a new constructive proof on the compositionality theorem of\nlinearizability inspired by Multiway Merge. This proof deduces a theoretically\nefficient algorithm which generates linearization in O(N*logP) running time\nwith O(N) space, where P and N are process/event numbers respectively.\n", "versions": [{"version": "v1", "created": "Mon, 29 Dec 2014 12:50:42 GMT"}, {"version": "v2", "created": "Thu, 26 Mar 2015 06:56:09 GMT"}, {"version": "v3", "created": "Thu, 8 Feb 2018 05:50:06 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Lin", "Haoxiang", ""]]}, {"id": "1412.8461", "submitter": "Yanhong Annie Liu", "authors": "Yanhong A. Liu and Scott D. Stoller and Bo Lin", "title": "From Clarity to Efficiency for Distributed Algorithms", "comments": null, "journal-ref": "ACM Transactions on Programming Languages and Systems (TOPLAS)\n  Volume 39 Issue 3, July 2017 Article No. 12", "doi": "10.1145/2994595", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article describes a very high-level language for clear description of\ndistributed algorithms and optimizations necessary for generating efficient\nimplementations. The language supports high-level control flows where complex\nsynchronization conditions can be expressed using high-level queries,\nespecially logic quantifications, over message history sequences.\nUnfortunately, the programs would be extremely inefficient, including consuming\nunbounded memory, if executed straightforwardly.\n  We present new optimizations that automatically transform complex\nsynchronization conditions into incremental updates of necessary auxiliary\nvalues as messages are sent and received. The core of the optimizations is the\nfirst general method for efficient implementation of logic quantifications. We\nhave developed an operational semantics of the language, implemented a\nprototype of the compiler and the optimizations, and successfully used the\nlanguage and implementation on a variety of important distributed algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 29 Dec 2014 20:52:34 GMT"}, {"version": "v2", "created": "Sun, 4 Jan 2015 21:25:03 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2016 21:09:01 GMT"}, {"version": "v4", "created": "Sun, 12 Mar 2017 02:34:40 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Liu", "Yanhong A.", ""], ["Stoller", "Scott D.", ""], ["Lin", "Bo", ""]]}, {"id": "1412.8532", "submitter": "Lewis Tseng", "authors": "Lewis Tseng and Nitin Vaidya", "title": "Crash-Tolerant Consensus in Directed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work considers a point-to-point network of n nodes connected by directed\nlinks, and proves tight necessary and sufficient conditions on the underlying\ncommunication graphs for achieving consensus among these nodes under crash\nfaults. We identify the conditions in both synchronous and asynchronous systems\n", "versions": [{"version": "v1", "created": "Tue, 30 Dec 2014 02:06:01 GMT"}, {"version": "v2", "created": "Fri, 2 Jan 2015 05:57:14 GMT"}], "update_date": "2015-01-05", "authors_parsed": [["Tseng", "Lewis", ""], ["Vaidya", "Nitin", ""]]}]