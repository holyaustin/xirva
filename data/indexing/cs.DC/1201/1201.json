[{"id": "1201.0205", "submitter": "Feng Xia", "authors": "Guowei Wu, Dongze Lu, Feng Xia, Lin Yao", "title": "A Fault-Tolerant Emergency-Aware Access Control Scheme for\n  Cyber-Physical Systems", "comments": null, "journal-ref": "Information Technology and Control, 2011, Vol.40, No.1, pp. 29-40", "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Access control is an issue of paramount importance in cyber-physical systems\n(CPS). In this paper, an access control scheme, namely FEAC, is presented for\nCPS. FEAC can not only provide the ability to control access to data in normal\nsituations, but also adaptively assign emergency-role and permissions to\nspecific subjects and inform subjects without explicit access requests to\nhandle emergency situations in a proactive manner. In FEAC, emergency-group and\nemergency-dependency are introduced. Emergencies are processed in sequence\nwithin the group and in parallel among groups. A priority and dependency model\ncalled PD-AGM is used to select optimal response-action execution path aiming\nto eliminate all emergencies that occurred within the system. Fault-tolerant\naccess control polices are used to address failure in emergency management. A\ncase study of the hospital medical care application shows the effectiveness of\nFEAC.\n", "versions": [{"version": "v1", "created": "Sat, 31 Dec 2011 01:13:13 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Wu", "Guowei", ""], ["Lu", "Dongze", ""], ["Xia", "Feng", ""], ["Yao", "Lin", ""]]}, {"id": "1201.0349", "submitter": "Matthias W\\\"ahlisch", "authors": "Thomas C. Schmidt and Matthias W\\\"ahlisch", "title": "Why We Shouldn't Forget Multicast in Name-oriented Publish/Subscribe", "comments": null, "journal-ref": "Thomas C. Schmidt, Matthias W\\\"ahlisch, Dominik Charousset,\n  Sebastian Meiling, On Name-based Group Communication: Challenges Concepts and\n  Transparent Deployment, Computer Communications, Vol. 36, No. 15--16, pp.\n  1657-1664, Sep-Oct 2013", "doi": "10.1016/j.comcom.2013.08.001", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Name-oriented networks introduce the vision of an information-centric,\nsecure, globally available publish-subscribe infrastructure. Current approaches\nconcentrate on unicast-based pull mechanisms and thereby fall short in\nautomatically updating content at receivers. In this paper, we argue that an\ninclusion of multicast will grant additional benefits to the network layer,\nnamely efficient distribution of real-time data, a many-to-many communication\nmodel, and simplified rendezvous processes. These aspects are comprehensively\nreflected by a group-oriented naming concept that integrates the various\navailable group schemes and introduces new use cases. A first draft of this\nname-oriented multicast access has been implemented in the HAMcast middleware.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2012 12:58:24 GMT"}], "update_date": "2013-12-05", "authors_parsed": [["Schmidt", "Thomas C.", ""], ["W\u00e4hlisch", "Matthias", ""]]}, {"id": "1201.0360", "submitter": "Toni Stojanovski", "authors": "Toni Stojanovski, Ljupco Krstevski", "title": "On the Performance of Exhaustive Search with Cooperating agents", "comments": "ETAI Conference, September 2011, Ohrid, Macedonia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite the occurrence of elegant algorithms for solving complex problem,\nexhaustive search has retained its significance since many real-life problems\nexhibit no regular structure and exhaustive search is the only possible\nsolution. The advent of high-performance computing either via multicore\nprocessors or distributed processors emphasizes the possibility for exhaustive\nsearch by multiple search agents. Here we analyse the performance of exhaustive\nsearch when it is conducted by multiple search agents. Several strategies for\ncooperation between the search agents are evaluated. We discover that the\nperformance of the search improves with the increase in the level of\ncooperation. Same search performance can be achieved with homogeneous and\nheterogeneous search agents provided that the length of subregions allocated to\nindividual search regions follow the differences in the speeds of heterogeneous\nsearch agents.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jan 2012 16:03:49 GMT"}], "update_date": "2012-01-04", "authors_parsed": [["Stojanovski", "Toni", ""], ["Krstevski", "Ljupco", ""]]}, {"id": "1201.1363", "submitter": "Anisur Molla Rahaman", "authors": "Atish Das Sarma, Anisur Rahaman Molla and Gopal Pandurangan", "title": "Near-Optimal Random Walk Sampling in Distributed Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performing random walks in networks is a fundamental primitive that has found\nnumerous applications in communication networks such as token management, load\nbalancing, network topology discovery and construction, search, and\npeer-to-peer membership management. While several such algorithms are\nubiquitous, and use numerous random walk samples, the walks themselves have\nalways been performed naively.\n  In this paper, we focus on the problem of performing random walk sampling\nefficiently in a distributed network. Given bandwidth constraints, the goal is\nto minimize the number of rounds and messages required to obtain several random\nwalk samples in a continuous online fashion. We present the first round and\nmessage optimal distributed algorithms that present a significant improvement\non all previous approaches. The theoretical analysis and comprehensive\nexperimental evaluation of our algorithms show that they perform very well in\ndifferent types of networks of differing topologies.\n  In particular, our results show how several random walks can be performed\ncontinuously (when source nodes are provided only at runtime, i.e., online),\nsuch that each walk of length $\\ell$ can be performed exactly in just\n$\\tilde{O}(\\sqrt{\\ell D})$ rounds, (where $D$ is the diameter of the network),\nand $O(\\ell)$ messages. This significantly improves upon both, the naive\ntechnique that requires $O(\\ell)$ rounds and $O(\\ell)$ messages, and the\nsophisticated algorithm of [DasSarma et al. PODC 2010] that has the same round\ncomplexity as this paper but requires $\\Omega(m\\sqrt{\\ell})$ messages (where\n$m$ is the number of edges in the network). Our theoretical results are\ncorroborated through extensive experiments on various topological data sets.\nOur algorithms are fully decentralized, lightweight, and easily implementable,\nand can serve as building blocks in the design of topologically-aware networks.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jan 2012 08:16:45 GMT"}, {"version": "v2", "created": "Wed, 11 Jan 2012 16:32:42 GMT"}], "update_date": "2012-01-12", "authors_parsed": [["Sarma", "Atish Das", ""], ["Molla", "Anisur Rahaman", ""], ["Pandurangan", "Gopal", ""]]}, {"id": "1201.1695", "submitter": "Nikzad Babaii-Rizvandi", "authors": "Nikzad Babaii Rizvandi, Javid Taheri, and Albert Y. Zomaya", "title": "Some Observations on Optimal Frequency Selection in DVFS-based Energy\n  Consumption Minimization", "comments": "Journal of Parallel and Distributed Systems, August 2011", "journal-ref": "Journal of Parallel and Distributed Computing, Volume 71, Issue 8,\n  August 2011, Pages 1154-1164", "doi": "10.1016/j.jpdc.2011.01.004", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, the issue of energy consumption in parallel and distributed\ncomputing systems has attracted a great deal of attention. In response to this,\nmany energy-aware scheduling algorithms have been developed primarily using the\ndynamic voltage-frequency scaling (DVFS) capability which has been incorporated\ninto recent commodity processors. Majority of these algorithms involve two\npasses: schedule generation and slack reclamation. The former pass involves the\nredistribution of tasks among DVFS-enabled processors based on a given cost\nfunction that includes makespan and energy consumption; and, while the latter\npass is typically achieved by executing individual tasks with slacks at a lower\nprocessor frequency. In this paper, a new slack reclamation algorithm is\nproposed by approaching the energy reduction problem from a different angle.\nFirstly, the problem of task slack reclamation by using combinations of\nprocessors' frequencies is formulated. Secondly, several proofs are provided to\nshow that (1) if the working frequency set of processor is assumed to be\ncontinues, the optimal energy will be always achieved by using only one\nfrequency, (2) for real processors with a discrete set of working frequencies,\nthe optimal energy is always achieved by using at most two frequencies, and (3)\nthese two frequencies are adjacent/neighbouring when processor energy\nconsumption is a convex function of frequency. Thirdly, a novel algorithm to\nfind the best combination of frequencies to result the optimal energy is\npresented. The presented algorithm has been evaluated based on results obtained\nfrom experiments with three different sets of task graphs: 3000 randomly\ngenerated task graphs, and 600 task graphs for two popular applications\n(Gauss-Jordan and LU decomposition). The results show the superiority of the\nproposed algorithm in comparison with other techniques.\n", "versions": [{"version": "v1", "created": "Mon, 9 Jan 2012 06:31:03 GMT"}], "update_date": "2013-01-30", "authors_parsed": [["Rizvandi", "Nikzad Babaii", ""], ["Taheri", "Javid", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "1201.2118", "submitter": "Erik Schnetter", "authors": "Marek Blazewicz, Steven R. Brandt, Peter Diener, David M. Koppelman,\n  Krzysztof Kurowski, Frank L\\\"offler, Erik Schnetter, Jian Tao", "title": "A Massive Data Parallel Computational Framework for Petascale/Exascale\n  Hybrid Computer Systems", "comments": "Parallel Computing 2011 (ParCo2011), 30 August -- 2 September 2011,\n  Ghent, Belgium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous systems are becoming more common on High Performance Computing\n(HPC) systems. Even using tools like CUDA and OpenCL it is a non-trivial task\nto obtain optimal performance on the GPU. Approaches to simplifying this task\ninclude Merge (a library based framework for heterogeneous multi-core systems),\nZippy (a framework for parallel execution of codes on multiple GPUs), BSGP (a\nnew programming language for general purpose computation on the GPU) and\nCUDA-lite (an enhancement to CUDA that transforms code based on annotations).\nIn addition, efforts are underway to improve compiler tools for automatic\nparallelization and optimization of affine loop nests for GPUs and for\nautomatic translation of OpenMP parallelized codes to CUDA.\n  In this paper we present an alternative approach: a new computational\nframework for the development of massively data parallel scientific codes\napplications suitable for use on such petascale/exascale hybrid systems built\nupon the highly scalable Cactus framework. As the first non-trivial\ndemonstration of its usefulness, we successfully developed a new 3D CFD code\nthat achieves improved performance.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2012 17:20:17 GMT"}], "update_date": "2012-01-11", "authors_parsed": [["Blazewicz", "Marek", ""], ["Brandt", "Steven R.", ""], ["Diener", "Peter", ""], ["Koppelman", "David M.", ""], ["Kurowski", "Krzysztof", ""], ["L\u00f6ffler", "Frank", ""], ["Schnetter", "Erik", ""], ["Tao", "Jian", ""]]}, {"id": "1201.2125", "submitter": "Suresh Kumar Mr.", "authors": "P. Suresh Kumar, P. Sateesh Kumar, S. Ramachandram", "title": "Purging of untrustworthy recommendations from a grid", "comments": "8 pages, 4 figures, 1 table published by IJNGN journal; International\n  Journal of Next-Generation Networks (IJNGN) Vol.3, No.4, December 2011", "journal-ref": null, "doi": "10.5121/ijngn.2011.3403", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In grid computing, trust has massive significance. There is lot of research\nto propose various models in providing trusted resource sharing mechanisms. The\ntrust is a belief or perception that various researchers have tried to\ncorrelate with some computational model. Trust on any entity can be direct or\nindirect. Direct trust is the impact of either first impression over the entity\nor acquired during some direct interaction. Indirect trust is the trust may be\ndue to either reputation gained or recommendations received from various\nrecommenders of a particular domain in a grid or any other domain outside that\ngrid or outside that grid itself. Unfortunately, malicious indirect trust leads\nto the misuse of valuable resources of the grid. This paper proposes the\nmechanism of identifying and purging the untrustworthy recommendations in the\ngrid environment. Through the obtained results, we show the way of purging of\nuntrustworthy entities.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jan 2012 17:46:16 GMT"}], "update_date": "2012-01-11", "authors_parsed": [["Kumar", "P. Suresh", ""], ["Kumar", "P. Sateesh", ""], ["Ramachandram", "S.", ""]]}, {"id": "1201.2288", "submitter": "Vijay Dhir", "authors": "Vijay Dhir, Rattan K. Datta and Maitreyee Dutta", "title": "Nimble@ITCEcnoGrid: A Grid in Research Domain for Weather Forecasting", "comments": "11 pages", "journal-ref": "International Journal of Grid Computing & Applications (IJGCA)\n  Vol.2, No.4, December 2011, 37-47", "doi": "10.5121/ijgca.2011.2404", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer Technology has Revolutionized Science. This has motivated scientists\nto develop mathematical model to simulate salient features of Physical\nuniverse. These models can approximate reality at many levels of scale such as\natomic nucleus, Earth's biosphere & weather/climate assessment. If the computer\npower is greater, the greater will be the accuracy in approximation i.e. close\nwill be the approximation to the reality. The speed of the computer required\nfor solution of such problems require computers with processing power of\nteraflops to Pets flops speed.. The way to speed up the computation is to\n\"parallelize\" it. One of the approach is to use multimillion dollar\nSupercomputer or use Computational Grid (which is also called poor man's\nsupercomputer) having geographically distributed resources e.g. SETI@home (Used\nto detect radio waves emitted by intelligent civilizations outside earth) has\n4.6 million participants computers. There are many alternatives tools available\nto achieve this goal like Globus Toolkit, Entropia, Legion, BOINC etc but they\nare mainly based on Linux platform. As majority of the computers available are\nwindows based, so it will be easy to develop a larger network of computers\nwhich will use the free cycles of the computer to solve the complex problem at\nwindow platform. Nimble@ITCEcnoGrid has been developed. It includes the feature\nof Inter Thread Communication which is missing in any of the toolkits\navailable. Nimble@ITCEcnoGrid Framework (A Fast Grid with Inter-thread\ncommunication with Economic Based Policy) was tested for computation of 'PI' up\nto 120 decimal points. Encouraged by the speed the same system has been\nutilized to computes the Momentum, Thermodynamics and Continuity equations for\nthe Weather Forecasting using the Windows based Desktop computers.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2012 12:02:39 GMT"}], "update_date": "2012-01-12", "authors_parsed": [["Dhir", "Vijay", ""], ["Datta", "Rattan K.", ""], ["Dutta", "Maitreyee", ""]]}, {"id": "1201.2360", "submitter": "Matteo Dell'Amico Ph.D.", "authors": "Matteo Dell'Amico, Pietro Michiardi, Laszlo Toka, Pasquale Cataldi", "title": "Adaptive Redundancy Management for Durable P2P Backup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and analyze the performance of a redundancy management mechanism\nfor Peer-to-Peer backup applications. Armed with the realization that a backup\nsystem has peculiar requirements -- namely, data is read over the network only\nduring restore processes caused by data loss -- redundancy management targets\ndata durability rather than attempting to make each piece of information\navailabile at any time.\n  In our approach each peer determines, in an on-line manner, an amount of\nredundancy sufficient to counter the effects of peer deaths, while preserving\nacceptable data restore times. Our experiments, based on trace-driven\nsimulations, indicate that our mechanism can reduce the redundancy by a factor\nbetween two and three with respect to redundancy policies aiming for data\navailability. These results imply an according increase in storage capacity and\ndecrease in time to complete backups, at the expense of longer times required\nto restore data. We believe this is a very reasonable price to pay, given the\nnature of the application.\n  We complete our work with a discussion on practical issues, and their\nsolutions, related to which encoding technique is more suitable to support our\nscheme.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jan 2012 17:56:56 GMT"}, {"version": "v2", "created": "Fri, 17 Jan 2014 10:23:00 GMT"}], "update_date": "2014-01-20", "authors_parsed": [["Dell'Amico", "Matteo", ""], ["Michiardi", "Pietro", ""], ["Toka", "Laszlo", ""], ["Cataldi", "Pasquale", ""]]}, {"id": "1201.2703", "submitter": "Rachit Agarwal", "authors": "Rachit Agarwal, P. Brighten Godfrey, Sariel Har-Peled", "title": "Faster Approximate Distance Queries and Compact Routing in Sparse Graphs", "comments": "20 pages, an earlier version appeared in INFOCOM 2011, this version\n  presents data structures with improved space/query-time trade-off", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distance oracle is a compact representation of the shortest distance matrix\nof a graph. It can be queried to approximate shortest paths between any pair of\nvertices. Any distance oracle that returns paths of worst-case stretch (2k-1)\nmust require space $\\Omega(n^{1 + 1/k})$ for graphs of n nodes. The hard cases\nthat enforce this lower bound are, however, rather dense graphs with average\ndegree \\Omega(n^{1/k}).\n  We present distance oracles that, for sparse graphs, substantially break the\nlower bound barrier at the expense of higher query time. For any 1 \\leq \\alpha\n\\leq n, our distance oracles can return stretch 2 paths using O(m + n^2/\\alpha)\nspace and stretch 3 paths using O(m + n^2/\\alpha^2) space, at the expense of\nO(\\alpha m/n) query time. By setting appropriate values of \\alpha, we get the\nfirst distance oracles that have size linear in the size of the graph, and\nreturn constant stretch paths in non-trivial query time. The query time can be\nfurther reduced to O(\\alpha), by using an additional O(m \\alpha) space for all\nour distance oracles, or at the cost of a small constant additive stretch.\n  We use our stretch 2 distance oracle to present the first compact routing\nscheme with worst-case stretch 2. Any compact routing scheme with stretch less\nthan 2 must require linear memory at some nodes even for sparse graphs; our\nscheme, hence, achieves the optimal stretch with non-trivial memory\nrequirements. Moreover, supported by large-scale simulations on graphs\nincluding the AS-level Internet graph, we argue that our stretch-2 scheme would\nbe simple and efficient to implement as a distributed compact routing protocol.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jan 2012 23:03:18 GMT"}], "update_date": "2012-01-16", "authors_parsed": [["Agarwal", "Rachit", ""], ["Godfrey", "P. Brighten", ""], ["Har-Peled", "Sariel", ""]]}, {"id": "1201.2715", "submitter": "He Sun", "authors": "Thomas Sauerwald and He Sun", "title": "Tight Bounds for Randomized Load Balancing on Arbitrary Network\n  Topologies", "comments": "74 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DC cs.DS math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of balancing load items (tokens) in networks.\nStarting with an arbitrary load distribution, we allow nodes to exchange tokens\nwith their neighbors in each round. The goal is to achieve a distribution where\nall nodes have nearly the same number of tokens.\n  For the continuous case where tokens are arbitrarily divisible, most load\nbalancing schemes correspond to Markov chains, whose convergence is fairly\nwell-understood in terms of their spectral gap. However, in many applications,\nload items cannot be divided arbitrarily, and we need to deal with the discrete\ncase where the load is composed of indivisible tokens. This discretization\nentails a non-linear behavior due to its rounding errors, which makes this\nanalysis much harder than in the continuous case.\n  We investigate several randomized protocols for different communication\nmodels in the discrete case. As our main result, we prove that for any regular\nnetwork in the matching model, all nodes have the same load up to an additive\nconstant in (asymptotically) the same number of rounds as required in the\ncontinuous case. This generalizes and tightens the previous best result, which\nonly holds for expander graphs, and demonstrates that there is almost no\ndifference between the discrete and continuous cases. Our results also provide\na positive answer to the question of how well discrete load balancing can be\napproximated by (continuous) Markov chains, which has been posed by many\nresearchers.\n", "versions": [{"version": "v1", "created": "Fri, 13 Jan 2012 00:25:54 GMT"}, {"version": "v2", "created": "Mon, 9 Apr 2012 21:28:27 GMT"}, {"version": "v3", "created": "Mon, 10 Nov 2014 18:49:42 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Sauerwald", "Thomas", ""], ["Sun", "He", ""]]}, {"id": "1201.3310", "submitter": "Gahyun Park", "authors": "Gahyun Park", "title": "A Generalization of Multiple Choice Balls-into-Bins: Tight Bounds", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates a general version of the multiple choice model called\nthe $(k,d)$-choice process in which $n$ balls are assigned to $n$ bins. In the\nprocess, $k<d$ balls are placed into $k$ least loaded out of $d$ bins chosen\nindependently and uniformly at random in each of $\\frac{n}{k}$ rounds. The\nprimary goal is to derive tight bounds on the maximum bin load for\n$(k,d)$-choice for any $1 \\leq k < d \\leq n$. Our results enable one to choose\nsuitable parameters $k$ and $d$ for which the $(k,d)$-choice process achieves\nthe optimal tradeoff between the maximum bin load and message cost: a constant\nmaximum load and $2n$ messages. It is also shown that the maximum load for a\nheavily loaded case, in which $m>n$ balls are placed into $n$ bins, if $d \\geq\n2k$. Potential applications are also discussed such as distributed storage as\nwell as parallel job scheduling in a cluster.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 16:37:06 GMT"}, {"version": "v2", "created": "Thu, 5 Apr 2012 01:57:06 GMT"}, {"version": "v3", "created": "Wed, 9 Jul 2014 14:16:59 GMT"}, {"version": "v4", "created": "Tue, 24 Feb 2015 16:04:31 GMT"}, {"version": "v5", "created": "Mon, 11 Jul 2016 11:32:03 GMT"}], "update_date": "2016-07-12", "authors_parsed": [["Park", "Gahyun", ""]]}, {"id": "1201.3318", "submitter": "Marcin Kik", "authors": "Marcin Kik", "title": "Notes on Bit-reversal Broadcast Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report contains revision and extension of some results about RBO\n[arXiv:1108.5095]. RBO is a simple and efficient broadcast scheduling of $n =\n2^k$ uniform frames for battery powered radio receivers. Each frame contains a\nkey from some arbitrary linearly ordered universe. The broadcast cycle -- a\nsequence of frames sorted by the keys and permuted by $k$-bit reversal -- is\ntransmitted in a round robin fashion by the broadcaster. At arbitrary time\nduring the transmission, the receiver may start a simple protocol that reports\nto him all the frames with the keys that are contained in a specified interval\nof the key values $[K', K\"]$. RBO receives at most $2 k + 1$ other frames' keys\nbefore receiving the first key from $[K', K\"]$ or noticing that there are no\nsuch keys in the broadcast cycle. As a simple corollary, $4 k + 2$ is upper\nbound the number of keys outside $[K', K\"]$ that will ever be received. In\nunreliable network the expected number of efforts to receive such frames is\nbounded by $(8 k + 4) / p + 2 (1 - p) / p^2$, where $p$ is probability of\nsuccessful reception, and the reception rate of the requested frames is $p$ --\nthe highest possible. The receiver's protocol state consists of the values $k$,\n$K'$ and $K\"$, one wake-up timer and two other $k$-bit variables. Its only\nnontrivial computation -- the computation of the next wake-up time slot -- can\nbe performed in $O (k)$ simple operations, such as arithmetic/bit-wise\noperations on $k$-bit numbers, using only constant number of $k$-bit variables.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jan 2012 16:56:45 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Kik", "Marcin", ""]]}, {"id": "1201.3667", "submitter": "Simon Kramer", "authors": "Simon Kramer", "title": "A Logic of Interactive Proofs (Formal Theory of Knowledge Transfer)", "comments": "added Appendix D; related to arXiv:1208.1842, arXiv:1208.5913, and\n  arXiv:1309.1328", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.CR cs.DC cs.MA math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a logic of interactive proofs as a framework for an intuitionistic\nfoundation for interactive computation, which we construct via an interactive\nanalog of the Goedel-McKinsey-Tarski-Artemov definition of Intuitionistic Logic\nas embedded into a classical modal logic of proofs, and of the Curry-Howard\nisomorphism between intuitionistic proofs and typed programs. Our interactive\nproofs effectuate a persistent epistemic impact in their intended communities\nof peer reviewers that consists in the induction of the (propositional)\nknowledge of their proof goal by means of the (individual) knowledge of the\nproof with the interpreting reviewer. That is, interactive proofs effectuate a\ntransfer of propositional knowledge (knowable facts) via the transmission of\ncertain individual knowledge (knowable proofs) in multi-agent distributed\nsystems. In other words, we as a community can have the formal common knowledge\nthat a proof is that which if known to one of our peer members would induce the\nknowledge of its proof goal with that member. Last but not least, we prove\nnon-trivial interactive computation as definable within our simply typed\ninteractive Combinatory Logic to be nonetheless equipotent to non-interactive\ncomputation as defined by simply typed Combinatory Logic.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jan 2012 23:33:40 GMT"}, {"version": "v2", "created": "Thu, 23 Feb 2012 09:23:57 GMT"}, {"version": "v3", "created": "Thu, 14 Jun 2012 14:45:17 GMT"}, {"version": "v4", "created": "Fri, 19 Sep 2014 10:50:33 GMT"}, {"version": "v5", "created": "Tue, 5 Apr 2016 07:58:48 GMT"}, {"version": "v6", "created": "Tue, 8 Aug 2017 08:48:52 GMT"}], "update_date": "2017-08-09", "authors_parsed": [["Kramer", "Simon", ""]]}, {"id": "1201.3804", "submitter": "Mads Kristensen", "authors": "Mads Ruben Burgdorff Kristensen and Brian Vinter", "title": "Managing Communication Latency-Hiding at Runtime for Parallel\n  Programming Languages and Libraries", "comments": "PREPRINT", "journal-ref": "Proceeding HPCC '12 Proceedings of the 2012 IEEE 14th\n  International Conference on High Performance Computing and Communication &\n  2012 IEEE 9th International Conference on Embedded Software and Systems", "doi": "10.1109/HPCC.2012.80", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a runtime model for managing communication with support\nfor latency-hiding. The model enables non-computer science researchers to\nexploit communication latency-hiding techniques seamlessly. For compiled\nlanguages, it is often possible to create efficient schedules for\ncommunication, but this is not the case for interpreted languages. By\nmaintaining data dependencies between scheduled operations, it is possible to\naggressively initiate communication and lazily evaluate tasks to allow maximal\ntime for the communication to finish before entering a wait state. We implement\na heuristic of this model in DistNumPy, an auto-parallelizing version of\nnumerical Python that allows sequential NumPy programs to run on distributed\nmemory architectures. Furthermore, we present performance comparisons for eight\nbenchmarks with and without automatic latency-hiding. The results shows that\nour model reduces the time spent on waiting for communication as much as 27\ntimes, from a maximum of 54% to only 2% of the total execution time, in a\nstencil application.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 14:43:43 GMT"}], "update_date": "2013-05-16", "authors_parsed": [["Kristensen", "Mads Ruben Burgdorff", ""], ["Vinter", "Brian", ""]]}, {"id": "1201.3881", "submitter": "Alain-J\\'er\\^ome Foug\\`eres", "authors": "Alain-J\\'er\\^ome Foug\\`eres", "title": "Agent-Based {\\mu}-Tools Integrated into a Co-Design Platform", "comments": "10 pages; IJCSI International Journal of Computer Science Issues,\n  Vol. 7, Issue 1, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present successively the proposition and the design of: 1)\n{\\mu}-tools adapted to collaborative activity of design, and 2) a multi-agent\nplatform adapted to innovative and distributed design of products or services.\nThis platform called PLACID (innovating and distributed design platform) must\nsupport applications of assistance to actors implies in a design process that\nwe have called {\\mu}-tools. {\\mu}-tools are developed with an aim of bringing\nassistance to Co-design. The use of the paradigm agent as well relates to the\nmodeling and the development of various layers of the platform, that those of\nthe human-computer interfaces. With these objectives, constraints are added to\nfacilitate the integration of new co-operative tools.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2012 19:08:23 GMT"}], "update_date": "2012-01-19", "authors_parsed": [["Foug\u00e8res", "Alain-J\u00e9r\u00f4me", ""]]}, {"id": "1201.4153", "submitter": "Vance Faber", "authors": "Vance Faber", "title": "Global sum on symmetric networks", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are interested in the following problem we call global sum. Each processor\nstarts with a single real value. At each time step, every directed edge in the\ngraph can simultaneously be used to transmit a single (bounded) number between\nthe processors (vertices). How many time steps s are required to ensure that\nevery processor acquires the global sum? We know that s is bounded below by the\ndiameter and above by two times the diameter. We conjecture that for vertex\nsymmetric graphs, s is equal to the diameter. We show this is true if the\ndiameter is 2.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2012 19:27:40 GMT"}], "update_date": "2012-01-20", "authors_parsed": [["Faber", "Vance", ""]]}, {"id": "1201.4183", "submitter": "Guanfeng Liang", "authors": "Nitin Vaidya and Lewis Tseng and Guanfeng Liang", "title": "Iterative Approximate Byzantine Consensus in Arbitrary Directed Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore the problem of iterative approximate Byzantine\nconsensus in arbitrary directed graphs. In particular, we prove a necessary and\nsufficient condition for the existence of iterative byzantine consensus\nalgorithms. Additionally, we use our sufficient condition to examine whether\nsuch algorithms exist for some specific graphs.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2012 22:05:08 GMT"}, {"version": "v2", "created": "Thu, 2 Feb 2012 21:59:47 GMT"}], "update_date": "2012-02-06", "authors_parsed": [["Vaidya", "Nitin", ""], ["Tseng", "Lewis", ""], ["Liang", "Guanfeng", ""]]}, {"id": "1201.4262", "submitter": "Chris Hankin", "authors": "Fan Yang, Chris Hankin, Flemming Nielson, Hanne Riis Nielson", "title": "Secondary use of data in EHR systems", "comments": "40 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to use aspect-oriented programming to separate security and trust\nissues from the logical design of mobile, distributed systems. The main\nchallenge is how to enforce various types of security policies, in particular\npredictive access control policies - policies based on the future behavior of a\nprogram. A novel feature of our approach is that advice is able to analyze the\nfuture use of data. We consider a number of different security policies,\nconcerning both primary and secondary use of data, some of which can only be\nenforced by analysis of process continuations.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jan 2012 11:11:37 GMT"}], "update_date": "2012-01-23", "authors_parsed": [["Yang", "Fan", ""], ["Hankin", "Chris", ""], ["Nielson", "Flemming", ""], ["Nielson", "Hanne Riis", ""]]}, {"id": "1201.4480", "submitter": "Saber Jafarizadeh", "authors": "Saber Jafarizadeh, Abbas Jamalipour", "title": "A Solution to Fastest Distributed Consensus Problem for Generic Star &\n  K-cored Star Networks", "comments": "8 pages, 5 figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed average consensus is the main mechanism in algorithms for\ndecentralized computation. In distributed average consensus algorithm each node\nhas an initial state, and the goal is to compute the average of these initial\nstates in every node. To accomplish this task, each node updates its state by a\nweighted average of its own and neighbors' states, by using local communication\nbetween neighboring nodes. In the networks with fixed topology, convergence\nrate of distributed average consensus algorithm depends on the choice of\nweights. This paper studies the weight optimization problem in distributed\naverage consensus algorithm. The network topology considered here is a star\nnetwork where the branches have different lengths. Closed-form formulas of\noptimal weights and convergence rate of algorithm are determined in terms of\nthe network's topological parameters. Furthermore generic K-cored star topology\nhas been introduced as an alternative to star topology. The introduced topology\nbenefits from faster convergence rate compared to star topology. By simulation\nbetter performance of optimal weights compared to other common weighting\nmethods has been proved.\n", "versions": [{"version": "v1", "created": "Sat, 21 Jan 2012 15:05:01 GMT"}], "update_date": "2012-01-24", "authors_parsed": [["Jafarizadeh", "Saber", ""], ["Jamalipour", "Abbas", ""]]}, {"id": "1201.4522", "submitter": "Rajkumar Buyya", "authors": "Rajkumar Buyya, Saurabh Kumar Garg, and Rodrigo N. Calheiros", "title": "SLA-Oriented Resource Provisioning for Cloud Computing: Challenges,\n  Architecture, and Solutions", "comments": "10 pages, 7 figures, Conference Keynote Paper: 2011 IEEE\n  International Conference on Cloud and Service Computing (CSC 2011, IEEE\n  Press, USA), Hong Kong, China, December 12-14, 2011", "journal-ref": "Proceedings of the 2011 IEEE International Conference on Cloud and\n  Service Computing (CSC 2011, IEEE Press, USA), Hong Kong, China, December\n  12-14, 2011", "doi": "10.1109/CSC.2011.6138522", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing systems promise to offer subscription-oriented,\nenterprise-quality computing services to users worldwide. With the increased\ndemand for delivering services to a large number of users, they need to offer\ndifferentiated services to users and meet their quality expectations. Existing\nresource management systems in data centers are yet to support Service Level\nAgreement (SLA)-oriented resource allocation, and thus need to be enhanced to\nrealize cloud computing and utility computing. In addition, no work has been\ndone to collectively incorporate customer-driven service management,\ncomputational risk management, and autonomic resource management into a\nmarket-based resource management system to target the rapidly changing\nenterprise requirements of Cloud computing. This paper presents vision,\nchallenges, and architectural elements of SLA-oriented resource management. The\nproposed architecture supports integration of marketbased provisioning policies\nand virtualisation technologies for flexible allocation of resources to\napplications. The performance results obtained from our working prototype\nsystem shows the feasibility and effectiveness of SLA-based resource\nprovisioning in Clouds.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jan 2012 01:41:04 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Buyya", "Rajkumar", ""], ["Garg", "Saurabh Kumar", ""], ["Calheiros", "Rodrigo N.", ""]]}, {"id": "1201.4788", "submitter": "Kenneth Mighell", "authors": "Kenneth J. Mighell", "title": "Benchmarking CRBLASTER on the 350-MHz 49-core Maestro Development Board", "comments": "10 pages, 3 figures. To appear in the ADASS XXI (Paris, 2011)\n  conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I describe the performance of the CRBLASTER computational framework on a\n350-MHz 49-core Maestro Development Board (MDB). The 49-core Interim Test Chip\n(ITC) was developed by the U.S. Government and is based on the intellectual\nproperty of the 64-core TILE64 processor of the Tilera Corporation. The Maestro\nprocessor is intended for use in the high radiation environments found in\nspace; the ITC was fabricated using IBM 90-nm CMOS 9SF technology and\nRadiation-Hardening-by-Design (RHDB) rules. CRBLASTER is a parallel-processing\ncosmic-ray rejection application based on a simple computational framework that\nuses the high-performance computing industry standard Message Passing Interface\n(MPI) library. CRBLASTER was designed to be used by research scientists to\neasily port image-analysis programs based on embarrassingly-parallel algorithms\nto a parallel-processing environment such as a multi-node Beowulf cluster or\nmulti-core processors using MPI. I describe my experience of porting CRBLASTER\nto the 64-core TILE64 processor, the Maestro simulator, and finally the 49-core\nMaestro processor itself. Performance comparisons using the ITC are presented\nbetween emulating all floating-point operations in software and doing all\nfloating point operations with hardware assist from an IEEE-754 compliant\nAurora FPU (floating point unit) that is attached to each of the 49 cores.\nBenchmarking of the CRBLASTER computational framework using the\nmemory-intensive L.A.COSMIC cosmic ray rejection algorithm and a\ncomputational-intensive Poisson noise generator reveal subtleties of the\nMaestro hardware design. Lastly, I describe the importance of using real\nscientific applications during the testing phase of next-generation computer\nhardware; complex real-world scientific applications can stress hardware in\nnovel ways that may not necessarily be revealed while executing simple\napplications or unit tests.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2012 17:52:59 GMT"}], "update_date": "2012-01-24", "authors_parsed": [["Mighell", "Kenneth J.", ""]]}, {"id": "1201.4871", "submitter": "Alexander  Heu{\\ss}ner", "authors": "Gilles Geeraerts and Alexander Heu{\\ss}ner and Jean-Fran\\c{c}ois\n  Raskin", "title": "Queue-Dispatch Asynchronous Systems", "comments": "38 pages, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To make the development of efficient multi-core applications easier,\nlibraries, such as Grand Central Dispatch, have been proposed. When using such\na library, the programmer writes so-called blocks, which are chunks of codes,\nand dispatches them, using synchronous or asynchronous calls, to several types\nof waiting queues. A scheduler is then responsible for dispatching those blocks\non the available cores. Blocks can synchronize via a global memory. In this\npaper, we propose Queue-Dispatch Asynchronous Systems as a mathematical model\nthat faithfully formalizes the synchronization mechanisms and the behavior of\nthe scheduler in those systems. We study in detail their relationships to\nclassical formalisms such as pushdown systems, Petri nets, fifo systems, and\ncounter systems. Our main technical contributions are precise worst-case\ncomplexity results for the Parikh coverability problem for several subclasses\nof our model.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2012 21:19:03 GMT"}, {"version": "v2", "created": "Mon, 16 Apr 2012 15:28:10 GMT"}, {"version": "v3", "created": "Wed, 17 Oct 2012 07:00:58 GMT"}], "update_date": "2012-10-18", "authors_parsed": [["Geeraerts", "Gilles", ""], ["Heu\u00dfner", "Alexander", ""], ["Raskin", "Jean-Fran\u00e7ois", ""]]}, {"id": "1201.5135", "submitter": "Richard Peng", "authors": "Richard Peng, Kanat Tangwongsan, Peng Zhang", "title": "Faster and Simpler Width-Independent Parallel Algorithms for Positive\n  Semidefinite Programming", "comments": "Fixed a mistake in the runtime analyses of previous versions", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the problem of finding an $(1+\\epsilon)$-approximate\nsolution to positive semidefinite programs. These are semidefinite programs in\nwhich all matrices in the constraints and objective are positive semidefinite\nand all scalars are non-negative.\n  We present a simpler \\NC parallel algorithm that on input with $n$ constraint\nmatrices, requires $O(\\frac{1}{\\epsilon^3} log^3 n)$ iterations, each of which\ninvolves only simple matrix operations and computing the trace of the product\nof a matrix exponential and a positive semidefinite matrix. Further, given a\npositive SDP in a factorized form, the total work of our algorithm is\nnearly-linear in the number of non-zero entries in the factorization.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jan 2012 21:36:00 GMT"}, {"version": "v2", "created": "Wed, 13 Aug 2014 15:47:51 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2016 04:54:54 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Peng", "Richard", ""], ["Tangwongsan", "Kanat", ""], ["Zhang", "Peng", ""]]}, {"id": "1201.5824", "submitter": "Sebastien Tixeuil", "authors": "Alexandre Maurer (LIP6, LINCS), S\\'ebastien Tixeuil (LIP6, LINCS, IUF)", "title": "Limiting Byzantien Influence in Multihop Asynchronous Networks", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reliably broadcasting information in a multihop\nasyn- chronous network that is subject to Byzantine failures. That is, some\nnodes of the network can exhibit arbitrary (and potentially malicious)\nbehavior. Existing solutions provide de- terministic guarantees for\nbroadcasting between all correct nodes, but require that the communication\nnetwork is highly-connected (typically, 2k + 1 connectivity is required, where\nk is the total number of Byzantine nodes in the network). In this paper, we\ninvestigate the possibility of Byzantine tolerant reliable broadcast be- tween\nmost correct nodes in low-connectivity networks (typically, networks with\nconstant connectivity). In more details, we propose a new broadcast protocol\nthat is specifically designed for low-connectivity networks. We provide\nsufficient conditions for correct nodes using our protocol to reliably\ncommunicate despite Byzantine participants. We present experimental results\nthat show that our approach is especially effective in low-connectivity\nnetworks when Byzantine nodes are randomly distributed.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jan 2012 16:36:50 GMT"}], "update_date": "2012-01-30", "authors_parsed": [["Maurer", "Alexandre", "", "LIP6, LINCS"], ["Tixeuil", "S\u00e9bastien", "", "LIP6, LINCS, IUF"]]}, {"id": "1201.6090", "submitter": "Rahul Jain", "authors": "Rahul Jain and Penghui Yao", "title": "A parallel approximation algorithm for mixed packing and covering\n  semidefinite programs", "comments": "8 pages, version 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a parallel approximation algorithm for a class of mixed packing\nand covering semidefinite programs which generalize on the class of positive\nsemidefinite programs as considered by Jain and Yao [2011]. As a corollary we\nget a faster approximation algorithm for positive semidefinite programs with\nbetter dependence of the parallel running time on the approximation factor, as\ncompared to that of Jain and Yao [2011]. Our algorithm and analysis is on\nsimilar lines as that of Young [2001] who considered analogous linear programs.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2012 23:00:30 GMT"}], "update_date": "2012-01-31", "authors_parsed": [["Jain", "Rahul", ""], ["Yao", "Penghui", ""]]}, {"id": "1201.6488", "submitter": "Christian Schulz", "authors": "Ilya Safro, Peter Sanders, Christian Schulz", "title": "Advanced Coarsening Schemes for Graph Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The graph partitioning problem is widely used and studied in many practical\nand theoretical applications. The multilevel strategies represent today one of\nthe most effective and efficient generic frameworks for solving this problem on\nlarge-scale graphs. Most of the attention in designing the multilevel\npartitioning frameworks has been on the refinement phase. In this work we focus\non the coarsening phase, which is responsible for creating structurally similar\nto the original but smaller graphs. We compare different matching- and\nAMG-based coarsening schemes, experiment with the algebraic distance between\nnodes, and demonstrate computational results on several classes of graphs that\nemphasize the running time and quality advantages of different coarsenings.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 09:50:18 GMT"}, {"version": "v2", "created": "Tue, 3 Apr 2012 13:17:20 GMT"}], "update_date": "2012-04-04", "authors_parsed": [["Safro", "Ilya", ""], ["Sanders", "Peter", ""], ["Schulz", "Christian", ""]]}, {"id": "1201.6652", "submitter": "Christoph Lenzen", "authors": "Danny Dolev, Christoph Lenzen, Shir Peled", "title": "\"Tri, Tri again\": Finding Triangles and Small Subgraphs in a Distributed\n  Setting", "comments": "22 pages, no figures, extended abstract published at DISC'12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let G = (V,E) be an n-vertex graph and M_d a d-vertex graph, for some\nconstant d. Is M_d a subgraph of G? We consider this problem in a model where\nall n processes are connected to all other processes, and each message contains\nup to O(log n) bits. A simple deterministic algorithm that requires\nO(n^((d-2)/d) / log n) communication rounds is presented. For the special case\nthat M_d is a triangle, we present a probabilistic algorithm that requires an\nexpected O(ceil(n^(1/3) / (t^(2/3) + 1))) rounds of communication, where t is\nthe number of triangles in the graph, and O(min{n^(1/3) log^(2/3) n / (t^(2/3)\n+ 1), n^(1/3)}) with high probability.\n  We also present deterministic algorithms specially suited for sparse graphs.\nIn any graph of maximum degree Delta, we can test for arbitrary subgraphs of\ndiameter D in O(ceil(Delta^(D+1) / n)) rounds. For triangles, we devise an\nalgorithm featuring a round complexity of O(A^2 / n + log_(2+n/A^2) n), where A\ndenotes the arboricity of G.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 19:02:49 GMT"}, {"version": "v2", "created": "Sun, 5 Aug 2012 13:14:23 GMT"}, {"version": "v3", "created": "Mon, 5 Nov 2012 11:00:36 GMT"}], "update_date": "2012-11-06", "authors_parsed": [["Dolev", "Danny", ""], ["Lenzen", "Christoph", ""], ["Peled", "Shir", ""]]}, {"id": "1201.6675", "submitter": "Jukka Suomela", "authors": "Mika G\\\"o\\\"os, Juho Hirvonen, Jukka Suomela", "title": "Lower Bounds for Local Approximation", "comments": "28 pages, 9 figures", "journal-ref": "Journal of the ACM 60 (2013), issue 5, article 39", "doi": "10.1145/2528405", "report-no": null, "categories": "cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the study of deterministic distributed algorithms it is commonly assumed\nthat each node has a unique $O(\\log n)$-bit identifier. We prove that for a\ngeneral class of graph problems, local algorithms (constant-time distributed\nalgorithms) do not need such identifiers: a port numbering and orientation is\nsufficient.\n  Our result holds for so-called simple PO-checkable graph optimisation\nproblems; this includes many classical packing and covering problems such as\nvertex covers, edge covers, matchings, independent sets, dominating sets, and\nedge dominating sets. We focus on the case of bounded-degree graphs and show\nthat if a local algorithm finds a constant-factor approximation of a simple\nPO-checkable graph problem with the help of unique identifiers, then the same\napproximation ratio can be achieved on anonymous networks.\n  As a corollary of our result and by prior work, we derive a tight lower bound\non the local approximability of the minimum edge dominating set problem.\n  Our main technical tool is an algebraic construction of homogeneously ordered\ngraphs: We say that a graph is $(\\alpha,r)$-homogeneous if its nodes are\nlinearly ordered so that an $\\alpha$ fraction of nodes have pairwise isomorphic\nradius-$r$ neighbourhoods. We show that there exists a finite\n$(\\alpha,r)$-homogeneous $2k$-regular graph of girth at least $g$ for any\n$\\alpha < 1$ and any $r$, $k$, and $g$.\n", "versions": [{"version": "v1", "created": "Tue, 31 Jan 2012 20:31:15 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["G\u00f6\u00f6s", "Mika", ""], ["Hirvonen", "Juho", ""], ["Suomela", "Jukka", ""]]}]