[{"id": "1101.0085", "submitter": "Rathinakumar Appuswamy", "authors": "Rathinakumar Appuswamy, Massimo Franceschetti, Nikhil Karamchandani,\n  and Kenneth Zeger", "title": "Linear Codes, Target Function Classes, and Network Computing Capacity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.CO math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the use of linear codes for network computing in single-receiver\nnetworks with various classes of target functions of the source messages. Such\nclasses include reducible, injective, semi-injective, and linear target\nfunctions over finite fields. Computing capacity bounds and achievability are\ngiven with respect to these target function classes for network codes that use\nrouting, linear coding, or nonlinear coding.\n", "versions": [{"version": "v1", "created": "Thu, 30 Dec 2010 13:40:13 GMT"}, {"version": "v2", "created": "Wed, 23 Feb 2011 19:23:05 GMT"}, {"version": "v3", "created": "Sat, 7 May 2011 08:25:09 GMT"}], "update_date": "2011-05-10", "authors_parsed": [["Appuswamy", "Rathinakumar", ""], ["Franceschetti", "Massimo", ""], ["Karamchandani", "Nikhil", ""], ["Zeger", "Kenneth", ""]]}, {"id": "1101.0093", "submitter": "Georg Hager", "authors": "Markus Wittmann and Georg Hager", "title": "Optimizing ccNUMA locality for task-parallel execution under OpenMP and\n  TBB on multicore-based systems", "comments": "9 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task parallelism as employed by the OpenMP task construct or some Intel\nThreading Building Blocks (TBB) components, although ideal for tackling\nirregular problems or typical producer/consumer schemes, bears some potential\nfor performance bottlenecks if locality of data access is important, which is\ntypically the case for memory-bound code on ccNUMA systems. We present a thin\nsoftware layer ameliorates adverse effects of dynamic task distribution by\nsorting tasks into locality queues, each of which is preferably processed by\nthreads that belong to the same locality domain. Dynamic scheduling is fully\npreserved inside each domain, and is preferred over possible load imbalance\neven if nonlocal access is required, making this strategy well-suited for\ntypical multicore-mutisocket systems. The effectiveness of the approach is\ndemonstrated by using a blocked six-point stencil solver as a toy model.\n", "versions": [{"version": "v1", "created": "Thu, 30 Dec 2010 14:55:02 GMT"}], "update_date": "2011-01-04", "authors_parsed": [["Wittmann", "Markus", ""], ["Hager", "Georg", ""]]}, {"id": "1101.0133", "submitter": "Nihar Shah", "authors": "K. V. Rashmi, Nihar B. Shah, P. Vijay Kumar", "title": "Enabling Node Repair in Any Erasure Code for Distributed Storage", "comments": "IEEE International Symposium on Information Theory (ISIT) 2011 (to be\n  presented)", "journal-ref": null, "doi": "10.1109/ISIT.2011.6033732", "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Erasure codes are an efficient means of storing data across a network in\ncomparison to data replication, as they tend to reduce the amount of data\nstored in the network and offer increased resilience in the presence of node\nfailures. The codes perform poorly though, when repair of a failed node is\ncalled for, as they typically require the entire file to be downloaded to\nrepair a failed node. A new class of erasure codes, termed as regenerating\ncodes were recently introduced, that do much better in this respect. However,\ngiven the variety of efficient erasure codes available in the literature, there\nis considerable interest in the construction of coding schemes that would\nenable traditional erasure codes to be used, while retaining the feature that\nonly a fraction of the data need be downloaded for node repair. In this paper,\nwe present a simple, yet powerful, framework that does precisely this. Under\nthis framework, the nodes are partitioned into two 'types' and encoded using\ntwo codes in a manner that reduces the problem of node-repair to that of\nerasure-decoding of the constituent codes. Depending upon the choice of the two\ncodes, the framework can be used to avail one or more of the following\nadvantages: simultaneous minimization of storage space and repair-bandwidth,\nlow complexity of operation, fewer disk reads at helper nodes during repair,\nand error detection and correction.\n", "versions": [{"version": "v1", "created": "Thu, 30 Dec 2010 19:00:00 GMT"}, {"version": "v2", "created": "Thu, 30 Jun 2011 10:10:00 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Rashmi", "K. V.", ""], ["Shah", "Nihar B.", ""], ["Kumar", "P. Vijay", ""]]}, {"id": "1101.0357", "submitter": "R. J. Sobie", "authors": "R.J. Sobie, A.Agarwal, M.Anderson, P.Armstrong, K.Fransham, I.Gable,\n  D.Harris, C.Leavett-Brown, M.Paterson, D.Penfold-Brown, M.Vliet,\n  A.Charbonneau, R.Impey and W.Podaima", "title": "Data Intensive High Energy Physics Analysis in a Distributed Cloud", "comments": "6 pages, 4 figures, conference paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that distributed Infrastructure-as-a-Service (IaaS) compute clouds\ncan be effectively used for the analysis of high energy physics data. We have\ndesigned a distributed cloud system that works with any application using large\ninput data sets requiring a high throughput computing environment. The system\nuses IaaS-enabled science and commercial clusters in Canada and the United\nStates. We describe the process in which a user prepares an analysis virtual\nmachine (VM) and submits batch jobs to a central scheduler. The system boots\nthe user-specific VM on one of the IaaS clouds, runs the jobs and returns the\noutput to the user. The user application accesses a central database for\ncalibration data during the execution of the application. Similarly, the data\nis located in a central location and streamed by the running application. The\nsystem can easily run one hundred simultaneous jobs in an efficient manner and\nshould scale to many hundreds and possibly thousands of user jobs.\n", "versions": [{"version": "v1", "created": "Sat, 1 Jan 2011 17:44:04 GMT"}], "update_date": "2011-01-04", "authors_parsed": [["Sobie", "R. J.", ""], ["Agarwal", "A.", ""], ["Anderson", "M.", ""], ["Armstrong", "P.", ""], ["Fransham", "K.", ""], ["Gable", "I.", ""], ["Harris", "D.", ""], ["Leavett-Brown", "C.", ""], ["Paterson", "M.", ""], ["Penfold-Brown", "D.", ""], ["Vliet", "M.", ""], ["Charbonneau", "A.", ""], ["Impey", "R.", ""], ["Podaima", "W.", ""]]}, {"id": "1101.0605", "submitter": "Derek Groen", "authors": "Derek Groen (Leiden University), Simon Portegies Zwart (Leiden\n  University), Tomoaki Ishiyama (NAOJ, Tokyo), Junichiro Makino (NAOJ, Tokyo)", "title": "High Performance Gravitational N-body Simulations on a Planet-wide\n  Distributed Supercomputer", "comments": "30 pages, 11 figures, accepted by Comp. Science and Discovery", "journal-ref": "Comput. Sci. Disc. 4 (2011) 015001", "doi": "10.1088/1749-4699/4/1/015001", "report-no": null, "categories": "cs.DC astro-ph.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on the performance of our cold-dark matter cosmological N-body\nsimulation which was carried out concurrently using supercomputers across the\nglobe. We ran simulations on 60 to 750 cores distributed over a variety of\nsupercomputers in Amsterdam (the Netherlands, Europe), in Tokyo (Japan, Asia),\nEdinburgh (UK, Europe) and Espoo (Finland, Europe). Regardless the network\nlatency of 0.32 seconds and the communication over 30.000 km of optical network\ncable we are able to achieve about 87% of the performance compared to an equal\nnumber of cores on a single supercomputer. We argue that using widely\ndistributed supercomputers in order to acquire more compute power is\ntechnically feasible, and that the largest obstacle is introduced by local\nscheduling and reservation policies.\n", "versions": [{"version": "v1", "created": "Mon, 3 Jan 2011 21:00:07 GMT"}], "update_date": "2011-01-25", "authors_parsed": [["Groen", "Derek", "", "Leiden University"], ["Zwart", "Simon Portegies", "", "Leiden\n  University"], ["Ishiyama", "Tomoaki", "", "NAOJ, Tokyo"], ["Makino", "Junichiro", "", "NAOJ, Tokyo"]]}, {"id": "1101.0664", "submitter": "Evgenii Vorozhtsov", "authors": "G.A. Tarnavsky and E.V. Vorozhtsov", "title": "Computer Simulation Center in Internet", "comments": "12 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The general description of infrastructure and content of SciShop.ru computer\nsimulation center is given. This resource is a new form of knowledge generation\nand remote education using modern Cloud Computing technologies.\n", "versions": [{"version": "v1", "created": "Tue, 4 Jan 2011 06:58:07 GMT"}], "update_date": "2011-01-05", "authors_parsed": [["Tarnavsky", "G. A.", ""], ["Vorozhtsov", "E. V.", ""]]}, {"id": "1101.1038", "submitter": "Benjamin Morandi", "authors": "Benjamin Morandi, Sebastian Nanz, Bertrand Meyer", "title": "A comprehensive operational semantics of the SCOOP programming model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Operational semantics has established itself as a flexible but rigorous means\nto describe the meaning of programming languages. Oftentimes, it is felt\nnecessary to keep a semantics small, for example to facilitate its use for\nmodel checking by avoiding state space explosion. However, omitting many\ndetails in a semantics typically makes results valid for a limited core\nlanguage only, leaving a wide gap towards any real implementation. In this\npaper we present a full-fledged semantics of the concurrent object-oriented\nprogramming language SCOOP (Simple Concurrent Object-Oriented Programming). The\nsemantics has been found detailed enough to guide an implementation of the\nSCOOP compiler and runtime system, and to detect and correct a variety of\nerrors and ambiguities in the original informal specification and prototype\nimplementation. In our formal specification, we use abstract data types with\npreconditions and axioms to describe the state, and introduce a number of\nspecial run-time operations to model the runtime system with our inference\nrules. This approach allows us to make our large formal specification\nmanageable, providing a first step towards reference documents for specifying\nobject-oriented languages based on operational semantics.\n", "versions": [{"version": "v1", "created": "Wed, 5 Jan 2011 17:32:02 GMT"}, {"version": "v2", "created": "Fri, 13 Apr 2012 11:54:38 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Morandi", "Benjamin", ""], ["Nanz", "Sebastian", ""], ["Meyer", "Bertrand", ""]]}, {"id": "1101.1680", "submitter": "Ted Herman", "authors": "Ted Herman", "title": "Safe Register Token Transfer in a Ring", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": "TR-11-01", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A token ring is an arrangement of N processors that take turns engaging in an\nactivity which must be controlled. A token confers the right to engage in the\ncontrolled activity. Processors communicate with neighbors in the ring to\nobtain and release a token. The communication mechanism investigated in this\npaper is the safe register abstraction, which may arbitrarily corrupt a value\nthat a processor reads when the operation reading a register is concurrent with\nan write operation on that register by a neighboring processor. The main\nresults are simple protocols for quasi-atomic communication, constructed from\nsafe registers. A quasi-atomic register behaves atomically except that a\nspecial undefined value may be returned in the case of concurrent read and\nwrite operations. Under certain conditions that constrain the number of writes\nand registers, quasi-atomic protocols are adequate substitutes for atomic\nprotocols. The paper demonstrates how quasi-atomic protocols can be used to\nimplement a self-stabilizing token ring, either by using two safe registers\nbetween neighboring processors or by using O(lg N) safe registers between\nneighbors, which lowers read complexity.\n", "versions": [{"version": "v1", "created": "Sun, 9 Jan 2011 22:24:44 GMT"}], "update_date": "2011-01-11", "authors_parsed": [["Herman", "Ted", ""]]}, {"id": "1101.1846", "submitter": "Sami Hissoiny", "authors": "S. Hissoiny, P. Despr\\'es, B. Ozell", "title": "Using graphics processing units to generate random numbers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The future of high-performance computing is aligning itself towards the\nefficient use of highly parallel computing environments. One application where\nthe use of massive parallelism comes instinctively is Monte Carlo simulations,\nwhere a large number of independent events have to be simulated. At the core of\nthe Monte Carlo simulation lies the Random Number Generator (RNG). In this\npaper, the massively parallel implementation of a collection of pseudo-random\nnumber generators on a graphics processing unit (GPU) is presented. The results\nof the GPU implementation, in terms of samples/s, effective bandwidth and\noperations per second, are presented. A comparison with other implementations\non different hardware platforms, in terms of samples/s, power efficiency and\ncost-benefit, is also presented. Random numbers generation throughput of up to\n~18MSamples/s have been achieved on the graphics hardware used. Efficient\nhardware utilization, in terms of operations per second, has reached ~98% of\nthe possible integer operation throughput.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jan 2011 15:27:48 GMT"}], "update_date": "2011-01-11", "authors_parsed": [["Hissoiny", "S.", ""], ["Despr\u00e9s", "P.", ""], ["Ozell", "B.", ""]]}, {"id": "1101.1902", "submitter": "Nodari Sitchinava", "authors": "Michael T. Goodrich, Nodari Sitchinava, Qin Zhang", "title": "Sorting, Searching, and Simulation in the MapReduce Framework", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the MapReduce framework from an algorithmic\nstandpoint and demonstrate the usefulness of our approach by designing and\nanalyzing efficient MapReduce algorithms for fundamental sorting, searching,\nand simulation problems. This study is motivated by a goal of ultimately\nputting the MapReduce framework on an equal theoretical footing with the\nwell-known PRAM and BSP parallel models, which would benefit both the theory\nand practice of MapReduce algorithms. We describe efficient MapReduce\nalgorithms for sorting, multi-searching, and simulations of parallel algorithms\nspecified in the BSP and CRCW PRAM models. We also provide some applications of\nthese results to problems in parallel computational geometry for the MapReduce\nframework, which result in efficient MapReduce algorithms for sorting, 2- and\n3-dimensional convex hulls, and fixed-dimensional linear programming. For the\ncase when mappers and reducers have a memory/message-I/O size of\n$M=\\Theta(N^\\epsilon)$, for a small constant $\\epsilon>0$, all of our MapReduce\nalgorithms for these applications run in a constant number of rounds.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jan 2011 17:46:40 GMT"}], "update_date": "2011-01-11", "authors_parsed": [["Goodrich", "Michael T.", ""], ["Sitchinava", "Nodari", ""], ["Zhang", "Qin", ""]]}, {"id": "1101.1932", "submitter": "Washington Taylor", "authors": "Washington Taylor, Jud Leonard and Lawrence C. Stewart", "title": "Efficient tilings of de Bruijn and Kautz graphs", "comments": "29 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": "MIT-CTP-4202", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kautz and de Bruijn graphs have a high degree of connectivity which makes\nthem ideal candidates for massively parallel computer network topologies. In\norder to realize a practical computer architecture based on these graphs, it is\nuseful to have a means of constructing a large-scale system from smaller,\nsimpler modules. In this paper we consider the mathematical problem of\nuniformly tiling a de Bruijn or Kautz graph. This can be viewed as a\ngeneralization of the graph bisection problem. We focus on the problem of graph\ntilings by a set of identical subgraphs. Tiles should contain a maximal number\nof internal edges so as to minimize the number of edges connecting distinct\ntiles. We find necessary and sufficient conditions for the construction of\ntilings. We derive a simple lower bound on the number of edges which must leave\neach tile, and construct a class of tilings whose number of edges leaving each\ntile agrees asymptotically in form with the lower bound to within a constant\nfactor. These tilings make possible the construction of large-scale computing\nsystems based on de Bruijn and Kautz graph topologies.\n", "versions": [{"version": "v1", "created": "Mon, 10 Jan 2011 19:34:56 GMT"}], "update_date": "2011-01-11", "authors_parsed": [["Taylor", "Washington", ""], ["Leonard", "Jud", ""], ["Stewart", "Lawrence C.", ""]]}, {"id": "1101.2573", "submitter": "Vishal Goyal", "authors": "Sanjay Bansal, Nirved Pandey", "title": "An Overview of Portable Distributed Techniques", "comments": "International Journal of Computer Science Issues online at\n  http://www.ijcsi.org", "journal-ref": "IJCSI, Volume 7, Issue 3, May 2010", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we reviewed of several portable parallel programming paradigms\nfor use in a distributed programming environment. The Techniques reviewed here\nare portable. These are mainly distributing computing using MPI pure java\nbased, MPI native java based (JNI) and PVM. We will discuss architecture and\nutilities of each technique based on our literature review. We explored these\nportable distributed techniques in four important characteristics scalability,\nfault tolerance, load balancing and performance. We have identified the various\nfactors and issues for improving these four important characteristics.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jan 2011 14:50:33 GMT"}], "update_date": "2011-01-14", "authors_parsed": [["Bansal", "Sanjay", ""], ["Pandey", "Nirved", ""]]}, {"id": "1101.2678", "submitter": "Martyn Amos", "authors": "Jose M. Cecilia, Jose M. Garcia, Manuel Ujaldon, Andy Nisbet and\n  Martyn Amos", "title": "Parallelization Strategies for Ant Colony Optimisation on GPUs", "comments": "Accepted by 14th International Workshop on Nature Inspired\n  Distributed Computing (NIDISC 2011), held in conjunction with the 25th\n  IEEE/ACM International Parallel and Distributed Processing Symposium (IPDPS\n  2011)", "journal-ref": null, "doi": "10.1109/IPDPS.2011.170", "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ant Colony Optimisation (ACO) is an effective population-based meta-heuristic\nfor the solution of a wide variety of problems. As a population-based\nalgorithm, its computation is intrinsically massively parallel, and it is\nthere- fore theoretically well-suited for implementation on Graphics Processing\nUnits (GPUs). The ACO algorithm comprises two main stages: Tour construction\nand Pheromone update. The former has been previously implemented on the GPU,\nusing a task-based parallelism approach. However, up until now, the latter has\nalways been implemented on the CPU. In this paper, we discuss several\nparallelisation strategies for both stages of the ACO algorithm on the GPU. We\npropose an alternative data-based parallelism scheme for Tour construction,\nwhich fits better on the GPU architecture. We also describe novel GPU\nprogramming strategies for the Pheromone update stage. Our results show a total\nspeed-up exceeding 28x for the Tour construction stage, and 20x for Pheromone\nupdate, and suggest that ACO is a potentially fruitful area for future research\nin the GPU domain.\n", "versions": [{"version": "v1", "created": "Thu, 13 Jan 2011 21:28:52 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Cecilia", "Jose M.", ""], ["Garcia", "Jose M.", ""], ["Ujaldon", "Manuel", ""], ["Nisbet", "Andy", ""], ["Amos", "Martyn", ""]]}, {"id": "1101.3161", "submitter": "Eloisa Bentivegna", "authors": "Eloisa Bentivegna, Gabrielle Allen, Oleg Korobkin, Erik Schnetter", "title": "Ensuring Correctness at the Application Level: a Software Framework\n  Approach", "comments": "11 pages, 5 figures, presented at the 2009 Workshop on\n  Component-Based High Performance Computing (CBHPC 2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As scientific applications extend to the simulation of more and more complex\nsystems, they involve an increasing number of abstraction levels, at each of\nwhich errors can emerge and across which they can propagate; tools for\ncorrectness evaluation and enforcement at every level (from the code level to\nthe application level) are therefore necessary. Whilst code-level debugging\ntools are already a well established standard, application-level tools are\nlagging behind, possibly due to their stronger dependence on the application's\ndetails. In this paper, we describe the programming model introduced by the\nCactus framework, review the High Performance Computing (HPC) challenges that\nCactus is designed to address, and illustrate the correctness strategies that\nare currently available in Cactus at the code, component, and application\nlevel.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jan 2011 09:42:17 GMT"}], "update_date": "2011-01-18", "authors_parsed": [["Bentivegna", "Eloisa", ""], ["Allen", "Gabrielle", ""], ["Korobkin", "Oleg", ""], ["Schnetter", "Erik", ""]]}, {"id": "1101.3356", "submitter": "Raimund Kirner", "authors": "Alex Shafarenko and Raimund Kirner", "title": "CAL: A Language for Aggregating Functional and Extrafunctional\n  Constraints in Streaming Networks", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present the {\\em Constraint Aggregation Language} (CAL), a\ndeclarative language for describing properties of stateless program components\nthat interact by exchanging messages. CAL allows one to describe functional as\nwell as extra-functional behaviours, such as computation latency. The CAL\nlanguage intention is to be able to describe the behaviour of so-called boxes\nin the context of S-Net. However, the language would find application in other\ncoordination models based on stateless components.\n", "versions": [{"version": "v1", "created": "Mon, 17 Jan 2011 23:51:59 GMT"}, {"version": "v2", "created": "Wed, 19 Jan 2011 14:07:27 GMT"}], "update_date": "2011-01-20", "authors_parsed": [["Shafarenko", "Alex", ""], ["Kirner", "Raimund", ""]]}, {"id": "1101.3444", "submitter": "Yunus Sarikaya", "authors": "C. Emre Koksal, Ozgur Ercetin and Yunus Sarikaya", "title": "Control of Wireless Networks with Secrecy", "comments": "To appear in IEEE/ACM Transactions on Networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of cross-layer resource allocation in time-varying\ncellular wireless networks, and incorporate information theoretic secrecy as a\nQuality of Service constraint. Specifically, each node in the network injects\ntwo types of traffic, private and open, at rates chosen in order to maximize a\nglobal utility function, subject to network stability and secrecy constraints.\nThe secrecy constraint enforces an arbitrarily low mutual information leakage\nfrom the source to every node in the network, except for the sink node. We\nfirst obtain the achievable rate region for the problem for single and\nmulti-user systems assuming that the nodes have full CSI of their neighbors.\nThen, we provide a joint flow control, scheduling and private encoding scheme,\nwhich does not rely on the knowledge of the prior distribution of the gain of\nany channel. We prove that our scheme achieves a utility, arbitrarily close to\nthe maximum achievable utility. Numerical experiments are performed to verify\nthe analytical results, and to show the efficacy of the dynamic control\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jan 2011 12:40:21 GMT"}, {"version": "v2", "created": "Fri, 18 Mar 2011 15:50:04 GMT"}, {"version": "v3", "created": "Wed, 25 Apr 2012 22:32:36 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Koksal", "C. Emre", ""], ["Ercetin", "Ozgur", ""], ["Sarikaya", "Yunus", ""]]}, {"id": "1101.3520", "submitter": "Guanfeng Liang", "authors": "Guanfeng Liang and Nitin Vaidya", "title": "Error-Free Multi-Valued Consensus with Byzantine Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an efficient deterministic algorithm for consensus\nin presence of Byzantine failures. Our algorithm achieves consensus on an\n$L$-bit value with communication complexity $O(nL + n^4 L^{0.5} + n^6)$ bits,\nin a network consisting of $n$ processors with up to $t$ Byzantine failures,\nsuch that $t<n/3$. For large enough $L$, communication complexity of the\nproposed algorithm approaches $O(nL)$ bits. In other words, for large $L$, the\ncommunication complexity is linear in the number of processors in the network.\nThis is an improvement over the work of Fitzi and Hirt (from PODC 2006), who\nproposed a probabilistically correct multi-valued Byzantine consensus algorithm\nwith a similar complexity for large $L$. In contrast to the algorithm by Fitzi\nand Hirt, our algorithm is guaranteed to be always error-free. Our algorithm\nrequire no cryptographic technique, such as authentication, nor any secret\nsharing mechanism. To the best of our knowledge, we are the first to show that,\nfor large $L$, error-free multi-valued Byzantine consensus on an $L$-bit value\nis achievable with $O(nL)$ bits of communication.\n", "versions": [{"version": "v1", "created": "Tue, 18 Jan 2011 18:32:22 GMT"}], "update_date": "2011-01-19", "authors_parsed": [["Liang", "Guanfeng", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1101.3761", "submitter": "Luca Maria Aiello", "authors": "Luca Maria Aiello, Marco Milanesio, Giancarlo Ruffo and Rossano\n  Schifanella", "title": "Tagging with DHARMA, a DHT-based Approach for Resource Mapping through\n  Approximation", "comments": "8 pages, 8 figures", "journal-ref": "HOTP2P '10 : 7th International Workshop on Hot Topics in\n  Peer-to-Peer Systems, Atlanta, Georgia, April 19-23, 2010", "doi": "10.1109/IPDPSW.2010.5470931", "report-no": null, "categories": "cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce collaborative tagging and faceted search on structured P2P\nsystems. Since a trivial and brute force mapping of an entire folksonomy over a\nDHT-based system may reduce scalability, we propose an approximated graph\nmaintenance approach. Evaluations on real data coming from Last.fm prove that\nsuch strategies reduce vocabulary noise (i.e., representation's overfitting\nphenomena) and hotspots issues.\n", "versions": [{"version": "v1", "created": "Wed, 19 Jan 2011 19:50:13 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Aiello", "Luca Maria", ""], ["Milanesio", "Marco", ""], ["Ruffo", "Giancarlo", ""], ["Schifanella", "Rossano", ""]]}, {"id": "1101.3891", "submitter": "Patricia Marcu", "authors": "Patricia Marcu, Wolfgang Hommel", "title": "Inter-organizational fault management: Functional and organizational\n  core aspects of management architectures", "comments": "International Journal of Computer Networks & Communications (IJCNC)", "journal-ref": "International Journal of Computer Networks & Communications\n  (IJCNC), Editor: AIRCC, January 2011, Volume 3. Number 1, pages:101-117,\n  ISSN-Online: 0974 - 9322,ISSN-Print: 0975- 2293", "doi": "10.5121/ijcnc.2011.3107", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Outsourcing -- successful, and sometimes painful -- has become one of the\nhottest topics in IT service management discussions over the past decade. IT\nservices are outsourced to external service provider in order to reduce the\neffort required for and overhead of delivering these services within the own\norganization. More recently also IT services providers themselves started to\neither outsource service parts or to deliver those services in a\nnon-hierarchical cooperation with other providers. Splitting a service into\nseveral service parts is a non-trivial task as they have to be implemented,\noperated, and maintained by different providers. One key aspect of such\ninter-organizational cooperation is fault management, because it is crucial to\nlocate and solve problems, which reduce the quality of service, quickly and\nreliably. In this article we present the results of a thorough use case based\nrequirements analysis for an architecture for inter-organizational fault\nmanagement (ioFMA). Furthermore, a concept of the organizational respective\nfunctional model of the ioFMA is given.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jan 2011 13:08:06 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Marcu", "Patricia", ""], ["Hommel", "Wolfgang", ""]]}, {"id": "1101.3896", "submitter": "Patricia Marcu", "authors": "Patricia Marcu, David Schmitz, Wolfgang Fritz, Mark Yampolskiy,\n  Wolfgang Hommel", "title": "Integrated monitoring of multi-domain backbone connections --\n  Operational experience in the LHC optical private network", "comments": "International Journal of Computer Networks & Communications (IJCNC)", "journal-ref": "Intl.J.Comput.Net.Commun.3:82-99,2011", "doi": "10.5121/ijcnc.2011.3106", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel large scale research projects often require cooperation between various\ndifferent project partners that are spread among the entire world. They do not\nonly need huge computing resources, but also a reliable network to operate on.\nThe Large Hadron Collider (LHC) at CERN is a representative example for such a\nproject. Its experiments result in a vast amount of data, which is interesting\nfor researchers around the world. For transporting the data from CERN to 11\ndata processing and storage sites, an optical private network (OPN) has been\nconstructed. As the experiment data is highly valuable, LHC defines very high\nrequirements to the underlying network infrastructure. In order to fulfil those\nrequirements, the connections have to be managed and monitored permanently. In\nthis paper, we present the integrated monitoring solution developed for the\nLHCOPN. We first outline the requirements and show how they are met on the\nsingle network layers. After that, we describe, how those single measurements\ncan be combined into an integrated view. We cover design concepts as well as\ntool implementation highlights.\n", "versions": [{"version": "v1", "created": "Thu, 20 Jan 2011 13:16:58 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Marcu", "Patricia", ""], ["Schmitz", "David", ""], ["Fritz", "Wolfgang", ""], ["Yampolskiy", "Mark", ""], ["Hommel", "Wolfgang", ""]]}, {"id": "1101.4116", "submitter": "Riccardo Murri", "authors": "Riccardo Murri, Peter Z. Kunszt, Sergio Maffioletti, Valery Tschopp", "title": "GridCertLib: a Single Sign-on Solution for Grid Web Applications and\n  Portals", "comments": "18 pages, 1 figure; final manuscript accepted for publication by the\n  \"Journal of Grid Computing\"", "journal-ref": null, "doi": "10.1007/s10723-011-9195-y", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the design and implementation of GridCertLib, a Java\nlibrary leveraging a Shibboleth-based authentication infrastructure and the\nSLCS online certificate signing service, to provide short-lived X.509\ncertificates and Grid proxies. The main use case envisioned for GridCertLib, is\nto provide seamless and secure access to Grid/X.509 certificates and proxies in\nweb applications and portals: when a user logs in to the portal using\nShibboleth authentication, GridCertLib can automatically obtain a Grid/X.509\ncertificate from the SLCS service and generate a VOMS proxy from it. We give an\noverview of the architecture of GridCertLib and briefly describe its\nprogramming model. Its application to some deployment scenarios is outlined, as\nwell as a report on practical experience integrating GridCertLib into portals\nfor Bioinformatics and Computational Chemistry applications, based on the\npopular P-GRADE and Django softwares.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jan 2011 11:56:07 GMT"}, {"version": "v2", "created": "Thu, 21 Apr 2011 15:46:37 GMT"}, {"version": "v3", "created": "Tue, 6 Sep 2011 14:38:56 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Murri", "Riccardo", ""], ["Kunszt", "Peter Z.", ""], ["Maffioletti", "Sergio", ""], ["Tschopp", "Valery", ""]]}, {"id": "1101.4193", "submitter": "Camille Coti", "authors": "Franck Butelle and Camille Coti", "title": "A Model for Coherent Distributed Memory For Race Condition Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new model for distributed shared memory systems, based on remote\ndata accesses. Such features are offered by network interface cards that allow\none-sided operations, remote direct memory access and OS bypass. This model\nleads to new interpretations of distributed algorithms allowing us to propose\nan innovative detection technique of race conditions only based on logical\nclocks. Indeed, the presence of (data) races in a parallel program makes it\nhard to reason about and is usually considered as a bug.\n", "versions": [{"version": "v1", "created": "Fri, 21 Jan 2011 17:47:24 GMT"}, {"version": "v2", "created": "Sat, 12 Feb 2011 14:42:21 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Butelle", "Franck", ""], ["Coti", "Camille", ""]]}, {"id": "1101.4260", "submitter": "Mahfuza Sharmin", "authors": "Nashid Shahriar, Mahfuza Sharmin, Reaz Ahmed, Raouf Boutaba", "title": "Networking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses an efficient approach to design and implement a highly\navailable peer- to-peer system irrespective of peer timing and churn.\n", "versions": [{"version": "v1", "created": "Sat, 22 Jan 2011 04:18:01 GMT"}, {"version": "v2", "created": "Fri, 20 May 2011 16:04:51 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Shahriar", "Nashid", ""], ["Sharmin", "Mahfuza", ""], ["Ahmed", "Reaz", ""], ["Boutaba", "Raouf", ""]]}, {"id": "1101.4372", "submitter": "Michael Borokhovich", "authors": "Chen Avin, Michael Borokhovich, Keren Censor-Hillel, Zvi Lotker", "title": "Order Optimal Information Spreading Using Algebraic Gossip", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study gossip based information spreading with bounded\nmessage sizes. We use algebraic gossip to disseminate $k$ distinct messages to\nall $n$ nodes in a network. For arbitrary networks we provide a new upper bound\nfor uniform algebraic gossip of $O((k+\\log n + D)\\Delta)$ rounds with high\nprobability, where $D$ and $\\Delta$ are the diameter and the maximum degree in\nthe network, respectively. For many topologies and selections of $k$ this bound\nimproves previous results, in particular, for graphs with a constant maximum\ndegree it implies that uniform gossip is \\emph{order optimal} and the stopping\ntime is $\\Theta(k + D)$.\n  To eliminate the factor of $\\Delta$ from the upper bound we propose a\nnon-uniform gossip protocol, TAG, which is based on algebraic gossip and an\narbitrary spanning tree protocol $\\S$. The stopping time of TAG is $O(k+\\log n\n+d(\\S)+t(\\S))$, where $t(\\S)$ is the stopping time of the spanning tree\nprotocol, and $d(\\S)$ is the diameter of the spanning tree. We provide two\ngeneral cases in which this bound leads to an order optimal protocol. The first\nis for $k=\\Omega(n)$, where, using a simple gossip broadcast protocol that\ncreates a spanning tree in at most linear time, we show that TAG finishes after\n$\\Theta(n)$ rounds for any graph. The second uses a sophisticated, recent\ngossip protocol to build a fast spanning tree on graphs with large weak\nconductance. In turn, this leads to the optimally of TAG on these graphs for\n$k=\\Omega(\\mathrm{polylog}(n))$. The technique used in our proofs relies on\nqueuing theory, which is an interesting approach that can be useful in future\ngossip analysis.\n", "versions": [{"version": "v1", "created": "Sun, 23 Jan 2011 13:44:38 GMT"}], "update_date": "2011-01-25", "authors_parsed": [["Avin", "Chen", ""], ["Borokhovich", "Michael", ""], ["Censor-Hillel", "Keren", ""], ["Lotker", "Zvi", ""]]}, {"id": "1101.4429", "submitter": "EPTCS", "authors": "Luca Padovani (Dipartimento di Informatica, Universit\\`a di Torino,\n  Italy)", "title": "Session Types = Intersection Types + Union Types", "comments": "In Proceedings ITRS 2010, arXiv:1101.4104", "journal-ref": "EPTCS 45, 2011, pp. 71-89", "doi": "10.4204/EPTCS.45.6", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a semantically grounded theory of session types which relies on\nintersection and union types. We argue that intersection and union types are\nnatural candidates for modeling branching points in session types and we show\nthat the resulting theory overcomes some important defects of related\nbehavioral theories. In particular, intersections and unions provide a native\nsolution to the problem of computing joins and meets of session types. Also,\nthe subtyping relation turns out to be a pre-congruence, while this is not\nalways the case in related behavioral theories.\n", "versions": [{"version": "v1", "created": "Mon, 24 Jan 2011 01:39:52 GMT"}], "update_date": "2011-01-25", "authors_parsed": [["Padovani", "Luca", "", "Dipartimento di Informatica, Universit\u00e0 di Torino,\n  Italy"]]}, {"id": "1101.4474", "submitter": "Serban Cristina C", "authors": "Cristina Serban and Carmen Maftei", "title": "Thermal Analysis of Climate Regions using Remote Sensing and Grid\n  Computing", "comments": "16 pages; ISSN - [Online: 0974 - 9322 Print : 0975- 2293]", "journal-ref": "International Journal of Computer Networks & Communications\n  (IJCNC),Vol.3, No.1, 2011", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of climate regions is very important for designers and\narchitects, because the increase in density and built up spaces and reduction\nin open spaces and green lands induce the increase of heat, especially in an\nurban area, deteriorating the environment and causing health problems. This\nstudy analyzes the Land Surface Temperature (LST) differences in the region of\nDobrogea, Romania, and compares with the land use and land cover types using TM\nand ETM+ data of 1989 and 2000. As the analysis is performed on large data\nsets, we used Grid Computing to implement a service for using on Computational\nGrids with a Web-based client interface, which will be greatly useful and\nconvenient for those who are studying the ground thermal environment and heat\nisland effects by using Landsat TM/ETM+ bands, and have typical workstations,\nwith no special computing and storing resources for computationally intensive\nsatellite image processing and no license for a commercial image processing\ntool. Based on the satellite imagery, the paper also addresses a Supervised\nClassification algorithm and the computation of two indices of great value in\nwater resources management, Normalized Difference Vegetation Index (NDVI),\nrespectively Land Surface Emissivity (LSE).\n", "versions": [{"version": "v1", "created": "Mon, 24 Jan 2011 09:32:03 GMT"}], "update_date": "2011-01-25", "authors_parsed": [["Serban", "Cristina", ""], ["Maftei", "Carmen", ""]]}, {"id": "1101.5257", "submitter": "Kenneth Shum", "authors": "Kenneth W. Shum", "title": "Cooperative Regenerating Codes for Distributed Storage Systems", "comments": "5 pages, 7 figures, to appear in Proc. IEEE ICC, 2011", "journal-ref": null, "doi": "10.1109/icc.2011.5962548", "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When there are multiple node failures in a distributed storage system,\nregenerating the failed storage nodes individually in a one-by-one manner is\nsuboptimal as far as repair-bandwidth minimization is concerned. If data\nexchange among the newcomers is enabled, we can get a better tradeoff between\nrepair bandwidth and the storage per node. An explicit and optimal construction\nof cooperative regenerating code is illustrated.\n", "versions": [{"version": "v1", "created": "Thu, 27 Jan 2011 11:13:47 GMT"}, {"version": "v2", "created": "Tue, 8 Feb 2011 02:12:24 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Shum", "Kenneth W.", ""]]}, {"id": "1101.5428", "submitter": "Gerard Briscoe Dr", "authors": "Gerard Briscoe and Philippe De Wilde", "title": "The Computing of Digital Ecosystems", "comments": "18 pages, 11 figures, journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A primary motivation for our research in digital ecosystems is the desire to\nexploit the self-organising properties of biological ecosystems. Ecosystems are\nthought to be robust, scalable architectures that can automatically solve\ncomplex, dynamic problems. However, the computing technologies that contribute\nto these properties have not been made explicit in digital ecosystems research.\nHere, we discuss how different computing technologies can contribute to\nproviding the necessary self-organising features, including Multi-Agent Systems\n(MASs), Service-Oriented Architectures (SOAs), and distributed evolutionary\ncomputing (DEC). The potential for exploiting these properties in digital\necosystems is considered, suggesting how several key features of biological\necosystems can be exploited in Digital Ecosystems, and discussing how mimicking\nthese features may assist in developing robust, scalable self-organising\narchitectures. An example architecture, the Digital Ecosystem, is considered in\ndetail. The Digital Ecosystem is then measured experimentally through\nsimulations, considering the self-organised diversity of its evolving agent\npopulations relative to the user request behaviour.\n", "versions": [{"version": "v1", "created": "Fri, 28 Jan 2011 02:08:56 GMT"}], "update_date": "2011-01-31", "authors_parsed": [["Briscoe", "Gerard", ""], ["De Wilde", "Philippe", ""]]}, {"id": "1101.5791", "submitter": "Bela Genge", "authors": "Genge Bela and Haller Piroska", "title": "Using Planetlab to Implement Multicast at the Application Level", "comments": null, "journal-ref": "International Journal of Computer Networks & Communications\n  (IJCNC) Vol.3, No.1, January 2011", "doi": null, "report-no": null, "categories": "cs.DC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application-layer multicast implements the multicast functionality at the\napplication layer. The main goal of application-layer multicast is to construct\nand maintain efficient distribution structures between endhosts. In this paper\nwe focus on the implementation of an application-layer multicast network using\nPlanetLab. We observe that the total time required to measure network latency\nover TCP is influenced dramatically by the TCP connection time. We argue that\nend-host distribution is not only influenced by the quality of network links\nbut also by the time required to make connections between nodes. We provide\nseveral solutions to decrease the total end-host distribution time.\n", "versions": [{"version": "v1", "created": "Sun, 30 Jan 2011 17:49:58 GMT"}], "update_date": "2011-02-01", "authors_parsed": [["Bela", "Genge", ""], ["Piroska", "Haller", ""]]}, {"id": "1101.5915", "submitter": "Walter Quattrociocchi", "authors": "Sara Brunetti, Elena Lodi, Walter Quattrociocchi", "title": "Dynamic Monopolies in Colored Tori", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC cs.DS physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The {\\em information diffusion} has been modeled as the spread of an\ninformation within a group through a process of social influence, where the\ndiffusion is driven by the so called {\\em influential network}. Such a process,\nwhich has been intensively studied under the name of {\\em viral marketing}, has\nthe goal to select an initial good set of individuals that will promote a new\nidea (or message) by spreading the \"rumor\" within the entire social network\nthrough the word-of-mouth. Several studies used the {\\em linear threshold\nmodel} where the group is represented by a graph, nodes have two possible\nstates (active, non-active), and the threshold triggering the adoption\n(activation) of a new idea to a node is given by the number of the active\nneighbors.\n  The problem of detecting in a graph the presence of the minimal number of\nnodes that will be able to activate the entire network is called {\\em target\nset selection} (TSS). In this paper we extend TSS by allowing nodes to have\nmore than two colors. The multicolored version of the TSS can be described as\nfollows: let $G$ be a torus where every node is assigned a color from a finite\nset of colors. At each local time step, each node can recolor itself, depending\non the local configurations, with the color held by the majority of its\nneighbors. We study the initial distributions of colors leading the system to a\nmonochromatic configuration of color $k$, focusing on the minimum number of\ninitial $k$-colored nodes. We conclude the paper by providing the time\ncomplexity to achieve the monochromatic configuration.\n", "versions": [{"version": "v1", "created": "Mon, 31 Jan 2011 11:22:45 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Brunetti", "Sara", ""], ["Lodi", "Elena", ""], ["Quattrociocchi", "Walter", ""]]}]