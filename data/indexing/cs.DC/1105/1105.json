[{"id": "1105.0074", "submitter": "Rajesh Sharma", "authors": "Rajesh Sharma and Anwitaman Datta", "title": "SuperNova: Super-peers Based Architecture for Decentralized Online\n  Social Networks", "comments": "20 Pages, 10 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen several earnest initiatives from both academic\nresearchers as well as open source communities to implement and deploy\ndecentralized online social networks (DOSNs). The primary motivations for DOSNs\nare privacy and autonomy from big brotherly service providers. The promise of\ndecentralization is complete freedom for end-users from any service providers\nboth in terms of keeping privacy about content and communication, and also from\nany form of censorship. However decentralization introduces many challenges.\nOne of the principal problems is to guarantee availability of data even when\nthe data owner is not online, so that others can access the said data even when\na node is offline or down. In this paper, we argue that a pragmatic design\nneeds to explicitly allow for and leverage on system heterogeneity, and provide\nincentives for the resource rich participants in the system to contribute such\nresources. To that end we introduce SuperNova - a super-peer based DOSN\narchitecture. While proposing the SuperNova architecture, we envision a dynamic\nsystem driven by incentives and reputation, however, investigation of such\nincentives and reputation, and its effect on determining peer behaviors is a\nsubject for our future study. In this paper we instead investigate the efficacy\nof a super-peer based system at any time point (a snap-shot of the envisioned\ndynamic system), that is to say, we try to quantify the performance of\nSuperNova system given any (fixed) mix of peer population and strategies.\n", "versions": [{"version": "v1", "created": "Sat, 30 Apr 2011 10:49:27 GMT"}, {"version": "v2", "created": "Wed, 25 May 2011 13:56:50 GMT"}], "update_date": "2011-05-26", "authors_parsed": [["Sharma", "Rajesh", ""], ["Datta", "Anwitaman", ""]]}, {"id": "1105.0149", "submitter": "Ali Khajeh-Hosseini", "authors": "Ali Khajeh-Hosseini, Ian Sommerville, Jurgen Bogaerts, Pradeep\n  Teregowda", "title": "Decision Support Tools for Cloud Migration in the Enterprise", "comments": "To appear in IEEE CLOUD 2011", "journal-ref": null, "doi": "10.1109/CLOUD.2011.59", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes two tools that aim to support decision making during the\nmigration of IT systems to the cloud. The first is a modeling tool that\nproduces cost estimates of using public IaaS clouds. The tool enables IT\narchitects to model their applications, data and infrastructure requirements in\naddition to their computational resource usage patterns. The tool can be used\nto compare the cost of different cloud providers, deployment options and usage\nscenarios. The second tool is a spreadsheet that outlines the benefits and\nrisks of using IaaS clouds from an enterprise perspective; this tool provides a\nstarting point for risk assessment. Two case studies were used to evaluate the\ntools. The tools were useful as they informed decision makers about the costs,\nbenefits and risks of using the cloud.\n", "versions": [{"version": "v1", "created": "Sun, 1 May 2011 07:48:42 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Khajeh-Hosseini", "Ali", ""], ["Sommerville", "Ian", ""], ["Bogaerts", "Jurgen", ""], ["Teregowda", "Pradeep", ""]]}, {"id": "1105.0232", "submitter": "Ankur Sahai", "authors": "Ankur Sahai", "title": "Online Assignment Algorithms for Dynamic Bipartite Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes the problem of assigning weights to edges incrementally\nin a dynamic complete bipartite graph consisting of producer and consumer\nnodes. The objective is to minimize the overall cost while satisfying certain\nconstraints. The cost and constraints are functions of attributes of the edges,\nnodes and online service requests. Novelty of this work is that it models\nreal-time distributed resource allocation using an approach to solve this\ntheoretical problem. This paper studies variants of this assignment problem\nwhere the edges, producers and consumers can disappear and reappear or their\nattributes can change over time. Primal-Dual algorithms are used for solving\nthese problems and their competitive ratios are evaluated.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2011 02:09:05 GMT"}], "update_date": "2011-05-03", "authors_parsed": [["Sahai", "Ankur", ""]]}, {"id": "1105.0233", "submitter": "Ankur Sahai", "authors": "Ankur Sahai", "title": "Derandomization of Online Assignment Algorithms for Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes different online algorithms for the problem of assigning\nweights to edges in a fully-connected bipartite graph that minimizes the\noverall cost while satisfying constraints. Edges in this graph may disappear\nand reappear over time. Performance of these algorithms is measured using\nsimulations. This paper also attempts to derandomize the randomized online\nalgorithm for this problem.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2011 02:13:24 GMT"}], "update_date": "2011-05-03", "authors_parsed": [["Sahai", "Ankur", ""]]}, {"id": "1105.0296", "submitter": "Yang Li Daniel", "authors": "Yang D. Li", "title": "A Formal Model of Anonymous Systems", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We put forward a formal model of anonymous systems. And we concentrate on the\nanonymous failure detectors in our model. In particular, we give three examples\nof anonymous failure detectors and show that they can be used to solve the\nconsensus problem and that they are equivalent to their classic counterparts.\nMoreover, we show some relationship among them and provide a simple\nclassification of anonymous failure detectors.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2011 10:44:12 GMT"}], "update_date": "2011-05-03", "authors_parsed": [["Li", "Yang D.", ""]]}, {"id": "1105.0379", "submitter": "Anwitaman Datta", "authors": "Frederique Oggier and Anwitaman Datta", "title": "Self-Repairing Codes for Distributed Storage - A Projective Geometric\n  Construction", "comments": "5 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-Repairing Codes (SRC) are codes designed to suit the need of coding for\ndistributed networked storage: they not only allow stored data to be recovered\neven in the presence of node failures, they also provide a repair mechanism\nwhere as little as two live nodes can be contacted to regenerate the data of a\nfailed node. In this paper, we propose a new instance of self-repairing codes,\nbased on constructions of spreads coming from projective geometry. We study\nsome of their properties to demonstrate the suitability of these codes for\ndistributed networked storage.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2011 16:54:17 GMT"}], "update_date": "2011-05-03", "authors_parsed": [["Oggier", "Frederique", ""], ["Datta", "Anwitaman", ""]]}, {"id": "1105.0381", "submitter": "Gabriele D'Angelo", "authors": "Gabriele D'Angelo", "title": "Parallel and Distributed Simulation: Five W's (and One H)", "comments": "MIMOS DSIMday 2011, Universita di Roma Tor Vergata, February 25,2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A well known golden rule of journalism (and many other fields too) is that if\nyou want to know the full story about something you have to answer all the five\nW's (Who, What, When, Where, Why) and the H (How). This extended abstract is\nabout what is missing in parallel and distributed simulation and how this\naffects its popularity.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2011 16:57:32 GMT"}, {"version": "v2", "created": "Tue, 3 May 2011 06:52:13 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["D'Angelo", "Gabriele", ""]]}, {"id": "1105.0438", "submitter": "Johanne Cohen", "authors": "Vincent Reinhard, Johanne Cohen, Joanna Tomasik, Dominique Barth,\n  Marc-Antoine Weisser", "title": "Performance improvement of an optical network providing services based\n  on multicast", "comments": "16 pages, 13 figures, extended version from Conference ISCIS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Operators of networks covering large areas are confronted with demands from\nsome of their customers who are virtual service providers. These providers may\ncall for the connectivity service which fulfils the specificity of their\nservices, for instance a multicast transition with allocated bandwidth. On the\nother hand, network operators want to make profit by trading the connectivity\nservice of requested quality to their customers and to limit their\ninfrastructure investments (or do not invest anything at all).\n  We focus on circuit switching optical networks and work on repetitive\nmulticast demands whose source and destinations are {\\em \\`a priori} known by\nan operator. He may therefore have corresponding trees \"ready to be allocated\"\nand adapt his network infrastructure according to these recurrent\ntransmissions. This adjustment consists in setting available branching routers\nin the selected nodes of a predefined tree. The branching nodes are\nopto-electronic nodes which are able to duplicate data and retransmit it in\nseveral directions. These nodes are, however, more expensive and more energy\nconsuming than transparent ones.\n  In this paper we are interested in the choice of nodes of a multicast tree\nwhere the limited number of branching routers should be located in order to\nminimize the amount of required bandwidth. After formally stating the problem\nwe solve it by proposing a polynomial algorithm whose optimality we prove. We\nperform exhaustive computations to show an operator gain obtained by using our\nalgorithm. These computations are made for different methods of the multicast\ntree construction. We conclude by giving dimensioning guidelines and outline\nour further work.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2011 20:49:00 GMT"}], "update_date": "2011-05-04", "authors_parsed": [["Reinhard", "Vincent", ""], ["Cohen", "Johanne", ""], ["Tomasik", "Joanna", ""], ["Barth", "Dominique", ""], ["Weisser", "Marc-Antoine", ""]]}, {"id": "1105.0479", "submitter": "Shailesh Vaya", "authors": "Shailesh Vaya", "title": "Faster Gossiping in Bidirectional Radio Networks with Large Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider unknown ad-hoc radio networks, when the underlying network is\nbidirectional and nodes can have polynomially large labels. For this model, we\npresent a deterministic protocol for gossiping which takes $O(n \\lg^2 n \\lg \\lg\nn)$ rounds. This improves upon the previous best result for deterministic\ngossiping for this model by [Gasienec, Potapov, Pagourtizis, Deterministic\nGossiping in Radio Networks with Large labels, ESA (2002)], who present a\nprotocol of round complexity $O(n \\lg^3 n \\lg \\lg n)$ for this problem. This\nresolves open problem posed in [Gasienec, Efficient gossiping in radio\nnetworks, SIROCCO (2009)], who cite bridging gap between lower and upper bounds\nfor this problem as an important objective. We emphasize that a salient feature\nof our protocol is its simplicity, especially with respect to the previous best\nknown protocol for this problem.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 06:06:15 GMT"}], "update_date": "2011-05-04", "authors_parsed": [["Vaya", "Shailesh", ""]]}, {"id": "1105.0545", "submitter": "Stefano Ferretti Stefano Ferretti", "authors": "Stefano Ferretti", "title": "On the Degree Distribution of Faulty Peer-to-Peer Overlays", "comments": "A revised version is published in ICST Transactions on Complex\n  Systems, ICST, Vol.12, 1-20, 2012,\n  http://eudl.eu/doi/10.4108/trans.comsys.2012.10-12.e2", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an analytical framework to model fault-tolerance in\nunstructured peer-to-peer overlays, represented as complex networks. We define\na distributed protocol peers execute for managing the overlay and reacting to\nnode faults. Based on the protocol, evolution equations are defined and\nmanipulated by resorting to generating functions. Obtained outcomes provide\ninsights on the nodes' degree probability distribution. From the study of the\ndegree distribution, it is possible to estimate other important metrics of the\npeer-to-peer overlay, such as the diameter of the network. We study different\nnetworks, characterized by three specific desired degree distributions, i.e.\nnets with nodes having a fixed desired degree, random graphs and scale-free\nnetworks. All these networks are assessed via the analytical tool and\nsimulation as well. Results show that the approach can be factually employed to\ndynamically tune the average attachment rate at peers so that they maintain\ntheir own desired degree and, in general, the desired network topology.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 11:02:37 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2012 06:50:56 GMT"}, {"version": "v3", "created": "Mon, 7 Jan 2013 15:55:10 GMT"}, {"version": "v4", "created": "Tue, 8 Jan 2013 08:15:30 GMT"}], "update_date": "2013-01-09", "authors_parsed": [["Ferretti", "Stefano", ""]]}, {"id": "1105.0661", "submitter": "Jan David Mol", "authors": "Jan David Mol and John W. Romein", "title": "The LOFAR Beam Former: Implementation and Performance Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional radio telescopes use large, steel dishes to observe radio\nsources. The LOFAR radio telescope is different, and uses tens of thousands of\nfixed, non-movable antennas instead, a novel design that promises\nground-breaking research in astronomy. The antennas observe omnidirectionally,\nand sky sources are observed by signal-processing techniques that combine the\ndata from all antennas.\n  Another new feature of LOFAR is the elaborate use of software to do signal\nprocessing in real time, where traditional telescopes use custom-built\nhardware. The use of software leads to an instrument that is inherently more\nflexible. However, the enormous data rate (198 Gb/s of input data) and\nprocessing requirements compel the use of a supercomputer: we use an IBM Blue\nGene/P.\n  This paper presents a collection of new processing pipelines, collectively\ncalled the beam-forming pipelines, that greatly enhance the functionality of\nthe telescope. Where our first pipeline could only correlate data to create sky\nimages, the new pipelines allow the discovery of unknown pulsars, observations\nof known pulsars, and (in the future), to observe cosmic rays and study\ntransient events. Unlike traditional telescopes, we can observe in hundreds of\ndirections simultaneously. This is useful, for example, to search the sky for\nnew pulsars. The use of software allows us to quickly add new functionality and\nto adapt to new insights that fully exploit the novel features and the power of\nour unique instrument. We also describe our optimisations to use the Blue\nGene/P at very high efficiencies, maximising the effectiveness of the entire\ntelescope. A thorough performance study identifies the limits of our system.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 19:28:06 GMT"}], "update_date": "2011-05-04", "authors_parsed": [["Mol", "Jan David", ""], ["Romein", "John W.", ""]]}, {"id": "1105.0668", "submitter": "Partha Sarathi Mandal Dr.", "authors": "Partha Sarathi Mandal and Anil K. Ghosh", "title": "Secure Position Verification for Wireless Sensor Networks in Noisy\n  Channels", "comments": "16 pages, The paper has been accepted for presentation at the 10th\n  International Conference on Ad Hoc Networks and Wireless (ADHOC NOW 2011)\n  July 18-20, 2011, Paderborn, Germany", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Position verification in wireless sensor networks (WSNs) is quite tricky in\npresence of attackers (malicious sensor nodes), who try to break the\nverification protocol by reporting their incorrect positions (locations) during\nthe verification stage. In the literature of WSNs, most of the existing methods\nof position verification have used trusted verifiers, which are in fact\nvulnerable to attacks by malicious nodes. They also depend on some distance\nestimation techniques, which are not accurate in noisy channels (mediums). In\nthis article, we propose a secure position verification scheme for WSNs in\nnoisy channels without relying on any trusted entities. Our verification scheme\ndetects and filters out all malicious nodes from the network with very high\nprobability.\n", "versions": [{"version": "v1", "created": "Tue, 3 May 2011 19:59:13 GMT"}, {"version": "v2", "created": "Thu, 5 May 2011 16:52:06 GMT"}], "update_date": "2011-05-06", "authors_parsed": [["Mandal", "Partha Sarathi", ""], ["Ghosh", "Anil K.", ""]]}, {"id": "1105.0966", "submitter": "Aaron Turon", "authors": "Aaron Turon and Mitchell Wand", "title": "A resource analysis of the pi-calculus", "comments": "Preliminary version for MFPS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a new treatment of the pi-calculus based on the semantic theory of\nseparation logic, continuing a research program begun by Hoare and O'Hearn.\nUsing a novel resource model that distinguishes between public and private\nownership, we refactor the operational semantics so that sending, receiving,\nand allocating are commands that influence owned resources. These ideas lead\nnaturally to two denotational models: one for safety and one for liveness. Both\nmodels are fully abstract for the corresponding observables, but more\nimportantly both are very simple. The close connections with the model theory\nof separation logic (in particular, with Brookes's action trace model) give\nrise to a logic of processes and resources.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2011 01:29:17 GMT"}], "update_date": "2011-05-06", "authors_parsed": [["Turon", "Aaron", ""], ["Wand", "Mitchell", ""]]}, {"id": "1105.0991", "submitter": "Qiang Zhu Professor", "authors": "Qiang Zhu, Xinke Wang, Juanjuan Ren", "title": "Extra connectivity measures of 3-ary n-cubes", "comments": "10 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The h-extra connectivity is an important parameter to measure the reliability\nand fault tolerance ability of large interconnection networks. The k-ary n-cube\nis an important interconnection network of parallel computing systems. The\n1-restricted connectivity of k-ary n-cubes has been obtained by Chen et al. for\nk > 3 in [Y.-C. Chen, J. J. M. Tan, Restricted connectivity for three families\nof interconnection networks, Applied Mathematics and Computation 188 (2)\n(2007)1848--1855]. Nevertheless, the h-extra connectivity of 3-ary n-cubes has\nnot been obtained yet. In this paper we prove that the 1-extra connectivity of\na 3-ary n-cube is 4n-3 for n> 1 and the 2-extra connectivity of 3-ary n-cube is\n6n-7 for n> 2.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2011 06:49:07 GMT"}], "update_date": "2011-05-06", "authors_parsed": [["Zhu", "Qiang", ""], ["Wang", "Xinke", ""], ["Ren", "Juanjuan", ""]]}, {"id": "1105.1074", "submitter": "Dorina Thanou", "authors": "Dorina Thanou, Effrosyni Kokiopoulou, Pascal Frossard", "title": "Progressive quantization in distributed average consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of distributed average consensus in a sensor network\nwhere sensors exchange quantized information with their neighbors. We propose a\nnovel quantization scheme that exploits the increasing correlation between the\nvalues exchanged by the sensors throughout the iterations of the consensus\nalgorithm. A low complexity, uniform quantizer is implemented in each sensor,\nand refined quantization is achieved by progressively reducing the quantization\nintervals during the convergence of the consensus algorithm. We propose a\nrecurrence relation for computing the quantization parameters that depend on\nthe network topology and the communication rate. We further show that the\nrecurrence relation can lead to a simple exponential model for the size of the\nquantization step size over the iterations, whose parameters can be computed a\npriori. Finally, simulation results demonstrate the effectiveness of the\nprogressive quantization scheme that leads to the consensus solution even at\nlow communication rate.\n", "versions": [{"version": "v1", "created": "Thu, 5 May 2011 13:56:48 GMT"}, {"version": "v2", "created": "Wed, 21 Mar 2012 14:09:14 GMT"}], "update_date": "2012-03-22", "authors_parsed": [["Thanou", "Dorina", ""], ["Kokiopoulou", "Effrosyni", ""], ["Frossard", "Pascal", ""]]}, {"id": "1105.1242", "submitter": "Hemant Kowshik", "authors": "Hemant Kowshik and P. R. Kumar", "title": "Optimal Computation of Symmetric Boolean Functions in Collocated\n  Networks", "comments": "submitted to IEEE Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider collocated wireless sensor networks, where each node has a\nBoolean measurement and the goal is to compute a given Boolean function of\nthese measurements. We first consider the worst case setting and study optimal\nblock computation strategies for computing symmetric Boolean functions. We\nstudy three classes of functions: threshold functions, delta functions and\ninterval functions. We provide exactly optimal strategies for the first two\nclasses, and a scaling law order-optimal strategy with optimal preconstant for\ninterval functions. We also extend the results to the case of integer\nmeasurements and certain integer-valued functions. We use lower bounds from\ncommunication complexity theory, and provide an achievable scheme using\ninformation theoretic tools.\n  Next, we consider the case where nodes measurements are random and drawn from\nindependent Bernoulli distributions. We address the problem of optimal function\ncomputation so as to minimize the expected total number of bits that are\ntransmitted. In the case of computing a single instance of a Boolean threshold\nfunction, we show the surprising result that the optimal order of transmissions\ndepends in an extremely simple way on the values of previously transmitted\nbits, and the ordering of the marginal probabilities of the Boolean variables.\n  The approach presented can be generalized to the case where each node has a\nblock of measurements, though the resulting problem is somewhat harder, and we\nconjecture the optimal strategy. We further show how to generalize to a pulse\nmodel of communication. One can also consider the related problem of\napproximate computation given a fixed number of bits. In this case, the optimal\nstrategy is significantly different, and lacks an elegant characterization.\nHowever, for the special case of the parity function, we show that the greedy\nstrategy is optimal.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2011 08:28:41 GMT"}], "update_date": "2011-05-09", "authors_parsed": [["Kowshik", "Hemant", ""], ["Kumar", "P. R.", ""]]}, {"id": "1105.1248", "submitter": "Peter Pietrzyk", "authors": "Patrick Briest and Bastian Degener and Barbara Kempkes and Peter Kling\n  and Peter Pietrzyk", "title": "A Distributed Approximation Algorithm for the Metric Uncapacitated\n  Facility Location Problem in the Congest Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a randomized distributed approximation algorithm for the metric\nuncapacitated facility location problem. The algorithm is executed on a\nbipartite graph in the Congest model yielding a (1.861 + epsilon) approximation\nfactor, where epsilon is an arbitrary small positive constant. It needs\nO(n^{3/4}log_{1+epsilon}^2(n) communication rounds with high probability (n\ndenoting the number of facilities and clients). To the best of our knowledge,\nour algorithm currently has the best approximation factor for the facility\nlocation problem in a distributed setting. It is based on a greedy sequential\napproximation algorithm by Jain et al. (J. ACM 50(6), pages: 795-824, 2003).\nThe main difficulty in executing this sequential algorithm lies in dealing with\nsituations, where multiple facilities are eligible for opening, but (in order\nto preserve the approximation factor of the sequential algorithm) only a subset\nof them can actually be opened. Note that while the presented runtime bound of\nour algorithm is \"with high probability\", the approximation factor is not \"in\nexpectation\" but always guaranteed to be (1.861 + epsilon). Thus, our main\ncontribution is a sublinear time selection mechanism that, while increasing the\napproximation factor by an arbitrary small additive term, allows us to decide\nwhich of the eligible facilities to open.\n", "versions": [{"version": "v1", "created": "Fri, 6 May 2011 09:36:03 GMT"}], "update_date": "2011-05-09", "authors_parsed": [["Briest", "Patrick", ""], ["Degener", "Bastian", ""], ["Kempkes", "Barbara", ""], ["Kling", "Peter", ""], ["Pietrzyk", "Peter", ""]]}, {"id": "1105.1486", "submitter": "Mladen Pavicic", "authors": "Norman D. Megill and Mladen Pavicic", "title": "Estimating Bernoulli trial probability from a small sample", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.PR stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The standard textbook method for estimating the probability of a biased coin\nfrom finite tosses implicitly assumes the sample sizes are large and gives\nincorrect results for small samples. We describe the exact solution, which is\ncorrect for any sample size.\n", "versions": [{"version": "v1", "created": "Sun, 8 May 2011 01:46:29 GMT"}], "update_date": "2011-05-11", "authors_parsed": [["Megill", "Norman D.", ""], ["Pavicic", "Mladen", ""]]}, {"id": "1105.1827", "submitter": "Gregory Kerr", "authors": "Gregory Kerr", "title": "Dissecting a Small InfiniBand Application Using the Verbs API", "comments": "18 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  InfiniBand is a switched fabric interconnect. The InfiniBand specification\ndoes not define an API. However the OFED package, libibverbs, has become the\ndefault API on Linux and Solaris systems. Sparse documentation exists for the\nverbs API. The simplest InfiniBand program provided by OFED, ibv_rc_pingpong,\nis about 800 lines long. The semantics of using the verbs API for this program\nis not obvious to the first time reader. This paper will dissect the\nibv_rc_pingpong program in an attempt to make clear to users how to interact\nwith verbs.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 00:03:04 GMT"}, {"version": "v2", "created": "Tue, 24 May 2011 18:29:32 GMT"}], "update_date": "2011-05-25", "authors_parsed": [["Kerr", "Gregory", ""]]}, {"id": "1105.1891", "submitter": "David Shuman", "authors": "David I Shuman, Pierre Vandergheynst, and Pascal Frossard", "title": "Chebyshev Polynomial Approximation for Distributed Signal Processing", "comments": "8 pages, 5 figures, to appear in the Proceedings of the IEEE\n  International Conference on Distributed Computing in Sensor Systems (DCOSS),\n  June, 2011, Barcelona, Spain", "journal-ref": null, "doi": "10.1109/DCOSS.2011.5982158", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unions of graph Fourier multipliers are an important class of linear\noperators for processing signals defined on graphs. We present a novel method\nto efficiently distribute the application of these operators to the\nhigh-dimensional signals collected by sensor networks. The proposed method\nfeatures approximations of the graph Fourier multipliers by shifted Chebyshev\npolynomials, whose recurrence relations make them readily amenable to\ndistributed computation. We demonstrate how the proposed method can be used in\na distributed denoising task, and show that the communication requirements of\nthe method scale gracefully with the size of the network.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 09:35:54 GMT"}, {"version": "v2", "created": "Fri, 27 May 2011 16:03:52 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Shuman", "David I", ""], ["Vandergheynst", "Pierre", ""], ["Frossard", "Pascal", ""]]}, {"id": "1105.1982", "submitter": "Vaibhav Khadilkar", "authors": "Vaibhav Khadilkar, Murat Kantarcioglu, Bhavani Thuraisingham, Sharad\n  Mehrotra", "title": "Secure Data Processing in a Hybrid Cloud", "comments": "16 pages (13 pages + 3 page appendix), 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Cloud computing has made it possible for a user to be able to select a\ncomputing service precisely when needed. However, certain factors such as\nsecurity of data and regulatory issues will impact a user's choice of using\nsuch a service. A solution to these problems is the use of a hybrid cloud that\ncombines a user's local computing capabilities (for mission- or\norganization-critical tasks) with a public cloud (for less influential tasks).\nWe foresee three challenges that must be overcome before the adoption of a\nhybrid cloud approach: 1) data design: How to partition relations in a hybrid\ncloud? The solution to this problem must account for the sensitivity of\nattributes in a relation as well as the workload of a user; 2) data security:\nHow to protect a user's data in a public cloud with encryption while enabling\nquery processing over this encrypted data? and 3) query processing: How to\nexecute queries efficiently over both, encrypted and unencrypted data? This\npaper addresses these challenges and incorporates their solutions into an\nadd-on tool for a Hadoop and Hive based cloud computing infrastructure.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 15:49:38 GMT"}], "update_date": "2011-05-11", "authors_parsed": [["Khadilkar", "Vaibhav", ""], ["Kantarcioglu", "Murat", ""], ["Thuraisingham", "Bhavani", ""], ["Mehrotra", "Sharad", ""]]}, {"id": "1105.2213", "submitter": "Andreas Baldi", "authors": "Elarbi Badidi, Larbi Esmahi", "title": "A Cloud-based Approach for Context Information Provisioning", "comments": "8 Pages", "journal-ref": "World of Computer Science and Information Technology Journal\n  (WCSIT) , ISSN: 2221-0741, Vol. 1, No. 3, 63-70, 2011", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As a result of the phenomenal proliferation of modern mobile Internet-enabled\ndevices and the widespread utilization of wireless and cellular data networks,\nmobile users are increasingly requiring services tailored to their current\ncontext. High-level context information is typically obtained from context\nservices that aggregate raw context information sensed by various sensors and\nmobile devices. Given the massive amount of sensed data, traditional context\nservices are lacking the necessary resources to store and process these data,\nas well as to disseminate high-level context information to a variety of\npotential context consumers. In this paper, we propose a novel framework for\ncontext information provisioning, which relies on deploying context services on\nthe cloud and using context brokers to mediate between context consumers and\ncontext services using a publish/subscribe model. Moreover, we describe a\nmulti-attributes decision algorithm for the selection of potential context\nservices that can fulfill context consumers' requests for context information.\nThe algorithm calculates the score of each context service, per context\ninformation type, based on the quality-of-service (QoS) and quality-of-context\ninformation (QoC) requirements expressed by the context consumer. One of the\nbenefits of the approach is that context providers can scale up and down, in\nterms of cloud resources they use, depending on current demand for context\ninformation. Besides, the selection algorithm allows ranking context services\nby matching their QoS and QoC offers against the QoS and QoC requirements of\nthe context consumer.\n", "versions": [{"version": "v1", "created": "Tue, 10 May 2011 18:02:56 GMT"}], "update_date": "2011-05-12", "authors_parsed": [["Badidi", "Elarbi", ""], ["Esmahi", "Larbi", ""]]}, {"id": "1105.2274", "submitter": "Hua Ouyang", "authors": "Hua Ouyang, Alexander Gray", "title": "Data-Distributed Weighted Majority and Online Mirror Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the question of the extent to which online\nlearning can benefit from distributed computing. We focus on the setting in\nwhich $N$ agents online-learn cooperatively, where each agent only has access\nto its own data. We propose a generic data-distributed online learning\nmeta-algorithm. We then introduce the Distributed Weighted Majority and\nDistributed Online Mirror Descent algorithms, as special cases. We show, using\nboth theoretical analysis and experiments, that compared to a single agent:\ngiven the same computation time, these distributed algorithms achieve smaller\ngeneralization errors; and given the same generalization errors, they can be\n$N$ times faster.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2011 18:59:13 GMT"}], "update_date": "2019-08-17", "authors_parsed": [["Ouyang", "Hua", ""], ["Gray", "Alexander", ""]]}, {"id": "1105.2279", "submitter": "Frank Winter", "authors": "Frank Winter", "title": "Accelerating QDP++ using GPUs", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": "Edinburgh 2011/17", "categories": "hep-lat cs.DC cs.PL physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphic Processing Units (GPUs) are getting increasingly important as target\narchitectures in scientific High Performance Computing (HPC). NVIDIA\nestablished CUDA as a parallel computing architecture controlling and making\nuse of the compute power of GPUs. CUDA provides sufficient support for C++\nlanguage elements to enable the Expression Template (ET) technique in the\ndevice memory domain. QDP++ is a C++ vector class library suited for quantum\nfield theory which provides vector data types and expressions and forms the\nbasis of the lattice QCD software suite Chroma. In this work accelerating QDP++\nexpression evaluation to a GPU was successfully implemented leveraging the ET\ntechnique and using Just-In-Time (JIT) compilation. The Portable Expression\nTemplate Engine (PETE) and the C API for CUDA kernel arguments were used to\nbuild the bridge between host and device memory domains. This provides the\npossibility to accelerate Chroma routines to a GPU which are typically not\nsubject to special optimisation. As an application example a smearing routine\nwas accelerated to execute on a GPU. A significant speed-up compared to normal\nCPU execution could be measured.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2011 19:16:14 GMT"}], "update_date": "2011-05-12", "authors_parsed": [["Winter", "Frank", ""]]}, {"id": "1105.2301", "submitter": "Gabriele D'Angelo", "authors": "Gabriele D'Angelo", "title": "Parallel and Distributed Simulation from Many Cores to the Public Cloud\n  (Extended Version)", "comments": "Tutorial paper published in the Proceedings of the International\n  Conference on High Performance Computing and Simulation (HPCS 2011). Istanbul\n  (Turkey), IEEE, July 2011. ISBN 978-1-61284-382-7", "journal-ref": null, "doi": "10.1109/HPCSim.2011.5999802", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this tutorial paper, we will firstly review some basic simulation concepts\nand then introduce the parallel and distributed simulation techniques in view\nof some new challenges of today and tomorrow. More in particular, in the last\nyears there has been a wide diffusion of many cores architectures and we can\nexpect this trend to continue. On the other hand, the success of cloud\ncomputing is strongly promoting the everything as a service paradigm. Is\nparallel and distributed simulation ready for these new challenges? The current\napproaches present many limitations in terms of usability and adaptivity: there\nis a strong need for new evaluation metrics and for revising the currently\nimplemented mechanisms. In the last part of the paper, we propose a new\napproach based on multi-agent systems for the simulation of complex systems. It\nis possible to implement advanced techniques such as the migration of simulated\nentities in order to build mechanisms that are both adaptive and very easy to\nuse. Adaptive mechanisms are able to significantly reduce the communication\ncost in the parallel/distributed architectures, to implement load-balance\ntechniques and to cope with execution environments that are both variable and\ndynamic. Finally, such mechanisms will be used to build simulations on top of\nunreliable cloud services.\n", "versions": [{"version": "v1", "created": "Wed, 11 May 2011 20:01:11 GMT"}, {"version": "v2", "created": "Wed, 29 Jun 2011 14:11:08 GMT"}, {"version": "v3", "created": "Wed, 9 Nov 2011 08:30:29 GMT"}, {"version": "v4", "created": "Tue, 29 Jul 2014 10:26:28 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["D'Angelo", "Gabriele", ""]]}, {"id": "1105.2447", "submitter": "Gabriele D'Angelo", "authors": "Gabriele D'Angelo and Stefano Ferretti", "title": "LUNES: Agent-based Simulation of P2P Systems (Extended Version)", "comments": "Proceedings of the International Workshop on Modeling and Simulation\n  of Peer-to-Peer Architectures and Systems (MOSPAS 2011). As part of the 2011\n  International Conference on High Performance Computing and Simulation (HPCS\n  2011)", "journal-ref": null, "doi": "10.1109/HPCSim.2011.5999879", "report-no": null, "categories": "cs.DC cs.MA cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present LUNES, an agent-based Large Unstructured NEtwork Simulator, which\nallows to simulate complex networks composed of a high number of nodes. LUNES\nis modular, since it splits the three phases of network topology creation,\nprotocol simulation and performance evaluation. This permits to easily\nintegrate external software tools into the main software architecture. The\nsimulation of the interaction protocols among network nodes is performed via a\nsimulation middleware that supports both the sequential and the\nparallel/distributed simulation approaches. In the latter case, a specific\nmechanism for the communication overhead-reduction is used; this guarantees\nhigh levels of performance and scalability. To demonstrate the efficiency of\nLUNES, we test the simulator with gossip protocols executed on top of networks\n(representing peer-to-peer overlays), generated with different topologies.\nResults demonstrate the effectiveness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 12:26:40 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2012 08:58:52 GMT"}, {"version": "v3", "created": "Mon, 28 Jul 2014 09:38:29 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["D'Angelo", "Gabriele", ""], ["Ferretti", "Stefano", ""]]}, {"id": "1105.2461", "submitter": "Sebastien Tixeuil", "authors": "St\\'ephane Devismes (VERIMAG - IMAG), Anissa Lamani (MIS), Franck\n  Petit (LIP6, INRIA Rocquencourt), Pascal Raymond (VERIMAG - IMAG),\n  S\\'ebastien Tixeuil (LIP6, IUF)", "title": "Optimal grid exploration by asynchronous oblivious robots", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM cs.NI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a team of {\\em autonomous weak robots} that are endowed with\nvisibility sensors and motion actuators. Autonomous means that the team cannot\nrely on any kind of central coordination mechanism or scheduler. By weak we\nmean that the robots are devoid of (1) any (observable) IDs allowing to\ndifferentiate them (anonymous), (2) means of communication allowing them to\ncommunicate directly, and (3) any way to remember any previous observation nor\ncomputation performed in any previous step (oblivious). Robots asynchronously\noperate in cycles of three phases: Look, Compute, and Move. Furthermore, the\nnetwork is an anonymous unoriented grid. In such settings, the robots must\ncollaborate to solve a collective task, here the terminating grid exploration\n(exploration for short), despite being limited with respect to input from the\nenvironment, asymmetry, memory, etc. Exploration requires that robots explore\nthe grid and stop when the task is complete. We propose optimal (w.r.t. the\nnumber of robots) solutions for the deterministic terminating exploration of a\ngrid shaped network by a team of $k$ asynchronous oblivious robots in the fully\nasynchronous and non-atomic model, so called CORDA. In more details, we first\nassume the ATOM model in which each Look-Compute-Move cycle execution is\nexecuted atomically, ie every robot that is activated at instant t\ninstantaneously executes a full cycle between t and t+1. ATOM being strictly\nstronger than CORDA, all impossibility results in ATOM also hold in CORDA. We\nshow that it is impossible to explore a grid of at least three nodes with less\nthan three robots in ATOM. (This first result holds for both deterministic and\nprobabilistic settings.) Next, we show that it is impossible to\ndeterministically explore a (2,2)-Grid with less than 4 robots, and a\n(3,3)-Grid with less than 5 robots, respectively. Then, we propose\ndeterministic algorithms in CORDA to exhibit the optimal number of robots\nallowing to explore of a given grid. Our results show that except in two\nparticular cases, 3 robots are necessary and sufficient to deterministically\nexplore a grid of at least three nodes. The optimal number of robots for the\ntwo remaining cases is: 4 for the (2,2)-Grid and 5 for the (3,3)-Grid.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 13:08:17 GMT"}, {"version": "v2", "created": "Mon, 23 Jan 2012 14:20:33 GMT"}, {"version": "v3", "created": "Wed, 7 Mar 2012 20:36:23 GMT"}], "update_date": "2012-03-08", "authors_parsed": [["Devismes", "St\u00e9phane", "", "VERIMAG - IMAG"], ["Lamani", "Anissa", "", "MIS"], ["Petit", "Franck", "", "LIP6, INRIA Rocquencourt"], ["Raymond", "Pascal", "", "VERIMAG - IMAG"], ["Tixeuil", "S\u00e9bastien", "", "LIP6, IUF"]]}, {"id": "1105.2584", "submitter": "James Smith", "authors": "James W. Smith, Ian Sommerville", "title": "Workload Classification & Software Energy Measurement for Efficient\n  Scheduling on Private Cloud Platforms", "comments": "10 pages, Submitted to ACM SOCC 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  At present there are a number of barriers to creating an energy efficient\nworkload scheduler for a Private Cloud based data center. Firstly, the\nrelationship between different workloads and power consumption must be\ninvestigated. Secondly, current hardware-based solutions to providing energy\nusage statistics are unsuitable in warehouse scale data centers where low cost\nand scalability are desirable properties. In this paper we discuss the effect\nof different workloads on server power consumption in a Private Cloud platform.\nWe display a noticeable difference in energy consumption when servers are given\ntasks that dominate various resources (CPU, Memory, Hard Disk and Network). We\nthen use this insight to develop CloudMonitor, a software utility that is\ncapable of >95% accurate power predictions from monitoring resource consumption\nof workloads, after a \"training phase\" in which a dynamic power model is\ndeveloped.\n", "versions": [{"version": "v1", "created": "Thu, 12 May 2011 22:00:36 GMT"}], "update_date": "2011-05-16", "authors_parsed": [["Smith", "James W.", ""], ["Sommerville", "Ian", ""]]}, {"id": "1105.3232", "submitter": "Sokol Kosta", "authors": "Sokol Kosta, Andrius Aucinas, Pan Hui, Richard Mortier, Xinwen Zhang", "title": "Unleashing the Power of Mobile Cloud Computing using ThinkAir", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smartphones have exploded in popularity in recent years, becoming ever more\nsophisticated and capable. As a result, developers worldwide are building\nincreasingly complex applications that require ever increasing amounts of\ncomputational power and energy. In this paper we propose ThinkAir, a framework\nthat makes it simple for developers to migrate their smartphone applications to\nthe cloud. ThinkAir exploits the concept of smartphone virtualization in the\ncloud and provides method level computation offloading. Advancing on previous\nworks, it focuses on the elasticity and scalability of the server side and\nenhances the power of mobile cloud computing by parallelizing method execution\nusing multiple Virtual Machine (VM) images. We evaluate the system using a\nrange of benchmarks starting from simple micro-benchmarks to more complex\napplications. First, we show that the execution time and energy consumption\ndecrease two orders of magnitude for the N-queens puzzle and one order of\nmagnitude for a face detection and a virus scan application, using cloud\noffloading. We then show that if a task is parallelizable, the user can request\nmore than one VM to execute it, and these VMs will be provided dynamically. In\nfact, by exploiting parallelization, we achieve a greater reduction on the\nexecution time and energy consumption for the previous applications. Finally,\nwe use a memory-hungry image combiner tool to demonstrate that applications can\ndynamically request VMs with more computational power in order to meet their\ncomputational requirements.\n", "versions": [{"version": "v1", "created": "Mon, 16 May 2011 21:45:54 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Kosta", "Sokol", ""], ["Aucinas", "Andrius", ""], ["Hui", "Pan", ""], ["Mortier", "Richard", ""], ["Zhang", "Xinwen", ""]]}, {"id": "1105.3843", "submitter": "James Hanlon", "authors": "James Hanlon and Simon J. Hollis", "title": "Fast Distributed Process Creation with the XMOS XS1 Architecture", "comments": "To appear in Communicating Process Architectures (CPA) 2011, 14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The provision of mechanisms for processor allocation in current distributed\nparallel programming models is very limited. This makes difficult, or even\nprohibits, the expression of a large class of programs which require a run-time\nassessment of their required resources. This includes programs whose structure\nis irregular, composite or unbounded. Efficient allocation of processors\nrequires a process creation mechanism able to initiate and terminate remote\ncomputations quickly. This paper presents the design, demonstration and\nanalysis of an explicit mechanism to do this, implemented on the XMOS XS1\narchitecture, as a foundation for a more dynamic scheme. It shows that process\ncreation can be made efficient so that it incurs only a fractional overhead of\nthe total runtime and that it can be combined naturally with recursion to\nenable rapid distribution of computations over a system.\n", "versions": [{"version": "v1", "created": "Thu, 19 May 2011 11:18:46 GMT"}], "update_date": "2011-05-20", "authors_parsed": [["Hanlon", "James", ""], ["Hollis", "Simon J.", ""]]}, {"id": "1105.4136", "submitter": "Riccardo Murri", "authors": "Riccardo Murri", "title": "A novel parallel algorithm for Gaussian Elimination of sparse\n  unsymmetric matrices", "comments": "14 pages; 2 PDF figures; LaTeX2e; final version submitted for the\n  PPAM2011 conference proceedings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new algorithm for Gaussian Elimination suitable for general\n(unsymmetric and possibly singular) sparse matrices, of any entry type, which\nhas a natural parallel and distributed-memory formulation but degrades\ngracefully to sequential execution.\n  We present a sample MPI implementation of a program computing the rank of a\nsparse integer matrix using the proposed algorithm. Some preliminary\nperformance measurements are presented and discussed, and the performance of\nthe algorithm is compared to corresponding state-of-the-art algorithms for\nfloating-point and integer matrices.\n", "versions": [{"version": "v1", "created": "Fri, 20 May 2011 17:29:57 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2011 18:36:54 GMT"}, {"version": "v3", "created": "Sun, 15 Jan 2012 21:34:56 GMT"}], "update_date": "2012-01-17", "authors_parsed": [["Murri", "Riccardo", ""]]}, {"id": "1105.4204", "submitter": "Kunal Narayan Chaudhury", "authors": "Kunal Narayan Chaudhury, Daniel Sage, and Michael Unser", "title": "Fast O(1) bilateral filtering using trigonometric range kernels", "comments": "Accepted in IEEE Transactions on Image Processing. Also see addendum:\n  https://sites.google.com/site/kunalspage/home/Addendum.pdf", "journal-ref": "IEEE Transactions on Image Processing, vol. 20(12), pp. 3376 -\n  3382, 2011", "doi": null, "report-no": null, "categories": "cs.CV cs.CE cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that spatial averaging can be realized (in space or\nfrequency domain) using algorithms whose complexity does not depend on the size\nor shape of the filter. These fast algorithms are generally referred to as\nconstant-time or O(1) algorithms in the image processing literature. Along with\nthe spatial filter, the edge-preserving bilateral filter [Tomasi1998] involves\nan additional range kernel. This is used to restrict the averaging to those\nneighborhood pixels whose intensity are similar or close to that of the pixel\nof interest. The range kernel operates by acting on the pixel intensities. This\nmakes the averaging process non-linear and computationally intensive,\nespecially when the spatial filter is large. In this paper, we show how the\nO(1) averaging algorithms can be leveraged for realizing the bilateral filter\nin constant-time, by using trigonometric range kernels. This is done by\ngeneralizing the idea in [Porikli2008] of using polynomial range kernels. The\nclass of trigonometric kernels turns out to be sufficiently rich, allowing for\nthe approximation of the standard Gaussian bilateral filter. The attractive\nfeature of our approach is that, for a fixed number of terms, the quality of\napproximation achieved using trigonometric kernels is much superior to that\nobtained in [Porikli2008] using polynomials.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2011 01:44:38 GMT"}, {"version": "v2", "created": "Thu, 26 May 2011 01:50:38 GMT"}, {"version": "v3", "created": "Wed, 27 Jul 2011 17:33:32 GMT"}], "update_date": "2013-07-23", "authors_parsed": [["Chaudhury", "Kunal Narayan", ""], ["Sage", "Daniel", ""], ["Unser", "Michael", ""]]}, {"id": "1105.4252", "submitter": "Sandeep Tata", "authors": "Avrilia Floratou (University of Wisconsin-Madison), Jignesh Patel\n  (University of Wisconsin-Madison), Eugene Shekita (IBM Research), Sandeep\n  Tata (IBM Research)", "title": "Column-Oriented Storage Techniques for MapReduce", "comments": "VLDB2011", "journal-ref": null, "doi": null, "report-no": "Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 7, pp.\n  419-429 (2011)", "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Users of MapReduce often run into performance problems when they scale up\ntheir workloads. Many of the problems they encounter can be overcome by\napplying techniques learned from over three decades of research on parallel\nDBMSs. However, translating these techniques to a MapReduce implementation such\nas Hadoop presents unique challenges that can lead to new design choices. This\npaper describes how column-oriented storage techniques can be incorporated in\nHadoop in a way that preserves its popular programming APIs.\n  We show that simply using binary storage formats in Hadoop can provide a 3x\nperformance boost over the naive use of text files. We then introduce a\ncolumn-oriented storage format that is compatible with the replication and\nscheduling constraints of Hadoop and show that it can speed up MapReduce jobs\non real workloads by an order of magnitude. We also show that dealing with\ncomplex column types such as arrays, maps, and nested records, which are common\nin MapReduce jobs, can incur significant CPU overhead. Finally, we introduce a\nnovel skip list column format and lazy record construction strategy that avoids\ndeserializing unwanted records to provide an additional 1.5x performance boost.\nExperiments on a real intranet crawl are used to show that our column-oriented\nstorage techniques can improve the performance of the map phase in Hadoop by as\nmuch as two orders of magnitude.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2011 12:07:37 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Floratou", "Avrilia", "", "University of Wisconsin-Madison"], ["Patel", "Jignesh", "", "University of Wisconsin-Madison"], ["Shekita", "Eugene", "", "IBM Research"], ["Tata", "Sandeep", "", "IBM Research"]]}, {"id": "1105.4256", "submitter": "Gianmarco De Francisci Morales", "authors": "Gianmarco De Francisci Morales (IMT Lucca), Aristides Gionis (Yahoo!\n  Research), Mauro Sozio (MPI Saarbruecken)", "title": "Social content matching in MapReduce", "comments": "VLDB2011", "journal-ref": "Proceedings of the VLDB Endowment (PVLDB), Vol. 4, No. 7, pp.\n  460-469 (2011)", "doi": null, "report-no": null, "categories": "cs.SI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matching problems are ubiquitous. They occur in economic markets, labor\nmarkets, internet advertising, and elsewhere. In this paper we focus on an\napplication of matching for social media. Our goal is to distribute content\nfrom information suppliers to information consumers. We seek to maximize the\noverall relevance of the matched content from suppliers to consumers while\nregulating the overall activity, e.g., ensuring that no consumer is overwhelmed\nwith data and that all suppliers have chances to deliver their content.\n  We propose two matching algorithms, GreedyMR and StackMR, geared for the\nMapReduce paradigm. Both algorithms have provable approximation guarantees, and\nin practice they produce high-quality solutions. While both algorithms scale\nextremely well, we can show that StackMR requires only a poly-logarithmic\nnumber of MapReduce steps, making it an attractive option for applications with\nvery large datasets. We experimentally show the trade-offs between quality and\nefficiency of our solutions on two large datasets coming from real-world\nsocial-media web sites.\n", "versions": [{"version": "v1", "created": "Sat, 21 May 2011 12:11:12 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Morales", "Gianmarco De Francisci", "", "IMT Lucca"], ["Gionis", "Aristides", "", "Yahoo!\n  Research"], ["Sozio", "Mauro", "", "MPI Saarbruecken"]]}, {"id": "1105.4301", "submitter": "Neil J. Gunther", "authors": "Neil J. Gunther, Shanti Subramanyam, Stefan Parvu", "title": "A Methodology for Optimizing Multithreaded System Scalability on\n  Multi-cores", "comments": "21 pages, 11 figures. To appear in \"Programming Multi-core and\n  Many-core Computing Systems,\" eds. S. Pllana and F. Xhafa, Wiley Series on\n  Parallel and Distributed Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to quantify scalability with the Universal Scalability Law (USL)\nby applying it to performance measurements of memcached, J2EE, and Weblogic on\nmulti-core platforms. Since commercial multicores are essentially black-boxes,\nthe accessible performance gains are primarily available at the application\nlevel. We also demonstrate how our methodology can identify the most\nsignificant performance tuning opportunities to optimize application\nscalability, as well as providing an easy means for exploring other aspects of\nthe multi-core system design space.\n", "versions": [{"version": "v1", "created": "Sun, 22 May 2011 01:12:11 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Gunther", "Neil J.", ""], ["Subramanyam", "Shanti", ""], ["Parvu", "Stefan", ""]]}, {"id": "1105.4424", "submitter": "Antonio Wendell De Oliveira Rodrigues", "authors": "Antonio Wendell De Oliveira Rodrigues (INRIA Lille - Nord Europe),\n  Fr\\'ed\\'eric Guyomarc'H (INRIA Lille - Nord Europe), Jean-Luc Dekeyser (INRIA\n  Lille - Nord Europe)", "title": "A Modeling Approach based on UML/MARTE for GPU Architecture", "comments": "Symposium en Architectures nouvelles de machines (SympA'14) (2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the High Performance Computing is part of the context of embedded\nsystems. Graphics Processing Units (GPUs) are more and more used in\nacceleration of the most part of algorithms and applications. Over the past\nyears, not many efforts have been done to describe abstractions of applications\nin relation to their target architectures. Thus, when developers need to\nassociate applications and GPUs, for example, they find difficulty and prefer\nusing API for these architectures. This paper presents a metamodel extension\nfor MARTE profile and a model for GPU architectures. The main goal is to\nspecify the task and data allocation in the memory hierarchy of these\narchitectures. The results show that this approach will help to generate code\nfor GPUs based on model transformations using Model Driven Engineering (MDE).\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2011 07:54:02 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Rodrigues", "Antonio Wendell De Oliveira", "", "INRIA Lille - Nord Europe"], ["Guyomarc'H", "Fr\u00e9d\u00e9ric", "", "INRIA Lille - Nord Europe"], ["Dekeyser", "Jean-Luc", "", "INRIA\n  Lille - Nord Europe"]]}, {"id": "1105.4490", "submitter": "Bas Fagginger Auer", "authors": "B. O. Fagginger Auer and R. H. Bisseling", "title": "A Geometric Approach to Matrix Ordering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a recursive way to partition hypergraphs which creates and\nexploits hypergraph geometry and is suitable for many-core parallel\narchitectures. Such partitionings are then used to bring sparse matrices in a\nrecursive Bordered Block Diagonal form (for processor-oblivious parallel LU\ndecomposition) or recursive Separated Block Diagonal form (for cache-oblivious\nsparse matrix-vector multiplication). We show that the quality of the obtained\npartitionings and orderings is competitive by comparing obtained fill-in for LU\ndecomposition with SuperLU (with better results for 8 of the 28 test matrices)\nand comparing cut sizes for sparse matrix-vector multiplication with Mondriaan\n(with better results for 4 of the 12 test matrices). The main advantage of the\nnew method is its speed: it is on average 21.6 times faster than Mondriaan.\n", "versions": [{"version": "v1", "created": "Mon, 23 May 2011 13:14:30 GMT"}], "update_date": "2011-05-24", "authors_parsed": [["Auer", "B. O. Fagginger", ""], ["Bisseling", "R. H.", ""]]}, {"id": "1105.4780", "submitter": "Christoph Lenzen", "authors": "Danny Dolev, Matthias Fuegger, Christoph Lenzen, and Ulrich Schmid", "title": "Fault-tolerant Algorithms for Tick-Generation in Asynchronous Logic:\n  Robust Pulse Generation", "comments": "52 pages, 7 figures, extended abstract published at SSS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's hardware technology presents a new challenge in designing robust\nsystems. Deep submicron VLSI technology introduced transient and permanent\nfaults that were never considered in low-level system designs in the past.\nStill, robustness of that part of the system is crucial and needs to be\nguaranteed for any successful product. Distributed systems, on the other hand,\nhave been dealing with similar issues for decades. However, neither the basic\nabstractions nor the complexity of contemporary fault-tolerant distributed\nalgorithms match the peculiarities of hardware implementations. This paper is\nintended to be part of an attempt striving to overcome this gap between theory\nand practice for the clock synchronization problem. Solving this task\nsufficiently well will allow to build a very robust high-precision clocking\nsystem for hardware designs like systems-on-chips in critical applications. As\nour first building block, we describe and prove correct a novel Byzantine\nfault-tolerant self-stabilizing pulse synchronization protocol, which can be\nimplemented using standard asynchronous digital logic. Despite the strict\nlimitations introduced by hardware designs, it offers optimal resilience and\nsmaller complexity than all existing protocols.\n", "versions": [{"version": "v1", "created": "Tue, 24 May 2011 14:32:18 GMT"}, {"version": "v2", "created": "Sat, 28 May 2011 20:22:55 GMT"}, {"version": "v3", "created": "Fri, 14 Oct 2011 15:02:13 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Dolev", "Danny", ""], ["Fuegger", "Matthias", ""], ["Lenzen", "Christoph", ""], ["Schmid", "Ulrich", ""]]}, {"id": "1105.5062", "submitter": "Michele Mazzucco", "authors": "Michele Mazzucco and Marlon Dumas", "title": "Reserved or On-Demand Instances? A Revenue Maximization Model for Cloud\n  Providers", "comments": "8 pages, to appear in Proceedings of the 4th International Conference\n  on Cloud Computing (IEEE Cloud 2011), Washington DC (USA), July 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the problem of managing a server farm in a way that attempts to\nmaximize the net revenue earned by a cloud provider by renting servers to\ncustomers according to a typical Platform-as-a-Service model. The Cloud\nprovider offers its resources to two classes of customers: `premium' and\n`basic'. Premium customers pay upfront fees to reserve servers for a specified\nperiod of time (e.g. a year). Premium customers can submit jobs for their\nreserved servers at any time and pay a fee for the server-hours they use. The\nprovider is liable to pay a penalty every time a `premium' job can not be\nexecuted due to lack of resources. On the other hand, `basic' customers are\nserved on a best-effort basis, and pay a server-hour fee that may be higher\nthan the one paid by premium customers. The provider incurs energy costs when\nrunning servers. Hence, it has an incentive to turn off idle servers. The\nquestion of how to choose the number of servers to allocate to each pool (basic\nand premium) is answered by analyzing a suitable queuing model and maximizing a\nrevenue function. Experimental results show that the proposed scheme adapts to\ndifferent traffic conditions, penalty levels, energy costs and usage fees.\n", "versions": [{"version": "v1", "created": "Wed, 25 May 2011 15:22:00 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Mazzucco", "Michele", ""], ["Dumas", "Marlon", ""]]}, {"id": "1105.5177", "submitter": "David Felber", "authors": "David Felber and Adam Meyerson", "title": "Scheduling under Precedence, Communication, and Energy Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of scheduling a set of $n$ tasks on $m$ processors\nunder precedence, communication, and global system energy constraints to\nminimize makespan. We extend existing scheduling models to account for energy\nusage and give convex programming algorithms that yield essentially the same\nresults as existing algorithms that do not consider energy, while adhering to a\nstrict energy bound.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2011 00:27:07 GMT"}], "update_date": "2011-05-27", "authors_parsed": [["Felber", "David", ""], ["Meyerson", "Adam", ""]]}, {"id": "1105.5255", "submitter": "Amitabh Trehan", "authors": "Shay Kutten, Ron Lavi, Amitabh Trehan", "title": "Composition Games for Distributed Systems: the EU Grant games", "comments": "Accepted at AAAI 2013: Twenty-Seventh Conference on Artificial\n  Intelligence, Bellevue, Washington, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze ways by which people decompose into groups in distributed systems.\nWe are interested in systems in which an agent can increase its utility by\nconnecting to other agents, but must also pay a cost that increases with the\nsize of the sys- tem. The right balance is achieved by the right size group of\nagents. We formulate and analyze three intuitive and realistic games and show\nhow simple changes in the protocol can dras- tically improve the price of\nanarchy of these games. In partic- ular, we identify two important properties\nfor a low price of anarchy: agreement in joining the system, and the possibil-\nity of appealing a rejection from a system. We show that the latter property is\nespecially important if there are some pre- existing constraints regarding who\nmay collaborate (or com- municate) with whom.\n", "versions": [{"version": "v1", "created": "Thu, 26 May 2011 10:49:50 GMT"}, {"version": "v2", "created": "Mon, 4 Jun 2012 12:19:47 GMT"}, {"version": "v3", "created": "Mon, 20 May 2013 13:55:18 GMT"}], "update_date": "2013-05-21", "authors_parsed": [["Kutten", "Shay", ""], ["Lavi", "Ron", ""], ["Trehan", "Amitabh", ""]]}, {"id": "1105.5509", "submitter": "Mikael Vejdemo-Johansson", "authors": "Mikael Vejdemo-Johansson and Emil Sk\\\"oldberg and Jason Dusek", "title": "A parallel Buchberger algorithm for multigraded ideals", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": "Mittag-Leffler-2011spring", "categories": "math.AC cs.DC cs.SC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We demonstrate a method to parallelize the computation of a Gr\\\"obner basis\nfor a homogenous ideal in a multigraded polynomial ring. Our method uses\nanti-chains in the lattice $\\mathbb N^k$ to separate mutually independent\nS-polynomials for reduction.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2011 09:46:53 GMT"}], "update_date": "2011-05-30", "authors_parsed": [["Vejdemo-Johansson", "Mikael", ""], ["Sk\u00f6ldberg", "Emil", ""], ["Dusek", "Jason", ""]]}, {"id": "1105.5641", "submitter": "Suresh Jaganathan", "authors": "Suresh Jaganathan and Jeevan Eranti", "title": "High Quality of Service on Video Streaming in P2P Networks using FST-MDC", "comments": "11 pages, 8 figures, journal", "journal-ref": "International Journal of Multimedia & Its Applications (IJMA),\n  Vol:3, No:2, May 2011, 33-43", "doi": "10.5121/ijma.2011.3203", "report-no": null, "categories": "cs.DC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Video streaming applications have newly attracted a large number of\nparticipants in a distribution network. Traditional client-server based video\nstreaming solutions sustain precious bandwidth provision rate on the server.\nRecently, several P2P streaming systems have been organized to provide\non-demand and live video streaming services on the wireless network at reduced\nserver cost. Peer-to-Peer (P2P) computing is a new pattern to construct\ndisseminated network applications. Typical error control techniques are not\nvery well matched and on the other hand error prone channels has increased\ngreatly for video transmission e.g., over wireless networks and IP. These two\nfacts united together provided the essential motivation for the development of\na new set of techniques (error concealment) capable of dealing with\ntransmission errors in video systems. In this paper, we propose an flexible\nmultiple description coding method named as Flexible Spatial-Temporal (FST)\nwhich improves error resilience in the sense of frame loss possibilities over\nindependent paths. It introduces combination of both spatial and temporal\nconcealment technique at the receiver and to conceal the lost frames more\neffectively. Experimental results show that, proposed approach attains\nreasonable quality of video performance over P2P wireless network.\n", "versions": [{"version": "v1", "created": "Fri, 27 May 2011 13:34:42 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Jaganathan", "Suresh", ""], ["Eranti", "Jeevan", ""]]}, {"id": "1105.5817", "submitter": "Zohir Bouzid", "authors": "Zohir Bouzid (LIP6), Anissa Lamani (MIS)", "title": "Robot Networks with Homonyms: The Case of Patterns Formation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the problem of formation of a series of geometric\npatterns [4] by a network of oblivious mobile robots that communicate only\nthrough vision. So far, the problem has been studied in models where robots are\neither assumed to have distinct identifiers or to be completely anonymous. To\ngeneralize these results and to better understand how anonymity affects the\ncomputational power of robots, we study the problem in a new model, introduced\nrecently in [5], in which n robots may share up to 1 <= h <= n different\nidentifiers. We present necessary and sufficient conditions, relating\nsymmetricity and homonymy, that makes the problem solvable. We also show that\nin the case where h = n, making the identifiers of robots invisible does not\nlimit their computational power. This contradicts a result of [4]. To present\nour algorithms, we use a function that computes the Weber point for many\nregular and symmetric configurations. This function is interesting in its own\nright, since the problem of finding Weber points has been solved up to now for\nonly few other patterns.\n", "versions": [{"version": "v1", "created": "Sun, 29 May 2011 19:23:54 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Bouzid", "Zohir", "", "LIP6"], ["Lamani", "Anissa", "", "MIS"]]}, {"id": "1105.5900", "submitter": "Juli\\'an Jes\\'us Dom\\'inguez Romero", "authors": "Juli\\'an Dom\\'inguez and Enrique Alba", "title": "Ethane: A Heterogeneous Parallel Search Algorithm for Heterogeneous\n  Platforms", "comments": "Paper 6 for the First International Workshop of Distributed\n  Evolutionary computation in Informal Environments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present Ethane, a parallel search algorithm specifically\ndesigned for its execution on heterogeneous hardware environments. With Ethane\nwe propose an algorithm inspired in the structure of the chemical compound of\nthe same name, implementing a heterogeneous island model based in the structure\nof its chemical bonds. We also propose a schema for describing a family of\nparallel heterogeneous metaheuristics inspired by the structure of hydrocarbons\nin Nature, HydroCM (HydroCarbon inspired Metaheuristics), establishing a resem-\nblance between atoms and computers, and between chemical bonds and\ncommunication links. Our goal is to gracefully match computers of different\npower to algorithms of different behavior (GA and SA in this study), all them\ncollaborating to solve the same problem. The analysis will show that Ethane,\nthough simple, can solve search problems in a faster and more robust way than\nwell-known panmitic and distributed algorithms very popular in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 08:30:18 GMT"}, {"version": "v2", "created": "Tue, 31 May 2011 19:29:24 GMT"}], "update_date": "2011-06-01", "authors_parsed": [["Dom\u00ednguez", "Juli\u00e1n", ""], ["Alba", "Enrique", ""]]}, {"id": "1105.5986", "submitter": "Rena Bakhshi", "authors": "Rena Bakhshi and Daniela Gavidia and Wan Fokkink and Maarten van Steen", "title": "A Modeling Framework for Gossip-based Information Spread", "comments": "25 pages, including appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM cs.IT cs.PF math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an analytical framework for gossip protocols based on the pairwise\ninformation exchange between interacting nodes. This framework allows for\nstudying the impact of protocol parameters on the performance of the protocol.\nPreviously, gossip-based information dissemination protocols have been analyzed\nunder the assumption of perfect, lossless communication channels. We extend our\nframework for the analysis of networks with lossy channels. We show how the\npresence of message loss, coupled with specific topology configurations,impacts\nthe expected behavior of the protocol. We validate the obtained models against\nsimulations for two protocols.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 13:20:43 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Bakhshi", "Rena", ""], ["Gavidia", "Daniela", ""], ["Fokkink", "Wan", ""], ["van Steen", "Maarten", ""]]}, {"id": "1105.6040", "submitter": "Alaa Elnashar", "authors": "Alaa Ismail Elnashar", "title": "Parallel Performance of MPI Sorting Algorithms on Dual-Core Processor\n  Windows-Based Systems", "comments": null, "journal-ref": null, "doi": "10.5121/ijdps.2011.2301", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message Passing Interface (MPI) is widely used to implement parallel\nprograms. Although Windowsbased architectures provide the facilities of\nparallel execution and multi-threading, little attention has been focused on\nusing MPI on these platforms. In this paper we use the dual core Window-based\nplatform to study the effect of parallel processes number and also the number\nof cores on the performance of three MPI parallel implementations for some\nsorting algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 30 May 2011 16:53:36 GMT"}], "update_date": "2011-05-31", "authors_parsed": [["Elnashar", "Alaa Ismail", ""]]}, {"id": "1105.6151", "submitter": "Miguel Mosteiro", "authors": "Martin Farach-Colton, Antonio Fernandez Anta, Alessia Milani, Miguel\n  A. Mosteiro, and Shmuel Zaks", "title": "Opportunistic Information Dissemination in Mobile Ad-hoc Networks:\n  adaptiveness vs. obliviousness and randomization vs. determinism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper the problem of information dissemination in Mobile Ad-hoc\nNetworks (MANET) is studied. The problem is to disseminate a piece of\ninformation, initially held by a distinguished source node, to all nodes in a\nset defined by some predicate. We use a model of MANETs that is well suited for\ndynamic networks and opportunistic communication. In this model nodes are\nplaced in a plane, in which they can move with bounded speed, and communication\nbetween nodes occurs over a collision-prone single channel. In this setup\ninformed and uninformed nodes can be disconnected for some time (bounded by a\nparameter alpha), but eventually some uninformed node must become neighbor of\nan informed node and remain so for some time (bounded by a parameter beta). In\naddition, nodes can start at different times, and they can crash and recover.\nUnder the above framework, we show negative and positive results for different\ntypes of randomized protocols, and we put those results in perspective with\nrespect to previous deterministic results.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2011 02:44:06 GMT"}], "update_date": "2011-06-01", "authors_parsed": [["Farach-Colton", "Martin", ""], ["Anta", "Antonio Fernandez", ""], ["Milani", "Alessia", ""], ["Mosteiro", "Miguel A.", ""], ["Zaks", "Shmuel", ""]]}, {"id": "1105.6205", "submitter": "Juan Juli\\'an Merelo-Guerv\\'os Pr.", "authors": "Juan-J. Merelo, Maribel Garc\\'ia-Arenas, Antonio M. Mora, Pedro\n  Castillo, Gustavo Romero, JLJ Laredo", "title": "Cloud-based Evolutionary Algorithms: An algorithmic study", "comments": "Paper 4 for the First International Workshop of Distributed\n  Evolutionary computation in Informal Environments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  After a proof of concept using Dropbox(tm), a free storage and\nsynchronization service, showed that an evolutionary algorithm using several\ndissimilar computers connected via WiFi or Ethernet had a good scaling behavior\nin terms of evaluations per second, it remains to be proved whether that effect\nalso translates to the algorithmic performance of the algorithm. In this paper\nwe will check several different, and difficult, problems, and see what effects\nthe automatic load-balancing and asynchrony have on the speed of resolution of\nproblems.\n", "versions": [{"version": "v1", "created": "Tue, 31 May 2011 08:55:17 GMT"}], "update_date": "2011-06-01", "authors_parsed": [["Merelo", "Juan-J.", ""], ["Garc\u00eda-Arenas", "Maribel", ""], ["Mora", "Antonio M.", ""], ["Castillo", "Pedro", ""], ["Romero", "Gustavo", ""], ["Laredo", "JLJ", ""]]}]