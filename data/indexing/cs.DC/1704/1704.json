[{"id": "1704.00082", "submitter": "Yanhong Annie Liu", "authors": "Yanhong A. Liu, Saksham Chand, Scott D. Stoller", "title": "Moderately Complex Paxos Made Simple: High-Level Executable\n  Specification of Distributed Algorithms", "comments": null, "journal-ref": "PPDP 2019: Proceedings of the 21st International Symposium on\n  Principles and Practice of Declarative Programming. October 2019. Article No.\n  15. Pages 1-15. ACM Press", "doi": "10.1145/3354166.3354180", "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes the application of a high-level language and method in\ndeveloping simpler specifications of more complex variants of the Paxos\nalgorithm for distributed consensus. The specifications are for Multi-Paxos\nwith preemption, replicated state machine, and reconfiguration and optimized\nwith state reduction and failure detection. The language is DistAlgo. The key\nis to express complex control flows and synchronization conditions precisely at\na high level, using nondeterministic waits and message-history queries. We\nobtain complete executable specifications that are almost completely\ndeclarative---updating only a number for the protocol round besides the sets of\nmessages sent and received.\n  We show the following results: 1.English and pseudocode descriptions of\ndistributed algorithms can be captured completely and precisely at a high\nlevel, without adding, removing, or reformulating algorithm details to fit\nlower-level, more abstract, or less direct languages. 2.We created higher-level\ncontrol flows and synchronization conditions than all previous specifications,\nand obtained specifications that are much simpler and smaller, even matching or\nsmaller than abstract specifications that omit many algorithm details. 3.The\nsimpler specifications led us to easily discover useless replies, unnecessary\ndelays, and liveness violations (if messages can be lost) in previous published\nspecifications, by just following the simplified algorithm flows. 4.The\nresulting specifications can be executed directly, and we can express\noptimizations cleanly, yielding drastic performance improvement over naive\nexecution and facilitating a general method for merging processes. 5.We\nsystematically translated the resulting specifications into TLA+ and developed\nmachine-checked safety proofs, which also allowed us to detect and fix a subtle\nsafety violation in an earlier unpublished specification.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 23:22:40 GMT"}, {"version": "v2", "created": "Sun, 23 Jul 2017 13:13:00 GMT"}, {"version": "v3", "created": "Thu, 31 Jan 2019 14:17:37 GMT"}, {"version": "v4", "created": "Mon, 12 Aug 2019 06:12:40 GMT"}], "update_date": "2020-12-25", "authors_parsed": [["Liu", "Yanhong A.", ""], ["Chand", "Saksham", ""], ["Stoller", "Scott D.", ""]]}, {"id": "1704.00411", "submitter": "Vineet John", "authors": "Vineet John, Xia Liu", "title": "A Survey of Distributed Message Broker Queues", "comments": "8 pages, 10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper surveys the message brokers that are in vogue today for\ndistributed communication. Their primary goal is to facilitate the construction\nof decentralized topologies without single points of failure, enabling fault\ntolerance and high availability. These characteristics make them optimal for\nusage within distributed architectures. However, there are multiple protocols\nbuilt to achieve this, and it would be beneficial to have a empirical\ncomparison between their features and performance to determine their real-world\napplicability.\n  This paper focuses on two popular protocols (Kafka and AMQP) and explores the\ndivergence in their features as well as their performance under varied testing\nworkloads.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 03:24:28 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["John", "Vineet", ""], ["Liu", "Xia", ""]]}, {"id": "1704.00513", "submitter": "Julian Romera", "authors": "Julian Romera", "title": "Optimizing Communication by Compression for Multi-GPU Scalable\n  Breadth-First Searches", "comments": "Initial version, 105 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Breadth First Search (BFS) algorithm is the foundation and building block\nof many higher graph-based operations such as spanning trees, shortest paths\nand betweenness centrality. The importance of this algorithm increases each day\ndue to it is a key requirement for many data structures which are becoming\npopular nowadays. When the BFS algorithm is parallelized by distributing the\ngraph between several processors the interconnection network limits the\nperformance. Hence, improvements on this area may benefit the overall\nperformance of the algorithm.\n  This work presents an alternative compression scheme for communications in\ndistributed BFS processing. It focuses on BFS processors using General-Purpose\nGraphics Processing Units.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 10:22:32 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Romera", "Julian", ""]]}, {"id": "1704.00693", "submitter": "Istv\\'an Z Reguly", "authors": "Istvan Z Reguly, Gihan R Mudalige, Mike B Giles", "title": "Loop Tiling in Large-Scale Stencil Codes at Run-time with OPS", "comments": null, "journal-ref": null, "doi": "10.1109/TPDS.2017.2778161", "report-no": null, "categories": "cs.PF cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The key common bottleneck in most stencil codes is data movement, and prior\nresearch has shown that improving data locality through optimisations that\nschedule across loops do particularly well. However, in many large PDE\napplications it is not possible to apply such optimisations through compilers\nbecause there are many options, execution paths and data per grid point, many\ndependent on run-time parameters, and the code is distributed across different\ncompilation units. In this paper, we adapt the data locality improving\noptimisation called iteration space slicing for use in large OPS applications\nboth in shared-memory and distributed-memory systems, relying on run-time\nanalysis and delayed execution. We evaluate our approach on a number of\napplications, observing speedups of 2$\\times$ on the Cloverleaf 2D/3D proxy\napplication, which contain 83/141 loops respectively, $3.5\\times$ on the linear\nsolver TeaLeaf, and $1.7\\times$ on the compressible Navier-Stokes solver\nOpenSBLI. We demonstrate strong and weak scalability up to 4608 cores of\nCINECA's Marconi supercomputer. We also evaluate our algorithms on Intel's\nKnights Landing, demonstrating maintained throughput as the problem size grows\nbeyond 16GB, and we do scaling studies up to 8704 cores. The approach is\ngenerally applicable to any stencil DSL that provides per loop data access\ninformation.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 17:16:39 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 14:57:19 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Reguly", "Istvan Z", ""], ["Mudalige", "Gihan R", ""], ["Giles", "Mike B", ""]]}, {"id": "1704.00705", "submitter": "Christian Schulz", "authors": "Orlando Moreira, Merten Popp, Christian Schulz", "title": "Graph Partitioning with Acyclicity Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are widely used to model execution dependencies in applications. In\nparticular, the NP-complete problem of partitioning a graph under constraints\nreceives enormous attention by researchers because of its applicability in\nmultiprocessor scheduling. We identified the additional constraint of acyclic\ndependencies between blocks when mapping computer vision and imaging\napplications to a heterogeneous embedded multiprocessor. Existing algorithms\nand heuristics do not address this requirement and deliver results that are not\napplicable for our use-case. In this work, we show that this more constrained\nversion of the graph partitioning problem is NP-complete and present heuristics\nthat achieve a close approximation of the optimal solution found by an\nexhaustive search for small problem instances and much better scalability for\nlarger instances. In addition, we can show a positive impact on the schedule of\na real imaging application that improves communication volume and execution\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 17:45:10 GMT"}], "update_date": "2017-04-04", "authors_parsed": [["Moreira", "Orlando", ""], ["Popp", "Merten", ""], ["Schulz", "Christian", ""]]}, {"id": "1704.00830", "submitter": "Sikder Huq", "authors": "Sikder Huq and Sukumar Ghosh", "title": "Locally Self-Adjusting Skip Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a distributed self-adjusting algorithm for skip graphs that\nminimizes the average routing costs between arbitrary communication pairs by\nperforming topological adaptation to the communication pattern. Our algorithm\nis fully decentralized, conforms to the $\\mathcal{CONGEST}$ model (i.e. uses\n$O(\\log n)$ bit messages), and requires $O(\\log n)$ bits of memory for each\nnode, where $n$ is the total number of nodes. Upon each communication request,\nour algorithm first establishes communication by using the standard skip graph\nrouting, and then locally and partially reconstructs the skip graph topology to\nperform topological adaptation. We propose a computational model for such\nalgorithms, as well as a yardstick (working set property) to evaluate them. Our\nworking set property can also be used to evaluate self-adjusting algorithms for\nother graph classes where multiple tree-like subgraphs overlap (e.g. hypercube\nnetworks). We derive a lower bound of the amortized routing cost for any\nalgorithm that follows our model and serves an unknown sequence of\ncommunication requests. We show that the routing cost of our algorithm is at\nmost a constant factor more than the amortized routing cost of any algorithm\nconforming to our computational model. We also show that the expected\ntransformation cost for our algorithm is at most a logarithmic factor more than\nthe amortized routing cost of any algorithm conforming to our computational\nmodel.\n", "versions": [{"version": "v1", "created": "Mon, 3 Apr 2017 22:53:58 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Huq", "Sikder", ""], ["Ghosh", "Sukumar", ""]]}, {"id": "1704.00845", "submitter": "Sung-Han Lin", "authors": "Ranjan Pal, Sung-Han Lin, Aditya Ahujay, Leana Golubchik", "title": "The Cloudlet Bazaar Dynamic Markets for the Small Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent emergence of the small cloud (SC), both in concept and in\npractice, has been driven mainly by issues related to service cost and\ncomplexity of commercial cloud providers (e.g., Amazon) employing massive data\ncenters. However, the resource inelasticity problem faced by the SCs due to\ntheir relatively scarce resources (e.g., virtual machines) might lead to a\npotential degradation of customer QoS and loss of revenue. A proposed solution\nto this problem recommends the sharing of resources between competing SCs to\nalleviate the resource inelasticity issues that might arise [1]. Based on this\nidea, a recent effort ([2]) proposed SC-Share, a performance-driven static\nmarket model for competitive small cloud environments that results in an\nefficient market equilibrium jointly optimizing customer QoS satisfaction and\nSC revenue generation. However, an important non-obvious question still remains\nto be answered, without which SC sharing markets may not be guaranteed to\nsustain in the long-run - is it still possible to achieve a stable market\nefficient state when the supply of SC resources is dynamic in nature and there\nis a variation of customer demand over time? In this paper, we address the\nproblem of efficient market design for SC resource sharing in dynamic\nenvironments. We answer our previous question in the affirmative through the\nuse of Arrow and Hurwicz's disequilibrium process [3], [4] in economics, and\nthe gradient play technique in game theory that allows us to iteratively\nconverge upon efficient and stable market equilibria\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 01:08:29 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 07:15:23 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Pal", "Ranjan", ""], ["Lin", "Sung-Han", ""], ["Ahujay", "Aditya", ""], ["Golubchik", "Leana", ""]]}, {"id": "1704.00874", "submitter": "Abbas Mehrabian", "authors": "Omer Angel, Abbas Mehrabian and Yuval Peres", "title": "The string of diamonds is nearly tight for rumour spreading", "comments": "Will be presented at RANDOM'2017 conference. 14 pages, Theorem 2.5\n  added in this version", "journal-ref": "Combinator. Probab. Comp. 29 (2020) 190-199", "doi": "10.1017/S0963548319000385", "report-no": null, "categories": "math.PR cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a rumour spreading protocol, the spread time is defined as the first time\nthat everyone learns the rumour. We compare the synchronous push&pull rumour\nspreading protocol with its asynchronous variant, and show that for any\n$n$-vertex graph and any starting vertex, the ratio between their expected\nspread times is bounded by $O \\left({n}^{1/3}{\\log^{2/3} n}\\right)$. This\nimproves the $O(\\sqrt n)$ upper bound of Giakkoupis, Nazari, and Woelfel (in\nProceedings of ACM Symposium on Principles of Distributed Computing, 2016). Our\nbound is tight up to a factor of $O(\\log n)$, as illustrated by the string of\ndiamonds graph. We also show that if for a pair $\\alpha,\\beta$ of real numbers,\nthere exists infinitely many graphs for which the two spread times are\n$n^{\\alpha}$ and $n^{\\beta}$ in expectation, then $0\\leq\\alpha \\leq 1$ and\n$\\alpha \\leq \\beta \\leq \\frac13 + \\frac23 \\alpha$; and we show each such pair\n$\\alpha,\\beta$ is achievable.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 05:04:01 GMT"}, {"version": "v2", "created": "Tue, 18 Jul 2017 20:43:07 GMT"}], "update_date": "2020-04-01", "authors_parsed": [["Angel", "Omer", ""], ["Mehrabian", "Abbas", ""], ["Peres", "Yuval", ""]]}, {"id": "1704.00878", "submitter": "Shixiang Wan", "authors": "Shixiang Wan, Quan Zou", "title": "HAlign-II: efficient ultra-large multiple sequence alignment and\n  phylogenetic tree reconstruction with distributed and parallel computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple sequence alignment (MSA) plays a key role in biological sequence\nanalyses, especially in phylogenetic tree construction. Extreme increase in\nnext-generation sequencing results in shortage of efficient ultra-large\nbiological sequence alignment approaches for coping with different sequence\ntypes. Distributed and parallel computing represents a crucial technique for\naccelerating ultra-large sequence analyses. Based on HAlign and Spark\ndistributed computing system, we implement a highly cost-efficient and\ntime-efficient HAlign-II tool to address ultra-large multiple biological\nsequence alignment and phylogenetic tree construction. After comparing with\nmost available state-of-the-art methods, our experimental results indicate the\nfollowing: 1) HAlign-II can efficiently carry out MSA and construct\nphylogenetic trees with ultra-large biological sequences; 2) HAlign-II shows\nextremely high memory efficiency and scales well with increases in computing\nresource; 3) HAlign-II provides a user-friendly web server based on our\ndistributed computing infrastructure. HAlign-II with open-source codes and\ndatasets was established at http://lab.malab.cn/soft/halign.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 05:49:04 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Wan", "Shixiang", ""], ["Zou", "Quan", ""]]}, {"id": "1704.00978", "submitter": "Matteo Turilli", "authors": "Danila Oleynik, Sergey Panitkin, Matteo Turilli, Alessio Angius,\n  Kaushik De, Alexei Klimentov, Sarp H. Oral, Jack C. Wells, Shantenu Jha", "title": "High-Throughput Computing on High-Performance Platforms: A Case Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computing systems used by LHC experiments has historically consisted of\nthe federation of hundreds to thousands of distributed resources, ranging from\nsmall to mid-size resource. In spite of the impressive scale of the existing\ndistributed computing solutions, the federation of small to mid-size resources\nwill be insufficient to meet projected future demands. This paper is a case\nstudy of how the ATLAS experiment has embraced Titan---a DOE leadership\nfacility in conjunction with traditional distributed high- throughput computing\nto reach sustained production scales of approximately 52M core-hours a years.\nThe three main contributions of this paper are: (i) a critical evaluation of\ndesign and operational considerations to support the sustained, scalable and\nproduction usage of Titan; (ii) a preliminary characterization of a next\ngeneration executor for PanDA to support new workloads and advanced execution\nmodes; and (iii) early lessons for how current and future experimental and\nobservational systems can be integrated with production supercomputers and\nother platforms in a general and extensible manner.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 12:27:49 GMT"}, {"version": "v2", "created": "Sat, 28 Oct 2017 03:05:37 GMT"}], "update_date": "2017-10-31", "authors_parsed": [["Oleynik", "Danila", ""], ["Panitkin", "Sergey", ""], ["Turilli", "Matteo", ""], ["Angius", "Alessio", ""], ["De", "Kaushik", ""], ["Klimentov", "Alexei", ""], ["Oral", "Sarp H.", ""], ["Wells", "Jack C.", ""], ["Jha", "Shantenu", ""]]}, {"id": "1704.01127", "submitter": "Thomas H\\\"aner", "authors": "Thomas H\\\"aner, Damian S. Steiger", "title": "0.5 Petabyte Simulation of a 45-Qubit Quantum Circuit", "comments": null, "journal-ref": "Proceedings of the International Conference for High Performance\n  Computing, Networking, Storage and Analysis. SC 2017. Article No. 33", "doi": "10.1145/3126908.3126947", "report-no": null, "categories": "quant-ph cs.DC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-term quantum computers will soon reach sizes that are challenging to\ndirectly simulate, even when employing the most powerful supercomputers. Yet,\nthe ability to simulate these early devices using classical computers is\ncrucial for calibration, validation, and benchmarking. In order to make use of\nthe full potential of systems featuring multi- and many-core processors, we use\nautomatic code generation and optimization of compute kernels, which also\nenables performance portability. We apply a scheduling algorithm to quantum\nsupremacy circuits in order to reduce the required communication and simulate a\n45-qubit circuit on the Cori II supercomputer using 8,192 nodes and 0.5\npetabytes of memory. To our knowledge, this constitutes the largest quantum\ncircuit simulation to this date. Our highly-tuned kernels in combination with\nthe reduced communication requirements allow an improvement in time-to-solution\nover state-of-the-art simulations by more than an order of magnitude at every\nscale.\n", "versions": [{"version": "v1", "created": "Tue, 4 Apr 2017 18:00:08 GMT"}, {"version": "v2", "created": "Mon, 18 Sep 2017 11:24:06 GMT"}], "update_date": "2017-11-21", "authors_parsed": [["H\u00e4ner", "Thomas", ""], ["Steiger", "Damian S.", ""]]}, {"id": "1704.01144", "submitter": "Jean Marie Couteyen Carpaye", "authors": "Jean Marie Couteyen Carpaye, Jean Roman, Pierre Brenner", "title": "Design and Analysis of a Task-based Parallelization over a Runtime\n  System of an Explicit Finite-Volume CFD Code with Adaptive Time Stepping", "comments": "Accepted manuscript of a paper in Journal of Computational Science", "journal-ref": null, "doi": "10.1016/j.jocs.2017.03.008", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FLUSEPA (Registered trademark in France No. 134009261) is an advanced\nsimulation tool which performs a large panel of aerodynamic studies. It is the\nunstructured finite-volume solver developed by Airbus Safran Launchers company\nto calculate compressible, multidimensional, unsteady, viscous and reactive\nflows around bodies in relative motion. The time integration in FLUSEPA is done\nusing an explicit temporal adaptive method. The current production version of\nthe code is based on MPI and OpenMP. This implementation leads to important\nsynchronizations that must be reduced. To tackle this problem, we present the\nstudy of a task-based parallelization of the aerodynamic solver of FLUSEPA\nusing the runtime system StarPU and combining up to three levels of\nparallelism. We validate our solution by the simulation (using a finite-volume\nmesh with 80 million cells) of a take-off blast wave propagation for Ariane 5\nlauncher.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 14:34:43 GMT"}, {"version": "v2", "created": "Thu, 6 Apr 2017 17:17:04 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Carpaye", "Jean Marie Couteyen", ""], ["Roman", "Jean", ""], ["Brenner", "Pierre", ""]]}, {"id": "1704.01676", "submitter": "Aman Chadha Mr.", "authors": "Anthony Gregerson, Aman Chadha, Katherine Morrow", "title": "Multi-Personality Partitioning for Heterogeneous Systems", "comments": "International Conference on Field-Programmable Technology (ICFPT),\n  Kyoto Research Park, Japan, Dec. 9-11, 2013. hardware design; hardware\n  architecture; cad; computer aided design; IC design; integrated circuit\n  design; partitioning algorithms; field programmable gate arrays; benchmark\n  testing; heuristic algorithms; resource management; dynamic scheduling;\n  digital signal processing", "journal-ref": null, "doi": "10.1109/FPT.2013.6718375", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Design flows use graph partitioning both as a precursor to place and route\nfor single devices, and to divide netlists or task graphs among multiple\ndevices. Partitioners have accommodated FPGA heterogeneity via multi-resource\nconstraints, but have not yet exploited the corresponding ability to implement\nsome computations in multiple ways (e.g., LUTs vs. DSP blocks), which could\nenable a superior solution. This paper introduces multi-personality graph\npartitioning, which incorporates aspects of resource mapping into partitioning.\nWe present a modified multi-level KLFM partitioning algorithm that also\nperforms heterogeneous resource mapping for nodes with multiple potential\nimplementations (multiple personalities). We evaluate several variants of our\nmulti-personality FPGA circuit partitioner using 21 circuits and benchmark\ngraphs, and show that dynamic resource mapping improves cut size on average by\n27% over static mapping for these circuits. We further show that it improves\ndeviation from target resource utilizations by 50% over post-partitioning\nresource mapping.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 01:04:24 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Gregerson", "Anthony", ""], ["Chadha", "Aman", ""], ["Morrow", "Katherine", ""]]}, {"id": "1704.01927", "submitter": "Barun Gorain", "authors": "Barun Gorain and Andrzej Pelc", "title": "Short Labeling Schemes for Topology Recognition in Wireless Tree\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of topology recognition in wireless (radio) networks\nmodeled as undirected graphs. Topology recognition is a fundamental task in\nwhich every node of the network has to output a map of the underlying graph\ni.e., an isomorphic copy of it, and situate itself in this map. In wireless\nnetworks, nodes communicate in synchronous rounds. In each round a node can\neither transmit a message to all its neighbors, or stay silent and listen. At\nthe receiving end, a node $v$ hears a message from a neighbor $w$ in a given\nround, if $v$ listens in this round, and if $w$ is its only neighbor that\ntransmits in this round. Nodes have labels which are (not necessarily\ndifferent) binary strings. The length of a labeling scheme is the largest\nlength of a label. We concentrate on wireless networks modeled by trees, and we\ninvestigate two problems.\n  \\begin{itemize} \\item What is the shortest labeling scheme that permits\ntopology recognition in all wireless tree networks of diameter $D$ and maximum\ndegree $\\Delta$?\n  \\item What is the fastest topology recognition algorithm working for all\nwireless tree networks of diameter $D$ and maximum degree $\\Delta$, using such\na short labeling scheme? \\end{itemize}\n  We are interested in deterministic topology recognition algorithms. For the\nfirst problem, we show that the minimum length of a labeling scheme allowing\ntopology recognition in all trees of maximum degree $\\Delta \\geq 3$ is\n$\\Theta(\\log\\log \\Delta)$. For such short schemes, used by an algorithm working\nfor the class of trees of diameter $D\\geq 4$ and maximum degree $\\Delta \\geq\n3$, we show almost matching bounds on the time of topology recognition: an\nupper bound $O(D\\Delta)$, and a lower bound $\\Omega(D\\Delta^{\\epsilon})$, for\nany constant $\\epsilon<1$.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 16:47:59 GMT"}], "update_date": "2017-04-07", "authors_parsed": [["Gorain", "Barun", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1704.02003", "submitter": "Samuel Pollard", "authors": "Samuel Pollard and Boyana Norris", "title": "A Comparison of Parallel Graph Processing Implementations", "comments": "10 pages, 10 figures, Submitted to EuroPar 2017 and rejected. Revised\n  and submitted to IEEE Cluster 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly growing number of large network analysis problems has led to the\nemergence of many parallel and distributed graph processing systems---one\nsurvey in 2014 identified over 80. Since then, the landscape has evolved; some\npackages have become inactive while more are being developed. Determining the\nbest approach for a given problem is infeasible for most developers. To enable\neasy, rigorous, and repeatable comparison of the capabilities of such systems,\nwe present an approach and associated software for analyzing the performance\nand scalability of parallel, open-source graph libraries. We demonstrate our\napproach on five graph processing packages: GraphMat, the Graph500, the Graph\nAlgorithm Platform Benchmark Suite, GraphBIG, and PowerGraph using synthetic\nand real-world datasets. We examine previously overlooked aspects of parallel\ngraph processing performance such as phases of execution and energy usage for\nthree algorithms: breadth first search, single source shortest paths, and\nPageRank and compare our results to Graphalytics.\n", "versions": [{"version": "v1", "created": "Thu, 6 Apr 2017 19:48:37 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 01:44:23 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Pollard", "Samuel", ""], ["Norris", "Boyana", ""]]}, {"id": "1704.02061", "submitter": "Joseph Tassarotti", "authors": "Joseph Tassarotti", "title": "Probabilistic Recurrence Relations for Work and Span of Parallel\n  Algorithms", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present a method for obtaining tail-bounds for random\nvariables satisfying certain probabilistic recurrences that arise in the\nanalysis of randomized parallel divide and conquer algorithms. In such\nalgorithms, some computation is initially done to process an input x, which is\nthen randomly split into subproblems $h_1(x), ..., h_n(x)$, and the algorithm\nproceeds recursively in parallel on each subproblem. The total work on input x,\nW(x), then satisfies a probabilistic recurrence of the form $W(x) = a(x) +\n\\sum_{i=1}^n W (h_i(x))$, and the span (the longest chain of sequential\ndependencies), satisfies $S(x) = b(x) + \\max_{i=1}^n S(h_i(x))$, where a(x) and\nb(x) are the work and span to split x and combine the results of the recursive\ncalls.\n  Karp has previously presented methods for obtaining tail-bounds in the case\nwhen n = 1, and under certain stronger assumptions for the work-recurrence when\nn > 1, but left open the question of the span-recurrence. We first show how to\nextend his technique to handle the span-recurrence. We then show that in some\ncases, the work-recurrence can be bounded under simpler assumptions than Karp's\nby transforming it into a related span-recurrence and applying our first\nresult. We demonstrate our results by deriving tail bounds for the work and\nspan of quicksort and the height of a randomly generated binary search tree.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 01:00:36 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Tassarotti", "Joseph", ""]]}, {"id": "1704.02259", "submitter": "Mireya Paredes Ms.", "authors": "Mireya Paredes, Graham Riley and Mikel Lujan", "title": "Vectorization of Hybrid Breadth First Search on the Intel Xeon Phi", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Breadth-First Search (BFS) algorithm is an important building block for\ngraph analysis of large datasets. The BFS parallelisation has been shown to be\nchallenging because of its inherent characteristics, including irregular memory\naccess patterns, data dependencies and workload imbalance, that limit its\nscalability. We investigate the optimisation and vectorisation of the hybrid\nBFS (a combination of top-down and bottom-up approaches for BFS) on the Xeon\nPhi, which has advanced vector processing capabilities. The results show that\nour new implementation improves by 33\\%, for a one million vertices graph,\ncompared to the state-of-the-art.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 15:12:05 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 03:59:33 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Paredes", "Mireya", ""], ["Riley", "Graham", ""], ["Lujan", "Mikel", ""]]}, {"id": "1704.02272", "submitter": "Xavier Bellekens", "authors": "Xavier Bellekens and Christos Tachtatzis and Robert Atkinson and Craig\n  Renfrew and Tony Kirkham", "title": "A Highly-Efficient Memory-Compression Scheme for GPU-Accelerated\n  Intrusion Detection Systems", "comments": "Published in The 7th International Conference of Security of\n  Information and Networks, SIN 2014, Glasgow, UK, September, 2014", "journal-ref": null, "doi": "10.1145/2659651.2659723", "report-no": null, "categories": "cs.DC cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pattern Matching is a computationally intensive task used in many research\nfields and real world applications. Due to the ever-growing volume of data to\nbe processed, and increasing link speeds, the number of patterns to be matched\nhas risen significantly. In this paper we explore the parallel capabilities of\nmodern General Purpose Graphics Processing Units (GPGPU) applications for high\nspeed pattern matching. A highly compressed failure-less Aho-Corasick algorithm\nis presented for Intrusion Detection Systems on off-the-shelf hardware. This\napproach maximises the bandwidth for data transfers between the host and the\nGraphics Processing Unit (GPU). Experiments are performed on multiple alphabet\nsizes, demonstrating the capabilities of the library to be used in different\nresearch fields, while sustaining an adequate throughput for intrusion\ndetection systems or DNA sequencing. The work also explores the performance\nimpact of adequate prefix matching for alphabet sizes and varying pattern\nnumbers achieving speeds up to 8Gbps and low memory consumption for intrusion\ndetection systems.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 15:57:37 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Bellekens", "Xavier", ""], ["Tachtatzis", "Christos", ""], ["Atkinson", "Robert", ""], ["Renfrew", "Craig", ""], ["Kirkham", "Tony", ""]]}, {"id": "1704.02278", "submitter": "Xavier Bellekens", "authors": "Xavier Bellekens and Christos Tachtatzis and Robert Atkinson and Craig\n  Renfrew and Tony Kirkham", "title": "GLoP: Enabling Massively Parallel Incident Response Through GPU Log\n  Processing", "comments": "Published in The 7th International Conference of Security of\n  Information and Networks, SIN 2014, Glasgow, UK, September, 2014", "journal-ref": null, "doi": "10.1145/2659651.2659700", "report-no": null, "categories": "cs.DC cs.CR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Large industrial systems that combine services and applications, have become\ntargets for cyber criminals and are challenging from the security, monitoring\nand auditing perspectives. Security log analysis is a key step for uncovering\nanomalies, detecting intrusion, and enabling incident response. The constant\nincrease of link speeds, threats and users, produce large volumes of log data\nand become increasingly difficult to analyse on a Central Processing Unit\n(CPU). This paper presents a massively parallel Graphics Processing Unit (GPU)\nLOg Processing (GLoP) library and can also be used for Deep Packet Inspection\n(DPI), using a prefix matching technique, harvesting the full power of\noff-the-shelf technologies. GLoP implements two different algorithm using\ndifferent GPU memory and is compared against CPU counterpart implementations.\nThe library can be used for processing nodes with single or multiple GPUs as\nwell as GPU cloud farms. The results show throughput of 20Gbps and demonstrate\nthat modern GPUs can be utilised to increase the operational speed of large\nscale log processing scenarios, saving precious time before and after an\nintrusion has occurred.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 16:21:26 GMT"}], "update_date": "2017-04-10", "authors_parsed": [["Bellekens", "Xavier", ""], ["Tachtatzis", "Christos", ""], ["Atkinson", "Robert", ""], ["Renfrew", "Craig", ""], ["Kirkham", "Tony", ""]]}, {"id": "1704.02341", "submitter": "Ehsan Totoni", "authors": "Ehsan Totoni, Wajih Ul Hassan, Todd A. Anderson, Tatiana Shpeisman", "title": "HiFrames: High Performance Data Frames in a Scripting Language", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data frames in scripting languages are essential abstractions for processing\nstructured data. However, existing data frame solutions are either not\ndistributed (e.g., Pandas in Python) and therefore have limited scalability, or\nthey are not tightly integrated with array computations (e.g., Spark SQL). This\npaper proposes a novel compiler-based approach where we integrate data frames\ninto the High Performance Analytics Toolkit (HPAT) to build HiFrames. It\nprovides expressive and flexible data frame APIs which are tightly integrated\nwith array operations. HiFrames then automatically parallelizes and compiles\nrelational operations along with other array computations in end-to-end data\nanalytics programs, and generates efficient MPI/C++ code. We demonstrate that\nHiFrames is significantly faster than alternatives such as Spark SQL on\nclusters, without forcing the programmer to switch to embedded SQL for part of\nthe program. HiFrames is 3.6x to 70x faster than Spark SQL for basic relational\noperations, and can be up to 20,000x faster for advanced analytics operations,\nsuch as weighted moving averages (WMA), that the map-reduce paradigm cannot\nhandle effectively. HiFrames is also 5x faster than Spark SQL for TPCx-BB Q26\non 64 nodes of Cori supercomputer.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 18:33:06 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Totoni", "Ehsan", ""], ["Hassan", "Wajih Ul", ""], ["Anderson", "Todd A.", ""], ["Shpeisman", "Tatiana", ""]]}, {"id": "1704.02380", "submitter": "Oren Louidor", "authors": "Lihi Cohen, Yuval Emek, Oren Louidor, Jara Uitto", "title": "Exploring an Infinite Space with Finite Memory Scouts", "comments": "Added (forgotten) acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a small number of scouts exploring the infinite $d$-dimensional grid\nwith the aim of hitting a hidden target point. Each scout is controlled by a\nprobabilistic finite automaton that determines its movement (to a neighboring\ngrid point) based on its current state. The scouts, that operate under a fully\nsynchronous schedule, communicate with each other (in a way that affects their\nrespective states) when they share the same grid point and operate\nindependently otherwise. Our main research question is: How many scouts are\nrequired to guarantee that the target admits a finite mean hitting time?\nRecently, it was shown that $d + 1$ is an upper bound on the answer to this\nquestion for any dimension $d \\geq 1$ and the main contribution of this paper\ncomes in the form of proving that this bound is tight for $d \\in \\{ 1, 2 \\}$.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 21:43:30 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 11:10:12 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Cohen", "Lihi", ""], ["Emek", "Yuval", ""], ["Louidor", "Oren", ""], ["Uitto", "Jara", ""]]}, {"id": "1704.02397", "submitter": "Ling Ren", "authors": "Ittai Abraham, Srinivas Devadas, Danny Dolev, Kartik Nayak and Ling\n  Ren", "title": "Efficient Synchronous Byzantine Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new protocols for Byzantine state machine replication and\nByzantine agreement in the synchronous and authenticated setting. The\ncelebrated PBFT state machine replication protocol tolerates $f$ Byzantine\nfaults in an asynchronous setting using $3f+1$ replicas, and has since been\nstudied or deployed by numerous works. In this work, we improve the Byzantine\nfault tolerance threshold to $n=2f+1$ by utilizing a relaxed synchrony\nassumption. We present a synchronous state machine replication protocol that\ncommits a decision every 3 rounds in the common case. The key challenge is to\nensure quorum intersection at one honest replica. Our solution is to rely on\nthe synchrony assumption to form a post-commit quorum of size $2f+1$, which\nintersects at $f+1$ replicas with any pre-commit quorums of size $f+1$. Our\nprotocol also solves synchronous authenticated Byzantine agreement in expected\n8 rounds. The best previous solution (Katz and Koo, 2006) requires expected 24\nrounds. Our protocols may be applied to build Byzantine fault tolerant systems\nor improve cryptographic protocols such as cryptocurrencies when synchrony can\nbe assumed.\n", "versions": [{"version": "v1", "created": "Fri, 7 Apr 2017 23:00:22 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 18:28:11 GMT"}], "update_date": "2017-09-14", "authors_parsed": [["Abraham", "Ittai", ""], ["Devadas", "Srinivas", ""], ["Dolev", "Danny", ""], ["Nayak", "Kartik", ""], ["Ren", "Ling", ""]]}, {"id": "1704.02418", "submitter": "EPTCS", "authors": "Vasco T. Vasconcelos (University of Lisbon), Philipp Haller (KTH Royal\n  Institute of Technology)", "title": "Proceedings Tenth Workshop on Programming Language Approaches to\n  Concurrency- and Communication-cEntric Software", "comments": null, "journal-ref": "EPTCS 246, 2017", "doi": "10.4204/EPTCS.246", "report-no": null, "categories": "cs.PL cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PLACES 2017 (full title: Programming Language Approaches to Concurrency- and\nCommunication-cEntric Software) is the tenth edition of the PLACES workshop\nseries. After the first PLACES, which was affiliated to DisCoTec in 2008, the\nworkshop has been part of ETAPS every year since 2009 and is now an established\npart of the ETAPS satellite events. PLACES 2017 was held on 29th April in\nUppsala, Sweden. The workshop series was started in order to promote the\napplication of novel programming language ideas to the increasingly important\nproblem of developing software for systems in which concurrency and\ncommunication are intrinsic aspects. This includes software for both multi-core\nsystems and large-scale distributed and/or service-oriented systems. The scope\nof PLACES includes new programming language features, whole new programming\nlanguage designs, new type systems, new semantic approaches, new program\nanalysis techniques, and new implementation mechanisms. This volume consists of\nthe papers accepted for presentation at the workshop.\n", "versions": [{"version": "v1", "created": "Sat, 8 Apr 2017 01:32:06 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Vasconcelos", "Vasco T.", "", "University of Lisbon"], ["Haller", "Philipp", "", "KTH Royal\n  Institute of Technology"]]}, {"id": "1704.02427", "submitter": "Giuseppe Antonio Di Luna", "authors": "Giuseppe Antonio Di Luna, Paola Flocchini, Linda Pagli, Giuseppe\n  Prencipe, Nicola Santoro, Giovanni Viglietta", "title": "Gathering in Dynamic Rings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The gathering problem requires a set of mobile agents, arbitrarily positioned\nat different nodes of a network to group within finite time at the same\nlocation, not fixed in advanced.\n  The extensive existing literature on this problem shares the same fundamental\nassumption: the topological structure does not change during the rendezvous or\nthe gathering; this is true also for those investigations that consider faulty\nnodes. In other words, they only consider static graphs. In this paper we start\nthe investigation of gathering in dynamic graphs, that is networks where the\ntopology changes continuously and at unpredictable locations.\n  We study the feasibility of gathering mobile agents, identical and without\nexplicit communication capabilities, in a dynamic ring of anonymous nodes; the\nclass of dynamics we consider is the classic 1-interval-connectivity.\n  We focus on the impact that factors such as chirality (i.e., a common sense\nof orientation) and cross detection (i.e., the ability to detect, when\ntraversing an edge, whether some agent is traversing it in the other\ndirection), have on the solvability of the problem. We provide a complete\ncharacterization of the classes of initial configurations from which the\ngathering problem is solvable in presence and in absence of cross detection and\nof chirality. The feasibility results of the characterization are all\nconstructive: we provide distributed algorithms that allow the agents to\ngather. In particular, the protocols for gathering with cross detection are\ntime optimal. We also show that cross detection is a powerful computational\nelement.\n  We prove that, without chirality, knowledge of the ring size is strictly more\npowerful than knowledge of the number of agents; on the other hand, with\nchirality, knowledge of n can be substituted by knowledge of k, yielding the\nsame classes of feasible initial configurations.\n", "versions": [{"version": "v1", "created": "Sat, 8 Apr 2017 02:42:35 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 14:44:38 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Di Luna", "Giuseppe Antonio", ""], ["Flocchini", "Paola", ""], ["Pagli", "Linda", ""], ["Prencipe", "Giuseppe", ""], ["Santoro", "Nicola", ""], ["Viglietta", "Giovanni", ""]]}, {"id": "1704.02436", "submitter": "Barun Gorain", "authors": "Barun Gorain and Partha Sarathi Mandal", "title": "Approximation Algorithms for Barrier Sweep Coverage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Time-varying coverage, namely sweep coverage is a recent development in the\narea of wireless sensor networks, where a small number of mobile sensors sweep\nor monitor comparatively large number of locations periodically. In this\narticle we study barrier sweep coverage with mobile sensors where the barrier\nis considered as a finite length continuous curve on a plane. The coverage at\nevery point on the curve is time-variant. We propose an optimal solution for\nsweep coverage of a finite length continuous curve. Usually energy source of a\nmobile sensor is battery with limited power, so energy restricted sweep\ncoverage is a challenging problem for long running applications. We propose an\nenergy restricted sweep coverage problem where every mobile sensors must visit\nan energy source frequently to recharge or replace its battery. We propose a\n$\\frac{13}{3}$-approximation algorithm for this problem. The proposed algorithm\nfor multiple curves achieves the best possible approximation factor 2 for a\nspecial case. We propose a 5-approximation algorithm for the general problem.\nAs an application of the barrier sweep coverage problem for a set of line\nsegments, we formulate a data gathering problem. In this problem a set of\nmobile sensors is arbitrarily monitoring the line segments one for each. A set\nof data mules periodically collects the monitoring data from the set of mobile\nsensors. We prove that finding the minimum number of data mules to collect data\nperiodically from every mobile sensor is NP-hard and propose a 3-approximation\nalgorithm to solve it.\n", "versions": [{"version": "v1", "created": "Sat, 8 Apr 2017 04:01:33 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Gorain", "Barun", ""], ["Mandal", "Partha Sarathi", ""]]}, {"id": "1704.02632", "submitter": "Ripon Patgiri", "authors": "Rajdeep Das, Rohit Pratap Singh, Ripon Patgiri", "title": "MapReduce Scheduler: A 360-degree view", "comments": "Journal Article", "journal-ref": "International Journal of Current Engineering and Scientific\n  Research, volume 3(11), pages 88-100, 2016", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Undoubtedly, the MapReduce is the most powerful programming paradigm in\ndistributed computing. The enhancement of the MapReduce is essential and it can\nlead the computing faster. Therefore, here are many scheduling algorithms to\ndiscuss based on their characteristics. Moreover, there are many shortcoming to\ndiscover in this field. In this article, we present the state-of-the-art\nscheduling algorithm to enhance the understanding of the algorithms. The\nalgorithms are presented systematically such that there can be many future\npossibilities in scheduling algorithm through this article. In this paper, we\nprovide in-depth insight on the MapReduce scheduling algorithm. In addition, we\ndiscuss various issues of MapReduce scheduler developed for large-scale\ncomputing as well as heterogeneous environment.\n", "versions": [{"version": "v1", "created": "Sun, 9 Apr 2017 17:26:41 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Das", "Rajdeep", ""], ["Singh", "Rohit Pratap", ""], ["Patgiri", "Ripon", ""]]}, {"id": "1704.02658", "submitter": "Stanislav Minsker", "authors": "Stanislav Minsker and Nate Strawn", "title": "Distributed Statistical Estimation and Rates of Convergence in Normal\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DC stat.ML stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a class of new algorithms for distributed statistical\nestimation that exploit divide-and-conquer approach. We show that one of the\nkey benefits of the divide-and-conquer strategy is robustness, an important\ncharacteristic for large distributed systems. We establish connections between\nperformance of these distributed algorithms and the rates of convergence in\nnormal approximation, and prove non-asymptotic deviations guarantees, as well\nas limit theorems, for the resulting estimators. Our techniques are illustrated\nthrough several examples: in particular, we obtain new results for the\nmedian-of-means estimator, as well as provide performance guarantees for\ndistributed maximum likelihood estimation.\n", "versions": [{"version": "v1", "created": "Sun, 9 Apr 2017 20:43:55 GMT"}, {"version": "v2", "created": "Thu, 20 Apr 2017 21:50:04 GMT"}, {"version": "v3", "created": "Mon, 27 Aug 2018 22:25:54 GMT"}], "update_date": "2018-08-29", "authors_parsed": [["Minsker", "Stanislav", ""], ["Strawn", "Nate", ""]]}, {"id": "1704.02683", "submitter": "Muhammad Bilal", "authors": "Muhammad Bilal and Shin-Gak Kang", "title": "A Secure Key Agreement Protocol for Dynamic Group", "comments": "This article is accepted for the publication in Cluster Computing-The\n  Journal of Networks, Software Tools and Applications. Print ISSN 1386-7857,\n  Online ISSN 1573-7543", "journal-ref": "Cluster Computing, Volume 20, Issue 3, September 2017, Pages\n  2779-2792", "doi": "10.1007/s10586-017-0853-0", "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To accomplish secure group communication, it is essential to share a unique\ncryptographic key among group members. The underlying challenges to group key\nagreement are scalability, efficiency, and security. In a dynamic group\nenvironment, the rekeying process is more frequent; therefore, it is more\ncrucial to design an efficient group key agreement protocol. Moreover, with the\nemergence of various group-based services, it is becoming common for several\nmulticast groups to coexist in the same network. These multicast groups may\nhave several shared users; a join or leave request by a single user can trigger\nregeneration of multiple group keys. Under the given circumstances the rekeying\nprocess becomes a challenging task. In this work, we propose a novel\nmethodology for group key agreement which exploits the state vectors of group\nmembers. The state vector is a set of randomly generated nonce instances which\ndetermine the logical link between group members and which empowers the group\nmember to generate multiple cryptographic keys independently. Using local\nknowledge of a secret nonce, each member can generate and share a large number\nof secure keys, indicating that SGRS inherently provides a considerable amount\nof secure subgroup multicast communication using subgroup multicasting keys\nderived from local state vectors. The resulting protocol is secure and\nefficient in terms of both communication and computation.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 01:35:44 GMT"}], "update_date": "2019-07-29", "authors_parsed": [["Bilal", "Muhammad", ""], ["Kang", "Shin-Gak", ""]]}, {"id": "1704.02696", "submitter": "Shaoshan Liu", "authors": "Shaoshan Liu, Jie Tang, Chao Wang, Quan Wang, Jean-Luc Gaudiot", "title": "Implementing a Cloud Platform for Autonomous Driving", "comments": "8 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous driving clouds provide essential services to support autonomous\nvehicles. Today these services include but not limited to distributed\nsimulation tests for new algorithm deployment, offline deep learning model\ntraining, and High-Definition (HD) map generation. These services require\ninfrastructure support including distributed computing, distributed storage, as\nwell as heterogeneous computing. In this paper, we present the details of how\nwe implement a unified autonomous driving cloud infrastructure, and how we\nsupport these services on top of this infrastructure.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 03:46:00 GMT"}], "update_date": "2017-04-11", "authors_parsed": [["Liu", "Shaoshan", ""], ["Tang", "Jie", ""], ["Wang", "Chao", ""], ["Wang", "Quan", ""], ["Gaudiot", "Jean-Luc", ""]]}, {"id": "1704.02770", "submitter": "Marlon Esteban Brenes Navarro", "authors": "Marlon Brenes, Vipin Kerala Varma, Antonello Scardicchio and Ivan\n  Girotto", "title": "Massively parallel implementation and approaches to simulate quantum\n  dynamics using Krylov subspace techniques", "comments": "16 pages, 6 figures, 3 tables", "journal-ref": "Comput. Phys. Commun. 235, 477-488 (2019)", "doi": "10.1016/j.cpc.2018.08.010", "report-no": null, "categories": "physics.comp-ph cond-mat.dis-nn cond-mat.str-el cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed an application and implemented parallel algorithms in order\nto provide a computational framework suitable for massively parallel\nsupercomputers to study the unitary dynamics of quantum systems. We use\nrenowned parallel libraries such as PETSc/SLEPc combined with high-performance\ncomputing approaches in order to overcome the large memory requirements to be\nable to study systems whose Hilbert space dimension comprises over 9 billion\nindependent quantum states. Moreover, we provide descriptions on the parallel\napproach used for the three most important stages of the simulation: handling\nthe Hilbert subspace basis, constructing a matrix representation for a generic\nHamiltonian operator and the time evolution of the system by means of the\nKrylov subspace methods. We employ our setup to study the evolution of\nquasidisordered and clean many-body systems, focussing on the return\nprobability and related dynamical exponents: the large system sizes accessible\nprovide novel insights into their thermalization properties.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 09:13:39 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Brenes", "Marlon", ""], ["Varma", "Vipin Kerala", ""], ["Scardicchio", "Antonello", ""], ["Girotto", "Ivan", ""]]}, {"id": "1704.02855", "submitter": "Ioannis Giannakopoulos", "authors": "Ioannis Giannakopoulos, Dimitrios Tsoumakos and Nectarios Koziris", "title": "A Decision Tree Based Approach Towards Adaptive Profiling of Distributed\n  Applications", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The adoption of the distributed paradigm has allowed applications to increase\ntheir scalability, robustness and fault tolerance, but it has also complicated\ntheir structure, leading to an exponential growth of the applications'\nconfiguration space and increased difficulty in predicting their performance.\nIn this work, we describe a novel, automated profiling methodology that makes\nno assumptions on application structure. Our approach utilizes oblique Decision\nTrees in order to recursively partition an application's configuration space in\ndisjoint regions, choose a set of representative samples from each subregion\naccording to a defined policy and return a model for the entire space as a\ncomposition of linear models over each subregion. An extensive evaluation over\nreal-life applications and synthetic performance functions showcases that our\nscheme outperforms other state-of-the-art profiling methodologies. It\nparticularly excels at reflecting abnormalities and discontinuities of the\nperformance function, allowing the user to influence the sampling policy based\non the modeling accuracy and the space coverage.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 13:46:58 GMT"}, {"version": "v2", "created": "Sun, 21 May 2017 13:36:45 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Giannakopoulos", "Ioannis", ""], ["Tsoumakos", "Dimitrios", ""], ["Koziris", "Nectarios", ""]]}, {"id": "1704.02978", "submitter": "Zafar Takhirov", "authors": "Zafar Takhirov and Joseph Wang and Marcia S. Louis and Venkatesh\n  Saligrama and Ajay Joshi", "title": "Field of Groves: An Energy-Efficient Random Forest", "comments": "Submitted as Work in Progress to DAC'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine Learning (ML) algorithms, like Convolutional Neural Networks (CNN),\nSupport Vector Machines (SVM), etc. have become widespread and can achieve high\nstatistical performance. However their accuracy decreases significantly in\nenergy-constrained mobile and embedded systems space, where all computations\nneed to be completed under a tight energy budget. In this work, we present a\nfield of groves (FoG) implementation of random forests (RF) that achieves an\naccuracy comparable to CNNs and SVMs under tight energy budgets. Evaluation of\nthe FoG shows that at comparable accuracy it consumes ~1.48x, ~24x, ~2.5x, and\n~34.7x lower energy per classification compared to conventional RF, SVM_RBF ,\nMLP, and CNN, respectively. FoG is ~6.5x less energy efficient than SVM_LR, but\nachieves 18% higher accuracy on average across all considered datasets.\n", "versions": [{"version": "v1", "created": "Mon, 10 Apr 2017 15:02:07 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Takhirov", "Zafar", ""], ["Wang", "Joseph", ""], ["Louis", "Marcia S.", ""], ["Saligrama", "Venkatesh", ""], ["Joshi", "Ajay", ""]]}, {"id": "1704.03319", "submitter": "Balaji Arun", "authors": "Balaji Arun, Sebastiano Peluso, Roberto Palmieri, Giuliano Losa, Binoy\n  Ravindran", "title": "Speeding up Consensus by Chasing Fast Decisions", "comments": "Extended Technical Report of the paper published in the 47th\n  IEEE/IFIP International Conference on Dependable Systems and Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes Caesar, a novel multi-leader Generalized Consensus\nprotocol for geographically replicated sites. The main goal of Caesar is to\novercome one of the major limitations of existing approaches, which is the\nsignificant performance degradation when application workload produces\nconflicting requests. Caesar does that by changing the way a fast decision is\ntaken: its ordering protocol does not reject a fast decision for a client\nrequest if a quorum of nodes reply with different dependency sets for that\nrequest. The effectiveness of Caesar is demonstrated through an evaluation\nstudy performed on Amazon's EC2 infrastructure using 5 geo-replicated sites.\nCaesar outperforms other multi-leader (e.g., EPaxos) competitors by as much as\n1.7x in the presence of 30% conflicting requests, and single-leader (e.g.,\nMulti-Paxos) by up to 3.5x.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 14:40:47 GMT"}, {"version": "v2", "created": "Mon, 23 Dec 2019 00:13:39 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Arun", "Balaji", ""], ["Peluso", "Sebastiano", ""], ["Palmieri", "Roberto", ""], ["Losa", "Giuliano", ""], ["Ravindran", "Binoy", ""]]}, {"id": "1704.03324", "submitter": "Luis Veiga", "authors": "Duarte Patr\\'icio and Jos\\'e Sim\\~ao and Lu\\'is Veiga", "title": "Gang-GC: Locality-aware Parallel Data Placement Optimizations for\n  Key-Value Storages", "comments": null, "journal-ref": null, "doi": null, "report-no": "INESC-ID Tec. Rep. 5/2017, Feb 2017", "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cloud applications rely on fast and non-relational storage to aid in the\nprocessing of large amounts of data. Managed runtimes are now widely used to\nsupport the execution of several storage solutions of the NoSQL movement,\nparticularly when dealing with big data key-value store-driven applications.\nThe benefits of these runtimes can however be limited by modern parallel\nthroughput-oriented GC algorithms, where related objects have the potential to\nbe dispersed in memory, either in the same or different generations. In the\nlong run this causes more page faults and degradation of locality on\nsystem-level memory caches.\n  We propose, Gang-CG, an extension to modern heap layouts and to a parallel GC\nalgorithm to promote locality between groups of related objects. This is done\nwithout extensive profiling of the applications and in a way that is\ntransparent to the programmer, without the need to use specialized data\nstructures. The heap layout and algorithmic extensions were implemented over\nthe Parallel Scavenge garbage collector of the HotSpot JVM\\@.\n  Using microbenchmarks that capture the architecture of several key-value\nstores databases, we show negligible overhead in frequent operations such as\nthe allocation of new objects and improvements to the access speed of data,\nsupported by lower misses in system-level memory caches. Overall, we show a 6\\%\nimprovement in the average time of read and update operations and an average\ndecrease of 12.4\\% in page faults.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 14:44:29 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Patr\u00edcio", "Duarte", ""], ["Sim\u00e3o", "Jos\u00e9", ""], ["Veiga", "Lu\u00eds", ""]]}, {"id": "1704.03329", "submitter": "Eike Hermann M\\\"uller", "authors": "William R. Saunders and James Grant and Eike H. M\\\"uller", "title": "A Domain Specific Language for Performance Portable Molecular Dynamics\n  Algorithms", "comments": "24 pages, 12 figures, 11 tables, accepted for publication in Computer\n  Physics Communications on 12 Nov 2017", "journal-ref": null, "doi": "10.1016/j.cpc.2017.11.006", "report-no": null, "categories": "cs.DC cs.SE physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Developers of Molecular Dynamics (MD) codes face significant challenges when\nadapting existing simulation packages to new hardware. In a continuously\ndiversifying hardware landscape it becomes increasingly difficult for\nscientists to be experts both in their own domain (physics/chemistry/biology)\nand specialists in the low level parallelisation and optimisation of their\ncodes. To address this challenge, we describe a \"Separation of Concerns\"\napproach for the development of parallel and optimised MD codes: the science\nspecialist writes code at a high abstraction level in a domain specific\nlanguage (DSL), which is then translated into efficient computer code by a\nscientific programmer. In a related context, an abstraction for the solution of\npartial differential equations with grid based methods has recently been\nimplemented in the (Py)OP2 library. Inspired by this approach, we develop a\nPython code generation system for molecular dynamics simulations on different\nparallel architectures, including massively parallel distributed memory systems\nand GPUs. We demonstrate the efficiency of the auto-generated code by studying\nits performance and scalability on different hardware and compare it to other\nstate-of-the-art simulation packages. With growing data volumes the extraction\nof physically meaningful information from the simulation becomes increasingly\nchallenging and requires equally efficient implementations. A particular\nadvantage of our approach is the easy expression of such analysis algorithms.\nWe consider two popular methods for deducing the crystalline structure of a\nmaterial from the local environment of each atom, show how they can be\nexpressed in our abstraction and implement them in the code generation\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 14:52:55 GMT"}, {"version": "v2", "created": "Mon, 13 Nov 2017 15:02:44 GMT"}], "update_date": "2018-03-14", "authors_parsed": [["Saunders", "William R.", ""], ["Grant", "James", ""], ["M\u00fcller", "Eike H.", ""]]}, {"id": "1704.03383", "submitter": "Felipe A. Cruz", "authors": "Lucas Benedicic, Felipe A. Cruz, Alberto Madonna and Kean Mariotti", "title": "Portable, high-performance containers for HPC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Building and deploying software on high-end computing systems is a\nchallenging task. High performance applications have to reliably run across\nmultiple platforms and environments, and make use of site-specific resources\nwhile resolving complicated software-stack dependencies. Containers are a type\nof lightweight virtualization technology that attempt to solve this problem by\npackaging applications and their environments into standard units of software\nthat are: portable, easy to build and deploy, have a small footprint, and low\nruntime overhead. In this work we present an extension to the container runtime\nof Shifter that provides containerized applications with a mechanism to access\nGPU accelerators and specialized networking from the host system, effectively\nenabling performance portability of containers across HPC resources. The\npresented extension makes possible to rapidly deploy high-performance software\non supercomputers from containerized applications that have been developed,\nbuilt, and tested in non-HPC commodity hardware, e.g. the laptop or workstation\nof a researcher.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 15:57:33 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Benedicic", "Lucas", ""], ["Cruz", "Felipe A.", ""], ["Madonna", "Alberto", ""], ["Mariotti", "Kean", ""]]}, {"id": "1704.03527", "submitter": "Nhien-An Le-Khac", "authors": "V-H Cao, K-X Chu, Nhien-An Le-Khac, M-T Kechadi, Debra F. Laefer, Linh\n  Truong-Hong", "title": "Toward a new approach for massive LiDAR data processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Laser scanning (also known as Light Detection And Ranging) has been widely\napplied in various application. As part of that, aerial laser scanning (ALS)\nhas been used to collect topographic data points for a large area, which\ntriggers to million points to be acquired. Furthermore, today, with integrating\nfull wareform (FWF) technology during ALS data acquisition, all return\ninformation of laser pulse is stored. Thus, ALS data are to be massive and\ncomplexity since the FWF of each laser pulse can be stored up to 256 samples\nand density of ALS data is also increasing significantly. Processing LiDAR data\ndemands heavy operations and the traditional approaches require significant\nhardware and running time. On the other hand, researchers have recently\nproposed parallel approaches for analysing LiDAR data. These approaches are\nnormally based on parallel architecture of target systems such as multi-core\nprocessors, GPU, etc. However, there is still missing efficient\napproaches/tools supporting the analysis of LiDAR data due to the lack of a\ndeep study on both library tools and algorithms used in processing this data.\nIn this paper, we present a comparative study of software libraries and\nalgorithms to optimise the processing of LiDAR data. We also propose new method\nto improve this process with experiments on large LiDAR data. Finally, we\ndiscuss on a parallel solution of our approach where we integrate parallel\ncomputing in processing LiDAR data.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 20:33:28 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Cao", "V-H", ""], ["Chu", "K-X", ""], ["Le-Khac", "Nhien-An", ""], ["Kechadi", "M-T", ""], ["Laefer", "Debra F.", ""], ["Truong-Hong", "Linh", ""]]}, {"id": "1704.03530", "submitter": "Nhien-An Le-Khac", "authors": "Nhien-An Le-Khac, M-Tahar Kechadi, Bo Wu, C. Chen", "title": "Feature Selection Parallel Technique for Remotely Sensed Imagery\n  Classification", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote sensing research focusing on feature selection has long attracted the\nattention of the remote sensing community because feature selection is a\nprerequisite for image processing and various applications. Different feature\nselection methods have been proposed to improve the classification accuracy.\nThey vary from basic search techniques to clonal selections, and various\noptimal criteria have been investigated. Recently, methods using\ndependence-based measures have attracted much attention due to their ability to\ndeal with very high dimensional datasets. However, these methods are based on\nCramers V test, which has performance issues with large datasets. In this\npaper, we propose a parallel approach to improve their performance. We evaluate\nour approach on hyper-spectral and high spatial resolution images and compare\nit to the proposed methods with a centralized version as preliminary results.\nThe results are very promising.\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 20:44:10 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Le-Khac", "Nhien-An", ""], ["Kechadi", "M-Tahar", ""], ["Wu", "Bo", ""], ["Chen", "C.", ""]]}, {"id": "1704.03538", "submitter": "Nhien-An Le-Khac", "authors": "Nhien-An Le-Khac, Lamine Aouad, M-Tahar Kechadi", "title": "Toward a Distributed Knowledge Discovery system for Grid systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During the last decade or so, we have had a deluge of data from not only\nscience fields but also industry and commerce fields. Although the amount of\ndata available to us is constantly increasing, our ability to process it\nbecomes more and more difficult. Efficient discovery of useful knowledge from\nthese datasets is therefore becoming a challenge and a massive economic need.\nThis led to the need of developing large-scale data mining (DM) techniques to\ndeal with these huge datasets either from science or economic applications. In\nthis chapter, we present a new DDM system combining dataset-driven and\narchitecture-driven strategies. Data-driven strategies will consider the size\nand heterogeneity of the data, while architecture driven will focus on the\ndistribution of the datasets. This system is based on a Grid middleware tools\nthat integrate appropriate large data manipulation operations. Therefore, this\nallows more dynamicity and autonomicity during the mining, integrating and\nprocessing phases\n", "versions": [{"version": "v1", "created": "Tue, 11 Apr 2017 21:07:07 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Le-Khac", "Nhien-An", ""], ["Aouad", "Lamine", ""], ["Kechadi", "M-Tahar", ""]]}, {"id": "1704.03647", "submitter": "Sleiman Mhanna Dr.", "authors": "Sleiman Mhanna, Gregor Verbic and Archie Chapman", "title": "A Component-Based Dual Decomposition Method for the OPF Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a component-based dual decomposition of the nonconvex AC\noptimal power flow (OPF) problem, where the modified dual function is solved in\na distributed fashion. The main contribution of this work is that is\ndemonstrates that a distributed method with carefully tuned parameters can\nconverge to globally optimal solutions despite the inherent nonconvexity of the\nproblem and the absence of theoretical guarantees of convergence. This paper is\nthe first to conduct extensive numerical analysis resulting in the\nidentification and tabulation of the algorithmic parameter settings that are\ncrucial for the convergence of the method on 72 AC OPF test instances.\nMoreover, this work provides a deeper insight into the geometry of the modified\nLagrange dual function of the OPF problem and highlights the conditions that\nmake this function differentiable. This numerical demonstration of convergence\ncoupled with the scalability and the privacy preserving nature of the proposed\nmethod makes it well suited for smart grid applications such as multi-period\nOPF with demand response (DR) and security constrained unit commitment (SCUC)\nwith contingency constraints and multiple transmission system operators (TSOs).\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 07:30:53 GMT"}, {"version": "v2", "created": "Wed, 19 Apr 2017 11:49:25 GMT"}, {"version": "v3", "created": "Wed, 3 May 2017 02:25:00 GMT"}, {"version": "v4", "created": "Sun, 18 Jun 2017 06:08:14 GMT"}, {"version": "v5", "created": "Thu, 29 Jun 2017 14:32:37 GMT"}, {"version": "v6", "created": "Fri, 30 Jun 2017 02:48:58 GMT"}, {"version": "v7", "created": "Fri, 7 Jul 2017 00:51:17 GMT"}, {"version": "v8", "created": "Tue, 22 Aug 2017 04:41:46 GMT"}], "update_date": "2017-08-23", "authors_parsed": [["Mhanna", "Sleiman", ""], ["Verbic", "Gregor", ""], ["Chapman", "Archie", ""]]}, {"id": "1704.03696", "submitter": "Patrick P. C. Lee", "authors": "Yuchong Hu, Xiaolu Li, Mi Zhang, Patrick P. C. Lee, Xiaoyang Zhang,\n  Pan Zhou, Dan Feng", "title": "Optimal Repair Layering for Erasure-Coded Data Centers: From Theory to\n  Practice", "comments": "24 pages. Accepted by ACM Transactions on Storage", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Repair performance in hierarchical data centers is often bottlenecked by\ncross-rack network transfer. Recent theoretical results show that the\ncross-rack repair traffic can be minimized through repair layering, whose idea\nis to partition a repair operation into inner-rack and cross-rack layers.\nHowever, how repair layering should be implemented and deployed in practice\nremains an open issue. In this paper, we address this issue by proposing a\npractical repair layering framework called DoubleR. We design two families of\npractical double regenerating codes (DRC), which not only minimize the\ncross-rack repair traffic, but also have several practical properties that\nimprove state-of-the-art regenerating codes. We implement and deploy DoubleR\natop Hadoop Distributed File System (HDFS), and show that DoubleR maintains the\ntheoretical guarantees of DRC and improves the repair performance of\nregenerating codes in both node recovery and degraded read operations.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 10:55:16 GMT"}, {"version": "v2", "created": "Fri, 15 Sep 2017 13:39:44 GMT"}], "update_date": "2017-09-18", "authors_parsed": [["Hu", "Yuchong", ""], ["Li", "Xiaolu", ""], ["Zhang", "Mi", ""], ["Lee", "Patrick P. C.", ""], ["Zhang", "Xiaoyang", ""], ["Zhou", "Pan", ""], ["Feng", "Dan", ""]]}, {"id": "1704.03764", "submitter": "Rodrigo Bruno Mr.", "authors": "Rodrigo Bruno, Lu\\'is Oliveira, Paulo Ferreira", "title": "NG2C: Pretenuring N-Generational GC for HotSpot Big Data Applications", "comments": "Accepted at ISMM'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big Data applications suffer from unpredictable and unacceptably high pause\ntimes due to Garbage Collection (GC). This is the case in latency-sensitive\napplications such as on-line credit-card fraud detection, graph-based computing\nfor analysis on social networks, etc. Such pauses compromise latency\nrequirements of the whole application stack and result from applications'\naggressive buffering/caching of data, exposing an ill-suited GC design, which\nassumes that most objects will die young and does not consider that\napplications hold large amounts of middle-lived data in memory.\n  To avoid such pauses, we propose NG2C, a new GC algorithm that combines\npretenuring with an N-Generational heap. By being able to allocate objects into\ndifferent generations, NG2C is able to group objects with similar lifetime\nprofiles in the same generation. By allocating objects with similar lifetime\nprofiles close to each other, i.e. in the same generation, we avoid object\npromotion (copying between generations) and heap fragmentation (which leads to\nheap compactions) both responsible for most of the duration of HotSpot GC pause\ntimes.\n  NG2C is implemented for the OpenJDK 8 HotSpot Java Virtual Machine, as an\nextension of the Garbage First GC. We evaluate NG2C using Cassandra, Lucene,\nand GraphChi with three different GCs: Garbage First (G1), Concurrent Mark\nSweep (CMS), and NG2C. Results show that NG2C decreases the worst observable GC\npause time by up to 94.8% for Cassandra, 85.0% for Lucene and 96.45% for\nGraphChi, when compared to current collectors (G1 and CMS). In addition, NG2C\nhas no negative impact on application throughput or memory usage.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 14:03:32 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Bruno", "Rodrigo", ""], ["Oliveira", "Lu\u00eds", ""], ["Ferreira", "Paulo", ""]]}, {"id": "1704.03767", "submitter": "Yongchao Liu", "authors": "Yongchao Liu, Tony Pan, Oded Green, Srinivas Aluru", "title": "Parallelized Kendall's Tau Coefficient Computation via SIMD Vectorized\n  Sorting On Many-Integrated-Core Processors", "comments": "29 pages, 6 figures, 5 tables, submitted to Journal of Parallel and\n  Distributed Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pairwise association measure is an important operation in data analytics.\nKendall's tau coefficient is one widely used correlation coefficient\nidentifying non-linear relationships between ordinal variables. In this paper,\nwe investigated a parallel algorithm accelerating all-pairs Kendall's tau\ncoefficient computation via single instruction multiple data (SIMD) vectorized\nsorting on Intel Xeon Phis by taking advantage of many processing cores and\n512-bit SIMD vector instructions. To facilitate workload balancing and overcome\non-chip memory limitation, we proposed a generic framework for symmetric\nall-pairs computation by building provable bijective functions between job\nidentifier and coordinate space. Performance evaluation demonstrated that our\nalgorithm on one 5110P Phi achieves two orders-of-magnitude speedups over\n16-threaded MATLAB and three orders-of-magnitude speedups over sequential R,\nboth running on high-end CPUs. Besides, our algorithm exhibited rather good\ndistributed computing scalability with respect to number of Phis. Source code\nand datasets are publicly available at http://lightpcc.sourceforge.net.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 14:29:39 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Liu", "Yongchao", ""], ["Pan", "Tony", ""], ["Green", "Oded", ""], ["Aluru", "Srinivas", ""]]}, {"id": "1704.04213", "submitter": "Vishal Sharma", "authors": "Vishal Sharma, Kathiravan Srinivasan, Dushantha Nalin K. Jayakody,\n  Omer Rana, Ravinder Kumar", "title": "Managing Service-Heterogeneity using Osmotic Computing", "comments": "7 pages, 4 Figures, International Conference on Communication,\n  Management and Information Technology (ICCMIT 2017), At Warsaw, Poland, 3-5\n  April 2017, http://www.iccmit.net/ (Best Paper Award)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational resource provisioning that is closer to a user is becoming\nincreasingly important, with a rise in the number of devices making continuous\nservice requests and with the significant recent take up of latency-sensitive\napplications, such as streaming and real-time data processing. Fog computing\nprovides a solution to such types of applications by bridging the gap between\nthe user and public/private cloud infrastructure via the inclusion of a \"fog\"\nlayer. Such approach is capable of reducing the overall processing latency, but\nthe issues of redundancy, cost-effectiveness in utilizing such computing\ninfrastructure and handling services on the basis of a difference in their\ncharacteristics remain. This difference in characteristics of services because\nof variations in the requirement of computational resources and processes is\ntermed as service heterogeneity. A potential solution to these issues is the\nuse of Osmotic Computing -- a recently introduced paradigm that allows division\nof services on the basis of their resource usage, based on parameters such as\nenergy, load, processing time on a data center vs. a network edge resource.\nService provisioning can then be divided across different layers of a\ncomputational infrastructure, from edge devices, in-transit nodes, and a data\ncenter, and supported through an Osmotic software layer. In this paper, a\nfitness-based Osmosis algorithm is proposed to provide support for osmotic\ncomputing by making more effective use of existing Fog server resources. The\nproposed approach is capable of efficiently distributing and allocating\nservices by following the principle of osmosis. The results are presented using\nnumerical simulations demonstrating gains in terms of lower allocation time and\na higher probability of services being handled with high resource utilization.\n", "versions": [{"version": "v1", "created": "Thu, 13 Apr 2017 17:05:46 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Sharma", "Vishal", ""], ["Srinivasan", "Kathiravan", ""], ["Jayakody", "Dushantha Nalin K.", ""], ["Rana", "Omer", ""], ["Kumar", "Ravinder", ""]]}, {"id": "1704.04374", "submitter": "Paul Springer", "authors": "Paul Springer, Tong Su, Paolo Bientinesi", "title": "HPTT: A High-Performance Tensor Transposition C++ Library", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently we presented TTC, a domain-specific compiler for tensor\ntranspositions. Despite the fact that the performance of the generated code is\nnearly optimal, due to its offline nature, TTC cannot be utilized in all the\napplication codes in which the tensor sizes and the necessary tensor\npermutations are determined at runtime. To overcome this limitation, we\nintroduce the open-source C++ library High-Performance Tensor Transposition\n(HPTT). Similar to TTC, HPTT incorporates optimizations such as blocking,\nmulti-threading, and explicit vectorization; furthermore it decomposes any\ntransposition into multiple loops around a so called micro-kernel. This modular\ndesign---inspired by BLIS---makes HPTT easy to port to different architectures,\nby only replacing the hand-vectorized micro-kernel (e.g., a 4x4 transpose).\nHPTT also offers an optional autotuning framework---guided by a performance\nmodel---that explores a vast search space of implementations at runtime\n(similar to FFTW). Across a wide range of different tensor transpositions and\narchitectures (e.g., Intel Ivy Bridge, Intel Knights Landing, ARMv7, IBM\nPower7), HPTT attains a bandwidth comparable to that of SAXPY, and yields\nremarkable speedups over Eigen's tensor transposition implementation. Most\nimportantly, the integration of HPTT into the Cyclops Tensor Framework (CTF)\nimproves the overall performance of tensor contractions by up to 3.1x.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 09:45:06 GMT"}, {"version": "v2", "created": "Wed, 10 May 2017 21:34:51 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Springer", "Paul", ""], ["Su", "Tong", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1704.04389", "submitter": "Micha{\\l}  Karpi\\'nski", "authors": "Micha{\\l} Karpi\\'nski, Marek Piotr\\'ow", "title": "Encoding Cardinality Constraints using Generalized Selection Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean cardinality constraints state that at most (at least, or exactly) $k$\nout of $n$ propositional literals can be true. We propose a new class of\nselection networks that can be used for an efficient encoding of them. Several\ncomparator networks have been proposed recently for encoding cardinality\nconstraints and experiments have proved their efficiency. Those were based\nmainly on the odd-even or pairwise comparator networks. We use similar ideas,\nbut we extend the model of comparator networks so that the basic components are\nnot only comparators (2-sorters) but more general $m$-sorters, for $m \\geq 2$.\nThe inputs are organized into $m$ columns, in which elements are recursively\nselected and, after that, columns are merged using an idea of multi-way\nmerging. We present two algorithms parametrized by $m \\geq 2$. We call those\nnetworks $m$-Wise Selection Network and $m$-Odd-Even Selection Network. We give\ndetailed construction of the mergers when $m=4$. The construction can be\ndirectly applied to any values of $k$ and $n$. The proposed encoding of sorters\nis standard, therefore the arc-consistency is preserved. We prove correctness\nof the constructions and present the theoretical and experimental evaluation,\nwhich show that the new encodings are competitive to the other state-of-art\nencodings.\n", "versions": [{"version": "v1", "created": "Fri, 14 Apr 2017 10:53:34 GMT"}], "update_date": "2017-04-17", "authors_parsed": [["Karpi\u0144ski", "Micha\u0142", ""], ["Piotr\u00f3w", "Marek", ""]]}, {"id": "1704.04560", "submitter": "Charles Siegel", "authors": "Abhinav Vishnu, Joseph Manzano, Charles Siegel, Jeff Daily", "title": "User-transparent Distributed TensorFlow", "comments": "9 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning (DL) algorithms have become the {\\em de facto} choice for data\nanalysis. Several DL implementations -- primarily limited to a single compute\nnode -- such as Caffe, TensorFlow, Theano and Torch have become readily\navailable. Distributed DL implementations capable of execution on large scale\nsystems are becoming important to address the computational needs of large data\nproduced by scientific simulations and experiments. Yet, the adoption of\ndistributed DL implementations faces significant impediments: 1) most\nimplementations require DL analysts to modify their code significantly -- which\nis a show-stopper, 2) several distributed DL implementations are geared towards\ncloud computing systems -- which is inadequate for execution on massively\nparallel systems such as supercomputers.\n  This work addresses each of these problems. We provide a distributed memory\nDL implementation by incorporating required changes in the TensorFlow runtime\nitself. This dramatically reduces the entry barrier for using a distributed\nTensorFlow implementation. We use Message Passing Interface (MPI) -- which\nprovides performance portability, especially since MPI specific changes are\nabstracted from users. Lastly -- and arguably most importantly -- we make our\nimplementation available for broader use, under the umbrella of Machine\nLearning Toolkit for Extreme Scale (MaTEx) at {\\texttt\nhttp://hpc.pnl.gov/matex}. We refer to our implementation as MaTEx-TensorFlow.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 00:15:10 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Vishnu", "Abhinav", ""], ["Manzano", "Joseph", ""], ["Siegel", "Charles", ""], ["Daily", "Jeff", ""]]}, {"id": "1704.04588", "submitter": "Saeid Pourroostaei Ardakani", "authors": "Saeid Pourroostaei Ardakani", "title": "Data aggregation routing protocols in wireless sensor networks: a\n  taxonomy", "comments": null, "journal-ref": null, "doi": "10.5121/ijcnc.2017.9207", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Routing in Wireless Sensor Network (WSN) aims to interconnect sensor nodes\nvia single or multi-hop paths. The routes are established to forward data\npackets from sensor nodes to the sink. Establishing a single path to report\neach data packet results in increasing energy consumption in WSN, hence, data\naggregation routing is used to combine data packets and consequently reduce the\nnumber of transmissions. This reduces the routing overhead by eliminating\nredundant and meaningless data. There are two models for data aggregation\nrouting in WSN: mobile agent and client/server. This paper describes data\naggregation routing and classifies then the routing protocols according to the\nnetwork architecture and routing models. The key issues of the data aggregation\nrouting models (client/server and mobile agent) are highlighted and discussed.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 05:55:31 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Ardakani", "Saeid Pourroostaei", ""]]}, {"id": "1704.04599", "submitter": "Arkan Al-Hamodi", "authors": "Arkan A. G. Al-Hamodi, Songfeng Lu", "title": "A novel approach for fast mining frequent itemsets use N-list structure\n  based on MapReduce", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Frequent Pattern Mining is a one field of the most significant topics in data\nmining. In recent years, many algorithms have been proposed for mining frequent\nitemsets. A new algorithm has been presented for mining frequent itemsets based\non N-list data structure called Prepost algorithm. The Prepost algorithm is\nenhanced by implementing compact PPC-tree with the general tree. Prepost\nalgorithm can only find a frequent itemsets with required (pre-order and\npost-order) for each node. In this chapter, we improved prepost algorithm based\non Hadoop platform (HPrepost), proposed using the Mapreduce programming model.\nThe main goals of proposed method are efficient mining frequent itemsets\nrequiring less running time and memory usage. We have conduct experiments for\nthe proposed scheme to compare with another algorithms. With dense datasets,\nwhich have a large average length of transactions, HPrepost is more effective\nthan frequent itemsets algorithms in terms of execution time and memory usage\nfor all min-sup. Generally, our algorithm outperforms algorithms in terms of\nruntime and memory usage with small thresholds and large datasets.\n", "versions": [{"version": "v1", "created": "Sat, 15 Apr 2017 07:23:40 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Al-Hamodi", "Arkan A. G.", ""], ["Lu", "Songfeng", ""]]}, {"id": "1704.04712", "submitter": "Shaoshan Liu", "authors": "Shaoshan Liu, Bolin Ding, Jie Tang, Dawei Sun, Zhe Zhang, Grace Tsai,\n  and Jean-Luc Gaudiot", "title": "Learn-Memorize-Recall-Reduce A Robotic Cloud Computing Paradigm", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of robotic applications has led to the generation of a huge volume\nof unstructured data, whereas the current cloud infrastructure was designed to\nprocess limited amounts of structured data. To address this problem, we propose\na learn-memorize-recall-reduce paradigm for robotic cloud computing. The\nlearning stage converts incoming unstructured data into structured data; the\nmemorization stage provides effective storage for the massive amount of data;\nthe recall stage provides efficient means to retrieve the raw data; while the\nreduction stage provides means to make sense of this massive amount of\nunstructured data with limited computing resources.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 02:55:07 GMT"}, {"version": "v2", "created": "Tue, 18 Apr 2017 00:20:51 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Liu", "Shaoshan", ""], ["Ding", "Bolin", ""], ["Tang", "Jie", ""], ["Sun", "Dawei", ""], ["Zhang", "Zhe", ""], ["Tsai", "Grace", ""], ["Gaudiot", "Jean-Luc", ""]]}, {"id": "1704.04782", "submitter": "Andres Gomez Ramirez", "authors": "A. Gomez Ramirez, M. Martinez Pedreira, C. Grigoras, L. Betev, C. Lara\n  and U. Kebschull (for the ALICE Collaboration)", "title": "A Security Monitoring Framework For Virtualization Based HEP\n  Infrastructures", "comments": "Proceedings of the 22nd International Conference on Computing in High\n  Energy and Nuclear Physics, CHEP 2016, 10-14 October 2016, San Francisco.\n  Submitted to Journal of Physics: Conference Series (JPCS)", "journal-ref": null, "doi": "10.1088/1742-6596/898/10/102004", "report-no": null, "categories": "cs.DC cs.AI cs.CR hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High Energy Physics (HEP) distributed computing infrastructures require\nautomatic tools to monitor, analyze and react to potential security incidents.\nThese tools should collect and inspect data such as resource consumption, logs\nand sequence of system calls for detecting anomalies that indicate the presence\nof a malicious agent. They should also be able to perform automated reactions\nto attacks without administrator intervention. We describe a novel framework\nthat accomplishes these requirements, with a proof of concept implementation\nfor the ALICE experiment at CERN. We show how we achieve a fully virtualized\nenvironment that improves the security by isolating services and Jobs without a\nsignificant performance impact. We also describe a collected dataset for\nMachine Learning based Intrusion Prevention and Detection Systems on Grid\ncomputing. This dataset is composed of resource consumption measurements (such\nas CPU, RAM and network traffic), logfiles from operating system services, and\nsystem call data collected from production Jobs running in an ALICE Grid test\nsite and a big set of malware. This malware was collected from security\nresearch sites. Based on this dataset, we will proceed to develop Machine\nLearning algorithms able to detect malicious Jobs.\n", "versions": [{"version": "v1", "created": "Sun, 16 Apr 2017 14:59:21 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Ramirez", "A. Gomez", "", "for the ALICE Collaboration"], ["Pedreira", "M. Martinez", "", "for the ALICE Collaboration"], ["Grigoras", "C.", "", "for the ALICE Collaboration"], ["Betev", "L.", "", "for the ALICE Collaboration"], ["Lara", "C.", "", "for the ALICE Collaboration"], ["Kebschull", "U.", "", "for the ALICE Collaboration"]]}, {"id": "1704.04947", "submitter": "Rati Gelashvili", "authors": "Dan Alistarh, James Aspnes, Rati Gelashvili", "title": "Space-Optimal Majority in Population Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population protocols are a model of distributed computing, in which $n$\nagents with limited local state interact randomly, and cooperate to\ncollectively compute global predicates. An extensive series of papers, across\ndifferent communities, has examined the computability and complexity\ncharacteristics of this model. Majority, or consensus, is a central task, in\nwhich agents need to collectively reach a decision as to which one of two\nstates $A$ or $B$ had a higher initial count. Two complexity metrics are\nimportant: the time that a protocol requires to stabilize to an output\ndecision, and the state space size that each agent requires.\n  It is known that majority requires $\\Omega(\\log \\log n)$ states per agent to\nallow for poly-logarithmic time stabilization, and that $O(\\log^2 n)$ states\nare sufficient. Thus, there is an exponential gap between the upper and lower\nbounds.\n  We address this question. We provide a new lower bound of $\\Omega(\\log n)$\nstates for any protocol which stabilizes in $O( n^{1-c} )$ time, for any $c >\n0$ constant. This result is conditional on basic monotonicity and output\nassumptions, satisfied by all known protocols. Technically, it represents a\nsignificant departure from previous lower bounds. Instead of relying on dense\nconfigurations, we introduce a new surgery technique to construct executions\nwhich contradict the correctness of algorithms that stabilize too fast.\nSubsequently, our lower bound applies to general initial configurations.\n  We give an algorithm for majority which uses $O(\\log n)$ states, and\nstabilizes in $O(\\log^2 n)$ time. Central to the algorithm is a new leaderless\nphase clock, which allows nodes to synchronize in phases of $\\Theta(n \\log{n})$\nconsecutive interactions using $O(\\log n)$ states per node. We also employ our\nphase clock to build a leader election algorithm with $O(\\log n )$ states,\nwhich stabilizes in $O(\\log^2 n)$ time.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 12:53:02 GMT"}, {"version": "v2", "created": "Thu, 11 May 2017 09:12:36 GMT"}, {"version": "v3", "created": "Fri, 12 May 2017 03:46:39 GMT"}, {"version": "v4", "created": "Sun, 28 May 2017 20:30:25 GMT"}, {"version": "v5", "created": "Thu, 13 Jul 2017 21:18:42 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Alistarh", "Dan", ""], ["Aspnes", "James", ""], ["Gelashvili", "Rati", ""]]}, {"id": "1704.05017", "submitter": "Mathieu Galtier", "authors": "Mathieu Galtier and Camille Marini", "title": "Morpheo: Traceable Machine Learning on Hidden data", "comments": "whitepaper, 9 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CR cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Morpheo is a transparent and secure machine learning platform collecting and\nanalysing large datasets. It aims at building state-of-the art prediction\nmodels in various fields where data are sensitive. Indeed, it offers strong\nprivacy of data and algorithm, by preventing anyone to read the data, apart\nfrom the owner and the chosen algorithms. Computations in Morpheo are\norchestrated by a blockchain infrastructure, thus offering total traceability\nof operations. Morpheo aims at building an attractive economic ecosystem around\ndata prediction by channelling crypto-money from prediction requests to useful\ndata and algorithms providers. Morpheo is designed to handle multiple data\nsources in a transfer learning approach in order to mutualize knowledge\nacquired from large datasets for applications with smaller but similar\ndatasets.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 16:24:29 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Galtier", "Mathieu", ""], ["Marini", "Camille", ""]]}, {"id": "1704.05021", "submitter": "Alham Fikri Aji", "authors": "Alham Fikri Aji and Kenneth Heafield", "title": "Sparse Communication for Distributed Gradient Descent", "comments": "EMNLP 2017", "journal-ref": null, "doi": "10.18653/v1/D17-1045", "report-no": null, "categories": "cs.CL cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We make distributed stochastic gradient descent faster by exchanging sparse\nupdates instead of dense updates. Gradient updates are positively skewed as\nmost updates are near zero, so we map the 99% smallest updates (by absolute\nvalue) to zero then exchange sparse matrices. This method can be combined with\nquantization to further improve the compression. We explore different\nconfigurations and apply them to neural machine translation and MNIST image\nclassification tasks. Most configurations work on MNIST, whereas different\nconfigurations reduce convergence rate on the more complex translation task.\nOur experiments show that we can achieve up to 49% speed up on MNIST and 22% on\nNMT without damaging the final accuracy or BLEU.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 16:32:02 GMT"}, {"version": "v2", "created": "Mon, 24 Jul 2017 21:47:51 GMT"}], "update_date": "2019-06-11", "authors_parsed": [["Aji", "Alham Fikri", ""], ["Heafield", "Kenneth", ""]]}, {"id": "1704.05112", "submitter": "Daniel Porto", "authors": "Daniel Porto, Jo\\~ao Loff, Rui Duarte, Luis Ceze and Rodrigo Rodrigues", "title": "Making data center computations fast, but not so furious", "comments": "The 7th Workshop on Multi-core and Rack Scale Systems - MARS'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an aggressive computational sprinting variant for data center\nenvironments. While most of previous work on computational sprinting focuses on\nmaximizing the sprinting process while ensuring non-faulty conditions, we take\nadvantage of the existing replication in data centers to push the system beyond\nits safety limits. In this paper we outline this vision, we survey existing\ntechniques for achieving it, and we present some design ideas for future work\nin this area.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 20:09:23 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Porto", "Daniel", ""], ["Loff", "Jo\u00e3o", ""], ["Duarte", "Rui", ""], ["Ceze", "Luis", ""], ["Rodrigues", "Rodrigo", ""]]}, {"id": "1704.05132", "submitter": "Nikolaos Antoniadis", "authors": "Nikolaos Antoniadis, Angelo Sifaleras", "title": "A hybrid CPU-GPU parallelization scheme of variable neighborhood search\n  for inventory optimization problems", "comments": "8 pages, 1 figure", "journal-ref": "Electronic Notes in Discrete Mathematics, Volume 58, April 2017,\n  Pages 47-54, ISSN 1571-0653", "doi": "10.1016/j.endm.2017.03.007", "report-no": null, "categories": "cs.NE cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study various parallelization schemes for the Variable\nNeighborhood Search (VNS) metaheuristic on a CPU-GPU system via OpenMP and\nOpenACC. A hybrid parallel VNS method is applied to recent benchmark problem\ninstances for the multi-product dynamic lot sizing problem with product returns\nand recovery, which appears in reverse logistics and is known to be NP-hard. We\nreport our findings regarding these parallelization approaches and present\npromising computational results.\n", "versions": [{"version": "v1", "created": "Mon, 17 Apr 2017 21:31:14 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Antoniadis", "Nikolaos", ""], ["Sifaleras", "Angelo", ""]]}, {"id": "1704.05272", "submitter": "Miguel Martinez Pedreira", "authors": "M Martinez Pedreira and C Grigoras (for the ALICE Collaboration)", "title": "Scalable Global Grid catalogue for LHC Run3 and beyond", "comments": "Proceedings of the 22nd International Conference on Computing in High\n  Energy and Nuclear Physics, CHEP 2016, 10-14 October 2016, San Francisco.\n  Submitted to Journal of Physics: Conference Series (JPCS)", "journal-ref": null, "doi": "10.1088/1742-6596/898/9/092006", "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The AliEn (ALICE Environment) file catalogue is a global unique namespace\nproviding mapping between a UNIX-like logical name structure and the\ncorresponding physical files distributed over 80 storage elements worldwide.\nPowerful search tools and hierarchical metadata information are integral parts\nof the system and are used by the Grid jobs as well as local users to store and\naccess all files on the Grid storage elements. The catalogue has been in\nproduction since 2005 and over the past 11 years has grown to more than 2\nbillion logical file names. The backend is a set of distributed relational\ndatabases, ensuring smooth growth and fast access. Due to the anticipated fast\nfuture growth, we are looking for ways to enhance the performance and\nscalability by simplifying the catalogue schema while keeping the functionality\nintact. We investigated different backend solutions, such as distributed key\nvalue stores, as replacement for the relational database. This contribution\ncovers the architectural changes in the system, together with the technology\nevaluation, benchmark results and conclusions.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 11:18:21 GMT"}], "update_date": "2019-08-13", "authors_parsed": [["Pedreira", "M Martinez", "", "for the ALICE Collaboration"], ["Grigoras", "C", "", "for the ALICE Collaboration"]]}, {"id": "1704.05316", "submitter": "Sabri Pllana", "authors": "Suejb Memeti and Lu Li and Sabri Pllana and Joanna Kolodziej and\n  Christoph Kessler", "title": "Benchmarking OpenCL, OpenACC, OpenMP, and CUDA: programming\n  productivity, performance, and energy consumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many modern parallel computing systems are heterogeneous at their node level.\nSuch nodes may comprise general purpose CPUs and accelerators (such as, GPU, or\nIntel Xeon Phi) that provide high performance with suitable energy-consumption\ncharacteristics. However, exploiting the available performance of heterogeneous\narchitectures may be challenging. There are various parallel programming\nframeworks (such as, OpenMP, OpenCL, OpenACC, CUDA) and selecting the one that\nis suitable for a target context is not straightforward.\n  In this paper, we study empirically the characteristics of OpenMP, OpenACC,\nOpenCL, and CUDA with respect to programming productivity, performance, and\nenergy. To evaluate the programming productivity we use our homegrown tool\nCodeStat, which enables us to determine the percentage of code lines that was\nrequired to parallelize the code using a specific framework. We use our tool\nx-MeterPU to evaluate the energy consumption and the performance. Experiments\nare conducted using the industry-standard SPEC benchmark suite and the Rodinia\nbenchmark suite for accelerated computing on heterogeneous systems that combine\nIntel Xeon E5 Processors with a GPU accelerator or an Intel Xeon Phi\nco-processor.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 13:08:35 GMT"}], "update_date": "2017-04-19", "authors_parsed": [["Memeti", "Suejb", ""], ["Li", "Lu", ""], ["Pllana", "Sabri", ""], ["Kolodziej", "Joanna", ""], ["Kessler", "Christoph", ""]]}, {"id": "1704.05521", "submitter": "Riccardo Lazzeretti PhD", "authors": "Antonella Del Pozzo, Silvia Bonomi, Riccardo Lazzeretti and Roberto\n  Baldoni", "title": "Building Regular Registers with Rational Malicious Servers and Anonymous\n  Clients -- Extended Version", "comments": "Extended version of paper accepted at 2017 International Symposium on\n  Cyber Security Cryptography and Machine Learning (CSCML 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper addresses the problem of emulating a regular register in a\nsynchronous distributed system where clients invoking ${\\sf read}()$ and ${\\sf\nwrite}()$ operations are anonymous while server processes maintaining the state\nof the register may be compromised by rational adversaries (i.e., a server\nmight behave as \\emph{rational malicious Byzantine} process). We first model\nour problem as a Bayesian game between a client and a rational malicious server\nwhere the equilibrium depends on the decisions of the malicious server (behave\ncorrectly and not be detected by clients vs returning a wrong register value to\nclients with the risk of being detected and then excluded by the computation).\nWe prove such equilibrium exists and finally we design a protocol implementing\nthe regular register that forces the rational malicious server to behave\ncorrectly.\n", "versions": [{"version": "v1", "created": "Tue, 18 Apr 2017 20:37:46 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Del Pozzo", "Antonella", ""], ["Bonomi", "Silvia", ""], ["Lazzeretti", "Riccardo", ""], ["Baldoni", "Roberto", ""]]}, {"id": "1704.05573", "submitter": "Yoji Yamato", "authors": "Yoji Yamato", "title": "Proposal of Vital Data Analysis Platform using Wearable Sensor", "comments": "6 pages, 2 figures, 5th IIAE International Conference on Industrial\n  Application Engineering 2017 (ICIAE2017), pp.138-143, Mar. 2017", "journal-ref": "5th IIAE International Conference on Industrial Application\n  Engineering 2017 (ICIAE2017), pp.138-143, Mar. 2017", "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a vital data analysis platform which resolves\nexisting problems to utilize vital data for real-time actions. Recently, IoT\ntechnologies have been progressed but in the healthcare area, real-time actions\nbased on analyzed vital data are not considered sufficiently yet. The causes\nare proper use of analyzing methods of stream / micro batch processing and\nnetwork cost. To resolve existing problems, we propose our vital data analysis\nplatform. Our platform collects vital data of Electrocardiograph and\nacceleration using an example of wearable vital sensor and analyzes them to\nextract posture, fatigue and relaxation in smart phones or cloud. Our platform\ncan show analyzed dangerous posture or fatigue level change. We implemented the\nplatform. And we are now preparing a field test.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 01:16:24 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Yamato", "Yoji", ""]]}, {"id": "1704.05592", "submitter": "Alexey Vasyukov", "authors": "Alexey Ermakov, Alexey Vasyukov", "title": "Testing Docker Performance for HPC Applications", "comments": "10 pages, 12 figures, 13 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main goal for this article is to compare performance penalties when using\nKVM virtualization and Docker containers for creating isolated environments for\nHPC applications. The article provides both data obtained using commonly\naccepted synthetic tests (High Performance Linpack) and real life applications\n(OpenFOAM). The article highlights the influence on resulting application\nperformance of major infrastructure configuration options: CPU type presented\nto VM, networking connection type used.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 02:48:49 GMT"}], "update_date": "2017-04-20", "authors_parsed": [["Ermakov", "Alexey", ""], ["Vasyukov", "Alexey", ""]]}, {"id": "1704.05739", "submitter": "Laurent Feuilloley", "authors": "Laurent Feuilloley", "title": "How Long It Takes for an Ordinary Node with an Ordinary ID to Output?", "comments": "(Submitted) Journal version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the context of distributed synchronous computing, processors perform in\nrounds, and the time-complexity of a distributed algorithm is classically\ndefined as the number of rounds before all computing nodes have output. Hence,\nthis complexity measure captures the running time of the slowest node(s). In\nthis paper, we are interested in the running time of the ordinary nodes, to be\ncompared with the running time of the slowest nodes. The node-averaged\ntime-complexity of a distributed algorithm on a given instance is defined as\nthe average, taken over every node of the instance, of the number of rounds\nbefore that node output. We compare the node-averaged time-complexity with the\nclassical one in the standard LOCAL model for distributed network computing. We\nshow that there can be an exponential gap between the node-averaged\ntime-complexity and the classical time-complexity, as witnessed by, e.g.,\nleader election. Our first main result is a positive one, stating that, in\nfact, the two time-complexities behave the same for a large class of problems\non very sparse graphs. In particular, we show that, for LCL problems on cycles,\nthe node-averaged time complexity is of the same order of magnitude as the\nslowest node time-complexity.\n  In addition, in the LOCAL model, the time-complexity is computed as a worst\ncase over all possible identity assignments to the nodes of the network. In\nthis paper, we also investigate the ID-averaged time-complexity, when the\nnumber of rounds is averaged over all possible identity assignments. Our second\nmain result is that the ID-averaged time-complexity is essentially the same as\nthe expected time-complexity of randomized algorithms (where the expectation is\ntaken over all possible random bits used by the nodes, and the number of rounds\nis measured for the worst-case identity assignment).\n  Finally, we study the node-averaged ID-averaged time-complexity.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 14:14:23 GMT"}, {"version": "v2", "created": "Tue, 21 Nov 2017 09:50:15 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Feuilloley", "Laurent", ""]]}, {"id": "1704.05816", "submitter": "Leonid Sokolinsky", "authors": "L.B. Sokolinsky", "title": "Analytical study of the \"master-worker\" framework scalability on\n  multiprocessors with distributed memory", "comments": "Submitted to \"Parallel computational technologies 2018\" (in Russian)", "journal-ref": null, "doi": "10.14529/cmse180203", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper is devoted to an analytical study of the \"master-worker\" framework\nscalability on multiprocessors with distributed memory. A new model of parallel\ncomputations called BSF is proposed. The BSF model is based on BSP and SPMD\nmodels. The scope of BSF model is the compute-intensive applications. The\narchitecture of BSF-computer is defined. The structure of BSF-program is\ndescribed. The Using this metric, the upper scalability bounds of BSF programs\non distributed memory multiprocessors are evaluated. The formulas for\nestimating the parallel efficiency of BSF programs also proposed.\n", "versions": [{"version": "v1", "created": "Wed, 19 Apr 2017 16:54:28 GMT"}, {"version": "v2", "created": "Tue, 25 Apr 2017 16:02:14 GMT"}, {"version": "v3", "created": "Wed, 26 Apr 2017 16:55:06 GMT"}, {"version": "v4", "created": "Sat, 29 Apr 2017 16:23:45 GMT"}, {"version": "v5", "created": "Fri, 5 May 2017 03:15:11 GMT"}, {"version": "v6", "created": "Sat, 13 May 2017 15:41:34 GMT"}, {"version": "v7", "created": "Fri, 30 Jun 2017 05:09:00 GMT"}, {"version": "v8", "created": "Sun, 10 Sep 2017 07:20:40 GMT"}], "update_date": "2020-09-09", "authors_parsed": [["Sokolinsky", "L. B.", ""]]}, {"id": "1704.05915", "submitter": "Yuri G. Gordienko", "authors": "S. Stirenko, Yu. Gordienko, T. Shemsedinov, O. Alienin, Yu. Kochura,\n  N. Gordienko, A. Rojbi, J.R. L\\'opez Benito, E. Artetxe Gonz\\'alez", "title": "User-driven Intelligent Interface on the Basis of Multimodal Augmented\n  Reality and Brain-Computer Interaction for People with Functional\n  Disabilities", "comments": "10 pages, 11 figures, 1 table, submitted to Future of Information and\n  Communication Conference (FICC) 2018, 5-6 April 2018, Singapore", "journal-ref": "In: Arai K., Kapoor S., Bhatia R. (eds) Advances in Information\n  and Communication Networks. FICC 2018. Advances in Intelligent Systems and\n  Computing, vol 886, pp.612-631. Springer, Cham", "doi": "10.1007/978-3-030-03402-3_43", "report-no": null, "categories": "cs.HC cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of the current integration attempts of some modes and use cases\nof user-machine interaction is presented. The new concept of the user-driven\nintelligent interface is proposed on the basis of multimodal augmented reality\nand brain-computer interaction for various applications: in disabilities\nstudies, education, home care, health care, etc. The several use cases of\nmultimodal augmentation are presented. The perspectives of the better human\ncomprehension by the immediate feedback through neurophysical channels by means\nof brain-computer interaction are outlined. It is shown that brain-computer\ninterface (BCI) technology provides new strategies to overcome limits of the\ncurrently available user interfaces, especially for people with functional\ndisabilities. The results of the previous studies of the low end consumer and\nopen-source BCI-devices allow us to conclude that combination of machine\nlearning (ML), multimodal interactions (visual, sound, tactile) with BCI will\nprofit from the immediate feedback from the actual neurophysical reactions\nclassified by ML methods. In general, BCI in combination with other modes of AR\ninteraction can deliver much more information than these types of interaction\nthemselves. Even in the current state the combined AR-BCI interfaces could\nprovide the highly adaptable and personal services, especially for people with\nfunctional disabilities.\n", "versions": [{"version": "v1", "created": "Wed, 12 Apr 2017 21:03:52 GMT"}, {"version": "v2", "created": "Tue, 15 Aug 2017 22:51:53 GMT"}], "update_date": "2018-12-11", "authors_parsed": [["Stirenko", "S.", ""], ["Gordienko", "Yu.", ""], ["Shemsedinov", "T.", ""], ["Alienin", "O.", ""], ["Kochura", "Yu.", ""], ["Gordienko", "N.", ""], ["Rojbi", "A.", ""], ["Benito", "J. R. L\u00f3pez", ""], ["Gonz\u00e1lez", "E. Artetxe", ""]]}, {"id": "1704.06070", "submitter": "Alkida Balliu", "authors": "Alkida Balliu, Pierre Fraigniaud", "title": "Certification of Compact Low-Stretch Routing Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  On the one hand, the correctness of routing protocols in networks is an issue\nof utmost importance for guaranteeing the delivery of messages from any source\nto any target. On the other hand, a large collection of routing schemes have\nbeen proposed during the last two decades, with the objective of transmitting\nmessages along short routes, while keeping the routing tables small.\nRegrettably, all these schemes share the property that an adversary may modify\nthe content of the routing tables with the objective of, e.g., blocking the\ndelivery of messages between some pairs of nodes, without being detected by any\nnode.\n  In this paper, we present a simple certification mechanism which enables the\nnodes to locally detect any alteration of their routing tables. In particular,\nwe show how to locally verify the stretch-3 routing scheme by Thorup and Zwick\n[SPAA 2001] by adding certificates of $\\widetilde{O}(\\sqrt{n})$ bits at each\nnode in $n$-node networks, that is, by keeping the memory size of the same\norder of magnitude as the original routing tables. We also propose a new\nname-independent routing scheme using routing tables of size\n$\\widetilde{O}(\\sqrt{n})$ bits. This new routing scheme can be locally verified\nusing certificates on $\\widetilde{O}(\\sqrt{n})$ bits. Its stretch is3 if using\nhandshaking, and 5 otherwise.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 09:50:48 GMT"}, {"version": "v2", "created": "Sat, 21 Oct 2017 22:57:18 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Balliu", "Alkida", ""], ["Fraigniaud", "Pierre", ""]]}, {"id": "1704.06078", "submitter": "Alkida Balliu", "authors": "Alkida Balliu, Dennis Olivetti", "title": "Name Independent Fault Tolerant Routing Scheme", "comments": "The stretch analysis is faulty, so the whole idea does not work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We consider the problem of routing in presence of faults in undirected\nweighted graphs. More specifically, we focus on the design of compact\nname-independent fault-tolerant routing schemes, where the designer of the\nscheme is not allowed to assign names to nodes, i.e., the name of a node is\njust its identifier. Given a set $F$ of faulty (or forbidden) edges, the goal\nis to route from a source node $s$ to a target $t$ avoiding the forbidden edges\nin $F$.\n  Given any name-dependent fault-tolerant routing scheme and any\nname-independent routing scheme, we show how to use them as a black box to\nconstruct a name-independent fault-tolerant routing scheme. In particular, we\npresent a name-independent routing scheme able to handle any set $F$ of\nforbidden edges in $|F|+1$ connected graphs. This has stretch\n$O(k^2\\,|F|^3(|F|+\\log^2 n)\\log D)$, where $D$ is the diameter of the graph. It\nuses tables of size $ \\widetilde{O}(k\\, n^{1/k}(k + deg(v)))$ bits at every\nnode $v$, where $deg(v)$ is the degree of node $v$. In the context of networks\nthat suffer only from occasional failures, we present a name-independent\nrouting scheme that handles only $1$ fault at a time, and another routing\nscheme that handles at most $2$ faults at a time. The former uses\n$\\widetilde{O}(k^2\\, n^{1/k} + k\\,deg(v))$ bits of memory per node, with\nstretch $O(k^3\\log D)$. The latter consumes in average $ \\widetilde{O}(k^2\n\\,n^{1/k} + deg(v))$ bits of memory per node, with stretch $O(k^2\\log D)$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 10:16:44 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 15:25:52 GMT"}, {"version": "v3", "created": "Thu, 26 Oct 2017 23:10:59 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Balliu", "Alkida", ""], ["Olivetti", "Dennis", ""]]}, {"id": "1704.06092", "submitter": "Dennis Olivetti", "authors": "Dennis Olivetti", "title": "How Bandwidth Affects the $CONGEST$ Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The $CONGEST$ model for distributed network computing is well suited for\nanalyzing the impact of limiting the throughput of a network on its capacity to\nsolve tasks efficiently. For many \"global\" problems there exists a lower bound\nof $\\Omega(D + \\sqrt{n/B})$, where $B$ is the amount of bits that can be\nexchanged between two nodes in one round of communication, $n$ is the number of\nnodes and $D$ is the diameter of the graph. Typically, upper bounds are given\nonly for the case $B=O(\\log n)$, or for the case $B = +\\infty$. For $B=O(\\log\nn)$, the Minimum Spanning Tree (MST) construction problem can be solved in $O(D\n+ \\sqrt{n}\\log^* n)$ rounds, and the Single Source Shortest Path (SSSP) problem\ncan be $(1+\\epsilon)$-approximated in $\\widetilde{O}(\\epsilon^{-O(1)}\n(D+\\sqrt{n}) )$ rounds. We extend these results by providing algorithms with a\ncomplexity parametric on $B$. We show that, for any $B=\\Omega(\\log n)$, there\nexists an algorithm that constructs a MST in $\\widetilde{O}(D + \\sqrt{n/B})$\nrounds, and an algorithm that $(1+\\epsilon)$-approximate the SSSP problem in\n$\\widetilde{O}(\\epsilon^{-O(1)} (D+\\sqrt{n/B}) )$ rounds. We also show that\nthere exist problems that are bandwidth insensitive.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 11:30:03 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Olivetti", "Dennis", ""]]}, {"id": "1704.06192", "submitter": "Daniel Reiter Horn", "authors": "Daniel Reiter Horn, Ken Elkabany, Chris Lesniewski-Laas, Keith\n  Winstein", "title": "The Design, Implementation, and Deployment of a System to Transparently\n  Compress Hundreds of Petabytes of Image Files for a File-Storage Service", "comments": "12 pages", "journal-ref": "Proc. NSDI 2017, Boston. p1-15", "doi": null, "report-no": null, "categories": "cs.MM cs.DC cs.GR cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We report the design, implementation, and deployment of Lepton, a\nfault-tolerant system that losslessly compresses JPEG images to 77% of their\noriginal size on average. Lepton replaces the lowest layer of baseline JPEG\ncompression-a Huffman code-with a parallelized arithmetic code, so that the\nexact bytes of the original JPEG file can be recovered quickly. Lepton matches\nthe compression efficiency of the best prior work, while decoding more than\nnine times faster and in a streaming manner. Lepton has been released as\nopen-source software and has been deployed for a year on the Dropbox\nfile-storage backend. As of February 2017, it had compressed more than 203 PiB\nof user JPEG files, saving more than 46 PiB.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 00:38:30 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Horn", "Daniel Reiter", ""], ["Elkabany", "Ken", ""], ["Lesniewski-Laas", "Chris", ""], ["Winstein", "Keith", ""]]}, {"id": "1704.06193", "submitter": "Andres Gomez Ramirez", "authors": "Andres Gomez, Camilo Lara, Udo Kebschull (for the ALICE Collaboration)", "title": "Intrusion Prevention and Detection in Grid Computing - The ALICE Case", "comments": "Journal of Physics: Conference Series, Volume 664", "journal-ref": "J. Phys.: Conf. Ser. 664 062017 (2015)", "doi": "10.1088/1742-6596/664/6/062017", "report-no": null, "categories": "cs.DC cs.AI cs.CR hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grids allow users flexible on-demand usage of computing resources through\nremote communication networks. A remarkable example of a Grid in High Energy\nPhysics (HEP) research is used in the ALICE experiment at European Organization\nfor Nuclear Research CERN. Physicists can submit jobs used to process the huge\namount of particle collision data produced by the Large Hadron Collider (LHC).\nGrids face complex security challenges. They are interesting targets for\nattackers seeking for huge computational resources. Since users can execute\narbitrary code in the worker nodes on the Grid sites, special care should be\nput in this environment. Automatic tools to harden and monitor this scenario\nare required. Currently, there is no integrated solution for such requirement.\nThis paper describes a new security framework to allow execution of job\npayloads in a sandboxed context. It also allows process behavior monitoring to\ndetect intrusions, even when new attack methods or zero day vulnerabilities are\nexploited, by a Machine Learning approach. We plan to implement the proposed\nframework as a software prototype that will be tested as a component of the\nALICE Grid middleware.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 15:47:44 GMT"}], "update_date": "2017-04-21", "authors_parsed": [["Gomez", "Andres", "", "for the ALICE Collaboration"], ["Lara", "Camilo", "", "for the ALICE Collaboration"], ["Kebschull", "Udo", "", "for the ALICE Collaboration"]]}, {"id": "1704.06297", "submitter": "Yi-Jun Chang", "authors": "Yi-Jun Chang, Seth Pettie", "title": "A Time Hierarchy Theorem for the LOCAL Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The celebrated Time Hierarchy Theorem for Turing machines states, informally,\nthat more problems can be solved given more time. The extent to which a time\nhierarchy-type theorem holds in the distributed LOCAL model has been open for\nmany years. It is consistent with previous results that all natural problems in\nthe LOCAL model can be classified according to a small constant number of\ncomplexities, such as $O(1),O(\\log^* n), O(\\log n), 2^{O(\\sqrt{\\log n})}$, etc.\n  In this paper we establish the first time hierarchy theorem for the LOCAL\nmodel and prove that several gaps exist in the LOCAL time hierarchy.\n  1. We define an infinite set of simple coloring problems called Hierarchical\n$2\\frac{1}{2}$-Coloring}. A correctly colored graph can be confirmed by simply\nchecking the neighborhood of each vertex, so this problem fits into the class\nof locally checkable labeling (LCL) problems. However, the complexity of the\n$k$-level Hierarchical $2\\frac{1}{2}$-Coloring problem is $\\Theta(n^{1/k})$,\nfor $k\\in\\mathbb{Z}^+$. The upper and lower bounds hold for both general graphs\nand trees, and for both randomized and deterministic algorithms.\n  2. Consider any LCL problem on bounded degree trees. We prove an\nautomatic-speedup theorem that states that any randomized $n^{o(1)}$-time\nalgorithm solving the LCL can be transformed into a deterministic $O(\\log\nn)$-time algorithm. Together with a previous result, this establishes that on\ntrees, there are no natural deterministic complexities in the ranges\n$\\omega(\\log^* n)$---$o(\\log n)$ or $\\omega(\\log n)$---$n^{o(1)}$.\n  3. We expose a gap in the randomized time hierarchy on general graphs. Any\nrandomized algorithm that solves an LCL problem in sublogarithmic time can be\nsped up to run in $O(T_{LLL})$ time, which is the complexity of the distributed\nLovasz local lemma problem, currently known to be $\\Omega(\\log\\log n)$ and\n$O(\\log n)$.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 18:49:12 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Chang", "Yi-Jun", ""], ["Pettie", "Seth", ""]]}, {"id": "1704.06302", "submitter": "Gustavo Maciel Dias Vieira", "authors": "Vin\\'icius A. Reis, Gustavo M. D. Vieira", "title": "Quality of Service of an Asynchronous Crash-Recovery Leader Election\n  Algorithm", "comments": "14 pages, published in the Proc. of the 35th Brazilian Symposium on\n  Computer Networks, Belem, Brazil, May 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In asynchronous distributed systems it is very hard to assess if one of the\nprocesses taking part in a computation is operating correctly or has failed. To\novercome this problem, distributed algorithms are created using unreliable\nfailure detectors that capture in an abstract way timing assumptions necessary\nto assess the operating status of a process. One particular type of failure\ndetector is a leader election, that indicates a single process that has not\nfailed. The unreliability of these failure detectors means that they can make\nmistakes, however if they are to be used in practice there must be limits to\nthe eventual behavior of these detectors. These limits are defined as the\nquality of service (QoS) provided by the detector. Many works have tackled the\nproblem of creating failure detectors with predictable QoS, but only for\ncrash-stop processes and synchronous systems. This paper presents and analyzes\nthe behavior of a new leader election algorithm named NFD-L for the\nasynchronous crash-recovery failure model that is efficient in terms of its use\nof stable memory and message exchanges.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 18:58:08 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Reis", "Vin\u00edcius A.", ""], ["Vieira", "Gustavo M. D.", ""]]}, {"id": "1704.06530", "submitter": "Qixia Yuan", "authors": "Andrzej Mizera and Jun Pang and Hongyang Qu and Qixia Yuan", "title": "Taming Asynchrony for Attractor Detection in Large Boolean Networks\n  (Technical Report)", "comments": "28 pages, version 3 (correct a mistake in Table 2)", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.MN cs.DC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Boolean networks is a well-established formalism for modelling biological\nsystems. A vital challenge for analysing a Boolean network is to identify all\nthe attractors. This becomes more challenging for large asynchronous Boolean\nnetworks, due to the asynchronous updating scheme. Existing methods are\nprohibited due to the well-known state-space explosion problem in large Boolean\nnetworks. In this paper, we tackle this challenge by proposing a SCC-based\ndecomposition method. We prove the correctness of our proposed method and\ndemonstrate its efficiency with two real-life biological networks.\n", "versions": [{"version": "v1", "created": "Thu, 20 Apr 2017 16:52:26 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2017 08:39:57 GMT"}, {"version": "v3", "created": "Tue, 13 Jun 2017 13:28:02 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Mizera", "Andrzej", ""], ["Pang", "Jun", ""], ["Qu", "Hongyang", ""], ["Yuan", "Qixia", ""]]}, {"id": "1704.06623", "submitter": "Andr\\'es Goens", "authors": "Andr\\'es Goens, Sergio Siccha, Jeronimo Castrillon", "title": "Symmetry in Software Synthesis", "comments": "31 pages, 18 figures", "journal-ref": "ACM Trans. Archit. Code Optim. 14, 2, Article 20 (July 2017)", "doi": "10.1145/3095747", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the surge of multi- and manycores, much research has focused on\nalgorithms for mapping and scheduling on these complex platforms. Large classes\nof these algorithms face scalability problems. This is why diverse methods are\ncommonly used for reducing the search space. While most such approaches\nleverage the inherent symmetry of architectures and applications, they do it in\na problem-specific and intuitive way. However, intuitive approaches become\nimpractical with growing hardware complexity, like Network-on-Chip interconnect\nor heterogeneous cores. In this paper, we present a formal framework that can\ndetermine the inherent symmetry of architectures and applications\nalgorithmically and leverage these for problems in software synthesis. Our\napproach is based on the mathematical theory of groups and a generalization\ncalled inverse semigroups. We evaluate our approach in two state-of-the-art\nmapping frameworks. Even for the platforms with a handful of cores of today and\nmoderate-size benchmarks, our approach consistently yields reductions of the\noverall execution time of algorithms, accelerating them by a factor up to 10 in\nour experiments, or improving the quality of the results.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 16:36:37 GMT"}], "update_date": "2017-07-27", "authors_parsed": [["Goens", "Andr\u00e9s", ""], ["Siccha", "Sergio", ""], ["Castrillon", "Jeronimo", ""]]}, {"id": "1704.06724", "submitter": "Jakub Nalepa", "authors": "Miroslaw Blocho, Jakub Nalepa", "title": "Complexity Analysis of the Parallel Guided Ejection Search for the\n  Pickup and Delivery Problem with Time Windows", "comments": "4 pages, presented at the Work in Progress Session at PDP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the pessimistic time complexity analysis of the parallel\nalgorithm for minimizing the fleet size in the pickup and delivery problem with\ntime windows. We show how to estimate the pessimistic complexity step by step.\nThis approach can be easily adopted to other parallel algorithms for solving\ncomplex transportation problems.\n", "versions": [{"version": "v1", "created": "Fri, 21 Apr 2017 23:31:44 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Blocho", "Miroslaw", ""], ["Nalepa", "Jakub", ""]]}, {"id": "1704.06738", "submitter": "Peng Sun", "authors": "Peng Sun, Yonggang Wen, Ta Nguyen Binh Duong, Shengen Yan", "title": "Towards Distributed Machine Learning in Shared Clusters: A\n  Dynamically-Partitioned Approach", "comments": null, "journal-ref": null, "doi": "10.1109/SMARTCOMP.2017.7947053", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cluster management systems (CMSs) have been proposed to share a single\ncluster with multiple distributed computing systems. However, none of the\nexisting approaches can handle distributed machine learning (ML) workloads\ngiven the following criteria: high resource utilization, fair resource\nallocation and low sharing overhead. To solve this problem, we propose a new\nCMS named Dorm, incorporating a dynamically-partitioned cluster management\nmechanism and an utilization-fairness optimizer. Specifically, Dorm uses the\ncontainer-based virtualization technique to partition a cluster, runs one\napplication per partition, and can dynamically resize each partition at\napplication runtime for resource efficiency and fairness. Each application\ndirectly launches its tasks on the assigned partition without petitioning for\nresources frequently, so Dorm imposes flat sharing overhead. Extensive\nperformance evaluations showed that Dorm could simultaneously increase the\nresource utilization by a factor of up to 2.32, reduce the fairness loss by a\nfactor of up to 1.52, and speed up popular distributed ML applications by a\nfactor of up to 2.72, compared to existing approaches. Dorm's sharing overhead\nis less than 5% in most cases.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 03:17:18 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Sun", "Peng", ""], ["Wen", "Yonggang", ""], ["Duong", "Ta Nguyen Binh", ""], ["Yan", "Shengen", ""]]}, {"id": "1704.06749", "submitter": "Mohammed ElBamby", "authors": "Mohammed S. Elbamby, Mehdi Bennis, Walid Saad", "title": "Proactive Edge Computing in Latency-Constrained Fog Networks", "comments": "6 pages, 5 figures, accepted in EuCNC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the fundamental problem of distribution and proactive caching\nof computing tasks in fog networks is studied under latency and reliability\nconstraints. In the proposed scenario, computing can be executed either locally\nat the user device or offloaded to an edge cloudlet. Moreover, cloudlets\nexploit both their computing and storage capabilities by proactively caching\npopular task computation results to minimize computing latency. To this end, a\nclustering method to group spatially proximate user devices with mutual task\npopularity interests and their serving cloudlets is proposed. Then, cloudlets\ncan proactively cache the popular tasks' computations of their cluster members\nto minimize computing latency. Additionally, the problem of distributing tasks\nto cloudlets is formulated as a matching game in which a cost function of\ncomputing delay is minimized under latency and reliability constraints.\nSimulation results show that the proposed scheme guarantees reliable\ncomputations with bounded latency and achieves up to 91% decrease in computing\nlatency as compared to baseline schemes.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 05:37:18 GMT"}, {"version": "v2", "created": "Wed, 26 Apr 2017 13:56:42 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Elbamby", "Mohammed S.", ""], ["Bennis", "Mehdi", ""], ["Saad", "Walid", ""]]}, {"id": "1704.06829", "submitter": "Florian Schornbaum", "authors": "Florian Schornbaum, Ulrich R\\\"ude", "title": "Extreme-Scale Block-Structured Adaptive Mesh Refinement", "comments": "38 pages, 17 figures, 11 tables", "journal-ref": "SIAM J. Sci. Comput. 40-3 (2018), pp. C358-C387", "doi": "10.1137/17M1128411", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present a novel approach for block-structured adaptive\nmesh refinement (AMR) that is suitable for extreme-scale parallelism. All data\nstructures are designed such that the size of the meta data in each distributed\nprocessor memory remains bounded independent of the processor number. In all\nstages of the AMR process, we use only distributed algorithms. No central\nresources such as a master process or replicated data are employed, so that an\nunlimited scalability can be achieved. For the dynamic load balancing in\nparticular, we propose to exploit the hierarchical nature of the\nblock-structured domain partitioning by creating a lightweight, temporary copy\nof the core data structure. This copy acts as a local and fully distributed\nproxy data structure. It does not contain simulation data, but only provides\ntopological information about the domain partitioning into blocks. Ultimately,\nthis approach enables an inexpensive, local, diffusion-based dynamic load\nbalancing scheme.\n  We demonstrate the excellent performance and the full scalability of our new\nAMR implementation for two architecturally different petascale supercomputers.\nBenchmarks on an IBM Blue Gene/Q system with a mesh containing 3.7 trillion\nunknowns distributed to 458,752 processes confirm the applicability for future\nextreme-scale parallel machines. The algorithms proposed in this article\noperate on blocks that result from the domain partitioning. This concept and\nits realization support the storage of arbitrary data. In consequence, the\nsoftware framework can be used for different simulation methods, including mesh\nbased and meshless methods. In this article, we demonstrate fluid simulations\nbased on the lattice Boltzmann method.\n", "versions": [{"version": "v1", "created": "Sat, 22 Apr 2017 18:21:36 GMT"}, {"version": "v2", "created": "Wed, 27 Sep 2017 22:03:08 GMT"}, {"version": "v3", "created": "Fri, 13 Apr 2018 18:54:16 GMT"}], "update_date": "2018-07-24", "authors_parsed": [["Schornbaum", "Florian", ""], ["R\u00fcde", "Ulrich", ""]]}, {"id": "1704.06976", "submitter": "Zhe Zhang", "authors": "Zhe Zhang and Brian Bockelman", "title": "Exploring compression techniques for ROOT IO", "comments": "Proceedings for 22nd International Conference on Computing in High\n  Energy and Nuclear Physics (CHEP 2016)", "journal-ref": null, "doi": "10.1088/1742-6596/898/7/072043", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  ROOT provides an flexible format used throughout the HEP community. The\nnumber of use cases - from an archival data format to end-stage analysis - has\nrequired a number of tradeoffs to be exposed to the user. For example, a high\n\"compression level\" in the traditional DEFLATE algorithm will result in a\nsmaller file (saving disk space) at the cost of slower decompression (costing\nCPU time when read). At the scale of the LHC experiment, poor design choices\ncan result in terabytes of wasted space or wasted CPU time. We explore and\nattempt to quantify some of these tradeoffs. Specifically, we explore: the use\nof alternate compressing algorithms to optimize for read performance; an\nalternate method of compressing individual events to allow efficient random\naccess; and a new approach to whole-file compression. Quantitative results are\ngiven, as well as guidance on how to make compression decisions for different\nuse cases.\n", "versions": [{"version": "v1", "created": "Sun, 23 Apr 2017 20:37:11 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Zhang", "Zhe", ""], ["Bockelman", "Brian", ""]]}, {"id": "1704.07004", "submitter": "Hanwen Wu", "authors": "Hanwen Wu and Hongwei Xi", "title": "Dependent Session Types", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Session types offer a type-based discipline for enforcing communication\nprotocols in distributed programming. We have previously formalized simple\nsession types in the setting of multi-threaded $\\lambda$-calculus with linear\ntypes. In this work, we build upon our earlier work by presenting a form of\ndependent session types (of DML-style). The type system we formulate provides\nlinearity and duality guarantees with no need for any runtime checks or special\nencodings. Our formulation of dependent session types is the first of its kind,\nand it is particularly suitable for practical implementation. As an example, we\ndescribe one implementation written in ATS that compiles to an Erlang/Elixir\nback-end.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 00:33:36 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Wu", "Hanwen", ""], ["Xi", "Hongwei", ""]]}, {"id": "1704.07133", "submitter": "Stephan Holzer", "authors": "Stephan Holzer and Nancy Lynch", "title": "Beeping a Maximal Independent Set Fast", "comments": "Full version of a brief announcement with the same title that\n  appeared at the 30th International Symposium on Distributed Computing (DISC),\n  Paris, France, September 2016. 17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We adapt a recent algorithm by Ghaffari [SODA'16] for computing a Maximal\nIndependent Set in the LOCAL model, so that it works in the significantly\nweaker BEEP model. For networks with maximum degree $\\Delta$, our algorithm\nterminates locally within time $O((\\log \\Delta + \\log (1/\\epsilon)) \\cdot\n\\log(1/\\epsilon))$, with probability at least $1 - \\epsilon$. The key idea of\nthe modification is to replace explicit messages about transmission\nprobabilities with estimates based on the number of received messages.\n  After the successful introduction (and implicit use) of local analysis, e.g.,\nby Barenboim et al. [JACM'16], Chung et al. [PODC'14], Ghaffari [SODA'16], and\nHalldorsson et al. [PODC'15], we study this concept in the BEEP model for the\nfirst time.\n  By doing so, we improve over local bounds that are implicitly derived from\nprevious work (that uses traditional global analysis) on computing a Maximal\nIndependent Set in the \\beep model for a large range of values of the parameter\n$\\Delta$. At the same time, we show that our algorithm in the \\beep model only\nneeds to pay a $\\log(1/\\epsilon)$ factor in the runtime compared to the best\nknown MIS algorithm in the much more powerful \\local model. We demonstrate that\nthis overhead is negligible, as communication via beeps can be implemented\nusing significantly less resources than communication in the LOCAL model. In\nparticular, when looking at implementing these models, one round of the \\local\nmodel needs at least $O(\\Delta)$ time units, while one round in the BEEP model\nneeds $O(\\log\\Delta)$ time units, an improvement that diminishes the loss of a\n$\\log(1/\\epsilon)$ factor in most settings.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 10:42:37 GMT"}], "update_date": "2017-04-25", "authors_parsed": [["Holzer", "Stephan", ""], ["Lynch", "Nancy", ""]]}, {"id": "1704.07234", "submitter": "Natalia Chechina", "authors": "Phil Trinder, Natalia Chechina, Nikolaos Papaspyrou, Konstantinos\n  Sagonas, Simon Thompson, Stephen Adams, Stavros Aronis, Robert Baker, Eva\n  Bihari, Olivier Boudeville, Francesco Cesarini, Maurizio Di Stefano, Sverker\n  Eriksson, Viktoria Fordos, Amir Ghaffari, Aggelos Giantsios, Rickard Green,\n  Csaba Hoch, David Klaftenegger, Huiqing Li, Kenneth Lundin, Kenneth\n  Mackenzie, Katerina Roukounaki, Yiannis Tsiouris, Kjell Winblad", "title": "Scaling Reliably: Improving the Scalability of the Erlang Distributed\n  Actor Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed actor languages are an effective means of constructing scalable\nreliable systems, and the Erlang programming language has a well-established\nand influential model. While Erlang model conceptually provides reliable\nscalability, it has some inherent scalability limits and these force developers\nto depart from the model at scale. This article establishes the scalability\nlimits of Erlang systems, and reports the work to improve the language\nscalability.\n  We systematically study the scalability limits of Erlang and address the\nissues at the virtual machine (VM), language, and tool levels. More\nspecifically: (1) We have evolved the Erlang VM so that it can work effectively\nin large scale single-host multicore and NUMA architectures. We have made\nimportant architectural improvements to the Erlang/OTP. (2) We have designed\nand implemented Scalable Distributed (SD) Erlang libraries to address\nlanguage-level scalability issues, and provided and validated a set of\nsemantics for the new language constructs. (3) To make large Erlang systems\neasier to deploy, monitor, and debug we have developed and made open source\nreleases of five complementary tools, some specific to SD Erlang.\n  Throughout the article we use two case studies to investigate the\ncapabilities of our new technologies and tools: a distributed hash table based\nOrbit calculation and Ant Colony Optimisation (ACO). Chaos Monkey experiments\nshow that two versions of ACO survive random process failure and hence that SD\nErlang preserves the Erlang reliability model. Even for programs with no global\nrecovery data to maintain, SD Erlang partitions the network to reduce network\ntraffic and hence improves performance of the Orbit and ACO benchmarks above 80\nhosts. ACO measurements show that maintaining global recovery data dramatically\nlimits scalability; however scalability is recovered by partitioning the\nrecovery data.\n", "versions": [{"version": "v1", "created": "Mon, 24 Apr 2017 13:52:28 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 09:35:43 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Trinder", "Phil", ""], ["Chechina", "Natalia", ""], ["Papaspyrou", "Nikolaos", ""], ["Sagonas", "Konstantinos", ""], ["Thompson", "Simon", ""], ["Adams", "Stephen", ""], ["Aronis", "Stavros", ""], ["Baker", "Robert", ""], ["Bihari", "Eva", ""], ["Boudeville", "Olivier", ""], ["Cesarini", "Francesco", ""], ["Di Stefano", "Maurizio", ""], ["Eriksson", "Sverker", ""], ["Fordos", "Viktoria", ""], ["Ghaffari", "Amir", ""], ["Giantsios", "Aggelos", ""], ["Green", "Rickard", ""], ["Hoch", "Csaba", ""], ["Klaftenegger", "David", ""], ["Li", "Huiqing", ""], ["Lundin", "Kenneth", ""], ["Mackenzie", "Kenneth", ""], ["Roukounaki", "Katerina", ""], ["Tsiouris", "Yiannis", ""], ["Winblad", "Kjell", ""]]}, {"id": "1704.07649", "submitter": "Grzegorz Stachowiak", "authors": "Leszek Gasieniec and Grzegorz Stachowiak", "title": "Fast Space Optimal Leader Election in Population Protocols", "comments": "21 pages, 2 figures, published in SODA 2018 proceedings", "journal-ref": null, "doi": "10.1137/1.9781611975031.169", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The model of population protocols refers to the growing in popularity\ntheoretical framework suitable for studying pairwise interactions within a\nlarge collection of simple indistinguishable entities, frequently called\nagents. In this paper the emphasis is on the space complexity in fast leader\nelection via population protocols governed by the random scheduler, which\nuniformly at random selects pairwise interactions within the population of n\nagents.\n  The main result of this paper is a new fast and space optimal leader election\nprotocol. The new protocol utilises O(log^2 n) parallel time (which is\nequivalent to O(n log^2 n) sequential pairwise interactions), and each agent\noperates on O(log log n) states. This double logarithmic space usage matches\nasymptotically the lower bound 1/2 log log n on the minimal number of states\nrequired by agents in any leader election algorithm with the running time\no(n/polylog n).\n  Our solution takes an advantage of the concept of phase clocks, a fundamental\nsynchronisation and coordination tool in distributed computing. We propose a\nnew fast and robust population protocol for initialisation of phase clocks to\nbe run simultaneously in multiple modes and intertwined with the leader\nelection process. We also provide the reader with the relevant formal\nargumentation indicating that our solution is always correct, and fast with\nhigh probability.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 11:57:01 GMT"}, {"version": "v2", "created": "Thu, 18 May 2017 11:54:52 GMT"}, {"version": "v3", "created": "Tue, 27 Mar 2018 11:47:52 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Gasieniec", "Leszek", ""], ["Stachowiak", "Grzegorz", ""]]}, {"id": "1704.07807", "submitter": "Ming Yan", "authors": "Zhi Li and Wei Shi and Ming Yan", "title": "A decentralized proximal-gradient method with network independent\n  step-sizes and separated convergence rates", "comments": null, "journal-ref": "IEEE Transactions on Signal Processing, 67 (2019), 4494-4506", "doi": "10.1109/TSP.2019.2926022", "report-no": null, "categories": "math.OC cs.DC cs.LG cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a novel proximal-gradient algorithm for a decentralized\noptimization problem with a composite objective containing smooth and\nnon-smooth terms. Specifically, the smooth and nonsmooth terms are dealt with\nby gradient and proximal updates, respectively. The proposed algorithm is\nclosely related to a previous algorithm, PG-EXTRA \\cite{shi2015proximal}, but\nhas a few advantages. First of all, agents use uncoordinated step-sizes, and\nthe stable upper bounds on step-sizes are independent of network topologies.\nThe step-sizes depend on local objective functions, and they can be as large as\nthose of the gradient descent. Secondly, for the special case without\nnon-smooth terms, linear convergence can be achieved under the strong convexity\nassumption. The dependence of the convergence rate on the objective functions\nand the network are separated, and the convergence rate of the new algorithm is\nas good as one of the two convergence rates that match the typical rates for\nthe general gradient descent and the consensus averaging. We provide numerical\nexperiments to demonstrate the efficacy of the introduced algorithm and\nvalidate our theoretical discoveries.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 17:36:15 GMT"}, {"version": "v2", "created": "Tue, 18 Jun 2019 02:26:10 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Li", "Zhi", ""], ["Shi", "Wei", ""], ["Yan", "Ming", ""]]}, {"id": "1704.07883", "submitter": "Eric Goubault", "authors": "Eric Goubault and Sergio Rajsbaum", "title": "Models of fault-tolerant distributed computation via dynamic epistemic\n  logic", "comments": "arXiv admin note: text overlap with arXiv:1703.11005", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO cs.MA math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computability power of a distributed computing model is determined by the\ncommunication media available to the processes, the timing assumptions about\nprocesses and communication, and the nature of failures that processes can\nsuffer. In a companion paper we showed how dynamic epistemic logic can be used\nto give a formal semantics to a given distributed computing model, to capture\nprecisely the knowledge needed to solve a distributed task, such as consensus.\nFurthermore, by moving to a dual model of epistemic logic defined by simplicial\ncomplexes, topological invariants are exposed, which determine task\nsolvability. In this paper we show how to extend the setting above to include\nin the knowledge of the processes, knowledge about the model of computation\nitself. The extension describes the knowledge processes gain about the current\nexecution, in problems where processes have no input values at all.\n", "versions": [{"version": "v1", "created": "Tue, 25 Apr 2017 19:44:49 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Goubault", "Eric", ""], ["Rajsbaum", "Sergio", ""]]}, {"id": "1704.08065", "submitter": "Marios Isaakidis", "authors": "Carmela Troncoso, Marios Isaakidis, George Danezis, and Harry Halpin", "title": "Systematizing Decentralization and Privacy: Lessons from 15 Years of\n  Research and Deployments", "comments": null, "journal-ref": "Proceedings on Privacy Enhancing Technologies (2017) 307-329", "doi": "10.1515/popets-2017-0052", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Decentralized systems are a subset of distributed systems where multiple\nauthorities control different components and no authority is fully trusted by\nall. This implies that any component in a decentralized system is potentially\nadversarial. We revise fifteen years of research on decentralization and\nprivacy, and provide an overview of key systems, as well as key insights for\ndesigners of future systems. We show that decentralized designs can enhance\nprivacy, integrity, and availability but also require careful trade-offs in\nterms of system complexity, properties provided, and degree of\ndecentralization. These trade-offs need to be understood and navigated by\ndesigners. We argue that a combination of insights from cryptography,\ndistributed systems, and mechanism design, aligned with the development of\nadequate incentives, are necessary to build scalable and successful\nprivacy-preserving decentralized systems.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 11:40:55 GMT"}, {"version": "v2", "created": "Wed, 21 Jun 2017 11:54:31 GMT"}, {"version": "v3", "created": "Wed, 28 Jun 2017 13:23:54 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Troncoso", "Carmela", ""], ["Isaakidis", "Marios", ""], ["Danezis", "George", ""], ["Halpin", "Harry", ""]]}, {"id": "1704.08239", "submitter": "Ivy Bo Peng", "authors": "Ivy Bo Peng, Stefano Markidis, Erwin Laure, Gokcen Kestor, Roberto\n  Gioiosa", "title": "Exploring Application Performance on Emerging Hybrid-Memory\n  Supercomputers", "comments": "18th International Conference on High Performance Computing and\n  Communications, IEEE, 2016", "journal-ref": null, "doi": "10.1109/HPCC-SmartCity-DSS.2016.0074", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next-generation supercomputers will feature more hierarchical and\nheterogeneous memory systems with different memory technologies working\nside-by-side. A critical question is whether at large scale existing HPC\napplications and emerging data-analytics workloads will have performance\nimprovement or degradation on these systems. We propose a systematic and fair\nmethodology to identify the trend of application performance on emerging\nhybrid-memory systems. We model the memory system of next-generation\nsupercomputers as a combination of \"fast\" and \"slow\" memories. We then analyze\nperformance and dynamic execution characteristics of a variety of workloads,\nfrom traditional scientific applications to emerging data analytics to compare\ntraditional and hybrid-memory systems. Our results show that data analytics\napplications can clearly benefit from the new system design, especially at\nlarge scale. Moreover, hybrid-memory systems do not penalize traditional\nscientific applications, which may also show performance improvement.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 17:49:14 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Peng", "Ivy Bo", ""], ["Markidis", "Stefano", ""], ["Laure", "Erwin", ""], ["Kestor", "Gokcen", ""], ["Gioiosa", "Roberto", ""]]}, {"id": "1704.08244", "submitter": "Ivy Bo Peng", "authors": "Ivy Bo Peng, Stefano Markidis, Erwin Laure, Gokcen Kestor, Roberto\n  Gioiosa", "title": "Idle Period Propagation in Message-Passing Applications", "comments": "18th International Conference on High Performance Computing and\n  Communications, IEEE, 2016", "journal-ref": null, "doi": "10.1109/HPCC-SmartCity-DSS.2016.0134", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Idle periods on different processes of Message Passing applications are\nunavoidable. While the origin of idle periods on a single process is well\nunderstood as the effect of system and architectural random delays, yet it is\nunclear how these idle periods propagate from one process to another. It is\nimportant to understand idle period propagation in Message Passing applications\nas it allows application developers to design communication patterns avoiding\nidle period propagation and the consequent performance degradation in their\napplications. To understand idle period propagation, we introduce a methodology\nto trace idle periods when a process is waiting for data from a remote delayed\nprocess in MPI applications. We apply this technique in an MPI application that\nsolves the heat equation to study idle period propagation on three different\nsystems. We confirm that idle periods move between processes in the form of\nwaves and that there are different stages in idle period propagation. Our\nmethodology enables us to identify a self-synchronization phenomenon that\noccurs on two systems where some processes run slower than the other processes.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 17:58:28 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Peng", "Ivy Bo", ""], ["Markidis", "Stefano", ""], ["Laure", "Erwin", ""], ["Kestor", "Gokcen", ""], ["Gioiosa", "Roberto", ""]]}, {"id": "1704.08273", "submitter": "Ivy Bo Peng", "authors": "Ivy Bo Peng, Roberto Gioiosa, Gokcen Kestor, Erwin Laure and Stefano\n  Markidis", "title": "Exploring the Performance Benefit of Hybrid Memory System on HPC\n  Environments", "comments": null, "journal-ref": null, "doi": "10.1109/IPDPSW.2017.115", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware accelerators have become a de-facto standard to achieve high\nperformance on current supercomputers and there are indications that this trend\nwill increase in the future. Modern accelerators feature high-bandwidth memory\nnext to the computing cores. For example, the Intel Knights Landing (KNL)\nprocessor is equipped with 16 GB of high-bandwidth memory (HBM) that works\ntogether with conventional DRAM memory. Theoretically, HBM can provide 5x\nhigher bandwidth than conventional DRAM. However, many factors impact the\neffective performance achieved by applications, including the application\nmemory access pattern, the problem size, the threading level and the actual\nmemory configuration. In this paper, we analyze the Intel KNL system and\nquantify the impact of the most important factors on the application\nperformance by using a set of applications that are representative of\nscientific and data-analytics workloads. Our results show that applications\nwith regular memory access benefit from MCDRAM, achieving up to 3x performance\nwhen compared to the performance obtained using only DRAM. On the contrary,\napplications with random memory access pattern are latency-bound and may suffer\nfrom performance degradation when using only MCDRAM. For those applications,\nthe use of additional hardware threads may help hide latency and achieve higher\naggregated bandwidth when using HBM.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 18:10:57 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Peng", "Ivy Bo", ""], ["Gioiosa", "Roberto", ""], ["Kestor", "Gokcen", ""], ["Laure", "Erwin", ""], ["Markidis", "Stefano", ""]]}, {"id": "1704.08343", "submitter": "James Ross", "authors": "David Richie, James Ross, Jamie Infantolino", "title": "A Distributed Shared Memory Model and C++ Templated Meta-Programming\n  Interface for the Epiphany RISC Array Processor", "comments": "10 pages, 2 figures, ICCS/ALCHEMY Workshop 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Adapteva Epiphany many-core architecture comprises a scalable 2D mesh\nNetwork-on-Chip (NoC) of low-power RISC cores with minimal uncore\nfunctionality. Whereas such a processor offers high computational energy\nefficiency and parallel scalability, developing effective programming models\nthat address the unique architecture features has presented many challenges. We\npresent here a distributed shared memory (DSM) model supported in software\ntransparently using C++ templated metaprogramming techniques. The approach\noffers an extremely simple parallel programming model well suited for the\narchitecture. Initial results are presented that demonstrate the approach and\nprovide insight into the efficiency of the programming model and also the\nability of the NoC to support a DSM without explicit control over data movement\nand localization.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 20:38:57 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Richie", "David", ""], ["Ross", "James", ""], ["Infantolino", "Jamie", ""]]}, {"id": "1704.08364", "submitter": "Eduardo Miqueles Dr.", "authors": "Gilberto Martinez Jr., Janito V. Ferreira Filho, Eduardo X. Miqueles", "title": "Low-complexity Distributed Tomographic Backprojection for large datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this manuscript we present a fast GPU implementation for tomographic\nreconstruction of large datasets using data obtained at the Brazilian\nsynchrotron light source. The algorithm is distributed in a cluster with 4 GPUs\nthrough a fast pipeline implemented in C programming language. Our algorithm is\ntheoretically based on a recently discovered low complexity formula, computing\nthe total volume within O(N3logN) floating point operations; much less than\ntraditional algorithms that operates with O(N4) flops over an input data of\nsize O(N3). The results obtained with real data indicate that a reconstruction\ncan be achieved within 1 second provided the data is transferred completely to\nthe memory.\n", "versions": [{"version": "v1", "created": "Wed, 26 Apr 2017 22:18:34 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Martinez", "Gilberto", "Jr."], ["Filho", "Janito V. Ferreira", ""], ["Miqueles", "Eduardo X.", ""]]}, {"id": "1704.08492", "submitter": "Sergio Rivas-Gomez", "authors": "Sergio Rivas-Gomez, Stefano Markidis, Ivy Bo Peng, Erwin Laure, Gokcen\n  Kestor, Roberto Gioiosa", "title": "Extending Message Passing Interface Windows to Storage", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents an extension to MPI supporting the one-sided communication\nmodel and window allocations in storage. Our design transparently integrates\nwith the current MPI implementations, enabling applications to target MPI\nwindows in storage, memory or both simultaneously, without major modifications.\nInitial performance results demonstrate that the presented MPI window extension\ncould potentially be helpful for a wide-range of use-cases and with\nlow-overhead.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 09:56:34 GMT"}], "update_date": "2017-04-28", "authors_parsed": [["Rivas-Gomez", "Sergio", ""], ["Markidis", "Stefano", ""], ["Peng", "Ivy Bo", ""], ["Laure", "Erwin", ""], ["Kestor", "Gokcen", ""], ["Gioiosa", "Roberto", ""]]}, {"id": "1704.08713", "submitter": "Barun Gorain", "authors": "Barun Gorain and Andrzej Pelc", "title": "Finding the Size and the Diameter of a Radio Network Using Short Labels", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The number of nodes of a network, called its size, and the largest distance\nbetween nodes of a network, called its diameter, are among the most important\nnetwork parameters. Knowing the size and/or diameter is a prerequisite of many\ndistributed network algorithms. A radio network is a collection of nodes, with\nwireless transmission and receiving capabilities. It is modeled as a simple\nundirected graph whose nodes communicate in synchronous rounds. In each round,\na node can either transmit a message to all its neighbors, or stay silent and\nlisten. At the receiving end, a node $v$ hears a message from a neighbor $w$ in\na round $i$, if $v$ listens in round $i$, and if $w$ is its only neighbor that\ntransmits in round $i$. If $v$ listens in a round, and multiple neighbors of\n$v$ transmit in this round, a collision occurs at $v$. If $v$ transmits in a\nround, it does not hear anything. If listening nodes can distinguish collision\nfrom silence, we say that the network has collision detection capability,\notherwise there is no collision detection. We consider the tasks of size\ndiscovery and diameter discovery: finding the size (resp. the diameter) of an\nunknown radio network with collision detection. All nodes have to output the\nsize (resp. the diameter) of the network, using a deterministic algorithm.\nNodes have labels which are binary strings. The length of a labeling scheme is\nthe largest length of a label. We concentrate on the following problems:\n  1. What is the shortest labeling scheme that permits size discovery in all\nradio networks of maximum degree $\\Delta$? 2. What is the shortest labeling\nscheme that permits diameter discovery in all radio networks?\n  We show that the minimum length of a labeling scheme that permits size\ndiscovery is $\\Theta(\\log\\log \\Delta)$. By contrast, we show that diameter\ndiscovery can be done using a labeling scheme of constant length.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 18:46:18 GMT"}, {"version": "v2", "created": "Wed, 11 Nov 2020 17:05:32 GMT"}], "update_date": "2020-11-12", "authors_parsed": [["Gorain", "Barun", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1704.08738", "submitter": "Prateek Sharma", "authors": "Prateek Sharma, David Irwin, Prashant Shenoy", "title": "Portfolio-driven Resource Management for Transient Cloud Servers", "comments": null, "journal-ref": "Proceedings of the ACM Series on Computing Systems Modeling,\n  Measurement and Evaluation. 2017. Volume 1, Series 1, Article 1", "doi": "10.1145/3084442", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud providers have begun to offer their surplus capacity in the form of\nlow-cost transient servers, which can be revoked unilaterally at any time.\nWhile the low cost of transient servers makes them attractive for a wide range\nof applications, such as data processing and scientific computing, failures due\nto server revocation can severely degrade application performance. Since\ndifferent transient server types offer different cost and availability\ntradeoffs, we present the notion of server portfolios that is based on\nfinancial portfolio modeling. Server portfolios enable construction of an\n\"optimal\" mix of severs to meet an application's sensitivity to cost and\nrevocation risk. We implement model-driven portfolios in a system called\nExoSphere, and show how diverse applications can use portfolios and\napplication-specific policies to gracefully handle transient servers. We show\nthat ExoSphere enables widely-used parallel applications such as Spark, MPI,\nand BOINC to be made transiency-aware with modest effort. Our experiments show\nthat allowing the applications to use suitable transiency-aware policies,\nExoSphere is able to achieve 80\\% cost savings when compared to on-demand\nservers and greatly reduces revocation risk compared to existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 27 Apr 2017 20:33:14 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Sharma", "Prateek", ""], ["Irwin", "David", ""], ["Shenoy", "Prashant", ""]]}, {"id": "1704.08880", "submitter": "Andrzej Pelc", "authors": "Andrzej Pelc", "title": "Deterministic Gathering with Crash Faults", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A team consisting of an unknown number of mobile agents, starting from\ndifferent nodes of an unknown network, have to meet at the same node and\nterminate. This problem is known as {\\em gathering}. We study deterministic\ngathering algorithms under the assumption that agents are subject to {\\em crash\nfaults} which can occur at any time. Two fault scenarios are considered. A {\\em\nmotion fault} immobilizes the agent at a node or inside an edge but leaves\nintact its memory at the time when the fault occurred. A more severe {\\em total\nfault} immobilizes the agent as well, but also erases its entire memory. Of\ncourse, we cannot require faulty agents to gather. Thus the gathering problem\nfor fault prone agents calls for all fault-free agents to gather at a single\nnode, and terminate.\n  When agents move completely asynchronously, gathering with crash faults of\nany type is impossible. Hence we consider a restricted version of asynchrony,\nwhere each agent is assigned by the adversary a fixed speed, possibly different\nfor each agent. Agents have clocks ticking at the same rate. Each agent can\nwait for a time of its choice at any node, or decide to traverse an edge but\nthen it moves at constant speed assigned to it. Moreover, agents have different\nlabels. Each agent knows its label and speed but not those of other agents.\n  We construct a gathering algorithm working for any team of at least two\nagents in the scenario of motion faults, and a gathering algorithm working in\nthe presence of total faults, provided that at least two agents are fault free\nall the time. If only one agent is fault free, the task of gathering with total\nfaults is sometimes impossible. Both our algorithms work in time polynomial in\nthe size of the graph, in the logarithm of the largest label, in the inverse of\nthe smallest speed, and in the ratio between the largest and the smallest\nspeed.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 11:29:23 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Pelc", "Andrzej", ""]]}]