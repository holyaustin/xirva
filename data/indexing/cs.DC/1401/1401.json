[{"id": "1401.0034", "submitter": "Atta ur Rehman Khan", "authors": "Atta ur Rehman Khan, Mazliza Othman, Abdul Nasir Khan", "title": "A Novel Application Licensing Framework for Mobile Cloud Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile cloud computing is a new technology that enhances smartphone\napplications capabilities in terms of performance, energy efficiency, and\nexecution support. These features are achieved via computation offloading\ntechnique that is supported by specialized mobile cloud application development\nmodels. However, the cloud-enabled applications are prone to application piracy\nissue for which the traditional licensing frameworks are of no use. Therefore,\na new licensing framework is required to control application piracy in mobile\ncloud environment. This paper presents a preliminary design of a novel\napplication licensing framework for mobile cloud environment that restricts\nexecution of applications on unauthenticated smartphones and cloud resources.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 21:59:30 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Khan", "Atta ur Rehman", ""], ["Othman", "Mazliza", ""], ["Khan", "Abdul Nasir", ""]]}, {"id": "1401.0042", "submitter": "Grigory Yaroslavtsev", "authors": "Alexandr Andoni, Aleksandar Nikolov, Krzysztof Onak, Grigory\n  Yaroslavtsev", "title": "Parallel Algorithms for Geometric Graph Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give algorithms for geometric graph problems in the modern parallel models\ninspired by MapReduce. For example, for the Minimum Spanning Tree (MST) problem\nover a set of points in the two-dimensional space, our algorithm computes a\n$(1+\\epsilon)$-approximate MST. Our algorithms work in a constant number of\nrounds of communication, while using total space and communication proportional\nto the size of the data (linear space and near linear time algorithms). In\ncontrast, for general graphs, achieving the same result for MST (or even\nconnectivity) remains a challenging open problem, despite drawing significant\nattention in recent years.\n  We develop a general algorithmic framework that, besides MST, also applies to\nEarth-Mover Distance (EMD) and the transportation cost problem. Our algorithmic\nframework has implications beyond the MapReduce model. For example it yields a\nnew algorithm for computing EMD cost in the plane in near-linear time,\n$n^{1+o_\\epsilon(1)}$. We note that while recently Sharathkumar and Agarwal\ndeveloped a near-linear time algorithm for $(1+\\epsilon)$-approximating EMD,\nour algorithm is fundamentally different, and, for example, also solves the\ntransportation (cost) problem, raised as an open question in their work.\nFurthermore, our algorithm immediately gives a $(1+\\epsilon)$-approximation\nalgorithm with $n^{\\delta}$ space in the streaming-with-sorting model with\n$1/\\delta^{O(1)}$ passes. As such, it is tempting to conjecture that the\nparallel models may also constitute a concrete playground in the quest for\nefficient algorithms for EMD (and other similar problems) in the vanilla\nstreaming model, a well-known open problem.\n", "versions": [{"version": "v1", "created": "Mon, 30 Dec 2013 22:34:56 GMT"}, {"version": "v2", "created": "Sat, 4 Jan 2014 05:57:47 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Andoni", "Alexandr", ""], ["Nikolov", "Aleksandar", ""], ["Onak", "Krzysztof", ""], ["Yaroslavtsev", "Grigory", ""]]}, {"id": "1401.0102", "submitter": "Mahdi Zamani", "authors": "Mahdi Zamani and Mahnush Movahedi and Mohammad Ebadzadeh and Hossein\n  Pedram", "title": "A DDoS-Aware IDS Model Based on Danger Theory and Mobile Agents", "comments": "10 pages, 3 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.CR cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose an artificial immune model for intrusion detection in distributed\nsystems based on a relatively recent theory in immunology called Danger theory.\nBased on Danger theory, immune response in natural systems is a result of\nsensing corruption as well as sensing unknown substances. In contrast,\ntraditional self-nonself discrimination theory states that immune response is\nonly initiated by sensing nonself (unknown) patterns. Danger theory solves many\nproblems that could only be partially explained by the traditional model.\nAlthough the traditional model is simpler, such problems result in high false\npositive rates in immune-inspired intrusion detection systems. We believe using\ndanger theory in a multi-agent environment that computationally emulates the\nbehavior of natural immune systems is effective in reducing false positive\nrates. We first describe a simplified scenario of immune response in natural\nsystems based on danger theory and then, convert it to a computational model as\na network protocol. In our protocol, we define several immune signals and model\ncell signaling via message passing between agents that emulate cells. Most\nmessages include application-specific patterns that must be meaningfully\nextracted from various system properties. We show how to model these messages\nin practice by performing a case study on the problem of detecting distributed\ndenial-of-service attacks in wireless sensor networks. We conduct a set of\nsystematic experiments to find a set of performance metrics that can accurately\ndistinguish malicious patterns. The results indicate that the system can be\nefficiently used to detect malicious patterns with a high level of accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 31 Dec 2013 06:18:18 GMT"}, {"version": "v2", "created": "Fri, 28 Feb 2014 22:07:13 GMT"}, {"version": "v3", "created": "Sun, 28 Dec 2014 05:14:01 GMT"}], "update_date": "2014-12-30", "authors_parsed": [["Zamani", "Mahdi", ""], ["Movahedi", "Mahnush", ""], ["Ebadzadeh", "Mohammad", ""], ["Pedram", "Hossein", ""]]}, {"id": "1401.0355", "submitter": "Liya Fan", "authors": "Liya Fan, Bo Gao, Xi Sun, Fa Zhang and Zhiyong Liu", "title": "Improving the Load Balance of MapReduce Operations based on the Key\n  Distribution of Pairs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Load balance is important for MapReduce to reduce job duration, increase\nparallel efficiency, etc. Previous work focuses on coarse-grained scheduling.\nThis study concerns fine-grained scheduling on MapReduce operations. Each\noperation represents one invocation of the Map or Reduce function. Scheduling\nMapReduce operations is difficult due to highly screwed operation loads, no\nsupport to collect workload statistics, and high complexity of the scheduling\nproblem. So current implementations adopt simple strategies, leading to poor\nload balance. To address these difficulties, we design an algorithm to schedule\noperations based on the key distribution of intermediate pairs. The algorithm\ninvolves a sub-program for selecting operations for task slots, and we name it\nthe Balanced Subset Sum (BSS) problem. We discuss properties of BSS and design\nexact and approximation algorithms for it. To transparently incorporate these\nalgorithms into MapReduce, we design a communication mechanism to collect\nstatistics, and a pipeline within Reduce tasks to increase resource\nutilization. To the best of our knowledge, this is the first work on scheduling\nMapReduce workload at this fine-grained level. Experiments on PUMA [T+12]\nbenchmarks show consistent performance improvement. The job duration can be\nreduced by up to 37%, compared with standard MapReduce.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2014 01:42:23 GMT"}, {"version": "v2", "created": "Mon, 14 Apr 2014 03:35:22 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Fan", "Liya", ""], ["Gao", "Bo", ""], ["Sun", "Xi", ""], ["Zhang", "Fa", ""], ["Liu", "Zhiyong", ""]]}, {"id": "1401.0396", "submitter": "Marek Piotr\\'ow", "authors": "Marek Piotr\\'ow", "title": "Faster 3-Periodic Merging Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of merging two sorted sequences on a comparator\nnetwork that is used repeatedly, that is, if the output is not sorted, the\nnetwork is applied again using the output as input. The challenging task is to\nconstruct such networks of small depth. The first constructions of merging\nnetworks with a constant period were given by Kuty{\\l}owski, Lory\\'s and\nOesterdikhoff. They have given $3$-periodic network that merges two sorted\nsequences of $N$ numbers in time $12\\log N$ and a similar network of period $4$\nthat works in $5.67\\log N$. We present a new family of such networks that are\nbased on Canfield and Williamson periodic sorter. Our $3$-periodic merging\nnetworks work in time upper-bounded by $6\\log N$. The construction can be\neasily generalized to larger constant periods with decreasing running time, for\nexample, to $4$-periodic ones that work in time upper-bounded by $4\\log N$.\nMoreover, to obtain the facts we have introduced a new proof technique.\n", "versions": [{"version": "v1", "created": "Thu, 2 Jan 2014 09:24:17 GMT"}], "update_date": "2014-01-03", "authors_parsed": [["Piotr\u00f3w", "Marek", ""]]}, {"id": "1401.0608", "submitter": "Ali Sheharyar", "authors": "Ali Sheharyar, Othmane Bouhali", "title": "A Framework for Creating a Distributed Rendering Environment on the\n  Compute Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses the deployment of existing render farm manager in a\ntypical compute cluster environment such as a university. Usually, both a\nrender farm and a compute cluster use different queue managers and assume total\ncontrol over the physical resources. But, taking out the physical resources\nfrom an existing compute cluster in a university-like environment whose primary\nuse of the cluster is to run numerical simulations may not be possible. It can\npotentially reduce the overall resource utilization in a situation where\ncompute tasks are more than rendering tasks. Moreover, it can increase the\nsystem administration cost. In this paper, a framework has been proposed that\ncreates a dynamic distributed rendering environment on top of the compute\nclusters using existing render farm managers without requiring the physical\nseparation of the resources.\n", "versions": [{"version": "v1", "created": "Fri, 3 Jan 2014 08:48:25 GMT"}], "update_date": "2014-01-06", "authors_parsed": [["Sheharyar", "Ali", ""], ["Bouhali", "Othmane", ""]]}, {"id": "1401.0763", "submitter": "Sparsh Mittal", "authors": "Sparsh Mittal", "title": "A Study of Successive Over-relaxation Method Parallelization Over Modern\n  HPC Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Successive over-relaxation (SOR) is a computationally intensive, yet\nextremely important iterative solver for solving linear systems. Due to recent\ntrends of exponential growth in amount of data generated and increasing problem\nsizes, serial platforms have proved to be insufficient in providing the\nrequired computational power. In this paper, we present parallel\nimplementations of red-black SOR method using three modern programming\nlanguages namely Chapel, D and Go. We employ SOR method for solving 2D\nsteady-state heat conduction problem. We discuss the optimizations incorporated\nand the features of these languages which are crucial for improving the program\nperformance. Experiments have been performed using 2, 4, and 8 threads and\nperformance results are compared with serial execution. The analysis of results\nprovides important insights into working of SOR method.\n", "versions": [{"version": "v1", "created": "Sat, 4 Jan 2014 01:31:48 GMT"}], "update_date": "2014-01-07", "authors_parsed": [["Mittal", "Sparsh", ""]]}, {"id": "1401.1903", "submitter": "Young-Chul Shim", "authors": "Young-Chul Shim", "title": "Distributed Cloud Computing Environment Enhanced with Capabilities for\n  Wide-Area Migration and Replication of Virtual Machines", "comments": "13 pages", "journal-ref": "International Journal of Computer Science & Information\n  Technology, Vol. 5, No. 6, December 2013", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When a network application is implmented as a virtual machine on a cloud and\nis used by a large number of users, the location of the virtual machine should\nbe selected carefully so that the response time experienced by users is\nminimized. As the user population moves and/or increases, the virtual machine\nmay need to be migrated to a new location or replicated on many locations over\na wide-area network. Virtual machine migration and replication have been\nstudied extensively but in most cases are limited within a subnetwork to be\nable to maintain service continuity. In this paper we introduce a distributed\ncloud computing environment which facilitates the migration and replication of\na virtual machine over a wide area network. The mechanism is provided by an\noverlay network of smart routers, each of which connects a cooperating data\ncenter to the Internet. The proposed approach is analyzed and compared with\nrelated works\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 06:39:15 GMT"}], "update_date": "2014-01-10", "authors_parsed": [["Shim", "Young-Chul", ""]]}, {"id": "1401.2008", "submitter": "Jeya Bharathi", "authors": "C.Jeyabharathi and A.Pethalakshmi", "title": "New Approaches with Chord in Efficient P2P Grid Resource Discovery", "comments": "14 pages,9 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid computing is a type of distributed computing which allows sharing of\ncomputer resources through Internet. It not only allows us to share files but\nalso most of the software and hardware resources. An efficient resource\ndiscovery mechanism is the fundamental requirements for grid computing systems,\nas it supports resource management and scheduling of applications. Among\nvarious discovery mechanisms,Peer-to-Peer (P2P) technology witnessed rapid\ndevelopment and the key component for this success is efficient lookup\napplications of P2P. Chord is a P2P structural model widely used as a routing\nprotocol to find resources in grid environment. Plenty of ideas are implemented\nby researchers to improve the lookup performance of chord protocol in Grid\nenvironment. In this paper, we discuss the recent researches made on Chord\nStructured P2P protocol and present our proposed methods in which we use the\naddress of Recently Visited Node (RVN) and fuzzy technique to easily locate the\ngrid resources by reducing message complexity and time complexity.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 14:09:16 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Jeyabharathi", "C.", ""], ["Pethalakshmi", "A.", ""]]}, {"id": "1401.2039", "submitter": "Konstantin Petrov", "authors": "Denis Barthou, Olivier Brand-Foissac, Romain Dolbeau, Gilbert\n  Grosdidier, Christina Eisenbeis, Michael Kruse, Olivier Pene, Konstantin\n  Petrov, Claude Tadonki", "title": "Automated Code Generation for Lattice Quantum Chromodynamics and beyond", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/510/1/012005", "report-no": "LPT-Orsay-13-142, hal-00926513", "categories": "hep-lat cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here our ongoing work on a Domain Specific Language which aims to\nsimplify Monte-Carlo simulations and measurements in the domain of Lattice\nQuantum Chromodynamics. The tool-chain, called Qiral, is used to produce\nhigh-performance OpenMP C code from LaTeX sources. We discuss conceptual issues\nand details of implementation and optimization. The comparison of the\nperformance of the generated code to the well-established simulation software\nis also made.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 15:56:31 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Barthou", "Denis", ""], ["Brand-Foissac", "Olivier", ""], ["Dolbeau", "Romain", ""], ["Grosdidier", "Gilbert", ""], ["Eisenbeis", "Christina", ""], ["Kruse", "Michael", ""], ["Pene", "Olivier", ""], ["Petrov", "Konstantin", ""], ["Tadonki", "Claude", ""]]}, {"id": "1401.2198", "submitter": "Ashkan Paya Mr.", "authors": "Ashkan Paya and Dan C.Marinescu", "title": "Energy-aware Load Balancing Policies for the Cloud Ecosystem", "comments": "10 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The energy consumption of computer and communication systems does not scale\nlinearly with the workload. A system uses a significant amount of energy even\nwhen idle or lightly loaded. A widely reported solution to resource management\nin large data centers is to concentrate the load on a subset of servers and,\nwhenever possible, switch the rest of the servers to one of the possible sleep\nstates. We propose a reformulation of the traditional concept of load balancing\naiming to optimize the energy consumption of a large-scale system: {\\it\ndistribute the workload evenly to the smallest set of servers operating at an\noptimal energy level, while observing QoS constraints, such as the response\ntime.} Our model applies to clustered systems; the model also requires that the\ndemand for system resources to increase at a bounded rate in each reallocation\ninterval. In this paper we report the VM migration costs for application\nscaling.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 23:03:00 GMT"}], "update_date": "2014-01-13", "authors_parsed": [["Paya", "Ashkan", ""], ["Marinescu", "Dan C.", ""]]}, {"id": "1401.2440", "submitter": "Erich Schikuta", "authors": "Werner Mach and Benedikt Pittl and Erich Schikuta", "title": "A Prediction Model for the Probability of SLA Matching in Consumer\n  Provider Contracting of Web Services", "comments": "Conference submission, not published yet", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future e-business models will rely on electronic contracts which are agreed\ndynamically and adaptively by web services. Thus, the automatic negotiation of\nService Level Agreements (SLAs) between consumers and providers is key for\nenabling service-based value chains.\n  The process of finding appropriate providers for web services seems to be\nsimple. Consumers contact several providers and take the provider which offers\nthe best matching SLA. However, currently consumers are not able forecasting\nthe probability of finding a matching provider for their requested SLA. So\nconsumers contact several providers and check if their offers are matching. In\ncase of continuing faults, on the one hand consumers may adapt their Service\nLevel Objects (SLOs) of the required SLA or on the other hand simply accept\noffered SLAs of the contacted providers.\n  By forecasting the probability of finding a matching provider, consumers\ncould assess their chances of finding a provider offering the requested SLA. If\na low probability is predicted, consumers can immediately adapt their SLOs or\nincrease the numbers of providers to be contacted.\n  Thus, this paper proposes an analytical forecast model, which allows\nconsumers to get a realistic assessment of the probability to find matching\nproviders. Additionally, we present an optimization algorithm based on the\nforecast results, which allows adapting the SLO parameter ranges in order to\nfind at least one matching provider. Not only consumers, but also providers can\nuse this forecast model to predict the prospective demand. So providers are\nable to assess the number of potential consumers based on their offers too.\n  Justification of our approach is done by simulation of practical examples\nchecking our theoretical findings.\n", "versions": [{"version": "v1", "created": "Fri, 10 Jan 2014 20:10:38 GMT"}], "update_date": "2014-01-13", "authors_parsed": [["Mach", "Werner", ""], ["Pittl", "Benedikt", ""], ["Schikuta", "Erich", ""]]}, {"id": "1401.2518", "submitter": "Pooja Vyavahare", "authors": "Pooja Vyavahare and Nutan Limaye and D. Manjunath", "title": "Optimal Embedding of Functions for In-Network Computation: Complexity\n  Analysis and Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider optimal distributed computation of a given function of\ndistributed data. The input (data) nodes and the sink node that receives the\nfunction form a connected network that is described by an undirected weighted\nnetwork graph. The algorithm to compute the given function is described by a\nweighted directed acyclic graph and is called the computation graph. An\nembedding defines the computation communication sequence that obtains the\nfunction at the sink. Two kinds of optimal embeddings are sought, the embedding\nthat---(1)~minimizes delay in obtaining function at sink, and (2)~minimizes\ncost of one instance of computation of function. This abstraction is motivated\nby three applications---in-network computation over sensor networks, operator\nplacement in distributed databases, and module placement in distributed\ncomputing.\n  We first show that obtaining minimum-delay and minimum-cost embeddings are\nboth NP-complete problems and that cost minimization is actually MAX SNP-hard.\nNext, we consider specific forms of the computation graph for which polynomial\ntime solutions are possible. When the computation graph is a tree, a polynomial\ntime algorithm to obtain the minimum delay embedding is described. Next, for\nthe case when the function is described by a layered graph we describe an\nalgorithm that obtains the minimum cost embedding in polynomial time. This\nalgorithm can also be used to obtain an approximation for delay minimization.\nWe then consider bounded treewidth computation graphs and give an algorithm to\nobtain the minimum cost embedding in polynomial time.\n", "versions": [{"version": "v1", "created": "Sat, 11 Jan 2014 11:05:51 GMT"}, {"version": "v2", "created": "Wed, 27 Aug 2014 07:07:06 GMT"}, {"version": "v3", "created": "Tue, 14 Jul 2015 12:33:53 GMT"}], "update_date": "2015-07-15", "authors_parsed": [["Vyavahare", "Pooja", ""], ["Limaye", "Nutan", ""], ["Manjunath", "D.", ""]]}, {"id": "1401.2596", "submitter": "Zhenqi Huang", "authors": "Zhenqi Huang, Sayan Mitra, Nitin Vaidya", "title": "Differentially Private Distributed Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed optimization and iterative consensus literature, a standard\nproblem is for $N$ agents to minimize a function $f$ over a subset of Euclidean\nspace, where the cost function is expressed as a sum $\\sum f_i$. In this paper,\nwe study the private distributed optimization (PDOP) problem with the\nadditional requirement that the cost function of the individual agents should\nremain differentially private. The adversary attempts to infer information\nabout the private cost functions from the messages that the agents exchange.\nAchieving differential privacy requires that any change of an individual's cost\nfunction only results in unsubstantial changes in the statistics of the\nmessages. We propose a class of iterative algorithms for solving PDOP, which\nachieves differential privacy and convergence to the optimal value. Our\nanalysis reveals the dependence of the achieved accuracy and the privacy levels\non the the parameters of the algorithm. We observe that to achieve\n$\\epsilon$-differential privacy the accuracy of the algorithm has the order of\n$O(\\frac{1}{\\epsilon^2})$.\n", "versions": [{"version": "v1", "created": "Sun, 12 Jan 2014 07:43:39 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["Huang", "Zhenqi", ""], ["Mitra", "Sayan", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1401.2720", "submitter": "Vedran Novakovic", "authors": "Vedran Novakovi\\'c", "title": "A hierarchically blocked Jacobi SVD algorithm for single and multiple\n  graphics processing units", "comments": "Accepted for publication in SIAM Journal on Scientific Computing", "journal-ref": "SIAM J. Sci. Comput. 37 (2015), C1-C30", "doi": "10.1137/140952429", "report-no": null, "categories": "cs.NA cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a hierarchically blocked one-sided Jacobi algorithm for the\nsingular value decomposition (SVD), targeting both single and multiple graphics\nprocessing units (GPUs). The blocking structure reflects the levels of GPU's\nmemory hierarchy. The algorithm may outperform MAGMA's dgesvd, while retaining\nhigh relative accuracy. To this end, we developed a family of parallel pivot\nstrategies on GPU's shared address space, but applicable also to inter-GPU\ncommunication. Unlike common hybrid approaches, our algorithm in a single GPU\nsetting needs a CPU for the controlling purposes only, while utilizing GPU's\nresources to the fullest extent permitted by the hardware. When required by the\nproblem size, the algorithm, in principle, scales to an arbitrary number of GPU\nnodes. The scalability is demonstrated by more than twofold speedup for\nsufficiently large matrices on a Tesla S2050 system with four GPUs vs. a single\nFermi card.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 06:12:17 GMT"}, {"version": "v2", "created": "Sat, 7 Jun 2014 14:23:33 GMT"}, {"version": "v3", "created": "Sat, 27 Sep 2014 22:51:33 GMT"}], "update_date": "2015-02-05", "authors_parsed": [["Novakovi\u0107", "Vedran", ""]]}, {"id": "1401.2920", "submitter": "Vincenzo De Florio", "authors": "Vincenzo De Florio, Greet Deconinck, Rudy Lauwereins", "title": "The EFTOS Voting Farm: A Software Tool for Fault Masking in Message\n  Passing Parallel Environments", "comments": "Proc. of the 24th EUROMICRO Conf. on Engineering Systems and Software\n  for the next decade, Vaesteras, Sweden, August 25-27, 1998; pp. 379-386", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a set of C functions implementing a distributed software voting\nmechanism for EPX or similar message passing environments, and we place it\nwithin the EFTOS framework (Embedded Fault-Tolerant Supercomputing, ESPRIT-IV\nProject 21012) of software tools for enhancing the dependability of a user\napplication. The described mechanism can be used for instance to implement\nrestoring organs i.e., N-modular redundancy systems with N-replicated voters.\nWe show that, besides structural design goals like fault transparency, this\ntool achieves replication transparency, a high degree of flexibility and\nease-of-use, and good performance.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 17:14:44 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["De Florio", "Vincenzo", ""], ["Deconinck", "Greet", ""], ["Lauwereins", "Rudy", ""]]}, {"id": "1401.2965", "submitter": "Vincenzo De Florio", "authors": "Vincenzo De Florio, G. Deconinck, M. Truyens, W. Rosseel, and Rudy\n  Lauwereins", "title": "A Hypermedia Distributed Application for Monitoring and Fault-Injection\n  in Embedded Fault-tolerant Parallel Programs", "comments": "Proc. of the 6th Conf. on Parallel and Distributed Processing (PDP98)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a distributed, multimedia application which is being developed in\nthe framework of the ESPRIT-IV Project 21012 EFTOS (Embedded Fault-Tolerant\nSupercomputing). The application dynamically sets up a hierarchy of HTML pages\nreflecting the current status of an EFTOS-compliant dependable application\nrunning on a Parsytec CC system. These pages are fed to a World-Wide Web\nbrowser playing the role of a hypermedia monitor. The adopted approach allows\nthe user to concentrate on the high-level aspects of his/her application so to\nquickly assess the quality of its current fault-tolerance design. This view of\nthe system lends itself well for being coupled with a tool to interactively\ninject software faults in the user application; this tool is currently under\ndevelopment.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 19:51:26 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["De Florio", "Vincenzo", ""], ["Deconinck", "G.", ""], ["Truyens", "M.", ""], ["Rosseel", "W.", ""], ["Lauwereins", "Rudy", ""]]}, {"id": "1401.2974", "submitter": "Vincenzo De Florio", "authors": "Vincenzo De Florio, G. Deconinck, Rudy Lauwereins", "title": "Software Tool Combining Fault Masking with User-Defined Recovery\n  Strategies", "comments": null, "journal-ref": "IEE Proc. Software, Vol. 145, No. 6 (December 1998)", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the voting farm, a tool which implements a distributed software\nvoting mechanism for a number of parallel message passing systems. The tool,\ndeveloped in the framework of EFTOS (Embedded Fault-Tolerant Supercomputing),\ncan be used in stand-alone mode or in conjunction with other EFTOS fault\ntolerance tools. In the former case, we describe how the mechanism can be\nexploited, e.g., to implement restoring organs ($N\\!$-modular redundancy\nsystems with $N\\!$-replicated voters); in the latter case, we show how it is\npossible for the user to implement in an easy and effective way a number of\ndifferent recovery strategies via a custom, high-level language. Combining such\nstrategies with the basic fault masking capabilities of the voting tool makes\nit possible to set up complex fault-tolerant systems such as, for instance,\n$N$-and-$M$-spare systems or gracefully degrading voting farms. We also report\nabout the impact that our tool can have on reliability, and we show how,\nbesides structural design goals like fault transparency, our tool achieves\nreplication transparency, a high degree of flexibility and ease-of-use, and\ngood performance.\n", "versions": [{"version": "v1", "created": "Mon, 13 Jan 2014 20:40:40 GMT"}], "update_date": "2014-01-14", "authors_parsed": [["De Florio", "Vincenzo", ""], ["Deconinck", "G.", ""], ["Lauwereins", "Rudy", ""]]}, {"id": "1401.3615", "submitter": "Johannes Hofmann", "authors": "Johannes Hofmann, Jan Treibig, Georg Hager, Gerhard Wellein", "title": "Performance Engineering for a Medical Imaging Application on the Intel\n  Xeon Phi Accelerator", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the Xeon Phi, which is based on Intel's Many Integrated Cores\narchitecture, for its suitability to run the FDK algorithm--the most commonly\nused algorithm to perform the 3D image reconstruction in cone-beam computed\ntomography. We study the challenges of efficiently parallelizing the\napplication and means to enable sensible data sharing between threads despite\nthe lack of a shared last level cache. Apart from parallelization, SIMD\nvectorization is critical for good performance on the Xeon Phi; we perform\nvarious micro-benchmarks to investigate the platform's new set of vector\ninstructions and put a special emphasis on the newly introduced vector gather\ncapability. We refine a previous performance model for the application and\nadapt it for the Xeon Phi to validate the performance of our optimized\nhand-written assembly implementation, as well as the performance of several\ndifferent auto-vectorization approaches.\n", "versions": [{"version": "v1", "created": "Tue, 17 Dec 2013 14:46:19 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["Hofmann", "Johannes", ""], ["Treibig", "Jan", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1401.3683", "submitter": "Vincenzo De Florio", "authors": "Vincenzo De Florio and G. Deconinck", "title": "$\\mathcal R\\!\\raise2pt\\hbox{$\\varepsilon$}\\!\\hbox{$\\mathcal L$}$: A\n  Fault Tolerance Linguistic Structure for Distributed Applications", "comments": "Proc. of the 9th IEEE Conf. and Workshop on Engineering of\n  Computer-Based Systems (ECBS-2002), Lund, Sweden, 8-11 April, 2002; pp. 51-58", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The embedding of fault tolerance provisions into the application layer of a\nprogramming language is a non-trivial task that has not found a satisfactory\nsolution yet. Such a solution is very important, and the lack of a simple,\ncoherent and effective structuring technique for fault tolerance has been\ntermed by researchers in this field as the \"software bottleneck of system\ndevelopment\". The aim of this paper is to report on the current status of a\nnovel fault tolerance linguistic structure for distributed applications\ncharacterized by soft real-time requirements. A compliant prototype\narchitecture is also described. The key aspect of this structure is that it\nallows to decompose the target fault-tolerant application into three distinct\ncomponents, respectively responsible for (1) the functional service, (2) the\nmanagement of the fault tolerance provisions, and (3) the adaptation to the\ncurrent environmental conditions. The paper also briefly mentions a few case\nstudies and preliminary results obtained exercising the prototype.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 17:31:52 GMT"}], "update_date": "2014-01-16", "authors_parsed": [["De Florio", "Vincenzo", ""], ["Deconinck", "G.", ""]]}, {"id": "1401.3733", "submitter": "Ed Bennett", "authors": "Ed Bennett, Luigi Del Debbio, Kirk Jordan, Biagio Lucini, Agostino\n  Patella, Claudio Pica, Antonio Rago", "title": "BSMBench: a flexible and scalable supercomputer benchmark from\n  computational particle physics", "comments": "6 pages, 5 figures; version as presented at High Performance\n  Computing and Simulation, HPCS 2016", "journal-ref": "2016 International Conference on High Performance Computing &\n  Simulation (HPCS), Innsbruck, Austria, 2016, pp. 834-839", "doi": "10.1109/HPCSim.2016.7568421", "report-no": "CP3-Origins-2014-001 DNRF90 & DIAS-2014-1", "categories": "cs.DC hep-lat", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Lattice Quantum ChromoDynamics (QCD), and by extension its parent field,\nLattice Gauge Theory (LGT), make up a significant fraction of supercomputing\ncycles worldwide. As such, it would be irresponsible not to evaluate machines'\nsuitability for such applications. To this end, a benchmark has been developed\nto assess the performance of LGT applications on modern HPC platforms. Distinct\nfrom previous QCD-based benchmarks, this allows probing the behaviour of a\nvariety of theories, which allows varying the ratio of demands between on-node\ncomputations and inter-node communications. The results of testing this\nbenchmark on various recent HPC platforms are presented, and directions for\nfuture development are discussed.\n", "versions": [{"version": "v1", "created": "Wed, 15 Jan 2014 20:33:38 GMT"}, {"version": "v2", "created": "Thu, 22 Sep 2016 12:27:22 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Bennett", "Ed", ""], ["Del Debbio", "Luigi", ""], ["Jordan", "Kirk", ""], ["Lucini", "Biagio", ""], ["Patella", "Agostino", ""], ["Pica", "Claudio", ""], ["Rago", "Antonio", ""]]}, {"id": "1401.3861", "submitter": "Ethan Burns", "authors": "Ethan Burns, Sofia Lemons, Wheeler Ruml, Rong Zhou", "title": "Best-First Heuristic Search for Multicore Machines", "comments": null, "journal-ref": "Journal Of Artificial Intelligence Research, Volume 39, pages\n  689-743, 2010", "doi": "10.1613/jair.3094", "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To harness modern multicore processors, it is imperative to develop parallel\nversions of fundamental algorithms. In this paper, we compare different\napproaches to parallel best-first search in a shared-memory setting. We present\na new method, PBNF, that uses abstraction to partition the state space and to\ndetect duplicate states without requiring frequent locking. PBNF allows\nspeculative expansions when necessary to keep threads busy. We identify and fix\npotential livelock conditions in our approach, proving its correctness using\ntemporal logic. Our approach is general, allowing it to extend easily to\nsuboptimal and anytime heuristic search. In an empirical comparison on STRIPS\nplanning, grid pathfinding, and sliding tile puzzle problems using 8-core\nmachines, we show that A*, weighted A* and Anytime weighted A* implemented\nusing PBNF yield faster search than improved versions of previous parallel\nsearch proposals.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 05:04:02 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["Burns", "Ethan", ""], ["Lemons", "Sofia", ""], ["Ruml", "Wheeler", ""], ["Zhou", "Rong", ""]]}, {"id": "1401.4063", "submitter": "Maciej Cytowski Mr", "authors": "Jakub Katarzy\\'nski and Maciej Cytowski", "title": "Towards Autotuning of OpenMP Applications on Multicore Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe an autotuning tool for optimization of OpenMP\napplications on highly multicore and multithreaded architectures. Our work was\nmotivated by in-depth performance analysis of scientific applications and\nsynthetic benchmarks on IBM Power 775 architecture. The tool provides an\nautomatic code instrumentation of OpenMP parallel regions. Based on measurement\nof chosen hardware performance counters the tool decides on the number of\nparallel threads that should be used for execution of chosen code fragments.\n", "versions": [{"version": "v1", "created": "Thu, 16 Jan 2014 15:30:17 GMT"}], "update_date": "2014-01-17", "authors_parsed": [["Katarzy\u0144ski", "Jakub", ""], ["Cytowski", "Maciej", ""]]}, {"id": "1401.4441", "submitter": "Jose Gracia", "authors": "Christoph Niethammer, Colin W. Glass, Jose Gracia", "title": "Avoiding Serialization Effects in Data-Dependency aware Task Parallel\n  Algorithms for Spatial Decomposition", "comments": "6 pages, 9 figures, published at ISPA2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spatial decomposition is a popular basis for parallelising code. Cast in the\nframe of task parallelism, calculations on a spatial domain can be treated as a\ntask. If neighbouring domains interact and share results, access to the\nspecific data needs to be synchronized to avoid race conditions. This is the\ncase for a variety of applications, like most molecular dynamics and many\ncomputational fluid dynamics codes. Here we present an unexpected problem which\ncan occur in dependency-driven task parallelization models like StarSs: the\ntasks accessing a specific spatial domain are treated as interdependent, as\ndependencies are detected automatically via memory addresses. Thus, the order\nin which tasks are generated will have a severe impact on the dependency tree.\nIn the worst case, a complete serialization is reached and no two tasks can be\ncalculated in parallel. We present the problem in detail based on an example\nfrom molecular dynamics, and introduce a theoretical framework to calculate the\ndegree of serialization. Furthermore, we present strategies to avoid this\nunnecessary problem. We recommend treating these strategies as best practice\nwhen using dependency-driven task parallel programming models like StarSs on\nsuch scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 17 Jan 2014 19:28:10 GMT"}], "update_date": "2014-01-20", "authors_parsed": [["Niethammer", "Christoph", ""], ["Glass", "Colin W.", ""], ["Gracia", "Jose", ""]]}, {"id": "1401.4972", "submitter": "Lelia Blin", "authors": "L\\'elia Blin and S\\'ebastien Tixeuil", "title": "Compact Deterministic Self-Stabilizing Leader Election: The Exponential\n  Advantage of Being Talkative", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on compact deterministic self-stabilizing solutions for\nthe leader election problem. When the protocol is required to be \\emph{silent}\n(i.e., when communication content remains fixed from some point in time during\nany execution), there exists a lower bound of Omega(\\log n) bits of memory per\nnode participating to the leader election (where n denotes the number of nodes\nin the system). This lower bound holds even in rings. We present a new\ndeterministic (non-silent) self-stabilizing protocol for n-node rings that uses\nonly O(\\log\\log n) memory bits per node, and stabilizes in O(n\\log^2 n) rounds.\nOur protocol has several attractive features that make it suitable for\npractical purposes. First, the communication model fits with the model used by\nexisting compilers for real networks. Second, the size of the ring (or any\nupper bound on this size) needs not to be known by any node. Third, the node\nidentifiers can be of various sizes. Finally, no synchrony assumption, besides\na weakly fair scheduler, is assumed. Therefore, our result shows that, perhaps\nsurprisingly, trading silence for exponential improvement in term of memory\nspace does not come at a high cost regarding stabilization time or minimal\nassumptions.\n", "versions": [{"version": "v1", "created": "Mon, 20 Jan 2014 16:34:46 GMT"}], "update_date": "2014-01-21", "authors_parsed": [["Blin", "L\u00e9lia", ""], ["Tixeuil", "S\u00e9bastien", ""]]}, {"id": "1401.5155", "submitter": "Jafar Shayan", "authors": "Jafar Shayan, Ahmad Azarnik, Suriayati Chuprat, Sasan Karamizadeh,\n  Mojtaba Alizadeh", "title": "Identifying Benefits and risks associated with utilizing cloud computing", "comments": null, "journal-ref": null, "doi": "10.7321/jscse.v3.n3.63", "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is an emerging computing model where IT and computing\noperations are delivered as services in highly scalable and cost effective\nmanner. Recently, embarking this new model in business has become popular.\nCompanies in diverse sectors intend to leverage cloud computing architecture,\nplatforms and applications in order to gain higher competitive advantages.\nLikewise other models, cloud computing brought advantages to attract business\nbut meanwhile fostering cloud has led to some risks, which can cause major\nimpacts if business does not plan for mitigation. This paper surveys the\nadvantages of cloud computing and in contrast the risks associated using them.\nFinally we conclude that a well-defined risk management program that focused on\ncloud computing is an essential part of gaining value from benefits of cloud\ncomputing.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 02:52:39 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Shayan", "Jafar", ""], ["Azarnik", "Ahmad", ""], ["Chuprat", "Suriayati", ""], ["Karamizadeh", "Sasan", ""], ["Alizadeh", "Mojtaba", ""]]}, {"id": "1401.5208", "submitter": "Chen Guo", "authors": "Chen Guo, Cenzhe Zhu, Teng Tiow Tay", "title": "ShAppliT: A Novel Broker-mediated Solution to Generic Application\n  Sharing in a Cluster of Closed Operating Systems", "comments": "17 pages", "journal-ref": "International Journal of Soft Computing and Software Engineering\n  Vol. 2, No. 6, 2012", "doi": "10.7321/jscse.v2.n6.2", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With advances in hardware and networking technologies and mass manufacturing,\nthe cost of high end hardware had fall dramatically in recent years. However,\nsoftware cost still remains high and is the dominant fraction of the overall\ncomputing budget. Application sharing is a promising solution to reduce the\noverall IT cost. Currently software licenses are still based on the number of\ncopies installed. An organization can thus reduce the IT cost if the users are\nable to remotely access the software that is installed on certain computer\nservers instead of running the software on every local computer. In this paper,\nwe propose a generic application sharing architecture for users' application\nsharing in a cluster of closed operating systems such as Microsoft Windows. We\nalso propose a broker-mediated solution where we allow multiple users to access\na single user software license on a time multiplex basis through a single\nlogged in user. An application sharing tool called ShAppliT has been introduced\nand implemented in Microsoft Windows operating system. We evaluated their\nperformance on CPU usage and memory consumption when a computer is hosting\nmultiple concurrent shared application sessions.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 07:37:08 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Guo", "Chen", ""], ["Zhu", "Cenzhe", ""], ["Tay", "Teng Tiow", ""]]}, {"id": "1401.5216", "submitter": "Micha{\\l}  Karpi\\'nski", "authors": "Micha{\\l} Karpi\\'nski and Maciej Pacut", "title": "Multi-GPU parallel memetic algorithm for capacitated vehicle routing\n  problem", "comments": "This paper has been withdrawn by the author due to crucial error in\n  the experimental evaluation", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of this paper is to propose and test a new memetic algorithm for the\ncapacitated vehicle routing problem in parallel computing environment. In this\npaper we consider simple variation of vehicle routing problem in which the only\nparameter is the capacity of the vehicle and each client only needs one\npackage. We present simple reduction to prove the existence of polynomial-time\nalgorithm for capacity 2. We analyze the efficiency of the algorithm using\nhierarchical Parallel Random Access Machine (PRAM) model and run experiments\nwith code written in CUDA (for capacities larger than 2).\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 08:18:20 GMT"}, {"version": "v2", "created": "Mon, 6 Mar 2017 12:27:48 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Karpi\u0144ski", "Micha\u0142", ""], ["Pacut", "Maciej", ""]]}, {"id": "1401.5258", "submitter": "Farrukh Arslan", "authors": "Farrukh Arslan", "title": "Service Oriented Paradigm for Massive Multiplayer Online Games", "comments": null, "journal-ref": "International Journal of Soft Computing and Software Engineering\n  [JSCSE], Vol. 2, No. 5, pp. 35-47, 2012", "doi": "10.7321/jscse.v2.n5.4", "report-no": null, "categories": "cs.NI cs.DC cs.MM cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent times Massive Multiplayer Online Game has appeared as a computer\ngame that enables hundreds of players from all parts of the world to interact\nin a game world (common platform) at the same time instance. Current\narchitecture used for MMOGs based on the classic tightly coupled distributed\nsystem. While, MMOGs are getting more interactive same time number of\ninteracting users is increasing, classic implementation architecture may raise\nscalability and interdependence issues. This requires a loosely coupled service\noriented architecture to support evolution in MMOG application. Data flow\narchitecture, Event driven architecture and client server architecture are\nbasic date orchestration approaches used by any service oriented architecture.\nReal time service is hottest issue for service oriented architecture. The basic\nrequirement of any real time service oriented architecture is to ensure the\nquality of service. In this paper we have proposed a service oriented\narchitecture for massive multiplayer online game and a specific middleware\n(based on open source DDS) in MMOGs for fulfilling real time constraints.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 10:49:01 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Arslan", "Farrukh", ""]]}, {"id": "1401.5316", "submitter": "Hsin-Hao Su", "authors": "Hsin-Hao Su", "title": "A Distributed Minimum Cut Approximation Scheme", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the problem of approximating the minimum cut in a\ndistributed message-passing model, the CONGEST model. The minimum cut problem\nhas been well-studied in the context of centralized algorithms. However, there\nwere no known non-trivial algorithms in the distributed model until the recent\nwork of Ghaffari and Kuhn. They gave algorithms for finding cuts of size\n$O(\\epsilon^{-1}\\lambda)$ and $(2+\\epsilon)\\lambda$ in\n$O(D)+\\tilde{O}(n^{1/2+\\epsilon})$ rounds and $\\tilde{O}(D+\\sqrt{n})$ rounds\nrespectively, where $\\lambda$ is the size of the minimum cut. This matches the\nlower bound they provided up to a polylogarithmic factor. Yet, no scheme that\nachieves $(1+\\epsilon)$-approximation ratio is known. We give a distributed\nalgorithm that finds a cut of size $(1+\\epsilon)\\lambda$ in\n$\\tilde{O}(D+\\sqrt{n})$ time, which is optimal up to polylogarithmic factors.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 13:39:38 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["Su", "Hsin-Hao", ""]]}, {"id": "1401.5346", "submitter": "Malcolm McRoberts", "authors": "Malcolm McRoberts", "title": "Software Licensing in the Cloud Age", "comments": null, "journal-ref": "International Journal of Soft Computing and Software Engineering\n  [JSCSE], Vol. 3, No. 3, pp. 395-402, 2013", "doi": "10.7321/jscse.v3.n3.60", "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing represents a major shift in information systems architecture,\ncombining both new deployment models and new business models. Rapid\nprovisioning, elastic scaling, and metered usage are essential characteristics\nof cloud services, and they require cloud resources with these same\ncharacteristics. When cloud services depend on commercial software, the\nlicenses for that software become another resource to be managed by the cloud.\nThis paper examines common licensing models, including open source, and how\nwell they function in a cloud services model. It discusses creative, new,\ncloud-centric licensing models and how they allow providers to preserve and\nexpand their revenue streams as their partners and customers transition to the\ncloud. The paper concludes by identifying the next steps to achieve\nstandardized, cloud-friendly licensing models.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 15:25:04 GMT"}], "update_date": "2014-01-22", "authors_parsed": [["McRoberts", "Malcolm", ""]]}, {"id": "1401.5686", "submitter": "Ayman Bahaa-Eldin", "authors": "Ayman M. Bahaa-Eldin, Hoda K. Mohamead, Sally S. Deraz", "title": "Increasing Server Availability for Overall System Security: A Preventive\n  Maintenance Approach Based on Failure Prediction", "comments": "arXiv admin note: text overlap with arXiv:1206.1534 by other authors", "journal-ref": "Ain Shams Journal of Electrical Engineering (ASJEE), Volume 1,\n  Issue 2, pp 135-143 (2009)", "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Server Availability (SA) is an important measure of overall systems security.\nImportant security systems rely on the availability of their hosting servers to\ndeliver critical security services. Many of these servers offer management\ninterface through web mainly using an Apache server. This paper investigates\nthe increase of Server Availability by the use of Artificial Neural Networks\n(ANN) to predict software aging phenomenon. Several resource usage data is\ncollected and analyzed on a typical long-running software system (a web\nserver). A Multi-Layer Perceptron feed forward Artificial Neural Network was\ntrained on an Apache web server data-set to predict future server resource\nexhaustion through uni-variate time series forecasting. The results were\nbenchmarked against those obtained from non-parametric statistical techniques,\nparametric time series models and empirical modeling techniques reported in the\nliterature.\n", "versions": [{"version": "v1", "created": "Tue, 21 Jan 2014 10:13:25 GMT"}], "update_date": "2014-01-23", "authors_parsed": [["Bahaa-Eldin", "Ayman M.", ""], ["Mohamead", "Hoda K.", ""], ["Deraz", "Sally S.", ""]]}, {"id": "1401.5921", "submitter": "Ciaran McCreesh", "authors": "Ciaran McCreesh and Patrick Prosser", "title": "The Shape of the Search Tree for the Maximum Clique Problem, and the\n  Implications for Parallel Branch and Bound", "comments": "Substantial revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a maximum clique in a given graph is one of the fundamental NP-hard\nproblems. We compare two multi-core thread-parallel adaptations of a\nstate-of-the-art branch and bound algorithm for the maximum clique problem, and\nprovide a novel explanation as to why they are successful. We show that load\nbalance is sometimes a problem, but that the interaction of parallel search\norder and the most likely location of solutions within the search space is\noften the dominating consideration. We use this explanation to propose a new\nlow-overhead, scalable work splitting mechanism. Our approach uses explicit\nearly diversity to avoid strong commitment to the weakest heuristic advice, and\nlate resplitting for balance. More generally, we argue that for branch and\nbound, parallel algorithm design should not be performed independently of the\nunderlying sequential algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 10:01:35 GMT"}, {"version": "v2", "created": "Thu, 20 Feb 2014 11:45:40 GMT"}, {"version": "v3", "created": "Thu, 4 Sep 2014 11:44:24 GMT"}], "update_date": "2014-09-05", "authors_parsed": [["McCreesh", "Ciaran", ""], ["Prosser", "Patrick", ""]]}, {"id": "1401.6015", "submitter": "Parisa Jalili Marandi", "authors": "Parisa Jalili Marandi, Marco Primi, Nicolas Schiper, Fernando Pedone", "title": "Ring Paxos: High-Throughput Atomic Broadcast", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atomic broadcast is an important communication primitive often used to\nimplement state-machine replication. Despite the large number of atomic\nbroadcast algorithms proposed in the literature, few papers have discussed how\nto turn these algorithms into efficient executable protocols. This paper\nfocuses on a class of atomic broadcast algorithms based on Paxos, with its\ncorresponding desirable properties: safety under asynchrony assumptions,\nliveness under weak synchrony assumptions, and resiliency-optimality. The paper\npresents two protocols, M-Ring Paxos and U-Ring Paxos, derived from Paxos. The\nprotocols inherit the properties of Paxos and can be implemented very\nefficiently. We report a detailed performance analysis of M-Ring Paxos and\nU-Ring Paxos and compare them to other atomic broadcast protocols.\n", "versions": [{"version": "v1", "created": "Thu, 23 Jan 2014 15:49:17 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Marandi", "Parisa Jalili", ""], ["Primi", "Marco", ""], ["Schiper", "Nicolas", ""], ["Pedone", "Fernando", ""]]}, {"id": "1401.6100", "submitter": "K. Eric Harper", "authors": "K. Eric Harper and Thijmen de Gooijer", "title": "Performance Impact of Lock-Free Algorithms on Multicore Communication\n  APIs", "comments": "17 pages, 8 figures, 36 references, Embedded World Conference 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data race conditions in multi-tasking software applications are prevented by\nserializing access to shared memory resources, ensuring data consistency and\ndeterministic behavior. Traditionally tasks acquire and release locks to\nsynchronize operations on shared memory. Unfortunately, lock management can add\nsignificant processing overhead especially for multicore deployments where\ntasks on different cores convoy in queues waiting to acquire a lock.\nImplementing more than one lock introduces the risk of deadlock and using\nspinlocks constrains which cores a task can run on. The better alternative is\nto eliminate locks and validate that real-time properties are met, which is not\ndirectly considered in many embedded applications. Removing the locks is\nnon-trivial and packaging lock-free algorithms for developers reduces the\npossibility of concurrency defects. This paper details how a multicore\ncommunication API implementation is enhanced to support lock-free messaging and\nthe impact this has on data exchange latency between tasks. Throughput and\nlatency are compared on Windows and Linux between lock-based and lock-free\nimplementations for data exchange of messages, packets, and scalars. A model of\nthe lock-free exchange predicts performance at the system architecture level\nand provides a stop criterion for the refactoring. The results show that\nmigration from single to multicore hardware architectures degrades lock-based\nperformance, and increases lock-free performance.\n", "versions": [{"version": "v1", "created": "Thu, 9 Jan 2014 00:04:41 GMT"}], "update_date": "2014-01-24", "authors_parsed": [["Harper", "K. Eric", ""], ["de Gooijer", "Thijmen", ""]]}, {"id": "1401.6267", "submitter": "Harun Rasit Er M.S.", "authors": "Harun Rasit Er, Nadia Erdogan", "title": "Parallel Genetic Algorithm to Solve Traveling Salesman Problem on\n  MapReduce Framework using Hadoop Cluster", "comments": "The International Journal of Soft Computing and Software Engineering\n  [JSCSE], Vol. 3, No. 3, Special Issue. The Proceeding of International\n  Conference on Soft Computing and Software Engineering 2013", "journal-ref": null, "doi": "10.7321/jscse.v3.n3.57", "report-no": "e-ISSN: 2251-7545", "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traveling Salesman Problem (TSP) is one of the most common studied problems\nin combinatorial optimization. Given the list of cities and distances between\nthem, the problem is to find the shortest tour possible which visits all the\ncities in list exactly once and ends in the city where it starts. Despite the\nTraveling Salesman Problem is NP-Hard, a lot of methods and solutions are\nproposed to the problem. One of them is Genetic Algorithm (GA). GA is a simple\nbut an efficient heuristic method that can be used to solve Traveling Salesman\nProblem. In this paper, we will show a parallel genetic algorithm\nimplementation on MapReduce framework in order to solve Traveling Salesman\nProblem. MapReduce is a framework used to support distributed computation on\nclusters of computers. We used free licensed Hadoop implementation as MapReduce\nframework.\n", "versions": [{"version": "v1", "created": "Fri, 24 Jan 2014 06:59:08 GMT"}], "update_date": "2014-01-27", "authors_parsed": [["Er", "Harun Rasit", ""], ["Erdogan", "Nadia", ""]]}, {"id": "1401.6615", "submitter": "Lewis Tseng", "authors": "Lewis Tseng, and Nitin Vaidya", "title": "Iterative Approximate Consensus in the presence of Byzantine Link\n  Failures", "comments": "arXiv admin note: text overlap with arXiv:1202.6094", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the problem of reaching approximate consensus in\nsynchronous point-to-point networks, where each directed link of the underlying\ncommunication graph represents a communication channel between a pair of nodes.\nWe adopt the transient Byzantine link failure model [15, 16], where an\nomniscient adversary controls a subset of the directed communication links, but\nthe nodes are assumed to be fault-free.\n  Recent work has addressed the problem of reaching approximate consen- sus in\nincomplete graphs with Byzantine nodes using a restricted class of iterative\nalgorithms that maintain only a small amount of memory across iterations [22,\n21, 23, 12]. However, to the best of our knowledge, we are the first to\nconsider approximate consensus in the presence of Byzan- tine links. We extend\nour past work that provided exact characterization of graphs in which the\niterative approximate consensus problem in the presence of Byzantine node\nfailures is solvable [22, 21]. In particular, we prove a tight necessary and\nsufficient condition on the underlying com- munication graph for the existence\nof iterative approximate consensus algorithms under transient Byzantine link\nmodel. The condition answers (part of) the open problem stated in [16].\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2014 05:45:02 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Tseng", "Lewis", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1401.6628", "submitter": "Yuqing Zhu", "authors": "Yuqing Zhu, Jianfeng Zhan, Chuliang Weng, Raghunath Nambiar, Jinchao\n  Zhang, Xingzhen Chen, and Lei Wang", "title": "BigOP: Generating Comprehensive Big Data Workloads as a Benchmarking\n  Framework", "comments": "10 pages, 3 figures", "journal-ref": "Database Systems for Advanced Applications: 19th International\n  Conference, DASFAA 2014, Bali, Indonesia, April 21-24, 2014", "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big Data is considered proprietary asset of companies, organizations, and\neven nations. Turning big data into real treasure requires the support of big\ndata systems. A variety of commercial and open source products have been\nunleashed for big data storage and processing. While big data users are facing\nthe choice of which system best suits their needs, big data system developers\nare facing the question of how to evaluate their systems with regard to general\nbig data processing needs. System benchmarking is the classic way of meeting\nthe above demands. However, existent big data benchmarks either fail to\nrepresent the variety of big data processing requirements, or target only one\nspecific platform, e.g. Hadoop.\n  In this paper, with our industrial partners, we present BigOP, an end-to-end\nsystem benchmarking framework, featuring the abstraction of representative\nOperation sets, workload Patterns, and prescribed tests. BigOP is part of an\nopen-source big data benchmarking project, BigDataBench. BigOP's abstraction\nmodel not only guides the development of BigDataBench, but also enables\nautomatic generation of tests with comprehensive workloads.\n  We illustrate the feasibility of BigOP by implementing an automatic test\ngeneration tool and benchmarking against three widely used big data processing\nsystems, i.e. Hadoop, Spark and MySQL Cluster. Three tests targeting three\ndifferent application scenarios are prescribed. The tests involve relational\ndata, text data and graph data, as well as all operations and workload\npatterns. We report results following test specifications.\n", "versions": [{"version": "v1", "created": "Sun, 26 Jan 2014 08:41:50 GMT"}, {"version": "v2", "created": "Wed, 27 Dec 2017 03:56:44 GMT"}], "update_date": "2017-12-29", "authors_parsed": [["Zhu", "Yuqing", ""], ["Zhan", "Jianfeng", ""], ["Weng", "Chuliang", ""], ["Nambiar", "Raghunath", ""], ["Zhang", "Jinchao", ""], ["Chen", "Xingzhen", ""], ["Wang", "Lei", ""]]}, {"id": "1401.6929", "submitter": "Wojciech Wislicki", "authors": "W. Wi\\'slicki, T. Bednarski, P. Bia{\\l}as, E. Czerwi\\'nski, {\\L}.\n  Kap{\\l}on, A. Kochanowski, G. Korcyl, J. Kowal, P. Kowalski, T. Kozik, W.\n  Krzemie\\'n, M. Molenda, P. Moskal, S. Nied\\'zwiecki, M. Pa{\\l}ka, M. Pawlik,\n  L. Raczy\\'nski, Z. Rudy, P. Salabura, N.G. Sharma, M. Silarski, A.\n  S{\\l}omski, J. Smyrski, A. Strzelecki, A. Wieczorek, M. Zieli\\'nski, N. Zo\\'n", "title": "Computing support for advanced medical data analysis and imaging", "comments": "9 p, 3 figs, based on talk given at Symposium on Positron Emission\n  Tomography, Sept. 19-22, 2013, Jagiellonian University, Krak\\'ow, Pl", "journal-ref": "Bio-Algorithms and Med-Systems 10(2014)52", "doi": "10.1515/bams-2014-0001", "report-no": null, "categories": "physics.comp-ph cs.CV cs.DC physics.ins-det physics.med-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss computing issues for data analysis and image reconstruction of\nPET-TOF medical scanner or other medical scanning devices producing large\nvolumes of data. Service architecture based on the grid and cloud concepts for\ndistributed processing is proposed and critically discussed.\n", "versions": [{"version": "v1", "created": "Mon, 27 Jan 2014 17:02:37 GMT"}], "update_date": "2014-05-27", "authors_parsed": [["Wi\u015blicki", "W.", ""], ["Bednarski", "T.", ""], ["Bia\u0142as", "P.", ""], ["Czerwi\u0144ski", "E.", ""], ["Kap\u0142on", "\u0141.", ""], ["Kochanowski", "A.", ""], ["Korcyl", "G.", ""], ["Kowal", "J.", ""], ["Kowalski", "P.", ""], ["Kozik", "T.", ""], ["Krzemie\u0144", "W.", ""], ["Molenda", "M.", ""], ["Moskal", "P.", ""], ["Nied\u017awiecki", "S.", ""], ["Pa\u0142ka", "M.", ""], ["Pawlik", "M.", ""], ["Raczy\u0144ski", "L.", ""], ["Rudy", "Z.", ""], ["Salabura", "P.", ""], ["Sharma", "N. G.", ""], ["Silarski", "M.", ""], ["S\u0142omski", "A.", ""], ["Smyrski", "J.", ""], ["Strzelecki", "A.", ""], ["Wieczorek", "A.", ""], ["Zieli\u0144ski", "M.", ""], ["Zo\u0144", "N.", ""]]}, {"id": "1401.7436", "submitter": "Rahim Rahmani", "authors": "Rahim Rahmani, Hasibur Rahman and Theo Kanter", "title": "On Performance of Logical-Clustering Of Flow-Sensors", "comments": "13 pages, 15 Figures and published on International Journal of\n  Computer Science Issues, IJCSI Volume 10 Issue 5, September 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In state-of-the-art Pervasive Computing, it is envisioned that unlimited\naccess to information will be facilitated for anyone and anything. Wireless\nsensor networks will play a pivotal role in the stated vision. This reflects\nthe phenomena where any situation can be sensed and analyzed anywhere. It makes\nheterogeneous context ubiquitous. Clustering context is one of the techniques\nto manage ubiquitous context information efficiently to maximize its potential.\nLogical-clustering is useful to share real-time context where sensors are\nphysically distributed but logically clustered. This paper investigates the\nnetwork performance of logical-clustering based on ns-3 simulations. In\nparticular reliability, scalability, and reachability in terms of delay,\njitter, and packet loss for the logically clustered network have been\ninvestigated. The performance study shows that jitter demonstrates 40 % and 44\n% fluctuation for 200 % increase in the node per cluster and 100 % increase in\nthe cluster size respectively. Packet loss exhibits only 18 % increase for 83 %\nincrease in the packet flow-rate.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 09:00:31 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Rahmani", "Rahim", ""], ["Rahman", "Hasibur", ""], ["Kanter", "Theo", ""]]}, {"id": "1401.7437", "submitter": "Rahim Rahmani", "authors": "Theo Kanter, Rahim Rahmani, and Arif Mahmud", "title": "Conceptual Framework for Internet of Things' Virtualization via OpenFlow\n  in Context-aware Networks", "comments": "12 pages, 19 Figures, 1 table", "journal-ref": "International Journal of Computer Science Issues, ISSN: 1694-0784,\n  1694-0814, November 2013 Issue (Volume 10, Issue 6)\n  http://ijcsi.org/papers/IJCSI-10-6-1-16-27.pdf", "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  A novel conceptual framework is presented in this paper with an aim to\nstandardize and virtualize Internet of Things(IoT) infrastructure through\ndeploying OpenFlow technology. The framework can receivee services based on\ncontext information leaving the current infrastructure unchanged. This\nframework allows the active collaboration of heterogeneous devices and\nprotocols. Moreover it is capable to model placement of physical objects,\nmanage the system and to collect information for services deployed on an IoT\ninfrastructure. Our proposed IoT virtualization is applicable to a random\ntopology scenario which makes it possible to 1) share flow sensors resources 2)\nestablish multioperational sensor networks, and 3) extend reachability within\nthe framework without establishing any further physical networks. Flow sensors\nachieve better results comparable to the typical sensors with respect to packet\ngeneration, reachability, simulation time, throughput, energy consumption point\nof view. Even better results are possible through utilizing multicast groups in\nlarge scale networks.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 09:00:41 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Kanter", "Theo", ""], ["Rahmani", "Rahim", ""], ["Mahmud", "Arif", ""]]}, {"id": "1401.7457", "submitter": "Ruibang Luo", "authors": "Chi-Man Liu, Ruibang Luo, Tak-Wah Lam", "title": "GPU-Accelerated BWT Construction for Large Collection of Short Reads", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.DC cs.DS q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in DNA sequencing technology have stimulated the development of\nalgorithms and tools for processing very large collections of short strings\n(reads). Short-read alignment and assembly are among the most well-studied\nproblems. Many state-of-the-art aligners, at their core, have used the\nBurrows-Wheeler transform (BWT) as a main-memory index of a reference genome\n(typical example, NCBI human genome). Recently, BWT has also found its use in\nstring-graph assembly, for indexing the reads (i.e., raw data from DNA\nsequencers). In a typical data set, the volume of reads is tens of times of the\nsequenced genome and can be up to 100 Gigabases. Note that a reference genome\nis relatively stable and computing the index is not a frequent task. For reads,\nthe index has to computed from scratch for each given input. The ability of\nefficient BWT construction becomes a much bigger concern than before. In this\npaper, we present a practical method called CX1 for constructing the BWT of\nvery large string collections. CX1 is the first tool that can take advantage of\nthe parallelism given by a graphics processing unit (GPU, a relative cheap\ndevice providing a thousand or more primitive cores), as well as simultaneously\nthe parallelism from a multi-core CPU and more interestingly, from a cluster of\nGPU-enabled nodes. Using CX1, the BWT of a short-read collection of up to 100\nGigabases can be constructed in less than 2 hours using a machine equipped with\na quad-core CPU and a GPU, or in about 43 minutes using a cluster with 4 such\nmachines (the speedup is almost linear after excluding the first 16 minutes for\nloading the reads from the hard disk). The previously fastest tool BRC is\nmeasured to take 12 hours to process 100 Gigabases on one machine; it is\nnon-trivial how BRC can be parallelized to take advantage a cluster of\nmachines, let alone GPUs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 10:06:07 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Liu", "Chi-Man", ""], ["Luo", "Ruibang", ""], ["Lam", "Tak-Wah", ""]]}, {"id": "1401.7494", "submitter": "Johannes Hofmann", "authors": "Johannes Hofmann, Jan Treibig, Georg Hager, Gerhard Wellein", "title": "Comparing the Performance of Different x86 SIMD Instruction Sets for a\n  Medical Imaging Application on Modern Multi- and Manycore Chips", "comments": "arXiv admin note: text overlap with arXiv:1401.3615", "journal-ref": null, "doi": "10.1145/2568058.2568068", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Single Instruction, Multiple Data (SIMD) vectorization is a major driver of\nperformance in current architectures, and is mandatory for achieving good\nperformance with codes that are limited by instruction throughput. We\ninvestigate the efficiency of different SIMD-vectorized implementations of the\nRabbitCT benchmark. RabbitCT performs 3D image reconstruction by back\nprojection, a vital operation in computed tomography applications. The\nunderlying algorithm is a challenge for vectorization because it consists,\napart from a streaming part, also of a bilinear interpolation requiring\nscattered access to image data. We analyze the performance of SSE (128 bit),\nAVX (256 bit), AVX2 (256 bit), and IMCI (512 bit) implementations on recent\nIntel x86 systems. A special emphasis is put on the vector gather\nimplementation on Intel Haswell and Knights Corner microarchitectures. Finally\nwe discuss why GPU implementations perform much better for this specific\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 12:41:44 GMT"}], "update_date": "2014-01-30", "authors_parsed": [["Hofmann", "Johannes", ""], ["Treibig", "Jan", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1401.7528", "submitter": "Reza Farrahi Moghaddam", "authors": "Reza Farrahi Moghaddam, Vahid Asghari, Fereydoun Farrahi Moghaddam,\n  Yves Lemieux, Mohamed Cheriet", "title": "A Monte-Carlo Approach to Lifespan Failure Performance Analysis of the\n  Network Fabric in Modular Data Centers", "comments": "29 Pages, 14 figures", "journal-ref": null, "doi": "10.1016/j.jnca.2017.03.015", "report-no": null, "categories": "cs.PF cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data centers have been evolved from a passive element of compute\ninfrastructure to become an active, core part of any ICT solution. In\nparticular, modular data centers (MDCs), which are a promising design approach\nto improve resiliency of data centers, can play a key role in deploying ICT\ninfrastructure in remote and inhospitable environments in order to take\nadvantage of low temperatures and hydro- and wind-electric capabilities. This\nis because of capability of the modular data centers to survive even in lack of\ncontinuous on-site maintenance and support. The most critical part of a data\ncenter is its network fabric that could impede the whole system even if all\nother components are fully functional, assuming that other analyses has been\nalready performed to ensure the reliability of the underlying infrastructure\nand support systems. In this work, a complete failure analysis of modular data\ncenters using failure models of various components including servers, switches,\nand links is performed using a proposed Monte-Carlo approach. The proposed\nMonte-Carlo approach, which is based on the concept of snapshots, allows us to\neffectively calculate the performance of a design along its lifespan even up to\nthe terminal stages. To show the capabilities of the proposed approach, various\nnetwork topologies, such as FatTree, BCube, MDCube, and their modifications are\nconsidered. The performance and also the lifespan of each topology design in\npresence of failures of their components are studied against the topology\nparameters.\n", "versions": [{"version": "v1", "created": "Wed, 29 Jan 2014 15:02:16 GMT"}, {"version": "v2", "created": "Wed, 12 Mar 2014 03:33:12 GMT"}, {"version": "v3", "created": "Wed, 22 Mar 2017 16:23:49 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Moghaddam", "Reza Farrahi", ""], ["Asghari", "Vahid", ""], ["Moghaddam", "Fereydoun Farrahi", ""], ["Lemieux", "Yves", ""], ["Cheriet", "Mohamed", ""]]}, {"id": "1401.8131", "submitter": "Ankit Mundra", "authors": "Bhagvan Krishna Gupta, Ankit Mundra, Nitin Rakesh", "title": "Failure Detection and Recovery in Hierarchical Network Using FTN\n  Approach", "comments": "8 pages, 7 figure. International Journal of Computer Science Issues,\n  2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current scenario several commercial and social organizations are using\ncomputer networks for their business and management purposes. In order to meet\nthe business requirements networks are also grow. The growth of network also\npromotes the handling capability of large networks because it counter raises\nthe possibilities of various faults in the network. A fault in network degrades\nits performance by affecting parameters like throughput, delay, latency,\nreliability etc. In hierarchical network models any possibility of fault may\ncollapse entire network. If a fault occurrence disables a device in\nhierarchical network then it may distresses all the devices underneath. Thus it\naffects entire networks performance. In this paper we propose Fault Tolerable\nhierarchical Network (FTN) approach as a solution to the problems of\nhierarchical networks. The proposed approach firstly detects possibilities of\nfault in the network and accordingly provides specific recovery mechanism. We\nhave evaluated the performance of FTN approach in terms of delay and throughput\nof network.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jan 2014 11:06:41 GMT"}], "update_date": "2014-02-03", "authors_parsed": [["Gupta", "Bhagvan Krishna", ""], ["Mundra", "Ankit", ""], ["Rakesh", "Nitin", ""]]}]