[{"id": "1610.00024", "submitter": "Snehanshu Saha", "authors": "Gambhire Swati Sampatrao, Sudeepa Roy Dey, Bidisha Goswami, Sai\n  Prasanna M.S, Snehanshu Saha", "title": "A Study of Revenue Cost Dynamics in Large Data Centers: A Factorial\n  Design Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Revenue optimization of large data centers is an open and challenging\nproblem. The intricacy of the problem is due to the presence of too many\nparameters posing as costs or investment. This paper proposes a model to\noptimize the revenue in cloud data center and analyzes the model, revenue and\ndifferent investment or cost commitments of organizations investing in data\ncenters. The model uses the Cobb-Douglas production function to quantify the\nboundaries and the most significant factors to generate the revenue. The\ndynamics between revenue and cost is explored by designing an experiment (DoE)\nwhich is an interpretation of revenue as function of cost/investment as factors\nwith different levels/fluctuations. Optimal elasticities associated with these\nfactors of the model for maximum revenue are computed and verified . The model\nresponse is interpreted in light of the business scenario of data centers.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 20:29:01 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Sampatrao", "Gambhire Swati", ""], ["Dey", "Sudeepa Roy", ""], ["Goswami", "Bidisha", ""], ["S", "Sai Prasanna M.", ""], ["Saha", "Snehanshu", ""]]}, {"id": "1610.00049", "submitter": "Ali Shoker", "authors": "Ali Shoker", "title": "Exploiting Universal Redundancy", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault tolerance is essential for building reliable services; however, it\ncomes at the price of redundancy, mainly the \"replication factor\" and\n\"diversity\". With the increasing reliance on Internet-based services, more\nmachines (mainly servers) are needed to scale out, multiplied with the extra\nexpense of replication. This paper revisits the very fundamentals of fault\ntolerance and presents \"artificial redundancy\": a formal generalization of\n\"exact copy\" redundancy in which new sources of redundancy are exploited to\nbuild fault tolerant systems. On this concept, we show how to build \"artificial\nreplication\" and design \"artificial fault tolerance\" (AFT). We discuss the\nproperties of these new techniques showing that AFT extends current fault\ntolerant approaches to use other forms of redundancy aiming at reduced cost and\nhigh diversity.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 22:35:27 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Shoker", "Ali", ""]]}, {"id": "1610.00125", "submitter": "Yiannis Andreopoulos", "authors": "Joseph Doyle, Vasileios Giotsas, Mohammad Ashraful Anam and Yiannis\n  Andreopoulos", "title": "Dithen: A Computation-as-a-Service Cloud Platform For Large-Scale\n  Multimedia Processing", "comments": "to appear in IEEE Transactions on Cloud Computing. arXiv admin note:\n  substantial text overlap with arXiv:1604.04804", "journal-ref": null, "doi": "10.1109/TCC.2016.2617363", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Dithen, a novel computation-as-a-service (CaaS) cloud platform\nspecifically tailored to the parallel execution of large-scale multimedia\ntasks. Dithen handles the upload/download of both multimedia data and\nexecutable items, the assignment of compute units to multimedia workloads, and\nthe reactive control of the available compute units to minimize the cloud\ninfrastructure cost under deadline-abiding execution. Dithen combines three key\nproperties: (i) the reactive assignment of individual multimedia tasks to\navailable computing units according to availability and predetermined\ntime-to-completion constraints; (ii) optimal resource estimation based on\nKalman-filter estimates; (iii) the use of additive increase multiplicative\ndecrease (AIMD) algorithms (famous for being the resource management in the\ntransport control protocol) for the control of the number of units servicing\nworkloads. The deployment of Dithen over Amazon EC2 spot instances is shown to\nbe capable of processing more than 80,000 video transcoding, face detection and\nimage processing tasks (equivalent to the processing of more than 116 GB of\ncompressed data) for less than $1 in billing cost from EC2. Moreover, the\nproposed AIMD-based control mechanism, in conjunction with the Kalman\nestimates, is shown to provide for more than 27% reduction in EC2 spot instance\ncost against methods based on reactive resource estimation. Finally, Dithen is\nshown to offer a 38% to 500% reduction of the billing cost against the current\nstate-of-the-art in CaaS platforms on Amazon EC2 (Amazon Lambda and Amazon\nAutoscale). A baseline version of Dithen is currently available at\nhttp://www.dithen.com under the \"AutoScale\" option.\n", "versions": [{"version": "v1", "created": "Sat, 1 Oct 2016 12:33:35 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Doyle", "Joseph", ""], ["Giotsas", "Vasileios", ""], ["Anam", "Mohammad Ashraful", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "1610.00289", "submitter": "Bechir Hamdaoui", "authors": "Sherif Abdelwahab and Bechir Hamdaoui", "title": "Flocking Virtual Machines in Quest for Responsive IoT Cloud Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Flock; a simple and scalable protocol that enables live migration\nof Virtual Machines (VMs) across heterogeneous edge and conventional cloud\nplatforms to improve the responsiveness of cloud services. Flock is designed\nwith properties that are suitable for the use cases of the Internet of Things\n(IoT). We describe the properties of regularized latency measurements that\nFlock can use for asynchronous and autonomous migration decisions. Such\ndecisions allow communicating VMs to follow a flocking-like behavior that\nconsists of three simple rules: separation, alignment, and cohesion. Using game\ntheory, we derive analytical bounds on Flock's Price of Anarchy (PoA), and\nprove that flocking VMs converge to a Nash Equilibrium while settling in the\nbest possible cloud platforms. We verify the effectiveness of Flock through\nsimulations and discuss how its generic objective can simply be tweaked to\nachieve other objectives, such as cloud load balancing and energy consumption\nminimization.\n", "versions": [{"version": "v1", "created": "Sun, 2 Oct 2016 15:47:20 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Abdelwahab", "Sherif", ""], ["Hamdaoui", "Bechir", ""]]}, {"id": "1610.00457", "submitter": "Dinesh Dash", "authors": "Dinesh Dash, Anurag Dasgupta", "title": "Energy Efficient Restoring of Barrier Coverage in Wireless Sensor\n  Networks Using Limited Mobility Sensors", "comments": "20 pages, 8 figures", "journal-ref": "IET Wireless Sensor System, 2017", "doi": "10.1049/iet-wss.2017.0020", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Wireless Sensor Networks, sensors are used for tracking objects,\nmonitoring health and observing a region/territory for different environmental\nparameters. Coverage problem in sensor network ensures quality of monitoring a\ngiven region. Depending on applications different measures of coverage are\nthere. Barrier coverage is a type of coverage, which ensures all paths that\ncross the boundary of a region intersect at least one sensor's sensing region.\nThe goal of the sensors is to detect intruders as they cross the boundary or as\nthey penetrate a protected area. The sensors are dependent on their battery\nlife. Restoring barrier coverage on sensor failure using mobile sensors with\nminimum total displacement is the primary objective of this paper. A\ncentralized barrier coverage restoring scheme is proposed to increase the\nrobustness of the network. We formulate restoring barrier coverage as bipartite\nmatching problem. A distributed restoring of barrier coverage algorithm is also\nproposed, which restores it by first finding existing alternate barrier. If\nalternate barrier is not found, an alternate barrier is reconstructed by\nshifting existing sensors in a cascaded manner. Detailed simulation results are\nshown to evaluate the performance of our algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 09:18:16 GMT"}], "update_date": "2017-11-16", "authors_parsed": [["Dash", "Dinesh", ""], ["Dasgupta", "Anurag", ""]]}, {"id": "1610.00620", "submitter": "Bechir Hamdaoui", "authors": "Sherif Abdelwahab and Bechir Hamdaoui", "title": "FogMQ: A Message Broker System for Enabling Distributed, Internet-Scale\n  IoT Applications over Heterogeneous Cloud Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Excessive tail end-to-end latency occurs with conventional message brokers as\na result of having massive numbers of geographically distributed devices\ncommunicate through a message broker. On the other hand, broker-less messaging\nsystems, though ensure low latency, are highly dependent on the limitation of\ndirect device-to-device (D2D) communication technologies, and cannot scale well\nas large numbers of resource-limited devices exchange messages. In this paper,\nwe propose FogMQ, a cloud-based message broker system that overcomes the\nlimitations of conventional systems by enabling autonomous discovery,\nself-deployment, and online migration of message brokers across heterogeneous\ncloud platforms. For each device, FogMQ provides a high capacity device cloning\nservice that subscribes to device messages. The clones facilitate near-the-edge\ndata analytics in resourceful cloud compute nodes. Clones in FogMQ apply Flock,\nan algorithm mimicking flocking-like behavior to allow clones to dynamically\nselect and autonomously migrate to different heterogeneous cloud platforms in a\ndistributed manner.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 16:23:05 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Abdelwahab", "Sherif", ""], ["Hamdaoui", "Bechir", ""]]}, {"id": "1610.00624", "submitter": "Snehanshu Saha", "authors": "Jyotirmoy Sarkar, Bidisha Goswami, Snehanshu Saha and Saibal Kar", "title": "CDSFA Stochastic Frontier Analysis Approach to Revenue Modeling in Large\n  Cloud Data Centers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Enterprises are investing heavily in cloud data centers to meet the ever\nsurging business demand. Data Center is a facility, which houses computer\nsystems and associated components, such as telecommunications and storage\nsystems. It generally includes power supply equipment, communication\nconnections and cooling equipment. A large data center can use as much\nelectricity as a small town. Due to the emergence of data center based\ncomputing services, it has become necessary to examine how the costs associated\nwith data centers evolve over time, mainly in view of efficiency issues. We\nhave presented a quasi form of Cobb Douglas model, which addresses revenue and\nprofit issues in running large data centers. The stochastic form has been\nintroduced and explored along with the quasi Cobb Douglas model to understand\nthe behavior of the model in depth. Harrod neutrality and Solow neutrality are\nincorporated in the model to identify the technological progress in cloud data\ncenters. This allows us to shed light on the stochastic uncertainty of cloud\ndata center operations. A general approach to optimizing the revenue cost of\ndata centers using Cobb Douglas Stochastic Frontier Analysis,CDSFA is\npresented. Next, we develop the optimization model for large data centers. The\nmathematical basis of CDSFA has been utilized for cost optimization and profit\nmaximization in data centers. The results are found to be quite useful in view\nof production reorganization in large data centers around the world.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 16:36:44 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Sarkar", "Jyotirmoy", ""], ["Goswami", "Bidisha", ""], ["Saha", "Snehanshu", ""], ["Kar", "Saibal", ""]]}, {"id": "1610.00664", "submitter": "Dionysios Logothetis", "authors": "Sergey Edunov, Dionysios Logothetis, Cheng Wang, Avery Ching, Maja\n  Kabiljo", "title": "Darwini: Generating realistic large-scale social graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Synthetic graph generators facilitate research in graph algorithms and\nprocessing systems by providing access to data, for instance, graphs resembling\nsocial networks, while circumventing privacy and security concerns.\nNevertheless, their practical value lies in their ability to capture important\nmetrics of real graphs, such as degree distribution and clustering properties.\nGraph generators must also be able to produce such graphs at the scale of\nreal-world industry graphs, that is, hundreds of billions or trillions of\nedges.\n  In this paper, we propose Darwini, a graph generator that captures a number\nof core characteristics of real graphs. Importantly, given a source graph, it\ncan reproduce the degree distribution and, unlike existing approaches, the\nlocal clustering coefficient and joint-degree distributions. Furthermore,\nDarwini maintains metrics such node PageRank, eigenvalues and the K-core\ndecomposition of a source graph. Comparing Darwini with state-of-the-art\ngenerative models, we show that it can reproduce these characteristics more\naccurately. Finally, we provide an open source implementation of our approach\non the vertex-centric Apache Giraph model that allows us to create synthetic\ngraphs with one trillion edges.\n", "versions": [{"version": "v1", "created": "Mon, 3 Oct 2016 18:29:08 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Edunov", "Sergey", ""], ["Logothetis", "Dionysios", ""], ["Wang", "Cheng", ""], ["Ching", "Avery", ""], ["Kabiljo", "Maja", ""]]}, {"id": "1610.01004", "submitter": "Brijesh Dongol", "authors": "Alasdair Armstrong, Brijesh Dongol, Simon Doherty", "title": "Reducing Opacity to Linearizability: A Sound and Complete Method", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transactional memory is a mechanism that manages thread synchronisation on\nbehalf of a programmer so that blocks of code execute with an illusion of\natomicity. The main safety criterion for transactional memory is opacity, which\ndefines conditions for serialising concurrent transactions.\n  Proving opacity is complicated because it allows concurrent transactions to\nobserve distinct memory states, while TM implementations are typically based on\none single shared store. This paper presents a sound and complete method, based\non coarse-grained abstraction, for reducing proofs of opacity to the relatively\nsimpler correctness condition: linearizability. We use our methods to verify\nTML and NORec from the literature and show our techniques extend to relaxed\nmemory models by showing that both are opaque under TSO without requiring\nadditional fences. Our methods also elucidate TM designs at higher level of\nabstraction; as an application, we develop a variation of NORec with fast-path\nreads transactions. All our proofs have been mechanised, either in the Isabelle\ntheorem prover or the PAT model checker.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 14:07:52 GMT"}], "update_date": "2016-10-05", "authors_parsed": [["Armstrong", "Alasdair", ""], ["Dongol", "Brijesh", ""], ["Doherty", "Simon", ""]]}, {"id": "1610.01140", "submitter": "Pamela Zave", "authors": "Pamela Zave", "title": "Reasoning about identifier spaces: How to make Chord correct", "comments": "14 pages including references; 6 figures. arXiv admin note: text\n  overlap with arXiv:1502.06461", "journal-ref": "ACM/IEEE Transactions on Software Engineering, December 2017", "doi": "10.1109/TSE.2017.2655056", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Chord distributed hash table (DHT) is well-known and often used to\nimplement peer-to-peer systems. Chord peers find other peers, and access their\ndata, through a ring-shaped pointer structure in a large identifier space.\nDespite claims of proven correctness, i.e., eventual reachability, previous\nwork has shown that the Chord ring-maintenance protocol is not correct under\nits original operating assumptions. Previous work has not, however, discovered\nwhether Chord could be made correct under the same assumptions. The\ncontribution of this paper is to provide the first specification of correct\noperations and initialization for Chord, an inductive invariant that is\nnecessary and sufficient to support a proof of correctness, and two independent\nproofs of correctness. One proof is informal and intuitive, and applies to\nnetworks of any size. The other proof is based on a formal model in Alloy, and\nuses fully automated analysis to prove the assertions for networks of bounded\nsize. The two proofs complement each other in several important ways.\n", "versions": [{"version": "v1", "created": "Tue, 4 Oct 2016 19:42:13 GMT"}, {"version": "v2", "created": "Thu, 25 Jul 2019 14:12:51 GMT"}], "update_date": "2019-07-26", "authors_parsed": [["Zave", "Pamela", ""]]}, {"id": "1610.01295", "submitter": "Gabriele D'Angelo", "authors": "Gabriele D'Angelo", "title": "The Simulation Model Partitioning Problem: an Adaptive Solution Based on\n  Self-Clustering (Extended Version)", "comments": null, "journal-ref": "Simulation Modelling Practice and Theory, Elsevier, Volume 70,\n  January 2017 pages 1-20", "doi": "10.1016/j.simpat.2016.10.001", "report-no": null, "categories": "cs.DC cs.MA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about partitioning in parallel and distributed simulation. That\nmeans decomposing the simulation model into a numberof components and to\nproperly allocate them on the execution units. An adaptive solution based on\nself-clustering, that considers both communication reduction and computational\nload-balancing, is proposed. The implementation of the proposed mechanism is\ntested using a simulation model that is challenging both in terms of structure\nand dynamicity. Various configurations of the simulation model and the\nexecution environment have been considered. The obtained performance results\nare analyzed using a reference cost model. The results demonstrate that the\nproposed approach is promising and that it can reduce the simulation execution\ntime in both parallel and distributed architectures.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 07:30:54 GMT"}, {"version": "v2", "created": "Fri, 4 Nov 2016 12:16:11 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["D'Angelo", "Gabriele", ""]]}, {"id": "1610.01423", "submitter": "Petr  Kuznetsov", "authors": "Eli Gafni, Yuan He, Petr Kuznetsov, Thibault Rieutord", "title": "Read-Write Memory and k-Set Consensus as an Affine Task", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The wait-free read-write memory model has been characterized as an iterated\n\\emph{Immediate Snapshot} (IS) task. The IS task is \\emph{affine}---it can be\ndefined as a (sub)set of simplices of the standard chromatic subdivision. It is\nknown that the task of \\emph{Weak Symmetry Breaking} (WSB) cannot be\nrepresented as an affine task. In this paper, we highlight the phenomenon of a\n\"natural\" model that can be captured by an iterated affine task and, thus, by a\nsubset of runs of the iterated immediate snapshot model. We show that the\nread-write memory model in which, additionally, $k$-set-consensus objects can\nbe used is, unlike WSB, \"natural\" by presenting the corresponding simple affine\ntask captured by a subset of $2$-round IS runs. Our results imply the first\ncombinatorial characterization of models equipped with abstractions other than\nread-write memory that applies to generic tasks.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 14:01:56 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["Gafni", "Eli", ""], ["He", "Yuan", ""], ["Kuznetsov", "Petr", ""], ["Rieutord", "Thibault", ""]]}, {"id": "1610.01458", "submitter": "Dariusz Dereniowski", "authors": "Dariusz Dereniowski and Dorota Urba\\'nska", "title": "Distributed Searching of Partial Grids", "comments": null, "journal-ref": "Theory of Computing Systems 63(8): 1819-1848 (2019)", "doi": "10.1007/s00224-019-09948-6", "report-no": null, "categories": "cs.DM cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following distributed pursuit-evasion problem. A team of\nmobile agents called searchers starts at an arbitrary node of an unknown\n$n$-node network. Their goal is to execute a search strategy that guarantees\ncapturing a fast and invisible intruder regardless of its movements using as\nfew agents as possible. We restrict our attention to networks that are embedded\ninto partial grids: nodes are placed on the plane at integer coordinates and\nonly nodes at distance one can be adjacent. We give a distributed algorithm for\nthe searchers that allow them to compute a connected and monotone strategy that\nguarantees searching any unknown partial grid with the use of $O(\\sqrt{n})$\nsearchers. As for a lower bound, not only there exist partial grids that\nrequire $\\Omega(\\sqrt{n})$ searchers, but we prove that for each distributed\nsearching algorithm there is a partial grid that forces the algorithm to use\n$\\Omega(\\sqrt{n})$ searchers but $O(\\log n)$ searchers are sufficient in the\noffline scenario. This gives a lower bound of $\\Omega(\\sqrt{n}/\\log n)$ in\nterms of achievable competitive ratio of any distributed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 14:47:54 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Dereniowski", "Dariusz", ""], ["Urba\u0144ska", "Dorota", ""]]}, {"id": "1610.01482", "submitter": "Karl F\\\"urlinger", "authors": "Karl F\\\"urlinger and Tobias Fuchs and Roger Kowalewski", "title": "DASH: A C++ PGAS Library for Distributed Data Structures and Parallel\n  Algorithms", "comments": "Accepted for publication at HPCC 2016, 12-14 December 2016, Syndey\n  Australia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DASH, a C++ template library that offers distributed data\nstructures and parallel algorithms and implements a compiler-free PGAS\n(partitioned global address space) approach. DASH offers many productivity and\nperformance features such as global-view data structures, efficient support for\nthe owner-computes model, flexible multidimensional data distribution schemes\nand inter-operability with STL (standard template library) algorithms. DASH\nalso features a flexible representation of the parallel target machine and\nallows the exploitation of several hierarchically organized levels of locality\nthrough a concept of Teams. We evaluate DASH on a number of benchmark\napplications and we port a scientific proxy application using the MPI two-sided\nmodel to DASH. We find that DASH offers excellent productivity and performance\nand demonstrate scalability up to 9800 cores.\n", "versions": [{"version": "v1", "created": "Wed, 5 Oct 2016 15:37:07 GMT"}], "update_date": "2016-10-06", "authors_parsed": [["F\u00fcrlinger", "Karl", ""], ["Fuchs", "Tobias", ""], ["Kowalewski", "Roger", ""]]}, {"id": "1610.01728", "submitter": "Saurabh Hukerikar", "authors": "Saurabh Hukerikar, Keita Teranishi, Pedro C. Diniz and Robert F. Lucas", "title": "RedThreads: An Interface for Application-level Fault\n  Detection/Correction through Adaptive Redundant Multithreading", "comments": "Submitted to Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the presence of accelerated fault rates, which are projected to be the\nnorm on future exascale systems, it will become increasingly difficult for\nhigh-performance computing (HPC) applications to accomplish useful computation.\nDue to the fault-oblivious nature of current HPC programming paradigms and\nexecution environments, HPC applications are insufficiently equipped to deal\nwith errors. We believe that HPC applications should be enabled with\ncapabilities to actively search for and correct errors in their computations.\nThe redundant multithreading (RMT) approach offers lightweight replicated\nexecution streams of program instructions within the context of a single\napplication process. However, the use of complete redundancy incurs significant\noverhead to the application performance.\n  In this paper we present RedThreads, an interface that provides\napplication-level fault detection and correction based on RMT, but applies the\nthread-level redundancy adaptively. We describe the RedThreads syntax and\nsemantics, and the supporting compiler infrastructure and runtime system. Our\napproach enables application programmers to scope the extent of redundant\ncomputation. Additionally, the runtime system permits the use of RMT to be\ndynamically enabled, or disabled, based on the resiliency needs of the\napplication and the state of the system. Our experimental results demonstrate\nhow adaptive RMT exploits programmer insight and runtime inference to\ndynamically navigate the trade-off space between an application's resilience\ncoverage and the associated performance overhead of redundant computation.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 04:29:57 GMT"}, {"version": "v2", "created": "Tue, 17 Jan 2017 19:34:28 GMT"}], "update_date": "2017-01-19", "authors_parsed": [["Hukerikar", "Saurabh", ""], ["Teranishi", "Keita", ""], ["Diniz", "Pedro C.", ""], ["Lucas", "Robert F.", ""]]}, {"id": "1610.01784", "submitter": "Qiang Wang", "authors": "Xinxin Mei, Qiang Wang, Xiaowen Chu", "title": "A Survey and Measurement Study of GPU DVFS on Energy Conservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy efficiency has become one of the top design criteria for current\ncomputing systems. The dynamic voltage and frequency scaling (DVFS) has been\nwidely adopted by laptop computers, servers, and mobile devices to conserve\nenergy, while the GPU DVFS is still at a certain early age. This paper aims at\nexploring the impact of GPU DVFS on the application performance and power\nconsumption, and furthermore, on energy conservation. We survey the\nstate-of-the-art GPU DVFS characterizations, and then summarize recent research\nworks on GPU power and performance models. We also conduct real GPU DVFS\nexperiments on NVIDIA Fermi and Maxwell GPUs. According to our experimental\nresults, GPU DVFS has significant potential for energy saving. The effect of\nscaling core voltage/frequency and memory voltage/frequency depends on not only\nthe GPU architectures, but also the characteristic of GPU applications.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 09:21:22 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Mei", "Xinxin", ""], ["Wang", "Qiang", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1610.01807", "submitter": "Junbo Zhang", "authors": "Junbo Zhang, Tianrui Li, Yi Pan", "title": "Parallel Large-Scale Attribute Reduction on Cloud Systems", "comments": "14 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of emerging information technologies and application\npatterns in modern society, e.g., Internet, Internet of Things, Cloud Computing\nand Tri-network Convergence, has caused the advent of the era of big data. Big\ndata contains huge values, however, mining knowledge from big data is a\ntremendously challenging task because of data uncertainty and inconsistency.\nAttribute reduction (also known as feature selection) can not only be used as\nan effective preprocessing step, but also exploits the data redundancy to\nreduce the uncertainty. However, existing solutions are designed 1) either for\na single machine that means the entire data must fit in the main memory and the\nparallelism is limited; 2) or for the Hadoop platform which means that the data\nhave to be loaded into the distributed memory frequently and therefore become\ninefficient. In this paper, we overcome these shortcomings for maximum\nefficiency possible, and propose a unified framework for Parallel Large-scale\nAttribute Reduction, termed PLAR, for big data analysis. PLAR consists of three\ncomponents: 1) Granular Computing (GrC)-based initialization: it converts a\ndecision table (i.e., original data representation) into a granularity\nrepresentation which reduces the amount of space and hence can be easily cached\nin the distributed memory: 2) model-parallelism: it simultaneously evaluates\nall feature candidates and makes attribute reduction highly parallelizable; 3)\ndata-parallelism: it computes the significance of an attribute in parallel\nusing a MapReduce-style manner. We implement PLAR with four representative\nheuristic feature selection algorithms on Spark, and evaluate them on various\nhuge datasets, including UCI and astronomical datasets, finding our method's\nadvantages beyond existing solutions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 10:36:48 GMT"}], "update_date": "2016-10-07", "authors_parsed": [["Zhang", "Junbo", ""], ["Li", "Tianrui", ""], ["Pan", "Yi", ""]]}, {"id": "1610.02084", "submitter": "Cameron Musco", "authors": "Nancy Lynch, Cameron Musco, Merav Parter", "title": "Computational Tradeoffs in Biological Neural Networks: Self-Stabilizing\n  Winner-Take-All Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a line of investigation into biological neural networks from an\nalgorithmic perspective. We develop a simplified but biologically plausible\nmodel for distributed computation in stochastic spiking neural networks and\nstudy tradeoffs between computation time and network complexity in this model.\nOur aim is to abstract real neural networks in a way that, while not capturing\nall interesting features, preserves high-level behavior and allows us to make\nbiologically relevant conclusions.\n  In this paper, we focus on the important `winner-take-all' (WTA) problem,\nwhich is analogous to a neural leader election unit: a network consisting of\n$n$ input neurons and $n$ corresponding output neurons must converge to a state\nin which a single output corresponding to a firing input (the `winner') fires,\nwhile all other outputs remain silent. Neural circuits for WTA rely on\ninhibitory neurons, which suppress the activity of competing outputs and drive\nthe network towards a converged state with a single firing winner. We attempt\nto understand how the number of inhibitors used affects network convergence\ntime.\n  We show that it is possible to significantly outperform naive WTA\nconstructions through a more refined use of inhibition, solving the problem in\n$O(\\theta)$ rounds in expectation with just $O(\\log^{1/\\theta} n)$ inhibitors\nfor any $\\theta$. An alternative construction gives convergence in\n$O(\\log^{1/\\theta} n)$ rounds with $O(\\theta)$ inhibitors. We compliment these\nupper bounds with our main technical contribution, a nearly matching lower\nbound for networks using $\\ge \\log\\log n$ inhibitors. Our lower bound uses\nfamiliar indistinguishability and locality arguments from distributed computing\ntheory. It lets us derive a number of interesting conclusions about the\nstructure of any network solving WTA with good probability, and the use of\nrandomness and inhibition within such a network.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 21:56:38 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Lynch", "Nancy", ""], ["Musco", "Cameron", ""], ["Parter", "Merav", ""]]}, {"id": "1610.02143", "submitter": "Tianyi Chen", "authors": "Tianyi Chen, Aryan Mokhtari, Xin Wang, Alejandro Ribeiro, and Georgios\n  B. Giannakis", "title": "Stochastic Averaging for Constrained Optimization with Application to\n  Online Resource Allocation", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2017.2679690", "report-no": null, "categories": "math.OC cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing approaches to resource allocation for nowadays stochastic networks\nare challenged to meet fast convergence and tolerable delay requirements. The\npresent paper leverages online learning advances to facilitate stochastic\nresource allocation tasks. By recognizing the central role of Lagrange\nmultipliers, the underlying constrained optimization problem is formulated as a\nmachine learning task involving both training and operational modes, with the\ngoal of learning the sought multipliers in a fast and efficient manner. To this\nend, an order-optimal offline learning approach is developed first for batch\ntraining, and it is then generalized to the online setting with a procedure\ntermed learn-and-adapt. The novel resource allocation protocol permeates\nbenefits of stochastic approximation and statistical learning to obtain\nlow-complexity online updates with learning errors close to the statistical\naccuracy limits, while still preserving adaptation performance, which in the\nstochastic network optimization context guarantees queue stability. Analysis\nand simulated tests demonstrate that the proposed data-driven approach improves\nthe delay and convergence performance of existing resource allocation schemes.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 05:11:23 GMT"}, {"version": "v2", "created": "Sun, 26 Feb 2017 06:31:20 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Chen", "Tianyi", ""], ["Mokhtari", "Aryan", ""], ["Wang", "Xin", ""], ["Ribeiro", "Alejandro", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1610.02273", "submitter": "Hyeokjun Choe", "authors": "Hyeokjun Choe, Seil Lee, Hyunha Nam, Seongsik Park, Seijoon Kim,\n  Eui-Young Chung, Sungroh Yoon", "title": "Near-Data Processing for Differentiable Machine Learning Models", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Near-data processing (NDP) refers to augmenting memory or storage with\nprocessing power. Despite its potential for acceleration computing and reducing\npower requirements, only limited progress has been made in popularizing NDP for\nvarious reasons. Recently, two major changes have occurred that have ignited\nrenewed interest and caused a resurgence of NDP. The first is the success of\nmachine learning (ML), which often demands a great deal of computation for\ntraining, requiring frequent transfers of big data. The second is the\npopularity of NAND flash-based solid-state drives (SSDs) containing multicore\nprocessors that can accommodate extra computation for data processing. In this\npaper, we evaluate the potential of NDP for ML using a new SSD platform that\nallows us to simulate instorage processing (ISP) of ML workloads. Our platform\n(named ISP-ML) is a full-fledged simulator of a realistic multi-channel SSD\nthat can execute various ML algorithms using data stored in the SSD. To conduct\na thorough performance analysis and an in-depth comparison with alternative\ntechniques, we focus on a specific algorithm: stochastic gradient descent\n(SGD), which is the de facto standard for training differentiable models such\nas logistic regression and neural networks. We implement and compare three SGD\nvariants (synchronous, Downpour, and elastic averaging) using ISP-ML,\nexploiting the multiple NAND channels to parallelize SGD. In addition, we\ncompare the performance of ISP and that of conventional in-host processing,\nrevealing the advantages of ISP. Based on the advantages and limitations\nidentified through our experiments, we further discuss directions for future\nresearch on ISP for accelerating ML.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 05:28:33 GMT"}, {"version": "v2", "created": "Wed, 9 Nov 2016 01:58:47 GMT"}, {"version": "v3", "created": "Fri, 28 Apr 2017 03:57:56 GMT"}], "update_date": "2017-05-01", "authors_parsed": [["Choe", "Hyeokjun", ""], ["Lee", "Seil", ""], ["Nam", "Hyunha", ""], ["Park", "Seongsik", ""], ["Kim", "Seijoon", ""], ["Chung", "Eui-Young", ""], ["Yoon", "Sungroh", ""]]}, {"id": "1610.02288", "submitter": "Vincenzo De Florio", "authors": "Vincenzo De Florio", "title": "The Voting Farm: A Distributed Class for Software Voting", "comments": "Revised version of Technical Report ESAT/ACCA/1997/3, ESAT Dept.,\n  University of Leuven, Belgium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document describes a class of C functions implementing a distributed\nsoftware voting mechanism for EPX or similar message passing multi-threaded\nenvironments. Such a tool may be used for example, to set up a restoring organ,\ni.e., an NMR (i.e., N-module redundant) system with N voters. In order to\ndescribe the tool we start defining its basic building block, the voter. A\nvoter is defined as a software module connected to one user module and to a\nfarm of fellow voters arranged into a clique. By means of the functions in the\nclass the user module is able: to create a static \"picture\" of the voting farm,\nneeded for the set up of the clique; to instantiate the local voter; to send\ninput or control messages to that voter. No interlocutor is needed other than\nthe local voter. The other user modules are supposed to create coherent\npictures and instances of voters on other nodes of the machine and to manage\nconsistently the task of their local intermediary. All technicalities\nconcerning the set up of the clique and the exchange of messages between the\nvoters are completely transparent to the user module. In the following the\nbasic functionalities of the VotingFarm class will be discussed, namely how to\nset up a \"passive farm\", or a non-alive topological representation of a\nyet-to-be-activated voting farm; how to initiate the voting farm; how to\ncontrol the farm.\n", "versions": [{"version": "v1", "created": "Sat, 27 Feb 2016 21:11:27 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["De Florio", "Vincenzo", ""]]}, {"id": "1610.02291", "submitter": "Bin Liu", "authors": "Jiejie Wang, Bin Liu", "title": "Online Fault-Tolerant Dynamic Event Region Detection in Sensor Networks\n  via Trust Model", "comments": "8 pages, 3 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a Bayesian modeling approach to address the problem of\nonline fault-tolerant dynamic event region detection in wireless sensor\nnetworks. In our model every network node is associated with a virtual\ncommunity and a trust index, which quantitatively measures the trustworthiness\nof this node in its community. If a sensor node's trust value is smaller than a\nthreshold, it suggests that this node encounters a fault and thus its sensor\nreading can not be trusted at this moment. This concept of sensor node trust\ndiscriminates our model with the other alternatives, e.g.,the Markov random\nfields. The practical issues, including spatiotemporal correlations of neighbor\nnodes' sensor readings, the presence of sensor faults and the requirement of\nonline processing are linked together by the concept trust and are all taken\ninto account in the modeling stage. Based on the proposed model, the trust\nvalue of each node is updated online by a particle filter algorithm upon the\narrival of new observations. The decision on whether a node is located in the\nevent region is made based upon the current estimate of this node's trust\nvalue. Experimental results demonstrate that the proposed solution can provide\nstriking better performance than existent methods in terms of error rate in\ndetecting the event region.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 14:00:56 GMT"}, {"version": "v2", "created": "Fri, 16 Dec 2016 17:19:44 GMT"}], "update_date": "2016-12-19", "authors_parsed": [["Wang", "Jiejie", ""], ["Liu", "Bin", ""]]}, {"id": "1610.02327", "submitter": "Roly Perera", "authors": "Roly Perera, Deepak Garg, James Cheney", "title": "Causally consistent dynamic slicing", "comments": "in Proceedings of 27th International Conference on Concurrency Theory\n  (CONCUR 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We offer a lattice-theoretic account of dynamic slicing for {\\pi}-calculus,\nbuilding on prior work in the sequential setting. For any run of a concurrent\nprogram, we exhibit a Galois connection relating forward slices of the start\nconfiguration to backward slices of the end configuration. We prove that, up to\nlattice isomorphism, the same Galois connection arises for any causally\nequivalent execution, allowing an efficient concurrent implementation of\nslicing via a standard interleaving semantics. Our approach has been formalised\nin the dependently-typed language Agda.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 15:35:30 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Perera", "Roly", ""], ["Garg", "Deepak", ""], ["Cheney", "James", ""]]}, {"id": "1610.02333", "submitter": "Fahim Imam", "authors": "Fahim T. Imam", "title": "Application of Ontologies in Cloud Computing: The State-Of-The-Art", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper presents a systematic survey on existing literature and seminal\nworks relevant to the application of ontologies in different aspects of Cloud\ncomputing. Our hypothesis is that ontologies along with their reasoning\ncapabilities can have significant impact on improving various aspects of the\nCloud computing phenomena. Ontologies can promote intelligent decision support\nmechanisms for various Cloud based services. They can also provide effective\ninteroperability among the Cloud based systems and resources. This survey can\npromote a comprehensive understanding on the roles and significance of\nontologies within the overall domain of Cloud Computing. Also, this project can\npotentially form the basis of new research area and possibilities for both\nontology and Cloud computing communities.\n", "versions": [{"version": "v1", "created": "Thu, 6 Oct 2016 05:39:37 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Imam", "Fahim T.", ""]]}, {"id": "1610.02373", "submitter": "Mohamad Ivan Fanany", "authors": "Arif Budiman, Mohamad Ivan Fanany, Chan Basaruddin", "title": "Distributed Averaging CNN-ELM for Big Data", "comments": "Submitted to IEEE Transactions on Systems, Man and Cybernetics:\n  Systems", "journal-ref": null, "doi": null, "report-no": "SMCA-16-09-1039", "categories": "cs.LG cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing the scalability of machine learning to handle big volume of data\nis a challenging task. The scale up approach has some limitations. In this\npaper, we proposed a scale out approach for CNN-ELM based on MapReduce on\nclassifier level. Map process is the CNN-ELM training for certain partition of\ndata. It involves many CNN-ELM models that can be trained asynchronously.\nReduce process is the averaging of all CNN-ELM weights as final training\nresult. This approach can save a lot of training time than single CNN-ELM\nmodels trained alone. This approach also increased the scalability of machine\nlearning by combining scale out and scale up approaches. We verified our method\nin extended MNIST data set and not-MNIST data set experiment. However, it has\nsome drawbacks by additional iteration learning parameters that need to be\ncarefully taken and training data distribution that need to be carefully\nselected. Further researches to use more complex image data set are required.\n", "versions": [{"version": "v1", "created": "Fri, 7 Oct 2016 18:59:23 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Budiman", "Arif", ""], ["Fanany", "Mohamad Ivan", ""], ["Basaruddin", "Chan", ""]]}, {"id": "1610.02496", "submitter": "Kaiwei Li", "authors": "Kaiwei Li, Jianfei Chen, Wenguang Chen, Jun Zhu", "title": "SaberLDA: Sparsity-Aware Learning of Topic Models on GPUs", "comments": "13 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Latent Dirichlet Allocation (LDA) is a popular tool for analyzing discrete\ncount data such as text and images. Applications require LDA to handle both\nlarge datasets and a large number of topics. Though distributed CPU systems\nhave been used, GPU-based systems have emerged as a promising alternative\nbecause of the high computational power and memory bandwidth of GPUs. However,\nexisting GPU-based LDA systems cannot support a large number of topics because\nthey use algorithms on dense data structures whose time and space complexity is\nlinear to the number of topics. In this paper, we propose SaberLDA, a GPU-based\nLDA system that implements a sparsity-aware algorithm to achieve sublinear time\ncomplexity and scales well to learn a large number of topics. To address the\nchallenges introduced by sparsity, we propose a novel data layout, a new\nwarp-based sampling kernel, and an efficient sparse count matrix updating\nalgorithm that improves locality, makes efficient utilization of GPU warps, and\nreduces memory consumption. Experiments show that SaberLDA can learn from\nbillions-token-scale data with up to 10,000 topics, which is almost two orders\nof magnitude larger than that of the previous GPU-based systems. With a single\nGPU card, SaberLDA is able to learn 10,000 topics from a dataset of billions of\ntokens in a few hours, which is only achievable with clusters with tens of\nmachines before.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 07:57:00 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2016 12:39:07 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Li", "Kaiwei", ""], ["Chen", "Jianfei", ""], ["Chen", "Wenguang", ""], ["Zhu", "Jun", ""]]}, {"id": "1610.02551", "submitter": "Andrzej Karbowski", "authors": "Andrzej Karbowski", "title": "Correction to the article \"Dynamic power management in energy-aware\n  computer networks and data intensive computing systems\" published in \"Future\n  Generation Computer Systems\" journal", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper indicates two errors in the formulation of the main optimization\nmodel in the article \"Dynamic power management in energy-aware computer\nnetworks and data intensive computing systems\" by Niewiadomska-Szynkiewicz et\nal. [FGCS, vol.37 (2014), pp.284-296] and shows how to fix them.\n", "versions": [{"version": "v1", "created": "Sat, 8 Oct 2016 16:11:34 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2016 18:03:00 GMT"}, {"version": "v3", "created": "Thu, 13 Oct 2016 06:48:24 GMT"}], "update_date": "2016-10-14", "authors_parsed": [["Karbowski", "Andrzej", ""]]}, {"id": "1610.02742", "submitter": "Benda Xu", "authors": "Guilherme Amadio and Benda Xu", "title": "Portage: Bringing Hackers' Wisdom to Science", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Providing users of HPC systems with a wide variety of up to date software\npackages is a challenging task. Large software stacks built from source are\ndifficult to manage, requiring powerful package management tools. The Portage\npackage manager from Gentoo is a highly flexible tool that offers a mature\nsolution to this otherwise daunting task. The Gentoo Prefix project develops\nand maintains a way of installing Gentoo systems in non-standard locations,\nbringing the virtues of Gentoo to other operating systems. Here we demonstrate\nhow a Gentoo Prefix installation can be used to cross compile software packages\nfor the Intel Xeon Phi known as Knights Corner, as well as to manage large\nsoftware stacks in HPC environments.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 00:19:32 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Amadio", "Guilherme", ""], ["Xu", "Benda", ""]]}, {"id": "1610.02885", "submitter": "Roy Friedman", "authors": "Roy Friedman and Roni Licher", "title": "Hardening Cassandra Against Byzantine Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cassandra is one of the most widely used distributed data stores these days.\nCassandra supports flexible consistency guarantees over a wide-column data\naccess model and provides almost linear scale-out performance. This enables\napplication developers to tailor the performance and availability of Cassandra\nto their exact application's needs and required semantics. Yet, Cassandra is\ndesigned to withstand benign failures, and cannot cope with most forms of\nByzantine attacks.\n  In this work, we present an analysis of Cassandra's vulnerabilities and\npropose protocols for hardening Cassandra against Byzantine failures. We\nexamine several alternative design choices and compare between them both\nqualitatively and empirically by using the Yahoo! Cloud Serving Benchmark\n(YCSB) performance benchmark. We include incremental performance analysis for\nour algorithmic and cryptographic adjustments, supporting our design choices.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 12:34:59 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Friedman", "Roy", ""], ["Licher", "Roni", ""]]}, {"id": "1610.02931", "submitter": "Mohamad Ahmadi", "authors": "Mohamad Ahmadi and Fabian Kuhn", "title": "Multi-Message Broadcast in Dynamic Radio Networks", "comments": "appears in ALGOSENSORS 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We continue the recent line of research studying information dissemination\nproblems in adversarial dynamic radio networks. We give two generic algorithms\nwhich allow to transform generalized version of single-message broadcast\nalgorithms into multi-message broadcast algorithms. Based on these generic\nalgorithms, we obtain multi-message broadcast algorithms for dynamic radio\nnetworks for a number of different dynamic network settings. For one of the\nmodeling assumptions, our algorithms are complemented by a lower bound which\nshows that the upper bound is close to optimal.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 14:29:04 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Ahmadi", "Mohamad", ""], ["Kuhn", "Fabian", ""]]}, {"id": "1610.03007", "submitter": "Timo Bingmann", "authors": "Timo Bingmann, Simon Gog, and Florian Kurpicz", "title": "Scalable Construction of Text Indexes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The suffix array is the key to efficient solutions for myriads of string\nprocessing problems in different applications domains, like data compression,\ndata mining, or Bioinformatics. With the rapid growth of available data, suffix\narray construction algorithms had to be adapted to advanced computational\nmodels such as external memory and distributed computing. In this article, we\npresent five suffix array construction algorithms utilizing the new algorithmic\nbig data batch processing framework Thrill, which allows us to process input\nsizes in orders of magnitude that have not been considered before.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 17:40:26 GMT"}], "update_date": "2016-10-11", "authors_parsed": [["Bingmann", "Timo", ""], ["Gog", "Simon", ""], ["Kurpicz", "Florian", ""]]}, {"id": "1610.03052", "submitter": "Lihao Liang", "authors": "Lihao Liang, Paul E. McKenney, Daniel Kroening, Tom Melham", "title": "Verification of the Tree-Based Hierarchical Read-Copy Update in the\n  Linux Kernel", "comments": "This is a long version of a conference paper published in the 2018\n  Design, Automation and Test in Europe Conference (DATE)", "journal-ref": "Design, Automation and Test in Europe Conference (2018): 61-66", "doi": "10.23919/DATE.2018.8341980", "report-no": null, "categories": "cs.LO cs.DC cs.OS cs.SE", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Read-Copy Update (RCU) is a scalable, high-performance Linux-kernel\nsynchronization mechanism that runs low-overhead readers concurrently with\nupdaters. Production-quality RCU implementations for multi-core systems are\ndecidedly non-trivial. Giving the ubiquity of Linux, a rare \"million-year\" bug\ncan occur several times per day across the installed base. Stringent validation\nof RCU's complex behaviors is thus critically important. Exhaustive testing is\ninfeasible due to the exponential number of possible executions, which suggests\nuse of formal verification.\n  Previous verification efforts on RCU either focus on simple implementations\nor use modeling languages, the latter requiring error-prone manual translation\nthat must be repeated frequently due to regular changes in the Linux kernel's\nRCU implementation. In this paper, we first describe the implementation of Tree\nRCU in the Linux kernel. We then discuss how to construct a model directly from\nTree RCU's source code in C, and use the CBMC model checker to verify its\nsafety and liveness properties. To our best knowledge, this is the first\nverification of a significant part of RCU's source code, and is an important\nstep towards integration of formal verification into the Linux kernel's\nregression test suite.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 19:59:32 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 17:15:33 GMT"}, {"version": "v3", "created": "Thu, 22 Nov 2018 17:40:49 GMT"}], "update_date": "2018-11-27", "authors_parsed": [["Liang", "Lihao", ""], ["McKenney", "Paul E.", ""], ["Kroening", "Daniel", ""], ["Melham", "Tom", ""]]}, {"id": "1610.03105", "submitter": "Yadu Babuji", "authors": "Yadu N. Babuji, Kyle Chard, Aaron Gerow, Eamon Duede", "title": "A Secure Data Enclave and Analytics Platform for Social Scientists", "comments": "Forthcoming eScience 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-driven research is increasingly ubiquitous and data itself is a defining\nasset for researchers, particularly in the computational social sciences and\nhumanities. Entire careers and research communities are built around valuable,\nproprietary or sensitive datasets. However, many existing computation resources\nfail to support secure and cost-effective storage of data while also enabling\nsecure and flexible analysis of the data. To address these needs we present\nCLOUD KOTTA, a cloud-based architecture for the secure management and analysis\nof social science data. CLOUD KOTTA leverages reliable, secure, and scalable\ncloud resources to deliver capabilities to users, and removes the need for\nusers to manage complicated infrastructure. CLOUD KOTTA implements automated,\ncost-aware models for efficiently provisioning tiered storage and automatically\nscaled compute resources. CLOUD KOTTA has been used in production for several\nmonths and currently manages approximately 10TB of data and has been used to\nprocess more than 5TB of data with over 75,000 CPU hours. It has been used for\na broad variety of text analysis workflows, matrix factorization, and various\nmachine learning algorithms, and more broadly, it supports fast, secure and\ncost-effective research.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 21:44:12 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Babuji", "Yadu N.", ""], ["Chard", "Kyle", ""], ["Gerow", "Aaron", ""], ["Duede", "Eamon", ""]]}, {"id": "1610.03108", "submitter": "Eamon Duede", "authors": "Yadu N. Babuji, Kyle Chard, Aaron Gerow, and Eamon Duede", "title": "Cloud Kotta: Enabling Secure and Scalable Data Analytics in the Cloud", "comments": "A version of this paper is forthcoming at BigData 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed communities of researchers rely increasingly on valuable,\nproprietary, or sensitive datasets. Given the growth of such data, especially\nin fields new to data-driven, computationally intensive research like the\nsocial sciences and humanities, coupled with what are often strict and complex\ndata-use agreements, many research communities now require methods that allow\nsecure, scalable and cost-effective storage and analysis. Here we present CLOUD\nKOTTA: a cloud-based data management and analytics framework. CLOUD KOTTA\ndelivers an end-to-end solution for coordinating secure access to large\ndatasets, and an execution model that provides both automated infrastructure\nscaling and support for executing analytics near to the data. CLOUD KOTTA\nimplements a fine-grained security model ensuring that only authorized users\nmay access, analyze, and download protected data. It also implements automated\nmethods for acquiring and configuring low-cost storage and compute resources as\nthey are needed. We present the architecture and implementation of CLOUD KOTTA\nand demonstrate the advantages it provides in terms of increased performance\nand flexibility. We show that CLOUD KOTTA's elastic provisioning model can\nreduce costs by up to 16x when compared with statically provisioned models.\n", "versions": [{"version": "v1", "created": "Mon, 10 Oct 2016 21:58:09 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2016 19:07:46 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Babuji", "Yadu N.", ""], ["Chard", "Kyle", ""], ["Gerow", "Aaron", ""], ["Duede", "Eamon", ""]]}, {"id": "1610.03360", "submitter": "Philipp F\\\"odisch", "authors": "Philipp F\\\"odisch, Artsiom Bryksa, Bert Lange, Wolfgang Enghardt,\n  Peter Kaever", "title": "Implementing High-Order FIR Filters in FPGAs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary field-programmable gate arrays (FPGAs) are predestined for the\napplication of finite impulse response (FIR) filters. Their embedded digital\nsignal processing (DSP) blocks for multiply-accumulate operations enable\nefficient fixed-point computations, in cases where the filter structure is\naccurately mapped to the dedicated hardware architecture. This brief presents a\ngeneric systolic structure for high-order FIR filters, efficiently exploiting\nthe hardware resources of an FPGA in terms of routability and timing. Although\nthis seems to be an easily implementable task, the synthesizing tools require\nan adaptation of the straightforward digital filter implementation for an\noptimal mapping. Using the example of a symmetric FIR filter with 90 taps, we\ndemonstrate the performance of the proposed structure with FPGAs from Xilinx\nand Altera. The implementation utilizes less than 1% of slice logic and runs at\nclock frequencies up to 526 MHz. Moreover, an enhancement of the structure\nultimately provides an extended dynamic range for the quantized coefficients\nwithout the costs of additional slice logic.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 14:24:52 GMT"}, {"version": "v2", "created": "Wed, 12 Oct 2016 11:23:27 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["F\u00f6disch", "Philipp", ""], ["Bryksa", "Artsiom", ""], ["Lange", "Bert", ""], ["Enghardt", "Wolfgang", ""], ["Kaever", "Peter", ""]]}, {"id": "1610.03383", "submitter": "David Harris", "authors": "David G. Harris", "title": "Deterministic parallel algorithms for fooling polylogarithmic juntas and\n  the Lovasz Local Lemma", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many randomized algorithms can be derandomized efficiently using either the\nmethod of conditional expectations or probability spaces with low (almost-)\nindependence. A series of papers, beginning with Luby (1993) and continuing\nwith Berger & Rompel (1991) and Chari et al. (2000), showed that these\ntechniques can be combined to give deterministic parallel algorithms for\ncombinatorial optimization problems involving sums of $w$-juntas. We improve\nthese algorithms through derandomized variable partitioning and a new code\nconstruction for fooling Fourier characters over $GF(2)$. This reduces the\nprocessor complexity to essentially independent of $w$ while the running time\nis reduced from exponential in $w$ to linear in $w$.\n  As a key subroutine, we give a new algorithm to generate a probability space\nwhich can fool a given set of neighborhoods. Schulman (1992) gave an NC\nalgorithm to do so for neighborhoods of size $w \\leq O(\\log n)$. Our new\nalgorithm is NC1, with essentially optimal time and processor complexity, when\n$w = O(\\log n)$; it remains NC up to $w = \\text{polylog}(n)$. This answers an\nopen problem of Schulman.\n  One major application of these algorithms is an NC algorithm for the\nLov\\'{a}sz Local Lemma. Previous NC algorithms, including the seminal algorithm\nof Moser & Tardos (2010) and the work of Chandrasekaran et. al (2013), required\nthat (essentially) the bad-events could span only $O(\\log n)$ variables; we\nrelax this to $\\text{polylog}(n)$ variables. We use this for an $\\text{NC}^2$\nalgorithm for defective vertex coloring, which works for arbitrary degree\ngraphs.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 15:11:31 GMT"}, {"version": "v10", "created": "Mon, 20 Aug 2018 19:07:59 GMT"}, {"version": "v2", "created": "Tue, 18 Oct 2016 12:13:12 GMT"}, {"version": "v3", "created": "Thu, 20 Oct 2016 15:59:48 GMT"}, {"version": "v4", "created": "Thu, 15 Jun 2017 20:55:31 GMT"}, {"version": "v5", "created": "Thu, 22 Jun 2017 21:47:45 GMT"}, {"version": "v6", "created": "Mon, 29 Jan 2018 15:42:55 GMT"}, {"version": "v7", "created": "Mon, 21 May 2018 20:40:04 GMT"}, {"version": "v8", "created": "Wed, 30 May 2018 20:13:52 GMT"}, {"version": "v9", "created": "Sat, 11 Aug 2018 14:28:58 GMT"}], "update_date": "2018-08-22", "authors_parsed": [["Harris", "David G.", ""]]}, {"id": "1610.03450", "submitter": "Chairi Kiourt", "authors": "Chairi Kiourt and Dimitris Kalles", "title": "A Distributed Multi Agents Based Platform for High Performance Computing\n  Infrastructures", "comments": "12 pages,4 figures, Conference: Workshop Parallel and Distributed\n  Computing for Knowledge Discovery in Data Bases, a workshop of the European\n  Conference on Machine Learning and Principles and Practice of Knowledge\n  Discovery, At Porto, Portugal, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces a novel, modular, layered web based platform for\nmanaging machine learning experiments on grid-based High Performance Computing\ninfrastructures. The coupling of the communication services offered by the\ngrid, with an administration layer and conventional web server programming, via\na data synchronization utility, leads to the straightforward development of a\nweb-based user interface that allows the monitoring and managing of diverse\nonline distributed computing applications. It also introduces an experiment\ngeneration and monitoring tool particularly suitable for investigating machine\nlearning in game playing. The platform is demonstrated with experiments for two\ndifferent games.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 18:07:38 GMT"}], "update_date": "2016-10-12", "authors_parsed": [["Kiourt", "Chairi", ""], ["Kalles", "Dimitris", ""]]}, {"id": "1610.03524", "submitter": "Julian Shun", "authors": "Julian Shun", "title": "Improved Parallel Construction of Wavelet Trees and Rank/Select\n  Structures", "comments": "This paper appears in Information & Computation, 2020. A preliminary\n  version appears in the Proceedings of the IEEE Data Compression Conference,\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing parallel algorithms for wavelet tree construction have a work\ncomplexity of $O(n\\log\\sigma)$. This paper presents parallel algorithms for the\nproblem with improved work complexity. Our first algorithm is based on parallel\ninteger sorting and has either $O(n\\log\\log n\\lceil\\log\\sigma/\\sqrt{\\log\nn\\log\\log n}\\rceil)$ work and polylogarithmic depth, or\n$O(n\\lceil\\log\\sigma/\\sqrt{\\log n}\\rceil)$ work and sub-linear depth. We also\ndescribe another algorithm that has $O(n\\lceil\\log\\sigma/\\sqrt{\\log n} \\rceil)$\nwork and $O(\\sigma+\\log n)$ depth. We then show how to use similar ideas to\nconstruct variants of wavelet trees (arbitrary-shaped binary trees and multiary\ntrees) as well as wavelet matrices in parallel with lower work complexity than\nprior algorithms. Finally, we show that the rank and select structures on\nbinary sequences and multiary sequences, which are stored on wavelet tree\nnodes, can be constructed in parallel with improved work bounds, matching those\nof the best existing sequential algorithms for constructing rank and select\nstructures.\n", "versions": [{"version": "v1", "created": "Tue, 11 Oct 2016 20:51:47 GMT"}, {"version": "v2", "created": "Wed, 18 Jan 2017 10:54:05 GMT"}, {"version": "v3", "created": "Thu, 16 Jan 2020 04:36:38 GMT"}], "update_date": "2020-01-17", "authors_parsed": [["Shun", "Julian", ""]]}, {"id": "1610.03618", "submitter": "Chao Li", "authors": "Chao Li, Yi Yang, Min Feng, Srimat Chakradhar, Huiyang Zhou", "title": "Optimizing Memory Efficiency for Deep Convolutional Neural Networks on\n  GPUs", "comments": "Published as a conference paper International Conference on High\n  Performance Computing, Networking, Storage, and Analysis (SC'16), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leveraging large data sets, deep Convolutional Neural Networks (CNNs) achieve\nstate-of-the-art recognition accuracy. Due to the substantial compute and\nmemory operations, however, they require significant execution time. The\nmassive parallel computing capability of GPUs make them as one of the ideal\nplatforms to accelerate CNNs and a number of GPU-based CNN libraries have been\ndeveloped. While existing works mainly focus on the computational efficiency of\nCNNs, the memory efficiency of CNNs have been largely overlooked. Yet CNNs have\nintricate data structures and their memory behavior can have significant impact\non the performance. In this work, we study the memory efficiency of various CNN\nlayers and reveal the performance implication from both data layouts and memory\naccess patterns. Experiments show the universal effect of our proposed\noptimizations on both single layers and various networks, with up to 27.9x for\na single layer and up to 5.6x on the whole networks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 07:02:48 GMT"}], "update_date": "2016-10-13", "authors_parsed": [["Li", "Chao", ""], ["Yang", "Yi", ""], ["Feng", "Min", ""], ["Chakradhar", "Srimat", ""], ["Zhou", "Huiyang", ""]]}, {"id": "1610.03897", "submitter": "Vivek B. Sardeshmukh", "authors": "Sriram V. Pemmaraju and Vivek B. Sardeshmukh", "title": "Super-fast MST Algorithms in the Congested Clique using $o(m)$ Messages", "comments": "Full version of FST-TCS 2016 paper with the same title", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a sequence of recent results (PODC 2015 and PODC 2016), the running time\nof the fastest algorithm for the \\emph{minimum spanning tree (MST)} problem in\nthe \\emph{Congested Clique} model was first improved to $O(\\log \\log \\log n)$\nfrom $O(\\log \\log n)$ (Hegeman et al., PODC 2015) and then to $O(\\log^* n)$\n(Ghaffari and Parter, PODC 2016). All of these algorithms use $\\Theta(n^2)$\nmessages independent of the number of edges in the input graph.\n  This paper positively answers a question raised in Hegeman et al., and\npresents the first \"super-fast\" MST algorithm with $o(m)$ message complexity\nfor input graphs with $m$ edges. Specifically, we present an algorithm running\nin $O(\\log^* n)$ rounds, with message complexity $\\tilde{O}(\\sqrt{m \\cdot n})$\nand then build on this algorithm to derive a family of algorithms, containing\nfor any $\\varepsilon$, $0 < \\varepsilon \\le 1$, an algorithm running in\n$O(\\log^* n/\\varepsilon)$ rounds, using $\\tilde{O}(n^{1 +\n\\varepsilon}/\\varepsilon)$ messages. Setting $\\varepsilon = \\log\\log n/\\log n$\nleads to the first sub-logarithmic round Congested Clique MST algorithm that\nuses only $\\tilde{O}(n)$ messages.\n  Our primary tools in achieving these results are (i) a component-wise bound\non the number of candidates for MST edges, extending the sampling lemma of\nKarger, Klein, and Tarjan (Karger, Klein, and Tarjan, JACM 1995) and (ii)\n$\\Theta(\\log n)$-wise-independent linear graph sketches (Cormode and Firmani,\nDist.~Par.~Databases, 2014) for generating MST candidate edges.\n", "versions": [{"version": "v1", "created": "Wed, 12 Oct 2016 23:10:04 GMT"}, {"version": "v2", "created": "Mon, 17 Oct 2016 23:53:24 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Pemmaraju", "Sriram V.", ""], ["Sardeshmukh", "Vivek B.", ""]]}, {"id": "1610.04091", "submitter": "Eric Kerrigan", "authors": "Mason Thammawichai, Sujit P. Baliyarasimhuni, Eric C. Kerrigan, Jo\\~ao\n  B. Sousa", "title": "Optimizing Communication and Computation for Multi-UAV Information\n  Gathering Applications", "comments": null, "journal-ref": null, "doi": "10.1109/TAES.2017.2761139", "report-no": null, "categories": "cs.SY cs.DC cs.RO math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile agent networks, such as multi-UAV systems, are constrained by limited\nresources. In particular, limited energy affects system performance directly,\nsuch as system lifetime. It has been demonstrated in the wireless sensor\nnetwork literature that the communication energy consumption dominates the\ncomputational and the sensing energy consumption. Hence, the lifetime of the\nmulti-UAV systems can be extended significantly by optimizing the amount of\ncommunication data, at the expense of increasing computational cost. In this\nwork, we aim at attaining an optimal trade-off between the communication and\nthe computational energy. Specifically, we propose a mixed-integer optimization\nformulation for a multi-hop hierarchical clustering-based self-organizing UAV\nnetwork incorporating data aggregation, to obtain an energy-efficient\ninformation routing scheme. The proposed framework is tested on two\napplications, namely target tracking and area mapping. Based on simulation\nresults, our method can significantly save energy compared to a baseline\nstrategy, where there is no data aggregation and clustering scheme.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 14:09:39 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Thammawichai", "Mason", ""], ["Baliyarasimhuni", "Sujit P.", ""], ["Kerrigan", "Eric C.", ""], ["Sousa", "Jo\u00e3o B.", ""]]}, {"id": "1610.04154", "submitter": "Sergio Ram\\'irez-Gallego", "authors": "Sergio Ram\\'irez-Gallego, H\\'ector Mouri\\~no-Tal\\'in, David\n  Mart\\'inez-Rego, Ver\\'onica Bol\\'on-Canedo, Jos\\'e Manuel Ben\\'itez, Amparo\n  Alonso-Betanzos, Francisco Herrera", "title": "An Information Theoretic Feature Selection Framework for Big Data under\n  Apache Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of extremely high dimensional datasets, dimensionality\nreduction techniques are becoming mandatory. Among many techniques, feature\nselection has been growing in interest as an important tool to identify\nrelevant features on huge datasets --both in number of instances and\nfeatures--. The purpose of this work is to demonstrate that standard feature\nselection methods can be parallelized in Big Data platforms like Apache Spark,\nboosting both performance and accuracy. We thus propose a distributed\nimplementation of a generic feature selection framework which includes a wide\ngroup of well-known Information Theoretic methods. Experimental results on a\nwide set of real-world datasets show that our distributed framework is capable\nof dealing with ultra-high dimensional datasets as well as those with a huge\nnumber of samples in a short period of time, outperforming the sequential\nversion in all the cases studied.\n", "versions": [{"version": "v1", "created": "Thu, 13 Oct 2016 16:17:07 GMT"}, {"version": "v2", "created": "Wed, 19 Oct 2016 16:46:28 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Ram\u00edrez-Gallego", "Sergio", ""], ["Mouri\u00f1o-Tal\u00edn", "H\u00e9ctor", ""], ["Mart\u00ednez-Rego", "David", ""], ["Bol\u00f3n-Canedo", "Ver\u00f3nica", ""], ["Ben\u00edtez", "Jos\u00e9 Manuel", ""], ["Alonso-Betanzos", "Amparo", ""], ["Herrera", "Francisco", ""]]}, {"id": "1610.04309", "submitter": "Maicon Alves", "authors": "Maicon Melo Alves and L\\'ucia Maria de Assump\\c{c}\\~ao Drummond", "title": "A Quantitative Model for Predicting Cross-application Interference in\n  Virtual Environments", "comments": "14 pages, 6 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cross-application interference can affect drastically performance of HPC\napplications when running in clouds. This problem is caused by concurrent\naccess performed by co-located applications to shared and non-sliceable\nresources such as cache and memory. In order to address this issue, some works\nadopted a qualitative approach that does not take into account the amount of\naccess to shared resources. In addition, a few works, even considering the\namount of access, evaluated just the SLLC access contention as the root of this\nproblem. However, our experiments revealed that interference is intrinsically\nrelated to the amount of simultaneous access to shared resources, besides\nshowing that another shared resources, apart from SLLC, can also influence the\ninterference suffered by co-located applications. In this paper, we present a\nquantitative model for predicting cross-application interference in virtual\nenvironments. Our proposed model takes into account the amount of simultaneous\naccess to SLLC, DRAM and virtual network, and the similarity of application's\naccess burden to predict the level of interference suffered by applications\nwhen co-located in a same physical machine. Experiments considering a real\npetroleum reservoir simulator and applications from HPCC benchmark showed that\nour model reached an average and maximum prediction errors around 4\\% and 12\\%,\nbesides achieving an error less than 10\\% in approximately 96\\% of all tested\ncases.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 01:25:59 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Alves", "Maicon Melo", ""], ["Drummond", "L\u00facia Maria de Assump\u00e7\u00e3o", ""]]}, {"id": "1610.04493", "submitter": "Kamal Hakimzadeh", "authors": "Shelan Perera, Ashansa Perera, Kamal Hakimzadeh", "title": "Reproducible Experiments for Comparing Apache Flink and Apache Spark on\n  Public Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data processing is a hot topic in today's computer science world. There\nis a significant demand for analysing big data to satisfy many requirements of\nmany industries. Emergence of the Kappa architecture created a strong\nrequirement for a highly capable and efficient data processing engine.\nTherefore data processing engines such as Apache Flink and Apache Spark emerged\nin open source world to fulfil that efficient and high performing data\nprocessing requirement. There are many available benchmarks to evaluate those\ntwo data processing engines. But complex deployment patterns and dependencies\nmake those benchmarks very difficult to reproduce by our own. This project has\ntwo main goals. They are making few of community accepted benchmarks easily\nreproducible on cloud and validate the performance claimed by those studies.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 15:07:24 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Perera", "Shelan", ""], ["Perera", "Ashansa", ""], ["Hakimzadeh", "Kamal", ""]]}, {"id": "1610.04572", "submitter": "Mansaf Alam Dr", "authors": "Mansaf Alam and Kashish Ara Shakil", "title": "Big Data Analytics in Cloud environment using Hadoop", "comments": "conference paper ICMPAS-2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Big Data management is a problem right now. The Big Data growth is very\nhigh. It is very difficult to manage due to various characteristics. This\nmanuscript focuses on Big Data analytics in cloud environment using Hadoop. We\nhave classified the Big Data according to its characteristics like Volume,\nValue, Variety and Velocity. We have made various nodes to process the data\nbased on their volume, velocity, value and variety. In this work we have\nclassify the input data and routed to various processing node. At the last\nafter processing from each node, we can combine the output of all nodes to get\nthe final result. We have used Hadoop to partition the data as well as process\nit.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 15:12:10 GMT"}], "update_date": "2016-10-17", "authors_parsed": [["Alam", "Mansaf", ""], ["Shakil", "Kashish Ara", ""]]}, {"id": "1610.04636", "submitter": "Anindya Sundar Chakrabarti", "authors": "Anindya S. Chakrabarti, Diptesh Ghosh", "title": "Improving Server Utilization in a Distributed Computing Set-up with\n  Independent Clients", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a set-up in which there are multiple servers and multiple clients\nin a large distributed computing system. Clients request servers to process\njobs. Servers can only process one job in unit time. There is no coordinating\nagent to route client requests to servers, and clients choose servers\nindependently and simultaneously, and only have access to the outcomes of their\nown past requests. If more than one clients choose the same server, then only\none randomly chosen client's requests will be fulfilled. If some servers do not\nreceive any request, they remain idle. In this paper, we show that a large\ncategory of strategies are not effective in terms of server utilization. We\ndevise strategies for clients that improve server utilization of such systems\nover those of strategies known in the current literature.\n", "versions": [{"version": "v1", "created": "Mon, 2 May 2016 10:23:11 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Chakrabarti", "Anindya S.", ""], ["Ghosh", "Diptesh", ""]]}, {"id": "1610.04660", "submitter": "Alexander Semenov", "authors": "Artem Mazeev, Alexander Semenov, Alexey Simonov", "title": "A Distributed Parallel Algorithm for Minimum Spanning Tree Problem", "comments": "11 pages, 5 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present and evaluate a parallel algorithm for solving a\nminimum spanning tree (MST) problem for supercomputers with distributed memory.\nThe algorithm relies on the relaxation of the message processing order\nrequirement for one specific message type compared to the original GHS\n(Gallager, Humblet, Spira) algorithm. Our algorithm adopts hashing and message\ncompression optimization techniques as well. To the best of our knowledge, this\nis the first parallel implementation of the GHS algorithm that linearly scales\nto more than 32 nodes (256 cores) of Infiniband cluster.\n", "versions": [{"version": "v1", "created": "Fri, 14 Oct 2016 22:09:13 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Mazeev", "Artem", ""], ["Semenov", "Alexander", ""], ["Simonov", "Alexey", ""]]}, {"id": "1610.04676", "submitter": "Shuai Zheng", "authors": "Shuai Zheng, Zon-Yin Shae, Xiangliang Zhang, Hani Jamjoom, and Liana\n  Fong", "title": "Analysis and Modeling of Social Influence in High Performance Computing\n  Workloads", "comments": "The 17th International European Conference on Parallel and\n  Distributed Computing, Euro-Par 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social influence among users (e.g., collaboration on a project) creates\nbursty behavior in the underlying high performance computing (HPC) workloads.\nUsing representative HPC and cluster workload logs, this paper identifies,\nanalyzes, and quantifies the level of social influence across HPC users. We\nshow the existence of a social graph that is characterized by a pattern of\ndominant users and followers. This pattern also follows a power-law\ndistribution, which is consistent with those observed in mainstream social\nnetworks. Given its potential impact on HPC workloads prediction and\nscheduling, we propose a fast-converging, computationally-efficient online\nlearning algorithm for identifying social groups. Extensive evaluation shows\nthat our online algorithm can (1) quickly identify the social relationships by\nusing a small portion of incoming jobs and (2) can efficiently track group\nevolution over time.\n", "versions": [{"version": "v1", "created": "Sat, 15 Oct 2016 00:33:10 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Zheng", "Shuai", ""], ["Shae", "Zon-Yin", ""], ["Zhang", "Xiangliang", ""], ["Jamjoom", "Hani", ""], ["Fong", "Liana", ""]]}, {"id": "1610.04714", "submitter": "Nicolas Loizou", "authors": "Nicolas Loizou, Peter Richt\\'arik", "title": "A New Perspective on Randomized Gossip Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this short note we propose a new approach for the design and analysis of\nrandomized gossip algorithms which can be used to solve the average consensus\nproblem. We show how that Randomized Block Kaczmarz (RBK) method - a method for\nsolving linear systems - works as gossip algorithm when applied to a special\nsystem encoding the underlying network. The famous pairwise gossip algorithm\narises as a special case. Subsequently, we reveal a hidden duality of\nrandomized gossip algorithms, with the dual iterative process maintaining a set\nof numbers attached to the edges as opposed to nodes of the network. We prove\nthat RBK obtains a superlinear speedup in the size of the block, and\ndemonstrate this effect through experiments.\n", "versions": [{"version": "v1", "created": "Sat, 15 Oct 2016 10:30:34 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Loizou", "Nicolas", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "1610.04779", "submitter": "Andrzej Karbowski", "authors": "Andrzej Karbowski", "title": "Remarks to the paper \"Control system for reducing energy consumption in\n  backbone computer network\" from \"Concurrency and Computation: Practice and\n  Experience\" journal", "comments": "5 pages. arXiv admin note: substantial text overlap with\n  arXiv:1610.02551", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper indicates two errors in the formulation of the main optimization\nmodel in the article \"Control system for reducing energy consumption in\nbackbone computer network\" by Niewiadomska-Szynkiewicz et al. and shows how to\nfix them.\n", "versions": [{"version": "v1", "created": "Sat, 15 Oct 2016 19:59:00 GMT"}, {"version": "v2", "created": "Thu, 29 Dec 2016 08:10:40 GMT"}], "update_date": "2016-12-30", "authors_parsed": [["Karbowski", "Andrzej", ""]]}, {"id": "1610.04872", "submitter": "Bodhisattwa Majumder", "authors": "Bodhisattwa Prasad Majumder, Ayan Sengupta, Sajal jain, Parikshit\n  Bhaduri", "title": "Fault Detection Engine in Intelligent Predictive Analytics Platform for\n  DCIM", "comments": "Accepted in 4th International Conference on Business Analytics and\n  Intelligence (ICBAI 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advancement of huge data generation and data handling capability,\nMachine Learning and Probabilistic modelling enables an immense opportunity to\nemploy predictive analytics platform in high security critical industries\nnamely data centers, electricity grids, utilities, airport etc. where downtime\nminimization is one of the primary objectives. This paper proposes a novel,\ncomplete architecture of an intelligent predictive analytics platform, Fault\nEngine, for huge device network connected with electrical/information flow.\nThree unique modules, here proposed, seamlessly integrate with available\ntechnology stack of data handling and connect with middleware to produce online\nintelligent prediction in critical failure scenarios. The Markov Failure module\npredicts the severity of a failure along with survival probability of a device\nat any given instances. The Root Cause Analysis model indicates probable\ndevices as potential root cause employing Bayesian probability assignment and\ntopological sort. Finally, a community detection algorithm produces correlated\nclusters of device in terms of failure probability which will further narrow\ndown the search space of finding route cause. The whole Engine has been tested\nwith different size of network with simulated failure environments and shows\nits potential to be scalable in real-time implementation.\n", "versions": [{"version": "v1", "created": "Sun, 16 Oct 2016 15:14:36 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Majumder", "Bodhisattwa Prasad", ""], ["Sengupta", "Ayan", ""], ["jain", "Sajal", ""], ["Bhaduri", "Parikshit", ""]]}, {"id": "1610.05116", "submitter": "Sameh Shohdy", "authors": "Sameh Shohdy, Abhinav Vishnu, Gagan Agrawal", "title": "Fault Tolerant Frequent Pattern Mining", "comments": "10 Pages, High Performance Computing Conference (HIPC 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FP-Growth algorithm is a Frequent Pattern Min- ing (FPM) algorithm that has\nbeen extensively used to study correlations and patterns in large scale\ndatasets. While several researchers have designed distributed memory FP-Growth\nalgorithms, it is pivotal to consider fault tolerant FP-Growth, which can\naddress the increasing fault rates in large scale systems. In this work, we\npropose a novel parallel, algorithm-level fault-tolerant FP-Growth algorithm.\nWe leverage algorithmic properties and MPI advanced features to guarantee an\nO(1) space complexity, achieved by using the dataset memory space itself for\ncheckpointing. We also propose a recovery algorithm that can use in-memory and\ndisk-based checkpointing, though in many cases the recovery can be completed\nwithout any disk access, and incurring no memory overhead for checkpointing. We\nevaluate our FT algorithm on a large scale InfiniBand cluster with several\nlarge datasets using up to 2K cores. Our evaluation demonstrates excellent\nefficiency for checkpointing and recovery in comparison to the disk-based\napproach. We have also observed 20x average speed-up in comparison to Spark,\nestablishing that a well designed algorithm can easily outperform a solution\nbased on a general fault-tolerant programming model.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 13:54:53 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Shohdy", "Sameh", ""], ["Vishnu", "Abhinav", ""], ["Agrawal", "Gagan", ""]]}, {"id": "1610.05118", "submitter": "Wagram Airian", "authors": "V. Airiian", "title": "Analysis of the modernization prospects of the WLCG monitoring\n  framework's messaging subsystem", "comments": "5 pages, XIX International Scientific Conference of Young Scientists\n  and Specialists (AYSS-2015), JINR, Dubna, 16-20 February 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The purpose of the project is an analysis of the modernization prospects of\nthe WLCG monitoring framework's messaging subsystem based on Nagios monitoring\nsoftware and Apache ActiveMQ technologies. The modernization process demands\nthorough examination of the existing subsystem to determine the vital upgrade\nrequirements. Thus the work is focused on research of the main underlying\ntechnologies, the existing subsystem's structure and revision of its design and\nused software.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 17:43:02 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Airiian", "V.", ""]]}, {"id": "1610.05121", "submitter": "Fang Junhua", "authors": "Junhua Fang, Rong Zhang, Tom Z.J.Fu, Zhenjie Zhang, Aoying Zhou,\n  Junhua Zhu", "title": "Parallel Stream Processing Against Workload Skewness and Variance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Key-based workload partitioning is a common strategy used in parallel stream\nprocessing engines, enabling effective key-value tuple distribution over worker\nthreads in a logical operator. While randomized hashing on the keys is capable\nof balancing the workload for key-based partitioning when the keys generally\nfollow a static distribution, it is likely to generate poor balancing\nperformance when workload variance occurs on the incoming data stream. This\npaper presents a new key-based workload partitioning framework, with practical\nalgorithms to support dynamic workload assignment for stateful operators. The\nframework combines hash-based and explicit key-based routing strategies for\nworkload distribution, which specifies the destination worker threads for a\nhandful of keys and assigns the other keys with the hashing function. When\nshort-term distribution fluctuations occur to the incoming data stream, the\nsystem adaptively updates the routing table containing the chosen keys, in\norder to rebalance the workload with minimal migration overhead within the\nstateful operator. We formulate the rebalance operation as an optimization\nproblem, with multiple objectives on minimizing state migration costs,\ncontrolling the size of the routing table and breaking workload imbalance among\nworker threads. Despite of the NP-hardness nature behind the optimization\nformulation, we carefully investigate and justify the heuristics behind key\n(re)routing and state migration, to facilitate fast response to workload\nvariance with ignorable cost to the normal processing in the distributed\nsystem. Empirical studies on synthetic data and real-world stream applications\nvalidate the usefulness of our proposals and prove the huge advantage of our\napproaches over state-of-the-art solutions in the literature.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 14:03:41 GMT"}, {"version": "v2", "created": "Tue, 13 Dec 2016 09:04:03 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Fang", "Junhua", ""], ["Zhang", "Rong", ""], ["Fu", "Tom Z. J.", ""], ["Zhang", "Zhenjie", ""], ["Zhou", "Aoying", ""], ["Zhu", "Junhua", ""]]}, {"id": "1610.05141", "submitter": "Lorenz H\\\"ubschle-Schneider", "authors": "Peter Sanders, Sebastian Lamm, Lorenz H\\\"ubschle-Schneider, Emanuel\n  Schrade and Carsten Dachsbacher", "title": "Efficient Random Sampling -- Parallel, Vectorized, Cache-Efficient, and\n  Online", "comments": null, "journal-ref": "ACM Transactions on Mathematical Software (TOMS), Volume 44, Issue\n  3 (April 2018), pages 29:1-29:14", "doi": "10.1145/3157734", "report-no": null, "categories": "cs.DS cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sampling $n$ numbers from the range\n$\\{1,\\ldots,N\\}$ without replacement on modern architectures. The main result\nis a simple divide-and-conquer scheme that makes sequential algorithms more\ncache efficient and leads to a parallel algorithm running in expected time\n$\\mathcal{O}(n/p+\\log p)$ on $p$ processors, i.e., scales to massively parallel\nmachines even for moderate values of $n$. The amount of communication between\nthe processors is very small (at most $\\mathcal{O}(\\log p)$) and independent of\nthe sample size. We also discuss modifications needed for load balancing,\nonline sampling, sampling with replacement, Bernoulli sampling, and\nvectorization on SIMD units or GPUs.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 14:38:02 GMT"}, {"version": "v2", "created": "Fri, 15 Nov 2019 15:27:42 GMT"}], "update_date": "2019-11-18", "authors_parsed": [["Sanders", "Peter", ""], ["Lamm", "Sebastian", ""], ["H\u00fcbschle-Schneider", "Lorenz", ""], ["Schrade", "Emanuel", ""], ["Dachsbacher", "Carsten", ""]]}, {"id": "1610.05202", "submitter": "Aur\\'elien Bellet", "authors": "Paul Vanhaesebrouck, Aur\\'elien Bellet, Marc Tommasi", "title": "Decentralized Collaborative Learning of Personalized Models over\n  Networks", "comments": "To appear in the Proceedings of the 20th International Conference on\n  Artificial Intelligence and Statistics (AISTATS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a set of learning agents in a collaborative peer-to-peer network,\nwhere each agent learns a personalized model according to its own learning\nobjective. The question addressed in this paper is: how can agents improve upon\ntheir locally trained model by communicating with other agents that have\nsimilar objectives? We introduce and analyze two asynchronous gossip algorithms\nrunning in a fully decentralized manner. Our first approach, inspired from\nlabel propagation, aims to smooth pre-trained local models over the network\nwhile accounting for the confidence that each agent has in its initial model.\nIn our second approach, agents jointly learn and propagate their model by\nmaking iterative updates based on both their local dataset and the behavior of\ntheir neighbors. To optimize this challenging objective, our decentralized\nalgorithm is based on ADMM.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 16:51:49 GMT"}, {"version": "v2", "created": "Wed, 15 Feb 2017 18:32:17 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Vanhaesebrouck", "Paul", ""], ["Bellet", "Aur\u00e9lien", ""], ["Tommasi", "Marc", ""]]}, {"id": "1610.05507", "submitter": "Arda Aytekin", "authors": "Arda Aytekin, Hamid Reza Feyzmahdavian, Mikael Johansson", "title": "Analysis and Implementation of an Asynchronous Optimization Algorithm\n  for the Parameter Server", "comments": "10 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an asynchronous incremental aggregated gradient algorithm\nand its implementation in a parameter server framework for solving regularized\noptimization problems. The algorithm can handle both general convex (possibly\nnon-smooth) regularizers and general convex constraints. When the empirical\ndata loss is strongly convex, we establish linear convergence rate, give\nexplicit expressions for step-size choices that guarantee convergence to the\noptimum, and bound the associated convergence factors. The expressions have an\nexplicit dependence on the degree of asynchrony and recover classical results\nunder synchronous operation. Simulations and implementations on commercial\ncompute clouds validate our findings.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 09:48:51 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Aytekin", "Arda", ""], ["Feyzmahdavian", "Hamid Reza", ""], ["Johansson", "Mikael", ""]]}, {"id": "1610.05601", "submitter": "Zhehao Li", "authors": "Zhehao Li, Jifang Jin, Lingli Wang", "title": "High-performance K-means Implementation based on a Simplified Map-Reduce\n  Architecture", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The k-means algorithm is one of the most common clustering algorithms and\nwidely used in data mining and pattern recognition. The increasing\ncomputational requirement of big data applications makes hardware acceleration\nfor the k-means algorithm necessary. In this paper, a simplified Map-Reduce\narchitecture is proposed to implement the k-means algorithm on an FPGA.\nAlgorithmic segmentation, data path elaboration and automatic control are\napplied to optimize the architecture for high performance. In addition, high\nlevel synthesis technique is utilized to reduce development cycles and\ncomplexity. For a single iteration in the k-means algorithm, a throughput of\n28.74 Gbps is achieved. The performance shows at least 3.93x speedup compared\nwith four representative existing FPGA-based implementations and can satisfy\nthe demand of big data applications.\n", "versions": [{"version": "v1", "created": "Mon, 17 Oct 2016 13:46:43 GMT"}, {"version": "v2", "created": "Thu, 10 Nov 2016 07:47:29 GMT"}, {"version": "v3", "created": "Tue, 22 Nov 2016 16:20:05 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Li", "Zhehao", ""], ["Jin", "Jifang", ""], ["Wang", "Lingli", ""]]}, {"id": "1610.05646", "submitter": "Anisur Molla Rahaman", "authors": "Anisur Rahaman Molla and Gopal Pandurangan", "title": "Distributed Computation of Mixing Time", "comments": "To appear in the Proceedings of ICDCN 2017, 10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mixing time of a graph is an important metric, which is not only useful\nin analyzing connectivity and expansion properties of the network, but also\nserves as a key parameter in designing efficient algorithms. We present an\nefficient distributed algorithm for computing the mixing time of undirected\ngraphs. Our algorithm estimates the mixing time $\\tau_s$ (with respect to a\nsource node $s$) of any $n$-node undirected graph in $O(\\tau_s \\log n)$ rounds.\nOur algorithm is based on random walks and require very little memory and use\nlightweight local computations, and work in the CONGEST model. Hence our\nalgorithm is scalable under bandwidth constraints and can be an helpful\nbuilding block in the design of topologically aware networks.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 14:40:12 GMT"}], "update_date": "2016-10-19", "authors_parsed": [["Molla", "Anisur Rahaman", ""], ["Pandurangan", "Gopal", ""]]}, {"id": "1610.05821", "submitter": "Yihui Ren", "authors": "Yihui Ren and Stephen Eubank and Madhurima Nath", "title": "From Network Reliability to the Ising Model: A Parallel Scheme for\n  Estimating the Joint Density of States", "comments": "Ver.2. 8 pages, 7 figures. Accepted. Phys. Rev. E", "journal-ref": null, "doi": "10.1103/PhysRevE.94.042125", "report-no": null, "categories": "cond-mat.stat-mech cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network reliability is the probability that a dynamical system composed of\ndiscrete elements interacting on a network will be found in a configuration\nthat satisfies a particular property. We introduce a new reliability property,\nIsing feasibility, for which the network reliability is the Ising model s\npartition function. As shown by Moore and Shannon, the network reliability can\nbe separated into two factors: structural, solely determined by the network\ntopology, and dynamical, determined by the underlying dynamics. In this case,\nthe structural factor is known as the joint density of states. Using methods\ndeveloped to approximate the structural factor for other reliability\nproperties, we simulate the joint density of states, yielding an approximation\nfor the partition function. Based on a detailed examination of why naive Monte\nCarlo sampling gives a poor approximation, we introduce a novel parallel scheme\nfor estimating the joint density of states using a Markov chain Monte Carlo\nmethod with a spin exchange random walk. This parallel scheme makes simulating\nthe Ising model in the presence of an external field practical on small\ncomputer clusters for networks with arbitrary topology with 10 to 6 energy\nlevels and more than 10 to 308 microstates.\n", "versions": [{"version": "v1", "created": "Tue, 18 Oct 2016 22:40:23 GMT"}], "update_date": "2016-11-23", "authors_parsed": [["Ren", "Yihui", ""], ["Eubank", "Stephen", ""], ["Nath", "Madhurima", ""]]}, {"id": "1610.06044", "submitter": "Carl Kesselman", "authors": "Karl Czajkowski, Carl Kesselman, Robert Schuler, Hongsuda\n  Tangmunarunkit", "title": "ERMrest: an entity-relationship data storage service for web-based,\n  data-oriented collaboration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.DL cs.HC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific discovery is increasingly dependent on a scientist's ability to\nacquire, curate, integrate, analyze, and share large and diverse collections of\ndata. While the details vary from domain to domain, these data often consist of\ndiverse digital assets (e.g. image files, sequence data, or simulation outputs)\nthat are organized with complex relationships and context which may evolve over\nthe course of an investigation. In addition, discovery is often collaborative,\nsuch that sharing of the data and its organizational context is highly\ndesirable. Common systems for managing file or asset metadata hide their\ninherent relational structures, while traditional relational database systems\ndo not extend to the distributed collaborative environment often seen in\nscientific investigations. To address these issues, we introduce ERMrest, a\ncollaborative data management service which allows general entity-relationship\nmodeling of metadata manipulated by RESTful access methods. We present the\ndesign criteria, architecture, and service implementation, as well as describe\nan ecosystem of tools and services that we have created to integrate metadata\ninto an end-to-end scientific data life cycle. ERMrest has been deployed to\nhundreds of users across multiple scientific research communities and projects.\nWe present two representative use cases: an international consortium and an\nearly-phase, multidisciplinary research project.\n", "versions": [{"version": "v1", "created": "Wed, 19 Oct 2016 14:52:15 GMT"}], "update_date": "2016-10-20", "authors_parsed": [["Czajkowski", "Karl", ""], ["Kesselman", "Carl", ""], ["Schuler", "Robert", ""], ["Tangmunarunkit", "Hongsuda", ""]]}, {"id": "1610.06276", "submitter": "Alexander Ulanov", "authors": "Alexander Ulanov, Andrey Simanovsky, Manish Marwah", "title": "Modeling Scalability of Distributed Machine Learning", "comments": "6 pages, 4 figures, appears at ICDE 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Present day machine learning is computationally intensive and processes large\namounts of data. It is implemented in a distributed fashion in order to address\nthese scalability issues. The work is parallelized across a number of computing\nnodes. It is usually hard to estimate in advance how many nodes to use for a\nparticular workload. We propose a simple framework for estimating the\nscalability of distributed machine learning algorithms. We measure the\nscalability by means of the speedup an algorithm achieves with more nodes. We\npropose time complexity models for gradient descent and graphical model\ninference. We validate our models with experiments on deep learning training\nand belief propagation. This framework was used to study the scalability of\nmachine learning algorithms in Apache Spark.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 03:28:40 GMT"}, {"version": "v2", "created": "Sat, 25 Mar 2017 02:17:04 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Ulanov", "Alexander", ""], ["Simanovsky", "Andrey", ""], ["Marwah", "Manish", ""]]}, {"id": "1610.06309", "submitter": "Markus Fidler", "authors": "Markus Fidler and Brenton Walker and Yuming Jiang", "title": "Non-Asymptotic Delay Bounds for Multi-Server Systems with\n  Synchronization Constraints", "comments": "arXiv admin note: text overlap with arXiv:1512.08354", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-server systems have received increasing attention with important\nimplementations such as Google MapReduce, Hadoop, and Spark. Common to these\nsystems are a fork operation, where jobs are first divided into tasks that are\nprocessed in parallel, and a later join operation, where completed tasks wait\nuntil the results of all tasks of a job can be combined and the job leaves the\nsystem. The synchronization constraint of the join operation makes the analysis\nof fork-join systems challenging and few explicit results are known. In this\nwork, we model fork-join systems using a max-plus server model that enables us\nto derive statistical bounds on waiting and sojourn times for general arrival\nand service time processes. We contribute end-to-end delay bounds for\nmulti-stage fork-join networks that grow in $\\mathcal{O}(h \\ln k)$ for $h$\nfork-join stages, each with $k$ parallel servers. We perform a detailed\ncomparison of different multi-server configurations and highlight their pros\nand cons. We also include an analysis of single-queue fork-join systems that\nare non-idling and achieve a fundamental performance gain, and compare these\nresults to both simulation and a live Spark system.\n", "versions": [{"version": "v1", "created": "Thu, 20 Oct 2016 07:39:23 GMT"}], "update_date": "2016-10-21", "authors_parsed": [["Fidler", "Markus", ""], ["Walker", "Brenton", ""], ["Jiang", "Yuming", ""]]}, {"id": "1610.06759", "submitter": "Leonid Barenboim", "authors": "Leonid Barenboim and Michael Elkin and Tzalik Maimon", "title": "Deterministic Distributed (Delta + o(\\Delta))-Edge-Coloring, and\n  Vertex-Coloring of Graphs with Bounded Diversity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider coloring problems in the distributed message-passing setting. The\npreviously-known deterministic algorithms for edge-coloring employed at least\n(2Delta - 1) colors, even though any graph admits an edge-coloring with Delta +\n1 colors [V64]. Moreover, the previously-known deterministic algorithms that\nemployed at most O(Delta) colors required superlogarithmic time\n[B15,BE10,BE11,FHK15]. In the current paper we devise deterministic\nedge-coloring algorithms that employ only Delta + o(Delta) colors, for a very\nwide family of graphs. Specifically, as long as the arboricity is a =\nO(Delta^{1 - \\epsilon}), for a constant epsilon > 0, our algorithm computes\nsuch a coloring within {polylogarithmic} deterministic time. We also devise\nsignificantly improved deterministic edge-coloring algorithms for {general\ngraphs} for a very wide range of parameters. Specifically, for any value $\\chi$\nin the range [4Delta, 2^{o(log Delta)} \\cdot Delta], our \\chi-edge-coloring\nalgorithm has smaller running time than the best previously-known\n\\chi-edge-coloring algorithms. Our algorithms are actually much more general,\nsince edge-coloring is equivalent to {vertex-coloring of line graphs.} Our\nmethod is applicable to vertex-coloring of the family of graphs with {bounded\ndiversity} that contains line graphs, line graphs of hypergraphs, and many\nother graphs.\n  Our results are obtained using a novel technique that connects vertices or\nedges in a certain way that reduces clique size. The resulting structures,\nwhich we call {connectors}, can be colored more efficiently than the original\ngraph. Moreover, the color classes constitute simpler subgraphs that can be\ncolored even more efficiently using appropriate connectors. Hence, we recurse\nuntil we obtain sufficiently simple structures that are colored directly. We\nintroduce several types of connectors that are useful for various scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 21 Oct 2016 12:28:32 GMT"}], "update_date": "2016-10-24", "authors_parsed": [["Barenboim", "Leonid", ""], ["Elkin", "Michael", ""], ["Maimon", "Tzalik", ""]]}, {"id": "1610.07184", "submitter": "Soumitra Pal", "authors": "Soumitra Pal, Tingyang Xu, Tianbao Yang, Sanguthevar Rajasekaran,\n  Jinbo Bi", "title": "Hybrid-DCA: A Double Asynchronous Approach for Stochastic Dual\n  Coordinate Ascent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In prior works, stochastic dual coordinate ascent (SDCA) has been\nparallelized in a multi-core environment where the cores communicate through\nshared memory, or in a multi-processor distributed memory environment where the\nprocessors communicate through message passing. In this paper, we propose a\nhybrid SDCA framework for multi-core clusters, the most common high performance\ncomputing environment that consists of multiple nodes each having multiple\ncores and its own shared memory. We distribute data across nodes where each\nnode solves a local problem in an asynchronous parallel fashion on its cores,\nand then the local updates are aggregated via an asynchronous across-node\nupdate scheme. The proposed double asynchronous method converges to a global\nsolution for $L$-Lipschitz continuous loss functions, and at a linear\nconvergence rate if a smooth convex loss function is used. Extensive empirical\ncomparison has shown that our algorithm scales better than the best known\nshared-memory methods and runs faster than previous distributed-memory methods.\nBig datasets, such as one of 280 GB from the LIBSVM repository, cannot be\naccommodated on a single node and hence cannot be solved by a parallel\nalgorithm. For such a dataset, our hybrid algorithm takes 30 seconds to achieve\na duality gap of $10^{-6}$ on 16 nodes each using 8 cores, which is\nsignificantly faster than the best known distributed algorithms, such as\nCoCoA+, that take more than 300 seconds on 16 nodes.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2016 15:17:43 GMT"}, {"version": "v2", "created": "Wed, 2 Nov 2016 17:50:50 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Pal", "Soumitra", ""], ["Xu", "Tingyang", ""], ["Yang", "Tianbao", ""], ["Rajasekaran", "Sanguthevar", ""], ["Bi", "Jinbo", ""]]}, {"id": "1610.07220", "submitter": "George M Slota", "authors": "George M Slota, Sivasankaran Rajamanickam, Karen Devine, Kamesh\n  Madduri", "title": "Partitioning Trillion-edge Graphs in Minutes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce XtraPuLP, a new distributed-memory graph partitioner designed to\nprocess trillion-edge graphs. XtraPuLP is based on the scalable label\npropagation community detection technique, which has been demonstrated as a\nviable means to produce high quality partitions with minimal computation time.\nOn a collection of large sparse graphs, we show that XtraPuLP partitioning\nquality is comparable to state-of-the-art partitioning methods. We also\ndemonstrate that XtraPuLP can produce partitions of real-world graphs with\nbillion+ vertices in minutes. Further, we show that using XtraPuLP partitions\nfor distributed-memory graph analytics leads to significant end-to-end\nexecution time reduction.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2016 19:07:47 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Slota", "George M", ""], ["Rajamanickam", "Sivasankaran", ""], ["Devine", "Karen", ""], ["Madduri", "Kamesh", ""]]}, {"id": "1610.07236", "submitter": "Sanjay Rajopadhye", "authors": "Tian Jin, Nirmal Prajapati, Waruna Ranasinghe, Guillaume Iooss, Yun\n  Zou, Sanjay Rajopadhye and David Wonnacott", "title": "Hybrid Static/Dynamic Schedules for Tiled Polyhedral Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Polyhedral compilers perform optimizations such as tiling and\nparallelization; when doing both, they usually generate code that executes\n\"barrier-synchronized wavefronts\" of tiles. We present a system to express and\ngenerate code for hybrid schedules, where some constraints are automatically\nsatisfied through the structure of the code, and the remainder are dynamically\nenforced at run-time with data flow mechanisms. We prove bounds on the added\noverheads that are better, by at least one polynomial degree, than those of\nprevious techniques.\n  We propose a generic mechanism to implement the needed synchronization, and\nshow it can be easily realized for a variety of targets: OpenMP, Pthreads, GPU\n(CUDA or OpenCL) code, languages like X10, Habanero, Cilk, as well as data flow\nplatforms like DAGuE, and OpenStream and MPI. We also provide a simple concrete\nimplementation that works without the need of any sophisticated run-time\nmechanism.\n  Our experiments show our simple implementation to be competitive or better\nthan the wavefront-synchronized code generated by other systems. We also show\nhow the proposed mechanism can achieve 24% to 70% reduction in energy.\n", "versions": [{"version": "v1", "created": "Sun, 23 Oct 2016 21:29:29 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Jin", "Tian", ""], ["Prajapati", "Nirmal", ""], ["Ranasinghe", "Waruna", ""], ["Iooss", "Guillaume", ""], ["Zou", "Yun", ""], ["Rajopadhye", "Sanjay", ""], ["Wonnacott", "David", ""]]}, {"id": "1610.07310", "submitter": "Rodrigo Canales", "authors": "Rodrigo Canales, Elmar Peise, Paolo Bientinesi", "title": "Large Scale Parallel Computations in R through Elemental", "comments": "16 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though in recent years the scale of statistical analysis problems has\nincreased tremendously, many statistical software tools are still limited to\nsingle-node computations. However, statistical analyses are largely based on\ndense linear algebra operations, which have been deeply studied, optimized and\nparallelized in the high-performance-computing community. To make\nhigh-performance distributed computations available for statistical analysis,\nand thus enable large scale statistical computations, we introduce RElem, an\nopen source package that integrates the distributed dense linear algebra\nlibrary Elemental into R. While on the one hand, RElem provides direct wrappers\nof Elemental's routines, on the other hand, it overloads various operators and\nfunctions to provide an entirely native R experience for distributed\ncomputations. We showcase how simple it is to port existing R programs to Relem\nand demonstrate that Relem indeed allows to scale beyond the single-node\nlimitation of R with the full performance of Elemental without any overhead.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 07:30:27 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Canales", "Rodrigo", ""], ["Peise", "Elmar", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1610.07339", "submitter": "Krzysztof Rzadca", "authors": "Fanny Pascual, Krzysztof Rzadca", "title": "Optimizing egalitarian performance in the side-effects model of\n  colocation for data center resource management", "comments": "Author's version of a paper published in Euro-Par 2017 Proceedings,\n  extends the published paper with addtional results and proofs", "journal-ref": "In: Rivera F.,(eds) Euro-Par 2017, Lecture Notes in Computer\n  Science, vol 10417. Springer, Cham", "doi": "10.1007/978-3-319-64203-1_15", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In data centers, up to dozens of tasks are colocated on a single physical\nmachine. Machines are used more efficiently, but tasks' performance\ndeteriorates, as colocated tasks compete for shared resources. As tasks are\nheterogeneous, the resulting performance dependencies are complex. In our\nprevious work [18] we proposed a new combinatorial optimization model that uses\ntwo parameters of a task - its size and its type - to characterize how a task\ninfluences the performance of other tasks allocated to the same machine.\n  In this paper, we study the egalitarian optimization goal: maximizing the\nworst-off performance. This problem generalizes the classic makespan\nminimization on multiple processors (P||Cmax). We prove that\npolynomially-solvable variants of multiprocessor scheduling are NP-hard and\nhard to approximate when the number of types is not constant. For a constant\nnumber of types, we propose a PTAS, a fast approximation algorithm, and a\nseries of heuristics. We simulate the algorithms on instances derived from a\ntrace of one of Google clusters. Algorithms aware of jobs' types lead to better\nperformance compared with algorithms solving P||Cmax.\n  The notion of type enables us to model degeneration of performance caused by\nusing standard combinatorial optimization methods. Types add a layer of\nadditional complexity. However, our results - approximation algorithms and good\naverage-case performance - show that types can be handled efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 09:34:03 GMT"}, {"version": "v2", "created": "Thu, 9 Feb 2017 13:36:55 GMT"}, {"version": "v3", "created": "Mon, 28 Aug 2017 12:51:56 GMT"}], "update_date": "2017-08-29", "authors_parsed": [["Pascual", "Fanny", ""], ["Rzadca", "Krzysztof", ""]]}, {"id": "1610.07371", "submitter": "Patrizio Dazzi Ph.D.", "authors": "Emanuele Carlini, Massimo Coppola, Patrizio Dazzi, Matteo Mordacchini", "title": "Challenges to be addressed for realising an Ephemeral Cloud Federation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper sketches the challenges to address to realise a support able to\nachieve an Ephemeral Cloud Federation, an innovative cloud computing paradigm\nthat enables the exploitation of a dynamic, personalised and context-aware set\nof resources.\n  The aim of the Ephemeral Federation is to answer to the need of combining\nprivate data-centres with both federation of cloud providers and the resource\non the edge of the network.\n  The goal of the Ephemeral Federation is to deliver a context-aware and\npersonalised federations of computational, data and network resources, able to\nmanage their heterogeneity in a highly distributed deployment, which can\ndynamically bring data and computation close to the final user.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 11:38:34 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Carlini", "Emanuele", ""], ["Coppola", "Massimo", ""], ["Dazzi", "Patrizio", ""], ["Mordacchini", "Matteo", ""]]}, {"id": "1610.07394", "submitter": "Crist\\'obal A. Navarro", "authors": "Crist\\'obal A. Navarro, Benjam\\'in Bustos, Nancy Hitscheld", "title": "Possibilities of Recursive GPU Mapping for Discrete Orthogonal Simplices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of parallel thread mapping is studied for the case of discrete\northogonal $m$-simplices. The possibility of a $O(1)$ time recursive\nblock-space map $\\lambda: \\mathbb{Z}^m \\mapsto \\mathbb{Z}^m$ is analyzed from\nthe point of view of parallel space efficiency and potential performance\nimprovement. The $2$-simplex and $3$-simplex are analyzed as special cases,\nwhere constant time maps are found, providing a potential improvement of up to\n$2\\times$ and $6\\times$ more efficient than a bounding-box approach,\nrespectively. For the general case it is shown that finding an efficient\nrecursive parallel space for an $m$-simplex depends of the choice of two\nparameters, for which some insights are provided which can lead to a volume\nthat matches the $m$-simplex for $n>n_0$, making parallel space approximately\n$m!$ times more efficient than a bounding-box.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 12:58:55 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Navarro", "Crist\u00f3bal A.", ""], ["Bustos", "Benjam\u00edn", ""], ["Hitscheld", "Nancy", ""]]}, {"id": "1610.07459", "submitter": "Theo Jepsen", "authors": "Theo Jepsen, Leandro Pacheco de Sousa, Huynh Tu Dang, Fernando Pedone,\n  Robert Soul\\'e", "title": "Optimistic Aborts for Geo-distributed Transactions", "comments": null, "journal-ref": null, "doi": null, "report-no": "USI-INF-TR-2016-05", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network latency can have a significant impact on the performance of\ntransactional storage systems, particularly in wide area or geo-distributed\ndeployments. To reduce latency, systems typically rely on a cache to service\nread-requests closer to the client. However, caches are not effective for\nwrite-heavy workloads, which have to be processed by the storage system in\norder to maintain serializability.\n  This paper presents a new technique, called optimistic abort, which reduces\nnetwork latency for high-contention, write-heavy workloads by identifying\ntransactions that will abort as early as possible, and aborting them before\nthey reach the store. We have implemented optimistic abort in a system called\nGotthard, which leverages recent advances in network data plane programmability\nto execute transaction processing logic directly in network devices. Gotthard\nexamines network traffic to observe and log transaction requests. If Gotthard\nsuspects that a transaction is likely to be aborted at the store, it aborts the\ntransaction early by re-writing the packet header, and routing the packets back\nto the client. Gotthard significantly reduces the overall latency and improves\nthe throughput for high-contention workloads.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 15:35:09 GMT"}], "update_date": "2016-10-25", "authors_parsed": [["Jepsen", "Theo", ""], ["de Sousa", "Leandro Pacheco", ""], ["Dang", "Huynh Tu", ""], ["Pedone", "Fernando", ""], ["Soul\u00e9", "Robert", ""]]}, {"id": "1610.07700", "submitter": "EPTCS", "authors": "Razieh Behjati (Simula Research Laboratory), Ahmed Elmokashfi (Simula\n  Research Laboratory)", "title": "Proceedings of the First International Workshop on Formal Methods for\n  and on the Cloud", "comments": null, "journal-ref": "EPTCS 228, 2016", "doi": "10.4204/EPTCS.228", "report-no": null, "categories": "cs.DC cs.LO cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud solutions are increasingly used for a plethora of purposes, including\nsolving memory-intensive and computation-intensive problems. Ensuring the\nreliability, availability, scalability, and security of cloud solutions, as\nnetworked distributed systems with properties such as dynamic reallocation of\nresources, is a challenging problem that requires rigorous modeling, analysis,\nand verification tools. Such tools can be devised using the techniques provided\nby the formal methods community. On the other hand, many formal analysis and\nverification tools are memory-intensive and computation-intensive solutions,\nwhich can benefit from the cloud technology.\n  The goal of the iFMCloud workshop is to identify and better understand\nchallenges of using formal and semi-formal methods for modeling and\nverification of Cloud-based systems and computer and communication networks, as\nwell as challenges and opportunities in providing formal analysis and\nverification as services on the Cloud. We aim to reach these goals by bringing\ntogether researchers and practitioners from these, and other related fields.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 01:18:53 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Behjati", "Razieh", "", "Simula Research Laboratory"], ["Elmokashfi", "Ahmed", "", "Simula\n  Research Laboratory"]]}, {"id": "1610.07735", "submitter": "Charles Jordan", "authors": "David Avis and Charles Jordan", "title": "A parallel framework for reverse search using mts", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe mts, which is a generic framework for parallelizing certain types\nof tree search programs, that (a) provides a single common wrapper containing\nall of the parallelization, and (b) minimizes the changes needed to the\nexisting single processor legacy code. The mts code was derived from ideas used\nto develop mplrs, a parallelization of the reverse search vertex enumeration\ncode lrs. The tree search properties required for the use of mts are satisfied\nby any reverse search algorithm as well as other tree search methods such as\nbacktracking and branch and bound. mts is programmed in C, uses the MPI\nparallel environment, and can be run on a network of computers.\n  As examples we parallelize two simple existing reverse search codes:\ngenerating topological orderings and generating spanning trees of a graph. We\ngive computational results comparing the parallel codes with state of the art\nsequential codes for the same problems.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 05:25:55 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Avis", "David", ""], ["Jordan", "Charles", ""]]}, {"id": "1610.07902", "submitter": "Aydin Buluc", "authors": "Ariful Azad, Aydin Buluc", "title": "A work-efficient parallel sparse matrix-sparse vector multiplication\n  algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and develop a work-efficient multithreaded algorithm for sparse\nmatrix-sparse vector multiplication (SpMSpV) where the matrix, the input\nvector, and the output vector are all sparse. SpMSpV is an important primitive\nin the emerging GraphBLAS standard and is the workhorse of many graph\nalgorithms including breadth-first search, bipartite graph matching, and\nmaximal independent set. As thread counts increase, existing multithreaded\nSpMSpV algorithms can spend more time accessing the sparse matrix data\nstructure than doing arithmetic. Our shared-memory parallel SpMSpV algorithm is\nwork efficient in the sense its total work is proportional to the number of\narithmetic operations required. The key insight is to avoid each thread\nindividually scan the list of matrix columns.\n  Our algorithm is simple to implement and operates on existing column-based\nsparse matrix formats. It performs well on diverse matrices and vectors with\nheterogeneous sparsity patterns. A high-performance implementation of the\nalgorithm attains up to 15x speedup on a 24-core Intel Ivy Bridge processor and\nup to 49x speedup on a 64-core Intel KNL manycore processor. In contrast to\nimplementations of existing algorithms, the performance of our algorithm is\nsustained on a variety of different input types include matrices representing\nscale-free and high-diameter graphs.\n", "versions": [{"version": "v1", "created": "Tue, 25 Oct 2016 14:47:42 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Azad", "Ariful", ""], ["Buluc", "Aydin", ""]]}, {"id": "1610.08015", "submitter": "Nicola Wadeson Dr", "authors": "Nicola Wadeson, Mark Basham", "title": "Savu: A Python-based, MPI Framework for Simultaneous Processing of\n  Multiple, N-dimensional, Large Tomography Datasets", "comments": "10 pages, 10 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Diamond Light Source (DLS), the UK synchrotron facility, attracts scientists\nfrom across the world to perform ground-breaking x-ray experiments. With over\n3000 scientific users per year, vast amounts of data are collected across the\nexperimental beamlines, with the highest volume of data collected during\ntomographic imaging experiments. A growing interest in tomography as an imaging\ntechnique, has led to an expansion in the range of experiments performed, in\naddition to a growth in the size of the data per experiment.\n  Savu is a portable, flexible, scientific processing pipeline capable of\nprocessing multiple, n-dimensional datasets in serial on a PC, or in parallel\nacross a cluster. Developed at DLS, and successfully deployed across the\nbeamlines, it uses a modular plugin format to enable experiment-specific\nprocessing and utilises parallel HDF5 to remove RAM restrictions. The Savu\ndesign, described throughout this paper, focuses on easy integration of\nexisting and new functionality, flexibility and ease of use for users and\ndevelopers alike.\n", "versions": [{"version": "v1", "created": "Mon, 24 Oct 2016 13:22:09 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Wadeson", "Nicola", ""], ["Basham", "Mark", ""]]}, {"id": "1610.08128", "submitter": "Aydin Buluc", "authors": "Ariful Azad, Mathias Jacquelin, Aydin Buluc, Esmond G. Ng", "title": "The Reverse Cuthill-McKee Algorithm in Distributed-Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ordering vertices of a graph is key to minimize fill-in and data structure\nsize in sparse direct solvers, maximize locality in iterative solvers, and\nimprove performance in graph algorithms. Except for naturally parallelizable\nordering methods such as nested dissection, many important ordering methods\nhave not been efficiently mapped to distributed-memory architectures. In this\npaper, we present the first-ever distributed-memory implementation of the\nreverse Cuthill-McKee (RCM) algorithm for reducing the profile of a sparse\nmatrix. Our parallelization uses a two-dimensional sparse matrix decomposition.\nWe achieve high performance by decomposing the problem into a small number of\nprimitives and utilizing optimized implementations of these primitives. Our\nimplementation shows strong scaling up to 1024 cores for smaller matrices and\nup to 4096 cores for larger matrices.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 00:26:44 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Azad", "Ariful", ""], ["Jacquelin", "Mathias", ""], ["Buluc", "Aydin", ""], ["Ng", "Esmond G.", ""]]}, {"id": "1610.08170", "submitter": "EPTCS", "authors": "Dominic Duggan (Stevens Institute of Technology), Jianhua Yao (Stevens\n  Institute of Technology)", "title": "Parameterized Dataflow (Extended Abstract)", "comments": "In Proceedings QAPL'16, arXiv:1610.07696", "journal-ref": "EPTCS 227, 2016, pp. 63-81", "doi": "10.4204/EPTCS.227.5", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dataflow networks have application in various forms of stream processing, for\nexample for parallel processing of multimedia data. The description of dataflow\ngraphs, including their firing behavior, is typically non-compositional and not\namenable to separate compilation. This article considers a dataflow language\nwith a type and effect system that captures the firing behavior of actors. This\nsystem allows definitions to abstract over actor firing rates, supporting the\ndefinition and safe composition of actor definitions where firing rates are not\ninstantiated until a dataflow graph is launched.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 05:00:33 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Duggan", "Dominic", "", "Stevens Institute of Technology"], ["Yao", "Jianhua", "", "Stevens\n  Institute of Technology"]]}, {"id": "1610.08172", "submitter": "EPTCS", "authors": "Freek van den Berg (University of Twente), Bj\\\"orn F. Postema\n  (University of Twente), Boudewijn R. Haverkort (University of Twente)", "title": "Evaluating load balancing policies for performance and energy-efficiency", "comments": "In Proceedings QAPL'16, arXiv:1610.07696", "journal-ref": "EPTCS 227, 2016, pp. 98-117", "doi": "10.4204/EPTCS.227.7", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, more and more increasingly hard computations are performed in\nchallenging fields like weather forecasting, oil and gas exploration, and\ncryptanalysis. Many of such computations can be implemented using a computer\ncluster with a large number of servers. Incoming computation requests are then,\nvia a so-called load balancing policy, distributed over the servers to ensure\noptimal performance. Additionally, being able to switch-off some servers during\nlow period of workload, gives potential to reduced energy consumption.\nTherefore, load balancing forms, albeit indirectly, a trade-off between\nperformance and energy consumption. In this paper, we introduce a syntax for\nload-balancing policies to dynamically select a server for each request based\non relevant criteria, including the number of jobs queued in servers, power\nstates of servers, and transition delays between power states of servers. To\nevaluate many policies, we implement two load balancers in: (i) iDSL, a\nlanguage and tool-chain for evaluating service-oriented systems, and (ii) a\nsimulation framework in AnyLogic. Both implementations are successfully\nvalidated by comparison of the results.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 05:00:54 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Berg", "Freek van den", "", "University of Twente"], ["Postema", "Bj\u00f6rn F.", "", "University of Twente"], ["Haverkort", "Boudewijn R.", "", "University of Twente"]]}, {"id": "1610.08198", "submitter": "EPTCS", "authors": "Rahul Kumar (Microsoft Research, Redmond, WA, USA), Chetan Bansal\n  (Microsoft Research, Redmond, WA, USA), Jakob Lichtenberg (Microsoft,\n  Redmond, WA, USA)", "title": "Static Analysis Using the Cloud", "comments": "In Proceedings iFMCloud 2016, arXiv:1610.07700", "journal-ref": "EPTCS 228, 2016, pp. 2-15", "doi": "10.4204/EPTCS.228.2", "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe our experience of using Microsoft Azure cloud\ncomputing platform for static analysis. We start by extending Static Driver\nVerifier to operate in the Microsoft Azure cloud with significant improvements\nin performance and scalability. We present our results of using SDV on single\ndrivers and driver suites using various configurations of the cloud relative to\na local machine. Finally, we describe the Static Module Verifier platform, a\nhighly extensible and configurable platform for static analysis of generic\nmodules, where we have integrated support for verification using a cloud\nservices provider (Microsoft Azure in this case).\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 06:51:52 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Kumar", "Rahul", "", "Microsoft Research, Redmond, WA, USA"], ["Bansal", "Chetan", "", "Microsoft Research, Redmond, WA, USA"], ["Lichtenberg", "Jakob", "", "Microsoft,\n  Redmond, WA, USA"]]}, {"id": "1610.08199", "submitter": "EPTCS", "authors": "Einar Broch Johnsen, Ka I Pun, S. Lizeth Tapia Tarifa", "title": "Modeling Deployment Decisions for Elastic Services with ABS", "comments": "In Proceedings iFMCloud 2016, arXiv:1610.07700", "journal-ref": "EPTCS 228, 2016, pp. 16-26", "doi": "10.4204/EPTCS.228.3", "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of cloud technology can offer significant savings for the deployment\nof services, provided that the service is able to make efficient use of the\navailable virtual resources to meet service-level requirements. To avoid\nsoftware designs that scale poorly, it is important to make deployment\ndecisions for the service at design time, early in the development of the\nservice itself. ABS offers a formal, model-based approach which integrates the\ndesign of services with the modeling of deployment decisions. In this paper, we\nillustrate the main concepts of this approach by modeling a scalable pool of\nworkers with an auto-scaling strategy and by using the model to compare\ndeployment decisions with respect to client traffic with peak loads.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 06:52:01 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Johnsen", "Einar Broch", ""], ["Pun", "Ka I", ""], ["Tarifa", "S. Lizeth Tapia", ""]]}, {"id": "1610.08201", "submitter": "EPTCS", "authors": "Nuno Oliveira (HASLab INESC TEX), Luis Soares Barbosa (HASLab INESC\n  TEC)", "title": "An Enhanced Model for Stochastic Coordination", "comments": "In Proceedings iFMCloud 2016, arXiv:1610.07700", "journal-ref": "EPTCS 228, 2016, pp. 35-45", "doi": "10.4204/EPTCS.228.5", "report-no": null, "categories": "cs.DC cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications developed over the cloud coordinate several, often anonymous,\ncomputational resources, distributed over different execution nodes, within\nflexible architectures. Coordination models able to represent quantitative data\nprovide a powerful basis for their analysis and validation. This paper extends\nIMCreo, a semantic model for Stochastic reo based on interactive Markov chains,\nto enhance its scalability, by regarding each channel and node, as well as\ninterface components, as independent stochastic processes that may (or may not)\nsynchronise with the rest of the coordination circuit.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 06:52:22 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Oliveira", "Nuno", "", "HASLab INESC TEX"], ["Barbosa", "Luis Soares", "", "HASLab INESC\n  TEC"]]}, {"id": "1610.08373", "submitter": "Theophanis Hadjistasi", "authors": "Theophanis Hadjistasi, Nicolas Nicolaou and Alexander A. Schwarzmann", "title": "Oh-RAM! One and a Half Round Atomic Memory", "comments": "A Brief Announcement related to this work was presented at ACM PODC,\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emulating atomic read/write shared objects in a message-passing system is a\nfundamental problem in distributed computing. Considering that network\ncommunication is the most expensive resource, efficiency is measured first of\nall in terms of the communication needed to implement read and write\noperations. It is well known that 2 communication round-trip phases involving\nin total 4 message exchanges are sufficient to implemented atomic operations.\nIt is also known that under certain constraints on the number of readers with\nrespect to the numbers of replica servers and failures it is possible to\nimplement single-writer atomic objects such that each operation involves one\nround-trip phase. We present algorithms that allow operations to complete in 3\ncommunication exchanges without imposing any constraints on the number of\nreaders and writers. Specifically, we present an atomic memory implementation\nfor the SWMR setting, where reads complete in 3 communication exchanges and\nwrites complete in 2 exchanges. We pose the question of whether it is possible\nto implement MWMR memory where operations complete in at most 3 communication\nexchanges. We answer this question in the negative by showing that an atomic\nmemory implementation is impossible if both read and write operations take 3\ncommunication exchanges, even when assuming two writers, two readers, and a\nsingle replica server failure. Motivated by this impossibility result, we\nprovide a MWMR atomic memory implementation where reads involve 3 and writes 4\ncommunication exchanges. In light of our impossibility result these algorithms\nare optimal in terms of the number of communication exchanges. We rigorously\nreason about the correctness of the algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 15:14:13 GMT"}, {"version": "v2", "created": "Mon, 16 Nov 2020 08:36:42 GMT"}], "update_date": "2020-11-17", "authors_parsed": [["Hadjistasi", "Theophanis", ""], ["Nicolaou", "Nicolas", ""], ["Schwarzmann", "Alexander A.", ""]]}, {"id": "1610.08494", "submitter": "Saurabh Hukerikar", "authors": "Saurabh Hukerikar, Christian Engelmann", "title": "Havens: Explicit Reliable Memory Regions for HPC Applications", "comments": "2016 IEEE High Performance Extreme Computing Conference (HPEC '16),\n  September 2016, Waltham, MA, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supporting error resilience in future exascale-class supercomputing systems\nis a critical challenge. Due to transistor scaling trends and increasing memory\ndensity, scientific simulations are expected to experience more interruptions\ncaused by transient errors in the system memory. Existing hardware-based\ndetection and recovery techniques will be inadequate to manage the presence of\nhigh memory fault rates.\n  In this paper we propose a partial memory protection scheme based on\nregion-based memory management. We define the concept of regions called havens\nthat provide fault protection for program objects. We provide reliability for\nthe regions through a software-based parity protection mechanism. Our approach\nenables critical program objects to be placed in these havens. The fault\ncoverage provided by our approach is application agnostic, unlike\nalgorithm-based fault tolerance techniques.\n", "versions": [{"version": "v1", "created": "Wed, 26 Oct 2016 19:56:09 GMT"}], "update_date": "2016-10-27", "authors_parsed": [["Hukerikar", "Saurabh", ""], ["Engelmann", "Christian", ""]]}, {"id": "1610.08685", "submitter": "Ale\\v{s} Bizjak", "authors": "Karine Altisen, Pierre Corbineau, and Stephane Devismes", "title": "A Framework for Certified Self-Stabilization", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 13, Issue 4 (November\n  28, 2017) lmcs:4098", "doi": "10.23638/LMCS-13(4:14)2017", "report-no": null, "categories": "cs.DC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a general framework to build certified proofs of distributed\nself-stabilizing algorithms with the proof assistant Coq. We first define in\nCoq the locally shared memory model with composite atomicity, the most commonly\nused model in the self-stabilizing area. We then validate our framework by\ncertifying a non trivial part of an existing silent self-stabilizing algorithm\nwhich builds a $k$-clustering of the network. We also certify a quantitative\nproperty related to the output of this algorithm. Precisely, we show that the\ncomputed $k$-clustering contains at most $\\lfloor \\frac{n-1}{k+1} \\rfloor + 1$\nclusterheads, where $n$ is the number of nodes in the network. To obtain these\nresults, we also developed a library which contains general tools related to\npotential functions and cardinality of sets.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 10:02:25 GMT"}, {"version": "v2", "created": "Wed, 25 Oct 2017 09:26:21 GMT"}, {"version": "v3", "created": "Tue, 21 Nov 2017 09:33:12 GMT"}], "update_date": "2019-03-14", "authors_parsed": [["Altisen", "Karine", ""], ["Corbineau", "Pierre", ""], ["Devismes", "Stephane", ""]]}, {"id": "1610.08691", "submitter": "Nick Brown", "authors": "Nick Brown", "title": "Type oriented parallel programming for Exascale", "comments": "As presented at the Exascale Applications and Software Conference\n  (EASC), 9th-11th April 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Whilst there have been great advances in HPC hardware and software in recent\nyears, the languages and models that we use to program these machines have\nremained much more static. This is not from a lack of effort, but instead by\nvirtue of the fact that the foundation that many programming languages are\nbuilt on is not sufficient for the level of expressivity required for parallel\nwork. The result is an implicit trade-off between programmability and\nperformance which is made worse due to the fact that, whilst many scientific\nusers are experts within their own fields, they are not HPC experts.\n  Type oriented programming looks to address this by encoding the complexity of\na language via the type system. Most of the language functionality is contained\nwithin a loosely coupled type library that can be flexibly used to control many\naspects such as parallelism. Due to the high level nature of this approach\nthere is much information available during compilation which can be used for\noptimisation and, in the absence of type information, the compiler can apply\nsensible default options thus supporting both the expert programmer and novice\nalike.\n  We demonstrate that, at no performance or scalability penalty when running on\nup to 8196 cores of a Cray XE6 system, codes written in this type oriented\nmanner provide improved programmability. The programmer is able to write\nsimple, implicit parallel, HPC code at a high level and then explicitly tune by\nadding additional type information if required.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 10:28:53 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Brown", "Nick", ""]]}, {"id": "1610.08833", "submitter": "Erik Schnetter", "authors": "Anshu Dubey, Ann Almgren, John Bell, Martin Berzins, Steve Brandt,\n  Greg Bryan, Phillip Colella, Daniel Graves, Michael Lijewski, Frank\n  L\\\"offler, Brian O'Shea, Erik Schnetter, Brian Van Straalen, Klaus Weide", "title": "A Survey of High Level Frameworks in Block-Structured Adaptive Mesh\n  Refinement Packages", "comments": null, "journal-ref": "Journal of Parallel and Distributed Computing, Volume 74, Issue\n  12, December 2014, Pages 3217-3227", "doi": "10.1016/j.jpdc.2014.07.001", "report-no": null, "categories": "cs.DC astro-ph.HE gr-qc", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the last decade block-structured adaptive mesh refinement (SAMR) has\nfound increasing use in large, publicly available codes and frameworks. SAMR\nframeworks have evolved along different paths. Some have stayed focused on\nspecific domain areas, others have pursued a more general functionality,\nproviding the building blocks for a larger variety of applications. In this\nsurvey paper we examine a representative set of SAMR packages and SAMR-based\ncodes that have been in existence for half a decade or more, have a reasonably\nsized and active user base outside of their home institutions, and are publicly\navailable. The set consists of a mix of SAMR packages and application codes\nthat cover a broad range of scientific domains. We look at their high-level\nframeworks, and their approach to dealing with the advent of radical changes in\nhardware architecture. The codes included in this survey are BoxLib, Cactus,\nChombo, Enzo, FLASH, and Uintah.\n", "versions": [{"version": "v1", "created": "Thu, 27 Oct 2016 15:23:34 GMT"}], "update_date": "2016-10-28", "authors_parsed": [["Dubey", "Anshu", ""], ["Almgren", "Ann", ""], ["Bell", "John", ""], ["Berzins", "Martin", ""], ["Brandt", "Steve", ""], ["Bryan", "Greg", ""], ["Colella", "Phillip", ""], ["Graves", "Daniel", ""], ["Lijewski", "Michael", ""], ["L\u00f6ffler", "Frank", ""], ["O'Shea", "Brian", ""], ["Schnetter", "Erik", ""], ["Van Straalen", "Brian", ""], ["Weide", "Klaus", ""]]}, {"id": "1610.09146", "submitter": "Satya Pramod Jammy", "authors": "Satya P. Jammy, Christian T. Jacobs, Neil D. Sandham", "title": "Performance evaluation of explicit finite difference algorithms with\n  varying amounts of computational and memory intensity", "comments": "Author accepted version. Accepted for publication in Journal of\n  Computational Science on 27 October 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.MS physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future architectures designed to deliver exascale performance motivate the\nneed for novel algorithmic changes in order to fully exploit their\ncapabilities. In this paper, the performance of several numerical algorithms,\ncharacterised by varying degrees of memory and computational intensity, are\nevaluated in the context of finite difference methods for fluid dynamics\nproblems. It is shown that, by storing some of the evaluated derivatives as\nsingle thread- or process-local variables in memory, or recomputing the\nderivatives on-the-fly, a speed-up of ~2 can be obtained compared to\ntraditional algorithms that store all derivatives in global arrays.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 09:45:31 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Jammy", "Satya P.", ""], ["Jacobs", "Christian T.", ""], ["Sandham", "Neil D.", ""]]}, {"id": "1610.09190", "submitter": "Lican Huang", "authors": "Lican Huang", "title": "Domain Specific Distributed Search Engine Based on Semantic P2P Networks", "comments": "10 pages, 7 figures , ICNDC2016 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a distributed search engine based on semantic P2P\nNetworks. The user's computers join the domains in which user wants to share\ninformation in semantic P2P networks which is domain specific virtual tree\n(VIRGO ). Each user computer contains search engine which indexes the domain\nspecific information on local computer or Internet. We can get all search\ninformation through P2P message provided by all joined computers. By companies'\neffort, we have implemented a prototype of distributed search engine, which\ndemonstrates easily retrieving domain-related information provided by joined\ncomputers .\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 12:53:02 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Huang", "Lican", ""]]}, {"id": "1610.09261", "submitter": "Laurent Duval", "authors": "Abir Ben Khaled-El Feki and Laurent Duval and Cyril Faure and Daniel\n  Simon and Mongi Ben Gaid", "title": "CHOPtrey: contextual online polynomial extrapolation for enhanced\n  multi-core co-simulation of complex systems", "comments": null, "journal-ref": "Simulation: Transactions of the Society for Modeling and\n  Simulation International, March 2017, Volume 93, Number 3, pages 185-200", "doi": "10.1177/0037549716684026", "report-no": null, "categories": "cs.SY cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing complexity of Cyber-Physical Systems (CPS), together with\nincreasingly available parallelism provided by multi-core chips, fosters the\nparallelization of simulation. Simulation speed-ups are expected from\nco-simulation and parallelization based on model splitting into weak-coupled\nsub-models, as for instance in the framework of Functional Mockup Interface\n(FMI). However, slackened synchronization between sub-models and their\nassociated solvers running in parallel introduces integration errors, which\nmust be kept inside acceptable bounds.\n  CHOPtrey denotes a forecasting framework enhancing the performance of complex\nsystem co-simulation, with a trivalent articulation. First, we consider the\nframework of a Computationally Hasty Online Prediction system (CHOPred). It\nallows to improve the trade-off between integration speed-ups, needing large\ncommunication steps, and simulation precision, needing frequent updates for\nmodel inputs. Second, smoothed adaptive forward prediction improves\nco-simulation accuracy. It is obtained by past-weighted extrapolation based on\nCausal Hopping Oblivious Polynomials (CHOPoly). And third, signal behavior is\nsegmented to handle the discontinuities of the exchanged signals: the\nsegmentation is performed in a Contextual \\& Hierarchical Ontology of Patterns\n(CHOPatt).\n  Implementation strategies and simulation results demonstrate the framework\nability to adaptively relax data communication constraints beyond\nsynchronization points which sensibly accelerate simulation. The CHOPtrey\nframework extends the range of applications of standard Lagrange-type methods,\noften deemed unstable. The embedding of predictions in lag-dependent smoothing\nand discontinuity handling demonstrates its practical efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 28 Oct 2016 15:17:02 GMT"}, {"version": "v2", "created": "Sun, 5 Feb 2017 00:26:43 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Feki", "Abir Ben Khaled-El", ""], ["Duval", "Laurent", ""], ["Faure", "Cyril", ""], ["Simon", "Daniel", ""], ["Gaid", "Mongi Ben", ""]]}, {"id": "1610.09435", "submitter": "Giuseppe Antonio Di Luna", "authors": "Giuseppe Antonio Di Luna, Paola Flocchini, Taisuke Izumi, Tomoko\n  Izumi, Nicola Santoro, Giovanni Viglietta", "title": "On the Power of Weaker Pairwise Interaction: Fault-Tolerant Simulation\n  of Population Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate the computational power of Population Protocols\n(PP) under some unreliable and/or weaker interaction models. More precisely, we\nfocus on two features related to the power of interactions: omission failures\nand one-way communications. An omission failure, a notion that this paper\nintroduces for the first time in the context of PP, is the loss by one or both\nparties of the information transmitted in an interaction. The failure may or\nmay not be detected by either party. On the other hand, in one-way models,\ncommunication happens only in one direction: only one of the two agents can\nchange its state depending on both agents' states, and the other agent may or\nmay not be aware of the interaction. These notions can be combined, obtaining\none-way protocols with (possibly detectable) omission failures.\n  A general question is what additional power is necessary and sufficient to\ncompletely overcome the weakness of one-way protocols and enable them to\nsimulate two-way protocols, with and without omission failures. As a basic\nfeature, a simulator needs to implement an atomic communication of states\nbetween two agents; this task is further complicated by the anonymity of the\nagents, their lack of knowledge of the system, and the limited amount of memory\nthat they may have.\n  We provide the first answers to these questions by presenting and analyzing\nseveral simulators, i.e., wrapper protocols converting any protocol for the\nstandard two-way model into one running on a weaker one.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2016 01:25:43 GMT"}, {"version": "v2", "created": "Tue, 1 Nov 2016 20:01:52 GMT"}], "update_date": "2016-11-03", "authors_parsed": [["Di Luna", "Giuseppe Antonio", ""], ["Flocchini", "Paola", ""], ["Izumi", "Taisuke", ""], ["Izumi", "Tomoko", ""], ["Santoro", "Nicola", ""], ["Viglietta", "Giovanni", ""]]}, {"id": "1610.09451", "submitter": "Evan Sparks", "authors": "Evan R. Sparks, Shivaram Venkataraman, Tomer Kaftan, Michael J.\n  Franklin, Benjamin Recht", "title": "KeystoneML: Optimizing Pipelines for Large-Scale Advanced Analytics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern advanced analytics applications make use of machine learning\ntechniques and contain multiple steps of domain-specific and general-purpose\nprocessing with high resource requirements. We present KeystoneML, a system\nthat captures and optimizes the end-to-end large-scale machine learning\napplications for high-throughput training in a distributed environment with a\nhigh-level API. This approach offers increased ease of use and higher\nperformance over existing systems for large scale learning. We demonstrate the\neffectiveness of KeystoneML in achieving high quality statistical accuracy and\nscalable training using real world datasets in several domains. By optimizing\nexecution KeystoneML achieves up to 15x training throughput over unoptimized\nexecution on a real image classification application.\n", "versions": [{"version": "v1", "created": "Sat, 29 Oct 2016 04:21:24 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Sparks", "Evan R.", ""], ["Venkataraman", "Shivaram", ""], ["Kaftan", "Tomer", ""], ["Franklin", "Michael J.", ""], ["Recht", "Benjamin", ""]]}, {"id": "1610.09590", "submitter": "Shreenath Dutt Sharma", "authors": "Shreenath Dutt, Ankita Kalra", "title": "A Scalable and Robust Framework for Intelligent Real-time Video\n  Surveillance", "comments": "4 pages, 3 figures, Presented in International Conference on Advances\n  in Computing, Communications and Informatics (ICACCI-2016), September 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an intelligent, reliable and storage-efficient\nvideo surveillance system using Apache Storm and OpenCV. As a Storm topology,\nwe have added multiple information extraction modules that only write important\ncontent to the disk. Our topology is extensible, capable of adding novel\nalgorithms as per the use case without affecting the existing ones, since all\nthe processing is independent of each other. This framework is also highly\nscalable and fault tolerant, which makes it a best option for organisations\nthat need to monitor a large network of surveillance cameras.\n", "versions": [{"version": "v1", "created": "Sun, 30 Oct 2016 01:22:52 GMT"}], "update_date": "2016-11-01", "authors_parsed": [["Dutt", "Shreenath", ""], ["Kalra", "Ankita", ""]]}, {"id": "1610.09962", "submitter": "Sabeur Aridhi", "authors": "Wissem Inoubli, Sabeur Aridhi, Haithem Mezni, Mondher Maddouri,\n  Engelbert Mephu Nguifo", "title": "An Experimental Survey on Big Data Frameworks", "comments": null, "journal-ref": null, "doi": "10.1016/j.future.2018.04.032", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, increasingly large amounts of data are generated from a variety of\nsources. Existing data processing technologies are not suitable to cope with\nthe huge amounts of generated data. Yet, many research works focus on Big Data,\na buzzword referring to the processing of massive volumes of (unstructured)\ndata. Recently proposed frameworks for Big Data applications help to store,\nanalyze and process the data. In this paper, we discuss the challenges of Big\nData and we survey existing Big Data frameworks. We also present an\nexperimental evaluation and a comparative study of the most popular Big Data\nframeworks. This survey is concluded with a presentation of best practices\nrelated to the use of the studied frameworks in several application domains\nsuch as machine learning, graph processing and real-world applications.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 15:08:07 GMT"}, {"version": "v2", "created": "Sun, 26 Mar 2017 12:05:24 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2018 15:34:57 GMT"}], "update_date": "2018-06-07", "authors_parsed": [["Inoubli", "Wissem", ""], ["Aridhi", "Sabeur", ""], ["Mezni", "Haithem", ""], ["Maddouri", "Mondher", ""], ["Nguifo", "Engelbert Mephu", ""]]}, {"id": "1610.10061", "submitter": "Bader AlBdaiwi", "authors": "Bader F. AlBdaiwi, Hosam M.F. AboElFotoh", "title": "A GPU-Based Genetic Algorithm for the P-Median Problem", "comments": null, "journal-ref": "The Journal of Supercomputing 73 (10), Oct 2018, 4221-4244", "doi": "10.1007/s11227-017-2006-x", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The p-median problem is a well-known NP-hard problem. Many heuristics have\nbeen proposed in the literature for this problem. In this paper, we exploit a\nGPGPU parallel computing platform to present a new genetic algorithm\nimplemented in Cuda and based on a Pseudo Boolean formulation of the p-median\nproblem. We have tested the effectiveness of our algorithm using a Tesla K40\n(2880 Cuda cores) on 290 different benchmark instances obtained from\nOR-Library, discrete location problems benchmark library, and benchmarks\nintroduced in recent publications. The algorithm succeeded in finding optimal\nsolutions for all instances except for two OR-library instances, namely pmed30\nand pmed40, where better than 99.9\\% approximations were obtained.\n", "versions": [{"version": "v1", "created": "Mon, 31 Oct 2016 18:46:30 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["AlBdaiwi", "Bader F.", ""], ["AboElFotoh", "Hosam M. F.", ""]]}]