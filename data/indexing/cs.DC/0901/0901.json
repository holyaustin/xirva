[{"id": "0901.0029", "submitter": "John J. Rehr", "authors": "J. J. Rehr, J. P. Gardner, M. Prange, L. Svec and F. Vila", "title": "Scientific Computing in the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the feasibility of high performance scientific computation\nusing cloud computers as an alternative to traditional computational tools. The\navailability of these large, virtualized pools of compute resources raises the\npossibility of a new compute paradigm for scientific research with many\nadvantages. For research groups, cloud computing provides convenient access to\nreliable, high performance clusters and storage, without the need to purchase\nand maintain sophisticated hardware. For developers, virtualization allows\nscientific codes to be optimized and pre-installed on machine images,\nfacilitating control over the computational environment. Preliminary tests are\npresented for serial and parallelized versions of the widely used x-ray\nspectroscopy and electronic structure code FEFF on the Amazon Elastic Compute\nCloud, including CPU and network performance.\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2008 20:35:40 GMT"}], "update_date": "2009-01-05", "authors_parsed": [["Rehr", "J. J.", ""], ["Gardner", "J. P.", ""], ["Prange", "M.", ""], ["Svec", "L.", ""], ["Vila", "F.", ""]]}, {"id": "0901.0043", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek, Ursula Goltz, Jens-Wolfhard Schicke", "title": "Symmetric and Asymmetric Asynchronous Interaction", "comments": "27 pages. An extended abstract of this paper was presented at the\n  first Interaction and Concurrency Experience (ICE'08) on Synchronous and\n  Asynchronous Interactions in Concurrent Distributed Systems, and will appear\n  in Electronic Notes in Theoretical Computer Science, Elsevier", "journal-ref": null, "doi": null, "report-no": "Technical Report 2008-03, Technical University of Braunschweig", "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate classes of systems based on different interaction patterns\nwith the aim of achieving distributability. As our system model we use Petri\nnets. In Petri nets, an inherent concept of simultaneity is built in, since\nwhen a transition has more than one preplace, it can be crucial that tokens are\nremoved instantaneously. When modelling a system which is intended to be\nimplemented in a distributed way by a Petri net, this built-in concept of\nsynchronous interaction may be problematic. To investigate this we consider\nasynchronous implementations of nets, in which removing tokens from places can\nno longer be considered as instantaneous. We model this by inserting silent\n(unobservable) transitions between transitions and some of their preplaces. We\ninvestigate three such implementations, differing in the selection of preplaces\nof a transition from which the removal of a token is considered time consuming,\nand the possibility of collecting the tokens in a given order.\n  We investigate the effect of these different transformations of instantaneous\ninteraction into asynchronous interaction patterns by comparing the behaviours\nof nets before and after insertion of the silent transitions. We exhibit for\nwhich classes of Petri nets we obtain equivalent behaviour with respect to\nfailures equivalence.\n  It turns out that the resulting hierarchy of Petri net classes can be\ndescribed by semi-structural properties. For two of the classes we obtain\nprecise characterisations; for the remaining class we obtain lower and upper\nbounds.\n  We briefly comment on possible applications of our results to Message\nSequence Charts.\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2008 03:43:25 GMT"}], "update_date": "2009-01-05", "authors_parsed": [["van Glabbeek", "Rob", ""], ["Goltz", "Ursula", ""], ["Schicke", "Jens-Wolfhard", ""]]}, {"id": "0901.0048", "submitter": "Rob van Glabbeek", "authors": "Rob van Glabbeek, Ursula Goltz and Jens-Wolfhard Schicke", "title": "On Synchronous and Asynchronous Interaction in Distributed Systems", "comments": "26 pages. An extended abstract of this paper appeared in Proceedings\n  33rd International Symposium on Mathematical Foundations of Computer Science\n  (MFCS 2008), Torun, Poland, August 2008 (E. Ochmanski & J. Tyszkiewicz,\n  eds.), LNCS 5162, Springer, 2008, pp. 16-35", "journal-ref": null, "doi": null, "report-no": "Technical Report 2008-04, Technical University of Braunschweig", "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When considering distributed systems, it is a central issue how to deal with\ninteractions between components. In this paper, we investigate the paradigms of\nsynchronous and asynchronous interaction in the context of distributed systems.\nWe investigate to what extent or under which conditions synchronous interaction\nis a valid concept for specification and implementation of such systems. We\nchoose Petri nets as our system model and consider different notions of\ndistribution by associating locations to elements of nets. First, we\ninvestigate the concept of simultaneity which is inherent in the semantics of\nPetri nets when transitions have multiple input places. We assume that tokens\nmay only be taken instantaneously by transitions on the same location. We\nexhibit a hierarchy of `asynchronous' Petri net classes by different\nassumptions on possible distributions. Alternatively, we assume that the\nsynchronisations specified in a Petri net are crucial system properties. Hence\ntransitions and their preplaces may no longer placed on separate locations. We\nthen answer the question which systems may be implemented in a distributed way\nwithout restricting concurrency, assuming that locations are inherently\nsequential. It turns out that in both settings we find semi-structural\nproperties of Petri nets describing exactly the problematic situations for\ninteractions in distributed systems.\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2008 04:13:35 GMT"}], "update_date": "2009-01-05", "authors_parsed": [["van Glabbeek", "Rob", ""], ["Goltz", "Ursula", ""], ["Schicke", "Jens-Wolfhard", ""]]}, {"id": "0901.0131", "submitter": "Ioan Raicu", "authors": "Ian Foster, Yong Zhao, Ioan Raicu, Shiyong Lu", "title": "Cloud Computing and Grid Computing 360-Degree Compared", "comments": "IEEE Grid Computing Environments (GCE08) 2008", "journal-ref": null, "doi": "10.1109/GCE.2008.4738445", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Computing has become another buzzword after Web 2.0. However, there are\ndozens of different definitions for Cloud Computing and there seems to be no\nconsensus on what a Cloud is. On the other hand, Cloud Computing is not a\ncompletely new concept; it has intricate connection to the relatively new but\nthirteen-year established Grid Computing paradigm, and other relevant\ntechnologies such as utility computing, cluster computing, and distributed\nsystems in general. This paper strives to compare and contrast Cloud Computing\nwith Grid Computing from various angles and give insights into the essential\ncharacteristics of both.\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2008 19:13:05 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Foster", "Ian", ""], ["Zhao", "Yong", ""], ["Raicu", "Ioan", ""], ["Lu", "Shiyong", ""]]}, {"id": "0901.0134", "submitter": "Ioan Raicu", "authors": "Zhao Zhang, Allan Espinosa, Kamil Iskra, Ioan Raicu, Ian Foster,\n  Michael Wilde", "title": "Design and Evaluation of a Collective IO Model for Loosely Coupled\n  Petascale Programming", "comments": "IEEE Many-Task Computing on Grids and Supercomputers (MTAGS08) 2008", "journal-ref": null, "doi": "10.1109/MTAGS.2008.4777908", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loosely coupled programming is a powerful paradigm for rapidly creating\nhigher-level applications from scientific programs on petascale systems,\ntypically using scripting languages. This paradigm is a form of many-task\ncomputing (MTC) which focuses on the passing of data between programs as\nordinary files rather than messages. While it has the significant benefits of\ndecoupling producer and consumer and allowing existing application programs to\nbe executed in parallel with no recoding, its typical implementation using\nshared file systems places a high performance burden on the overall system and\non the user who will analyze and consume the downstream data. Previous efforts\nhave achieved great speedups with loosely coupled programs, but have done so\nwith careful manual tuning of all shared file system access. In this work, we\nevaluate a prototype collective IO model for file-based MTC. The model enables\nefficient and easy distribution of input data files to computing nodes and\ngathering of output results from them. It eliminates the need for such manual\ntuning and makes the programming of large-scale clusters using a loosely\ncoupled model easier. Our approach, inspired by in-memory approaches to\ncollective operations for parallel programming, builds on fast local file\nsystems to provide high-speed local file caches for parallel scripts, uses a\nbroadcast approach to handle distribution of common input data, and uses\nefficient scatter/gather and caching techniques for input and output. We\ndescribe the design of the prototype model, its implementation on the Blue\nGene/P supercomputer, and present preliminary measurements of its performance\non synthetic benchmarks and on a large-scale molecular dynamics application.\n", "versions": [{"version": "v1", "created": "Wed, 31 Dec 2008 19:35:07 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Zhang", "Zhao", ""], ["Espinosa", "Allan", ""], ["Iskra", "Kamil", ""], ["Raicu", "Ioan", ""], ["Foster", "Ian", ""], ["Wilde", "Michael", ""]]}, {"id": "0901.0179", "submitter": "Janardan Misra", "authors": "Janardan Misra and Suman Roy", "title": "Techniques for Distributed Reachability Analysis with Partial Order and\n  Symmetry based Reductions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose techniques for efficient reachability analysis of the\nstate space (e.g., detection of bad states) using a combination of partial\norder and symmetry based reductions in a distributed setting. The proposed\ntechniques are focused towards explicit state space enumeration based\nmodel-checkers like SPIN. We consider variants for both depth-first as well as\nbreadth-first based generation of the reduced state graphs on-the-fly.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jan 2009 15:29:28 GMT"}], "update_date": "2009-01-05", "authors_parsed": [["Misra", "Janardan", ""], ["Roy", "Suman", ""]]}, {"id": "0901.0291", "submitter": "Mugurel Ionut Andreica", "authors": "Alexandra Carpen-Amarie, Mugurel Ionut Andreica, Valentin Cristea", "title": "An Algorithm for File Transfer Scheduling in Grid Environments", "comments": "Proceedings of the International Workshop on High Performance Grid\n  Middleware (HiPerGrid), pp. 33-40, Bucharest, Romania, 21-22 November, 2008.\n  (ISSN: 2065-0701)", "journal-ref": "Proceedings of the International Workshop on High Performance Grid\n  Middleware (HiPerGrid), pp. 33-40, Bucharest, Romania, 2008. (ISSN:\n  2065-0701)", "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the data transfer scheduling problem for Grid\nenvironments, presenting a centralized scheduler developed with dynamic and\nadaptive features. The algorithm offers a reservation system for user transfer\nrequests that allocates them transfer times and bandwidth, according to the\nnetwork topology and the constraints the user specified for the requests. This\npaper presents the projects related to the data transfer field, the design of\nthe framework for which the scheduler was built, the main features of the\nscheduler, the steps for transfer requests rescheduling and two tests that\nillustrate the system's behavior for different types of transfer requests.\n", "versions": [{"version": "v1", "created": "Fri, 2 Jan 2009 22:03:02 GMT"}], "update_date": "2009-01-06", "authors_parsed": [["Carpen-Amarie", "Alexandra", ""], ["Andreica", "Mugurel Ionut", ""], ["Cristea", "Valentin", ""]]}, {"id": "0901.1123", "submitter": "Reza Rastegar", "authors": "Arash Hariri, K. Navi, Reza Rastegar", "title": "A High Dynamic Range 3-Moduli-Set with Efficient Reverse Converter", "comments": null, "journal-ref": "Computers & Mathematics with Applications (2008), Vol 55, No 4,\n  660-668", "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  -Residue Number System (RNS) is a valuable tool for fast and parallel\narithmetic. It has a wide application in digital signal processing, fault\ntolerant systems, etc. In this work, we introduce the 3-moduli set {2^n,\n2^{2n}-1, 2^{2n}+1} and propose its residue to binary converter using the\nChinese Remainder Theorem. We present its simple hardware implementation that\nmainly includes one Carry Save Adder (CSA) and a Modular Adder (MA). We compare\nthe performance and area utilization of our reverse converter to the reverse\nconverters of the moduli sets {2^n-1, 2^n, 2^n+1, 2^{2n}+1} and {2^n-1, 2^n,\n2^n+1, 2^n-2^{(n+1)/2}+1, 2^n+2^{(n+1)/2}+1} that have the same dynamic range\nand we demonstrate that our architecture is better in terms of performance and\narea utilization. Also, we show that our reverse converter is faster than the\nreverse converter of {2^n-1, 2^n, 2^n+1} for dynamic ranges like 8-bit, 16-bit,\n32-bit and 64-bit however it requires more area.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jan 2009 20:14:00 GMT"}], "update_date": "2009-01-09", "authors_parsed": [["Hariri", "Arash", ""], ["Navi", "K.", ""], ["Rastegar", "Reza", ""]]}, {"id": "0901.1307", "submitter": "Marc Daumas", "authors": "Sylvain Collange (ELIAUS), Yoginder Dandass (CSE), Marc Daumas\n  (ELIAUS), David Defour (ELIAUS)", "title": "Using Graphics Processors for Parallelizing Hash-based Data Carving", "comments": null, "journal-ref": "42nd Hawaii International Conference on System Sciences, Waikoloa\n  : \\'Etats-Unis d'Am\\'erique (2009)", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to detect fragments of deleted image files and to reconstruct\nthese image files from all available fragments on disk is a key activity in the\nfield of digital forensics. Although reconstruction of image files from the\nfile fragments on disk can be accomplished by simply comparing the content of\nsectors on disk with the content of known files, this brute-force approach can\nbe time consuming. This paper presents results from research into the use of\nGraphics Processing Units (GPUs) in detecting specific image file byte patterns\nin disk clusters. Unique identifying pattern for each disk sector is compared\nagainst patterns in known images. A pattern match indicates the potential\npresence of an image and flags the disk sector for further in-depth examination\nto confirm the match. The GPU-based implementation outperforms the software\nimplementation by a significant margin.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jan 2009 20:15:26 GMT"}], "update_date": "2009-01-12", "authors_parsed": [["Collange", "Sylvain", "", "ELIAUS"], ["Dandass", "Yoginder", "", "CSE"], ["Daumas", "Marc", "", "ELIAUS"], ["Defour", "David", "", "ELIAUS"]]}, {"id": "0901.1582", "submitter": "Michael Noble S.", "authors": "Michael S. Noble, Li Ji, Andrew Young, Julia Lee", "title": "Parallelizing the XSTAR Photoionization Code", "comments": "ADASS 2008 (Quebec) proceedings (4 pages, 1 figure)", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe two means by which XSTAR, a code which computes physical\nconditions and emission spectra of photoionized gases, has been parallelized.\nThe first is pvm_xstar, a wrapper which can be used in place of the serial\nxstar2xspec script to foster concurrent execution of the XSTAR command line\napplication on independent sets of parameters. The second is PModel, a plugin\nfor the Interactive Spectral Interpretation System (ISIS) which allows\narbitrary components of a broad range of astrophysical models to be distributed\nacross processors during fitting and confidence limits calculations, by\nscientists with little training in parallel programming. Plugging the XSTAR\nfamily of analytic models into PModel enables multiple ionization states (e.g.,\nof a complex absorber/emitter) to be computed simultaneously, alleviating the\noften prohibitive expense of the traditional serial approach. Initial\nperformance results indicate that these methods substantially enlarge the\nproblem space to which XSTAR may be applied within practical timeframes.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jan 2009 14:28:52 GMT"}], "update_date": "2009-01-23", "authors_parsed": [["Noble", "Michael S.", ""], ["Ji", "Li", ""], ["Young", "Andrew", ""], ["Lee", "Julia", ""]]}, {"id": "0901.2310", "submitter": "Adam Barker", "authors": "Adam Barker, Jano I. van Hemert, Richard A. Baldock, Malcolm P.\n  Atkinson", "title": "An e-Infrastructure for Collaborative Research in Human Embryo\n  Development", "comments": "Summary of the EU-funded DGEMap project: 6 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Within the context of the EU Design Study Developmental Gene Expression Map,\nwe identify a set of challenges when facilitating collaborative research on\nearly human embryo development. These challenges bring forth requirements, for\nwhich we have identified solutions and technology. We summarise our solutions\nand demonstrate how they integrate to form an e-infrastructure to support\ncollaborative research in this area of developmental biology.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jan 2009 16:43:37 GMT"}], "update_date": "2009-01-16", "authors_parsed": [["Barker", "Adam", ""], ["van Hemert", "Jano I.", ""], ["Baldock", "Richard A.", ""], ["Atkinson", "Malcolm P.", ""]]}, {"id": "0901.2682", "submitter": "Danny Bickson", "authors": "Danny Bickson, Ezra N. Hoch, Harel Avissar and Danny Dolev", "title": "Self-stabilizing Numerical Iterative Computation", "comments": "Submitted to Theory of Computer Science (TCS) Journal", "journal-ref": null, "doi": null, "report-no": "TCS09", "categories": "cs.NA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many challenging tasks in sensor networks, including sensor calibration,\nranking of nodes, monitoring, event region detection, collaborative filtering,\ncollaborative signal processing, {\\em etc.}, can be formulated as a problem of\nsolving a linear system of equations. Several recent works propose different\ndistributed algorithms for solving these problems, usually by using linear\niterative numerical methods.\n  The main problem with previous approaches is that once the problem inputs\nchange during the process of computation, the computation may output unexpected\nresults. In real life settings, sensor measurements are subject to varying\nenvironmental conditions and to measurement noise.\n  We present a simple iterative scheme called SS-Iterative for solving systems\nof linear equations, and examine its properties in the self-stabilizing\nperspective. We analyze the behavior of the proposed scheme under changing\ninput sequences using two different assumptions on the input: a box bound, and\na probabilistic distribution.\n  As a case study, we discuss the sensor calibration problem and provide\nsimulation results to support the applicability of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jan 2009 06:56:59 GMT"}], "update_date": "2009-01-20", "authors_parsed": [["Bickson", "Danny", ""], ["Hoch", "Ezra N.", ""], ["Avissar", "Harel", ""], ["Dolev", "Danny", ""]]}, {"id": "0901.2684", "submitter": "Danny Bickson", "authors": "Danny Bickson, Yoav Tock, Argyris Zymnis, Stephen Boyd and Danny Dolev", "title": "Distributed Large Scale Network Utility Maximization", "comments": "In the International Symposium on Information Theory (ISIT) 2009", "journal-ref": null, "doi": "10.1109/ISIT.2009.5205655", "report-no": null, "categories": "cs.IT cs.DC math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent work by Zymnis et al. proposes an efficient primal-dual interior-point\nmethod, using a truncated Newton method, for solving the network utility\nmaximization (NUM) problem. This method has shown superior performance relative\nto the traditional dual-decomposition approach. Other recent work by Bickson et\nal. shows how to compute efficiently and distributively the Newton step, which\nis the main computational bottleneck of the Newton method, utilizing the\nGaussian belief propagation algorithm.\n  In the current work, we combine both approaches to create an efficient\ndistributed algorithm for solving the NUM problem. Unlike the work of Zymnis,\nwhich uses a centralized approach, our new algorithm is easily distributed.\nUsing an empirical evaluation we show that our new method outperforms previous\napproaches, including the truncated Newton method and dual-decomposition\nmethods. As an additional contribution, this is the first work that evaluates\nthe performance of the Gaussian belief propagation algorithm vs. the\npreconditioned conjugate gradient method, for a large scale problem.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jan 2009 07:02:55 GMT"}, {"version": "v2", "created": "Sat, 9 May 2009 07:07:09 GMT"}], "update_date": "2010-03-23", "authors_parsed": [["Bickson", "Danny", ""], ["Tock", "Yoav", ""], ["Zymnis", "Argyris", ""], ["Boyd", "Stephen", ""], ["Dolev", "Danny", ""]]}, {"id": "0901.2685", "submitter": "Danny Bickson", "authors": "Danny Bickson, Gidon Gershinsky, Ezra N. Hoch and Konstantin Shagin", "title": "A Statistical Approach to Performance Monitoring in Soft Real-Time\n  Distributed Systems", "comments": "Submitted to the 29th Int'l Conference on Distributed Computing\n  Systems (ICDCS 2009)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Soft real-time applications require timely delivery of messages conforming to\nthe soft real-time constraints. Satisfying such requirements is a complex task\nboth due to the volatile nature of distributed environments, as well as due to\nnumerous domain-specific factors that affect message latency. Prompt detection\nof the root-cause of excessive message delay allows a distributed system to\nreact accordingly. This may significantly improve compliance with the required\ntimeliness constraints.\n  In this work, we present a novel approach for distributed performance\nmonitoring of soft-real time distributed systems. We propose to employ recent\ndistributed algorithms from the statistical signal processing and learning\ndomains, and to utilize them in a different context of online performance\nmonitoring and root-cause analysis, for pinpointing the reasons for violation\nof performance requirements. Our approach is general and can be used for\nmonitoring of any distributed system, and is not limited to the soft real-time\ndomain.\n  We have implemented the proposed framework in TransFab, an IBM prototype of\nsoft real-time messaging fabric. In addition to root-cause analysis, the\nframework includes facilities to resolve resource allocation problems, such as\nmemory and bandwidth deficiency. The experiments demonstrate that the system\ncan identify and resolve latency problems in a timely fashion.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jan 2009 07:16:59 GMT"}], "update_date": "2009-01-20", "authors_parsed": [["Bickson", "Danny", ""], ["Gershinsky", "Gidon", ""], ["Hoch", "Ezra N.", ""], ["Shagin", "Konstantin", ""]]}, {"id": "0901.2687", "submitter": "Danny Bickson", "authors": "Danny Bickson, Ezra N. Hoch, Nir Naaman and Yoav Tock", "title": "A Hybrid Multicast-Unicast Infrastructure for Efficient\n  Publish-Subscribe in Enterprise Networks", "comments": null, "journal-ref": "SYSTOR 2010 - The 3rd Annual Haifa Experimental Systems\n  Conference, Haifa, Israel, May 24-26, 2010", "doi": "10.1145/1815695.1815722", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges in building a large scale publish-subscribe\ninfrastructure in an enterprise network, is to provide the subscribers with the\nrequired information, while minimizing the consumed host and network resources.\nTypically, previous approaches utilize either IP multicast or point-to-point\nunicast for efficient dissemination of the information.\n  In this work, we propose a novel hybrid framework, which is a combination of\nboth multicast and unicast data dissemination. Our hybrid framework allows us\nto take the advantages of both multicast and unicast, while avoiding their\ndrawbacks. We investigate several algorithms for computing the best mapping of\npublishers' transmissions into multicast and unicast transport.\n  Using extensive simulations, we show that our hybrid framework reduces\nconsumed host and network resources, outperforming traditional solutions. To\ninsure the subscribers interests closely resemble those of real-world settings,\nour simulations are based on stock market data and on recorded IBM WebShpere\nsubscriptions.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jan 2009 08:52:22 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2009 08:51:45 GMT"}, {"version": "v3", "created": "Mon, 12 Apr 2010 13:18:21 GMT"}], "update_date": "2010-06-30", "authors_parsed": [["Bickson", "Danny", ""], ["Hoch", "Ezra N.", ""], ["Naaman", "Nir", ""], ["Tock", "Yoav", ""]]}, {"id": "0901.2742", "submitter": "Fahad Saeed", "authors": "Fahad Saeed and Ashfaq Khokhar", "title": "Sample-Align-D: A High Performance Multiple Sequence Alignment System\n  using Phylogenetic Sampling and Domain Decomposition", "comments": "12 pages, 8 figures, paper appeared in HICOMB, IPDPS 2008", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple Sequence Alignment (MSA) is one of the most computationally\nintensive tasks in Computational Biology. Existing best known solutions for\nmultiple sequence alignment take several hours (in some cases days) of\ncomputation time to align, for example, 2000 homologous sequences of average\nlength 300. Inspired by the Sample Sort approach in parallel processing, in\nthis paper we propose a highly scalable multiprocessor solution for the MSA\nproblem in phylogenetically diverse sequences. Our method employs an\nintelligent scheme to partition the set of sequences into smaller subsets using\nkmer count based similarity index, referred to as k-mer rank. Each subset is\nthen independently aligned in parallel using any sequential approach. Further\nfine tuning of the local alignments is achieved using constraints derived from\na global ancestor of the entire set. The proposed Sample-Align-D Algorithm has\nbeen implemented on a cluster of workstations using MPI message passing\nlibrary. The accuracy of the proposed solution has been tested on standard\nbenchmarks such as PREFAB. The accuracy of the alignment produced by our\nmethods is comparable to that of well known sequential MSA techniques. We were\nable to align 2000 randomly selected sequences from the Methanosarcina\nacetivorans genome in less than 10 minutes using Sample-Align-D on a 16 node\ncluster, compared to over 23 hours on sequential MUSCLE system running on a\nsingle cluster node.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jan 2009 22:31:26 GMT"}], "update_date": "2009-01-20", "authors_parsed": [["Saeed", "Fahad", ""], ["Khokhar", "Ashfaq", ""]]}, {"id": "0901.2751", "submitter": "Fahad Saeed", "authors": "Fahad Saeed", "title": "Pyro-Align: Sample-Align based Multiple Alignment system for\n  Pyrosequencing Reads of Large Number", "comments": "6 pages, 1 figure, Technical Report, Department of Biosystems Science\n  and Engineering, ETH Zurich Switzerland", "journal-ref": null, "doi": null, "report-no": "DBSSE-08-2008", "categories": "cs.DS cs.DC q-bio.GN q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pyro-Align is a multiple alignment program specifically designed for\npyrosequencing reads of huge number. Multiple sequence alignment is shown to be\nNP-hard and heuristics are designed for approximate solutions. Multiple\nsequence alignment of pyrosequenceing reads is complex mainly because of 2\nfactors. One being the huge number of reads, making the use of traditional\nheuristics,that scale very poorly for large number, unsuitable. The second\nreason is that the alignment cannot be performed arbitrarily, because the\nposition of the reads with respect to the original genome is important and has\nto be taken into account.In this report we present a short description of the\nmultiple alignment system for pyrosequencing reads.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jan 2009 00:26:18 GMT"}], "update_date": "2009-01-20", "authors_parsed": [["Saeed", "Fahad", ""]]}, {"id": "0901.3384", "submitter": "Marko A. Rodriguez", "authors": "Michael I. Ham and Marko A. Rodriguez", "title": "A Boundary Approximation Algorithm for Distributed Sensor Networks", "comments": null, "journal-ref": "International Journal of Sensor Networks, 8(1), pp. 41-46,\n  ISSN:1748-1279, 2010", "doi": null, "report-no": "LA-UR-09-00111", "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We present an algorithm for boundary approximation in locally-linked sensor\nnetworks that communicate with a remote monitoring station. Delaunay\ntriangulations and Voronoi diagrams are used to generate a sensor communication\nnetwork and define boundary segments between sensors, respectively. The\nproposed algorithm reduces remote station communication by approximating\nboundaries via a decentralized computation executed within the sensor network.\nMoreover, the algorithm identifies boundaries based on differences between\nneighboring sensor readings, and not absolute sensor values. An analysis of the\nbandwidth consumption of the algorithm is presented and compared to two naive\napproaches. The proposed algorithm reduces the amount of remote communication\n(compared to the naive approaches) and becomes increasingly useful in networks\nwith more nodes.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jan 2009 00:59:01 GMT"}], "update_date": "2010-06-22", "authors_parsed": [["Ham", "Michael I.", ""], ["Rodriguez", "Marko A.", ""]]}, {"id": "0901.4762", "submitter": "Adam Barker", "authors": "Adam Barker", "title": "Optimizing Service Orchestrations", "comments": "12 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the number of services and the size of data involved in workflows\nincreases, centralised orchestration techniques are reaching the limits of\nscalability. In the classic orchestration model, all data passes through a\ncentralised engine, which results in unnecessary data transfer, wasted\nbandwidth and the engine to become a bottleneck to the execution of a workflow.\n  This paper presents and evaluates the Circulate architecture which maintains\nthe robustness and simplicity of centralised orchestration, but facilitates\nchoreography by allowing services to exchange data directly with one another.\nCirculate could be realised within any existing workflow framework, in this\npaper, we focus on WS-Circulate, a Web services based implementation.\n  Taking inspiration from the Montage workflow, a number of common workflow\npatterns (sequence, fan-in and fan-out), input to output data size\nrelationships and network configurations are identified and evaluated. The\nperformance analysis concludes that a substantial reduction in communication\noverhead results in a 2-4 fold performance benefit across all patterns. An\nend-to-end pattern through the Montage workflow results in an 8 fold\nperformance benefit and demonstrates how the advantage of using the Circulate\narchitecture increases as the complexity of a workflow grows.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jan 2009 20:30:35 GMT"}], "update_date": "2009-09-30", "authors_parsed": [["Barker", "Adam", ""]]}, {"id": "0901.4835", "submitter": "Yoo Chung", "authors": "Yoo Chung, Dongman Lee", "title": "A Mathematical Basis for the Chaining of Lossy Interface Adapters", "comments": "22 pages, 6 figures", "journal-ref": "IET Software, 4(1):54-54, February 2010", "doi": "10.1049/iet-sen.2009.0019", "report-no": null, "categories": "cs.DM cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Despite providing similar functionality, multiple network services may\nrequire the use of different interfaces to access the functionality, and this\nproblem will only get worse with the widespread deployment of ubiquitous\ncomputing environments. One way around this problem is to use interface\nadapters that adapt one interface into another. Chaining these adapters allows\nflexible interface adaptation with fewer adapters, but the loss incurred due to\nimperfect interface adaptation must be considered. This paper outlines a\nmathematical basis for analyzing the chaining of lossy interface adapters. We\nalso show that the problem of finding an optimal interface adapter chain is\nNP-complete.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2009 08:17:43 GMT"}, {"version": "v2", "created": "Thu, 5 Feb 2009 14:46:00 GMT"}, {"version": "v3", "created": "Tue, 21 Jul 2009 03:23:34 GMT"}, {"version": "v4", "created": "Wed, 10 Feb 2010 01:24:15 GMT"}], "update_date": "2010-02-10", "authors_parsed": [["Chung", "Yoo", ""], ["Lee", "Dongman", ""]]}, {"id": "0901.4934", "submitter": "Carl Hewitt", "authors": "Carl Hewitt", "title": "A historical perspective on developing foundations iInfo(TM) information\n  systems: iConsult(TM) and iEntertain(TM) apps using iDescribers(TM)\n  information integration for iOrgs(TM) information systems", "comments": "updated title and abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Technology now at hand can integrate all kinds of digital information for\nindividuals, groups, and organizations so their information usefully links\ntogether. iInfo(TM) information integration works by making connections\nincluding examples like the following:\n  - A statistical connection between \"being in a traffic jam\" and \"driving in\ndowntown Trenton between 5PM and 6PM on a weekday.\"\n  - A terminological connection between \"MSR\" and \"Microsoft Research.\"\n  - A causal connection between \"joining a group\" and \"being a member of the\ngroup.\"\n  - A syntactic connection between \"a pin dropped\" and \"a dropped pin.\"\n  - A biological connection between \"a dolphin\" and \"a mammal\".\n  - A demographic connection between \"undocumented residents of California\" and\n\"7% of the population of California.\"\n  - A geographical connection between \"Leeds\" and \"England.\"\n  - A temporal connection between \"turning on a computer\" and \"joining an\non-line discussion.\"\n  By making these connections, iInfo offers tremendous value for individuals,\nfamilies, groups, and organizations in making more effective use of information\ntechnology.\n  In practice, integrated information is invariably pervasively inconsistent.\nTherefore iInfo must be able to make connections even in the face of\ninconsistency. The business of iInfo is not to make difficult decisions like\ndeciding the ultimate truth or probability of propositions. Instead it provides\nmeans for processing information and carefully recording its provenance\nincluding arguments (including arguments about arguments) for and against\npropositions that is used by iConsult(TM) and iEntertain(TM) apps in iOrgs(TM)\nInformation Systems.\n  A historical perspective on the above questions is highly pertinent to the\ncurrent quest to develop foundations for privacy-friendly client-cloud\ncomputing.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jan 2009 17:33:14 GMT"}, {"version": "v10", "created": "Tue, 17 Nov 2009 12:54:00 GMT"}, {"version": "v11", "created": "Tue, 24 Nov 2009 15:36:18 GMT"}, {"version": "v12", "created": "Tue, 29 Dec 2009 22:54:57 GMT"}, {"version": "v13", "created": "Thu, 7 Jan 2010 20:11:54 GMT"}, {"version": "v14", "created": "Tue, 12 Jan 2010 19:19:22 GMT"}, {"version": "v15", "created": "Thu, 21 Jan 2010 21:50:00 GMT"}, {"version": "v16", "created": "Thu, 8 Apr 2010 21:48:15 GMT"}, {"version": "v17", "created": "Mon, 19 Apr 2010 04:13:36 GMT"}, {"version": "v18", "created": "Tue, 20 Apr 2010 12:27:24 GMT"}, {"version": "v19", "created": "Mon, 26 Apr 2010 15:18:50 GMT"}, {"version": "v2", "created": "Tue, 24 Feb 2009 01:37:44 GMT"}, {"version": "v20", "created": "Mon, 4 Oct 2010 21:16:49 GMT"}, {"version": "v3", "created": "Tue, 14 Apr 2009 11:54:47 GMT"}, {"version": "v4", "created": "Mon, 1 Jun 2009 23:05:51 GMT"}, {"version": "v5", "created": "Mon, 20 Jul 2009 00:53:03 GMT"}, {"version": "v6", "created": "Sun, 2 Aug 2009 21:06:55 GMT"}, {"version": "v7", "created": "Tue, 29 Sep 2009 18:19:02 GMT"}, {"version": "v8", "created": "Fri, 2 Oct 2009 14:42:21 GMT"}, {"version": "v9", "created": "Thu, 29 Oct 2009 21:14:14 GMT"}], "update_date": "2010-10-06", "authors_parsed": [["Hewitt", "Carl", ""]]}]