[{"id": "1205.0106", "submitter": "Toni Stojanovski", "authors": "Verche Cvetanoska, Toni Stojanovski", "title": "Using high performance computing and Monte Carlo simulation for pricing\n  american options", "comments": "CIIT Conference, April 2012, Bitola Macedonia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC q-fin.CP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High performance computing (HPC) is a very attractive and relatively new area\nof research, which gives promising results in many applications. In this paper\nHPC is used for pricing of American options. Although the American options are\nvery significant in computational finance; their valuation is very challenging,\nespecially when the Monte Carlo simulation techniques are used. For getting the\nmost accurate price for these types of options we use Quasi Monte Carlo\nsimulation, which gives the best convergence. Furthermore, this algorithm is\nimplemented on both GPU and CPU. Additionally, the CUDA architecture is used\nfor harnessing the power and the capability of the GPU for executing the\nalgorithm in parallel which is later compared with the serial implementation on\nthe CPU. In conclusion this paper gives the reasons and the advantages of\napplying HPC in computational finance.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2012 07:46:11 GMT"}], "update_date": "2012-05-02", "authors_parsed": [["Cvetanoska", "Verche", ""], ["Stojanovski", "Toni", ""]]}, {"id": "1205.0282", "submitter": "Amr Hassan", "authors": "A.H. Hassan, C.J. Fluke, and D.G. Barnes", "title": "A Distributed GPU-based Framework for real-time 3D Volume Rendering of\n  Large Astronomical Data Cubes", "comments": "13 Pages, 7 figures, has been accepted for publication in\n  Publications of the Astronomical Society of Australia", "journal-ref": null, "doi": "10.1071/AS12025", "report-no": null, "categories": "astro-ph.IM cs.DC cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a framework to interactively volume-render three-dimensional data\ncubes using distributed ray-casting and volume bricking over a cluster of\nworkstations powered by one or more graphics processing units (GPUs) and a\nmulti-core CPU. The main design target for this framework is to provide an\nin-core visualization solution able to provide three-dimensional interactive\nviews of terabyte-sized data cubes. We tested the presented framework using a\ncomputing cluster comprising 64 nodes with a total of 128 GPUs. The framework\nproved to be scalable to render a 204 GB data cube with an average of 30 frames\nper second. Our performance analyses also compare between using NVIDIA Tesla\n1060 and 2050 GPU architectures and the effect of increasing the visualization\noutput resolution on the rendering performance. Although our initial focus, and\nthe examples presented in this work, is volume rendering of spectral data cubes\nfrom radio astronomy, we contend that our approach has applicability to other\ndisciplines where close to real-time volume rendering of terabyte-order 3D data\nsets is a requirement.\n", "versions": [{"version": "v1", "created": "Tue, 1 May 2012 23:17:42 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Hassan", "A. H.", ""], ["Fluke", "C. J.", ""], ["Barnes", "D. G.", ""]]}, {"id": "1205.0439", "submitter": "Aridj Mohamed", "authors": "Aridj Mohamed, Zegour Djamel Eddine", "title": "TH*:Scalable Distributed Trie Hashing", "comments": "IJCSI International Journal of Computer Science Issues, Vol. 7, Issue\n  6, November 2010 ISSN (Online): 1694-0814 http://www.IJCSI.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In today's world of computers, dealing with huge amounts of data is not\nunusual. The need to distribute this data in order to increase its availability\nand increase the performance of accessing it is more urgent than ever. For\nthese reasons it is necessary to develop scalable distributed data structures.\nIn this paper we propose a TH* distributed variant of the Trie Hashing data\nstructure. First we propose Thsw new version of TH without node Nil in digital\ntree (trie), then this version will be adapted to multicomputer environment.\nThe simulation results reveal that TH* is scalable in the sense that it grows\ngracefully, one bucket at a time, to a large number of servers, also TH* offers\na good storage space utilization and high query efficiency special for ordering\noperations.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2012 14:17:16 GMT"}], "update_date": "2012-05-03", "authors_parsed": [["Mohamed", "Aridj", ""], ["Eddine", "Zegour Djamel", ""]]}, {"id": "1205.0451", "submitter": "Saeid Abolfazli", "authors": "Saeid Abolfazli, Zohreh Sanaei, Abdullah Gani", "title": "Mobile Cloud Computing: A Review on Smartphone Augmentation Approaches", "comments": null, "journal-ref": "Saeid Abolfazli, Zohreh Sanaei, Abdullah Gani, Mobile Cloud\n  Computing: A Review on Smartphone Augmentation Approaches, 1st International\n  Conference on Computing, Information Systems, and Communications(CISCO'12),\n  May 2012, Singapore", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Smartphones have recently gained significant popularity in heavy mobile\nprocessing while users are increasing their expectations toward rich computing\nexperience. However, resource limitations and current mobile computing\nadvancements hinder this vision. Therefore, resource-intensive application\nexecution remains a challenging task in mobile computing that necessitates\ndevice augmentation. In this article, smartphone augmentation approaches are\nreviewed and classified in two main groups, namely hardware and software.\nGenerating high-end hardware is a subset of hardware augmentation approaches,\nwhereas conserving local resource and reducing resource requirements approaches\nare grouped under software augmentation methods. Our study advocates that\nconsreving smartphones' native resources, which is mainly done via task\noffloading, is more appropriate for already-developed applications than new\nones, due to costly re-development process. Cloud computing has recently\nobtained momentous ground as one of the major cornerstone technologies in\naugmenting smartphones. We present sample execution model for intensive mobile\napplications and devised taxonomy of augmentation approaches. For better\ncomprehension, the results of this study are summarized in a table.\n", "versions": [{"version": "v1", "created": "Wed, 2 May 2012 15:04:04 GMT"}, {"version": "v2", "created": "Tue, 15 May 2012 03:21:28 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Abolfazli", "Saeid", ""], ["Sanaei", "Zohreh", ""], ["Gani", "Abdullah", ""]]}, {"id": "1205.0652", "submitter": "Peiyan Yuan", "authors": "Peiyan Yuan, Huadong Ma, Shaojie Tang", "title": "On Exploiting Hotspot and Entropy for Data Forwarding in Delay Tolerant\n  Networks", "comments": "This paper has been withdrawn by the author due to further studies", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance of data forwarding in Delay Tolerant Networks (DTNs) benefits\nconsiderably if one can make use of human mobility in terms of social\nstructures. However, it is difficult and time-consuming to calculate the\ncentrality and similarity of nodes by using solutions for traditional social\nnetworks, this is mainly because of the transient node contact and the\nintermittently connected environment. In this work, we are interested in the\nfollowing question: Can we explore some other stable social attributes to\nquantify the centrality and similarity of nodes? Taking GPS traces of human\nwalks from the real world, we find that there exist two known phenomena. One is\npublic hotspot, the other is personal hotspot. Motivated by this observation,\nwe present Hoten (hotspot and entropy), a novel routing metric to improve\nrouting performance in DTNs. First, we use the relative entropy between the\npublic hotspots and the personal hotspots to compute the centrality of nodes.\nThen we utilize the inverse symmetrized entropy of the personal hotspots\nbetween two nodes to compute the similarity between them. Third, we exploit the\nentropy of personal hotspots of a node to estimate its personality. Besides, we\npropose a method to ascertain the optimized size of hotspot. Finally, we\ncompare our routing strategy with other state-of-the-art routing schemes\nthrough extensive trace-driven simulations, the results show that Hoten largely\noutperforms other solutions, especially in terms of combined overhead/packet\ndelivery ratio and the average number of hops per message.\n", "versions": [{"version": "v1", "created": "Thu, 3 May 2012 09:02:44 GMT"}, {"version": "v2", "created": "Fri, 27 Jun 2014 09:01:19 GMT"}], "update_date": "2014-06-30", "authors_parsed": [["Yuan", "Peiyan", ""], ["Ma", "Huadong", ""], ["Tang", "Shaojie", ""]]}, {"id": "1205.0960", "submitter": "Peter Pollner", "authors": "Peter Pollner, Gergely Palla, Tamas Vicsek", "title": "Parallel clustering with CFinder", "comments": "Electronic version of an article published as\n  http://www.worldscinet.com/ppl/22/2201/S0129626412400014.html copyright World\n  Scientific Publishing Company", "journal-ref": "Parallel Processing Letters 22:(1) p. 1240001. (2012)", "doi": "10.1142/S0129626412400014", "report-no": null, "categories": "physics.soc-ph cs.DC cs.DS cs.SI physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The amount of available data about complex systems is increasing every year,\nmeasurements of larger and larger systems are collected and recorded. A natural\nrepresentation of such data is given by networks, whose size is following the\nsize of the original system. The current trend of multiple cores in computing\ninfrastructures call for a parallel reimplementation of earlier methods. Here\nwe present the grid version of CFinder, which can locate overlapping\ncommunities in directed, weighted or undirected networks based on the clique\npercolation method (CPM). We show that the computation of the communities can\nbe distributed among several CPU-s or computers. Although switching to the\nparallel version not necessarily leads to gain in computing time, it definitely\nmakes the community structure of extremely large networks accessible.\n", "versions": [{"version": "v1", "created": "Fri, 4 May 2012 14:09:23 GMT"}], "update_date": "2012-05-07", "authors_parsed": [["Pollner", "Peter", ""], ["Palla", "Gergely", ""], ["Vicsek", "Tamas", ""]]}, {"id": "1205.1171", "submitter": "Kevin Wortman", "authors": "Jeffrey M. White and Kevin A. Wortman", "title": "Divide-and-Conquer 3D Convex Hulls on the GPU", "comments": "11 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CG", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We describe a pure divide-and-conquer parallel algorithm for computing 3D\nconvex hulls. We implement that algorithm on GPU hardware, and find a\nsignificant speedup over comparable CPU implementations.\n", "versions": [{"version": "v1", "created": "Sun, 6 May 2012 01:33:15 GMT"}], "update_date": "2012-05-08", "authors_parsed": [["White", "Jeffrey M.", ""], ["Wortman", "Kevin A.", ""]]}, {"id": "1205.1457", "submitter": "Fergal Reid", "authors": "Kiril Dichev, Fergal Reid, Alexey Lastovetsky", "title": "Efficient and reliable network tomography in heterogeneous networks\n  using BitTorrent broadcasts and clustering algorithms", "comments": "11pages, 13figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the area of network performance and discovery, network tomography focuses\non reconstructing network properties using only end-to-end measurements at the\napplication layer. One challenging problem in network tomography is\nreconstructing available bandwidth along all links during multiple\nsource/multiple destination transmissions. The traditional measurement\nprocedures used for bandwidth tomography are extremely time consuming. We\npropose a novel solution to this problem. Our method counts the fragments\nexchanged during a BitTorrent broadcast. While this measurement has a high\nlevel of randomness, it can be obtained very efficiently, and aggregated into a\nreliable metric. This data is then analyzed with state-of-the-art algorithms,\nwhich reliably reconstruct logical clusters of nodes inter-connected by high\nbandwidth, as well as bottlenecks between these logical clusters. Our\nexperiments demonstrate that the proposed two-phase approach efficiently solves\nthe presented problem for a number of settings on a complex grid\ninfrastructure.\n", "versions": [{"version": "v1", "created": "Mon, 7 May 2012 16:45:21 GMT"}], "update_date": "2012-05-08", "authors_parsed": [["Dichev", "Kiril", ""], ["Reid", "Fergal", ""], ["Lastovetsky", "Alexey", ""]]}, {"id": "1205.1579", "submitter": "Michael Goodrich", "authors": "Michael T. Goodrich, Michael Mitzenmacher", "title": "Anonymous Card Shuffling and its Applications to Parallel Mixnets", "comments": "Full version of a paper appearing in ICALP 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the question of how to shuffle $n$ cards when faced with an opponent\nwho knows the initial position of all the cards {\\em and} can track every card\nwhen permuted, {\\em except} when one takes $K< n$ cards at a time and shuffles\nthem in a private buffer \"behind your back,\" which we call {\\em buffer\nshuffling}. The problem arises naturally in the context of parallel mixnet\nservers as well as other security applications. Our analysis is based on\nrelated analyses of load-balancing processes. We include extensions to\nvariations that involve corrupted servers and adversarially injected messages,\nwhich correspond to an opponent who can peek at some shuffles in the buffer and\nwho can mark some number of the cards. In addition, our analysis makes novel\nuse of a sum-of-squares metric for anonymity, which leads to improved\nperformance bounds for parallel mixnets and can also be used to bound\nwell-known existing anonymity measures.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 02:35:53 GMT"}, {"version": "v2", "created": "Thu, 28 Jun 2012 17:25:22 GMT"}], "update_date": "2012-06-29", "authors_parsed": [["Goodrich", "Michael T.", ""], ["Mitzenmacher", "Michael", ""]]}, {"id": "1205.1622", "submitter": "Sinung Suakanto Mr", "authors": "Sinung Suakanto, Suhono H Supangkat, Suhardi, Roberd Saragih", "title": "Performance Measurement of Cloud Computing Services", "comments": "It was published at International Journal on Cloud Computing:\n  Services and Architecture (IJCCSA), April 2012, Volume 2, Number 2\n  http://airccse.org/journal/ijccsa/current2012.html\n  http://airccse.org/journal/ijccsa/papers/2212ijccsa02.pdf", "journal-ref": "http://airccse.org/journal/ijccsa/current2012.html\n  http://airccse.org/journal/ijccsa/papers/2212ijccsa02.pdf", "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing today has now been growing as new technologies and new\nbusiness models. In distributed technology perspective, cloud computing most\nlike client-server services like web-based or web-service but it used virtual\nresources to execute. Currently, cloud computing relies on the use of an\nelastic virtual machine and the use of network for data exchange. We conduct an\nexperimental setup to measure the quality of service received by cloud\ncomputing customers. Experimental setup done by creating a HTTP service that\nruns in the cloud computing infrastructure. We interest to know about the\nimpact of increasing the number of users on the average quality received by\nusers. The qualities received by user measured within two parameters consist of\naverage response times and the number of requests time out. Experimental\nresults of this study show that increasing the number of users has increased\nthe average response time. Similarly, the number of request time out increasing\nwith increasing number of users. It means that the qualities of service\nreceived by user are decreasing also. We found that the impact of the number of\nusers on the quality of service is no longer in linear trend. The results of\nthis study can be used as a reference model for the network operator in\nperforming services in which a certain number of users in order to obtain\noptimal quality services.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 08:05:34 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["Suakanto", "Sinung", ""], ["Supangkat", "Suhono H", ""], ["Suhardi", "", ""], ["Saragih", "Roberd", ""]]}, {"id": "1205.1668", "submitter": "Ramesh K", "authors": "K.Ramesh and Dr. K.Somasundaram", "title": "Improved Fair-Zone technique using Mobility Prediction in WSN", "comments": "10 pages, 7 figures, Published in International Journal Of Advanced\n  Smart Sensor Network Systems (IJASSN)", "journal-ref": "International Journal Of Advanced Smart Sensor Network Systems (\n  IJASSN ), Vol 2, No.2, April 2012", "doi": "10.5121/ijassn.2012.2203", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The self-organizational ability of ad-hoc Wireless Sensor Networks (WSNs) has\nled them to be the most popular choice in ubiquitous computing. Clustering\nsensor nodes organizing them hierarchically have proven to be an effective\nmethod to provide better data aggregation and scalability for the sensor\nnetwork while conserving limited energy. It has some limitation in energy and\nmobility of nodes. In this paper we propose a mobility prediction technique\nwhich tries overcoming above mentioned problems and improves the life time of\nthe network. The technique used here is Exponential Moving Average for online\nupdates of nodal contact probability in cluster based network.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 12:18:33 GMT"}], "update_date": "2012-05-09", "authors_parsed": [["Ramesh", "K.", ""], ["Somasundaram", "Dr. K.", ""]]}, {"id": "1205.1733", "submitter": "Guodong Shi", "authors": "Guodong Shi and Karl Henrik Johansson", "title": "Finite-time and Asymptotic Convergence of Distributed Averaging and\n  Maximizing Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we formulate and investigate a generalized consensus algorithm\nwhich makes an attempt to unify distributed averaging and maximizing algorithms\nconsidered in the literature. Each node iteratively updates its state as a\ntime-varying weighted average of its own state, the minimal state, and the\nmaximal state of its neighbors. We prove that finite-time consensus is almost\nimpossible for averaging under this uniform model. Both time-dependent and\nstate-dependent graphs are considered, and various necessary and/or sufficient\nconditions are presented on the consensus convergence. For time-dependent\ngraphs, we show that quasi-strong connectivity is critical for averaging, as is\nstrong connectivity for maximizing. For state-dependent graphs defined by a\n$\\mu$-nearest-neighbor rule, where each node interacts with its $\\mu$ nearest\nsmaller neighbors and the $\\mu$ nearest larger neighbors, we show that $\\mu+1$\nis a critical threshold on the total number of nodes for the transit from\nfinite-time to asymptotic convergence for averaging, in the absence of node\nself-confidence. The threshold is $2\\mu$ if each node chooses to connect only\nto neighbors with unique values. Numerical examples illustrate the tightness of\nthe conditions. The results characterize some fundamental similarities and\ndifferences between distributed averaging and maximizing algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 8 May 2012 15:59:06 GMT"}, {"version": "v2", "created": "Wed, 5 Sep 2012 14:31:10 GMT"}], "update_date": "2012-09-06", "authors_parsed": [["Shi", "Guodong", ""], ["Johansson", "Karl Henrik", ""]]}, {"id": "1205.1924", "submitter": "Venkatesan Chakaravarthy", "authors": "Venkatesan T. Chakaravarthy, Sambuddha Roy, Yogish Sabharwal", "title": "Distributed Algorithms for Scheduling on Line and Tree Networks", "comments": "Accepted to PODC 2012, full version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have a set of processors (or agents) and a set of graph networks defined\nover some vertex set. Each processor can access a subset of the graph networks.\nEach processor has a demand specified as a pair of vertices $<u, v>$, along\nwith a profit; the processor wishes to send data between $u$ and $v$. Towards\nthat goal, the processor needs to select a graph network accessible to it and a\npath connecting $u$ and $v$ within the selected network. The processor requires\nexclusive access to the chosen path, in order to route the data. Thus, the\nprocessors are competing for routes/channels. A feasible solution selects a\nsubset of demands and schedules each selected demand on a graph network\naccessible to the processor owning the demand; the solution also specifies the\npaths to use for this purpose. The requirement is that for any two demands\nscheduled on the same graph network, their chosen paths must be edge disjoint.\nThe goal is to output a solution having the maximum aggregate profit. Prior\nwork has addressed the above problem in a distibuted setting for the special\ncase where all the graph networks are simply paths (i.e, line-networks).\nDistributed constant factor approximation algorithms are known for this case.\n  The main contributions of this paper are twofold. First we design a\ndistributed constant factor approximation algorithm for the more general case\nof tree-networks. The core component of our algorithm is a tree-decomposition\ntechnique, which may be of independent interest. Secondly, for the case of\nline-networks, we improve the known approximation guarantees by a factor of 5.\nOur algorithms can also handle the capacitated scenario, wherein the demands\nand edges have bandwidth requirements and capacities, respectively.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 09:42:40 GMT"}, {"version": "v2", "created": "Fri, 5 Oct 2012 11:44:14 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Chakaravarthy", "Venkatesan T.", ""], ["Roy", "Sambuddha", ""], ["Sabharwal", "Yogish", ""]]}, {"id": "1205.1975", "submitter": "Arnaud Casteigts", "authors": "Arnaud Casteigts, Paola Flocchini, Emmanuel Godard, Nicola Santoro,\n  Masafumi Yamashita", "title": "Expressivity of Time-Varying Graphs and the Power of Waiting in Dynamic\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In infrastructure-less highly dynamic networks, computing and performing even\nbasic tasks (such as routing and broadcasting) is a very challenging activity\ndue to the fact that connectivity does not necessarily hold, and the network\nmay actually be disconnected at every time instant. Clearly the task of\ndesigning protocols for these networks is less difficult if the environment\nallows waiting (i.e., it provides the nodes with store-carry-forward-like\nmechanisms such as local buffering) than if waiting is not feasible. No\nquantitative corroborations of this fact exist (e.g., no answer to the\nquestion: how much easier?). In this paper, we consider these qualitative\nquestions about dynamic networks, modeled as time-varying (or evolving) graphs,\nwhere edges exist only at some times.\n  We examine the difficulty of the environment in terms of the expressivity of\nthe corresponding time-varying graph; that is in terms of the language\ngenerated by the feasible journeys in the graph. We prove that the set of\nlanguages $L_{nowait}$ when no waiting is allowed contains all computable\nlanguages. On the other end, using algebraic properties of quasi-orders, we\nprove that $L_{wait}$ is just the family of regular languages. In other words,\nwe prove that, when waiting is no longer forbidden, the power of the accepting\nautomaton (difficulty of the environment) drops drastically from being as\npowerful as a Turing machine, to becoming that of a Finite-State machine. This\n(perhaps surprisingly large) gap is a measure of the computational power of\nwaiting.\n  We also study bounded waiting; that is when waiting is allowed at a node only\nfor at most $d$ time units. We prove the negative result that $L_{wait[d]} =\nL_{nowait}$; that is, the expressivity decreases only if the waiting is finite\nbut unpredictable (i.e., under the control of the protocol designer and not of\nthe environment).\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 13:19:46 GMT"}], "update_date": "2012-05-10", "authors_parsed": [["Casteigts", "Arnaud", ""], ["Flocchini", "Paola", ""], ["Godard", "Emmanuel", ""], ["Santoro", "Nicola", ""], ["Yamashita", "Masafumi", ""]]}, {"id": "1205.2005", "submitter": "Mich\\`ele Weiland", "authors": "Michele Weiland, Lawrence Mitchell, Gerard Gorman, Stephan Kramer,\n  Mark Parsons and James Southern", "title": "Mixed-mode implementation of PETSc for scalable linear algebra on\n  multi-core processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With multi-core processors a ubiquitous building block of modern\nsupercomputers, it is now past time to enable applications to embrace these\ndevelopments in processor design. To achieve exascale performance, applications\nwill need ways of exploiting the new levels of parallelism that are exposed in\nmodern high-performance computers. A typical approach to this is to use\nshared-memory programming techniques to best exploit multi-core nodes along\nwith inter-node message passing. In this paper, we describe the addition of\nOpenMP threaded functionality to the PETSc library. We highlight some issues\nthat hinder good performance of threaded applications on modern processors and\ndescribe how to negate them. The OpenMP branch of PETSc was benchmarked using\nmatrices extracted from Fluidity, a CFD application code, which uses the\nlibrary as its linear solver engine. The overall performance of the mixed-mode\nimplementation is shown to be superior to that of the pure-MPI version.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 14:54:55 GMT"}, {"version": "v2", "created": "Fri, 10 Aug 2012 12:31:24 GMT"}], "update_date": "2012-08-13", "authors_parsed": [["Weiland", "Michele", ""], ["Mitchell", "Lawrence", ""], ["Gorman", "Gerard", ""], ["Kramer", "Stephan", ""], ["Parsons", "Mark", ""], ["Southern", "James", ""]]}, {"id": "1205.2051", "submitter": "Jukka Suomela", "authors": "Lauri Hella, Matti J\\\"arvisalo, Antti Kuusisto, Juhana Laurinharju,\n  Tuomo Lempi\\\"ainen, Kerkko Luosto, Jukka Suomela, Jonni Virtema", "title": "Weak Models of Distributed Computing, with Connections to Modal Logic", "comments": "1 + 40 pages, 9 figures", "journal-ref": null, "doi": "10.1007/s00446-013-0202-3", "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents a classification of weak models of distributed computing.\nWe focus on deterministic distributed algorithms, and study models of computing\nthat are weaker versions of the widely-studied port-numbering model. In the\nport-numbering model, a node of degree d receives messages through d input\nports and sends messages through d output ports, both numbered with 1,2,...,d.\nIn this work, VVc is the class of all graph problems that can be solved in the\nstandard port-numbering model. We study the following subclasses of VVc:\n  VV: Input port i and output port i are not necessarily connected to the same\nneighbour.\n  MV: Input ports are not numbered; algorithms receive a multiset of messages.\n  SV: Input ports are not numbered; algorithms receive a set of messages.\n  VB: Output ports are not numbered; algorithms send the same message to all\noutput ports.\n  MB: Combination of MV and VB.\n  SB: Combination of SV and VB.\n  Now we have many trivial containment relations, such as SB \\subseteq MB\n\\subseteq VB \\subseteq VV \\subseteq VVc, but it is not obvious if, for example,\neither of VB \\subseteq SV or SV \\subseteq VB should hold. Nevertheless, it\nturns out that we can identify a linear order on these classes. We prove that\nSB \\subsetneq MB = VB \\subsetneq SV = MV = VV \\subsetneq VVc. The same holds\nfor the constant-time versions of these classes.\n  We also show that the constant-time variants of these classes can be\ncharacterised by a corresponding modal logic. Hence the linear order identified\nin this work has direct implications in the study of the expressibility of\nmodal logic. Conversely, one can use tools from modal logic to study these\nclasses.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 18:07:23 GMT"}, {"version": "v2", "created": "Thu, 25 Oct 2012 10:59:19 GMT"}, {"version": "v3", "created": "Sat, 21 Dec 2013 12:47:00 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["Hella", "Lauri", ""], ["J\u00e4rvisalo", "Matti", ""], ["Kuusisto", "Antti", ""], ["Laurinharju", "Juhana", ""], ["Lempi\u00e4inen", "Tuomo", ""], ["Luosto", "Kerkko", ""], ["Suomela", "Jukka", ""], ["Virtema", "Jonni", ""]]}, {"id": "1205.2170", "submitter": "Amos Korman", "authors": "Ofer Feinerman, Amos Korman (LIAFA, GANG), Zvi Lotker (UPD7),\n  Jean-S\\'ebastien Sereni (MASCOTTE)", "title": "Collaborative search on the plane without communication", "comments": null, "journal-ref": "ACM Symposium on Principles of Distributed Computing, PODC 2012,\n  Jul 2012, Madeira, Portugal. 2012", "doi": "10.1145/2332432.2332444", "report-no": null, "categories": "cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the classical cow-path problem [7, 14, 38, 39] into a question\nthat is relevant for collective foraging in animal groups. Specifically, we\nconsider a setting in which k identical (probabilistic) agents, initially\nplaced at some central location, collectively search for a treasure in the\ntwo-dimensional plane. The treasure is placed at a target location by an\nadversary and the goal is to find it as fast as possible as a function of both\nk and D, where D is the distance between the central location and the target.\nThis is biologically motivated by cooperative, central place foraging such as\nperformed by ants around their nest. In this type of search there is a strong\npreference to locate nearby food sources before those that are further away.\nOur focus is on trying to find what can be achieved if communication is limited\nor altogether absent. Indeed, to avoid overlaps agents must be highly dispersed\nmaking communication difficult. Furthermore, if agents do not commence the\nsearch in synchrony then even initial communication is problematic. This holds,\nin particular, with respect to the question of whether the agents can\ncommunicate and conclude their total number, k. It turns out that the knowledge\nof k by the individual agents is crucial for performance. Indeed, it is a\nstraightforward observation that the time required for finding the treasure is\n$\\Omega$(D + D 2 /k), and we show in this paper that this bound can be matched\nif the agents have knowledge of k up to some constant approximation. We present\nan almost tight bound for the competitive penalty that must be paid, in the\nrunning time, if agents have no information about k. Specifically, on the\nnegative side, we show that in such a case, there is no algorithm whose\ncompetitiveness is O(log k). On the other hand, we show that for every constant\n$\\epsilon \\textgreater{} 0$, there exists a rather simple uniform search\nalgorithm which is $O( \\log^{1+\\epsilon} k)$-competitive. In addition, we give\na lower bound for the setting in which agents are given some estimation of k.\nAs a special case, this lower bound implies that for any constant $\\epsilon\n\\textgreater{} 0$, if each agent is given a (one-sided)\n$k^\\epsilon$-approximation to k, then the competitiveness is $\\Omega$(log k).\nInformally, our results imply that the agents can potentially perform well\nwithout any knowledge of their total number k, however, to further improve,\nthey must be given a relatively good approximation of k. Finally, we propose a\nuniform algorithm that is both efficient and extremely simple suggesting its\nrelevance for actual biological scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 07:00:17 GMT"}, {"version": "v2", "created": "Tue, 24 Jan 2017 10:09:26 GMT"}], "update_date": "2017-01-25", "authors_parsed": [["Feinerman", "Ofer", "", "LIAFA, GANG"], ["Korman", "Amos", "", "LIAFA, GANG"], ["Lotker", "Zvi", "", "UPD7"], ["Sereni", "Jean-S\u00e9bastien", "", "MASCOTTE"]]}, {"id": "1205.2282", "submitter": "Fabrice Rossi", "authors": "Matthieu Durut (LTCI), Beno\\^it Patra (LSTA), Fabrice Rossi (SAMM)", "title": "A Discussion on Parallelization Schemes for Stochastic Vector\n  Quantization Algorithms", "comments": null, "journal-ref": "20-th European Symposium on Artificial Neural Networks,\n  Computational Intelligence and Machine Learning (ESANN 2012), Bruges :\n  Belgium (2012)", "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies parallelization schemes for stochastic Vector Quantization\nalgorithms in order to obtain time speed-ups using distributed resources. We\nshow that the most intuitive parallelization scheme does not lead to better\nperformances than the sequential algorithm. Another distributed scheme is\ntherefore introduced which obtains the expected speed-ups. Then, it is improved\nto fit implementation on distributed architectures where communications are\nslow and inter-machines synchronization too costly. The schemes are tested with\nsimulated distributed architectures and, for the last one, with Microsoft\nWindows Azure platform obtaining speed-ups up to 32 Virtual Machines.\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 14:44:31 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Durut", "Matthieu", "", "LTCI"], ["Patra", "Beno\u00eet", "", "LSTA"], ["Rossi", "Fabrice", "", "SAMM"]]}, {"id": "1205.2367", "submitter": "Adrian Jackson", "authors": "Adrian Jackson and Orestis Agathokleous", "title": "Dynamic Loop Parallelisation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regions of nested loops are a common feature of High Performance Computing\n(HPC) codes. In shared memory programming models, such as OpenMP, these\nstructure are the most common source of parallelism. Parallelising these\nstructures requires the programmers to make a static decision on how\nparallelism should be applied. However, depending on the parameters of the\nproblem and the nature of the code, static decisions on which loop to\nparallelise may not be optimial, especially as they do not enable the\nexploitation of any runtime characteristics of the execution including changes\nto the iterations of the loops to be parallelised.\n  We have developed a system that allows a code to make a dynamic choice, at\nruntime, of what parallelism is applied to nested loops. Our method for\nproviding dynamic decisions on which loop to parallelise significantly\noutperforms the standard methods for acheiving this through OpenMP (using if\nclauses).\n", "versions": [{"version": "v1", "created": "Thu, 10 May 2012 11:18:40 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Jackson", "Adrian", ""], ["Agathokleous", "Orestis", ""]]}, {"id": "1205.2509", "submitter": "Adrian Jackson", "authors": "Adrian Jackson, Joachim Hein, and C. M. Roach", "title": "Optimising Performance Through Unbalanced Decompositions", "comments": null, "journal-ref": "IEEE TPDS 2014", "doi": "10.1109/TPDS.2014.2351826", "report-no": null, "categories": "cs.DC physics.plasm-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  GS2 is an initial value gyrokinetic simulation code developed to study\nlow-frequency turbulence in magnetized plasma. It is parallelised using MPI\nwith the simulation domain decomposed across tasks. The optimal domain\ndecomposition is non-trivial, and complicated by the different requirements of\nthe linear and non-linear parts of the calculations. GS2 users currently choose\na data layout, and are guided towards processor count that are efficient for\nlinear calculations. These choices can, however, lead to data decompositions\nthat are relatively inefficient for the non-linear calculations. We have\nanalysed the performance impact of the data decompositions on the non-linear\ncalculation and associated communications. This has helped us to optimise the\ndecomposition algorithm by using unbalanced data layouts for the non-linear\ncalculations whilst maintaining the existing decompositions for the linear\ncalculations, which has completely eliminated communications for parts of the\nnon-linear simulation and improved performance by up to 15% for a\nrepresentative simulation.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2012 13:06:54 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Jackson", "Adrian", ""], ["Hein", "Joachim", ""], ["Roach", "C. M.", ""]]}, {"id": "1205.2546", "submitter": "James Smith", "authors": "James William Smith, Ali Khajeh-Hosseini, Jonathan Stuart Ward and Ian\n  Sommerville", "title": "CloudMonitor: Profiling Power Usage", "comments": "2 page submission to appear in IEEE Cloud 2012 Work In Progress Track", "journal-ref": null, "doi": "10.1109/CLOUD.2012.112", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Cloud Computing platforms the addition of hardware monitoring devices to\ngather power usage data can be impractical or uneconomical due to the large\nnumber of machines to be metered. CloudMonitor, a monitoring tool that can\ngenerate power models for software-based power estimation, can provide insights\nto the energy costs of deployments without additional hardware. Accurate power\nusage data leads to the possibility of Cloud providers creating a separate\ntariff for power and therefore incentivizing software developers to create\nenergy-efficient applications.\n", "versions": [{"version": "v1", "created": "Fri, 11 May 2012 15:00:53 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Smith", "James William", ""], ["Khajeh-Hosseini", "Ali", ""], ["Ward", "Jonathan Stuart", ""], ["Sommerville", "Ian", ""]]}, {"id": "1205.2645", "submitter": "Joseph E. Gonzalez", "authors": "Joseph E. Gonzalez, Yucheng Low, Carlos E. Guestrin, David O'Hallaron", "title": "Distributed Parallel Inference on Large Factor Graphs", "comments": "Appears in Proceedings of the Twenty-Fifth Conference on Uncertainty\n  in Artificial Intelligence (UAI2009)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2009-PG-203-212", "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As computer clusters become more common and the size of the problems\nencountered in the field of AI grows, there is an increasing demand for\nefficient parallel inference algorithms. We consider the problem of parallel\ninference on large factor graphs in the distributed memory setting of computer\nclusters. We develop a new efficient parallel inference algorithm, DBRSplash,\nwhich incorporates over-segmented graph partitioning, belief residual\nscheduling, and uniform work Splash operations. We empirically evaluate the\nDBRSplash algorithm on a 120 processor cluster and demonstrate linear to\nsuper-linear performance gains on large factor graph models.\n", "versions": [{"version": "v1", "created": "Wed, 9 May 2012 15:23:28 GMT"}], "update_date": "2012-05-14", "authors_parsed": [["Gonzalez", "Joseph E.", ""], ["Low", "Yucheng", ""], ["Guestrin", "Carlos E.", ""], ["O'Hallaron", "David", ""]]}, {"id": "1205.3247", "submitter": "Zohreh Sanaei", "authors": "Zohreh Sanaei, Saeid Abolfazli, Abdullah Gani, Rashid Hafeez Khokhar", "title": "Tripod of Requirements in Horizontal Heterogeneous Mobile Cloud\n  Computing", "comments": null, "journal-ref": "Z. Sanaei, S. Abolfazli, A. Gani, and R. H. Khokhar, \"Tripod of\n  requirements in horizontal heterogeneous mobile cloud computing,\" in Proc.1st\n  Int'l Conf. Computing, Information Systems, and Communications, 2012", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Recent trend of mobile computing is emerging toward executing\nresource-intensive applications in mobile devices regardless of underlying\nresource restrictions (e.g. limited processor and energy) that necessitate\nimminent technologies. Prosperity of cloud computing in stationary computers\nbreeds Mobile Cloud Computing (MCC) technology that aims to augment computing\nand storage capabilities of mobile devices besides conserving energy. However,\nMCC is more heterogeneous and unreliable (due to wireless connectivity) compare\nto cloud computing. Problems like variations in OS, data fragmentation, and\nsecurity and privacy discourage and decelerate implementation and pervasiveness\nof MCC. In this paper, we describe MCC as a horizontal heterogeneous ecosystem\nand identify thirteen critical metrics and approaches that influence on\nmobile-cloud solutions and success of MCC. We divide them into three major\nclasses, namely ubiquity, trust, and energy efficiency and devise a tripod of\nrequirements in MCC. Our proposed tripod shows that success of MCC is\nachievable by reducing mobility challenges (e.g. seamless connectivity,\nfragmentation), increasing trust, and enhancing energy efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2012 03:29:23 GMT"}], "update_date": "2012-05-16", "authors_parsed": [["Sanaei", "Zohreh", ""], ["Abolfazli", "Saeid", ""], ["Gani", "Abdullah", ""], ["Khokhar", "Rashid Hafeez", ""]]}, {"id": "1205.3402", "submitter": "Mikael Gast", "authors": "Mikael Gast and Mathias Hauptmann", "title": "Efficient Parallel Computation of Nearest Neighbor Interchange Distances", "comments": "17 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC q-bio.PE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nni-distance is a well-known distance measure for phylogenetic trees. We\nconstruct an efficient parallel approximation algorithm for the nni-distance in\nthe CRCW-PRAM model running in O(log n) time on O(n) processors. Given two\nphylogenetic trees T1 and T2 on the same set of taxa and with the same\nmulti-set of edge-weights, the algorithm constructs a sequence of\nnni-operations of weight at most O(log n) \\cdot opt, where opt denotes the\nminimum weight of a sequence of nni-operations transforming T1 into T2 . This\nalgorithm is based on the sequential approximation algorithm for the\nnni-distance given by DasGupta et al. (2000). Furthermore, we show that the\nproblem of identifying so called good edge-pairs between two weighted\nphylogenies can be computed in O(log n) time on O(n log n) processors.\n", "versions": [{"version": "v1", "created": "Tue, 15 May 2012 14:59:56 GMT"}], "update_date": "2012-05-16", "authors_parsed": [["Gast", "Mikael", ""], ["Hauptmann", "Mathias", ""]]}, {"id": "1205.3676", "submitter": "Heath LeBlanc", "authors": "Heath J. LeBlanc, Haotian Zhang, Shreyas Sundaram, Xenofon Koutsoukos", "title": "Consensus of Multi-Agent Networks in the Presence of Adversaries Using\n  Only Local Information", "comments": "This report contains the proofs of the results presented at HiCoNS\n  2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of resilient consensus in the presence of\nmisbehaving nodes. Although it is typical to assume knowledge of at least some\nnonlocal information when studying secure and fault-tolerant consensus\nalgorithms, this assumption is not suitable for large-scale dynamic networks.\nTo remedy this, we emphasize the use of local strategies to deal with\nresilience to security breaches. We study a consensus protocol that uses only\nlocal information and we consider worst-case security breaches, where the\ncompromised nodes have full knowledge of the network and the intentions of the\nother nodes. We provide necessary and sufficient conditions for the normal\nnodes to reach consensus despite the influence of the malicious nodes under\ndifferent threat assumptions. These conditions are stated in terms of a novel\ngraph-theoretic property referred to as network robustness.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2012 00:05:04 GMT"}, {"version": "v2", "created": "Wed, 20 Jun 2012 16:40:39 GMT"}], "update_date": "2012-06-21", "authors_parsed": [["LeBlanc", "Heath J.", ""], ["Zhang", "Haotian", ""], ["Sundaram", "Shreyas", ""], ["Koutsoukos", "Xenofon", ""]]}, {"id": "1205.3797", "submitter": "Ulric Ferner", "authors": "Ulric J. Ferner and Muriel Medard and Emina Soljanin", "title": "Toward Sustainable Networking: Storage Area Networks with Network Coding", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This manuscript provides a model to characterize the energy savings of\nnetwork coded storage (NCS) in storage area networks (SANs). We consider\nblocking probability of drives as our measure of performance. A mapping\ntechnique to analyze SANs as independent M/G/K/K queues is presented, and\nblocking probabilities for uncoded storage schemes and NCS are derived and\ncompared. We show that coding operates differently than the amalgamation of\nfile chunks and energy savings are shown to scale well with striping number. We\nillustrate that for enterprise-level SANs energy savings of 20-50% can be\nrealized.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2012 20:15:49 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Ferner", "Ulric J.", ""], ["Medard", "Muriel", ""], ["Soljanin", "Emina", ""]]}, {"id": "1205.3809", "submitter": "Assefaw Gebremedhin", "authors": "Umit Catalyurek, John Feo, Assefaw Gebremedhin, Mahantesh\n  Halappanavar, Alex Pothen", "title": "Graph Coloring Algorithms for Muti-core and Massively Multithreaded\n  Architectures", "comments": "25 pages, 11 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the interplay between architectures and algorithm design in the\ncontext of shared-memory platforms and a specific graph problem of central\nimportance in scientific and high-performance computing, distance-1 graph\ncoloring. We introduce two different kinds of multithreaded heuristic\nalgorithms for the stated, NP-hard, problem. The first algorithm relies on\nspeculation and iteration, and is suitable for any shared-memory system. The\nsecond algorithm uses dataflow principles, and is targeted at the\nnon-conventional, massively multithreaded Cray XMT system. We study the\nperformance of the algorithms on the Cray XMT and two multi-core systems, Sun\nNiagara 2 and Intel Nehalem. Together, the three systems represent a spectrum\nof multithreading capabilities and memory structure. As testbed, we use\nsynthetically generated large-scale graphs carefully chosen to cover a wide\nrange of input types. The results show that the algorithms have scalable\nruntime performance and use nearly the same number of colors as the underlying\nserial algorithm, which in turn is effective in practice. The study provides\ninsight into the design of high performance algorithms for irregular problems\non many-core architectures.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2012 20:59:48 GMT"}], "update_date": "2012-05-18", "authors_parsed": [["Catalyurek", "Umit", ""], ["Feo", "John", ""], ["Gebremedhin", "Assefaw", ""], ["Halappanavar", "Mahantesh", ""], ["Pothen", "Alex", ""]]}, {"id": "1205.3830", "submitter": "Andrew Lucas", "authors": "Andrew Lucas, Mark Stalzer, John Feo", "title": "Parallel implementation of fast randomized algorithms for the\n  decomposition of low rank matrices", "comments": "9 pages, 2 figures, 5 tables. v2: extended version. this is a\n  preprint of a published paper - see published version for definitive version", "journal-ref": "Parallel Processing Letters 24, 1450004 (2014)", "doi": "10.1142/S0129626414500042", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the parallel performance of randomized interpolative decomposition\nby decomposing low rank complex-valued Gaussian random matrices up to 64 GB. We\nchose a Cray XMT supercomputer as it provides an almost ideal PRAM model\npermitting quick investigation of parallel algorithms without obfuscation from\nhardware idiosyncrasies. We obtain that on non-square matrices performance\nbecomes very good, with overall runtime over 70 times faster on 128 processors.\nWe also verify that numerically discovered error bounds still hold on matrices\nnearly two orders of magnitude larger than those previously tested.\n", "versions": [{"version": "v1", "created": "Wed, 16 May 2012 23:41:33 GMT"}, {"version": "v2", "created": "Tue, 1 Apr 2014 16:17:43 GMT"}], "update_date": "2014-04-02", "authors_parsed": [["Lucas", "Andrew", ""], ["Stalzer", "Mark", ""], ["Feo", "John", ""]]}, {"id": "1205.4385", "submitter": "Mehdi Bahrami", "authors": "Mehdi Bahrami, Mohammad Bahrami", "title": "An overview to Software Architecture in Intrusion Detection System", "comments": "8 Pages, International Journal of Soft Computing and Software\n  Engineering [JSCSE]. arXiv admin note: text overlap with arXiv:1101.0241 by\n  other authors", "journal-ref": "International Journal of Soft Computing and Software Engineering\n  [JSCSE], Vol. 1, No. 1, pp. 1-8, 2011", "doi": "10.7321/jscse.v1.n1.1", "report-no": null, "categories": "cs.SE cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today by growing network systems, security is a key feature of each network\ninfrastructure. Network Intrusion Detection Systems (IDS) provide defense model\nfor all security threats which are harmful to any network. The IDS could detect\nand block attack-related network traffic. The network control is a complex\nmodel. Implementation of an IDS could make delay in the network. Several\nsoftware-based network intrusion detection systems are developed. However, the\nmodel has a problem with high speed traffic. This paper reviews of many type of\nsoftware architecture in intrusion detection systems and describes the design\nand implementation of a high-performance network intrusion detection system\nthat combines the use of software-based network intrusion detection sensors and\na network processor board. The network processor which is a hardware-based\nmodel could acts as a customized load balancing splitter. This model cooperates\nwith a set of modified content-based network intrusion detection sensors rather\nthan IDS in processing network traffic and controls the high-speed.\n", "versions": [{"version": "v1", "created": "Sun, 20 May 2012 05:38:36 GMT"}, {"version": "v2", "created": "Fri, 21 Feb 2014 08:38:02 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Bahrami", "Mehdi", ""], ["Bahrami", "Mohammad", ""]]}, {"id": "1205.4545", "submitter": "Amos Korman", "authors": "Ofer Feinerman and Amos Korman", "title": "Memory Lower Bounds for Randomized Collaborative Search and Applications\n  to Biology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Initial knowledge regarding group size can be crucial for collective\nperformance. We study this relation in the context of the {\\em Ants Nearby\nTreasure Search (ANTS)} problem \\cite{FKLS}, which models natural cooperative\nforaging behavior such as that performed by ants around their nest. In this\nproblem, $k$ (probabilistic) agents, initially placed at some central location,\ncollectively search for a treasure on the two-dimensional grid. The treasure is\nplaced at a target location by an adversary and the goal is to find it as fast\nas possible as a function of both $k$ and $D$, where $D$ is the (unknown)\ndistance between the central location and the target. It is easy to see that\n$T=\\Omega(D+D^2/k)$ time units are necessary for finding the treasure.\nRecently, it has been established that $O(T)$ time is sufficient if the agents\nknow their total number $k$ (or a constant approximation of it), and enough\nmemory bits are available at their disposal \\cite{FKLS}. In this paper, we\nestablish lower bounds on the agent memory size required for achieving certain\nrunning time performances. To the best our knowledge, these bounds are the\nfirst non-trivial lower bounds for the memory size of probabilistic searchers.\nFor example, for every given positive constant $\\epsilon$, terminating the\nsearch by time $O(\\log^{1-\\epsilon} k \\cdot T)$ requires agents to use\n$\\Omega(\\log\\log k)$ memory bits. Such distributed computing bounds may provide\na novel, strong tool for the investigation of complex biological systems.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2012 09:52:57 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Feinerman", "Ofer", ""], ["Korman", "Amos", ""]]}, {"id": "1205.4605", "submitter": "Mika G\\\"o\\\"os", "authors": "Mika G\\\"o\\\"os, Jukka Suomela", "title": "No Sublogarithmic-time Approximation Scheme for Bipartite Vertex Cover", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": "10.1007/s00446-013-0194-z", "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  K\\\"onig's theorem states that on bipartite graphs the size of a maximum\nmatching equals the size of a minimum vertex cover. It is known from prior work\nthat for every \\epsilon > 0 there exists a constant-time distributed algorithm\nthat finds a (1+\\epsilon)-approximation of a maximum matching on 2-coloured\ngraphs of bounded degree. In this work, we show---somewhat surprisingly---that\nno sublogarithmic-time approximation scheme exists for the dual problem: there\nis a constant \\delta > 0 so that no randomised distributed algorithm with\nrunning time o(\\log n) can find a (1+\\delta)-approximation of a minimum vertex\ncover on 2-coloured graphs of maximum degree 3. In fact, a simple application\nof the Linial--Saks (1993) decomposition demonstrates that this lower bound is\ntight.\n  Our lower-bound construction is simple and, to some extent, independent of\nprevious techniques. Along the way we prove that a certain cut minimisation\nproblem, which might be of independent interest, is hard to approximate locally\non expander graphs.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2012 14:07:00 GMT"}], "update_date": "2013-12-24", "authors_parsed": [["G\u00f6\u00f6s", "Mika", ""], ["Suomela", "Jukka", ""]]}, {"id": "1205.4611", "submitter": "Stefan Engblom", "authors": "Anders Goude and Stefan Engblom", "title": "Adaptive fast multipole methods on the GPU", "comments": "Software available at http://user.it.uu.se/~stefane/freeware.html", "journal-ref": "J. Supercomput. 63(3): 897--918 (2013)", "doi": "10.1007/s11227-012-0836-0", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a highly general implementation of fast multipole methods on\ngraphics processing units (GPUs). Our two-dimensional double precision code\nfeatures an asymmetric type of adaptive space discretization leading to a\nparticularly elegant and flexible implementation. All steps of the multipole\nalgorithm are efficiently performed on the GPU, including the initial phase\nwhich assembles the topological information of the input data. Through careful\ntiming experiments we investigate the effects of the various peculiarities of\nthe GPU architecture.\n", "versions": [{"version": "v1", "created": "Mon, 21 May 2012 14:22:54 GMT"}, {"version": "v2", "created": "Mon, 8 Oct 2012 13:39:14 GMT"}], "update_date": "2013-02-22", "authors_parsed": [["Goude", "Anders", ""], ["Engblom", "Stefan", ""]]}, {"id": "1205.4809", "submitter": "Lewis Tseng", "authors": "Lewis Tseng and Nitin Vaidya", "title": "Iterative Approximate Byzantine Consensus under a Generalized Fault\n  Model", "comments": "arXiv admin note: text overlap with arXiv:1203.1888", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we consider a generalized fault model that can be used to\nrepresent a wide range of failure scenarios, including correlated failures and\nnon-uniform node reliabilities. This fault model is general in the sense that\nfault models studied in prior related work, such as f -total and f -local\nmodels, are special cases of the generalized fault model. Under the generalized\nfault model, we explore iterative approximate Byzantine consensus (IABC)\nalgorithms in arbitrary directed networks. We prove a necessary and sufficient\ncondition for the existence of IABC algorithms. The use of the generalized\nfault model helps to gain a better understanding of IABC algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 05:43:53 GMT"}], "update_date": "2012-05-23", "authors_parsed": [["Tseng", "Lewis", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1205.4813", "submitter": "Praveen Sivadasan", "authors": "Praveen Sivadasan, P. Sojan Lal", "title": "Securing SQLJ Source Codes from Business Logic Disclosure by Data Hiding\n  Obfuscation", "comments": "4 pages,3 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information security is protecting information from unauthorized access, use,\ndisclosure, disruption, modification, perusal and destruction. CAIN model\nsuggest maintaining the Confidentiality, Authenticity, Integrity and\nNon-repudiation (CAIN) of information. Oracle 8i, 9i and 11g Databases support\nSQLJ framework allowing embedding of SQL statements in Java Programs and\nproviding programmer friendly means to access the Oracle database. As cloud\ncomputing technology is becoming popular, SQLJ is considered as a flexible and\nuser friendly language for developing distributed applications in grid\narchitectures. SQLJ source codes are translated to java byte codes and\ndecompilation is generation of source codes from intermediate byte codes. The\nintermediate SQLJ application byte codes are open to decompilation, allowing a\nmalicious reader to forcefully decompile it for understanding confidential\nbusiness logic or data from the codes. To the best of our knowledge, strong and\ncost effective techniques exist for Oracle Database security, but still data\nsecurity techniques are lacking for client side applications, giving\npossibility for revelation of confidential business data. Data obfuscation is\nhiding the data in codes and we suggest enhancing the data security in SQLJ\nsource codes by data hiding, to mitigate disclosure of confidential business\ndata, especially integers in distributed applications.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 06:18:32 GMT"}], "update_date": "2012-05-23", "authors_parsed": [["Sivadasan", "Praveen", ""], ["Lal", "P. Sojan", ""]]}, {"id": "1205.4883", "submitter": "Gang Liao", "authors": "Gang Liao, Lian Luo, Lei Liu", "title": "Hybrid Parallel Bidirectional Sieve based on SMP Cluster", "comments": "11 pages,7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this article, hybrid parallel bidirectional sieve method is implemented by\nSMP Cluster, the individual computational units joined together by the\ncommunication network, are usually shared-memory systems with one or more\nmulticore processor. To high-efficiency optimization, we propose average divide\ndata into nodes, generating double-ended queues (deque) for sieve method that\nare able to exploit dual-cores simultaneously start sifting out primes from the\nhead and tail.And each node create a FIFO queue as dynamic data buffer to ache\ntemporary data from another nodes send to. The approach obtains huge speedup\nand efficiency on SMP Cluster.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 11:27:10 GMT"}], "update_date": "2012-05-23", "authors_parsed": [["Liao", "Gang", ""], ["Luo", "Lian", ""], ["Liu", "Lei", ""]]}, {"id": "1205.5003", "submitter": "Anissa Lamani", "authors": "Ajoy K. Datta, Anissa Lamani (MIS), Lawrence L. Larmore, Franck Petit\n  (LIP6)", "title": "Ring Exploration with Oblivious Myopic Robots", "comments": "(2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exploration problem in the discrete universe, using identical oblivious\nasynchronous robots without direct communication, has been well investigated.\nThese robots have sensors that allow them to see their environment and move\naccordingly. However, the previous work on this problem assume that robots have\nan unlimited visibility, that is, they can see the position of all the other\nrobots. In this paper, we consider deterministic exploration in an anonymous,\nunoriented ring using asynchronous, oblivious, and myopic robots. By myopic, we\nmean that the robots have only a limited visibility. We study the computational\nlimits imposed by such robots and we show that under some conditions the\nexploration problem can still be solved. We study the cases where the robots\nvisibility is limited to 1, 2, and 3 neighboring nodes, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 18:50:48 GMT"}], "update_date": "2012-05-23", "authors_parsed": [["Datta", "Ajoy K.", "", "MIS"], ["Lamani", "Anissa", "", "MIS"], ["Larmore", "Lawrence L.", "", "LIP6"], ["Petit", "Franck", "", "LIP6"]]}, {"id": "1205.5055", "submitter": "Matthew Anderson", "authors": "Matthew Anderson, Maciej Brodowicz, Hartmut Kaiser, Bryce\n  Adelstein-Lelbach, and Thomas Sterling", "title": "Neutron Star Evolutions using Tabulated Equations of State with a New\n  Execution Model", "comments": "9 pages, 8 figures. arXiv admin note: substantial text overlap with\n  arXiv:1110.1131", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The addition of nuclear and neutrino physics to general relativistic fluid\ncodes allows for a more realistic description of hot nuclear matter in neutron\nstar and black hole systems. This additional microphysics requires that each\nprocessor have access to large tables of data, such as equations of state, and\nin large simulations the memory required to store these tables locally can\nbecome excessive unless an alternative execution model is used. In this work we\npresent relativistic fluid evolutions of a neutron star obtained using a\nmessage driven multi-threaded execution model known as ParalleX. These neutron\nstar simulations would require substantial memory overhead dedicated entirely\nto the equation of state table if using a more traditional execution model. We\nintroduce a ParalleX component based on Futures for accessing large tables of\ndata, including out-of-core sized tables, which does not require substantial\nmemory overhead and effectively hides any increased network latency.\n", "versions": [{"version": "v1", "created": "Tue, 22 May 2012 20:46:11 GMT"}], "update_date": "2012-05-24", "authors_parsed": [["Anderson", "Matthew", ""], ["Brodowicz", "Maciej", ""], ["Kaiser", "Hartmut", ""], ["Adelstein-Lelbach", "Bryce", ""], ["Sterling", "Thomas", ""]]}, {"id": "1205.5177", "submitter": "Pablo Garc\\'ia-Risue\\~no", "authors": "Pablo Garc\\'ia-Risue\\~no, Pablo E. Ib\\'a\\~nez", "title": "A review of High Performance Computing foundations for scientists", "comments": "33 pages", "journal-ref": null, "doi": "10.1142/S0129183112300011", "report-no": null, "categories": "physics.comp-ph cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increase of existing computational capabilities has made simulation\nemerge as a third discipline of Science, lying midway between experimental and\npurely theoretical branches [1, 2]. Simulation enables the evaluation of\nquantities which otherwise would not be accessible, helps to improve\nexperiments and provides new insights on systems which are analysed [3-6].\nKnowing the fundamentals of computation can be very useful for scientists, for\nit can help them to improve the performance of their theoretical models and\nsimulations. This review includes some technical essentials that can be useful\nto this end, and it is devised as a complement for researchers whose education\nis focused on scientific issues and not on technological respects. In this\ndocument we attempt to discuss the fundamentals of High Performance Computing\n(HPC) [7] in a way which is easy to understand without much previous\nbackground. We sketch the way standard computers and supercomputers work, as\nwell as discuss distributed computing and discuss essential aspects to take\ninto account when running scientific calculations in computers.\n", "versions": [{"version": "v1", "created": "Wed, 23 May 2012 14:10:12 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Garc\u00eda-Risue\u00f1o", "Pablo", ""], ["Ib\u00e1\u00f1ez", "Pablo E.", ""]]}, {"id": "1205.5487", "submitter": "Tigran Gevorgyan", "authors": "H. V. Astsatryan, T. V. Gevorgyan and A. R. Shahinyan", "title": "Web Portal for Photonic Technologies Using Grid Infrastructures", "comments": null, "journal-ref": "JSEA, Vol.5 No.11, PP. 864-869, 2012", "doi": "10.4236/jsea.2012.511100", "report-no": null, "categories": "physics.comp-ph cs.DC quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The modeling of physical processes is an integral part of scientific and\ntechnical research. In this area, the Extendible C++ Application in Quantum\nTechnologies (ECAQT) package provides the numerical simulations and modeling of\ncomplex quantum systems in the presence of decoherence with wide applications\nin photonics. It allows creating models of interacting complex systems and\nsimulates their time evolution with a number of available time-evolution\ndrivers. Physical simulations involving massive amounts of calculations are\noften executed on distributed computing infrastructures. It is often difficult\nfor non expert users to use such computational infrastructures or even to use\nadvanced libraries over the infrastructures, because they often require being\nfamiliar with middleware and tools, parallel programming techniques and\npackages. The P-RADE Grid Portal is a Grid portal solution that allows users to\nmanage the whole life-cycle for executing a parallel application on the\ncomputing Grid infrastructures. The article describes the functionality and the\nstructure of the web portal based on ECAQT package.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2012 15:40:27 GMT"}, {"version": "v2", "created": "Wed, 9 Jan 2013 19:56:51 GMT"}], "update_date": "2013-01-10", "authors_parsed": [["Astsatryan", "H. V.", ""], ["Gevorgyan", "T. V.", ""], ["Shahinyan", "A. R.", ""]]}, {"id": "1205.5525", "submitter": "Anisur Molla Rahaman", "authors": "Atish Das Sarma, Anisur Rahaman Molla, Gopal Pandurangan", "title": "Fast Distributed Computation in Dynamic Networks via Random Walks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper investigates efficient distributed computation in dynamic networks\nin which the network topology changes (arbitrarily) from round to round.\n  Our first contribution is a rigorous framework for design and analysis of\ndistributed random walk algorithms in dynamic networks. We then develop a fast\ndistributed random walk based algorithm that runs in $\\tilde{O}(\\sqrt{\\tau\n\\Phi})$ rounds (with high probability), where $\\tau$ is the dynamic mixing time\nand $\\Phi$ is the dynamic diameter of the network respectively, and returns a\nsample close to a suitably defined stationary distribution of the dynamic\nnetwork. We also apply our fast random walk algorithm to devise fast\ndistributed algorithms for two key problems, namely, information dissemination\nand decentralized computation of spectral properties in a dynamic network.\n  Our next contribution is a fast distributed algorithm for the fundamental\nproblem of information dissemination (also called as gossip) in a dynamic\nnetwork. In gossip, or more generally, $k$-gossip, there are $k$ pieces of\ninformation (or tokens) that are initially present in some nodes and the\nproblem is to disseminate the $k$ tokens to all nodes. We present a random-walk\nbased algorithm that runs in $\\tilde{O}(\\min\\{n^{1/3}k^{2/3}(\\tau \\Phi)^{1/3},\nnk\\})$ rounds (with high probability). To the best of our knowledge, this is\nthe first $o(nk)$-time fully-distributed token forwarding algorithm that\nimproves over the previous-best $O(nk)$ round distributed algorithm [Kuhn et\nal., STOC 2010], although in an oblivious adversary model.\n  Our final contribution is a simple and fast distributed algorithm for\nestimating the dynamic mixing time and related spectral properties of the\nunderlying dynamic network.\n", "versions": [{"version": "v1", "created": "Thu, 24 May 2012 18:36:18 GMT"}], "update_date": "2012-05-25", "authors_parsed": [["Sarma", "Atish Das", ""], ["Molla", "Anisur Rahaman", ""], ["Pandurangan", "Gopal", ""]]}, {"id": "1205.5871", "submitter": "Michele Mazzucco", "authors": "Michele Mazzucco and Martti Vasar and Marlon Dumas", "title": "Squeezing out the Cloud via Profit-Maximizing Resource Allocation\n  Policies", "comments": "16 pages, 9 Figures. A 10 pages version of this manuscript will\n  appear in IEEE MASCOTS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of maximizing the average hourly profit earned by a\nSoftware-as-a-Service (SaaS) provider who runs a software service on behalf of\na customer using servers rented from an Infrastructure-as-a-Service (IaaS)\nprovider. The SaaS provider earns a fee per successful transaction and incurs\ncosts proportional to the number of server-hours it uses. A number of resource\nallocation policies for this or similar problems have been proposed in previous\nwork. However, to the best of our knowledge, these policies have not been\ncomparatively evaluated in a cloud environment. This paper reports on an\nempirical evaluation of three policies using a replica of Wikipedia deployed on\nthe Amazon EC2 cloud. Experimental results show that a policy based on a\nsolution to an optimization problem derived from the SaaS provider's utility\nfunction outperforms well-known heuristics that have been proposed for similar\nproblems. It is also shown that all three policies outperform a \"reactive\"\nallocation approach based on Amazon's auto-scaling feature.\n", "versions": [{"version": "v1", "created": "Sat, 26 May 2012 10:37:27 GMT"}, {"version": "v2", "created": "Tue, 17 Jul 2012 08:40:00 GMT"}, {"version": "v3", "created": "Wed, 18 Jul 2012 07:31:05 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Mazzucco", "Michele", ""], ["Vasar", "Martti", ""], ["Dumas", "Marlon", ""]]}, {"id": "1205.6249", "submitter": "Dariusz Dereniowski", "authors": "Dariusz Dereniowski, Andrzej Pelc", "title": "Leader Election for Anonymous Asynchronous Agents in Arbitrary Networks", "comments": null, "journal-ref": "Distributed Computing 27 (2014) 21-38", "doi": "10.1007/s00446-013-0196-x", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of leader election among mobile agents operating in an\narbitrary network modeled as an undirected graph. Nodes of the network are\nunlabeled and all agents are identical. Hence the only way to elect a leader\namong agents is by exploiting asymmetries in their initial positions in the\ngraph. Agents do not know the graph or their positions in it, hence they must\ngain this knowledge by navigating in the graph and share it with other agents\nto accomplish leader election. This can be done using meetings of agents, which\nis difficult because of their asynchronous nature: an adversary has total\ncontrol over the speed of agents. When can a leader be elected in this\nadversarial scenario and how to do it? We give a complete answer to this\nquestion by characterizing all initial configurations for which leader election\nis possible and by constructing an algorithm that accomplishes leader election\nfor all configurations for which this can be done.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2012 02:27:35 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Dereniowski", "Dariusz", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1205.6349", "submitter": "Wenqiang Wang", "authors": "Wen Qiang Wang, Dinh Tien Tuan Anh, Hock Beng Lim, and Anwitaman Datta", "title": "Cloud and the City: Facilitating Flexible Access Control over Data\n  Streams", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of sensing devices create plethora of data-streams, which\nin turn can be harnessed to carry out sophisticated analytics to support\nvarious real-time applications and services as well as long-term planning,\ne.g., in the context of intelligent cities or smart homes to name a few\nprominent ones. A mature cloud infrastructure brings such a vision closer to\nreality than ever before. However, we believe that the ability for data-owners\nto flexibly and easily to control the granularity at which they share their\ndata with other entities is very important - in making data owners feel\ncomfortable to share to start with, and also to leverage on such fine-grained\ncontrol to realize different business models or logics. In this paper, we\nexplore some basic operations to flexibly control the access on a data stream\nand propose a framework eXACML+ that extends OASIS's XACML model to achieve the\nsame. We develop a prototype using the commercial StreamBase engine to\ndemonstrate a seamless combination of stream data processing with (a small but\nimportant selected set of) fine-grained access control mechanisms, and study\nthe framework's efficacy based on experiments in cloud like environments.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2012 12:46:04 GMT"}, {"version": "v2", "created": "Thu, 31 May 2012 16:59:58 GMT"}], "update_date": "2012-06-01", "authors_parsed": [["Wang", "Wen Qiang", ""], ["Anh", "Dinh Tien Tuan", ""], ["Lim", "Hock Beng", ""], ["Datta", "Anwitaman", ""]]}, {"id": "1205.6465", "submitter": "Alejandro Hernandez", "authors": "Alejandro Mario Hernandez", "title": "Globally reasoning about localised security policies in distributed\n  systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report, we aim at establishing proper ways for model checking the\nglobal security of distributed systems, which are designed consisting of set of\nlocalised security policies that enforce specific issues about the security\nexpected.\n  The systems are formally specified following a syntax, defined in detail in\nthis report, and their behaviour is clearly established by the Semantics, also\ndefined in detail in this report. The systems include the formal attachment of\nsecurity policies into their locations, whose intended interactions are trapped\nby the policies, aiming at taking access control decisions of the system, and\nthe Semantics also takes care of this.\n  Using the Semantics, a Labelled Transition System (LTS) can be induced for\nevery particular system, and over this LTS some model checking tasks could be\ndone. We identify how this LTS is indeed obtained, and propose an alternative\nway of model checking the not-yet-induced LTS, by using the system design\ndirectly. This may lead to over-approximation thereby producing imprecise,\nthough safe, results. We restrict ourselves to finite systems, in the sake of\nbeing certain about the decidability of the proposed method.\n  To illustrate the usefulness and validity of our proposal, we present 2 small\ncase-study-like examples, where we show how the system can be specified, which\npolicies could be added to it, and how to decide if the desired global security\nproperty is met.\n  Finally, an Appendix is given for digging deeply into how a tool for\nautomatically performing this task is being built, including some\nimplementation issues. The tool takes advantage of the proposed method, and\ngiven some system and some desired global security property, it safely (i.e.\nwithout false positives) ensures satisfaction of it.\n", "versions": [{"version": "v1", "created": "Tue, 29 May 2012 19:59:00 GMT"}], "update_date": "2012-05-30", "authors_parsed": [["Hernandez", "Alejandro Mario", ""]]}, {"id": "1205.6961", "submitter": "Bernhard Haeupler", "authors": "Bernhard Haeupler", "title": "Tighter Worst-Case Bounds on Algebraic Gossip", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gossip and in particular network coded algebraic gossip have recently\nattracted attention as a fast, bandwidth-efficient, reliable and distributed\nway to broadcast or multicast multiple messages. While the algorithms are\nsimple, involved queuing approaches are used to study their performance. The\nmost recent result in this direction shows that uniform algebraic gossip\ndisseminates k messages in O({\\Delta}(D + k + log n)) rounds where D is the\ndiameter, n the size of the network and {\\Delta} the maximum degree.\n  In this paper we give a simpler, short and self-contained proof for this\nworst-case guarantee. Our approach also allows to reduce the quadratic\n{\\Delta}D term to min{3n, {\\Delta}D}. We furthermore show that a simple round\nrobin routing scheme also achieves min{3n, {\\Delta}D} + {\\Delta}k rounds,\neliminating both randomization and coding. Lastly, we combine a recent\nnon-uniform gossip algorithm with a simple routing scheme to get a O(D + k +\nlog^{O(1)}) gossip information dissemination algorithm. This is order optimal\nas long as D and k are not both polylogarithmically small.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2012 11:30:18 GMT"}], "update_date": "2012-06-01", "authors_parsed": [["Haeupler", "Bernhard", ""]]}, {"id": "1205.7014", "submitter": "Bernhard Haeupler", "authors": "Noga Alon, Mohsen Ghaffari, Bernhard Haeupler, Majid Khabbazian", "title": "Broadcast Throughput in Radio Networks: Routing vs. Network Coding", "comments": null, "journal-ref": null, "doi": "10.1137/1.9781611973402.132", "report-no": null, "categories": "cs.DS cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The broadcast throughput in a network is defined as the average number of\nmessages that can be transmitted per unit time from a given source to all other\nnodes when time goes to infinity.\n  Classical broadcast algorithms treat messages as atomic tokens and route them\nfrom the source to the receivers by making intermediate nodes store and forward\nmessages. The more recent network coding approach, in contrast, prompts\nintermediate nodes to mix and code together messages. It has been shown that\ncertain wired networks have an asymptotic network coding gap, that is, they\nhave asymptotically higher broadcast throughput when using network coding\ncompared to routing. Whether such a gap exists for wireless networks has been\nan open question of great interest. We approach this question by studying the\nbroadcast throughput of the radio network model which has been a standard\nmathematical model to study wireless communication.\n  We show that there is a family of radio networks with a tight $\\Theta(\\log\n\\log n)$ network coding gap, that is, networks in which the asymptotic\nthroughput achievable via routing messages is a $\\Theta(\\log \\log n)$ factor\nsmaller than that of the optimal network coding algorithm. We also provide new\ntight upper and lower bounds that show that the asymptotic worst-case broadcast\nthroughput over all networks with $n$ nodes is $\\Theta(1 / \\log n)$\nmessages-per-round for both routing and network coding.\n", "versions": [{"version": "v1", "created": "Thu, 31 May 2012 15:03:58 GMT"}, {"version": "v2", "created": "Wed, 31 Oct 2012 17:27:02 GMT"}, {"version": "v3", "created": "Thu, 28 Aug 2014 14:36:35 GMT"}], "update_date": "2014-08-29", "authors_parsed": [["Alon", "Noga", ""], ["Ghaffari", "Mohsen", ""], ["Haeupler", "Bernhard", ""], ["Khabbazian", "Majid", ""]]}]