[{"id": "1211.0157", "submitter": "Partha Sarathi Mandal Dr.", "authors": "Barun Gorain and Partha Sarathi Mandal", "title": "Optimal Covering with Mobile Sensors in an Unbounded Region", "comments": "7 pages, submitted in the Eighth International Conference on Wireless\n  Communication and Sensor Networks (WCSN-2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Covering a bounded region with minimum number of homogeneous sensor nodes is\na NP-complete problem \\cite{Li09}. In this paper we have proposed an {\\it id}\nbased distributed algorithm for optimal coverage in an unbounded region. The\nproposed algorithm guarantees maximum spreading in $O(\\sqrt{n})$ rounds without\ncreating any coverage hole. The algorithm executes in synchronous rounds\nwithout exchanging any message.\n  We have also explained how our proposed algorithm can achieve optimal energy\nconsumption and handle random sensor node deployment for optimal spreading.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2012 12:11:23 GMT"}], "update_date": "2012-11-02", "authors_parsed": [["Gorain", "Barun", ""], ["Mandal", "Partha Sarathi", ""]]}, {"id": "1211.0235", "submitter": "Peter Jeavons", "authors": "Alex Scott, Peter Jeavons, Lei Xu", "title": "Feedback from nature: an optimal distributed algorithm for maximal\n  independent set selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximal Independent Set selection is a fundamental problem in distributed\ncomputing. A novel probabilistic algorithm for this problem has recently been\nproposed by Afek et al, inspired by the study of the way that developing cells\nin the fly become specialised. The algorithm they propose is simple and robust,\nbut not as efficient as previous approaches: the expected time complexity is\nO(log^2 n). Here we first show that the approach of Afek et al cannot achieve\nbetter efficiency than this across all networks, no matter how the probability\nvalues are chosen. However, we then propose a new algorithm that incorporates\nanother important feature of the biological system: adapting the probabilities\nused at each node based on local feedback from neighbouring nodes. Our new\nalgorithm retains all the advantages of simplicity and robustness, but also\nachieves the optimal efficiency of O(log n) expected time.\n", "versions": [{"version": "v1", "created": "Thu, 1 Nov 2012 17:41:34 GMT"}], "update_date": "2012-11-02", "authors_parsed": [["Scott", "Alex", ""], ["Jeavons", "Peter", ""], ["Xu", "Lei", ""]]}, {"id": "1211.0415", "submitter": "Toni Ernvall", "authors": "Toni Ernvall, Salim El Rouayheb, Camilla Hollanti, H. Vincent Poor", "title": "Capacity and Security of Heterogeneous Distributed Storage Systems", "comments": "7 pages, 2 figures", "journal-ref": "IEEE JSAC, December 2013, Volume: 31, Issue: 12, Pages: 2701 -\n  2709", "doi": "10.1109/JSAC.2013.131210", "report-no": null, "categories": "cs.DC cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the capacity of heterogeneous distributed storage systems under\nrepair dynamics. Examples of these systems include peer-to-peer storage clouds,\nwireless, and Internet caching systems. Nodes in a heterogeneous system can\nhave different storage capacities and different repair bandwidths. We give\nlower and upper bounds on the system capacity. These bounds depend on either\nthe average resources per node, or on a detailed knowledge of the node\ncharacteristics. Moreover, we study the case in which nodes may be compromised\nby an eavesdropper, and give bounds on the system secrecy capacity. One\nimplication of our results is that symmetric repair maximizes the capacity of a\nhomogeneous system, which justifies the model widely used in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 2 Nov 2012 10:54:33 GMT"}], "update_date": "2013-12-16", "authors_parsed": [["Ernvall", "Toni", ""], ["Rouayheb", "Salim El", ""], ["Hollanti", "Camilla", ""], ["Poor", "H. Vincent", ""]]}, {"id": "1211.1279", "submitter": "Sunirmal Khatua", "authors": "Sunirmal Khatua and Nandini Mukherjee", "title": "Application-centric Resource Provisioning for Amazon EC2 Spot Instances", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In late 2009, Amazon introduced spot instances to offer their unused\nresources at lower cost with reduced reliability. Amazon's spot instances allow\ncustomers to bid on unused Amazon EC2 capacity and run those instances for as\nlong as their bid exceeds the current spot price. The spot price changes\nperiodically based on supply and demand, and customers whose bids exceed it\ngain access to the available spot instances. Customers may expect their\nservices at lower cost with spot instances compared to on-demand or reserved.\nHowever the reliability is compromised since the instances(IaaS) providing the\nservice(SaaS) may become unavailable at any time without any notice to the\ncustomer. Checkpointing and migration schemes are of great use to cope with\nsuch situation. In this paper we study various checkpointing schemes that can\nbe used with spot instances. Also we device some algorithms for checkpointing\nscheme on top of application-centric resource provisioning framework that\nincrease the reliability while reducing the cost significantly.\n", "versions": [{"version": "v1", "created": "Tue, 6 Nov 2012 15:58:55 GMT"}], "update_date": "2012-11-07", "authors_parsed": [["Khatua", "Sunirmal", ""], ["Mukherjee", "Nandini", ""]]}, {"id": "1211.1447", "submitter": "Harshad Prajapati", "authors": "Harshad B. Prajapati and Vipul A. Shah", "title": "Advance Reservation based DAG Application Scheduling Simulator for Grid\n  Environment", "comments": "7 pages, 9 figures, 1 table", "journal-ref": "International Journal of Computer Applications, 2013", "doi": "10.5120/9944-4585", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the last decade, scheduling of Directed Acyclic Graph (DAG) application in\nthe context of Grid environment has attracted attention of many researchers.\nHowever, deployment of Grid environment requires skills, efforts, budget, and\ntime. Although various simulation toolkits or frameworks are available for\nsimulating Grid environment, either they support different possible studies in\nGrid computing area or takes lot of efforts in molding them to make them\nsuitable for scheduling of DAG application. In this paper, we describe design\nand implementation of GridSim based ready to use application scheduler for\nscheduling of DAG application in Grid environment. The proposed application\nscheduler supports supplying DAG application and configuration of Grid\nresources through GUI. We also describe implementation of Min-Min static\nscheduling algorithm for scheduling of DAG application to validate the proposed\nscheduler. Our proposed DAG application scheduling simulator is useful, easy,\nand time-saver.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 04:21:58 GMT"}], "update_date": "2013-01-21", "authors_parsed": [["Prajapati", "Harshad B.", ""], ["Shah", "Vipul A.", ""]]}, {"id": "1211.1457", "submitter": "Pallavali Radha Krishna Reddy", "authors": "G. Vidhisha, C. Surekha, S. Sanjeeva Rayudu, U. Seshadri", "title": "Preserving privacy for secure and outsourcing for Linear Programming in\n  cloud computing", "comments": "8, 2012 Vol 1 Issue 2 November 2278-9200, http://www.cschronicle.org", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Cloud computing is the long dreamed vision of computing as a utility, where\nusers can remotely store their data into the cloud so as to enjoy the on-demand\nhigh quality applications and services from a shared pool of configurable\ncomputing resources. By data outsourcing, users can be relieved from the burden\nof local data storage and maintenance. we utilize the public key based\nhomomorphism authenticator and uniquely integrate it with random mask technique\nto achieve a privacy-preserving public auditing system for cloud data storage\nsecurity while keeping all above requirements in mind. To support efficient\nhandling of multiple auditing tasks, we further explore the technique of\nbilinear aggregate signature to extend our main result into a multi-user\nsetting, where TPA can perform multiple auditing tasks simultaneously along\nwith investigates secure outsourcing of widely applicable linear programming\n(LP) computations. In order to achieve practical efficiency, our mechanism\ndesign explicitly decomposes the LP computation outsourcing into public LP\nsolvers running on the cloud and private LP parameters owned by the customer\nExtensive security and performance analysis shows the proposed schemes are\nprovably secure and highly efficient.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 05:39:46 GMT"}], "update_date": "2012-11-08", "authors_parsed": [["Vidhisha", "G.", ""], ["Surekha", "C.", ""], ["Rayudu", "S. Sanjeeva", ""], ["Seshadri", "U.", ""]]}, {"id": "1211.1658", "submitter": "Amol Ghoting", "authors": "Prabhanjan Kambadur, Amol Ghoting, Anshul Gupta, Andrew Lumsdaine", "title": "Extending Task Parallelism for Frequent Pattern Mining", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Algorithms for frequent pattern mining, a popular informatics application,\nhave unique requirements that are not met by any of the existing parallel\ntools. In particular, such applications operate on extremely large data sets\nand have irregular memory access patterns. For efficient parallelization of\nsuch applications, it is necessary to support dynamic load balancing along with\nscheduling mechanisms that allow users to exploit data locality. Given these\nrequirements, task parallelism is the most promising of the available parallel\nprogramming models. However, existing solutions for task parallelism schedule\ntasks implicitly and hence, custom scheduling policies that can exploit data\nlocality cannot be easily employed. In this paper we demonstrate and\ncharacterize the speedup obtained in a frequent pattern mining application\nusing a custom clustered scheduling policy in place of the popular Cilk-style\npolicy. We present PFunc, a novel task parallel library whose customizable task\nscheduling and task priorities facilitated the implementation of our clustered\nscheduling policy.\n", "versions": [{"version": "v1", "created": "Wed, 7 Nov 2012 20:18:30 GMT"}], "update_date": "2012-11-08", "authors_parsed": [["Kambadur", "Prabhanjan", ""], ["Ghoting", "Amol", ""], ["Gupta", "Anshul", ""], ["Lumsdaine", "Andrew", ""]]}, {"id": "1211.2032", "submitter": "Mohamed Firdhous", "authors": "Mohamed Firdhous", "title": "Implementation of Security in Distributed Systems - A Comparative Study", "comments": "6 pages, 4 figures", "journal-ref": "International Journal of Computer Information Systems (IJCIS),\n  Vol. 2, No. 2, February 2011, pp-1-6", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a comparative study of distributed systems and the\nsecurity issues associated with those systems. Four commonly used distributed\nsystems were considered for detailed analysis in terms of technologies\ninvolved, security issues faced by them and solution proposed to circumvent\nthose issues. Finally the security issues and the solutions were summarized and\ncompared with each other.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 02:52:32 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Firdhous", "Mohamed", ""]]}, {"id": "1211.2038", "submitter": "Krishnahari Thouti", "authors": "Krishnahari Thouti, S. R. Sathe", "title": "Comparison of OpenMP & OpenCL Parallel Processing Technologies", "comments": "6 pages, 7 figures;\n  http://thesai.org/Downloads/Volume3No4/Paper_10-Comparison_of_OpenMP_OpenCL_Parallel_Processing_Technologies.pdf", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications (IJACSA), Volume 3, issue 4, 2012, 56-61", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a comparison of OpenMP and OpenCL based on the parallel\nimplementation of algorithms from various fields of computer applications. The\nfocus of our study is on the performance of benchmark comparing OpenMP and\nOpenCL. We observed that OpenCL programming model is a good option for mapping\nthreads on different processing cores. Balancing all available cores and\nallocating sufficient amount of work among all computing units, can lead to\nimproved performance. In our simulation, we used Fedora operating system; a\nsystem with Intel Xeon Dual core processor having thread count 24 coupled with\nNVIDIA Quadro FX 3800 as graphical processing unit.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 04:27:32 GMT"}], "update_date": "2012-11-12", "authors_parsed": [["Thouti", "Krishnahari", ""], ["Sathe", "S. R.", ""]]}, {"id": "1211.2132", "submitter": "Euhanna Ghadimi", "authors": "Euhanna Ghadimi, Iman Shames, and Mikael Johansson", "title": "Accelerated Gradient Methods for Networked Optimization", "comments": null, "journal-ref": null, "doi": "10.1109/TSP.2013.2278149", "report-no": null, "categories": "math.OC cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop multi-step gradient methods for network-constrained optimization\nof strongly convex functions with Lipschitz-continuous gradients. Given the\ntopology of the underlying network and bounds on the Hessian of the objective\nfunction, we determine the algorithm parameters that guarantee the fastest\nconvergence and characterize situations when significant speed-ups can be\nobtained over the standard gradient method. Furthermore, we quantify how the\nperformance of the gradient method and its accelerated counterpart are affected\nby uncertainty in the problem data, and conclude that in most cases our\nproposed method outperforms gradient descent. Finally, we apply the proposed\ntechnique to three engineering problems: resource allocation under network-wide\nbudget constraints, distributed averaging, and Internet congestion control. In\nall cases, we demonstrate that our algorithm converges more rapidly than\nalternative algorithms reported in the literature.\n", "versions": [{"version": "v1", "created": "Fri, 9 Nov 2012 13:41:53 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Ghadimi", "Euhanna", ""], ["Shames", "Iman", ""], ["Johansson", "Mikael", ""]]}, {"id": "1211.2292", "submitter": "Duy Truong", "authors": "Truong Vinh Truong Duy, Katsuhiro Yamazaki, Kosai Ikegami, and Shigeru\n  Oyanagi", "title": "Hybrid MPI-OpenMP Paradigm on SMP Clusters: MPEG-2 Encoder and N-Body\n  Simulation", "comments": "8 pages, 9 figures, 6 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clusters of SMP nodes provide support for a wide diversity of parallel\nprogramming paradigms. Combining both shared memory and message passing\nparallelizations within the same application, the hybrid MPI-OpenMP paradigm is\nan emerging trend for parallel programming to fully exploit distributed\nshared-memory architecture. In this paper, we improve the performance of MPEG-2\nencoder and n-body simulation by employing the hybrid MPI-OpenMP programming\nparadigm on SMP clusters. The hierarchical image data structure of the MPEG\nbit-stream is eminently suitable for the hybrid model to achieve multiple\nlevels of parallelism: MPI for parallelism at the group of pictures level\nacross SMP nodes and OpenMP for parallelism within pictures at the slice level\nwithin each SMP node. Similarly, the work load of the force calculation which\naccounts for upwards of 90% of the cycles in typical computations in the n-body\nsimulation is shared among OpenMP threads after ORB domain decomposition among\nMPI processes. Besides, loop scheduling of OpenMP threads is adopted with\nappropriate chunk size to provide better load balance of work, leading to\nenhanced performance. With the n-body simulation, experimental results\ndemonstrate that the hybrid MPI-OpenMP program outperforms the corresponding\npure MPI program by average factors of 1.52 on a 4-way cluster and 1.21 on a\n2-way cluster. Likewise, the hybrid model offers a performance improvement of\n18% compared to the MPI model for the MPEG-2 encoder.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2012 05:51:06 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Duy", "Truong Vinh Truong", ""], ["Yamazaki", "Katsuhiro", ""], ["Ikegami", "Kosai", ""], ["Oyanagi", "Shigeru", ""]]}, {"id": "1211.2293", "submitter": "Duy Truong", "authors": "Truong Vinh Truong Duy, Katsuhiro Yamazaki, and Shigeru Oyanagi", "title": "Performance Evaluation of Treecode Algorithm for N-Body Simulation Using\n  GridRPC System", "comments": "4 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is aimed at improving the performance of the treecode algorithm\nfor N-Body simulation by employing the NetSolve GridRPC programming model to\nexploit the use of multiple clusters. N-Body is a classical problem, and\nappears in many areas of science and engineering, including astrophysics,\nmolecular dynamics, and graphics. In the simulation of N-Body, the specific\nroutine for calculating the forces on the bodies which accounts for upwards of\n90% of the cycles in typical computations is eminently suitable for obtaining\nparallelism with GridRPC calls. It is divided among the compute nodes by\nsimultaneously calling multiple GridRPC requests to them. The performance of\nthe GridRPC implementation is then compared to that of the MPI version and\nhybrid MPI-OpenMP version for the treecode algorithm on individual clusters.\n", "versions": [{"version": "v1", "created": "Sat, 10 Nov 2012 06:08:36 GMT"}], "update_date": "2012-11-13", "authors_parsed": [["Duy", "Truong Vinh Truong", ""], ["Yamazaki", "Katsuhiro", ""], ["Oyanagi", "Shigeru", ""]]}, {"id": "1211.2963", "submitter": "Derek Groen", "authors": "Derek Groen, Joris Borgdorff, Carles Bona-Casas, James Hetherington,\n  Rupert W. Nash, Stefan J. Zasada, Ilya Saverchenko, Mariusz Mamonski,\n  Krzysztof Kurowski, Miguel O. Bernabeu, Alfons G. Hoekstra and Peter V.\n  Coveney", "title": "Flexible composition and execution of high performance, high fidelity\n  multiscale biomedical simulations", "comments": "accepted by Interface Focus. 17 pages, 2 figures, 4 tables", "journal-ref": "Interface Focus April 6, 2013 3 2 20120087", "doi": "10.1098/rsfs.2012.0087", "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiscale simulations are essential in the biomedical domain to accurately\nmodel human physiology. We present a modular approach for designing,\nconstructing and executing multiscale simulations on a wide range of resources,\nfrom desktops to petascale supercomputers, including combinations of these. Our\nwork features two multiscale applications, in-stent restenosis and\ncerebrovascular bloodflow, which combine multiple existing single-scale\napplications to create a multiscale simulation. These applications can be\nefficiently coupled, deployed and executed on computers up to the largest\n(peta) scale, incurring a coupling overhead of 1 to 10% of the total execution\ntime.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2012 12:11:09 GMT"}, {"version": "v2", "created": "Mon, 28 Jan 2013 10:45:37 GMT"}], "update_date": "2013-03-19", "authors_parsed": [["Groen", "Derek", ""], ["Borgdorff", "Joris", ""], ["Bona-Casas", "Carles", ""], ["Hetherington", "James", ""], ["Nash", "Rupert W.", ""], ["Zasada", "Stefan J.", ""], ["Saverchenko", "Ilya", ""], ["Mamonski", "Mariusz", ""], ["Kurowski", "Krzysztof", ""], ["Bernabeu", "Miguel O.", ""], ["Hoekstra", "Alfons G.", ""], ["Coveney", "Peter V.", ""]]}, {"id": "1211.3006", "submitter": "K. Shashi Prabh", "authors": "K. Shashi Prabh", "title": "Near-Optimal Distributed Scheduling Algorithms for Regular Wireless\n  Sensor Networks", "comments": "Version 2: Added new evaluations and revised text", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless sensor networks are normally characterized by resource challenged\nnodes. Since communication costs the most in terms of energy in these networks,\nminimizing this overhead is important. We consider minimum length node\nscheduling in regular multi-hop wireless sensor networks. We present\ncollision-free decentralized scheduling algorithms based on TDMA with spatial\nreuse that do not use message passing, this saving communication overhead. We\ndevelop the algorithms using graph-based k-hop interference model and show that\nthe schedule complexity in regular networks is independent of the number of\nnodes and varies quadratically with k which is typically a very small number.\nWe follow it by characterizing feasibility regions in the SINR parameter space\nwhere the constant complexity continues to hold while simultaneously satisfying\nthe SINR criteria. Using simulation, we evaluate the efficiency of our solution\non random network deployments.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2012 14:49:45 GMT"}, {"version": "v2", "created": "Wed, 23 Jan 2013 20:41:06 GMT"}], "update_date": "2013-01-24", "authors_parsed": [["Prabh", "K. Shashi", ""]]}, {"id": "1211.3056", "submitter": "Mourad Gouicem", "authors": "Pierre Fortin (LIP6), Mourad Gouicem (LIP6), Stef Graillat (LIP6)", "title": "GPU-accelerated generation of correctly-rounded elementary functions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The IEEE 754-2008 standard recommends the correct rounding of some elementary\nfunctions. This requires to solve the Table Maker's Dilemma which implies a\nhuge amount of CPU computation time. We consider in this paper accelerating\nsuch computations, namely Lefe'vre algorithm on Graphics Processing Units\n(GPUs) which are massively parallel architectures with a partial SIMD execution\n(Single Instruction Multiple Data). We first propose an analysis of the\nLef\\`evre hard-to-round argument search using the concept of continued\nfractions. We then propose a new parallel search algorithm much more efficient\non GPU thanks to its more regular control flow. We also present an efficient\nhybrid CPU-GPU deployment of the generation of the polynomial approximations\nrequired in Lef\\`evre algorithm. In the end, we manage to obtain overall\nspeedups up to 53.4x on one GPU over a sequential CPU execution, and up to 7.1x\nover a multi-core CPU, which enable a much faster solving of the Table Maker's\nDilemma for the double precision format.\n", "versions": [{"version": "v1", "created": "Tue, 13 Nov 2012 17:28:03 GMT"}, {"version": "v2", "created": "Wed, 5 Jun 2013 11:51:55 GMT"}], "update_date": "2013-06-06", "authors_parsed": [["Fortin", "Pierre", "", "LIP6"], ["Gouicem", "Mourad", "", "LIP6"], ["Graillat", "Stef", "", "LIP6"]]}, {"id": "1211.3823", "submitter": "Guillaume Latu", "authors": "Guillaume Latu (IRFM, INRIA Nancy - Grand Est / IECN / LSIIT / IRMA),\n  Marina Becoulet (IRFM), Guilhem Dif-Pradalier (IRFM), Virginie Grandgirard\n  (IRFM), Matthias Hoelzl (IPP Garching), G. Huysmans, Xavier Lacoste (INRIA\n  Bordeaux - Sud-Ouest), Eric Nardon (IRFM), Francois Orain (IRFM), Chantal\n  Passeron (IRFM), Pierre Ramet (INRIA Bordeaux - Sud-Ouest, LaBRI), Ahmed\n  Ratnani (IRFM)", "title": "Non regression testing for the JOREK code", "comments": "No. RR-8134 (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non Regression Testing (NRT) aims to check if software modifications result\nin undesired behaviour. Suppose the behaviour of the application previously\nknown, this kind of test makes it possible to identify an eventual regression,\na bug. Improving and tuning a parallel code can be a time-consuming and\ndifficult task, especially whenever people from different scientific fields\ninteract closely. The JOREK code aims at investing Magnetohydrodynamic (MHD)\ninstabilities in a Tokamak plasma. This paper describes the NRT procedure that\nhas been tuned for this simulation code. Automation of the NRT is one keypoint\nto keeping the code healthy in a source code repository.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2012 08:31:24 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["Latu", "Guillaume", "", "IRFM, INRIA Nancy - Grand Est / IECN / LSIIT / IRMA"], ["Becoulet", "Marina", "", "IRFM"], ["Dif-Pradalier", "Guilhem", "", "IRFM"], ["Grandgirard", "Virginie", "", "IRFM"], ["Hoelzl", "Matthias", "", "IPP Garching"], ["Huysmans", "G.", "", "INRIA\n  Bordeaux - Sud-Ouest"], ["Lacoste", "Xavier", "", "INRIA\n  Bordeaux - Sud-Ouest"], ["Nardon", "Eric", "", "IRFM"], ["Orain", "Francois", "", "IRFM"], ["Passeron", "Chantal", "", "IRFM"], ["Ramet", "Pierre", "", "INRIA Bordeaux - Sud-Ouest, LaBRI"], ["Ratnani", "Ahmed", "", "IRFM"]]}, {"id": "1211.3979", "submitter": "Mohamed Firdhous", "authors": "Mohamed Firdhous and Osman Ghazali and Suhaidi Hassan", "title": "Trust Management in Cloud Computing: A Critical Review", "comments": "13 pages, 1 figure, 1 table, 61 references", "journal-ref": "Publication in the International Journal on Advances in ICT for\n  Emerging Regions (ICTer), vol. 04, no. 02, 2011, pp. 24-36", "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has been attracting the attention of several researchers both\nin the academia and the industry as it provides many opportunities for\norganizations by offering a range of computing services. For cloud computing to\nbecome widely adopted by both the enterprises and individuals, several issues\nhave to be solved. A key issue that needs special attention is security of\nclouds, and trust management is an important component of cloud security. In\nthis paper, the authors look at what trust is and how trust has been applied in\ndistributed computing. Trust models proposed for various distributed system has\nthen been summarized. The trust management systems proposed for cloud computing\nhave been investigated with special emphasis on their capability, applicability\nin practical heterogonous cloud environment and implementabilty. Finally, the\nproposed models/systems have been compared with each other based on a selected\nset of cloud computing parameters in a table.\n", "versions": [{"version": "v1", "created": "Mon, 12 Nov 2012 02:22:54 GMT"}], "update_date": "2012-11-19", "authors_parsed": [["Firdhous", "Mohamed", ""], ["Ghazali", "Osman", ""], ["Hassan", "Suhaidi", ""]]}, {"id": "1211.4055", "submitter": "Bruce Berriman", "authors": "G. Bruce Berriman, Carolyn Brinkworth, Dawn Gelino, Dennis K. Wittman,\n  Ewa Deelman, Gideon Juve, Mats Rynge and Jamie Kinney", "title": "A Tale Of 160 Scientists, Three Applications, A Workshop and A Cloud", "comments": "4 pages, 1 figure, 1 table. Submitted to Astronomical Data Analysis\n  Software and Systems XXII", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The NASA Exoplanet Science Institute (NExScI) hosts the annual Sagan\nWorkshops, thematic meetings aimed at introducing researchers to the latest\ntools and methodologies in exoplanet research. The theme of the Summer 2012\nworkshop, held from July 23 to July 27 at Caltech, was to explore the use of\nexoplanet light curves to study planetary system architectures and atmospheres.\nA major part of the workshop was to use hands-on sessions to instruct attendees\nin the use of three open source tools for the analysis of light curves,\nespecially from the Kepler mission. Each hands-on session involved the 160\nattendees using their laptops to follow step-by-step tutorials given by\nexperts. We describe how we used the Amazon Elastic Cloud 2 to run these\napplications.\n", "versions": [{"version": "v1", "created": "Fri, 16 Nov 2012 22:28:27 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Berriman", "G. Bruce", ""], ["Brinkworth", "Carolyn", ""], ["Gelino", "Dawn", ""], ["Wittman", "Dennis K.", ""], ["Deelman", "Ewa", ""], ["Juve", "Gideon", ""], ["Rynge", "Mats", ""], ["Kinney", "Jamie", ""]]}, {"id": "1211.4101", "submitter": "Gang Liao", "authors": "Gang Liao, Zhi-hui Qin, Long-fei Ma, Qi Sun", "title": "Optimizing Synchronization Algorithm for Auto-parallelizing Compiler", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we focus on the need for two approaches to optimize producer\nand consumer synchronization for auto-parallelizing compiler. Emphasis is\nplaced on the construction of a criterion model by which the compiler reduce\nthe number of synchronization operations needed to synchronize the dependence\nin a loop and perform optimization reduces the overhead of enforcing all\ndependence. In accordance with our study, we transform to modify and eliminate\ndependence on iteration space diagram (ISD), and carry out the problems of\nacyclic and cyclic dependence in detail. we eliminate partial dependence and\noptimize the synchronize instructions. Some didactic examples are included to\nillustrate the optimize procedure.\n", "versions": [{"version": "v1", "created": "Sat, 17 Nov 2012 09:29:17 GMT"}, {"version": "v2", "created": "Mon, 26 Nov 2012 07:15:26 GMT"}, {"version": "v3", "created": "Fri, 1 Mar 2013 03:14:34 GMT"}], "update_date": "2013-03-04", "authors_parsed": [["Liao", "Gang", ""], ["Qin", "Zhi-hui", ""], ["Ma", "Long-fei", ""], ["Sun", "Qi", ""]]}, {"id": "1211.4290", "submitter": "Wojciech Golab", "authors": "Muntasir Raihan Rahman, Wojciech Golab, Alvin AuYoung, Kimberly\n  Keeton, Jay J. Wylie", "title": "Toward a Principled Framework for Benchmarking Consistency", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large-scale key-value storage systems sacrifice consistency in the interest\nof dependability (i.e., partition tolerance and availability), as well as\nperformance (i.e., latency). Such systems provide eventual\nconsistency,which---to this point---has been difficult to quantify in real\nsystems. Given the many implementations and deployments of\neventually-consistent systems (e.g., NoSQL systems), attempts have been made to\nmeasure this consistency empirically, but they suffer from important drawbacks.\nFor example, state-of-the art consistency benchmarks exercise the system only\nin restricted ways and disrupt the workload, which limits their accuracy.\n  In this paper, we take the position that a consistency benchmark should paint\na comprehensive picture of the relationship between the storage system under\nconsideration, the workload, the pattern of failures, and the consistency\nobserved by clients. To illustrate our point, we first survey prior efforts to\nquantify eventual consistency. We then present a benchmarking technique that\novercomes the shortcomings of existing techniques to measure the consistency\nobserved by clients as they execute the workload under consideration. This\nmethod is versatile and minimally disruptive to the system under test. As a\nproof of concept, we demonstrate this tool on Cassandra.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 02:59:53 GMT"}, {"version": "v2", "created": "Tue, 20 Nov 2012 02:25:27 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["Rahman", "Muntasir Raihan", ""], ["Golab", "Wojciech", ""], ["AuYoung", "Alvin", ""], ["Keeton", "Kimberly", ""], ["Wylie", "Jay J.", ""]]}, {"id": "1211.4328", "submitter": "Ragib Hasan", "authors": "Shams Zawoad, Ragib Hasan", "title": "I Have the Proof: Providing Proofs of Past Data Possession in Cloud\n  Forensics", "comments": "To appear at the Proceedings of the 2012 ASE International Conference\n  on Cyber Security", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has emerged as a popular computing paradigm in recent years.\nHowever, today's cloud computing architectures often lack support for computer\nforensic investigations. A key task of digital forensics is to prove the\npresence of a particular file in a given storage system. Unfortunately, it is\nvery hard to do so in a cloud given the black-box nature of clouds and the\nmulti-tenant cloud models. In clouds, analyzing the data from a virtual machine\ninstance or data stored in a cloud storage only allows us to investigate the\ncurrent content of the cloud storage, but not the previous contents. In this\npaper, we introduce the idea of building proofs of past data possession in the\ncontext of a cloud storage service. We present a scheme for creating such\nproofs and evaluate its performance in a real cloud provider. We also discuss\nhow this proof of past data possession can be used effectively in cloud\nforensics.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 08:16:59 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Zawoad", "Shams", ""], ["Hasan", "Ragib", ""]]}, {"id": "1211.4414", "submitter": "Raluca Diaconu", "authors": "Joaqu\\'in Keller, Raluca Diaconu (LIP6), Mathieu Valero (LIP6, INRIA\n  Rocquencourt)", "title": "Towards a Scalable Dynamic Spatial Database System", "comments": "(2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rise of GPS-enabled smartphones and other similar mobile devices,\nmassive amounts of location data are available. However, no scalable solutions\nfor soft real-time spatial queries on large sets of moving objects have yet\nemerged. In this paper we explore and measure the limits of actual algorithms\nand implementations regarding different application scenarios. And finally we\npropose a novel distributed architecture to solve the scalability issues.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 13:43:39 GMT"}], "update_date": "2012-11-20", "authors_parsed": [["Keller", "Joaqu\u00edn", "", "LIP6"], ["Diaconu", "Raluca", "", "LIP6"], ["Valero", "Mathieu", "", "LIP6, INRIA\n  Rocquencourt"]]}, {"id": "1211.4627", "submitter": "Nicolas Kourtellis Ph.D.", "authors": "Nicolas Kourtellis, Jeremy Blackburn, Cristian Borcea and Adriana\n  Iamnitchi", "title": "Enabling Social Applications via Decentralized Social Data Management", "comments": "27 pages, single ACM column, 9 figures, accepted in Special Issue of\n  Foundations of Social Computing, ACM Transactions on Internet Technology", "journal-ref": "ACM Trans. Internet Technol. 15, 1, (March 2015)", "doi": "10.1145/2700057", "report-no": null, "categories": "cs.SI cs.CY cs.DC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An unprecedented information wealth produced by online social networks,\nfurther augmented by location/collocation data, is currently fragmented across\ndifferent proprietary services. Combined, it can accurately represent the\nsocial world and enable novel socially-aware applications. We present\nPrometheus, a socially-aware peer-to-peer service that collects social\ninformation from multiple sources into a multigraph managed in a decentralized\nfashion on user-contributed nodes, and exposes it through an interface\nimplementing non-trivial social inferences while complying with user-defined\naccess policies. Simulations and experiments on PlanetLab with emulated\napplication workloads show the system exhibits good end-to-end response time,\nlow communication overhead and resilience to malicious attacks.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 23:31:58 GMT"}, {"version": "v2", "created": "Tue, 28 Apr 2015 13:25:28 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Kourtellis", "Nicolas", ""], ["Blackburn", "Jeremy", ""], ["Borcea", "Cristian", ""], ["Iamnitchi", "Adriana", ""]]}, {"id": "1211.4720", "submitter": "Priscill Orue Esquivel Ms.", "authors": "Priscill Orue-Esquivel and Bartolom\\'e Rubio", "title": "WiSANCloud: a set of UML-based specifications for the integration of\n  Wireless Sensor and Actor Networks (WSANs) with the Cloud Computing", "comments": "WSAN-Cloud integration proposal, 31 pages, 31 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Giving the current trend to combine the advantages of Wireless Sensor and\nActor Networks (WSANs)with the Cloud Computing technology, this work proposes a\nset of specifications, based on the Unified Modeling Language - UML, in order\nto provide the general framework for the design of the integration of said\ncomponents. One of the keys of the integration is the architecture of the WSAN,\ndue to its structural relationship with the Cloud in the definition of the\ncombination. Regarding the standard applied in the integration, UML and its\nsubset, Systems Modeling Language - SysML, are proposed by the Object\nManagement Group - OMG to deal with cloud applications; so, this indicates the\nstarting point of the process of the design of specifications for WSAN-Cloud\nintegration. Based on the current state of UML tools for analysis and design,\nthere are several aspects to take into account in order to define the\nintegration process.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2012 11:41:10 GMT"}], "update_date": "2012-11-21", "authors_parsed": [["Orue-Esquivel", "Priscill", ""], ["Rubio", "Bartolom\u00e9", ""]]}, {"id": "1211.4864", "submitter": "Salman Habib", "authors": "Salman Habib, Vitali Morozov, Hal Finkel, Adrian Pope, Katrin\n  Heitmann, Kalyan Kumaran, Tom Peterka, Joe Insley, David Daniel, Patricia\n  Fasel, Nicholas Frontiere, and Zarija Lukic", "title": "The Universe at Extreme Scale: Multi-Petaflop Sky Simulation on the BG/Q", "comments": "11 pages, 11 figures, final version of paper for talk presented at\n  SC12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC astro-ph.CO astro-ph.IM cs.PF physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remarkable observational advances have established a compelling\ncross-validated model of the Universe. Yet, two key pillars of this model --\ndark matter and dark energy -- remain mysterious. Sky surveys that map billions\nof galaxies to explore the `Dark Universe', demand a corresponding\nextreme-scale simulation capability; the HACC (Hybrid/Hardware Accelerated\nCosmology Code) framework has been designed to deliver this level of\nperformance now, and into the future. With its novel algorithmic structure,\nHACC allows flexible tuning across diverse architectures, including accelerated\nand multi-core systems.\n  On the IBM BG/Q, HACC attains unprecedented scalable performance -- currently\n13.94 PFlops at 69.2% of peak and 90% parallel efficiency on 1,572,864 cores\nwith an equal number of MPI ranks, and a concurrency of 6.3 million. This level\nof performance was achieved at extreme problem sizes, including a benchmark run\nwith more than 3.6 trillion particles, significantly larger than any\ncosmological simulation yet performed.\n", "versions": [{"version": "v1", "created": "Mon, 19 Nov 2012 23:23:22 GMT"}], "update_date": "2012-11-28", "authors_parsed": [["Habib", "Salman", ""], ["Morozov", "Vitali", ""], ["Finkel", "Hal", ""], ["Pope", "Adrian", ""], ["Heitmann", "Katrin", ""], ["Kumaran", "Kalyan", ""], ["Peterka", "Tom", ""], ["Insley", "Joe", ""], ["Daniel", "David", ""], ["Fasel", "Patricia", ""], ["Frontiere", "Nicholas", ""], ["Lukic", "Zarija", ""]]}, {"id": "1211.4896", "submitter": "Amr Hassan", "authors": "A. H. Hassan, C. J. Fluke, D. G. Barnes, and V. A. Kilborn", "title": "Tera-scale Astronomical Data Analysis and Visualization", "comments": "16 pages, 14 Figures, accepted for publication in Monthly Notices of\n  the Royal Astronomical Society", "journal-ref": null, "doi": "10.1093/mnras/sts513", "report-no": null, "categories": "astro-ph.IM cs.DC cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a high-performance, graphics processing unit (GPU)-based framework\nfor the efficient analysis and visualization of (nearly) terabyte (TB)-sized\n3-dimensional images. Using a cluster of 96 GPUs, we demonstrate for a 0.5 TB\nimage: (1) volume rendering using an arbitrary transfer function at 7--10\nframes per second; (2) computation of basic global image statistics such as the\nmean intensity and standard deviation in 1.7 s; (3) evaluation of the image\nhistogram in 4 s; and (4) evaluation of the global image median intensity in\njust 45 s. Our measured results correspond to a raw computational throughput\napproaching one teravoxel per second, and are 10--100 times faster than the\nbest possible performance with traditional single-node, multi-core CPU\nimplementations. A scalability analysis shows the framework will scale well to\nimages sized 1 TB and beyond. Other parallel data analysis algorithms can be\nadded to the framework with relative ease, and accordingly, we present our\nframework as a possible solution to the image analysis and visualization\nrequirements of next-generation telescopes, including the forthcoming Square\nKilometre Array pathfinder radiotelescopes.\n", "versions": [{"version": "v1", "created": "Tue, 20 Nov 2012 23:00:51 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Hassan", "A. H.", ""], ["Fluke", "C. J.", ""], ["Barnes", "D. G.", ""], ["Kilborn", "V. A.", ""]]}, {"id": "1211.5227", "submitter": "Vishnuvardhan Mannava M.E", "authors": "Vishnuvardhan Mannava and T. Ramesh", "title": "Service Composition Design Pattern for Autonomic Computing Systems using\n  Association Rule based Learning and Service-Oriented Architecture", "comments": "19 pages, 7 figures, International Journal of Grid Computing &\n  Applications (IJGCA). arXiv admin note: text overlap with arXiv:1208.3836", "journal-ref": "IJGCA, 3(3), 21-39 (2012)", "doi": null, "report-no": null, "categories": "cs.SE cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper we present a Service Injection and composition Design Pattern\nfor Unstructured Peer-to-Peer networks, which is designed with Aspect-oriented\ndesign patterns, and amalgamation of the Strategy, Worker Object, and\nCheck-List Design Patterns used to design the Self-Adaptive Systems. It will\napply self reconfiguration planes dynamically without the interruption or\nintervention of the administrator for handling service failures at the servers.\nWhen a client requests for a complex service, Service Composition should be\ndone to fulfil the request. If a service is not available in the memory, it\nwill be injected as Aspectual Feature Module code. We used Service Oriented\nArchitecture (SOA) with Web Services in Java to Implement the composite Design\nPattern. As far as we know, there are no studies on composition of design\npatterns for Peer-to-peer computing domain. The pattern is described using a\njava-like notation for the classes and interfaces. A simple UML class and\nSequence diagrams are depicted.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2012 08:33:09 GMT"}], "update_date": "2015-06-01", "authors_parsed": [["Mannava", "Vishnuvardhan", ""], ["Ramesh", "T.", ""]]}, {"id": "1211.5481", "submitter": "Stefano Cavuoti", "authors": "Stefano Cavuoti, Mauro Garofalo, Massimo Brescia, Antonio Pescap\\'e,\n  Giuseppe Longo, and Giorgio Ventre", "title": "Genetic Algorithm Modeling with GPU Parallel Computing Technology", "comments": "11 pages, 2 figures, refereed proceedings; Neural Nets and\n  Surroundings, Proceedings of 22nd Italian Workshop on Neural Nets, WIRN 2012;\n  Smart Innovation, Systems and Technologies, Vol. 19, Springer", "journal-ref": null, "doi": "10.1007/978-3-642-35467-0_4", "report-no": null, "categories": "astro-ph.IM cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-purpose genetic algorithm, designed and implemented with\nGPGPU / CUDA parallel computing technology. The model was derived from a\nmulti-core CPU serial implementation, named GAME, already scientifically\nsuccessfully tested and validated on astrophysical massive data classification\nproblems, through a web application resource (DAMEWARE), specialized in data\nmining based on Machine Learning paradigms. Since genetic algorithms are\ninherently parallel, the GPGPU computing paradigm has provided an exploit of\nthe internal training features of the model, permitting a strong optimization\nin terms of processing performances and scalability.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2012 12:21:38 GMT"}], "update_date": "2015-01-30", "authors_parsed": [["Cavuoti", "Stefano", ""], ["Garofalo", "Mauro", ""], ["Brescia", "Massimo", ""], ["Pescap\u00e9", "Antonio", ""], ["Longo", "Giuseppe", ""], ["Ventre", "Giorgio", ""]]}, {"id": "1211.5530", "submitter": "Sabri Pllana", "authors": "Jiri Dokulil, Enes Bajrovic, Siegfried Benkner, Sabri Pllana, Martin\n  Sandrieser, Beverly Bachmayer", "title": "Efficient Hybrid Execution of C++ Applications using Intel(R) Xeon\n  Phi(TM) Coprocessor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The introduction of Intel(R) Xeon Phi(TM) coprocessors opened up new\npossibilities in development of highly parallel applications. The familiarity\nand flexibility of the architecture together with compiler support integrated\ninto the Intel C++ Composer XE allows the developers to use familiar\nprogramming paradigms and techniques, which are usually not suitable for other\naccelerated systems. It is now easy to use complex C++ template-heavy codes on\nthe coprocessor, including for example the Intel Threading Building Blocks\n(TBB) parallelization library. These techniques are not only possible, but\nusually efficient as well, since host and coprocessor are of the same\narchitectural family, making optimization techniques designed for the Xeon CPU\nalso beneficial on Xeon Phi. As a result, highly optimized Xeon codes (like the\nTBB library) work well on both.\n  In this paper we present a new parallel library construct, which makes it\neasy to apply a function to every member of an array in parallel, dynamically\ndistributing the work between the host CPUs and one or more coprocessor cards.\nWe describe the associated runtime support and use a physical simulation\nexample to demonstrate that our library construct can be used to quickly create\na C++ application that will significantly benefit from hybrid execution,\nsimultaneously exploiting CPU cores and coprocessor cores. Experimental results\nshow that one optimized source code is sufficient to make the host and the\ncoprocessors run efficiently.\n", "versions": [{"version": "v1", "created": "Fri, 23 Nov 2012 15:42:45 GMT"}], "update_date": "2012-11-26", "authors_parsed": [["Dokulil", "Jiri", ""], ["Bajrovic", "Enes", ""], ["Benkner", "Siegfried", ""], ["Pllana", "Sabri", ""], ["Sandrieser", "Martin", ""], ["Bachmayer", "Beverly", ""]]}, {"id": "1211.5596", "submitter": "Vishnuvardhan Mannava M.E", "authors": "Vishnuvardhan Mannava and T. Ramesh", "title": "A Composite Design Pattern for Service Injection and Composition of Web\n  Services for Peer-To-Peer Computing with Service Oriented Architecture", "comments": "15 pages, 9 figures, International Journal on Web Service Computing\n  (IJWSC). arXiv admin note: substantial text overlap with arXiv:1208.3836,\n  arXiv:1211.5227", "journal-ref": "International Journal on Web Service Computing 3 (3), 49-63, 2012", "doi": "10.5121/ijwsc", "report-no": null, "categories": "cs.SE cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  In this paper we present a Service Injection and composition Design Pattern\nfor Unstructured Peer-to-Peer networks, which is designed with Aspect-oriented\ndesign patterns, and amalgamation of the Strategy, Worker Object, and\nCheck-List Design Patterns used to design the Self-Adaptive Systems. It will\napply self reconfiguration planes dynamically without the interruption or\nintervention of the administrator for handling service failures at the servers.\nWhen a client requests for a complex service, Service Composition should be\ndone to fulfil the request. If a service is not available in the memory, it\nwill be injected as Aspectual Feature Module code. We used Service Oriented\nArchitecture (SOA) with Web Services in Java to Implement the composite Design\nPattern. As far as we know, there are no studies on composition of design\npatterns for Peer-to-peer computing domain. The pattern is described using a\njava-like notation for the classes and interfaces. A simple UML class and\nSequence diagrams are depicted.\n", "versions": [{"version": "v1", "created": "Thu, 22 Nov 2012 08:55:25 GMT"}], "update_date": "2012-12-13", "authors_parsed": [["Mannava", "Vishnuvardhan", ""], ["Ramesh", "T.", ""]]}, {"id": "1211.5747", "submitter": "Majed ValadBeigi", "authors": "Majed ValadBeigi, Farshad Safaei and Bahareh Pourshirazi", "title": "DBR: A Simple, Fast and Efficient Dynamic Network Reconfiguration\n  Mechanism Based on Deadlock Recovery Scheme", "comments": "14 pages, 8 figures, 1 table", "journal-ref": "International Journal of VLSI design & Communication Systems\n  (VLSICS) Vol.3, No.5, 2012, 13-26", "doi": "10.5121/vlsic.2012.3502", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Dynamic network reconfiguration is described as the process of replacing one\nrouting function with another while the network keeps running. The main\nchallenge is avoiding deadlock anomalies while keeping limitations on message\ninjection and forwarding minimal. Current approaches, whose complexity is so\nhigh that their practical applicability is limited, either require the\nexistence of extra network resources like virtual channels, or they affect the\nperformance of the network during the reconfiguration process. In this paper we\npresent a simple, fast and efficient mechanism for dynamic network\nreconfiguration which is based on regressive deadlock recoveries instead of\navoiding deadlocks. The mechanism which is referred to as DBR guarantees a\ndeadlock-free reconfiguration based on wormhole switching (WS) and it does not\nrequire additional resources. In this approach, the need for a reliable message\ntransmission has led to a modified WS mechanism which includes additional flits\nor control signals. DBR allows cycles to be formed and in such conditions when\na deadlock occurs, the messages suffer from time-out. Then, this method\nreleases the buffers and channels from the current node and thus the source\nretransmits the message after a random time gap. Evaluating results reveal that\nthe mechanism shows substantial performance improvements over the other methods\nand it works efficiently in different topologies with various routing\nalgorithms.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2012 09:31:50 GMT"}], "update_date": "2012-11-27", "authors_parsed": [["ValadBeigi", "Majed", ""], ["Safaei", "Farshad", ""], ["Pourshirazi", "Bahareh", ""]]}, {"id": "1211.5787", "submitter": "Amos Korman", "authors": "Ofer Feinerman and Amos Korman and Shay Kutten and Yoav Rodeh", "title": "Fast Rendezvous on a Cycle by Agents with Different Speeds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The difference between the speed of the actions of different processes is\ntypically considered as an obstacle that makes the achievement of cooperative\ngoals more difficult. In this work, we aim to highlight potential benefits of\nsuch asynchrony phenomena to tasks involving symmetry breaking. Specifically,\nin this paper, identical (except for their speeds) mobile agents are placed at\narbitrary locations on a cycle of length $n$ and use their speed difference in\norder to rendezvous fast. We normalize the speed of the slower agent to be 1,\nand fix the speed of the faster agent to be some $c>1$. (An agent does not know\nwhether it is the slower agent or the faster one.) The straightforward\ndistributed-race DR algorithm is the one in which both agents simply start\nwalking until rendezvous is achieved. It is easy to show that, in the worst\ncase, the rendezvous time of DR is $n/(c-1)$. Note that in the interesting\ncase, where $c$ is very close to 1 this bound becomes huge. Our first result is\na lower bound showing that, up to a multiplicative factor of 2, this bound is\nunavoidable, even in a model that allows agents to leave arbitrary marks, even\nassuming sense of direction, and even assuming $n$ and $c$ are known to agents.\nThat is, we show that under such assumptions, the rendezvous time of any\nalgorithm is at least $\\frac{n}{2(c-1)}$ if $c\\leq 3$ and slightly larger if\n$c>3$. We then construct an algorithm that precisely matches the lower bound\nfor the case $c\\leq 2$, and almost matches it when $c>2$. Moreover, our\nalgorithm performs under weaker assumptions than those stated above, as it does\nnot assume sense of direction, and it allows agents to leave only a single mark\n(a pebble) and only at the place where they start the execution. Finally, we\ninvestigate the setting in which no marks can be used at all, and show tight\nbounds for $c\\leq 2$, and almost tight bounds for $c>2$.\n", "versions": [{"version": "v1", "created": "Sun, 25 Nov 2012 17:49:28 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2015 16:35:47 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Feinerman", "Ofer", ""], ["Korman", "Amos", ""], ["Kutten", "Shay", ""], ["Rodeh", "Yoav", ""]]}, {"id": "1211.6315", "submitter": "Petr  Kuznetsov", "authors": "Petr Kuznetsov and Sathya Peri", "title": "Non-Interference and Local Correctness in Transactional Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transactional memory promises to make concurrent programming tractable and\nefficient by allowing the user to assemble sequences of actions in atomic\ntransactions with all-or-nothing semantics. It is believed that, by its very\nvirtue, transactional memory must ensure that all committed transactions\nconstitute a serial execution respecting the real-time order. In contrast,\naborted or incomplete transactions should not \"take effect.\" But what does \"not\ntaking effect\" mean exactly?\n  It seems natural to expect that aborted or incomplete transactions do not\nappear in the global serial execution, and, thus, no committed transaction can\nbe affected by them. We investigate another, less obvious, feature of \"not\ntaking effect\" called non-interference: aborted or incomplete transactions\nshould not force any other transaction to abort. In the strongest form of\nnon-interference that we explore in this paper, by removing a subset of aborted\nor incomplete transactions from the history, we should not be able to turn an\naborted transaction into a committed one without violating the correctness\ncriterion.\n  We show that non-interference is, in a strict sense, not implementable with\nrespect to the popular criterion of opacity that requires all transactions (be\nthey committed, aborted or incomplete) to witness the same global serial\nexecution. In contrast, when we only require local correctness,\nnon-interference is implementable. Informally, a correctness criterion is local\nif it only requires that every transaction can be serialized along with (a\nsubset of) the transactions committed before its last event (aborted or\nincomplete transactions ignored). We give a few examples of local correctness\nproperties, including the recently proposed criterion of virtual world\nconsistency, and present a simple though efficient implementation that\nsatisfies non-interference and local opacity.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2012 14:31:06 GMT"}, {"version": "v2", "created": "Fri, 7 Dec 2012 22:15:53 GMT"}, {"version": "v3", "created": "Fri, 11 Jan 2013 12:29:37 GMT"}, {"version": "v4", "created": "Mon, 27 May 2013 13:51:56 GMT"}, {"version": "v5", "created": "Sat, 12 Oct 2013 12:23:21 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Kuznetsov", "Petr", ""], ["Peri", "Sathya", ""]]}, {"id": "1211.6473", "submitter": "Christophe Cerin", "authors": "Christophe C\\'erin (LIPN), Alain Takoudjou (LIPN), Nicolas Gren\\`eche\n  (LIPN)", "title": "Int\\'egration des intergiciels de grilles de PC dans le nuage SlapOS :\n  le cas de BOINC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we describe the problems and solutions related to the\nintegration of desktop grid middleware in a cloud, in this case the open source\nSlapOS cloud. We focus on the issues about recipes that describe the\nintegration and the problem of the confinement of execution. They constitute\ntwo aspects of service-oriented architecture and Cloud Computing. These two\nissues solved with SlapOS are not in relation to what is traditionally done in\nthe clouds because we do not rely on virtual machines and, there is no data\ncenter (as defined in cloud). Moreover, we show that from the initial\ndeployment model we take into account not only Web applications, B2B\napplications... but also applications from the field of grids; here desktop\ngrid middleware which is a case study.\n", "versions": [{"version": "v1", "created": "Tue, 27 Nov 2012 23:05:10 GMT"}], "update_date": "2012-11-29", "authors_parsed": [["C\u00e9rin", "Christophe", "", "LIPN"], ["Takoudjou", "Alain", "", "LIPN"], ["Gren\u00e8che", "Nicolas", "", "LIPN"]]}, {"id": "1211.6526", "submitter": "Ashish Goel", "authors": "Ashish Goel and Kamesh Munagala", "title": "Complexity Measures for Map-Reduce, and Comparison to Parallel Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The programming paradigm Map-Reduce and its main open-source implementation,\nHadoop, have had an enormous impact on large scale data processing. Our goal in\nthis expository writeup is two-fold: first, we want to present some complexity\nmeasures that allow us to talk about Map-Reduce algorithms formally, and\nsecond, we want to point out why this model is actually different from other\nmodels of parallel programming, most notably the PRAM (Parallel Random Access\nMemory) model. We are looking for complexity measures that are detailed enough\nto make fine-grained distinction between different algorithms, but which also\nabstract away many of the implementation details.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2012 06:03:24 GMT"}], "update_date": "2012-11-29", "authors_parsed": [["Goel", "Ashish", ""], ["Munagala", "Kamesh", ""]]}, {"id": "1211.6778", "submitter": "Nikolai Krivulin", "authors": "Sergei M. Ermakov, Nikolai K. Krivulin", "title": "Efficient parallel algorithms for tandem queueing system simulation", "comments": "The 3rd Beijing International Conference on System Simulation and\n  Scientific Computing, October 17-19, 1995, Beijing, China", "journal-ref": "Proceedings of the 3rd Beijing International Conference on System\n  Simulation and Scientific Computing: Delayed papers / Ed. by Xingren Wang et\n  al. International Academic Publishers, 1995, pp. 8-12", "doi": null, "report-no": null, "categories": "math.NA cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel algorithms designed for simulation and performance evaluation of\nsingle-server tandem queueing systems with both infinite and finite buffers are\npresented. The algorithms exploit a simple computational procedure based on\nrecursive equations as a representation of system dynamics. A brief analysis of\nthe performance of the algorithms are given to show that they involve low time\nand memory requirements.\n", "versions": [{"version": "v1", "created": "Wed, 28 Nov 2012 23:04:55 GMT"}], "update_date": "2012-11-30", "authors_parsed": [["Ermakov", "Sergei M.", ""], ["Krivulin", "Nikolai K.", ""]]}, {"id": "1211.7277", "submitter": "Cl\\'audia Soares", "authors": "Claudia Soares and Joao Xavier and Joao Gomes", "title": "DCOOL-NET: Distributed cooperative localization for sensor networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DCOOL-NET, a scalable distributed in-network algorithm for sensor\nnetwork localization based on noisy range measurements. DCOOL-NET operates by\nparallel, collaborative message passing between single-hop neighbor sensors,\nand involves simple computations at each node. It stems from an application of\nthe majorization-minimization (MM) framework to the nonconvex optimization\nproblem at hand, and capitalizes on a novel convex majorizer. The proposed\nmajorizer is endowed with several desirable properties and represents a key\ncontribution of this work. It is a more accurate match to the underlying\nnonconvex cost function than popular MM quadratic majorizers, and is readily\namenable to distributed minimization via the alternating direction method of\nmultipliers (ADMM). Moreover, it allows for low-complexity, fast Nesterov\ngradient methods to tackle the ADMM subproblems induced at each node. Computer\nsimulations show that DCOOL-NET achieves comparable or better sensor position\naccuracies than a state-of-art method which, furthermore, is not parallel.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2012 14:54:43 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Soares", "Claudia", ""], ["Xavier", "Joao", ""], ["Gomes", "Joao", ""]]}, {"id": "1211.7309", "submitter": "Elad Gilboa Elad Gilboa", "authors": "Elad Gilboa, Phani Chavali, Peng Yang, Arye Nehorai", "title": "Distributed Optimization via Adaptive Regularization for Large Problems\n  with Separable Constraints", "comments": "5 Pages, 2 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many practical applications require solving an optimization over large and\nhigh-dimensional data sets, which makes these problems hard to solve and\nprohibitively time consuming. In this paper, we propose a parallel distributed\nalgorithm that uses an adaptive regularizer (PDAR) to solve a joint\noptimization problem with separable constraints. The regularizer is adaptive\nand depends on the step size between iterations and the iteration number. We\nshow theoretical converge of our algorithm to an optimal solution, and use a\nmulti-agent three-bin resource allocation example to illustrate the\neffectiveness of the proposed algorithm. Numerical simulations show that our\nalgorithm converges to the same optimal solution as other distributed methods,\nwith significantly reduced computational time.\n", "versions": [{"version": "v1", "created": "Fri, 30 Nov 2012 16:58:43 GMT"}], "update_date": "2012-12-03", "authors_parsed": [["Gilboa", "Elad", ""], ["Chavali", "Phani", ""], ["Yang", "Peng", ""], ["Nehorai", "Arye", ""]]}]