[{"id": "1703.00042", "submitter": "Vicky Steeves", "authors": "Andreas Wolke, Martin Bichler, Fernando Chirigati, Victoria Steeves", "title": "Reproducible experiments on dynamic resource allocation in cloud data\n  centers", "comments": null, "journal-ref": "Information Systems, Volume 59, July 2016, Pages 98-101, ISSN\n  0306-4379", "doi": "10.1016/j.is.2015.12.004", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In Wolke et al. [1] we compare the efficiency of different resource\nallocation strategies experimentally. We focused on dynamic environments where\nvirtual machines need to be allocated and deallocated to servers over time. In\nthis companion paper, we describe the simulation framework and how to run\nsimulations to replicate experiments or run new experiments within the\nframework.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 20:25:09 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Wolke", "Andreas", ""], ["Bichler", "Martin", ""], ["Chirigati", "Fernando", ""], ["Steeves", "Victoria", ""]]}, {"id": "1703.00185", "submitter": "Alessandro Gabbana", "authors": "E. Calore, A. Gabbana, J. Kraus, E. Pellegrini, S.F. Schifano, R.\n  Tripiccione", "title": "Massively parallel lattice-Boltzmann codes on large GPU clusters", "comments": null, "journal-ref": null, "doi": "10.1016/j.parco.2016.08.005", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a massively parallel code for a state-of-the art thermal\nlattice- Boltzmann method. Our code has been carefully optimized for\nperformance on one GPU and to have a good scaling behavior extending to a large\nnumber of GPUs. Versions of this code have been already used for large-scale\nstudies of convective turbulence. GPUs are becoming increasingly popular in HPC\napplications, as they are able to deliver higher performance than traditional\nprocessors. Writing efficient programs for large clusters is not an easy task\nas codes must adapt to increasingly parallel architectures, and the overheads\nof node-to-node communications must be properly handled. We describe the\nstructure of our code, discussing several key design choices that were guided\nby theoretical models of performance and experimental benchmarks. We present an\nextensive set of performance measurements and identify the corresponding main\nbot- tlenecks; finally we compare the results of our GPU code with those\nmeasured on other currently available high performance processors. Our results\nare a production-grade code able to deliver a sustained performance of several\ntens of Tflops as well as a design and op- timization methodology that can be\nused for the development of other high performance applications for\ncomputational physics.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 08:59:48 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Calore", "E.", ""], ["Gabbana", "A.", ""], ["Kraus", "J.", ""], ["Pellegrini", "E.", ""], ["Schifano", "S. F.", ""], ["Tripiccione", "R.", ""]]}, {"id": "1703.00186", "submitter": "Alessandro Gabbana", "authors": "E. Calore, A. Gabbana, J. Kraus, S. F. Schifano, R. Tripiccione", "title": "Performance and Portability of Accelerated Lattice Boltzmann\n  Applications with OpenACC", "comments": null, "journal-ref": null, "doi": "10.1002/cpe.3862", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasingly large number of HPC systems rely on heterogeneous\narchitectures combining traditional multi-core CPUs with power efficient\naccelerators. Designing efficient applications for these systems has been\ntroublesome in the past as accelerators could usually be programmed using\nspecific programming languages threatening maintainability, portability and\ncorrectness. Several new programming environments try to tackle this problem.\nAmong them, OpenACC offers a high-level approach based on compiler directive\nclauses to mark regions of existing C, C++ or Fortran codes to run on\naccelerators. This approach directly addresses code portability, leaving to\ncompilers the support of each different accelerator, but one has to carefully\nassess the relative costs of portable approaches versus computing efficiency.\nIn this paper we address precisely this issue, using as a test-bench a\nmassively parallel Lattice Boltzmann algorithm. We first describe our\nmulti-node implementation and optimization of the algorithm, using OpenACC and\nMPI. We then benchmark the code on a variety of processors, including\ntraditional CPUs and GPUs, and make accurate performance comparisons with other\nGPU implementations of the same algorithm using CUDA and OpenCL. We also asses\nthe performance impact associated to portable programming, and the actual\nportability and performance-portability of OpenACC-based applications across\nseveral state-of-the- art architectures.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 09:00:46 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Calore", "E.", ""], ["Gabbana", "A.", ""], ["Kraus", "J.", ""], ["Schifano", "S. F.", ""], ["Tripiccione", "R.", ""]]}, {"id": "1703.00374", "submitter": "Swapnil Parikh Mr.", "authors": "Swapnil M Parikh, Narendra M Patel and Harshadkumar B Prajapati", "title": "Resource Management in Cloud Computing: Classification and Taxonomy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Computing is a new era of remote computing / Internet based computing\nwhere one can access their personal resources easily from any computer through\nInternet. Cloud delivers computing as a utility as it is available to the cloud\nconsumers on demand. It is a simple pay-per-use consumer-provider service\nmodel. It contains large number of shared resources. So Resource Management is\nalways a major issue in cloud computing like any other computing paradigm. Due\nto the availability of finite resources it is very challenging for cloud\nproviders to provide all the requested resources. From the cloud providers\nperspective cloud resources must be allocated in a fair and efficient manner.\nResearch Survey is not available from the perspective of resource management as\na process in cloud computing. So this research paper provides a detailed\nsequential view / steps on resource management in cloud computing. Firstly this\nresearch paper classifies various resources in cloud computing. It also gives\ntaxonomy on resource management in cloud computing through which one can do\nfurther research. Lastly comparisons on various resource management algorithms\nhas been presented.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 11:39:59 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Parikh", "Swapnil M", ""], ["Patel", "Narendra M", ""], ["Prajapati", "Harshadkumar B", ""]]}, {"id": "1703.00375", "submitter": "Yehia Elkhatib PhD", "authors": "Yehia Elkhatib and Barry Porter and Heverson B. Ribeiro and Mohamed\n  Faten Zhani and Junaid Qadir and Etienne Riviere", "title": "On Using Micro-Clouds to Deliver the Fog", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has demonstrated itself to be a scalable and cost-efficient\nsolution for many real-world applications. However, its modus operandi is not\nideally suited to resource-constrained environments that are characterized by\nlimited network bandwidth and high latencies. With the increasing proliferation\nand sophistication of edge devices, the idea of fog computing proposes to\noffload some of the computation to the edge. To this end, micro-clouds---which\nare modular and portable assemblies of small single-board computers---have\nstarted to gain attention as infrastructures to support fog computing by\noffering isolated resource provisioning at the edge in a cost-effective way. We\ninvestigate the feasibility and readiness of micro-clouds for delivering the\nvision of fog computing. Through a number of experiments, we showcase the\npotential of micro-clouds formed by collections of Raspberry Pi computers to\nhost a range of fog-related applications, particularly for locations where\nthere is limited network bandwidths and long latencies.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 10:26:59 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Elkhatib", "Yehia", ""], ["Porter", "Barry", ""], ["Ribeiro", "Heverson B.", ""], ["Zhani", "Mohamed Faten", ""], ["Qadir", "Junaid", ""], ["Riviere", "Etienne", ""]]}, {"id": "1703.00403", "submitter": "Brian McWilliams", "authors": "Christina Heinze-Deml, Brian McWilliams, Nicolai Meinshausen", "title": "Preserving Differential Privacy Between Features in Distributed\n  Estimation", "comments": null, "journal-ref": "Stat 7 (1), 2018", "doi": "10.1002/sta4.189", "report-no": null, "categories": "stat.ML cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Privacy is crucial in many applications of machine learning. Legal, ethical\nand societal issues restrict the sharing of sensitive data making it difficult\nto learn from datasets that are partitioned between many parties. One important\ninstance of such a distributed setting arises when information about each\nrecord in the dataset is held by different data owners (the design matrix is\n\"vertically-partitioned\").\n  In this setting few approaches exist for private data sharing for the\npurposes of statistical estimation and the classical setup of differential\nprivacy with a \"trusted curator\" preparing the data does not apply. We work\nwith the notion of $(\\epsilon,\\delta)$-distributed differential privacy which\nextends single-party differential privacy to the distributed,\nvertically-partitioned case. We propose PriDE, a scalable framework for\ndistributed estimation where each party communicates perturbed random\nprojections of their locally held features ensuring\n$(\\epsilon,\\delta)$-distributed differential privacy is preserved. For\n$\\ell_2$-penalized supervised learning problems PriDE has bounded estimation\nerror compared with the optimal estimates obtained without privacy constraints\nin the non-distributed setting. We confirm this empirically on real world and\nsynthetic datasets.\n", "versions": [{"version": "v1", "created": "Wed, 1 Mar 2017 17:30:14 GMT"}, {"version": "v2", "created": "Tue, 27 Jun 2017 08:59:48 GMT"}], "update_date": "2018-09-21", "authors_parsed": [["Heinze-Deml", "Christina", ""], ["McWilliams", "Brian", ""], ["Meinshausen", "Nicolai", ""]]}, {"id": "1703.00626", "submitter": "Onur Mutlu", "authors": "Onur Mutlu", "title": "The RowHammer Problem and Other Issues We May Face as Memory Becomes\n  Denser", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As memory scales down to smaller technology nodes, new failure mechanisms\nemerge that threaten its correct operation. If such failure mechanisms are not\nanticipated and corrected, they can not only degrade system reliability and\navailability but also, perhaps even more importantly, open up security\nvulnerabilities: a malicious attacker can exploit the exposed failure mechanism\nto take over the entire system. As such, new failure mechanisms in memory can\nbecome practical and significant threats to system security.\n  In this work, we discuss the RowHammer problem in DRAM, which is a prime (and\nperhaps the first) example of how a circuit-level failure mechanism in DRAM can\ncause a practical and widespread system security vulnerability. RowHammer, as\nit is popularly referred to, is the phenomenon that repeatedly accessing a row\nin a modern DRAM chip causes bit flips in physically-adjacent rows at\nconsistently predictable bit locations. It is caused by a hardware failure\nmechanism called DRAM disturbance errors, which is a manifestation of\ncircuit-level cell-to-cell interference in a scaled memory technology. We\nanalyze the root causes of the RowHammer problem and examine various solutions.\nWe also discuss what other vulnerabilities may be lurking in DRAM and other\ntypes of memories, e.g., NAND flash memory or Phase Change Memory, that can\npotentially threaten the foundations of secure systems, as the memory\ntechnologies scale to higher densities. We conclude by describing and\nadvocating a principled approach to memory reliability and security research\nthat can enable us to better anticipate and prevent such vulnerabilities.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 05:19:38 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Mutlu", "Onur", ""]]}, {"id": "1703.00687", "submitter": "Sebastian Deorowicz", "authors": "Marek Kokot and Sebastian Deorowicz and Maciej Dlugosz", "title": "Even faster sorting of (not only) integers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce RADULS2, the fastest parallel sorter based on\nradix algorithm. It is optimized to process huge amounts of data making use of\nmodern multicore CPUs. The main novelties include: extremely optimized\nalgorithm for handling tiny arrays (up to about a hundred of records) that\ncould appear even billions times as subproblems to handle and improved\nprocessing of larger subarrays with better use of non-temporal memory stores.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 09:54:11 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Kokot", "Marek", ""], ["Deorowicz", "Sebastian", ""], ["Dlugosz", "Maciej", ""]]}, {"id": "1703.00690", "submitter": "Sebastian Deorowicz", "authors": "Maciej Dlugosz and Sebastian Deorowicz and Marek Kokot", "title": "Even better correction of genome sequencing data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an improved version of RECKONER, an error corrector for Illumina\nwhole genome sequencing data. By modifying its workflow we reduce the\ncomputation time even 10 times. We also propose a new method of determination\nof $k$-mer length, the key parameter of $k$-spectrum-based family of\ncorrectors. The correction algorithms are examined on huge data sets, i.e.,\nhuman and maize genomes for both Illumina HiSeq and MiSeq instruments.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 10:03:11 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Dlugosz", "Maciej", ""], ["Deorowicz", "Sebastian", ""], ["Kokot", "Marek", ""]]}, {"id": "1703.00734", "submitter": "Xiangju Qin", "authors": "Xiangju Qin, Paul Blomstedt, Eemeli Lepp\\\"aaho, Pekka Parviainen,\n  Samuel Kaski", "title": "Distributed Bayesian Matrix Factorization with Limited Communication", "comments": "28 pages, 8 figures. The paper is published in Machine Learning\n  journal. An implementation of the method is is available in SMURFF software\n  on github (bmfpp branch): https://github.com/ExaScience/smurff", "journal-ref": "Machine Learning, 2019", "doi": "10.1007/s10994-019-05778-2", "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NA stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bayesian matrix factorization (BMF) is a powerful tool for producing low-rank\nrepresentations of matrices and for predicting missing values and providing\nconfidence intervals. Scaling up the posterior inference for massive-scale\nmatrices is challenging and requires distributing both data and computation\nover many workers, making communication the main computational bottleneck.\nEmbarrassingly parallel inference would remove the communication needed, by\nusing completely independent computations on different data subsets, but it\nsuffers from the inherent unidentifiability of BMF solutions. We introduce a\nhierarchical decomposition of the joint posterior distribution, which couples\nthe subset inferences, allowing for embarrassingly parallel computations in a\nsequence of at most three stages. Using an efficient approximate\nimplementation, we show improvements empirically on both real and simulated\ndata. Our distributed approach is able to achieve a speed-up of almost an order\nof magnitude over the full posterior, with a negligible effect on predictive\naccuracy. Our method outperforms state-of-the-art embarrassingly parallel MCMC\nmethods in accuracy, and achieves results competitive to other available\ndistributed and parallel implementations of BMF.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 11:48:24 GMT"}, {"version": "v2", "created": "Tue, 13 Feb 2018 09:47:09 GMT"}, {"version": "v3", "created": "Fri, 28 Dec 2018 18:58:59 GMT"}, {"version": "v4", "created": "Wed, 27 Feb 2019 17:07:21 GMT"}], "update_date": "2019-02-28", "authors_parsed": [["Qin", "Xiangju", ""], ["Blomstedt", "Paul", ""], ["Lepp\u00e4aho", "Eemeli", ""], ["Parviainen", "Pekka", ""], ["Kaski", "Samuel", ""]]}, {"id": "1703.00830", "submitter": "Colin White", "authors": "Pranjal Awasthi, Ainesh Bakshi, Maria-Florina Balcan, Colin White, and\n  David Woodruff", "title": "Robust Communication-Optimal Distributed Clustering Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study the $k$-median and $k$-means clustering problems when\nthe data is distributed across many servers and can contain outliers. While\nthere has been a lot of work on these problems for worst-case instances, we\nfocus on gaining a finer understanding through the lens of beyond worst-case\nanalysis. Our main motivation is the following: for many applications such as\nclustering proteins by function or clustering communities in a social network,\nthere is some unknown target clustering, and the hope is that running a\n$k$-median or $k$-means algorithm will produce clusterings which are close to\nmatching the target clustering. Worst-case results can guarantee constant\nfactor approximations to the optimal $k$-median or $k$-means objective value,\nbut not closeness to the target clustering.\n  Our first result is a distributed algorithm which returns a near-optimal\nclustering assuming a natural notion of stability, namely, approximation\nstability [Balcan et. al 2013], even when a constant fraction of the data are\noutliers. The communication complexity is $\\tilde O(sk+z)$ where $s$ is the\nnumber of machines, $k$ is the number of clusters, and $z$ is the number of\noutliers.\n  Next, we show this amount of communication cannot be improved even in the\nsetting when the input satisfies various non-worst-case assumptions. We give a\nmatching $\\Omega(sk+z)$ lower bound on the communication required both for\napproximating the optimal $k$-means or $k$-median cost up to any constant, and\nfor returning a clustering that is close to the target clustering in Hamming\ndistance. These lower bounds hold even when the data satisfies approximation\nstability or other common notions of stability, and the cluster sizes are\nbalanced. Therefore, $\\Omega(sk+z)$ is a communication bottleneck, even for\nreal-world instances.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 15:27:14 GMT"}, {"version": "v2", "created": "Thu, 12 Oct 2017 19:08:04 GMT"}, {"version": "v3", "created": "Wed, 6 Mar 2019 19:18:19 GMT"}], "update_date": "2019-03-08", "authors_parsed": [["Awasthi", "Pranjal", ""], ["Bakshi", "Ainesh", ""], ["Balcan", "Maria-Florina", ""], ["White", "Colin", ""], ["Woodruff", "David", ""]]}, {"id": "1703.00924", "submitter": "Matthew D. Jones", "authors": "Matthew D. Jones, Joseph P. White, Martins Innus, Robert L. DeLeon,\n  Nikolay Simakov, Jeffrey T. Palmer, Steven M. Gallo, and Thomas R. Furlani,\n  Michael Showerman, Robert Brunner, Andry Kot, Gregory Bauer, Brett Bode,\n  Jeremy Enos, and William Kramer", "title": "Workload Analysis of Blue Waters", "comments": "107 pages, >100 figures (figure sizes reduced to save space, contact\n  authors for version with full resolution)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blue Waters is a Petascale-level supercomputer whose mission is to enable the\nnational scientific and research community to solve \"grand challenge\" problems\nthat are orders of magnitude more complex than can be carried out on other high\nperformance computing systems. Given the important and unique role that Blue\nWaters plays in the U.S. research portfolio, it is important to have a detailed\nunderstanding of its workload in order to guide performance optimization both\nat the software and system configuration level as well as inform architectural\nbalance tradeoffs. Furthermore, understanding the computing requirements of the\nBlue Water's workload (memory access, IO, communication, etc.), which is\ncomprised of some of the most computationally demanding scientific problems,\nwill help drive changes in future computing architectures, especially at the\nleading edge. With this objective in mind, the project team carried out a\ndetailed workload analysis of Blue Waters.\n", "versions": [{"version": "v1", "created": "Thu, 2 Mar 2017 19:22:39 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Jones", "Matthew D.", ""], ["White", "Joseph P.", ""], ["Innus", "Martins", ""], ["DeLeon", "Robert L.", ""], ["Simakov", "Nikolay", ""], ["Palmer", "Jeffrey T.", ""], ["Gallo", "Steven M.", ""], ["Furlani", "Thomas R.", ""], ["Showerman", "Michael", ""], ["Brunner", "Robert", ""], ["Kot", "Andry", ""], ["Bauer", "Gregory", ""], ["Bode", "Brett", ""], ["Enos", "Jeremy", ""], ["Kramer", "William", ""]]}, {"id": "1703.01041", "submitter": "Esteban Real", "authors": "Esteban Real, Sherry Moore, Andrew Selle, Saurabh Saxena, Yutaka Leon\n  Suematsu, Jie Tan, Quoc Le, Alex Kurakin", "title": "Large-Scale Evolution of Image Classifiers", "comments": "Accepted for publication at ICML 2017 (34th International Conference\n  on Machine Learning)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.AI cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Neural networks have proven effective at solving difficult problems but\ndesigning their architectures can be challenging, even for image classification\nproblems alone. Our goal is to minimize human participation, so we employ\nevolutionary algorithms to discover such networks automatically. Despite\nsignificant computational requirements, we show that it is now possible to\nevolve models with accuracies within the range of those published in the last\nyear. Specifically, we employ simple evolutionary techniques at unprecedented\nscales to discover models for the CIFAR-10 and CIFAR-100 datasets, starting\nfrom trivial initial conditions and reaching accuracies of 94.6% (95.6% for\nensemble) and 77.0%, respectively. To do this, we use novel and intuitive\nmutation operators that navigate large search spaces; we stress that no human\nparticipation is required once evolution starts and that the output is a\nfully-trained model. Throughout this work, we place special emphasis on the\nrepeatability of results, the variability in the outcomes and the computational\nrequirements.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 05:41:30 GMT"}, {"version": "v2", "created": "Sun, 11 Jun 2017 08:42:28 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Real", "Esteban", ""], ["Moore", "Sherry", ""], ["Selle", "Andrew", ""], ["Saxena", "Saurabh", ""], ["Suematsu", "Yutaka Leon", ""], ["Tan", "Jie", ""], ["Le", "Quoc", ""], ["Kurakin", "Alex", ""]]}, {"id": "1703.01054", "submitter": "Aneesh Sharma Aneesh Sharma", "authors": "Aneesh Sharma and C. Seshadhri and Ashish Goel", "title": "When Hashes Met Wedges: A Distributed Algorithm for Finding High\n  Similarity Vectors", "comments": null, "journal-ref": null, "doi": "10.1145/3038912.3052633", "report-no": null, "categories": "cs.SI cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding similar user pairs is a fundamental task in social networks, with\nnumerous applications in ranking and personalization tasks such as link\nprediction and tie strength detection. A common manifestation of user\nsimilarity is based upon network structure: each user is represented by a\nvector that represents the user's network connections, where pairwise cosine\nsimilarity among these vectors defines user similarity. The predominant task\nfor user similarity applications is to discover all similar pairs that have a\npairwise cosine similarity value larger than a given threshold $\\tau$. In\ncontrast to previous work where $\\tau$ is assumed to be quite close to 1, we\nfocus on recommendation applications where $\\tau$ is small, but still\nmeaningful. The all pairs cosine similarity problem is computationally\nchallenging on networks with billions of edges, and especially so for settings\nwith small $\\tau$. To the best of our knowledge, there is no practical solution\nfor computing all user pairs with, say $\\tau = 0.2$ on large social networks,\neven using the power of distributed algorithms.\n  Our work directly addresses this challenge by introducing a new algorithm ---\nWHIMP --- that solves this problem efficiently in the MapReduce model. The key\ninsight in WHIMP is to combine the \"wedge-sampling\" approach of Cohen-Lewis for\napproximate matrix multiplication with the SimHash random projection techniques\nof Charikar. We provide a theoretical analysis of WHIMP, proving that it has\nnear optimal communication costs while maintaining computation cost comparable\nwith the state of the art. We also empirically demonstrate WHIMP's scalability\nby computing all highly similar pairs on four massive data sets, and show that\nit accurately finds high similarity pairs. In particular, we note that WHIMP\nsuccessfully processes the entire Twitter network, which has tens of billions\nof edges.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 06:41:02 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Sharma", "Aneesh", ""], ["Seshadhri", "C.", ""], ["Goel", "Ashish", ""]]}, {"id": "1703.01148", "submitter": "Bikash Chandra", "authors": "Bikash Chandra, S. Sudarshan", "title": "Runtime Optimization of Join Location in Parallel Data Management\n  Systems", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications running on parallel systems often need to join a streaming\nrelation or a stored relation with data indexed in a parallel data storage\nsystem. Some applications also compute UDFs on the joined tuples. The join can\nbe done at the data storage nodes, corresponding to reduce side joins, or by\nfetching data from the storage system to compute nodes, corresponding to map\nside join. Both may be suboptimal: reduce side joins may cause skew, while map\nside joins may lead to a lot of data being transferred and replicated.\n  In this paper, we present techniques to make runtime decisions between the\ntwo options on a per key basis, in order to improve the throughput of the join,\naccounting for UDF computation if any. Our techniques are based on an extended\nski-rental algorithm and provide worst-case performance guarantees with respect\nto the optimal point in the space considered by us. Our techniques use load\nbalancing taking into account the CPU, network and I/O costs as well as the\nload on compute and storage nodes. We have implemented our techniques on\nHadoop, Spark and the Muppet stream processing engine. Our experiments show\nthat our optimization techniques provide a significant improvement in\nthroughput over existing techniques.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 13:21:25 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 06:01:10 GMT"}, {"version": "v3", "created": "Mon, 31 Jul 2017 09:26:37 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Chandra", "Bikash", ""], ["Sudarshan", "S.", ""]]}, {"id": "1703.01200", "submitter": "Andrey Ustyuzhanin", "authors": "Andrey Ustyuzhanin, Timothy Daniel Head, Igor Babuschkin and Alexander\n  Tiunov", "title": "Everware toolkit. Supporting reproducible science and challenge-driven\n  education", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/898/7/072051", "report-no": null, "categories": "cs.CY cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Modern science clearly demands for a higher level of reproducibility and\ncollaboration. To make research fully reproducible one has to take care of\nseveral aspects: research protocol description, data access, environment\npreservation, workflow pipeline, and analysis script preservation. Version\ncontrol systems like git help with the workflow and analysis scripts part.\nVirtualization techniques like Docker or Vagrant can help deal with\nenvironments. Jupyter notebooks are a powerful platform for conducting research\nin a collaborative manner. We present project Everware that seamlessly\nintegrates git repository management systems such as Github or Gitlab, Docker\nand Jupyter helping with a) sharing results of real research and b) boosts\neducation activities. With the help of Everware one can not only share the\nfinal artifacts of research but all the depth of the research process. This\nbeen shown to be extremely helpful during organization of several data analysis\nhackathons and machine learning schools. Using Everware participants could\nstart from an existing solution instead of starting from scratch. They could\nstart contributing immediately. Everware allows its users to make use of their\nown computational resources to run the workflows they are interested in, which\nleads to higher scalability of the toolkit.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 15:14:07 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Ustyuzhanin", "Andrey", ""], ["Head", "Timothy Daniel", ""], ["Babuschkin", "Igor", ""], ["Tiunov", "Alexander", ""]]}, {"id": "1703.01286", "submitter": "Narayana Moorthy Prakash", "authors": "Kishori M. Konwar, N. Prakash, Nancy Lynch, Muriel Medard", "title": "A Layered Architecture for Erasure-Coded Consistent Distributed Storage", "comments": "To appear in ACM PODC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by emerging applications to the edge computing paradigm, we\nintroduce a two-layer erasure-coded fault-tolerant distributed storage system\noffering atomic access for read and write operations. In edge computing,\nclients interact with an edge-layer of servers that is geographically near; the\nedge-layer in turn interacts with a back-end layer of servers. The edge-layer\nprovides low latency access and temporary storage for client operations, and\nuses the back-end layer for persistent storage. Our algorithm, termed Layered\nData Storage (LDS) algorithm, offers several features suitable for\nedge-computing systems, works under asynchronous message-passing environments,\nsupports multiple readers and writers, and can tolerate $f_1 < n_1/2$ and $f_2\n< n_2/3$ crash failures in the two layers having $n_1$ and $n_2$ servers,\nrespectively. We use a class of erasure codes known as regenerating codes for\nstorage of data in the back-end layer. The choice of regenerating codes,\ninstead of popular choices like Reed-Solomon codes, not only optimizes the cost\nof back-end storage, but also helps in optimizing communication cost of read\noperations, when the value needs to be recreated all the way from the back-end.\nThe two-layer architecture permits a modular implementation of atomicity and\nerasure-code protocols; the implementation of erasure-codes is mostly limited\nto interaction between the two layers. We prove liveness and atomicity of LDS,\nand also compute performance costs associated with read and write operations.\nFurther, in a multi-object system running $N$ independent instances of LDS,\nwhere only a small fraction of the objects undergo concurrent accesses at any\npoint during the execution, the overall storage cost is dominated by that of\npersistent storage in the back-end layer, and is given by $\\Theta(N)$.\n", "versions": [{"version": "v1", "created": "Fri, 3 Mar 2017 18:52:34 GMT"}, {"version": "v2", "created": "Tue, 30 May 2017 22:14:23 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Konwar", "Kishori M.", ""], ["Prakash", "N.", ""], ["Lynch", "Nancy", ""], ["Medard", "Muriel", ""]]}, {"id": "1703.01673", "submitter": "Tianyi Chen", "authors": "Tianyi Chen, Qing Ling, and Georgios B. Giannakis", "title": "Learn-and-Adapt Stochastic Dual Gradients for Network Resource\n  Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network resource allocation shows revived popularity in the era of data\ndeluge and information explosion. Existing stochastic optimization approaches\nfall short in attaining a desirable cost-delay tradeoff. Recognizing the\ncentral role of Lagrange multipliers in network resource allocation, a novel\nlearn-and-adapt stochastic dual gradient (LA-SDG) method is developed in this\npaper to learn the sample-optimal Lagrange multiplier from historical data, and\naccordingly adapt the upcoming resource allocation strategy. Remarkably, LA-SDG\nonly requires just an extra sample (gradient) evaluation relative to the\ncelebrated stochastic dual gradient (SDG) method. LA-SDG can be interpreted as\na foresighted learning scheme with an eye on the future, or, a modified\nheavy-ball iteration from an optimization viewpoint. It is established - both\ntheoretically and empirically - that LA-SDG markedly improves the cost-delay\ntradeoff over state-of-the-art allocation schemes.\n", "versions": [{"version": "v1", "created": "Sun, 5 Mar 2017 22:02:50 GMT"}, {"version": "v2", "created": "Tue, 31 Oct 2017 19:12:33 GMT"}], "update_date": "2017-11-02", "authors_parsed": [["Chen", "Tianyi", ""], ["Ling", "Qing", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1703.01704", "submitter": "Miguel Mosteiro", "authors": "Dariusz R. Kowalski, Harshita Kudaravalli, Miguel A. Mosteiro", "title": "Ad-hoc Affectance-selective Families for Layer Dissemination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information dissemination protocols for ad-hoc wireless networks frequently\nuse a minimal subset of the available communication links, defining a rooted\n\"broadcast\" tree. In this work, we focus on the core challenge of disseminating\nfrom one layer to the next one of such tree. We call this problem Layer\nDissemination. We study Layer Dissemination under a generalized model of\ninterference, called affectance. The affectance model subsumes previous models,\nsuch as Radio Network and Signal to Inteference-plus-Noise Ratio. We present\nrandomized and deterministic protocols for Layer Dissemination. These protocols\nare based on a combinatorial object that we call Affectance-selective Families.\nOur approach combines an engineering solution with theoretical guarantees. That\nis, we provide a method to characterize the network with a global measure of\naffectance based on measurements of interference in the specific deployment\narea. Then, our protocols distributedly produce an ad-hoc transmissions\nschedule for dissemination. In the randomized protocol only the network\ncharacterization is needed, whereas the deterministic protocol requires full\nknowledge of affectance. Our theoretical analysis provides guarantees on\nschedule length. We also present simulations of a real network-deployment area\ncontrasting the performance of our randomized protocol, which takes into\naccount affectance, against previous work for interference models that ignore\nsome physical constraints. The striking improvement in performance shown by our\nsimulations show the importance of utilizing a more physically-accurate model\nof interference that takes into account other effects beyond distance to\ntransmitters.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 02:05:09 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Kowalski", "Dariusz R.", ""], ["Kudaravalli", "Harshita", ""], ["Mosteiro", "Miguel A.", ""]]}, {"id": "1703.01859", "submitter": "Peter Davies", "authors": "Artur Czumaj, Peter Davies", "title": "Exploiting Spontaneous Transmissions for Broadcasting and Leader\n  Election in Radio Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study two fundamental communication primitives: broadcasting and leader\nelection in the classical model of multi-hop radio networks with unknown\ntopology and without collision detection mechanisms.\n  It has been known for almost 20 years that in undirected networks with n\nnodes and diameter D, randomized broadcasting requires Omega(D log n/D + log^2\nn) rounds in expectation, assuming that uninformed nodes are not allowed to\ncommunicate (until they are informed). Only very recently, Haeupler and Wajc\n(PODC'2016) showed that this bound can be slightly improved for the model with\nspontaneous transmissions, providing an O(D log n loglog n / log D + log^O(1)\nn)-time broadcasting algorithm. In this paper, we give a new and faster\nalgorithm that completes broadcasting in O(D log n/log D + log^O(1) n) time,\nwith high probability. This yields the first optimal O(D)-time broadcasting\nalgorithm whenever D is polynomial in n.\n  Furthermore, our approach can be applied to design a new leader election\nalgorithm that matches the performance of our broadcasting algorithm.\nPreviously, all fast randomized leader election algorithms have been using\nbroadcasting as their subroutine and their complexity have been asymptotically\nstrictly bigger than the complexity of broadcasting. In particular, the fastest\npreviously known randomized leader election algorithm of Ghaffari and Haeupler\n(SODA'2013) requires O(D log n/D min{loglog n, log n/D} + log^O(1) n)-time with\nhigh probability. Our new algorithm requires O(D log n / log D + log^O(1) n)\ntime with high probability, and it achieves the optimal O(D) time whenever D is\npolynomial in n.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 13:22:08 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Czumaj", "Artur", ""], ["Davies", "Peter", ""]]}, {"id": "1703.01975", "submitter": "Ruben Mayer", "authors": "Ruben Mayer, Harshit Gupta, Enrique Saurez, Umakishore Ramachandran", "title": "The Fog Makes Sense: Enabling Social Sensing Services With Limited\n  Internet Connectivity", "comments": "Ruben Mayer, Harshit Gupta, Enrique Saurez, and Umakishore\n  Ramachandran. 2017. The Fog Makes Sense: Enabling Social Sensing Services\n  With Limited Internet Connectivity. In Proceedings of The 2nd International\n  Workshop on Social Sensing, Pittsburgh, PA, USA, April 21 2017\n  (SocialSens'17), 6 pages", "journal-ref": null, "doi": "10.1145/3055601.3055614", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social sensing services use humans as sensor carriers, sensor operators and\nsensors themselves in order to provide situation-awareness to applications.\nThis promises to provide a multitude of benefits to the users, for example in\nthe management of natural disasters or in community empowerment. However,\ncurrent social sensing services depend on Internet connectivity since the\nservices are deployed on central Cloud platforms. In many circumstances,\nInternet connectivity is constrained, for instance when a natural disaster\ncauses Internet outages or when people do not have Internet access due to\neconomical reasons. In this paper, we propose the emerging Fog Computing\ninfrastructure to become a key-enabler of social sensing services in situations\nof constrained Internet connectivity. To this end, we develop a generic\narchitecture and API of Fog-enabled social sensing services. We exemplify the\nusage of the proposed social sensing architecture on a number of concrete use\ncases from two different scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 17:02:14 GMT"}], "update_date": "2017-03-07", "authors_parsed": [["Mayer", "Ruben", ""], ["Gupta", "Harshit", ""], ["Saurez", "Enrique", ""], ["Ramachandran", "Umakishore", ""]]}, {"id": "1703.02247", "submitter": "Marius Rafailescu", "authors": "Marius Rafailescu", "title": "Fault Tolerant Leader Election in Distributed Systems", "comments": null, "journal-ref": null, "doi": "10.5121/ijcsit.2017.9102", "report-no": "International Journal of Computer Science & Information Technology\n  (IJCSIT) Vol 9, No 1, February 2017", "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  There are many distributed systems which use a leader in their logic. When\nsuch systems need to be fault tolerant and the current leader suffers a\ntechnical problem, it is necesary to apply a special algorithm in order to\nchoose a new leader. In this paper I present a new fault tolerant algorithm\nwhich elects a new leader based on a random roulette wheel selection.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 07:28:05 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Rafailescu", "Marius", ""]]}, {"id": "1703.02438", "submitter": "Zheng Yuan", "authors": "Zheng Yuan, William Hendrix, Seung Woo Son, Christoph Federrath, Ankit\n  Agrawal, Wei-keng Liao, Alok Choudhary", "title": "Parallel Implementation of Lossy Data Compression for Temporal Data Sets", "comments": "10 pages, HiPC 2016", "journal-ref": null, "doi": "10.1109/HiPC.2016.017", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many scientific data sets contain temporal dimensions. These are the data\nstoring information at the same spatial location but different time stamps.\nSome of the biggest temporal datasets are produced by parallel computing\napplications such as simulations of climate change and fluid dynamics. Temporal\ndatasets can be very large and cost a huge amount of time to transfer among\nstorage locations. Using data compression techniques, files can be transferred\nfaster and save storage space. NUMARCK is a lossy data compression algorithm\nfor temporal data sets that can learn emerging distributions of element-wise\nchange ratios along the temporal dimension and encodes them into an index table\nto be concisely represented. This paper presents a parallel implementation of\nNUMARCK. Evaluated with six data sets obtained from climate and astrophysics\nsimulations, parallel NUMARCK achieved scalable speedups of up to 8788 when\nrunning 12800 MPI processes on a parallel computer. We also compare the\ncompression ratios against two lossy data compression algorithms, ISABELA and\nZFP. The results show that NUMARCK achieved higher compression ratio than\nISABELA and ZFP.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 15:37:30 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Yuan", "Zheng", ""], ["Hendrix", "William", ""], ["Son", "Seung Woo", ""], ["Federrath", "Christoph", ""], ["Agrawal", "Ankit", ""], ["Liao", "Wei-keng", ""], ["Choudhary", "Alok", ""]]}, {"id": "1703.02484", "submitter": "Francisco Carter", "authors": "Francisco Carter, Nancy Hitschfeld, Crist\\'obal Navarro, Rodrigo Soto", "title": "GPU parallel simulation algorithm of Brownian particles with excluded\n  volume using Delaunay triangulations", "comments": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract appearing here is slightly shorter than the one in\n  the PDF file", "journal-ref": null, "doi": "10.1016/j.cpc.2018.04.006", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel parallel simulation algorithm on the GPU, implemented in CUDA and\nC++, is presented for the simulation of Brownian particles that display\nexcluded volume repulsion and interact with long and short range forces. When\nan explicit Euler-Maruyama integration step is performed to take into account\nthe pairwise forces and Brownian motion, particle overlaps can appear. The\nexcluded volume property brings up the need for correcting these overlaps as\nthey happen, since predicting them is not feasible due to the random\ndisplacement of Brownian particles. The proposed solution handles, at each time\nstep, a Delaunay triangulation of the particle positions because it allows us\nto efficiently solve overlaps between particles by checking just their\nneighborhood. The algorithm starts by generating a Delaunay triangulation of\nthe particle initial positions on CPU, but after that the triangulation is\nalways kept on GPU memory. We used a parallel edge-flip implementation to keep\nthe triangulation updated during each time step, checking previously that the\ntriangulation was not rendered invalid due to the particle displacements. The\nalgorithm is validated with two models of active colloidal particles. Upon\ntesting the parallel implementation of a long range forces simulation, the\nresults show a performance improvement of up to two orders of magnitude when\ncompared to the previously existing sequential solution.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 17:33:52 GMT"}], "update_date": "2018-07-04", "authors_parsed": [["Carter", "Francisco", ""], ["Hitschfeld", "Nancy", ""], ["Navarro", "Crist\u00f3bal", ""], ["Soto", "Rodrigo", ""]]}, {"id": "1703.02743", "submitter": "Tomasz Jurdzinski", "authors": "Tomasz Jurdzinski and Krzysztof Nowicki", "title": "MSF and Connectivity in Limited Variants of the Congested Clique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The congested clique is a synchronous, message-passing model of distributed\ncomputing in which each computational unit (node) in each round can send\nmessage of O(log n) bits to each other node of the network, where n is the\nnumber of nodes. This model has been considered under two extreme scanarios:\nunicast or broadcast. In the unicast model, a node can send (possibly)\ndifferent message to each other node of the network. In contrast, in the\nbroadcast model each node sends a single (the same) message to all other nodes.\nWe study the congested clique model parametrized by the range r, the maximum\nnumber of different messages a node can send in one round. Following recent\nprogress in design of algorihms for graph connectivity and minimum span- ning\nforest (MSF) in the unicast congested clique, we study these problems in\nlimited variants of the congested clique. We present the first sub-logarithmic\nalgorithm for connected components in the broadcast congested clique. Then, we\nshow that efficient unicast deterministic algorithm for MSF and randomized\nalgorithm for connected components can be efficiently imple- mented in the\nrcast model with range r = 2, the weakest model of the congested clique above\nthe broadcast variant (r = 1) in the hierarchy with respect to range. More\nimportantly, our al- gorithms give the first solutions with optimal capacity of\ncommunication edges, while preserving small round complexity.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 08:15:40 GMT"}], "update_date": "2017-07-28", "authors_parsed": [["Jurdzinski", "Tomasz", ""], ["Nowicki", "Krzysztof", ""]]}, {"id": "1703.02755", "submitter": "Jesus Arias Fisteus", "authors": "Jesus Arias Fisteus, Luis Sanchez Fernandez, Victor Corcoba Maga\\~na,\n  Mario Mu\\~noz Organero, Jorge Yago Fernandez, Juan Antonio Alvarez Garcia", "title": "A Scalable Data Streaming Infrastructure for Smart Cities", "comments": "Preprint of a paper accepted for publication at http://ceur-ws.org/\n  as part of the Proceedings of JARCA 2016 (XVIII Jornadas de ARCA Sistemas\n  Cualitativos y sus Aplicaciones en Diagnosis, Rob\\'otica e Inteligencia\n  Ambiental), Almeria, Spain, June 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many of the services a smart city can provide to its citizens rely on the\nability of its infrastructure to collect and process in real time vast amounts\nof continuous data that sensors deployed through the city produce. In this\npaper we present the server infrastructure we have designed in the context of\nthe HERMES project to collect the data from sensors and aggregate it in streams\nfor their use in services of the smart city.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 09:26:11 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Fisteus", "Jesus Arias", ""], ["Fernandez", "Luis Sanchez", ""], ["Maga\u00f1a", "Victor Corcoba", ""], ["Organero", "Mario Mu\u00f1oz", ""], ["Fernandez", "Jorge Yago", ""], ["Garcia", "Juan Antonio Alvarez", ""]]}, {"id": "1703.02757", "submitter": "El Mahdi El Mhamdi", "authors": "Peva Blanchard, El Mahdi El Mhamdi, Rachid Guerraoui, Julien Stainer", "title": "Byzantine-Tolerant Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of data, the need for scalability and the complexity of models\nused in modern machine learning calls for distributed implementations. Yet, as\nof today, distributed machine learning frameworks have largely ignored the\npossibility of arbitrary (i.e., Byzantine) failures. In this paper, we study\nthe robustness to Byzantine failures at the fundamental level of stochastic\ngradient descent (SGD), the heart of most machine learning algorithms. Assuming\na set of $n$ workers, up to $f$ of them being Byzantine, we ask how robust can\nSGD be, without limiting the dimension, nor the size of the parameter space.\n  We first show that no gradient descent update rule based on a linear\ncombination of the vectors proposed by the workers (i.e, current approaches)\ntolerates a single Byzantine failure. We then formulate a resilience property\nof the update rule capturing the basic requirements to guarantee convergence\ndespite $f$ Byzantine workers. We finally propose Krum, an update rule that\nsatisfies the resilience property aforementioned. For a $d$-dimensional\nlearning problem, the time complexity of Krum is $O(n^2 \\cdot (d + \\log n))$.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 09:26:36 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Blanchard", "Peva", ""], ["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""], ["Stainer", "Julien", ""]]}, {"id": "1703.02788", "submitter": "Enrico Calore", "authors": "Enrico Calore, Alessandro Gabbana, Sebastiano Fabio Schifano, Raffaele\n  Tripiccione", "title": "Evaluation of DVFS techniques on modern HPC processors and accelerators\n  for energy-aware applications", "comments": null, "journal-ref": null, "doi": "10.1002/cpe.4143", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy efficiency is becoming increasingly important for computing systems,\nin particular for large scale HPC facilities. In this work we evaluate, from an\nuser perspective, the use of Dynamic Voltage and Frequency Scaling (DVFS)\ntechniques, assisted by the power and energy monitoring capabilities of modern\nprocessors in order to tune applications for energy efficiency. We run selected\nkernels and a full HPC application on two high-end processors widely used in\nthe HPC context, namely an NVIDIA K80 GPU and an Intel Haswell CPU. We evaluate\nthe available trade-offs between energy-to-solution and time-to-solution,\nattempting a function-by-function frequency tuning. We finally estimate the\nbenefits obtainable running the full code on a HPC multi-GPU node, with respect\nto default clock frequency governors. We instrument our code to accurately\nmonitor power consumption and execution time without the need of any additional\nhardware, and we enable it to change CPUs and GPUs clock frequencies while\nrunning. We analyze our results on the different architectures using a simple\nenergy-performance model, and derive a number of energy saving strategies which\ncan be easily adopted on recent high-end HPC systems for generic applications.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 11:13:24 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Calore", "Enrico", ""], ["Gabbana", "Alessandro", ""], ["Schifano", "Sebastiano Fabio", ""], ["Tripiccione", "Raffaele", ""]]}, {"id": "1703.02898", "submitter": "Biswa Sengupta", "authors": "B Sengupta, E Vazquez, M Sasdelli, Y Qian, M Peniak, L Netherton and G\n  Delfino", "title": "Large-scale image analysis using docker sandboxing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.IR cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the advent of specialized hardware such as Graphics Processing Units\n(GPUs), large scale image localization, classification and retrieval have seen\nincreased prevalence. Designing scalable software architecture that co-evolves\nwith such specialized hardware is a challenge in the commercial setting. In\nthis paper, we describe one such architecture (\\textit{Cortexica}) that\nleverages scalability of GPUs and sandboxing offered by docker containers. This\nallows for the flexibility of mixing different computer architectures as well\nas computational algorithms with the security of a trusted environment. We\nillustrate the utility of this framework in a commercial setting i.e.,\nsearching for multiple products in an image by combining image localisation and\nretrieval.\n", "versions": [{"version": "v1", "created": "Tue, 7 Mar 2017 09:40:48 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Sengupta", "B", ""], ["Vazquez", "E", ""], ["Sasdelli", "M", ""], ["Qian", "Y", ""], ["Peniak", "M", ""], ["Netherton", "L", ""], ["Delfino", "G", ""]]}, {"id": "1703.02920", "submitter": "Miguel Carcamo", "authors": "M. C\\'arcamo, P. Rom\\'an, S. Casassus, V. Moral, F.R. Rannou", "title": "Multi-GPU maximum entropy image synthesis for radio astronomy", "comments": "11 pages, 13 figures", "journal-ref": null, "doi": "10.1016/j.ascom.2017.11.003", "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The maximum entropy method (MEM) is a well known deconvolution technique in\nradio-interferometry. This method solves a non-linear optimization problem with\nan entropy regularization term. Other heuristics such as CLEAN are faster but\nhighly user dependent. Nevertheless, MEM has the following advantages: it is\nunsupervised, it has a statistical basis, it has a better resolution and better\nimage quality under certain conditions. This work presents a high performance\nGPU version of non-gridding MEM, which is tested using real and simulated data.\nWe propose a single-GPU and a multi-GPU implementation for single and\nmulti-spectral data, respectively. We also make use of the Peer-to-Peer and\nUnified Virtual Addressing features of newer GPUs which allows to exploit\ntransparently and efficiently multiple GPUs. Several ALMA data sets are used to\ndemonstrate the effectiveness in imaging and to evaluate GPU performance. The\nresults show that a speedup from 1000 to 5000 times faster than a sequential\nversion can be achieved, depending on data and image size. This allows to\nreconstruct the HD142527 CO(6-5) short baseline data set in 2.1 minutes,\ninstead of 2.5 days that takes a sequential version on CPU.\n", "versions": [{"version": "v1", "created": "Wed, 8 Mar 2017 17:15:03 GMT"}, {"version": "v2", "created": "Wed, 5 Jul 2017 20:31:51 GMT"}, {"version": "v3", "created": "Mon, 6 Nov 2017 18:49:31 GMT"}], "update_date": "2017-12-08", "authors_parsed": [["C\u00e1rcamo", "M.", ""], ["Rom\u00e1n", "P.", ""], ["Casassus", "S.", ""], ["Moral", "V.", ""], ["Rannou", "F. R.", ""]]}, {"id": "1703.03190", "submitter": "Arnaud Casteigts", "authors": "Arnaud Casteigts, Swan Dubois, Franck Petit, John Michael Robson", "title": "Robustness in Highly Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate a special case of hereditary property that we refer to as {\\em\nrobustness}. A property is {\\em robust} in a given graph if it is inherited by\nall connected spanning subgraphs of this graph. We motivate this definition in\ndifferent contexts, showing that it plays a central role in highly dynamic\nnetworks, although the problem is defined in terms of classical (static) graph\ntheory. In this paper, we focus on the robustness of {\\em maximal independent\nsets} (MIS). Following the above definition, a MIS is said to be {\\em robust}\n(RMIS) if it remains a valid MIS in all connected spanning subgraphs of the\noriginal graph. We characterize the class of graphs in which {\\em all} possible\nMISs are robust. We show that, in these particular graphs, the problem of\nfinding a robust MIS is {\\em local}; that is, we present an RMIS algorithm\nusing only a sublogarithmic number of rounds (in the number of nodes $n$) in\nthe ${\\cal LOCAL}$ model. On the negative side, we show that, in general\ngraphs, the problem is not local. Precisely, we prove a $\\Omega(n)$ lower bound\non the number of rounds required for the nodes to decide consistently in some\ngraphs. This result implies a separation between the RMIS problem and the MIS\nproblem in general graphs. It also implies that any strategy in this case is\nasymptotically (in order) as bad as collecting all the network information at\none node and solving the problem in a centralized manner. Motivated by this\nobservation, we present a centralized algorithm that computes a robust MIS in a\ngiven graph, if one exists, and rejects otherwise. Significantly, this\nalgorithm requires only a polynomial amount of local computation time, despite\nthe fact that exponentially many MISs and exponentially many connected spanning\nsubgraphs may exist.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 09:26:05 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Casteigts", "Arnaud", ""], ["Dubois", "Swan", ""], ["Petit", "Franck", ""], ["Robson", "John Michael", ""]]}, {"id": "1703.03225", "submitter": "Zhe Chen", "authors": "Sai Xie, Zhe Chen", "title": "Anomaly Detection and Redundancy Elimination of Big Sensor Data in\n  Internet of Things", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era of big data and Internet of things, massive sensor data are\ngathered with Internet of things. Quantity of data captured by sensor networks\nare considered to contain highly useful and valuable information. However, for\na variety of reasons, received sensor data often appear abnormal. Therefore,\neffective anomaly detection methods are required to guarantee the quality of\ndata collected by those sensor nodes. Since sensor data are usually correlated\nin time and space, not all the gathered data are valuable for further data\nprocessing and analysis. Preprocessing is necessary for eliminating the\nredundancy in gathered massive sensor data. In this paper, the proposed work\ndefines a sensor data preprocessing framework. It is mainly composed of two\nparts, i.e., sensor data anomaly detection and sensor data redundancy\nelimination. In the first part, methods based on principal statistic analysis\nand Bayesian network is proposed for sensor data anomaly detection. Then,\napproaches based on static Bayesian network (SBN) and dynamic Bayesian networks\n(DBNs) are proposed for sensor data redundancy elimination. Static sensor data\nredundancy detection algorithm (SSDRDA) for eliminating redundant data in\nstatic datasets and real-time sensor data redundancy detection algorithm\n(RSDRDA) for eliminating redundant sensor data in real-time are proposed. The\nefficiency and effectiveness of the proposed methods are validated using\nreal-world gathered sensor datasets.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 10:49:52 GMT"}], "update_date": "2017-03-10", "authors_parsed": [["Xie", "Sai", ""], ["Chen", "Zhe", ""]]}, {"id": "1703.03315", "submitter": "Stephane Devismes", "authors": "St\\'ephane Devismes, David Ilcinkas (LaBRI), Colette Johnen (LaBRI)", "title": "Self-Stabilizing Disconnected Components Detection and Rooted\n  Shortest-Path Tree Maintenance in Polynomial Steps", "comments": null, "journal-ref": "Discrete Mathematics and Theoretical Computer Science, DMTCS,\n  2017, ISS, pp.14 - 14", "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We deal with the problem of maintaining a shortest-path tree rooted at some\nprocess r in a network that may be disconnected after topological changes. The\ngoal is then to maintain a shortest-path tree rooted at r in its connected\ncomponent, V\\_r, and make all processes of other components detecting that r is\nnot part of their connected component. We propose, in the composite atomicity\nmodel, a silent self-stabilizing algorithm for this problem working in\nsemi-anonymous networks, where edges have strictly positive weights. This\nalgorithm does not require any a priori knowledge about global parameters of\nthe network. We prove its correctness assuming the distributed unfair daemon,\nthe most general daemon. Its stabilization time in rounds is at most 3nmax+D,\nwhere nmax is the maximum number of non-root processes in a connected component\nand D is the hop-diameter of V\\_r. Furthermore, if we additionally assume that\nedge weights are positive integers, then it stabilizes in a polynomial number\nof steps: namely, we exhibit a bound in O(maxi nmax^3 n), where maxi is the\nmaximum weight of an edge and n is the number of processes.\n", "versions": [{"version": "v1", "created": "Thu, 9 Mar 2017 16:04:37 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 13:17:15 GMT"}, {"version": "v3", "created": "Thu, 30 Nov 2017 13:31:28 GMT"}], "update_date": "2017-12-01", "authors_parsed": [["Devismes", "St\u00e9phane", "", "LaBRI"], ["Ilcinkas", "David", "", "LaBRI"], ["Johnen", "Colette", "", "LaBRI"]]}, {"id": "1703.03594", "submitter": "Alireza Poshtkohi", "authors": "Alireza Poshtkohi, M.B. Ghaznavi-Ghoushchi", "title": "The xDotGrid Native, Cross-Platform, High-Performance xDFS File Transfer\n  Framework", "comments": "25 pages, 20 figures", "journal-ref": "Computers & Electrical Engineering 38(6), 1409-1432 (2012)", "doi": "10.1016/j.compeleceng.2012.04.007", "report-no": "01", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we introduce and describe the highly concurrent xDFS file\ntransfer protocol and examine its cross-platform and cross-language\nimplementation in native code for both Linux and Windows in 32 or 64-bit\nmulti-core processor architectures. The implemented xDFS protocol based on\nxDotGrid.NET framework is fully compared with the Globus GridFTP protocol. We\nfinally propose the xDFS protocol as a new paradigm of distributed systems for\nInternet services, and data-intensive Grid and Cloud applications. Also, we\nincrementally consider different developmental methods of the optimum file\ntransfer systems, and their advantages and disadvantages. The vision of this\npaper tries as possible to minimize the overhead concerned with the file\ntransfer protocol itself and to examine optimal software design patterns of\nthat protocol. In all disk-to-disk tests for transferring a 2GB file with or\nwithout parallelism, the xDFS throughput at minimum 30% and at most 53% was\nsuperior to the GridFTP.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 09:33:45 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Poshtkohi", "Alireza", ""], ["Ghaznavi-Ghoushchi", "M. B.", ""]]}, {"id": "1703.03607", "submitter": "Alireza Poshtkohi", "authors": "Mahdi MollaMotalebi, Raheleh Maghami, Abdul Samad Ismail, Alireza\n  Poshtkohi", "title": "The Efficiency Challenges of Resource Discovery in Grid Environments", "comments": "22 pages", "journal-ref": "Cybernetics and Systems: An International Journal, 45:8, 671-692,\n  2014", "doi": "10.1080/01969722.2014.972100", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource discovery is one of the most important services that significantly\naffects the efficiency of grid computing systems. The inherent dynamic and\nlarge-scale characteristics of grid environments make their resource discovery\na challenging task. In recent years, different approaches have been proposed\nfor resource discovery, attempting to tackle the challenges of grid\nenvironments and improve the efficiency. Being aware of these challenges and\napproaches is worthwhile in order to choose an appropriate approach according\nto the application in different organizations. This study reviews the most\nimportant factors that should be considered and challenges to be tackled in\norder to develop an efficient grid resource discovery system.\n", "versions": [{"version": "v1", "created": "Fri, 10 Mar 2017 10:16:42 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["MollaMotalebi", "Mahdi", ""], ["Maghami", "Raheleh", ""], ["Ismail", "Abdul Samad", ""], ["Poshtkohi", "Alireza", ""]]}, {"id": "1703.03904", "submitter": "Alireza Poshtkohi", "authors": "Alireza Poshtkohi, Ali Haj Abutalebi, Shaahin Hessabi", "title": "DotGrid: a .NET-based cross-platform software for desktop grids", "comments": "20 pages, 14 figures", "journal-ref": "Int. J. Web and Grid Services, Vol. 3, No. 3, pp.313-332, 2007", "doi": "10.1504/IJWGS.2007.014955", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Grid infrastructures that have provided wide integrated use of resources are\nbecoming the de-facto computing platform for solving large-scale problems in\nscience, engineering and commerce. In this evolution, desktop grid technologies\nallow the grid communities to exploit the idle cycles of pervasive desktop PC\nsystems to increase the available computing power. In this paper we present\nDotGrid, a cross-platform grid software. DotGrid is the first comprehensive\ndesktop grid software utilising Microsoft's .NET Framework in Windows-based\nenvironments and MONO .NET in Unix-class operating systems to operate. Using\nDotGrid services and APIs, grid desktop middleware and applications can be\nimplemented conveniently. We evaluated our DotGrid's performance by\nimplementing a set of grid-based applications.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 04:13:25 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Poshtkohi", "Alireza", ""], ["Abutalebi", "Ali Haj", ""], ["Hessabi", "Shaahin", ""]]}, {"id": "1703.03905", "submitter": "Alireza Poshtkohi", "authors": "Alireza Poshtkohi, M.B. Ghaznavi-Ghoushchi", "title": "DotDFS: A Grid-based high-throughput file transfer system", "comments": "28 pages, 21 figures", "journal-ref": "Parallel Computing, 37 (2011) 114-136", "doi": "10.1016/j.parco.2010.12.003", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DotGrid platform is a Grid infrastructure integrated with a set of open and\nstandard protocols recently implemented on the top of Microsoft .NET in Windows\nand MONO .NET in UNIX/Linux. DotGrid infrastructure along with its proposed\nprotocols provides a right and solid approach to targeting other platforms,\ne.g., the native C/C++ runtime. In this paper, we propose a new file transfer\nprotocol called DotDFS as a high-throughput distributed file transfer component\nfor DotGrid. DotDFS introduces some open binary protocols for efficient file\ntransfers on current Grid infrastructures. DotDFS protocol also provides\nmechanisms for multiple file streams to gain high-throughput file transfer\nsimilar to GridFTP protocol, but by proposing and implementing a new parallel\nTCP connection-oriented paradigm. In our LAN tests, we have achieved better\nresults than Globus GridFTP implementation particularly in multiple TCP streams\nand directory tree transfers. Our LAN experiences in memory-to-memory tests\nshow that DotDFS accesses to the 94% bottleneck bandwidth while GridFTP is\naccessing 91%. In LAN disk-to-disk tests, comparing DotDFS protocol with\nGridFTP protocol unveils a set of interesting and technical problems in GridFTP\nfor both the nature of the protocol and its implementation by Globus. In the\nWAN experimental studies, we propose a new idea for analytical modeling of file\ntransfer protocols like DotDFS inspired by sampling, experimentation and\nmathematical interpolation approaches. The cross-platform and open\nstandard-based features of DotDFS provide a substantial framework for unifying\ndata access and resource sharing in real heterogeneous Grid environments.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 04:17:07 GMT"}, {"version": "v2", "created": "Sat, 18 Mar 2017 08:47:54 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Poshtkohi", "Alireza", ""], ["Ghaznavi-Ghoushchi", "M. B.", ""]]}, {"id": "1703.03924", "submitter": "Robert Nishihara", "authors": "Robert Nishihara, Philipp Moritz, Stephanie Wang, Alexey Tumanov,\n  William Paul, Johann Schleier-Smith, Richard Liaw, Mehrdad Niknami, Michael\n  I. Jordan, Ion Stoica", "title": "Real-Time Machine Learning: The Missing Pieces", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning applications are increasingly deployed not only to serve\npredictions using static models, but also as tightly-integrated components of\nfeedback loops involving dynamic, real-time decision making. These applications\npose a new set of requirements, none of which are difficult to achieve in\nisolation, but the combination of which creates a challenge for existing\ndistributed execution frameworks: computation with millisecond latency at high\nthroughput, adaptive construction of arbitrary task graphs, and execution of\nheterogeneous kernels over diverse sets of resources. We assert that a new\ndistributed execution framework is needed for such ML applications and propose\na candidate approach with a proof-of-concept architecture that achieves a 63x\nperformance improvement over a state-of-the-art execution framework for a\nrepresentative application.\n", "versions": [{"version": "v1", "created": "Sat, 11 Mar 2017 07:46:51 GMT"}, {"version": "v2", "created": "Fri, 19 May 2017 22:52:32 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Nishihara", "Robert", ""], ["Moritz", "Philipp", ""], ["Wang", "Stephanie", ""], ["Tumanov", "Alexey", ""], ["Paul", "William", ""], ["Schleier-Smith", "Johann", ""], ["Liaw", "Richard", ""], ["Niknami", "Mehrdad", ""], ["Jordan", "Michael I.", ""], ["Stoica", "Ion", ""]]}, {"id": "1703.04057", "submitter": "Anh Dinh", "authors": "Tien Tuan Anh Dinh, Ji Wang, Gang Chen, Rui Liu, Beng Chin Ooi,\n  Kian-Lee Tan", "title": "BLOCKBENCH: A Framework for Analyzing Private Blockchains", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technologies are taking the world by storm. Public blockchains,\nsuch as Bitcoin and Ethereum, enable secure peer-to-peer applications like\ncrypto-currency or smart contracts. Their security and performance are well\nstudied. This paper concerns recent private blockchain systems designed with\nstronger security (trust) assumption and performance requirement. These systems\ntarget and aim to disrupt applications which have so far been implemented on\ntop of database systems, for example banking, finance applications. Multiple\nplatforms for private blockchains are being actively developed and fine tuned.\nHowever, there is a clear lack of a systematic framework with which different\nsystems can be analyzed and compared against each other. Such a framework can\nbe used to assess blockchains' viability as another distributed data processing\nplatform, while helping developers to identify bottlenecks and accordingly\nimprove their platforms.\n  In this paper, we first describe BlockBench, the first evaluation framework\nfor analyzing private blockchains. It serves as a fair means of comparison for\ndifferent platforms and enables deeper understanding of different system design\nchoices. Any private blockchain can be integrated to BlockBench via simple APIs\nand benchmarked against workloads that are based on real and synthetic smart\ncontracts. BlockBench measures overall and component-wise performance in terms\nof throughput, latency, scalability and fault-tolerance. Next, we use\nBlockBench to conduct comprehensive evaluation of three major private\nblockchains: Ethereum, Parity and Hyperledger Fabric. The results demonstrate\nthat these systems are still far from displacing current database systems in\ntraditional data processing workloads. Furthermore, there are gaps in\nperformance among the three systems which are attributed to the design choices\nat different layers of the software stack.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 02:10:06 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Dinh", "Tien Tuan Anh", ""], ["Wang", "Ji", ""], ["Chen", "Gang", ""], ["Liu", "Rui", ""], ["Ooi", "Beng Chin", ""], ["Tan", "Kian-Lee", ""]]}, {"id": "1703.04171", "submitter": "Oliver Gutsche", "authors": "Oliver Gutsche (1), Matteo Cremonesi (1), Peter Elmer (2), Bo\n  Jayatilaka (1), Jim Kowalkowski (1), Jim Pivarski (2), Saba Sehrish (1),\n  Cristina Mantilla Surez (3), Alexey Svyatkovskiy (2), Nhan Tran (1) ((1)\n  Fermi National Accelerator Laboratory, (2) Princeton University, (3) Fermi\n  National Accelerator Laboratory now Johns Hopkins University)", "title": "Big Data in HEP: A comprehensive use case study", "comments": "Proceedings for 22nd International Conference on Computing in High\n  Energy and Nuclear Physics (CHEP 2016)", "journal-ref": null, "doi": "10.1088/1742-6596/898/7/072012", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Experimental Particle Physics has been at the forefront of analyzing the\nworlds largest datasets for decades. The HEP community was the first to develop\nsuitable software and computing tools for this task. In recent times, new\ntoolkits and systems collectively called Big Data technologies have emerged to\nsupport the analysis of Petabyte and Exabyte datasets in industry. While the\nprinciples of data analysis in HEP have not changed (filtering and transforming\nexperiment-specific data formats), these new technologies use different\napproaches and promise a fresh look at analysis of very large datasets and\ncould potentially reduce the time-to-physics with increased interactivity. In\nthis talk, we present an active LHC Run 2 analysis, searching for dark matter\nwith the CMS detector, as a testbed for Big Data technologies. We directly\ncompare the traditional NTuple-based analysis with an equivalent analysis using\nApache Spark on the Hadoop ecosystem and beyond. In both cases, we start the\nanalysis with the official experiment data formats and produce publication\nphysics plots. We will discuss advantages and disadvantages of each approach\nand give an outlook on further studies needed.\n", "versions": [{"version": "v1", "created": "Sun, 12 Mar 2017 20:37:29 GMT"}], "update_date": "2017-11-23", "authors_parsed": [["Gutsche", "Oliver", ""], ["Cremonesi", "Matteo", ""], ["Elmer", "Peter", ""], ["Jayatilaka", "Bo", ""], ["Kowalkowski", "Jim", ""], ["Pivarski", "Jim", ""], ["Sehrish", "Saba", ""], ["Surez", "Cristina Mantilla", ""], ["Svyatkovskiy", "Alexey", ""], ["Tran", "Nhan", ""]]}, {"id": "1703.04215", "submitter": "Jinliang Xu", "authors": "Jinliang Xu, Shangguang Wang, Fangchun Yang, Jie Tang", "title": "Multiple User Context Inference by Fusing Data Sources", "comments": "This paper has been withdrawn by the author due to a crucial sign\n  error in some equations and figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inference of user context information, including user's gender, age, marital\nstatus, location and so on, has been proven to be valuable for building context\naware recommender system. However, prevalent existing studies on user context\ninference have two shortcommings: 1. focusing on only a single data source\n(e.g. Internet browsing logs, or mobile call records), and 2. ignoring the\ninterdependence of multiple user contexts (e.g. interdependence between age and\nmarital status), which have led to poor inference performance. To solve this\nproblem, in this paper, we first exploit tensor outer product to fuse multiple\ndata sources in the feature space to obtain an extensional user feature\nrepresentation. Following this, by taking this extensional user feature\nrepresentation as input, we propose a multiple attribute probabilistic model\ncalled MulAProM to infer user contexts that can take advantage of the\ninterdependence between them. Our study is based on large telecommunication\ndatasets from the local mobile operator of Shanghai, China, and consists of two\ndata sources, 4.6 million call detail records and 7.5 million data traffic\nrecords of 8,000 mobile users, collected in the course of six months. The\nexperimental results show that our model can outperform other models in terms\nof \\emph{recall}, \\emph{precision}, and the \\emph{F1-measure}.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 01:23:17 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 15:06:20 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Xu", "Jinliang", ""], ["Wang", "Shangguang", ""], ["Yang", "Fangchun", ""], ["Tang", "Jie", ""]]}, {"id": "1703.04216", "submitter": "Jinliang Xu", "authors": "Jinliang Xu, Shangguang Wang, Fangchun Yang, Rong N. Chang", "title": "Cognitive Inference of Demographic Data by User Ratings", "comments": "This paper has been withdrawn by the author due to a crucial sign\n  error in some equations and figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive inference of user demographics, such as gender and age, plays an\nimportant role in creating user profiles for adjusting marketing strategies and\ngenerating personalized recommendations because user demographic data is\nusually not available due to data privacy concerns. At present, users can\nreadily express feedback regarding products or services that they have\npurchased. During this process, user demographics are concealed, but the data\nhas never yet been successfully utilized to contribute to the cognitive\ninference of user demographics. In this paper, we investigate the inference\npower of user ratings data, and propose a simple yet general cognitive\ninference model, called rating to profile (R2P), to infer user demographics\nfrom user provided ratings. In particular, the proposed R2P model can achieve\nthe following: 1. Correctly integrate user ratings into model training. 2.Infer\nmultiple demographic attributes of users simultaneously, capturing the\nunderlying relevance between different demographic attributes. 3. Train its two\ncomponents, i.e. feature extractor and classifier, in an integrated manner\nunder a supervised learning paradigm, which effectively helps to discover\nuseful hidden patterns from highly sparse ratings data. We introduce how to\nincorporate user ratings data into the research field of cognitive inference of\nuser demographic data, and detail the model development and optimization\nprocess for the proposed R2P. Extensive experiments are conducted on two\nreal-world ratings datasets against various compared state-of-the-art methods,\nand the results from multiple aspects demonstrate that our proposed R2P model\ncan significantly improve on the cognitive inference performance of user\ndemographic data.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 01:23:31 GMT"}, {"version": "v2", "created": "Thu, 16 Mar 2017 15:07:33 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Xu", "Jinliang", ""], ["Wang", "Shangguang", ""], ["Yang", "Fangchun", ""], ["Chang", "Rong N.", ""]]}, {"id": "1703.04221", "submitter": "Zhe Li", "authors": "Ning Liu and Zhe Li and Zhiyuan Xu and Jielong Xu and Sheng Lin and\n  Qinru Qiu and Jian Tang and Yanzhi Wang", "title": "A Hierarchical Framework of Cloud Resource Allocation and Power\n  Management Using Deep Reinforcement Learning", "comments": "accepted by 37th IEEE International Conference on Distributed\n  Computing (ICDCS 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic decision-making approaches, such as reinforcement learning (RL),\nhave been applied to (partially) solve the resource allocation problem\nadaptively in the cloud computing system. However, a complete cloud resource\nallocation framework exhibits high dimensions in state and action spaces, which\nprohibit the usefulness of traditional RL techniques. In addition, high power\nconsumption has become one of the critical concerns in design and control of\ncloud computing systems, which degrades system reliability and increases\ncooling cost. An effective dynamic power management (DPM) policy should\nminimize power consumption while maintaining performance degradation within an\nacceptable level. Thus, a joint virtual machine (VM) resource allocation and\npower management framework is critical to the overall cloud computing system.\nMoreover, novel solution framework is necessary to address the even higher\ndimensions in state and action spaces. In this paper, we propose a novel\nhierarchical framework for solving the overall resource allocation and power\nmanagement problem in cloud computing systems. The proposed hierarchical\nframework comprises a global tier for VM resource allocation to the servers and\na local tier for distributed power management of local servers. The emerging\ndeep reinforcement learning (DRL) technique, which can deal with complicated\ncontrol problems with large state space, is adopted to solve the global tier\nproblem. Furthermore, an autoencoder and a novel weight sharing structure are\nadopted to handle the high-dimensional state space and accelerate the\nconvergence speed. On the other hand, the local tier of distributed server\npower managements comprises an LSTM based workload predictor and a model-free\nRL based power manager, operating in a distributed manner.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 01:49:27 GMT"}, {"version": "v2", "created": "Fri, 11 Aug 2017 18:58:12 GMT"}], "update_date": "2017-08-15", "authors_parsed": [["Liu", "Ning", ""], ["Li", "Zhe", ""], ["Xu", "Zhiyuan", ""], ["Xu", "Jielong", ""], ["Lin", "Sheng", ""], ["Qiu", "Qinru", ""], ["Tang", "Jian", ""], ["Wang", "Yanzhi", ""]]}, {"id": "1703.04367", "submitter": "Stefan Jaax", "authors": "Michael Blondin, Javier Esparza, Stefan Jaax, Philipp J. Meyer", "title": "Towards Efficient Verification of Population Protocols", "comments": "29 pages, 1 figure", "journal-ref": null, "doi": "10.1145/3087801.3087816", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population protocols are a well established model of computation by\nanonymous, identical finite state agents. A protocol is well-specified if from\nevery initial configuration, all fair executions reach a common consensus. The\ncentral verification question for population protocols is the\nwell-specification problem: deciding if a given protocol is well-specified.\nEsparza et al. have recently shown that this problem is decidable, but with\nvery high complexity: it is at least as hard as the Petri net reachability\nproblem, which is EXPSPACE-hard, and for which only algorithms of non-primitive\nrecursive complexity are currently known.\n  In this paper we introduce the class WS3 of well-specified strongly-silent\nprotocols and we prove that it is suitable for automatic verification. More\nprecisely, we show that WS3 has the same computational power as general\nwell-specified protocols, and captures standard protocols from the literature.\nMoreover, we show that the membership problem for WS3 reduces to solving\nboolean combinations of linear constraints over N. This allowed us to develop\nthe first software able to automatically prove well-specification for all of\nthe infinitely many possible inputs.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 13:03:47 GMT"}, {"version": "v2", "created": "Tue, 8 Aug 2017 09:31:00 GMT"}, {"version": "v3", "created": "Mon, 30 Jul 2018 10:44:35 GMT"}], "update_date": "2018-07-31", "authors_parsed": [["Blondin", "Michael", ""], ["Esparza", "Javier", ""], ["Jaax", "Stefan", ""], ["Meyer", "Philipp J.", ""]]}, {"id": "1703.04381", "submitter": "Othon Michail", "authors": "Othon Michail, George Skretas, Paul G. Spirakis", "title": "On the Transformation Capability of Feasible Mechanisms for Programmable\n  Matter", "comments": "48 pages, 32 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we study theoretical models of \\emph{programmable matter}\nsystems. The systems under consideration consist of spherical modules, kept\ntogether by magnetic forces and able to perform two minimal mechanical\noperations (or movements): \\emph{rotate} around a neighbor and \\emph{slide}\nover a line. In terms of modeling, there are $n$ nodes arranged in a\n2-dimensional grid and forming some initial \\emph{shape}. The goal is for the\ninitial shape $A$ to \\emph{transform} to some target shape $B$ by a sequence of\nmovements. Most of the paper focuses on \\emph{transformability} questions,\nmeaning whether it is in principle feasible to transform a given shape to\nanother. We first consider the case in which only rotation is available to the\nnodes. Our main result is that deciding whether two given shapes $A$ and $B$\ncan be transformed to each other, is in $\\mathbf{P}$. We then insist on\nrotation only and impose the restriction that the nodes must maintain global\nconnectivity throughout the transformation. We prove that the corresponding\ntransformability question is in $\\mathbf{PSPACE}$ and study the problem of\ndetermining the minimum \\emph{seeds} that can make feasible, otherwise\ninfeasible transformations. Next we allow both rotations and slidings and prove\nuniversality: any two connected shapes $A,B$ of the same order, can be\ntransformed to each other without breaking connectivity. The worst-case number\nof movements of the generic strategy is $\\Omega(n^2)$. We improve this to\n$O(n)$ parallel time, by a pipelining strategy, and prove optimality of both by\nmatching lower bounds. In the last part of the paper, we turn our attention to\ndistributed transformations. The nodes are now distributed processes able to\nperform communicate-compute-move rounds. We provide distributed algorithms for\na general type of transformations.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 13:31:17 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Michail", "Othon", ""], ["Skretas", "George", ""], ["Spirakis", "Paul G.", ""]]}, {"id": "1703.04519", "submitter": "Frederic Le Mouel", "authors": "Fr\\'ed\\'eric Le Mou\\\"el (CITI), Carlos Barrios Hern\\'andez (UIS),\n  Oscar Carrillo (CITI), Gabriel Pedraza (UIS)", "title": "Decentralized, Robust and Efficient Services for an Autonomous and\n  Real-time Urban Crisis Management", "comments": "in French. Colloque international interdisciplinaire Colombie --\n  France \" La Ville-R\\'egion durable comme projet: d\\'efis actuels. Regards\n  crois\\'es et perspectives \", Mar 2017, Bogota, Colombie", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The globalization of trade and the organization of work are currently causing\na large migratory flow towards the cities. This growth of cities requires new\nurban planning where digital tools take a preponderant place to capture data\nand understand and decide in face of changes. These tools however hardly resist\nto natural disasters, terrorism, accidents, etc. Based on the expertise of the\nCITI laboratory of INSA Lyon and SC3 of the Industrial University of Santander,\nwe propose to create the ALERT project - Autonomous Liable Emergency service in\nReal Time - with decentralized, reliable and efficient services, physically\nclose to the citizens, taking decisions locally, in a relevant manner without\nrisk of disconnection with a central authority. These information gathering and\ndecision-making will involve the population with participatory and social\napproaches.\n", "versions": [{"version": "v1", "created": "Mon, 6 Mar 2017 12:26:58 GMT"}], "update_date": "2017-03-14", "authors_parsed": [["Mou\u00ebl", "Fr\u00e9d\u00e9ric Le", "", "CITI"], ["Hern\u00e1ndez", "Carlos Barrios", "", "UIS"], ["Carrillo", "Oscar", "", "CITI"], ["Pedraza", "Gabriel", "", "UIS"]]}, {"id": "1703.04552", "submitter": "Yingqi Xiong", "authors": "Yingqi Xiong, Bin Wang, Chi-cheng Chu, Rajit Gadh", "title": "Distributed Optimal Vehicle Grid Integration Strategy with User Behavior\n  Prediction", "comments": "IEEE PES General Meeting 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing of electric vehicle (EV) adoption in recent years, the\nimpact of EV charging activities to the power grid becomes more and more\nsignificant. In this article, an optimal scheduling algorithm which combines\nsmart EV charging and V2G gird service is developed to integrate EVs into power\ngrid as distributed energy resources, with improved system cost performance.\nSpecifically, an optimization problem is formulated and solved at each EV\ncharging station according to control signal from aggregated control center and\nuser charging behavior prediction by mean estimation and linear regression. The\ncontrol center collects distributed optimization results and updates the\ncontrol signal, periodically. The iteration continues until it converges to\noptimal scheduling. Experimental result shows this algorithm helps fill the\nvalley and shave the peak in electric load profiles within a microgrid, while\nthe energy demand of individual driver can be satisfied.\n", "versions": [{"version": "v1", "created": "Mon, 13 Mar 2017 20:54:05 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Xiong", "Yingqi", ""], ["Wang", "Bin", ""], ["Chu", "Chi-cheng", ""], ["Gadh", "Rajit", ""]]}, {"id": "1703.04594", "submitter": "Alessandro Gabbana", "authors": "E. Calore, A. Gabbana, S. F. Schifano, R. Tripiccione", "title": "Optimization of Lattice Boltzmann Simulations on Heterogeneous Computers", "comments": null, "journal-ref": null, "doi": "10.1177/1094342017703771", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance computing systems are more and more often based on\naccelerators. Computing applications targeting those systems often follow a\nhost-driven approach in which hosts offload almost all compute-intensive\nsections of the code onto accelerators; this approach only marginally exploits\nthe computational resources available on the host CPUs, limiting performance\nand energy efficiency. The obvious step forward is to run compute-intensive\nkernels in a concurrent and balanced way on both hosts and accelerators. In\nthis paper we consider exactly this problem for a class of applications based\non Lattice Boltzmann Methods, widely used in computational fluid-dynamics. Our\ngoal is to develop just one program, portable and able to run efficiently on\nseveral different combinations of hosts and accelerators. To reach this goal,\nwe define common data layouts enabling the code to exploit efficiently the\ndifferent parallel and vector options of the various accelerators, and matching\nthe possibly different requirements of the compute-bound and memory-bound\nkernels of the application. We also define models and metrics that predict the\nbest partitioning of workloads among host and accelerator, and the optimally\nachievable overall performance level. We test the performance of our codes and\ntheir scaling properties using as testbeds HPC clusters incorporating different\naccelerators: Intel Xeon-Phi many-core processors, NVIDIA GPUs and AMD GPUs.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 17:20:39 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Calore", "E.", ""], ["Gabbana", "A.", ""], ["Schifano", "S. F.", ""], ["Tripiccione", "R.", ""]]}, {"id": "1703.04603", "submitter": "Sebastian Schweizer", "authors": "Egor Derevenetc, Roland Meyer, Sebastian Schweizer", "title": "Locality and Singularity for Store-Atomic Memory Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robustness is a correctness notion for concurrent programs running under\nrelaxed consistency models. The task is to check that the relaxed behavior\ncoincides (up to traces) with sequential consistency (SC). Although\ncomputationally simple on paper (robustness has been shown to be\nPSPACE-complete for TSO, PGAS, and Power), building a practical robustness\nchecker remains a challenge. The problem is that the various relaxations lead\nto a dramatic number of computations, only few of which violate robustness.\n  In the present paper, we set out to reduce the search space for robustness\ncheckers. We focus on store-atomic consistency models and establish two\ncompleteness results. The first result, called locality, states that a\nnon-robust program always contains a violating computation where only one\nthread delays commands. The second result, called singularity, is even stronger\nbut restricted to programs without lightweight fences. It states that there is\na violating computation where a single store is delayed.\n  As an application of the results, we derive a linear-size source-to-source\ntranslation of robustness to SC-reachability. It applies to general programs,\nregardless of the data domain and potentially with an unbounded number of\nthreads and with unbounded buffers. We have implemented the translation and\nverified, for the first time, PGAS algorithms in a fully automated fashion. For\nTSO, our analysis outperforms existing tools.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 17:28:27 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Derevenetc", "Egor", ""], ["Meyer", "Roland", ""], ["Schweizer", "Sebastian", ""]]}, {"id": "1703.04785", "submitter": "Myung Cho", "authors": "Myung Cho, Lifeng Lai, Weiyu Xu", "title": "Distributed Dual Coordinate Ascent in General Tree Networks and\n  Communication Network Effect on Synchronous Machine Learning", "comments": "34 pages, 18 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the big size of data and limited data storage volume of a single\ncomputer or a single server, data are often stored in a distributed manner.\nThus, performing large-scale machine learning operations with the distributed\ndatasets through communication networks is often required. In this paper, we\nstudy the convergence rate of the distributed dual coordinate ascent for\ndistributed machine learning problems in a general tree-structured network.\nSince a tree network model can be understood as the generalization of a star\nnetwork model, our algorithm can be thought of as the generalization of the\ndistributed dual coordinate ascent in a star network model. We provide the\nconvergence rate of the distributed dual coordinate ascent over a general tree\nnetwork in a recursive manner and analyze the network effect on the convergence\nrate. Secondly, by considering network communication delays, we optimize the\ndistributed dual coordinate ascent algorithm to maximize its convergence speed.\nFrom our analytical result, we can choose the optimal number of local\niterations depending on the communication delay severity to achieve the fastest\nconvergence speed. In numerical experiments, we consider machine learning\nscenarios over communication networks, where local workers cannot directly\nreach to a central node due to constraints in communication, and demonstrate\nthat the usability of our distributed dual coordinate ascent algorithm in tree\nnetworks. Additionally, we show that adapting number of local and global\niterations to network communication delays in the distributed dual coordinated\nascent algorithm can improve its convergence speed.\n", "versions": [{"version": "v1", "created": "Tue, 14 Mar 2017 22:30:57 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2018 04:16:33 GMT"}, {"version": "v3", "created": "Tue, 20 Nov 2018 13:53:07 GMT"}, {"version": "v4", "created": "Fri, 8 Mar 2019 21:53:45 GMT"}, {"version": "v5", "created": "Sun, 15 Mar 2020 06:42:31 GMT"}, {"version": "v6", "created": "Tue, 21 Jul 2020 11:53:36 GMT"}, {"version": "v7", "created": "Thu, 18 Feb 2021 16:20:37 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Cho", "Myung", ""], ["Lai", "Lifeng", ""], ["Xu", "Weiyu", ""]]}, {"id": "1703.05045", "submitter": "Emanuele Natale", "authors": "Luca Becchetti, Andrea Clementi, Pasin Manurangsi, Emanuele Natale,\n  Francesco Pasquale, Prasad Raghavendra, and Luca Trevisan", "title": "Average whenever you meet: Opportunistic protocols for community\n  detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following asynchronous, opportunistic communication model over a\ngraph $G$: in each round, one edge is activated uniformly and independently at\nrandom and (only) its two endpoints can exchange messages and perform local\ncomputations. Under this model, we study the following random process: The\nfirst time a vertex is an endpoint of an active edge, it chooses a random\nnumber, say $\\pm 1$ with probability $1/2$; then, in each round, the two\nendpoints of the currently active edge update their values to their average. We\nshow that, if $G$ exhibits a two-community structure (for example, two\nexpanders connected by a sparse cut), the values held by the nodes will\ncollectively reflect the underlying community structure over a suitable phase\nof the above process, allowing efficient and effective recovery in important\ncases.\n  In more detail, we first provide a first-moment analysis showing that, for a\nlarge class of almost-regular clustered graphs that includes the stochastic\nblock model, the expected values held by all but a negligible fraction of the\nnodes eventually reflect the underlying cut signal. We prove this property\nemerges after a mixing period of length $\\mathcal O(n\\log n)$. We further\nprovide a second-moment analysis for a more restricted class of regular\nclustered graphs that includes the regular stochastic block model. For this\ncase, we are able to show that most nodes can efficiently and locally identify\ntheir community of reference over a suitable time window. This results in the\nfirst opportunistic protocols that approximately recover community structure\nusing only polylogarithmic work per node. Even for the above class of regular\ngraphs, our second moment analysis requires new concentration bounds on the\nproduct of certain random matrices that are technically challenging and\npossibly of independent interest.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 09:35:37 GMT"}, {"version": "v2", "created": "Fri, 27 Oct 2017 15:45:26 GMT"}, {"version": "v3", "created": "Thu, 22 Feb 2018 00:28:00 GMT"}], "update_date": "2018-02-23", "authors_parsed": [["Becchetti", "Luca", ""], ["Clementi", "Andrea", ""], ["Manurangsi", "Pasin", ""], ["Natale", "Emanuele", ""], ["Pasquale", "Francesco", ""], ["Raghavendra", "Prasad", ""], ["Trevisan", "Luca", ""]]}, {"id": "1703.05106", "submitter": "Xie Pei", "authors": "Pei Xie, Keyou You and Cheng Wu", "title": "How to Stop Consensus Algorithms, locally?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies problems on locally stopping distributed consensus\nalgorithms over networks where each node updates its state by interacting with\nits neighbors and decides by itself whether certain level of agreement has been\nachieved among nodes. Since an individual node is unable to access the states\nof those beyond its neighbors, this problem becomes challenging. In this work,\nwe first define the stopping problem for generic distributed algorithms. Then,\na distributed algorithm is explicitly provided for each node to stop consensus\nupdating by exploring the relationship between the so-called local and global\nconsensus. Finally, we show both in theory and simulation that its\neffectiveness depends both on the network size and the structure.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 12:11:25 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Xie", "Pei", ""], ["You", "Keyou", ""], ["Wu", "Cheng", ""]]}, {"id": "1703.05126", "submitter": "Pengfei Zuo", "authors": "Pengfei Zuo, Yu Hua, Cong Wang, Wen Xia, Shunde Cao, Yukun Zhou,\n  Yuanyuan Sun", "title": "Bandwidth-efficient Storage Services for Mitigating Side Channel Attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data deduplication is able to effectively identify and eliminate redundant\ndata and only maintain a single copy of files and chunks. Hence, it is widely\nused in cloud storage systems to save storage space and network bandwidth.\nHowever, the occurrence of deduplication can be easily identified by monitoring\nand analyzing network traffic, which leads to the risk of user privacy leakage.\nThe attacker can carry out a very dangerous side channel attack, i.e.,\nlearn-the-remaining-information (LRI) attack, to reveal users' privacy\ninformation by exploiting the side channel of network traffic in deduplication.\nExisting work addresses the LRI attack at the cost of the high bandwidth\nefficiency of deduplication. In order to address this problem, we propose a\nsimple yet effective scheme, called randomized redundant chunk scheme (RRCS),\nto significantly mitigate the risk of the LRI attack while maintaining the high\nbandwidth efficiency of deduplication. The basic idea behind RRCS is to add\nrandomized redundant chunks to mix up the real deduplication states of files\nused for the LRI attack, which effectively obfuscates the view of the attacker,\nwho attempts to exploit the side channel of network traffic for the LRI attack.\nOur security analysis shows that RRCS could significantly mitigate the risk of\nthe LRI attack. We implement the RRCS prototype and evaluate it by using three\nlarge-scale real-world datasets. Experimental results demonstrate the\nefficiency and efficacy of RRCS.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 12:45:17 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Zuo", "Pengfei", ""], ["Hua", "Yu", ""], ["Wang", "Cong", ""], ["Xia", "Wen", ""], ["Cao", "Shunde", ""], ["Zhou", "Yukun", ""], ["Sun", "Yuanyuan", ""]]}, {"id": "1703.05424", "submitter": "Zhuolun Xiang", "authors": "Zhuolun Xiang and Nitin H. Vaidya", "title": "Partially Replicated Causally Consistent Shared Memory: Lower Bounds and\n  An Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this paper is on causal consistency in a {\\em partially\nreplicated} distributed shared memory (DSM) system that provides the\nabstraction of shared read/write registers. Maintaining causal consistency in\ndistributed shared memory systems has received significant attention in the\npast, mostly on {\\em full replication} wherein each replica stores a copy of\nall the registers in the shared memory. To ensure causal consistency, all\ncausally preceding updates must be performed before an update is performed at\nany given replica. Therefore, some mechanism for tracking causal dependencies\nis required, such as vector timestamps with the number of vector elements being\nequal to the number of replicas in the context of full replication. In this\npaper, we investigate causal consistency in {\\em partially replicated systems},\nwherein each replica may store only a subset of the shared registers. Building\non the past work, this paper makes three key contributions: 1. We present a\nnecessary condition on the metadata (which we refer as a {\\em timestamp}) that\nmust be maintained by each replica to be able to track causality accurately.\nThe necessary condition identifies a set of directed edges in a {\\em share\ngraph} that a replica's timestamp must keep track of. 2. We present an\nalgorithm for achieving causal consistency using a timestamp that matches the\nabove necessary condition, thus showing that the condition is necessary and\nsufficient. 3. We define a measurement of timestamp space size and present a\nlower bound (in bits) on the size of the timestamps. The lower bound matches\nour algorithm in several special cases.\n", "versions": [{"version": "v1", "created": "Wed, 15 Mar 2017 23:34:24 GMT"}, {"version": "v2", "created": "Sun, 13 May 2018 07:31:38 GMT"}, {"version": "v3", "created": "Wed, 29 May 2019 05:33:50 GMT"}], "update_date": "2019-05-30", "authors_parsed": [["Xiang", "Zhuolun", ""], ["Vaidya", "Nitin H.", ""]]}, {"id": "1703.05435", "submitter": "Mitar Milutinovic", "authors": "Mitar Milutinovic, Warren He, Howard Wu, Maxinder Kanwal", "title": "Proof of Luck: an Efficient Blockchain Consensus Protocol", "comments": "SysTEX '16, December 12-16, 2016, Trento, Italy", "journal-ref": null, "doi": "10.1145/3007788.3007790", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper, we present designs for multiple blockchain consensus primitives\nand a novel blockchain system, all based on the use of trusted execution\nenvironments (TEEs), such as Intel SGX-enabled CPUs. First, we show how using\nTEEs for existing proof of work schemes can make mining equitably distributed\nby preventing the use of ASICs. Next, we extend the design with proof of time\nand proof of ownership consensus primitives to make mining energy- and\ntime-efficient. Further improving on these designs, we present a blockchain\nusing a proof of luck consensus protocol. Our proof of luck blockchain uses a\nTEE platform's random number generation to choose a consensus leader, which\noffers low-latency transaction validation, deterministic confirmation time,\nnegligible energy consumption, and equitably distributed mining. Lastly, we\ndiscuss a potential protection against up to a constant number of compromised\nTEEs.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 00:32:02 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Milutinovic", "Mitar", ""], ["He", "Warren", ""], ["Wu", "Howard", ""], ["Kanwal", "Maxinder", ""]]}, {"id": "1703.05509", "submitter": "Christian Schulz", "authors": "Christian Schulz and Jesper Larsson Tr\\\"aff", "title": "VieM v1.00 -- Vienna Mapping and Sparse Quadratic Assignment User Guide", "comments": "arXiv admin note: text overlap with arXiv:1311.1714", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper severs as a user guide to the mapping framework VieM (Vienna\nMapping and Sparse Quadratic Assignment). We give a rough overview of the\ntechniques used within the framework and describe the user interface as well as\nthe file formats used.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 08:52:21 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["Schulz", "Christian", ""], ["Tr\u00e4ff", "Jesper Larsson", ""]]}, {"id": "1703.05647", "submitter": "Blair Archibald", "authors": "Blair Archibald, Patrick Maier, Ciaran McCreesh, Rob Stewart, Phil\n  Trinder", "title": "Replicable Parallel Branch and Bound Search", "comments": "36 pages, 12 figures, submitted to the Journal of Parallel and\n  Distributed Computing", "journal-ref": null, "doi": "10.1016/j.jpdc.2017.10.010", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Combinatorial branch and bound searches are a common technique for solving\nglobal optimisation and decision problems. Their performance often depends on\ngood search order heuristics, refined over decades of algorithms research.\nParallel search necessarily deviates from the sequential search order,\nsometimes dramatically and unpredictably, e.g. by distributing work at random.\nThis can disrupt effective search order heuristics and lead to unexpected and\nhighly variable parallel performance. The variability makes it hard to reason\nabout the parallel performance of combinatorial searches.\n  This paper presents a generic parallel branch and bound skeleton, implemented\nin Haskell, with replicable parallel performance. The skeleton aims to preserve\nthe search order heuristic by distributing work in an ordered fashion, closely\nfollowing the sequential search order. We demonstrate the generality of the\napproach by applying the skeleton to 40 instances of three combinatorial\nproblems: Maximum Clique, 0/1 Knapsack and Travelling Salesperson. The\noverheads of our Haskell skeleton are reasonable: giving slowdown factors of\nbetween 1.9 and 6.2 compared with a class-leading, dedicated, and highly\noptimised C++ Maximum Clique solver. We demonstrate scaling up to 200 cores of\na Beowulf cluster, achieving speedups of 100x for several Maximum Clique\ninstances. We demonstrate low variance of parallel performance across all\ninstances of the three combinatorial problems and at all scales up to 200\ncores, with median Relative Standard Deviation (RSD) below 2%. Parallel solvers\nthat do not follow the sequential search order exhibit far higher variance,\nwith median RSD exceeding 85% for Knapsack.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 14:43:09 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 14:13:35 GMT"}], "update_date": "2017-11-28", "authors_parsed": [["Archibald", "Blair", ""], ["Maier", "Patrick", ""], ["McCreesh", "Ciaran", ""], ["Stewart", "Rob", ""], ["Trinder", "Phil", ""]]}, {"id": "1703.05713", "submitter": "Bas Van IJzendoorn", "authors": "Bas van IJzendoorn", "title": "The challenge of decentralized marketplaces", "comments": "responsible teacher: Johan Pouwelse", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online trust systems are playing an important role in to-days world and face\nvarious challenges in building them. Billions of dollars of products and\nservices are traded through electronic commerce, files are shared among large\npeer-to-peer networks and smart contracts can potentially replace paper\ncontracts with digital contracts. These systems rely on trust mechanisms in\npeer-to-peer networks like reputation systems or a trustless public ledger. In\nmost cases, reputation systems are build to determine the trustworthiness of\nusers and to provide incentives for users to make a fair contribution to the\npeer-to-peer network. The main challenges are how to set up a good trust\nsystem, how to deal with security issues and how to deal with strategic users\ntrying to cheat on the system. The Sybil attack, the most important attack on\nreputation systems is discussed. At last match making in two sided markets and\nthe strategy proofness of these markets are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 16 Mar 2017 16:48:28 GMT"}], "update_date": "2017-03-17", "authors_parsed": [["van IJzendoorn", "Bas", ""]]}, {"id": "1703.06058", "submitter": "Lixing Chen", "authors": "Lixing Chen, Sheng Zhou, Jie Xu", "title": "Computation Peer Offloading for Energy-Constrained Mobile Edge Computing\n  in Small-Cell Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The (ultra-)dense deployment of small-cell base stations (SBSs) endowed with\ncloud-like computing functionalities paves the way for pervasive mobile edge\ncomputing (MEC), enabling ultra-low latency and location-awareness for a\nvariety of emerging mobile applications and the Internet of Things. To handle\nspatially uneven computation workloads in the network, cooperation among SBSs\nvia workload peer offloading is essential to avoid large computation latency at\noverloaded SBSs and provide high quality of service to end users. However,\nperforming effective peer offloading faces many unique challenges in small cell\nnetworks due to limited energy resources committed by self-interested SBS\nowners, uncertainties in the system dynamics and co-provisioning of radio\naccess and computing services. This paper develops a novel online SBS peer\noffloading framework, called OPEN, by leveraging the Lyapunov technique, in\norder to maximize the long-term system performance while keeping the energy\nconsumption of SBSs below individual long-term constraints. OPEN works online\nwithout requiring information about future system dynamics, yet provides\nprovably near-optimal performance compared to the oracle solution that has the\ncomplete future information. In addition, this paper formulates a novel peer\noffloading game among SBSs, analyzes its equilibrium and efficiency loss in\nterms of the price of anarchy in order to thoroughly understand SBSs' strategic\nbehaviors, thereby enabling decentralized and autonomous peer offloading\ndecision making. Extensive simulations are carried out and show that peer\noffloading among SBSs dramatically improves the edge computing performance.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 15:50:41 GMT"}, {"version": "v2", "created": "Fri, 25 May 2018 20:21:24 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Chen", "Lixing", ""], ["Zhou", "Sheng", ""], ["Xu", "Jie", ""]]}, {"id": "1703.06065", "submitter": "Urvashi Oswal", "authors": "Urvashi Oswal, Swayambhoo Jain, Kevin S. Xu, and Brian Eriksson", "title": "Block CUR: Decomposing Matrices using Groups of Columns", "comments": "shorter version to appear in ECML-PKDD 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common problem in large-scale data analysis is to approximate a matrix\nusing a combination of specifically sampled rows and columns, known as CUR\ndecomposition. Unfortunately, in many real-world environments, the ability to\nsample specific individual rows or columns of the matrix is limited by either\nsystem constraints or cost. In this paper, we consider matrix approximation by\nsampling predefined \\emph{blocks} of columns (or rows) from the matrix. We\npresent an algorithm for sampling useful column blocks and provide novel\nguarantees for the quality of the approximation. This algorithm has application\nin problems as diverse as biometric data analysis to distributed computing. We\ndemonstrate the effectiveness of the proposed algorithms for computing the\nBlock CUR decomposition of large matrices in a distributed setting with\nmultiple nodes in a compute cluster, where such blocks correspond to columns\n(or rows) of the matrix stored on the same node, which can be retrieved with\nmuch less overhead than retrieving individual columns stored across different\nnodes. In the biometric setting, the rows correspond to different users and\ncolumns correspond to users' biometric reaction to external stimuli, {\\em\ne.g.,}~watching video content, at a particular time instant. There is\nsignificant cost in acquiring each user's reaction to lengthy content so we\nsample a few important scenes to approximate the biometric response. An\nindividual time sample in this use case cannot be queried in isolation due to\nthe lack of context that caused that biometric reaction. Instead, collections\nof time segments ({\\em i.e.,} blocks) must be presented to the user. The\npractical application of these algorithms is shown via experimental results\nusing real-world user biometric data from a content testing environment.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 16:08:23 GMT"}, {"version": "v2", "created": "Mon, 9 Jul 2018 14:27:52 GMT"}], "update_date": "2018-07-10", "authors_parsed": [["Oswal", "Urvashi", ""], ["Jain", "Swayambhoo", ""], ["Xu", "Kevin S.", ""], ["Eriksson", "Brian", ""]]}, {"id": "1703.06130", "submitter": "Chaodong Zheng", "authors": "Seth Gilbert, Fabian Kuhn, Chaodong Zheng", "title": "Communication Primitives in Cognitive Radio Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive radio networks are a new type of multi-channel wireless network in\nwhich different nodes can have access to different sets of channels. By\nproviding multiple channels, they improve the efficiency and reliability of\nwireless communication. However, the heterogeneous nature of cognitive radio\nnetworks also brings new challenges to the design and analysis of distributed\nalgorithms.\n  In this paper, we focus on two fundamental problems in cognitive radio\nnetworks: neighbor discovery, and global broadcast. We consider a network\ncontaining $n$ nodes, each of which has access to $c$ channels. We assume the\nnetwork has diameter $D$, and each pair of neighbors have at least $k\\geq 1$,\nand at most $k_{max}\\leq c$, shared channels. We also assume each node has at\nmost $\\Delta$ neighbors. For the neighbor discovery problem, we design a\nrandomized algorithm CSeek which has time complexity\n$\\tilde{O}((c^2/k)+(k_{max}/k)\\cdot\\Delta)$. CSeek is flexible and robust,\nwhich allows us to use it as a generic \"filter\" to find \"well-connected\"\nneighbors with an even shorter running time. We then move on to the global\nbroadcast problem, and propose CGCast, a randomized algorithm which takes\n$\\tilde{O}((c^2/k)+(k_{max}/k)\\cdot\\Delta+D\\cdot\\Delta)$ time. CGCast uses\nCSeek to achieve communication among neighbors, and uses edge coloring to\nestablish an efficient schedule for fast message dissemination.\n  Towards the end of the paper, we give lower bounds for solving the two\nproblems. These lower bounds demonstrate that in many situations, CSeek and\nCGCast are near optimal.\n", "versions": [{"version": "v1", "created": "Fri, 17 Mar 2017 17:48:21 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Gilbert", "Seth", ""], ["Kuhn", "Fabian", ""], ["Zheng", "Chaodong", ""]]}, {"id": "1703.06376", "submitter": "Ehab Salahat Mr", "authors": "Ehab Salahat and Murad Qasaimeh", "title": "Recent Advances in Features Extraction and Description Algorithms: A\n  Comprehensive Survey", "comments": "Annual IEEE Industrial Electronics Societys 18th International Conf.\n  on Industrial Technology (ICIT), 22-25 March, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer vision is one of the most active research fields in information\ntechnology today. Giving machines and robots the ability to see and comprehend\nthe surrounding world at the speed of sight creates endless potential\napplications and opportunities. Feature detection and description algorithms\ncan be indeed considered as the retina of the eyes of such machines and robots.\nHowever, these algorithms are typically computationally intensive, which\nprevents them from achieving the speed of sight real-time performance. In\naddition, they differ in their capabilities and some may favor and work better\ngiven a specific type of input compared to others. As such, it is essential to\ncompactly report their pros and cons as well as their performances and recent\nadvances. This paper is dedicated to provide a comprehensive overview on the\nstate-of-the-art and recent advances in feature detection and description\nalgorithms. Specifically, it starts by overviewing fundamental concepts. It\nthen compares, reports and discusses their performance and capabilities. The\nMaximally Stable Extremal Regions algorithm and the Scale Invariant Feature\nTransform algorithms, being two of the best of their type, are selected to\nreport their recent algorithmic derivatives.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 01:00:27 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Salahat", "Ehab", ""], ["Qasaimeh", "Murad", ""]]}, {"id": "1703.06391", "submitter": "Hongwei Xi", "authors": "Hongwei Xi and Hanwen Wu", "title": "Multirole Logic (Extended Abstract)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.LO cs.DC cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We identify multirole logic as a new form of logic in which\nconjunction/disjunction is interpreted as an ultrafilter on the power set of\nsome underlying set (of roles) and the notion of negation is generalized to\nendomorphisms on this underlying set. We formalize both multirole logic (MRL)\nand linear multirole logic (LMRL) as natural generalizations of classical logic\n(CL) and classical linear logic (CLL), respectively, and also present a\nfilter-based interpretation for intuitionism in multirole logic. Among various\nmeta-properties established for MRL and LMRL, we obtain one named multiparty\ncut-elimination stating that every cut involving one or more sequents (as a\ngeneralization of a (binary) cut involving exactly two sequents) can be\neliminated, thus extending the celebrated result of cut-elimination by Gentzen.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 04:47:19 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Xi", "Hongwei", ""], ["Wu", "Hanwen", ""]]}, {"id": "1703.06409", "submitter": "Farzad Khodadadi", "authors": "Farzad Khodadadi, Amir Vahid Dastjerdi, and Rajkumar Buyya", "title": "Internet of Things: An Overview", "comments": "Keywords: Internet of Things; IoT; Web of Things; Cloud of Things", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As technology proceeds and the number of smart devices continues to grow\nsubstantially, need for ubiquitous context-aware platforms that support\ninterconnected, heterogeneous, and distributed network of devices has given\nrise to what is referred today as Internet-of-Things. However, paving the path\nfor achieving aforementioned objectives and making the IoT paradigm more\ntangible requires integration and convergence of different knowledge and\nresearch domains, covering aspects from identification and communication to\nresource discovery and service integration. Through this chapter, we aim to\nhighlight researches in topics including proposed architectures, security and\nprivacy, network communication means and protocols, and eventually conclude by\nproviding future directions and open challenges facing the IoT development.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 09:58:52 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Khodadadi", "Farzad", ""], ["Dastjerdi", "Amir Vahid", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1703.06416", "submitter": "Tam Nguyen", "authors": "Tam Nguyen, Takeshi Hatanaka, Mamoru Doi, Emanuele Garone, Masayuki\n  Fujita", "title": "A Passivity-Based Distributed Reference Governor for Constrained Robotic\n  Networks", "comments": "8 pages, International Federation of Automatic Conference 2017, 8\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC cs.RO cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on a passivity-based distributed reference governor (RG)\napplied to a pre-stabilized mobile robotic network. The novelty of this paper\nlies in the method used to solve the RG problem, where a passivity-based\ndistributed optimization scheme is proposed. In particular, the gradient\ndescent method minimizes the global objective function while the dual ascent\nmethod maximizes the Hamiltonian. To make the agents converge to the agreed\noptimal solution, a proportional-integral consensus estimator is used. This\npaper proves the convergence of the state estimates of the RG to the optimal\nsolution through passivity arguments, considering the physical system static.\nThen, the effectiveness of the scheme considering the dynamics of the physical\nsystem is demonstrated through simulations and experiments.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 10:35:17 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Nguyen", "Tam", ""], ["Hatanaka", "Takeshi", ""], ["Doi", "Mamoru", ""], ["Garone", "Emanuele", ""], ["Fujita", "Masayuki", ""]]}, {"id": "1703.06503", "submitter": "Cedric Nugteren", "authors": "Cedric Nugteren and Valeriu Codreanu", "title": "CLTune: A Generic Auto-Tuner for OpenCL Kernels", "comments": "8 pages, published in MCSoC '15, IEEE 9th International Symposium on\n  Embedded Multicore/Many-core Systems-on-Chip (MCSoC), 2015", "journal-ref": null, "doi": "10.1109/MCSoC.2015.10", "report-no": null, "categories": "cs.PF cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work presents CLTune, an auto-tuner for OpenCL kernels. It evaluates and\ntunes kernel performance of a generic, user-defined search space of possible\nparameter-value combinations. Example parameters include the OpenCL workgroup\nsize, vector data-types, tile sizes, and loop unrolling factors. CLTune can be\nused in the following scenarios: 1) when there are too many tunable parameters\nto explore manually, 2) when performance portability across OpenCL devices is\ndesired, or 3) when the optimal parameters change based on input argument\nvalues (e.g. matrix dimensions). The auto-tuner is generic, easy to use,\nopen-source, and supports multiple search strategies including simulated\nannealing and particle swarm optimisation. CLTune is evaluated on two GPU\ncase-studies inspired by the recent successes in deep learning: 2D convolution\nand matrix-multiplication (GEMM). For 2D convolution, we demonstrate the need\nfor auto-tuning by optimizing for different filter sizes, achieving performance\non-par or better than the state-of-the-art. For matrix-multiplication, we use\nCLTune to explore a parameter space of more than two-hundred thousand\nconfigurations, we show the need for device-specific tuning, and outperform the\nclBLAS library on NVIDIA, AMD and Intel GPUs.\n", "versions": [{"version": "v1", "created": "Sun, 19 Mar 2017 20:10:00 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Nugteren", "Cedric", ""], ["Codreanu", "Valeriu", ""]]}, {"id": "1703.06577", "submitter": "EPTCS", "authors": "Hubert Garavel, Wendelin Serwe", "title": "The Unheralded Value of the Multiway Rendezvous: Illustration with the\n  Production Cell Benchmark", "comments": "In Proceedings MARS 2017, arXiv:1703.05812", "journal-ref": "EPTCS 244, 2017, pp. 230-270", "doi": "10.4204/EPTCS.244.10", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The multiway rendezvous introduced in Theoretical CSP is a powerful paradigm\nto achieve synchronization and communication among a group of (possibly more\nthan two) processes. We illustrate the advantages of this paradigm on the\nproduction cell benchmark, a model of a real metal processing plant, for which\nwe propose a compositional software controller, which is written in LNT and\nLOTOS, and makes intensive use of the multiway rendezvous.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 02:49:31 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Garavel", "Hubert", ""], ["Serwe", "Wendelin", ""]]}, {"id": "1703.06590", "submitter": "EPTCS", "authors": "Jan Kofro\\v{n} (Charles University), Jana Tumova (KTH Royal Institute\n  of Technology)", "title": "Proceedings International Workshop on Formal Engineering approaches to\n  Software Components and Architectures", "comments": null, "journal-ref": "EPTCS 245, 2017", "doi": "10.4204/EPTCS.245", "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  These are the proceedings of the 14th International Workshop on Formal\nEngineering approaches to Software Components and Architectures (FESCA). The\nworkshop was held on April 22, 2017 in Uppsala (Sweden) as a satellite event to\nthe European Joint Conference on Theory and Practice of Software (ETAPS'17).\n  The aim of the FESCA workshop is to bring together junior researchers from\nformal methods, software engineering, and industry interested in the\ndevelopment and application of formal modelling approaches as well as\nassociated analysis and reasoning techniques with practical benefits for\nsoftware engineering.\n  In recent years, the growing importance of functional correctness and the\nincreased relevance of system quality properties (e.g. performance,\nreliability, security) have stimulated the emergence of analytical and\nmodelling techniques for the design and development of software systems. With\nthe increasing complexity and utilization of today's software systems, FESCA\naims at addressing two research questions: (1) what role is played by the\nsoftware design phase in the systematic addressing of the analytical and\nmodelling challenges, and (2) how can formal and semi-formal techniques be\neffectively applied to make the issues easier to address automatically, with\nlower human intervention.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 04:18:48 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Kofro\u0148", "Jan", "", "Charles University"], ["Tumova", "Jana", "", "KTH Royal Institute\n  of Technology"]]}, {"id": "1703.06659", "submitter": "Shuo Chen", "authors": "Shuo Chen, Rongxing Lu, and Jie Zhang", "title": "A Flexible Privacy-preserving Framework for Singular Value Decomposition\n  under Internet of Things Environment", "comments": "24 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The singular value decomposition (SVD) is a widely used matrix factorization\ntool which underlies plenty of useful applications, e.g. recommendation system,\nabnormal detection and data compression. Under the environment of emerging\nInternet of Things (IoT), there would be an increasing demand for data analysis\nto better human's lives and create new economic growth points. Moreover, due to\nthe large scope of IoT, most of the data analysis work should be done in the\nnetwork edge, i.e. handled by fog computing. However, the devices which provide\nfog computing may not be trustable while the data privacy is often the\nsignificant concern of the IoT application users. Thus, when performing SVD for\ndata analysis purpose, the privacy of user data should be preserved. Based on\nthe above reasons, in this paper, we propose a privacy-preserving fog computing\nframework for SVD computation. The security and performance analysis shows the\npracticability of the proposed framework. Furthermore, since different\napplications may utilize the result of SVD operation in different ways, three\napplications with different objectives are introduced to show how the framework\ncould flexibly achieve the purposes of different applications, which indicates\nthe flexibility of the design.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 10:35:44 GMT"}, {"version": "v2", "created": "Wed, 22 Mar 2017 04:35:23 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Chen", "Shuo", ""], ["Lu", "Rongxing", ""], ["Zhang", "Jie", ""]]}, {"id": "1703.06680", "submitter": "Gabriele D'Angelo", "authors": "Moreno Marzolla, Gabriele D'Angelo", "title": "Parallel Sort-Based Matching for Data Distribution Management on\n  Shared-Memory Multiprocessors", "comments": "Proceedings of the 21-th ACM/IEEE International Symposium on\n  Distributed Simulation and Real Time Applications (DS-RT 2017). Best Paper\n  Award @DS-RT 2017", "journal-ref": null, "doi": "10.1109/DISTRA.2017.8167660", "report-no": null, "categories": "cs.DC cs.DS cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of identifying intersections between\ntwo sets of d-dimensional axis-parallel rectangles. This is a common problem\nthat arises in many agent-based simulation studies, and is of central\nimportance in the context of High Level Architecture (HLA), where it is at the\ncore of the Data Distribution Management (DDM) service. Several realizations of\nthe DDM service have been proposed; however, many of them are either\ninefficient or inherently sequential. These are serious limitations since\nmulticore processors are now ubiquitous, and DDM algorithms -- being\nCPU-intensive -- could benefit from additional computing power. We propose a\nparallel version of the Sort-Based Matching algorithm for shared-memory\nmultiprocessors. Sort-Based Matching is one of the most efficient serial\nalgorithms for the DDM problem, but is quite difficult to parallelize due to\ndata dependencies. We describe the algorithm and compute its asymptotic running\ntime; we complete the analysis by assessing its performance and scalability\nthrough extensive experiments on two commodity multicore systems based on a\ndual socket Intel Xeon processor, and a single socket Intel Core i7 processor.\n", "versions": [{"version": "v1", "created": "Mon, 20 Mar 2017 11:17:39 GMT"}, {"version": "v2", "created": "Thu, 6 Jul 2017 06:02:24 GMT"}, {"version": "v3", "created": "Wed, 25 Oct 2017 08:42:20 GMT"}, {"version": "v4", "created": "Tue, 7 Aug 2018 07:20:05 GMT"}], "update_date": "2018-08-08", "authors_parsed": [["Marzolla", "Moreno", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "1703.07150", "submitter": "Stefano Bennati", "authors": "Stefano Bennati and Catholijn M. Jonker", "title": "PriMaL: A Privacy-Preserving Machine Learning Method for Event Detection\n  in Distributed Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces PriMaL, a general PRIvacy-preserving MAchine-Learning\nmethod for reducing the privacy cost of information transmitted through a\nnetwork. Distributed sensor networks are often used for automated\nclassification and detection of abnormal events in high-stakes situations, e.g.\nfire in buildings, earthquakes, or crowd disasters. Such networks might\ntransmit privacy-sensitive information, e.g. GPS location of smartphones, which\nmight be disclosed if the network is compromised. Privacy concerns might slow\ndown the adoption of the technology, in particular in the scenario of social\nsensing where participation is voluntary, thus solutions are needed which\nimprove privacy without compromising on the event detection accuracy. PriMaL is\nimplemented as a machine-learning layer that works on top of an existing event\ndetection algorithm. Experiments are run in a general simulation framework, for\nseveral network topologies and parameter values. The privacy footprint of\nstate-of-the-art event detection algorithms is compared within the proposed\nframework. Results show that PriMaL is able to reduce the privacy cost of a\ndistributed event detection algorithm below that of the corresponding\ncentralized algorithm, within the bounds of some assumptions about the\nprotocol. Moreover the performance of the distributed algorithm is not\nstatistically worse than that of the centralized algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 11:15:15 GMT"}], "update_date": "2017-03-22", "authors_parsed": [["Bennati", "Stefano", ""], ["Jonker", "Catholijn M.", ""]]}, {"id": "1703.07417", "submitter": "Yasamin Nazari", "authors": "Michael Dinitz, Yasamin Nazari", "title": "Distributed Distance-Bounded Network Design Through Distributed Convex\n  Programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Solving linear programs is often a challenging task in distributed settings.\nWhile there are good algorithms for solving packing and covering linear\nprograms in a distributed manner (Kuhn et al.~2006), this is essentially the\nonly class of linear programs for which such an algorithm is known. In this\nwork we provide a distributed algorithm for solving a different class of convex\nprograms which we call \"distance-bounded network design convex programs\". These\ncan be thought of as relaxations of network design problems in which the\nconnectivity requirement includes a distance constraint (most notably, graph\nspanners). Our algorithm runs in $O( (D/\\epsilon) \\log n)$ rounds in the\n$\\mathcal{LOCAL}$ model and finds a $(1+\\epsilon)$-approximation to the optimal\nLP solution for any $0 < \\epsilon \\leq 1$, where $D$ is the largest distance\nconstraint. While solving linear programs in a distributed setting is\ninteresting in its own right, this class of convex programs is particularly\nimportant because solving them is often a crucial step when designing\napproximation algorithms. Hence we almost immediately obtain new and improved\ndistributed approximation algorithms for a variety of network design problems,\nincluding Basic $3$- and $4$-Spanner, Directed $k$-Spanner, Lowest Degree\n$k$-Spanner, and Shallow-Light Steiner Network Design with a spanning demand\ngraph. Our algorithms do not require any \"heavy\" computation and essentially\nmatch the best-known centralized approximation algorithms, while previous\napproaches which do not use heavy computation give approximations which are\nworse than the best-known centralized bounds.\n", "versions": [{"version": "v1", "created": "Tue, 21 Mar 2017 20:28:52 GMT"}, {"version": "v2", "created": "Fri, 31 Mar 2017 18:05:45 GMT"}, {"version": "v3", "created": "Fri, 8 Sep 2017 19:37:51 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Dinitz", "Michael", ""], ["Nazari", "Yasamin", ""]]}, {"id": "1703.07562", "submitter": "Josef Spillner", "authors": "Josef Spillner", "title": "Snafu: Function-as-a-Service (FaaS) Runtime Design and Implementation", "comments": "15 pages, 9 figures, 4 tables, repeatable, unreviewed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Snafu, or Snake Functions, is a modular system to host, execute and manage\nlanguage-level functions offered as stateless (micro-)services to diverse\nexternal triggers. The system interfaces resemble those of commercial FaaS\nproviders but its implementation provides distinct features which make it\noverall useful to research on FaaS and prototyping of FaaS-based applications.\nThis paper argues about the system motivation in the presence of already\nexisting alternatives, its design and architecture, the open source\nimplementation and collected metrics which characterise the system.\n", "versions": [{"version": "v1", "created": "Wed, 22 Mar 2017 08:32:59 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Spillner", "Josef", ""]]}, {"id": "1703.08015", "submitter": "Tadeusz Tomczak", "authors": "Tadeusz Tomczak, Roman G. Szafran", "title": "Sparse geometries handling in lattice-Boltzmann method implementation\n  for graphic processors", "comments": "Accepted in IEEE Transactions on Parallel and Distributed Systems, 14\n  pages, 9 figures, 5 tables", "journal-ref": null, "doi": "10.1109/TPDS.2018.2810237", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a high-performance implementation of the lattice-Boltzmann method\n(LBM) for sparse geometries on graphic processors. In our implementation we\ncover the whole geometry with a uniform mesh of small tiles and carry out\ncalculations for each tile independently with a proper data synchronization at\ntile edges. For this method we provide both the theoretical analysis of\ncomplexity and the results for real implementations for 2D and 3D geometries.\nBased on the theoretical model, we show that tiles offer significantly smaller\nbandwidth overhead than solutions based on indirect addressing. For\n2-dimensional lattice arrangements a reduction of memory usage is also\npossible, though at the cost of diminished performance. We reached the\nperformance of 682 MLUPS on GTX Titan (72\\% of peak theoretical memory\nbandwidth) for D3Q19 lattice arrangement and double precision data.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 11:38:36 GMT"}, {"version": "v2", "created": "Tue, 29 May 2018 06:13:42 GMT"}], "update_date": "2018-05-30", "authors_parsed": [["Tomczak", "Tadeusz", ""], ["Szafran", "Roman G.", ""]]}, {"id": "1703.08212", "submitter": "Joshua Beizer", "authors": "Joshua Beizer", "title": "Speeding up TestU01 with the use of HTCondor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Testing random number generators is a very important task that, in the resent\npast, has taken upwards of twelve hours when testing with the current agship\ntesting suite TestU01. Through this paper we will discuss the possible\nperformance increases to the existing random number generator testing suite\nTestU01 that are available by offering the executable to an HTCondor pool to\nexecute on. We will see that with a few modifications we are able to decrease\nthe running time of a sample run of Big Crush from about five and a half hours\nto only five and a half minutes. We will also see that not only the time taken\nfor the testing to complete is shortened, but also the amount of time the user\nis unable to use their testing computer is reduced to almost none.\nAdditionally, during this paper we will look at the standard implementation of\nTestU01 and how it compares with a preexisting Parallel version of TestU01. We\nwill be comparing the performance of the standard version of TestU01 with the\nparallel version so that we have a performance baseline to test our own\nmodifications against. Finally, this paper will also discuss the use of the\ndistributed computing system HTCondor, and cover some basic instructions\nrelated to setting up and using HTCondor. HTCondor is already known to increase\nthe performance of a networked group of computers by allowing super users to\nutilize additional resources from other lesser users idle workstation. We will\nrelate the model recommended for HTCondor to a standard computer lab found at a\nUniversity and explain why they are the perfect candidates for the system.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 19:43:41 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Beizer", "Joshua", ""]]}, {"id": "1703.08219", "submitter": "Tiark Rompf", "authors": "Gr\\'egory M. Essertel, Ruby Y. Tahboub, James M. Decker, Kevin J.\n  Brown, Kunle Olukotun, Tiark Rompf", "title": "Flare: Native Compilation for Heterogeneous Workloads in Apache Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for modern data analytics to combine relational, procedural, and\nmap-reduce-style functional processing is widely recognized. State-of-the-art\nsystems like Spark have added SQL front-ends and relational query optimization,\nwhich promise an increase in expressiveness and performance. But how good are\nthese extensions at extracting high performance from modern hardware platforms?\n  While Spark has made impressive progress, we show that for relational\nworkloads, there is still a significant gap compared with best-of-breed query\nengines. And when stepping outside of the relational world, query optimization\ntechniques are ineffective if large parts of a computation have to be treated\nas user-defined functions (UDFs).\n  We present Flare: a new back-end for Spark that brings performance closer to\nthe best SQL engines, without giving up the added expressiveness of Spark. We\ndemonstrate order of magnitude speedups both for relational workloads such as\nTPC-H, as well as for a range of machine learning kernels that combine\nrelational and iterative functional processing.\n  Flare achieves these results through (1) compilation to native code, (2)\nreplacing parts of the Spark runtime system, and (3) extending the scope of\noptimization and code generation to large classes of UDFs.\n", "versions": [{"version": "v1", "created": "Thu, 23 Mar 2017 20:04:55 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Essertel", "Gr\u00e9gory M.", ""], ["Tahboub", "Ruby Y.", ""], ["Decker", "James M.", ""], ["Brown", "Kevin J.", ""], ["Olukotun", "Kunle", ""], ["Rompf", "Tiark", ""]]}, {"id": "1703.08228", "submitter": "Craig Blackmore", "authors": "Craig Blackmore, Oliver Ray, Kerstin Eder", "title": "Automatically Tuning the GCC Compiler to Optimize the Performance of\n  Applications Running on Embedded Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel method for automatically tuning the selection\nof compiler flags to optimize the performance of software intended to run on\nembedded hardware platforms. We begin by developing our approach on code\ncompiled by the GNU C Compiler (GCC) for the ARM Cortex-M3 (CM3) processor; and\nwe show how our method outperforms the industry standard -O3 optimization level\nacross a diverse embedded benchmark suite. First we quantify the potential\ngains by using existing iterative compilation approaches that time-intensively\nsearch for optimal configurations for each benchmark. Then we adapt iterative\ncompilation to output a single configuration that optimizes performance across\nthe entire benchmark suite. Although this is a time-consuming process, our\napproach constructs an optimized variation of -O3, which we call -Ocm3, that\nrealizes nearly two thirds of known available gains on the CM3 and\nsignificantly outperforms a more complex state-of-the-art predictive method in\ncross-validation experiments. Finally, we demonstrate our method on additional\nplatforms by constructing two more optimization levels that find even more\nsignificant speed-ups on the ARM Cortex-A8 and 8-bit AVR processors.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 17:36:08 GMT"}, {"version": "v2", "created": "Tue, 11 Apr 2017 15:17:59 GMT"}], "update_date": "2017-04-12", "authors_parsed": [["Blackmore", "Craig", ""], ["Ray", "Oliver", ""], ["Eder", "Kerstin", ""]]}, {"id": "1703.08280", "submitter": "Yinghao Yu", "authors": "Yinghao Yu, Wei Wang, Jun Zhang, Khaled Ben Letaief", "title": "LRC: Dependency-Aware Cache Management for Data Analytics Clusters", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory caches are being aggressively used in today's data-parallel systems\nsuch as Spark, Tez, and Piccolo. However, prevalent systems employ rather\nsimple cache management policies--notably the Least Recently Used (LRU)\npolicy--that are oblivious to the application semantics of data dependency,\nexpressed as a directed acyclic graph (DAG). Without this knowledge, memory\ncaching can at best be performed by \"guessing\" the future data access patterns\nbased on historical information (e.g., the access recency and/or frequency),\nwhich frequently results in inefficient, erroneous caching with low hit ratio\nand a long response time. In this paper, we propose a novel cache replacement\npolicy, Least Reference Count (LRC), which exploits the application-specific\nDAG information to optimize the cache management. LRC evicts the cached data\nblocks whose reference count is the smallest. The reference count is defined,\nfor each data block, as the number of dependent child blocks that have not been\ncomputed yet. We demonstrate the efficacy of LRC through both empirical\nanalysis and cluster deployments against popular benchmarking workloads. Our\nSpark implementation shows that, compared with LRU, LRC speeds up typical\napplications by 60%.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 03:31:34 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Yu", "Yinghao", ""], ["Wang", "Wei", ""], ["Zhang", "Jun", ""], ["Letaief", "Khaled Ben", ""]]}, {"id": "1703.08337", "submitter": "Abubakr O. Al-Abbasi", "authors": "Vaneet Aggarwal, Abubakr O. Al-Abbasi, Jingxian Fan, and Tian Lan", "title": "Taming Tail Latency for Erasure-coded, Distributed Storage Systems", "comments": "11 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed storage systems are known to be susceptible to long tails in\nresponse time. In modern online storage systems such as Bing, Facebook, and\nAmazon, the long tails of the service latency are of particular concern. with\n99.9th percentile response times being orders of magnitude worse than the mean.\nAs erasure codes emerge as a popular technique to achieve high data reliability\nin distributed storage while attaining space efficiency, taming tail latency\nstill remains an open problem due to the lack of mathematical models for\nanalyzing such systems. To this end, we propose a framework for quantifying and\noptimizing tail latency in erasure-coded storage systems. In particular, we\nderive upper bounds on tail latency in closed form for arbitrary service time\ndistribution and heterogeneous files. Based on the model, we formulate an\noptimization problem to jointly minimize the weighted latency tail probability\nof all files over the placement of files on the servers, and the choice of\nservers to access the requested files. The non-convex problem is solved using\nan efficient, alternating optimization algorithm. Numerical results show\nsignificant reduction of tail latency for erasure-coded storage systems with a\nrealistic workload.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 10:09:03 GMT"}], "update_date": "2017-04-27", "authors_parsed": [["Aggarwal", "Vaneet", ""], ["Al-Abbasi", "Abubakr O.", ""], ["Fan", "Jingxian", ""], ["Lan", "Tian", ""]]}, {"id": "1703.08348", "submitter": "Vaneet Aggarwal", "authors": "Abubakr O. Al-Abbasi and Vaneet Aggarwal", "title": "Video Streaming in Distributed Erasure-coded Storage Systems: Stall\n  Duration Analysis", "comments": "18 pages, accepted to IEEE/ACM Transactions on Networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.IT cs.MM math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demand for global video has been burgeoning across industries. With the\nexpansion and improvement of video-streaming services, cloud-based video is\nevolving into a necessary feature of any successful business for reaching\ninternal and external audiences. This paper considers video streaming over\ndistributed systems where the video segments are encoded using an erasure code\nfor better reliability thus being the first work to our best knowledge that\nconsiders video streaming over erasure-coded distributed cloud systems. The\ndownload time of each coded chunk of each video segment is characterized and\nordered statistics over the choice of the erasure-coded chunks is used to\nobtain the playback time of different video segments. Using the playback times,\nbounds on the moment generating function on the stall duration is used to bound\nthe mean stall duration. Moment generating function based bounds on the ordered\nstatistics are also used to bound the stall duration tail probability which\ndetermines the probability that the stall time is greater than a pre-defined\nnumber. These two metrics, mean stall duration and the stall duration tail\nprobability, are important quality of experience (QoE) measures for the end\nusers. Based on these metrics, we formulate an optimization problem to jointly\nminimize the convex combination of both the QoE metrics averaged over all\nrequests over the placement and access of the video content. The non-convex\nproblem is solved using an efficient iterative algorithm. Numerical results\nshow significant improvement in QoE metrics for cloud-based video as compared\nto the considered baselines.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 10:39:05 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 11:32:48 GMT"}], "update_date": "2018-06-27", "authors_parsed": [["Al-Abbasi", "Abubakr O.", ""], ["Aggarwal", "Vaneet", ""]]}, {"id": "1703.08370", "submitter": "Ivano Notarnicola", "authors": "Ivano Notarnicola and Giuseppe Notarstefano", "title": "A randomized primal distributed algorithm for partitioned and big-data\n  non-convex optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a distributed optimization scenario in which the\naggregate objective function to minimize is partitioned, big-data and possibly\nnon-convex. Specifically, we focus on a set-up in which the dimension of the\ndecision variable depends on the network size as well as the number of local\nfunctions, but each local function handled by a node depends only on a (small)\nportion of the entire optimization variable. This problem set-up has been shown\nto appear in many interesting network application scenarios. As main paper\ncontribution, we develop a simple, primal distributed algorithm to solve the\noptimization problem, based on a randomized descent approach, which works under\nasynchronous gossip communication. We prove that the proposed asynchronous\nalgorithm is a proper, ad-hoc version of a coordinate descent method and thus\nconverges to a stationary point. To show the effectiveness of the proposed\nalgorithm, we also present numerical simulations on a non-convex quadratic\nprogram, which confirm the theoretical results.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 11:43:51 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Notarnicola", "Ivano", ""], ["Notarstefano", "Giuseppe", ""]]}, {"id": "1703.08376", "submitter": "Ivano Notarnicola", "authors": "Ivano Notarnicola and Mauro Franceschelli and Giuseppe Notarstefano", "title": "A duality-based approach for distributed min-max optimization with\n  application to demand side management", "comments": "arXiv admin note: substantial text overlap with arXiv:1611.09168", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider a distributed optimization scenario in which a set\nof processors aims at minimizing the maximum of a collection of \"separable\nconvex functions\" subject to local constraints. This set-up is motivated by\npeak-demand minimization problems in smart grids. Here, the goal is to minimize\nthe peak value over a finite horizon with: (i) the demand at each time instant\nbeing the sum of contributions from different devices, and (ii) the local\nstates at different time instants being coupled through local dynamics. The\nmin-max structure and the double coupling (through the devices and over the\ntime horizon) makes this problem challenging in a distributed set-up (e.g.,\nwell-known distributed dual decomposition approaches cannot be applied). We\npropose a distributed algorithm based on the combination of duality methods and\nproperties from min-max optimization. Specifically, we derive a series of\nequivalent problems by introducing ad-hoc slack variables and by going back and\nforth from primal and dual formulations. On the resulting problem we apply a\ndual subgradient method, which turns out to be a distributed algorithm. We\nprove the correctness of the proposed algorithm and show its effectiveness via\nnumerical computations.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 11:49:57 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Notarnicola", "Ivano", ""], ["Franceschelli", "Mauro", ""], ["Notarstefano", "Giuseppe", ""]]}, {"id": "1703.08469", "submitter": "Carlos Antonio Perea G\\'omez", "authors": "Carlos Antonio Perea-G\\'omez", "title": "Virtualization technology for distributed time sensitive domains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on the state of the art of virtualization technology for\nboth general purpose domains as well as real-time domains. There exits no\nentirely instantaneous data transmission/transfer. There always exist a delay\nwhile transmitting data, either in the processing or in the medium itself.\nHowever most systems are designed to function appropriately with a delay\ntolerance. This delay, inevitably, is affected when operating with an extra\nlayer, the virtualization. For real time systems it is crucial to know the\ntemporal limits in order not to surpass them. Introducing virtualization in the\nreal-time domain therefore requires deeper analysis by making use of techniques\nthat will offer results with deterministic execution times. The study of time\nin systems and its behaviour under various possible circumstances is hence a\nkey for properly assessing this technology applied to both domains, especially\nthe real-time domain.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 15:38:17 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Perea-G\u00f3mez", "Carlos Antonio", ""]]}, {"id": "1703.08525", "submitter": "Vikram Saraph", "authors": "Vikram Saraph, Maurice Herlihy, Eli Gafni", "title": "An Algorithmic Approach to the Asynchronous Computability Theorem", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asynchronous computability theorem (ACT) uses concepts from combinatorial\ntopology to characterize which tasks have wait-free solutions in read-write\nmemory. A task can be expressed as a relation between two chromatic simplicial\ncomplexes. The theorem states that a task has a protocol (algorithm) if and\nonly if there is a certain chromatic simplicial map compatible with that\nrelation.\n  While the original proof of the ACT relied on an involved combinatorial\nargument, Borowsky and Gafni later proposed an alternative proof that relied on\na algorithmic construction, termed the \"convergence algorithm\". The description\nof this algorithm was incomplete, and presented without proof. In this paper,\nwe give the first complete description, along with a proof of correctness.\n", "versions": [{"version": "v1", "created": "Fri, 24 Mar 2017 17:29:58 GMT"}], "update_date": "2017-03-27", "authors_parsed": [["Saraph", "Vikram", ""], ["Herlihy", "Maurice", ""], ["Gafni", "Eli", ""]]}, {"id": "1703.08702", "submitter": "Leran Cai", "authors": "Leran Cai, Thomas Sauerwald", "title": "Randomized Load Balancing on Networks with Stochastic Inputs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Iterative load balancing algorithms for indivisible tokens have been studied\nintensively in the past. Complementing previous worst-case analyses, we study\nan average-case scenario where the load inputs are drawn from a fixed\nprobability distribution. For cycles, tori, hypercubes and expanders, we obtain\nalmost matching upper and lower bounds on the discrepancy, the difference\nbetween the maximum and the minimum load. Our bounds hold for a variety of\nprobability distributions including the uniform and binomial distribution but\nalso distributions with unbounded range such as the Poisson and geometric\ndistribution. For graphs with slow convergence like cycles and tori, our\nresults demonstrate a substantial difference between the convergence in the\nworst- and average-case. An important ingredient in our analysis is new upper\nbound on the t-step transition probability of a general Markov chain, which is\nderived by invoking the evolving set process.\n", "versions": [{"version": "v1", "created": "Sat, 25 Mar 2017 15:03:49 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Cai", "Leran", ""], ["Sauerwald", "Thomas", ""]]}, {"id": "1703.08831", "submitter": "Saber Salehkaleybar", "authors": "Saber Salehkaleybar, S. Jamaloddin Golestani", "title": "Token-based Function Computation with Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed function computation, each node has an initial value and the\ngoal is to compute a function of these values in a distributed manner. In this\npaper, we propose a novel token-based approach to compute a wide class of\ntarget functions to which we refer as \"Token-based function Computation with\nMemory\" (TCM) algorithm. In this approach, node values are attached to tokens\nand travel across the network. Each pair of travelling tokens would coalesce\nwhen they meet, forming a token with a new value as a function of the original\ntoken values. In contrast to the Coalescing Random Walk (CRW) algorithm, where\ntoken movement is governed by random walk, meeting of tokens in our scheme is\naccelerated by adopting a novel chasing mechanism. We proved that, compared to\nthe CRW algorithm, the TCM algorithm results in a reduction of time complexity\nby a factor of at least $\\sqrt{n/\\log(n)}$ in Erd\\\"os-Renyi and complete\ngraphs, and by a factor of $\\log(n)/\\log(\\log(n))$ in torus networks.\nSimulation results show that there is at least a constant factor improvement in\nthe message complexity of TCM algorithm in all considered topologies.\nRobustness of the CRW and TCM algorithms in the presence of node failure is\nanalyzed. We show that their robustness can be improved by running multiple\ninstances of the algorithms in parallel.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 16:01:28 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Salehkaleybar", "Saber", ""], ["Golestani", "S. Jamaloddin", ""]]}, {"id": "1703.08838", "submitter": "Saber Salehkaleybar", "authors": "Saber Salehkaleybar, Arsalan Sharif-Nassab, S. Jamaloddin Golestani", "title": "Distributed Voting/Ranking with Optimal Number of States per Node", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering a network with $n$ nodes, where each node initially votes for one\n(or more) choices out of $K$ possible choices, we present a Distributed\nMulti-choice Voting/Ranking (DMVR) algorithm to determine either the choice\nwith maximum vote (the voting problem) or to rank all the choices in terms of\ntheir acquired votes (the ranking problem). The algorithm consolidates node\nvotes across the network by updating the states of interacting nodes using two\nkey operations, the union and the intersection. The proposed algorithm is\nsimple, independent from network size, and easily scalable in terms of the\nnumber of choices $K$, using only $K\\times 2^{K-1}$ nodal states for voting,\nand $K\\times K!$ nodal states for ranking. We prove the number of states to be\noptimal in the ranking case, this optimality is conjectured to also apply to\nthe voting case. The time complexity of the algorithm is analyzed in complete\ngraphs. We show that the time complexity for both ranking and voting is\n$O(\\log(n))$ for given vote percentages, and is inversely proportional to the\nminimum of the vote percentage differences among various choices.\n", "versions": [{"version": "v1", "created": "Sun, 26 Mar 2017 16:19:31 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Salehkaleybar", "Saber", ""], ["Sharif-Nassab", "Arsalan", ""], ["Golestani", "S. Jamaloddin", ""]]}, {"id": "1703.08905", "submitter": "Ailidani Ailijiang", "authors": "Ailidani Ailijiang, Aleksey Charapko, Murat Demirbas, Tevfik Kosar", "title": "WPaxos: Wide Area Network Flexible Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  WPaxos is a multileader Paxos protocol that provides low-latency and\nhigh-throughput consensus across wide-area network (WAN) deployments. WPaxos\nuses multileaders, and partitions the object-space among these multileaders.\nUnlike statically partitioned multiple Paxos deployments, WPaxos is able to\nadapt to the changing access locality through object stealing. Multiple\nconcurrent leaders coinciding in different zones steal ownership of objects\nfrom each other using phase-1 of Paxos, and then use phase-2 to commit\nupdate-requests on these objects locally until they are stolen by other\nleaders. To achieve fast phase-2 commits, WPaxos adopts the flexible quorums\nidea in a novel manner, and appoints phase-2 acceptors to be close to their\nrespective leaders. We implemented WPaxos and evaluated it on WAN deployments\nacross 5 AWS regions. The dynamic partitioning of the object-space and emphasis\non zone-local commits allow WPaxos to significantly outperform both partitioned\nPaxos deployments and leaderless Paxos approaches.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 02:34:01 GMT"}, {"version": "v2", "created": "Fri, 28 Apr 2017 01:55:21 GMT"}, {"version": "v3", "created": "Sun, 24 Dec 2017 17:39:34 GMT"}, {"version": "v4", "created": "Wed, 3 Apr 2019 05:50:21 GMT"}], "update_date": "2019-04-04", "authors_parsed": [["Ailijiang", "Ailidani", ""], ["Charapko", "Aleksey", ""], ["Demirbas", "Murat", ""], ["Kosar", "Tevfik", ""]]}, {"id": "1703.08955", "submitter": "Rashmi C", "authors": "C Rashmi", "title": "Analysis of Different Approaches of Parallel Block Processing for\n  K-Means Clustering Algorithm", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Computation has been a recent trend in engineering research.\nParallel Computation is widely used in different areas of Data Mining, Image\nProcessing, Simulating Models, Aerodynamics and so forth. One of the major\nusage of Parallel Processing is widely implemented for clustering the satellite\nimages of size more than dimension of 1000x1000 in a legacy system. This paper\nmainly focuses on the different approaches of parallel block processing such as\nrow-shaped, column-shaped and square-shaped. These approaches are applied for\nclassification problem. These approaches is applied to the K-Means clustering\nalgorithm as this is widely used for the detection of features for high\nresolution orthoimagery satellite images. The different approaches are\nanalyzed, which lead to reduction in execution time and resulted the influence\nof improvement in performance measurement compared to sequential K-Means\nClustering algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 07:12:56 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Rashmi", "C", ""]]}, {"id": "1703.08981", "submitter": "Xiong Zhang", "authors": "Xuanhua Shi and Xiong Zhang and Ligang He and Hai Jin and Zhixiang Ke\n  and Song Wu", "title": "MURS: Mitigating Memory Pressure in Service-oriented Data Processing\n  Systems", "comments": "9 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Although a data processing system often works as a batch processing system,\nmany enterprises deploy such a system as a service, which we call the\nservice-oriented data processing system. It has been shown that in-memory data\nprocessing systems suffer from serious memory pressure. The situation becomes\neven worse for the service-oriented data processing systems due to various\nreasons. For example, in a service-oriented system, multiple submitted tasks\nare launched at the same time and executed in the same context in the\nresources, comparing with the batch processing mode where the tasks are\nprocessed one by one. Therefore, the memory pressure will affect all submitted\ntasks, including the tasks that only incur the light memory pressure when they\nare run alone. In this paper, we find that the reason why memory pressure\narises is because the running tasks produce massive long-living data objects in\nthe limited memory space. Our studies further reveal that the long-living data\nobjects are generated by the API functions that are invoked by the in-memory\nprocessing frameworks. Based on these findings, we propose a method to classify\nthe API functions based on the memory usage rate. Further, we design a\nscheduler called MURS to mitigate the memory pressure. We implement MURS in\nSpark and conduct the experiments to evaluate the performance of MURS. The\nresults show that when comparing to Spark, MURS can 1) decrease the execution\ntime of the submitted jobs by up to 65.8\\%, 2) mitigate the memory pressure in\nthe server by decreasing the garbage collection time by up to 81\\%, and 3)\nreduce the data spilling, and hence disk I/O, by approximately 90\\%.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 09:23:52 GMT"}, {"version": "v2", "created": "Wed, 29 Mar 2017 11:28:43 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Shi", "Xuanhua", ""], ["Zhang", "Xiong", ""], ["He", "Ligang", ""], ["Jin", "Hai", ""], ["Ke", "Zhixiang", ""], ["Wu", "Song", ""]]}, {"id": "1703.09185", "submitter": "Shripad Gade", "authors": "Shripad Gade and Nitin H. Vaidya", "title": "Private Learning on Networks: Part II", "comments": "Privacy-Convergence Trade-off added. New simulation results added\n  (Current Version: 5 November 2017. First Version: 27 March 2017. )", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers a distributed multi-agent optimization problem, with the\nglobal objective consisting of the sum of local objective functions of the\nagents. The agents solve the optimization problem using local computation and\ncommunication between adjacent agents in the network. We present two randomized\niterative algorithms for distributed optimization. To improve privacy, our\nalgorithms add \"structured\" randomization to the information exchanged between\nthe agents. We prove deterministic correctness (in every execution) of the\nproposed algorithms despite the information being perturbed by noise with\nnon-zero mean. We prove that a special case of a proposed algorithm (called\nfunction sharing) preserves privacy of individual polynomial objective\nfunctions under a suitable connectivity condition on the network topology.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 16:59:49 GMT"}, {"version": "v2", "created": "Sun, 5 Nov 2017 23:41:58 GMT"}], "update_date": "2017-11-07", "authors_parsed": [["Gade", "Shripad", ""], ["Vaidya", "Nitin H.", ""]]}, {"id": "1703.09257", "submitter": "Ruonan Wang", "authors": "Ruonan Wang, Christopher Harris, and Andreas Wicenec", "title": "AdiosStMan: Parallelizing Casacore Table Data System Using Adaptive IO\n  System", "comments": "20 pages, journal article, 2016", "journal-ref": "Astronomy and Computing, Volume 16, July 2016, Pages 146-154, ISSN\n  2213-1337", "doi": null, "report-no": null, "categories": "cs.DC astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate the Casacore Table Data System (CTDS) used in\nthe casacore and CASA libraries, and methods to parallelize it. CTDS provides a\nstorage manager plugin mechanism for third-party devel- opers to design and\nimplement their own CTDS storage managers. Hav- ing this in mind, we looked\ninto various storage backend techniques that can possibly enable parallel I/O\nfor CTDS by implementing new storage managers. After carrying on benchmarks\nshowing the excellent parallel I/O throughput of the Adaptive IO System\n(ADIOS), we implemented an ADIOS based parallel CTDS storage manager. We then\napplied the CASA MSTransform frequency split task to verify the ADIOS Storage\nManager. We also ran a series of performance tests to examine the I/O\nthroughput in a massively parallel scenario.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 18:35:51 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Wang", "Ruonan", ""], ["Harris", "Christopher", ""], ["Wicenec", "Andreas", ""]]}, {"id": "1703.09264", "submitter": "Zahra Khatami", "authors": "Zahra Khatami, Hartmut Kaiser and J. Ramanujam", "title": "Redesigning OP2 Compiler to Use HPX Runtime Asynchronous Techniques", "comments": "18th IEEE International Workshop on Parallel and Distributed\n  Scientific and Engineering Computing (PDSEC 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maximizing parallelism level in applications can be achieved by minimizing\noverheads due to load imbalances and waiting time due to memory latencies.\nCompiler optimization is one of the most effective solutions to tackle this\nproblem. The compiler is able to detect the data dependencies in an application\nand is able to analyze the specific sections of code for parallelization\npotential. However, all of these techniques provided with a compiler are\nusually applied at compile time, so they rely on static analysis, which is\ninsufficient for achieving maximum parallelism and producing desired\napplication scalability. One solution to address this challenge is the use of\nruntime methods. This strategy can be implemented by delaying certain amount of\ncode analysis to be done at runtime. In this research, we improve the parallel\napplication performance generated by the OP2 compiler by leveraging HPX, a C++\nruntime system, to provide runtime optimizations. These optimizations include\nasynchronous tasking, loop interleaving, dynamic chunk sizing, and data\nprefetching. The results of the research were evaluated using an Airfoil\napplication which showed a 40-50% improvement in parallel performance.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 18:51:09 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Khatami", "Zahra", ""], ["Kaiser", "Hartmut", ""], ["Ramanujam", "J.", ""]]}, {"id": "1703.09316", "submitter": "Katarzyna Mazur", "authors": "Katarzyna Mazur and Bogdan Ksiezopolski", "title": "On Data Flow Management: the Multilevel Analysis of Data Center Total\n  Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Information management is one of the most significant issues in nowadays data\ncenters. Selection of appropriate software, security mechanisms and effective\nenergy consumption management together with caring for the environment enforces\na profound analysis of the considered system. Besides these factors, financial\nanalysis of data center maintenance is another important aspect that needs to\nbe considered. Data centers are mission-critical components of all large\nenterprises and frequently cost hundreds of millions of dollars to build, yet\nfew high-level executives understand the true cost of operating such\nfacilities. Costs are typically spread across the IT, networking, and\nfacilities, which makes management of these costs and assessment of\nalternatives difficult. This paper deals with a research on multilevel analysis\nof data center management and presents an approach to estimate the true total\ncosts of operating data center physical facilities, taking into account the\nproper management of the information flow.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 21:31:17 GMT"}], "update_date": "2017-03-29", "authors_parsed": [["Mazur", "Katarzyna", ""], ["Ksiezopolski", "Bogdan", ""]]}, {"id": "1703.09326", "submitter": "Vidhya Tekken Valapil", "authors": "Vidhya Tekken Valapil, Sandeep S. Kulkarni", "title": "Preserving Stabilization while Practically Bounding State Space", "comments": "Moved some content from the Appendix to the main paper, added some\n  details to the transformation algorithm and to its description", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stabilization is a key dependability property for dealing with unanticipated\ntransient faults, as it guarantees that even in the presence of such faults,\nthe system will recover to states where it satisfies its specification. One of\nthe desirable attributes of stabilization is the use of bounded space for each\nvariable. In this paper, we present an algorithm that transforms a stabilizing\nprogram that uses variables with unbounded domain into a stabilizing program\nthat uses bounded variables and (practically bounded) physical time. While\nnon-stabilizing programs (that do not handle transient faults) can deal with\nunbounded variables by assigning large enough but bounded space, stabilizing\nprograms that need to deal with arbitrary transient faults cannot do the same\nsince a transient fault may corrupt the variable to its maximum value. We show\nthat our transformation algorithm is applicable to several problems including\nlogical clocks, vector clocks, mutual exclusion, leader election, diffusing\ncomputations, Paxos based consensus, and so on. Moreover, our approach can also\nbe used to bound counters used in an earlier work by Katz and Perry for adding\nstabilization to a non-stabilizing program. By combining our algorithm with\nthat earlier work by Katz and Perry, it would be possible to provide\nstabilization for a rich class of problems, by assigning large enough but\nbounded space for variables.\n", "versions": [{"version": "v1", "created": "Mon, 27 Mar 2017 22:24:36 GMT"}, {"version": "v2", "created": "Fri, 9 Jun 2017 17:43:21 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Valapil", "Vidhya Tekken", ""], ["Kulkarni", "Sandeep S.", ""]]}, {"id": "1703.09542", "submitter": "Yongzhe Zhang", "authors": "Yongzhe Zhang, Hsiang-Shang Ko, Zhenjiang Hu", "title": "Palgol: A High-Level DSL for Vertex-Centric Graph Processing with Remote\n  Data Access", "comments": "12 pages, 10 figures, extended version of APLAS 2017 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Pregel is a popular distributed computing model for dealing with large-scale\ngraphs. However, it can be tricky to implement graph algorithms correctly and\nefficiently in Pregel's vertex-centric model, especially when the algorithm has\nmultiple computation stages, complicated data dependencies, or even\ncommunication over dynamic internal data structures. Some domain-specific\nlanguages (DSLs) have been proposed to provide more intuitive ways to implement\ngraph algorithms, but due to the lack of support for remote access --- reading\nor writing attributes of other vertices through references --- they cannot\nhandle the above mentioned dynamic communication, causing a class of Pregel\nalgorithms with fast convergence impossible to implement.\n  To address this problem, we design and implement Palgol, a more declarative\nand powerful DSL which supports remote access. In particular, programmers can\nuse a more declarative syntax called chain access to naturally specify dynamic\ncommunication as if directly reading data on arbitrary remote vertices. By\nanalyzing the logic patterns of chain access, we provide a novel algorithm for\ncompiling Palgol programs to efficient Pregel code. We demonstrate the power of\nPalgol by using it to implement several practical Pregel algorithms, and the\nevaluation result shows that the efficiency of Palgol is comparable with that\nof hand-written code.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 12:35:33 GMT"}, {"version": "v2", "created": "Wed, 6 Sep 2017 17:00:30 GMT"}], "update_date": "2017-09-07", "authors_parsed": [["Zhang", "Yongzhe", ""], ["Ko", "Hsiang-Shang", ""], ["Hu", "Zhenjiang", ""]]}, {"id": "1703.09707", "submitter": "Bin Chen", "authors": "Bin Chen, Ronald Kantowski, Xinyu Dai, Eddie Baron, Paul Van der Mark", "title": "Accelerating gravitational microlensing simulations using the Xeon Phi\n  coprocessor", "comments": "18 pages, 3 figures, accepted by the Astronomy & Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.HE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Graphics Processing Units (GPUs) have been used to speed up very\nCPU-intensive gravitational microlensing simulations. In this work, we use the\nXeon Phi coprocessor to accelerate such simulations and compare its performance\non a microlensing code with that of NVIDIA's GPUs. For the selected set of\nparameters evaluated in our experiment, we find that the speedup by Intel's\nKnights Corner coprocessor is comparable to that by NVIDIA's Fermi family of\nGPUs with compute capability 2.0, but less significant than GPUs with higher\ncompute capabilities such as the Kepler. However, the very recently released\nsecond generation Xeon Phi, Knights Landing, is about 5.8 times faster than the\nKnights Corner, and about 2.9 times faster than the Kepler GPU used in our\nsimulations. We conclude that the Xeon Phi is a very promising alternative to\nGPUs for modern high performance microlensing simulations.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 18:00:01 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Chen", "Bin", ""], ["Kantowski", "Ronald", ""], ["Dai", "Xinyu", ""], ["Baron", "Eddie", ""], ["Van der Mark", "Paul", ""]]}, {"id": "1703.09756", "submitter": "Nhien-An Le-Khac", "authors": "Nhien-An Le-Khac, M-Tahar Kechadi, Joe Carthy", "title": "Admire framework: Distributed data mining on data grid platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present the ADMIRE architecture; a new framework for\ndeveloping novel and innovative data mining techniques to deal with very large\nand distributed heterogeneous datasets in both commercial and academic\napplications. The main ADMIRE components are detailed as well as its interfaces\nallowing the user to efficiently develop and implement their data mining\napplications techniques on a Grid platform such as Globus ToolKit, DGET, etc.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 19:22:42 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Le-Khac", "Nhien-An", ""], ["Kechadi", "M-Tahar", ""], ["Carthy", "Joe", ""]]}, {"id": "1703.10105", "submitter": "Mansaf Alam Dr", "authors": "Kashish Ara Shakil, Ari Ora, Mansaf Alam and Shabih Shakeel", "title": "Exploiting Data Reduction Principles in Cloud-Based Data Management for\n  Cryo-Image Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is a cost-effective way for start-up life sciences\nlaboratories to store and manage their data. However, in many instances the\ndata stored over the cloud could be redundant which makes cloud-based data\nmanagement inefficient and costly because one has to pay for every byte of data\nstored over the cloud. Here, we tested efficient management of data generated\nby an electron cryo microscopy (cryoEM) lab on a cloud-based environment. The\ntest data was obtained from cryoEM repository EMPIAR. All the images were\nsubjected to an in-house parallelized version of principal component analysis.\nAn efficient cloud-based MapReduce modality was used for parallelization. We\nshowed that large data in order of terabytes could be efficiently reduced to\nits minimal essential self in a cost-effective scalable manner. Furthermore,\non-spot instance on Amazon EC2 was shown to reduce costs by a margin of about\n27 percent. This approach could be scaled to data of any large volume and type.\n", "versions": [{"version": "v1", "created": "Tue, 28 Mar 2017 11:26:48 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["Shakil", "Kashish Ara", ""], ["Ora", "Ari", ""], ["Alam", "Mansaf", ""], ["Shakeel", "Shabih", ""]]}, {"id": "1703.10242", "submitter": "James Ross", "authors": "David Richie, James Ross", "title": "I CAN HAS SUPERCOMPUTER? A Novel Approach to Teaching Parallel and\n  Distributed Computing Concepts Using a Meme-Based Programming Language", "comments": "7 pages, 2 figures, example code, accepted for publication at the 7th\n  NSF/TCPP Workshop on Parallel and Distributed Computing Education (EduPar-17)\n  workshop in conjunction with the 31st IEEE International Parallel &\n  Distributed Processing Symposium (IPDPS 17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach is presented to teach the parallel and distributed computing\nconcepts of synchronization and remote memory access. The single program\nmultiple data (SPMD) partitioned global address space (PGAS) model presented in\nthis paper uses a procedural programming language appealing to undergraduate\nstudents. We propose that the amusing nature of the approach may engender\ncreativity and interest using these concepts later in more sober environments.\nSpecifically, we implement parallel extensions to LOLCODE within a\nsource-to-source compiler sufficient for the development of parallel and\ndistributed algorithms normally implemented using conventional high-performance\ncomputing languages and APIs.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 20:42:28 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Richie", "David", ""], ["Ross", "James", ""]]}, {"id": "1703.10272", "submitter": "Arjun Singhvi", "authors": "Robert Grandl, Arjun Singhvi, Raajay Viswanathan and Aditya Akella", "title": "Whiz: A Fast and Flexible Data Analytics System", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's data analytics frameworks are compute-centric, with analytics\nexecution almost entirely dependent on the pre-determined physical structure of\nthe high-level computation. Relegating intermediate data to a second class\nentity in this manner hurts flexibility, performance, and efficiency. We\npresent Whiz, a new analytics framework that cleanly separates computation from\nintermediate data. It enables runtime visibility into data via programmable\nmonitoring, and data-driven computation (where intermediate data values drive\nwhen/what computation runs) via an event abstraction. Experiments with a Whiz\nprototype on a large cluster using batch, streaming, and graph analytics\nworkloads show that its performance is 1.3-2x better than state-of-the-art.\n", "versions": [{"version": "v1", "created": "Wed, 29 Mar 2017 23:45:16 GMT"}, {"version": "v2", "created": "Sun, 1 Apr 2018 06:57:46 GMT"}, {"version": "v3", "created": "Wed, 13 Feb 2019 06:43:49 GMT"}, {"version": "v4", "created": "Thu, 14 Feb 2019 04:53:32 GMT"}, {"version": "v5", "created": "Fri, 21 Jun 2019 04:01:59 GMT"}], "update_date": "2019-06-24", "authors_parsed": [["Grandl", "Robert", ""], ["Singhvi", "Arjun", ""], ["Viswanathan", "Raajay", ""], ["Akella", "Aditya", ""]]}, {"id": "1703.10318", "submitter": "Sung-Han Lin", "authors": "Sung-Han Lin, Ranjan Pal, Marco Paolieri, Leana Golubchik", "title": "SC-Share: Performance Driven Resource Sharing Markets for the Small\n  Cloud", "comments": "To be published in ICDCS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small-scale clouds (SCs) often suffer from resource under-provisioning during\npeak demand, leading to inability to satisfy service level agreements (SLAs)\nand consequent loss of customers. One approach to address this problem is for a\nset of autonomous SCs to share resources among themselves in a cost-induced\ncooperative fashion, thereby increasing their individual capacities (when\nneeded) without having to significantly invest in more resources. A central\nproblem (in this context) is how to properly share resources (for a price) to\nachieve profitable service while maintaining customer SLAs. To address this\nproblem, in this paper, we propose the SC-Share framework that utilizes two\ninteracting models: (i) a stochastic performance model that estimates the\nachieved performance characteristics under given SLA requirements, and (ii) a\nmarket-based game-theoretic model that (as shown empirically) converges to\nefficient resource sharing decisions at market equilibrium. Our results include\nextensive evaluations that illustrate the utility of the proposed framework.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 05:28:36 GMT"}, {"version": "v2", "created": "Mon, 7 Aug 2017 00:04:21 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Lin", "Sung-Han", ""], ["Pal", "Ranjan", ""], ["Paolieri", "Marco", ""], ["Golubchik", "Leana", ""]]}, {"id": "1703.10435", "submitter": "Antonio Tadeu Azevedo Gomes", "authors": "Antonio Tadeu A. Gomes, Weslley S. Pereira, Frederic Valentin, Diego\n  Paredes", "title": "On the Implementation of a Scalable Simulator for Multiscale\n  Hybrid-Mixed Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The family of Multiscale Hybrid-Mixed (MHM) finite element methods has\nreceived considerable attention from the mathematics and engineering community\nin the last few years. The MHM methods allow solving highly heterogeneous\nproblems on coarse meshes while providing solutions with high-order precision.\nIt embeds independent local problems which are responsible for upscaling\nunresolved scales into the numerical solution. These local contributions are\nbrought together through a global problem defined on the skeleton of the coarse\npartition. Since the local problems are completely independent, they can be\neasily computed in parallel. In this paper, we present two simulator prototypes\nspecifically crafted for the MHM methods, which adopt two different\nimplementation strategies: (i) a multi-programming language approach, each\nlanguage tackling different simulation issues; and (ii) a classical,\nsingle-programming language approach. Specifically, we use C++ for numerical\ncomputation of the global and local problems in a modular way; for process\ndistribution in the simulator, we adopt the Erlang concurrent language in the\nfirst approach, and the MPI standard in the second approach. The aim of\nexploring these different approaches is twofold: (i) allow for the deployment\nof the simulator both in high-performance computing (with MPI) and in cloud\ncomputing environments (with Erlang); and (ii) pave the way for further\nexploration of quality attributes related to software productivity and\nfault-tolerance, which are key to Exascale systems. We present a performance\nevaluation of the two simulator prototypes taking into account their\nefficiency.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 12:26:32 GMT"}], "update_date": "2017-03-31", "authors_parsed": [["Gomes", "Antonio Tadeu A.", ""], ["Pereira", "Weslley S.", ""], ["Valentin", "Frederic", ""], ["Paredes", "Diego", ""]]}, {"id": "1703.10446", "submitter": "Luis Veiga", "authors": "Miguel E. Coimbra and Mennan Selimi and Alexandre P. Francisco and\n  Felix Freitag and Lu\\'is Veiga", "title": "Gelly-Scheduling: Distributed Graph Processing for Network Service\n  Placement in Community Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": "INESC-ID Lisboa Technical Report 4/2017, Feb 2017", "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community networks (CNs) have seen an increase in the last fifteen years.\nTheir members contact nodes which operate Internet proxies, web servers, user\nfile storage and video streaming services, to name a few. Detecting communities\nof nodes with properties (such as co-location) and assessing node eligibility\nfor service placement is thus a key-factor in optimizing the experience of\nusers. We present a novel solution for the problem of service placement as a\ntwo-phase approach, based on: 1) community finding using a scalable graph label\npropagation technique and 2) a decentralized election procedure to address the\nmulti-objective challenge of optimizing service placement in CNs. Herein we: i)\nhighlight the applicability of leader election heuristics which are important\nfor service placement in community networks and scheduler-dependent scenarios;\nii) present a parallel and distributed solution designed as a scalable\nalternative for the problem of service placement, which has mostly seen\ncomputational approaches based on centralization and sequential execution.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 12:52:46 GMT"}, {"version": "v2", "created": "Thu, 18 Jan 2018 14:45:37 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Coimbra", "Miguel E.", ""], ["Selimi", "Mennan", ""], ["Francisco", "Alexandre P.", ""], ["Freitag", "Felix", ""], ["Veiga", "Lu\u00eds", ""]]}, {"id": "1703.10628", "submitter": "Luis Veiga", "authors": "Miguel E. Coimbra and Alexandre P. Francisco and Luis Veiga", "title": "Study on Resource Efficiency of Distributed Graph Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": "INESC-ID Lisboa Technical Report 17/2016, Dec. 2016", "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs may be used to represent many different problem domains -- a concrete\nexample is that of detecting communities in social networks, which are\nrepresented as graphs. With big data and more sophisticated applications\nbecoming widespread in recent years, graph processing has seen an emergence of\nrequirements pertaining data volume and volatility. This multidisciplinary\nstudy presents a review of relevant distributed graph processing systems.\nHerein they are presented in groups defined by common traits (distributed\nprocessing paradigm, type of graph operations, among others), with an overview\nof each system's strengths and weaknesses. The set of systems is then narrowed\ndown to a set of two, upon which quantitative analysis was performed. For this\nquantitative comparison of systems, focus was cast on evaluating the\nperformance of algorithms for the problem of detecting communities. To help\nfurther understand the evaluations performed, a background is provided on graph\nclustering.\n", "versions": [{"version": "v1", "created": "Thu, 30 Mar 2017 18:26:53 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Coimbra", "Miguel E.", ""], ["Francisco", "Alexandre P.", ""], ["Veiga", "Luis", ""]]}, {"id": "1703.10731", "submitter": "David Avis", "authors": "David Avis and Luc Devroye", "title": "An analysis of budgeted parallel search on conditional Galton-Watson\n  trees", "comments": "15 pages, 3 figures, 2 tables Minor revisions including an extended\n  description of the Q-process with additional figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently Avis and Jordan have demonstrated the efficiency of a simple\ntechnique called budgeting for the parallelization of a number of tree search\nalgorithms. The idea is to limit the amount of work that a processor performs\nbefore it terminates its search and returns any unexplored nodes to a master\nprocess. This limit is set by a critical budget parameter which determines the\noverhead of the process. In this paper we study the behaviour of the budget\nparameter on conditional Galton-Watson trees obtaining asymptotically tight\nbounds on this overhead. We present empirical results to show that this bound\nis surprisingly accurate in practice.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 02:03:36 GMT"}, {"version": "v2", "created": "Thu, 5 Sep 2019 15:18:13 GMT"}], "update_date": "2019-09-06", "authors_parsed": [["Avis", "David", ""], ["Devroye", "Luc", ""]]}, {"id": "1703.10959", "submitter": "Thom Fruehwirth", "authors": "Thom Fruehwirth", "title": "Parallelism, Concurrency and Distribution in Constraint Handling Rules:\n  A Survey", "comments": "Under consideration in Theory and Practice of Logic Programming\n  (TPLP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Constraint Handling Rules is an effective concurrent declarative programming\nlanguage and a versatile computational logic formalism. CHR programs consist of\nguarded reactive rules that transform multisets of constraints. One of the main\nfeatures of CHR is its inherent concurrency. Intuitively, rules can be applied\nto parts of a multiset in parallel. In this comprehensive survey, we give an\noverview of concurrent and parallel as well as distributed CHR semantics,\nstandard and more exotic, that have been proposed over the years at various\nlevels of refinement. These semantics range from the abstract to the concrete.\nThey are related by formal soundness results. Their correctness is established\nas correspondence between parallel and sequential computations. We present\ncommon concise sample CHR programs that have been widely used in experiments\nand benchmarks. We review parallel CHR implementations in software and\nhardware. The experimental results obtained show a consistent parallel speedup.\nMost implementations are available online. The CHR formalism can also be used\nto implement and reason with models for concurrency. To this end, the Software\nTransaction Model, the Actor Model, Colored Petri Nets and the Join-Calculus\nhave been faithfully encoded in CHR. Under consideration in Theory and Practice\nof Logic Programming (TPLP).\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 15:51:51 GMT"}, {"version": "v2", "created": "Mon, 3 Apr 2017 11:53:11 GMT"}, {"version": "v3", "created": "Fri, 22 Dec 2017 12:59:30 GMT"}, {"version": "v4", "created": "Fri, 6 Apr 2018 15:41:19 GMT"}], "update_date": "2018-04-09", "authors_parsed": [["Fruehwirth", "Thom", ""]]}, {"id": "1703.10979", "submitter": "Alexander Meshcheryakov V.", "authors": "Ivan Kolosov, Sergey Gerasimov and Alexander Meshcheryakov", "title": "Architecture of processing and analysis system for big astronomical data", "comments": "4 pages, to appear in the Proceedings of ADASS 2016, Astronomical\n  Society of the Pacific (ASP) Conference Series", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work explores the use of big data technologies deployed in the cloud for\nprocessing of astronomical data. We have applied Hadoop and Spark to the task\nof co-adding astronomical images. We compared the overhead and execution time\nof these frameworks. We conclude that performance of both frameworks is\ngenerally on par. The Spark API is more flexible, which allows one to easily\nconstruct astronomical data processing pipelines.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 16:51:31 GMT"}], "update_date": "2017-04-03", "authors_parsed": [["Kolosov", "Ivan", ""], ["Gerasimov", "Sergey", ""], ["Meshcheryakov", "Alexander", ""]]}, {"id": "1703.11005", "submitter": "Sergio Rajsbaum", "authors": "Eric Goubault and Sergio Rajsbaum", "title": "A simplicial complex model of dynamic epistemic logic for fault-tolerant\n  distributed computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usual epistemic S5 model for multi-agent systems is a Kripke graph, whose\nedges are labeled with the agents that do not distinguish between two states.\nWe propose to uncover the higher dimensional information implicit in the Kripke\ngraph, by using as a model its dual, a chromatic simplicial complex. For each\nstate of the Kripke model there is a facet in the complex, with one vertex per\nagent. If an edge (u,v) is labeled with a set of agents S, the facets\ncorresponding to u and v intersect in a simplex consisting of one vertex for\neach agent of S. Then we use dynamic epistemic logic to study how the\nsimplicial complex epistemic model changes after the agents communicate with\neach other. We show that there are topological invariants preserved from the\ninitial epistemic complex to the epistemic complex after an action model is\napplied, that depend on how reliable the communication is. In turn these\ntopological properties determine the knowledge that the agents may gain after\nthe communication happens.\n", "versions": [{"version": "v1", "created": "Fri, 31 Mar 2017 17:53:06 GMT"}, {"version": "v2", "created": "Tue, 4 Apr 2017 12:50:53 GMT"}], "update_date": "2017-04-05", "authors_parsed": [["Goubault", "Eric", ""], ["Rajsbaum", "Sergio", ""]]}]