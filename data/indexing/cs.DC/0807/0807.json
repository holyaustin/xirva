[{"id": "0807.0140", "submitter": "Ioannis Chatzigiannakis", "authors": "Ioannis Chatzigiannakis and Paul G. Spirakis", "title": "The Dynamics of Probabilistic Population Protocols", "comments": "To appear as a Brief Announced in Proc. of 22nd International\n  Symposium on Distributed Computing (DISC 2008), September 22-24, 2008,\n  Arcachon, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study here the dynamics (and stability) of Probabilistic Population\nProtocols, via the differential equations approach. We provide a quite general\nmodel and we show that it includes the model of Angluin et. al. in the case of\nvery large populations. For the general model we give a sufficient condition\nfor stability that can be checked in polynomial time. We also study two\ninteresting subcases: (a) protocols whose specifications (in our terms) are\nconfiguration independent. We show that they are always stable and that their\neventual subpopulation percentages are actually a Markov Chain stationary\ndistribution. (b) protocols that have dynamics resembling virus spread. We show\nthat their dynamics are actually similar to the well-known Replicator Dynamics\nof Evolutionary Games. We also provide a sufficient condition for stability in\nthis case.\n", "versions": [{"version": "v1", "created": "Tue, 1 Jul 2008 12:49:22 GMT"}], "update_date": "2008-07-02", "authors_parsed": [["Chatzigiannakis", "Ioannis", ""], ["Spirakis", "Paul G.", ""]]}, {"id": "0807.0644", "submitter": "Neal E. Young", "authors": "Christos Koufogiannakis and Neal E. Young", "title": "Greedy D-Approximation Algorithm for Covering with Arbitrary Constraints\n  and Submodular Cost", "comments": null, "journal-ref": "Algorithmica 66(1):113-152 (2013)", "doi": "10.1007/978-3-642-02927-1_53", "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a simple greedy D-approximation algorithm for any\ncovering problem whose objective function is submodular and non-decreasing, and\nwhose feasible region can be expressed as the intersection of arbitrary (closed\nupwards) covering constraints, each of which constrains at most D variables of\nthe problem. (A simple example is Vertex Cover, with D = 2.) The algorithm\ngeneralizes previous approximation algorithms for fundamental covering problems\nand online paging and caching problems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Jul 2008 23:31:29 GMT"}, {"version": "v2", "created": "Thu, 20 Nov 2008 01:26:09 GMT"}, {"version": "v3", "created": "Fri, 8 May 2009 02:11:42 GMT"}, {"version": "v4", "created": "Fri, 30 Dec 2011 17:40:35 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Koufogiannakis", "Christos", ""], ["Young", "Neal E.", ""]]}, {"id": "0807.1267", "submitter": "Rahul Jain", "authors": "Rahul Jain and Pranab Sen and Jaikumar Radhakrishnan", "title": "Optimal Direct Sum and Privacy Trade-off Results for Quantum and\n  Classical Communication Complexity", "comments": "Full version (version 1), 31 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show optimal Direct Sum result for the one-way entanglement-assisted\nquantum communication complexity for any relation f subset of X x Y x Z. We\nshow: Q^{1,pub}(f^m) = Omega(m Q^{1,pub}(f)), where Q^{1,pub}(f), represents\nthe one-way entanglement-assisted quantum communication complexity of f with\nerror at most 1/3 and f^m represents m-copies of f. Similarly for the one-way\npublic-coin classical communication complexity we show: R^{1,pub}(f^m) =\nOmega(m R^{1,pub}(f)), where R^{1,pub}(f), represents the one-way public-coin\nclassical communication complexity of f with error at most 1/3. We show similar\noptimal Direct Sum results for the Simultaneous Message Passing quantum and\nclassical models. For two-way protocols we present optimal Privacy Trade-off\nresults leading to a Weak Direct Sum result for such protocols. We show our\nDirect Sum and Privacy Trade-off results via message compression arguments\nwhich also imply a new round elimination lemma in quantum communication. This\nallows us to extend classical lower bounds on the cell probe complexity of some\ndata structure problems, e.g. Approximate Nearest Neighbor Searching on the\nHamming cube {0,1}^n and Predecessor Search to the quantum setting. In a\nseparate result we show that Newman's technique of reducing the number of\npublic-coins in a classical protocol cannot be lifted to the quantum setting.\nWe do this by defining a general notion of black-box reduction of prior\nentanglement that subsumes Newman's technique. We prove that such a black-box\nreduction is impossible for quantum protocols. In the final result in the theme\nof message compression, we provide an upper bound on the problem of Exact\nRemote State Preparation.\n", "versions": [{"version": "v1", "created": "Tue, 8 Jul 2008 15:05:45 GMT"}], "update_date": "2008-07-09", "authors_parsed": [["Jain", "Rahul", ""], ["Sen", "Pranab", ""], ["Radhakrishnan", "Jaikumar", ""]]}, {"id": "0807.1475", "submitter": "Maziar Nekovee", "authors": "Maziar Nekovee", "title": "Simulations of Large-scale WiFi-based Wireless Networks:\n  Interdisciplinary Challenges and Applications", "comments": "Future Generation Computer Systems, Article in Press", "journal-ref": null, "doi": "10.1016/j.future.2008.05.007", "report-no": null, "categories": "cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless Fidelity (WiFi) is the fastest growing wireless technology to date.\nIn addition to providing wire-free connectivity to the Internet WiFi technology\nalso enables mobile devices to connect directly to each other and form highly\ndynamic wireless adhoc networks. Such distributed networks can be used to\nperform cooperative communication tasks such ad data routing and information\ndissemination in the absence of a fixed infrastructure. Furthermore, adhoc\ngrids composed of wirelessly networked portable devices are emerging as a new\nparadigm in grid computing. In this paper we review computational and\nalgorithmic challenges of high-fidelity simulations of such WiFi-based wireless\ncommunication and computing networks, including scalable topology maintenance,\nmobility modelling, parallelisation and synchronisation. We explore\nsimilarities and differences between the simulations of these networks and\nsimulations of interacting many-particle systems, such as molecular dynamics\n(MD) simulations. We show how the cell linked-list algorithm which we have\nadapted from our MD simulations can be used to greatly improve the\ncomputational performance of wireless network simulators in the presence of\nmobility, and illustrate with an example from our simulation studies of worm\nattacks on mobile wireless adhoc networks.\n", "versions": [{"version": "v1", "created": "Wed, 9 Jul 2008 16:04:37 GMT"}], "update_date": "2008-07-10", "authors_parsed": [["Nekovee", "Maziar", ""]]}, {"id": "0807.1720", "submitter": "Veronika Rehn-Sonigo", "authors": "Anne Benoit (LIP), Henri Casanova, Veronika Rehn-Sonigo (LIP), Yves\n  Robert (LIP)", "title": "Resource Allocation Strategies for In-Network Stream Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the operator mapping problem for in-network stream\nprocessing applications. In-network stream processing consists in applying a\ntree of operators in steady-state to multiple data objects that are continually\nupdated at various locations on a network. Examples of in-network stream\nprocessing include the processing of data in a sensor network, or of continuous\nqueries on distributed relational databases. We study the operator mapping\nproblem in a ``constructive'' scenario, i.e., a scenario in which one builds a\nplatform dedicated to the application buy purchasing processing servers with\nvarious costs and capabilities. The objective is to minimize the cost of the\nplatform while ensuring that the application achieves a minimum steady-state\nthroughput. The first contribution of this paper is the formalization of a set\nof relevant operator-placement problems as linear programs, and a proof that\neven simple versions of the problem are NP-complete. Our second contribution is\nthe design of several polynomial time heuristics, which are evaluated via\nextensive simulations and compared to theoretical bounds for optimal solutions.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2008 19:14:14 GMT"}], "update_date": "2008-07-11", "authors_parsed": [["Benoit", "Anne", "", "LIP"], ["Casanova", "Henri", "", "LIP"], ["Rehn-Sonigo", "Veronika", "", "LIP"], ["Robert", "Yves", "", "LIP"]]}, {"id": "0807.1753", "submitter": "Maria Gradinariu Potop-Butucaru", "authors": "Julien Clement (1), Xavier Defago (2), Maria Gradinariu Potop-Butucaru\n  (2) and Stephane Messika (1) ((1) LRI, Universite Paris 11, France (2) JAIST,\n  Japon, (3) LIP6, Universite Paris 6)", "title": "The cost of probabilistic gathering in oblivious robot networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the complexity issues of two agreement problems in\noblivious robot networks namely gathering and scattering. These abstractions\nare fundamental coordination problems in cooperative mobile robotics. Moreover,\ntheir oblivious characteristics makes them appealing for self-stabilization\nsince they are self-stabilizing with no extra-cost. Given a set of robots with\narbitrary initial location and no initial agreement on a global coordinate\nsystem, gathering requires that all robots reach the exact same but not\npredetermined location while scattering aims at scatter robots such that no two\nrobots share the same location. Both deterministic gathering and scattering\nhave been proved impossible under arbitrary schedulers therefore probabilistic\nsolutions have been recently proposed. The contribution of this paper is\ntwofold. First, we propose a detailed complexity analysis of the existent\nprobabilistic gathering algorithms in both fault-free and fault-prone\nenvironments. We consider both crash and byzantine-prone environments.\nMoreover, using Markov chains tools and additional assumptions on the\nenvironment we prove that the gathering convergence time can be reduced from\nO(n^2) (the best known tight bound) to O(nln(n)). Additionally, we prove that\nin crash-prone environments gathering is achieved in O(nln(n)+2f). Second,\nusing the same technique we prove that the best known scattering strategy\nconverges in fault-free systems is O(n) (which is one to optimal) while in\ncrash-prone environments it needs O(n-f). Finally, we conclude the paper with a\ndiscussion related to different strategies to gather oblivious robots.\n", "versions": [{"version": "v1", "created": "Thu, 10 Jul 2008 22:43:42 GMT"}], "update_date": "2008-07-14", "authors_parsed": [["Clement", "Julien", ""], ["Defago", "Xavier", ""], ["Potop-Butucaru", "Maria Gradinariu", ""], ["Messika", "Stephane", ""]]}, {"id": "0807.1949", "submitter": "Fei Wei", "authors": "Fei Wei, Huazhong Yang", "title": "Virtual Transmission Method, A New Distributed Algorithm to Solve Sparse\n  Linear System", "comments": "v1: short paper to describe VTM, published by NCM'08; v2: add an\n  example of level-two splitting; v3: full paper; v4: rename EVS to GNBT; add\n  lines coupling technique; v5: reuse EVS, get rid of GNBT; more info, see\n  http://weifei00.googlepages.com", "journal-ref": null, "doi": "10.1109/NCM.2008.160", "report-no": null, "categories": "math.NA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new parallel algorithm which could work naturally\non the parallel computer with arbitrary number of processors. This algorithm is\nnamed Virtual Transmission Method (VTM). Its physical backgroud is the lossless\ntransmission line and microwave network. The basic idea of VTM is to insert\nlossless transmission lines into the sparse linear system to achieve\ndistributed computing.\n  VTM is proved to be convergent to solve SPD linear system. Preconditioning\nmethod and performance model are presented. Numerical experiments show that VTM\nis efficient, accurate and stable.\n  Accompanied with VTM, we bring in a new technique to partition the symmetric\nlinear system, which is named Generalized Node & Branch Tearing (GNBT). It is\nbased on Kirchhoff's Current Law from circuit theory. We proved that GNBT is\nfeasible to partition any SPD linear system.\n", "versions": [{"version": "v1", "created": "Sat, 12 Jul 2008 03:19:51 GMT"}, {"version": "v2", "created": "Mon, 20 Oct 2008 03:01:22 GMT"}, {"version": "v3", "created": "Tue, 17 Feb 2009 04:35:25 GMT"}, {"version": "v4", "created": "Thu, 29 Apr 2010 13:51:10 GMT"}, {"version": "v5", "created": "Tue, 7 Sep 2010 23:35:28 GMT"}], "update_date": "2010-09-09", "authors_parsed": [["Wei", "Fei", ""], ["Yang", "Huazhong", ""]]}, {"id": "0807.2515", "submitter": "Joseph Mohr", "authors": "Joseph J. Mohr (1), Wayne Barkhouse (2), Cristina Beldica (1),\n  Emmanuel Bertin (3), Y. Dora Cai (1), Luiz da Costa (4), J. Anthony Darnell\n  (1), Gregory E. Daues (1), Michael Jarvis (5), Michelle Gower (1), Huan Lin\n  (6), leandro Martelli (4), Eric Neilsen (6), Chow-Choong Ngeow (1), Ricardo\n  Ogando (4), Alex Parga (1), Erin Sheldon (7), Douglas Tucker (6), Nikolay\n  Kuropatkin (6), Chris Stoughton (6) ((1) University of Illinois, (2)\n  University of North Dakota, (3) Institut d'Astrophysque, Paris, (4)\n  Observatorio Nacional, Brasil, (5) University of Pennsylvania, (6) Fermilab,\n  (7) New York University)", "title": "The Dark Energy Survey Data Management System", "comments": "To be published in the proceedings of the SPIE conference on\n  Astronomical Instrumentation (held in Marseille in June 2008). This preprint\n  is made available with the permission of SPIE. Further information together\n  with preprint containing full quality images is available at\n  http://desweb.cosmology.uiuc.edu/wiki", "journal-ref": null, "doi": "10.1117/12.789550", "report-no": null, "categories": "astro-ph cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Dark Energy Survey collaboration will study cosmic acceleration with a\n5000 deg2 griZY survey in the southern sky over 525 nights from 2011-2016. The\nDES data management (DESDM) system will be used to process and archive these\ndata and the resulting science ready data products. The DESDM system consists\nof an integrated archive, a processing framework, an ensemble of astronomy\ncodes and a data access framework. We are developing the DESDM system for\noperation in the high performance computing (HPC) environments at NCSA and\nFermilab. Operating the DESDM system in an HPC environment offers both speed\nand flexibility. We will employ it for our regular nightly processing needs,\nand for more compute-intensive tasks such as large scale image coaddition\ncampaigns, extraction of weak lensing shear from the full survey dataset, and\nmassive seasonal reprocessing of the DES data. Data products will be available\nto the Collaboration and later to the public through a virtual-observatory\ncompatible web portal. Our approach leverages investments in publicly available\nHPC systems, greatly reducing hardware and maintenance costs to the project,\nwhich must deploy and maintain only the storage, database platforms and\norchestration and web portal nodes that are specific to DESDM. In Fall 2007, we\ntested the current DESDM system on both simulated and real survey data. We used\nTeragrid to process 10 simulated DES nights (3TB of raw data), ingesting and\ncalibrating approximately 250 million objects into the DES Archive database. We\nalso used DESDM to process and calibrate over 50 nights of survey data acquired\nwith the Mosaic2 camera. Comparison to truth tables in the case of the\nsimulated data and internal crosschecks in the case of the real data indicate\nthat astrometric and photometric data quality is excellent.\n", "versions": [{"version": "v1", "created": "Wed, 16 Jul 2008 08:37:43 GMT"}], "update_date": "2009-11-13", "authors_parsed": [["Mohr", "Joseph J.", ""], ["Barkhouse", "Wayne", ""], ["Beldica", "Cristina", ""], ["Bertin", "Emmanuel", ""], ["Cai", "Y. Dora", ""], ["da Costa", "Luiz", ""], ["Darnell", "J. Anthony", ""], ["Daues", "Gregory E.", ""], ["Jarvis", "Michael", ""], ["Gower", "Michelle", ""], ["Lin", "Huan", ""], ["Martelli", "leandro", ""], ["Neilsen", "Eric", ""], ["Ngeow", "Chow-Choong", ""], ["Ogando", "Ricardo", ""], ["Parga", "Alex", ""], ["Sheldon", "Erin", ""], ["Tucker", "Douglas", ""], ["Kuropatkin", "Nikolay", ""], ["Stoughton", "Chris", ""]]}, {"id": "0807.3632", "submitter": "Alain Bui", "authors": "Alain Bui and Devan Sohier", "title": "How to Compute Times of Random Walks based Distributed Algorithms", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random walk based distributed algorithms make use of a token that circulates\nin the system according to a random walk scheme to achieve their goal. To study\ntheir efficiency and compare it to one of the deterministic solutions, one is\nled to compute certain quantities, namely the hitting times and the cover time.\nUntil now, only bounds on these quantities were defined. First, this paper\npresents two generalizations of the notions of hitting and cover times to\nweighted graphs. Indeed, the properties of random walks on symmetrically\nweighted graphs provide interesting results on random walk based distributed\nalgorithms, such as local load balancing. Both of these generalization are\nproposed to precisely represent the behaviour of these algorithms, and to take\ninto account what the weights represent. Then, we propose an algorithm to\ncompute the n^2 hitting times on a weighted graph of n vertices, which we\nimprove to obtain a O(n^3) complexity. This complexity is the lowest up to now.\nThis algorithm computes both of the generalizations that we propose for the\nhitting times on a weighted graph. Finally, we provide the first algorithm to\ncompute the cover time (in both senses) of a graph. We improve it to achieve a\ncomplexity of O(n^3 2^n). The algorithms that we present are all robust to a\ntopological change in a limited number of edges. This property allows us to use\nthem on dynamic graphs.\n", "versions": [{"version": "v1", "created": "Wed, 23 Jul 2008 10:10:59 GMT"}], "update_date": "2008-07-24", "authors_parsed": [["Bui", "Alain", ""], ["Sohier", "Devan", ""]]}, {"id": "0807.4609", "submitter": "Achmad Benny Mutiara", "authors": "A.B. Mutiara", "title": "Analisis Kinerja Sistem Cluster Terhadapa Aplikasi Simulasi Dinamika\n  Molekular NAMD Memanfaatkan Pustaka CHARM++", "comments": "8 pages, 3 Figures (in Indonesian)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tingkat kompleksitas dari program simulasi dinamika molekular membutuhkan\nmesin pemroses dengan kemampuan yang sangat besar. Mesin-mesin paralel terbukti\nmemiliki potensi untuk menjawab tantangan komputasi ini. Untuk memanfaatkan\npotensi ini secara maksimal, diperlukan suatu program paralel dengan tingkat\nefisiensi, efektifitas, skalabilitas, dan ekstensibilitas yang maksimal pula.\nProgram NAMD yang dibahas pada penulisan ini dianggap mampu untuk memenuhi\nsemua kriteria yang diinginkan. Program ini dirancang dengan\nmengimplementasikan pustaka Charm++ untuk pembagian tugas perhitungan secara\nparalel. NAMD memiliki sistem automatic load balancing secara periodik yang\ncerdas, sehingga dapat memaksimalkan penggunaan kemampuan mesin yang tersedia.\nProgram ini juga dirancang secara modular, sehingga dapat dimodifikasi dan\nditambah dengan sangat mudah. NAMD menggunakan banyak kombinasi algoritma\nperhitungan dan tehnik-tehnik numerik lainnya dalam melakukan tugasnya. NAMD\n2.5 mengimplementasikan semua tehnik dan persamaan perhitungan yang digunakan\ndalam dunia simulasi dinamika molekular saat ini. NAMD dapat berjalan diatas\nberbagai mesin paralel termasuk arsitektur cluster, dengan hasil speedup yang\nmengejutkan. Tulisan ini akan menjelaskan dan membuktikan kemampuan NAMD secara\nparalel diatas lima buah mesin cluster. Penulisan ini juga akan memaparkan\nkinerja NAMD pada beberapa.\n", "versions": [{"version": "v1", "created": "Tue, 29 Jul 2008 09:18:21 GMT"}], "update_date": "2008-07-30", "authors_parsed": [["Mutiara", "A. B.", ""]]}]