[{"id": "1102.0058", "submitter": "Oresris  Akribopoulos", "authors": "Orestis Akribopoulos, Vasileios Georgitzikis, Christos Koninis,\n  Ioannis Papavasileiou and Ioannis Chatzigiannakis", "title": "Deployment and Evaluation of a 802.15.4 Heterogeneous Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the performance of a heterogeneous wireless sensor\nnetwork which consists of 4 different hardware platforms (TelosB, SunSPOT,\nArduino, iSense). All hardware platforms use 802.15.4 compliant radios. Due to\npartial implementation of the standard, they do not communicate out of the box.\nA first contribution of our work is a careful description of the necessary\nsteps to make such a heterogeneous network interoperate. Our software code is\navailable online. We deploy a heterogeneous network testbed and conduct a\nthorough evaluation of the performance. We examine various network performance\nmetrics (e.g., transmission rate, receiving rate, packet loss, etc.), and\nassess the capabilities of each device and their intercommunication. We used\ndifferent setups (e.g., distance between transmitters and receivers, etc.) to\nbetter understand the network limitations for each hardware platform.\n", "versions": [{"version": "v1", "created": "Tue, 1 Feb 2011 02:05:34 GMT"}, {"version": "v2", "created": "Wed, 2 Feb 2011 22:48:18 GMT"}], "update_date": "2011-02-04", "authors_parsed": [["Akribopoulos", "Orestis", ""], ["Georgitzikis", "Vasileios", ""], ["Koninis", "Christos", ""], ["Papavasileiou", "Ioannis", ""], ["Chatzigiannakis", "Ioannis", ""]]}, {"id": "1102.0144", "submitter": "Peeyush Prasad", "authors": "Peeyush Prasad and C.R. Subrahmanya", "title": "A High Speed Networked Signal Processing Platform for Multi-element\n  Radio Telescopes", "comments": "19 pages, 4 eps figures, To be published in Experimental Astronomy\n  (Springer)", "journal-ref": null, "doi": "10.1007/s10686-011-9216-7", "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new architecture is presented for a Networked Signal Processing System\n(NSPS) suitable for handling the real-time signal processing of multi-element\nradio telescopes. In this system, a multi-element radio telescope is viewed as\nan application of a multi-sensor, data fusion problem which can be decomposed\ninto a general set of computing and network components for which a practical\nand scalable architecture is enabled by current technology. The need for such a\nsystem arose in the context of an ongoing program for reconfiguring the Ooty\nRadio Telescope (ORT) as a programmable 264-element array, which will enable\nseveral new observing capabilities for large scale surveys on this mature\ntelescope. For this application, it is necessary to manage, route and combine\nlarge volumes of data whose real-time collation requires large I/O bandwidths\nto be sustained. Since these are general requirements of many multi-sensor\nfusion applications, we first describe the basic architecture of the NSPS in\nterms of a Fusion Tree before elaborating on its application for the ORT. The\npaper addresses issues relating to high speed distributed data acquisition,\nField Programmable Gate Array (FPGA) based peer-to-peer networks supporting\nsignificant on-the fly processing while routing, and providing a last mile\ninterface to a typical commodity network like Gigabit Ethernet. The system is\nfundamentally a pair of two co-operative networks, among which one is part of a\ncommodity high performance computer cluster and the other is based on\nCommercial-Off The-Shelf (COTS) technology with support from software/firmware\ncomponents in the public domain.\n", "versions": [{"version": "v1", "created": "Tue, 1 Feb 2011 12:32:42 GMT"}], "update_date": "2011-02-02", "authors_parsed": [["Prasad", "Peeyush", ""], ["Subrahmanya", "C. R.", ""]]}, {"id": "1102.0204", "submitter": "Nicolas Le Scouarnec", "authors": "Anne-Marie Kermarrec and Gilles Straub and Nicolas Le Scouarnec", "title": "Repairing Multiple Failures with Coordinated and Adaptive Regenerating\n  Codes", "comments": "Update to previous version adding (i) study of lazy repairs, (ii)\n  adaptive codes at the MBR point, and (iii) discussion of related work.\n  Extended from a regular paper at NetCod 2011 available at\n  http://dx.doi.org/10.1109/ISNETCOD.2011.5978920 . First version: \"Beyond\n  Regenerating Codes\", September 2010 on http://hal.inria.fr/inria-00516647/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Erasure correcting codes are widely used to ensure data persistence in\ndistributed storage systems. This paper addresses the simultaneous repair of\nmultiple failures in such codes. We go beyond existing work (i.e., regenerating\ncodes by Dimakis et al.) by describing (i) coordinated regenerating codes (also\nknown as cooperative regenerating codes) which support the simultaneous repair\nof multiple devices, and (ii) adaptive regenerating codes which allow adapting\nthe parameters at each repair. Similarly to regenerating codes by Dimakis et\nal., these codes achieve the optimal tradeoff between storage and the repair\nbandwidth. Based on these extended regenerating codes, we study the impact of\nlazy repairs applied to regenerating codes and conclude that lazy repairs\ncannot reduce the costs in term of network bandwidth but allow reducing the\ndisk-related costs (disk bandwidth and disk I/O).\n", "versions": [{"version": "v1", "created": "Tue, 1 Feb 2011 16:26:07 GMT"}, {"version": "v2", "created": "Mon, 27 Jun 2011 09:44:03 GMT"}, {"version": "v3", "created": "Tue, 17 Sep 2013 11:41:09 GMT"}], "update_date": "2013-09-18", "authors_parsed": [["Kermarrec", "Anne-Marie", ""], ["Straub", "Gilles", ""], ["Scouarnec", "Nicolas Le", ""]]}, {"id": "1102.0467", "submitter": "Pierre Fraigniaud", "authors": "Pierre Fraigniaud and Andrzej Pelc", "title": "Delays Induce an Exponential Memory Gap for Rendezvous in Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of rendezvous in a graph is meeting of two mobile agents at some node\nof an unknown anonymous connected graph. In this paper, we focus on rendezvous\nin trees, and, analogously to the efforts that have been made for solving the\nexploration problem with compact automata, we study the size of memory of\nmobile agents that permits to solve the rendezvous problem deterministically.\nWe assume that the agents are identical, and move in synchronous rounds.\n  We first show that if the delay between the starting times of the agents is\narbitrary, then the lower bound on memory required for rendezvous is Omega(log\nn) bits, even for the line of length n. This lower bound meets a previously\nknown upper bound of O(log n) bits for rendezvous in arbitrary graphs of size\nat most n. Our main result is a proof that the amount of memory needed for\nrendezvous with simultaneous start depends essentially on the number L of\nleaves of the tree, and is exponentially less impacted by the number n of\nnodes. Indeed, we present two identical agents with O(log L + loglog n) bits of\nmemory that solve the rendezvous problem in all trees with at most n nodes and\nat most L leaves. Hence, for the class of trees with polylogarithmically many\nleaves, there is an exponential gap in minimum memory size needed for\nrendezvous between the scenario with arbitrary delay and the scenario with\ndelay zero. Moreover, we show that our upper bound is optimal by proving that\nOmega(log L + loglog n)$ bits of memory are required for rendezvous, even in\nthe class of trees with degrees bounded by 3.\n", "versions": [{"version": "v1", "created": "Wed, 2 Feb 2011 15:39:17 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Fraigniaud", "Pierre", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1102.0516", "submitter": "Sanjay Patel", "authors": "Sanjay Patel and Madhuri Bhavsar", "title": "QOS based user driven scheduler for grid environment", "comments": "9 pages, ACIJ", "journal-ref": "Advanced Computing: An International Journal ( ACIJ ), Vol.2,\n  No.1, January 2011", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  As grids are in essence heterogeneous, dynamic, shared and distributed\nenvironments, managing these kinds of platforms efficiently is extremely\ncomplex. A promising scalable approach to deal with these intricacies is the\ndesign of self-managing of autonomic applications. Autonomic applications adapt\ntheir execution accordingly by considering knowledge about their own behaviour\nand environmental conditions.QoS based User Driven scheduling for grid that\nprovides the self-optimizing ability in autonomic applications. Computational\ngrids to provide a user to solve large scale problem by spreading a single\nlarge computation across multiple machines of physical location. QoS based User\nDriven scheduler for grid also provides reliability of the grid systems and\nincrease the performance of the grid to reducing the execution time of job by\napplying scheduling policies defined by the user. The main aim of this paper is\nto distribute the computational load among the available grid nodes and to\ndeveloped a QoS based scheduling algorithm for grid and making grid more\nreliable.Grid computing system is different from conventional distributed\ncomputing systems by its focus on large scale resource sharing, where\nprocessors and communication have significant inuence on Grid computing\nreliability. Reliability capabilities initiated by end users from within\napplications they submit to the grid for execution. Reliability of\ninfrastructure and management services that perform essential functions\nnecessary for grid systems to operate, such as resource allocation and\nscheduling.\n", "versions": [{"version": "v1", "created": "Wed, 2 Feb 2011 17:36:58 GMT"}], "update_date": "2011-02-04", "authors_parsed": [["Patel", "Sanjay", ""], ["Bhavsar", "Madhuri", ""]]}, {"id": "1102.0629", "submitter": "Walter Quattrociocchi", "authors": "Nicola Santoro, Walter Quattrociocchi, Paola Flocchini, Arnaud\n  Casteigts, and Frederic Amblard", "title": "Time-Varying Graphs and Social Network Analysis: Temporal Indicators and\n  Metrics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.AI cs.DC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most instruments - formalisms, concepts, and metrics - for social networks\nanalysis fail to capture their dynamics. Typical systems exhibit different\nscales of dynamics, ranging from the fine-grain dynamics of interactions (which\nrecently led researchers to consider temporal versions of distance,\nconnectivity, and related indicators), to the evolution of network properties\nover longer periods of time. This paper proposes a general approach to study\nthat evolution for both atemporal and temporal indicators, based respectively\non sequences of static graphs and sequences of time-varying graphs that cover\nsuccessive time-windows. All the concepts and indicators, some of which are\nnew, are expressed using a time-varying graph formalism.\n", "versions": [{"version": "v1", "created": "Thu, 3 Feb 2011 09:26:50 GMT"}], "update_date": "2011-02-04", "authors_parsed": [["Santoro", "Nicola", ""], ["Quattrociocchi", "Walter", ""], ["Flocchini", "Paola", ""], ["Casteigts", "Arnaud", ""], ["Amblard", "Frederic", ""]]}, {"id": "1102.0720", "submitter": "Gabriele D'Angelo", "authors": "Gabriele D'Angelo, Stefano Ferretti, Moreno Marzolla", "title": "Adaptive Event Dissemination for Peer-to-Peer Multiplayer Online Games", "comments": "ICST/CREATE-NET DISIO 2011: 2nd Workshop on DIstributed SImulation\n  and Online gaming. March 21, 2011, Barcelona, Spain", "journal-ref": null, "doi": "10.4108/icst.simutools.2011.245539", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we show that gossip algorithms may be effectively used to\ndisseminate game events in Peer-to-Peer (P2P) Multiplayer Online Games (MOGs).\nGame events are disseminated through an overlay network. The proposed scheme\nexploits the typical behavior of players to tune the data dissemination. In\nfact, it is well known that users playing a MOG typically generate game events\nat a rate that can be approximated using some (game dependent) probability\ndistribution. Hence, as soon as a given node experiences a reception rate, for\nmessages coming from a given peer, which is lower than expected, it can send a\nstimulus to the neighbor that usually forwards these messages, asking it to\nincrease its dissemination probability. Three variants of this approach will be\nstudied. According to the first one, upon reception of a stimulus from a\nneighbor, a peer increases its dissemination probability towards that node\nirrespectively from the sender. In the second protocol a peer increases only\nthe dissemination probability for a given sender towards all its neighbors.\nFinally, the third protocol takes into consideration both the sender and the\nneighbor in order to decide how to increase the dissemination probability. We\nperformed extensive simulations to assess the efficacy of the proposed scheme,\nand based on the simulation results we compare the different dissemination\nprotocols. The results confirm that adaptive gossip schemes are indeed\neffective and deserve further investigation.\n", "versions": [{"version": "v1", "created": "Thu, 3 Feb 2011 16:17:00 GMT"}, {"version": "v2", "created": "Thu, 27 Dec 2012 08:49:49 GMT"}, {"version": "v3", "created": "Mon, 28 Jul 2014 09:53:28 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["D'Angelo", "Gabriele", ""], ["Ferretti", "Stefano", ""], ["Marzolla", "Moreno", ""]]}, {"id": "1102.1003", "submitter": "Rasmus Pagh", "authors": "Rasmus Resen Amossen and Rasmus Pagh", "title": "A New Data Layout For Set Intersection on GPUs", "comments": "A version of this paper appears in Proceedings of IPDPS 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Set intersection is the core in a variety of problems, e.g. frequent itemset\nmining and sparse boolean matrix multiplication. It is well-known that large\nspeed gains can, for some computational problems, be obtained by using a\ngraphics processing unit (GPU) as a massively parallel computing device.\nHowever, GPUs require highly regular control flow and memory access patterns,\nand for this reason previous GPU methods for intersecting sets have used a\nsimple bitmap representation. This representation requires excessive space on\nsparse data sets. In this paper we present a novel data layout, \"BatMap\", that\nis particularly well suited for parallel processing, and is compact even for\nsparse data.\n  Frequent itemset mining is one of the most important applications of set\nintersection. As a case-study on the potential of BatMaps we focus on frequent\npair mining, which is a core special case of frequent itemset mining. The main\nfinding is that our method is able to achieve speedups over both Apriori and\nFP-growth when the number of distinct items is large, and the density of the\nproblem instance is above 1%. Previous implementations of frequent itemset\nmining on GPU have not been able to show speedups over the best single-threaded\nimplementations.\n", "versions": [{"version": "v1", "created": "Fri, 4 Feb 2011 19:47:41 GMT"}], "update_date": "2011-02-07", "authors_parsed": [["Amossen", "Rasmus Resen", ""], ["Pagh", "Rasmus", ""]]}, {"id": "1102.1609", "submitter": "Kenneth Shum", "authors": "Kenneth W. Shum and Yuchong Hu", "title": "Exact Minimum-Repair-Bandwidth Cooperative Regenerating Codes for\n  Distributed Storage Systems", "comments": "5 pages, 4 figures, presented at IEEE ISIT 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to provide high data reliability, distributed storage systems\ndisperse data with redundancy to multiple storage nodes. Regenerating codes is\na new class of erasure codes to introduce redundancy for the purpose of\nimproving the data repair performance in distributed storage. Most of the\nstudies on regenerating codes focus on the single-failure recovery, but it is\nnot uncommon to see two or more node failures at the same time in large storage\nnetworks. To exploit the opportunity of repairing multiple failed nodes\nsimultaneously, a cooperative repair mechanism, in the sense that the nodes to\nbe repaired can exchange data among themselves, is investigated. A lower bound\non the repair-bandwidth for cooperative repair is derived and a construction of\na family of exact cooperative regenerating codes matching this lower bound is\npresented.\n", "versions": [{"version": "v1", "created": "Tue, 8 Feb 2011 14:11:58 GMT"}, {"version": "v2", "created": "Wed, 11 May 2011 12:03:54 GMT"}, {"version": "v3", "created": "Wed, 1 Jun 2011 03:56:38 GMT"}], "update_date": "2015-03-18", "authors_parsed": [["Shum", "Kenneth W.", ""], ["Hu", "Yuchong", ""]]}, {"id": "1102.1754", "submitter": "Rohini S -", "authors": "S. Rohini and K. Indumathi", "title": "Probability Based Adaptive Invoked Clustering Algorithm in MANETs", "comments": "6 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A mobile ad hoc network (MANET), is a self-configuring network of mobile\ndevices connected by wireless links. In order to achieve stable clusters, the\ncluster-heads maintaining the cluster should be stable with minimum overhead of\ncluster re-elections. In this paper we propose a Probability Based Adaptive\nInvoked Weighted Clustering Algorithm (PAIWCA) which can enhance the stability\nof the clusters by taking battery power of the nodes into considerations for\nthe clustering formation and electing stable cluster-heads using cluster head\nprobability of a node. In this simulation study a comparison was conducted to\nmeasure the performance of our algorithm with maximal weighted independent set\n(MWIS) in terms of the number of clusters formed, the connectivity of the\nnetwork, dominant set updates,throughput of the overall network and packet\ndelivery ratio. The result shows that our algorithm performs better than\nexisting one and is also tunable to different kinds of network conditions.\n", "versions": [{"version": "v1", "created": "Wed, 9 Feb 2011 00:25:31 GMT"}], "update_date": "2011-02-10", "authors_parsed": [["Rohini", "S.", ""], ["Indumathi", "K.", ""]]}, {"id": "1102.2131", "submitter": "Deepak Dahiya", "authors": "Usha Batra, Deepak Dahiya and Sachin Bhardwaj", "title": "Analytical Study of Object Components for Distributed and Ubiquitous\n  Computing Environment", "comments": "This paper has been withdrawn by the authors", "journal-ref": "WSEAS TRANSACTIONS on INFORMATION SCIENCE & APPLICATIONS, Issue 6,\n  Volume 5, June 2008, ISSN: 1790-0832", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Distributed object computing is a paradigm that allows objects to be\ndistributed across a heterogeneous network, and allows each of the components\nto interoperate as a unified whole. A new generation of distributed\napplications, such as telemedicine and e-commerce applications, are being\ndeployed in heterogeneous and ubiquitous computing environments. The objective\nof this paper is to explore an applicability of a component based services in\nubiquitous computational environment. While the fundamental structure of\nvarious distributed object components is similar, there are differences that\ncan profoundly impact an application developer or the administrator of a\ndistributed simulation exercise and to implement in Ubiquitous Computing\nEnvironment.\n", "versions": [{"version": "v1", "created": "Thu, 10 Feb 2011 14:39:49 GMT"}, {"version": "v2", "created": "Thu, 17 Feb 2011 07:33:00 GMT"}], "update_date": "2011-02-18", "authors_parsed": [["Batra", "Usha", ""], ["Dahiya", "Deepak", ""], ["Bhardwaj", "Sachin", ""]]}, {"id": "1102.2346", "submitter": "Hubert Simma", "authors": "Marcello Pivanti, Sebastiano Fabio Schifano, Hubert Simma", "title": "An FPGA-based Torus Communication Network", "comments": "7 pages, 3 figures, proceedings of the XXVIII International Symposium\n  on Lattice Field Theory, Lattice2010, June 14-19, 2010, Villasimius,\n  Sardinia, Italy", "journal-ref": "PoS LATTICE2010:038,2010", "doi": null, "report-no": "DESY 11-011", "categories": "hep-lat cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe the design and FPGA implementation of a 3D torus network (TNW) to\nprovide nearest-neighbor communications between commodity multi-core\nprocessors. The aim of this project is to build up tightly interconnected and\nscalable parallel systems for scientific computing. The design includes the\nVHDL code to implement on latest FPGA devices a network processor, which can be\naccessed by the CPU through a PCIe interface and which controls the external\nPHYs of the physical links. Moreover, a Linux driver and a library implementing\ncustom communication APIs are provided. The TNW has been successfully\nintegrated in two recent parallel machine projects, QPACE and AuroraScience. We\ndescribe some details of the porting of the TNW for the AuroraScience system\nand report performance results.\n", "versions": [{"version": "v1", "created": "Fri, 11 Feb 2011 13:31:47 GMT"}], "update_date": "2011-03-15", "authors_parsed": [["Pivanti", "Marcello", ""], ["Schifano", "Sebastiano Fabio", ""], ["Simma", "Hubert", ""]]}, {"id": "1102.2608", "submitter": "Lskrao Chimakurthi", "authors": "Lskrao Chimakurthi, Madhu Kumar S D", "title": "Power Efficient Resource Allocation for Clouds Using Ant Colony\n  Framework", "comments": "6 pages, 1 figure, 6 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is one of the rapidly improving technologies. It provides\nscalable resources needed for the ap- plications hosted on it. As cloud-based\nservices become more dynamic, resource provisioning becomes more challenging.\nThe QoS constrained resource allocation problem is considered in this paper, in\nwhich customers are willing to host their applications on the provider's cloud\nwith a given SLA requirements for performance such as throughput and response\ntime. Since, the data centers hosting the applications consume huge amounts of\nenergy and cause huge operational costs, solutions that reduce energy\nconsumption as well as operational costs are gaining importance. In this work,\nwe propose an energy efficient mechanism that allocates the cloud resources to\nthe applications without violating the given service level agreements(SLA)\nusing Ant colony framework.\n", "versions": [{"version": "v1", "created": "Sun, 13 Feb 2011 15:56:29 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Chimakurthi", "Lskrao", ""], ["D", "Madhu Kumar S", ""]]}, {"id": "1102.2616", "submitter": "William Jackson", "authors": "Sanjay Bansal and Sanjeev Sharma", "title": "An Improved Multiple Faults Reassignment based Recovery in Cluster\n  Computing", "comments": "Online at http://journalofcomputing.org", "journal-ref": "Journal of Computing, Volume 2, Issue 11, November 2010, eISSN\n  2151-9617", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In case of multiple node failures performance becomes very low as compare to\nsingle node failure. Failures of nodes in cluster computing can be tolerated by\nmultiple fault tolerant computing. Existing recovery schemes are efficient for\nsingle fault but not with multiple faults. Recovery scheme proposed in this\npaper having two phases; sequentially phase, concurrent phase. In sequentially\nphase, loads of all working nodes are uniformly and evenly distributed by\nproposed dynamic rank based and load distribution algorithm. In concurrent\nphase, loads of all failure nodes as well as new job arrival are assigned\nequally to all available nodes by just finding the least loaded node among the\nseveral nodes by failure nodes job allocation algorithm. Sequential and\nconcurrent executions of algorithms improve the performance as well better\nresource utilization. Dynamic rank based algorithm for load redistribution\nworks as a sequential restoration algorithm and reassignment algorithm for\ndistribution of failure nodes to least loaded computing nodes works as a\nconcurrent recovery reassignment algorithm. Since load is evenly and uniformly\ndistributed among all available working nodes with less number of iterations,\nlow iterative time and communication overheads hence performance is improved.\nDynamic ranking algorithm is low overhead, high convergence algorithm for\nreassignment of tasks uniformly among all available nodes. Reassignments of\nfailure nodes are done by a low overhead efficient failure job allocation\nalgorithm. Test results to show effectiveness of the proposed scheme are\npresented.\n", "versions": [{"version": "v1", "created": "Sun, 13 Feb 2011 16:50:30 GMT"}], "update_date": "2011-02-15", "authors_parsed": [["Bansal", "Sanjay", ""], ["Sharma", "Sanjeev", ""]]}, {"id": "1102.2906", "submitter": "Danupon Nanongkai", "authors": "Danupon Nanongkai, Atish Das Sarma, Gopal Pandurangan", "title": "A Tight Lower Bound on Distributed Random Walk Computation", "comments": "PODC 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of performing a random walk in a distributed network.\nGiven bandwidth constraints, the goal of the problem is to minimize the number\nof rounds required to obtain a random walk sample. Das Sarma et al. [PODC'10]\nshow that a random walk of length $\\ell$ on a network of diameter $D$ can be\nperformed in $\\tilde O(\\sqrt{\\ell D}+D)$ time. A major question left open is\nwhether there exists a faster algorithm, especially whether the multiplication\nof $\\sqrt{\\ell}$ and $\\sqrt{D}$ is necessary.\n  In this paper, we show a tight unconditional lower bound on the time\ncomplexity of distributed random walk computation. Specifically, we show that\nfor any $n$, $D$, and $D\\leq \\ell \\leq (n/(D^3\\log n))^{1/4}$, performing a\nrandom walk of length $\\Theta(\\ell)$ on an $n$-node network of diameter $D$\nrequires $\\Omega(\\sqrt{\\ell D}+D)$ time. This bound is {\\em unconditional},\ni.e., it holds for any (possibly randomized) algorithm. To the best of our\nknowledge, this is the first lower bound that the diameter plays a role of\nmultiplicative factor. Our bound shows that the algorithm of Das Sarma et al.\nis time optimal.\n  Our proof technique introduces a new connection between {\\em bounded-round}\ncommunication complexity and distributed algorithm lower bounds with $D$ as a\ntrade-off parameter, strengthening the previous study by Das Sarma et al.\n[STOC'11]. In particular, we make use of the bounded-round communication\ncomplexity of the pointer chasing problem. Our technique can be of independent\ninterest and may be useful in showing non-trivial lower bounds on the\ncomplexity of other fundamental distributed computing problems.\n", "versions": [{"version": "v1", "created": "Mon, 14 Feb 2011 21:32:54 GMT"}, {"version": "v2", "created": "Sat, 15 Oct 2011 17:27:18 GMT"}], "update_date": "2011-10-18", "authors_parsed": [["Nanongkai", "Danupon", ""], ["Sarma", "Atish Das", ""], ["Pandurangan", "Gopal", ""]]}, {"id": "1102.3058", "submitter": "Michele Mazzucco", "authors": "Michele Mazzucco and Dmytro Dyachuk and Ralph Deters", "title": "Maximizing Cloud Providers Revenues via Energy Aware Allocation Policies", "comments": "8 pages", "journal-ref": "2010 IEEE 3rd International Conference on Cloud Computing, 2010 --\n  pp 131-138", "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Cloud providers, like Amazon, offer their data centers' computational and\nstorage capacities for lease to paying customers. High electricity consumption,\nassociated with running a data center, not only reflects on its carbon\nfootprint, but also increases the costs of running the data center itself. This\npaper addresses the problem of maximizing the revenues of Cloud providers by\ntrimming down their electricity costs. As a solution allocation policies which\nare based on the dynamic powering servers on and off are introduced and\nevaluated. The policies aim at satisfying the conflicting goals of maximizing\nthe users' experience while minimizing the amount of consumed electricity. The\nresults of numerical experiments and simulations are described, showing that\nthe proposed scheme performs well under different traffic conditions.\n", "versions": [{"version": "v1", "created": "Tue, 15 Feb 2011 12:56:25 GMT"}], "update_date": "2011-02-16", "authors_parsed": [["Mazzucco", "Michele", ""], ["Dyachuk", "Dmytro", ""], ["Deters", "Ralph", ""]]}, {"id": "1102.3059", "submitter": "Michele Mazzucco", "authors": "Michele Mazzucco and Dmytro Dyachuk and Marios Dikaiakos", "title": "Profit-Aware Server Allocation for Green Internet Services", "comments": "8 pages", "journal-ref": "18th Annual IEEE/ACM International Symposium on Modeling, Analysis\n  and Simulation of Computer and Telecommunication Systems, 2010, pp 277-284", "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  A server farm is examined, where a number of servers are used to offer a\nservice to impatient customers. Every completed request generates a certain\namount of profit, running servers consume electricity for power and cooling,\nwhile waiting customers might leave the system before receiving service if they\nexperience excessive delays. A dynamic allocation policy aiming at satisfying\nthe conflicting goals of maximizing the quality of users' experience while\nminimizing the cost for the provider is introduced and evaluated. The results\nof several experiments are described, showing that the proposed scheme performs\nwell under different traffic conditions.\n", "versions": [{"version": "v1", "created": "Tue, 15 Feb 2011 13:07:53 GMT"}], "update_date": "2011-02-16", "authors_parsed": [["Mazzucco", "Michele", ""], ["Dyachuk", "Dmytro", ""], ["Dikaiakos", "Marios", ""]]}, {"id": "1102.3114", "submitter": "Sam Skipsey", "authors": "Samuel C Skipsey (1), Wahid Bhimji (2), Mike Kenyon (3) ((1)\n  University of Glasgow, (2) University of Edinburgh, (3) IT Department, CERN)", "title": "Establishing Applicability of SSDs to LHC Tier-2 Hardware Configuration", "comments": "6 pages, 1 figure, 4 tables. Conference proceedings for CHEP2010", "journal-ref": null, "doi": "10.1088/1742-6596/331/5/052019", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Solid State Disk technologies are increasingly replacing high-speed hard\ndisks as the storage technology in high-random-I/O environments. There are\nseveral potentially I/O bound services within the typical LHC Tier-2 - in the\nback-end, with the trend towards many-core architectures continuing, worker\nnodes running many single-threaded jobs and storage nodes delivering many\nsimultaneous files can both exhibit I/O limited efficiency. We estimate the\neffectiveness of affordable SSDs in the context of worker nodes, on a large\nTier-2 production setup using both low level tools and real LHC I/O intensive\ndata analysis jobs comparing and contrasting with high performance spinning\ndisk based solutions. We consider the applicability of each solution in the\ncontext of its price/performance metrics, with an eye on the pragmatic issues\nfacing Tier-2 provision and upgrades\n", "versions": [{"version": "v1", "created": "Tue, 15 Feb 2011 16:05:04 GMT"}], "update_date": "2015-05-27", "authors_parsed": [["Skipsey", "Samuel C", ""], ["Bhimji", "Wahid", ""], ["Kenyon", "Mike", ""]]}, {"id": "1102.3272", "submitter": "Michele Mazzucco", "authors": "Dmytro Dyachuk and Michele Mazzucco", "title": "On Allocation Policies for Power and Performance", "comments": "8 pages, 11 figures, 2010 11th IEEE/ACM International Conference on\n  Grid Computing (GRID), pp 313 - 320 (E2GC2-2010 workshop)", "journal-ref": "2010 11th IEEE/ACM International Conference on Grid Computing\n  (GRID), pp 313 - 320", "doi": "10.1109/GRID.2010.5697986", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  With the increasing popularity of Internet-based services and applications,\npower efficiency is becoming a major concern for data center operators, as high\nelectricity consumption not only increases greenhouse gas emissions, but also\nincreases the cost of running the server farm itself. In this paper we address\nthe problem of maximizing the revenue of a service provider by means of dynamic\nallocation policies that run the minimum amount of servers necessary to meet\nuser's requirements in terms of performance. The results of several experiments\nexecuted using Wikipedia traces are described, showing that the proposed\nschemes work well, even if the workload is non-stationary. Since any resource\nallocation policy requires the use of forecasting mechanisms, various schemes\nallowing compensating errors in the load forecasts are presented and evaluated.\n", "versions": [{"version": "v1", "created": "Wed, 16 Feb 2011 09:25:26 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Dyachuk", "Dmytro", ""], ["Mazzucco", "Michele", ""]]}, {"id": "1102.3493", "submitter": "Joseph Koo", "authors": "Joseph C. Koo, John Gill", "title": "Scalable constructions of fractional repetition codes in distributed\n  storage systems", "comments": "8 pages, 6 figures, presented at 49th Allerton Conference on\n  Communication Control and Computing, 2011", "journal-ref": null, "doi": "10.1109/Allerton.2011.6120326", "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed storage systems built using commodity hardware, it is\nnecessary to have data redundancy in order to ensure system reliability. In\nsuch systems, it is also often desirable to be able to quickly repair storage\nnodes that fail. We consider a scheme--introduced by El Rouayheb and\nRamchandran--which uses combinatorial block design in order to design storage\nsystems that enable efficient (and exact) node repair. In this work, we\ninvestigate systems where node sizes may be much larger than replication\ndegrees, and explicitly provide algorithms for constructing these storage\ndesigns. Our designs, which are related to projective geometries, are based on\nthe construction of bipartite cage graphs (with girth 6) and the concept of\nmutually-orthogonal Latin squares. Via these constructions, we can guarantee\nthat the resulting designs require the fewest number of storage nodes for the\ngiven parameters, and can further show that these systems can be easily\nexpanded without need for frequent reconfiguration.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 04:31:27 GMT"}, {"version": "v2", "created": "Fri, 30 Sep 2011 03:56:13 GMT"}], "update_date": "2012-01-24", "authors_parsed": [["Koo", "Joseph C.", ""], ["Gill", "John", ""]]}, {"id": "1102.3563", "submitter": "Alexander Semenov", "authors": "Alexander Semenov, Oleg Zaikin, Dmitry Bespalov, Mikhail Posypkin", "title": "Parallel algorithms for SAT in application to inversion problems of some\n  discrete functions", "comments": "16 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we consider the inversion problem for polynomially computable\ndiscrete functions. These functions describe behavior of many discrete systems\nand are used in model checking, hardware verification, cryptanalysis, computer\nbiology and other domains. Quite often it is necessary to invert these\nfunctions, i.e. to find an unknown preimage if an image and algorithm of\nfunction computation are given. In general case this problem is computationally\nintractable. However, many of it's special cases are very important in\npractical applications. Thus development of algorithms that are applicable to\nthese special cases is of importance. The practical applicability of such\nalgorithms can be validated by their ability to solve the problems that are\nconsidered to be computationally hard (for example cryptanalysis problems). In\nthis article we propose the technology of solving the inversion problem for\npolynomially computable discrete functions. This technology was implemented in\ndistributed computing environments (parallel clusters and Grid-systems). It is\nbased on reducing the inversion problem for the considered function to some SAT\nproblem. We describe a general approach to coarse-grained parallelization for\nobtained SAT problems. Efficiency of each parallelization scheme is determined\nby the means of a special predictive function. The proposed technology was\nvalidated by successful solving of cryptanalysis problems for some keystream\ngenerators. The main practical result of this work is a complete cryptanalysis\nof keystream generator A5/1 which was performed in a Grid system specially\nbuilt for this task.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 11:28:21 GMT"}], "update_date": "2011-02-18", "authors_parsed": [["Semenov", "Alexander", ""], ["Zaikin", "Oleg", ""], ["Bespalov", "Dmitry", ""], ["Posypkin", "Mikhail", ""]]}, {"id": "1102.3699", "submitter": "Michele Mazzucco", "authors": "Michele Mazzucco", "title": "Towards Autonomic Service Provisioning Systems", "comments": "11 pages, 9 Figures,\n  http://www.wipo.int/pctdb/en/wo.jsp?WO=2010026362", "journal-ref": "10th IEEE/ACM CCGrid 2010, pp 273-282", "doi": "10.1109/CCGRID.2010.125", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper discusses our experience in building SPIRE, an autonomic system\nfor service provision. The architecture consists of a set of hosted Web\nServices subject to QoS constraints, and a certain number of servers used to\nrun session-based traffic. Customers pay for having their jobs run, but require\nin turn certain quality guarantees: there are different SLAs specifying charges\nfor running jobs and penalties for failing to meet promised performance\nmetrics. The system is driven by an utility function, aiming at optimizing the\naverage earned revenue per unit time. Demand and performance statistics are\ncollected, while traffic parameters are estimated in order to make dynamic\ndecisions concerning server allocation and admission control. Different utility\nfunctions are introduced and a number of experiments aiming at testing their\nperformance are discussed. Results show that revenues can be dramatically\nimproved by imposing suitable conditions for accepting incoming traffic; the\nproposed system performs well under different traffic settings, and it\nsuccessfully adapts to changes in the operating environment.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 21:07:38 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Mazzucco", "Michele", ""]]}, {"id": "1102.3703", "submitter": "Michele Mazzucco", "authors": "Michele Mazzucco, Isi Mitrani, Mike Fisher, Paul McKee", "title": "Allocation and Admission Policies for Service Streams", "comments": "8 pages, 5 figures, 16th International Symposium on Modeling,\n  Analysis, and Simulation of Computer and Telecommunication Systems (MASCOTS\n  2008), pp155-162 (Best Paper Award)", "journal-ref": "16th International Symposium on Modeling, Analysis, and Simulation\n  of Computer and Telecommunication Systems (MASCOTS 2008), pp155-162", "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A service provisioning system is examined, where a number of servers are used\nto offer different types of services to paying customers. A customer is charged\nfor the execution of a stream of jobs; the number of jobs in the stream and the\nrate of their submission is specified. On the other hand, the provider promises\na certain quality of service (QoS), measured by the average waiting time of the\njobs in the stream. A penalty is paid if the agreed QoS requirement is not met.\nThe objective is to maximize the total average revenue per unit time. Dynamic\npolicies for making server allocation and stream admission decisions are\nintroduced and evaluated. The results of several simulations are described.\n", "versions": [{"version": "v1", "created": "Thu, 17 Feb 2011 21:20:06 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Mazzucco", "Michele", ""], ["Mitrani", "Isi", ""], ["Fisher", "Mike", ""], ["McKee", "Paul", ""]]}, {"id": "1102.3741", "submitter": "EPTCS", "authors": "Johannes Reich (SAP AG, Walldorf), Bernd Finkbeiner (Universit\\\"at des\n  Saarlandes)", "title": "Proceedings International Workshop on Interactions, Games and Protocols", "comments": null, "journal-ref": "EPTCS 50, 2011", "doi": "10.4204/EPTCS.50", "report-no": null, "categories": "cs.GT cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of the iWIGP workshop is the interrelation between interactions,\ngames and protocols. How does computer science deal with nondeterministic\ninteractions where the actions a system takes are not (completely) determined\nby the interactions the system is involved in? In computer science,\nnondeterministic interactions are usually described by protocols. However,\nthese interactions can also be viewed as games. As to be expected, games have\nbecome an increasingly important modeling tool wherever nondeterministic\ninteractions are involved -- from foundations in game semantics and reactive\nsystems to applications in communication protocols and electronic business\napplications. The goal of this workshop has been to bring researchers from\nindustry and academia together and to explore how a better understanding of the\ninterrelation between interactions, games and protocols leads to\nbetter-designed and more reliable nondeterministic interacting systems.\n  iWIGP 2011 was collocated with ETAPS 2011 in Saarbruecken, Germany. The\nprogramme consisted of three invited talks, by Kim Larsen, Marielle Stoelinga\nand Viktor Kuncak, and five refereed papers, selected by a strong programme\ncommittee of international reputation. The refereed papers are contained in\nthis volume.\n", "versions": [{"version": "v1", "created": "Fri, 18 Feb 2011 03:02:15 GMT"}], "update_date": "2011-02-21", "authors_parsed": [["Reich", "Johannes", "", "SAP AG, Walldorf"], ["Finkbeiner", "Bernd", "", "Universit\u00e4t des\n  Saarlandes"]]}, {"id": "1102.4100", "submitter": "Cristina Fernandes", "authors": "Cristina G. Fernandes and Maya Stein", "title": "Geodesic stability for memoryless binary long-lived consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The determination of the stability of the long-lived consensus problem is a\nfundamental open problem in distributed systems. We concentrate on the\nmemoryless binary case with geodesic paths. We offer a conjecture on the\nstability in this case, exhibit two classes of colourings which attain this\nconjectured bound, and improve the known lower bounds for all colourings. We\nalso introduce a related parameter, which measures the stability only for\ncertain geodesics, and for which we also prove lower bounds.\n", "versions": [{"version": "v1", "created": "Sun, 20 Feb 2011 20:06:59 GMT"}], "update_date": "2011-02-22", "authors_parsed": [["Fernandes", "Cristina G.", ""], ["Stein", "Maya", ""]]}, {"id": "1102.4293", "submitter": "Pawe{\\l} Widera", "authors": "Pawe{\\l} Widera and Natalio Krasnogor", "title": "Protein Models Comparator: Scalable Bioinformatics Computing on the\n  Google App Engine Platform", "comments": "10 pages, 6 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC q-bio.BM", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The comparison of computer generated protein structural models is an\nimportant element of protein structure prediction. It has many uses including\nmodel quality evaluation, selection of the final models from a large set of\ncandidates or optimisation of parameters of energy functions used in\ntemplate-free modelling and refinement. Although many protein comparison\nmethods are available online on numerous web servers, they are not well suited\nfor large scale model comparison: (1) they operate with methods designed to\ncompare actual proteins, not the models of the same protein, (2) majority of\nthem offer only a single pairwise structural comparison and are unable to scale\nup to a required order of thousands of comparisons. To bridge the gap between\nthe protein and model structure comparison we have developed the Protein Models\nComparator (pm-cmp). To be able to deliver the scalability on demand and handle\nlarge comparison experiments the pm-cmp was implemented \"in the cloud\".\n  Protein Models Comparator is a scalable web application for a fast\ndistributed comparison of protein models with RMSD, GDT TS, TM-score and\nQ-score measures. It runs on the Google App Engine (GAE) cloud platform and is\na showcase of how the emerging PaaS (Platform as a Service) technology could be\nused to simplify the development of scalable bioinformatics services. The\nfunctionality of pm-cmp is accessible through API which allows a full\nautomation of the experiment submission and results retrieval. Protein Models\nComparator is free software released on the Affero GNU Public Licence and is\navailable with its source code at: http://www.infobiotics.org/pm-cmp\n  This article presents a new web application addressing the need for a\nlarge-scale model-specific protein structure comparison and provides an insight\ninto the GAE (Google App Engine) platform and its usefulness in scientific\ncomputing.\n", "versions": [{"version": "v1", "created": "Mon, 21 Feb 2011 17:57:04 GMT"}, {"version": "v2", "created": "Tue, 26 Jul 2011 18:30:22 GMT"}], "update_date": "2011-07-27", "authors_parsed": [["Widera", "Pawe\u0142", ""], ["Krasnogor", "Natalio", ""]]}, {"id": "1102.4423", "submitter": "Peter Robinson", "authors": "Martin Biely, Peter Robinson, Ulrich Schmid", "title": "Solving k-Set Agreement with Stable Skeleton Graphs", "comments": "to appear in 16th IEEE Workshop on Dependable Parallel, Distributed\n  and Network-Centric Systems", "journal-ref": null, "doi": "10.1109/IPDPS.2011.301", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the k-set agreement problem in distributed\nmessage-passing systems using a round-based approach: Both synchrony of\ncommunication and failures are captured just by means of the messages that\narrive within a round, resulting in round-by-round communication graphs that\ncan be characterized by simple communication predicates. We introduce the weak\ncommunication predicate PSources(k) and show that it is tight for k-set\nagreement, in the following sense: We (i) prove that there is no algorithm for\nsolving (k-1)-set agreement in systems characterized by PSources(k), and (ii)\npresent a novel distributed algorithm that achieves k-set agreement in runs\nwhere PSources(k) holds. Our algorithm uses local approximations of the stable\nskeleton graph, which reflects the underlying perpetual synchrony of a run. We\nprove that this approximation is correct in all runs, regardless of the\ncommunication predicate, and show that graph-theoretic properties of the stable\nskeleton graph can be used to solve k-set agreement if PSources(k) holds.\n", "versions": [{"version": "v1", "created": "Tue, 22 Feb 2011 07:41:38 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Biely", "Martin", ""], ["Robinson", "Peter", ""], ["Schmid", "Ulrich", ""]]}, {"id": "1102.4666", "submitter": "Jerome Lelong", "authors": "C\\'eline Labart (LAMA), J\\'er\\^ome Lelong (LJK)", "title": "A Parallel Algorithm for solving BSDEs - Application to the pricing and\n  hedging of American options", "comments": "25 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a parallel algorithm for solving backward stochastic differential\nequations (BSDEs in short) which are very useful theoretic tools to deal with\nmany financial problems ranging from option pricing option to risk management.\nOur algorithm based on Gobet and Labart (2010) exploits the link between BSDEs\nand non linear partial differential equations (PDEs in short) and hence enables\nto solve high dimensional non linear PDEs. In this work, we apply it to the\npricing and hedging of American options in high dimensional local volatility\nmodels, which remains very computationally demanding. We have tested our\nalgorithm up to dimension 10 on a cluster of 512 CPUs and we obtained linear\nspeedups which proves the scalability of our implementation\n", "versions": [{"version": "v1", "created": "Wed, 23 Feb 2011 06:17:16 GMT"}], "update_date": "2011-02-25", "authors_parsed": [["Labart", "C\u00e9line", "", "LAMA"], ["Lelong", "J\u00e9r\u00f4me", "", "LJK"]]}, {"id": "1102.4728", "submitter": "Xu Chen", "authors": "Xu Chen and Jianwei Huang and Husheng Li", "title": "Adaptive Channel Recommendation For Opportunistic Spectrum Access", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a dynamic spectrum access scheme where secondary users recommend\n\"good\" channels to each other and access accordingly. We formulate the problem\nas an average reward based Markov decision process. We show the existence of\nthe optimal stationary spectrum access policy, and explore its structure\nproperties in two asymptotic cases. Since the action space of the Markov\ndecision process is continuous, it is difficult to find the optimal policy by\nsimply discretizing the action space and use the policy iteration, value\niteration, or Q-learning methods. Instead, we propose a new algorithm based on\nthe Model Reference Adaptive Search method, and prove its convergence to the\noptimal policy. Numerical results show that the proposed algorithms achieve up\nto 18% and 100% performance improvement than the static channel recommendation\nscheme in homogeneous and heterogeneous channel environments, respectively, and\nis more robust to channel dynamics.\n", "versions": [{"version": "v1", "created": "Wed, 23 Feb 2011 12:57:21 GMT"}, {"version": "v2", "created": "Wed, 13 Jul 2011 08:46:59 GMT"}], "update_date": "2011-07-14", "authors_parsed": [["Chen", "Xu", ""], ["Huang", "Jianwei", ""], ["Li", "Husheng", ""]]}, {"id": "1102.4946", "submitter": "Armando Casta\\~neda", "authors": "Armando Casta\\~neda, Maurice Herlihy and Sergio Rajsbaum", "title": "An Equivariance Theorem with Applications to Renaming (Preliminary\n  Version)", "comments": "20 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the renaming problem, each process in a distributed system is issued a\nunique name from a large name space, and the processes must coordinate with one\nanother to choose unique names from a much smaller name space. We show that\nlower bounds on the solvability of renaming in an asynchronous distributed\nsystem can be formulated as a purely topological question about the existence\nof an equivariant chain map from a topological disk to a topological annulus.\nProving the non-existence of such a map implies the non-existence of a\ndistributed renaming algorithm in several related models of computation.\n", "versions": [{"version": "v1", "created": "Thu, 24 Feb 2011 10:24:43 GMT"}], "update_date": "2011-02-25", "authors_parsed": [["Casta\u00f1eda", "Armando", ""], ["Herlihy", "Maurice", ""], ["Rajsbaum", "Sergio", ""]]}, {"id": "1102.4981", "submitter": "Maria Potop-Butucaru", "authors": "Taisuke Izumi, Maria Potop-Butucaru (LIP6, INRIA Rocquencourt),\n  Mathieu Valero (LIP6, INRIA Rocquencourt)", "title": "Physical expander in Virtual Tree Overlay", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a new construction of constantdegree expanders\nmotivated by their application in P2P overlay networks and in particular in the\ndesign of robust trees overlay. Our key result can be stated as follows.\nConsider a complete binary tree T and construct a random pairing {\\Pi} between\nleaf nodes and internal nodes. We prove that the graph G\\Pi obtained from T by\ncontracting all pairs (leaf-internal nodes) achieves a constant node expansion\nwith high probability. The use of our result in improving the robustness of\ntree overlays is straightforward. That is, if each physical node participating\nto the overlay manages a random pair that couples one virtual internal node and\none virtual leaf node then the physical-node layer exhibits a constant\nexpansion with high probability. We encompass the difficulty of obtaining this\nrandom tree virtualization by proposing a local, selforganizing and churn\nresilient uniformly-random pairing algorithm with O(log2 n) running time. Our\nalgorithm has the merit to not modify the original tree virtual overlay (we\njust control the mapping between physical nodes and virtual nodes). Therefore,\nour scheme is general and can be applied to a large number of tree overlay\nimplementations. We validate its performances in dynamic environments via\nextensive simulations.\n", "versions": [{"version": "v1", "created": "Thu, 24 Feb 2011 13:17:17 GMT"}], "update_date": "2011-02-25", "authors_parsed": [["Izumi", "Taisuke", "", "LIP6, INRIA Rocquencourt"], ["Potop-Butucaru", "Maria", "", "LIP6, INRIA Rocquencourt"], ["Valero", "Mathieu", "", "LIP6, INRIA Rocquencourt"]]}, {"id": "1102.5328", "submitter": "Emmanuel Agullo", "authors": "Emmanuel Agullo (INRIA Bordeaux - Sud-Ouest, LaBRI), Jack Dongarra\n  (ICL), Rajib Nath (ICL), Stanimire Tomov (ICL)", "title": "Fully Empirical Autotuned QR Factorization For Multicore Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": "RR-7526", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Tuning numerical libraries has become more difficult over time, as systems\nget more sophisticated. In particular, modern multicore machines make the\nbehaviour of algorithms hard to forecast and model. In this paper, we tackle\nthe issue of tuning a dense QR factorization on multicore architectures. We\nshow that it is hard to rely on a model, which motivates us to design a fully\nempirical approach. We exhibit few strong empirical properties that enable us\nto efficiently prune the search space. Our method is automatic, fast and\nreliable. The tuning process is indeed fully performed at install time in less\nthan one and ten minutes on five out of seven platforms. We achieve an average\nperformance varying from 97% to 100% of the optimum performance depending on\nthe platform. This work is a basis for autotuning the PLASMA library and\nenabling easy performance portability across hardware systems.\n", "versions": [{"version": "v1", "created": "Fri, 25 Feb 2011 20:21:32 GMT"}], "update_date": "2011-02-28", "authors_parsed": [["Agullo", "Emmanuel", "", "INRIA Bordeaux - Sud-Ouest, LaBRI"], ["Dongarra", "Jack", "", "ICL"], ["Nath", "Rajib", "", "ICL"], ["Tomov", "Stanimire", "", "ICL"]]}, {"id": "1102.5425", "submitter": "Christoph Lenzen", "authors": "Christoph Lenzen and Roger Wattenhofer", "title": "Tight Bounds for Parallel Randomized Load Balancing", "comments": "39 pages, 2 figures. Extended abstract will be published at STOC'11", "journal-ref": null, "doi": null, "report-no": "TIK report number 324", "categories": "cs.CC cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore the fundamental limits of distributed balls-into-bins algorithms.\nWe present an adaptive symmetric algorithm that achieves a bin load of two in\nlog* n+O(1) communication rounds using O(n) messages in total. Larger bin loads\ncan be traded in for smaller time complexities. We prove a matching lower bound\nof (1-o(1))log* n on the time complexity of symmetric algorithms that guarantee\nsmall bin loads at an asymptotically optimal message complexity of O(n). For\neach assumption of the lower bound, we provide an algorithm violating it, in\nturn achieving a constant maximum bin load in constant time.\n  As an application, we consider the following problem. Given a fully connected\ngraph of n nodes, where each node needs to send and receive up to n messages,\nand in each round each node may send one message over each link, deliver all\nmessages as quickly as possible to their destinations. We give a simple and\nrobust algorithm of time complexity O(log* n) for this task and provide a\ngeneralization to the case where all nodes initially hold arbitrary sets of\nmessages. A less practical algorithm terminates within asymptotically optimal\nO(1) rounds. All these bounds hold with high probability.\n", "versions": [{"version": "v1", "created": "Sat, 26 Feb 2011 15:45:45 GMT"}], "update_date": "2011-03-01", "authors_parsed": [["Lenzen", "Christoph", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1102.5529", "submitter": "Arnaud Casteigts", "authors": "Arnaud Casteigts, Serge Chaumette, Afonso Ferreira", "title": "Characterizing Topological Assumptions of Distributed Algorithms in\n  Dynamic Networks", "comments": "18 pages, 12 figures, long version of a Sirocco'09 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Besides the complexity in time or in number of messages, a common approach\nfor analyzing distributed algorithms is to look at the assumptions they make on\nthe underlying network. We investigate this question from the perspective of\nnetwork dynamics. In particular, we ask how a given property on the evolution\nof the network can be rigorously proven as necessary or sufficient for a given\nalgorithm. The main contribution of this paper is to propose the combination of\ntwo existing tools in this direction: local computations by means of graph\nrelabelings, and evolving graphs. Such a combination makes it possible to\nexpress fine-grained properties on the network dynamics, then examine what\nimpact those properties have on the execution at a precise, intertwined, level.\nWe illustrate the use of this framework through the analysis of three simple\nalgorithms, then discuss general implications of this work, which include (i)\nthe possibility to compare distributed algorithms on the basis of their\ntopological requirements, (ii) a formal hierarchy of dynamic networks based on\nthese requirements, and (iii) the potential for mechanization induced by our\nframework, which we believe opens a door towards automated analysis and\ndecision support in dynamic networks.\n", "versions": [{"version": "v1", "created": "Sun, 27 Feb 2011 17:59:14 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2011 18:23:17 GMT"}, {"version": "v3", "created": "Fri, 16 Dec 2011 23:00:56 GMT"}, {"version": "v4", "created": "Mon, 30 Jan 2012 18:54:22 GMT"}, {"version": "v5", "created": "Thu, 1 May 2014 11:33:10 GMT"}], "update_date": "2014-05-02", "authors_parsed": [["Casteigts", "Arnaud", ""], ["Chaumette", "Serge", ""], ["Ferreira", "Afonso", ""]]}]