[{"id": "2102.00059", "submitter": "Michael Chiu", "authors": "Michael Chiu and Uro\\v{s} Kalabi\\'c", "title": "Debt Representation in UTXO Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a UTXO model of blockchain transactions that is able to represent\nboth credit and debt on the same blockchain. Ordinarily, the UTXO model is\nsolely used to represent credit and the representation of credit and debit\ntogether is achieved using the account model because of its support for\nbalances. However, the UTXO model provides superior privacy, safety, and\nscalability when compared to the account model. In this work, we introduce a\nUTXO model that has the flexibility of balances with the usual benefits of the\nUTXO model. This model extends the conventional UTXO model, which represents\ncredits as unmatched outputs, by representing debts as unmatched inputs. We\napply our model to solving the problem of transparency in reverse mortgage\nmarkets, in which some transparency is necessary for a healthy market but\ncomplete transparency leads to adverse outcomes. Here the pseudonymous\nproperties of the UTXO model protect the privacy of loan recipients while still\nallowing an aggregate view of the loan market. We present a prototype of our\nimplementation in Tendermint and discuss the design and its benefits.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 20:47:19 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Chiu", "Michael", ""], ["Kalabi\u0107", "Uro\u0161", ""]]}, {"id": "2102.00096", "submitter": "Fabrizio Romano Genovese", "authors": "Fabrizio Genovese, Jelle Herold", "title": "A Categorical Semantics for Hierarchical Petri Nets", "comments": "14 Pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CT cs.DC cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We show how a particular flavor of hierarchical nets, where the firing of a\ntransition in the parent net must correspond to an execution in some child net,\ncan be modelled utilizing a functorial semantics from a free category -\nrepresenting the parent net - to the category of sets and spans between them.\nThis semantics can be internalized via Grothendieck construction, resulting in\nthe category of executions of a Petri net representing the semantics of the\noverall hierarchical net. We conclude the paper by giving an\nengineering-oriented overview of how our model of hiearchic nets can be\nimplemented in a transaction-based smart contract environment.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 22:37:34 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Genovese", "Fabrizio", ""], ["Herold", "Jelle", ""]]}, {"id": "2102.00294", "submitter": "Ian Colbert", "authors": "Ian Colbert, Jake Daly, Ken Kreutz-Delgado, and Srinjoy Das", "title": "A Competitive Edge: Can FPGAs Beat GPUs at DCNN Inference Acceleration\n  in Resource-Limited Edge Computing Applications?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR eess.IV eess.SP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When trained as generative models, Deep Learning algorithms have shown\nexceptional performance on tasks involving high dimensional data such as image\ndenoising and super-resolution. In an increasingly connected world dominated by\nmobile and edge devices, there is surging demand for these algorithms to run\nlocally on embedded platforms. FPGAs, by virtue of their reprogrammability and\nlow-power characteristics, are ideal candidates for these edge computing\napplications. As such, we design a spatio-temporally parallelized hardware\narchitecture capable of accelerating a deconvolution algorithm optimized for\npower-efficient inference on a resource-limited FPGA. We propose this\nFPGA-based accelerator to be used for Deconvolutional Neural Network (DCNN)\ninference in low-power edge computing applications. To this end, we develop\nmethods that systematically exploit micro-architectural innovations, design\nspace exploration, and statistical analysis. Using a Xilinx PYNQ-Z2 FPGA, we\nleverage our architecture to accelerate inference for two DCNNs trained on the\nMNIST and CelebA datasets using the Wasserstein GAN framework. On these\nnetworks, our FPGA design achieves a higher throughput to power ratio with\nlower run-to-run variation when compared to the NVIDIA Jetson TX1 edge\ncomputing GPU.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 19:20:14 GMT"}, {"version": "v2", "created": "Tue, 9 Mar 2021 05:19:30 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Colbert", "Ian", ""], ["Daly", "Jake", ""], ["Kreutz-Delgado", "Ken", ""], ["Das", "Srinjoy", ""]]}, {"id": "2102.00404", "submitter": "Yipeng Zhou", "authors": "Wenzhuo Yang, Yipeng Zhou, Maio Hu, Di Wu, James Xi Zheng, Hui Wang,\n  Song Guo", "title": "Gain without Pain: Offsetting DP-injected Nosies Stealthily in\n  Cross-device Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) is an emerging paradigm through which decentralized\ndevices can collaboratively train a common model. However, a serious concern is\nthe leakage of privacy from exchanged gradient information between clients and\nthe parameter server (PS) in FL. To protect gradient information, clients can\nadopt differential privacy (DP) to add additional noises and distort original\ngradients before they are uploaded to the PS. Nevertheless, the model accuracy\nwill be significantly impaired by DP noises, making DP impracticable in real\nsystems. In this work, we propose a novel Noise Information Secretly Sharing\n(NISS) algorithm to alleviate the disturbance of DP noises by sharing negated\nnoises among clients. We theoretically prove that: 1) If clients are\ntrustworthy, DP noises can be perfectly offset on the PS; 2) Clients can easily\ndistort negated DP noises to protect themselves in case that other clients are\nnot totally trustworthy, though the cost lowers model accuracy. NISS is\nparticularly applicable for FL across multiple IoT (Internet of Things)\nsystems, in which all IoT devices need to collaboratively train a model. To\nverify the effectiveness and the superiority of the NISS algorithm, we conduct\nexperiments with the MNIST and CIFAR-10 datasets. The experiment results verify\nour analysis and demonstrate that NISS can improve model accuracy by 21% on\naverage and obtain better privacy protection if clients are trustworthy.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 07:39:28 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Yang", "Wenzhuo", ""], ["Zhou", "Yipeng", ""], ["Hu", "Maio", ""], ["Wu", "Di", ""], ["Zheng", "James Xi", ""], ["Wang", "Hui", ""], ["Guo", "Song", ""]]}, {"id": "2102.00422", "submitter": "Sven Hofmann", "authors": "Sven Hofmann", "title": "A Trust-Based Approach for Volunteer-Based Distributed Computing in the\n  Context of Biological Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As simulating complex biological processes become more important for modern\nmedicine, new ways to compute this increasingly challenging data are necessary.\nIn this paper, one of the most extensive volunteer-based distributed computing\nsystems, called folding@home, is analyzed, and a trust-based approach is\ndeveloped based upon it. Afterward, all advantages and disadvantages are\npresented. This approach uses trusted communities that are a subset of all\navailable clients where they trust each other. Using such TCs, the system\nbecomes more organic and responds better to malicious or malfunctioning\nclients.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 10:27:02 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hofmann", "Sven", ""]]}, {"id": "2102.00514", "submitter": "Fatemeh Yaghoobi", "authors": "Fatemeh Yaghoobi, Adrien Corenflos, Sakira Hassan, Simo S\\\"arkk\\\"a", "title": "Parallel Iterated Extended and Sigma-point Kalman Smoothers", "comments": "Accepted to be published in IEEE International Conference on\n  Acoustics, Speech and Signal Processing (ICASSP) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC stat.CO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The problem of Bayesian filtering and smoothing in nonlinear models with\nadditive noise is an active area of research. Classical Taylor series as well\nas more recent sigma-point based methods are two well-known strategies to deal\nwith these problems. However, these methods are inherently sequential and do\nnot in their standard formulation allow for parallelization in the time domain.\nIn this paper, we present a set of parallel formulas that replace the existing\nsequential ones in order to achieve lower time (span) complexity. Our\nexperimental results done with a graphics processing unit (GPU) illustrate the\nefficiency of the proposed methods over their sequential counterparts.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2021 19:09:45 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Yaghoobi", "Fatemeh", ""], ["Corenflos", "Adrien", ""], ["Hassan", "Sakira", ""], ["S\u00e4rkk\u00e4", "Simo", ""]]}, {"id": "2102.00655", "submitter": "Syed Zawad", "authors": "Syed Zawad, Ahsan Ali, Pin-Yu Chen, Ali Anwar, Yi Zhou, Nathalie\n  Baracaldo, Yuan Tian, Feng Yan", "title": "Curse or Redemption? How Data Heterogeneity Affects the Robustness of\n  Federated Learning", "comments": "Accepted in AAAI 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data heterogeneity has been identified as one of the key features in\nfederated learning but often overlooked in the lens of robustness to\nadversarial attacks. This paper focuses on characterizing and understanding its\nimpact on backdooring attacks in federated learning through comprehensive\nexperiments using synthetic and the LEAF benchmarks. The initial impression\ndriven by our experimental results suggests that data heterogeneity is the\ndominant factor in the effectiveness of attacks and it may be a redemption for\ndefending against backdooring as it makes the attack less efficient, more\nchallenging to design effective attack strategies, and the attack result also\nbecomes less predictable. However, with further investigations, we found data\nheterogeneity is more of a curse than a redemption as the attack effectiveness\ncan be significantly boosted by simply adjusting the client-side backdooring\ntiming. More importantly,data heterogeneity may result in overfitting at the\nlocal training of benign clients, which can be utilized by attackers to\ndisguise themselves and fool skewed-feature based defenses. In addition,\neffective attack strategies can be made by adjusting attack data distribution.\nFinally, we discuss the potential directions of defending the curses brought by\ndata heterogeneity. The results and lessons learned from our extensive\nexperiments and analysis offer new insights for designing robust federated\nlearning methods and systems\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 06:06:21 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Zawad", "Syed", ""], ["Ali", "Ahsan", ""], ["Chen", "Pin-Yu", ""], ["Anwar", "Ali", ""], ["Zhou", "Yi", ""], ["Baracaldo", "Nathalie", ""], ["Tian", "Yuan", ""], ["Yan", "Feng", ""]]}, {"id": "2102.00872", "submitter": "Qin Wang", "authors": "Qin Wang and Rujia Li", "title": "A Weak Consensus Algorithm and Its Application to High-Performance\n  Blockchain", "comments": "IEEE INFOCOM 2021, May 2021, Online, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A large number of consensus algorithms have been proposed. However, the\nrequirement of strict consistency limits their wide adoption, especially in\nhigh-performance required systems. In this paper, we propose a weak consensus\nalgorithm that only maintains the consistency of relative positions between the\nmessages. We apply this consensus algorithm to construct a high-performance\nblockchain system, called \\textit{Sphinx}. We implement the system with 32k+\nlines of code including all components like consensus/P2P/ledger/etc. The\nevaluations show that Sphinx can reach a peak throughput of 43k TPS (with 8\nfull nodes), which is significantly faster than current blockchain systems such\nas Ethereum given the same experimental environment. To the best of our\nknowledge, we present the first weak consensus algorithm with a fully\nimplemented blockchain system.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 14:29:19 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2021 05:13:53 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Wang", "Qin", ""], ["Li", "Rujia", ""]]}, {"id": "2102.00875", "submitter": "Agrin Aram Hilmkil", "authors": "Agrin Hilmkil and Sebastian Callh and Matteo Barbieri and Leon Ren\\'e\n  S\\\"utfeld and Edvin Listo Zec and Olof Mogren", "title": "Scaling Federated Learning for Fine-tuning of Large Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a promising approach to distributed compute, as\nwell as distributed data, and provides a level of privacy and compliance to\nlegal frameworks. This makes FL attractive for both consumer and healthcare\napplications. While the area is actively being explored, few studies have\nexamined FL in the context of larger language models and there is a lack of\ncomprehensive reviews of robustness across tasks, architectures, numbers of\nclients, and other relevant factors. In this paper, we explore the fine-tuning\nof Transformer-based language models in a federated learning setting. We\nevaluate three popular BERT-variants of different sizes (BERT, ALBERT, and\nDistilBERT) on a number of text classification tasks such as sentiment analysis\nand author identification. We perform an extensive sweep over the number of\nclients, ranging up to 32, to evaluate the impact of distributed compute on\ntask performance in the federated averaging setting. While our findings suggest\nthat the large sizes of the evaluated models are not generally prohibitive to\nfederated training, we found that the different models handle federated\naveraging to a varying degree. Most notably, DistilBERT converges significantly\nslower with larger numbers of clients, and under some circumstances, even\ncollapses to chance level performance. Investigating this issue presents an\ninteresting perspective for future research.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 14:31:39 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Hilmkil", "Agrin", ""], ["Callh", "Sebastian", ""], ["Barbieri", "Matteo", ""], ["S\u00fctfeld", "Leon Ren\u00e9", ""], ["Zec", "Edvin Listo", ""], ["Mogren", "Olof", ""]]}, {"id": "2102.00969", "submitter": "Saeed Alsamhi Dr", "authors": "S. H. Alsamhi, B. Lee, M. Guizani, N. Kumar, Y. Qiao, Xuan Liu", "title": "Blockchain for Decentralized Multi-Drone to Combat COVID-19", "comments": null, "journal-ref": "Transactions on Emerging Telecommunication Technologies,2021", "doi": null, "report-no": null, "categories": "cs.DC cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Currently, drones represent a promising technology for combating Coronavirus\ndisease 2019 (COVID-19) due to the transport of goods, medical supplies to a\ngiven target location in the quarantine areas experiencing an epidemic\noutbreak. Drone missions will increasingly rely on drone collaboration, which\nrequires the drones to reduce communication complexity and be controlled in a\ndecentralized fashion. Blockchain technology becomes a must in industrial\napplications because it provides decentralized data, accessibility,\nimmutability, and irreversibility. Therefore, Blockchain makes data public for\nall drones and enables drones to log information concerning world states, time,\nlocation, resources, delivery data, and drone relation to all neighbors drones.\nThis paper introduces decentralized independent multi-drones to accomplish the\ntask collaboratively. Improving blockchain with a consensus algorithm can\nimprove network partitioning and scalability in order to combat COVID-19. The\nmulti-drones task is to combat COVID-19 via monitoring and detecting, social\ndistancing, sanitization, data analysis, delivering goods and medical supplies,\nand announcement while avoiding collisions with one another. We discuss End to\nEnd (E2E) delivery application of combination blockchain and multi-drone in\ncombating COVID-19 and beyond future pandemics. Furthermore, the challenges and\nopportunities of our proposed framework are highlighted.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 16:54:30 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Alsamhi", "S. H.", ""], ["Lee", "B.", ""], ["Guizani", "M.", ""], ["Kumar", "N.", ""], ["Qiao", "Y.", ""], ["Liu", "Xuan", ""]]}, {"id": "2102.00973", "submitter": "Suryanarayana Sankagiri", "authors": "Suryanarayana Sankagiri, Shreyas Gandlur, Bruce Hajek", "title": "The Longest-Chain Protocol Under Random Delays", "comments": "30 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In the field of distributed consensus and blockchains, the synchronous\ncommunication model assumes that all messages between honest parties are\ndelayed at most by a known constant $\\Delta$. Recent literature establishes\nthat the longest-chain blockchain protocol is secure under the synchronous\nmodel. However, for a fixed mining rate, the security guarantees degrade with\n$\\Delta$. We analyze the performance of the longest-chain protocol under the\nassumption that the communication delays are random, independent, and\nidentically distributed. This communication model allows for distributions with\nunbounded support and is a strict generalization of the synchronous model. We\nprovide safety and liveness guarantees with simple, explicit bounds on the\nfailure probabilities. These bounds hold for infinite-horizon executions and\ndecay exponentially with the security parameter. In particular, we show that\nthe longest-chain protocol has good security guarantees when delays are\nsporadically large and possibly unbounded, which is reflective of real-world\nnetwork conditions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 16:56:08 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Sankagiri", "Suryanarayana", ""], ["Gandlur", "Shreyas", ""], ["Hajek", "Bruce", ""]]}, {"id": "2102.00981", "submitter": "Bola Abimbola", "authors": "Bola Abimbola", "title": "Cloud Computing Concept and Roots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is a particular implementation of distributed computing. It\ninherited many properties of distributed computing such as scalability,\nreliability and distribution transparency. The transparency middle layer\nabstracts the underlying platform away from the end user. Virtualization\ntechnology is the foundation of Cloud computing. Virtual machine provides\nabstraction of the physical server resources and securely isolates different\nusers in multi-tenant environment. To the Cloud services consumer, all the\ncomputing power and resources are accessed through high speed internet access\nby client platforms. This eliminates the cost to build and maintain local data\ncenter. Resource pooling and rapid elasticity are the main characters of Cloud\ncomputing. The scalability of Cloud computing comes from resources which can\nspan multiple data centers and geographic regions. There is virtually no\nlimitation on the amount of resources available from Cloud. New processing and\nstorage resources can be added into the Cloud resource pool seamlessly.\n", "versions": [{"version": "v1", "created": "Thu, 28 Jan 2021 17:42:46 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 19:03:48 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Abimbola", "Bola", ""]]}, {"id": "2102.01009", "submitter": "Michael Kane", "authors": "Craig Poulin, Michael Kane", "title": "Infrastructure Resilience Curves: Performance Measures and Summary\n  Metrics", "comments": "48 pages, 4 figures. Submitted to Reliability Engineering & System\n  Safety", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Resilience curves communicate system behavior and resilience properties to\ncritical infrastructure stakeholders and can quantitatively facilitate\nresilient design. Generally, these curves illustrate the evolution of system\nperformance before, during, and after a disruption. As simple as these curves\nmay appear, the literature contains underexplored nuance when defining\n\"performance\" and distilling curves with summary metrics. This manuscript,\nthrough a review of 274 publications, defines a taxonomy of resilience curve\nperformance measures and discusses associated performance targets and\nnormalization techniques. Furthermore, a taxonomy of summary metrics is defined\nto facilitate comparisons of system behavior and resilience strategies. In\naddition to defining common taxonomies, this review synthesizes recommendations\nfor selecting measures and metrics for common applications and stakeholders\nacross critical infrastructure resilience domains. Key recommendations include\nbroader adoption of productivity measures with variable and adaptive\nperformance targets; deliberate consideration of curve milestones when defining\nsummary metrics; and the need for future research on variable and adaptive\nweighting for ensemble measures and metrics.\n", "versions": [{"version": "v1", "created": "Fri, 29 Jan 2021 14:10:27 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Poulin", "Craig", ""], ["Kane", "Michael", ""]]}, {"id": "2102.01041", "submitter": "Svea Wisy", "authors": "Svea Wisy", "title": "Simple Trust Metric in a Low-Power Sensor Network", "comments": "2020 Conference on Self-Organising Systems at Christian-Albrechts\n  University in Kiel; 5 pages; 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Distributed systems become more and more important to our life. Especially in\nareas like Smart Home and the Internet of Things (IoT) reliable low-power\nsensor networks become increasingly important. For ensuring this there are a\nlot of trust metrics. In this paper we compare a model of a distributed\nlow-power sensor network including one root node and the corresponding Simple\nTrust Metric to the requirements from \"Representation of Trust and Reputation\nin Self-Managed Computing Systems\" [1], the Weighted Trust Metric and the\nWeighted Simple Exponential Smoothing\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 18:24:39 GMT"}], "update_date": "2021-02-02", "authors_parsed": [["Wisy", "Svea", ""]]}, {"id": "2102.01071", "submitter": "Pramod Mane", "authors": "Pramod C. Mane, Nagarajan Krishnamurthy, Kapil Ahuja", "title": "Resource Availability in the Social Cloud: An Economics Perspective", "comments": "11 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC econ.GN q-fin.EC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on social cloud formation, where agents are involved in a\ncloseness-based conditional resource sharing and build their resource sharing\nnetwork themselves. The objectives of this paper are: (1) to investigate the\nimpact of agents' decisions of link addition and deletion on their local and\nglobal resource availability, (2) to analyze spillover effects in terms of the\nimpact of link addition between a pair of agents on others' utility, (3) to\nstudy the role of agents' closeness in determining what type of spillover\neffects these agents experience in the network, and (4) to model the choices of\nagents that suggest with whom they want to add links in the social cloud. The\nfindings include the following. Firstly, agents' decision of link addition\n(deletion) increases (decreases) their local resource availability. However,\nthese observations do not hold in the case of global resource availability.\nSecondly, in a connected network, agents experience either positive or negative\nspillover effect and there is no case with no spillover effects. Agents observe\nno spillover effects if and only if the network is disconnected and consists of\nmore than two components (sub-networks). Furthermore, if there is no change in\nthe closeness of an agent (not involved in link addition) due to a newly added\nlink, then the agent experiences negative spillover effect. Although an\nincrease in the closeness of agents is necessary in order to experience\npositive spillover effects, the condition is not sufficient. By focusing on\nparameters such as closeness and shortest distances, we provide conditions\nunder which agents choose to add links so as to maximise their resource\navailability.\n", "versions": [{"version": "v1", "created": "Sat, 30 Jan 2021 06:00:03 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Mane", "Pramod C.", ""], ["Krishnamurthy", "Nagarajan", ""], ["Ahuja", "Kapil", ""]]}, {"id": "2102.01167", "submitter": "Karl Crary", "authors": "Karl Crary", "title": "Verifying the Hashgraph Consensus Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": "CMU-CS-21-102", "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Hashgraph consensus algorithm is an algorithm for asynchronous Byzantine\nfault tolerance intended for distributed shared ledgers. Its main\ndistinguishing characteristic is it achieves consensus without exchanging any\nextra messages; each participant's votes can be determined from public\ninformation, so votes need not be transmitted.\n  In this paper, we discuss our experience formalizing the Hashgraph algorithm\nand its correctness proof using the Coq proof assistant. The paper is\nself-contained; it includes a complete discussion of the algorithm and its\ncorrectness argument in English.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 21:09:23 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Crary", "Karl", ""]]}, {"id": "2102.01241", "submitter": "Bernard Mans", "authors": "Dalia Popescu, Philippe Jacquet, Bernard Mans and Bartomiej\n  Blaszczyszyn", "title": "Characterizing the Energy Trade-Offs of End-to-End Vehicular\n  Communications using an Hyperfractal Urban Modelling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We characterize trade-offs between the end-to-end communication delay and the\nenergy in urban vehicular communications with infrastructure assistance. Our\nstudy exploits the self-similarity of the location of communication entities in\ncities by modeling them with an innovative model called \"hyperfractal\". We show\nthat the hyperfractal model can be extended to incorporate road-side\ninfrastructure and provide stochastic geometry tools to allow a rigorous\nanalysis. We compute theoretical bounds for the end-to-end communication hop\ncount considering two different energy-minimizing goals: either total\naccumulated energy or maximum energy per node. We prove that the hop count for\nan end-to-end transmission is bounded by $O(n^{1-\\alpha/(d_F-1)})$ where\n$\\alpha<1$ and $d_F>2$ is the fractal dimension of the mobile nodes process.\nThis proves that for both constraints the energy decreases as we allow choosing\nrouting paths of higher length. The asymptotic limit of the energy becomes\nsignificantly small when the number of nodes becomes asymptotically large. A\nlower bound on the network throughput capacity with constraints on path energy\nis also given. We show that our model fits real deployments where open data\nsets are available. The results are confirmed through simulations using\ndifferent fractal dimensions in a Matlab simulator.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 00:53:17 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Popescu", "Dalia", ""], ["Jacquet", "Philippe", ""], ["Mans", "Bernard", ""], ["Blaszczyszyn", "Bartomiej", ""]]}, {"id": "2102.01251", "submitter": "Bogdan Chlebus", "authors": "Bogdan S. Chlebus and Dariusz R. Kowalski and Jan Olkowski and Jedrzej\n  Olkowski", "title": "Consensus in Networks Prone to Link Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider deterministic distributed algorithms solving Consensus in\nsynchronous networks of arbitrary topologies. Links are prone to failures.\nAgreement is understood as holding in each connected component of a network\nobtained by removing faulty links. We introduce the concept of stretch, which\nis a function of the number of connected components of a network and their\nrespective diameters. Fast and early-stopping algorithms solving Consensus are\ndefined by referring to stretch resulting in removing faulty links. We develop\nalgorithms that rely only on nodes knowing their own names and the ability to\nassociate communication with local ports. A network has $n$ nodes and it starts\nwith $m$ functional links. We give a general algorithm operating in time $n$\nthat uses messages of $O(\\log n)$ bits. If we additionally restrict executions\nto be subject to a bound $\\Lambda$ on stretch, then there is a fast algorithm\nsolving Consensus in time $O(\\Lambda)$ using messages of $O(\\log n)$ bits. Let\n$\\lambda$ be an unknown stretch occurring in an execution; we give an algorithm\nworking in time $(\\lambda+2)^3$ and using messages of $O(n\\log n)$ bits. We\nshow that Consensus can be solved in the optimal $O(\\lambda)$ time, but at the\ncost of increasing message size to $O(m\\log n)$. We also demonstrate how to\nsolve Consensus by an algorithm that uses only $O(n)$ non-faulty links and\nworks in time $O(n m)$, while nodes start with their ports mapped to neighbors\nand messages carry $O(m\\log n)$ bits. We prove lower bounds on performance of\nConsensus solutions that refer to parameters of evolving network topologies and\nthe knowledge available to nodes.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 01:30:06 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Chlebus", "Bogdan S.", ""], ["Kowalski", "Dariusz R.", ""], ["Olkowski", "Jan", ""], ["Olkowski", "Jedrzej", ""]]}, {"id": "2102.01254", "submitter": "Xinbiao Gan", "authors": "Xinbiao Gan", "title": "Customizing Graph500 for Tianhe Pre-exacale system", "comments": "12 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  BFS (Breadth-First Search) is a typical graph algorithm used as a key\ncomponent of many graph applications. However, current distributed parallel BFS\nimplementations suffer from irregular data communication with large volumes of\ntransfers across nodes, leading to inefficiency in performance. In this paper,\nwe present a set of optimization techniques to improve the Graph500 performance\nfor Pre-exacale system, including BFS accelerating with SVE (Scalable Vector\nextension) in matrix2000+, sorting with buffering for heavy vertices, and\ngroup-based monitor communication based on proprietary interconnection built in\nTianhe Pre-exacale system. Performance evaluation on the customized Graph500\ntesting on the Tianhe Pre-exacale system achieves 2131.98 Giga TEPS on 512-node\nwith 96608 cores, which surpasses the ranking of Tianhe-2 with about 16X fewer\nnodes in the June 2018 Graph500 list, and shows our customized Graph500 is 3.15\ntimes faster on 512 nodes than the base version using the state-of-the-art\ntechniques.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 01:44:59 GMT"}, {"version": "v2", "created": "Sun, 21 Feb 2021 00:51:52 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Gan", "Xinbiao", ""]]}, {"id": "2102.01333", "submitter": "Minghui Xu", "authors": "Minghui Xu, Chunchi Liu, Yifei Zou, Feng Zhao, Jiguo Yu, Xiuzhen Cheng", "title": "wChain: A Fast Fault-Tolerant Blockchain Protocol for Multihop Wireless\n  Networks", "comments": "11 pages, 3 figures; preprint", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents $\\mathit{wChain}$, a blockchain protocol specifically\ndesigned for multihop wireless networks that deeply integrates wireless\ncommunication properties and blockchain technologies under the realistic SINR\nmodel. We adopt a hierarchical spanner as the communication backbone to address\nmedium contention and achieve fast data aggregation within $O(\\log\nN\\log\\Gamma)$ slots where $N$ is the network size and $\\Gamma$ refers to the\nratio of the maximum distance to the minimum distance between any two nodes.\nBesides, $\\mathit{wChain}$ employs data aggregation and reaggregation, and node\nrecovery mechanisms to ensure efficiency, fault tolerance, persistence, and\nliveness. The worst-case runtime of $\\mathit{wChain}$ is upper bounded by\n$O(f\\log N\\log\\Gamma)$, where $f=\\lfloor \\frac{N}{2} \\rfloor$ is the upper\nbound of the number of faulty nodes. To validate our design, we conduct both\ntheoretical analysis and simulation studies, and the results only demonstrate\nthe nice properties of $\\mathit{wChain}$, but also point to a vast new space\nfor the exploration of blockchain protocols in wireless networks.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:20:02 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Xu", "Minghui", ""], ["Liu", "Chunchi", ""], ["Zou", "Yifei", ""], ["Zhao", "Feng", ""], ["Yu", "Jiguo", ""], ["Cheng", "Xiuzhen", ""]]}, {"id": "2102.01348", "submitter": "Dainius Jenkus", "authors": "Dainius Jenkus, Fei Xia, Rishad Shafik, Alex Yakovlev", "title": "QoS-Aware Power Minimization of Distributed Many-Core Servers using\n  Transfer Q-Learning", "comments": "Presented at DATE Friday Workshop on System-level Design Methods for\n  Deep Learning on Heterogeneous Architectures (SLOHA 2021) (arXiv:2102.00818)", "journal-ref": null, "doi": null, "report-no": "SLOHA/2021/07", "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web servers scaled across distributed systems necessitate complex runtime\ncontrols for providing quality of service (QoS) guarantees as well as\nminimizing the energy costs under dynamic workloads. This paper presents a\nQoS-aware runtime controller using horizontal scaling (node allocation) and\nvertical scaling (resource allocation within nodes) methods synergistically to\nprovide adaptation to workloads while minimizing the power consumption under\nQoS constraint (i.e., response time). A horizontal scaling determines the\nnumber of active nodes based on workload demands and the required QoS according\nto a set of rules. Then, it is coupled with vertical scaling using transfer\nQ-learning, which further tunes power/performance based on workload profile\nusing dynamic voltage/frequency scaling (DVFS). It transfers Q-values within\nminimally explored states reducing exploration requirements. In addition, the\napproach exploits a scalable architecture of the many-core server allowing to\nreuse available knowledge from fully or partially explored nodes. When\ncombined, these methods allow to reduce the exploration time and QoS violations\nwhen compared to model-free Q-learning. The technique balances design-time and\nruntime costs to maximize the portability and operational optimality\ndemonstrated through persistent power reductions with minimal QoS violations\nunder different workload scenarios on heterogeneous multi-processing nodes of a\nserver cluster.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 06:47:58 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Jenkus", "Dainius", ""], ["Xia", "Fei", ""], ["Shafik", "Rishad", ""], ["Yakovlev", "Alex", ""]]}, {"id": "2102.01413", "submitter": "Yusuf Samil Ezer", "authors": "Yusuf Samil Ezer", "title": "Two Social Concepts in Virtual Communities: Trust and Reputation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Our social interactions mainly depend on the social phenomenon called trust.\nWe evaluate our trust in our peer to decide whether to start an interaction or\nnot. When our information about the peer is not sufficient, we use the\nknowledge of others. This knowledge can also be referred to as the reputation\nof the peer in the community. Like real-life communities, trust and reputation\nplay a key role in virtual communities, too. These two notions help us overcome\nthe complex interactions between agents in virtual communities. In previous\nstudies regarding this topic, the social aspect of trust and reputation is\npartly ignored. In this paper, we will review an article which we accept as a\nstarting point and compare it with another article that provides a more\nadvanced model. Additionally, a new trust model which is mainly based on\nsociological notions will also be introduced.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 10:10:05 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Ezer", "Yusuf Samil", ""]]}, {"id": "2102.01443", "submitter": "Yi Lihui", "authors": "Shu-Jie Cao, Lihui Yi, Haoning Chen and Youlong Wu", "title": "Optimal Coding Scheme and Resource Allocation for Distributed\n  Computation with Limited Resources", "comments": "Submitted to ISIT 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A central issue of distributed computing systems is how to optimally allocate\ncomputing and storage resources and design data shuffling strategies such that\nthe total execution time for computing and data shuffling is minimized. This is\nextremely critical when the computation, storage and communication resources\nare limited. In this paper, we study the resource allocation and coding scheme\nfor the MapReduce-type framework with limited resources. In particular, we\nfocus on the coded distributed computing (CDC) approach proposed by Li et al..\nWe first extend the asymmetric CDC (ACDC) scheme proposed by Yu et al. to the\ncascade case where each output function is computed by multiple servers. Then\nwe demonstrate that whether CDC or ACDC is better depends on system parameters\n(e.g., number of computing servers) and task parameters (e.g., number of input\nfiles), implying that neither CDC nor ACDC is optimal. By merging the ideas of\nCDC and ACDC, we propose a hybrid scheme and show that it can strictly\noutperform CDC and ACDC. Furthermore, we derive an information-theoretic\nconverse showing that for the MapReduce task using a type of weakly symmetric\nReduce assignment, which includes the Reduce assignments of CDC and ACDC as\nspecial cases, the hybrid scheme with a corresponding resource allocation\nstrategy is optimal, i.e., achieves the minimum execution time, for an\narbitrary amount of computing servers and storage memories.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 11:36:19 GMT"}], "update_date": "2021-02-03", "authors_parsed": [["Cao", "Shu-Jie", ""], ["Yi", "Lihui", ""], ["Chen", "Haoning", ""], ["Wu", "Youlong", ""]]}, {"id": "2102.01733", "submitter": "Wentai Wu", "authors": "Wentai Wu, Ligang He, Weiwei Lin, Rui Mao", "title": "FedProf: Efficient Federated Learning with Data Representation Profiling", "comments": "12 pages (references and appendices included), 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated Learning (FL) has shown great potential as a privacy-preserving\nsolution to learning from decentralized data which are only accessible locally\non end devices (i.e., clients). In many scenarios, however, a large proportion\nof the clients are probably in possession of low-quality data that are biased,\nnoisy or even irrelevant. As a result, they could significantly slow down the\nconvergence of the global model we aim to build and also compromise its\nquality. In light of this, we propose FedProf, a novel protocol for optimizing\nFL under such circumstances without breaching data privacy. The key of our\napproach is using the global model to dynamically profile the latent\nrepresentations of data (termed representation footprints) on the clients. By\nmatching local footprints on clients against a baseline footprint on the\nserver, we adaptively score each client and adjust its probability of being\nselected each round so as to mitigate the impact of the clients with\nlow-quality data on the training process. We have conducted extensive\nexperiments on public data sets using various FL settings. The results show\nthat FedProf effectively reduces the number of communication rounds and overall\ntime (providing up to 4.5x speedup) for the global model to converge while\nimproving the accuracy of the final global model.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2021 20:10:14 GMT"}, {"version": "v2", "created": "Fri, 14 May 2021 10:50:02 GMT"}, {"version": "v3", "created": "Wed, 19 May 2021 08:50:29 GMT"}, {"version": "v4", "created": "Thu, 20 May 2021 19:40:21 GMT"}, {"version": "v5", "created": "Tue, 25 May 2021 09:52:49 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Wu", "Wentai", ""], ["He", "Ligang", ""], ["Lin", "Weiwei", ""], ["Mao", "Rui", ""]]}, {"id": "2102.01854", "submitter": "Xiaoyu Cao", "authors": "Xiaoyu Cao, Jinyuan Jia, Neil Zhenqiang Gong", "title": "Provably Secure Federated Learning against Malicious Clients", "comments": "Accepted by AAAI-21", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning enables clients to collaboratively learn a shared global\nmodel without sharing their local training data with a cloud server. However,\nmalicious clients can corrupt the global model to predict incorrect labels for\ntesting examples. Existing defenses against malicious clients leverage\nByzantine-robust federated learning methods. However, these methods cannot\nprovably guarantee that the predicted label for a testing example is not\naffected by malicious clients. We bridge this gap via ensemble federated\nlearning. In particular, given any base federated learning algorithm, we use\nthe algorithm to learn multiple global models, each of which is learnt using a\nrandomly selected subset of clients. When predicting the label of a testing\nexample, we take majority vote among the global models. We show that our\nensemble federated learning with any base federated learning algorithm is\nprovably secure against malicious clients. Specifically, the label predicted by\nour ensemble global model for a testing example is provably not affected by a\nbounded number of malicious clients. Moreover, we show that our derived bound\nis tight. We evaluate our method on MNIST and Human Activity Recognition\ndatasets. For instance, our method can achieve a certified accuracy of 88% on\nMNIST when 20 out of 1,000 clients are malicious.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 03:24:17 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 03:43:50 GMT"}, {"version": "v3", "created": "Tue, 16 Feb 2021 16:14:35 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Cao", "Xiaoyu", ""], ["Jia", "Jinyuan", ""], ["Gong", "Neil Zhenqiang", ""]]}, {"id": "2102.01887", "submitter": "Francisco Romero", "authors": "Francisco Romero, Mark Zhao, Neeraja J. Yadwadkar, Christos Kozyrakis", "title": "Llama: A Heterogeneous & Serverless Framework for Auto-Tuning Video\n  Analytics Pipelines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The proliferation of camera-enabled devices and large video repositories has\nled to a diverse set of video analytics applications. These applications rely\non video pipelines, represented as DAGs of operations, to transform videos,\nprocess extracted metadata, and answer questions like, \"Is this intersection\ncongested?\" The latency and resource efficiency of pipelines can be optimized\nusing configurable knobs for each operation (e.g., sampling rate, batch size,\nor type of hardware used). However, determining efficient configurations is\nchallenging because (a) the configuration search space is exponentially large,\nand (b) the optimal configuration depends on users' desired latency and cost\ntargets, (c) input video contents may exercise different paths in the DAG and\nproduce a variable amount intermediate results. Existing video analytics and\nprocessing systems leave it to the users to manually configure operations and\nselect hardware resources.\n  We present Llama: a heterogeneous and serverless framework for auto-tuning\nvideo pipelines. Given an end-to-end latency target, Llama optimizes for cost\nefficiency by (a) calculating a latency target for each operation invocation,\nand (b) dynamically running a cost-based optimizer to assign configurations\nacross heterogeneous hardware that best meet the calculated per-invocation\nlatency target. This makes the problem of auto-tuning large video pipelines\ntractable and allows us to handle input-dependent behavior, conditional\nbranches in the DAG, and execution variability. We describe the algorithms in\nLlama and evaluate it on a cloud platform using serverless CPU and GPU\nresources. We show that compared to state-of-the-art cluster and serverless\nvideo analytics and processing systems, Llama achieves 7.8x lower latency and\n16x cost reduction on average.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 06:03:18 GMT"}, {"version": "v2", "created": "Fri, 28 May 2021 17:59:03 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Romero", "Francisco", ""], ["Zhao", "Mark", ""], ["Yadwadkar", "Neeraja J.", ""], ["Kozyrakis", "Christos", ""]]}, {"id": "2102.01936", "submitter": "Liangxi Liu", "authors": "Liangxi Liu, Feng Zheng, Hong Chen, Guo-Jun Qi, Heng Huang and Ling\n  Shao", "title": "A Bayesian Federated Learning Framework with Online Laplace\n  Approximation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Federated learning (FL) allows multiple clients to collaboratively learn a\nglobally shared model through cycles of model aggregation and local model\ntraining, without the need to share data. Most existing FL methods train local\nmodels separately on different clients, and then simply average their\nparameters to obtain a centralized model on the server side. However, these\napproaches generally suffer from large aggregation errors and severe local\nforgetting, which are particularly bad in heterogeneous data settings. To\ntackle these issues, in this paper, we propose a novel FL framework that uses\nonline Laplace approximation to approximate posteriors on both the client and\nserver side. On the server side, a multivariate Gaussian product mechanism is\nemployed to construct and maximize a global posterior, largely reducing the\naggregation errors induced by large discrepancies between local models. On the\nclient side, a prior loss that uses the global posterior probabilistic\nparameters delivered from the server is designed to guide the local training.\nBinding such learning constraints from other clients enables our method to\nmitigate local forgetting. Finally, we achieve state-of-the-art results on\nseveral benchmarks, clearly demonstrating the advantages of the proposed\nmethod.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 08:36:58 GMT"}, {"version": "v2", "created": "Tue, 20 Jul 2021 16:44:04 GMT"}], "update_date": "2021-07-21", "authors_parsed": [["Liu", "Liangxi", ""], ["Zheng", "Feng", ""], ["Chen", "Hong", ""], ["Qi", "Guo-Jun", ""], ["Huang", "Heng", ""], ["Shao", "Ling", ""]]}, {"id": "2102.01970", "submitter": "Jiashuo Zhang", "authors": "Jiashuo Zhang, Jianbo Gao, Ke Wang, Zhenhao Wu, Ying Lan, Zhi Guan,\n  Zhong Chen", "title": "Efficient Byzantine Fault Tolerance using Trusted Execution Environment:\n  Preventing Equivocation is only the Beginning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid development of blockchain, Byzantine fault-tolerant protocols\nhave attracted revived interest recently. To overcome the theoretical bounds of\nByzantine fault tolerance, many protocols attempt to use Trusted Execution\nEnvironment (TEE) to prevent equivocation and improve performance and\nscalability. However, due to the broken quorum intersection assumption caused\nby the reduction of the replica number, the improvement is mostly at the cost\nof increased communication complexity which prevents existing TEE-based\nprotocols to be applied to large-scale blockchain systems. In this paper, we\npropose TBFT, an efficient Byzantine fault-tolerant protocol in the partial\nsynchrony setting, which has O(n) message complexity in both normal-case and\nview-change. Compared to previous protocols, TBFT uses TEE-assisted primitives\nto limit more types of malicious behaviors of replicas rather than preventing\nequivocation only, thereby reducing the latency and communication complexity of\nclients and replicas. Besides, we also introduce lightweight cryptographic\nprimitives including a novel leader election mechanism and an efficient voting\nmessage aggregation mechanism for better security and performance. We evaluate\nTBFT via systematic analysis and experiments, and the results show that TBFT\nhas better performance and scalability compared to other protocols.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 09:41:56 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 08:42:37 GMT"}, {"version": "v3", "created": "Tue, 6 Jul 2021 08:41:10 GMT"}], "update_date": "2021-07-07", "authors_parsed": [["Zhang", "Jiashuo", ""], ["Gao", "Jianbo", ""], ["Wang", "Ke", ""], ["Wu", "Zhenhao", ""], ["Lan", "Ying", ""], ["Guan", "Zhi", ""], ["Chen", "Zhong", ""]]}, {"id": "2102.02079", "submitter": "Qinbin Li", "authors": "Qinbin Li, Yiqun Diao, Quan Chen, Bingsheng He", "title": "Federated Learning on Non-IID Data Silos: An Experimental Study", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to the increasing privacy concerns and data regulations, training data\nhave been increasingly fragmented, forming distributed databases of multiple\n``data silos'' (e.g., within different organizations and countries). To develop\neffective machine learning services, there is a must to exploit data from such\ndistributed databases without exchanging the raw data. Recently, federated\nlearning (FL) has been a solution with growing interests, which enables\nmultiple parties to collaboratively train a machine learning model without\nexchanging their local data. A key and common challenge on distributed\ndatabases is the heterogeneity of the data distribution (i.e., non-IID) among\nthe parties. There have been many FL algorithms to address the learning\neffectiveness under non-IID data settings. However, there lacks an experimental\nstudy on systematically understanding their advantages and disadvantages, as\nprevious studies have very rigid data partitioning strategies among parties,\nwhich are hardly representative and thorough. In this paper, to help\nresearchers better understand and study the non-IID data setting in federated\nlearning, we propose comprehensive data partitioning strategies to cover the\ntypical non-IID data cases. Moreover, we conduct extensive experiments to\nevaluate state-of-the-art FL algorithms. We find that non-IID does bring\nsignificant challenges in learning accuracy of FL algorithms, and none of the\nexisting state-of-the-art FL algorithms outperforms others in all cases. Our\nexperiments provide insights for future studies of addressing the challenges in\n``data silos''.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 14:29:09 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2021 06:45:28 GMT"}, {"version": "v3", "created": "Thu, 22 Jul 2021 14:01:16 GMT"}], "update_date": "2021-07-23", "authors_parsed": [["Li", "Qinbin", ""], ["Diao", "Yiqun", ""], ["Chen", "Quan", ""], ["He", "Bingsheng", ""]]}, {"id": "2102.02109", "submitter": "Nick Brown", "authors": "Maurice Jamieson, Nick Brown", "title": "Compact Native Code Generation for Dynamic Languages on Micro-core\n  Architectures", "comments": "Preprint of paper accepted to ACM SIGPLAN 2021 International\n  Conference on Compiler Construction (CC 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Micro-core architectures combine many simple, low memory, low power-consuming\nCPU cores onto a single chip. Potentially providing significant performance and\nlow power consumption, this technology is not only of great interest in\nembedded, edge, and IoT uses, but also potentially as accelerators for\ndata-center workloads. Due to the restricted nature of such CPUs, these\narchitectures have traditionally been challenging to program, not least due to\nthe very constrained amounts of memory (often around 32KB) and idiosyncrasies\nof the technology. However, more recently, dynamic languages such as Python\nhave been ported to a number of micro-cores, but these are often delivered as\ninterpreters which have an associated performance limitation.\n  Targeting the four objectives of performance, unlimited code-size,\nportability between architectures, and maintaining the programmer productivity\nbenefits of dynamic languages, the limited memory available means that classic\ntechniques employed by dynamic language compilers, such as just-in-time (JIT),\nare simply not feasible. In this paper we describe the construction of a\ncompilation approach for dynamic languages on micro-core architectures which\naims to meet these four objectives, and use Python as a vehicle for exploring\nthe application of this in replacing the existing micro-core interpreter. Our\nexperiments focus on the metrics of performance, architecture portability,\nminimum memory size, and programmer productivity, comparing our approach\nagainst that of writing native C code. The outcome of this work is the\nidentification of a series of techniques that are not only suitable for\ncompiling Python code, but also applicable to a wide variety of dynamic\nlanguages on micro-cores.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 15:36:31 GMT"}], "update_date": "2021-02-04", "authors_parsed": [["Jamieson", "Maurice", ""], ["Brown", "Nick", ""]]}, {"id": "2102.02286", "submitter": "Fahad Saeed", "authors": "Muhammad Haseeb and Fahad Saeed", "title": "HiCOPS: High Performance Computing Framework for Tera-Scale Database\n  Search of Mass Spectrometry based Omics Data", "comments": "Under peer review. 37 pages, 9 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC q-bio.MN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Database-search algorithms, that deduce peptides from Mass Spectrometry (MS)\ndata, have tried to improve the computational efficiency to accomplish larger,\nand more complex systems biology studies. Existing serial, and high-performance\ncomputing (HPC) search engines, otherwise highly successful, are known to\nexhibit poor-scalability with increasing size of theoretical search-space\nneeded for increased complexity of modern non-model, multi-species MS-based\nomics analysis. Consequently, the bottleneck for computational techniques is\nthe communication costs of moving the data between hierarchy of memory, or\nprocessing units, and not the arithmetic operations. This post-Moore change in\narchitecture, and demands of modern systems biology experiments have dampened\nthe overall effectiveness of the existing HPC workflows. We present a novel\nefficient parallel computational method, and its implementation on\nmemory-distributed architectures for peptide identification tool called HiCOPS,\nthat enables more than 100-fold improvement in speed over most existing HPC\nproteome database search tools. HiCOPS empowers the supercomputing database\nsearch concept for comprehensive identification of peptides, and all their\nmodified forms within a reasonable time-frame. We demonstrate this by searching\nGigabytes of experimental MS data against Terabytes of databases where HiCOPS\ncompletes peptide identification in few minutes using 72 parallel nodes (1728\ncores) compared to several weeks required by existing state-of-the-art tools\nusing 1 node (24 cores); 100 minutes vs 5 weeks; 500x speedup. Finally, we\nformulate a theoretical framework for our overhead-avoiding strategy, and\nreport superior performance evaluation results for key metrics including\nexecution time, CPU utilization, speedups, and I/O efficiency. The software\nwill be made available at: hicops.github.io\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 20:48:09 GMT"}, {"version": "v2", "created": "Fri, 5 Feb 2021 16:54:25 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Haseeb", "Muhammad", ""], ["Saeed", "Fahad", ""]]}, {"id": "2102.02330", "submitter": "Anshul Jindal", "authors": "Anshul Jindal, Michael Gerndt, Mohak Chadha, Vladimir Podolskiy and\n  Pengfei Chen", "title": "Function Delivery Network: Extending Serverless Computing for\n  Heterogeneous Platforms", "comments": "Accepted at Journal of Software: Practice and Experience", "journal-ref": null, "doi": "10.1002/spe.2966", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Serverless computing has rapidly grown following the launch of Amazon's\nLambda platform. Function-as-a-Service (FaaS) a key enabler of serverless\ncomputing allows an application to be decomposed into simple, standalone\nfunctions that are executed on a FaaS platform. The FaaS platform is\nresponsible for deploying and facilitating resources to the functions. Several\nof today's cloud applications spread over heterogeneous connected computing\nresources and are highly dynamic in their structure and resource requirements.\nHowever, FaaS platforms are limited to homogeneous clusters and homogeneous\nfunctions and do not account for the data access behavior of functions before\nscheduling.\n  We introduce an extension of FaaS to heterogeneous clusters and to support\nheterogeneous functions through a network of distributed heterogeneous target\nplatforms called Function Delivery Network (FDN). A target platform is a\ncombination of a cluster of homogeneous nodes and a FaaS platform on top of it.\nFDN provides Function-Delivery-as-a-Service (FDaaS), delivering the function to\nthe right target platform. We showcase the opportunities such as varied target\nplatform's characteristics, possibility of collaborative execution between\nmultiple target platforms, and localization of data that the FDN offers in\nfulfilling two objectives: Service Level Objective (SLO) requirements and\nenergy efficiency when scheduling functions by evaluating over five distributed\ntarget platforms using the FDNInspector, a tool developed by us for\nbenchmarking distributed target platforms. Scheduling functions on an edge\ntarget platform in our evaluation reduced the overall energy consumption by 17x\nwithout violating the SLO requirements in comparison to scheduling on a\nhigh-end target platform.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2021 23:24:48 GMT"}], "update_date": "2021-03-11", "authors_parsed": [["Jindal", "Anshul", ""], ["Gerndt", "Michael", ""], ["Chadha", "Mohak", ""], ["Podolskiy", "Vladimir", ""], ["Chen", "Pengfei", ""]]}, {"id": "2102.02402", "submitter": "Zhuosheng Zhang", "authors": "Zhuosheng Zhang, Jiarui Li, Shucheng Yu, Christian Makaya", "title": "SAFELearning: Enable Backdoor Detectability In Federated Learning With\n  Secure Aggregation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For model privacy, local model parameters in federated learning shall be\nobfuscated before sent to the remote aggregator. This technique is referred to\nas \\emph{secure aggregation}. However, secure aggregation makes model poisoning\nattacks, e.g., to insert backdoors, more convenient given existing anomaly\ndetection methods mostly require access to plaintext local models. This paper\nproposes SAFELearning which supports backdoor detection for secure aggregation.\nWe achieve this through two new primitives - \\emph{oblivious random grouping\n(ORG)} and \\emph{partial parameter disclosure (PPD)}. ORG partitions\nparticipants into one-time random subgroups with group configurations oblivious\nto participants; PPD allows secure partial disclosure of aggregated subgroup\nmodels for anomaly detection without leaking individual model privacy.\nSAFELearning is able to significantly reduce backdoor model accuracy without\njeopardizing the main task accuracy under common backdoor strategies. Extensive\nexperiments show SAFELearning reduces backdoor accuracy from $100\\%$ to $8.2\\%$\nfor ResNet-18 over CIFAR-10 when $10\\%$ participants are malicious.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 04:07:39 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Zhang", "Zhuosheng", ""], ["Li", "Jiarui", ""], ["Yu", "Shucheng", ""], ["Makaya", "Christian", ""]]}, {"id": "2102.02514", "submitter": "Felix Sattler", "authors": "Felix Sattler and Tim Korjakow and Roman Rischke and Wojciech Samek", "title": "FedAUX: Leveraging Unlabeled Auxiliary Data in Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated Distillation (FD) is a popular novel algorithmic paradigm for\nFederated Learning, which achieves training performance competitive to prior\nparameter averaging based methods, while additionally allowing the clients to\ntrain different model architectures, by distilling the client predictions on an\nunlabeled auxiliary set of data into a student model. In this work we propose\nFedAUX, an extension to FD, which, under the same set of assumptions,\ndrastically improves performance by deriving maximum utility from the unlabeled\nauxiliary data. FedAUX modifies the FD training procedure in two ways: First,\nunsupervised pre-training on the auxiliary data is performed to find a model\ninitialization for the distributed training. Second, $(\\varepsilon,\n\\delta)$-differentially private certainty scoring is used to weight the\nensemble predictions on the auxiliary data according to the certainty of each\nclient model. Experiments on large-scale convolutional neural networks and\ntransformer models demonstrate, that the training performance of FedAUX exceeds\nSOTA FL baseline methods by a substantial margin in both the iid and non-iid\nregime, further closing the gap to centralized training performance. Code is\navailable at github.com/fedl-repo/fedaux.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 09:53:53 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Sattler", "Felix", ""], ["Korjakow", "Tim", ""], ["Rischke", "Roman", ""], ["Samek", "Wojciech", ""]]}, {"id": "2102.02582", "submitter": "Manuel Arenaz", "authors": "Manuel Arenaz, Xavier Martorell", "title": "Parallelware Tools: An Experimental Evaluation on POWER Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Static code analysis tools are designed to aid software developers to build\nbetter quality software in less time, by detecting defects early in the\nsoftware development life cycle. Even the most experienced developer regularly\nintroduces coding defects. Identifying, mitigating and resolving defects is an\nessential part of the software development process, but frequently defects can\ngo undetected. One defect can lead to a minor malfunction or cause serious\nsecurity and safety issues. This is magnified in the development of the complex\nparallel software required to exploit modern heterogeneous multicore hardware.\nThus, there is an urgent need for new static code analysis tools to help in\nbuilding better concurrent and parallel software. The paper reports preliminary\nresults about the use of Appentra's Parallelware technology to address this\nproblem from the following three perspectives: finding concurrency issues in\nthe code, discovering new opportunities for parallelization in the code, and\ngenerating parallel-equivalent codes that enable tasks to run faster. The paper\nalso presents experimental results using well-known scientific codes and POWER\nsystems.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 12:56:02 GMT"}], "update_date": "2021-02-05", "authors_parsed": [["Arenaz", "Manuel", ""], ["Martorell", "Xavier", ""]]}, {"id": "2102.02867", "submitter": "Nastaran Abadi Khooshemehr", "authors": "Nastaran Abadi Khooshemehr, Mohammad Ali Maddah-Ali", "title": "The Discrepancy Attack on Polyshard-ed Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Sharding, i.e. splitting the miners or validators to form and run several\nsubchains in parallel, is known as one of the main solutions to the scalability\nproblem of blockchains. The drawback is that as the number of miners expanding\neach subchain becomes small, it becomes vulnerable to security attacks. To\nsolve this problem, a framework, named as \\textit{Polyshard}, has been proposed\nin which each validator verifies a coded combination of the blocks introduced\nby different subchains, thus helping to protect the security of all subchains.\nIn this paper, we introduce an attack on Polyshard, called \\textit{the\ndiscrepancy} attack, which is the result of malicious nodes controlling a few\nsubchains and dispersing different blocks to different nodes. We show that this\nattack undermines the security of Polyshard and is undetectable in its current\nsetting.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 20:01:54 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2021 15:57:01 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Khooshemehr", "Nastaran Abadi", ""], ["Maddah-Ali", "Mohammad Ali", ""]]}, {"id": "2102.02888", "submitter": "Hanlin Tang", "authors": "Hanlin Tang, Shaoduo Gan, Ammar Ahmad Awan, Samyam Rajbhandari,\n  Conglong Li, Xiangru Lian, Ji Liu, Ce Zhang, Yuxiong He", "title": "1-bit Adam: Communication Efficient Large-Scale Training with Adam's\n  Convergence Speed", "comments": "arXiv admin note: text overlap with arXiv:2008.11343", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Scalable training of large models (like BERT and GPT-3) requires careful\noptimization rooted in model design, architecture, and system capabilities.\nFrom a system standpoint, communication has become a major bottleneck,\nespecially on commodity systems with standard TCP interconnects that offer\nlimited network bandwidth. Communication compression is an important technique\nto reduce training time on such systems. One of the most effective methods is\nerror-compensated compression, which offers robust convergence speed even under\n1-bit compression. However, state-of-the-art error compensation techniques only\nwork with basic optimizers like SGD and momentum SGD, which are linearly\ndependent on the gradients. They do not work with non-linear gradient-based\noptimizers like Adam, which offer state-of-the-art convergence efficiency and\naccuracy for models like BERT. In this paper, we propose 1-bit Adam that\nreduces the communication volume by up to $5\\times$, offers much better\nscalability, and provides the same convergence speed as uncompressed Adam. Our\nkey finding is that Adam's variance (non-linear term) becomes stable (after a\nwarmup phase) and can be used as a fixed precondition for the rest of the\ntraining (compression phase). Experiments on up to 256 GPUs show that 1-bit\nAdam enables up to $3.3\\times$ higher throughput for BERT-Large pre-training\nand up to $2.9\\times$ higher throughput for SQuAD fine-tuning. In addition, we\nprovide theoretical analysis for our proposed work.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 21:02:19 GMT"}, {"version": "v2", "created": "Tue, 29 Jun 2021 18:25:26 GMT"}], "update_date": "2021-07-01", "authors_parsed": [["Tang", "Hanlin", ""], ["Gan", "Shaoduo", ""], ["Awan", "Ammar Ahmad", ""], ["Rajbhandari", "Samyam", ""], ["Li", "Conglong", ""], ["Lian", "Xiangru", ""], ["Liu", "Ji", ""], ["Zhang", "Ce", ""], ["He", "Yuxiong", ""]]}, {"id": "2102.02957", "submitter": "Jun Doi", "authors": "Jun Doi, Hiroshi Horii", "title": "Cache Blocking Technique to Large Scale Quantum Computing Simulation on\n  Supercomputers", "comments": null, "journal-ref": "2020 IEEE International Conference on Quantum Computing and\n  Engineering (QCE), Denver, CO, USA, 2020, pp. 212-222", "doi": "10.1109/QCE49297.2020.00035", "report-no": null, "categories": "quant-ph cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Classical computers require large memory resources and computational power to\nsimulate quantum circuits with a large number of qubits. Even supercomputers\nthat can store huge amounts of data face a scalability issue in regard to\nparallel quantum computing simulations because of the latency of data movements\nbetween distributed memory spaces. Here, we apply a cache blocking technique by\ninserting swap gates in quantum circuits to decrease data movements. We\nimplemented this technique in the open source simulation framework Qiskit Aer.\nWe evaluated our simulator on GPU clusters and observed good scalability.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 02:03:44 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Doi", "Jun", ""], ["Horii", "Hiroshi", ""]]}, {"id": "2102.03012", "submitter": "Huaizheng Zhang", "authors": "Huaizheng Zhang, Meng Shen, Yizheng Huang, Yonggang Wen, Yong Luo,\n  Guanyu Gao, Kyle Guan", "title": "A Serverless Cloud-Fog Platform for DNN-Based Video Analytics with\n  Incremental Learning", "comments": "11 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DNN-based video analytics have empowered many new applications (e.g.,\nautomated retail). Meanwhile, the proliferation of fog devices provides\ndevelopers with more design options to improve performance and save cost. To\nthe best of our knowledge, this paper presents the first serverless system that\ntakes full advantage of the client-fog-cloud synergy to better serve the\nDNN-based video analytics. Specifically, the system aims to achieve two goals:\n1) Provide the optimal analytics results under the constraints of lower\nbandwidth usage and shorter round-trip time (RTT) by judiciously managing the\ncomputational and bandwidth resources deployed in the client, fog, and cloud\nenvironment. 2) Free developers from tedious administration and operation\ntasks, including DNN deployment, cloud and fog's resource management. To this\nend, we implement a holistic cloud-fog system referred to as VPaaS\n(Video-Platform-as-a-Service). VPaaS adopts serverless computing to enable\ndevelopers to build a video analytics pipeline by simply programming a set of\nfunctions (e.g., model inference), which are then orchestrated to process\nvideos through carefully designed modules. To save bandwidth and reduce RTT,\nVPaaS provides a new video streaming protocol that only sends low-quality video\nto the cloud. The state-of-the-art (SOTA) DNNs deployed at the cloud can\nidentify regions of video frames that need further processing at the fog ends.\nAt the fog ends, misidentified labels in these regions can be corrected using a\nlight-weight DNN model. To address the data drift issues, we incorporate\nlimited human feedback into the system to verify the results and adopt\nincremental learning to improve our system continuously. The evaluation\ndemonstrates that VPaaS is superior to several SOTA systems: it maintains high\naccuracy while reducing bandwidth usage by up to 21%, RTT by up to 62.5%, and\ncloud monetary cost by up to 50%.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 05:59:36 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Zhang", "Huaizheng", ""], ["Shen", "Meng", ""], ["Huang", "Yizheng", ""], ["Wen", "Yonggang", ""], ["Luo", "Yong", ""], ["Gao", "Guanyu", ""], ["Guan", "Kyle", ""]]}, {"id": "2102.03040", "submitter": "Bernard Mans", "authors": "Dalia Popescu, Philippe Jacquet and Bernard Mans", "title": "Connecting flying backhauls of UAVs to enhance vehicular networks with\n  fixed 5G NR infrastructure", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.NI math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper investigates moving networks of Unmanned Aerial Vehicles (UAVs),\nsuch as drones, as one of the innovative opportunities brought by the 5G. With\na main purpose to extend connectivity and guarantee data rates, the drones\nrequire hovering locations due to limitations such as flight time and coverage\nsurface. We provide analytic bounds on the requirements in terms of\nconnectivity extension for vehicular networks served by fixed Enhanced Mobile\nBroadBand (eMBB) infrastructure, where both vehicular networks and\ninfrastructures are modeled using stochastic and fractal geometry as a model\nfor urban environment. We prove that assuming $n$ mobile nodes (distributed\naccording to a hyperfractal distribution of dimension $d_F$) and an average of\n$\\rho$ Next Generation NodeB (gNBs), distributed like an hyperfractal of\ndimension $d_r$ if $\\rho=n^\\theta$ with $\\theta>d_r/4$ and letting $n$ tending\nto infinity (to reflect megalopolis cities), then the average fraction of\nmobile nodes not covered by a gNB tends to zero like\n$O\\left(n^{-\\frac{(d_F-2)}{d_r}(2\\theta-\\frac{d_r}{2})}\\right)$. Interestingly,\nwe then prove that the average number of drones, needed to connect each mobile\nnode not covered by gNBs is comparable to the number of isolated mobile nodes.\nWe complete the characterisation by proving that when $\\theta<d_r/4$ the\nproportion of covered mobile nodes tends to zero. We provide insights on the\nintelligent placement of the \"garage of drones\", the home location of these\nnomadic infrastructure nodes, such as to minimize what we call the\n\"flight-to-coverage time\". We provide a fast procedure to select the relays\nthat will be garages (and store drones) in order to minimize the number of\ngarages and minimize the delay. Finally we confirm our analytical results using\nsimulations carried out in Matlab.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 07:54:42 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Popescu", "Dalia", ""], ["Jacquet", "Philippe", ""], ["Mans", "Bernard", ""]]}, {"id": "2102.03051", "submitter": "Li  Li", "authors": "Wenting Zou, Li Li, Zichen Xu, Chengzhong Xu", "title": "DEAL: Decremental Energy-Aware Learning in a Federated System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning struggles with their heavy energy footprint on\nbattery-powered devices. The learning process keeps all devices awake while\ndraining expensive battery power to train a shared model collaboratively, yet\nit may still leak sensitive personal information. Traditional energy management\ntechniques in system kernel mode can force the training device entering low\npower states, but it may violate the SLO of the collaborative learning. To\naddress the conflict between learning SLO and energy efficiency, we propose\nDEAL, an energy efficient learning system that saves energy and preserves\nprivacy with a decremental learning design. DEAL reduces the energy footprint\nfrom two layers: 1) an optimization layer that selects a subset of workers with\nsufficient capacity and maximum rewards. 2) a specified decremental learning\nalgorithm that actively provides a decremental and incremental update\nfunctions, which allows kernel to correctly tune the local DVFS. We prototyped\nDEAL in containerized services with modern smartphone profiles and evaluated it\nwith several learning benchmarks with realistic traces. We observed that DEAL\nachieves 75.6%-82.4% less energy footprint in different datasets, compared to\nthe traditional methods. All learning processes are faster than\nstate-of-the-practice FL frameworks up to 2-4X in model convergence.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 08:31:42 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Zou", "Wenting", ""], ["Li", "Li", ""], ["Xu", "Zichen", ""], ["Xu", "Chengzhong", ""]]}, {"id": "2102.03124", "submitter": "Luis Miguel Vaquero Gonzalez", "authors": "Luis M Vaquero, Yehia Elkhatib, Felix Cuadrado", "title": "Disaggregated Memory at the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  This paper describes how to augment techniques such as Distributed Shared\nMemory with recent trends on disaggregated Non Volatile Memory in the data\ncentre so that the combination can be used in an edge environment with\npotentially volatile and mobile resources. This article identifies the main\nadvantages and challenges, and offers an architectural evolution to incorporate\nrecent research trends into production-ready disaggregated edges. We also\npresent two prototypes showing the feasibility of this proposal.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 12:03:29 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Vaquero", "Luis M", ""], ["Elkhatib", "Yehia", ""], ["Cuadrado", "Felix", ""]]}, {"id": "2102.03139", "submitter": "Sebastian M\\\"uller", "authors": "Bartosz Ku\\'smierz, Sebastian M\\\"uller, Angelo Capossele", "title": "Committee selection in DAG distributed ledgers and applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose several solutions to the committee selection\nproblem among participants of a DAG distributed ledger. Our methods are based\non a ledger intrinsic reputation model that serves as a selection criterion.\nThe main difficulty arises from the fact that the DAG ledger is a priori not\ntotally ordered and that the participants need to reach a consensus on\nparticipants' reputation. Furthermore, we outline applications of the proposed\nprotocols, including: (i) self-contained decentralized random number beacon;\n(ii) selection of oracles in smart contracts; (iii) applications in consensus\nprotocols and sharding solutions. We conclude with a discussion on the security\nand liveness of the proposed protocols by modeling reputation with a Zipf law.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 12:31:26 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["Ku\u015bmierz", "Bartosz", ""], ["M\u00fcller", "Sebastian", ""], ["Capossele", "Angelo", ""]]}, {"id": "2102.03226", "submitter": "Boris D\\\"udder", "authors": "Boris D\\\"udder and Haiqin Wu and Michael Henke and Natalia Straub and\n  Tan G\\\"urpinar and Philipp Asterios Ioannidis and Vladislav Fomin and\n  Raimundas Matulevi\\v{c}ius and Mubashar Iqbal", "title": "BlockNet Report: Curriculum Guidance Document", "comments": "BlockChain Network Online Education for interdisciplinary European\n  Competence Transfer (BlockNet), funded by Erasmus+ KA2 program. Project No:\n  2018-1-LT01-KA203-047044, pages 49", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain is a challenging topic since it is novel and fosters potential\ninnovation. The blockchain is attractive for various disciplines, and, because\nof its cross-cutting nature, needs knowledge stemming from various disciplines.\nThe devised curriculum can be instantiated specifically to meet the needs of\nstudents' groups from various disciplines. The pedagogical innovation of the\nproject is the inclusion of interdisciplinary project groups with participant's\ninteraction via online platforms for project-based learning activities. MOOCs\nand SNOCs allow blended-learning for interdisciplinary and geographically\ndistributed student groups.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 15:17:32 GMT"}], "update_date": "2021-02-08", "authors_parsed": [["D\u00fcdder", "Boris", ""], ["Wu", "Haiqin", ""], ["Henke", "Michael", ""], ["Straub", "Natalia", ""], ["G\u00fcrpinar", "Tan", ""], ["Ioannidis", "Philipp Asterios", ""], ["Fomin", "Vladislav", ""], ["Matulevi\u010dius", "Raimundas", ""], ["Iqbal", "Mubashar", ""]]}, {"id": "2102.03448", "submitter": "Karan Singhal", "authors": "Karan Singhal, Hakim Sidahmed, Zachary Garrett, Shanshan Wu, Keith\n  Rush, Sushant Prakash", "title": "Federated Reconstruction: Partially Local Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Personalization methods in federated learning aim to balance the benefits of\nfederated and local training for data availability, communication cost, and\nrobustness to client heterogeneity. Approaches that require clients to\ncommunicate all model parameters can be undesirable due to privacy and\ncommunication constraints. Other approaches require always-available or\nstateful clients, impractical in large-scale cross-device settings. We\nintroduce Federated Reconstruction, the first model-agnostic framework for\npartially local federated learning suitable for training and inference at\nscale. We motivate the framework via a connection to model-agnostic meta\nlearning, empirically demonstrate its performance over existing approaches for\ncollaborative filtering and next word prediction, and release an open-source\nlibrary for evaluating approaches in this setting. We also describe the\nsuccessful deployment of this approach at scale for federated collaborative\nfiltering in a mobile keyboard application.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 23:33:43 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 22:27:11 GMT"}, {"version": "v3", "created": "Fri, 26 Mar 2021 22:59:32 GMT"}, {"version": "v4", "created": "Sun, 6 Jun 2021 16:06:15 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Singhal", "Karan", ""], ["Sidahmed", "Hakim", ""], ["Garrett", "Zachary", ""], ["Wu", "Shanshan", ""], ["Rush", "Keith", ""], ["Prakash", "Sushant", ""]]}, {"id": "2102.03496", "submitter": "Nima Nikmehr", "authors": "Nima Nikmehr, Mikhail A. Bragin, Peter B. Luh and Peng Zhang", "title": "Distributed and Asynchronous Operational Optimization of Networked\n  Microgrids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "eess.SY cs.DC cs.SY math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Smart programmable microgrids (SPM) is an emerging technology for making\nmicrogrids more software-defined and less hardware-independent such that\nconverting distributed energy resources (DERs) to networked community\nmicrogrids becomes affordable, autonomic, and secure. As one of the\ncornerstones of SPM, this paper pioneers a concept of software-defined\noperation optimization for networked microgrids, where operation objectives,\ngrid connection, and DER participation will be defined by software and\nplug-and-play, and can be quickly reconfigured, based on the development of\nmodularized and tightened models and a novel asynchronous price-based\ndecomposition-and-coordination method. Key contributions include: (1) design\nthe architecture of the operational optimization of networked microgrids which\ncan be readily implemented to ensure the programmability of islanded microgrids\nin solving the distributed optimization models, (2) realize a novel discrete\nmodel of droop controller, and (3) introduce a powerful distributed and\nasynchronous method Distributed and Asynchronous Surrogate Lagrangian\nRelaxation (DA-SLR) to efficiently coordinate microgrids asynchronously. Two\ncase studies are tested to demonstrate the efficiency of developed DA-SLR, and\nspecifically, the testing results show the superiority of DA-SLR as compared to\nprevious methods such as ADMM.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 03:20:42 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Nikmehr", "Nima", ""], ["Bragin", "Mikhail A.", ""], ["Luh", "Peter B.", ""], ["Zhang", "Peng", ""]]}, {"id": "2102.03614", "submitter": "Jeremie Lagraviere", "authors": "J\\'er\\'emie Lagravi\\`ere, Johannes Langguth, Martina Prugger, Phuong\n  H. Ha, Xing Cai", "title": "A Newcomer In The PGAS World -- UPC++ vs UPC: A Comparative Study", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF cs.PL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A newcomer in the Partitioned Global Address Space (PGAS) 'world' has arrived\nin its version 1.0: Unified Parallel C++ (UPC++). UPC++ targets distributed\ndata structures where communication is irregular or fine-grained. The key\nabstractions are global pointers, asynchronous programming via RPC, futures and\npromises. UPC++ API for moving non-contiguous data and handling memories with\ndifferent optimal access methods resemble those used in modern C++. In this\nstudy we provide two kernels implemented in UPC++: a sparse-matrix vector\nmultiplication (SpMV) as part of a Partial-Differential Equation solver, and an\nimplementation of the Heat Equation on a 2D-domain. Code listings of these two\nkernels are available in the article in order to show the differences in\nprogramming style between UPC and UPC++. We provide a performance comparison\nbetween UPC and UPC++ using single-node, multi-node hardware and many-core\nhardware (Intel Xeon Phi Knight's Landing).\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 17:06:02 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Lagravi\u00e8re", "J\u00e9r\u00e9mie", ""], ["Langguth", "Johannes", ""], ["Prugger", "Martina", ""], ["Ha", "Phuong H.", ""], ["Cai", "Xing", ""]]}, {"id": "2102.03620", "submitter": "Anirban Das", "authors": "Anirban Das and Stacy Patterson", "title": "Multi-Tier Federated Learning for Vertically Partitioned Data", "comments": "11 pages, 3 figures, To be published in ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider decentralized model training in tiered communication networks.\nOur network model consists of a set of silos, each holding a vertical partition\nof the data. Each silo contains a hub and a set of clients, with the silo's\nvertical data shard partitioned horizontally across its clients. We propose\nTiered Decentralized Coordinate Descent (TDCD), a communication-efficient\ndecentralized training algorithm for such two-tiered networks. To reduce\ncommunication overhead, the clients in each silo perform multiple local\ngradient steps before sharing updates with their hub. Each hub adjusts its\ncoordinates by averaging its workers' updates, and then hubs exchange\nintermediate updates with one another. We present a theoretical analysis of our\nalgorithm and show the dependence of the convergence rate on the number of\nvertical partitions, the number of local updates, and the number of clients in\neach hub. We further validate our approach empirically via simulation-based\nexperiments using a variety of datasets and both convex and non-convex\nobjectives.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 17:34:14 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Das", "Anirban", ""], ["Patterson", "Stacy", ""]]}, {"id": "2102.03819", "submitter": "Patrick Diehl", "authors": "Pranav Gadikar and Patrick Diehl and Prashant K. Jha", "title": "Load balancing for distributed nonlocal models within asynchronous\n  many-task systems", "comments": null, "journal-ref": null, "doi": "10.1109/IPDPSW52791.2021.00103", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this work, we consider the challenges of developing a distributed solver\nfor models based on nonlocal interactions. In nonlocal models, in contrast to\nthe local model, such as the wave and heat partial differential equation, the\nmaterial interacts with neighboring points on a larger-length scale compared to\nthe mesh discretization. In developing a fully distributed solver, the\ninteraction over a length scale greater than mesh size introduces additional\ndata dependencies among the compute nodes and communication bottleneck. In this\nwork, we carefully look at these challenges in the context of nonlocal models;\nto keep the presentation specific to the computational issues, we consider a\nnonlocal heat equation in a 2d setting. In particular, the distributed\nframework we propose pays greater attention to the bottleneck of data\ncommunication and the dynamic balancing of loads among nodes with varying\ncompute capacity. For load balancing, we propose a novel framework that\nassesses the compute capacity of nodes and dynamically balances the load so\nthat the idle time among nodes is minimal. Our framework relies heavily on HPX\nlibrary, an asynchronous many-task run time system. We present several results\ndemonstrating the effectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 15:31:07 GMT"}, {"version": "v2", "created": "Thu, 11 Mar 2021 20:27:46 GMT"}, {"version": "v3", "created": "Sat, 10 Apr 2021 00:26:42 GMT"}], "update_date": "2021-07-09", "authors_parsed": [["Gadikar", "Pranav", ""], ["Diehl", "Patrick", ""], ["Jha", "Prashant K.", ""]]}, {"id": "2102.03863", "submitter": "David Dice", "authors": "Dave Dice and Alex Kogan", "title": "Hemlock : Compact and Scalable Mutual Exclusion", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present Hemlock, a novel mutual exclusion locking algorithm that is\nextremely compact, requiring just one word per thread plus one word per lock,\nbut which still provides local spinning in most circumstances, high throughput\nunder contention, and low latency in the uncontended case. Hemlock is\ncontext-free -- not requiring any information to be passed from a lock\noperation to the corresponding unlock -- and FIFO. The performance of Hemlock\nis competitive with and often better than the best scalable spin locks.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2021 17:46:25 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2021 16:35:09 GMT"}, {"version": "v3", "created": "Thu, 13 May 2021 20:02:13 GMT"}], "update_date": "2021-05-17", "authors_parsed": [["Dice", "Dave", ""], ["Kogan", "Alex", ""]]}, {"id": "2102.03970", "submitter": "An Xu", "authors": "An Xu, Heng Huang", "title": "Double Momentum SGD for Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication efficiency is crucial in federated learning. Conducting many\nlocal training steps in clients to reduce the communication frequency between\nclients and the server is a common method to address this issue. However, the\nclient drift problem arises as the non-i.i.d. data distributions in different\nclients can severely deteriorate the performance of federated learning. In this\nwork, we propose a new SGD variant named as DOMO to improve the model\nperformance in federated learning, where double momentum buffers are\nmaintained. One momentum buffer tracks the server update direction, while the\nother tracks the local update direction. We introduce a novel server momentum\nfusion technique to coordinate the server and local momentum SGD. We also\nprovide the first theoretical analysis involving both the server and local\nmomentum SGD. Extensive experimental results show a better model performance of\nDOMO than FedAvg and existing momentum SGD variants in federated learning\ntasks.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 02:47:24 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Xu", "An", ""], ["Huang", "Heng", ""]]}, {"id": "2102.04063", "submitter": "Alex Auvolat", "authors": "Alex Auvolat (WIDE), Y\\'erom-David Bromberg (WIDE), Davide Frey\n  (WIDE), Fran\\c{c}ois Ta\\\"iani (WIDE)", "title": "$\\scriptstyle{BASALT}$: A Rock-Solid Foundation for Epidemic Consensus\n  Algorithms in Very Large, Very Open Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI cs.SE cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent works have proposed new Byzantine consensus algorithms for blockchains\nbased on epidemics, a design which enables highly scalable performance at a low\ncost. These methods however critically depend on a secure random peer sampling\nservice: a service that provides a stream of random network nodes where no\nattacking entity can become over-represented. To ensure this security property,\ncurrent epidemic platforms use a Proof-of-Stake system to select peer samples.\nHowever such a system limits the openness of the system as only nodes with\nsignificant stake can participate in the consensus, leading to an oligopoly\nsituation. Moreover, this design introduces a complex interdependency between\nthe consensus algorithm and the cryptocurrency built upon it. In this paper, we\npropose a radically different security design for the peer sampling service,\nbased on the distribution of IP addresses to prevent Sybil attacks. We propose\na new algorithm, $\\scriptstyle{BASALT}$, that implements our design using a\nstubborn chaotic search to counter attackers' attempts at becoming\nover-represented. We show in theory and using Monte Carlo simulations that\n$\\scriptstyle{BASALT}$ provides samples which are extremely close to the\noptimal distribution even in adversarial scenarios such as tentative Eclipse\nattacks. Live experiments on a production cryptocurrency platform confirm that\nthe samples obtained using $\\scriptstyle{BASALT}$ are equitably distributed\namongst nodes, allowing for a system which is both open and where no single\nentity can gain excessive power.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 08:52:19 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Auvolat", "Alex", "", "WIDE"], ["Bromberg", "Y\u00e9rom-David", "", "WIDE"], ["Frey", "Davide", "", "WIDE"], ["Ta\u00efani", "Fran\u00e7ois", "", "WIDE"]]}, {"id": "2102.04133", "submitter": "Louis Esperet", "authors": "Louis Esperet and Benjamin L\\'ev\\^eque", "title": "Local certification of graphs on surfaces", "comments": "9 pages, 5 figures - v2: revised version (with more background on\n  surfaces)", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A proof labelling scheme for a graph class $\\mathcal{C}$ is an assignment of\ncertificates to the vertices of any graph in the class $\\mathcal{C}$, such that\nupon reading its certificate and the certificate of its neighbors, every vertex\nfrom a graph $G\\in \\mathcal{C}$ accepts the instance, while if $G\\not\\in\n\\mathcal{C}$, for every possible assignment of certificates, at least one\nvertex rejects the instance. It was proved recently that for any fixed surface\n$\\Sigma$, the class of graphs embeddable in $\\Sigma$ has a proof labelling\nscheme in which each vertex of an $n$-vertex graph receives a certificate of at\nmost $O(\\log n)$ bits. The proof is quite long and intricate and heavily relies\non an earlier result for planar graphs. Here we give a very short proof for any\nsurface. The main idea is to encode a rotation system locally, together with a\nspanning tree supporting the local computation of the genus via Euler's\nformula.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 11:22:33 GMT"}, {"version": "v2", "created": "Tue, 25 May 2021 10:02:29 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Esperet", "Louis", ""], ["L\u00e9v\u00eaque", "Benjamin", ""]]}, {"id": "2102.04322", "submitter": "Pei Peng", "authors": "Pei Peng, Moslem Noori, Emina Soljanin", "title": "Distributed Storage Allocations for Optimal Service Rates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Redundant storage maintains the performance of distributed systems under\nvarious forms of uncertainty. This paper considers the uncertainty in node\naccess and download service. We consider two access models under two download\nservice models. In one access model, a user can access each node with a fixed\nprobability, and in the other, a user can access a random fixed-size subset of\nnodes. We consider two download service models. In the first (small file)\nmodel, the randomness associated with the file size is negligible. In the\nsecond (large file) model, randomness is associated with both the file size and\nthe system's operations. We focus on the service rate of the system. For a\nfixed redundancy level, the systems' service rate is determined by the\nallocation of coded chunks over the storage nodes. We consider quasi-uniform\nallocations, where coded content is uniformly spread among a subset of nodes.\nThe question we address asks what the size of this subset (spreading) should\nbe. We show that in the small file model, concentrating the coded content to a\nminimum-size subset is universally optimal. For the large file model, the\noptimal spreading depends on the system parameters. These conclusions hold for\nboth access models.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 16:26:53 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Peng", "Pei", ""], ["Noori", "Moslem", ""], ["Soljanin", "Emina", ""]]}, {"id": "2102.04326", "submitter": "Anurag Jain", "authors": "Anurag Jain and Shoeb Siddiqui and Sujit Gujar", "title": "We might walk together, but I run faster: Network Fairness and\n  Scalability in Blockchains", "comments": "Full Version of the paper submitted to AAMAS as an Extended Abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain-based Distributed Ledgers (DLs) promise to transform the existing\nfinancial system by making it truly democratic. In the past decade, blockchain\ntechnology has seen many novel applications ranging from the banking industry\nto real estate. However, in order to be adopted universally, blockchain systems\nmust be scalable to support a high volume of transactions. As we increase the\nthroughput of the DL system, the underlying peer-to-peer network might face\nmultiple levels of challenges to keep up with the requirements. Due to varying\nnetwork capacities, the slower nodes would be at a relative disadvantage\ncompared to the faster ones, which could negatively impact their revenue. In\norder to quantify their relative advantage or disadvantage, we introduce two\nmeasures of network fairness, $p_f$, the probability of frontrunning and\n$\\alpha_f$, the publishing fairness. We show that as we scale the blockchain,\nboth these measures deteriorate, implying that the slower nodes face a\ndisadvantage at higher throughputs. It results in the faster nodes getting more\nthan their fair share of the reward while the slower nodes (slow in terms of\nnetwork quality) get less. Thus, fairness and scalability in blockchain systems\ndo not go hand in hand.\n  In a setting with rational miners, lack of fairness causes miners to deviate\nfrom the \"longest chain rule\" or undercut, which would reduce the blockchain's\nresilience against byzantine adversaries. Hence, fairness is not only a\ndesirable property for a blockchain system but also essential for the security\nof the blockchain and any scalable blockchain protocol proposed must ensure\nfairness.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 16:30:04 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 17:22:28 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Jain", "Anurag", ""], ["Siddiqui", "Shoeb", ""], ["Gujar", "Sujit", ""]]}, {"id": "2102.04429", "submitter": "Xiaodong Cui", "authors": "Xiaodong Cui, Songtao Lu and Brian Kingsbury", "title": "Federated Acoustic Modeling For Automatic Speech Recognition", "comments": "Accepted by ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.DC eess.AS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data privacy and protection is a crucial issue for any automatic speech\nrecognition (ASR) service provider when dealing with clients. In this paper, we\ninvestigate federated acoustic modeling using data from multiple clients. A\nclient's data is stored on a local data server and the clients communicate only\nmodel parameters with a central server, and not their data. The communication\nhappens infrequently to reduce the communication cost. To mitigate the non-iid\nissue, client adaptive federated training (CAFT) is proposed to canonicalize\ndata across clients. The experiments are carried out on 1,150 hours of speech\ndata from multiple domains. Hybrid LSTM acoustic models are trained via\nfederated learning and their performance is compared to traditional centralized\nacoustic model training. The experimental results demonstrate the effectiveness\nof the proposed federated acoustic modeling strategy. We also show that CAFT\ncan further improve the performance of the federated acoustic model.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 18:39:36 GMT"}], "update_date": "2021-02-09", "authors_parsed": [["Cui", "Xiaodong", ""], ["Lu", "Songtao", ""], ["Kingsbury", "Brian", ""]]}, {"id": "2102.04446", "submitter": "Justin Gould", "authors": "Justin Gould", "title": "A Framework for Auditing Data Center Energy Usage and Mitigating\n  Environmental Footprint", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  As the Data Science field continues to mature, and we collect more data, the\ndemand to store and analyze them will continue to increase. This increase in\ndata availability and demand for analytics will put a strain on data centers\nand compute clusters-with implications for both energy costs and emissions. As\nthe world battles a climate crisis, it is prudent for organizations with data\ncenters to have a framework for combating increasing energy costs and emissions\nto meet demand for analytics work. In this paper, I present a generalized\nframework for organizations to audit data centers energy efficiency to\nunderstand the resources required to operate a given data center and effective\nsteps organizations can take to improve data center efficiency and lower the\nenvironmental impact.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 18:58:41 GMT"}, {"version": "v2", "created": "Tue, 9 Feb 2021 13:29:11 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Gould", "Justin", ""]]}, {"id": "2102.04487", "submitter": "Divyansh Jhunjhunwala", "authors": "Divyansh Jhunjhunwala, Advait Gadhikar, Gauri Joshi, Yonina C. Eldar", "title": "Adaptive Quantization of Model Updates for Communication-Efficient\n  Federated Learning", "comments": "Accepted to ICASSP 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication of model updates between client nodes and the central\naggregating server is a major bottleneck in federated learning, especially in\nbandwidth-limited settings and high-dimensional models. Gradient quantization\nis an effective way of reducing the number of bits required to communicate each\nmodel update, albeit at the cost of having a higher error floor due to the\nhigher variance of the stochastic gradients. In this work, we propose an\nadaptive quantization strategy called AdaQuantFL that aims to achieve\ncommunication efficiency as well as a low error floor by changing the number of\nquantization levels during the course of training. Experiments on training deep\nneural networks show that our method can converge in much fewer communicated\nbits as compared to fixed quantization level setups, with little or no impact\non training and test accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 19:14:21 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Jhunjhunwala", "Divyansh", ""], ["Gadhikar", "Advait", ""], ["Joshi", "Gauri", ""], ["Eldar", "Yonina C.", ""]]}, {"id": "2102.04546", "submitter": "Alexandre Nolin", "authors": "Magn\\'us M. Halld\\'orsson, Alexandre Nolin", "title": "Superfast Coloring in CONGEST via Efficient Color Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  We present a procedure for efficiently sampling colors in the {\\congest}\nmodel. It allows nodes whose number of colors exceeds their number of neighbors\nby a constant fraction to sample up to $\\Theta(\\log n)$ semi-random colors\nunused by their neighbors in $O(1)$ rounds, even in the distance-2 setting.\nThis yields algorithms with $O(\\log^* \\Delta)$ complexity for different\nedge-coloring, vertex coloring, and distance-2 coloring problems, matching the\nbest possible. In particular, we obtain an $O(\\log^* \\Delta)$-round CONGEST\nalgorithm for $(1+\\epsilon)\\Delta$-edge coloring when $\\Delta \\ge\n\\log^{1+1/\\log^*n} n$, and a poly($\\log\\log n$)-round algorithm for\n$(2\\Delta-1)$-edge coloring in general. The sampling procedure is inspired by a\nseminal result of Newman in communication complexity.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 21:49:26 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 14:29:37 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Halld\u00f3rsson", "Magn\u00fas M.", ""], ["Nolin", "Alexandre", ""]]}, {"id": "2102.04635", "submitter": "Zhishuai Guo", "authors": "Zhuoning Yuan, Zhishuai Guo, Yi Xu, Yiming Ying, Tianbao Yang", "title": "Federated Deep AUC Maximization for Heterogeneous Data with a Constant\n  Communication Complexity", "comments": "Zhuoning and Zhishuai contributed equally to this work", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \\underline{D}eep \\underline{A}UC (area under the ROC curve)\n\\underline{M}aximization (DAM) has attracted much attention recently due to its\ngreat potential for imbalanced data classification. However, the research on\n\\underline{F}ederated \\underline{D}eep \\underline{A}UC \\underline{M}aximization\n(FDAM) is still limited. Compared with standard federated learning (FL)\napproaches that focus on decomposable minimization objectives, FDAM is more\ncomplicated due to its minimization objective is non-decomposable over\nindividual examples. In this paper, we propose improved FDAM algorithms for\nheterogeneous data by solving the popular non-convex strongly-concave min-max\nformulation of DAM in a distributed fashion. A striking result of this paper is\nthat the communication complexity of the proposed algorithm is a constant\nindependent of the number of machines and also independent of the accuracy\nlevel, which improves an existing result by orders of magnitude. Of independent\ninterest, the proposed algorithm can also be applied to a class of\nnon-convex-strongly-concave min-max problems. The experiments have demonstrated\nthe effectiveness of our FDAM algorithm on benchmark datasets, and on medical\nchest X-ray images from different organizations. Our experiment shows that the\nperformance of FDAM using data from multiple hospitals can improve the AUC\nscore on testing data from a single hospital for detecting life-threatening\ndiseases based on chest radiographs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 04:05:19 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Yuan", "Zhuoning", ""], ["Guo", "Zhishuai", ""], ["Xu", "Yi", ""], ["Ying", "Yiming", ""], ["Yang", "Tianbao", ""]]}, {"id": "2102.04681", "submitter": "Dennis Bautembach", "authors": "Dennis Bautembach, Iason Oikonomidis, Antonis Argyros", "title": "Multi-GPU SNN Simulation with Static Load Balancing", "comments": "Camera-ready version, accepted to IJCNN 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a SNN simulator which scales to millions of neurons, billions of\nsynapses, and 8 GPUs. This is made possible by 1) a novel, cache-aware spike\ntransmission algorithm 2) a model parallel multi-GPU distribution scheme and 3)\na static, yet very effective load balancing strategy. The simulator further\nfeatures an easy to use API and the ability to create custom models. We compare\nthe proposed simulator against two state of the art ones on a series of\nbenchmarks using three well-established models. We find that our simulator is\nfaster, consumes less memory, and scales linearly with the number of GPUs.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 07:07:34 GMT"}, {"version": "v2", "created": "Thu, 22 Apr 2021 18:50:23 GMT"}], "update_date": "2021-04-26", "authors_parsed": [["Bautembach", "Dennis", ""], ["Oikonomidis", "Iason", ""], ["Argyros", "Antonis", ""]]}, {"id": "2102.04736", "submitter": "Gabriel Barth-Maron", "authors": "Albin Cassirer, Gabriel Barth-Maron, Eugene Brevdo, Sabela Ramos, Toby\n  Boyd, Thibault Sottiaux, Manuel Kroiss", "title": "Reverb: A Framework For Experience Replay", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A central component of training in Reinforcement Learning (RL) is Experience:\nthe data used for training. The mechanisms used to generate and consume this\ndata have an important effect on the performance of RL algorithms.\n  In this paper, we introduce Reverb: an efficient, extensible, and easy to use\nsystem designed specifically for experience replay in RL. Reverb is designed to\nwork efficiently in distributed configurations with up to thousands of\nconcurrent clients.\n  The flexible API provides users with the tools to easily and accurately\nconfigure the replay buffer. It includes strategies for selecting and removing\nelements from the buffer, as well as options for controlling the ratio between\nsampled and inserted elements. This paper presents the core design of Reverb,\ngives examples of how it can be applied, and provides empirical results of\nReverb's performance characteristics.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 10:03:17 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Cassirer", "Albin", ""], ["Barth-Maron", "Gabriel", ""], ["Brevdo", "Eugene", ""], ["Ramos", "Sabela", ""], ["Boyd", "Toby", ""], ["Sottiaux", "Thibault", ""], ["Kroiss", "Manuel", ""]]}, {"id": "2102.04737", "submitter": "Onur G\\\"unl\\\"u Dr.-Ing.", "authors": "Muah Kim, Onur G\\\"unl\\\"u, and Rafael F. Schaefer", "title": "Federated Learning with Local Differential Privacy: Trade-offs between\n  Privacy, Utility, and Communication", "comments": "To appear in IEEE International Conference on Acoustics, Speech, and\n  Signal Processing 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.IT eess.SP math.IT", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning (FL) allows to train a massive amount of data privately\ndue to its decentralized structure. Stochastic gradient descent (SGD) is\ncommonly used for FL due to its good empirical performance, but sensitive user\ninformation can still be inferred from weight updates shared during FL\niterations. We consider Gaussian mechanisms to preserve local differential\nprivacy (LDP) of user data in the FL model with SGD. The trade-offs between\nuser privacy, global utility, and transmission rate are proved by defining\nappropriate metrics for FL with LDP. Compared to existing results, the query\nsensitivity used in LDP is defined as a variable and a tighter privacy\naccounting method is applied. The proposed utility bound allows heterogeneous\nparameters over all users. Our bounds characterize how much utility decreases\nand transmission rate increases if a stronger privacy regime is targeted.\nFurthermore, given a target privacy level, our results guarantee a\nsignificantly larger utility and a smaller transmission rate as compared to\nexisting privacy accounting methods.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 10:04:18 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Kim", "Muah", ""], ["G\u00fcnl\u00fc", "Onur", ""], ["Schaefer", "Rafael F.", ""]]}, {"id": "2102.04875", "submitter": "Parwat Singh Anjana", "authors": "Parwat Singh Anjana, Sweta Kumari, Sathya Peri, Sachin Rathor, Archit\n  Somani", "title": "OptSmart: A Space Efficient Optimistic Concurrent Execution of Smart\n  Contracts", "comments": "43 pages, 13 figure, 1 Table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Popular blockchains such as Ethereum and several others execute complex\ntransactions in blocks through user-defined scripts known as smart contracts.\nSerial execution of smart contract transactions/atomic-units (AUs) fails to\nharness the multiprocessing power offered by the prevalence of multi-core\nprocessors. By adding concurrency to the execution of AUs, we can achieve\nbetter efficiency and higher throughput.\n  In this paper, we develop a concurrent miner that proposes a block by\nexecuting the AUs concurrently using optimistic Software Transactional Memory\nsystems (STMs). It captures the independent AUs in a concurrent bin and\ndependent AUs in the block graph (BG) efficiently. Later, we propose a\nconcurrent validator that re-executes the same AUs concurrently and\ndeterministically using a concurrent bin followed by a BG given by the miner to\nverify the proposed block. We rigorously prove the correctness of concurrent\nexecution of AUs and achieve significant performance gain over the\nstate-of-the-art.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 15:18:42 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 06:20:02 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Anjana", "Parwat Singh", ""], ["Kumari", "Sweta", ""], ["Peri", "Sathya", ""], ["Rathor", "Sachin", ""], ["Somani", "Archit", ""]]}, {"id": "2102.04974", "submitter": "Michele Garetto", "authors": "Michele Garetto and Emilio Leonardi and Giovanni Neglia", "title": "Content Placement in Networks of Similarity Caches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.IR", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Similarity caching systems have recently attracted the attention of the\nscientific community, as they can be profitably used in many application\ncontexts, like multimedia retrieval, advertising, object recognition,\nrecommender systems and online content-match applications. In such systems, a\nuser request for an object $o$, which is not in the cache, can be (partially)\nsatisfied by a similar stored object $o$', at the cost of a loss of user\nutility. In this paper we make a first step into the novel area of similarity\ncaching networks, where requests can be forwarded along a path of caches to get\nthe best efficiency-accuracy tradeoff. The offline problem of content placement\ncan be easily shown to be NP-hard, while different polynomial algorithms can be\ndevised to approach the optimal solution in discrete cases. As the content\nspace grows large, we propose a continuous problem formulation whose solution\nexhibits a simple structure in a class of tree topologies. We verify our\nfindings using synthetic and realistic request traces.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 17:48:24 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Garetto", "Michele", ""], ["Leonardi", "Emilio", ""], ["Neglia", "Giovanni", ""]]}, {"id": "2102.05021", "submitter": "Haimonti Dutta", "authors": "Haimonti Dutta, Nitin Nataraj, Saurabh Amarnath Mahindre", "title": "Consensus Based Multi-Layer Perceptrons for Edge Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, storing large volumes of data on distributed devices has\nbecome commonplace. Applications involving sensors, for example, capture data\nin different modalities including image, video, audio, GPS and others. Novel\nalgorithms are required to learn from this rich distributed data. In this\npaper, we present consensus based multi-layer perceptrons for\nresource-constrained devices. Assuming nodes (devices) in the distributed\nsystem are arranged in a graph and contain vertically partitioned data, the\ngoal is to learn a global function that minimizes the loss. Each node learns a\nfeed-forward multi-layer perceptron and obtains a loss on data stored locally.\nIt then gossips with a neighbor, chosen uniformly at random, and exchanges\ninformation about the loss. The updated loss is used to run a back propagation\nalgorithm and adjust weights appropriately. This method enables nodes to learn\nthe global function without exchange of data in the network. Empirical results\nreveal that the consensus algorithm converges to the centralized model and has\nperformance comparable to centralized multi-layer perceptrons and tree-based\nalgorithms including random forests and gradient boosted decision trees.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 18:39:46 GMT"}], "update_date": "2021-02-10", "authors_parsed": [["Dutta", "Haimonti", ""], ["Nataraj", "Nitin", ""], ["Mahindre", "Saurabh Amarnath", ""]]}, {"id": "2102.05037", "submitter": "Wenjie Chu", "authors": "Wenjie Chu, Wei Zhang, Haiyan Zhao, Zhi Jin, Hong Mei", "title": "Massive Self-Assembly in Grid Environments", "comments": "37 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-assembly plays an essential role in many natural processes, involving\nthe formation and evolution of living or non-living structures, and shows\npotential applications in many emerging domains. In existing research and\npractice, there still lacks an ideal self-assembly mechanism that manifests\nefficiency, scalability, and stability at the same time. Inspired by phototaxis\nobserved in nature, we propose a computational approach for massive\nself-assembly of connected shapes in grid environments. The key component of\nthis approach is an artificial light field superimposed on a grid environment,\nwhich is determined by the positions of all agents and at the same time drives\nall agents to change their positions, forming a dynamic mutual feedback\nprocess. This work advances the understanding and potential applications of\nself-assembly.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2021 17:37:29 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2021 13:56:59 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Chu", "Wenjie", ""], ["Zhang", "Wei", ""], ["Zhao", "Haiyan", ""], ["Jin", "Zhi", ""], ["Mei", "Hong", ""]]}, {"id": "2102.05187", "submitter": "Luanzheng Guo", "authors": "Ruiqin Tian, Luanzheng Guo, Jiajia Li, Bin Ren, Gokcen Kestor", "title": "A High-Performance Sparse Tensor Algebra Compiler in Multi-Level IR", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Tensor algebra is widely used in many applications, such as scientific\ncomputing, machine learning, and data analytics. The tensors represented\nreal-world data are usually large and sparse. There are tens of storage formats\ndesigned for sparse matrices and/or tensors and the performance of sparse\ntensor operations depends on a particular architecture and/or selected sparse\nformat, which makes it challenging to implement and optimize every tensor\noperation of interest and transfer the code from one architecture to another.\nWe propose a tensor algebra domain-specific language (DSL) and compiler\ninfrastructure to automatically generate kernels for mixed sparse-dense tensor\nalgebra operations, named COMET. The proposed DSL provides high-level\nprogramming abstractions that resemble the familiar Einstein notation to\nrepresent tensor algebra operations. The compiler performs code optimizations\nand transformations for efficient code generation while covering a wide range\nof tensor storage formats. COMET compiler also leverages data reordering to\nimprove spatial or temporal locality for better performance. Our results show\nthat the performance of automatically generated kernels outperforms the\nstate-of-the-art sparse tensor algebra compiler, with up to 20.92x, 6.39x, and\n13.9x performance improvement, for parallel SpMV, SpMM, and TTM over TACO,\nrespectively.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 23:43:53 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Tian", "Ruiqin", ""], ["Guo", "Luanzheng", ""], ["Li", "Jiajia", ""], ["Ren", "Bin", ""], ["Kestor", "Gokcen", ""]]}, {"id": "2102.05191", "submitter": "Wenhao Li", "authors": "Wenhao Li, Niranjan Bidargaddi, John Fouyaxis", "title": "DHLink: A Microservice Platform supporting Rapid Application Development\n  and Secure Real-time Data Sharing in Digital Health", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Digital health applications that leverage multiple sources of patient data\nfor insights to patients' behaviours or disease symptoms as well as remote\npatient monitoring, nudging and treatments are becoming increasingly popular in\nvarious medical practices and research. One common issue among these\napplications is that they are generally based on project-specific solutions and\ndeveloped from scratch. Such application development fashion results in large\namounts of repetitive effort, for example, in building study specific websites\nand mobile frontends, deploying customised infrastructures, and collecting data\nthat may have already been collected in other studies and projects. What is\nworse, the data collected, and functions built cannot be easily reused by other\napplications. In this paper, we present an event-driven microservice platform,\nnamely DHLink, to address this issue. DHLink securely links existing digital\nhealth applications of different projects, facilitates real-time data sharing,\nand supports rapid application development by reusing data and functions of\nexisting digital health applications. In addition, comes with DHLink, a set of\nhighly generic and reusable microservices is provided, which allows developers\nto rapidly create a typical above-mentioned digital health application by only\ndeveloping the core algorithms. Two use cases outlined in this paper have shown\nthe use of DHLink and the set of microservices for application collaboration\nand new application development to be efficient and practical.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2021 23:55:16 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Li", "Wenhao", ""], ["Bidargaddi", "Niranjan", ""], ["Fouyaxis", "John", ""]]}, {"id": "2102.05238", "submitter": "Shantanu Sharma", "authors": "Peeyush Gupta, Sharad Mehrotra, Shantanu Sharma, Nalini\n  Venkatasubramanian, Guoxi Wang", "title": "Concealer: SGX-based Secure, Volume Hiding, and Verifiable Processing of\n  Spatial Time-Series Datasets", "comments": "A preliminary version of this paper has been accepted in the 24th\n  International Conference on Extending Database Technology (EDBT) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DC cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a system, entitled Concealer that allows sharing\ntime-varying spatial data (e.g., as produced by sensors) in encrypted form to\nan untrusted third-party service provider to provide location-based\napplications (involving aggregation queries over selected regions over time\nwindows) to users. Concealer exploits carefully selected encryption techniques\nto use indexes supported by database systems and combines ways to add fake\ntuples in order to realize an efficient system that protects against leakage\nbased on output-size. Thus, the design of Concealer overcomes two limitations\nof existing symmetric searchable encryption (SSE) techniques: (i) it avoids the\nneed of specialized data structures that limit usability/practicality of SSE in\nlarge scale deployments, and (ii) it avoids information leakages based on the\noutput-size, which may leak data distributions. Experimental results validate\nthe efficiency of the proposed algorithms over a spatial time-series dataset\n(collected from a smart space) and TPC-H datasets, each of 136 Million rows,\nthe size of which prior approaches have not scaled to.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 03:28:25 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Gupta", "Peeyush", ""], ["Mehrotra", "Sharad", ""], ["Sharma", "Shantanu", ""], ["Venkatasubramanian", "Nalini", ""], ["Wang", "Guoxi", ""]]}, {"id": "2102.05297", "submitter": "Ji\\v{r}\\'i Filipovi\\v{c}", "authors": "Ji\\v{r}\\'i Filipovi\\v{c} and Jana Hozzov\\'a and Amin Nezarat and\n  Jaroslav O\\v{l}ha and Filip Petrovi\\v{c}", "title": "Using hardware performance counters to speed up autotuning convergence\n  on GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, GPU accelerators are commonly used to speed up general-purpose\ncomputing tasks on a variety of hardware. However, due to the diversity of GPU\narchitectures and processed data, optimization of codes for a particular type\nof hardware and specific data characteristics can be extremely challenging. The\nautotuning of performance-relevant source-code parameters allows for automatic\noptimization of applications and keeps their performance portable. Although the\nautotuning process typically results in code speed-up, searching the tuning\nspace can bring unacceptable overhead if (i) the tuning space is vast and full\nof poorly-performing implementations, or (ii) the autotuning process has to be\nrepeated frequently because of changes in processed data or migration to\ndifferent hardware.\n  In this paper, we introduce a novel method for searching tuning spaces. The\nmethod takes advantage of collecting hardware performance counters (also known\nas profiling counters) during empirical tuning. Those counters are used to\nnavigate the searching process towards faster implementations. The method\nrequires the tuning space to be sampled on any GPU. It builds a\nproblem-specific model, which can be used during autotuning on various, even\npreviously unseen inputs or GPUs. Using a set of five benchmarks, we\nexperimentally demonstrate that our method can speed up autotuning when an\napplication needs to be ported to different hardware or when it needs to\nprocess data with different characteristics. We also compared our method to\nstate of the art and show that our method is superior in terms of the number of\nsearching steps and typically outperforms other searches in terms of\nconvergence time.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 07:42:39 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Filipovi\u010d", "Ji\u0159\u00ed", ""], ["Hozzov\u00e1", "Jana", ""], ["Nezarat", "Amin", ""], ["O\u013eha", "Jaroslav", ""], ["Petrovi\u010d", "Filip", ""]]}, {"id": "2102.05299", "submitter": "Ji\\v{r}\\'i Filipovi\\v{c}", "authors": "Ji\\v{r}\\'i Filipovi\\v{c} and Jana Hozzov\\'a and Amin Nezarat and\n  Jaroslav O\\v{l}ha and Filip Petrovi\\v{c}", "title": "Searching CUDA code autotuning spaces with hardware performance\n  counters: data from benchmarks running on various GPU architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed several autotuning benchmarks in CUDA that take into\naccount performance-relevant source-code parameters and reach near\npeak-performance on various GPU architectures. We have used them during the\ndevelopment and evaluation of a novel search method for tuning space proposed\nin [1]. With our framework Kernel Tuning Toolkit, freely available at Github,\nwe measured computation times and hardware performance counters on several GPUs\nfor the complete tuning spaces of five benchmarks. These data, which we provide\nhere, might benefit research of search algorithms for the tuning spaces of GPU\ncodes or research of relation between applied code optimization, hardware\nperformance counters, and GPU kernels' performance.\n  Moreover, we describe the scripts we used for robust evaluation of our\nsearcher and comparison to others in detail. In particular, the script that\nsimulates the tuning, i.e., replaces time-demanding compiling and executing the\ntuned kernels with a quick reading of the computation time from our measured\ndata, makes it possible to inspect the convergence of tuning search over a\nlarge number of experiments. These scripts, freely available with our other\ncodes, make it easier to experiment with search algorithms and compare them in\na robust way.\n  During our research, we generated models for predicting values of performance\ncounters from values of tuning parameters of our benchmarks. Here, we provide\nthe models themselves and describe the scripts we implemented for their\ntraining. These data might benefit researchers who want to reproduce or build\non our research.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 07:51:09 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Filipovi\u010d", "Ji\u0159\u00ed", ""], ["Hozzov\u00e1", "Jana", ""], ["Nezarat", "Amin", ""], ["O\u013eha", "Jaroslav", ""], ["Petrovi\u010d", "Filip", ""]]}, {"id": "2102.05301", "submitter": "Daniel Anderson", "authors": "Daniel Anderson and Guy E. Blelloch", "title": "Parallel Minimum Cuts in $O(m \\log^2(n))$ Work and Low Depth", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an $O(m \\log^2(n))$ work, $O(\\text{polylog}(n))$ depth parallel\nalgorithm for minimum cut. This algorithm matches the work of a recent\nsequential algorithm by Gawrychowski, Mozes, and Weimann [ICALP'20, (2020),\n57:1-57:15], and improves on the previously best known parallel algorithm by\nGeissmann and Gianinazzi [SPAA'18, (2018), pp. 1-11] which performs $O(m\n\\log^4(n))$ work in $O(\\text{polylog}(n))$ depth.\n  Our algorithm makes use of three components that might be of independent\ninterest. Firstly, we design a parallel data structure for dynamic trees that\nsolves mixed batches of queries and weight updates in low depth. It generalizes\nand improves the work bounds of a previous data structure of Geissmann and\nGianinazzi and is work efficient with respect to the best sequential algorithm.\nSecondly, we design a parallel algorithm for approximate minimum cut that\nimproves on previous results by Karger and Motwani. We use this algorithm to\ngive a work-efficient procedure to produce a tree packing, as in Karger's\nsequential algorithm for minimum cuts. Lastly, we design a work-efficient\nparallel algorithm for solving the minimum $2$-respecting cut problem.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 07:56:02 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Anderson", "Daniel", ""], ["Blelloch", "Guy E.", ""]]}, {"id": "2102.05504", "submitter": "Joaquim Silva", "authors": "Joaquim Silva, Eduardo R.B. Marques, Lu\\'is M.B Lopes, Fernando Silva", "title": "Energy-Aware Adaptive Offloading of Soft Real-Time Jobs in Mobile Edge\n  Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We present a model for measuring the impact of offloading soft real-time jobs\nover multi-tier cloud infrastructures. The jobs originate in mobile devices and\noffloading strategies may choose to execute them locally, in neighbouring\ndevices, in cloudlets or in infrastructure cloud servers. Within this\nspecification, we put forward several such offloading strategies characterised\nby their differential use of the cloud tiers with the goal of optimizing\nexecution time and/or energy consumption. We implement an instance of the model\nusing Jay, a software framework for adaptive computation offloading in hybrid\nedge clouds. The framework is modular and allows the model and the offloading\nstrategies to be seamlessly implemented while providing the tools to make\ninformed runtime offloading decisions based on system feedback, namely through\na built-in system profiler that gathers runtime information such as workload,\nenergy consumption and available bandwidth for every participating device or\nserver. The results show that offloading strategies sensitive to runtime\nconditions can effectively and dynamically adjust their offloading decisions to\nproduce significant gains in terms of their target optimization functions,\nnamely, execution time, energy consumption and fulfillment of job deadlines.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 15:47:25 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 10:05:40 GMT"}], "update_date": "2021-06-03", "authors_parsed": [["Silva", "Joaquim", ""], ["Marques", "Eduardo R. B.", ""], ["Lopes", "Lu\u00eds M. B", ""], ["Silva", "Fernando", ""]]}, {"id": "2102.05559", "submitter": "Ilja Behnke", "authors": "Ilja Behnke, Lukas Pirl, Lauritz Thamsen, Robert Danicki, Andreas\n  Polze, Odej Kao", "title": "Interrupting Real-Time IoT Tasks: How Bad Can It Be to Connect Your\n  Critical Embedded System to the Internet?", "comments": "IPCCC 2020: 39th International Performance Computing and\n  Communications Conference", "journal-ref": "39th International Performance Computing and Communications\n  Conference (IPCCC), IEEE, 2020, pp. 1-6", "doi": "10.1109/IPCCC50635.2020.9391536", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded systems have been used to control physical environments for decades.\nUsually, such use cases require low latencies between commands and actions as\nwell as a high predictability of the expected worst-case delay. To achieve this\non small, low-powered microcontrollers, Real-Time Operating Systems (RTOSs) are\nused to manage the different tasks on these machines as deterministically as\npossible. However, with the advent of the Internet of Things (IoT) in\nindustrial applications, the same embedded systems are now equipped with\nnetworking capabilities, possibly endangering critical real-time systems\nthrough an open gate to interrupts. This paper presents our initial study of\nthe impact network connections can have on real-time embedded systems.\nSpecifically, we look at three aspects: The impact of network-generated\ninterrupts, the overhead of the related networking tasks, and the feasibility\nof sharing computing resources between networking and real-time tasks. We\nconducted experiments on two setups: One treating NICs and drivers as black\nboxes and one simulating network interrupts on the machines. The preliminary\nresults show that a critical task performance loss of up to 6.67% per received\npacket per second could be induced where lateness impacts of 1% per packet per\nsecond can be attributed exclusively to ISR-generated delays.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 16:42:27 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 11:14:42 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Behnke", "Ilja", ""], ["Pirl", "Lukas", ""], ["Thamsen", "Lauritz", ""], ["Danicki", "Robert", ""], ["Polze", "Andreas", ""], ["Kao", "Odej", ""]]}, {"id": "2102.05561", "submitter": "Omid Aramoon", "authors": "Omid Aramoon, Pin-Yu Chen, Gang Qu, Yuan Tian", "title": "Meta Federated Learning", "comments": "11 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to its distributed methodology alongside its privacy-preserving features,\nFederated Learning (FL) is vulnerable to training time adversarial attacks. In\nthis study, our focus is on backdoor attacks in which the adversary's goal is\nto cause targeted misclassifications for inputs embedded with an adversarial\ntrigger while maintaining an acceptable performance on the main learning task\nat hand. Contemporary defenses against backdoor attacks in federated learning\nrequire direct access to each individual client's update which is not feasible\nin recent FL settings where Secure Aggregation is deployed. In this study, we\nseek to answer the following question, Is it possible to defend against\nbackdoor attacks when secure aggregation is in place?, a question that has not\nbeen addressed by prior arts. To this end, we propose Meta Federated Learning\n(Meta-FL), a novel variant of federated learning which not only is compatible\nwith secure aggregation protocol but also facilitates defense against backdoor\nattacks. We perform a systematic evaluation of Meta-FL on two classification\ndatasets: SVHN and GTSRB. The results show that Meta-FL not only achieves\nbetter utility than classic FL, but also enhances the performance of\ncontemporary defenses in terms of robustness against adversarial attacks.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 16:48:32 GMT"}], "update_date": "2021-02-11", "authors_parsed": [["Aramoon", "Omid", ""], ["Chen", "Pin-Yu", ""], ["Qu", "Gang", ""], ["Tian", "Yuan", ""]]}, {"id": "2102.05715", "submitter": "Sai Aparna Aketi", "authors": "Sai Aparna Aketi, Amandeep Singh, Jan Rabaey", "title": "Sparse-Push: Communication- & Energy-Efficient Decentralized Distributed\n  Learning over Directed & Time-Varying Graphs with non-IID Datasets", "comments": "12 pages, 7 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current deep learning (DL) systems rely on a centralized computing paradigm\nwhich limits the amount of available training data, increases system latency,\nand adds privacy and security constraints. On-device learning, enabled by\ndecentralized and distributed training of DL models over peer-to-peer\nwirelessly connected edge devices, not only alleviate the above limitations but\nalso enable next-gen applications that need DL models to continuously interact\nand learn from their environment. However, this necessitates the development of\nnovel training algorithms that train DL models over time-varying and directed\npeer-to-peer graph structures while minimizing the amount of communication\nbetween the devices and also being resilient to non-IID data distributions. In\nthis work we propose, Sparse-Push, a communication efficient decentralized\ndistributed training algorithm that supports training over peer-to-peer,\ndirected, and time-varying graph topologies. The proposed algorithm enables\n466x reduction in communication with only 1% degradation in performance when\ntraining various DL models such as ResNet-20 and VGG11 over the CIFAR-10\ndataset. Further, we demonstrate how communication compression can lead to\nsignificant performance degradation in-case of non-IID datasets, and propose\nSkew-Compensated Sparse Push algorithm that recovers this performance drop\nwhile maintaining similar levels of communication compression.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 19:41:11 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2021 02:05:24 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Aketi", "Sai Aparna", ""], ["Singh", "Amandeep", ""], ["Rabaey", "Jan", ""]]}, {"id": "2102.05743", "submitter": "Sakira Hassan", "authors": "Sakira Hassan, Simo S\\\"arkk\\\"a and \\'Angel F. Garc\\'ia-Fern\\'andez", "title": "Temporal Parallelization of Inference in Hidden Markov Models", "comments": "submitted to the IEEE transactions on Signal Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents algorithms for parallelization of inference in hidden\nMarkov models (HMMs). In particular, we propose parallel backward-forward type\nof filtering and smoothing algorithm as well as parallel Viterbi-type\nmaximum-a-posteriori (MAP) algorithm. We define associative elements and\noperators to pose these inference problems as parallel-prefix-sum computations\nin sum-product and max-product algorithms and parallelize them using\nparallel-scan algorithms. The advantage of the proposed algorithms is that they\nare computationally efficient in HMM inference problems with long time\nhorizons. We empirically compare the performance of the proposed methods to\nclassical methods on a highly parallel graphical processing unit (GPU).\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 21:26:09 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Hassan", "Sakira", ""], ["S\u00e4rkk\u00e4", "Simo", ""], ["Garc\u00eda-Fern\u00e1ndez", "\u00c1ngel F.", ""]]}, {"id": "2102.05888", "submitter": "Michael Schirner", "authors": "Michael Schirner, Lia Domide, Dionysios Perdikis, Paul Triebkorn, Leon\n  Stefanovski, Roopa Pai, Paula Popa, Bogdan Valean, Jessica Palmer, Chlo\\^e\n  Langford, Andr\\'e Blickensd\\\"orfer, Michiel van der Vlag, Sandra Diaz-Pier,\n  Alexander Peyser, Wouter Klijn, Dirk Pleiter, Anne Nahm, Oliver Schmid,\n  Marmaduke Woodman, Lyuba Zehl, Jan Fousek, Spase Petkoski, Lionel Kusch,\n  Meysam Hashemi, Daniele Marinazzo, Jean-Fran\\c{c}ois Mangin, Agnes Fl\\\"oel,\n  Simisola Akintoye, Bernd Carsten Stahl, Michael Cepic, Emily Johnson, Gustavo\n  Deco, Anthony R. McIntosh, Claus C. Hilgetag, Marc Morgan, Bernd Schuller,\n  Alex Upton, Colin McMurtrie, Timo Dickscheid, Jan G. Bjaalie, Katrin Amunts,\n  Jochen Mersmann, Viktor Jirsa, Petra Ritter", "title": "Brain Modelling as a Service: The Virtual Brain on EBRAINS", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.CR cs.DC q-bio.NC q-bio.QM", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Virtual Brain (TVB) is now available as open-source cloud ecosystem on\nEBRAINS, a shared digital research platform for brain science. It offers\nservices for constructing, simulating and analysing brain network models (BNMs)\nincluding the TVB network simulator; magnetic resonance imaging (MRI)\nprocessing pipelines to extract structural and functional connectomes;\nmultiscale co-simulation of spiking and large-scale networks; a domain specific\nlanguage for automatic high-performance code generation from user-specified\nmodels; simulation-ready BNMs of patients and healthy volunteers; Bayesian\ninference of epilepsy spread; data and code for mouse brain simulation; and\nextensive educational material. TVB cloud services facilitate reproducible\nonline collaboration and discovery of data assets, models, and software\nembedded in scalable and secure workflows, a precondition for research on large\ncohort data sets, better generalizability and clinical translation.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 08:33:50 GMT"}, {"version": "v2", "created": "Mon, 29 Mar 2021 11:22:38 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Schirner", "Michael", ""], ["Domide", "Lia", ""], ["Perdikis", "Dionysios", ""], ["Triebkorn", "Paul", ""], ["Stefanovski", "Leon", ""], ["Pai", "Roopa", ""], ["Popa", "Paula", ""], ["Valean", "Bogdan", ""], ["Palmer", "Jessica", ""], ["Langford", "Chlo\u00ea", ""], ["Blickensd\u00f6rfer", "Andr\u00e9", ""], ["van der Vlag", "Michiel", ""], ["Diaz-Pier", "Sandra", ""], ["Peyser", "Alexander", ""], ["Klijn", "Wouter", ""], ["Pleiter", "Dirk", ""], ["Nahm", "Anne", ""], ["Schmid", "Oliver", ""], ["Woodman", "Marmaduke", ""], ["Zehl", "Lyuba", ""], ["Fousek", "Jan", ""], ["Petkoski", "Spase", ""], ["Kusch", "Lionel", ""], ["Hashemi", "Meysam", ""], ["Marinazzo", "Daniele", ""], ["Mangin", "Jean-Fran\u00e7ois", ""], ["Fl\u00f6el", "Agnes", ""], ["Akintoye", "Simisola", ""], ["Stahl", "Bernd Carsten", ""], ["Cepic", "Michael", ""], ["Johnson", "Emily", ""], ["Deco", "Gustavo", ""], ["McIntosh", "Anthony R.", ""], ["Hilgetag", "Claus C.", ""], ["Morgan", "Marc", ""], ["Schuller", "Bernd", ""], ["Upton", "Alex", ""], ["McMurtrie", "Colin", ""], ["Dickscheid", "Timo", ""], ["Bjaalie", "Jan G.", ""], ["Amunts", "Katrin", ""], ["Mersmann", "Jochen", ""], ["Jirsa", "Viktor", ""], ["Ritter", "Petra", ""]]}, {"id": "2102.06006", "submitter": "Fukuhito Ooshita", "authors": "Shota Nagahama, Fukuhito Ooshita, Michiko Inoue", "title": "Terminating grid exploration with myopic luminous robots", "comments": "39 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the terminating grid exploration for autonomous myopic\nluminous robots. Myopic robots mean that they can observe nodes only within a\ncertain fixed distance, and luminous robots mean that they have light devices\nthat can emit colors. First, we prove that, in the semi-synchronous and\nasynchronous models, three myopic robots are necessary to achieve the\nterminating grid exploration if the visible distance is one. Next, we give\nfourteen algorithms for the terminating grid exploration in various assumptions\nof synchrony (fully-synchronous, semi-synchronous, and asynchronous models),\nvisible distance, the number of colors, and a chirality. Six of them are\noptimal in terms of the number of robots.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 13:52:33 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Nagahama", "Shota", ""], ["Ooshita", "Fukuhito", ""], ["Inoue", "Michiko", ""]]}, {"id": "2102.06035", "submitter": "Raphael Berthier", "authors": "Rapha\\\"el Berthier (PSL, SIERRA), Francis Bach (SIERRA, PSL), Nicolas\n  Flammarion, Pierre Gaillard (UGA), Adrien Taylor (SIERRA, PSL)", "title": "A Continuized View on Nesterov Acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the \"continuized\" Nesterov acceleration, a close variant of\nNesterov acceleration whose variables are indexed by a continuous time\nparameter. The two variables continuously mix following a linear ordinary\ndifferential equation and take gradient steps at random times. This continuized\nvariant benefits from the best of the continuous and the discrete frameworks:\nas a continuous process, one can use differential calculus to analyze\nconvergence and obtain analytical expressions for the parameters; but a\ndiscretization of the continuized process can be computed exactly with\nconvergence rates similar to those of Nesterov original acceleration. We show\nthat the discretization has the same structure as Nesterov acceleration, but\nwith random parameters.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 14:20:12 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Berthier", "Rapha\u00ebl", "", "PSL, SIERRA"], ["Bach", "Francis", "", "SIERRA, PSL"], ["Flammarion", "Nicolas", "", "UGA"], ["Gaillard", "Pierre", "", "UGA"], ["Taylor", "Adrien", "", "SIERRA, PSL"]]}, {"id": "2102.06094", "submitter": "Morgan Geldenhuys", "authors": "Morgan Geldenhuys, Lauritz Thamsen, Kain Kordian Gontarska, Felix\n  Lorenz, Odej Kao", "title": "Effectively Testing System Configurations of Critical IoT Analytics\n  Pipelines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The emergence of the Internet of Things has seen the introduction of numerous\nconnected devices used for the monitoring and control of even Critical\nInfrastructures. Distributed stream processing has become key to analyzing data\ngenerated by these connected devices and improving our ability to make\ndecisions. However, optimizing these systems towards specific Quality of\nService targets is a difficult and time-consuming task, due to the large-scale\ndistributed systems involved, the existence of so many configuration\nparameters, and the inability to easily determine the impact of tuning these\nparameters.\n  In this paper we present an approach for the effective testing of system\nconfigurations for critical IoT analytics pipelines. We demonstrate our\napproach with a prototype that we called Timon which is integrated with\nKubernetes. This tool allows pipelines to be easily replicated in parallel and\nevaluated to determine the optimal configuration for specific applications. We\ndemonstrate the usefulness of our approach by investigating different\nconfigurations of an exemplary geographically-based traffic monitoring\napplication implemented in Apache Flink.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 16:20:23 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2021 13:04:56 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Geldenhuys", "Morgan", ""], ["Thamsen", "Lauritz", ""], ["Gontarska", "Kain Kordian", ""], ["Lorenz", "Felix", ""], ["Kao", "Odej", ""]]}, {"id": "2102.06170", "submitter": "Morgan Geldenhuys", "authors": "Morgan Geldenhuys, Lauritz Thamsen, Odej Kao", "title": "Chiron: Optimizing Fault Tolerance in QoS-aware Distributed Stream\n  Processing Jobs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fault tolerance is a property which needs deeper consideration when dealing\nwith streaming jobs requiring high levels of availability and low-latency\nprocessing even in case of failures where Quality-of-Service constraints must\nbe adhered to. Typically, systems achieve fault tolerance and the ability to\nrecover automatically from partial failures by implementing Checkpoint and\nRollback Recovery. However, this is an expensive operation which impacts\nnegatively on the overall performance of the system and manually optimizing\nfault tolerance for specific jobs is a difficult and time consuming task.\n  In this paper we introduce Chiron, an approach for automatically optimizing\nthe frequency with which checkpoints are performed in streaming jobs. For any\nchosen job, parallel profiling runs are performed, each containing a variant of\nthe configurations, with the resulting metrics used to model the impact of\ncheckpoint-based fault tolerance on performance and availability. Understanding\nthese relationships is key to minimizing performance objectives and meeting\nstrict Quality-of-Service constraints. We implemented Chiron prototypically\ntogether with Apache Flink and demonstrate its usefulness experimentally.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 18:20:44 GMT"}], "update_date": "2021-02-12", "authors_parsed": [["Geldenhuys", "Morgan", ""], ["Thamsen", "Lauritz", ""], ["Kao", "Odej", ""]]}, {"id": "2102.06243", "submitter": "Yuping Fan", "authors": "Yuping Fan, Zhiling Lan, Taylor Childers, Paul Rich, William Allcock\n  and Michael E. Papka", "title": "Deep Reinforcement Agent for Scheduling in HPC", "comments": "Accepted by IPDPS 2021", "journal-ref": "35th IEEE International Parallel & Distributed Processing\n  Symposium (2021)", "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cluster scheduler is crucial in high-performance computing (HPC). It\ndetermines when and which user jobs should be allocated to available system\nresources. Existing cluster scheduling heuristics are developed by human\nexperts based on their experience with specific HPC systems and workloads.\nHowever, the increasing complexity of computing systems and the highly dynamic\nnature of application workloads have placed tremendous burden on manually\ndesigned and tuned scheduling heuristics. More aggressive optimization and\nautomation are needed for cluster scheduling in HPC. In this work, we present\nan automated HPC scheduling agent named DRAS (Deep Reinforcement Agent for\nScheduling) by leveraging deep reinforcement learning. DRAS is built on a\nnovel, hierarchical neural network incorporating special HPC scheduling\nfeatures such as resource reservation and backfilling. A unique training\nstrategy is presented to enable DRAS to rapidly learn the target environment.\nOnce being provided a specific scheduling objective given by system manager,\nDRAS automatically learns to improve its policy through interaction with the\nscheduling environment and dynamically adjusts its policy as workload changes.\nThe experiments with different production workloads demonstrate that DRAS\noutperforms the existing heuristic and optimization approaches by up to 45%.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 20:08:38 GMT"}, {"version": "v2", "created": "Mon, 19 Apr 2021 22:31:44 GMT"}], "update_date": "2021-04-21", "authors_parsed": [["Fan", "Yuping", ""], ["Lan", "Zhiling", ""], ["Childers", "Taylor", ""], ["Rich", "Paul", ""], ["Allcock", "William", ""], ["Papka", "Michael E.", ""]]}, {"id": "2102.06280", "submitter": "Jian Li", "authors": "Guojun Xiong, Gang Yan, Rahul Singh, Jian Li", "title": "Straggler-Resilient Distributed Machine Learning with Dynamic Backup\n  Workers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing demand for large-scale training of machine learning\nmodels, consensus-based distributed optimization methods have recently been\nadvocated as alternatives to the popular parameter server framework. In this\nparadigm, each worker maintains a local estimate of the optimal parameter\nvector, and iteratively updates it by waiting and averaging all estimates\nobtained from its neighbors, and then corrects it on the basis of its local\ndataset. However, the synchronization phase can be time consuming due to the\nneed to wait for \\textit{stragglers}, i.e., slower workers. An efficient way to\nmitigate this effect is to let each worker wait only for updates from the\nfastest neighbors before updating its local parameter. The remaining neighbors\nare called \\textit{backup workers.} To minimize the globally training time over\nthe network, we propose a fully distributed algorithm to dynamically determine\nthe number of backup workers for each worker. We show that our algorithm\nachieves a linear speedup for convergence (i.e., convergence performance\nincreases linearly with respect to the number of workers). We conduct extensive\nexperiments on MNIST and CIFAR-10 to verify our theoretical results.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2021 21:39:53 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Xiong", "Guojun", ""], ["Yan", "Gang", ""], ["Singh", "Rahul", ""], ["Li", "Jian", ""]]}, {"id": "2102.06329", "submitter": "Xingyu Li", "authors": "Xingyu Li, Zhe Qu, Bo Tang, Zhuo Lu", "title": "Stragglers Are Not Disaster: A Hybrid Federated Learning Algorithm with\n  Delayed Gradients", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is a new machine learning framework which trains a\njoint model across a large amount of decentralized computing devices. Existing\nmethods, e.g., Federated Averaging (FedAvg), are able to provide an\noptimization guarantee by synchronously training the joint model, but usually\nsuffer from stragglers, i.e., IoT devices with low computing power or\ncommunication bandwidth, especially on heterogeneous optimization problems. To\nmitigate the influence of stragglers, this paper presents a novel FL algorithm,\nnamely Hybrid Federated Learning (HFL), to achieve a learning balance in\nefficiency and effectiveness. It consists of two major components: synchronous\nkernel and asynchronous updater. Unlike traditional synchronous FL methods, our\nHFL introduces the asynchronous updater which actively pulls unsynchronized and\ndelayed local weights from stragglers. An adaptive approximation method,\nAdaptive Delayed-SGD (AD-SGD), is proposed to merge the delayed local updates\ninto the joint model. The theoretical analysis of HFL shows that the\nconvergence rate of the proposed algorithm is $\\mathcal{O}(\\frac{1}{t+\\tau})$\nfor both convex and non-convex optimization problems.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 02:27:44 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Li", "Xingyu", ""], ["Qu", "Zhe", ""], ["Tang", "Bo", ""], ["Lu", "Zhuo", ""]]}, {"id": "2102.06333", "submitter": "Charlie Hou", "authors": "Charlie Hou, Kiran K. Thekumparampil, Giulia Fanti, Sewoong Oh", "title": "Efficient Algorithms for Federated Saddle Point Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider strongly convex-concave minimax problems in the federated\nsetting, where the communication constraint is the main bottleneck. When\nclients are arbitrarily heterogeneous, a simple Minibatch Mirror-prox achieves\nthe best performance. As the clients become more homogeneous, using multiple\nlocal gradient updates at the clients significantly improves upon Minibatch\nMirror-prox by communicating less frequently. Our goal is to design an\nalgorithm that can harness the benefit of similarity in the clients while\nrecovering the Minibatch Mirror-prox performance under arbitrary heterogeneity\n(up to log factors). We give the first federated minimax optimization algorithm\nthat achieves this goal. The main idea is to combine (i) SCAFFOLD (an algorithm\nthat performs variance reduction across clients for convex optimization) to\nerase the worst-case dependency on heterogeneity and (ii) Catalyst (a framework\nfor acceleration based on modifying the objective) to accelerate convergence\nwithout amplifying client drift. We prove that this algorithm achieves our\ngoal, and include experiments to validate the theory.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 02:55:36 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Hou", "Charlie", ""], ["Thekumparampil", "Kiran K.", ""], ["Fanti", "Giulia", ""], ["Oh", "Sewoong", ""]]}, {"id": "2102.06486", "submitter": "Vanja Dosko\\v{c}", "authors": "Francesco Quinzan and Vanja Dosko\\v{c} and Andreas G\\\"obel and Tobias\n  Friedrich", "title": "Adaptive Sampling for Fast Constrained Maximization of Submodular\n  Function", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Several large-scale machine learning tasks, such as data summarization, can\nbe approached by maximizing functions that satisfy submodularity. These\noptimization problems often involve complex side constraints, imposed by the\nunderlying application. In this paper, we develop an algorithm with\npoly-logarithmic adaptivity for non-monotone submodular maximization under\ngeneral side constraints. The adaptive complexity of a problem is the minimal\nnumber of sequential rounds required to achieve the objective.\n  Our algorithm is suitable to maximize a non-monotone submodular function\nunder a $p$-system side constraint, and it achieves a $(p +\nO(\\sqrt{p}))$-approximation for this problem, after only poly-logarithmic\nadaptive rounds and polynomial queries to the valuation oracle function.\nFurthermore, our algorithm achieves a $(p + O(1))$-approximation when the given\nside constraint is a $p$-extendible system.\n  This algorithm yields an exponential speed-up, with respect to the\nadaptivity, over any other known constant-factor approximation algorithm for\nthis problem. It also competes with previous known results in terms of the\nquery complexity. We perform various experiments on various real-world\napplications. We find that, in comparison with commonly used heuristics, our\nalgorithm performs better on these instances.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 12:38:03 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Quinzan", "Francesco", ""], ["Dosko\u010d", "Vanja", ""], ["G\u00f6bel", "Andreas", ""], ["Friedrich", "Tobias", ""]]}, {"id": "2102.06614", "submitter": "Barath Raghavan", "authors": "Jennifer Switzer, Rob McGuinness, Pat Pannuto, George Porter, Aaron\n  Schulman, Barath Raghavan", "title": "TerraWatt: Sustaining Sustainable Computing of Containers in Containers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Each day the world inches closer to a climate catastrophe and a\nsustainability revolution. To avoid the former and achieve the latter we must\ntransform our use of energy. Surprisingly, today's growing problem is that\nthere is too much wind and solar power generation at the wrong times and in the\nwrong places.\n  We argue for the construction of TerraWatt: a geographically-distributed,\nlarge-scale, zero-carbon compute infrastructure using renewable energy and\nolder hardware. Delivering zero-carbon compute for general cloud workloads is\nchallenging due to spatiotemporal power variability. We describe the systems\nchallenges in using intermittent renewable power at scale to fuel such an\nolder, decentralized compute infrastructure.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 16:48:39 GMT"}], "update_date": "2021-02-15", "authors_parsed": [["Switzer", "Jennifer", ""], ["McGuinness", "Rob", ""], ["Pannuto", "Pat", ""], ["Porter", "George", ""], ["Schulman", "Aaron", ""], ["Raghavan", "Barath", ""]]}, {"id": "2102.06621", "submitter": "Alex Kogan", "authors": "Dave Dice and Alex Kogan", "title": "Optimizing Inference Performance of Transformers on CPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CL cs.AI cs.DC cs.LG cs.MS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  The Transformer architecture revolutionized the field of natural language\nprocessing (NLP). Transformers-based models (e.g., BERT) power many important\nWeb services, such as search, translation, question-answering, etc. While\nenormous research attention is paid to the training of those models, relatively\nlittle efforts are made to improve their inference performance. This paper\ncomes to address this gap by presenting an empirical analysis of scalability\nand performance of inferencing a Transformer-based model on CPUs. Focusing on\nthe highly popular BERT model, we identify key components of the Transformer\narchitecture where the bulk of the computation happens, and propose three\noptimizations to speed them up. The optimizations are evaluated using the\ninference benchmark from HuggingFace, and are shown to achieve the speedup of\nup to x2.37. The considered optimizations do not require any changes to the\nimplementation of the models nor affect their accuracy.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 17:01:35 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2021 22:30:35 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2021 16:54:34 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Dice", "Dave", ""], ["Kogan", "Alex", ""]]}, {"id": "2102.06752", "submitter": "Usman Khan", "authors": "Ran Xin and Usman A. Khan and Soummya Kar", "title": "A Hybrid Variance-Reduced Method for Decentralized Stochastic Non-Convex\n  Optimization", "comments": "Accepted in ICML 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG cs.MA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers decentralized stochastic optimization over a network of\n$n$ nodes, where each node possesses a smooth non-convex local cost function\nand the goal of the networked nodes is to find an $\\epsilon$-accurate\nfirst-order stationary point of the sum of the local costs. We focus on an\nonline setting, where each node accesses its local cost only by means of a\nstochastic first-order oracle that returns a noisy version of the exact\ngradient. In this context, we propose a novel single-loop decentralized hybrid\nvariance-reduced stochastic gradient method, called GT-HSGD, that outperforms\nthe existing approaches in terms of both the oracle complexity and practical\nimplementation. The GT-HSGD algorithm implements specialized local hybrid\nstochastic gradient estimators that are fused over the network to track the\nglobal gradient. Remarkably, GT-HSGD achieves a network topology-independent\noracle complexity of $O(n^{-1}\\epsilon^{-3})$ when the required error tolerance\n$\\epsilon$ is small enough, leading to a linear speedup with respect to the\ncentralized optimal online variance-reduced approaches that operate on a single\nnode. Numerical experiments are provided to illustrate our main technical\nresults.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 20:13:05 GMT"}, {"version": "v2", "created": "Mon, 14 Jun 2021 16:03:24 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Xin", "Ran", ""], ["Khan", "Usman A.", ""], ["Kar", "Soummya", ""]]}, {"id": "2102.06780", "submitter": "Amir Daneshmand", "authors": "Amir Daneshmand and Gesualdo Scutari and Pavel Dvurechensky and\n  Alexander Gasnikov", "title": "Newton Method over Networks is Fast up to the Statistical Precision", "comments": "In proceedings of the 38th International Conference on Machine\n  Learning, PMLR 139, 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a distributed cubic regularization of the Newton method for\nsolving (constrained) empirical risk minimization problems over a network of\nagents, modeled as undirected graph. The algorithm employs an inexact,\npreconditioned Newton step at each agent's side: the gradient of the\ncentralized loss is iteratively estimated via a gradient-tracking consensus\nmechanism and the Hessian is subsampled over the local data sets. No Hessian\nmatrices are thus exchanged over the network. We derive global complexity\nbounds for convex and strongly convex losses. Our analysis reveals an\ninteresting interplay between sample and iteration/communication complexity:\nstatistically accurate solutions are achievable in roughly the same number of\niterations of the centralized cubic Newton method, with a communication cost\nper iteration of the order of\n$\\widetilde{\\mathcal{O}}\\big(1/\\sqrt{1-\\rho}\\big)$, where $\\rho$ characterizes\nthe connectivity of the network. This demonstrates a significant communication\nsaving with respect to that of existing, statistically oblivious, distributed\nNewton-based methods over networks.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 21:24:56 GMT"}, {"version": "v2", "created": "Wed, 16 Jun 2021 04:06:18 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Daneshmand", "Amir", ""], ["Scutari", "Gesualdo", ""], ["Dvurechensky", "Pavel", ""], ["Gasnikov", "Alexander", ""]]}, {"id": "2102.06804", "submitter": "Alex Weaver", "authors": "Calvin Newport, Alex Weaver, Chaodong Zheng", "title": "Asynchronous Gossip in Smartphone Peer-to-Peer Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study gossip algorithms in communication models that\ndescribe the peer-to-peer networking functionality included in most standard\nsmartphone operating systems. We begin by describing and analyzing a new\nsynchronous gossip algorithm in this setting that features both a faster round\ncomplexity and simpler operation than the best-known existing solutions. We\nalso prove a new lower bound on the rounds required to solve gossip that\nresolves a minor open question by establishing that existing synchronous\nsolutions are within logarithmic factors of optimal. We then adapt our\nsynchronous algorithm to produce a novel gossip strategy for an asynchronous\nmodel that directly captures the interface of a standard smartphone\npeer-to-peer networking library (enabling algorithms described in this model to\nbe easily implemented on real phones). Using new analysis techniques, we prove\nthat this asynchronous strategy efficiently solves gossip. This is the first\nknown efficient asynchronous information dissemination result for the\nsmartphone peer-to-peer setting. We argue that our new strategy can be used to\nimplement effective information spreading subroutines in real world smartphone\npeer-to-peer network applications, and that the analytical tools we developed\nto analyze it can be leveraged to produce other broadly useful algorithmic\nstrategies for this increasingly important setting.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 22:40:15 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Newport", "Calvin", ""], ["Weaver", "Alex", ""], ["Zheng", "Chaodong", ""]]}, {"id": "2102.06894", "submitter": "Luanzheng Guo", "authors": "Luanzheng Guo, Giorgis Georgakoudis, Konstantinos Parasyris, Ignacio\n  Laguna, Dong Li", "title": "MATCH: An MPI Fault Tolerance Benchmark Suite", "comments": null, "journal-ref": "IEEE International Symposium on Workload Characterization (IISWC\n  2020)", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  MPI has been ubiquitously deployed in flagship HPC systems aiming to\naccelerate distributed scientific applications running on tens of hundreds of\nprocesses and compute nodes. Maintaining the correctness and integrity of MPI\napplication execution is critical, especially for safety-critical scientific\napplications. Therefore, a collection of effective MPI fault tolerance\ntechniques have been proposed to enable MPI application execution to\nefficiently resume from system failures. However, there is no structured way to\nstudy and compare different MPI fault tolerance designs, so to guide the\nselection and development of efficient MPI fault tolerance techniques for\ndistinct scenarios. To solve this problem, we design, develop, and evaluate a\nbenchmark suite called MATCH to characterize, research, and comprehensively\ncompare different combinations and configurations of MPI fault tolerance\ndesigns. Our investigation derives useful findings: (1) Reinit recovery in\ngeneral performs better than ULFM recovery; (2) Reinit recovery is independent\nof the scaling size and the input problem size, whereas ULFM recovery is not;\n(3) Using Reinit recovery with FTI checkpointing is a highly efficient fault\ntolerance design. MATCH code is available at https://github.com/kakulo/MPI- FT-\nBench.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 10:26:18 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Guo", "Luanzheng", ""], ["Georgakoudis", "Giorgis", ""], ["Parasyris", "Konstantinos", ""], ["Laguna", "Ignacio", ""], ["Li", "Dong", ""]]}, {"id": "2102.06896", "submitter": "Luanzheng Guo", "authors": "Giorgis Georgakoudis, Luanzheng Guo, Ignacio Laguna", "title": "Reinit++: Evaluating the Performance of Global-Restart Recovery Methods\n  For MPI Fault Tolerance", "comments": "International Conference on High Performance Computing (ISC 2020)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Scaling supercomputers comes with an increase in failure rates due to the\nincreasing number of hardware components. In standard practice, applications\nare made resilient through checkpointing data and restarting execution after a\nfailure occurs to resume from the latest check-point. However, re-deploying an\napplication incurs overhead by tearing down and re-instating execution, and\npossibly limiting checkpointing retrieval from slow permanent storage. In this\npaper we present Reinit++, a new design and implementation of the Reinit\napproach for global-restart recovery, which avoids application re-deployment.\nWe extensively evaluate Reinit++ contrasted with the leading MPI\nfault-tolerance approach of ULFM, implementing global-restart recovery, and the\ntypical practice of restarting an application to derive new insight on\nperformance. Experimentation with three different HPC proxy applications made\nresilient to withstand process and node failures shows that Reinit++ recovers\nmuch faster than restarting, up to 6x, or ULFM, up to 3x, and that it scales\nexcellently as the number of MPI processes grows.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 10:41:19 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Georgakoudis", "Giorgis", ""], ["Guo", "Luanzheng", ""], ["Laguna", "Ignacio", ""]]}, {"id": "2102.06899", "submitter": "Luanzheng Guo", "authors": "Luanzheng Guo, Dong Li", "title": "MOARD: Modeling Application Resilience to Transient Faults on Data\n  Objects", "comments": "arXiv admin note: text overlap with arXiv:1705.00267", "journal-ref": "IEEE International Parallel and Distributed Processing Symposium\n  (IPDPS 2019)", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Understanding application resilience (or error tolerance) in the presence of\nhardware transient faults on data objects is critical to ensure computing\nintegrity and enable efficient application-level fault tolerance mechanisms.\nHowever, we lack a method and a tool to quantify application resilience to\ntransient faults on data objects. The traditional method, random fault\ninjection, cannot help, because of losing data semantics and insufficient\ninformation on how and where errors are tolerated. In this paper, we introduce\na method and a tool (called MOARD) to model and quantify application resilience\nto transient faults on data objects. Our method is based on systematically\nquantifying error masking events caused by application-inherent semantics and\nprogram constructs. We use MOARD to study how and why errors in data objects\ncan be tolerated by the application. We demonstrate tangible benefits of using\nMOARD to direct a fault tolerance mechanism to protect data objects.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2021 10:57:18 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Guo", "Luanzheng", ""], ["Li", "Dong", ""]]}, {"id": "2102.07053", "submitter": "Aritra Mitra", "authors": "Aritra Mitra, Rayana Jaafar, George J. Pappas, and Hamed Hassani", "title": "Achieving Linear Convergence in Federated Learning under Objective and\n  Systems Heterogeneity", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.SY eess.SY math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We consider a standard federated learning architecture where a group of\nclients periodically coordinate with a central server to train a statistical\nmodel. We tackle two major challenges in federated learning: (i) objective\nheterogeneity, which stems from differences in the clients' local loss\nfunctions, and (ii) systems heterogeneity, which leads to slow and straggling\nclient devices. Due to such client heterogeneity, we show that existing\nfederated learning algorithms suffer from a fundamental speed-accuracy\nconflict: they either guarantee linear convergence but to an incorrect point,\nor convergence to the global minimum but at a sub-linear rate, i.e., fast\nconvergence comes at the expense of accuracy.\n  To address the above limitation, we propose FedLin - a simple, new algorithm\nthat exploits past gradients and employs client-specific learning rates. When\nthe clients' local loss functions are smooth and strongly convex, we show that\nFedLin guarantees linear convergence to the global minimum. We then establish\nmatching upper and lower bounds on the convergence rate of FedLin that\nhighlight the trade-offs associated with infrequent, periodic communication.\nNotably, FedLin is the only approach that is able to match centralized\nconvergence rates (up to constants) for smooth strongly convex, convex, and\nnon-convex loss functions despite arbitrary objective and systems\nheterogeneity. We further show that FedLin preserves linear convergence rates\nunder aggressive gradient sparsification, and quantify the effect of the\ncompression level on the convergence rate.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 02:47:35 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Mitra", "Aritra", ""], ["Jaafar", "Rayana", ""], ["Pappas", "George J.", ""], ["Hassani", "Hamed", ""]]}, {"id": "2102.07148", "submitter": "The Canh Dinh", "authors": "Canh T. Dinh, Tung T. Vu, Nguyen H. Tran, Minh N. Dao, Hongyu Zhang", "title": "FedU: A Unified Framework for Federated Multi-Task Learning with\n  Laplacian Regularization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated multi-task learning (FMTL) has emerged as a natural choice to\ncapture the statistical diversity among the clients in federated learning. To\nunleash the potential of FMTL beyond statistical diversity, we formulate a new\nFMTL problem FedU using Laplacian regularization, which can explicitly leverage\nrelationships among the clients for multi-task learning. We first show that\nFedU provides a unified framework covering a wide range of problems such as\nconventional federated learning, personalized federated learning, few-shot\nlearning, and stratified model learning. We then propose algorithms including\nboth communication-centralized and decentralized schemes to learn optimal\nmodels of FedU. Theoretically, we show that the convergence rates of both\nFedU's algorithms achieve linear speedup for strongly convex and sublinear\nspeedup of order $1/2$ for nonconvex objectives. While the analysis of FedU is\napplicable to both strongly convex and nonconvex loss functions, the\nconventional FMTL algorithm MOCHA, which is based on CoCoA framework, is only\napplicable to convex case. Experimentally, we verify that FedU outperforms the\nvanilla FedAvg, MOCHA, as well as pFedMe and Per-FedAvg in personalized\nfederated learning.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 13:19:43 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Dinh", "Canh T.", ""], ["Vu", "Tung T.", ""], ["Tran", "Nguyen H.", ""], ["Dao", "Minh N.", ""], ["Zhang", "Hongyu", ""]]}, {"id": "2102.07158", "submitter": "Peter Richt\\'arik", "authors": "Rustem Islamov and Xun Qian and Peter Richt\\'arik", "title": "Distributed Second Order Methods with Fast Rates and Compressed\n  Communication", "comments": "44 pages, 5 algorithms, 7 theorems, 7 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop several new communication-efficient second-order methods for\ndistributed optimization. Our first method, NEWTON-STAR, is a variant of\nNewton's method from which it inherits its fast local quadratic rate. However,\nunlike Newton's method, NEWTON-STAR enjoys the same per iteration communication\ncost as gradient descent. While this method is impractical as it relies on the\nuse of certain unknown parameters characterizing the Hessian of the objective\nfunction at the optimum, it serves as the starting point which enables us\ndesign practical variants thereof with strong theoretical guarantees. In\nparticular, we design a stochastic sparsification strategy for learning the\nunknown parameters in an iterative fashion in a communication efficient manner.\nApplying this strategy to NEWTON-STAR leads to our next method, NEWTON-LEARN,\nfor which we prove local linear and superlinear rates independent of the\ncondition number. When applicable, this method can have dramatically superior\nconvergence behavior when compared to state-of-the-art methods. Finally, we\ndevelop a globalization strategy using cubic regularization which leads to our\nnext method, CUBIC-NEWTON-LEARN, for which we prove global sublinear and linear\nconvergence rates, and a fast superlinear rate. Our results are supported with\nexperimental results on real datasets, and show several orders of magnitude\nimprovement on baseline and state-of-the-art methods in terms of communication\ncomplexity.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 14:06:45 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Islamov", "Rustem", ""], ["Qian", "Xun", ""], ["Richt\u00e1rik", "Peter", ""]]}, {"id": "2102.07199", "submitter": "Lauritz Thamsen", "authors": "Lauritz Thamsen, Ilya Verbitskiy, Sasho Nedelkoski, Vinh Thuy Tran,\n  Vinicius Meyer, Miguel G. Xavier, Odej Kao, Cesar A. F. De Rose", "title": "Hugo: A Cluster Scheduler that Efficiently Learns to Select\n  Complementary Data-Parallel Jobs", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-030-48340-1_40", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed data processing systems like MapReduce, Spark, and Flink are\npopular tools for analysis of large datasets with cluster resources. Yet, users\noften overprovision resources for their data processing jobs, while the\nresource usage of these jobs also typically fluctuates considerably. Therefore,\nmultiple jobs usually get scheduled onto the same shared resources to increase\nthe resource utilization and throughput of clusters. However, job runtimes and\nthe utilization of shared resources can vary significantly depending on the\nspecific combinations of co-located jobs.\n  This paper presents Hugo, a cluster scheduler that continuously learns how\nefficiently jobs share resources, considering metrics for the resource\nutilization and interference among co-located jobs. The scheduler combines\noffline grouping of jobs with online reinforcement learning to provide a\nscheduling mechanism that efficiently generalizes from specific monitored job\ncombinations yet also adapts to changes in workloads. Our evaluation of a\nprototype shows that the approach can reduce the runtimes of exemplary Spark\njobs on a YARN cluster by up to 12.5%, while resource utilization is increased\nand waiting times can be bounded.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 17:10:38 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Thamsen", "Lauritz", ""], ["Verbitskiy", "Ilya", ""], ["Nedelkoski", "Sasho", ""], ["Tran", "Vinh Thuy", ""], ["Meyer", "Vinicius", ""], ["Xavier", "Miguel G.", ""], ["Kao", "Odej", ""], ["De Rose", "Cesar A. F.", ""]]}, {"id": "2102.07214", "submitter": "Foivos Alimisis", "authors": "Foivos Alimisis, Peter Davies, Dan Alistarh", "title": "Communication-Efficient Distributed Optimization with Quantized\n  Preconditioners", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We investigate fast and communication-efficient algorithms for the classic\nproblem of minimizing a sum of strongly convex and smooth functions that are\ndistributed among $n$ different nodes, which can communicate using a limited\nnumber of bits. Most previous communication-efficient approaches for this\nproblem are limited to first-order optimization, and therefore have\n\\emph{linear} dependence on the condition number in their communication\ncomplexity. We show that this dependence is not inherent:\ncommunication-efficient methods can in fact have sublinear dependence on the\ncondition number. For this, we design and analyze the first\ncommunication-efficient distributed variants of preconditioned gradient descent\nfor Generalized Linear Models, and for Newton's method. Our results rely on a\nnew technique for quantizing both the preconditioner and the descent direction\nat each step of the algorithms, while controlling their convergence rate. We\nalso validate our findings experimentally, showing fast convergence and reduced\ncommunication.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 18:29:09 GMT"}, {"version": "v2", "created": "Thu, 17 Jun 2021 23:33:48 GMT"}], "update_date": "2021-06-21", "authors_parsed": [["Alimisis", "Foivos", ""], ["Davies", "Peter", ""], ["Alistarh", "Dan", ""]]}, {"id": "2102.07221", "submitter": "Volodymyr Polosukhin", "authors": "Keren Censor-Hillel, Yannic Maus, Volodymyr Polosukhin", "title": "Near-Optimal Scheduling in the Congested Clique", "comments": "To appear in SIROCCO 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper provides three nearly-optimal algorithms for scheduling $t$ jobs\nin the $\\mathsf{CLIQUE}$ model. First, we present a deterministic scheduling\nalgorithm that runs in $O(\\mathsf{GlobalCongestion} + \\mathsf{dilation})$\nrounds for jobs that are sufficiently efficient in terms of their memory. The\n$\\mathsf{dilation}$ is the maximum round complexity of any of the given jobs,\nand the $\\mathsf{GlobalCongestion}$ is the total number of messages in all jobs\ndivided by the per-round bandwidth of $n^2$ of the $\\mathsf{CLIQUE}$ model.\nBoth are inherent lower bounds for any scheduling algorithm.\n  Then, we present a randomized scheduling algorithm which runs $t$ jobs in\n$O(\\mathsf{GlobalCongestion} + \\mathsf{dilation}\\cdot\\log{n}+t)$ rounds and\nonly requires that inputs and outputs do not exceed $O(n\\log n)$ bits per node,\nwhich is met by, e.g., almost all graph problems. Lastly, we adjust the\n\\emph{random-delay-based} scheduling algorithm [Ghaffari, PODC'15] from the\n$\\mathsf{CLIQUE}$ model and obtain an algorithm that schedules any $t$ jobs in\n$O(t / n + \\mathsf{LocalCongestion} + \\mathsf{dilation}\\cdot\\log{n})$ rounds,\nwhere the $\\mathsf{LocalCongestion}$ relates to the congestion at a single node\nof the $\\mathsf{CLIQUE}$. We compare this algorithm to the previous approaches\nand show their benefit.\n  We schedule the set of jobs on-the-fly, without a priori knowledge of its\nparameters or the communication patterns of the jobs. In light of the inherent\nlower bounds, all of our algorithms are nearly-optimal.\n  We exemplify the power of our algorithms by analyzing the message complexity\nof the state-of-the-art MIS protocol [Ghaffari, Gouleakis, Konrad, Mitrovic and\nRubinfeld, PODC'18], and we show that we can solve $t$ instances of MIS in $O(t\n+ \\log\\log\\Delta\\log{n})$ rounds, that is, in $O(1)$ amortized time, for $t\\geq\n\\log\\log\\Delta\\log{n}$.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 18:55:25 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Maus", "Yannic", ""], ["Polosukhin", "Volodymyr", ""]]}, {"id": "2102.07240", "submitter": "Zhuolun Xiang", "authors": "Ittai Abraham, Kartik Nayak, Ling Ren, Zhuolun Xiang", "title": "Good-case Latency of Byzantine Broadcast: a Complete Categorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the problem good-case latency of Byzantine fault-tolerant\nbroadcast, motivated by the real-world latency and performance of practical\nstate machine replication protocols. The good-case latency measures the time it\ntakes for all non-faulty parties to commit when the designated broadcaster is\nnon-faulty. We provide a complete characterization of tight bounds on good-case\nlatency, in the authenticated setting under synchrony, partial synchrony and\nasynchrony. Some of our new results may be surprising, e.g., 2-round PBFT-style\npartially synchronous Byzantine broadcast is possible if and only if $n\\geq\n5f-1$, and a tight bound for good-case latency under $n/3<f<n/2$ under\nsynchrony is not an integer multiple of the delay bound.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 20:41:28 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 23:13:57 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Abraham", "Ittai", ""], ["Nayak", "Kartik", ""], ["Ren", "Ling", ""], ["Xiang", "Zhuolun", ""]]}, {"id": "2102.07477", "submitter": "Ahmed M. Abdelmoniem", "authors": "Ahmed M. Abdelmoniem and Brahim Bensaou", "title": "T-RACKs: A Faster Recovery Mechanism for TCP in Data Center Networks", "comments": "Accepted for Publication in ACM/IEEE Transactions on Networking (ToN)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud interactive data-driven applications generate swarms of small TCP flows\nthat compete for the small buffer space in data-center switches. Such\napplications require a short flow completion time (FCT) to perform their jobs\neffectively. However, TCP is oblivious to the composite nature of application\ndata and artificially inflates the FCT of such flows by several orders of\nmagnitude. This is due to TCP's Internet-centric design that fixes the\nretransmission timeout (RTO) to be at least hundreds of milliseconds. To better\nunderstand this problem, in this paper, we use empirical measurements in a\nsmall testbed to study, at a microscopic level, the effects of various types of\npacket losses on TCP's performance. In particular, we single out packet losses\nthat impact the tail end of small flows, as well as bursty losses, that span a\nsignificant fraction of the small congestion window of TCP flows in\ndata-centers, to show a non-negligible effect on the FCT. Based on this, we\npropose the so-called, timely-retransmitted ACKs (or T-RACKs), a simple loss\nrecovery mechanism to conceal the drawbacks of the long RTO even in the\npresence of heavy packet losses. Interestingly enough, T-RACKS achieves this\ntransparently to TCP itself as it does not require any change to TCP in the\ntenant's virtual machine (VM). T-RACKs can be implemented as a software shim\nlayer in the hypervisor between the VMs and server's NIC or in hardware as a\nnetworking function in a SmartNIC. Simulation and real testbed results show\nthat T-RACKs achieves remarkable performance improvements.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 11:36:33 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Abdelmoniem", "Ahmed M.", ""], ["Bensaou", "Brahim", ""]]}, {"id": "2102.07500", "submitter": "Ahmed Mohamed Abdelmoniem Sayed", "authors": "Ahmed M. Abdelmoniem and Chen-Yu Ho and Pantelis Papageorgiou and\n  Muhammad Bilal and Marco Canini", "title": "On the Impact of Device and Behavioral Heterogeneity in Federated\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated learning (FL) is becoming a popular paradigm for collaborative\nlearning over distributed, private datasets owned by non-trusting entities. FL\nhas seen successful deployment in production environments, and it has been\nadopted in services such as virtual keyboards, auto-completion, item\nrecommendation, and several IoT applications. However, FL comes with the\nchallenge of performing training over largely heterogeneous datasets, devices,\nand networks that are out of the control of the centralized FL server.\nMotivated by this inherent setting, we make a first step towards characterizing\nthe impact of device and behavioral heterogeneity on the trained model. We\nconduct an extensive empirical study spanning close to 1.5K unique\nconfigurations on five popular FL benchmarks. Our analysis shows that these\nsources of heterogeneity have a major impact on both model performance and\nfairness, thus sheds light on the importance of considering heterogeneity in FL\nsystem design.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 12:04:38 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Abdelmoniem", "Ahmed M.", ""], ["Ho", "Chen-Yu", ""], ["Papageorgiou", "Pantelis", ""], ["Bilal", "Muhammad", ""], ["Canini", "Marco", ""]]}, {"id": "2102.07511", "submitter": "Jinho Lee", "authors": "Heesu Kim, Hanmin Park, Taehyun Kim, Kwanheum Cho, Eojin Lee, Soojung\n  Ryu, Hyuk-Jae Lee, Kiyoung Choi, Jinho Lee", "title": "GradPIM: A Practical Processing-in-DRAM Architecture for Gradient\n  Descent", "comments": "Accepted to HPCA 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present GradPIM, a processing-in-memory architecture which\naccelerates parameter updates of deep neural networks training. As one of\nprocessing-in-memory techniques that could be realized in the near future, we\npropose an incremental, simple architectural design that does not invade the\nexisting memory protocol. Extending DDR4 SDRAM to utilize bank-group\nparallelism makes our operation designs in processing-in-memory (PIM) module\nefficient in terms of hardware cost and performance. Our experimental results\nshow that the proposed architecture can improve the performance of DNN training\nand greatly reduce memory bandwidth requirement while posing only a minimal\namount of overhead to the protocol and DRAM area.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 12:25:26 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Kim", "Heesu", ""], ["Park", "Hanmin", ""], ["Kim", "Taehyun", ""], ["Cho", "Kwanheum", ""], ["Lee", "Eojin", ""], ["Ryu", "Soojung", ""], ["Lee", "Hyuk-Jae", ""], ["Choi", "Kiyoung", ""], ["Lee", "Jinho", ""]]}, {"id": "2102.07528", "submitter": "Kaushik Mondal", "authors": "Anisur Rahaman Molla, Kaushik Mondal, William K. Moses Jr", "title": "Byzantine Dispersion on Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of Byzantine dispersion and extends previous\nwork along several parameters. The problem of Byzantine dispersion asks: given\n$n$ robots, up to $f$ of which are Byzantine, initially placed arbitrarily on\nan $n$ node anonymous graph, design a terminating algorithm to be run by the\nrobots such that they eventually reach a configuration where each node has at\nmost one non-Byzantine robot on it. Previous work solved this problem for rings\nand tolerated up to $n-1$ Byzantine robots. In this paper, we investigate the\nproblem on more general graphs.\n  We first develop an algorithm that tolerates up to $n-1$ Byzantine robots and\nworks for a more general class of graphs. We then develop an algorithm that\nworks for any graph but tolerates a lesser number of Byzantine robots. We\nsubsequently turn our focus to the strength of the Byzantine robots. Previous\nwork considers only \"weak\" Byzantine robots that cannot fake their IDs. We\ndevelop an algorithm that solves the problem when Byzantine robots are not weak\nand can fake IDs. Finally, we study the situation where the number of the\nrobots is not $n$ but some $k$. We show that in such a scenario, the number of\nByzantine robots that can be tolerated is severely restricted. Specifically, we\nshow that it is impossible to deterministically solve Byzantine dispersion when\n$\\lceil k/n \\rceil > \\lceil (k-f)/n \\rceil$.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 13:01:28 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Molla", "Anisur Rahaman", ""], ["Mondal", "Kaushik", ""], ["Moses", "William K.", "Jr"]]}, {"id": "2102.07627", "submitter": "Xinchi Qiu", "authors": "Xinchi Qiu, Titouan Parcollet, Javier Fernandez-Marques, Pedro Porto\n  Buarque de Gusmao, Daniel J. Beutel, Taner Topal, Akhil Mathur, Nicholas D.\n  Lane", "title": "A first look into the carbon footprint of federated learning", "comments": "arXiv admin note: substantial text overlap with arXiv:2010.06537", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Despite impressive results, deep learning-based technologies also raise\nsevere privacy and environmental concerns induced by the training procedure\noften conducted in datacenters. In response, alternatives to centralized\ntraining such as Federated Learning (FL) have emerged. Perhaps unexpectedly,\nFL, in particular, is starting to be deployed at a global scale by companies\nthat must adhere to new legal demands and policies originating from governments\nand civil society for privacy protection. However, the potential environmental\nimpact related to FL remains unclear and unexplored. This paper offers the\nfirst-ever systematic study of the carbon footprint of FL. First, we propose a\nrigorous model to quantify the carbon footprint, hence facilitating the\ninvestigation of the relationship between FL design and carbon emissions. Then,\nwe compare the carbon footprint of FL to traditional centralized learning. Our\nfindings show that FL, despite being slower to converge in some cases, may\nresult in a comparatively greener impact than a centralized equivalent setup.\nWe performed extensive experiments across different types of datasets,\nsettings, and various deep learning models with FL. Finally, we highlight and\nconnect the reported results to the future challenges and trends in FL to\nreduce its environmental impact, including algorithms efficiency, hardware\ncapabilities, and stronger industry transparency.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 16:08:02 GMT"}, {"version": "v2", "created": "Wed, 12 May 2021 13:41:55 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 10:38:43 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Qiu", "Xinchi", ""], ["Parcollet", "Titouan", ""], ["Fernandez-Marques", "Javier", ""], ["de Gusmao", "Pedro Porto Buarque", ""], ["Beutel", "Daniel J.", ""], ["Topal", "Taner", ""], ["Mathur", "Akhil", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2102.07674", "submitter": "Tom Cornebize", "authors": "Tom Cornebize (POLARIS, UGA), Arnaud Legrand (CNRS, POLARIS)", "title": "Simulation-based Optimization and Sensibility Analysis of MPI\n  Applications: Variability Matters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finely tuning MPI applications and understanding the influence of\nkeyparameters (number of processes, granularity, collective\noperationalgorithms, virtual topology, and process placement) is critical\ntoobtain good performance on supercomputers. With the high consumptionof\nrunning applications at scale, doing so solely to optimize theirperformance is\nparticularly costly. Havinginexpensive but faithful predictions of expected\nperformance could bea great help for researchers and system administrators.\nThemethodology we propose decouples the complexity of the platform, whichis\ncaptured through statistical models of the performance of its maincomponents\n(MPI communications, BLAS operations), from the complexityof adaptive\napplications by emulating the application and skippingregular non-MPI parts of\nthe code. We demonstrate the capability of our method with\nHigh-PerformanceLinpack (HPL), the benchmark used to rank supercomputers in\ntheTOP500, which requires careful tuning. We briefly present (1) how\ntheopen-source version of HPL can be slightly modified to allow a fastemulation\non a single commodity server at the scale of asupercomputer. Then we present\n(2) an extensive (in)validation studythat compares simulation with real\nexperiments and demonstrates our ability to predict theperformance of HPL\nwithin a few percent consistently. This study allows us toidentify the main\nmodeling pitfalls (e.g., spatial and temporal nodevariability or network\nheterogeneity and irregular behavior) that needto be considered. Last, we show\n(3) how our ``surrogate'' allowsstudying several subtle HPL parameter\noptimization problems whileaccounting for uncertainty on the platform.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 17:00:04 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Cornebize", "Tom", "", "POLARIS, UGA"], ["Legrand", "Arnaud", "", "CNRS, POLARIS"]]}, {"id": "2102.07731", "submitter": "Johannes Sedlmeir", "authors": "Tobias Guggenberger and Johannes Sedlmeir and Gilbert Fridgen and\n  Andr\\'e Luckow", "title": "An In-Depth Investigation of Performance Characteristics of Hyperledger\n  Fabric", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.CR cs.DB cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Private permissioned blockchains, such as Hyperledger Fabric, are widely\ndeployed across the industry to facilitate cross-organizational processes and\npromise improved performance compared to their public counterparts. However,\nthe lack of empirical and theoretical results prevent precise prediction of the\nreal-world performance. We address this gap by conducting an in-depth\nperformance analysis of Hyperledger Fabric. The paper presents a detailed\ncompilation of various performance characteristics using an enhanced version of\nthe Distributed Ledger Performance Scan. Researchers and practitioners alike\ncan use the results as guidelines to better configure and implement their\nblockchains and utilize the DLPS framework to conduct their measurements.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:30:43 GMT"}], "update_date": "2021-02-16", "authors_parsed": [["Guggenberger", "Tobias", ""], ["Sedlmeir", "Johannes", ""], ["Fridgen", "Gilbert", ""], ["Luckow", "Andr\u00e9", ""]]}, {"id": "2102.07758", "submitter": "Alexander Rogozin V.", "authors": "Alexander Rogozin, Aleksandr Beznosikov, Darina Dvinskikh, Dmitry\n  Kovalev, Pavel Dvurechensky, Alexander Gasnikov", "title": "Decentralized Distributed Optimization for Saddle Point Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed convex-concave saddle point problems over arbitrary\nconnected undirected networks and propose a decentralized distributed algorithm\nfor their solution. The local functions distributed across the nodes are\nassumed to have global and local groups of variables. For the proposed\nalgorithm we prove non-asymptotic convergence rate estimates with explicit\ndependence on the network characteristics. To supplement the convergence rate\nanalysis, we propose lower bounds for strongly-convex-strongly-concave and\nconvex-concave saddle-point problems over arbitrary connected undirected\nnetworks. We illustrate the considered problem setting by a particular\napplication to distributed calculation of non-regularized Wasserstein\nbarycenters.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 18:55:58 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2021 18:34:26 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 20:07:59 GMT"}, {"version": "v4", "created": "Mon, 14 Jun 2021 11:07:11 GMT"}], "update_date": "2021-06-15", "authors_parsed": [["Rogozin", "Alexander", ""], ["Beznosikov", "Aleksandr", ""], ["Dvinskikh", "Darina", ""], ["Kovalev", "Dmitry", ""], ["Dvurechensky", "Pavel", ""], ["Gasnikov", "Alexander", ""]]}, {"id": "2102.07767", "submitter": "Mohammad Taha Toghani", "authors": "Mohammad Taha Toghani, Cesar A. Uribe", "title": "Communication-Efficient Distributed Cooperative Learning with Compressed\n  Beliefs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.MA math.OC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of distributed cooperative learning, where a group of\nagents seek to agree on a set of hypotheses that best describes a sequence of\nprivate observations. In the scenario where the set of hypotheses is large, we\npropose a belief update rule where agents share compressed (either sparse or\nquantized) beliefs with an arbitrary positive compression rate. Our algorithm\nleverages a unified and straightforward communication rule that enables agents\nto access wide-ranging compression operators as black-box modules. We prove the\nalmost sure asymptotic exponential convergence of beliefs around the set of\noptimal hypotheses. Additionally, we show a non-asymptotic, explicit, and\nlinear concentration rate in probability of the beliefs on the optimal\nhypothesis set. We provide numerical experiments to illustrate the\ncommunication benefits of our method. The simulation results show that the\nnumber of transmitted bits can be reduced to 5-10% of the non-compressed method\nin the studied scenarios.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2021 06:19:36 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Toghani", "Mohammad Taha", ""], ["Uribe", "Cesar A.", ""]]}, {"id": "2102.07886", "submitter": "Johannes Sedlmeir", "authors": "Johannes Sedlmeir and Hans Ulrich Buhl and Gilbert Fridgen and Robert\n  Keller", "title": "Recent Developments in Blockchain Technology and their Impact on Energy\n  Consumption", "comments": "This is a translated version of a German article published in\n  Informatik Spektrum", "journal-ref": null, "doi": "10.1007/s00287-020-01321-z", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The enormous power consumption of Bitcoin has led to undifferentiated\ndiscussions in science and practice about the sustainability of blockchain and\ndistributed ledger technology in general. However, blockchain technology is far\nfrom homogeneous - not only with regard to its applications, which now go far\nbeyond cryptocurrencies and have reached businesses and the public sector, but\nalso with regard to its technical characteristics and, in particular, its power\nconsumption. This paper summarizes the status quo of the power consumption of\nvarious implementations of blockchain technology, with special emphasis on the\nrecent 'Bitcoin Halving' and so-called 'zk-rollups'. We argue that although\nBitcoin and other proof-of-work blockchains do indeed consume a lot of power,\nalternative blockchain solutions with significantly lower power consumption are\nalready available today, and new promising concepts are being tested that could\nfurther reduce in particular the power consumption of large blockchain networks\nin the near future. From this we conclude that although the criticism of\nBitcoin's power consumption is legitimate, it should not be used to derive an\nenergy problem of blockchain technology in general. In many cases in which\nprocesses can be digitised or improved with the help of more energy-efficient\nblockchain variants, one can even expect net energy savings.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2021 22:55:30 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Sedlmeir", "Johannes", ""], ["Buhl", "Hans Ulrich", ""], ["Fridgen", "Gilbert", ""], ["Keller", "Robert", ""]]}, {"id": "2102.07932", "submitter": "Zhuolun Xiang", "authors": "Ittai Abraham, Kartik Nayak, Ling Ren, Zhuolun Xiang", "title": "Brief Note: Fast Authenticated Byzantine Consensus", "comments": "This is a complementary note of our previous paper on the good-case\n  latency of Byzantine broadcast", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Byzantine fault-tolerant (BFT) state machine replication (SMR) has been\nstudied for over 30 years. Recently it has received more attention due to its\napplication in permissioned blockchain systems. A sequence of research efforts\nfocuses on improving the commit latency of the SMR protocol in the common good\ncase, including PBFT with $3$-round latency and $n\\geq 3f+1$ and FaB with\n$2$-round latency and $n\\geq 5f+1$. In this paper, we propose an authenticated\nprotocol that solves $2$-round BFT SMR with only $n\\geq 5f-1$ replicas, which\nrefutes the optimal resiliency claim made in FaB for needing $n \\geq 5f+1$ for\n$2$-round PBFT-style BFT protocols. For the special case when $f=1$, our\nprotocol needs only $4$ replicas, and strictly improves PBFT by reducing the\nlatency by one round (even when one backup is faulty).\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 03:02:34 GMT"}, {"version": "v2", "created": "Sat, 20 Feb 2021 22:39:50 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Abraham", "Ittai", ""], ["Nayak", "Kartik", ""], ["Ren", "Ling", ""], ["Xiang", "Zhuolun", ""]]}, {"id": "2102.07988", "submitter": "Zhuohan Li", "authors": "Zhuohan Li, Siyuan Zhuang, Shiyuan Guo, Danyang Zhuo, Hao Zhang, Dawn\n  Song, Ion Stoica", "title": "TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale\n  Language Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Model parallelism has become a necessity for training modern large-scale deep\nlanguage models. In this work, we identify a new and orthogonal dimension from\nexisting model parallel approaches: it is possible to perform pipeline\nparallelism within a single training sequence for Transformer-based language\nmodels thanks to its autoregressive property. This enables a more fine-grained\npipeline compared with previous work. With this key idea, we design TeraPipe, a\nhigh-performance token-level pipeline parallel algorithm for synchronous\nmodel-parallel training of Transformer-based language models. We develop a\nnovel dynamic programming-based algorithm to calculate the optimal pipelining\nexecution scheme given a specific model and cluster configuration. We show that\nTeraPipe can speed up the training by 5.0x for the largest GPT-3 model with 175\nbillion parameters on an AWS cluster with 48 p3.16xlarge instances compared\nwith state-of-the-art model-parallel methods.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 07:34:32 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Li", "Zhuohan", ""], ["Zhuang", "Siyuan", ""], ["Guo", "Shiyuan", ""], ["Zhuo", "Danyang", ""], ["Zhang", "Hao", ""], ["Song", "Dawn", ""], ["Stoica", "Ion", ""]]}, {"id": "2102.08076", "submitter": "Saeed Akhoondian Amiri", "authors": "Saeed Akhoondian Amiri", "title": "Deterministic CONGEST Algorithm for MDS on Bounded Arboricity Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We provide a deterministic CONGEST algorithm to constant factor approximate\nthe minimum dominating set on graphs of bounded arboricity in $O(\\log n)$\nrounds. This improves over the well-known randomized algorithm of Lenzen and\nWattenhofer[DISC2010] by making it a deterministic algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 10:57:03 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 16:02:13 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Amiri", "Saeed Akhoondian", ""]]}, {"id": "2102.08166", "submitter": "John Stephan", "authors": "Rachid Guerraoui, Nirupam Gupta, Rafa\\\"el Pinot, S\\'ebastien Rouault,\n  John Stephan", "title": "Differential Privacy and Byzantine Resilience in SGD: Do They Add Up?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses the problem of combining Byzantine resilience with\nprivacy in machine learning (ML). Specifically, we study if a distributed\nimplementation of the renowned Stochastic Gradient Descent (SGD) learning\nalgorithm is feasible with both differential privacy (DP) and\n$(\\alpha,f)$-Byzantine resilience. To the best of our knowledge, this is the\nfirst work to tackle this problem from a theoretical point of view. A key\nfinding of our analyses is that the classical approaches to these two\n(seemingly) orthogonal issues are incompatible. More precisely, we show that a\ndirect composition of these techniques makes the guarantees of the resulting\nSGD algorithm depend unfavourably upon the number of parameters of the ML\nmodel, making the training of large models practically infeasible. We validate\nour theoretical results through numerical experiments on publicly-available\ndatasets; showing that it is impractical to ensure DP and Byzantine resilience\nsimultaneously.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 14:10:38 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 15:11:52 GMT"}, {"version": "v3", "created": "Thu, 24 Jun 2021 15:44:21 GMT"}], "update_date": "2021-06-25", "authors_parsed": [["Guerraoui", "Rachid", ""], ["Gupta", "Nirupam", ""], ["Pinot", "Rafa\u00ebl", ""], ["Rouault", "S\u00e9bastien", ""], ["Stephan", "John", ""]]}, {"id": "2102.08304", "submitter": "Burak Hasircioglu", "authors": "Burak Hasircioglu, Jesus Gomez-Vilardebo, Deniz Gunduz", "title": "Speeding Up Private Distributed Matrix Multiplication via Bivariate\n  Polynomial Codes", "comments": "To appear in IEEE International Symposium on Information Theory\n  (ISIT) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of private distributed matrix multiplication under\nlimited resources. Coded computation has been shown to be an effective solution\nin distributed matrix multiplication, both providing privacy against the\nworkers and boosting the computation speed by efficiently mitigating\nstragglers. In this work, we propose the use of recently-introduced bivariate\npolynomial codes to further speed up private distributed matrix multiplication\nby exploiting the partial work done by the stragglers rather than completely\nignoring them. We show that the proposed approach reduces the average\ncomputation time of private distributed matrix multiplication compared to its\ncompetitors in the literature while improving the upload communication cost and\nthe workers' storage efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 17:40:30 GMT"}, {"version": "v2", "created": "Tue, 13 Jul 2021 17:56:56 GMT"}], "update_date": "2021-07-14", "authors_parsed": [["Hasircioglu", "Burak", ""], ["Gomez-Vilardebo", "Jesus", ""], ["Gunduz", "Deniz", ""]]}, {"id": "2102.08323", "submitter": "Mahdi Nikdast", "authors": "Ebadollah Taheri and Ryan G. Kim and Mahdi Nikdast", "title": "AdEle: An Adaptive Congestion-and-Energy-Aware Elevator Selection for\n  Partially Connected 3D NoCs", "comments": "This paper will be published in Proc. IEEE/ACM Design Automation\n  Conference (DAC) 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By lowering the number of vertical connections in fully connected 3D\nnetworks-on-chip (NoCs), partially connected 3D NoCs (PC-3DNoCs) help alleviate\nreliability and fabrication issues. This paper proposes a novel, adaptive\ncongestion- and energy-aware elevator-selection scheme called AdEle to improve\nthe traffic distribution in PC-3DNoCs. AdEle employs an offline multi-objective\nsimulated-annealing-based algorithm to find good elevator subsets and an online\nelevator selection policy to enhance elevator selection during routing.\nCompared to the state-of-the-art techniques under different real-application\ntraffics and configuration scenarios, AdEle improves the network latency by\n14.9% on average (up to 21.4%) with less than 10.5% energy consumption\noverhead.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:10:26 GMT"}], "update_date": "2021-02-17", "authors_parsed": [["Taheri", "Ebadollah", ""], ["Kim", "Ryan G.", ""], ["Nikdast", "Mahdi", ""]]}, {"id": "2102.08325", "submitter": "Oded Naor", "authors": "Idit Keidar, Eleftherios Kokoris-Kogias, Oded Naor, Alexander\n  Spiegelman", "title": "All You Need is DAG", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DAG-Rider, the first asynchronous Byzantine Atomic Broadcast\nprotocol that achieves optimal resilience, optimal amortized communication\ncomplexity, and optimal time complexity. DAG-Rider is post-quantum safe and\nensures that all messages proposed by correct processes eventually get decided.\nWe construct DAG-Rider in two layers: In the first layer, processes reliably\nbroadcast their proposals and build a structured Directed Acyclic Graph (DAG)\nof the communication among them. In the second layer, processes locally observe\ntheir DAGs and totally order all proposals with no extra communication.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 18:12:59 GMT"}, {"version": "v2", "created": "Fri, 4 Jun 2021 05:07:56 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Keidar", "Idit", ""], ["Kokoris-Kogias", "Eleftherios", ""], ["Naor", "Oded", ""], ["Spiegelman", "Alexander", ""]]}, {"id": "2102.08440", "submitter": "Dimitris Stripelis", "authors": "Dimitris Stripelis, Jose Luis Ambite, Pradeep Lam and Paul Thompson", "title": "Scaling Neuroscience Research using Federated Learning", "comments": "To appear at IEEE International Symposium on Biomedical Imaging 2021\n  (ISBI 2021)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The amount of biomedical data continues to grow rapidly. However, the ability\nto analyze these data is limited due to privacy and regulatory concerns.\nMachine learning approaches that require data to be copied to a single location\nare hampered by the challenges of data sharing. Federated Learning is a\npromising approach to learn a joint model over data silos. This architecture\ndoes not share any subject data across sites, only aggregated parameters, often\nin encrypted environments, thus satisfying privacy and regulatory requirements.\nHere, we describe our Federated Learning architecture and training policies. We\ndemonstrate our approach on a brain age prediction model on structural MRI\nscans distributed across multiple sites with diverse amounts of data and\nsubject (age) distributions. In these heterogeneous environments, our\nSemi-Synchronous protocol provides faster convergence.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 20:30:04 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Stripelis", "Dimitris", ""], ["Ambite", "Jose Luis", ""], ["Lam", "Pradeep", ""], ["Thompson", "Paul", ""]]}, {"id": "2102.08463", "submitter": "Yu-Hsuan Shih", "authors": "Yu-hsuan Shih, Garrett Wright, Joakim And\\'en, Johannes Blaschke, Alex\n  H. Barnett", "title": "cuFINUFFT: a load-balanced GPU library for general-purpose nonuniform\n  FFTs", "comments": "10 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.NA eess.SP math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nonuniform fast Fourier transforms dominate the computational cost in many\napplications including image reconstruction and signal processing. We thus\npresent a general-purpose GPU-based CUDA library for type 1 (nonuniform to\nuniform) and type 2 (uniform to nonuniform) transforms in dimensions 2 and 3,\nin single or double precision. It achieves high performance for a given\nuser-requested accuracy, regardless of the distribution of nonuniform points,\nvia cache-aware point reordering, and load-balanced blocked spreading in shared\nmemory. At low accuracies, this gives on-GPU throughputs around $10^9$\nnonuniform points per second, and (even including host-device transfer) is\ntypically 4-10$\\times$ faster than the latest parallel CPU code FINUFFT (at 28\nthreads). It is competitive with two established GPU codes, being up to\n90$\\times$ faster at high accuracy and/or type 1 clustered point distributions.\nFinally we demonstrate a 5-12$\\times$ speedup versus CPU in an X-ray\ndiffraction 3D iterative reconstruction task at $10^{-12}$ accuracy, observing\nexcellent multi-GPU weak scaling up to one rank per GPU.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2021 21:57:23 GMT"}, {"version": "v2", "created": "Thu, 25 Mar 2021 23:18:05 GMT"}], "update_date": "2021-04-06", "authors_parsed": [["Shih", "Yu-hsuan", ""], ["Wright", "Garrett", ""], ["And\u00e9n", "Joakim", ""], ["Blaschke", "Johannes", ""], ["Barnett", "Alex H.", ""]]}, {"id": "2102.08547", "submitter": "Saeid Barati", "authors": "Saeid Barati, Lee Ehudin, Hank Hoffmann", "title": "NEAT: A Framework for Automated Exploration of Floating Point\n  Approximations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Much recent research is devoted to exploring tradeoffs between computational\naccuracy and energy efficiency at different levels of the system stack.\nApproximation at the floating point unit (FPU) allows saving energy by simply\nreducing the number of computed floating point bits in return for accuracy\nloss. Although, finding the most energy efficient approximation for various\napplications with minimal effort is the main challenge. To address this issue,\nwe propose NEAT: a pin tool that helps users automatically explore the\naccuracy-energy tradeoff space induced by various floating point\nimplementations. NEAT helps programmers explore the effects of simultaneously\nusing multiple floating point implementations to achieve the lowest energy\nconsumption for an accuracy constraint or vice versa. NEAT accepts one or more\nuser-defined floating point implementations and programmable placement rules\nfor where/when to apply them. NEAT then automatically replaces floating point\noperations with different implementations based on the user-specified rules\nduring the runtime and explores the resulting tradeoff space to find the best\nuse of approximate floating point implementations for the precision tuning\nthroughout the program. We evaluate NEAT by enforcing combinations of 24/53\ndifferent floating point implementations with three sets of placement rules on\na wide range of benchmarks. We find that heuristic precision tuning at the\nfunction level provides up to 22% and 48% energy savings at 1% and 10% accuracy\nloss comparing to applying a single implementation for the whole application.\nAlso, NEAT is applicable to neural networks where it finds the optimal\nprecision level for each layer considering an accuracy target for the model.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 03:23:38 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Barati", "Saeid", ""], ["Ehudin", "Lee", ""], ["Hoffmann", "Hank", ""]]}, {"id": "2102.08550", "submitter": "Sheng Huang", "authors": "Sheng Huang", "title": "Oscars: Adaptive Semi-Synchronous Parallel Model for Distributed Deep\n  Learning with Global View", "comments": "arXiv admin note: text overlap with arXiv:1910.13598 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has become an indispensable part of life, such as face\nrecognition, NLP, etc., but the training of deep model has always been a\nchallenge, and in recent years, the complexity of training data and models has\nshown explosive growth, so the training method is gradually transformed into\ndistributed training. Classical synchronization strategy can guarantee accuracy\nbut frequent communication can lead to a slow training speed, although\nasynchronous strategy training speed but can not guarantee the accuracy, and in\nthe face of the training of the heterogeneous cluster, the above work is not\nefficient to work, on the one hand, can cause serious waste of resources, on\nthe other hand, frequent communication also made slow training speed, so this\npaper proposes a semi-synchronous training strategy based on local-SDG,\neffectively improve the utilization efficiency of heterogeneous resources\ncluster and reduce communication overhead, to accelerate the training and\nensure the accuracy of the model.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 03:31:06 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Huang", "Sheng", ""]]}, {"id": "2102.08667", "submitter": "Jer Shyuan Ng", "authors": "Jer Shyuan Ng, Wei Yang Bryan Lim, Zehui Xiong, Dusit Niyato, Cyril\n  Leung, Dong In Kim, Junshan Zhang, Qiang Yang", "title": "A Game-theoretic Approach Towards Collaborative Coded Computation\n  Offloading", "comments": "arXiv admin note: text overlap with arXiv:2012.04854", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Coded distributed computing (CDC) has emerged as a promising approach because\nit enables computation tasks to be carried out in a distributed manner while\nmitigating straggler effects, which often account for the long overall\ncompletion times. Specifically, by using polynomial codes, computed results\nfrom only a subset of edge servers can be used to reconstruct the final result.\nHowever, incentive issues have not been studied systematically for the edge\nservers to complete the CDC tasks. In this paper, we propose a tractable\ntwo-level game-theoretic approach to incentivize the edge servers to complete\nthe CDC tasks. Specifically, in the lower level, a hedonic coalition formation\ngame is formulated where the edge servers share their resources within their\ncoalitions. By forming coalitions, the edge servers have more Central\nProcessing Unit (CPU) power to complete the computation tasks. In the upper\nlevel, given the CPU power of the coalitions of edge servers, an all-pay\nauction is designed to incentivize the edge servers to participate in the CDC\ntasks. In the all-pay auction, the bids of the edge servers are represented by\nthe allocation of their CPU power to the CDC tasks. The all-pay auction is\ndesigned to maximize the utility of the cloud server by determining the\nallocation of rewards to the winners. Simulation results show that the edge\nservers are incentivized to allocate more CPU power when multiple rewards are\noffered, i.e., there are multiple winners, instead of rewarding only the edge\nserver with the largest CPU power allocation. Besides, the utility of the cloud\nserver is maximized when it offers multiple homogeneous rewards, instead of\nheterogeneous rewards.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 10:15:47 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Ng", "Jer Shyuan", ""], ["Lim", "Wei Yang Bryan", ""], ["Xiong", "Zehui", ""], ["Niyato", "Dusit", ""], ["Leung", "Cyril", ""], ["Kim", "Dong In", ""], ["Zhang", "Junshan", ""], ["Yang", "Qiang", ""]]}, {"id": "2102.08703", "submitter": "Darya Melnyk", "authors": "Alkida Balliu, Juho Hirvonen, Darya Melnyk, Dennis Olivetti, Joel\n  Rybicki, and Jukka Suomela", "title": "Local Mending", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we introduce the graph-theoretic notion of mendability: for each\nlocally checkable graph problem we can define its mending radius, which\ncaptures the idea of how far one needs to modify a partial solution in order to\n\"patch a hole.\"\n  We explore how mendability is connected to the existence of efficient\nalgorithms, especially in distributed, parallel, and fault-tolerant settings.\nIt is easy to see that $O(1)$-mendable problems are also solvable in $O(\\log^*\nn)$ rounds in the LOCAL model of distributed computing. One of the surprises is\nthat in paths and cycles, a converse also holds in the following sense: if a\nproblem $\\Pi$ can be solved in $O(\\log^* n)$, there is always a restriction\n$\\Pi' \\subseteq \\Pi$ that is still efficiently solvable but that is also\n$O(1)$-mendable.\n  We also explore the structure of the landscape of mendability. For example,\nwe show that in trees, the mending radius of any locally checkable problem is\n$O(1)$, $\\Theta(\\log n)$, or $\\Theta(n)$, while in general graphs the structure\nis much more diverse.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 11:18:10 GMT"}, {"version": "v2", "created": "Mon, 22 Mar 2021 11:07:13 GMT"}, {"version": "v3", "created": "Tue, 18 May 2021 10:47:21 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Balliu", "Alkida", ""], ["Hirvonen", "Juho", ""], ["Melnyk", "Darya", ""], ["Olivetti", "Dennis", ""], ["Rybicki", "Joel", ""], ["Suomela", "Jukka", ""]]}, {"id": "2102.08710", "submitter": "Miguel Caballer", "authors": "Miguel Caballer, Marica Antonacci, Zden\\v{e}k \\v{S}ustr, Michele\n  Perniola, Germ\\'an Molt\\'o", "title": "Deployment of Elastic Virtual Hybrid Clusters Across Cloud Sites", "comments": "33 pages, 11 figures", "journal-ref": "J Grid Computing 19, 4 (2021)", "doi": "10.1007/s10723-021-09543-5", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtual clusters are widely used computing platforms than can be deployed in\nmultiple cloud platforms. The ability to dynamically grow and shrink the number\nof nodes has paved the way for customised elastic computing both for High\nPerformance Computing and High Throughput Computing workloads. However,\nelasticity is typically restricted to a single cloud site, thus hindering the\nability to provision computational resources from multiple geographically\ndistributed cloud sites. To this aim, this paper introduces an architecture of\nopen-source components that coherently deploy a virtual elastic cluster across\nmultiple cloud sites to perform large-scale computing. These hybrid virtual\nelastic clusters are automatically deployed and configured using an\nInfrastructure as Code (IaC) approach on a distributed hybrid testbed that\nspans different organizations, including on-premises and public clouds,\nsupporting automated tunneling of communications across the cluster nodes with\nadvanced VPN topologies. The results indicate that cluster-based computing of\nembarrassingly parallel jobs can benefit from hybrid virtual clusters that\naggregate computing resources from multiple cloud back-ends and bring them\ntogether into a dedicated, albeit virtual network.\n  The work presented in this article has been partially funded by the European\nUnion's (EU) Horizon 2020 research project DEEP Hybrid-DataCloud (grant\nagreement No 777435).\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 11:48:12 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Caballer", "Miguel", ""], ["Antonacci", "Marica", ""], ["\u0160ustr", "Zden\u011bk", ""], ["Perniola", "Michele", ""], ["Molt\u00f3", "Germ\u00e1n", ""]]}, {"id": "2102.08768", "submitter": "Francesco Betti Sorbelli", "authors": "Aakash Khochare, Yogesh Simmhan, Francesco Betti Sorbelli, Sajal K.\n  Das", "title": "Heuristic Algorithms for Co-scheduling of Edge Analytics and Routes for\n  UAV Fleet Missions", "comments": "infocom 2021 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Unmanned Aerial Vehicles (UAVs) or drones are increasingly used for urban\napplications like traffic monitoring and construction surveys. Autonomous\nnavigation allows drones to visit waypoints and accomplish activities as part\nof their mission. A common activity is to hover and observe a location using\non-board cameras. Advances in Deep Neural Networks (DNNs) allow such videos to\nbe analyzed for automated decision making. UAVs also host edge computing\ncapability for on-board inferencing by such DNNs. To this end, for a fleet of\ndrones, we propose a novel Mission Scheduling Problem (MSP) that co-schedules\nthe flight routes to visit and record video at waypoints, and their subsequent\non-board edge analytics. The proposed schedule maximizes the utility from the\nactivities while meeting activity deadlines as well as energy and computing\nconstraints. We first prove that MSP is NP-hard and then optimally solve it by\nformulating a mixed integer linear programming (MILP) problem. Next, we design\ntwo efficient heuristic algorithms, JSC and VRC, that provide fast sub-optimal\nsolutions. Evaluation of these three schedulers using real drone traces\ndemonstrate utility-runtime trade-offs under diverse workloads.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 18:33:26 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Khochare", "Aakash", ""], ["Simmhan", "Yogesh", ""], ["Sorbelli", "Francesco Betti", ""], ["Das", "Sajal K.", ""]]}, {"id": "2102.08794", "submitter": "Li Pan", "authors": "Bingbing Zheng and Li Pan and Shijun Liu", "title": "Market-Oriented Online Bi-Objective Service Scheduling for Pleasingly\n  Parallel Jobs with Variable Resources in Cloud Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  In this paper, we study the market-oriented online bi-objective service\nscheduling problem for pleasingly parallel jobs with variable resources in\ncloud environments, from the perspective of SaaS (Software-as-as-Service)\nproviders who provide job-execution services. The main process of scheduling\nSaaS services in clouds is: a SaaS provider purchases cloud instances from IaaS\nproviders to schedule end users' jobs and charges users accordingly. This\nproblem has several particular features, such as the job-oriented end users,\nthe pleasingly parallel jobs with soft deadline constraints, the online\nsettings, and the variable numbers of resources. For maximizing both the\nrevenue and the user satisfaction rate, we design an online algorithm for SaaS\nproviders to optimally purchase IaaS instances and schedule pleasingly parallel\njobs. The proposed algorithm can achieve competitive objectives in polynomial\nrun-time. The theoretical analysis and simulations based on real-world Google\njob traces as well as synthetic datasets validate the effectiveness and\nefficiency of our algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:40:10 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Zheng", "Bingbing", ""], ["Pan", "Li", ""], ["Liu", "Shijun", ""]]}, {"id": "2102.08797", "submitter": "Anton Bernshteyn", "authors": "Anton Bernshteyn", "title": "Probabilistic constructions in continuous combinatorics and a bridge to\n  distributed algorithms", "comments": "22 pp", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DC math.DS math.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The probabilistic method is a technique for proving combinatorial existence\nresults by means of showing that a randomly chosen object has the desired\nproperties with positive probability. A particularly powerful probabilistic\ntool is the Lov\\'{a}sz Local Lemma (the LLL for short), which was introduced by\nErd\\H{o}s and Lov\\'{a}sz in the mid-1970s. Here we develop a version of the LLL\nthat can be used to prove the existence of continuous colorings. We then give\nseveral applications in Borel and topological dynamics.\n  * Seward and Tucker-Drob showed that every free Borel action $\\Gamma\n\\curvearrowright X$ of a countable group $\\Gamma$ admits an equivariant Borel\nmap $\\pi \\colon X \\to Y$ to a free subshift $Y \\subset 2^\\Gamma$. We give a new\nsimple proof of this result.\n  * We show that for a countable group $\\Gamma$, $\\mathrm{Free}(2^\\Gamma)$ is\nweakly contained, in the sense of Elek, in every free continuous action of\n$\\Gamma$ on a zero-dimensional Polish space. This fact is analogous to the\ntheorem of Ab\\'{e}rt and Weiss for probability measure-preserving actions and\nhas a number of consequences in continuous combinatorics. In particular, we\ndeduce that a coloring problem admits a continuous solution on\n$\\mathrm{Free}(2^\\Gamma)$ if and only if it can be solved on finite subgraphs\nof the Cayley graph of $\\Gamma$ by an efficient deterministic distributed\nalgorithm (this fact was also proved independently and using different methods\nby Greb\\'{i}k, Jackson, Rozho\\v{n}, Seward, and Vidny\\'{a}nszky). This\nestablishes a formal correspondence between questions that have been studied\nindependently in continuous combinatorics and in distributed computing.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 14:49:42 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Bernshteyn", "Anton", ""]]}, {"id": "2102.08808", "submitter": "Joel Rybicki", "authors": "Dan Alistarh and Rati Gelashvili and Joel Rybicki", "title": "Fast Graphical Population Protocols", "comments": "42 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Let $G$ be a graph on $n$ nodes. In the stochastic population protocol model,\na collection of $n$ indistinguishable, resource-limited nodes collectively\nsolve tasks via pairwise interactions. In each interaction, two randomly chosen\nneighbors first read each other's states, and then update their local states. A\nrich line of research has established tight upper and lower bounds on the\ncomplexity of fundamental tasks, such as majority and leader election, in this\nmodel, when $G$ is a clique. Specifically, in the clique, these tasks can be\nsolved fast, i.e., in $n \\operatorname{polylog} n$ pairwise interactions, with\nhigh probability, using at most $\\operatorname{polylog} n$ states per node.\n  In this work, we consider the more general setting where $G$ is an arbitrary\ngraph, and present a technique for simulating protocols designed for\nfully-connected networks in any connected regular graph. Our main result is a\nsimulation that is efficient on many interesting graph families: roughly, the\nsimulation overhead is polylogarithmic in the number of nodes, and quadratic in\nthe conductance of the graph. As a sample application, we show that, in any\nregular graph with conductance $\\phi$, both leader election and exact majority\ncan be solved in $\\phi^{-2} \\cdot n \\operatorname{polylog} n$ pairwise\ninteractions, with high probability, using at most $\\phi^{-2} \\cdot\n\\operatorname{polylog} n$ states per node. This shows that there are fast and\nspace-efficient population protocols for leader election and exact majority on\ngraphs with good expansion properties. We believe our results will prove\ngenerally useful, as they allow efficient technology transfer between the\nwell-mixed (clique) case, and the under-explored spatial setting.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 15:13:25 GMT"}, {"version": "v2", "created": "Tue, 11 May 2021 18:51:38 GMT"}], "update_date": "2021-05-13", "authors_parsed": [["Alistarh", "Dan", ""], ["Gelashvili", "Rati", ""], ["Rybicki", "Joel", ""]]}, {"id": "2102.08833", "submitter": "David Johnson", "authors": "David S. Johnson, Wolfgang Lorenz, Michael Taenzer, Stylianos\n  Mimilakis, Sascha Grollmisch, Jakob Abe{\\ss}er, Hanna Lukashevich", "title": "DESED-FL and URBAN-FL: Federated Learning Datasets for Sound Event\n  Detection", "comments": "To be published in EUSIPCO 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SD cs.DC cs.LG eess.AS", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Research on sound event detection (SED) in environmental settings has seen\nincreased attention in recent years. The large amounts of (private) domestic or\nurban audio data needed raise significant logistical and privacy concerns. The\ninherently distributed nature of these tasks, make federated learning (FL) a\npromising approach to take advantage of largescale data while mitigating\nprivacy issues. While FL has also seen increased attention recently, to the\nbest of our knowledge there is no research towards FL for SED. To address this\ngap and foster further research in this field, we create and publish novel FL\ndatasets for SED in domestic and urban environments. Furthermore, we provide\nbaseline results on the datasets in a FL context for three deep neural network\narchitectures. The results indicate that FL is a promising approach for SED,\nbut faces challenges with divergent data distributions inherent to distributed\nclient edge devices.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 15:41:38 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2021 11:59:52 GMT"}, {"version": "v3", "created": "Mon, 31 May 2021 10:32:39 GMT"}], "update_date": "2021-06-01", "authors_parsed": [["Johnson", "David S.", ""], ["Lorenz", "Wolfgang", ""], ["Taenzer", "Michael", ""], ["Mimilakis", "Stylianos", ""], ["Grollmisch", "Sascha", ""], ["Abe\u00dfer", "Jakob", ""], ["Lukashevich", "Hanna", ""]]}, {"id": "2102.08904", "submitter": "Nima Mahmoudi", "authors": "Nima Mahmoudi, Hamzeh Khazaei", "title": "SimFaaS: A Performance Simulator for Serverless Computing Platforms", "comments": "to be published in \"The 11th IEEE International Conference on Cloud\n  Computing and Services Science (CLOSER 2021)\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Developing accurate and extendable performance models for serverless\nplatforms, aka Function-as-a-Service (FaaS) platforms, is a very challenging\ntask. Also, implementation and experimentation on real serverless platforms is\nboth costly and time-consuming. However, at the moment, there is no\ncomprehensive simulation tool or framework to be used instead of the real\nplatform. As a result, in this paper, we fill this gap by proposing a\nsimulation platform, called SimFaaS, which assists serverless application\ndevelopers to develop optimized Function-as-a-Service applications in terms of\ncost and performance. On the other hand, SimFaaS can be leveraged by FaaS\nproviders to tailor their platforms to be workload-aware so that they can\nincrease profit and quality of service at the same time. Also, serverless\nplatform providers can evaluate new designs, implementations, and deployments\non SimFaaS in a timely and cost-efficient manner.\n  SimFaaS is open-source, well-documented, and publicly available, making it\neasily usable and extendable to incorporate more use case scenarios in the\nfuture. Besides, it provides performance engineers with a set of tools that can\ncalculate several characteristics of serverless platform internal states, which\nis otherwise hard (mostly impossible) to extract from real platforms. We show\nhow SimFaaS facilitates the prediction of essential performance metrics such as\naverage response time, probability of cold start, and the average number of\ninstances reflecting the infrastructure cost incurred by the serverless\ncomputing provider. We evaluate the accuracy and applicability of SimFaaS by\ncomparing the prediction results with real-world traces from Amazon AWS Lambda.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 17:50:48 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Mahmoudi", "Nima", ""], ["Khazaei", "Hamzeh", ""]]}, {"id": "2102.08929", "submitter": "Jamal Toutouh", "authors": "Jamal Toutouh and Una-May O'Reilly", "title": "Signal Propagation in a Gradient-Based and Evolutionary Learning System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generative adversarial networks (GANs) exhibit training pathologies that can\nlead to convergence-related degenerative behaviors, whereas\nspatially-distributed, coevolutionary algorithms (CEAs) for GAN training, e.g.\nLipizzaner, are empirically robust to them. The robustness arises from\ndiversity that occurs by training populations of generators and discriminators\nin each cell of a toroidal grid. Communication, where signals in the form of\nparameters of the best GAN in a cell propagate in four directions: North,\nSouth, West, and East, also plays a role, by communicating adaptations that are\nboth new and fit. We propose Lipi-Ring, a distributed CEA like Lipizzaner,\nexcept that it uses a different spatial topology, i.e. a ring. Our central\nquestion is whether the different directionality of signal propagation\n(effectively migration to one or more neighbors on each side of a cell) meets\nor exceeds the performance quality and training efficiency of Lipizzaner\nExperimental analysis on different datasets (i.e, MNIST, CelebA, and COVID-19\nchest X-ray images) shows that there are no significant differences between the\nperformances of the trained generative models by both methods. However,\nLipi-Ring significantly reduces the computational time (14.2%. . . 41.2%).\nThus, Lipi-Ring offers an alternative to Lipizzaner when the computational cost\nof training matters.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2021 16:46:44 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Toutouh", "Jamal", ""], ["O'Reilly", "Una-May", ""]]}, {"id": "2102.08947", "submitter": "Pavel Vazquez", "authors": "Pavel Vazquez, Kayoko Shoji, Steffen Novik, Stefan Krauss and Simon\n  Rayner", "title": "A decentralized FAIR platform to facilitate data sharing in the life\n  sciences", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The Hybrid Technology Hub and many other research centers work in\ncross-functional teams whose workflow is not necessarily linear and where in\nmany cases technology advances are done through parallel work. The lack of\nproper tools and platforms for a collaborative environment can create time lags\nin coordination and limited sharing of research findings. To solve this, we\nhave developed a simple, user-friendly platform built for academic and\nscientific research collaboration. To ensure FAIRness compliance, the platform\nconsists of a metadata quality control based on blockchain technologies. The\ndata is stored separately in a distributed object storage that functions as a\ncloud. The platform also implements a version control system; it provides a\nhistory track of the project along with the possibility of reviewing the\nproject's development. This platform aims to be a standardized tool within the\nHybrid Technology Hub to ease collaboration, speed research workflow and\nimprove research quality.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2021 11:38:14 GMT"}], "update_date": "2021-02-18", "authors_parsed": [["Vazquez", "Pavel", ""], ["Shoji", "Kayoko", ""], ["Novik", "Steffen", ""], ["Krauss", "Stefan", ""], ["Rayner", "Simon", ""]]}, {"id": "2102.09001", "submitter": "Soeren Becker", "authors": "Soeren Becker, Florian Schmidt, Anton Gulenko, Alexander Acker, Odej\n  Kao", "title": "Towards AIOps in Edge Computing Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Edge computing was introduced as a technical enabler for the demanding\nrequirements of new network technologies like 5G. It aims to overcome\nchallenges related to centralized cloud computing environments by distributing\ncomputational resources to the edge of the network towards the customers. The\ncomplexity of the emerging infrastructures increases significantly, together\nwith the ramifications of outages on critical use cases such as self-driving\ncars or health care. Artificial Intelligence for IT Operations (AIOps) aims to\nsupport human operators in managing complex infrastructures by using machine\nlearning methods. This paper describes the system design of an AIOps platform\nwhich is applicable in heterogeneous, distributed environments. The overhead of\na high-frequency monitoring solution on edge devices is evaluated and\nperformance experiments regarding the applicability of three anomaly detection\nalgorithms on edge devices are conducted. The results show, that it is feasible\nto collect metrics with a high frequency and simultaneously run specific\nanomaly detection algorithms directly on edge devices with a reasonable\noverhead on the resource utilization.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2021 09:33:00 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Becker", "Soeren", ""], ["Schmidt", "Florian", ""], ["Gulenko", "Anton", ""], ["Acker", "Alexander", ""], ["Kao", "Odej", ""]]}, {"id": "2102.09032", "submitter": "Karl B\\\"ackstr\\\"om", "authors": "Karl B\\\"ackstr\\\"om, Ivan Walulya, Marina Papatriantafilou, Philippas\n  Tsigas", "title": "Consistent Lock-free Parallel Stochastic Gradient Descent for Fast and\n  Stable Convergence", "comments": "13 pages, 10 figures. Accepted in the 35th IEEE International\n  Parallel & Distributed Processing Symposium", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Stochastic gradient descent (SGD) is an essential element in Machine Learning\n(ML) algorithms. Asynchronous parallel shared-memory SGD (AsyncSGD), including\nsynchronization-free algorithms, e.g. HOGWILD!, have received interest in\ncertain contexts, due to reduced overhead compared to synchronous\nparallelization. Despite that they induce staleness and inconsistency, they\nhave shown speedup for problems satisfying smooth, strongly convex targets, and\ngradient sparsity. Recent works take important steps towards understanding the\npotential of parallel SGD for problems not conforming to these strong\nassumptions, in particular for deep learning (DL). There is however a gap in\ncurrent literature in understanding when AsyncSGD algorithms are useful in\npractice, and in particular how mechanisms for synchronization and consistency\nplay a role. We focus on the impact of consistency-preserving non-blocking\nsynchronization in SGD convergence, and in sensitivity to hyper-parameter\ntuning. We propose Leashed-SGD, an extensible algorithmic framework of\nconsistency-preserving implementations of AsyncSGD, employing lock-free\nsynchronization, effectively balancing throughput and latency. We argue\nanalytically about the dynamics of the algorithms, memory consumption, the\nthreads' progress over time, and the expected contention. We provide a\ncomprehensive empirical evaluation, validating the analytical claims,\nbenchmarking the proposed Leashed-SGD framework, and comparing to baselines for\ntraining multilayer perceptrons (MLP) and convolutional neural networks (CNN).\nWe observe the crucial impact of contention, staleness and consistency and show\nhow Leashed-SGD provides significant improvements in stability as well as\nwall-clock time to convergence (from 20-80% up to 4x improvements) compared to\nthe standard lock-based AsyncSGD algorithm and HOGWILD!, while reducing the\noverall memory footprint.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 21:24:44 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["B\u00e4ckstr\u00f6m", "Karl", ""], ["Walulya", "Ivan", ""], ["Papatriantafilou", "Marina", ""], ["Tsigas", "Philippas", ""]]}, {"id": "2102.09041", "submitter": "Gilad Stern", "authors": "Ittai Abraham, Philipp Jovanovic, Mary Maller, Sarah Meiklejohn, Gilad\n  Stern, Alin Tomescu", "title": "Reaching Consensus for Asynchronous Distributed Key Generation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We give a protocol for Asynchronous Distributed Key Generation (A-DKG) that\nis optimally resilient (can withstand $f<\\frac{n}{3}$ faulty parties), has a\nconstant expected number of rounds, has $\\tilde{O}(n^3)$ expected communication\ncomplexity, and assumes only the existence of a PKI. Prior to our work, the\nbest A-DKG protocols required $\\Omega(n)$ expected number of rounds, and\n$\\Omega(n^4)$ expected communication.\n  Our A-DKG protocol relies on several building blocks that are of independent\ninterest. We define and design a Proposal Election (PE) protocol that allows\nparties to retrospectively agree on a valid proposal after enough proposals\nhave been sent from different parties. With constant probability the elected\nproposal was proposed by a non-faulty party. In building our PE protocol, we\ndesign a Verifiable Gather protocol which allows parties to communicate which\nproposals they have and have not seen in a verifiable manner. The final\nbuilding block to our A-DKG is a Validated Asynchronous Byzantine Agreement\n(VABA) protocol. We use our PE protocol to construct a VABA protocol that does\nnot require leaders or an asynchronous DKG setup. Our VABA protocol can be used\nmore generally when it is not possible to use threshold signatures.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2021 21:55:49 GMT"}, {"version": "v2", "created": "Thu, 3 Jun 2021 15:45:45 GMT"}, {"version": "v3", "created": "Fri, 4 Jun 2021 21:26:36 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Abraham", "Ittai", ""], ["Jovanovic", "Philipp", ""], ["Maller", "Mary", ""], ["Meiklejohn", "Sarah", ""], ["Stern", "Gilad", ""], ["Tomescu", "Alin", ""]]}, {"id": "2102.09073", "submitter": "Kian Paimani", "authors": "Kian Paimani", "title": "SonicChain: A Wait-free, Pseudo-Static Approach Toward Concurrency in\n  Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchains have a two-sided reputation: they are praised for disrupting some\nof our institutions through innovative technology for good, yet notorious for\nbeing slow and expensive to use. In this work, we tackle this issue with\nconcurrency, yet we aim to take a radically different approach by valuing\nsimplicity. We embrace the simplicity through two steps: first, we formulate a\nsimple runtime mechanism to deal with conflicts called concurrency delegation.\nThis method is much simpler and has less overhead, particularly in scenarios\nwhere conflicting transactions are relatively rare. Moreover, to further reduce\nthe number of conflicting transactions, we propose using static annotations\nattached to each transaction, provided by the programmer. These annotations are\npseudo-static: they are static with respect to the lifetime of the transaction,\nand therefore are free to use information such as the origin and parameters of\nthe transaction. We propose a distributor component that can use the output of\nthis pseudo-static annotations and use them to effectively distribute\ntransactions between threads in the least-conflicting way. We name the outcome\nof a system combining concurrency delegation and pseudo-static annotations as\nSonicChain. We evaluate SonicChain for both validation and authoring tasks\nagainst a common workload in blockchains, namely, balance transfers, and\nobserve that it performs expectedly well while introducing very little overhead\nand additional complexity to the system.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2021 19:42:28 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Paimani", "Kian", ""]]}, {"id": "2102.09166", "submitter": "Sungho Lee", "authors": "Sungho Lee, Minsu Kim, Jemin Lee, Min-Soo Kim, Ruei-Hau Hsu, Tony Q.\n  S. Quek", "title": "Latency Modeling of Hyperledger Fabric for Blockchain-enabled IoT\n  Networks", "comments": "11 pages, 9 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the worldwide growth of the Internet of Things (IoT), new security\nrequirements have been raised, such as strong security, data integrity, or\nprivacy preservation. While blockchain technology is capable of addressing the\nissues, HLF, which is a private blockchain platform, has been leveraged for\nblockchain-enabled IoT (BC-IoT) networks. From the perspective of an IoT\napplication, however, the additional processing time spent in HLF may emerge as\nanother problem because many IoT applications handle real-time and\nlatency-critical jobs. In other words, it is necessary to estimate the HLF\nlatency before practical deployment of BC-IoT networks. However, this problem\nhas still remained unresolved because the distribution of the HLF latency has\nnot been revealed until the present. In this paper, therefore, we develop an\nHLF latency distribution model using probability distribution fitting and show\nthe latency can be modeled with the gamma distribution. Furthermore, we define\nthree influential HLF parameters on the HLF latency. Their impacts on the HLF\nlatency are analyzed to provide strategies for decreasing and minimizing the\nmean HLF latency.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 05:51:22 GMT"}, {"version": "v2", "created": "Wed, 23 Jun 2021 12:54:41 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Lee", "Sungho", ""], ["Kim", "Minsu", ""], ["Lee", "Jemin", ""], ["Kim", "Min-Soo", ""], ["Hsu", "Ruei-Hau", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "2102.09171", "submitter": "Minghong Fang", "authors": "Minghong Fang, Minghao Sun, Qi Li, Neil Zhenqiang Gong, Jin Tian, Jia\n  Liu", "title": "Data Poisoning Attacks and Defenses to Crowdsourcing Systems", "comments": "To appear in the Web Conference 2021 (WWW '21)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.HC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A key challenge of big data analytics is how to collect a large volume of\n(labeled) data. Crowdsourcing aims to address this challenge via aggregating\nand estimating high-quality data (e.g., sentiment label for text) from\npervasive clients/users. Existing studies on crowdsourcing focus on designing\nnew methods to improve the aggregated data quality from unreliable/noisy\nclients. However, the security aspects of such crowdsourcing systems remain\nunder-explored to date. We aim to bridge this gap in this work. Specifically,\nwe show that crowdsourcing is vulnerable to data poisoning attacks, in which\nmalicious clients provide carefully crafted data to corrupt the aggregated\ndata. We formulate our proposed data poisoning attacks as an optimization\nproblem that maximizes the error of the aggregated data. Our evaluation results\non one synthetic and two real-world benchmark datasets demonstrate that the\nproposed attacks can substantially increase the estimation errors of the\naggregated data. We also propose two defenses to reduce the impact of malicious\nclients. Our empirical results show that the proposed defenses can\nsubstantially reduce the estimation errors of the data poisoning attacks.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 06:03:48 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 23:10:31 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Fang", "Minghong", ""], ["Sun", "Minghao", ""], ["Li", "Qi", ""], ["Gong", "Neil Zhenqiang", ""], ["Tian", "Jin", ""], ["Liu", "Jia", ""]]}, {"id": "2102.09197", "submitter": "Soumyottam Chatterjee", "authors": "Soumyottam Chatterjee and Gopal Pandurangan and Peter Robinson", "title": "Network Size Estimation in Small-World Networks under Byzantine Faults", "comments": null, "journal-ref": null, "doi": "10.1109/IPDPS.2019.00094", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study the fundamental problem of counting the number of nodes in a sparse\nnetwork (of unknown size) under the presence of a large number of Byzantine\nnodes. We assume the full information model where the Byzantine nodes have\ncomplete knowledge about the entire state of the network at every round\n(including random choices made by all the nodes), have unbounded computational\npower, and can deviate arbitrarily from the protocol.\n  Our main contribution is a randomized distributed algorithm that estimates\nthe size of a network under the presence of a large number of Byzantine nodes.\nIn particular, our algorithm estimates the size of a sparse, \"small-world\",\nexpander network with up to $O(n^{1 - \\delta})$ Byzantine nodes, where $n$ is\nthe (unknown) network size and $\\delta$ can be be any arbitrarily small (but\nfixed) positive constant. Our algorithm outputs a (fixed) constant factor\nestimate of $\\log(n)$ with high probability; the correct estimate of the\nnetwork size will be known to a large fraction ($(1 - \\epsilon)$-fraction, for\nany fixed positive constant $\\epsilon$) of the honest nodes. Our algorithm is\nfully distributed, lightweight, and simple to implement, runs in $O(\\log^3{n})$\nrounds, and requires nodes to send and receive messages of only small-sized\nmessages per round; any node's local computation cost per round is also small.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 07:44:10 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Chatterjee", "Soumyottam", ""], ["Pandurangan", "Gopal", ""], ["Robinson", "Peter", ""]]}, {"id": "2102.09237", "submitter": "Hong Su Dr.", "authors": "Hong Su, Bing Guo, Yan Shen, and Tao Li", "title": "Strongly Connected Topology Model and Confirmation-based Propagation\n  Method for Cross-chain Interaction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cross-chain interaction is among different blockchains. When the number of\nblockchains increases, it is difficult for blockchains to form a single star\ntopology or a fully connected topology. Meanwhile, different from legacy\nnetworks, the propagation method is required to keep the data validity. Thus,\nthe blockchain topology and associated propagation methods are two key issues,\nwhich should be ensured during the propagation. In this paper, we first propose\nthe confirmation-based propagation method to keep the validity of the\ncross-chain data. The confirmation method is to seal the cross-chain\ntransaction synchronized from other blockchains. Second, we point out that a\nvalid topology requires blockchains to be strongly connected. With this\nrequirement, we propose several topologies, which match different connection\nscenarios. The simulation results show that the proposed methods can securely\npropagate the cross-chain data and the connection way is flexible.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 09:39:23 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 13:18:30 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Su", "Hong", ""], ["Guo", "Bing", ""], ["Shen", "Yan", ""], ["Li", "Tao", ""]]}, {"id": "2102.09277", "submitter": "Jan Studen\\'y", "authors": "Alkida Balliu, Sebastian Brandt, Yi-Jun Chang, Dennis Olivetti, Jan\n  Studen\\'y, Jukka Suomela, Aleksandr Tereshchenko", "title": "Locally Checkable Problems in Rooted Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider any locally checkable labeling problem $\\Pi$ in rooted regular\ntrees: there is a finite set of labels $\\Sigma$, and for each label $x \\in\n\\Sigma$ we specify what are permitted label combinations of the children for an\ninternal node of label $x$ (the leaf nodes are unconstrained). This formalism\nis expressive enough to capture many classic problems studied in distributed\ncomputing, including vertex coloring, edge coloring, and maximal independent\nset. We show that the distributed computational complexity of any such problem\n$\\Pi$ falls in one of the following classes: it is $O(1)$, $\\Theta(\\log^* n)$,\n$\\Theta(\\log n)$, or $n^{\\Theta(1)}$ rounds in trees with $n$ nodes (and all of\nthese classes are nonempty). We show that the complexity of any given problem\nis the same in all four standard models of distributed graph algorithms:\ndeterministic $\\mathsf{LOCAL}$, randomized $\\mathsf{LOCAL}$, deterministic\n$\\mathsf{CONGEST}$, and randomized $\\mathsf{CONGEST}$ model. In particular, we\nshow that randomness does not help in this setting, and the complexity class\n$\\Theta(\\log \\log n)$ does not exist (while it does exist in the broader\nsetting of general trees). We also show how to systematically determine the\ncomplexity class of any such problem $\\Pi$, i.e., whether $\\Pi$ takes $O(1)$,\n$\\Theta(\\log^* n)$, $\\Theta(\\log n)$, or $n^{\\Theta(1)}$ rounds. While the\nalgorithm may take exponential time in the size of the description of $\\Pi$, it\nis nevertheless practical: we provide a freely available implementation of the\nclassifier algorithm, and it is fast enough to classify many problems of\ninterest.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 11:42:03 GMT"}, {"version": "v2", "created": "Mon, 26 Jul 2021 17:51:08 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 17:18:07 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Balliu", "Alkida", ""], ["Brandt", "Sebastian", ""], ["Chang", "Yi-Jun", ""], ["Olivetti", "Dennis", ""], ["Studen\u00fd", "Jan", ""], ["Suomela", "Jukka", ""], ["Tereshchenko", "Aleksandr", ""]]}, {"id": "2102.09317", "submitter": "Kavya Alluru", "authors": "Kavya Alluru and Jeganathan.L", "title": "Graph based Data Dependence Identifier for Parallelization of Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Automatic parallelization improves the performance of serial program by\nautomatically converting to parallel program. Automatic parallelization\ntypically works in three phases: check for data dependencies in the input\nprogram, perform transformations, and generate the parallel code for target\nmachine. Though automatic parallelization is beneficial, it is not done as a\npart of compiling process because of the time complexity of the data dependence\ntests and transformation techniques. Data dependencies arise because of data\naccess from memory required for the execution of instructions of the program.\nIn a program, memory is allocated for variables like scalars, arrays and\npointers. As of now, different techniques are used to identify data\ndependencies in scalars, arrays and pointers in a program. In this paper, we\npropose a graph based Data Dependence Identifier (DDI), which is capable of\nidentifying all types of data dependencies that arise in all types of\nvariables, in polynomial time. In our proposed DDI model, for identifying data\ndependence in a program, we represent a program as graph. Though many graphical\nrepresentation of program exist, our approach of representing a program as\ngraph takes a different approach. Also using our DDI model, one can perform\nbasic transformations like dead code elimination, constant propagation, and\ninduction variable detection.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 13:22:33 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Alluru", "Kavya", ""], ["L", "Jeganathan.", ""]]}, {"id": "2102.09413", "submitter": "Joel Rybicki", "authors": "Maciej Pacut, Mahmoud Parham, Joel Rybicki, Stefan Schmid, Jukka\n  Suomela and Aleksandr Tereshchenko", "title": "Locality in Online Algorithms", "comments": "46 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online algorithms make decisions based on past inputs. In general, the\ndecision may depend on the entire history of inputs. If many computers run the\nsame online algorithm with the same input stream but are started at different\ntimes, they do not necessarily make consistent decisions.\n  In this work we introduce time-local online algorithms. These are online\nalgorithms where the output at a given time only depends on $T = O(1)$ latest\ninputs. The use of (deterministic) time-local algorithms in a distributed\nsetting automatically leads to globally consistent decisions.\n  Our key observation is that time-local online algorithms (in which the output\nat a given time only depends on local inputs in the temporal dimension) are\nclosely connected to local distributed graph algorithms (in which the output of\na given node only depends on local inputs in the spatial dimension). This makes\nit possible to interpret prior work on distributed graph algorithms from the\nperspective of online algorithms.\n  We describe an algorithm synthesis method that one can use to design optimal\ntime-local online algorithms for small values of $T$. We demonstrate the power\nof the technique in the context of a variant of the online file migration\nproblem, and show that e.g. for two nodes and unit migration costs there exists\na $3$-competitive time-local algorithm with horizon $T=4$, while no\ndeterministic online algorithm (in the classic sense) can do better. We also\nderive upper and lower bounds for a more general version of the problem; we\nshow that there is a $6$-competitive deterministic time-local algorithm and a\n$2.62$-competitive randomized time-local algorithm for any migration cost\n$\\alpha \\ge 1$.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 15:02:22 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Pacut", "Maciej", ""], ["Parham", "Mahmoud", ""], ["Rybicki", "Joel", ""], ["Schmid", "Stefan", ""], ["Suomela", "Jukka", ""], ["Tereshchenko", "Aleksandr", ""]]}, {"id": "2102.09491", "submitter": "Afaf Taik", "authors": "Afaf Taik, Zoubeir Mlika and Soumaya Cherkaoui", "title": "Data-Aware Device Scheduling for Federated Edge Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated Edge Learning (FEEL) involves the collaborative training of machine\nlearning models among edge devices, with the orchestration of a server in a\nwireless edge network. Due to frequent model updates, FEEL needs to be adapted\nto the limited communication bandwidth, scarce energy of edge devices, and the\nstatistical heterogeneity of edge devices' data distributions. Therefore, a\ncareful scheduling of a subset of devices for training and uploading models is\nnecessary. In contrast to previous work in FEEL where the data aspects are\nunder-explored, we consider data properties at the heart of the proposed\nscheduling algorithm. To this end, we propose a new scheduling scheme for\nnon-independent and-identically-distributed (non-IID) and unbalanced datasets\nin FEEL. As the data is the key component of the learning, we propose a new set\nof considerations for data characteristics in wireless scheduling algorithms in\nFEEL. In fact, the data collected by the devices depends on the local\nenvironment and usage pattern. Thus, the datasets vary in size and\ndistributions among the devices. In the proposed algorithm, we consider both\ndata and resource perspectives. In addition to minimizing the completion time\nof FEEL as well as the transmission energy of the participating devices, the\nalgorithm prioritizes devices with rich and diverse datasets. We first define a\ngeneral framework for the data-aware scheduling and the main axes and\nrequirements for diversity evaluation. Then, we discuss diversity aspects and\nsome exploitable techniques and metrics. Next, we formulate the problem and\npresent our FEEL scheduling algorithm. Evaluations in different scenarios show\nthat our proposed FEEL scheduling algorithm can help achieve high accuracy in\nfew rounds with a reduced cost.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 17:17:56 GMT"}], "update_date": "2021-02-19", "authors_parsed": [["Taik", "Afaf", ""], ["Mlika", "Zoubeir", ""], ["Cherkaoui", "Soumaya", ""]]}, {"id": "2102.09510", "submitter": "Federico Ricci-Tersenghi", "authors": "M. Bernaschi, M. Bisson, M. Fatica, E. Marinari, V. Martin-Mayor, G.\n  Parisi and F. Ricci-Tersenghi", "title": "How we are leading a 3-XORSAT challenge: from the energy landscape to\n  the algorithm and its efficient implementation on GPUs", "comments": "7 pages, 7 figure, EPL format + SM (2 pages)", "journal-ref": "EPL, 133 (2021) 60005", "doi": "10.1209/0295-5075/133/60005", "report-no": null, "categories": "cond-mat.dis-nn cond-mat.stat-mech cs.DC cs.DS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A recent 3-XORSAT challenge required to minimize a very complex and rough\nenergy function, typical of glassy models with a random first order transition\nand a golf course like energy landscape. We present the ideas beyond the\nquasi-greedy algorithm and its very efficient implementation on GPUs that are\nallowing us to rank first in such a competition. We suggest a better protocol\nto compare algorithmic performances and we also provide analytical predictions\nabout the exponential growth of the times to find the solution in terms of\nfree-energy barriers.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 17:52:32 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2021 10:58:33 GMT"}], "update_date": "2021-06-24", "authors_parsed": [["Bernaschi", "M.", ""], ["Bisson", "M.", ""], ["Fatica", "M.", ""], ["Marinari", "E.", ""], ["Martin-Mayor", "V.", ""], ["Parisi", "G.", ""], ["Ricci-Tersenghi", "F.", ""]]}, {"id": "2102.09594", "submitter": "Maria A Schett", "authors": "Maria A Schett and George Danezis", "title": "Embedding a Deterministic BFT Protocol in a Block DAG", "comments": null, "journal-ref": null, "doi": "10.1145/3465084.3467930", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This work formalizes the structure and protocols underlying recent\ndistributed systems leveraging block DAGs, which are essentially encoding\nLamport's happened-before relations between blocks, as their core network\nprimitives. We then present an embedding of any deterministic Byzantine fault\ntolerant protocol $\\mathcal{P}$ to employ a block DAG for interpreting\ninteractions between servers. Our main theorem proves that this embedding\nmaintains all safety and liveness properties of $\\mathcal{P}$. Technically, our\ntheorem is based on the insight that a block DAG merely acts as an efficient\nreliable point-to-point channel between instances of P while also using\n$\\mathcal{P}$ for efficient message compression.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 19:57:51 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 17:08:30 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Schett", "Maria A", ""], ["Danezis", "George", ""]]}, {"id": "2102.09631", "submitter": "Bradley Baker", "authors": "Bradley T. Baker, Vince D. Calhoun, Barak Pearlmutter, Sergey M. Plis", "title": "Efficient Distributed Auto-Differentiation", "comments": "8 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Although distributed machine learning has opened up numerous frontiers of\nresearch, the separation of large models across different devices, nodes, and\nsites can invite significant communication overhead, making reliable training\ndifficult.\n  The focus on gradients as the primary shared statistic during training has\nled to a number of intuitive algorithms for distributed deep learning; however,\ngradient-based algorithms for training large deep neural networks (DNNs) are\ncommunication-heavy, often requiring additional modifications via sparsity\nconstraints, compression, quantization, and other similar approaches, to lower\nbandwidth.\n  We introduce a surprisingly simple statistic for training distributed DNNs\nthat is more communication-friendly than the gradient. The error\nbackpropagation process can be modified to share these smaller intermediate\nvalues instead of the gradient, reducing communication overhead with no impact\non accuracy. The process provides the flexibility of averaging gradients during\nbackpropagation, enabling novel flexible training schemas while leaving room\nfor further bandwidth reduction via existing gradient compression methods.\nFinally, consideration of the matrices used to compute the gradient inspires a\nnew approach to compression via structured power iterations, which can not only\nreduce bandwidth but also enable introspection into distributed training\ndynamics, without significant performance loss.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2021 21:46:27 GMT"}, {"version": "v2", "created": "Mon, 22 Feb 2021 19:29:53 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Baker", "Bradley T.", ""], ["Calhoun", "Vince D.", ""], ["Pearlmutter", "Barak", ""], ["Plis", "Sergey M.", ""]]}, {"id": "2102.09688", "submitter": "Raghavendra Ramesh", "authors": "Raghavendra Ramesh", "title": "Algorithm for Cross-shard Cross-EE Atomic User-level ETH Transfer in\n  Ethereum", "comments": "11 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sharding is a way to address scalability problem in blockchain technologies.\nEthereum, a prominent blockchain technology, has included sharding in its\nroadmap to increase its throughput. The plan is also to include multiple\nexecution environments.\n  We address the problem of atomic cross shard value transfer in the presence\nof multiple execution environments. We leverage on the proposed Ethereum\narchitecture, more specificially on Beacon chain and crosslinks, and propose a\nsolution on top of the netted-balance approach that was proposed for EE-level\natomic \\eth transfers. We split a cross-shard transfer into two transactions: a\ndebit and a credit. First, the debit transaction is processed at the source\nshard. The corresponding credit transaction is processed at the destination\nshard in a subsequent block. We use {\\em netted} shard states as channels to\ncommunicate pending credits and pending reverts. We discuss various scenarios\nof debit failures and credit failures, and show our approach ensures atomicity\neven in the presence of a Byzantine Block proposer.\n  The benefits of our approach are that we do not use any locks nor impose any\nconstraints on the Block Proposer to select specific transactions. However we\ninherit the limitation of an expensive operation from the netted-balance\napproach of querying partial states from all other shards. We also show a bound\non the size of such inter-shard state reads.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 00:20:35 GMT"}, {"version": "v2", "created": "Mon, 17 May 2021 23:09:43 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Ramesh", "Raghavendra", ""]]}, {"id": "2102.09716", "submitter": "Chaodong Zheng", "authors": "Haimin Chen, Yonggang Jiang, Chaodong Zheng", "title": "Tight Trade-off in Contention Resolution without Collision Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we consider contention resolution on a multiple-access\ncommunication channel. In this problem, a set of nodes arrive over time, each\nwith a message it intends to send. In each time slot, each node may attempt to\nbroadcast its message or remain idle. If a single node broadcasts in a slot,\nthe message is received by all nodes; otherwise, if multiple nodes broadcast\nsimultaneously, a collision occurs and none succeeds. If collision detection is\navailable, nodes can differentiate collision and silence (i.e., no nodes\nbroadcast). Performance of contention resolution algorithms is often measured\nby throughput -- the number of successful transmissions within a period of\ntime; whereas robustness is often measured by jamming resistance -- a jammed\nslot always generates a collision. Previous work has shown, with collision\ndetection, optimal constant throughput can be attained, even if a constant\nfraction of all slots are jammed. The situation when collision detection is not\navailable, however, remains unclear.\n  In a recent breakthrough paper [Bender et al., STOC '20], a crucial case is\nresolved: constant throughput is possible without collision detection, but only\nif there is no jamming. Nonetheless, the exact trade-off between the best\npossible throughput and the severity of jamming remains unknown. In this paper,\nwe address this open question. Specifically, for any level of jamming ranging\nfrom none to constant fraction, we prove an upper bound on the best possible\nthroughput, along with an algorithm attaining that bound. An immediate and\ninteresting implication of our result is, when a constant fraction of all slots\nare jammed, which is the worst-case scenario, there still exists an algorithm\nachieving a decent throughput: $\\Theta(t/\\log{t})$ messages could be\nsuccessfully transmitted within $t$ slots.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 03:00:19 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Chen", "Haimin", ""], ["Jiang", "Yonggang", ""], ["Zheng", "Chaodong", ""]]}, {"id": "2102.09820", "submitter": "Yi-Jun Chang", "authors": "Yi-Jun Chang and Mohsen Ghaffari", "title": "Strong-Diameter Network Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network decomposition is a central concept in the study of distributed graph\nalgorithms. We present the first polylogarithmic-round deterministic\ndistributed algorithm with small messages that constructs a strong-diameter\nnetwork decomposition with polylogarithmic parameters.\n  Concretely, a ($C$, $D$) strong-diameter network decomposition is a\npartitioning of the nodes of the graph into disjoint clusters, colored with $C$\ncolors, such that neighboring clusters have different colors and the subgraph\ninduced by each cluster has a diameter at most $D$. In the weak-diameter\nvariant, the requirement is relaxed by measuring the diameter of each cluster\nin the original graph, instead of the subgraph induced by the cluster.\n  A recent breakthrough of Rozho\\v{n} and Ghaffari [STOC 2020] presented the\nfirst $\\text{poly}(\\log n)$-round deterministic algorithm for constructing a\nweak-diameter network decomposition where $C$ and $D$ are both in\n$\\text{poly}(\\log n)$. Their algorithm uses small $O(\\log n)$-bit messages. One\ncan transform their algorithm to a strong-diameter network decomposition\nalgorithm with similar parameters. However, that comes at the expense of\nrequiring unbounded messages. The key remaining qualitative question in the\nstudy of network decompositions was whether one can achieve a similar result\nfor strong-diameter network decompositions using small messages. We resolve\nthis question by presenting a novel technique that can transform any black-box\nweak-diameter network decomposition algorithm to a strong-diameter one, using\nsmall messages and with only moderate loss in the parameters.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 09:16:28 GMT"}, {"version": "v2", "created": "Sun, 6 Jun 2021 21:10:04 GMT"}], "update_date": "2021-06-08", "authors_parsed": [["Chang", "Yi-Jun", ""], ["Ghaffari", "Mohsen", ""]]}, {"id": "2102.09951", "submitter": "Sajib Mistry", "authors": "Sajib Mistry, Athman Bouguettaya, Lie Qu", "title": "Layer-based Composite Reputation Bootstrapping", "comments": "Accepted for publication in ACM Transactions on Internet Technology\n  (TOIT), 2021", "journal-ref": null, "doi": "10.1145/3448610", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a novel generic reputation bootstrapping framework for composite\nservices. Multiple reputation-related indicators are considered in a\nlayer-based framework to implicitly reflect the reputation of the component\nservices. The importance of an indicator on the future performance of a\ncomponent service is learned using a modified Random Forest algorithm. We\npropose a topology-aware Forest Deep Neural Network (fDNN) to find the\ncorrelations between the reputation of a composite service and reputation\nindicators of component services. The trained fDNN model predicts the\nreputation of a new composite service with the confidence value. Experimental\nresults with real-world dataset prove the efficiency of the proposed approach.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2021 15:00:30 GMT"}], "update_date": "2021-02-22", "authors_parsed": [["Mistry", "Sajib", ""], ["Bouguettaya", "Athman", ""], ["Qu", "Lie", ""]]}, {"id": "2102.10163", "submitter": "Sahasrajit Sarmasarkar", "authors": "Sahasrajit Sarmasarkar, V. Lalitha and Nikhil Karamchandani", "title": "On Gradient Coding with Partial Recovery", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a generalization of the recently proposed gradient coding\nframework where a large dataset is divided across $n$ workers and each worker\ntransmits to a master node one or more linear combinations of the gradients\nover the data subsets assigned to it. Unlike the conventional framework which\nrequires the master node to recover the sum of the gradients over all the data\nsubsets in the presence of $s$ straggler workers, we relax the goal of the\nmaster node to computing the sum of at least some $\\alpha$ fraction of the\ngradients. The broad goal of our work is to study the optimal computation and\ncommunication load per worker for this approximate gradient coding framework.\nWe begin by deriving a lower bound on the computation load of any feasible\nscheme and also propose a strategy which achieves this lower bound, albeit at\nthe cost of high communication load and a number of data partitions which can\nbe polynomial in the number of workers $n$. We then restrict attention to\nschemes which utilize a number of data partitions equal to $n$ and propose\nschemes based on cyclic assignment which have a lower communication load. When\neach worker transmits a single linear combination, we also prove lower bounds\non the computation load of any scheme using $n$ data partitions.\n", "versions": [{"version": "v1", "created": "Fri, 19 Feb 2021 21:27:31 GMT"}, {"version": "v2", "created": "Mon, 24 May 2021 20:59:52 GMT"}], "update_date": "2021-05-26", "authors_parsed": [["Sarmasarkar", "Sahasrajit", ""], ["Lalitha", "V.", ""], ["Karamchandani", "Nikhil", ""]]}, {"id": "2102.10245", "submitter": "Ahmed E. Helal", "authors": "Ahmed E. Helal, Jan Laukemann, Fabio Checconi, Jesmin Jahan Tithi,\n  Teresa Ranadive, Fabrizio Petrini, Jeewhan Choi", "title": "ALTO: Adaptive Linearized Storage of Sparse Tensors", "comments": "Accepted to ICS 2021", "journal-ref": null, "doi": "10.1145/3447818.3461703", "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of high-dimensional sparse data is becoming increasingly popular\nin many important domains. However, real-world sparse tensors are challenging\nto process due to their irregular shapes and data distributions. We propose the\nAdaptive Linearized Tensor Order (ALTO) format, a novel mode-agnostic (general)\nrepresentation that keeps neighboring nonzero elements in the multi-dimensional\nspace close to each other in memory. To generate the indexing metadata, ALTO\nuses an adaptive bit encoding scheme that trades off index computations for\nlower memory usage and more effective use of memory bandwidth. Moreover, by\ndecoupling its sparse representation from the irregular spatial distribution of\nnonzero elements, ALTO eliminates the workload imbalance and greatly reduces\nthe synchronization overhead of tensor computations. As a result, the parallel\nperformance of ALTO-based tensor operations becomes a function of their\ninherent data reuse. On a gamut of tensor datasets, ALTO outperforms an oracle\nthat selects the best state-of-the-art format for each dataset, when used in\nkey tensor decomposition operations. Specifically, ALTO achieves a geometric\nmean speedup of 8X over the best mode-agnostic (coordinate and hierarchical\ncoordinate) formats, while delivering a geometric mean compression ratio of\n4.3X relative to the best mode-specific (compressed sparse fiber) formats.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 03:32:08 GMT"}, {"version": "v2", "created": "Tue, 27 Apr 2021 07:36:07 GMT"}], "update_date": "2021-04-28", "authors_parsed": [["Helal", "Ahmed E.", ""], ["Laukemann", "Jan", ""], ["Checconi", "Fabio", ""], ["Tithi", "Jesmin Jahan", ""], ["Ranadive", "Teresa", ""], ["Petrini", "Fabrizio", ""], ["Choi", "Jeewhan", ""]]}, {"id": "2102.10319", "submitter": "Yuanqiu Mo", "authors": "Yuanqiu Mo, Soura Dasgupta, and Jacob Beal", "title": "Stability and Resilience of Distributed Information Spreading in\n  Aggregate Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SY eess.SY", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Spreading information through a network of devices is a core activity for\nmost distributed systems. As such, self-stabilizing algorithms implementing\ninformation spreading are one of the key building blocks enabling aggregate\ncomputing to provide resilient coordination in open complex distributed\nsystems. This paper improves a general spreading block in the aggregate\ncomputing literature by making it resilient to network perturbations,\nestablishes its global uniform asymptotic stability and proves that it is\nultimately bounded under persistent disturbances. The ultimate bounds depend\nonly on the magnitude of the largest perturbation and the network diameter, and\nthree design parameters trade off competing aspects of performance. For\nexample, as in many dynamical systems, values leading to greater resilience to\nnetwork perturbations slow convergence and vice versa.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 11:59:20 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Mo", "Yuanqiu", ""], ["Dasgupta", "Soura", ""], ["Beal", "Jacob", ""]]}, {"id": "2102.10340", "submitter": "Radu Dogaru", "authors": "Radu Dogaru, Ioana Dogaru", "title": "A Python Framework for Fast Modelling and Simulation of Cellular\n  Nonlinear Networks and other Finite-difference Time-domain Systems", "comments": "7 pages, preprint submitted to CSCS23 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC eess.IV", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  This paper introduces and evaluates a freely available cellular nonlinear\nnetwork simulator optimized for the effective use of GPUs, to achieve fast\nmodelling and simulations. Its relevance is demonstrated for several\napplications in nonlinear complex dynamical systems, such as slow-growth\nphenomena as well as for various image processing applications such as edge\ndetection. The simulator is designed as a Jupyter notebook written in Python\nand functionally tested and optimized to run on the freely available cloud\nplatform Google Collaboratory. Although the simulator, in its actual form, is\ndesigned to model the FitzHugh Nagumo Reaction-Diffusion cellular nonlinear\nnetwork, it can be easily adapted for any other type of finite-difference\ntime-domain model. Four implementation versions are considered, namely using\nthe PyCUDA, NUMBA respectively CUPY libraries (all three supporting GPU\ncomputations) as well as a NUMPY-based implementation to be used when GPU is\nnot available. The specificities and performances for each of the four\nimplementations are analyzed concluding that the PyCUDA implementation ensures\na very good performance being capable to run up to 14000 Mega cells per seconds\n(each cell referring to the basic nonlinear dynamic system composing the\ncellular nonlinear network).\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 13:12:19 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Dogaru", "Radu", ""], ["Dogaru", "Ioana", ""]]}, {"id": "2102.10424", "submitter": "Anastasios Kyrillidis", "authors": "Cameron R. Wolfe, Jingkang Yang, Arindam Chowdhury, Chen Dun, Artun\n  Bayer, Santiago Segarra, Anastasios Kyrillidis", "title": "GIST: Distributed Training for Large-Scale Graph Convolutional Networks", "comments": "18 pages, 4 figures, pre-print under review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC math.OC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The graph convolutional network (GCN) is a go-to solution for machine\nlearning on graphs, but its training is notoriously difficult to scale both in\nterms of graph size and the number of model parameters. Although some work has\nexplored training on large-scale graphs (e.g., GraphSAGE, ClusterGCN, etc.), we\npioneer efficient training of large-scale GCN models (i.e., ultra-wide,\noverparameterized models) with the proposal of a novel, distributed training\nframework. Our proposed training methodology, called GIST, disjointly\npartitions the parameters of a GCN model into several, smaller sub-GCNs that\nare trained independently and in parallel. In addition to being compatible with\nany GCN architecture, GIST improves model performance, scales to training on\narbitrarily large graphs, significantly decreases wall-clock training time, and\nenables the training of markedly overparameterized GCN models. Remarkably, with\nGIST, we train an astonishgly-wide 32,768-dimensional GraphSAGE model, which\nexceeds the capacity of a single GPU by a factor of 8X, to SOTA performance on\nthe Amazon2M dataset.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 19:25:38 GMT"}, {"version": "v2", "created": "Wed, 9 Jun 2021 21:11:07 GMT"}, {"version": "v3", "created": "Thu, 1 Jul 2021 13:14:57 GMT"}], "update_date": "2021-07-02", "authors_parsed": [["Wolfe", "Cameron R.", ""], ["Yang", "Jingkang", ""], ["Chowdhury", "Arindam", ""], ["Dun", "Chen", ""], ["Bayer", "Artun", ""], ["Segarra", "Santiago", ""], ["Kyrillidis", "Anastasios", ""]]}, {"id": "2102.10442", "submitter": "Pankaj Khanchandani", "authors": "Pankaj Khanchandani and Roger Wattenhofer", "title": "Byzantine Agreement with Unknown Participants and Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A set of mutually distrusting participants that want to agree on a common\nopinion must solve an instance of a Byzantine agreement problem. These problems\nhave been extensively studied in the literature. However, most of the existing\nsolutions assume that the participants are aware of $n$ -- the total number of\nparticipants in the system -- and $f$ -- an upper bound on the number of\nByzantine participants. In this paper, we show that most of the fundamental\nagreement problems can be solved without affecting resiliency even if the\nparticipants do not know the values of (possibly changing) $n$ and $f$.\nSpecifically, we consider a synchronous system where the participants have\nunique but not necessarily consecutive identifiers, and give Byzantine\nagreement algorithms for reliable broadcast, approximate agreement,\nrotor-coordinator, early terminating consensus and total ordering in static and\ndynamic systems, all with the optimal resiliency of $n> 3f$. Moreover, we show\nthat synchrony is necessary as an agreement with probabilistic termination is\nimpossible in a semi-synchronous or asynchronous system if the participants are\nunaware of $n$ and $f$.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2021 20:53:49 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Khanchandani", "Pankaj", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "2102.10513", "submitter": "Rohan Sarkar", "authors": "Rohan Sarkar and Avinash C. Kak", "title": "CheckSoft : A Scalable Event-Driven Software Architecture for Keeping\n  Track of People and Things in People-Centric Spaces", "comments": "33 pages, 25 figures, 6 Tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.AI cs.DC eess.IV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present CheckSoft, a scalable event-driven software architecture for\nkeeping track of people-object interactions in people-centric applications such\nas airport checkpoint security areas, automated retail stores, smart libraries,\nand so on. The architecture works off the video data generated in real time by\na network of surveillance cameras. Although there are many different aspects to\nautomating these applications, the most difficult part of the overall problem\nis keeping track of the interactions between the people and the objects.\nCheckSoft uses finite-state-machine (FSM) based logic for keeping track of such\ninteractions which allows the system to quickly reject any false detections of\nthe interactions by the video cameras. CheckSoft is easily scalable since the\narchitecture is based on multi-processing in which a separate process is\nassigned to each human and to each \"storage container\" for the objects. A\nstorage container may be a shelf on which the objects are displayed or a bin in\nwhich the objects are stored, depending on the specific application in which\nCheckSoft is deployed.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 05:22:55 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Sarkar", "Rohan", ""], ["Kak", "Avinash C.", ""]]}, {"id": "2102.10566", "submitter": "Milliam Maxime Zekeng Ndadji", "authors": "Milliam Maxime Zekeng Ndadji, Maurice Tchoup\\'e Tchendji, Cl\\'ementin\n  Tayou Djamegni, Didier Parigot", "title": "A Projection-Stable Grammatical Model for the Distributed Execution of\n  Administrative Processes with Emphasis on Actors' Views", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC cs.FL", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  During the last two decades, the decentralized execution of business\nprocesses has been one of the main research topics in Business Process\nManagement. Several models (languages) for processes' specification in order to\nfacilitate their distributed execution, have been proposed. LSAWfP is among the\nmost recent in this area: it helps to specify administrative processes with\ngrammatical models indicating, in addition to their fundamental elements, the\npermissions (reading, writing and execution) of each actor in relation to each\nof their tasks. In this paper, we present a model for a completely\ndecentralized and artifact-centric execution of administrative processes\nspecified using LSAWfP. The presented model puts particular emphasis on actors'\nviews: it then allows the confidential execution of certain tasks by ensuring\nthat, each actor potentially has only a partial perception of the processes'\nglobal execution states. The model thus solves a very important problem in\nbusiness process execution, which is often sidelined in existing approaches. To\naccomplish this, the model rely on three projection algorithms allowing to\npartially replicate the processes' global execution states at a given moment,\nto consistently update the obtained partial states and to deduce new coherent\nglobal states. The proposal of these three algorithms, the proof of underlying\nmathematical tools' stability and a proposal of their implementation, are this\npaper's main contributions.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 09:33:31 GMT"}, {"version": "v2", "created": "Sat, 27 Mar 2021 20:40:53 GMT"}], "update_date": "2021-03-30", "authors_parsed": [["Ndadji", "Milliam Maxime Zekeng", ""], ["Tchendji", "Maurice Tchoup\u00e9", ""], ["Djamegni", "Cl\u00e9mentin Tayou", ""], ["Parigot", "Didier", ""]]}, {"id": "2102.10597", "submitter": "Shir Cohen", "authors": "Shir Cohen and Idit Keidar", "title": "Tame the Wild with Byzantine Linearizability: Reliable Broadcast,\n  Snapshots, and Asset Transfer", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formalize Byzantine linearizability, a correctness condition that\nspecifies whether a concurrent object with a sequential specification is\nresilient against Byzantine failures. Using this definition, we systematically\nstudy Byzantine-tolerant emulations of various objects from registers. We focus\non three useful objects -- reliable broadcast, atomic snapshot, and asset\ntransfer. We prove that there is an $f$-resilient implementation of such\nobjects from registers with $n$ processes $f<\\frac{n}{2}$.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2021 12:51:10 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Cohen", "Shir", ""], ["Keidar", "Idit", ""]]}, {"id": "2102.10800", "submitter": "Abdelrahman Hosny", "authors": "Abdelrahman Hosny and Sherief Reda", "title": "Characterizing and Optimizing EDA Flows for the Cloud", "comments": "Presented at DATE2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Cloud computing accelerates design space exploration in logic synthesis, and\nparameter tuning in physical design. However, deploying EDA jobs on the cloud\nrequires EDA teams to deeply understand the characteristics of their jobs in\ncloud environments. Unfortunately, there has been little to no public\ninformation on these characteristics. Thus, in this paper, we formulate the\nproblem of migrating EDA jobs to the cloud. First, we characterize the\nperformance of four main EDA applications, namely: synthesis, placement,\nrouting and static timing analysis. We show that different EDA jobs require\ndifferent machine configurations. Second, using observations from our\ncharacterization, we propose a novel model based on Graph Convolutional\nNetworks to predict the total runtime of a given application on different\nmachine configurations. Our model achieves a prediction accuracy of 87%. Third,\nwe develop a new formulation for optimizing cloud deployments in order to\nreduce deployment costs while meeting deadline constraints. We present a\npseudo-polynomial optimal solution using a multi-choice knapsack mapping that\nreduces costs by 35.29%.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 06:51:09 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Hosny", "Abdelrahman", ""], ["Reda", "Sherief", ""]]}, {"id": "2102.10802", "submitter": "Praneeth Vepakomma", "authors": "Praneeth Vepakomma, Julia Balla, Ramesh Raskar", "title": "Differentially Private Supervised Manifold Learning with Applications\n  like Private Image Retrieval", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.CV cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Differential Privacy offers strong guarantees such as immutable privacy under\npost processing. Thus it is often looked to as a solution to learning on\nscattered and isolated data. This work focuses on supervised manifold learning,\na paradigm that can generate fine-tuned manifolds for a target use case. Our\ncontributions are two fold. 1) We present a novel differentially private method\n\\textit{PrivateMail} for supervised manifold learning, the first of its kind to\nour knowledge. 2) We provide a novel private geometric embedding scheme for our\nexperimental use case. We experiment on private \"content based image retrieval\"\n- embedding and querying the nearest neighbors of images in a private manner -\nand show extensive privacy-utility tradeoff results, as well as the\ncomputational efficiency and practicality of our methods.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 06:58:46 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Vepakomma", "Praneeth", ""], ["Balla", "Julia", ""], ["Raskar", "Ramesh", ""]]}, {"id": "2102.10837", "submitter": "Subho Sankar Banerjee", "authors": "Subho S. Banerjee, Saurabh Jha, Zbigniew T. Kalbarczyk, Ravishankar K.\n  Iyer", "title": "BayesPerf: Minimizing Performance Monitoring Errors Using Bayesian\n  Statistics", "comments": null, "journal-ref": "Proceedings of the Twenty-Sixth International Conference on\n  Architectural Support for Programming Languages and Operating Systems (ASPLOS\n  21), 2021", "doi": "10.1145/3445814.3446739", "report-no": null, "categories": "cs.DC cs.AI cs.AR cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hardware performance counters (HPCs) that measure low-level architectural and\nmicroarchitectural events provide dynamic contextual information about the\nstate of the system. However, HPC measurements are error-prone due to non\ndeterminism (e.g., undercounting due to event multiplexing, or OS\ninterrupt-handling behaviors). In this paper, we present BayesPerf, a system\nfor quantifying uncertainty in HPC measurements by using a domain-driven\nBayesian model that captures microarchitectural relationships between HPCs to\njointly infer their values as probability distributions. We provide the design\nand implementation of an accelerator that allows for low-latency and low-power\ninference of the BayesPerf model for x86 and ppc64 CPUs. BayesPerf reduces the\naverage error in HPC measurements from 40.1% to 7.6% when events are being\nmultiplexed. The value of BayesPerf in real-time decision-making is illustrated\nwith a simple example of scheduling of PCIe transfers.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 09:00:14 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Banerjee", "Subho S.", ""], ["Jha", "Saurabh", ""], ["Kalbarczyk", "Zbigniew T.", ""], ["Iyer", "Ravishankar K.", ""]]}, {"id": "2102.10925", "submitter": "Ivan Jericevich", "authors": "Ivan Jericevich and Dharmesh Sing and Tim Gebbie", "title": "CoinTossX: An open-source low-latency high-throughput matching engine", "comments": "21 pages, 10 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA q-fin.CP q-fin.TR", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We deploy and demonstrate the CoinTossX low-latency, high-throughput,\nopen-source matching engine with orders sent using the Julia and Python\nlanguages. We show how this can be deployed for small-scale local desk-top\ntesting and discuss a larger scale, but local hosting, with multiple traded\ninstruments managed concurrently and managed by multiple clients. We then\ndemonstrate a cloud based deployment using Microsoft Azure, with large-scale\nindustrial and simulation research use cases in mind. The system is exposed and\ninteracted with via sockets using UDP SBE message protocols and can be\nmonitored using a simple web browser interface using HTTP. We give examples\nshowing how orders can be be sent to the system and market data feeds monitored\nusing the Julia and Python languages. The system is developed in Java with\norders submitted as binary encodings (SBE) via UDP protocols using the Aeron\nMedia Driver as the low-latency, high throughput message transport. The system\nseparates the order-generation and simulation environments e.g. agent-based\nmodel simulation, from the matching of orders, data-feeds and various\nmodularised components of the order-book system. This ensures a more natural\nand realistic asynchronicity between events generating orders, and the events\nassociated with order-book dynamics and market data-feeds. We promote the use\nof Julia as the preferred order submission and simulation environment.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 11:50:34 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Jericevich", "Ivan", ""], ["Sing", "Dharmesh", ""], ["Gebbie", "Tim", ""]]}, {"id": "2102.11198", "submitter": "Ruslan Savchenko", "authors": "Ruslan Savchenko", "title": "Reading from External Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS cs.PF", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Modern external memory is represented by several device classes. At present,\nHDD, SATA SSD and NVMe SSD are widely used. Recently ultra-low latency SSD such\nas Intel Optane became available on the market. Each of these types exhibits\nit's own pattern for throughput, latency and parallelism. To achieve the\nhighest performance one has to pick an appropriate I/O interface provided by\nthe operating system. In this work we present a detailed overview and\nevaluation of modern storage reading performance with regard to available Linux\nsynchronous and asynchronous interfaces. While throughout this work we aim for\nthe highest throughput we also measure latency and CPU usage. We provide this\nreport in hope the detailed results could be interesting to both researchers\nand practitioners.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 17:24:08 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Savchenko", "Ruslan", ""]]}, {"id": "2102.11245", "submitter": "Harish Dattatraya Dixit", "authors": "Harish Dattatraya Dixit, Sneha Pendharkar, Matt Beadon, Chris Mason,\n  Tejasvi Chakravarthy, Bharath Muthiah, Sriram Sankar", "title": "Silent Data Corruptions at Scale", "comments": "8 pages, 3 figures, 33 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Silent Data Corruption (SDC) can have negative impact on large-scale\ninfrastructure services. SDCs are not captured by error reporting mechanisms\nwithin a Central Processing Unit (CPU) and hence are not traceable at the\nhardware level. However, the data corruptions propagate across the stack and\nmanifest as application-level problems. These types of errors can result in\ndata loss and can require months of debug engineering time. In this paper, we\ndescribe common defect types observed in silicon manufacturing that leads to\nSDCs. We discuss a real-world example of silent data corruption within a\ndatacenter application. We provide the debug flow followed to root-cause and\ntriage faulty instructions within a CPU using a case study, as an illustration\non how to debug this class of errors. We provide a high-level overview of the\nmitigations to reduce the risk of silent data corruptions within a large\nproduction fleet. In our large-scale infrastructure, we have run a vast library\nof silent error test scenarios across hundreds of thousands of machines in our\nfleet. This has resulted in hundreds of CPUs detected for these errors, showing\nthat SDCs are a systemic issue across generations. We have monitored SDCs for a\nperiod longer than 18 months. Based on this experience, we determine that\nreducing silent data corruptions requires not only hardware resiliency and\nproduction detection mechanisms, but also robust fault-tolerant software\narchitectures.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2021 18:30:15 GMT"}], "update_date": "2021-02-23", "authors_parsed": [["Dixit", "Harish Dattatraya", ""], ["Pendharkar", "Sneha", ""], ["Beadon", "Matt", ""], ["Mason", "Chris", ""], ["Chakravarthy", "Tejasvi", ""], ["Muthiah", "Bharath", ""], ["Sankar", "Sriram", ""]]}, {"id": "2102.11619", "submitter": "Philipp Czerner", "authors": "Philipp Czerner, Javier Esparza", "title": "Lower Bounds on the State Complexity of Population Protocols", "comments": "Various minor revisions", "journal-ref": null, "doi": "10.1145/3465084.3467912", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population protocols are a model of computation in which an arbitrary number\nof indistinguishable finite-state agents interact in pairs. The goal of the\nagents is to decide by stable consensus whether their initial global\nconfiguration satisfies a given property, specified as a predicate on the set\nof all initial configurations. The state complexity of a predicate is the\nnumber of states of a smallest protocol that computes it. Previous work by\nBlondin et al. has shown that the counting predicates $x \\ge \\eta$ have state\ncomplexity $\\mathcal{O}(\\log \\eta)$ for leaderless protocols and\n$\\mathcal{O}(\\log \\log \\eta)$ for protocols with leaders. We obtain the first\nnon-trivial lower bounds: the state complexity of $x \\geq \\eta$ is\n$\\Omega(\\log\\log\\log \\eta)$ for leaderless protocols, and the inverse of a\nnon-elementary function for protocols with leaders.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 10:55:11 GMT"}, {"version": "v2", "created": "Wed, 2 Jun 2021 18:22:27 GMT"}], "update_date": "2021-06-04", "authors_parsed": [["Czerner", "Philipp", ""], ["Esparza", "Javier", ""]]}, {"id": "2102.11623", "submitter": "Ilja Behnke", "authors": "Franz Bender, Jan Jonas Brune, Nick Lauritz Keutel, Ilja Behnke, and\n  Lauritz Thamsen", "title": "PIERES: A Playground for Network Interrupt Experiments on Real-Time\n  Embedded Systems in the IoT", "comments": "The Ninth International Workshop on Load Testing and Benchmarking of\n  Software Systems (LTB 2021)", "journal-ref": "2021 Companion of the ACM/SPEC International Conference on\n  Performance Engineering (ICPE '21), 81-84", "doi": "10.1145/3447545.3451189", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  IoT devices have become an integral part of our lives and the industry. Many\nof these devices run real-time systems or are used as part of them. As these\ndevices receive network packets over IP networks, the network interface informs\nthe CPU about their arrival using interrupts that might preempt critical\nprocesses. Therefore, the question arises whether network interrupts pose a\nthreat to the real-timeness of these devices. However, there are few tools to\ninvestigate this issue. We present a playground which enables researchers to\nconduct experiments in the context of network interrupt simulation. The\nplayground comprises different network interface controller implementations,\nload generators and timing utilities. It forms a flexible and easy to use\nfoundation for future network interrupt research. We conduct two verification\nexperiments and two real world examples. The latter give insight into the\nimpact of the interrupt handling strategy parameters and the influence of\ndifferent load types on the execution time with respect to these parameters.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 10:59:47 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Bender", "Franz", ""], ["Brune", "Jan Jonas", ""], ["Keutel", "Nick Lauritz", ""], ["Behnke", "Ilja", ""], ["Thamsen", "Lauritz", ""]]}, {"id": "2102.11660", "submitter": "Davin Choo", "authors": "M\\'elanie Cambus, Davin Choo, Havu Miikonen, Jara Uitto", "title": "Massively Parallel Correlation Clustering in Bounded Arboricity Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Identifying clusters of similar elements in a set is a common task in data\nanalysis. With the immense growth of data and physical limitations on single\nprocessor speed, it is necessary to find efficient parallel algorithms for\nclustering tasks. In this paper, we study the problem of correlation clustering\nin bounded arboricity graphs with respect to the Massively Parallel Computation\n(MPC) model. More specifically, we are given a complete graph where the edges\nare either positive or negative, indicating whether pairs of vertices are\nsimilar or dissimilar. The task is to partition the vertices into clusters with\nas few disagreements as possible. That is, we want to minimize the number of\npositive inter-cluster edges and negative intra-cluster edges.\n  Consider an input graph $G$ on $n$ vertices such that the positive edges\ninduce a $\\lambda$-arboric graph. Our main result is a 3-approximation\n($\\textit{in expectation}$) algorithm that runs in $\\mathcal{O}(\\log \\lambda\n\\cdot \\textrm{poly}(\\log \\log n))$ MPC rounds in the $\\textit{strongly\nsublinear memory regime}$. This is obtained by combining structural properties\nof correlation clustering on bounded arboricity graphs with the insights of\nFischer and Noever (SODA '18) on randomized greedy MIS and the $\\texttt{PIVOT}$\nalgorithm of Ailon, Charikar, and Newman (STOC '05). Combined with known graph\nmatching algorithms, our structural property also implies an exact algorithm\nand algorithms with $\\textit{worst case}$ $(1+\\epsilon)$-approximation\nguarantees in the special case of forests, where $\\lambda=1$.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 12:26:52 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 14:36:15 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Cambus", "M\u00e9lanie", ""], ["Choo", "Davin", ""], ["Miikonen", "Havu", ""], ["Uitto", "Jara", ""]]}, {"id": "2102.11786", "submitter": "Kaan Ozkara", "authors": "Kaan Ozkara, Navjot Singh, Deepesh Data, Suhas Diggavi", "title": "QuPeL: Quantized Personalization with Applications to Federated Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Traditionally, federated learning (FL) aims to train a single global model\nwhile collaboratively using multiple clients and a server. Two natural\nchallenges that FL algorithms face are heterogeneity in data across clients and\ncollaboration of clients with {\\em diverse resources}. In this work, we\nintroduce a \\textit{quantized} and \\textit{personalized} FL algorithm QuPeL\nthat facilitates collective training with heterogeneous clients while\nrespecting resource diversity. For personalization, we allow clients to learn\n\\textit{compressed personalized models} with different quantization parameters\ndepending on their resources. Towards this, first we propose an algorithm for\nlearning quantized models through a relaxed optimization problem, where\nquantization values are also optimized over. When each client participating in\nthe (federated) learning process has different requirements of the quantized\nmodel (both in value and precision), we formulate a quantized personalization\nframework by introducing a penalty term for local client objectives against a\nglobally trained model to encourage collaboration. We develop an alternating\nproximal gradient update for solving this quantized personalization problem,\nand we analyze its convergence properties. Numerically, we show that optimizing\nover the quantization levels increases the performance and we validate that\nQuPeL outperforms both FedAvg and local training of clients in a heterogeneous\nsetting.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 16:43:51 GMT"}], "update_date": "2021-02-24", "authors_parsed": [["Ozkara", "Kaan", ""], ["Singh", "Navjot", ""], ["Data", "Deepesh", ""], ["Diggavi", "Suhas", ""]]}, {"id": "2102.11960", "submitter": "William Schultz", "authors": "William Schultz, Siyuan Zhou, Stavros Tripakis", "title": "Design and Verification of a Logless Dynamic Reconfiguration Protocol in\n  MongoDB Replication", "comments": "18 page, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a novel dynamic reconfiguration protocol for the MongoDB\nreplication system that extends and generalizes the single server\nreconfiguration protocol of the Raft consensus algorithm. Our protocol\ndecouples the processing of configuration changes from the main database\noperation log, which allows reconfigurations to proceed in cases when the main\nlog is prevented from processing new operations. Additionally, this decoupling\nallows for configuration state to be managed by a logless replicated state\nmachine, by optimizing away the explicit log and storing only the latest\nversion of the configuration, avoiding the complexities of a log-based\nprotocol. We provide a formal specification of the protocol along with results\nfrom automated verification of its safety properties. We also provide an\nexperimental evaluation of the protocol benefits, showing how reconfigurations\nare able to quickly restore a system to healthy operation in scenarios where\nnode failures have stalled the main operation log.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2021 22:03:19 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Schultz", "William", ""], ["Zhou", "Siyuan", ""], ["Tripakis", "Stavros", ""]]}, {"id": "2102.12058", "submitter": "Wei Yao", "authors": "Wei Yao, Junyi Ye, Renita Murimi, and Guiling Wang", "title": "A Survey on Consortium Blockchain Consensus Mechanisms", "comments": "under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Blockchain is a distributed ledger that is decentralized, immutable, and\ntransparent, which maintains a continuously growing list of transaction records\nordered into blocks. As the core of blockchain, the consensus algorithm is an\nagreement to validate the correctness of blockchain transactions. For example,\nBitcoin is a public blockchain where each node in Bitcoin uses the Proof of\nWork (PoW) algorithm to reach a consensus by competing to solve a puzzle.\nUnlike a public blockchain, a consortium blockchain is an enterprise-level\nblockchain that does not contend with the issues of creating a resource-saving\nglobal consensus protocol. This paper highilights several state-of-the art\nsolutions in consensus algorithms for enterprise blockchain. For example, the\nHyperLedger by Linux Foundation includes implementing Practical Byzantine Fault\nTolerance (PBFT) as the consensus algorithm. PBFT can tolerate a range of\nmalicious nodes and reach consensus with quadratic complexity. Another\nconsensus algorithm, HotStuff, implemented by Facebook Libra project, has\nachieved linear complexity of the authenticator. This paper presents the\noperational mechanisms of these and other consensus protocols, and analyzes and\ncompares their advantages and drawbacks.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 04:19:50 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Yao", "Wei", ""], ["Ye", "Junyi", ""], ["Murimi", "Renita", ""], ["Wang", "Guiling", ""]]}, {"id": "2102.12156", "submitter": "Luidnel Maignan", "authors": "Alexandre Fernandez (LACL), Luidnel Maignan (LACL), Antoine Spicher\n  (LACL)", "title": "Cellular Automata and Kan Extensions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA math.CT math.DS nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we formalize precisely the sense in which the application of\ncellular automaton to partial configuration is a natural extension of its local\ntransition function through the categorical notion of Kan extension. In fact,\nthe two possible ways to do such an extension and the ingredients involved in\ntheir definition are related through Kan extensions in many ways. These\nrelations provide additional links between computer science and category\ntheory, and also give a new point of view on the famous Curtis-Hedlung theorem\nof cellular automata from the extended topological point of view provided by\ncategory theory. These relations provide additional links between computer\nscience and category theory. No prior knowledge of category theory is assumed.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 09:24:40 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 09:40:11 GMT"}], "update_date": "2021-03-05", "authors_parsed": [["Fernandez", "Alexandre", "", "LACL"], ["Maignan", "Luidnel", "", "LACL"], ["Spicher", "Antoine", "", "LACL"]]}, {"id": "2102.12221", "submitter": "Sheik Mohammad Mostakim Fattah", "authors": "Sheik Mohammad Mostakim Fattah, Athman Bouguettaya, and Sajib Mistry", "title": "A CP-Net based Qualitative Composition Approach for an IaaS Provider", "comments": "published in The 19th International Conference on Web Information\n  Systems Engineering (WISE) 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel CP-Net based composition approach to qualitatively select\nan optimal set of consumers for an IaaS provider. The IaaS provider's and\nconsumers' qualitative preferences are captured using CP-Nets. We propose a\nCP-Net composability model using the semantic congruence property of a\nqualitative composition. A greedy-based and a heuristic-based consumer\nselection approaches are proposed that effectively reduce the search space of\ncandidate consumers in the composition. Experimental results prove the\nfeasibility of the proposed composition approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 11:21:20 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Fattah", "Sheik Mohammad Mostakim", ""], ["Bouguettaya", "Athman", ""], ["Mistry", "Sajib", ""]]}, {"id": "2102.12222", "submitter": "Sheik Mohammad Mostakim Fattah", "authors": "Sheik Mohammad Mostakim Fattah, Athman Bouguettaya, and Sajib Mistry", "title": "Long-term IaaS Provider Selection using Short-term Trial Experience", "comments": "published in IEEE ICWS 2019", "journal-ref": null, "doi": "10.1109/ICWS.2019.00058", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel approach to select privacy-sensitive IaaS providers for a\nlong-term period. The proposed approach leverages a consumer's short-term trial\nexperiences for long-term selection. We design a novel equivalence partitioning\nbased trial strategy to discover the temporal and unknown QoS performance\nvariability of an IaaS provider. The consumer's long-term workloads are\npartitioned into multiple Virtual Machines in the short-term trial. We propose\na performance fingerprint matching approach to ascertain the confidence of the\nconsumer's trial experience. A trial experience transformation method is\nproposed to estimate the actual long-term performance of the provider.\nExperimental results with real-world datasets demonstrate the efficiency of the\nproposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 11:22:53 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Fattah", "Sheik Mohammad Mostakim", ""], ["Bouguettaya", "Athman", ""], ["Mistry", "Sajib", ""]]}, {"id": "2102.12236", "submitter": "Xiao Liu Dr", "authors": "Xuejun Li, Tianxiang Chen, Dong Yuan, Jia Xu, Xiao Liu", "title": "A Novel Graph-based Computation Offloading Strategy for Workflow\n  Applications in Mobile Edge Computing", "comments": "14 pages, 16 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the fast development of mobile edge computing (MEC), there is an\nincreasing demand for running complex applications on the edge. These complex\napplications can be represented as workflows where task dependencies are\nexplicitly specified. To achieve better Quality of Service (QoS), for instance,\nfaster response time and lower energy consumption, computation offloading is\nwidely used in the MEC environment. However, many existing computation\noffloading strategies only focus on independent computation tasks but overlook\nthe task dependencies. Meanwhile, most of these strategies are based on search\nalgorithms such as particle swarm optimization (PSO), genetic algorithm (GA)\nwhich are often time-consuming and hence not suitable for many delay-sensitive\ncomplex applications in MEC. Therefore, a highly efficient graph-based strategy\nwas proposed in our recent work but it can only deal with simple workflow\napplications with linear (namely sequential) structure. For solving these\nproblems, a novel graph-based strategy is proposed for workflow applications in\nMEC. Specifically, this strategy can deal with complex workflow applications\nwith nonlinear (viz. parallel, selective and iterative) structures. Meanwhile,\nthe offloading decision plan with the lowest energy consumption of the\nend-device under the deadline constraint can be found by using the graph-based\npartition technique. We have comprehensively evaluated our strategy using both\na real-world case study on a MEC based UAV (Unmanned Aerial Vehicle) delivery\nsystem and extensive simulation experiments on the FogWorkflowSim platform for\nMEC based workflow applications. The evaluation results successfully\ndemonstrate the effectiveness of our proposed strategy and its overall better\nperformance than other representative strategies.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 11:59:42 GMT"}], "update_date": "2021-02-25", "authors_parsed": [["Li", "Xuejun", ""], ["Chen", "Tianxiang", ""], ["Yuan", "Dong", ""], ["Xu", "Jia", ""], ["Liu", "Xiao", ""]]}, {"id": "2102.12416", "submitter": "Jaemin Choi", "authors": "Jaemin Choi, Zane Fink, Sam White, Nitin Bhat, David F. Richards,\n  Laxmikant V. Kale", "title": "GPU-aware Communication with UCX in Parallel Programming Models:\n  Charm++, MPI, and Python", "comments": "10 pages, 16 figures, to appear at IPDPS AsHES Workshop 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an increasing number of leadership-class systems embrace GPU accelerators\nin the race towards exascale, efficient communication of GPU data is becoming\none of the most critical components of high-performance computing. For\ndevelopers of parallel programming models, implementing support for GPU-aware\ncommunication using native APIs for GPUs such as CUDA can be a daunting task as\nit requires considerable effort with little guarantee of performance. In this\nwork, we demonstrate the capability of the Unified Communication X (UCX)\nframework to compose a GPU-aware communication layer that serves multiple\nparallel programming models of the Charm++ ecosystem: Charm++, Adaptive MPI\n(AMPI), and Charm4py. We demonstrate the performance impact of our designs with\nmicrobenchmarks adapted from the OSU benchmark suite, obtaining improvements in\nlatency of up to 10.2x, 11.7x, and 17.4x in Charm++, AMPI, and Charm4py,\nrespectively. We also observe increases in bandwidth of up to 9.6x in Charm++,\n10x in AMPI, and 10.5x in Charm4py. We show the potential impact of our designs\non real-world applications by evaluating a proxy application for the Jacobi\niterative method, improving the communication performance by up to 12.4x in\nCharm++, 12.8x in AMPI, and 19.7x in Charm4py.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 17:14:13 GMT"}, {"version": "v2", "created": "Thu, 1 Apr 2021 03:08:31 GMT"}], "update_date": "2021-04-02", "authors_parsed": [["Choi", "Jaemin", ""], ["Fink", "Zane", ""], ["White", "Sam", ""], ["Bhat", "Nitin", ""], ["Richards", "David F.", ""], ["Kale", "Laxmikant V.", ""]]}, {"id": "2102.12528", "submitter": "Aymeric Dieuleveut", "authors": "Constantin Philippenko and Aymeric Dieuleveut", "title": "Preserved central model for faster bidirectional compression in\n  distributed settings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.ST stat.TH", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We develop a new approach to tackle communication constraints in a\ndistributed learning problem with a central server. We propose and analyze a\nnew algorithm that performs bidirectional compression and achieves the same\nconvergence rate as algorithms using only uplink (from the local workers to the\ncentral server) compression. To obtain this improvement, we design MCM, an\nalgorithm such that the downlink compression only impacts local models, while\nthe global model is preserved. As a result, and contrary to previous works, the\ngradients on local servers are computed on perturbed models. Consequently,\nconvergence proofs are more challenging and require a precise control of this\nperturbation. To ensure it, MCM additionally combines model compression with a\nmemory mechanism. This analysis opens new doors, e.g. incorporating worker\ndependent randomized-models and partial participation.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 19:48:20 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Philippenko", "Constantin", ""], ["Dieuleveut", "Aymeric", ""]]}, {"id": "2102.12598", "submitter": "Sheik Mohammad Mostakim Fattah", "authors": "Sajib Mistry, Sheik Mohammad Mostakim Fattah, and Athman Bouguettaya", "title": "Sequential Learning-based IaaS Composition", "comments": "to appear in ACM Transactions Web in 2021", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We propose a novel IaaS composition framework that selects an optimal set of\nconsumer requests according to the provider's qualitative preferences on\nlong-term service provisions. Decision variables are included in the temporal\nconditional preference networks (TempCP-net) to represent qualitative\npreferences for both short-term and long-term consumers. The global preference\nranking of a set of requests is computed using a \\textit{k}-d tree indexing\nbased temporal similarity measure approach. We propose an extended\nthree-dimensional Q-learning approach to maximize the global preference\nranking. We design the on-policy based sequential selection learning approach\nthat applies the length of request to accept or reject requests in a\ncomposition. The proposed on-policy based learning method reuses historical\nexperiences or policies of sequential optimization using an agglomerative\nclustering approach. Experimental results prove the feasibility of the proposed\nframework.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 23:16:01 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Mistry", "Sajib", ""], ["Fattah", "Sheik Mohammad Mostakim", ""], ["Bouguettaya", "Athman", ""]]}, {"id": "2102.12660", "submitter": "Mohammad Mahdi Kamani", "authors": "Yuyang Deng, Mohammad Mahdi Kamani, Mehrdad Mahdavi", "title": "Distributionally Robust Federated Averaging", "comments": "Published in NeurIPS 2020:\n  https://proceedings.neurips.cc/paper/2020/hash/ac450d10e166657ec8f93a1b65ca1b14-Abstract.html", "journal-ref": "Advances in Neural Information Processing Systems (NeurIPS), Vol.\n  33, 2020", "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we study communication efficient distributed algorithms for\ndistributionally robust federated learning via periodic averaging with adaptive\nsampling. In contrast to standard empirical risk minimization, due to the\nminimax structure of the underlying optimization problem, a key difficulty\narises from the fact that the global parameter that controls the mixture of\nlocal losses can only be updated infrequently on the global stage. To\ncompensate for this, we propose a Distributionally Robust Federated Averaging\n(DRFA) algorithm that employs a novel snapshotting scheme to approximate the\naccumulation of history gradients of the mixing parameter. We analyze the\nconvergence rate of DRFA in both convex-linear and nonconvex-linear settings.\nWe also generalize the proposed idea to objectives with regularization on the\nmixture parameter and propose a proximal variant, dubbed as DRFA-Prox, with\nprovable convergence rates. We also analyze an alternative optimization method\nfor regularized cases in strongly-convex-strongly-concave and non-convex (under\nPL condition)-strongly-concave settings. To the best of our knowledge, this\npaper is the first to solve distributionally robust federated learning with\nreduced communication, and to analyze the efficiency of local descent methods\non distributed minimax problems. We give corroborating experimental evidence\nfor our theoretical results in federated learning settings.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 03:32:09 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Deng", "Yuyang", ""], ["Kamani", "Mohammad Mahdi", ""], ["Mahdavi", "Mehrdad", ""]]}, {"id": "2102.12717", "submitter": "Neda Mohammadi", "authors": "Hoda Taheri, Faeze Ramezani, Neda Mohammadi, Parisa Khoshdel, Bahareh\n  Taghavi, Neda Khorasani, Saeid Abrishami, and Abbas Rasoolzadegan", "title": "Cloud Broker: A Systematic Mapping Study", "comments": "43 pages, 21 Tables, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DL cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current systematic review includes a comprehensive 3-tier strategy\n(manual search, backward snowballing, and database search). The accuracy of the\nsearch methodology has been analyzed in terms of extracting related studies and\ncollecting comprehensive and complete information in a supplementary file. In\nthe search methodology, qualitative criteria have been defined to select\nstudies with the highest quality and the most relevant among all search spaces.\nAlso, some queries have been created using important keywords in the field\nunder study in order to find studies related to the field of the cloud broker.\nOut of 1928 extracted search spaces, 171 search spaces have been selected based\non defined quality criteria. Then, 1298 studies have been extracted from the\nselected search spaces and have been selected 496 high-quality papers published\nin prestigious journals, conferences, and workshops that the advent of them\nhave been from 2009 until the end of 2019. In Systematic Mapping Study (SMS), 8\nresearch questions have been designed to achieve goals such as identifying the\nmost important and hottest topics in the field of cloud broker, identifying\nexisting trends and issues, identifying active researchers and countries in the\ncloud broker field, a variety of commonly used techniques in building cloud\nbrokers, variety of evaluation methods, the amount of research conducted in\nthis field by year and place of publication and the identification of the most\nimportant active search spaces.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 07:36:21 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Taheri", "Hoda", ""], ["Ramezani", "Faeze", ""], ["Mohammadi", "Neda", ""], ["Khoshdel", "Parisa", ""], ["Taghavi", "Bahareh", ""], ["Khorasani", "Neda", ""], ["Abrishami", "Saeid", ""], ["Rasoolzadegan", "Abbas", ""]]}, {"id": "2102.12740", "submitter": "Aravind Sankaran", "authors": "Aravind Sankaran and Paolo Bientinesi", "title": "Performance Comparison for Scientific Computations on the Edge via\n  Relative Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a typical Internet-of-Things setting that involves scientific\napplications, a target computation can be evaluated in many different ways\ndepending on the split of computations among various devices. On the one hand,\ndifferent implementations (or algorithms)--equivalent from a mathematical\nperspective--might exhibit significant difference in terms of performance. On\nthe other hand, some of the implementations are likely to show similar\nperformance characteristics. In this paper, we focus on analyzing the\nperformance of a given set of algorithms by clustering them into performance\nclasses. To this end, we use a measurement-based approach to evaluate and score\nalgorithms based on pair-wise comparisons; we refer to this approach\nas\"Relative performance analysis\". Each comparison yields one of three\noutcomes: one algorithm can be \"better\", \"worse\", or \"equivalent\" to another;\nthose algorithms evaluating to have equivalent performance are merged into the\nsame performance class. We show that our clustering methodology facilitates\nalgorithm selection with respect to more than one metric; for instance, from\nthe subset of equivalently fast algorithms, one could then select an algorithm\nthat consumes the least energy on a certain device.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 09:10:27 GMT"}, {"version": "v2", "created": "Wed, 3 Mar 2021 09:37:21 GMT"}], "update_date": "2021-03-04", "authors_parsed": [["Sankaran", "Aravind", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "2102.12751", "submitter": "Muhammad Imran", "authors": "Muhammad Imran, Valentin Kuznetsov, Lina Marcella, Katarzyna Maria\n  Dziedziniewicz-Wojcik, Andreas Pfeiffer, Panos Paparrigopoulos", "title": "Migration of CMSWEB Cluster at CERN to Kubernetes", "comments": null, "journal-ref": null, "doi": "10.22323/1.390.0911", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  The CMS experiment heavily relies on the CMSWEB cluster to host critical\nservices for its operational needs. The cluster is deployed on virtual machines\n(VMs) from the CERN OpenStack cloud and is manually maintained by operators and\ndevelopers. The release cycle is composed of several steps, from building RPMs,\ntheir deployment to perform validation, and integration tests. To enhance the\nsustainability of the CMSWEB cluster, CMS decided to migrate its cluster to a\ncontainerized solution such as Docker, orchestrated with Kubernetes (k8s). This\nallows us to significantly reduce the release upgrade cycle, follow the\nend-to-end deployment procedure, and reduce operational cost. This paper gives\nan overview of the current CMSWEB cluster and its issues. We describe the new\narchitecture of the CMSWEB cluster in Kubernetes. We also provide a comparison\nof VM and Kubernetes deployment approaches and report on lessons learned during\nthe migration process.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 09:42:47 GMT"}], "update_date": "2021-05-31", "authors_parsed": [["Imran", "Muhammad", ""], ["Kuznetsov", "Valentin", ""], ["Marcella", "Lina", ""], ["Dziedziniewicz-Wojcik", "Katarzyna Maria", ""], ["Pfeiffer", "Andreas", ""], ["Paparrigopoulos", "Panos", ""]]}, {"id": "2102.12770", "submitter": "Martin Grambow", "authors": "Martin Grambow, Tobias Pfandzelter, Luk Burchard, Carsten Schubert,\n  Max Zhao, David Bermbach", "title": "BeFaaS: An Application-Centric Benchmarking Framework for FaaS Platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Following the increasing interest and adoption of FaaS systems, benchmarking\nframeworks for determining non-functional properties have also emerged. While\nexisting (microbenchmark) frameworks only evaluate single aspects of FaaS\nplatforms, a more holistic, application-driven approach is still missing.\n  In this paper, we design and present BeFaaS, an application-centric\nbenchmarking framework for FaaS environments that focuses on the evaluation\nwith realistic and typical use cases for FaaS applications. BeFaaS comes with\ntwo built-in benchmarks (an e-commerce and an IoT application), is extensible\nfor new workload profiles and new platforms, supports federated benchmark runs\nin which the benchmark application is distributed over multiple providers, and\nsupports a fine-grained result analysis.\n  Our evaluation compares three major FaaS providers in single cloud provider\nsetups and analyzes the traces of a federated fog setup. It shows that BeFaaS\nis capable of running each benchmark automatically with minimal configuration\neffort and providing detailed insights for each interaction.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 10:29:01 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Grambow", "Martin", ""], ["Pfandzelter", "Tobias", ""], ["Burchard", "Luk", ""], ["Schubert", "Carsten", ""], ["Zhao", "Max", ""], ["Bermbach", "David", ""]]}, {"id": "2102.12786", "submitter": "Nicolas Nicolaou", "authors": "Antonio Fernandez Anta, Chryssis Georgiou, Theophanis Hadjistasi,\n  Nicolas Nicolaou, Efstathios Stavrakis, Andria Trigeorgi", "title": "Fragmented Objects: Boosting Concurrency of Shared Large Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This work examines strategies to handle large shared data objects in\ndistributed storage systems (DSS), while boosting the number of concurrent\naccesses, maintaining strong consistency guarantees, and ensuring good\noperation performance. To this respect, we define the notion of fragmented\nobjects:con-current objects composed of a list of fragments (or blocks) that\nallow operations to manipulate each of their fragments individually. As the\nfragments belong to the same object, it is not enough that each fragment is\nlinearizable to have useful consistency guarantees in the composed object.\nHence, we capture the consistency semantic of the whole object with the notion\nof fragmented linearizability. Then, considering that a variance of\nlinearizability, coverability, is more suited for versioned objects like files,\nwe provide an implementation of a distributed file system, called COBFS, that\nutilizes coverable fragmented objects (i.e., files).In COBFS, each file is a\nlinked-list of coverable block objects. Preliminary emulation of COBFS\ndemonstrates the potential of our approach in boosting the concurrency of\nstrongly consistent large objects.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 11:17:41 GMT"}, {"version": "v2", "created": "Sun, 7 Mar 2021 09:06:10 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Anta", "Antonio Fernandez", ""], ["Georgiou", "Chryssis", ""], ["Hadjistasi", "Theophanis", ""], ["Nicolaou", "Nicolas", ""], ["Stavrakis", "Efstathios", ""], ["Trigeorgi", "Andria", ""]]}, {"id": "2102.12787", "submitter": "Yuval Emek", "authors": "Yuval Emek and Eyal Keren", "title": "A Thin Self-Stabilizing Asynchronous Unison Algorithm with Applications\n  to Fault Tolerant Biological Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Introduced by Emek and Wattenhofer (PODC 2013), the \\emph{stone age (SA)}\nmodel provides an abstraction for network algorithms distributed over\nrandomized finite state machines. This model, designed to resemble the dynamics\nof biological processes in cellular networks, assumes a weak communication\nscheme that is built upon the nodes' ability to sense their vicinity in an\nasynchronous manner. Recent works demonstrate that the weak computation and\ncommunication capabilities of the SA model suffice for efficient solutions to\nsome core tasks in distributed computing, but they do so under the (somewhat\nless realistic) assumption of fault free computations. In this paper, we\ninitiate the study of \\emph{self-stabilizing} SA algorithms that are guaranteed\nto recover from any combination of transient faults. Specifically, we develop\nefficient self-stabilizing SA algorithms for the \\emph{leader election} and\n\\emph{maximal independent set} tasks in bounded diameter graphs subject to an\nasynchronous scheduler. These algorithms rely on a novel efficient\nself-stabilizing \\emph{asynchronous unison (AU)} algorithm that is \"thin\" in\nterms of its state space: the number of states used by the AU algorithm is\nlinear in the graph's diameter bound, irrespective of the number of nodes.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 11:19:03 GMT"}, {"version": "v2", "created": "Tue, 18 May 2021 09:53:04 GMT"}], "update_date": "2021-05-19", "authors_parsed": [["Emek", "Yuval", ""], ["Keren", "Eyal", ""]]}, {"id": "2102.12796", "submitter": "Johannes Hofmann", "authors": "Johannes Hofmann", "title": "libtxsize -- a library for automated Bitcoin transaction-size estimates", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents libtxsize, a library to estimate the size requirements of\narbitrary Bitcoin transactions. To account for different use cases, the library\nprovides estimates in bytes, virtual bytes, and weight units. In addition to\nall currently existing input, output, and witness types, the library also\nsupports estimates for the anticipated Pay-to-Taproot transaction type, so that\nestimates can be used as input for models attempting to quantify the impact of\nTaproot on Bitcoin's scalability. libtxsize is based on analytic models, whose\ncredibility is established through first-principle analysis of transaction\ntypes as well as exhaustive empirical validation. Consequently, the paper can\nalso serve as reference for different Bitcoin data and transaction types, their\nsemantics, and their size requirements (both from an analytic and empirical\npoint of view).\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 11:50:46 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Hofmann", "Johannes", ""]]}, {"id": "2102.12825", "submitter": "Andrei Tonkikh", "authors": "Petr Kuznetsov, Andrei Tonkikh, Yan X Zhang", "title": "Revisiting Optimal Resilience of Fast Byzantine Consensus (Extended\n  Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is a common belief that Byzantine fault-tolerant solutions for consensus\nare significantly slower than their crash fault-tolerant counterparts. Indeed,\nin PBFT, the most widely known Byzantine fault-tolerant consensus protocol, it\ntakes three message delays to decide a value, in contrast with just two in\nPaxos. This motivates the search for fast Byzantine consensus algorithms that\ncan produce decisions after just two message delays \\emph{in the common case},\ne.g., under the assumption that the current leader is correct and not suspected\nby correct processes. The (optimal) two-step latency comes with the cost of\nlower resilience: fast Byzantine consensus requires more processes to tolerate\nthe same number of faults. In particular, $5f+1$ processes were claimed to be\nnecessary to tolerate $f$ Byzantine failures.\n  In this paper, we present a fast Byzantine consensus algorithm that relies on\njust $5f-1$ processes. Moreover, we show that $5f-1$ is the tight lower bound,\ncorrecting a mistake in the earlier work. While the difference of just $2$\nprocesses may appear insignificant for large values of $f$, it can be crucial\nfor systems of a smaller scale. In particular, for $f=1$, our algorithm\nrequires only $4$ processes, which is optimal for any (not necessarily fast)\npartially synchronous Byzantine consensus algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 12:53:34 GMT"}, {"version": "v2", "created": "Tue, 8 Jun 2021 19:22:27 GMT"}, {"version": "v3", "created": "Tue, 27 Jul 2021 17:30:12 GMT"}], "update_date": "2021-07-28", "authors_parsed": [["Kuznetsov", "Petr", ""], ["Tonkikh", "Andrei", ""], ["Zhang", "Yan X", ""]]}, {"id": "2102.12892", "submitter": "Marc Brooker", "authors": "Marc Brooker and Adrian Costin Catangiu and Mike Danilov and Alexander\n  Graf and Colm MacCarthaigh and Andrei Sandu", "title": "Restoring Uniqueness in MicroVM Snapshots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Code initialization -- the step of loading code, executing static code,\nfilling caches, and forming re-used connections -- tends to dominate cold-start\ntime in serverless compute systems such as AWS Lambda. Post-initialization\nmemory snapshots, cloned and restored on start, have emerged as a viable\nsolution to this problem, with incremental snapshot and fast restore support in\nVMMs like Firecracker.\n  Saving memory introduces the challenge of managing high-value memory\ncontents, such as cryptographic secrets. Cloning introduces the challenge of\nrestoring the uniqueness of the VMs, to allow them to do unique things like\ngenerate UUIDs, secrets, and nonces. This paper examines solutions to these\nproblems in the every microsecond counts context of serverless cold-start, and\ndiscusses the state-of-the-art of available solutions. We present two new\ninterfaces aimed at solving this problem -- MADV\\_WIPEONSUSPEND and SysGenId --\nand compare them to alternative solutions.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2021 21:56:28 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Brooker", "Marc", ""], ["Catangiu", "Adrian Costin", ""], ["Danilov", "Mike", ""], ["Graf", "Alexander", ""], ["MacCarthaigh", "Colm", ""], ["Sandu", "Andrei", ""]]}, {"id": "2102.12920", "submitter": "Shaoxiong Ji", "authors": "Shaoxiong Ji and Teemu Saravirta and Shirui Pan and Guodong Long and\n  Anwar Walid", "title": "Emerging Trends in Federated Learning: From Model Fusion to Federated X\n  Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Federated learning is a new learning paradigm that decouples data collection\nand model training via multi-party computation and model aggregation. As a\nflexible learning setting, federated learning has the potential to integrate\nwith other learning frameworks. We conduct a focused survey of federated\nlearning in conjunction with other learning algorithms. Specifically, we\nexplore various learning algorithms to improve the vanilla federated averaging\nalgorithm and review model fusion methods such as adaptive aggregation,\nregularization, clustered methods, and Bayesian methods. Following the emerging\ntrends, we also discuss federated learning in the intersection with other\nlearning paradigms, termed as federated x learning, where x includes multitask\nlearning, meta-learning, transfer learning, unsupervised learning, and\nreinforcement learning. This survey reviews the state of the art, challenges,\nand future directions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 15:18:13 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 07:19:07 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Ji", "Shaoxiong", ""], ["Saravirta", "Teemu", ""], ["Pan", "Shirui", ""], ["Long", "Guodong", ""], ["Walid", "Anwar", ""]]}, {"id": "2102.12941", "submitter": "Claudia Fohry", "authors": "Claudia Fohry", "title": "Checkpointing and Localized Recovery for Nested Fork-Join Programs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  While checkpointing is typically combined with a restart of the whole\napplication, localized recovery permits all but the affected processes to\ncontinue. In task-based cluster programming, for instance, the application can\nthen be finished on the intact nodes, and the lost tasks be reassigned.\n  This extended abstract suggests to adapt a checkpointing and localized\nrecovery technique that has originally been developed for independent tasks to\nnested fork-join programs. We consider a Cilk-like work stealing scheme with\nwork-first policy in a distributed memory setting, and describe the required\nalgorithmic changes. The original technique has checkpointing overheads below\n1% and neglectable costs for recovery, we expect the new algorithm to achieve a\nsimilar performance.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 15:37:58 GMT"}, {"version": "v2", "created": "Fri, 26 Feb 2021 07:56:03 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Fohry", "Claudia", ""]]}, {"id": "2102.12953", "submitter": "Gal Oren", "authors": "Kfir Zvi, Gal Oren", "title": "Optimized Memoryless Fair-Share HPC Resources Scheduling using\n  Transparent Checkpoint-Restart Preemption", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  Common resource management methods in supercomputing systems usually include\nhard divisions, capping, and quota allotment. Those methods, despite their\n'advantages', have some known serious disadvantages including unoptimized\nutilization of an expensive facility, and occasionally there is still a need to\ndynamically reschedule and reallocate the resources. Consequently, those\nmethods involve bad supply-and-demand management rather than a free market\nplayground that will eventually increase system utilization and productivity.\nIn this work, we propose the newly Optimized Memoryless Fair-Share HPC\nResources Scheduling using Transparent Checkpoint-Restart Preemption, in which\nthe social welfare increases using a free-of-cost interchangeable proprietary\npossession scheme. Accordingly, we permanently keep the status-quo in regard to\nthe fairness of the resources distribution while maximizing the ability of all\nusers to achieve more CPUs and CPU hours for longer period without any\nnon-straightforward costs, penalties or additional human intervention.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 16:02:07 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Zvi", "Kfir", ""], ["Oren", "Gal", ""]]}, {"id": "2102.13003", "submitter": "Claire Birnie PhD", "authors": "Claire Birnie, Haithem Jarraya and Fredrik Hansteen", "title": "An introduction to distributed training of deep neural networks for\n  segmentation tasks with large seismic datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.geo-ph cs.AI cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Deep learning applications are drastically progressing in seismic processing\nand interpretation tasks. However, the majority of approaches subsample data\nvolumes and restrict model sizes to minimise computational requirements.\nSubsampling the data risks losing vital spatio-temporal information which could\naid training whilst restricting model sizes can impact model performance, or in\nsome extreme cases, renders more complicated tasks such as segmentation\nimpossible. This paper illustrates how to tackle the two main issues of\ntraining of large neural networks: memory limitations and impracticably large\ntraining times. Typically, training data is preloaded into memory prior to\ntraining, a particular challenge for seismic applications where data is\ntypically four times larger than that used for standard image processing tasks\n(float32 vs. uint8). Using a microseismic use case, we illustrate how over\n750GB of data can be used to train a model by using a data generator approach\nwhich only stores in memory the data required for that training batch.\nFurthermore, efficient training over large models is illustrated through the\ntraining of a 7-layer UNet with input data dimensions of 4096X4096. Through a\nbatch-splitting distributed training approach, training times are reduced by a\nfactor of four. The combination of data generators and distributed training\nremoves any necessity of data 1 subsampling or restriction of neural network\nsizes, offering the opportunity of utilisation of larger networks,\nhigher-resolution input data or moving from 2D to 3D problem spaces.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 17:06:00 GMT"}], "update_date": "2021-02-26", "authors_parsed": [["Birnie", "Claire", ""], ["Jarraya", "Haithem", ""], ["Hansteen", "Fredrik", ""]]}, {"id": "2102.13018", "submitter": "Junchao Zhang", "authors": "Junchao Zhang, Jed Brown, Satish Balay, Jacob Faibussowitsch, Matthew\n  Knepley, Oana Marin, Richard Tran Mills, Todd Munson, Barry F. Smith, Stefano\n  Zampini", "title": "The PetscSF Scalable Communication Layer", "comments": "12 pages, 12 figures", "journal-ref": null, "doi": null, "report-no": "ANL/MCS-P9449-0221", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PetscSF, the communication component of the Portable, Extensible Toolkit for\nScientific Computation (PETSc), is designed to provide PETSc's communication\ninfrastructure suitable for exascale computers that utilize GPUs and other\naccelerators. PetscSF provides a simple application programming interface (API)\nfor managing common communication patterns in scientific computations by using\na star-forest graph representation. PetscSF supports several implementations\nbased on MPI and NVSHMEM, whose selection is based on the characteristics of\nthe application or the target architecture. An efficient and portable model for\nnetwork and intra-node communication is essential for implementing large-scale\napplications. The Message Passing Interface, which has been the de facto\nstandard for distributed memory systems, has developed into a large complex API\nthat does not yet provide high performance on the emerging heterogeneous\nCPU-GPU-based exascale systems. In this paper, we discuss the design of\nPetscSF, how it can overcome some difficulties of working directly with MPI on\nGPUs, and we demonstrate its performance, scalability, and novel features.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 17:22:35 GMT"}, {"version": "v2", "created": "Sat, 22 May 2021 02:45:50 GMT"}], "update_date": "2021-05-25", "authors_parsed": [["Zhang", "Junchao", ""], ["Brown", "Jed", ""], ["Balay", "Satish", ""], ["Faibussowitsch", "Jacob", ""], ["Knepley", "Matthew", ""], ["Marin", "Oana", ""], ["Mills", "Richard Tran", ""], ["Munson", "Todd", ""], ["Smith", "Barry F.", ""], ["Zampini", "Stefano", ""]]}, {"id": "2102.13125", "submitter": "Vasileios Theodorou", "authors": "Vasileios Theodorou, Ilias Gerostathopoulos, Iyad Alshabani, Alberto\n  Abello and David Breitgand", "title": "MEDAL: An AI-driven Data Fabric Concept for Elastic Cloud-to-Edge\n  Intelligence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current Cloud solutions for Edge Computing are inefficient for data-centric\napplications, as they focus on the IaaS/PaaS level and they miss the data\nmodeling and operations perspective. Consequently, Edge Computing opportunities\nare lost due to cumbersome and data assets-agnostic processes for end-to-end\ndeployment over the Cloud-to-Edge continuum. In this paper, we introduce MEDAL,\nan intelligent Cloud-to-Edge Data Fabric to support Data Operations\n(DataOps)across the continuum and to automate management and orchestration\noperations over a combined view of the data and the resource layer. MEDAL\nfacilitates building and managing data workflows on top of existing flexible\nand composable data services, seamlessly exploiting and federating\nIaaS/PaaS/SaaS resources across different Cloud and Edge environments. We\ndescribe the MEDAL Platform as a usable tool for Data Scientists and Engineers,\nencompassing our concept and we illustrate its application though a connected\ncars use case.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 19:01:23 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Theodorou", "Vasileios", ""], ["Gerostathopoulos", "Ilias", ""], ["Alshabani", "Iyad", ""], ["Abello", "Alberto", ""], ["Breitgand", "David", ""]]}, {"id": "2102.13133", "submitter": "Scott Luedtke", "authors": "Robert Bird, Nigel Tan, Scott V. Luedtke, Stephen Lien Harrell,\n  Michela Taufer, Brian Albright", "title": "VPIC 2.0: Next Generation Particle-in-Cell Simulations", "comments": null, "journal-ref": null, "doi": "10.1109/TPDS.2021.3084795", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  VPIC is a general purpose Particle-in-Cell simulation code for modeling\nplasma phenomena such as magnetic reconnection, fusion, solar weather, and\nlaser-plasma interaction in three dimensions using large numbers of particles.\nVPIC's capacity in both fidelity and scale makes it particularly well-suited\nfor plasma research on pre-exascale and exascale platforms. In this paper we\ndemonstrate the unique challenges involved in preparing the VPIC code for\noperation at exascale, outlining important optimizations to make VPIC efficient\non accelerators. Specifically, we show the work undertaken in adapting VPIC to\nexploit the portability-enabling framework Kokkos and highlight the\nenhancements to VPIC's modeling capabilities to achieve performance at\nexascale. We assess the achieved performance-portability trade-off through a\nsuite of studies on nine different varieties of modern pre-exascale hardware.\nOur performance-portability study includes weak-scaling runs on three of the\ntop ten TOP500 supercomputers, as well as a comparison of low-level system\nperformance of hardware from four different vendors.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 19:20:26 GMT"}], "update_date": "2021-06-16", "authors_parsed": [["Bird", "Robert", ""], ["Tan", "Nigel", ""], ["Luedtke", "Scott V.", ""], ["Harrell", "Stephen Lien", ""], ["Taufer", "Michela", ""], ["Albright", "Brian", ""]]}, {"id": "2102.13140", "submitter": "Lehman Garrison", "authors": "Lehman H. Garrison, Daniel J. Eisenstein, Nina A. Maksimova", "title": "Checkpointing with cp: the POSIX Shared Memory System", "comments": "3 pages, 1 figure. Extended abstract accepted by SuperCheck21.\n  Symposium presentation at\n  https://drive.google.com/file/d/1q63kk1TCyOuh15Lu47bUJ8K7iZ-pYP9U/view", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the checkpointing scheme of Abacus, an $N$-body simulation code\nthat allocates all persistent state in POSIX shared memory, or ramdisk.\nCheckpointing becomes as simple as copying files from ramdisk to external\nstorage. The main simulation executable is invoked once per time step, memory\nmapping the input state, computing the output state directly into ramdisk, and\nunmapping the input state. The main executable remains unaware of the concept\nof checkpointing, with the top-level driver code launching a file-system copy\nbetween executable invocations when a checkpoint is needed. Since the only\ninformation flow is through files on ramdisk, the checkpoint must be correct so\nlong as the simulation is correct. However, we find that with multi-GB of\nstate, there is a significant overhead to unmapping the shared memory. This can\nbe partially mitigated with multithreading, but ultimately, we do not recommend\nshared memory for use with a large state.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2021 19:38:02 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Garrison", "Lehman H.", ""], ["Eisenstein", "Daniel J.", ""], ["Maksimova", "Nina A.", ""]]}, {"id": "2102.13242", "submitter": "Xing Hu", "authors": "Vassos Hadzilacos, Xing Hu, Sam Toueg", "title": "On Register Linearizability and Termination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a seminal work, Golab et al. showed that a randomized algorithm that works\nwith atomic objects may lose some of its properties if we replace the atomic\nobjects that it uses with linearizable objects. It was not known whether the\nproperties that can be lost include the important property of termination (with\nprobability 1). In this paper, we first show that, for randomized algorithms,\ntermination can indeed be lost.\n  Golab et al. also introduced strong linearizability, and proved that strongly\nlinearizable objects can be used as if they were atomic objects, even for\nrandomized algorithms: they preserve the algorithm's correctness properties,\nincluding termination. Unfortunately, there are important cases where strong\nlinearizability is impossible to achieve. In particular, Helmi et al. MWMR\nregisters do not have strongly linearizable implementations from SWMR\nregisters.\n  So we propose a new type of register linearizability, called write\nstrong-linearizability, that is strictly stronger than linearizability but\nstrictly weaker than strong linearizability. We prove that some randomized\nalgorithms that fail to terminate with linearizable registers, work with write\nstrongly-linearizable ones. In other words, there are cases where\nlinearizability is not sufficient but write strong-linearizability is. In\ncontrast to the impossibility result mentioned above, we prove that write\nstrongly-linearizable MWMR registers are implementable from SWMR registers.\nAchieving write strong-linearizability, however, is harder than achieving just\nlinearizability: we give a simple implementation of MWMR registers from SWMR\nregisters and we prove that this implementation is linearizable but not write\nstrongly-linearizable. Finally, we prove that any linearizable implementation\nof SWMR registers is necessarily write strongly-linearizable; this holds for\nshared-memory, message-passing, and hybrid systems.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 00:16:39 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Hadzilacos", "Vassos", ""], ["Hu", "Xing", ""], ["Toueg", "Sam", ""]]}, {"id": "2102.13243", "submitter": "Brennan Saeta", "authors": "Brennan Saeta, Denys Shabalin, Marc Rasi, Brad Larson, Xihui Wu,\n  Parker Schuh, Michelle Casbon, Daniel Zheng, Saleem Abdulrasool, Aleksandr\n  Efremov, Dave Abrahams, Chris Lattner, and Richard Wei", "title": "Swift for TensorFlow: A portable, flexible platform for deep learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Swift for TensorFlow is a deep learning platform that scales from mobile\ndevices to clusters of hardware accelerators in data centers. It combines a\nlanguage-integrated automatic differentiation system and multiple Tensor\nimplementations within a modern ahead-of-time compiled language oriented around\nmutable value semantics. The resulting platform has been validated through use\nin over 30 deep learning models and has been employed across data center and\nmobile applications.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 00:21:15 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Saeta", "Brennan", ""], ["Shabalin", "Denys", ""], ["Rasi", "Marc", ""], ["Larson", "Brad", ""], ["Wu", "Xihui", ""], ["Schuh", "Parker", ""], ["Casbon", "Michelle", ""], ["Zheng", "Daniel", ""], ["Abdulrasool", "Saleem", ""], ["Efremov", "Aleksandr", ""], ["Abrahams", "Dave", ""], ["Lattner", "Chris", ""], ["Wei", "Richard", ""]]}, {"id": "2102.13310", "submitter": "Viveck Cadambe", "authors": "Viveck R. Cadambe and Shihang Lyu", "title": "CausalEC: A Causally Consistent Data Storage Algorithm based on\n  Cross-Object Erasure Coding", "comments": "Revised to include additional acknowledgements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causally consistent distributed storage systems have received significant\nrecent attention due to the potential for providing a low latency data access\nas compared with linearizability. Current causally consistent data stores use\npartial or full replication to ensure data access to clients over a distributed\nsetting.\n  In this paper, we develop, for the first time, an erasure coding based\nalgorithm called CausalEC that ensures causal consistency for a collection of\nread-write objects stored in a distributed set of nodes over an asynchronous\nmessage passing system. CausalEC can use an arbitrary linear erasure code for\ndata storage, and ensures liveness and storage properties prescribed by the\nerasure code.\n  CausalEC retains a key benefit of previously designed replication-based\nalgorithms - every write operation is local, that is, a server performs only\nlocal actions before returning to a client that issued a write operation. For\nservers that store certain objects in an uncoded manner, read operations to\nthose objects also return locally. In general, a read operation to an object\ncan be returned by a server on contacting a small subset of other servers so\nlong as the underlying erasure code allows for the object to be decoded from\nthat subset. As a byproduct, we develop EventualEC, a new eventually consistent\nerasure coding based data storage algorithm.\n  A novel technical aspect of CausalEC is the use of cross-object erasure\ncoding, where nodes encode values across multiple objects, unlike previous\nconsistent erasure coding based solutions. CausalEC navigates the technical\nchallenges of cross-object erasure coding, in particular, pertaining to\nre-encoding the objects when writes update the values and ensuring that reads\nare served in the transient state where the system transitions to storing the\ncodeword symbols corresponding to the new object versions.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 05:56:56 GMT"}, {"version": "v2", "created": "Mon, 8 Mar 2021 02:39:22 GMT"}], "update_date": "2021-03-09", "authors_parsed": [["Cadambe", "Viveck R.", ""], ["Lyu", "Shihang", ""]]}, {"id": "2102.13367", "submitter": "Sm Zobaed", "authors": "Sakib M Zobaed, Mohsen Amini Salehi, Rajkumar Buyya", "title": "SAED: Edge-Based Intelligence for Privacy-Preserving Enterprise Search\n  on the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud-based enterprise search services (e.g., AWS Kendra) have been\nentrancing big data owners by offering convenient and real-time search\nsolutions to them. However, the problem is that individuals and organizations\npossessing confidential big data are hesitant to embrace such services due to\nvalid data privacy concerns. In addition, to offer an intelligent search, these\nservices access the user search history that further jeopardizes his/her\nprivacy. To overcome the privacy problem, the main idea of this research is to\nseparate the intelligence aspect of the search from its pattern matching\naspect. According to this idea, the search intelligence is provided by an\non-premises edge tier and the shared cloud tier only serves as an exhaustive\npattern matching search utility. We propose Smartness At Edge (SAED mechanism\nthat offers intelligence in the form of semantic and personalized search at the\nedge tier while maintaining privacy of the search on the cloud tier. At the\nedge tier, SAED uses a knowledge-based lexical database to expand the query and\ncover its semantics. SAED personalizes the search via an RNN model that can\nlearn the user interest. A word embedding model is used to retrieve documents\nbased on their semantic relevance to the search query. SAED is generic and can\nbe plugged into existing enterprise search systems and enable them to offer\nintelligent and privacy-preserving search without enforcing any change on them.\nEvaluation results on two enterprise search systems under real settings and\nverified by human users demonstrate that SAED can improve the relevancy of the\nretrieved results by on average 24% for plain-text and 75% for encrypted\ngeneric datasets.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 09:27:26 GMT"}, {"version": "v2", "created": "Thu, 4 Mar 2021 19:50:26 GMT"}, {"version": "v3", "created": "Thu, 11 Mar 2021 17:26:16 GMT"}], "update_date": "2021-03-12", "authors_parsed": [["Zobaed", "Sakib M", ""], ["Salehi", "Mohsen Amini", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "2102.13451", "submitter": "Stefanos Laskaridis", "authors": "Samuel Horvath, Stefanos Laskaridis, Mario Almeida, Ilias Leontiadis,\n  Stylianos I. Venieris and Nicholas D. Lane", "title": "FjORD: Fair and Accurate Federated Learning under heterogeneous targets\n  with Ordered Dropout", "comments": "Updated results, additions in appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated Learning (FL) has been gaining significant traction across\ndifferent ML tasks, ranging from vision to keyboard predictions. In large-scale\ndeployments, client heterogeneity is a fact, and constitutes a primary problem\nfor fairness, training performance and accuracy. Although significant efforts\nhave been made into tackling statistical data heterogeneity, the diversity in\nthe processing capabilities and network bandwidth of clients, termed as system\nheterogeneity, has remained largely unexplored. Current solutions either\ndisregard a large portion of available devices or set a uniform limit on the\nmodel's capacity, restricted by the least capable participants. In this work,\nwe introduce Ordered Dropout, a mechanism that achieves an ordered, nested\nrepresentation of knowledge in Neural Networks and enables the extraction of\nlower footprint submodels without the need of retraining. We further show that\nfor linear maps our Ordered Dropout is equivalent to SVD. We employ this\ntechnique, along with a self-distillation methodology, in the realm of FL in a\nframework called FjORD. FjORD alleviates the problem of client system\nheterogeneity by tailoring the model width to the client's capabilities.\nExtensive evaluation on both CNNs and RNNs across diverse modalities shows that\nFjORD consistently leads to significant performance gains over state-of-the-art\nbaselines, while maintaining its nested structure.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 13:07:43 GMT"}, {"version": "v2", "created": "Mon, 1 Mar 2021 09:16:03 GMT"}, {"version": "v3", "created": "Mon, 10 May 2021 20:18:00 GMT"}, {"version": "v4", "created": "Fri, 4 Jun 2021 16:30:29 GMT"}], "update_date": "2021-06-07", "authors_parsed": [["Horvath", "Samuel", ""], ["Laskaridis", "Stefanos", ""], ["Almeida", "Mario", ""], ["Leontiadis", "Ilias", ""], ["Venieris", "Stylianos I.", ""], ["Lane", "Nicholas D.", ""]]}, {"id": "2102.13457", "submitter": "Juho Hirvonen", "authors": "Juho Hirvonen, Laura Schmid, Krishnendu Chatterjee, and Stefan Schmid", "title": "Classifying Convergence Complexity of Nash Equilibria in Graphical Games\n  Using Distributed Computing Theory", "comments": "Corrected typos", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphical games are a useful framework for modeling the interactions of\n(selfish) agents who are connected via an underlying topology and whose\nbehaviors influence each other. They have wide applications ranging from\ncomputer science to economics and biology. Yet, even though a player's payoff\nonly depends on the actions of their direct neighbors in graphical games,\ncomputing the Nash equilibria and making statements about the convergence time\nof \"natural\" local dynamics in particular can be highly challenging. In this\nwork, we present a novel approach for classifying complexity of Nash equilibria\nin graphical games by establishing a connection to local graph algorithms, a\nsubfield of distributed computing. In particular, we make the observation that\nthe equilibria of graphical games are equivalent to locally verifiable\nlabelings (LVL) in graphs; vertex labelings which are verifiable with a\nconstant-round local algorithm. This connection allows us to derive novel lower\nbounds on the convergence time to equilibrium of best-response dynamics in\ngraphical games. Since we establish that distributed convergence can sometimes\nbe provably slow, we also introduce and give bounds on an intuitive notion of\n\"time-constrained\" inefficiency of best responses. We exemplify how our results\ncan be used in the implementation of mechanisms that ensure convergence of best\nresponses to a Nash equilibrium. Our results thus also give insight into the\nconvergence of strategy-proof algorithms for graphical games, which is still\nnot well understood.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 13:22:01 GMT"}, {"version": "v2", "created": "Mon, 26 Apr 2021 12:43:52 GMT"}], "update_date": "2021-04-27", "authors_parsed": [["Hirvonen", "Juho", ""], ["Schmid", "Laura", ""], ["Chatterjee", "Krishnendu", ""], ["Schmid", "Stefan", ""]]}, {"id": "2102.13469", "submitter": "Abhishek Singh", "authors": "Abhishek Narain Singh", "title": "The unmasking of Mitochondrial Adam and Structural Variants larger than\n  point mutations as stronger candidates for traits, disease phenotype and sex\n  determination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.GN cs.DC q-bio.PE", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Background: Structural Variations, SVs, in a genome can be linked to a\ndisease or characteristic phenotype. The variations come in many types and it\nis a challenge, not only determining the variations accurately, but also\nconducting the downstream statistical and analytical procedure. Method:\nStructural variations, SVs, with size 1 base-pair to 1000s of base-pairs with\ntheir precise breakpoints and single-nucleotide polymorphisms, SNPs, were\ndetermined for members of a family. The genome was assembled using optimal\nmetrics of ABySS and SOAPdenovo assembly tools using paired-end DNA sequence.\nResults: An interesting discovery was the mitochondrial DNA could have paternal\nleakage of inheritance or that the mutations could be high from maternal\ninheritance. It is also discovered that the mitochondrial DNA is less prone to\nSVs re-arrangements than SNPs, which propose better standards for determining\nancestry and divergence between races and species over a long-time frame. Sex\ndetermination of an individual is found to be strongly confirmed using calls of\nnucleotide bases of SVs to the Y chromosome, more strongly determined than\nSNPs. We note that in general there is a larger variance -and thus the standard\ndeviation, in the sum of SVs nucleotide compared to sum of SNPs of an\nindividual when compared to reference sequence, and thus SVs serve as a\nstronger means to characterize an individual for a given trait or phenotype or\nto determine sex. The SVs and SNPs in HLA loci would also serve as a medical\ntransformation method for determining the success of an organ transplant for a\npatient, and predisposition to diseases apriori.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 15:23:43 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Singh", "Abhishek Narain", ""]]}, {"id": "2102.13470", "submitter": "Abhishek Singh", "authors": "Abhishek Narain Singh", "title": "Feature set optimization by clustering, univariate association, Deep &\n  Machine learning omics Wide Association Study (DMWAS) for Biomarkers\n  discovery as tested on GTEx pilot dataset for death due to heart attack", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "q-bio.QM cs.DC q-bio.GN", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Univariate and multivariate methods for association of the genom-ic\nvariations with the end-or-endo phenotype have been widely used for genome wide\nassociation studies. In addition to encoding the SNPs, we advocate usage of\nclustering as a novel method to encode the structural variations, SVs, in\ngenomes, such as the deletions and insertions polymorphism (DIPs), Copy Number\nVariations (CNVs), translocation, inversion, etc., that can be used as an\nindependent fea-ture variable value for downstream computation by artificial\nintelli-gence methods to predict the endo-or-end phenotype. We introduce a\nclustering based encoding scheme for structural variations and om-ics based\nanalysis. We conducted a complete all genomic variants association with the\nphenotype using deep learning and other ma-chine learning techniques, though\nother methods such as genetic al-gorithm can also be applied. Applying this\nencoding of SVs and one-hot encoding of SNPs on GTEx V7 pilot DNA variation\ndataset, we were able to get high accuracy using various methods of DMWAS, and\nparticularly found logistic regression to work the best for death due to\nheart-attack (MHHRTATT) phenotype. The genom-ic variants acting as feature sets\nwere then arranged in descending order of power of impact on the disease or\ntrait phenotype, which we call optimization and that also uses top univariate\nassociation into account. Variant Id P1_M_061510_3_402_P at chromosome 3 &\nposition 192063195 was found to be most highly associated to MHHRTATT. We\npresent here the top ten optimized genomic va-riant feature set for the\nMHHRTATT phenotypic cause of death.\n", "versions": [{"version": "v1", "created": "Wed, 24 Feb 2021 14:55:51 GMT"}], "update_date": "2021-03-01", "authors_parsed": [["Singh", "Abhishek Narain", ""]]}, {"id": "2102.13604", "submitter": "Yulin Shao", "authors": "Yulin Shao, Deniz Gunduz, Soung Chang Liew", "title": "Federated Edge Learning with Misaligned Over-The-Air Computation", "comments": "17 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG eess.SP math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over-the-air computation (OAC) is a promising technique to realize fast model\naggregation in the uplink of federated edge learning. OAC, however, hinges on\naccurate channel-gain precoding and strict synchronization among the edge\ndevices, which are challenging in practice. As such, how to design the maximum\nlikelihood (ML) estimator in the presence of residual channel-gain mismatch and\nasynchronies is an open problem. To fill this gap, this paper formulates the\nproblem of misaligned OAC for federated edge learning and puts forth a whitened\nmatched filtering and sampling scheme to obtain oversampled, but independent,\nsamples from the misaligned and overlapped signals. Given the whitened samples,\na sum-product ML estimator and an aligned-sample estimator are devised to\nestimate the arithmetic sum of the transmitted symbols. In particular, the\ncomputational complexity of our sum-product ML estimator is linear in the\npacket length and hence is significantly lower than the conventional ML\nestimator. Extensive simulations on the test accuracy versus the average\nreceived energy per symbol to noise power spectral density ratio (EsN0) yield\ntwo main results: 1) In the low EsN0 regime, the aligned-sample estimator can\nachieve superior test accuracy provided that the phase misalignment is\nnon-severe. In contrast, the ML estimator does not work well due to the error\npropagation and noise enhancement in the estimation process. 2) In the high\nEsN0 regime, the ML estimator attains the optimal learning performance\nregardless of the severity of phase misalignment. On the other hand, the\naligned-sample estimator suffers from a test-accuracy loss caused by phase\nmisalignment.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2021 17:19:56 GMT"}, {"version": "v2", "created": "Tue, 13 Apr 2021 02:34:27 GMT"}], "update_date": "2021-04-14", "authors_parsed": [["Shao", "Yulin", ""], ["Gunduz", "Deniz", ""], ["Liew", "Soung Chang", ""]]}]