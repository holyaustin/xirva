[{"id": "1705.00070", "submitter": "Yadu Babuji", "authors": "Yadu N. Babuji, Kyle Chard, Eamon Duede", "title": "Enabling Interactive Analytics of Secure Data using Cloud Kotta", "comments": "To appear in Proceedings of Workshop on Scientific Cloud Computing,\n  Washington, DC USA, June 2017 (ScienceCloud 2017), 7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Research, especially in the social sciences and humanities, is increasingly\nreliant on the application of data science methods to analyze large amounts of\n(often private) data. Secure data enclaves provide a solution for managing and\nanalyzing private data. However, such enclaves do not readily support discovery\nscience---a form of exploratory or interactive analysis by which researchers\nexecute a range of (sometimes large) analyses in an iterative and collaborative\nmanner. The batch computing model offered by many data enclaves is well suited\nto executing large compute tasks; however it is far from ideal for day-to-day\ndiscovery science. As researchers must submit jobs to queues and wait for\nresults, the high latencies inherent in queue-based, batch computing systems\nhinder interactive analysis. In this paper we describe how we have augmented\nthe Cloud Kotta secure data enclave to support collaborative and interactive\nanalysis of sensitive data. Our model uses Jupyter notebooks as a flexible\nanalysis environment and Python language constructs to support the execution of\narbitrary functions on private data within this secure framework.\n", "versions": [{"version": "v1", "created": "Fri, 28 Apr 2017 20:41:17 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Babuji", "Yadu N.", ""], ["Chard", "Kyle", ""], ["Duede", "Eamon", ""]]}, {"id": "1705.00249", "submitter": "Kai Wu", "authors": "Kai Wu, Yingchao Huang, Dong Li", "title": "Unimem: Runtime Data Management on Non-Volatile Memory-based\n  Heterogeneous Main Memory", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Non-volatile memory (NVM) provides a scalable and power-efficient solution to\nreplace DRAM as main memory. However, because of relatively high latency and\nlow bandwidth of NVM, NVM is often paired with DRAM to build a heterogeneous\nmemory system (HMS). As a result, data objects of the application must be\ncarefully placed to NVM and DRAM for best performance. In this paper, we\nintroduce a lightweight runtime solution that automatically and transparently\nmanage data placement on HMS without the requirement of hardware modifications\nand disruptive change to applications. Leveraging online profiling and\nperformance models, the runtime characterizes memory access patterns associated\nwith data objects, and minimizes unnecessary data movement. Our runtime\nsolution effectively bridges the performance gap between NVM and DRAM. We\ndemonstrate that using NVM to replace the majority of DRAM can be a feasible\nsolution for future HPC systems with the assistance of a software-based data\nmanagement.\n", "versions": [{"version": "v1", "created": "Sat, 29 Apr 2017 23:19:28 GMT"}, {"version": "v2", "created": "Tue, 2 May 2017 01:34:11 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Wu", "Kai", ""], ["Huang", "Yingchao", ""], ["Li", "Dong", ""]]}, {"id": "1705.00264", "submitter": "Yingchao Huang", "authors": "Yingchao Huang, Kai Wu, Dong Li", "title": "High Performance Data Persistence in Non-Volatile Memory for Resilient\n  High Performance Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resilience is a major design goal for HPC. Checkpoint is the most common\nmethod to enable resilient HPC. Checkpoint periodically saves critical data\nobjects to non-volatile storage to enable data persistence. However, using\ncheckpoint, we face dilemmas between resilience, recomputation and checkpoint\ncost. The reason that accounts for the dilemmas is the cost of data copying\ninherent in checkpoint. In this paper we explore how to build resilient HPC\nwith non-volatile memory (NVM) as main memory and address the dilemmas. We\nintroduce a variety of optimization techniques that leverage high performance\nand non-volatility of NVM to enable high performance data persistence for data\nobjects in applications. With NVM we avoid data copying; we optimize cache\nflushing needed to ensure consistency between caches and NVM. We demonstrate\nthat using NVM is feasible to establish data persistence frequently with small\noverhead (4.4% on average) to achieve highly resilient HPC and minimize\nrecomputation.\n", "versions": [{"version": "v1", "created": "Sun, 30 Apr 2017 03:24:14 GMT"}, {"version": "v2", "created": "Tue, 2 May 2017 01:02:33 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Huang", "Yingchao", ""], ["Wu", "Kai", ""], ["Li", "Dong", ""]]}, {"id": "1705.00267", "submitter": "Luanzheng Guo", "authors": "Luanzheng Guo, Hanlin He, Dong Li", "title": "Application-Level Resilience Modeling for HPC Fault Tolerance", "comments": "11 pages, 9 figures, the manuscript has been submitted to the\n  International Conference for High Performance Computing, Networking, Storage\n  and Analysis (SC '17) conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the application resilience in the presence of faults is\ncritical to address the HPC resilience challenge. Currently, we largely rely on\nrandom fault injection (RFI) to quantify the application resilience. However,\nRFI provides little information on how fault tolerance happens, and RFI results\nare often not deterministic due to its random nature. In this paper, we\nintroduce a new methodology to quantify the application resilience. Our\nmethodology is based on the observation that at the application level, the\napplication resilience to faults is due to the application-level fault masking.\nThe application-level fault masking happens because of application-inherent\nsemantics and program constructs. Based on this observation, we analyze\napplication execution information and use a data-oriented approach to model the\napplication resilience. We use our model to study how and why HPC applications\ncan (or cannot) tolerate faults. We demonstrate tangible benefits of using the\nmodel to direct fault tolerance mechanisms.\n", "versions": [{"version": "v1", "created": "Sun, 30 Apr 2017 04:13:21 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Guo", "Luanzheng", ""], ["He", "Hanlin", ""], ["Li", "Dong", ""]]}, {"id": "1705.00307", "submitter": "Jaeyong Rho", "authors": "Jaeyong Rho, Takuya Azumi, Mayo Nakagawa, Kenya Sato, Nobuhiko Nishio", "title": "Scheduling Parallel and Distributed Processing for Automotive Data\n  Stream Management System", "comments": "Accepted for publication at Journal of Parallel and Distributed\n  Computing (Elsevier) 2017", "journal-ref": "J. Parallel Distrib. Comput. 109: 286-300 (2017)", "doi": "10.1016/j.jpdc.2017.06.012", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, to analyze end-to-end timing behavior in heterogeneous\nprocessor and network environments accurately, we adopt a heterogeneous\nselection value on communication contention (HSV_CC) algorithm, which can\nsynchronize tasks and messages simultaneously, for stream processing\ndistribution. In order to adapt HSV_CC to automotive data stream management\nsystem (DSMSs), one must address three issues: (i) previous task and message\nschedules might lead to less efficient resource usages; (ii) the conventional\nmethod to determine the task scheduling order may not be best suited to deal\nwith stream processing graphs, and; (iii) there is a need to be able to\nschedule tasks with time-varying computational requirements efficiently. To\naddress (i), we propose the heterogeneous value with load balancing and\ncommunication contention (HVLB_CC) (A) algorithm, which considers load\nbalancing in addition to the parameters considered by the HSV_CC algorithm. We\npropose HVLB_CC (B) to address issue (ii). HVLB_CC (B) can deal with stream\nprocessing task graphs and more various directed acyclic graphs to prevent\nassigning a higher priority to successor tasks. In addition, to address issue\n(iii), we propose HVLB_CC_IC. To schedule tasks more efficiently with various\ncomputation times, HVLB_CC_IC utilizes schedule holes left in processors. These\nidle time slots can be used for the execution of an optional part to generate\nmore precise data results by applying imprecise computation models.\nExperimental results demonstrate that the proposed algorithms improve minimum\nschedule length, accuracy, and load balancing significantly compared to the\nHSV_CC algorithm. In addition, the proposed HVLB_CC (B) algorithm can schedule\nmore varied task graphs without reducing performance, and, using imprecise\ncomputation models, HVLB_CC_IC yields higher precision data than HVLB_CC\nwithout imprecise computation models.\n", "versions": [{"version": "v1", "created": "Sun, 30 Apr 2017 12:39:38 GMT"}, {"version": "v2", "created": "Sun, 18 Jun 2017 06:09:29 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Rho", "Jaeyong", ""], ["Azumi", "Takuya", ""], ["Nakagawa", "Mayo", ""], ["Sato", "Kenya", ""], ["Nishio", "Nobuhiko", ""]]}, {"id": "1705.00324", "submitter": "Giovanni Viglietta", "authors": "Giuseppe A. Di Luna, Paola Flocchini, Nicola Santoro, Giovanni\n  Viglietta, and Masafumi Yamashita", "title": "Meeting in a Polygon by Anonymous Oblivious Robots", "comments": "37 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CG cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Meeting problem for $k\\geq 2$ searchers in a polygon $P$ (possibly with\nholes) consists in making the searchers move within $P$, according to a\ndistributed algorithm, in such a way that at least two of them eventually come\nto see each other, regardless of their initial positions. The polygon is\ninitially unknown to the searchers, and its edges obstruct both movement and\nvision. Depending on the shape of $P$, we minimize the number of searchers $k$\nfor which the Meeting problem is solvable. Specifically, if $P$ has a\nrotational symmetry of order $\\sigma$ (where $\\sigma=1$ corresponds to no\nrotational symmetry), we prove that $k=\\sigma+1$ searchers are sufficient, and\nthe bound is tight. Furthermore, we give an improved algorithm that optimally\nsolves the Meeting problem with $k=2$ searchers in all polygons whose\nbarycenter is not in a hole (which includes the polygons with no holes). Our\nalgorithms can be implemented in a variety of standard models of mobile robots\noperating in Look-Compute-Move cycles. For instance, if the searchers have\nmemory but are anonymous, asynchronous, and have no agreement on a coordinate\nsystem or a notion of clockwise direction, then our algorithms work even if the\ninitial memory contents of the searchers are arbitrary and possibly misleading.\nMoreover, oblivious searchers can execute our algorithms as well, encoding\ninformation by carefully positioning themselves within the polygon. This code\nis computable with basic arithmetic operations, and each searcher can\ngeometrically construct its own destination point at each cycle using only a\ncompass. We stress that such memoryless searchers may be located anywhere in\nthe polygon when the execution begins, and hence the information they initially\nencode is arbitrary. Our algorithms use a self-stabilizing map construction\nsubroutine which is of independent interest.\n", "versions": [{"version": "v1", "created": "Sun, 30 Apr 2017 15:25:31 GMT"}, {"version": "v2", "created": "Sun, 30 Jul 2017 14:37:18 GMT"}, {"version": "v3", "created": "Mon, 15 Jan 2018 18:03:35 GMT"}, {"version": "v4", "created": "Sat, 6 Jul 2019 08:43:04 GMT"}], "update_date": "2019-07-09", "authors_parsed": [["Di Luna", "Giuseppe A.", ""], ["Flocchini", "Paola", ""], ["Santoro", "Nicola", ""], ["Viglietta", "Giovanni", ""], ["Yamashita", "Masafumi", ""]]}, {"id": "1705.00346", "submitter": "Andre Luckow", "authors": "Andre Luckow and Matthew Cook and Nathan Ashcraft and Edwin Weill and\n  Emil Djerekarov and Bennie Vorster", "title": "Deep Learning in the Automotive Industry: Applications and Tools", "comments": "10 pages", "journal-ref": null, "doi": "10.1109/BigData.2016.7841045", "report-no": null, "categories": "cs.LG cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep Learning refers to a set of machine learning techniques that utilize\nneural networks with many hidden layers for tasks, such as image\nclassification, speech recognition, language understanding. Deep learning has\nbeen proven to be very effective in these domains and is pervasively used by\nmany Internet services. In this paper, we describe different automotive uses\ncases for deep learning in particular in the domain of computer vision. We\nsurveys the current state-of-the-art in libraries, tools and infrastructures\n(e.\\,g.\\ GPUs and clouds) for implementing, training and deploying deep neural\nnetworks. We particularly focus on convolutional neural networks and computer\nvision use cases, such as the visual inspection process in manufacturing plants\nand the analysis of social media data. To train neural networks, curated and\nlabeled datasets are essential. In particular, both the availability and scope\nof such datasets is typically very limited. A main contribution of this paper\nis the creation of an automotive dataset, that allows us to learn and\nautomatically recognize different vehicle properties. We describe an end-to-end\ndeep learning application utilizing a mobile app for data collection and\nprocess support, and an Amazon-based cloud backend for storage and training.\nFor training we evaluate the use of cloud and on-premises infrastructures\n(including multiple GPUs) in conjunction with different neural network\narchitectures and frameworks. We assess both the training times as well as the\naccuracy of the classifier. Finally, we demonstrate the effectiveness of the\ntrained classifier in a real world setting during manufacturing process.\n", "versions": [{"version": "v1", "created": "Sun, 30 Apr 2017 17:17:44 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Luckow", "Andre", ""], ["Cook", "Matthew", ""], ["Ashcraft", "Nathan", ""], ["Weill", "Edwin", ""], ["Djerekarov", "Emil", ""], ["Vorster", "Bennie", ""]]}, {"id": "1705.00387", "submitter": "Reza Farahbakhsh", "authors": "Amirhossein Farahzadia, Pooyan Shams, Javad Rezazadeh, Reza\n  Farahbakhsh", "title": "Middleware Technologies for Cloud of Things - a survey", "comments": "http://www.sciencedirect.com/science/article/pii/S2352864817301268,\n  Digital Communications and Networks, Elsevier (2017)", "journal-ref": null, "doi": "10.1016/j.dcan.2017.04.005", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The next wave of communication and applications rely on the new services\nprovided by Internet of Things which is becoming an important aspect in human\nand machines future. The IoT services are a key solution for providing smart\nenvironments in homes, buildings and cities. In the era of a massive number of\nconnected things and objects with a high grow rate, several challenges have\nbeen raised such as management, aggregation and storage for big produced data.\nIn order to tackle some of these issues, cloud computing emerged to IoT as\nCloud of Things (CoT) which provides virtually unlimited cloud services to\nenhance the large scale IoT platforms. There are several factors to be\nconsidered in design and implementation of a CoT platform. One of the most\nimportant and challenging problems is the heterogeneity of different objects.\nThis problem can be addressed by deploying suitable \"Middleware\". Middleware\nsits between things and applications that make a reliable platform for\ncommunication among things with different interfaces, operating systems, and\narchitectures. The main aim of this paper is to study the middleware\ntechnologies for CoT. Toward this end, we first present the main features and\ncharacteristics of middlewares. Next we study different architecture styles and\nservice domains. Then we presents several middlewares that are suitable for CoT\nbased platforms and lastly a list of current challenges and issues in design of\nCoT based middlewares is discussed.\n", "versions": [{"version": "v1", "created": "Sun, 30 Apr 2017 23:35:47 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Farahzadia", "Amirhossein", ""], ["Shams", "Pooyan", ""], ["Rezazadeh", "Javad", ""], ["Farahbakhsh", "Reza", ""]]}, {"id": "1705.00582", "submitter": "Jiaxiao Zheng", "authors": "Jiaxiao Zheng, Pablo Caballero, Gustavo de Veciana, Seung Jun Baek,\n  Albert Banchs", "title": "Statistical Multiplexing and Traffic Shaping Games for Network Slicing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next generation wireless architectures are expected to enable slices of\nshared wireless infrastructure which are customized to specific mobile\noperators/services. Given infrastructure costs and the stochastic nature of\nmobile services' spatial loads, it is highly desirable to achieve efficient\nstatistical multiplexing amongst such slices. We study a simple dynamic\nresource sharing policy which allocates a 'share' of a pool of (distributed)\nresources to each slice-Share Constrained Proportionally Fair (SCPF). We give a\ncharacterization of SCPF's performance gains over static slicing and general\nprocessor sharing. We show that higher gains are obtained when a slice's\nspatial load is more 'imbalanced' than, and/or 'orthogonal' to, the aggregate\nnetwork load, and that the overall gain across slices is positive. We then\naddress the associated dimensioning problem. Under SCPF, traditional network\ndimensioning translates to a coupled share dimensioning problem, which\ncharacterizes the existence of a feasible share allocation given slices'\nexpected loads and performance requirements. We provide a solution to robust\nshare dimensioning for SCPF-based network slicing. Slices may wish to\nunilaterally manage their users' performance via admission control which\nmaximizes their carried loads subject to performance requirements. We show this\ncan be modeled as a 'traffic shaping' game with an achievable Nash equilibrium.\nUnder high loads, the equilibrium is explicitly characterized, as are the gains\nin the carried load under SCPF vs. static slicing. Detailed simulations of a\nwireless infrastructure supporting multiple slices with heterogeneous mobile\nloads show the fidelity of our models and range of validity of our high load\nequilibrium analysis.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 16:32:21 GMT"}, {"version": "v2", "created": "Wed, 3 May 2017 16:36:05 GMT"}, {"version": "v3", "created": "Tue, 15 May 2018 16:48:18 GMT"}], "update_date": "2018-05-16", "authors_parsed": [["Zheng", "Jiaxiao", ""], ["Caballero", "Pablo", ""], ["de Veciana", "Gustavo", ""], ["Baek", "Seung Jun", ""], ["Banchs", "Albert", ""]]}, {"id": "1705.00677", "submitter": "Nicholas Moehle", "authors": "Nicholas Moehle and Xinyue Shen and Zhi-Quan Luo and Stephen Boyd", "title": "A Distributed Method for Optimal Capacity Reservation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of reserving link capacity in a network in such a way\nthat any of a given set of flow scenarios can be supported. In the optimal\ncapacity reservation problem, we choose the reserved link capacities to\nminimize the reservation cost. This problem reduces to a large linear program,\nwith the number of variables and constraints on the order of the number of\nlinks times the number of scenarios. Small and medium size problems are within\nthe capabilities of generic linear program solvers. We develop a more scalable,\ndistributed algorithm for the problem that alternates between solving (in\nparallel) one flow problem per scenario, and coordination steps, which connect\nthe individual flows and the reservation capacities.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 19:30:58 GMT"}], "update_date": "2017-05-03", "authors_parsed": [["Moehle", "Nicholas", ""], ["Shen", "Xinyue", ""], ["Luo", "Zhi-Quan", ""], ["Boyd", "Stephen", ""]]}, {"id": "1705.00720", "submitter": "Jan Verschelde", "authors": "Anders Jensen, Jeff Sommars, and Jan Verschelde", "title": "Computing Tropical Prevarieties in Parallel", "comments": "Accepted for publication in the proceedings of PASCO 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CG cs.DC math.AG math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The computation of the tropical prevariety is the first step in the\napplication of polyhedral methods to compute positive dimensional solution sets\nof polynomial systems. In particular, pretropisms are candidate leading\nexponents for the power series developments of the solutions. The computation\nof the power series may start as soon as one pretropism is available, so our\nparallel computation of the tropical prevariety has an application in a\npipelined solver.\n  We present a parallel implementation of dynamic enumeration. Our first\ndistributed memory implementation with forked processes achieved good speedups,\nbut quite often resulted in large variations in the execution times of the\nprocesses. The shared memory multithreaded version applies work stealing to\nreduce the variability of the run time. Our implementation applies the thread\nsafe Parma Polyhedral Library (PPL), in exact arithmetic with the GNU\nMultiprecision Arithmetic Library (GMP), aided by the fast memory allocations\nof TCMalloc.\n  Our parallel implementation is capable of computing the tropical prevariety\nof the cyclic 16-roots problem. We also report on computational experiments on\nthe $n$-body and $n$-vortex problems; our computational results compare\nfavorably with Gfan.\n", "versions": [{"version": "v1", "created": "Mon, 1 May 2017 21:34:00 GMT"}, {"version": "v2", "created": "Sat, 1 Jul 2017 23:04:37 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Jensen", "Anders", ""], ["Sommars", "Jeff", ""], ["Verschelde", "Jan", ""]]}, {"id": "1705.01146", "submitter": "Tomasz Radzik", "authors": "Andreas Bilke, Colin Cooper, Robert Elsaesser, Tomasz Radzik", "title": "Population protocols for leader election and exact majority with O(log^2\n  n) states and O(log^2 n) convergence time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the model of population protocols, which can be viewed as a\nsequence of random pairwise interactions of $n$ agents (nodes). We show\npopulation protocols for two problems: the leader election and the exact\nmajority voting. The leader election starts with all agents in the same initial\nstate and the goal is to converge to the (global) state when exactly one agent\nis in a distinct state $L$. The exact majority voting starts with each agent in\none of the two distinct states $A$ or $B$ and the goal is to make all nodes\nknow which of these two states was the initial majority state, even if that\nmajority was just by a single vote.\n  Alistarh and Gelashvili [ICALP 2015] showed a leader-election protocol which\nconverges in $O(\\log^3 n)$ time w.h.p. and in expectation and needs\n$\\Theta(\\log^3 n)$ states per agent. We present a protocol which elects the\nleader in $O(\\log^2 n)$ time w.h.p. and in expectation and uses $\\Theta(\\log^2\nn)$ states per agent. For the exact majority voting, we show a population\nprotocol with the same asymptotic performance: $O(\\log^2 n)$ time and\n$\\Theta(\\log^2 n)$ states per agent. The exact-majority protocol proposed by\nAlistarh et al. [PODC 2015] achieves expected $O(\\log^2 n)$ time, but requires\na relatively high initial imbalance between $A$'s and $B$'s or a large number\nof states per agent. More recently, Alistarh et al. [SODA 2017] showed\n$O(\\log^2 n)$-state protocols for both problems, with the exact majority\nprotocol converging in time $O(\\log^3 n)$, and the leader election protocol\nconverging in time $O(\\log^{6.3} n)$ w.h.p. and $O(\\log^{5.3} n)$ in\nexpectation.\n  Our leader election and exact majority protocols are based on the idea of\nagents counting their local interactions and rely on the probabilistic fact\nthat the uniform random selection would limit the divergence of the individual\ncounts.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 19:17:15 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Bilke", "Andreas", ""], ["Cooper", "Colin", ""], ["Elsaesser", "Robert", ""], ["Radzik", "Tomasz", ""]]}, {"id": "1705.01176", "submitter": "Eddie Santos", "authors": "Eddie Antonio Santos, Carson McLean, Christopher Solinas, Abram Hindle", "title": "How does Docker affect energy consumption? Evaluating workloads in and\n  out of Docker containers", "comments": "12 pages (minus references), 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Context: Virtual machines provide isolation of services at the cost of\nhypervisors and more resource usage. This spurred the growth of systems like\nDocker that enable single hosts to isolate several applications, similar to\nVMs, within a low-overhead abstraction called containers.\n  Motivation: Although containers tout low overhead performance, do they still\nhave low energy consumption?\n  Methodology: This work statistically compares ($t$-test, Wilcoxon) the energy\nconsumption of three application workloads in Docker and on bare-metal Linux.\n  Results: In all cases, there was a statistically significant ($t$-test and\nWilcoxon $p < 0.05$) increase in energy consumption when running tests in\nDocker, mostly due to the performance of I/O system calls.\n", "versions": [{"version": "v1", "created": "Tue, 2 May 2017 21:29:28 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Santos", "Eddie Antonio", ""], ["McLean", "Carson", ""], ["Solinas", "Christopher", ""], ["Hindle", "Abram", ""]]}, {"id": "1705.01229", "submitter": "Avery Miller", "authors": "Avery Miller, Andrzej Pelc", "title": "Deterministic Distributed Construction of $T$-Dominating Sets in Time\n  $T$", "comments": "13 pages", "journal-ref": "Discrete Applied Mathematics 222: 172-178 (2017)", "doi": "10.1016/j.dam.2017.01.012", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $k$-dominating set is a set $D$ of nodes of a graph such that, for each\nnode $v$, there exists a node $w \\in D$ at distance at most $k$ from $v$. Our\naim is the deterministic distributed construction of small $T$-dominating sets\nin time $T$ in networks modeled as undirected $n$-node graphs and under the\n$\\cal{LOCAL}$ communication model.\n  For any positive integer $T$, if $b$ is the size of a pairwise disjoint\ncollection of balls of radii at least $T$ in a graph, then $b$ is an obvious\nlower bound on the size of a $T$-dominating set. Our first result shows that,\neven on rings, it is impossible to construct a $T$-dominating set of size $s$\nasymptotically $b$ (i.e., such that $s/b \\rightarrow 1$) in time $T$.\n  In the range of time $T \\in \\Theta (\\log^* n)$, the size of a $T$-dominating\nset turns out to be very sensitive to multiplicative constants in running time.\nIndeed, it follows from \\cite{KP}, that for time $T=\\gamma \\log^* n$ with large\nconstant $\\gamma$, it is possible to construct a $T$-dominating set whose size\nis a small fraction of $n$. By contrast, we show that, for time $T=\\alpha\n\\log^* n $ for small constant $\\alpha$, the size of a $T$-dominating set must\nbe a large fraction of $n$.\n  Finally, when $T \\in o (\\log^* n)$, the above lower bound implies that, for\nany constant $x<1$, it is impossible to construct a $T$-dominating set of size\nsmaller than $xn$, even on rings. On the positive side, we provide an algorithm\nthat constructs a $T$-dominating set of size $n- \\Theta(T)$ on all graphs.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 01:49:35 GMT"}], "update_date": "2017-05-04", "authors_parsed": [["Miller", "Avery", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1705.01522", "submitter": "Santosh Nagarakatte", "authors": "Adarsh Yoga and Santosh Nagarakatte", "title": "A Fast Causal Profiler for Task Parallel Programs", "comments": "11 pages", "journal-ref": null, "doi": null, "report-no": "Rutgers CS Technical Report: DCS-TR-728", "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes TASKPROF, a profiler that identifies parallelism\nbottlenecks in task parallel programs. It leverages the structure of a task\nparallel execution to perform fine-grained attribution of work to various parts\nof the program. TASKPROF's use of hardware performance counters to perform\nfine-grained measurements minimizes perturbation. TASKPROF's profile execution\nruns in parallel using multi-cores. TASKPROF's causal profile enables users to\nestimate improvements in parallelism when a region of code is optimized even\nwhen concrete optimizations are not yet known. We have used TASKPROF to isolate\nparallelism bottlenecks in twenty three applications that use the Intel\nThreading Building Blocks library. We have designed parallelization techniques\nin five applications to in- crease parallelism by an order of magnitude using\nTASKPROF. Our user study indicates that developers are able to isolate\nperformance bottlenecks with ease using TASKPROF.\n", "versions": [{"version": "v1", "created": "Wed, 3 May 2017 17:37:52 GMT"}, {"version": "v2", "created": "Sat, 27 May 2017 14:45:23 GMT"}, {"version": "v3", "created": "Sun, 2 Jul 2017 05:10:49 GMT"}], "update_date": "2017-07-04", "authors_parsed": [["Yoga", "Adarsh", ""], ["Nagarakatte", "Santosh", ""]]}, {"id": "1705.01660", "submitter": "Lykourgos Kekempanos", "authors": "Jeyarajan Thiyagalingam, Lykourgos Kekempanos, Simon Maskell", "title": "MapReduce Particle Filtering with Exact Resampling and Deterministic\n  Runtime", "comments": "31 pages, 16 figures", "journal-ref": null, "doi": "10.1186/s13634-017-0505-9", "report-no": null, "categories": "stat.CO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Particle filtering is a numerical Bayesian technique that has great potential\nfor solving sequential estimation problems involving non-linear and\nnon-Gaussian models. Since the estimation accuracy achieved by particle filters\nimproves as the number of particles increases, it is natural to consider as\nmany particles as possible. MapReduce is a generic programming model that makes\nit possible to scale a wide variety of algorithms to Big data. However, despite\nthe application of particle filters across many domains, little attention has\nbeen devoted to implementing particle filters using MapReduce.\n  In this paper, we describe an implementation of a particle filter using\nMapReduce. We focus on a component that what would otherwise be a bottleneck to\nparallel execution, the resampling component. We devise a new implementation of\nthis component, which requires no approximations, has $O\\left(N\\right)$ spatial\ncomplexity and deterministic $O\\left(\\left(\\log N\\right)^2\\right)$ time\ncomplexity. Results demonstrate the utility of this new component and culminate\nin consideration of a particle filter with $2^{24}$ particles being distributed\nacross $512$ processor cores.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 00:05:30 GMT"}], "update_date": "2017-11-22", "authors_parsed": [["Thiyagalingam", "Jeyarajan", ""], ["Kekempanos", "Lykourgos", ""], ["Maskell", "Simon", ""]]}, {"id": "1705.01662", "submitter": "Omid Mashayekhi", "authors": "Omid Mashayekhi, Hang Qu, Chinmayee Shah, Philip Levis", "title": "Execution Templates: Caching Control Plane Decisions for Strong Scaling\n  of Data Analytics", "comments": "To appear at USENIX ATC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Control planes of cloud frameworks trade off between scheduling granularity\nand performance. Centralized systems schedule at task granularity, but only\nschedule a few thousand tasks per second. Distributed systems schedule hundreds\nof thousands of tasks per second but changing the schedule is costly.\n  We present execution templates, a control plane abstraction that can schedule\nhundreds of thousands of tasks per second while supporting fine-grained,\nper-task scheduling decisions. Execution templates leverage a program's\nrepetitive control flow to cache blocks of frequently-executed tasks. Executing\na task in a template requires sending a single message. Large-scale scheduling\nchanges install new templates, while small changes apply edits to existing\ntemplates.\n  Evaluations of execution templates in Nimbus, a data analytics framework,\nfind that they provide the fine-grained scheduling flexibility of centralized\ncontrol planes while matching the strong scaling of distributed ones. Execution\ntemplates support complex, real-world applications, such as a fluid simulation\nwith a triply nested loop and data dependent branches.\n", "versions": [{"version": "v1", "created": "Thu, 4 May 2017 00:24:12 GMT"}], "update_date": "2017-05-05", "authors_parsed": [["Mashayekhi", "Omid", ""], ["Qu", "Hang", ""], ["Shah", "Chinmayee", ""], ["Levis", "Philip", ""]]}, {"id": "1705.02127", "submitter": "Sebastian Krinninger", "authors": "Karl Bringmann, Sebastian Krinninger", "title": "A Note on Hardness of Diameter Approximation", "comments": "Accepted to Information Processing Letters", "journal-ref": "Information Processing Letters 133: 10-15 (2018)", "doi": "10.1016/j.ipl.2017.12.010", "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the hardness of approximating the diameter of a network. In the\nCONGEST model of distributed computing, $ \\tilde \\Omega (n) $ rounds are\nnecessary to compute the diameter [Frischknecht et al. SODA'12], where $ \\tilde\n\\Omega (\\cdot) $ hides polylogarithmic factors. Abboud et al. [DISC 2016]\nextended this result to sparse graphs and, at a more fine-grained level, showed\nthat, for any integer $ 1 \\leq \\ell \\leq \\operatorname{polylog} (n) $,\ndistinguishing between networks of diameter $ 4 \\ell + 2 $ and $ 6 \\ell + 1 $\nrequires $ \\tilde \\Omega (n) $ rounds. We slightly tighten this result by\nshowing that even distinguishing between diameter $ 2 \\ell + 1 $ and $ 3 \\ell +\n1 $ requires $ \\tilde \\Omega (n) $ rounds. The reduction of Abboud et al. is\ninspired by recent conditional lower bounds in the RAM model, where the\northogonal vectors problem plays a pivotal role. In our new lower bound, we\nmake the connection to orthogonal vectors explicit, leading to a conceptually\nmore streamlined exposition.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 08:43:21 GMT"}, {"version": "v2", "created": "Mon, 8 Jan 2018 09:24:01 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Bringmann", "Karl", ""], ["Krinninger", "Sebastian", ""]]}, {"id": "1705.02257", "submitter": "Sascha Witt", "authors": "Michael Axtmann, Sascha Witt, Daniel Ferizovic, Peter Sanders", "title": "In-place Parallel Super Scalar Samplesort (IPS$^4$o)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We present a sorting algorithm that works in-place, executes in parallel, is\ncache-efficient, avoids branch-mispredictions, and performs work O(n log n) for\narbitrary inputs with high probability. The main algorithmic contributions are\nnew ways to make distribution-based algorithms in-place: On the practical side,\nby using coarse-grained block-based permutations, and on the theoretical side,\nwe show how to eliminate the recursion stack. Extensive experiments show that\nour algorithm IPS$^4$o scales well on a variety of multi-core machines. We\noutperform our closest in-place competitor by a factor of up to 3. Even as a\nsequential algorithm, we are up to 1.5 times faster than the closest sequential\ncompetitor, BlockQuicksort.\n", "versions": [{"version": "v1", "created": "Fri, 5 May 2017 15:18:08 GMT"}, {"version": "v2", "created": "Thu, 29 Jun 2017 18:27:34 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Axtmann", "Michael", ""], ["Witt", "Sascha", ""], ["Ferizovic", "Daniel", ""], ["Sanders", "Peter", ""]]}, {"id": "1705.02515", "submitter": "Omar Al-Bataineh I.", "authors": "Omar Al-Bataineh", "title": "Epistemic Model Checking of Atomic Commitment Protocols with Byzantine\n  Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The notion of knowledge-based program introduced by Halpern and Fagin\nprovides a useful formalism for designing, analysing, and optimising\ndistributed systems. This paper formulates the two phase commit protocol as a\nknowledge-based program and then an iterative process of model checking and\ncounter-example guided refinement is followed to find concrete implementations\nof the program for the case of perfect recall semantic in the Byzantine\nfailures context with synchronous reliable communication. We model several\ndifferent kinds of Byzantine failures and verify different strategies to fight\nand mitigate them. We address a number of questions that have not been\nconsidered in the prior literature, viz., under what circumstances a sender can\nknow that its transmission has been successful, and under what circumstances an\nagent can know that the coordinator is cheating, and find concrete answers to\nthese questions. The paper describes also a methodology based on\ntemporal-epistemic model checking technology that can be followed to verify the\nshortest and longest execution time of a distributed protocol and the scenarios\nthat lead to them.\n", "versions": [{"version": "v1", "created": "Sat, 6 May 2017 18:38:42 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 16:10:13 GMT"}, {"version": "v3", "created": "Wed, 10 May 2017 10:47:15 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Al-Bataineh", "Omar", ""]]}, {"id": "1705.02609", "submitter": "EPTCS", "authors": "Antti Kuusisto, Fabian Reiter", "title": "Emptiness Problems for Distributed Automata", "comments": "In Proceedings GandALF 2017, arXiv:1709.01761. 13 pages, 2 figures", "journal-ref": "EPTCS 256, 2017, pp. 210-222", "doi": "10.4204/EPTCS.256.15", "report-no": null, "categories": "cs.FL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the decidability of the emptiness problem for three classes of\ndistributed automata. These devices operate on finite directed graphs, acting\nas networks of identical finite-state machines that communicate in an infinite\nsequence of synchronous rounds. The problem is shown to be decidable in\nLogSpace for a class of forgetful automata, where the nodes see the messages\nreceived from their neighbors but cannot remember their own state. When\nrestricted to the appropriate families of graphs, these forgetful automata are\nequivalent to classical finite word automata, but strictly more expressive than\nfinite tree automata. On the other hand, we also show that the emptiness\nproblem is undecidable in general. This already holds for two heavily\nrestricted classes of distributed automata: those that reject immediately if\nthey receive more than one message per round, and those whose state diagram\nmust be acyclic except for self-loops.\n", "versions": [{"version": "v1", "created": "Sun, 7 May 2017 12:45:27 GMT"}, {"version": "v2", "created": "Thu, 7 Sep 2017 06:58:50 GMT"}], "update_date": "2017-09-08", "authors_parsed": [["Kuusisto", "Antti", ""], ["Reiter", "Fabian", ""]]}, {"id": "1705.02671", "submitter": "Dariusz Kowalski R", "authors": "Muhammed Abdulazeez, Pawel Garncarek, Dariusz R. Kowalski, Prudence\n  W.H. Wong", "title": "Lightweight Robust Framework for Workload Scheduling in Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliability, security and stability of cloud services without sacrificing too\nmuch resources have become a desired feature in the area of workload management\nin clouds. The paper proposes and evaluates a lightweight framework for\nscheduling a workload which part could be unreliable. This unreliability could\nbe caused by various types of failures or attacks. Our framework for robust\nworkload scheduling efficiently combines classic fault-tolerant and security\ntools, such as packet/job scanning, with workload scheduling, and it does not\nuse any heavy resource-consuming tools, e.g., cryptography or non-linear\noptimization. More specifically, the framework uses a novel objective function\nto allocate jobs to servers and constantly decides which job to scan based on a\nformula associated with the objective function. We show how to set up the\nobjective function and the corresponding scanning procedure to make the system\nprovably stable, provided it satisfies a specific stability condition. As a\nresult, we show that our framework assures cloud stability even if naive\nscanning-all and scanning-none strategies are not stable. We extend the\nframework to decentralized scheduling and evaluate it under several popular\nrouting procedures.\n", "versions": [{"version": "v1", "created": "Sun, 7 May 2017 17:53:01 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Abdulazeez", "Muhammed", ""], ["Garncarek", "Pawel", ""], ["Kowalski", "Dariusz R.", ""], ["Wong", "Prudence W. H.", ""]]}, {"id": "1705.02745", "submitter": "Vaneet Aggarwal", "authors": "Yang Zhang and Arnob Ghosh and Vaneet Aggarwal and Tian Lan", "title": "Tiered cloud storage via two-stage, latency-aware bidding", "comments": "14 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cloud storage, the digital data is stored in logical storage pools, backed\nby heterogeneous physical storage media and computing infrastructure that are\nmanaged by a Cloud Service Provider (CSP). To balance the tradeoff between\nservice performance and cost, CSPs often employ different storage tiers, for\ninstance, cold storage and hot storage. Storing data in hot storage incurs high\nstorage cost yet delivers low access latency, whereas cold storage is able to\ninexpensively store massive amounts of data and thus provides lower cost with\nhigher latency. In this paper, we address a major challenge confronting the\nCSPs utilizing such tiered storage architecture - how to maximize their overall\nprofit over a variety of storage tiers that offer distinct characteristics, as\nwell as file placement and access request scheduling policies. To this end, we\npropose a scheme where the CSP offers a two-stage auction process for (a)\nrequesting storage capacity, and (b) requesting accesses with latency\nrequirements. Our two-stage bidding scheme provides a hybrid storage and access\noptimization framework with the objective of maximizing the CSP's total net\nprofit over four dimensions: file acceptance decision, placement of accepted\nfiles, file access decision and access request scheduling policy. The proposed\noptimization is a mixed-integer nonlinear program that is hard to solve. We\npropose an efficient heuristic to relax the integer optimization and to solve\nthe resulting nonlinear stochastic programs. The algorithm is evaluated under\ndifferent scenarios and with different storage system parameters, and\ninsightful numerical results are reported by comparing the proposed approach\nwith other profit-maximization models. We see a profit increase of over 60% of\nour proposed method compared to other schemes in certain simulation scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 05:27:09 GMT"}, {"version": "v2", "created": "Mon, 15 May 2017 21:04:13 GMT"}, {"version": "v3", "created": "Thu, 2 Nov 2017 06:49:33 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Zhang", "Yang", ""], ["Ghosh", "Arnob", ""], ["Aggarwal", "Vaneet", ""], ["Lan", "Tian", ""]]}, {"id": "1705.02808", "submitter": "Rati Gelashvili", "authors": "Rati Gelashvili, Idit Keidar, Alexander Spiegelman, Roger Wattenhofer", "title": "Towards Reduced Instruction Sets for Synchronization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contrary to common belief, a recent work by Ellen, Gelashvili, Shavit, and\nZhu has shown that computability does not require multicore architectures to\nsupport \"strong\" synchronization instructions like compare-and-swap, as opposed\nto combinations of \"weaker\" instructions like decrement and multiply. However,\nthis is the status quo, and in turn, most efficient concurrent data-structures\nheavily rely on compare-and-swap (e.g. for swinging pointers and in general,\nconflict resolution).\n  We show that this need not be the case, by designing and implementing a\nconcurrent linearizable Log data-structure (also known as a History object),\nsupporting two operations: append(item), which appends the item to the log, and\nget-log(), which returns the appended items so far, in order. Readers are\nwait-free and writers are lock-free, and this data-structure can be used in a\nlock-free universal construction to implement any concurrent object with a\ngiven sequential specification. Our implementation uses atomic read, xor,\ndecrement, and fetch-and-increment instructions supported on X86 architectures,\nand provides similar performance to a compare-and-swap-based solution on\ntoday's hardware. This raises a fundamental question about minimal set of\nsynchronization instructions that the architectures have to support.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 10:12:42 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Gelashvili", "Rati", ""], ["Keidar", "Idit", ""], ["Spiegelman", "Alexander", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1705.02843", "submitter": "Alex Fukunaga", "authors": "Satoru Horie, Alex Fukunaga", "title": "Block-Parallel IDA* for GPUs (Extended Manuscript)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate GPU-based parallelization of Iterative-Deepening A* (IDA*). We\nshow that straightforward thread-based parallelization techniques which were\npreviously proposed for massively parallel SIMD processors perform poorly due\nto warp divergence and load imbalance. We propose Block-Parallel IDA* (BPIDA*),\nwhich assigns the search of a subtree to a block (a group of threads with\naccess to fast shared memory) rather than a thread. On the 15-puzzle, BPIDA* on\na NVIDIA GRID K520 with 1536 CUDA cores achieves a speedup of 4.98 compared to\na highly optimized sequential IDA* implementation on a Xeon E5-2670 core.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 12:11:36 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Horie", "Satoru", ""], ["Fukunaga", "Alex", ""]]}, {"id": "1705.02851", "submitter": "Vitaly Aksenov", "authors": "Vitaly Aksenov, Petr Kuznetsov", "title": "Flat Parallelization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are two intertwined factors that affect performance of concurrent data\nstructures: the ability of processes to access the data in parallel and the\ncost of synchronization. It has been observed that for a large class of\n\"concurrency-unfriendly\" data structures, fine-grained parallelization does not\npay off: an implementation based on a single global lock outperforms\nfine-grained solutions. The flat combining paradigm exploits this by ensuring\nthat a thread holding the global lock sequentially combines requests and then\nexecutes the combined requests on behalf of concurrent threads.\n  In this paper, we propose a synchronization technique that unites flat\ncombining and parallel bulk updates borrowed from parallel algorithms designed\nfor the PRAM model. The idea is that the combiner thread assigns waiting\nthreads to perform concurrent requests in parallel.\n  We foresee the technique to help in implementing efficient\n\"concurrency-ambivalent\" data structures, which can benefit from both\nparallelism and serialization, depending on the operational context. To\nvalidate the idea, we considered heap-based implementations of a priority\nqueue. These data structures exhibit two important features: concurrent remove\noperations are likely to conflict and thus may benefit from combining, while\nconcurrent insert operations can often be at least partly applied in parallel\nthus may benefit from parallel batching. We show that the resulting flat\nparallelization algorithm performs well compared to state-of-the-art priority\nqueue implementations.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 13:02:34 GMT"}, {"version": "v2", "created": "Tue, 9 May 2017 11:39:57 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Aksenov", "Vitaly", ""], ["Kuznetsov", "Petr", ""]]}, {"id": "1705.02884", "submitter": "Archit Somani", "authors": "Sathya Peri, Muktikanta Sa, Ajay Singh, Nandini Singhal, Archit Somani", "title": "Proving Correctness of Concurrent Objects by Validating Linearization\n  Points", "comments": "arXiv admin note: text overlap with arXiv:1611.03947", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent data structures or CDS such as concurrent stacks, queues, sets\netc. have become very popular in the past few years partly due to the rise of\nmulti-core systems. But one of the greatest challenges with CDSs has been\ndeveloping correct structures and then proving the correctness of these\nstructures. We believe that techniques that help prove the correctness of these\nCDSs can also guide in developing new CDSs. An intuitive technique to prove the\ncorrectness of CDSs is using Linearization Points or LPs. An LP is an atomic\nevent in the execution interval of each method such that the execution of the\nentire method seems to have taken place in the instant of that event. One of\nthe main challenges with the LP based approach is to identify the correct LPs\nof a CDS. Identifying the correct LPs can be deceptively wrong in many cases.\nIn fact, in many cases, the LP identified or even worse the CDS itself could be\nwrong. To address these issues, several automatic tools for verifying\nlinearizability have been developed. But we believe that these tools don't\nprovide insight to a programmer to develop the correct concurrent programs or\nidentify the LPs. Considering the complexity of developing a CDS and verifying\nits correctness, we address the most basic problem of this domain in this\npaper: given the set of LPs of a CDS, how to show its correctness? We assume\nthat we are given a CDS and its LPs. We have developed a hand-crafted technique\nof proving the correctness of the CDS by validating its LPs. As observed\nearlier, identifying the correct LPs is very tricky and erroneous. But since\nour technique is hand-crafted, we believe that the process of proving\ncorrectness might provide insight to identify the correct LPs, if the currently\nchosen LP is incorrect. We also believe that this technique might also offer\nthe programmer some insight to develop more efficient variants of the CDS.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 14:04:11 GMT"}, {"version": "v2", "created": "Sat, 13 May 2017 04:54:36 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 08:22:39 GMT"}, {"version": "v4", "created": "Sun, 4 Mar 2018 14:39:01 GMT"}, {"version": "v5", "created": "Thu, 7 Jun 2018 11:27:33 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Peri", "Sathya", ""], ["Sa", "Muktikanta", ""], ["Singh", "Ajay", ""], ["Singhal", "Nandini", ""], ["Somani", "Archit", ""]]}, {"id": "1705.02898", "submitter": "Manfred Schwarz", "authors": "Matthias F\\\"ugger and Thomas Nowak and Manfred Schwarz", "title": "Tight Bounds for Asymptotic and Approximate Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of asymptotic and approximate consensus algorithms\nunder harsh environmental conditions. The asymptotic consensus problem requires\na set of agents to repeatedly set their outputs such that the outputs converge\nto a common value within the convex hull of initial values. This problem, and\nthe related approximate consensus problem, are fundamental building blocks in\ndistributed systems where exact consensus among agents is not required or\npossible, e.g., man-made distributed control systems, and have applications in\nthe analysis of natural distributed systems, such as flocking and opinion\ndynamics. We prove tight lower bounds on the contraction rates of asymptotic\nconsensus algorithms in dynamic networks, from which we deduce bounds on the\ntime complexity of approximate consensus algorithms. In particular, the\nobtained bounds show optimality of asymptotic and approximate consensus\nalgorithms presented in [Charron-Bost et al., ICALP'16] for certain dynamic\nnetworks, including the weakest dynamic network model in which asymptotic and\napproximate consensus are solvable. As a corollary we also obtain\nasymptotically tight bounds for asymptotic consensus in the classical\nasynchronous model with crashes.\n  Central to our lower bound proofs is an extended notion of valency, the set\nof reachable limits of an asymptotic consensus algorithm starting from a given\nconfiguration. We further relate topological properties of valencies to the\nsolvability of exact consensus, shedding some light on the relation of these\nthree fundamental problems in dynamic networks.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 14:42:40 GMT"}, {"version": "v2", "created": "Wed, 27 Jun 2018 11:39:32 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["F\u00fcgger", "Matthias", ""], ["Nowak", "Thomas", ""], ["Schwarz", "Manfred", ""]]}, {"id": "1705.02899", "submitter": "George K. Thiruvathukal", "authors": "Konstantin L\\\"aufer and George K. Thiruvathukal", "title": "Teaching Concurrent Software Design: A Case Study Using Android", "comments": "Submitted to CDER NSF/IEEE-TCPP Curriculum Initiative on Parallel and\n  Distributed Computing - Core Topics for Undergraduates", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we explore various parallel and distributed computing topics\nfrom a user-centric software engineering perspective. Specifically, in the\ncontext of mobile application development, we study the basic building blocks\nof interactive applications in the form of events, timers, and asynchronous\nactivities, along with related software modeling, architecture, and design\ntopics.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 14:45:13 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["L\u00e4ufer", "Konstantin", ""], ["Thiruvathukal", "George K.", ""]]}, {"id": "1705.02970", "submitter": "Afshin Zafari", "authors": "Afshin Zafari", "title": "TaskUniVerse: A Task-Based Unified Interface for Versatile Parallel\n  Execution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Task based parallel programming has shown competitive outcomes in many\naspects of parallel programming such as efficiency, performance, productivity\nand scalability. Different approaches are used by different software\ndevelopment frameworks to provide these outcomes to the programmer, while\nmaking the underlying hardware architecture transparent to her. However, since\nprograms are not portable between these frameworks, using one framework or the\nother is still a vital decision by the programmer whose concerns are\nexpandability, adaptivity, maintainability and interoperability of the\nprograms. In this work, we propose a unified programming interface that a\nprogrammer can use for working with different task based parallel frameworks\ntransparently. In this approach we abstract the common concepts of task based\nparallel programming and provide them to the programmer in a single programming\ninterface uniformly for all frameworks. We have tested the interface by running\nprograms which implement matrix operations within frameworks that are optimized\nfor shared and distributed memory architectures and accelerators, while the\ncooperation between frameworks is configured externally with no need to modify\nthe programs. Further possible extensions of the interface and future potential\nresearch are also described.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 16:57:21 GMT"}], "update_date": "2017-05-09", "authors_parsed": [["Zafari", "Afshin", ""]]}, {"id": "1705.03102", "submitter": "Albert Reuther PhD", "authors": "Albert Reuther, Chansup Byun, William Arcand, David Bestor, Bill\n  Bergeron, Matthew Hubbell, Michael Jones, Peter Michaleas, Andrew Prout,\n  Antonio Rosa, Jeremy Kepner", "title": "Scalable System Scheduling for HPC and Big Data", "comments": "34 pages, 7 figures", "journal-ref": null, "doi": "10.1016/j.jpdc.2017.06.009", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the rapidly expanding field of parallel processing, job schedulers are the\n\"operating systems\" of modern big data architectures and supercomputing\nsystems. Job schedulers allocate computing resources and control the execution\nof processes on those resources. Historically, job schedulers were the domain\nof supercomputers, and job schedulers were designed to run massive,\nlong-running computations over days and weeks. More recently, big data\nworkloads have created a need for a new class of computations consisting of\nmany short computations taking seconds or minutes that process enormous\nquantities of data. For both supercomputers and big data systems, the\nefficiency of the job scheduler represents a fundamental limit on the\nefficiency of the system. Detailed measurement and modeling of the performance\nof schedulers are critical for maximizing the performance of a large-scale\ncomputing system. This paper presents a detailed feature analysis of 15\nsupercomputing and big data schedulers. For big data workloads, the scheduler\nlatency is the most important performance characteristic of the scheduler. A\ntheoretical model of the latency of these schedulers is developed and used to\ndesign experiments targeted at measuring scheduler latency. Detailed\nbenchmarking of four of the most popular schedulers (Slurm, Son of Grid Engine,\nMesos, and Hadoop YARN) are conducted. The theoretical model is compared with\ndata and demonstrates that scheduler performance can be characterized by two\nkey parameters: the marginal latency of the scheduler $t_s$ and a nonlinear\nexponent $\\alpha_s$. For all four schedulers, the utilization of the computing\nsystem decreases to < 10\\% for computations lasting only a few seconds.\nMultilevel schedulers that transparently aggregate short computations can\nimprove utilization for these short computations to > 90\\% for all four of the\nschedulers that were tested.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 21:58:12 GMT"}], "update_date": "2018-03-06", "authors_parsed": [["Reuther", "Albert", ""], ["Byun", "Chansup", ""], ["Arcand", "William", ""], ["Bestor", "David", ""], ["Bergeron", "Bill", ""], ["Hubbell", "Matthew", ""], ["Jones", "Michael", ""], ["Michaleas", "Peter", ""], ["Prout", "Andrew", ""], ["Rosa", "Antonio", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1705.03125", "submitter": "Mohammadamir Kavousi", "authors": "Mohammadamir Kavousi", "title": "Affinity Scheduling and the Applications on Data Center Scheduling with\n  Data Locality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MapReduce framework is the de facto standard in Hadoop. Considering the data\nlocality in data centers, the load balancing problem of map tasks is a special\ncase of affinity scheduling problem. There is a huge body of work on affinity\nscheduling, proposing heuristic algorithms which try to increase data locality\nin data centers like Delay Scheduling and Quincy. However, not enough attention\nhas been put on theoretical guarantees on throughput and delay optimality of\nsuch algorithms. In this work, we present and compare different algorithms and\ndiscuss their shortcoming and strengths. To the best of our knowledge, most\ndata centers are using static load balancing algorithms which are not efficient\nin any ways and results in wasting the resources and causing unnecessary delays\nfor users.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 00:00:38 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Kavousi", "Mohammadamir", ""]]}, {"id": "1705.03162", "submitter": "Kyle Niemeyer", "authors": "Daniel J Magee and Kyle E Niemeyer", "title": "Accelerating solutions of one-dimensional unsteady PDEs with GPU-based\n  swept time-space decomposition", "comments": "25 pages, 10 figures", "journal-ref": "J. Comput. Phys. 357 (2018) 338-352", "doi": "10.1016/j.jcp.2017.12.028", "report-no": null, "categories": "physics.comp-ph cs.DC cs.MS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The expedient design of precision components in aerospace and other high-tech\nindustries requires simulations of physical phenomena often described by\npartial differential equations (PDEs) without exact solutions. Modern design\nproblems require simulations with a level of resolution difficult to achieve in\nreasonable amounts of time---even in effectively parallelized solvers. Though\nthe scale of the problem relative to available computing power is the greatest\nimpediment to accelerating these applications, significant performance gains\ncan be achieved through careful attention to the details of memory\ncommunication and access. The swept time-space decomposition rule reduces\ncommunication between sub-domains by exhausting the domain of influence before\ncommunicating boundary values. Here we present a GPU implementation of the\nswept rule, which modifies the algorithm for improved performance on this\nprocessing architecture by prioritizing use of private (shared) memory,\navoiding interblock communication, and overwriting unnecessary values. It shows\nsignificant improvement in the execution time of finite-difference solvers for\none-dimensional unsteady PDEs, producing speedups of 2--9$\\times$ for a range\nof problem sizes, respectively, compared with simple GPU versions and\n7--300$\\times$ compared with parallel CPU versions. However, for a more\nsophisticated one-dimensional system of equations discretized with a\nsecond-order finite-volume scheme, the swept rule performs 1.2--1.9$\\times$\nworse than a standard implementation for all problem sizes.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 03:25:24 GMT"}, {"version": "v2", "created": "Fri, 10 Nov 2017 23:58:13 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Magee", "Daniel J", ""], ["Niemeyer", "Kyle E", ""]]}, {"id": "1705.03245", "submitter": "Xu Jiang", "authors": "Xu Jiang, Nan Guan, Xiang Long, Wang Yi", "title": "Semi-Federated Scheduling of Parallel Real-Time Tasks on Multiprocessors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Federated scheduling is a promising approach to schedule parallel real-time\ntasks on multi-cores, where each heavy task exclusively executes on a number of\ndedicated processors, while light tasks are treated as sequential sporadic\ntasks and share the remaining processors. However, federated scheduling suffers\nresource waste since a heavy task with processing capacity requirement $x +\n\\epsilon$ (where $x$ is an integer and $0 < \\epsilon < 1$) needs $x + 1$\ndedicated processors. In the extreme case, almost half of the processing\ncapacity is wasted. In this paper we propose the semi-federate scheduling\napproach, which only grants $x$ dedicated processors to a heavy task with\nprocessing capacity requirement $x + \\epsilon$, and schedules the remaining\n$\\epsilon$ part together with light tasks on shared processors. Experiments\nwith randomly generated task sets show the semi-federated scheduling approach\nsignificantly outperforms not only federated scheduling, but also all existing\napproaches for scheduling parallel real-time tasks on multi-cores.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 09:28:16 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Jiang", "Xu", ""], ["Guan", "Nan", ""], ["Long", "Xiang", ""], ["Yi", "Wang", ""]]}, {"id": "1705.03284", "submitter": "Janne H. Korhonen", "authors": "Janne H. Korhonen, Jukka Suomela", "title": "Towards a complexity theory for the congested clique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The congested clique model of distributed computing has been receiving\nattention as a model for densely connected distributed systems. While there has\nbeen significant progress on the side of upper bounds, we have very little in\nterms of lower bounds for the congested clique; indeed, it is now know that\nproving explicit congested clique lower bounds is as difficult as proving\ncircuit lower bounds.\n  In this work, we use various more traditional complexity-theoretic tools to\nbuild a clearer picture of the complexity landscape of the congested clique:\n  -- Nondeterminism and beyond: We introduce the nondeterministic congested\nclique model (analogous to NP) and show that there is a natural canonical\nproblem family that captures all problems solvable in constant time with\nnondeterministic algorithms. We further generalise these notions by introducing\nthe constant-round decision hierarchy (analogous to the polynomial hierarchy).\n  -- Non-constructive lower bounds: We lift the prior non-uniform counting\narguments to a general technique for proving non-constructive uniform lower\nbounds for the congested clique. In particular, we prove a time hierarchy\ntheorem for the congested clique, showing that there are decision problems of\nessentially all complexities, both in the deterministic and nondeterministic\nsettings.\n  -- Fine-grained complexity: We map out relationships between various natural\nproblems in the congested clique model, arguing that a reduction-based\ncomplexity theory currently gives us a fairly good picture of the complexity\nlandscape of the congested clique.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 11:43:38 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 12:29:35 GMT"}, {"version": "v3", "created": "Tue, 24 Apr 2018 14:48:45 GMT"}], "update_date": "2018-04-25", "authors_parsed": [["Korhonen", "Janne H.", ""], ["Suomela", "Jukka", ""]]}, {"id": "1705.03392", "submitter": "Hans van Ditmarsch", "authors": "Philippe Balbiani, Hans van Ditmarsch, Sa\\'ul Fern\\'andez Gonz\\'alez", "title": "Asynchronous Announcements", "comments": "Originally presented at workshop Strategic Reasoning 2017 Liverpool", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LO", "license": "http://creativecommons.org/licenses/by-nc-nd/4.0/", "abstract": "  We propose a multi-agent epistemic logic of asynchronous announcements, where\ntruthful announcements are publicly sent but individually received by agents,\nand in the order in which they were sent. Additional to epistemic modalities\nthe logic contains dynamic modalities for making announcements and for\nreceiving them. What an agent believes is a function of her initial uncertainty\nand of the announcements she has received. Beliefs need not be truthful,\nbecause announcements already made may not yet have been received. As\nannouncements are true when sent, certain message sequences can be ruled out,\njust like inconsistent cuts in distributed computing.\n  We provide a complete axiomatization for this \\emph{asynchronous announcement\nlogic} (AA). It is a reduction system that also demonstrates that any formula\nin $AA$ is equivalent to one without dynamic modalities, just as for public\nannouncement logic. A detailed example modelling message exchanging processes\nin distributed computing in $AA$ closes our investigation.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 15:30:47 GMT"}, {"version": "v2", "created": "Sat, 13 May 2017 14:23:20 GMT"}, {"version": "v3", "created": "Fri, 27 Sep 2019 10:41:12 GMT"}, {"version": "v4", "created": "Mon, 18 Jan 2021 17:06:43 GMT"}], "update_date": "2021-01-19", "authors_parsed": [["Balbiani", "Philippe", ""], ["van Ditmarsch", "Hans", ""], ["Gonz\u00e1lez", "Sa\u00fal Fern\u00e1ndez", ""]]}, {"id": "1705.03414", "submitter": "Nisheeth Vishnoi", "authors": "L. Elisa Celis, Peter M. Krafft, Nisheeth K. Vishnoi", "title": "A Distributed Learning Dynamics in Social Groups", "comments": "To appear in PODC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CY cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a distributed learning process observed in human groups and other\nsocial animals. This learning process appears in settings in which each\nindividual in a group is trying to decide over time, in a distributed manner,\nwhich option to select among a shared set of options. Specifically, we consider\na stochastic dynamics in a group in which every individual selects an option in\nthe following two-step process: (1) select a random individual and observe the\noption that individual chose in the previous time step, and (2) adopt that\noption if its stochastic quality was good at that time step. Various\ninstantiations of such distributed learning appear in nature, and have also\nbeen studied in the social science literature. From the perspective of an\nindividual, an attractive feature of this learning process is that it is a\nsimple heuristic that requires extremely limited computational capacities. But\nwhat does it mean for the group -- could such a simple, distributed and\nessentially memoryless process lead the group as a whole to perform optimally?\nWe show that the answer to this question is yes -- this distributed learning is\nhighly effective at identifying the best option and is close to optimal for the\ngroup overall. Our analysis also gives quantitative bounds that show fast\nconvergence of these stochastic dynamics. Prior to our work the only\ntheoretical work related to such learning dynamics has been either in\ndeterministic special cases or in the asymptotic setting. Finally, we observe\nthat our infinite population dynamics is a stochastic variant of the classic\nmultiplicative weights update (MWU) method. Consequently, we arrive at the\nfollowing interesting converse: the learning dynamics on a finite population\nconsidered here can be viewed as a novel distributed and low-memory\nimplementation of the classic MWU method.\n", "versions": [{"version": "v1", "created": "Mon, 8 May 2017 15:15:18 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Celis", "L. Elisa", ""], ["Krafft", "Peter M.", ""], ["Vishnoi", "Nisheeth K.", ""]]}, {"id": "1705.03427", "submitter": "Laurent Massoulie", "authors": "Laurent Massouli\\'e and R\\'emi Varloot", "title": "Rapid Mixing of Local Graph Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph dynamics arise naturally in many contexts. For instance in peer-to-peer\nnetworks, a participating peer may replace an existing connection with one\nneighbour by a new connection with a neighbour's neighbour. Several such local\nrewiring rules have been proposed to ensure that peer-to-peer networks achieve\ngood connectivity properties (e.g. high expansion) in equilibrium. However it\nhas remained an open question whether there existed such rules that also led to\nfast convergence to equilibrium. In this work we provide an affirmative answer:\nWe exhibit a local rewiring rule that converges to equilibrium after each\nparticipating node has undergone only a number of rewirings that is\npoly-logarithmic in the system size. The proof involves consideration of the\nwhole isoperimetric profile of the graph, and may be of independent interest.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 16:56:19 GMT"}], "update_date": "2017-05-10", "authors_parsed": [["Massouli\u00e9", "Laurent", ""], ["Varloot", "R\u00e9mi", ""]]}, {"id": "1705.03501", "submitter": "Lixing Chen", "authors": "Lixing Chen and Jie Xu", "title": "Socially Trusted Collaborative Edge Computing in Ultra Dense Networks", "comments": "arXiv admin note: text overlap with arXiv:1010.4501 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small cell base stations (SBSs) endowed with cloud-like computing\ncapabilities are considered as a key enabler of edge computing (EC), which\nprovides ultra-low latency and location-awareness for a variety of emerging\nmobile applications and the Internet of Things. However, due to the limited\ncomputation resources of an individual SBS, providing computation services of\nhigh quality to its users faces significant challenges when it is overloaded\nwith an excessive amount of computation workload. In this paper, we propose\ncollaborative edge computing among SBSs by forming SBS coalitions to share\ncomputation resources with each other, thereby accommodating more computation\nworkload in the edge system and reducing reliance on the remote cloud. A novel\nSBS coalition formation algorithm is developed based on the coalitional game\ntheory to cope with various new challenges in small-cell-based edge systems,\nincluding the co-provisioning of radio access and computing services,\ncooperation incentives, and potential security risks. To address these\nchallenges, the proposed method (1) allows collaboration at both the user-SBS\nassociation stage and the SBS peer offloading stage by exploiting the ultra\ndense deployment of SBSs, (2) develops a payment-based incentive mechanism that\nimplements proportionally fair utility division to form stable SBS coalitions,\nand (3) builds a social trust network for managing security risks among SBSs\ndue to collaboration. Systematic simulations in practical scenarios are carried\nout to evaluate the efficacy and performance of the proposed method, which\nshows that tremendous edge computing performance improvement can be achieved.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 19:28:04 GMT"}, {"version": "v2", "created": "Thu, 11 May 2017 03:42:50 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Chen", "Lixing", ""], ["Xu", "Jie", ""]]}, {"id": "1705.03538", "submitter": "Giovanni Viglietta", "authors": "Giuseppe A. Di Luna, Paola Flocchini, Nicola Santoro, Giovanni\n  Viglietta, and Yukiko Yamauchi", "title": "Shape Formation by Programmable Particles", "comments": "71 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Shape formation is a basic distributed problem for systems of computational\nmobile entities. Intensively studied for systems of autonomous mobile robots,\nit has recently been investigated in the realm of programmable matter. Namely,\nit has been studied in the geometric Amoebot model, where the anonymous\nentities, called particles, operate on a hexagonal tessellation of the plane\nand have limited computational power (they have constant memory), strictly\nlocal interaction and communication capabilities (only with particles in\nneighboring nodes of the grid), and limited motorial capabilities (from a grid\nnode to an empty neighboring node); their activation is controlled by an\nadversarial scheduler. Recent investigations have shown how, starting from a\nwell-structured configuration in which the particles form a (not necessarily\ncomplete) triangle, the particles can form a large class of shapes. This result\nhas been established under several assumptions: agreement on the clockwise\ndirection (i.e., chirality), a sequential activation schedule, and\nrandomization (i.e., particles can flip coins).\n  In this paper we provide a characterization of which shapes can be formed\ndeterministically starting from any simply connected initial configuration of\n$n$ particles. As a byproduct, if randomization is allowed, then any input\nshape can be formed from any initial (simply connected) shape by our algorithm,\nprovided that $n$ is large enough.\n  Our algorithm works without chirality, proving that chirality is\ncomputationally irrelevant for shape formation. Furthermore, it works under a\nstrong adversarial scheduler, not necessarily sequential. We also consider the\ncomplexity of shape formation in terms of both the number of rounds and of\nmoves performed by the particles. We prove that our solution has a complexity\nof $O(n^2)$ rounds and moves: this number of moves is also asymptotically\noptimal.\n", "versions": [{"version": "v1", "created": "Tue, 9 May 2017 20:57:19 GMT"}, {"version": "v2", "created": "Fri, 1 Sep 2017 13:22:21 GMT"}, {"version": "v3", "created": "Sat, 9 Sep 2017 22:54:04 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Di Luna", "Giuseppe A.", ""], ["Flocchini", "Paola", ""], ["Santoro", "Nicola", ""], ["Viglietta", "Giovanni", ""], ["Yamauchi", "Yukiko", ""]]}, {"id": "1705.03598", "submitter": "Kai Wu", "authors": "Wei Liu, Kai Wu, Jialin Liu, Feng Chen, Dong Li", "title": "Performance Evaluation and Modeling of HPC I/O on Non-Volatile Memory", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  HPC applications pose high demands on I/O performance and storage capability.\nThe emerging non-volatile memory (NVM) techniques offer low-latency, high\nbandwidth, and persistence for HPC applications. However, the existing I/O\nstack are designed and optimized based on an assumption of disk-based storage.\nTo effectively use NVM, we must re-examine the existing high performance\ncomputing (HPC) I/O sub-system to properly integrate NVM into it. Using NVM as\na fast storage, the previous assumption on the inferior performance of storage\n(e.g., hard drive) is not valid any more. The performance problem caused by\nslow storage may be mitigated; the existing mechanisms to narrow the\nperformance gap between storage and CPU may be unnecessary and result in large\noverhead. Thus fully understanding the impact of introducing NVM into the HPC\nsoftware stack demands a thorough performance study.\n  In this paper, we analyze and model the performance of I/O intensive HPC\napplications with NVM as a block device. We study the performance from three\nperspectives: (1) the impact of NVM on the performance of traditional page\ncache; (2) a performance comparison between MPI individual I/O and POSIX I/O;\nand (3) the impact of NVM on the performance of collective I/O. We reveal the\ndiminishing effects of page cache, minor performance difference between MPI\nindividual I/O and POSIX I/O, and performance disadvantage of collective I/O on\nNVM due to unnecessary data shuffling. We also model the performance of MPI\ncollective I/O and study the complex interaction between data shuffling,\nstorage performance, and I/O access patterns.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 03:29:55 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Liu", "Wei", ""], ["Wu", "Kai", ""], ["Liu", "Jialin", ""], ["Chen", "Feng", ""], ["Li", "Dong", ""]]}, {"id": "1705.03704", "submitter": "Carlos Baquero", "authors": "Deepthi Devaki Akkoorath, Jos\\'e Brand\\~ao, Annette Bieniusa, Carlos\n  Baquero", "title": "Global-Local View: Scalable Consistency for Concurrent Data Types", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Concurrent linearizable access to shared objects can be prohibitively\nexpensive in a high contention workload. Many applications apply ad-hoc\ntechniques to eliminate the need of synchronous atomic updates, which may\nresult in non-linearizable implementations. We propose a new programming model\nwhich leverages such patterns for concurrent access to objects in a shared\nmemory system. In this model, each thread maintains different views on the\nshared object - a thread-local view and a global view. As the thread-local view\nis not shared, it can be updated without incurring synchronization costs. These\nlocal updates become visible to other threads only after the thread-local view\nis merged with the global view. This enables better performance at the expense\nof linearizability. We show that it is possible to maintain thread-local views\nand to perform merge efficiently for several data types and evaluate their\nperformance and scalability compared to linearizable implementations. Further,\nwe discuss the consistency semantics of the data types and the associated\nprogramming model.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 11:22:32 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Akkoorath", "Deepthi Devaki", ""], ["Brand\u00e3o", "Jos\u00e9", ""], ["Bieniusa", "Annette", ""], ["Baquero", "Carlos", ""]]}, {"id": "1705.03834", "submitter": "Jara Uitto", "authors": "Sebastian Brandt, Jara Uitto and Roger Wattenhofer", "title": "Tight Bounds for Asynchronous Collaborative Grid Exploration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a small group of mobile agents whose goal is to locate a certain\ncell in a two-dimensional infinite grid. The agents operate in an asynchronous\nenvironment, where in each discrete time step, an arbitrary subset of the\nagents execute one atomic look-compute-move cycle. The protocol controlling\neach agent is determined by a (possibly distinct) finite automaton. The only\nmeans of communication is to sense the states of the agents sharing the same\ngrid cell. Whenever an agent moves, the destination cell of the movement is\nchosen by the agent's automaton from the set of neighboring grid cells. We\nstudy the minimum number of agents required to locate the target cell within\nfinite time and our main result states a tight lower bound for agents endowed\nwith a global compass. Furthermore, we show that the lack of such a compass\nmakes the problem strictly more difficult and present tight upper and lower\nbounds for this case.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 15:56:59 GMT"}, {"version": "v2", "created": "Mon, 7 May 2018 22:34:17 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Brandt", "Sebastian", ""], ["Uitto", "Jara", ""], ["Wattenhofer", "Roger", ""]]}, {"id": "1705.03876", "submitter": "Tuomo Lempi\\\"ainen", "authors": "Tuomo Lempi\\\"ainen and Jukka Suomela", "title": "Constant Space and Non-Constant Time in Distributed Computing", "comments": "13 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While the relationship of time and space is an established topic in\ntraditional centralised complexity theory, this is not the case in distributed\ncomputing. We aim to remedy this by studying the time and space complexity of\nalgorithms in a weak message-passing model of distributed computing. While a\nconstant number of communication rounds implies a constant number of states\nvisited during the execution, the other direction is not clear at all. We\nconsider several graph families and show that indeed, there exist non-trivial\ngraph problems that are solvable by constant-space algorithms but that require\na non-constant running time. This provides us with a new complexity class for\ndistributed computing and raises interesting questions about the existence of\nfurther combinations of time and space complexity.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 17:58:28 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Lempi\u00e4inen", "Tuomo", ""], ["Suomela", "Jukka", ""]]}, {"id": "1705.04042", "submitter": "Moti Medina", "authors": "Christoph Lenzen and Moti Medina", "title": "Robust Routing Made Easy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Designing routing schemes is a multidimensional and complex task that depends\non the objective function, the computational model (centralized vs.\ndistributed), and the amount of uncertainty (online vs. offline). Nevertheless,\nthere are quite a few well-studied general techniques, for a large variety of\nnetwork problems. In contrast, in our view, practical techniques for designing\nrobust routing schemes are scarce; while fault-tolerance has been studied from\na number of angles, existing approaches are concerned with dealing with faults\nafter the fact by rerouting, self-healing, or similar techniques. We argue that\nthis comes at a high burden for the designer, as in such a system any algorithm\nmust account for the effects of faults on communication.\n  With the goal of initiating efforts towards addressing this issue, we\nshowcase simple and generic transformations that can be used as a blackbox to\nincrease resilience against (independently distributed) faults. Given a network\nand a routing scheme, we determine a reinforced network and corresponding\nrouting scheme that faithfully preserves the specification and behavior of the\noriginal scheme. We show that reasonably small constant overheads in terms of\nsize of the new network compared to the old are sufficient for substantially\nrelaxing the reliability requirements on individual components. The main\nmessage in this paper is that the task of designing a robust routing scheme can\nbe decoupled into (i) designing a routing scheme that meets the specification\nin a fault-free environment, (ii) ensuring that nodes correspond to\nfault-containment regions, i.e., fail (approximately) independently, and (iii)\napplying our transformation to obtain a reinforced network and a robust routing\nscheme that is fault-tolerant.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 07:25:01 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Lenzen", "Christoph", ""], ["Medina", "Moti", ""]]}, {"id": "1705.04069", "submitter": "Kiran Verma", "authors": "Khalid Al Rasbi (MCBS), Hothefa Shaker (MCBS), Zeyad Sharef (College\n  of Engineering)", "title": "Survey on Data-Centric based Routing Protocols for Wireless Sensor\n  Networks", "comments": null, "journal-ref": "International Journal of Electrical, Electronics and Computers\n  (EEC Journal), 2017, 2, pp.9 - 16", "doi": "10.24001/eec.2.2.3", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The great concern for energy that grew with the technological advances in the\nfield of networks and especially in sensor network has triggered various\napproaches and protocols that relate to sensor networks. In this context, the\nrouting protocols were of great interest. The aim of the present paper is to\ndiscuss routing protocols for sensor networks. This paper will focus mainly on\nthe discussion of the data-centric approach (COUGAR, rumor, SPIN, flooding and\nGossiping), while shedding light on the other approaches occasionally. The\nfunctions of the nodes will be discussed as well. The methodology selected for\nthis paper is based on a close description and discussion of the protocol. As a\nconclusion, open research questions and limitations are proposed to the reader\nat the end of this paper.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 08:34:06 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Rasbi", "Khalid Al", "", "MCBS"], ["Shaker", "Hothefa", "", "MCBS"], ["Sharef", "Zeyad", "", "College\n  of Engineering"]]}, {"id": "1705.04144", "submitter": "Laurent Feuilloley", "authors": "Laurent Feuilloley and Pierre Fraigniaud", "title": "Error-Sensitive Proof-Labeling Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proof-labeling schemes are known mechanisms providing nodes of networks with\ncertificates that can be verified locally by distributed algorithms. Given a\nboolean predicate on network states, such schemes enable to check whether the\npredicate is satisfied by the actual state of the network, by having nodes\ninteracting with their neighbors only. Proof-labeling schemes are typically\ndesigned for enforcing fault-tolerance, by making sure that if the current\nstate of the network is illegal with respect to some given predicate, then at\nleast one node will detect it. Such a node can raise an alarm, or launch a\nrecovery procedure enabling the system to return to a legal state. In this\npaper, we introduce error-sensitive proof-labeling schemes. These are\nproof-labeling schemes which guarantee that the number of nodes detecting\nillegal states is linearly proportional to the edit-distance between the\ncurrent state and the set of legal states. By using error-sensitive\nproof-labeling schemes, states which are far from satisfying the predicate will\nbe detected by many nodes, enabling fast return to legality. We provide a\nstructural characterization of the set of boolean predicates on network states\nfor which there exist error-sensitive proof-labeling schemes. This\ncharacterization allows us to show that classical predicates such as, e.g.,\nacyclicity, and leader admit error-sensitive proof-labeling schemes, while\nothers like regular subgraphs don't. We also focus on compact error-sensitive\nproof-labeling schemes. In particular, we show that the known proof-labeling\nschemes for spanning tree and minimum spanning tree, using certificates on\n$O(\\log n)$ bits, and on $O\\left(\\log^2n\\right)$ bits, respectively, are\nerror-sensitive, as long as the trees are locally represented by adjacency\nlists, and not just by parent pointers.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 13:01:40 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Feuilloley", "Laurent", ""], ["Fraigniaud", "Pierre", ""]]}, {"id": "1705.04159", "submitter": "Tom Vander Aa", "authors": "Tom Vander Aa, Imen Chakroun and Tom Haber", "title": "Distributed Bayesian Probabilistic Matrix Factorization", "comments": null, "journal-ref": null, "doi": "10.1109/CLUSTER.2016.13", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix factorization is a common machine learning technique for recommender\nsystems. Despite its high prediction accuracy, the Bayesian Probabilistic\nMatrix Factorization algorithm (BPMF) has not been widely used on large scale\ndata because of its high computational cost. In this paper we propose a\ndistributed high-performance parallel implementation of BPMF on shared memory\nand distributed architectures. We show by using efficient load balancing using\nwork stealing on a single node, and by using asynchronous communication in the\ndistributed version we beat state of the art implementations.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 13:20:01 GMT"}], "update_date": "2017-05-12", "authors_parsed": [["Aa", "Tom Vander", ""], ["Chakroun", "Imen", ""], ["Haber", "Tom", ""]]}, {"id": "1705.04263", "submitter": "Wiktor Daszczuk", "authors": "Bogdan Czejdo, Sambit Bhattacharya, Miko{\\l}aj Baszun, Wiktor B.\n  Daszczuk", "title": "Improving Resilience of Autonomous Moving Platforms by Real Time\n  Analysis of Their Cooperation", "comments": "11 pages, 5 figures", "journal-ref": "Autobusy-TEST, vol. 17, No.3, pp.1294-1301 (2016)", "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Environmental changes, failures, collisions or even terrorist attacks can\ncause serious malfunctions of the delivery systems. We have presented a novel\napproach improving resilience of Autonomous Moving Platforms AMPs. The approach\nis based on multi-level state diagrams describing environmental trigger\nspecifications, movement actions and synchronization primitives. The upper\nlevel diagrams allowed us to model advanced interactions between autonomous\nAMPs and detect irregularities such as deadlocks live-locks etc. The techniques\nwere presented to verify and analyze combined AMPs' behaviors using model\nchecking technique. The described system, Dedan verifier, is still under\ndevelopment. In the near future, a graphical form of verified system\nrepresentation is planned.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 16:29:00 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Czejdo", "Bogdan", ""], ["Bhattacharya", "Sambit", ""], ["Baszun", "Miko\u0142aj", ""], ["Daszczuk", "Wiktor B.", ""]]}, {"id": "1705.04374", "submitter": "Jonas \\v{S}ukys", "authors": "Jonas \\v{S}ukys, Ursula Rasthofer, Fabian Wermelinger, Panagiotis\n  Hadjidoukas, and Petros Koumoutsakos", "title": "Optimal fidelity multi-level Monte Carlo for quantification of\n  uncertainty in simulations of cloud cavitation collapse", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC math.NA stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We quantify uncertainties in the location and magnitude of extreme pressure\nspots revealed from large scale multi-phase flow simulations of cloud\ncavitation collapse. We examine clouds containing 500 cavities and quantify\nuncertainties related to their initial spatial arrangement. The resulting\n2000-dimensional space is sampled using a non-intrusive and computationally\nefficient Multi-Level Monte Carlo (MLMC) methodology. We introduce novel\noptimal control variate coefficients to enhance the variance reduction in MLMC.\nThe proposed optimal fidelity MLMC leads to more than two orders of magnitude\nspeedup when compared to standard Monte Carlo methods. We identify large\nuncertainties in the location and magnitude of the peak pressure pulse and\npresent its statistical correlations and joint probability density functions\nwith the geometrical characteristics of the cloud. Characteristic properties of\nspatial cloud structure are identified as potential causes of significant\nuncertainties in exerted collapse pressures.\n", "versions": [{"version": "v1", "created": "Thu, 11 May 2017 20:54:51 GMT"}], "update_date": "2017-11-09", "authors_parsed": [["\u0160ukys", "Jonas", ""], ["Rasthofer", "Ursula", ""], ["Wermelinger", "Fabian", ""], ["Hadjidoukas", "Panagiotis", ""], ["Koumoutsakos", "Petros", ""]]}, {"id": "1705.04480", "submitter": "Robert Riemann", "authors": "Robert Riemann (DICE), St\\'ephane Grumbach (DICE)", "title": "Distributed Protocols at the Rescue for Trustworthy Online Voting", "comments": null, "journal-ref": null, "doi": "10.5220/0006228504990505", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While online services emerge in all areas of life, the voting procedure in\nmany democracies remains paper-based as the security of current online voting\ntechnology is highly disputed. We address the issue of trustworthy online\nvoting protocols and recall therefore their security concepts with its trust\nassumptions. Inspired by the Bitcoin protocol, the prospects of distributed\nonline voting protocols are analysed. No trusted authority is assumed to ensure\nballot secrecy. Further, the integrity of the voting is enforced by all voters\nthemselves and without a weakest link, the protocol becomes more robust. We\nintroduce a taxonomy of notions of distribution in online voting protocols that\nwe apply on selected online voting protocols. Accordingly, blockchain-based\nprotocols seem to be promising for online voting due to their similarity with\npaper-based protocols.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 09:21:36 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Riemann", "Robert", "", "DICE"], ["Grumbach", "St\u00e9phane", "", "DICE"]]}, {"id": "1705.04513", "submitter": "Mikhail Hushchyn", "authors": "Mikhail Hushchyn, Andrey Ustyuzhanin, Philippe Charpentier and\n  Christophe Haen", "title": "GRID Storage Optimization in Transparent and User-Friendly Way for LHCb\n  Datasets", "comments": null, "journal-ref": null, "doi": "10.1088/1742-6596/898/6/062023", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The LHCb collaboration is one of the four major experiments at the Large\nHadron Collider at CERN. Many petabytes of data are produced by the detectors\nand Monte-Carlo simulations. The LHCb Grid interware LHCbDIRAC is used to make\ndata available to all collaboration members around the world. The data is\nreplicated to the Grid sites in different locations. However the Grid disk\nstorage is limited and does not allow keeping replicas of each file at all\nsites. Thus it is essential to optimize number of replicas to achieve a better\nGrid performance.\n  In this study, we present a new approach of data replication and distribution\nstrategy based on data popularity prediction. The popularity is performed based\non the data access history and metadata, and uses machine learning techniques\nand time series analysis methods.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 11:11:45 GMT"}], "update_date": "2017-12-06", "authors_parsed": [["Hushchyn", "Mikhail", ""], ["Ustyuzhanin", "Andrey", ""], ["Charpentier", "Philippe", ""], ["Haen", "Christophe", ""]]}, {"id": "1705.04590", "submitter": "Aydin Buluc", "authors": "Aydin Buluc, Scott Beamer, Kamesh Madduri, Krste Asanovic, David\n  Patterson", "title": "Distributed-Memory Breadth-First Search on Massive Graphs", "comments": "arXiv admin note: text overlap with arXiv:1104.4518", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This chapter studies the problem of traversing large graphs using the\nbreadth-first search order on distributed-memory supercomputers. We consider\nboth the traditional level-synchronous top-down algorithm as well as the\nrecently discovered direction optimizing algorithm. We analyze the performance\nand scalability trade-offs in using different local data structures such as CSR\nand DCSC, enabling in-node multithreading, and graph decompositions such as 1D\nand 2D decomposition.\n", "versions": [{"version": "v1", "created": "Wed, 10 May 2017 21:49:01 GMT"}], "update_date": "2017-05-15", "authors_parsed": [["Buluc", "Aydin", ""], ["Beamer", "Scott", ""], ["Madduri", "Kamesh", ""], ["Asanovic", "Krste", ""], ["Patterson", "David", ""]]}, {"id": "1705.04769", "submitter": "Zane Witherspoon", "authors": "Zane Witherspoon", "title": "Advancing Consumer Adoption of Blockchain Applications", "comments": "12 pages, blockchain theory, business theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blockchain technology as a whole is experiencing a dramatic rise in adoption,\nin no small part due to the developer-friendly Ethereum network. While the\nnumber of smart-contract powered distributed applications (Dapps) continues to\nrise, they face many of the same challenges all new technologies face as they\nare introduced to a market. By modeling the consumer adoption of blockchain\ntechnology and analyzing scholarly literature on supply-side factors affecting\nthe diffusion of technology, we seek to prove the growth of a Dapp can be\naccelerated using abstraction, whole product planning, and complementaries.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 23:23:54 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Witherspoon", "Zane", ""]]}, {"id": "1705.04789", "submitter": "Hsiang-Huang Wu", "authors": "Hsiang-Huang Wu, Chien-Min Wang, Hsuan-Chi Kuo, Wei-Chun Chung and\n  Jan-Ming Ho", "title": "Scalable and Efficient Construction of Suffix Array with MapReduce and\n  In-Memory Data Store System", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Suffix Array (SA) is a cardinal data structure in many pattern matching\napplications, including data compression, plagiarism detection and sequence\nalignment. However, as the volumes of data increase abruptly, the construction\nof SA is not amenable to the current large-scale data processing frameworks\nanymore due to its intrinsic proliferation of suffixes during the construction.\nThat is, ameliorating the performance by just adding the resources to the\nframeworks becomes less cost- effective, even having the severe diminishing\nreturns. At issue now is whether we can permit SA construction to be more\nscalable and efficient for the everlasting accretion of data by creating a\nradical shift in perspective. Regarding TeraSort [1] as our baseline, we first\ndemonstrate the fragile scalability of TeraSort and investigate what causes it\nthrough the experiments on the sequence alignment of a grouper (i.e., the SA\nconstruc- tion used in bioinformatics). As such, we propose a scheme that\namalgamates the distributed key-value store system into MapReduce to leverage\nthe in-memory queries about suffixes. Rather than handling the communication of\nsuffixes, MapReduce is in charge of the communication of their indexes, which\nmeans better capacity for more data. It significantly abates the required disk\nspace for constructing SA and better utilizes the memory, which in turn\nimproves the scalability radically. We also examine the efficiency of our\nscheme in terms of memory and show it outperforms TeraSort. At last, our scheme\ncan complete the pair- end sequencing and alignment with two input files\nwithout any degradation on scalability, and can accommodate the suffixes of\nnearly 6.7 TB in a small cluster composed of 16 nodes and Gigabit Ethernet\nwithout any compression.\n", "versions": [{"version": "v1", "created": "Sat, 13 May 2017 04:47:44 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Wu", "Hsiang-Huang", ""], ["Wang", "Chien-Min", ""], ["Kuo", "Hsuan-Chi", ""], ["Chung", "Wei-Chun", ""], ["Ho", "Jan-Ming", ""]]}, {"id": "1705.04835", "submitter": "Damien Imbs", "authors": "Damien Imbs, Achour Most\\'efaoui, Matthieu Perrin, Michel Raynal", "title": "Which Broadcast Abstraction Captures $k$-Set Agreement?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that consensus (one-set agreement) and total order broadcast\nare equivalent in asynchronous systems prone to process crash failures.\nConsidering wait-free systems, this article addresses and answers the following\nquestion: which is the communication abstraction that \"captures\" $k$-set\nagreement? To this end, it introduces a new broadcast communication\nabstraction, called $k$-BO-Broadcast, which restricts the disagreement on the\nlocal deliveries of the messages that have been broadcast ($1$-BO-Broadcast\nboils down to total order broadcast). Hence, in this context, $k=1$ is not a\nspecial number, but only the first integer in an increasing integer sequence.\n  This establishes a new \"correspondence\" between distributed agreement\nproblems and communication abstractions, which enriches our understanding of\nthe relations linking fundamental issues of fault-tolerant distributed\ncomputing.\n", "versions": [{"version": "v1", "created": "Sat, 13 May 2017 14:37:17 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Imbs", "Damien", ""], ["Most\u00e9faoui", "Achour", ""], ["Perrin", "Matthieu", ""], ["Raynal", "Michel", ""]]}, {"id": "1705.04874", "submitter": "Saptarshi Das", "authors": "Saptarshi Das, Xi Chen, and Michael P. Hobson", "title": "Fast GPU-Based Seismogram Simulation from Microseismic Events in Marine\n  Environments Using Heterogeneous Velocity Models", "comments": "13 pages, 23 figures", "journal-ref": "IEEE Transactions on Computational Imaging, vol. 3, no. 2, pp.\n  316-329, Jun. 2017", "doi": "10.1109/TCI.2017.2654127", "report-no": null, "categories": "physics.geo-ph cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel approach is presented for fast generation of synthetic seismograms\ndue to microseismic events, using heterogeneous marine velocity models. The\npartial differential equations (PDEs) for the 3D elastic wave equation have\nbeen numerically solved using the Fourier domain pseudo-spectral method which\nis parallelizable on the graphics processing unit (GPU) cards, thus making it\nfaster compared to traditional CPU based computing platforms. Due to\ncomputationally expensive forward simulation of large geological models,\nseveral combinations of individual synthetic seismic traces are used for\nspecified microseismic event locations, in order to simulate the effect of\nrealistic microseismic activity patterns in the subsurface. We here explore the\npatterns generated by few hundreds of microseismic events with different source\nmechanisms using various combinations, both in event amplitudes and origin\ntimes, using the simulated pressure and three component particle velocity\nfields via 1D, 2D and 3D seismic visualizations.\n", "versions": [{"version": "v1", "created": "Sat, 13 May 2017 18:46:09 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Das", "Saptarshi", ""], ["Chen", "Xi", ""], ["Hobson", "Michael P.", ""]]}, {"id": "1705.04898", "submitter": "Moti Medina", "authors": "Guy Even and Reut Levi and Moti Medina", "title": "Faster and Simpler Distributed Algorithms for Testing and Correcting\n  Graph Properties in the CONGEST-Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present distributed testing algorithms of graph properties\nin the CONGEST-model [Censor-Hillel et al. 2016]. We present one-sided error\ntesting algorithms in the general graph model.\n  We first describe a general procedure for converting $\\epsilon$-testers with\na number of rounds $f(D)$, where $D$ denotes the diameter of the graph, to\n$O((\\log n)/\\epsilon)+f((\\log n)/\\epsilon)$ rounds, where $n$ is the number of\nprocessors of the network. We then apply this procedure to obtain an optimal\ntester, in terms of $n$, for testing bipartiteness, whose round complexity is\n$O(\\epsilon^{-1}\\log n)$, which improves over the $poly(\\epsilon^{-1} \\log\nn)$-round algorithm by Censor-Hillel et al. (DISC 2016). Moreover, for\ncycle-freeness, we obtain a \\emph{corrector} of the graph that locally corrects\nthe graph so that the corrected graph is acyclic. Note that, unlike a tester, a\ncorrector needs to mend the graph in many places in the case that the graph is\nfar from having the property.\n  In the second part of the paper we design algorithms for testing whether the\nnetwork is $H$-free for any connected $H$ of size up to four with round\ncomplexity of $O(\\epsilon^{-1})$. This improves over the\n$O(\\epsilon^{-2})$-round algorithms for testing triangle freeness by\nCensor-Hillel et al. (DISC 2016) and for testing excluded graphs of size $4$ by\nFraigniaud et al. (DISC 2016).\n  In the last part we generalize the global tester by Iwama and Yoshida (ITCS\n2014) of testing $k$-path freeness to testing the exclusion of any tree of\norder $k$. We then show how to simulate this algorithm in the CONGEST-model in\n$O(k^{k^2+1}\\cdot\\epsilon^{-k})$ rounds.\n", "versions": [{"version": "v1", "created": "Sat, 13 May 2017 23:17:28 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Even", "Guy", ""], ["Levi", "Reut", ""], ["Medina", "Moti", ""]]}, {"id": "1705.05249", "submitter": "Cedric Nugteren", "authors": "Cedric Nugteren", "title": "CLBlast: A Tuned OpenCL BLAS Library", "comments": "Conference paper in: IWOCL '18, the International Workshop on OpenCL", "journal-ref": null, "doi": "10.1145/3204919.3204924", "report-no": null, "categories": "cs.MS cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work introduces CLBlast, an open-source BLAS library providing optimized\nOpenCL routines to accelerate dense linear algebra for a wide variety of\ndevices. It is targeted at machine learning and HPC applications and thus\nprovides a fast matrix-multiplication routine (GEMM) to accelerate the core of\nmany applications (e.g. deep learning, iterative solvers, astrophysics,\ncomputational fluid dynamics, quantum chemistry). CLBlast has five main\nadvantages over other OpenCL BLAS libraries: 1) it is optimized for and tested\non a large variety of OpenCL devices including less commonly used devices such\nas embedded and low-power GPUs, 2) it can be explicitly tuned for specific\nproblem-sizes on specific hardware platforms, 3) it can perform operations in\nhalf-precision floating-point FP16 saving bandwidth, time and energy, 4) it has\nan optional CUDA back-end, 5) and it can combine multiple operations in a\nsingle batched routine, accelerating smaller problems significantly. This paper\ndescribes the library and demonstrates the advantages of CLBlast experimentally\nfor different use-cases on a wide variety of OpenCL hardware.\n", "versions": [{"version": "v1", "created": "Fri, 12 May 2017 17:16:59 GMT"}, {"version": "v2", "created": "Fri, 27 Apr 2018 09:10:16 GMT"}], "update_date": "2018-04-30", "authors_parsed": [["Nugteren", "Cedric", ""]]}, {"id": "1705.05491", "submitter": "Lili Su", "authors": "Yudong Chen, Lili Su, Jiaming Xu", "title": "Distributed Statistical Machine Learning in Adversarial Settings:\n  Byzantine Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of distributed statistical machine learning in\nadversarial settings, where some unknown and time-varying subset of working\nmachines may be compromised and behave arbitrarily to prevent an accurate model\nfrom being learned. This setting captures the potential adversarial attacks\nfaced by Federated Learning -- a modern machine learning paradigm that is\nproposed by Google researchers and has been intensively studied for ensuring\nuser privacy. Formally, we focus on a distributed system consisting of a\nparameter server and $m$ working machines. Each working machine keeps $N/m$\ndata samples, where $N$ is the total number of samples. The goal is to\ncollectively learn the underlying true model parameter of dimension $d$.\n  In classical batch gradient descent methods, the gradients reported to the\nserver by the working machines are aggregated via simple averaging, which is\nvulnerable to a single Byzantine failure. In this paper, we propose a Byzantine\ngradient descent method based on the geometric median of means of the\ngradients. We show that our method can tolerate $q \\le (m-1)/2$ Byzantine\nfailures, and the parameter estimate converges in $O(\\log N)$ rounds with an\nestimation error of $\\sqrt{d(2q+1)/N}$, hence approaching the optimal error\nrate $\\sqrt{d/N}$ in the centralized and failure-free setting. The total\ncomputational complexity of our algorithm is of $O((Nd/m) \\log N)$ at each\nworking machine and $O(md + kd \\log^3 N)$ at the central server, and the total\ncommunication cost is of $O(m d \\log N)$. We further provide an application of\nour general results to the linear regression problem.\n  A key challenge arises in the above problem is that Byzantine failures create\narbitrary and unspecified dependency among the iterations and the aggregated\ngradients. We prove that the aggregated gradient converges uniformly to the\ntrue gradient function.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 00:20:49 GMT"}, {"version": "v2", "created": "Mon, 23 Oct 2017 01:16:25 GMT"}], "update_date": "2017-10-24", "authors_parsed": [["Chen", "Yudong", ""], ["Su", "Lili", ""], ["Xu", "Jiaming", ""]]}, {"id": "1705.05541", "submitter": "Kai Wu", "authors": "Shuo Yang, Kai Wu, Yifan Qiao, Dong Li, Jidong Zhai", "title": "Algorithm-Directed Crash Consistence in Non-Volatile Memory for HPC", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Fault tolerance is one of the major design goals for HPC. The emergence of\nnon-volatile memories (NVM) provides a solution to build fault tolerant HPC.\nData in NVM-based main memory are not lost when the system crashes because of\nthe non-volatility nature of NVM. However, because of volatile caches, data\nmust be logged and explicitly flushed from caches into NVM to ensure\nconsistence and correctness before crashes, which can cause large runtime\noverhead.\n  In this paper, we introduce an algorithm-based method to establish crash\nconsistence in NVM for HPC applications. We slightly extend application data\nstructures or sparsely flush cache blocks, which introduce ignorable runtime\noverhead. Such extension or cache flushing allows us to use algorithm knowledge\nto \\textit{reason} data consistence or correct inconsistent data when the\napplication crashes. We demonstrate the effectiveness of our method for three\nalgorithms, including an iterative solver, dense matrix multiplication, and\nMonte-Carlo simulation. Based on comprehensive performance evaluation on a\nvariety of test environments, we demonstrate that our approach has very small\nruntime overhead (at most 8.2\\% and less than 3\\% in most cases), much smaller\nthan that of traditional checkpoint, while having the same or less\nrecomputation cost.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 06:01:39 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Yang", "Shuo", ""], ["Wu", "Kai", ""], ["Qiao", "Yifan", ""], ["Li", "Dong", ""], ["Zhai", "Jidong", ""]]}, {"id": "1705.05583", "submitter": "Johannes Lengler", "authors": "Mohsen Ghaffari and Johannes Lengler", "title": "Tight Analysis for the 3-Majority Consensus Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a tight analysis for the well-studied randomized 3-majority\ndynamics of stabilizing consensus, hence answering the main open question of\nBecchetti et al. [SODA'16].\n  Consider a distributed system of n nodes, each initially holding an opinion\nin {1, 2, ..., k}. The system should converge to a setting where all\n(non-corrupted) nodes hold the same opinion. This consensus opinion should be\n\\emph{valid}, meaning that it should be among the initially supported opinions,\nand the (fast) convergence should happen even in the presence of a malicious\nadversary who can corrupt a bounded number of nodes per round and in particular\nmodify their opinions. A well-studied distributed algorithm for this problem is\nthe 3-majority dynamics, which works as follows: per round, each node gathers\nthree opinions --- say by taking its own and two of other nodes sampled at\nrandom --- and then it sets its opinion equal to the majority of this set; ties\nare broken arbitrarily, e.g., towards the node's own opinion.\n  Becchetti et al. [SODA'16] showed that the 3-majority dynamics converges to\nconsensus in O((k^2\\sqrt{\\log n} + k\\log n)(k+\\log n)) rounds, even in the\npresence of a limited adversary. We prove that, even with a stronger adversary,\nthe convergence happens within O(k\\log n) rounds. This bound is known to be\noptimal.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 08:28:25 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Ghaffari", "Mohsen", ""], ["Lengler", "Johannes", ""]]}, {"id": "1705.05595", "submitter": "Peng Sun", "authors": "Peng Sun, Yonggang Wen, Ta Nguyen Binh Duong, Xiaokui Xiao", "title": "GraphH: High Performance Big Graph Analytics in Small Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is common for real-world applications to analyze big graphs using\ndistributed graph processing systems. Popular in-memory systems require an\nenormous amount of resources to handle big graphs. While several out-of-core\napproaches have been proposed for processing big graphs on disk, the high disk\nI/O overhead could significantly reduce performance. In this paper, we propose\nGraphH to enable high-performance big graph analytics in small clusters.\nSpecifically, we design a two-stage graph partition scheme to evenly divide the\ninput graph into partitions, and propose a GAB (Gather-Apply-Broadcast)\ncomputation model to make each worker process a partition in memory at a time.\nWe use an edge cache mechanism to reduce the disk I/O overhead, and design a\nhybrid strategy to improve the communication performance. GraphH can\nefficiently process big graphs in small clusters or even a single commodity\nserver. Extensive evaluations have shown that GraphH could be up to 7.8x faster\ncompared to popular in-memory systems, such as Pregel+ and PowerGraph when\nprocessing generic graphs, and more than 100x faster than recently proposed\nout-of-core systems, such as GraphD and Chaos when processing big graphs.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 08:50:36 GMT"}, {"version": "v2", "created": "Wed, 17 May 2017 12:02:54 GMT"}, {"version": "v3", "created": "Thu, 25 May 2017 03:09:13 GMT"}, {"version": "v4", "created": "Fri, 28 Jul 2017 13:27:57 GMT"}, {"version": "v5", "created": "Mon, 7 Aug 2017 08:27:59 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Sun", "Peng", ""], ["Wen", "Yonggang", ""], ["Duong", "Ta Nguyen Binh", ""], ["Xiao", "Xiaokui", ""]]}, {"id": "1705.05646", "submitter": "Seri Khoury", "authors": "Keren Censor-Hillel, Seri Khoury, and Ami Paz", "title": "Quadratic and Near-Quadratic Lower Bounds for the CONGEST Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the first super-linear lower bounds for natural graph problems in\nthe CONGEST model, answering a long-standing open question.\n  Specifically, we show that any exact computation of a minimum vertex cover or\na maximum independent set requires $\\Omega(n^2/\\log^2{n})$ rounds in the worst\ncase in the CONGEST model, as well as any algorithm for $\\chi$-coloring a\ngraph, where $\\chi$ is the chromatic number of the graph. We further show that\nsuch strong lower bounds are not limited to NP-hard problems, by showing two\nsimple graph problems in P which require a quadratic and near-quadratic number\nof rounds.\n  Finally, we address the problem of computing an exact solution to weighted\nall-pairs-shortest-paths (APSP), which arguably may be considered as a\ncandidate for having a super-linear lower bound. We show a simple $\\Omega(n)$\nlower bound for this problem, which implies a separation between the weighted\nand unweighted cases, since the latter is known to have a complexity of\n$\\Theta(n/\\log{n})$. We also formally prove that the standard Alice-Bob\nframework is incapable of providing a super-linear lower bound for exact\nweighted APSP, whose complexity remains an intriguing open question.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 11:11:37 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Khoury", "Seri", ""], ["Paz", "Ami", ""]]}, {"id": "1705.05684", "submitter": "Rafael Pereira Pires", "authors": "Rafael Pires and Daniel Gavril and Pascal Felber and Emanuel Onica and\n  Marcelo Pasin", "title": "A lightweight MapReduce framework for secure processing with SGX", "comments": "8 pages WACC@CCGRID International Workshop on Assured Cloud Computing\n  and QoS aware Big Data", "journal-ref": "2017 17th IEEE/ACM International Symposium on Cluster, Cloud and\n  Grid Computing", "doi": "10.1109/CCGRID.2017.129", "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MapReduce is a programming model used extensively for parallel data\nprocessing in distributed environments. A wide range of algorithms were\nimplemented using MapReduce, from simple tasks like sorting and searching up to\ncomplex clustering and machine learning operations. Many of these\nimplementations are part of services externalized to cloud infrastructures.\nOver the past years, however, many concerns have been raised regarding the\nsecurity guarantees offered in such environments. Some solutions relying on\ncryptography were proposed for countering threats but these typically imply a\nhigh computational overhead. Intel, the largest manufacturer of commodity CPUs,\nrecently introduced SGX (software guard extensions), a set of hardware\ninstructions that support execution of code in an isolated secure environment.\nIn this paper, we explore the use of Intel SGX for providing privacy guarantees\nfor MapReduce operations, and based on our evaluation we conclude that it\nrepresents a viable alternative to a cryptographic mechanism. We present\nresults based on the widely used k-means clustering algorithm, but our\nimplementation can be generalized to other applications that can be expressed\nusing MapReduce model.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 12:46:38 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Pires", "Rafael", ""], ["Gavril", "Daniel", ""], ["Felber", "Pascal", ""], ["Onica", "Emanuel", ""], ["Pasin", "Marcelo", ""]]}, {"id": "1705.05691", "submitter": "Pengfei Zhang", "authors": "Ben Hu, Huaimin Wang, Pengfei Zhang, Bo Ding, and Huimin Che", "title": "Cloudroid: A Cloud Framework for Transparent and QoS-aware Robotic\n  Computation Outsourcing", "comments": "Accepted by 10th IEEE International Conference on Cloud Computing in\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many robotic tasks require heavy computation, which can easily exceed the\nrobot's onboard computer capability. A promising solution to address this\nchallenge is outsourcing the computation to the cloud. However, exploiting the\npotential of cloud resources in robotic software is difficult, because it\ninvolves complex code modification and extensive (re)configuration procedures.\nMoreover, quality of service (QoS) such as timeliness, which is critical to\nrobot's behavior, have to be considered. In this paper, we propose a\ntransparent and QoS-aware software framework called Cloudroid for cloud robotic\napplications. This framework supports direct deployment of existing robotic\nsoftware packages to the cloud, transparently transforming them into\nInternet-accessible cloud services. And with the automatically generated\nservice stubs, robotic applications can outsource their computation to the\ncloud without any code modification. Furthermore, the robot and the cloud can\ncooperate to maintain the specific QoS property such as request response time,\neven in a highly dynamic and resource-competitive environment. We evaluated\nCloudroid based on a group of typical robotic scenarios and a set of software\npackages widely adopted in real-world robot practices. Results show that\nrobot's capability can be enhanced significantly without code modification and\nspecific QoS objectives can be guaranteed. In certain tasks, the \"cloud +\nrobot\" setup shows improved performance in orders of magnitude compared with\nthe robot native setup.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 12:57:39 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Hu", "Ben", ""], ["Wang", "Huaimin", ""], ["Zhang", "Pengfei", ""], ["Ding", "Bo", ""], ["Che", "Huimin", ""]]}, {"id": "1705.05704", "submitter": "Amos Korman", "authors": "Amos Korman (IRIF, GANG), Yoav Rodeh", "title": "Parallel Search with no Coordination", "comments": null, "journal-ref": "24th International Colloquium on Structural Information and\n  Communication Complexity (SIROCCO), Jun 2017, Porquerolles, France", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a parallel version of a classical Bayesian search problem. $k$\nagents are looking for a treasure that is placed in one of the boxes indexed by\n$\\mathbb{N}^+$ according to a known distribution $p$. The aim is to minimize\nthe expected time until the first agent finds it. Searchers run in parallel\nwhere at each time step each searcher can \"peek\" into a box. A basic family of\nalgorithms which are inherently robust is \\emph{non-coordinating} algorithms.\nSuch algorithms act independently at each searcher, differing only by their\nprobabilistic choices. We are interested in the price incurred by employing\nsuch algorithms when compared with the case of full coordination. We first show\nthat there exists a non-coordination algorithm, that knowing only the relative\nlikelihood of boxes according to $p$, has expected running time of at most\n$10+4(1+\\frac{1}{k})^2 T$, where $T$ is the expected running time of the best\nfully coordinated algorithm. This result is obtained by applying a refined\nversion of the main algorithm suggested by Fraigniaud, Korman and Rodeh in\nSTOC'16, which was designed for the context of linear parallel search.We then\ndescribe an optimal non-coordinating algorithm for the case where the\ndistribution $p$ is known. The running time of this algorithm is difficult to\nanalyse in general, but we calculate it for several examples. In the case where\n$p$ is uniform over a finite set of boxes, then the algorithm just checks boxes\nuniformly at random among all non-checked boxes and is essentially $2$ times\nworse than the coordinating algorithm.We also show simple algorithms for Pareto\ndistributions over $M$ boxes. That is, in the case where $p(x) \\sim 1/x^b$ for\n$0< b < 1$, we suggest the following algorithm: at step $t$ choose uniformly\nfrom the boxes unchecked in ${1, . . . ,min(M, \\lfloor t/\\sigma\\rfloor)}$,\nwhere $\\sigma = b/(b + k - 1)$. It turns out this algorithm is asymptotically\noptimal, and runs about $2+b$ times worse than the case of full coordination.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 13:48:49 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Korman", "Amos", "", "IRIF, GANG"], ["Rodeh", "Yoav", ""]]}, {"id": "1705.05824", "submitter": "Ruben Mayer", "authors": "Ruben Mayer, Muhammad Adnan Tariq, Kurt Rothermel", "title": "Minimizing Communication Overhead in Window-Based Parallel Complex Event\n  Processing", "comments": "In Proceedings of ACM International Conference on Distributed and\n  Event-Based Systems, Barcelona, Spain, June 19 - 23, 2017 (DEBS '17), 12\n  pages. DOI: http://dx.doi.org/10.1145/3093742.3093914", "journal-ref": null, "doi": "10.1145/3093742.3093914", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Complex Event Processing has emerged as a well-established\nparadigm to detect situations of interest from basic sensor streams, building\nan operator graph between sensors and applications. In order to detect event\npatterns that correspond to situations of interest, each operator correlates\nevents on its incoming streams according to a sliding window mechanism. To\nincrease the throughput of an operator, different windows can be assigned to\ndifferent operator instances---i.e., identical operator copies---which process\nthem in parallel. This implies that events that are part of multiple\noverlapping windows are replicated to different operator instances. The\ncommunication overhead of replicating the events can be reduced by assigning\noverlapping windows to the same operator instance. However, this imposes a\nhigher processing load on the single operator instance, possibly overloading\nit. In this paper, we address the trade-off between processing load and\ncommunication overhead when assigning overlapping windows to a single operator\ninstance. Controlling the trade-off is challenging and cannot be solved with\ntraditional reactive methods. To this end, we propose a model-based batch\nscheduling controller building on prediction. Evaluations show that our\napproach is able to significantly save bandwidth, while keeping a user-defined\nlatency bound in the operator instances.\n", "versions": [{"version": "v1", "created": "Tue, 16 May 2017 17:52:17 GMT"}], "update_date": "2017-05-17", "authors_parsed": [["Mayer", "Ruben", ""], ["Tariq", "Muhammad Adnan", ""], ["Rothermel", "Kurt", ""]]}, {"id": "1705.06024", "submitter": "Stefan Schmid", "authors": "Chen Avin, Kaushik Mondal, Stefan Schmid", "title": "Demand-Aware Network Designs of Bounded Degree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, networks such as datacenter interconnects are designed to\noptimize worst-case performance under arbitrary traffic patterns. Such network\ndesigns can however be far from optimal when considering the actual workloads\nand traffic patterns which they serve. This insight led to the development of\ndemand-aware datacenter interconnects which can be reconfigured depending on\nthe workload.\n  Motivated by these trends, this paper initiates the algorithmic study of\ndemand-aware networks (DANs) designs, and in particular the design of\nbounded-degree networks. The inputs to the network design problem are a\ndiscrete communication request distribution, D, defined over communicating\npairs from the node set V , and a bound, d, on the maximum degree. In turn, our\nobjective is to design an (undirected) demand-aware network N = (V,E) of\nbounded-degree d, which provides short routing paths between frequently\ncommunicating nodes distributed across N. In particular, the designed network\nshould minimize the expected path length on N (with respect to D), which is a\nbasic measure of the efficiency of the network.\n  We show that this fundamental network design problem exhibits interesting\nconnections to several classic combinatorial problems and to information\ntheory. We derive a general lower bound based on the entropy of the\ncommunication pattern D, and present asymptotically optimal network-aware\ndesign algorithms for important distribution families, such as sparse\ndistributions and distributions of locally bounded doubling dimensions.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 06:44:58 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Avin", "Chen", ""], ["Mondal", "Kaushik", ""], ["Schmid", "Stefan", ""]]}, {"id": "1705.06173", "submitter": "Joel Rybicki", "authors": "Christoph Lenzen and Joel Rybicki", "title": "Self-stabilising Byzantine Clock Synchronisation is Almost as Easy as\n  Consensus", "comments": "54 pages. To appear in JACM, preliminary version of this work has\n  appeared in DISC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give fault-tolerant algorithms for establishing synchrony in distributed\nsystems in which each of the $n$ nodes has its own clock. Our algorithms\noperate in a very strong fault model: we require self-stabilisation, i.e., the\ninitial state of the system may be arbitrary, and there can be up to $f<n/3$\nongoing Byzantine faults, i.e., nodes that deviate from the protocol in an\narbitrary manner. Furthermore, we assume that the local clocks of the nodes may\nprogress at different speeds (clock drift) and communication has bounded delay.\nIn this model, we study the pulse synchronisation problem, where the task is to\nguarantee that eventually all correct nodes generate well-separated local pulse\nevents (i.e., unlabelled logical clock ticks) in a synchronised manner.\n  Compared to prior work, we achieve exponential improvements in stabilisation\ntime and the number of communicated bits, and give the first sublinear-time\nalgorithm for the problem:\n  - In the deterministic setting, the state-of-the-art solutions stabilise in\ntime $\\Theta(f)$ and have each node broadcast $\\Theta(f \\log f)$ bits per time\nunit. We exponentially reduce the number of bits broadcasted per time unit to\n$\\Theta(\\log f)$ while retaining the same stabilisation time.\n  - In the randomised setting, the state-of-the-art solutions stabilise in time\n$\\Theta(f)$ and have each node broadcast $O(1)$ bits per time unit. We\nexponentially reduce the stabilisation time to $\\log^{O(1)} f$ while each node\nbroadcasts $\\log^{O(1)} f$ bits per time unit.\n  These results are obtained by means of a recursive approach reducing the\nabove task of self-stabilising pulse synchronisation in the bounded-delay model\nto non-self-stabilising binary consensus in the synchronous model. In general,\nour approach introduces at most logarithmic overheads in terms of stabilisation\ntime and broadcasted bits over the underlying consensus routine.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 14:16:20 GMT"}, {"version": "v2", "created": "Fri, 14 Jul 2017 13:37:07 GMT"}, {"version": "v3", "created": "Sun, 28 Jan 2018 11:54:07 GMT"}, {"version": "v4", "created": "Tue, 11 Jun 2019 10:28:16 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Lenzen", "Christoph", ""], ["Rybicki", "Joel", ""]]}, {"id": "1705.06202", "submitter": "Duncan Brown", "authors": "Derek Weitzel, Brian Bockelman, Duncan A. Brown, Peter Couvares, Frank\n  W\\\"urthwein, Edgar Fajardo Hernandez", "title": "Data Access for LIGO on the OSG", "comments": "6 pages, 3 figures, submitted to PEARC17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  During 2015 and 2016, the Laser Interferometer Gravitational-Wave Observatory\n(LIGO) conducted a three-month observing campaign. These observations delivered\nthe first direct detection of gravitational waves from binary black hole\nmergers. To search for these signals, the LIGO Scientific Collaboration uses\nthe PyCBC search pipeline. To deliver science results in a timely manner, LIGO\ncollaborated with the Open Science Grid (OSG) to distribute the required\ncomputation across a series of dedicated, opportunistic, and allocated\nresources. To deliver the petabytes necessary for such a large-scale\ncomputation, our team deployed a distributed data access infrastructure based\non the XRootD server suite and the CernVM File System (CVMFS). This data access\nstrategy grew from simply accessing remote storage to a POSIX-based interface\nunderpinned by distributed, secure caches across the OSG.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 15:14:00 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Weitzel", "Derek", ""], ["Bockelman", "Brian", ""], ["Brown", "Duncan A.", ""], ["Couvares", "Peter", ""], ["W\u00fcrthwein", "Frank", ""], ["Hernandez", "Edgar Fajardo", ""]]}, {"id": "1705.06215", "submitter": "Gautam Bhanage", "authors": "Gautam Bhanage", "title": "Mixing MACs: An Introduction to Hybrid Radio Wireless Virtualization", "comments": "6 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": "GDB2017-005", "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This study presents the design of the hybrid wireless virtualization HWV\ncontroller based network architecture. Using a HWV controller, an unified\napproach can be taken for provisioning and management of virtualized\nheterogeneous radios, irrespective of their MAC and PHY layer mechanisms. It is\nshown that the airtime occupancy by transmissions from different slices or\ngroups can be used as a single metric for tying these virtualized platforms.\nThe HWV controller can account and dynamically reprovision slice quotas, which\ncan be used for maximizing the revenue of the network operator or aggregate\nsystem throughput performance. Results from simulations show that an HWV\ncontroller based infrastructure is able to improve the revenue generated from a\nsingle virtualized basestation and an AP by up to 40 percent under tested\nconditions.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 15:35:52 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Bhanage", "Gautam", ""]]}, {"id": "1705.06266", "submitter": "Tristan Konolige", "authors": "Tristan Konolige, Jed Brown", "title": "A Parallel Solver for Graph Laplacians", "comments": "PASC '18, Code: https://github.com/ligmg/ligmg", "journal-ref": null, "doi": "10.1145/3218176.3218227", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Problems from graph drawing, spectral clustering, network flow and graph\npartitioning can all be expressed in terms of graph Laplacian matrices. There\nare a variety of practical approaches to solving these problems in serial.\nHowever, as problem sizes increase and single core speeds stagnate, parallelism\nis essential to solve such problems quickly. We present an unsmoothed\naggregation multigrid method for solving graph Laplacians in a distributed\nmemory setting. We introduce new parallel aggregation and low degree\nelimination algorithms targeted specifically at irregular degree graphs. These\nalgorithms are expressed in terms of sparse matrix-vector products using\ngeneralized sum and product operations. This formulation is amenable to linear\nalgebra using arbitrary distributions and allows us to operate on a 2D sparse\nmatrix distribution, which is necessary for parallel scalability. Our solver\noutperforms the natural parallel extension of the current state of the art in\nan algorithmic comparison. We demonstrate scalability to 576 processes and\ngraphs with up to 1.7 billion edges.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 17:24:05 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2018 15:06:52 GMT"}], "update_date": "2018-07-12", "authors_parsed": [["Konolige", "Tristan", ""], ["Brown", "Jed", ""]]}, {"id": "1705.06271", "submitter": "Thomas Dickerson", "authors": "Thomas D. Dickerson", "title": "Fast Snapshottable Concurrent Braun Heaps", "comments": "pre-print, submitted to DISC'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a new concurrent heap algorithm, based on a stateless\nshape property, which efficiently maintains balance during insert and removeMin\noperations implemented with hand-over-hand locking. It also provides a O(1)\nlinearizable snapshot operation based on lazy copy-on-write semantics. Such\nsnapshots can be used to provide consistent views of the heap during iteration,\nas well as to make speculative updates (which can later be dropped).\n  The simplicity of the algorithm allows it to be easily proven correct, and\nthe choice of shape property provides priority queue performance which is\ncompetitive with highly optimized skiplist implementations (and has stronger\nbounds on worst-case time complexity).\n  A Scala reference implementation is provided.\n", "versions": [{"version": "v1", "created": "Wed, 17 May 2017 17:43:26 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Dickerson", "Thomas D.", ""]]}, {"id": "1705.06390", "submitter": "Jaroslaw Zola", "authors": "Subhadeep Karan and Jaroslaw Zola", "title": "Scalable Exact Parent Sets Identification in Bayesian Networks Learning\n  with Apache Spark", "comments": null, "journal-ref": null, "doi": "10.1109/HiPC.2017.00014", "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Machine Learning, the parent set identification problem is to find a set\nof random variables that best explain selected variable given the data and some\npredefined scoring function. This problem is a critical component to structure\nlearning of Bayesian networks and Markov blankets discovery, and thus has many\npractical applications, ranging from fraud detection to clinical decision\nsupport. In this paper, we introduce a new distributed memory approach to the\nexact parent sets assignment problem. To achieve scalability, we derive\ntheoretical bounds to constraint the search space when MDL scoring function is\nused, and we reorganize the underlying dynamic programming such that the\ncomputational density is increased and fine-grain synchronization is\neliminated. We then design efficient realization of our approach in the Apache\nSpark platform. Through experimental results, we demonstrate that the method\nmaintains strong scalability on a 500-core standalone Spark cluster, and it can\nbe used to efficiently process data sets with 70 variables, far beyond the\nreach of the currently available solutions.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 01:50:04 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 20:24:01 GMT"}], "update_date": "2019-01-09", "authors_parsed": [["Karan", "Subhadeep", ""], ["Zola", "Jaroslaw", ""]]}, {"id": "1705.06391", "submitter": "Yangyang Xu", "authors": "Yangyang Xu", "title": "Asynchronous parallel primal-dual block coordinate update methods for\n  affinely constrained convex programs", "comments": null, "journal-ref": "Computational Optimization and Applications, 72(1), pp. 87-113,\n  2019", "doi": "10.1007/s10589-018-0037-8", "report-no": null, "categories": "math.OC cs.DC cs.NA math.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent several years have witnessed the surge of asynchronous (async-)\nparallel computing methods due to the extremely big data involved in many\nmodern applications and also the advancement of multi-core machines and\ncomputer clusters. In optimization, most works about async-parallel methods are\non unconstrained problems or those with block separable constraints.\n  In this paper, we propose an async-parallel method based on block coordinate\nupdate (BCU) for solving convex problems with nonseparable linear constraint.\nRunning on a single node, the method becomes a novel randomized primal-dual BCU\nwith adaptive stepsize for multi-block affinely constrained problems. For these\nproblems, Gauss-Seidel cyclic primal-dual BCU needs strong convexity to have\nconvergence. On the contrary, merely assuming convexity, we show that the\nobjective value sequence generated by the proposed algorithm converges in\nprobability to the optimal value and also the constraint residual to zero. In\naddition, we establish an ergodic $O(1/k)$ convergence result, where $k$ is the\nnumber of iterations. Numerical experiments are performed to demonstrate the\nefficiency of the proposed method and significantly better speed-up performance\nthan its sync-parallel counterpart.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 01:53:51 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2019 20:19:02 GMT"}], "update_date": "2019-10-17", "authors_parsed": [["Xu", "Yangyang", ""]]}, {"id": "1705.06453", "submitter": "Andr\\'e Martin", "authors": "Andr\\'e Martin, Andrey Britoy, Christof Fetzer", "title": "Elastic and Secure Energy Forecasting in Cloud Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although cloud computing offers many advantages with regards to adaption of\nresources, we witness either a strong resistance or a very slow adoption to\nthose new offerings. One reason for the resistance is that (i) many\ntechnologies such as stream processing systems still lack of appropriate\nmechanisms for elasticity in order to fully harness the power of the cloud, and\n(ii) do not provide mechanisms for secure processing of privacy sensitive data\nsuch as when analyzing energy consumption data provided through smart plugs in\nthe context of smart grids. In this white paper, we present our vision and\napproach for elastic and secure processing of streaming data. Our approach is\nbased on StreamMine3G, an elastic event stream processing system and Intel's\nSGX technology that provides secure processing using enclaves. We highlight the\nkey aspects of our approach and research challenges when using Intel's SGX\ntechnology.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 08:03:22 GMT"}], "update_date": "2017-05-19", "authors_parsed": [["Martin", "Andr\u00e9", ""], ["Britoy", "Andrey", ""], ["Fetzer", "Christof", ""]]}, {"id": "1705.06521", "submitter": "Yukiko Yamauchi", "authors": "Yusaku Tomita, Yukiko Yamauchi, Shuji Kijima, Masafumi Yamashita", "title": "Plane Formation by Synchronous Mobile Robots without Chirality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a distributed system consisting of autonomous mobile computing\nentities, called robots, moving in a specified space. The robots are anonymous,\noblivious, and have neither any access to the global coordinate system nor any\nexplicit communication medium. Each robot observes the positions of other\nrobots and moves in terms of its local coordinate system. To investigate the\nself-organization power of robot systems, formation problems in the two\ndimensional space (2D-space) have been extensively studied. Yamauchi et al.\n(DISC 2015) introduced robot systems in the three dimensional space (3D-space).\nWhile existing results for 3D-space assume that the robots agree on the\nhandedness of their local coordinate systems, we remove the assumption and\nconsider the robots without chirality. One of the most fundamental agreement\nproblems in 3D-space is the plane formation problem that requires the robots to\nland on a common plane, that is not predefined. It has been shown that the\nsolvability of the plane formation problem by robots with chirality is\ndetermined by the rotation symmetry of their initial local coordinate systems\nbecause the robots cannot break it. We show that when the robots lack\nchirality, the combination of rotation symmetry and reflection symmetry\ndetermines the solvability of the plane formation problem because a set of\nsymmetric local coordinate systems without chirality is obtained by rotations\nand reflections. This richer symmetry results in the increase of unsolvable\ninstances compared with robots with chirality and a flaw of existing plane\nformation algorithm. In this paper, we give a characterization of initial\nconfigurations from which the robots without chirality can form a plane and a\nnew plane formation algorithm for solvable instances.\n", "versions": [{"version": "v1", "created": "Thu, 18 May 2017 11:06:08 GMT"}, {"version": "v2", "created": "Fri, 19 May 2017 06:14:51 GMT"}], "update_date": "2017-05-22", "authors_parsed": [["Tomita", "Yusaku", ""], ["Yamauchi", "Yukiko", ""], ["Kijima", "Shuji", ""], ["Yamashita", "Masafumi", ""]]}, {"id": "1705.06936", "submitter": "Tomasz Grel", "authors": "Robert Adamski, Tomasz Grel, Maciej Klimek and Henryk Michalewski", "title": "Atari games and Intel processors", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-319-75931-9_1", "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The asynchronous nature of the state-of-the-art reinforcement learning\nalgorithms such as the Asynchronous Advantage Actor-Critic algorithm, makes\nthem exceptionally suitable for CPU computations. However, given the fact that\ndeep reinforcement learning often deals with interpreting visual information, a\nlarge part of the train and inference time is spent performing convolutions. In\nthis work we present our results on learning strategies in Atari games using a\nConvolutional Neural Network, the Math Kernel Library and TensorFlow 0.11rc0\nmachine learning framework. We also analyze effects of asynchronous\ncomputations on the convergence of reinforcement learning algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 11:19:45 GMT"}], "update_date": "2018-04-17", "authors_parsed": [["Adamski", "Robert", ""], ["Grel", "Tomasz", ""], ["Klimek", "Maciej", ""], ["Michalewski", "Henryk", ""]]}, {"id": "1705.07069", "submitter": "Kevin Yeo", "authors": "Sarvar Patel, Giuseppe Persiano, Kevin Yeo", "title": "CacheShuffle: An Oblivious Shuffle Algorithm Using Caches", "comments": "29 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Oblivious Shuffling and K-Oblivious Shuffling, a refinement\nthereof. We provide efficient algorithms for both and discuss their application\nto the design of Oblivious RAM. The task of K-Oblivious Shuffling is to\nobliviously shuffle N encrypted blocks that have been randomly allocated on the\nserver in such a way that an adversary learns nothing about the new allocation\nof blocks. The security guarantee should hold also with respect to an adversary\nthat has learned the initial position of K touched blocks out of the N blocks.\nThe classical notion of Oblivious Shuffling is obtained for K = N.\n  We present a family of algorithms for Oblivious Shuffling. Our first\nconstruction, CacheShuffleRoot, is tailored for clients with $O(\\sqrt{N})$\nblocks of memory and uses $(4+\\epsilon)N$ blocks of bandwidth, for every\n$\\epsilon > 0$. CacheShuffleRoot is a 4.5x improvement over previous best known\nresults on practical sizes of N. We also present CacheShuffle that obliviously\nshuffles using O(S) blocks of client memory with $O(N\\log_S N)$ blocks of\nbandwidth.\n  We then turn to K-Oblivious Shuffling and give algorithms that require 2N +\nf(K) blocks of bandwidth, for some function f. That is, any extra bandwidth\nabove the 2N lower bound depends solely on K. We present KCacheShuffleBasic\nthat uses O(K) client storage and exactly 2N blocks of bandwidth. For smaller\nclient storage requirements, we show KCacheShuffle, which uses O(S) client\nstorage and requires $2N+(1+\\epsilon)O(K\\log_S K)$ blocks of bandwidth.\n  Finally, we consider the case in which, in addition to the N blocks, the\nserver stores D dummy blocks whose content is is irrelevant but still their\npositions must be hidden by the shuffling. For this case, we design algorithm\nKCacheShuffleDummy that, for N + D blocks and K touched blocks, uses O(K)\nclient storage and $D+(2+\\epsilon)N$ blocks of bandwidth.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 16:15:08 GMT"}, {"version": "v2", "created": "Tue, 5 Sep 2017 22:45:41 GMT"}, {"version": "v3", "created": "Tue, 17 Oct 2017 20:37:23 GMT"}], "update_date": "2017-10-19", "authors_parsed": [["Patel", "Sarvar", ""], ["Persiano", "Giuseppe", ""], ["Yeo", "Kevin", ""]]}, {"id": "1705.07114", "submitter": "Pooyan Jamshidi", "authors": "Hamid Arabnejad, Claus Pahl, Pooyan Jamshidi, Giovani Estrada", "title": "A Comparison of Reinforcement Learning Techniques for Fuzzy Cloud\n  Auto-Scaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A goal of cloud service management is to design self-adaptable auto-scaler to\nreact to workload fluctuations and changing the resources assigned. The key\nproblem is how and when to add/remove resources in order to meet agreed\nservice-level agreements. Reducing application cost and guaranteeing\nservice-level agreements (SLAs) are two critical factors of dynamic controller\ndesign. In this paper, we compare two dynamic learning strategies based on a\nfuzzy logic system, which learns and modifies fuzzy scaling rules at runtime. A\nself-adaptive fuzzy logic controller is combined with two reinforcement\nlearning (RL) approaches: (i) Fuzzy SARSA learning (FSL) and (ii) Fuzzy\nQ-learning (FQL). As an off-policy approach, Q-learning learns independent of\nthe policy currently followed, whereas SARSA as an on-policy always\nincorporates the actual agent's behavior and leads to faster learning. Both\napproaches are implemented and compared in their advantages and disadvantages,\nhere in the OpenStack cloud platform. We demonstrate that both auto-scaling\napproaches can handle various load traffic situations, sudden and periodic, and\ndelivering resources on demand while reducing operating costs and preventing\nSLA violations. The experimental results demonstrate that FSL and FQL have\nacceptable performance in terms of adjusted number of virtual machine targeted\nto optimize SLA compliance and response time.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 17:56:42 GMT"}], "update_date": "2017-05-22", "authors_parsed": [["Arabnejad", "Hamid", ""], ["Pahl", "Claus", ""], ["Jamshidi", "Pooyan", ""], ["Estrada", "Giovani", ""]]}, {"id": "1705.07121", "submitter": "Mansaf Alam Dr", "authors": "Kashish A. Shakil, Farhana J. Zareen, Mansaf Alam and Suraiya Jabin", "title": "BAMHealthCloud: A Biometric Authentication and Data Management System\n  for Healthcare Data in Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in healthcare industry with new technology and population growth\nhas given rise to security threat to our most personal data. The healthcare\ndata management system consists of records in different formats such as text,\nnumeric, pictures and videos leading to data which is big and unstructured.\nAlso, hospitals have several branches at different locations throughout a\ncountry and overseas. In view of these requirements a cloud based healthcare\nmanagement system can be an effective solution for efficient health care data\nmanagement. One of the major concerns of a cloud based healthcare system is the\nsecurity aspect. It includes theft to identity, tax fraudulence, insurance\nfrauds, medical frauds and defamation of high profile patients. Hence, a secure\ndata access and retrieval is needed in order to provide security of critical\nmedical records in health care management system. Biometric authentication\nmechanism is suitable in this scenario since it overcomes the limitations of\ntoken theft and forgetting passwords in conventional token id-password\nmechanism used for providing security. It also has high accuracy rate for\nsecure data access and retrieval. In this paper we propose BAMHealthCloud which\nis a cloud based system for management of healthcare data, it ensures security\nof data through biometric authentication. It has been developed after\nperforming a detailed case study on healthcare sector in a developing country.\nTraining of the signature samples for authentication purpose has been performed\nin parallel on hadoop MapReduce framework using Resilient Backpropagation\nneural network. From rigorous experiments it can be concluded that it achieves\na speedup of 9x, Equal error rate (EER) of 0.12, sensitivity of 0.98 and\nspecificity of 0.95 as compared to other approaches existing in literature.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 11:00:40 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Shakil", "Kashish A.", ""], ["Zareen", "Farhana J.", ""], ["Alam", "Mansaf", ""], ["Jabin", "Suraiya", ""]]}, {"id": "1705.07175", "submitter": "Fabrizio Pedersoli", "authors": "Fabrizio Pedersoli and George Tzanetakis and Andrea Tagliasacchi", "title": "Espresso: Efficient Forward Propagation for BCNNs", "comments": "10 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many applications scenarios for which the computational performance\nand memory footprint of the prediction phase of Deep Neural Networks (DNNs)\nneeds to be optimized. Binary Neural Networks (BDNNs) have been shown to be an\neffective way of achieving this objective. In this paper, we show how\nConvolutional Neural Networks (CNNs) can be implemented using binary\nrepresentations. Espresso is a compact, yet powerful library written in C/CUDA\nthat features all the functionalities required for the forward propagation of\nCNNs, in a binary file less than 400KB, without any external dependencies.\nAlthough it is mainly designed to take advantage of massive GPU parallelism,\nEspresso also provides an equivalent CPU implementation for CNNs. Espresso\nprovides special convolutional and dense layers for BCNNs, leveraging\nbit-packing and bit-wise computations for efficient execution. These techniques\nprovide a speed-up of matrix-multiplication routines, and at the same time,\nreduce memory usage when storing parameters and activations. We experimentally\nshow that Espresso is significantly faster than existing implementations of\noptimized binary neural networks ($\\approx$ 2 orders of magnitude). Espresso is\nreleased under the Apache 2.0 license and is available at\nhttp://github.com/fpeder/espresso.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 20:29:42 GMT"}, {"version": "v2", "created": "Wed, 7 Mar 2018 17:59:16 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Pedersoli", "Fabrizio", ""], ["Tzanetakis", "George", ""], ["Tagliasacchi", "Andrea", ""]]}, {"id": "1705.07212", "submitter": "Gregory Chockler", "authors": "Gregory Chockler, Alexander Spiegelman", "title": "Space Complexity of Fault Tolerant Register Emulations", "comments": "Conference version appears in Proceedings of PODC '17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Driven by the rising popularity of cloud storage, the costs associated with\nimplementing reliable storage services from a collection of fault-prone servers\nhave recently become an actively studied question. The well-known ABD result\nshows that an f-tolerant register can be emulated using a collection of 2f + 1\nfault-prone servers each storing a single read-modify-write object type, which\nis known to be optimal. In this paper we generalize this bound: we investigate\nthe inherent space complexity of emulating reliable multi-writer registers as a\nfucntion of the type of the base objects exposed by the underlying servers, the\nnumber of writers to the emulated register, the number of available servers,\nand the failure threshold. We establish a sharp separation between registers,\nand both max-registers (the base object types assumed by ABD) and CAS in terms\nof the resources (i.e., the number of base objects of the respective types)\nrequired to support the emulation; we show that no such separation exists\nbetween max-registers and CAS. Our main technical contribution is lower and\nupper bounds on the resources required in case the underlying base objects are\nfault-prone read/write registers. We show that the number of required registers\nis directly proportional to the number of writers and inversely proportional to\nthe number of servers.\n", "versions": [{"version": "v1", "created": "Fri, 19 May 2017 22:32:57 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Chockler", "Gregory", ""], ["Spiegelman", "Alexander", ""]]}, {"id": "1705.07254", "submitter": "Yad Tahir", "authors": "Yad Tahir and Shusen Yang and Julie McCann", "title": "BRPL: Backpressure RPL for High-throughput and Mobile IoTs", "comments": "14 pages, to appear in IEEE Transactions on Mobile Computing, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  RPL, an IPv6 routing protocol for Low power Lossy Networks (LLNs), is\nconsidered to be the de facto routing standard for the Internet of Things\n(IoT). However, more and more experimental results demonstrate that RPL\nperforms poorly when it comes to throughput and adaptability to network\ndynamics. This significantly limits the application of RPL in many practical\nIoT scenarios, such as an LLN with high-speed sensor data streams and mobile\nsensing devices. To address this issue, we develop BRPL, an extension of RPL,\nproviding a practical approach that allows users to smoothly combine any RPL\nObject Function (OF) with backpressure routing. BRPL uses two novel algorithms,\nQuickTheta and QuickBeta, to support time-varying data traffic loads and node\nmobility respectively. We implement BRPL on Contiki OS, an open-source\noperating system for the Internet of Things. We conduct an extensive evaluation\nusing both real-world experiments based on the FIT IoT-LAB testbed and\nlarge-scale simulations using Cooja over 18 virtual servers on the Cloud. The\nevaluation results demonstrate that BRPL not only is fully backward compatible\nwith RPL (i.e. devices running RPL and BRPL can work together seamlessly), but\nalso significantly improves network throughput and adaptability to changes in\nnetwork topologies and data traffic loads. The observed packet loss reduction\nin mobile networks is, at a minimum, 60% and up to 1000% can be seen in extreme\ncases.\n", "versions": [{"version": "v1", "created": "Sat, 20 May 2017 03:18:39 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Tahir", "Yad", ""], ["Yang", "Shusen", ""], ["McCann", "Julie", ""]]}, {"id": "1705.07327", "submitter": "Fabian Kuhn", "authors": "Abdolhamid Ghodselahi and Fabian Kuhn", "title": "Dynamic Analysis of the Arrow Distributed Directory Protocol in General\n  Networks", "comments": "31 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Arrow protocol is a simple and elegant protocol to coordinate exclusive\naccess to a shared object in a network. The protocol solves the underlying\ndistributed queueing problem by using path reversal on a pre-computed spanning\ntree (or any other tree topology simulated on top of the given network).\n  It is known that the Arrow protocol solves the problem with a competitive\nratio of O(log D) on trees of diameter D. This implies a distributed queueing\nalgorithm with competitive ratio O(s*log D) for general networks with a\nspanning tree of diameter D and stretch s. In this work we show that when\nrunning the Arrow protocol on top of the well-known probabilistic tree\nembedding of Fakcharoenphol, Rao, and Talwar [STOC 03], we obtain a randomized\ndistributed queueing algorithm with a competitive ratio of O(log n) even on\ngeneral network topologies. The result holds even if the queueing requests\noccur in an arbitrarily dynamic and concurrent fashion and even if\ncommunication is asynchronous. From a technical point of view, the main of the\npaper shows that the competitive ratio of the Arrow protocol is constant on a\nspecial family of tree topologies, known as hierarchically well separated\ntrees.\n", "versions": [{"version": "v1", "created": "Sat, 20 May 2017 16:25:22 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Ghodselahi", "Abdolhamid", ""], ["Kuhn", "Fabian", ""]]}, {"id": "1705.07369", "submitter": "Ellis Hershkowitz", "authors": "Keren Censor-Hillel, Bernhard Haeupler, D. Ellis Hershkowitz, Goran\n  Zuzic", "title": "Broadcasting in Noisy Radio Networks", "comments": "Principles of Distributed Computing 2017", "journal-ref": null, "doi": "10.1145/3087801.3087808", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The widely-studied radio network model [Chlamtac and Kutten, 1985] is a\ngraph-based description that captures the inherent impact of collisions in\nwireless communication. In this model, the strong assumption is made that node\n$v$ receives a message from a neighbor if and only if exactly one of its\nneighbors broadcasts.\n  We relax this assumption by introducing a new noisy radio network model in\nwhich random faults occur at senders or receivers. Specifically, for a constant\nnoise parameter $p \\in [0,1)$, either every sender has probability $p$ of\ntransmitting noise or every receiver of a single transmission in its\nneighborhood has probability $p$ of receiving noise.\n  We first study single-message broadcast algorithms in noisy radio networks\nand show that the Decay algorithm [Bar-Yehuda et al., 1992] remains robust in\nthe noisy model while the diameter-linear algorithm of Gasieniec et al., 2007\ndoes not. We give a modified version of the algorithm of Gasieniec et al., 2007\nthat is robust to sender and receiver faults, and extend both this modified\nalgorithm and the Decay algorithm to robust multi-message broadcast algorithms.\n  We next investigate the extent to which (network) coding improves throughput\nin noisy radio networks. We address the previously perplexing result of Alon et\nal. 2014 that worst case coding throughput is no better than worst case routing\nthroughput up to constants: we show that the worst case throughput performance\nof coding is, in fact, superior to that of routing -- by a $\\Theta(\\log(n))$\ngap -- provided receiver faults are introduced. However, we show that any\ncoding or routing scheme for the noiseless setting can be transformed to be\nrobust to sender faults with only a constant throughput overhead. These\ntransformations imply that the results of Alon et al., 2014 carry over to noisy\nradio networks with sender faults.\n", "versions": [{"version": "v1", "created": "Sun, 21 May 2017 00:04:54 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Haeupler", "Bernhard", ""], ["Hershkowitz", "D. Ellis", ""], ["Zuzic", "Goran", ""]]}, {"id": "1705.07400", "submitter": "Juncheng Yang", "authors": "Juncheng Yang, Reza Karimi, Trausti S{\\ae}mundsson, Avani Wildani,\n  Ymir Vigfusson", "title": "MITHRIL: Mining Sporadic Associations for Cache Prefetching", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing pressure on cloud application scalability has accentuated storage\nperformance as a critical bottle- neck. Although cache replacement algorithms\nhave been extensively studied, cache prefetching - reducing latency by\nretrieving items before they are actually requested remains an underexplored\narea. Existing approaches to history-based prefetching, in particular, provide\ntoo few benefits for real systems for the resources they cost. We propose\nMITHRIL, a prefetching layer that efficiently exploits historical patterns in\ncache request associations. MITHRIL is inspired by sporadic association rule\nmining and only relies on the timestamps of requests. Through evaluation of 135\nblock-storage traces, we show that MITHRIL is effective, giving an average of a\n55% hit ratio increase over LRU and PROBABILITY GRAPH, a 36% hit ratio gain\nover AMP at reasonable cost. We further show that MITHRIL can supplement any\ncache replacement algorithm and be readily integrated into existing systems.\nFurthermore, we demonstrate the improvement comes from MITHRIL being able to\ncapture mid-frequency blocks.\n", "versions": [{"version": "v1", "created": "Sun, 21 May 2017 05:51:21 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Yang", "Juncheng", ""], ["Karimi", "Reza", ""], ["S\u00e6mundsson", "Trausti", ""], ["Wildani", "Avani", ""], ["Vigfusson", "Ymir", ""]]}, {"id": "1705.07478", "submitter": "Ganesh Gopalakrishnan", "authors": "Ganesh Gopalakrishnan and Paul D. Hovland and Costin Iancu and Sriram\n  Krishnamoorthy and Ignacio Laguna and Richard A. Lethin and Koushik Sen and\n  Stephen F. Siegel and Armando Solar-Lezama", "title": "Report of the HPC Correctness Summit, Jan 25--26, 2017, Washington, DC", "comments": "57 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Maintaining leadership in HPC requires the ability to support simulations at\nlarge scales and fidelity. In this study, we detail one of the most significant\nproductivity challenges in achieving this goal, namely the increasing\nproclivity to bugs, especially in the face of growing hardware and software\nheterogeneity and sheer system scale. We identify key areas where timely new\nresearch must be proactively begun to address these challenges, and create new\ncorrectness tools that must ideally play a significant role even while ramping\nup toward exacale. We close with the proposal for a two-day workshop in which\nthe problems identified in this report can be more broadly discussed, and\nspecific plans to launch these new research thrusts identified.\n", "versions": [{"version": "v1", "created": "Sun, 21 May 2017 17:15:04 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Gopalakrishnan", "Ganesh", ""], ["Hovland", "Paul D.", ""], ["Iancu", "Costin", ""], ["Krishnamoorthy", "Sriram", ""], ["Laguna", "Ignacio", ""], ["Lethin", "Richard A.", ""], ["Sen", "Koushik", ""], ["Siegel", "Stephen F.", ""], ["Solar-Lezama", "Armando", ""]]}, {"id": "1705.07861", "submitter": "Shreyas Pai", "authors": "Shreyas Pai, Gopal Pandurangan, Sriram V. Pemmaraju, Talal Riaz, Peter\n  Robinson", "title": "Symmetry Breaking in the Congest Model: Time- and Message-Efficient\n  Algorithms for Ruling Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We study local symmetry breaking problems in the CONGEST model, focusing on\nruling set problems, which generalize the fundamental Maximal Independent Set\n(MIS) problem. A $\\beta$-ruling set is an independent set such that every node\nin the graph is at most $\\beta$ hops from a node in the independent set. Our\nwork is motivated by the following central question: can we break the\n$\\Theta(\\log n)$ time complexity barrier and the $\\Theta(m)$ message complexity\nbarrier in the CONGEST model for MIS or closely-related symmetry breaking\nproblems? We present the following results:\n  - Time Complexity: We show that we can break the $O(\\log n)$ \"barrier\" for 2-\nand 3-ruling sets. We compute 3-ruling sets in $O\\left(\\frac{\\log n}{\\log \\log\nn}\\right)$ rounds with high probability (whp). More generally we show that\n2-ruling sets can be computed in $O\\left(\\log \\Delta \\cdot (\\log n)^{1/2 +\n\\varepsilon} + \\frac{\\log n}{\\log\\log n}\\right)$ rounds for any $\\varepsilon >\n0$, which is $o(\\log n)$ for a wide range of $\\Delta$ values (e.g., $\\Delta =\n2^{(\\log n)^{1/2-\\varepsilon}}$). These are the first 2- and 3-ruling set\nalgorithms to improve over the $O(\\log n)$-round complexity of Luby's algorithm\nin the CONGEST model.\n  - Message Complexity: We show an $\\Omega(n^2)$ lower bound on the message\ncomplexity of computing an MIS (i.e., 1-ruling set) which holds also for\nrandomized algorithms and present a contrast to this by showing a randomized\nalgorithm for 2-ruling sets that, whp, uses only $O(n \\log^2 n)$ messages and\nruns in $O(\\Delta \\log n)$ rounds. This is the first message-efficient\nalgorithm known for ruling sets, which has message complexity nearly linear in\n$n$ (which is optimal up to a polylogarithmic factor).\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 17:08:21 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Pai", "Shreyas", ""], ["Pandurangan", "Gopal", ""], ["Pemmaraju", "Sriram V.", ""], ["Riaz", "Talal", ""], ["Robinson", "Peter", ""]]}, {"id": "1705.07878", "submitter": "Wei Wen", "authors": "Wei Wen, Cong Xu, Feng Yan, Chunpeng Wu, Yandan Wang, Yiran Chen, Hai\n  Li", "title": "TernGrad: Ternary Gradients to Reduce Communication in Distributed Deep\n  Learning", "comments": "NIPS 2017 Oral", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High network communication cost for synchronizing gradients and parameters is\nthe well-known bottleneck of distributed training. In this work, we propose\nTernGrad that uses ternary gradients to accelerate distributed deep learning in\ndata parallelism. Our approach requires only three numerical levels {-1,0,1},\nwhich can aggressively reduce the communication time. We mathematically prove\nthe convergence of TernGrad under the assumption of a bound on gradients.\nGuided by the bound, we propose layer-wise ternarizing and gradient clipping to\nimprove its convergence. Our experiments show that applying TernGrad on AlexNet\ndoes not incur any accuracy loss and can even improve accuracy. The accuracy\nloss of GoogLeNet induced by TernGrad is less than 2% on average. Finally, a\nperformance model is proposed to study the scalability of TernGrad. Experiments\nshow significant speed gains for various deep neural networks. Our source code\nis available.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 17:42:15 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 06:41:05 GMT"}, {"version": "v3", "created": "Mon, 4 Sep 2017 23:49:08 GMT"}, {"version": "v4", "created": "Mon, 18 Sep 2017 16:21:51 GMT"}, {"version": "v5", "created": "Tue, 31 Oct 2017 16:36:41 GMT"}, {"version": "v6", "created": "Fri, 29 Dec 2017 02:51:48 GMT"}], "update_date": "2018-01-01", "authors_parsed": [["Wen", "Wei", ""], ["Xu", "Cong", ""], ["Yan", "Feng", ""], ["Wu", "Chunpeng", ""], ["Wang", "Yandan", ""], ["Chen", "Yiran", ""], ["Li", "Hai", ""]]}, {"id": "1705.07983", "submitter": "Michael Luby", "authors": "Michael G. Luby, Roberto Padovani, Thomas J. Richardson, Lorenz\n  Minder, Pooja Aggarwal", "title": "Liquid Cloud Storage", "comments": "44 pages, 21 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A liquid system provides durable object storage based on spreading\nredundantly generated data across a network of hundreds to thousands of\npotentially unreliable storage nodes. A liquid system uses a combination of a\nlarge code, lazy repair, and a flow storage organization. We show that a liquid\nsystem can be operated to enable flexible and essentially optimal combinations\nof storage durability, storage overhead, repair bandwidth usage, and access\nperformance.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 20:21:09 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Luby", "Michael G.", ""], ["Padovani", "Roberto", ""], ["Richardson", "Thomas J.", ""], ["Minder", "Lorenz", ""], ["Aggarwal", "Pooja", ""]]}, {"id": "1705.08169", "submitter": "Josef Spillner", "authors": "Josef Spillner", "title": "Transformation of Python Applications into Function-as-a-Service\n  Deployments", "comments": "14 pages, 2 tables, 5 figures, repeatable, unreviewed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New cloud programming and deployment models pose challenges to software\napplication engineers who are looking, often in vain, for tools to automate any\nnecessary code adaptation and transformation. Function-as-a-Service interfaces\nare particular non-trivial targets when considering that most cloud\napplications are implemented in non-functional languages. Among the most widely\nused of these languages is Python. This starting position calls for an\nautomated approach to transform monolithic Python code into modular FaaS units\nby partially automated decomposition. Hence, this paper introduces and\nevaluates Lambada, a Python module to dynamically decompose, convert and deploy\nunmodified Python code into AWS Lambda functions. Beyond the tooling in the\nform of a measured open source prototype implementation, the paper contributes\na description of the algorithms and code rewriting rules as blueprints for\ntransformations of other scripting languages.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 10:43:53 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Spillner", "Josef", ""]]}, {"id": "1705.08174", "submitter": "Hendrik Fichtenberger", "authors": "Hendrik Fichtenberger, Yadu Vasudev", "title": "Distributed Testing of Conductance", "comments": "revised introduction and some fixes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of testing conductance in the setting of distributed\ncomputing and give a two-sided tester that takes $\\mathcal{O}(\\log(n) /\n(\\epsilon \\Phi^2))$ rounds to decide if a graph has conductance at least $\\Phi$\nor is $\\epsilon$-far from having conductance at least $\\Phi^2 / 1000$ in the\ndistributed CONGEST model. We also show that $\\Omega(\\log n)$ rounds are\nnecessary for testing conductance even in the LOCAL model. In the case of a\nconnected graph, we show that we can perform the test even when the number of\nvertices in the graph is not known a priori. This is the first two-sided tester\nin the distributed model we are aware of. A key observation is that one can\nperform a polynomial number of random walks from a small set of vertices if it\nis sufficient to track only some small statistics of the walks. This greatly\nreduces the congestion on the edges compared to tracking each walk\nindividually.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 10:50:06 GMT"}, {"version": "v2", "created": "Mon, 17 Jul 2017 13:20:42 GMT"}, {"version": "v3", "created": "Thu, 19 Oct 2017 11:28:26 GMT"}], "update_date": "2017-10-20", "authors_parsed": [["Fichtenberger", "Hendrik", ""], ["Vasudev", "Yadu", ""]]}, {"id": "1705.08210", "submitter": "Wayne Joubert", "authors": "Wayne Joubert, James Nance, Deborah Weighill, Daniel Jacobson", "title": "Parallel Accelerated Vector Similarity Calculations for Genomics\n  Applications", "comments": null, "journal-ref": null, "doi": "10.1016/j.parco.2018.03.009", "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The surge in availability of genomic data holds promise for enabling\ndetermination of genetic causes of observed individual traits, with\napplications to problems such as discovery of the genetic roots of phenotypes,\nbe they molecular phenotypes such as gene expression or metabolite\nconcentrations, or complex phenotypes such as diseases. However, the growing\nsizes of these datasets and the quadratic, cubic or higher scaling\ncharacteristics of the relevant algorithms pose a serious computational\nchallenge necessitating use of leadership scale computing. In this paper we\ndescribe a new approach to performing vector similarity metrics calculations,\nsuitable for parallel systems equipped with graphics processing units (GPUs) or\nIntel Xeon Phi processors. Our primary focus is the Proportional Similarity\nmetric applied to Genome Wide Association Studies (GWAS) and Phenome Wide\nAssociation Studies (PheWAS). We describe the implementation of the algorithms\non accelerated processors, methods used for eliminating redundant calculations\ndue to symmetries, and techniques for efficient mapping of the calculations to\nmany-node parallel systems. Results are presented demonstrating high per-node\nperformance and parallel scalability with rates of more than five quadrillion\nelementwise comparisons achieved per second on the ORNL Titan system. In a\ncompanion paper we describe corresponding techniques applied to calculations of\nthe Custom Correlation Coefficient for comparative genomics applications.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 12:34:55 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 23:17:55 GMT"}, {"version": "v3", "created": "Fri, 20 Apr 2018 15:47:04 GMT"}], "update_date": "2018-04-23", "authors_parsed": [["Joubert", "Wayne", ""], ["Nance", "James", ""], ["Weighill", "Deborah", ""], ["Jacobson", "Daniel", ""]]}, {"id": "1705.08213", "submitter": "Wayne Joubert", "authors": "Wayne Joubert, James Nance, Sharlee Climer, Deborah Weighill, Daniel\n  Jacobson", "title": "Parallel Accelerated Custom Correlation Coefficient Calculations for\n  Genomics Applications", "comments": "arXiv admin note: text overlap with arXiv:1705.08210", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The massive quantities of genomic data being made available through gene\nsequencing techniques are enabling breakthroughs in genomic science in many\nareas such as medical advances in the diagnosis and treatment of diseases.\nAnalyzing this data, however, is a computational challenge insofar as the\ncomputational costs of the relevant algorithms can grow with quadratic, cubic\nor higher complexity-leading to the need for leadership scale computing. In\nthis paper we describe a new approach to calculations of the Custom Correlation\nCoefficient (CCC) between Single Nucleotide Polymorphisms (SNPs) across a\npopulation, suitable for parallel systems equipped with graphics processing\nunits (GPUs) or Intel Xeon Phi processors. We describe the mapping of the\nalgorithms to accelerated processors, techniques used for eliminating redundant\ncalculations due to symmetries, and strategies for efficient mapping of the\ncalculations to many-node parallel systems. Results are presented demonstrating\nhigh per-node performance and near-ideal parallel scalability with rates of\nmore than nine quadrillion elementwise comparisons achieved per second with the\nlatest optimized code on the ORNL Titan system, this being orders of magnitude\nfaster than rates achieved using other codes and platforms as reported in the\nliterature. Also it is estimated that as many as 90 quadrillion comparisons per\nsecond may be achievable on the upcoming ORNL Summit system, an additional 10X\nperformance increase. In a companion paper we describe corresponding techniques\napplied to calculations of the Proportional Similarity metric for comparative\ngenomics applications.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 12:39:05 GMT"}, {"version": "v2", "created": "Sun, 18 Mar 2018 23:14:28 GMT"}, {"version": "v3", "created": "Thu, 20 Sep 2018 20:51:41 GMT"}], "update_date": "2018-09-24", "authors_parsed": [["Joubert", "Wayne", ""], ["Nance", "James", ""], ["Climer", "Sharlee", ""], ["Weighill", "Deborah", ""], ["Jacobson", "Daniel", ""]]}, {"id": "1705.08230", "submitter": "Hossein Shafagh", "authors": "Hossein Shafagh, Lukas Burkhalter, Anwar Hithnawi, Simon Duquennoy", "title": "Towards Blockchain-based Auditable Storage and Sharing of IoT Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today the cloud plays a central role in storing, processing, and distributing\ndata. Despite contributing to the rapid development of IoT applications, the\ncurrent IoT cloud-centric architecture has led into a myriad of isolated data\nsilos that hinders the full potential of holistic data-driven analytics within\nthe IoT. In this paper, we present a blockchain-based design for the IoT that\nbrings a distributed access control and data management. We depart from the\ncurrent trust model that delegates access control of our data to a centralized\ntrusted authority and instead empower the users with data ownership. Our design\nis tailored for IoT data streams and enables secure data sharing. We enable a\nsecure and resilient access control management, by utilizing the blockchain as\nan auditable and distributed access control layer to the storage layer. We\nfacilitate the storage of time-series IoT data at the edge of the network via a\nlocality-aware decentralized storage system that is managed with the blockchain\ntechnology. Our system is agnostic of the physical storage nodes and supports\nas well utilization of cloud storage resources as storage nodes.\n", "versions": [{"version": "v1", "created": "Mon, 22 May 2017 15:46:55 GMT"}, {"version": "v2", "created": "Tue, 14 Nov 2017 15:06:35 GMT"}], "update_date": "2017-11-15", "authors_parsed": [["Shafagh", "Hossein", ""], ["Burkhalter", "Lukas", ""], ["Hithnawi", "Anwar", ""], ["Duquennoy", "Simon", ""]]}, {"id": "1705.08242", "submitter": "Sepehr Assadi", "authors": "Sepehr Assadi, Sanjeev Khanna", "title": "Randomized Composable Coresets for Matching and Vertex Cover", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common approach for designing scalable algorithms for massive data sets is\nto distribute the computation across, say $k$, machines and process the data\nusing limited communication between them. A particularly appealing framework\nhere is the simultaneous communication model whereby each machine constructs a\nsmall representative summary of its own data and one obtains an\napproximate/exact solution from the union of the representative summaries. If\nthe representative summaries needed for a problem are small, then this results\nin a communication-efficient and round-optimal protocol. While many fundamental\ngraph problems admit efficient solutions in this model, two prominent problems\nare notably absent from the list of successes, namely, the maximum matching\nproblem and the minimum vertex cover problem. Indeed, it was shown recently\nthat for both these problems, even achieving a polylog$(n)$ approximation\nrequires essentially sending the entire input graph from each machine.\n  The main insight of our work is that the intractability of matching and\nvertex cover in the simultaneous communication model is inherently connected to\nan adversarial partitioning of the underlying graph across machines. We show\nthat when the underlying graph is randomly partitioned across machines, both\nthese problems admit randomized composable coresets of size $\\widetilde{O}(n)$\nthat yield an $\\widetilde{O}(1)$-approximate solution. This results in an\n$\\widetilde{O}(1)$-approximation simultaneous protocol for these problems with\n$\\widetilde{O}(nk)$ total communication when the input is randomly partitioned\nacross $k$ machines. We further prove the optimality of our results. Finally,\nby a standard application of composable coresets, our results also imply\nMapReduce algorithms with the same approximation guarantee in one or two rounds\nof communication\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 13:33:28 GMT"}], "update_date": "2017-05-24", "authors_parsed": [["Assadi", "Sepehr", ""], ["Khanna", "Sanjeev", ""]]}, {"id": "1705.08350", "submitter": "Vijaya Ramachandran", "authors": "Richard Cole and Vijaya Ramachandran", "title": "Bounding Cache Miss Costs of Multithreaded Computations Under General\n  Schedulers", "comments": "Extended abstract in Proceedings of ACM Symp. on Parallel Alg. and\n  Architectures (SPAA) 2017, pp. 339-350. This revision has a few small updates\n  including a missing citation and the replacement of some big Oh terms with\n  precise constants", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze the caching overhead incurred by a class of multithreaded\nalgorithms when scheduled by an arbitrary scheduler. We obtain bounds that\nmatch or improve upon the well-known $O(Q+S \\cdot (M/B))$ caching cost for the\nrandomized work stealing (RWS) scheduler, where $S$ is the number of steals,\n$Q$ is the sequential caching cost, and $M$ and $B$ are the cache size and\nblock (or cache line) size respectively.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 15:09:12 GMT"}, {"version": "v2", "created": "Thu, 28 Sep 2017 18:59:17 GMT"}], "update_date": "2017-10-02", "authors_parsed": [["Cole", "Richard", ""], ["Ramachandran", "Vijaya", ""]]}, {"id": "1705.08435", "submitter": "Aur\\'elien Bellet", "authors": "Aur\\'elien Bellet, Rachid Guerraoui, Mahsa Taziki, Marc Tommasi", "title": "Personalized and Private Peer-to-Peer Machine Learning", "comments": "20 pages, to appear in the Proceedings of the 21st International\n  Conference on Artificial Intelligence and Statistics (AISTATS 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CR cs.DC cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rise of connected personal devices together with privacy concerns call\nfor machine learning algorithms capable of leveraging the data of a large\nnumber of agents to learn personalized models under strong privacy\nrequirements. In this paper, we introduce an efficient algorithm to address the\nabove problem in a fully decentralized (peer-to-peer) and asynchronous fashion,\nwith provable convergence rate. We show how to make the algorithm\ndifferentially private to protect against the disclosure of information about\nthe personal datasets, and formally analyze the trade-off between utility and\nprivacy. Our experiments show that our approach dramatically outperforms\nprevious work in the non-private case, and that under privacy constraints, we\ncan significantly improve over models learned in isolation.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 17:43:18 GMT"}, {"version": "v2", "created": "Mon, 19 Feb 2018 09:43:47 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Bellet", "Aur\u00e9lien", ""], ["Guerraoui", "Rachid", ""], ["Taziki", "Mahsa", ""], ["Tommasi", "Marc", ""]]}, {"id": "1705.08449", "submitter": "Hung Cao", "authors": "Hung Cao, Monica Wachowicz, Sangwhan Cha", "title": "Developing an edge computing platform for real-time descriptive\n  analytics", "comments": "Edge-based analytics, real-time transit data streams, fog computing,\n  descriptive analytics, Internet of Mobile Things, edge computing, mobile\n  cloud computing, mobile edge computing", "journal-ref": null, "doi": "10.1109/BigData.2017.8258497", "report-no": null, "categories": "cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Mobile Things encompasses stream data being generated by\nsensors, network communications that pull and push these data streams, as well\nas running processing and analytics that can effectively leverage actionable\ninformation for transportation planning, management, and business advantage.\nEdge computing emerges as a new paradigm that decentralizes the communication,\ncomputation, control and storage resources from the cloud to the edge of the\nnetwork. This paper proposes an edge computing platform where mobile edge nodes\nare physical devices deployed on a transit bus where descriptive analytics is\nused to uncover meaningful patterns from real-time transit data streams. An\napplication experiment is used to evaluate the advantages and disadvantages of\nour proposed platform to support descriptive analytics at a mobile edge node\nand generate actionable information to transit managers.\n", "versions": [{"version": "v1", "created": "Tue, 23 May 2017 16:22:06 GMT"}, {"version": "v2", "created": "Mon, 16 Oct 2017 01:38:21 GMT"}, {"version": "v3", "created": "Tue, 21 Nov 2017 16:52:05 GMT"}, {"version": "v4", "created": "Mon, 17 Dec 2018 00:19:43 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Cao", "Hung", ""], ["Wachowicz", "Monica", ""], ["Cha", "Sangwhan", ""]]}, {"id": "1705.08627", "submitter": "Yoram Moses", "authors": "Asa Dan and Rajit Manohar and Yoram Moses", "title": "On Using Time Without Clocks via Zigzag Causality", "comments": "This is an extended version of a paper to appear in PODC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even in the absence of clocks, time bounds on the duration of actions enable\nthe use of time for distributed coordination. This paper initiates an\ninvestigation of coordination in such a setting. A new communication structure\ncalled a zigzag pattern is introduced, and shown to guarantee bounds on the\nrelative timing of events in this clockless model. Indeed, zigzag patterns are\nshown to be necessary and sufficient for establishing that events occur in a\nmanner that satisfies prescribed bounds. We capture when a process can know\nthat an appropriate zigzag pattern exists, and use this to provide necessary\nand sufficient conditions for timed coordination of events using a\nfull-information protocol in the clockless model.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 06:42:01 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Dan", "Asa", ""], ["Manohar", "Rajit", ""], ["Moses", "Yoram", ""]]}, {"id": "1705.08885", "submitter": "Vikram Saraph", "authors": "Archita Agarwal, Zhiyu Liu, Eli Rosenthal, Vikram Saraph", "title": "Linearizable Iterators for Concurrent Sets", "comments": "15 pages, 14 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a general framework for adding linearizable iterators to\na class of data structures that implement set operations. We introduce a\ncondition on set operations, called local consistency, which informally states\nthat set operations never make elements unreachable to a sequential iterator's\ntraversal. We show that sets with locally consistent operations can be\naugmented with a linearizable iterator via the framework. Our technique is\nbroadly applicable to a variety of data structures, including hash tables and\nbinary search trees. We apply the technique to sets taken from existing\nliterature, prove their operations are locally consistent, and demonstrate that\niterators do not significantly affect the performance of concurrent set\noperations.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 17:58:13 GMT"}, {"version": "v2", "created": "Tue, 12 Sep 2017 16:55:35 GMT"}, {"version": "v3", "created": "Thu, 1 Mar 2018 15:33:22 GMT"}], "update_date": "2018-03-02", "authors_parsed": [["Agarwal", "Archita", ""], ["Liu", "Zhiyu", ""], ["Rosenthal", "Eli", ""], ["Saraph", "Vikram", ""]]}, {"id": "1705.09056", "submitter": "Xiangru Lian", "authors": "Xiangru Lian, Ce Zhang, Huan Zhang, Cho-Jui Hsieh, Wei Zhang, Ji Liu", "title": "Can Decentralized Algorithms Outperform Centralized Algorithms? A Case\n  Study for Decentralized Parallel Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most distributed machine learning systems nowadays, including TensorFlow and\nCNTK, are built in a centralized fashion. One bottleneck of centralized\nalgorithms lies on high communication cost on the central node. Motivated by\nthis, we ask, can decentralized algorithms be faster than its centralized\ncounterpart?\n  Although decentralized PSGD (D-PSGD) algorithms have been studied by the\ncontrol community, existing analysis and theory do not show any advantage over\ncentralized PSGD (C-PSGD) algorithms, simply assuming the application scenario\nwhere only the decentralized network is available. In this paper, we study a\nD-PSGD algorithm and provide the first theoretical analysis that indicates a\nregime in which decentralized algorithms might outperform centralized\nalgorithms for distributed stochastic gradient descent. This is because D-PSGD\nhas comparable total computational complexities to C-PSGD but requires much\nless communication cost on the busiest node. We further conduct an empirical\nstudy to validate our theoretical analysis across multiple frameworks (CNTK and\nTorch), different network configurations, and computation platforms up to 112\nGPUs. On network configurations with low bandwidth or high latency, D-PSGD can\nbe up to one order of magnitude faster than its well-optimized centralized\ncounterparts.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 05:58:17 GMT"}, {"version": "v2", "created": "Fri, 26 May 2017 00:22:51 GMT"}, {"version": "v3", "created": "Sat, 10 Jun 2017 05:08:21 GMT"}, {"version": "v4", "created": "Fri, 21 Jul 2017 13:50:26 GMT"}, {"version": "v5", "created": "Mon, 11 Sep 2017 04:21:43 GMT"}], "update_date": "2017-09-12", "authors_parsed": [["Lian", "Xiangru", ""], ["Zhang", "Ce", ""], ["Zhang", "Huan", ""], ["Hsieh", "Cho-Jui", ""], ["Zhang", "Wei", ""], ["Liu", "Ji", ""]]}, {"id": "1705.09061", "submitter": "Francois Le Gall", "authors": "Taisuke Izumi and Fran\\c{c}ois Le Gall", "title": "Triangle Finding and Listing in CONGEST Networks", "comments": "To appear in PODC 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Triangle-free graphs play a central role in graph theory, and triangle\ndetection (or triangle finding) as well as triangle enumeration (triangle\nlisting) play central roles in the field of graph algorithms. In distributed\ncomputing, algorithms with sublinear round complexity for triangle finding and\nlisting have recently been developed in the powerful CONGEST clique model,\nwhere communication is allowed between any two nodes of the network. In this\npaper we present the first algorithms with sublinear complexity for triangle\nfinding and triangle listing in the standard CONGEST model, where the\ncommunication topology is the same as the topology of the network. More\nprecisely, we give randomized algorithms for triangle finding and listing with\nround complexity $O(n^{2/3}(\\log n)^{2/3})$ and $O(n^{3/4}\\log n)$,\nrespectively, where $n$ denotes the number of nodes of the network. We also\nshow a lower bound $\\Omega(n^{1/3}/\\log n)$ on the round complexity of triangle\nlisting, which also holds for the CONGEST clique model.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 06:24:25 GMT"}], "update_date": "2017-05-26", "authors_parsed": [["Izumi", "Taisuke", ""], ["Gall", "Fran\u00e7ois Le", ""]]}, {"id": "1705.09073", "submitter": "Muhammad Anis Uddin Nasir", "authors": "Muhammad Anis Uddin Nasir, Hiroshi Horii, Marco Serafini, Nicolas\n  Kourtellis, Rudy Raymond, Sarunas Girdzijauskas, Takayuki Osogami", "title": "Load Balancing for Skewed Streams on Heterogeneous Cluster", "comments": "12 pages, under submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Streaming applications frequently encounter skewed workloads and execute on\nheterogeneous clusters. Optimal resource utilization in such adverse conditions\nbecomes a challenge, as it requires inferring the resource capacities and input\ndistribution at run time. In this paper, we tackle the aforementioned\nchallenges by modeling them as a load balancing problem. We propose a novel\npartitioning strategy called Consistent Grouping (CG), which enables each\nprocessing element instance (PEI) to process the workload according to its\ncapacity. The main idea behind CG is the notion of small, equal-sized virtual\nworkers at the sources, which are assigned to workers based on their\ncapacities. We provide a theoretical analysis of the proposed algorithm and\nshow via extensive empirical evaluation that our proposed scheme outperforms\nthe state-of-the-art approaches, like key grouping. In particular, CG achieves\n3.44x better performance in terms of latency compared to key grouping.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 07:25:51 GMT"}, {"version": "v2", "created": "Sun, 1 Oct 2017 15:33:07 GMT"}], "update_date": "2017-10-03", "authors_parsed": [["Nasir", "Muhammad Anis Uddin", ""], ["Horii", "Hiroshi", ""], ["Serafini", "Marco", ""], ["Kourtellis", "Nicolas", ""], ["Raymond", "Rudy", ""], ["Girdzijauskas", "Sarunas", ""], ["Osogami", "Takayuki", ""]]}, {"id": "1705.09271", "submitter": "Maxwell Young", "authors": "William C. Anderton and Maxwell Young", "title": "Is Our Model for Contention Resolution Wrong?", "comments": "Accepted to the 29th ACM Symposium on Parallelism in Algorithms and\n  Architectures (SPAA 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Randomized binary exponential backoff (BEB) is a popular algorithm for\ncoordinating access to a shared channel. With an operational history exceeding\nfour decades, BEB is currently an important component of several wireless\nstandards. Despite this track record, prior theoretical results indicate that\nunder bursty traffic (1) BEB yields poor makespan and (2) superior algorithms\nare possible. To date, the degree to which these findings manifest in practice\nhas not been resolved.\n  To address this issue, we examine one of the strongest cases against BEB: $n$\npackets that simultaneously begin contending for the wireless channel. Using\nNetwork Simulator 3, we compare against more recent algorithms that are\ninspired by BEB, but whose makespan guarantees are superior. Surprisingly, we\ndiscover that these newer algorithms significantly underperform. Through\nfurther investigation, we identify as the culprit a flawed but common\nabstraction regarding the cost of collisions. Our experimental results are\ncomplemented by analytical arguments that the number of collisions -- and not\nsolely makespan -- is an important metric to optimize. We believe that these\nfindings have implications for the design of contention-resolution algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 17:37:53 GMT"}, {"version": "v2", "created": "Thu, 1 Jun 2017 16:37:32 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Anderton", "William C.", ""], ["Young", "Maxwell", ""]]}, {"id": "1705.09358", "submitter": "Darren Strash", "authors": "Raphael Kimmig and Henning Meyerhenke and Darren Strash", "title": "Shared Memory Parallel Subgraph Enumeration", "comments": "18 pages, 12 figures, To appear at the 7th IEEE Workshop on Parallel\n  / Distributed Computing and Optimization (PDCO 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The subgraph enumeration problem asks us to find all subgraphs of a target\ngraph that are isomorphic to a given pattern graph. Determining whether even\none such isomorphic subgraph exists is NP-complete---and therefore finding all\nsuch subgraphs (if they exist) is a time-consuming task. Subgraph enumeration\nhas applications in many fields, including biochemistry and social networks,\nand interestingly the fastest algorithms for solving the problem for\nbiochemical inputs are sequential. Since they depend on depth-first tree\ntraversal, an efficient parallelization is far from trivial. Nevertheless,\nsince important applications produce data sets with increasing difficulty,\nparallelism seems beneficial.\n  We thus present here a shared-memory parallelization of the state-of-the-art\nsubgraph enumeration algorithms RI and RI-DS (a variant of RI for dense graphs)\nby Bonnici et al. [BMC Bioinformatics, 2013]. Our strategy uses work stealing\nand our implementation demonstrates a significant speedup on real-world\nbiochemical data---despite a highly irregular data access pattern. We also\nimprove RI-DS by pruning the search space better; this further improves the\nempirical running times compared to the already highly tuned RI-DS.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 20:52:48 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Kimmig", "Raphael", ""], ["Meyerhenke", "Henning", ""], ["Strash", "Darren", ""]]}, {"id": "1705.09366", "submitter": "Erik Saule", "authors": "Erik Saule, Dinesh Panchananam, Alexander Hohl, Wenwu Tang, Eric\n  Delmelle", "title": "Parallel Space-Time Kernel Density Estimation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential growth of available data has increased the need for\ninteractive exploratory analysis. Dataset can no longer be understood through\nmanual crawling and simple statistics. In Geographical Information Systems\n(GIS), the dataset is often composed of events localized in space and time; and\nvisualizing such a dataset involves building a map of where the events\noccurred.\n  We focus in this paper on events that are localized among three dimensions\n(latitude, longitude, and time), and on computing the first step of the\nvisualization pipeline, space-time kernel density estimation (STKDE), which is\nmost computationally expensive. Starting from a gold standard implementation,\nwe show how algorithm design and engineering, parallel decomposition, and\nscheduling can be applied to bring near real-time computing to space-time\nkernel density estimation. We validate our techniques on real world datasets\nextracted from infectious disease, social media, and ornithology.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 21:16:37 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Saule", "Erik", ""], ["Panchananam", "Dinesh", ""], ["Hohl", "Alexander", ""], ["Tang", "Wenwu", ""], ["Delmelle", "Eric", ""]]}, {"id": "1705.09382", "submitter": "Vahan Huroyan", "authors": "Vahan Huroyan and Gilad Lerman", "title": "Distributed Robust Subspace Recovery", "comments": null, "journal-ref": "SIAM J. Sci. Comput. 40 (2018) A3067-A3090", "doi": "10.1137/17M1131659", "report-no": null, "categories": "math.NA cs.AI cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose distributed solutions to the problem of Robust Subspace Recovery\n(RSR). Our setting assumes a huge dataset in an ad hoc network without a\ncentral processor, where each node has access only to one chunk of the dataset.\nFurthermore, part of the whole dataset lies around a low-dimensional subspace\nand the other part is composed of outliers that lie away from that subspace.\nThe goal is to recover the underlying subspace for the whole dataset, without\ntransferring the data itself between the nodes. We first apply the\nConsensus-Based Gradient method to the Geometric Median Subspace algorithm for\nRSR. For this purpose, we propose an iterative solution for the local dual\nminimization problem and establish its r-linear convergence. We then explain\nhow to distributedly implement the Reaper and Fast Median Subspace algorithms\nfor RSR. The proposed algorithms display competitive performance on both\nsynthetic and real data.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 22:22:51 GMT"}, {"version": "v2", "created": "Sat, 3 Mar 2018 21:31:02 GMT"}, {"version": "v3", "created": "Wed, 4 Jul 2018 21:56:51 GMT"}], "update_date": "2018-11-07", "authors_parsed": [["Huroyan", "Vahan", ""], ["Lerman", "Gilad", ""]]}, {"id": "1705.09555", "submitter": "Bruna Soares Peres", "authors": "Bruna Peres", "title": "Concurrent self-adjusting distributed tree networks", "comments": "Thesis project presented to the Graduate Program in Computer Science\n  of the Federal University of Minas Gerais in partial fulfillment of the\n  requirements for the degree of Doctor in Computer Science", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SplayNets are a distributed generalization of the classic splay tree data\nstructures. Given a set of communication requests and a network comprised of n\nnodes, such that any pair of nodes is capable of establishing a direct\nconnection, the goal is to dynamically find a (locally routable) binary tree\ntopology, which connects all nodes and optimizes the routing cost for that\ncommunication pattern, making local topology transformations (rotations) before\neach request is served. In this work we present a distributed and concurrent\nimplementation of SplayNets. Analytical results show that our proposed\nalgorithm prevents loops and deadlocks from occurring between concurrent\nrotations. We compute the total amortized average cost of a splay request in\nnumber of rounds and number of time-slots and as a function of the empirical\nentropies of source and destination nodes of the splay requests.\n", "versions": [{"version": "v1", "created": "Wed, 24 May 2017 22:27:35 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Peres", "Bruna", ""]]}, {"id": "1705.09566", "submitter": "Giacomo Scornavacca", "authors": "Andrea Clementi, Luciano Gual\\`a, Guido Proietti, Giacomo Scornavacca", "title": "Rational Fair Consensus in the GOSSIP Model", "comments": "Accepted at IPDPS'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The \\emph{rational fair consensus problem} can be informally defined as\nfollows. Consider a network of $n$ (selfish) \\emph{rational agents}, each of\nthem initially supporting a \\emph{color} chosen from a finite set $ \\Sigma$.\nThe goal is to design a protocol that leads the network to a stable\nmonochromatic configuration (i.e. a consensus) such that the probability that\nthe winning color is $c$ is equal to the fraction of the agents that initially\nsupport $c$, for any $c \\in \\Sigma$. Furthermore, this fairness property must\nbe guaranteed (with high probability) even in presence of any fixed\n\\emph{coalition} of rational agents that may deviate from the protocol in order\nto increase the winning probability of their supported colors. A protocol\nhaving this property, in presence of coalitions of size at most $t$, is said to\nbe a \\emph{whp\\,-$t$-strong equilibrium}. We investigate, for the first time,\nthe rational fair consensus problem in the GOSSIP communication model where, at\nevery round, every agent can actively contact at most one neighbor via a\n\\emph{push$/$pull} operation. We provide a randomized GOSSIP protocol that,\nstarting from any initial color configuration of the complete graph, achieves\nrational fair consensus within $O(\\log n)$ rounds using messages of\n$O(\\log^2n)$ size, w.h.p. More in details, we prove that our protocol is a\nwhp\\,-$t$-strong equilibrium for any $t = o(n/\\log n)$ and, moreover, it\ntolerates worst-case permanent faults provided that the number of non-faulty\nagents is $\\Omega(n)$. As far as we know, our protocol is the first solution\nwhich avoids any all-to-all communication, thus resulting in $o(n^2)$ message\ncomplexity.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 13:01:31 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Clementi", "Andrea", ""], ["Gual\u00e0", "Luciano", ""], ["Proietti", "Guido", ""], ["Scornavacca", "Giacomo", ""]]}, {"id": "1705.09609", "submitter": "Calvin Newport", "authors": "Calvin Newport", "title": "Gossip in a Smartphone Peer-to-Peer Network", "comments": "Extended Abstract to Appear in the Proceedings of the ACM Conference\n  on the Principles of Distributed Computing (PODC 2017)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the fundamental problem of gossip in the mobile\ntelephone model: a recently introduced variation of the classical telephone\nmodel modified to better describe the local peer-to-peer communication services\nimplemented in many popular smartphone operating systems. In more detail, the\nmobile telephone model differs from the classical telephone model in three\nways: (1) each device can participate in at most one connection per round; (2)\nthe network topology can undergo a parameterized rate of change; and (3)\ndevices can advertise a parameterized number of bits about their state to their\nneighbors in each round before connection attempts are initiated. We begin by\ndescribing and analyzing new randomized gossip algorithms in this model under\nthe harsh assumption of a network topology that can change completely in every\nround. We prove a significant time complexity gap between the case where nodes\ncan advertise $0$ bits to their neighbors in each round, and the case where\nnodes can advertise $1$ bit. For the latter assumption, we present two\nsolutions: the first depends on a shared randomness source, while the second\neliminates this assumption using a pseudorandomness generator we prove to exist\nwith a novel generalization of a classical result from the study of two-party\ncommunication complexity. We then turn our attention to the easier case where\nthe topology graph is stable, and describe and analyze a new gossip algorithm\nthat provides a substantial performance improvement for many parameters. We\nconclude by studying a relaxed version of gossip in which it is only necessary\nfor nodes to each learn a specified fraction of the messages in the system.\n", "versions": [{"version": "v1", "created": "Fri, 26 May 2017 15:10:39 GMT"}], "update_date": "2017-05-29", "authors_parsed": [["Newport", "Calvin", ""]]}, {"id": "1705.09617", "submitter": "Sebastian Siebertz", "authors": "Saeed Akhoondian Amiri, Stefan Schmid, Sebastian Siebertz", "title": "Distributed Dominating Set Approximations beyond Planar Graphs", "comments": "arXiv admin note: substantial text overlap with arXiv:1602.02991", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM cs.DS math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Minimum Dominating Set (MDS) problem is one of the most fundamental and\nchallenging problems in distributed computing. While it is well-known that\nminimum dominating sets cannot be approximated locally on general graphs, over\nthe last years, there has been much progress on computing local approximations\non sparse graphs, and in particular planar graphs.\n  In this paper we study distributed and deterministic MDS approximation\nalgorithms for graph classes beyond planar graphs. In particular, we show that\nexisting approximation bounds for planar graphs can be lifted to bounded genus\ngraphs, and present (1) a local constant-time, constant-factor MDS\napproximation algorithm and (2) a local $\\mathcal{O}(\\log^*{n})$-time\napproximation scheme. Our main technical contribution is a new analysis of a\nslightly modified variant of an existing algorithm by Lenzen et al.\nInterestingly, unlike existing proofs for planar graphs, our analysis does not\nrely on direct topological arguments.\n", "versions": [{"version": "v1", "created": "Thu, 25 May 2017 15:52:44 GMT"}, {"version": "v2", "created": "Tue, 16 Apr 2019 20:46:39 GMT"}], "update_date": "2019-04-18", "authors_parsed": [["Amiri", "Saeed Akhoondian", ""], ["Schmid", "Stefan", ""], ["Siebertz", "Sebastian", ""]]}, {"id": "1705.09786", "submitter": "Ryota Tomioka", "authors": "Alexander L. Gaunt, Matthew A. Johnson, Maik Riechert, Daniel Tarlow,\n  Ryota Tomioka, Dimitrios Vytiniotis, Sam Webster", "title": "AMPNet: Asynchronous Model-Parallel Training for Dynamic Neural Networks", "comments": "17 pages, 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New types of machine learning hardware in development and entering the market\nhold the promise of revolutionizing deep learning in a manner as profound as\nGPUs. However, existing software frameworks and training algorithms for deep\nlearning have yet to evolve to fully leverage the capability of the new wave of\nsilicon. We already see the limitations of existing algorithms for models that\nexploit structured input via complex and instance-dependent control flow, which\nprohibits minibatching. We present an asynchronous model-parallel (AMP)\ntraining algorithm that is specifically motivated by training on networks of\ninterconnected devices. Through an implementation on multi-core CPUs, we show\nthat AMP training converges to the same accuracy as conventional synchronous\ntraining algorithms in a similar number of epochs, but utilizes the available\nhardware more efficiently even for small minibatch sizes, resulting in\nsignificantly shorter overall training times. Our framework opens the door for\nscaling up a new class of deep learning models that cannot be efficiently\ntrained today.\n", "versions": [{"version": "v1", "created": "Sat, 27 May 2017 08:10:40 GMT"}, {"version": "v2", "created": "Sun, 11 Jun 2017 19:51:03 GMT"}, {"version": "v3", "created": "Thu, 22 Jun 2017 17:34:30 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Gaunt", "Alexander L.", ""], ["Johnson", "Matthew A.", ""], ["Riechert", "Maik", ""], ["Tarlow", "Daniel", ""], ["Tomioka", "Ryota", ""], ["Vytiniotis", "Dimitrios", ""], ["Webster", "Sam", ""]]}, {"id": "1705.09798", "submitter": "Adrian Kosowski", "authors": "Bartlomiej Dudek, Adrian Kosowski (GANG)", "title": "Universal Protocols for Information Dissemination Using Emergent Signals", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a population of $n$ agents which communicate with each other in a\ndecentralized manner, through random pairwise interactions. One or more agents\nin the population may act as authoritative sources of information, and the\nobjective of the remaining agents is to obtain information from or about these\nsource agents. We study two basic tasks: broadcasting, in which the agents are\nto learn the bit-state of an authoritative source which is present in the\npopulation, and source detection, in which the agents are required to decide if\nat least one source agent is present in the population or not.We focus on\ndesigning protocols which meet two natural conditions: (1) universality, i.e.,\nindependence of population size, and (2) rapid convergence to a correct global\nstate after a reconfiguration, such as a change in the state of a source agent.\nOur main positive result is to show that both of these constraints can be met.\nFor both the broadcasting problem and the source detection problem, we obtain\nsolutions with a convergence time of $O(\\log^2 n)$ rounds, w.h.p., from any\nstarting configuration. The solution to broadcasting is exact, which means that\nall agents reach the state broadcast by the source, while the solution to\nsource detection admits one-sided error on a $\\varepsilon$-fraction of the\npopulation (which is unavoidable for this problem). Both protocols are easy to\nimplement in practice and have a compact formulation.Our protocols exploit the\nproperties of self-organizing oscillatory dynamics. On the hardness side, our\nmain structural insight is to prove that any protocol which meets the\nconstraints of universality and of rapid convergence after reconfiguration must\ndisplay a form of non-stationary behavior (of which oscillatory dynamics are an\nexample). We also observe that the periodicity of the oscillatory behavior of\nthe protocol, when present, must necessarily depend on the number $^\\\\# X$ of\nsource agents present in the population. For instance, our protocols inherently\nrely on the emergence of a signal passing through the population, whose period\nis $\\Theta(\\log \\frac{n}{^\\\\# X})$ rounds for most starting configurations. The\ndesign of clocks with tunable frequency may be of independent interest, notably\nin modeling biological networks.\n", "versions": [{"version": "v1", "created": "Sat, 27 May 2017 09:46:18 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 15:22:48 GMT"}, {"version": "v3", "created": "Wed, 29 Nov 2017 15:04:55 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Dudek", "Bartlomiej", "", "GANG"], ["Kosowski", "Adrian", "", "GANG"]]}, {"id": "1705.09905", "submitter": "Bangtian Liu", "authors": "Bangtian Liu, Chengyao Wen, Anand D.Sarwate and Maryam Mehri Dehnavi", "title": "A Unified Optimization Approach for Sparse Tensor Operations on GPUs", "comments": null, "journal-ref": null, "doi": "10.1109/CLUSTER.2017.75", "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse tensors appear in many large-scale applications with multidimensional\nand sparse data. While multidimensional sparse data often need to be processed\non manycore processors, attempts to develop highly-optimized GPU-based\nimplementations of sparse tensor operations are rare. The irregular computation\npatterns and sparsity structures as well as the large memory footprints of\nsparse tensor operations make such implementations challenging. We leverage the\nfact that sparse tensor operations share similar computation patterns to\npropose a unified tensor representation called F-COO. Combined with\nGPU-specific optimizations, F-COO provides highly-optimized implementations of\nsparse tensor computations on GPUs. The performance of the proposed unified\napproach is demonstrated for tensor-based kernels such as the Sparse Matricized\nTensor- Times-Khatri-Rao Product (SpMTTKRP) and the Sparse Tensor- Times-Matrix\nMultiply (SpTTM) and is used in tensor decomposition algorithms. Compared to\nstate-of-the-art work we improve the performance of SpTTM and SpMTTKRP up to\n3.7 and 30.6 times respectively on NVIDIA Titan-X GPUs. We implement a\nCANDECOMP/PARAFAC (CP) decomposition and achieve up to 14.9 times speedup using\nthe unified method over state-of-the-art libraries on NVIDIA Titan-X GPUs.\n", "versions": [{"version": "v1", "created": "Sun, 28 May 2017 07:41:22 GMT"}], "update_date": "2017-12-18", "authors_parsed": [["Liu", "Bangtian", ""], ["Wen", "Chengyao", ""], ["Sarwate", "Anand D.", ""], ["Dehnavi", "Maryam Mehri", ""]]}, {"id": "1705.09927", "submitter": "Liang Dai", "authors": "Liang Dai, Nikolaos M. Freris", "title": "Fully distributed PageRank computation with exponential convergence", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies a fully distributed algorithm for computing the PageRank\nvector, which is inspired by the Matching Pursuit and features: 1) a fully\ndistributed implementation 2) convergence in expectation with exponential rate\n3) low storage requirement (two scalar values per page). Illustrative\nexperiments are conducted to verify the findings.\n", "versions": [{"version": "v1", "created": "Sun, 28 May 2017 11:19:59 GMT"}, {"version": "v2", "created": "Mon, 22 Oct 2018 08:04:58 GMT"}], "update_date": "2018-10-23", "authors_parsed": [["Dai", "Liang", ""], ["Freris", "Nikolaos M.", ""]]}, {"id": "1705.10195", "submitter": "Janne H. Korhonen", "authors": "Janne H. Korhonen and Joel Rybicki", "title": "Deterministic subgraph detection in broadcast CONGEST", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present simple deterministic algorithms for subgraph finding and\nenumeration in the broadcast CONGEST model of distributed computation:\n  -- For any constant $k$, detecting $k$-paths and trees on $k$ nodes can be\ndone in $O(1)$ rounds.\n  -- For any constant $k$, detecting $k$-cycles and pseudotrees on $k$ nodes\ncan be done in $O(n)$ rounds.\n  -- On $d$-degenerate graphs, cliques and $4$-cycles can be enumerated in $O(d\n+ \\log n)$ rounds, and $5$-cycles in $O(d^2 + \\log n)$ rounds.\n  In many cases, these bounds are tight up to logarithmic factors. Moreover, we\nshow that the algorithms for $d$-degenerate graphs can be improved to optimal\ncomplexity $O(d/\\log n)$ and $O(d^2/\\log n)$, respectively, in the supported\nCONGEST model, which can be seen as an intermediate model between CONGEST and\nthe congested clique.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 14:05:45 GMT"}, {"version": "v2", "created": "Thu, 21 Sep 2017 12:26:15 GMT"}], "update_date": "2017-09-22", "authors_parsed": [["Korhonen", "Janne H.", ""], ["Rybicki", "Joel", ""]]}, {"id": "1705.10208", "submitter": "Kiril Dichev", "authors": "Kiril Dichev and Herbert Jordan and Konstantinos Tovletoglou and\n  Thomas Heller and Dimitrios S. Nikolopoulos and Georgios Karakonstantis and\n  Charles Gillan", "title": "Dependency-Aware Rollback and Checkpoint-Restart for Distributed\n  Task-Based Runtimes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increase in compute nodes in large compute platforms, a proportional\nincrease in node failures will follow. Many application-based\ncheckpoint/restart (C/R) techniques have been proposed for MPI applications to\ntarget the reduced mean time between failures. However, rollback as part of the\nrecovery remains a dominant cost even in highly optimised MPI applications\nemploying C/R techniques. Continuing execution past a checkpoint (that is,\nreducing rollback) is possible in message-passing runtimes, but extremely\ncomplex to design and implement. Our work focuses on task-based runtimes, where\ntask dependencies are explicit and message passing is implicit. We see an\nopportunity for reducing rollback for such runtimes: we explore task\ndependencies in the rollback, which we call dependency-aware rollback. We also\ndesign a new C/R technique, which is influenced by recursive decomposition of\ntasks, and combine it with dependency-aware rollback. We expect the\ndependency-aware rollback to cancel and recompute less tasks in the presence of\nnode failures. We describe, implement and validate the proposed protocol in a\nsimulator, which confirms these expectations. In addition, we consistently\nobserve faster overall execution time for dependency-aware rollback in the\npresence of faults, despite the fact that reduced task cancellation does not\nguarantee reduced overall execution time.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 14:22:01 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Dichev", "Kiril", ""], ["Jordan", "Herbert", ""], ["Tovletoglou", "Konstantinos", ""], ["Heller", "Thomas", ""], ["Nikolopoulos", "Dimitrios S.", ""], ["Karakonstantis", "Georgios", ""], ["Gillan", "Charles", ""]]}, {"id": "1705.10218", "submitter": "Alfio Lazzaro", "authors": "Alfio Lazzaro, Joost VandeVondele, Juerg Hutter, Ole Schuett", "title": "Increasing the Efficiency of Sparse Matrix-Matrix Multiplication with a\n  2.5D Algorithm and One-Sided MPI", "comments": "In Proceedings of PASC '17, Lugano, Switzerland, June 26-28, 2017, 10\n  pages, 4 figures", "journal-ref": null, "doi": "10.1145/3093172.3093228", "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix-matrix multiplication is a basic operation in linear algebra and an\nessential building block for a wide range of algorithms in various scientific\nfields. Theory and implementation for the dense, square matrix case are\nwell-developed. If matrices are sparse, with application-specific sparsity\npatterns, the optimal implementation remains an open question. Here, we explore\nthe performance of communication reducing 2.5D algorithms and one-sided MPI\ncommunication in the context of linear scaling electronic structure theory. In\nparticular, we extend the DBCSR sparse matrix library, which is the basic\nbuilding block for linear scaling electronic structure theory and low scaling\ncorrelated methods in CP2K. The library is specifically designed to efficiently\nperform block-sparse matrix-matrix multiplication of matrices with a relatively\nlarge occupation. Here, we compare the performance of the original\nimplementation based on Cannon's algorithm and MPI point-to-point\ncommunication, with an implementation based on MPI one-sided communications\n(RMA), in both a 2D and a 2.5D approach. The 2.5D approach trades memory and\nauxiliary operations for reduced communication, which can lead to a speedup if\ncommunication is dominant. The 2.5D algorithm is somewhat easier to implement\nwith one-sided communications. A detailed description of the implementation is\nprovided, also for non ideal processor topologies, since this is important for\nactual applications. Given the importance of the precise sparsity pattern, and\neven the actual matrix data, which decides the effective fill-in upon\nmultiplication, the tests are performed within the CP2K package with\napplication benchmarks. Results show a substantial boost in performance for the\nRMA based 2.5D algorithm, up to 1.80x, which is observed to increase with the\nnumber of involved processes in the parallelization.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 14:42:14 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Lazzaro", "Alfio", ""], ["VandeVondele", "Joost", ""], ["Hutter", "Juerg", ""], ["Schuett", "Ole", ""]]}, {"id": "1705.10387", "submitter": "Maxwell Young", "authors": "Mercy O. Jaiyeola, Kyle Patron, Jared Saia, Maxwell Young, Qian M.\n  Zhou", "title": "Tiny Groups Tackle Byzantine Adversaries", "comments": "This work is supported by the National Science Foundation grant CCF\n  1613772 and a C Spire Research Gift", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A popular technique for tolerating malicious faults in open distributed\nsystems is to establish small groups of participants, each of which has a\nnon-faulty majority. These groups are used as building blocks to design\nattack-resistant algorithms.\n  Despite over a decade of active research, current constructions require group\nsizes of $O(\\log n)$, where $n$ is the number of participants in the system.\nThis group size is important since communication and state costs scale\npolynomially with this parameter. Given the stubbornness of this logarithmic\nbarrier, a natural question is whether better bounds are possible.\n  Here, we consider an attacker that controls a constant fraction of the total\ncomputational resources in the system. By leveraging proof-of-work (PoW), we\ndemonstrate how to reduce the group size exponentially to $O(\\log\\log n)$ while\nmaintaining strong security guarantees. This reduction in group size yields a\nsignificant improvement in communication and state costs.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 20:31:54 GMT"}, {"version": "v2", "created": "Mon, 31 Jul 2017 19:20:46 GMT"}, {"version": "v3", "created": "Mon, 23 Oct 2017 06:06:37 GMT"}, {"version": "v4", "created": "Fri, 3 Nov 2017 02:52:12 GMT"}, {"version": "v5", "created": "Tue, 9 Jan 2018 04:01:54 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Jaiyeola", "Mercy O.", ""], ["Patron", "Kyle", ""], ["Saia", "Jared", ""], ["Young", "Maxwell", ""], ["Zhou", "Qian M.", ""]]}, {"id": "1705.10464", "submitter": "Qian Yu", "authors": "Qian Yu, Mohammad Ali Maddah-Ali, A. Salman Avestimehr", "title": "Polynomial Codes: an Optimal Design for High-Dimensional Coded Matrix\n  Multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a large-scale matrix multiplication problem where the computation\nis carried out using a distributed system with a master node and multiple\nworker nodes, where each worker can store parts of the input matrices. We\npropose a computation strategy that leverages ideas from coding theory to\ndesign intermediate computations at the worker nodes, in order to efficiently\ndeal with straggling workers. The proposed strategy, named as \\emph{polynomial\ncodes}, achieves the optimum recovery threshold, defined as the minimum number\nof workers that the master needs to wait for in order to compute the output.\nFurthermore, by leveraging the algebraic structure of polynomial codes, we can\nmap the reconstruction problem of the final output to a polynomial\ninterpolation problem, which can be solved efficiently. Polynomial codes\nprovide order-wise improvement over the state of the art in terms of recovery\nthreshold, and are also optimal in terms of several other metrics. Furthermore,\nwe extend this code to distributed convolution and show its order-wise\noptimality.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 06:07:16 GMT"}, {"version": "v2", "created": "Wed, 24 Jan 2018 08:23:25 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Yu", "Qian", ""], ["Maddah-Ali", "Mohammad Ali", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "1705.10591", "submitter": "X. Sharon Hu", "authors": "Xiaoming Chen, Jianxu Chen, Danny Z. Chen, and Xiaobo Sharon Hu", "title": "Optimizing Memory Efficiency for Convolution Kernels on Kepler GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolution is a fundamental operation in many applications, such as computer\nvision, natural language processing, image processing, etc. Recent successes of\nconvolutional neural networks in various deep learning applications put even\nhigher demand on fast convolution. The high computation throughput and memory\nbandwidth of graphics processing units (GPUs) make GPUs a natural choice for\naccelerating convolution operations. However, maximally exploiting the\navailable memory bandwidth of GPUs for convolution is a challenging task. This\npaper introduces a general model to address the mismatch between the memory\nbank width of GPUs and computation data width of threads. Based on this model,\nwe develop two convolution kernels, one for the general case and the other for\na special case with one input channel. By carefully optimizing memory access\npatterns and computation patterns, we design a communication-optimized kernel\nfor the special case and a communication-reduced kernel for the general case.\nExperimental data based on implementations on Kepler GPUs show that our kernels\nachieve 5.16X and 35.5% average performance improvement over the latest cuDNN\nlibrary, for the special case and the general case, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 14:52:42 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Chen", "Xiaoming", ""], ["Chen", "Jianxu", ""], ["Chen", "Danny Z.", ""], ["Hu", "Xiaobo Sharon", ""]]}, {"id": "1705.10633", "submitter": "Tom Vander Aa", "authors": "Tom Vander Aa, Imen Chakroun and Tom Haber", "title": "Distributed Matrix Factorization using Asynchrounous Communication", "comments": "arXiv admin note: substantial text overlap with arXiv:1705.04159", "journal-ref": null, "doi": "10.1016/j.procs.2017.05.009", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using the matrix factorization technique in machine learning is very common\nmainly in areas like recommender systems. Despite its high prediction accuracy\nand its ability to avoid over-fitting of the data, the Bayesian Probabilistic\nMatrix Factorization algorithm (BPMF) has not been widely used on large scale\ndata because of the prohibitive cost. In this paper, we propose a distributed\nhigh-performance parallel implementation of the BPMF using Gibbs sampling on\nshared and distributed architectures. We show by using efficient load balancing\nusing work stealing on a single node, and by using asynchronous communication\nin the distributed version we beat state of the art implementations.\n", "versions": [{"version": "v1", "created": "Mon, 29 May 2017 08:24:10 GMT"}], "update_date": "2017-05-31", "authors_parsed": [["Aa", "Tom Vander", ""], ["Chakroun", "Imen", ""], ["Haber", "Tom", ""]]}, {"id": "1705.10826", "submitter": "Dorota Osula", "authors": "Dorota Osula", "title": "Minimizing the Cost of Team Exploration", "comments": "25 pages, 4 figures, 5 pseudo-codes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A group of mobile agents is given a task to explore an edge-weighted graph\n$G$, i.e., every vertex of $G$ has to be visited by at least one agent. There\nis no centralized unit to coordinate their actions, but they can freely\ncommunicate with each other. The goal is to construct a deterministic strategy\nwhich allows agents to complete their task optimally. In this paper we are\ninterested in a cost-optimal strategy, where the cost is understood as the\ntotal distance traversed by agents coupled with the cost of invoking them. Two\ngraph classes are analyzed, rings and trees, in the off-line and on-line\nsetting, i.e., when a structure of a graph is known and not known to agents in\nadvance. We present algorithms that compute the optimal solutions for a given\nring and tree of order $n$, in $O(n)$ time units. For rings in the on-line\nsetting, we give the $2$-competitive algorithm and prove the lower bound of\n$3/2$ for the competitive ratio for any on-line strategy. For every strategy\nfor trees in the on-line setting, we prove the competitive ratio to be no less\nthan $2$, which can be achieved by the $DFS$ algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 30 May 2017 19:12:42 GMT"}, {"version": "v2", "created": "Tue, 19 Feb 2019 14:52:23 GMT"}], "update_date": "2019-02-20", "authors_parsed": [["Osula", "Dorota", ""]]}, {"id": "1705.10948", "submitter": "Shaoshan Liu", "authors": "Jie Tang, Shaoshan Liu, Chao Wang, Quan Wang", "title": "Distributed Simulation Platform for Autonomous Driving", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autonomous vehicle safety and reliability are the paramount requirements when\ndeveloping autonomous vehicles. These requirements are guaranteed by massive\nfunctional and performance tests. Conducting these tests on real vehicles is\nextremely expensive and time consuming, and thus it is imperative to develop a\nsimulation platform to perform these tasks. For simulation, we can utilize the\nRobot Operating System (ROS) for data playback to test newly developed\nalgorithms. However, due to the massive amount of simulation data, performing\nsimulation on single machines is not practical. Hence, a high-performance\ndistributed simulation platform is a critical piece in autonomous driving\ndevelopment. In this paper we present our experiences of building a production\ndistributed autonomous driving simulation platform. This platform is built upon\nSpark distributed framework, for distributed computing management, and ROS, for\ndata playback simulations.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 05:51:08 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Tang", "Jie", ""], ["Liu", "Shaoshan", ""], ["Wang", "Chao", ""], ["Wang", "Quan", ""]]}, {"id": "1705.11046", "submitter": "Zhijie Ren", "authors": "Zhijie Ren, Kelong Cong, Johan Pouwelse, Zekeriya Erkin", "title": "Implicit Consensus: Blockchain with Unbounded Throughput", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the blockchain technique was put in the spotlight as it introduced\na systematic approach for multiple parties to reach consensus without needing\ntrust. However, the application of this technique in practice is severely\nrestricted due to its limitations in throughput. In this paper, we propose a\nnovel consensus model, namely the implicit consensus, with a distinctive\nblockchain-based distributed ledger in which each node holds its individual\nblockchain. In our system, the consensus is not on the transactions, but on a\nspecial type of blocks called Check Points that are used to validate individual\ntransactions. Our system exploits the ideas of self-interest and spontaneous\nsharding and achieves unbounded throughput with the transaction reliability\nthat equivalent to traditional Byzantine fault tolerance schemes.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 11:54:44 GMT"}, {"version": "v2", "created": "Thu, 1 Jun 2017 10:07:45 GMT"}, {"version": "v3", "created": "Fri, 14 Jul 2017 07:40:08 GMT"}], "update_date": "2017-07-17", "authors_parsed": [["Ren", "Zhijie", ""], ["Cong", "Kelong", ""], ["Pouwelse", "Johan", ""], ["Erkin", "Zekeriya", ""]]}, {"id": "1705.11147", "submitter": "Aydin Buluc", "authors": "Evangelos Georganas, Steven Hofmeyr, Rob Egan, Aydin Buluc, Leonid\n  Oliker, Daniel Rokhsar, Katherine Yelick", "title": "Extreme-Scale De Novo Genome Assembly", "comments": "To appear as a chapter in Exascale Scientific Applications:\n  Programming Approaches for Scalability, Performance, and Portability,\n  Straatsma, Antypas, Williams (editors), CRC Press, 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De novo whole genome assembly reconstructs genomic sequence from short,\noverlapping, and potentially erroneous DNA segments and is one of the most\nimportant computations in modern genomics. This work presents HipMER, a\nhigh-quality end-to-end de novo assembler designed for extreme scale analysis,\nvia efficient parallelization of the Meraculous code. Genome assembly software\nhas many components, each of which stresses different components of a computer\nsystem. This chapter explains the computational challenges involved in each\nstep of the HipMer pipeline, the key distributed data structures, and\ncommunication costs in detail. We present performance results of assembling the\nhuman genome and the large hexaploid wheat genome on large supercomputers up to\ntens of thousands of cores.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 15:34:36 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Georganas", "Evangelos", ""], ["Hofmeyr", "Steven", ""], ["Egan", "Rob", ""], ["Buluc", "Aydin", ""], ["Oliker", "Leonid", ""], ["Rokhsar", "Daniel", ""], ["Yelick", "Katherine", ""]]}]