[{"id": "0906.0065", "submitter": "Serguei Mokhov", "authors": "Serguei A. Mokhov, Lee Wei Huynh, Jian Li (Concordia University,\n  Montreal, Canada)", "title": "Managing Distributed MARF with SNMP", "comments": "39 pages, 16 figures, TOC, index. A large portion of this report has\n  been published at PDPTA'08. This 2007 report is a successor of the original\n  DMARF work documented at arXiv:0905.2459 ; v2 adds missing .ind file for the\n  index", "journal-ref": "Proceedings of PDPTA'08 (2008), Volume 2, pp. 948-954", "doi": null, "report-no": null, "categories": "cs.DC cs.CV", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The scope of this project's work focuses on the research and prototyping of\nthe extension of the Distributed MARF such that its services can be managed\nthrough the most popular management protocol familiarly, SNMP. The rationale\nbehind SNMP vs. MARF's proprietary management protocols, is that can be\nintegrated with the use of common network service and device management, so the\nadministrators can manage MARF nodes via a already familiar protocol, as well\nas monitor their performance, gather statistics, set desired configuration,\netc. perhaps using the same management tools they've been using for other\nnetwork devices and application servers.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2009 06:42:55 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2009 23:00:45 GMT"}], "update_date": "2009-07-27", "authors_parsed": [["Mokhov", "Serguei A.", "", "Concordia University,\n  Montreal, Canada"], ["Huynh", "Lee Wei", "", "Concordia University,\n  Montreal, Canada"], ["Li", "Jian", "", "Concordia University,\n  Montreal, Canada"]]}, {"id": "0906.0281", "submitter": "L.T. Handoko", "authors": "I. Firmansyah, Z. Akbar, L.T. Handoko", "title": "Microcontroller based distributed and networked control system for\n  public cluster", "comments": "4 pages, Proceeding of the International Conference on Quality in\n  Research 2009", "journal-ref": null, "doi": null, "report-no": "FISIKALIPI-09022", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the architecture and application of the distributed control in\npublic cluster, a parallel machine which is open for public access. Following\nthe nature of public cluster, the integrated distributed control system is\nfully accessible through network using a user-friendly web interface. The\nsystem is intended mainly to control the power of each node in a block of\nparallel computers provided to certain users. This is especially important to\nextend the life-time of related hardwares, and to reduce the whole running and\nmaintainance costs. The system consists of two parts : the master- and\nnode-controllers, and both are connected each other through RS-485 interface.\nEach node-controller is assigned with a unique address to distinguish each of\nthem. We also discuss briefly the implementation of the system at the LIPI\nPublic Cluster.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2009 13:25:21 GMT"}], "update_date": "2009-06-02", "authors_parsed": [["Firmansyah", "I.", ""], ["Akbar", "Z.", ""], ["Handoko", "L. T.", ""]]}, {"id": "0906.0350", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Eliana-Dina Tirsa, Nicolae Tapus, Florin Pop,\n  Ciprian Mihai Dobre", "title": "Towards a Centralized Scheduling Framework for Communication Flows in\n  Distributed Systems", "comments": null, "journal-ref": "Proceedings of the 17th International Conference on Control\n  Systems and Computer Science (CSCS), vol. 1, pp. 441-448, Bucharest, Romania,\n  26-29 May, 2009. (ISSN: 2066-4451)", "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The overall performance of a distributed system is highly dependent on the\ncommunication efficiency of the system. Although network resources (links,\nbandwidth) are becoming increasingly more available, the communication\nperformance of data transfers involving large volumes of data does not\nnecessarily improve at the same rate. This is due to the inefficient usage of\nthe available network resources. A solution to this problem consists of data\ntransfer scheduling techniques, which manage and allocate the network resources\nin an efficient manner. In this paper we present several online and offline\ndata transfer optimization techniques, in the context of a centrally controlled\ndistributed system.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2009 19:30:03 GMT"}], "update_date": "2009-06-02", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Tirsa", "Eliana-Dina", ""], ["Tapus", "Nicolae", ""], ["Pop", "Florin", ""], ["Dobre", "Ciprian Mihai", ""]]}, {"id": "0906.0376", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Eliana-Dina Tirsa, Alexandru Costan, Nicolae\n  Tapus", "title": "Offline Algorithms for Several Network Design, Clustering and QoS\n  Optimization Problems", "comments": null, "journal-ref": "Proceedings of the 17th International Conference on Control\n  Systems and Computer Science (CSCS), vol. 1, pp. 273-280, Bucharest, Romania,\n  26-29 May, 2009. (ISSN: 2066-4451)", "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address several network design, clustering and Quality of\nService (QoS) optimization problems and present novel, efficient, offline\nalgorithms which compute optimal or near-optimal solutions. The QoS\noptimization problems consist of reliability improvement (by computing backup\nshortest paths) and network link upgrades (in order to reduce the latency on\nseveral paths). The network design problems consist of determining small\ndiameter networks, as well as very well connected and regular network\ntopologies. The network clustering problems consider only the restricted model\nof static and mobile path networks, for which we were able to develop optimal\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2009 20:31:10 GMT"}], "update_date": "2009-06-03", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Tirsa", "Eliana-Dina", ""], ["Costan", "Alexandru", ""], ["Tapus", "Nicolae", ""]]}, {"id": "0906.0379", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Eliana-Dina Tirsa, Nicolae Tapus", "title": "Data Distribution Optimization using Offline Algorithms and a\n  Peer-to-Peer Small Diameter Tree Architecture with Bounded Node Degrees", "comments": null, "journal-ref": "Proc. of the 17th Intl. Conf. on Control Systems and Computer\n  Science (CSCS), vol. 2, pp. 445-452, 2009 (3rd Intl. Workshop on High\n  Performance Grid Middleware - HiPerGrid). (ISSN: 2066-4451)", "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multicast data transfers occur in many distributed systems and applications\n(e.g. IPTV, Grids, content delivery networks). Because of this, efficient\nmulticast data distribution optimization techniques are required. In the first\npart of this paper we present a small diameter, bounded degree, collaborative\npeer-to-peer multicast tree architecture, which supports dynamic node arrivals\nand departures making local decisions only. The architecture is fault tolerant\nand, at low arrival and departure rates, converges towards a theoretically\noptimal structure. In the second part of the paper we consider several offline\ndata distribution optimization problems, for which we present novel and\ntime-efficient algorithmic solutions.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2009 21:07:18 GMT"}], "update_date": "2009-06-03", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Tirsa", "Eliana-Dina", ""], ["Tapus", "Nicolae", ""]]}, {"id": "0906.0651", "submitter": "Maria Potop-Butucaru", "authors": "Zohir Bouzid (LIP6), Maria Potop-Butucaru (LIP6, INRIA Rocquencourt),\n  S\\'ebastien Tixeuil (LIP6, INRIA Futurs)", "title": "Optimal Byzantine Resilient Convergence in Asynchronous Robot Networks", "comments": null, "journal-ref": null, "doi": "10.1007/978-3-642-05118-0_12", "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose the first deterministic algorithm that tolerates up to $f$\nbyzantine faults in $3f+1$-sized networks and performs in the asynchronous\nCORDA model. Our solution matches the previously established lower bound for\nthe semi-synchronous ATOM model on the number of tolerated Byzantine robots.\nOur algorithm works under bounded scheduling assumptions for oblivious robots\nmoving in a uni-dimensional space.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2009 06:39:38 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Bouzid", "Zohir", "", "LIP6"], ["Potop-Butucaru", "Maria", "", "LIP6, INRIA Rocquencourt"], ["Tixeuil", "S\u00e9bastien", "", "LIP6, INRIA Futurs"]]}, {"id": "0906.0731", "submitter": "Paul Vitanyi", "authors": "Paul M.B. Vitanyi (CWI, Amsterdam)", "title": "Distributed elections in an Archimedean ring of processors", "comments": null, "journal-ref": "16th ACM Symposium on Theory of Computing, Washington D.C., 1984,\n  542 - 547", "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unlimited asynchronism is intolerable in real physically distributed computer\nsystems. Such systems, synchronous or not, use clocks and timeouts. Therefore\nthe magnitudes of elapsed absolute time in the system need to satisfy the axiom\nof Archimedes. Under this restriction of asynchronicity logically\ntime-independent solutions can be derived which are nonetheless better (in\nnumber of message passes) than is possible otherwise. The use of clocks by the\nindividual processors, in elections in a ring of asynchronous processors\nwithout central control, allows a deterministic solution which requires but a\nlinear number of message passes. To obtain the result it has to be assumed that\nthe clocks measure finitely proportional absolute time-spans for their time\nunits, that is, the magnitudes of elapsed time in the ring network satisfy the\naxiom of Archimedes. As a result, some basic subtilities associated with\ndistributed computations are highlighted. For instance, the known nonlinear\nlower bound on the required number of message passes is cracked. For the\nsynchronous case, in which the necessary assumptions hold a fortiori, the\nmethod is -asymptotically- the most efficient one yet, and of optimal order of\nmagnitude. The deterministic algorithm is of -asymptotically- optimal bit\ncomplexity, and, in the synchronous case, also yields an optimal method to\ndetermine the ring size. All of these results improve the known ones.\n", "versions": [{"version": "v1", "created": "Wed, 27 May 2009 16:07:56 GMT"}], "update_date": "2009-06-04", "authors_parsed": [["Vitanyi", "Paul M. B.", "", "CWI, Amsterdam"]]}, {"id": "0906.1147", "submitter": "Omer Khalid Mr", "authors": "Omer Khalid, Richard Anthony, Paul Nillson, Kate Keahey, Markus\n  Schulz, Miltos Petridis, Kevin Parrott", "title": "Enabling and Optimizing Pilot Jobs using Xen based Virtual Machines for\n  the HPC Grid Applications", "comments": "8 pages; Published in VTDC09 workshop which is part of IEEE ICAC09\n  Conference", "journal-ref": "Khalid O. et al, Enabling and Optimizing Pilot Jobs using Xen\n  Virtual Machines for HPC Grid Applications,. International Workshop on\n  Virtualiztion Technologies and Distributed Computing, ICAC 09, 2009", "doi": "10.1145/1555336.1555338", "report-no": null, "categories": "cs.DC cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary motivation for uptake of virtualization have been resource\nisolation, capacity management and resource customization: isolation and\ncapacity management allow providers to isolate users from the site and control\ntheir resources usage while customization allows end-users to easily project\nthe required environment onto a variety of sites. Various approaches have been\ntaken to integrate virtualization with Grid technologies. In this paper, we\npropose an approach that combines virtualization on the existing software\ninfrastructure such as Pilot Jobs with minimum change on the part of resource\nproviders.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jun 2009 15:26:14 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Khalid", "Omer", ""], ["Anthony", "Richard", ""], ["Nillson", "Paul", ""], ["Keahey", "Kate", ""], ["Schulz", "Markus", ""], ["Petridis", "Miltos", ""], ["Parrott", "Kevin", ""]]}, {"id": "0906.1326", "submitter": "Jianfeng Zhan", "authors": "Xu Liu, Jianfeng Zhan, Bibo Tu, Ming Zou, Dan Meng", "title": "Similarity Analysis in Automatic Performance Debugging of SPMD Parallel\n  Programs", "comments": "http://iss.ices.utexas.edu/sc08nlplss/program.html", "journal-ref": "Supercomputing 2008 Workshop on Node Level Parallelism for Large\n  Scale Supercomputers", "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different from sequential programs, parallel programs possess their own\ncharacteristics which are difficult to analyze in the multi-process or\nmulti-thread environment. This paper presents an innovative method to\nautomatically analyze the SPMD programs. Firstly, with the help of clustering\nmethod focusing on similarity analysis, an algorithm is designed to locate\nperformance problems in parallel programs automatically. Secondly a Rough Set\nmethod is used to uncover the performance problem and provide the insight into\nthe micro-level causes. Lastly, we have analyzed a production parallel\napplication to verify the effectiveness of our method and system.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2009 05:45:57 GMT"}], "update_date": "2009-06-09", "authors_parsed": [["Liu", "Xu", ""], ["Zhan", "Jianfeng", ""], ["Tu", "Bibo", ""], ["Zou", "Ming", ""], ["Meng", "Dan", ""]]}, {"id": "0906.1328", "submitter": "Jianfeng Zhan", "authors": "Wei Zhou, Jianfeng Zhan, Dan Meng", "title": "Multidimensional Analysis of System Logs in Large-scale Cluster Systems", "comments": null, "journal-ref": "The Proceeding of 38th Annual IEEE/IFIP International Conference\n  on Dependable Systems and Networks (DSN 2008), Fast abstract", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is effective to improve the reliability and availability of large-scale\ncluster systems through the analysis of failures. Existed failure analysis\nmethods understand and analyze failures from one or few dimension. The analysis\nresults are partial and with less precision because of the limitation of data\nsource. This paper presents multidimensional analysis based on graph mining to\nanalyze multi-source system logs, which is a promising failure analysis method\nto get more complete and precise failure knowledge.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2009 06:03:14 GMT"}], "update_date": "2009-06-09", "authors_parsed": [["Zhou", "Wei", ""], ["Zhan", "Jianfeng", ""], ["Meng", "Dan", ""]]}, {"id": "0906.1346", "submitter": "Jianfeng Zhan", "authors": "Jianfeng Zhan, Lei Wang, Bibo Tu, Yong Li, Peng Wang, Wei Zhou, Dan\n  Meng", "title": "Phoenix Cloud: Consolidating Different Computing Loads on Shared Cluster\n  System for Large Organization", "comments": "5 page, 8 figures, The First Workshop of Cloud Computing and its\n  Application, The modified version. The original version is on the web site of\n  http://www.cca08.org/, which is dated from August 13, 2008", "journal-ref": "The first workshop of cloud computing and its application (CCA\n  08), Chicago, 2008", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different departments of a large organization often run dedicated cluster\nsystems for different computing loads, like HPC (high performance computing)\njobs or Web service applications. In this paper, we have designed and\nimplemented a cloud management system software Phoenix Cloud to consolidate\nheterogeneous workloads from different departments affiliated to the same\norganization on the shared cluster system. We have also proposed cooperative\nresource provisioning and management policies for a large organization and its\naffiliated departments, running HPC jobs and Web service applications, to share\nthe consolidated cluster system. The experiments show that in comparison with\nthe case that each department operates its dedicated cluster system, Phoenix\nCloud significantly decreases the scale of the required cluster system for a\nlarge organization, improves the benefit of the scientific computing\ndepartment, and at the same time provisions enough resources to the other\ndepartment running Web services with varying loads.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2009 10:15:28 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2010 07:59:05 GMT"}, {"version": "v3", "created": "Wed, 24 Mar 2010 06:01:45 GMT"}, {"version": "v4", "created": "Tue, 6 Apr 2010 23:03:03 GMT"}, {"version": "v5", "created": "Thu, 15 Jul 2010 00:13:39 GMT"}, {"version": "v6", "created": "Sat, 17 Jul 2010 00:03:21 GMT"}], "update_date": "2010-07-20", "authors_parsed": [["Zhan", "Jianfeng", ""], ["Wang", "Lei", ""], ["Tu", "Bibo", ""], ["Li", "Yong", ""], ["Wang", "Peng", ""], ["Zhou", "Wei", ""], ["Meng", "Dan", ""]]}, {"id": "0906.1947", "submitter": "Sebastien Tixeuil", "authors": "Mikhail Nesterenko, S\\'ebastien Tixeuil (LIP6)", "title": "Ideal Stabilization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define and explore the concept of ideal stabilization. The program is\nideally stabilizing if its every state is legitimate. Ideal stabilization\nallows the specification designer to prescribe with arbitrary degree of\nprecision not only the fault-free program behavior but also its recovery\noperation. Specifications may or may not mention all possible states. We\nidentify approaches to designing ideal stabilization to both kinds of\nspecifications. For the first kind, we state the necessary condition for an\nideally stabilizing solution. On the basis of this condition we prove that\nthere is no ideally stabilizing solution to the leader election problem. We\nillustrate the utility of the concept by providing examples of well-known\nprograms and proving them ideally stabilizing. Specifically, we prove ideal\nstabilization of the conflict manager, the alternator, the propagation of\ninformation with feedback and the alternating bit protocol.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2009 14:31:18 GMT"}], "update_date": "2009-06-11", "authors_parsed": [["Nesterenko", "Mikhail", "", "LIP6"], ["Tixeuil", "S\u00e9bastien", "", "LIP6"]]}, {"id": "0906.2143", "submitter": "Andrea Manara", "authors": "J. T. Moscicki, A. Manara, M. Lamanna, P. Mendez, A. Muraru", "title": "Dependable Distributed Computing for the International Telecommunication\n  Union Regional Radio Conference RRC06", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The International Telecommunication Union (ITU) Regional Radio Conference\n(RRC06) established in 2006 a new frequency plan for the introduction of\ndigital broadcasting in European, African, Arab, CIS countries and Iran. The\npreparation of the plan involved complex calculations under short deadline and\nrequired dependable and efficient computing capability. The ITU designed and\ndeployed in-situ a dedicated PC farm, in parallel to the European Organization\nfor Nuclear Research (CERN) which provided and supported a system based on the\nEGEE Grid. The planning cycle at the RRC06 required a periodic execution in the\norder of 200,000 short jobs, using several hundreds of CPU hours, in a period\nof less than 12 hours. The nature of the problem required dynamic\nworkload-balancing and low-latency access to the computing resources. We\npresent the strategy and key technical choices that delivered a reliable\nservice to the RRC06.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jun 2009 16:04:12 GMT"}], "update_date": "2009-06-12", "authors_parsed": [["Moscicki", "J. T.", ""], ["Manara", "A.", ""], ["Lamanna", "M.", ""], ["Mendez", "P.", ""], ["Muraru", "A.", ""]]}, {"id": "0906.2914", "submitter": "Michal Zerola", "authors": "Michal Zerola, J\\'er\\^ome Lauret, Roman Bart\\'ak and Michal\n  \\v{S}umbera", "title": "Efficient Multi-site Data Movement Using Constraint Programming for Data\n  Hungry Science", "comments": "To appear in proceedings of Computing in High Energy and Nuclear\n  Physics 2009", "journal-ref": null, "doi": "10.1088/1742-6596/219/6/062069", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the past decade, HENP experiments have been heading towards a distributed\ncomputing model in an effort to concurrently process tasks over enormous data\nsets that have been increasing in size as a function of time. In order to\noptimize all available resources (geographically spread) and minimize the\nprocessing time, it is necessary to face also the question of efficient data\ntransfers and placements. A key question is whether the time penalty for moving\nthe data to the computational resources is worth the presumed gain. Onward to\nthe truly distributed task scheduling we present the technique using a\nConstraint Programming (CP) approach. The CP technique schedules data transfers\nfrom multiple resources considering all available paths of diverse\ncharacteristic (capacity, sharing and storage) having minimum user's waiting\ntime as an objective. We introduce a model for planning data transfers to a\nsingle destination (data transfer) as well as its extension for an optimal data\nset spreading strategy (data placement). Several enhancements for a solver of\nthe CP model will be shown, leading to a faster schedule computation time using\nsymmetry breaking, branch cutting, well studied principles from job-shop\nscheduling field and several heuristics. Finally, we will present the design\nand implementation of a corner-stone application aimed at moving datasets\naccording to the schedule. Results will include comparison of performance and\ntrade-off between CP techniques and a Peer-2-Peer model from simulation\nframework as well as the real case scenario taken from a practical usage of a\nCP scheduler.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2009 12:33:25 GMT"}, {"version": "v2", "created": "Thu, 18 Jun 2009 19:20:05 GMT"}], "update_date": "2015-05-13", "authors_parsed": [["Zerola", "Michal", ""], ["Lauret", "J\u00e9r\u00f4me", ""], ["Bart\u00e1k", "Roman", ""], ["\u0160umbera", "Michal", ""]]}, {"id": "0906.3394", "submitter": "Maziar Nekovee", "authors": "Maziar Nekovee", "title": "Quantifying the Availability of TV White Spaces for Cognitive Radio\n  Operation in the UK", "comments": "Extended version is available from the author", "journal-ref": "In Proc. IEEE ICC joint Workshop Cognitive Wireless Networks and\n  Systems, Dresden, Germany, June 2009", "doi": "10.1109/ICCW.2009.5208035", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cognitive radio is being intensively researched for opportunistic access to\nthe so-called TV White Spaces (TVWS): large portions of the VHF/UHF TV bands\nwhich become available on a geographical basis after the digital switchover.\nUsing accurate digital TV (DTV) coverage maps together with a database of DTV\ntransmitters, we develop a methodology for identifying TVWS frequencies at any\ngiven location in the United Kingdom. We use our methodology to investigate\nvariations in TVWS as a function of the location and transmit power of\ncognitive radios, and examine how constraints on adjacent channel interference\nimposed by regulators may affect the results. Our analysis provides a realistic\nview on the spectrum opportunity associated with cognitive devices, and\npresents the first quantitative study of the availability and frequency\ncomposition of TWVS outside the United States.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2009 09:54:20 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Nekovee", "Maziar", ""]]}, {"id": "0906.3424", "submitter": "Ziyuan Wang", "authors": "Ziyuan Wang, Lars Kulik, Kotagiri Ramamohanarao", "title": "Decentralized Traffic Management Strategies for Sensor-Enabled Cars", "comments": null, "journal-ref": null, "doi": null, "report-no": "SUM-06-07", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traffic Congestions and accidents are major concerns in today's\ntransportation systems. This thesis investigates how to optimize traffic flow\non highways, in particular for merging situations such as intersections where a\nramp leads onto the highway. In our work, cars are equipped with sensors that\ncan detect distance to neighboring cars, and communicate their velocity and\nacceleration readings with one another. Sensor-enabled cars can locally\nexchange sensed information about the traffic and adapt their behavior much\nearlier than regular cars.\n  We propose proactive algorithms for merging different streams of\nsensor-enabled cars into a single stream. A proactive merging algorithm\ndecouples the decision point from the actual merging point. Sensor-enabled cars\nallow us to decide where and when a car merges before it arrives at the actual\nmerging point. This leads to a significant improvement in traffic flow as\nvelocities can be adjusted appropriately. We compare proactive merging\nalgorithms against the conventional priority-based merging algorithm in a\ncontrolled simulation environment. Experiment results show that proactive\nmerging algorithms outperform the priority-based merging algorithm in terms of\nflow and delay.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2009 12:16:06 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Wang", "Ziyuan", ""], ["Kulik", "Lars", ""], ["Ramamohanarao", "Kotagiri", ""]]}, {"id": "0906.3483", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Nicolae Tapus", "title": "Efficient Offline Algorithmic Techniques for Several Packet Routing\n  Problems in Distributed Systems", "comments": null, "journal-ref": "Acta Universitatis Apulensis - Mathematics-Informatics, no. 18,\n  pp. 111-128, 2009. (ISSN: 1582-5329)", "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider several problems concerning packet routing in\ndistributed systems. Each problem is formulated using terms from Graph Theory\nand for each problem we present efficient, novel, algorithmic techniques for\ncomputing optimal solutions. We address topics like: bottleneck paths (trees),\noptimal paths with non-linear costs, optimal paths with multiple optimization\nobjectives, maintaining aggregate connectivity information under a sequence of\nnetwork link failures, and several others.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2009 17:38:39 GMT"}], "update_date": "2009-06-19", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Tapus", "Nicolae", ""]]}, {"id": "0906.3846", "submitter": "Michael Schapira", "authors": "Yi Wang, Michael Schapira, Jennifer Rexford", "title": "Neighbor-Specific BGP: More Flexible Routing Policies While Improving\n  Global Stability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Please Note: This document was written to summarize and facilitate discussion\nregarding (1) the benefits of changing the way BGP selects routes to selecting\nthe most preferred route allowed by export policies, or more generally, to\nselecting BGP routes on a per-neighbor basis, (2) the safety condition that\nguarantees global routing stability under the Neighbor-Specific BGP model, and\n(3) ways of deploying this model in practice. A paper presenting the formal\nmodel and proof of the stability conditions was published at SIGMETRICS 2009\nand is available online.\n", "versions": [{"version": "v1", "created": "Sun, 21 Jun 2009 04:58:23 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Wang", "Yi", ""], ["Schapira", "Michael", ""], ["Rexford", "Jennifer", ""]]}, {"id": "0906.3920", "submitter": "EPTCS", "authors": "Claudio Guidi, Fabrizio Montesi", "title": "Reasoning About a Service-oriented Programming Paradigm", "comments": null, "journal-ref": "EPTCS 2, 2009, pp. 67-81", "doi": "10.4204/EPTCS.2.6", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is about a new way for programming distributed applications: the\nservice-oriented one. It is a concept paper based upon our experience in\ndeveloping a theory and a language for programming services. Both the\ntheoretical formalization and the language interpreter showed us the evidence\nthat a new programming paradigm exists. In this paper we illustrate the basic\nfeatures it is characterized by.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2009 05:49:12 GMT"}], "update_date": "2009-06-23", "authors_parsed": [["Guidi", "Claudio", ""], ["Montesi", "Fabrizio", ""]]}, {"id": "0906.4154", "submitter": "Oliver Obst", "authors": "Oliver Obst", "title": "Distributed Fault Detection in Sensor Networks using a Recurrent Neural\n  Network", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In long-term deployments of sensor networks, monitoring the quality of\ngathered data is a critical issue. Over the time of deployment, sensors are\nexposed to harsh conditions, causing some of them to fail or to deliver less\naccurate data. If such a degradation remains undetected, the usefulness of a\nsensor network can be greatly reduced. We present an approach that learns\nspatio-temporal correlations between different sensors, and makes use of the\nlearned model to detect misbehaving sensors by using distributed computation\nand only local communication between nodes. We introduce SODESN, a distributed\nrecurrent neural network architecture, and a learning method to train SODESN\nfor fault detection in a distributed scenario. Our approach is evaluated using\ndata from different types of sensors and is able to work well even with\nless-than-perfect link qualities and more than 50% of failed nodes.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2009 01:54:55 GMT"}], "update_date": "2009-12-05", "authors_parsed": [["Obst", "Oliver", ""]]}, {"id": "0906.4302", "submitter": "Ahmed Mihoob Mr", "authors": "Ahmed Mihoob, Carlos Molina-Jimenez (School Of Computing Science,\n  University Of Newcastle, UK)", "title": "A Peer to Peer Protocol for Online Dispute Resolution over Storage\n  Consumption", "comments": "12 pages, 7 figures", "journal-ref": "EPTCS 2, 2009, pp. 3-14", "doi": "10.4204/EPTCS.2.1", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In bilateral accounting of resource consumption both the consumer and\nprovider independently measure the amount of resources consumed by the\nconsumer. The problem here is that potential disparities between the provider's\nand consumer's accountings, might lead to conflicts between the two parties\nthat need to be resolved. We argue that with the proper mechanisms available,\nmost of these conflicts can be solved online, as opposite to in court\nresolution; the design of such mechanisms is still a research topic; to help\ncover the gap, in this paper we propose a peer--to--peer protocol for online\ndispute resolution over storage consumption. The protocol is peer--to--peer and\ntakes into consideration the possible causes (e.g, transmission delays,\nunsynchronized metric collectors, etc.) of the disparity between the provider's\nand consumer's accountings to make, if possible, the two results converge.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2009 16:30:51 GMT"}], "update_date": "2009-06-24", "authors_parsed": [["Mihoob", "Ahmed", "", "School Of Computing Science,\n  University Of Newcastle, UK"], ["Molina-Jimenez", "Carlos", "", "School Of Computing Science,\n  University Of Newcastle, UK"]]}, {"id": "0906.4680", "submitter": "Olivier Passalacqua", "authors": "Eric Benoit (LISTIC), Marc-Philippe Huget (LISTIC), Patrice Moreaux\n  (LISTIC), Olivier Passalacqua (LISTIC)", "title": "Reconfiguration of Distributed Information Fusion System ? A case study", "comments": "6 pages - Preprint version", "journal-ref": "Workshop on Dependable Control of Discrete Systems, Bari : Italie\n  (2009)", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information Fusion Systems are now widely used in different fusion contexts,\nlike scientific processing, sensor networks, video and image processing. One of\nthe current trends in this area is to cope with distributed systems. In this\ncontext, we have defined and implemented a Dynamic Distributed Information\nFusion System runtime model. It allows us to cope with dynamic execution\nsupports while trying to maintain the functionalities of a given Dynamic\nDistributed Information Fusion System. The paper presents our system, the\nreconfiguration problems we are faced with and our solutions.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2009 12:35:57 GMT"}], "update_date": "2009-06-26", "authors_parsed": [["Benoit", "Eric", "", "LISTIC"], ["Huget", "Marc-Philippe", "", "LISTIC"], ["Moreaux", "Patrice", "", "LISTIC"], ["Passalacqua", "Olivier", "", "LISTIC"]]}, {"id": "0906.4837", "submitter": "Serguei Mokhov", "authors": "Bin Han, Serguei A. Mokhov, and Joey Paquet", "title": "Advances in the Design and Implementation of a Multi-Tier Architecture\n  in the GIPSY Environment", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": "10.1109/SERA.2010.40", "report-no": null, "categories": "cs.SE cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present advances in the software engineering design and implementation of\nthe multi-tier run-time system for the General Intensional Programming System\n(GIPSY) by further unifying the distributed technologies used to implement the\nDemand Migration Framework (DMF) in order to streamline distributed execution\nof hybrid intensional-imperative programs using Java.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2009 04:08:05 GMT"}], "update_date": "2010-07-09", "authors_parsed": [["Han", "Bin", ""], ["Mokhov", "Serguei A.", ""], ["Paquet", "Joey", ""]]}, {"id": "0906.5007", "submitter": "Ali Parandehgheibi", "authors": "Daron Acemoglu, Asuman Ozdaglar, Ali ParandehGheibi", "title": "Spread of Misinformation in Social Networks", "comments": "Submitted to Games and Economic Behavior", "journal-ref": null, "doi": null, "report-no": "LIDS report 2812", "categories": "cs.IT cs.DC math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide a model to investigate the tension between information aggregation\nand spread of misinformation in large societies (conceptualized as networks of\nagents communicating with each other). Each individual holds a belief\nrepresented by a scalar. Individuals meet pairwise and exchange information,\nwhich is modeled as both individuals adopting the average of their pre-meeting\nbeliefs. When all individuals engage in this type of information exchange, the\nsociety will be able to effectively aggregate the initial information held by\nall individuals. There is also the possibility of misinformation, however,\nbecause some of the individuals are \"forceful,\" meaning that they influence the\nbeliefs of (some) of the other individuals they meet, but do not change their\nown opinion. The paper characterizes how the presence of forceful agents\ninterferes with information aggregation. Under the assumption that even\nforceful agents obtain some information (however infrequent) from some others\n(and additional weak regularity conditions), we first show that beliefs in this\nclass of societies converge to a consensus among all individuals. This\nconsensus value is a random variable, however, and we characterize its\nbehavior. Our main results quantify the extent of misinformation in the society\nby either providing bounds or exact results (in some special cases) on how far\nthe consensus value can be from the benchmark without forceful agents (where\nthere is efficient information aggregation). The worst outcomes obtain when\nthere are several forceful agents and forceful agents themselves update their\nbeliefs only on the basis of information they obtain from individuals most\nlikely to have received their own information previously.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2009 20:57:55 GMT"}], "update_date": "2009-06-30", "authors_parsed": [["Acemoglu", "Daron", ""], ["Ozdaglar", "Asuman", ""], ["ParandehGheibi", "Ali", ""]]}]