[{"id": "1012.0006", "submitter": "Christian Schulz", "authors": "Peter Sanders and Christian Schulz", "title": "Engineering Multilevel Graph Partitioning Algorithms", "comments": "fixed a problem with the medium sized instances", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a multi-level graph partitioning algorithm using novel local\nimprovement algorithms and global search strategies transferred from the\nmulti-grid community. Local improvement algorithms are based max-flow min-cut\ncomputations and more localized FM searches. By combining these techniques, we\nobtain an algorithm that is fast on the one hand and on the other hand is able\nto improve the best known partitioning results for many inputs. For example, in\nWalshaw's well known benchmark tables we achieve 317 improvements for the\ntables 1%, 3% and 5% imbalance. Moreover, in 118 additional cases we have been\nable to reproduce the best cut in this benchmark.\n", "versions": [{"version": "v1", "created": "Tue, 30 Nov 2010 21:01:48 GMT"}, {"version": "v2", "created": "Tue, 29 Mar 2011 14:54:48 GMT"}, {"version": "v3", "created": "Mon, 4 Apr 2011 12:08:32 GMT"}], "update_date": "2011-04-05", "authors_parsed": [["Sanders", "Peter", ""], ["Schulz", "Christian", ""]]}, {"id": "1012.0009", "submitter": "Arnaud Casteigts", "authors": "Arnaud Casteigts, Paola Flocchini, Walter Quattrociocchi, Nicola\n  Santoro", "title": "Time-Varying Graphs and Dynamic Networks", "comments": "A short version appeared in ADHOC-NOW'11. This version is to be\n  published in Internation Journal of Parallel, Emergent and Distributed\n  Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The past few years have seen intensive research efforts carried out in some\napparently unrelated areas of dynamic systems -- delay-tolerant networks,\nopportunistic-mobility networks, social networks -- obtaining closely related\ninsights. Indeed, the concepts discovered in these investigations can be viewed\nas parts of the same conceptual universe; and the formal models proposed so far\nto express some specific concepts are components of a larger formal description\nof this universe. The main contribution of this paper is to integrate the vast\ncollection of concepts, formalisms, and results found in the literature into a\nunified framework, which we call TVG (for time-varying graphs). Using this\nframework, it is possible to express directly in the same formalism not only\nthe concepts common to all those different areas, but also those specific to\neach. Based on this definitional work, employing both existing results and\noriginal observations, we present a hierarchical classification of TVGs; each\nclass corresponds to a significant property examined in the distributed\ncomputing literature. We then examine how TVGs can be used to study the\nevolution of network properties, and propose different techniques, depending on\nwhether the indicators for these properties are a-temporal (as in the majority\nof existing studies) or temporal. Finally, we briefly discuss the introduction\nof randomness in TVGs.\n", "versions": [{"version": "v1", "created": "Tue, 30 Nov 2010 21:03:42 GMT"}, {"version": "v2", "created": "Fri, 25 Feb 2011 04:16:58 GMT"}, {"version": "v3", "created": "Fri, 17 Feb 2012 20:51:42 GMT"}], "update_date": "2012-02-20", "authors_parsed": [["Casteigts", "Arnaud", ""], ["Flocchini", "Paola", ""], ["Quattrociocchi", "Walter", ""], ["Santoro", "Nicola", ""]]}, {"id": "1012.0178", "submitter": "Stefano Balietti", "authors": "Dirk Helbing and Stefano Balietti", "title": "From Social Data Mining to Forecasting Socio-Economic Crisis", "comments": "65 pages, 1 figure, Visioneer White Paper, see\n  http://www.visioneer.ethz.ch", "journal-ref": "The European Physical Journal - Special Topics Volume 195, Number\n  1, 3-68, DOI: 10.1140/epjst/e2011-01401-8", "doi": "10.1140/epjst/e2011-01401-8", "report-no": null, "categories": "cs.CY cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Socio-economic data mining has a great potential in terms of gaining a better\nunderstanding of problems that our economy and society are facing, such as\nfinancial instability, shortages of resources, or conflicts. Without\nlarge-scale data mining, progress in these areas seems hard or impossible.\nTherefore, a suitable, distributed data mining infrastructure and research\ncenters should be built in Europe. It also appears appropriate to build a\nnetwork of Crisis Observatories. They can be imagined as laboratories devoted\nto the gathering and processing of enormous volumes of data on both natural\nsystems such as the Earth and its ecosystem, as well as on human\ntechno-socio-economic systems, so as to gain early warnings of impending\nevents. Reality mining provides the chance to adapt more quickly and more\naccurately to changing situations. Further opportunities arise by individually\ncustomized services, which however should be provided in a privacy-respecting\nway. This requires the development of novel ICT (such as a self- organizing\nWeb), but most likely new legal regulations and suitable institutions as well.\nAs long as such regulations are lacking on a world-wide scale, it is in the\npublic interest that scientists explore what can be done with the huge data\navailable. Big data do have the potential to change or even threaten democratic\nsocieties. The same applies to sudden and large-scale failures of ICT systems.\nTherefore, dealing with data must be done with a large degree of responsibility\nand care. Self-interests of individuals, companies or institutions have limits,\nwhere the public interest is affected, and public interest is not a sufficient\njustification to violate human rights of individuals. Privacy is a high good,\nas confidentiality is, and damaging it would have serious side effects for\nsociety.\n", "versions": [{"version": "v1", "created": "Wed, 1 Dec 2010 12:48:38 GMT"}, {"version": "v2", "created": "Thu, 2 Dec 2010 12:32:34 GMT"}, {"version": "v3", "created": "Mon, 24 Jan 2011 17:06:59 GMT"}, {"version": "v4", "created": "Thu, 24 Feb 2011 16:03:20 GMT"}, {"version": "v5", "created": "Tue, 26 Jul 2011 09:03:41 GMT"}], "update_date": "2015-05-20", "authors_parsed": [["Helbing", "Dirk", ""], ["Balietti", "Stefano", ""]]}, {"id": "1012.0253", "submitter": "Roberto Ammendola", "authors": "Roberto Ammendola, Andrea Biagioni, Ottorino Frezza, Francesca Lo\n  Cicero, Alessandro Lonardo, Pier Paolucci, Roberto Petronzio, Davide\n  Rossetti, Andrea Salamon, Gaetano Salina, Francesco Simula, Nazario Tantalo,\n  Laura Tosoratto, Piero Vicini", "title": "APEnet+: a 3D toroidal network enabling Petaflops scale Lattice QCD\n  simulations on commodity clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-lat cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many scientific computations need multi-node parallelism for matching up both\nspace (memory) and time (speed) ever-increasing requirements. The use of GPUs\nas accelerators introduces yet another level of complexity for the programmer\nand may potentially result in large overheads due to the complex memory\nhierarchy. Additionally, top-notch problems may easily employ more than a\nPetaflops of sustained computing power, requiring thousands of GPUs\norchestrated with some parallel programming model. Here we describe APEnet+,\nthe new generation of our interconnect, which scales up to tens of thousands of\nnodes with linear cost, thus improving the price/performance ratio on large\nclusters. The project target is the development of the Apelink+ host adapter\nfeaturing a low latency, high bandwidth direct network, state-of-the-art wire\nspeeds on the links and a PCIe X8 gen2 host interface. It features hardware\nsupport for the RDMA programming model and experimental acceleration of GPU\nnetworking. A Linux kernel driver, a set of low-level RDMA APIs and an OpenMPI\nlibrary driver are available, allowing for painless porting of standard\napplications. Finally, we give an insight of future work and intended\ndevelopments.\n", "versions": [{"version": "v1", "created": "Wed, 1 Dec 2010 17:40:39 GMT"}], "update_date": "2010-12-02", "authors_parsed": [["Ammendola", "Roberto", ""], ["Biagioni", "Andrea", ""], ["Frezza", "Ottorino", ""], ["Cicero", "Francesca Lo", ""], ["Lonardo", "Alessandro", ""], ["Paolucci", "Pier", ""], ["Petronzio", "Roberto", ""], ["Rossetti", "Davide", ""], ["Salamon", "Andrea", ""], ["Salina", "Gaetano", ""], ["Simula", "Francesco", ""], ["Tantalo", "Nazario", ""], ["Tosoratto", "Laura", ""], ["Vicini", "Piero", ""]]}, {"id": "1012.0385", "submitter": "Geza Odor", "authors": "Henrik Schulz, G\\'eza \\'Odor, Gergely \\'Odor, M\\'at\\'e Ferenc Nagy", "title": "Simulation of 1+1 dimensional surface growth and lattices gases using\n  GPUs", "comments": "20 pages 12 figures, 1 table, to appear in Comp. Phys. Comm", "journal-ref": "Computer Physics Communications 182 (2011) 1467-1476", "doi": "10.1016/j.cpc.2011.03.016", "report-no": null, "categories": "physics.comp-ph cond-mat.dis-nn cond-mat.stat-mech cs.DC nlin.CG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Restricted solid on solid surface growth models can be mapped onto binary\nlattice gases. We show that efficient simulation algorithms can be realized on\nGPUs either by CUDA or by OpenCL programming. We consider a\ndeposition/evaporation model following Kardar-Parisi-Zhang growth in 1+1\ndimensions related to the Asymmetric Simple Exclusion Process and show that for\nsizes, that fit into the shared memory of GPUs one can achieve the maximum\nparallelization speedup ~ x100 for a Quadro FX 5800 graphics card with respect\nto a single CPU of 2.67 GHz). This permits us to study the effect of quenched\ncolumnar disorder, requiring extremely long simulation times. We compare the\nCUDA realization with an OpenCL implementation designed for processor clusters\nvia MPI. A two-lane traffic model with randomized turning points is also\nrealized and the dynamical behavior has been investigated.\n", "versions": [{"version": "v1", "created": "Thu, 2 Dec 2010 12:36:12 GMT"}, {"version": "v2", "created": "Wed, 30 Mar 2011 18:42:47 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Schulz", "Henrik", ""], ["\u00d3dor", "G\u00e9za", ""], ["\u00d3dor", "Gergely", ""], ["Nagy", "M\u00e1t\u00e9 Ferenc", ""]]}, {"id": "1012.0759", "submitter": "Francesco Pagano", "authors": "Ernesto Damiani and Francesco Pagano", "title": "Handling Confidential Data on the Untrusted Cloud: An Agent-based\n  Approach", "comments": "7 pages, 9 figures, Cloud Computing 2010", "journal-ref": "CLOUD COMPUTING 2010 : The First International Conference on Cloud\n  Computing, GRIDs, and Virtualization - ISBN: 978-1-61208-001-7", "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.MA", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Cloud computing allows shared computer and storage facilities to be used by a\nmultitude of clients. While cloud management is centralized, the information\nresides in the cloud and information sharing can be implemented via\noff-the-shelf techniques for multiuser databases. Users, however, are very\ndiffident for not having full control over their sensitive data. Untrusted\ndatabase-as-a-server techniques are neither readily extendable to the cloud\nenvironment nor easily understandable by non-technical users. To solve this\nproblem, we present an approach where agents share reserved data in a secure\nmanner by the use of simple grant-and-revoke permissions on shared data.\n", "versions": [{"version": "v1", "created": "Fri, 3 Dec 2010 15:07:36 GMT"}], "update_date": "2010-12-06", "authors_parsed": [["Damiani", "Ernesto", ""], ["Pagano", "Francesco", ""]]}, {"id": "1012.1131", "submitter": "Hien Truong", "authors": "Hien Thi Thu Truong (INRIA Lorraine - LORIA), Claudia-Lavinia Ignat\n  (INRIA Lorraine - LORIA)", "title": "A Log Auditing Approach for Trust Management in Peer-to-Peer\n  Collaboration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays we are faced with an increasing popularity of social software\nincluding wikis, blogs, micro-blogs and online social networks such as Facebook\nand MySpace. Unfortunately, the mostly used social services are centralized and\npersonal information is stored at a single vendor. This results in potential\nprivacy problems as users do not have much control over how their private data\nis disseminated. To overcome this limitation, some recent approaches envisioned\nreplacing the single authority centralization of services by a peer-to-peer\ntrust-based approach where users can decide with whom they want to share their\nprivate data. In this peer-to-peer collaboration it is very difficult to ensure\nthat after data is shared with other peers, these peers will not misbehave and\nviolate data privacy. In this paper we propose a mechanism that addresses the\nissue of data privacy violation due to data disclosure to malicious peers. In\nour approach trust values between users are adjusted according to their\nprevious activities on the shared data. Users share their private data by\nspecifying some obligations the receivers must follow. We log modifications\ndone by users on the shared data as well as the obligations that must be\nfollowed when data is shared. By a log-auditing mechanism we detect users that\nmisbehaved and we adjust their associated trust values by using any existing\ndecentralized trust model.\n", "versions": [{"version": "v1", "created": "Mon, 6 Dec 2010 11:14:22 GMT"}], "update_date": "2010-12-07", "authors_parsed": [["Truong", "Hien Thi Thu", "", "INRIA Lorraine - LORIA"], ["Ignat", "Claudia-Lavinia", "", "INRIA Lorraine - LORIA"]]}, {"id": "1012.1288", "submitter": "Dohan Kim", "authors": "Dohan Kim", "title": "Representations of task assignments in distributed systems using Young\n  tableaux and symmetric groups", "comments": "This is an Accepted Manuscript of an article published by Taylor &\n  Francis Group in International Journal of Parallel, Emergent and Distributed\n  Systems on 02/02/2015, available online:\n  http://dx.doi.org/10.1080/17445760.2014.997729", "journal-ref": "International Journal of Parallel, Emergent and Distributed\n  Systems 31 (2016): 152-175", "doi": "10.1080/17445760.2014.997729", "report-no": null, "categories": "cs.DC math.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel approach to representing task assignments for\npartitioned agents (respectively, tasks) in distributed systems. A partition of\nagents (respectively, tasks) is represented by a Young tableau, which is one of\nthe main tools in studying symmetric groups and combinatorics. In this paper we\npropose a task, agent, and assignment tableau in order to represent a task\nassignment for partitioned agents (respectively, tasks) in a distributed\nsystem. This paper is concerned with representations of task assignments rather\nthan finding approximate or near optimal solutions for task assignments. A\nYoung tableau approach allows us to raise the expressiveness of partitioned\nagents (respectively, tasks) and their task assignments.\n", "versions": [{"version": "v1", "created": "Mon, 6 Dec 2010 19:16:18 GMT"}, {"version": "v2", "created": "Sun, 10 Jul 2011 13:45:44 GMT"}, {"version": "v3", "created": "Sun, 25 Sep 2011 18:56:53 GMT"}, {"version": "v4", "created": "Wed, 1 May 2013 15:33:15 GMT"}, {"version": "v5", "created": "Thu, 11 Feb 2016 04:05:41 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Kim", "Dohan", ""]]}, {"id": "1012.1367", "submitter": "Ohad Shamir", "authors": "Ofer Dekel, Ran Gilad-Bachrach, Ohad Shamir and Lin Xiao", "title": "Optimal Distributed Online Prediction using Mini-Batches", "comments": "Final version of paper to appear in Journal of Machine Learning\n  Research (JMLR)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online prediction methods are typically presented as serial algorithms\nrunning on a single processor. However, in the age of web-scale prediction\nproblems, it is increasingly common to encounter situations where a single\nprocessor cannot keep up with the high rate at which inputs arrive. In this\nwork, we present the \\emph{distributed mini-batch} algorithm, a method of\nconverting many serial gradient-based online prediction algorithms into\ndistributed algorithms. We prove a regret bound for this method that is\nasymptotically optimal for smooth convex loss functions and stochastic inputs.\nMoreover, our analysis explicitly takes into account communication latencies\nbetween nodes in the distributed environment. We show how our method can be\nused to solve the closely-related distributed stochastic optimization problem,\nachieving an asymptotically linear speed-up over multiple processors. Finally,\nwe demonstrate the merits of our approach on a web-scale online prediction\nproblem.\n", "versions": [{"version": "v1", "created": "Tue, 7 Dec 2010 00:00:22 GMT"}, {"version": "v2", "created": "Tue, 31 Jan 2012 18:12:21 GMT"}], "update_date": "2012-02-01", "authors_parsed": [["Dekel", "Ofer", ""], ["Gilad-Bachrach", "Ran", ""], ["Shamir", "Ohad", ""], ["Xiao", "Lin", ""]]}, {"id": "1012.1641", "submitter": "Yibing Wang", "authors": "Yibing Wang", "title": "A Generalized Streaming Model for Concurrent Computing", "comments": "12 pages, 7 figures. unpublished draft for a high-level discussion of\n  an abstract, parallel computing model", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Multicore parallel programming has some very difficult problems such as\ndeadlocks during synchronizations and race conditions brought by concurrency.\nAdded to the difficulty is the lack of a simple, well-accepted computing model\nfor multicore architectures--because of that it is hard to develop powerful\nprogramming environments and debugging tools. To tackle the challenges, we\npromote a generalized stream computing model, inspired by previous researches\non stream computing, that unifies parallelization strategies for programming\nlanguage design, compiler design and operating system design. Our model\nprovides a high-level abstraction in designing language constructs to convey\nconcepts of concurrent operations, in organizing a program's runtime layout for\nparallel execution, and in scheduling concurrent instruction blocks through\nruntime and/or operating systems. In this paper, we give a high-level\ndescription of the proposed model: we define the foundation of the model, show\nits simplicity through algebraic/computational operation analysis, illustrate a\nprogramming framework enabled by the model, and demonstrate its potential\nthrough powerful design options for programming languages, compilers and\noperating systems.\n", "versions": [{"version": "v1", "created": "Tue, 7 Dec 2010 23:43:09 GMT"}], "update_date": "2010-12-09", "authors_parsed": [["Wang", "Yibing", ""]]}, {"id": "1012.1824", "submitter": "Massimo Torquati", "authors": "Massimo Torquati", "title": "Single-Producer/Single-Consumer Queues on Shared Cache Multi-Core\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using efficient point-to-point communication channels is critical for\nimplementing fine grained parallel program on modern shared cache multi-core\narchitectures.\n  This report discusses in detail several implementations of wait-free\nSingle-Producer/Single-Consumer queue (SPSC), and presents a novel and\nefficient algorithm for the implementation of an unbounded wait-free SPSC queue\n(uSPSC). The correctness proof of the new algorithm, and several performance\nmeasurements based on simple synthetic benchmark and microbenchmark, are also\ndiscussed.\n", "versions": [{"version": "v1", "created": "Wed, 8 Dec 2010 18:50:29 GMT"}], "update_date": "2010-12-09", "authors_parsed": [["Torquati", "Massimo", ""]]}, {"id": "1012.1980", "submitter": "Ian Fisk", "authors": "Ian Fisk", "title": "First Experiences with LHC Grid Computing and Distributed Analysis", "comments": "6 pages, 2 figures, Proceedings of the Hadron Collider Physics\n  Symposium 2010 (HCP2010), Toronto Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.DC hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this presentation the experiences of the LHC experiments using grid\ncomputing were presented with a focus on experience with distributed analysis.\nAfter many years of development, preparation, exercises, and validation the LHC\n(Large Hadron Collider) experiments are in operations. The computing\ninfrastructure has been heavily utilized in the first 6 months of data\ncollection. The general experience of exploiting the grid infrastructure for\norganized processing and preparation is described, as well as the successes\nemploying the infrastructure for distributed analysis. At the end the expected\nevolution and future plans are outlined.\n", "versions": [{"version": "v1", "created": "Thu, 9 Dec 2010 11:41:21 GMT"}], "update_date": "2010-12-10", "authors_parsed": [["Fisk", "Ian", ""]]}, {"id": "1012.2171", "submitter": "Jaydip Sen", "authors": "Jaydip Sen", "title": "A Robust and Efficient Trust Management Scheme for Peer-to-Peer Networks", "comments": "15 pages, 8 figures, 1 table. 11th International Workshop on\n  Information Security Applications (WISA 2010), Jeju Island, Korea, August 24\n  - 26, 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Studies on the large scale peer-to-peer (P2P) network like Gnutella have\nshown the presence of large number of free riders. Moreover, the open and\ndecentralized nature of P2P network is exploited by malicious users who\ndistribute unauthentic or harmful contents. Despite the existence of a number\nof trust management schemes in the literature for combating against free riding\nand distribution of malicious files, these mechanisms are not scalable due to\ntheir high computational, communication and storage overhead. These schemes\nalso do not consider effect of trust management on quality-of-service (QoS) of\nthe search. This paper presents a trust management scheme for P2P networks that\nminimizes distribution of spurious files by a novel technique called topology\nadaptation. It also reduces search time since most of the queries are resolved\nwithin the community of trustworthy peers. Simulation results indicate that the\ntrust management overhead due to the pr oposed mechanism decreases considerably\nas the network topology stabilizes. The mechanism is also found to be robust\neven in presence of a large percentage of malicious peers.\n", "versions": [{"version": "v1", "created": "Fri, 10 Dec 2010 03:52:21 GMT"}], "update_date": "2010-12-13", "authors_parsed": [["Sen", "Jaydip", ""]]}, {"id": "1012.2203", "submitter": "Oleksiy Kurganskyy", "authors": "Oleksiy Kurganskyy", "title": "A collective of stateless automata in a $n$-dimensional environment as a\n  distributed dynamic automaton-like object: a model and its corollaries", "comments": "9 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work a collective of interacting stateless automata in a discrete\ngeometric $n$-dimenstional environment is considered as an integral\nautomaton-like computational dynamic object. For such distributed on the\nenvironment object different approaches to definition of the measure of state\ntransition are possible. We propose an approach for defining what a state is.\nThe approach is based on the concept of relativity in Poincar\\'e's\ninterpretation.\n", "versions": [{"version": "v1", "created": "Fri, 10 Dec 2010 08:40:41 GMT"}], "update_date": "2010-12-13", "authors_parsed": [["Kurganskyy", "Oleksiy", ""]]}, {"id": "1012.2256", "submitter": "Laurent Lefevre", "authors": "Anne-C\\'ecile Orgerie (INRIA Rh\\^one-Alpes / LIP Laboratoire de\n  l'Informatique du Parall\\'elisme), Laurent Lef\\`evre (INRIA Rh\\^one-Alpes /\n  LIP Laboratoire de l'Informatique du Parall\\'elisme)", "title": "A year in the life of a large scale experimental distributed system: the\n  Grid'5000 platform in 2008", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report presents the usage results of Grid'5000 over year 2008. Usage of\nthe main operationnal Grid'5000 sites (Bordeaux, Lille, Lyon, Nancy, Orsay,\nRennes, Sophia-Antipolis, Toulouse) is presented and analyzed.\n", "versions": [{"version": "v1", "created": "Fri, 10 Dec 2010 13:07:28 GMT"}], "update_date": "2010-12-13", "authors_parsed": [["Orgerie", "Anne-C\u00e9cile", "", "INRIA Rh\u00f4ne-Alpes / LIP Laboratoire de\n  l'Informatique du Parall\u00e9lisme"], ["Lef\u00e8vre", "Laurent", "", "INRIA Rh\u00f4ne-Alpes /\n  LIP Laboratoire de l'Informatique du Parall\u00e9lisme"]]}, {"id": "1012.2270", "submitter": "Tom\\'a\\v{s} Oberhuber", "authors": "Tom\\'a\\v{s} Oberhuber and Atsushi Suzuki and Jan Vacata", "title": "New Row-grouped CSR format for storing the sparse matrices on GPU with\n  implementation in CUDA", "comments": "21 pages, 8 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we present a new format for storing sparse matrices. The\nformat is designed to perform well mainly on the GPU devices. We present its\nimplementation in CUDA. The performance has been tested on 1,600 different\ntypes of matrices and we compare our format with the Hybrid format. We give\ndetailed comparison of both formats and show their strong and weak parts.\n", "versions": [{"version": "v1", "created": "Fri, 10 Dec 2010 14:04:33 GMT"}], "update_date": "2010-12-13", "authors_parsed": [["Oberhuber", "Tom\u00e1\u0161", ""], ["Suzuki", "Atsushi", ""], ["Vacata", "Jan", ""]]}, {"id": "1012.2273", "submitter": "Achmad Benny Mutiara", "authors": "D.T. Hasta and A.B. Mutiara", "title": "Performance Evaluation of Parallel Message Passing and Thread\n  Programming Model on Multicore Architectures", "comments": "46 pages 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current trend of multicore architectures on shared memory systems\nunderscores the need of parallelism. While there are some programming model to\nexpress parallelism, thread programming model has become a standard to support\nthese system such as OpenMP, and POSIX threads. MPI (Message Passing Interface)\nwhich remains the dominant model used in high-performance computing today faces\nthis challenge.\n  Previous version of MPI which is MPI-1 has no shared memory concept, and\nCurrent MPI version 2 which is MPI-2 has a limited support for shared memory\nsystems. In this research, MPI-2 version of MPI will be compared with OpenMP to\nsee how well does MPI perform on multicore / SMP (Symmetric Multiprocessor)\nmachines.\n  Comparison between OpenMP for thread programming model and MPI for message\npassing programming model will be conducted on multicore shared memory machine\narchitectures to see who has a better performance in terms of speed and\nthroughput. Application used to assess the scalability of the evaluated\nparallel programming solutions is matrix multiplication with customizable\nmatrix dimension.\n  Many research done on a large scale parallel computing which using high scale\nbenchmark such as NSA Parallel Benchmark (NPB) for their testing standarization\n[1]. This research will be conducted on a small scale parallel computing that\nemphasize more on the performance evaluation between MPI and OpenMPI parallel\nprogramming model using self created benchmark.\n", "versions": [{"version": "v1", "created": "Fri, 10 Dec 2010 14:17:19 GMT"}], "update_date": "2010-12-13", "authors_parsed": [["Hasta", "D. T.", ""], ["Mutiara", "A. B.", ""]]}, {"id": "1012.2440", "submitter": "Othon Michail", "authors": "Ioannis Chatzigiannakis, Othon Michail, Stavros Nikolaou, Andreas\n  Pavlogiannis, Paul G. Spirakis", "title": "Passively Mobile Communicating Machines that Use Restricted Space", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new theoretical model for passively mobile Wireless Sensor\nNetworks, called PM, standing for Passively mobile Machines. The main\nmodification w.r.t. the Population Protocol model is that agents now, instead\nof being automata, are Turing Machines. We provide general definitions for\nunbounded memories, but we are mainly interested in computations upper-bounded\nby plausible space limitations. However, we prove that our results hold for\nmore general cases. We focus on complete communication graphs and define the\ncomplexity classes PMSPACE(f(n)) parametrically, consisting of all predicates\nthat are stably computable by some PM protocol that uses O(f(n)) memory on each\nagent. We provide a protocol that generates unique ids from scratch only by\nusing O(log n) memory, and use it to provide an exact characterization for the\nclasses PMSPACE(f(n)) when f(n)={\\Omega}(log n): they are precisely the classes\nof all symmetric predicates in NSPACE(nf(n)). In this way, we provide a space\nhierarchy for the PM model when the memory bounds are {\\Omega}(log n). Finally,\nwe explore the computability of the PM model when the protocols use o(loglog n)\nspace per machine and prove that SEMILINEAR=PMSPACE(f(n)) when f(n)=o(loglog\nn), where SEMILINEAR denotes the class of the semilinear predicates. In fact,\nwe prove that this bound acts as a threshold, so that SEMILINEAR is a proper\nsubset of PMSPACE(f(n)) when f(n)=O(loglog n).\n", "versions": [{"version": "v1", "created": "Sat, 11 Dec 2010 10:05:38 GMT"}], "update_date": "2010-12-14", "authors_parsed": [["Chatzigiannakis", "Ioannis", ""], ["Michail", "Othon", ""], ["Nikolaou", "Stavros", ""], ["Pavlogiannis", "Andreas", ""], ["Spirakis", "Paul G.", ""]]}, {"id": "1012.2499", "submitter": "L.T. Handoko", "authors": "Z. Akbar, I. Firmansyah, B. Hermanto, L.T. Handoko", "title": "openPC : a toolkit for public cluster with full ownership", "comments": "8 pages", "journal-ref": "Int. J. Comput. Theor. Eng. 2 (2010) 978-985", "doi": "10.7763/IJCTE.2010.V2.273", "report-no": "FISIKALIPI-10037", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The openPC is a set of open source tools that realizes a parallel machine and\ndistributed computing environment divisible into several independent blocks of\nnodes, and each of them is remotely but fully in any means accessible for users\nwith a full ownership policy. The openPC components address fundamental issues\nrelating to security, resource access, resource allocation, compatibilities\nwith heterogeneous middlewares, user-friendly and integrated web-based\ninterfaces, hardware control and monitoring systems. These components have been\ndeployed successfully to the LIPI Public Cluster which is open for public use.\nIn this paper, the unique characteristics of openPC due to its rare\nrequirements are introduced, its components and a brief performance analysis\nare discussed.\n", "versions": [{"version": "v1", "created": "Sun, 12 Dec 2010 00:15:44 GMT"}], "update_date": "2013-06-18", "authors_parsed": [["Akbar", "Z.", ""], ["Firmansyah", "I.", ""], ["Hermanto", "B.", ""], ["Handoko", "L. T.", ""]]}, {"id": "1012.2648", "submitter": "Georg Gottlob", "authors": "S. Abiteboul, G. Gottlob, M. Manna", "title": "Distributed XML Design", "comments": "\"56 pages, 4 figures\"", "journal-ref": "Proceedings of PODS '09 (2009) 247-258", "doi": "10.1145/1559795.1559833", "report-no": null, "categories": "cs.DB cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A distributed XML document is an XML document that spans several machines. We\nassume that a distribution design of the document tree is given, consisting of\nan XML kernel-document T[f1,...,fn] where some leaves are \"docking points\" for\nexternal resources providing XML subtrees (f1,...,fn, standing, e.g., for Web\nservices or peers at remote locations). The top-down design problem consists\nin, given a type (a schema document that may vary from a DTD to a tree\nautomaton) for the distributed document, \"propagating\" locally this type into a\ncollection of types, that we call typing, while preserving desirable\nproperties. We also consider the bottom-up design which consists in, given a\ntype for each external resource, exhibiting a global type that is enforced by\nthe local types, again with natural desirable properties. In the article, we\nlay out the fundamentals of a theory of distributed XML design, analyze\nproblems concerning typing issues in this setting, and study their complexity.\n", "versions": [{"version": "v1", "created": "Mon, 13 Dec 2010 07:45:30 GMT"}], "update_date": "2010-12-15", "authors_parsed": [["Abiteboul", "S.", ""], ["Gottlob", "G.", ""], ["Manna", "M.", ""]]}, {"id": "1012.2860", "submitter": "Serguei Mokhov", "authors": "Yi Ji and Serguei A. Mokhov and Joey Paquet", "title": "Towards Refactoring the DMF to Support Jini and JMS DMS in GIPSY", "comments": "16 pages; 9 figures; an index. v4 includes significant updates and a\n  version was submitted to PPPJ'11", "journal-ref": null, "doi": "10.1145/2347583.2347588", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we report on our re-engineering effort to refactor and unify\ntwo somewhat disjoint Java distributed middleware technologies -- Jini and JMS\n-- used in the implementation of the Demand Migration System (DMS). In doing\nso, we refactor their parent Demand Migration Framework (DMF), within the\nGeneral Intensional Programming System (GIPSY). The complex Java-based GIPSY\nproject is used to investigate on the intensional and hybrid programming\nparadigms.\n", "versions": [{"version": "v1", "created": "Mon, 13 Dec 2010 20:58:58 GMT"}, {"version": "v2", "created": "Thu, 16 Dec 2010 19:53:12 GMT"}, {"version": "v3", "created": "Mon, 10 Jan 2011 21:02:24 GMT"}, {"version": "v4", "created": "Tue, 3 May 2011 18:39:52 GMT"}], "update_date": "2013-07-08", "authors_parsed": [["Ji", "Yi", ""], ["Mokhov", "Serguei A.", ""], ["Paquet", "Joey", ""]]}, {"id": "1012.3347", "submitter": "Mikael Fernandus Simalango", "authors": "Mikael Fernandus Simalango, Sangyoon Oh", "title": "An Architectural Design for Brokered Collaborative Content Delivery\n  System", "comments": "This paper has been withdrawn due to various reasons", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Advances in web technologies have driven massive content uploads and requests\nthat can be identified by the increased usage of multimedia web and social web\nservices. This situation enforces the content providers to scale their\ninfrastructure in order to cope with the extra provisioning of network traffic,\nstorage and other resources. Since the complexity and cost factors in scaling\nthe infrastructure exist, we propose a novel solution for providing and\ndelivering contents to clients by introducing a brokered collaborative content\ndelivery system. The architectural design of this system leverages content\nredundancy and content distribution mechanisms in other content providers to\ndeliver contents to the clients. With the recent emergence of cloud computing,\nwe show that this system can also be adopted to run on the cloud. In this\npaper, we focus on a brokering scheme to mediate user requests to the most\nappropriate content provider based on a ranking system. The architecture\nprovides a novel Global Rank Value (GRV) concept in estimating content provider\ncapability and transforming the QoS requirement of a content request. A\nfairness model that will bring this design to be attractive to the current\ncontent delivery regime is also introduced. Through simulation, we show that\nusing fair provider selection, contents can be provisioned by a better pool of\nqualified providers thus leveraging the collaboration and preventing potential\nQoS violation that may occur when the size of pool is smaller.\n", "versions": [{"version": "v1", "created": "Wed, 15 Dec 2010 14:31:05 GMT"}, {"version": "v2", "created": "Fri, 12 Apr 2013 12:31:26 GMT"}], "update_date": "2013-04-15", "authors_parsed": [["Simalango", "Mikael Fernandus", ""], ["Oh", "Sangyoon", ""]]}, {"id": "1012.4404", "submitter": "Walter Quattrociocchi", "authors": "Sara Brunetti, Elena Lodi, Walter Quattrociocchi", "title": "Multicolored Dynamos on Toroidal Meshes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Detecting on a graph the presence of the minimum number of nodes (target set)\nthat will be able to \"activate\" a prescribed number of vertices in the graph is\ncalled the target set selection problem (TSS) proposed by Kempe, Kleinberg, and\nTardos. In TSS's settings, nodes have two possible states (active or\nnon-active) and the threshold triggering the activation of a node is given by\nthe number of its active neighbors. Dealing with fault tolerance in a majority\nbased system the two possible states are used to denote faulty or non-faulty\nnodes, and the threshold is given by the state of the majority of neighbors.\nHere, the major effort was in determining the distribution of initial faults\nleading the entire system to a faulty behavior. Such an activation pattern,\nalso known as dynamic monopoly (or shortly dynamo), was introduced by Peleg in\n1996. In this paper we extend the TSS problem's settings by representing nodes'\nstates with a \"multicolored\" set. The extended version of the problem can be\ndescribed as follows: let G be a simple connected graph where every node is\nassigned a color from a finite ordered set C = {1, . . ., k} of colors. At each\nlocal time step, each node can recolor itself, depending on the local\nconfigurations, with the color held by the majority of its neighbors. Given G,\nwe study the initial distributions of colors leading the system to a k\nmonochromatic configuration in toroidal meshes, focusing on the minimum number\nof initial k-colored nodes. We find upper and lower bounds to the size of a\ndynamo, and then special classes of dynamos, outlined by means of a new\napproach based on recoloring patterns, are characterized.\n", "versions": [{"version": "v1", "created": "Mon, 20 Dec 2010 17:02:51 GMT"}], "update_date": "2010-12-21", "authors_parsed": [["Brunetti", "Sara", ""], ["Lodi", "Elena", ""], ["Quattrociocchi", "Walter", ""]]}, {"id": "1012.4712", "submitter": "Wenguang Wang", "authors": "Wenguang Wang, Weiping Wang, Yifan Zhu, Qun Li (College of Information\n  Systems and Management, National University of Defense Technology, Changsha,\n  China)", "title": "Service-Oriented Simulation Framework: An Overview and Unifying\n  Methodology", "comments": "23 pages, 4 figures, 13 tables, SIMULATION: Transactions of the\n  Society for Modeling and Simulation International. first published on\n  December 21, 2010. DOI: 10.1177/0037549710391838.\n  http://sim.sagepub.com/content/early/2010/12/18/0037549710391838.abstract", "journal-ref": "SIMULATION: Transactions of the Society for Modeling and\n  Simulation International. first published on December 21, 2010. DOI:\n  10.1177/0037549710391838.\n  http://sim.sagepub.com/content/early/2010/12/18/0037549710391838.abstract", "doi": "10.1177/0037549710391838", "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The prevailing net-centric environment demands and enables modeling and\nsimulation to combine efforts from numerous disciplines. Software techniques\nand methodology, in particular service-oriented architecture, provide such an\nopportunity. Service-oriented simulation has been an emerging paradigm\nfollowing on from object- and process-oriented methods. However, the ad-hoc\nframeworks proposed so far generally focus on specific domains or systems and\neach has its pros and cons. They are capable of addressing different issues\nwithin service-oriented simulation from different viewpoints. It is\nincreasingly important to describe and evaluate the progress of numerous\nframeworks. In this paper, we propose a novel three-dimensional reference model\nfor a service-oriented simulation paradigm. The model can be used as a\nguideline or an analytic means to find the potential and possible future\ndirections of the current simulation frameworks. In particular, the model\ninspects the crossover between the disciplines of modeling and simulation,\nservice-orientation, and software/systems engineering. Based on the model, we\npresent a comprehensive survey on several classical service-oriented simulation\nframeworks, including formalism-based, model-driven, interoperability protocol\nbased, eXtensible Modeling and Simulation Framework (XMSF), and Open Grid\nServices Architecture (OGSA) based frameworks etc. The comparison of these\nframeworks is also performed. Finally the significance both in academia and\npractice are presented and future directions are pointed out.\n", "versions": [{"version": "v1", "created": "Tue, 21 Dec 2010 16:03:50 GMT"}], "update_date": "2010-12-22", "authors_parsed": [["Wang", "Wenguang", "", "College of Information\n  Systems and Management, National University of Defense Technology, Changsha,\n  China"], ["Wang", "Weiping", "", "College of Information\n  Systems and Management, National University of Defense Technology, Changsha,\n  China"], ["Zhu", "Yifan", "", "College of Information\n  Systems and Management, National University of Defense Technology, Changsha,\n  China"], ["Li", "Qun", "", "College of Information\n  Systems and Management, National University of Defense Technology, Changsha,\n  China"]]}, {"id": "1012.4874", "submitter": "Xiaoxin Zhang", "authors": "Xiaoxin Zhang, Liang Chen, Jianwei Huang, Minghua Chen, and Yuping\n  Zhao", "title": "Distributed and Optimal Reduced Primal-Dual Algorithm for Uplink OFDM\n  Resource Allocation", "comments": "12 pages, 22 figures, and 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.CC cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Orthogonal Frequency Division Multiplexing (OFDM) is the key component of\nmany emerging broadband wireless access standards. The resource allocation in\nOFDM uplink, however, is challenging due to heterogeneity of users' Quality of\nService requirements, channel conditions, and individual resource constraints.\nWe formulate the resource allocation problem as a non-strictly convex\noptimization problem, which typically has multiple global optimal solutions. We\nthen propose a reduced primal-dual algorithm, which is distributed, low in\ncomputational complexity, and probably globally convergent to a global optimal\nsolution. The performance of the algorithm is studied through a realistic OFDM\nsimulator. Compared with the previously proposed centralized optimal algorithm,\nour algorithm not only significantly reduces the message overhead but also\nrequires less iterations to converge.\n", "versions": [{"version": "v1", "created": "Wed, 22 Dec 2010 03:34:38 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Zhang", "Xiaoxin", ""], ["Chen", "Liang", ""], ["Huang", "Jianwei", ""], ["Chen", "Minghua", ""], ["Zhao", "Yuping", ""]]}, {"id": "1012.5030", "submitter": "Martin Wimmer", "authors": "Martin Wimmer, Jesper Larsson Tr\\\"aff", "title": "Work-stealing for mixed-mode parallelism by deterministic team-building", "comments": null, "journal-ref": null, "doi": null, "report-no": "TR-10-5", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to extend classical work-stealing to deal also with data parallel\ntasks that can require any number of threads r >= 1 for their execution. We\nexplain in detail the so introduced idea of work-stealing with deterministic\nteam-building which in a natural way generalizes classical work-stealing. A\nprototype C++ implementation of the generalized work-stealing algorithm has\nbeen given and is briefly described. Building on this, a serious, well-known\ncontender for a best parallel Quicksort algorithm has been implemented, which\nnaturally relies on both task and data parallelism. For instance, sorting\n2^27-1 randomly generated integers we could improve the speed-up from 5.1 to\n8.7 on a 32-core Intel Nehalem EX system, being consistently better than the\ntuned, task-parallel Cilk++ system.\n", "versions": [{"version": "v1", "created": "Wed, 22 Dec 2010 16:43:12 GMT"}], "update_date": "2010-12-23", "authors_parsed": [["Wimmer", "Martin", ""], ["Tr\u00e4ff", "Jesper Larsson", ""]]}, {"id": "1012.5351", "submitter": "Tobias Friedrich", "authors": "Benjamin Doerr, Tobias Friedrich, Thomas Sauerwald", "title": "Quasirandom Rumor Spreading", "comments": "34 pages, to appear in ACM Transactions of Algorithms, parts of the\n  results appeared in SODA'08 and ICALP'09", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a quasirandom analogue of the classical push model for\ndisseminating information in networks (\"randomized rumor spreading\"). In the\nclassical model, in each round each informed vertex chooses a neighbor at\nrandom and informs it, if it was not informed before. It is known that this\nsimple protocol succeeds in spreading a rumor from one vertex to all others\nwithin O(log n) rounds on complete graphs, hypercubes, random regular graphs,\nErdos-Renyi random graph and Ramanujan graphs with probability 1-o(1). In the\nquasirandom model, we assume that each vertex has a (cyclic) list of its\nneighbors. Once informed, it starts at a random position on the list, but from\nthen on informs its neighbors in the order of the list. Surprisingly,\nirrespective of the orders of the lists, the above-mentioned bounds still hold.\nIn some cases, even better bounds than for the classical model can be shown.\n", "versions": [{"version": "v1", "created": "Fri, 24 Dec 2010 07:24:06 GMT"}, {"version": "v2", "created": "Wed, 7 Aug 2013 21:06:48 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Doerr", "Benjamin", ""], ["Friedrich", "Tobias", ""], ["Sauerwald", "Thomas", ""]]}, {"id": "1012.5834", "submitter": "Soji Omiwade", "authors": "Soji Omiwade, Rong Zheng", "title": "Maximum Lifetime for Data Regeneration in Wireless Sensor Networks", "comments": "This paper has been withdrawn by the authors. This paper has been\n  withdrawn due to the difficulty in understanding it", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Robust distributed storage systems dedicated to wireless sensor networks\nutilize several nodes to redundantly store sensed data so that when some\nstorage nodes fail, the sensed data can still be reconstructed. For the same\nlevel of redundancy, erasure coding based approaches are known to require less\ndata storage space than replication methods.\n  To maintain the same level of redundancy when one storage node fails, erasure\ncoded data can be restored onto some other storage node by having this node\ndownload respective pieces from other live storage nodes. Previous works showed\nthat the benefits in using erasure coding for robust storage over replication\nare made unappealing by the complication in regenerating lost data. More recent\nwork has, however, shown that the bandwidth for erasure coded data can be\nfurther reduced by proposing Regenerating Coding, making erasure codes again\ndesirable for robust data storage.\n  But none of these works on regenerating coding consider how these codes will\nperform for data regeneration in wireless sensor networks. We therefore propose\nan analytical model to quantify the network lifetime gains of regenerating\ncoding over classical schemes. We also propose a distributed algorithm, TROY,\nthat determines which nodes and routes to use for data regeneration. Our\nanalytical studies show that for certain topologies, TROY achieves maximum\nnetwork lifetime. Our evaluation studies in real sensor network traces show\nthat TROY achieves near optimal lifetime and performs better than baseline\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 28 Dec 2010 20:36:09 GMT"}, {"version": "v2", "created": "Tue, 4 Jan 2011 17:10:16 GMT"}, {"version": "v3", "created": "Thu, 17 Mar 2011 01:27:07 GMT"}, {"version": "v4", "created": "Fri, 18 Mar 2011 15:35:42 GMT"}, {"version": "v5", "created": "Wed, 15 Jun 2011 15:07:05 GMT"}], "update_date": "2011-06-16", "authors_parsed": [["Omiwade", "Soji", ""], ["Zheng", "Rong", ""]]}]