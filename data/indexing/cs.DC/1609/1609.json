[{"id": "1609.00098", "submitter": "Scott Field", "authors": "Lawrence E. Kidder, Scott E. Field, Francois Foucart, Erik Schnetter,\n  Saul A. Teukolsky, Andy Bohn, Nils Deppe, Peter Diener, Fran\\c{c}ois\n  H\\'ebert, Jonas Lippuner, Jonah Miller, Christian D. Ott, Mark A. Scheel,\n  Trevor Vincent", "title": "SpECTRE: A Task-based Discontinuous Galerkin Code for Relativistic\n  Astrophysics", "comments": "41 pages, 13 figures, and 7 tables. Ancillary data contains\n  simulation input files", "journal-ref": null, "doi": "10.1016/j.jcp.2016.12.059", "report-no": null, "categories": "astro-ph.HE cs.DC gr-qc physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new relativistic astrophysics code, SpECTRE, that combines a\ndiscontinuous Galerkin method with a task-based parallelism model. SpECTRE's\ngoal is to achieve more accurate solutions for challenging relativistic\nastrophysics problems such as core-collapse supernovae and binary neutron star\nmergers. The robustness of the discontinuous Galerkin method allows for the use\nof high-resolution shock capturing methods in regions where (relativistic)\nshocks are found, while exploiting high-order accuracy in smooth regions. A\ntask-based parallelism model allows efficient use of the largest supercomputers\nfor problems with a heterogeneous workload over disparate spatial and temporal\nscales. We argue that the locality and algorithmic structure of discontinuous\nGalerkin methods will exhibit good scalability within a task-based parallelism\nframework. We demonstrate the code on a wide variety of challenging benchmark\nproblems in (non)-relativistic (magneto)-hydrodynamics. We demonstrate the\ncode's scalability including its strong scaling on the NCSA Blue Waters\nsupercomputer up to the machine's full capacity of 22,380 nodes using 671,400\nthreads.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 03:37:52 GMT"}, {"version": "v2", "created": "Fri, 21 Jul 2017 19:25:15 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Kidder", "Lawrence E.", ""], ["Field", "Scott E.", ""], ["Foucart", "Francois", ""], ["Schnetter", "Erik", ""], ["Teukolsky", "Saul A.", ""], ["Bohn", "Andy", ""], ["Deppe", "Nils", ""], ["Diener", "Peter", ""], ["H\u00e9bert", "Fran\u00e7ois", ""], ["Lippuner", "Jonas", ""], ["Miller", "Jonah", ""], ["Ott", "Christian D.", ""], ["Scheel", "Mark A.", ""], ["Vincent", "Trevor", ""]]}, {"id": "1609.00130", "submitter": "Roberto Rigamonti", "authors": "Roberto Rigamonti and Baptiste Delporte and Anthony Convers and\n  Alberto Dassatti", "title": "Transparent Live Code Offloading on FPGA", "comments": "9 pages in FPGAs for Software Programmers (FSP 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Even though it seems that FPGAs have finally made the transition from\nresearch labs to the consumer devices' market, programming them remains\nchallenging. Despite the improvements made by High-Level Synthesis (HLS), which\nremoved the language and paradigm barriers that prevented many computer\nscientists from working with them, producing a new design typically requires at\nleast several hours, making data- and context-dependent adaptations virtually\nimpossible.\n  In this paper we present a new framework that off-loads, on-the-fly and\ntransparently to both the user and the developer, computationally-intensive\ncode fragments to FPGAs. While the performance should not surpass that of\nhand-crafted HDL code, or even code produced by HLS, our results come with no\nadditional development costs and do not require producing and deploying a new\nbit-stream to the FPGA each time a change is made. Moreover, since\noptimizations are made at run-time, they may fit particular datasets or usage\nscenarios, something which is rarely foreseeable at design or compile time.\n  Our proposal revolves around an overlay architecture that is pre-programmed\non the FPGA and dynamically reconfigured by our framework to execute code\nfragments extracted from the Data Flow Graph (DFG) of computational intensive\nroutines. We validated our solution using standard benchmarks and proved we are\nable to off-load to FPGAs without developer's intervention.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2016 07:18:41 GMT"}], "update_date": "2016-09-02", "authors_parsed": [["Rigamonti", "Roberto", ""], ["Delporte", "Baptiste", ""], ["Convers", "Anthony", ""], ["Dassatti", "Alberto", ""]]}, {"id": "1609.00512", "submitter": "Adrian Kosowski", "authors": "Adrian Kosowski (GANG), Laurent Viennot (GANG)", "title": "Beyond Highway Dimension: Small Distance Labels Using Tree Skeletons", "comments": "SODA 2017 - 28th ACM-SIAM Symposium on Discrete Algorithms, Jan 2017,\n  Barcelona, Spain. 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of a hub-based distance labeling scheme for a network G = (V, E) is\nto assign a small subset S(u) $\\subseteq$ V to each node u $\\in$ V, in such a\nway that for any pair of nodes u, v, the intersection of hub sets S(u) $\\cap$\nS(v) contains a node on the shortest uv-path. The existence of small hub sets,\nand consequently efficient shortest path processing algorithms, for road\nnetworks is an empirical observation. A theoretical explanation for this\nphenomenon was proposed by Abraham et al. (SODA 2010) through a network\nparameter they called highway dimension, which captures the size of a hitting\nset for a collection of shortest paths of length at least r intersecting a\ngiven ball of radius 2r. In this work, we revisit this explanation, introducing\na more tractable (and directly comparable) parameter based solely on the\nstructure of shortest-path spanning trees, which we call skeleton dimension. We\nshow that skeleton dimension admits an intuitive definition for both directed\nand undirected graphs, provides a way of computing labels more efficiently than\nby using highway dimension, and leads to comparable or stronger theoretical\nbounds on hub set size.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2016 09:15:19 GMT"}, {"version": "v2", "created": "Mon, 12 Dec 2016 14:28:43 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Kosowski", "Adrian", "", "GANG"], ["Viennot", "Laurent", "", "GANG"]]}, {"id": "1609.01043", "submitter": "Jose Aznar", "authors": "J. Aznar, E. Escalona, I. Canyameres, O. Moya, A. Vi\\~nes", "title": "CNSMO: A Network Services Manager/Orchestrator Tool for Cloud Federated\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Application service providers (ASPs) now develop, deploy, and maintain\ncomplex computing platforms within multiple cloud infrastructures to improve\nresilience, responsiveness and elasticity of their applications. On the other\nhand, complex applications have little control and visibility over network\nresources, and need to use low-level hacks to extract network properties and\nprioritize traffic. This biased view, limits tenants flexibility while\ndeploying their applications and prevents them from implementing part of the\napplication logic in the network. In this paper, we propose the CNSMO (CYCLONE\nNetwork Services Manager/Orchestrator) tool to bring the innovation at\nfederated cloud environments by bridging these network service capabilities to\ncloud based services as part of the overall CYCLONE solution. The integration\nof networking aspects with purely federated clouds, will allow users to request\nspecific infrastructures and manage their dedicated set of coordinated network\nand IT resources in an easy and transparent way while operating dynamic\ndeployments of distributed applications.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 07:43:35 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Aznar", "J.", ""], ["Escalona", "E.", ""], ["Canyameres", "I.", ""], ["Moya", "O.", ""], ["Vi\u00f1es", "A.", ""]]}, {"id": "1609.01055", "submitter": "Gilles Tredan", "authors": "Gilles Tredan and Hans Peter Schwefel", "title": "Fast Abstracts and Student Forum Proceedings - EDCC 2016 - 12th European\n  Dependable Computing Conference", "comments": "12th European Dependable Computing Conference, Gothenburg, Sweden,\n  September 5-9, 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fast Abstracts are short presentations of work in progress or opinion pieces\nand aim to serve as a rapid and flexible mechanism to (i) Report on current\nwork that may or may not be complete; (ii) Introduce new ideas to the\ncommunity; (iii) State positions on controversial issues or open problems. On\nthe other hand, the goal of the Student Forum is to encourage students to\nattend EDCC and present their work, exchange ideas with researchers and\npractitioners, and get early feedback on their research efforts.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 08:27:10 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Tredan", "Gilles", ""], ["Schwefel", "Hans Peter", ""]]}, {"id": "1609.01068", "submitter": "Christopher Meiklejohn", "authors": "Borja Arnau de R\\'egil Bas\\'a\\~nez, Christopher S. Meiklejohn", "title": "Dynamic Path Contraction for Distributed, Dynamic Dataflow Languages", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a work in progress report on applying deforestation to\ndistributed, dynamic dataflow programming models. We propose a novel algorithm,\ndynamic path contraction, that applies and reverses optimizations to a\ndistributed dataflow application as the program executes. With this algorithm,\ndata and control flow is tracked by the runtime system used to identify\npotential optimizations as the system is running. We demonstrate and present\npreliminary results regarding this technique on an actor-based distributed\nprogramming model, Lasp, implemented on the Erlang virtual machine.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 09:05:05 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Bas\u00e1\u00f1ez", "Borja Arnau de R\u00e9gil", ""], ["Meiklejohn", "Christopher S.", ""]]}, {"id": "1609.01171", "submitter": "Artem Khyzha", "authors": "Artem Khyzha, Alexey Gotsman, Matthew Parkinson", "title": "A Generic Logic for Proving Linearizability (Extended Version)", "comments": "Formal Methods 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Linearizability is a commonly accepted notion of correctness for libraries of\nconcurrent algorithms, and recent years have seen a number of proposals of\nprogram logics for proving it. Although these logics differ in technical\ndetails, they embody similar reasoning principles. To explicate these\nprinciples, we propose a logic for proving linearizability that is generic: it\ncan be instantiated with different means of compositional reasoning about\nconcurrency, such as separation logic or rely-guarantee. To this end, we\ngeneralise the Views framework for reasoning about concurrency to handle\nrelations between programs, required for proving linearizability. We present\nsample instantiations of our generic logic and show that it is powerful enough\nto handle concurrent algorithms with challenging features, such as helping.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 14:12:03 GMT"}], "update_date": "2016-09-06", "authors_parsed": [["Khyzha", "Artem", ""], ["Gotsman", "Alexey", ""], ["Parkinson", "Matthew", ""]]}, {"id": "1609.01257", "submitter": "Nuno Fachada", "authors": "Nuno Fachada, Vitor V. Lopes, Rui C. Martins, Agostinho C. Rosa", "title": "cf4ocl: a C framework for OpenCL", "comments": "The peer-reviewed version of this paper is published in Science of\n  Computer Programming at\n  http://www.sciencedirect.com/science/article/pii/S0167642317300540 . This\n  version is typeset by the authors and differs only in pagination and\n  typographical detail", "journal-ref": "Science of Computer Programming, 143, pp. 9-19, 2017", "doi": "10.1016/j.scico.2017.03.005", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenCL is an open standard for parallel programming of heterogeneous compute\ndevices, such as GPUs, CPUs, DSPs or FPGAs. However, the verbosity of its C\nhost API can hinder application development. In this paper we present cf4ocl, a\nsoftware library for rapid development of OpenCL programs in pure C. It aims to\nreduce the verbosity of the OpenCL API, offering straightforward memory\nmanagement, integrated profiling of events (e.g., kernel execution and data\ntransfers), simple but extensible device selection mechanism and user-friendly\nerror management. We compare two versions of a conceptual application example,\none based on cf4ocl, the other developed directly with the OpenCL host API.\nResults show that the former is simpler to implement and offers more features,\nat the cost of an effectively negligible computational overhead. Additionally,\nthe tools provided with cf4ocl allowed for a quick analysis on how to optimize\nthe application.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2016 19:07:48 GMT"}, {"version": "v2", "created": "Mon, 6 Feb 2017 22:40:33 GMT"}, {"version": "v3", "created": "Fri, 12 May 2017 22:26:23 GMT"}], "update_date": "2017-05-16", "authors_parsed": [["Fachada", "Nuno", ""], ["Lopes", "Vitor V.", ""], ["Martins", "Rui C.", ""], ["Rosa", "Agostinho C.", ""]]}, {"id": "1609.01410", "submitter": "M.M.A. Hashem", "authors": "Jarin Firose Moon, Shamminuj Aktar and M.M.A. Hashem", "title": "Securely Outsourcing Large Scale Eigen Value Problem to Public Cloud", "comments": null, "journal-ref": "Computer and Information Technology (ICCIT), 2015 18th\n  International Conference on", "doi": "10.1109/ICCITechn.2015.7488120", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing enables clients with limited computational power to\neconomically outsource their large scale computations to a public cloud with\nhuge computational power. Cloud has the massive storage, computational power\nand software which can be used by clients for reducing their computational\noverhead and storage limitation. But in case of outsourcing, privacy of\nclient's confidential data must be maintained. We have designed a protocol for\noutsourcing large scale Eigen value problem to a malicious cloud which provides\ninput/output data security, result verifiability and client's efficiency. As\nthe direct computation method to find all eigenvectors is computationally\nexpensive for large dimensionality, we have used power iterative method for\nfinding the largest Eigen value and the corresponding Eigen vector of a matrix.\nFor protecting the privacy, some transformations are applied to the input\nmatrix to get encrypted matrix which is sent to the cloud and then decrypting\nthe result that is returned from the cloud for getting the correct solution of\nEigen value problem. We have also proposed result verification mechanism for\ndetecting robust cheating and provided theoretical analysis and experimental\nresult that describes high-efficiency, correctness, security and robust\ncheating resistance of the proposed protocol.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 06:33:04 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Moon", "Jarin Firose", ""], ["Aktar", "Shamminuj", ""], ["Hashem", "M. M. A.", ""]]}, {"id": "1609.01479", "submitter": "Alan Gray", "authors": "Alan Gray and Kevin Stratford", "title": "A Lightweight Approach to Performance Portability with targetDP", "comments": "11 pages, 5 figures, accepted to the International Journal of High\n  Performance Computing Applications (IJHPCA), acceptance date 27th October\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC hep-lat", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leading HPC systems achieve their status through use of highly parallel\ndevices such as NVIDIA GPUs or Intel Xeon Phi many-core CPUs. The concept of\nperformance portability across such architectures, as well as traditional CPUs,\nis vital for the application programmer. In this paper we describe targetDP, a\nlightweight abstraction layer which allows grid-based applications to target\ndata parallel hardware in a platform agnostic manner. We demonstrate the\neffectiveness of our pragmatic approach by presenting performance results for a\ncomplex fluid application (with which the model was co-designed), plus a\nseparate lattice QCD particle physics code. For each application, a single\nsource code base is seen to achieve portable performance, as assessed within\nthe context of the Roofline model. TargetDP can be combined with MPI to allow\nuse on systems containing multiple nodes: we demonstrate this through provision\nof scaling results on traditional and GPU-accelerated large scale\nsupercomputers.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 10:38:02 GMT"}, {"version": "v2", "created": "Wed, 9 Nov 2016 20:28:04 GMT"}], "update_date": "2016-11-10", "authors_parsed": [["Gray", "Alan", ""], ["Stratford", "Kevin", ""]]}, {"id": "1609.01490", "submitter": "Crist\\'obal A. Navarro", "authors": "Crist\\'obal A. Navarro, Benjam\\'in Bustos, Nancy Hitschfeld", "title": "A Non-linear GPU Thread Map for Triangular Domains", "comments": "16 pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is a stage in the GPU computing pipeline where a grid of thread-blocks,\nin \\textit{parallel space}, is mapped onto the problem domain, in \\textit{data\nspace}. Since the parallel space is restricted to a box type geometry, the\nmapping approach is typically a $k$-dimensional bounding box (BB) that covers a\n$p$-dimensional data space. Threads that fall inside the domain perform\ncomputations while threads that fall outside are discarded at runtime. In this\nwork we study the case of mapping threads efficiently onto triangular domain\nproblems and propose a block-space linear map $\\lambda(\\omega)$, based on the\nproperties of the lower triangular matrix, that reduces the number of\nunnnecessary threads from $\\mathcal{O}(n^2)$ to $\\mathcal{O}(n)$. Performance\nresults for global memory accesses show an improvement of up to $18\\%$ with\nrespect to the \\textit{bounding-box} approach, placing $\\lambda(\\omega)$ on\nsecond place below the \\textit{rectangular-box} approach and above the\n\\textit{recursive-partition} and \\textit{upper-triangular} approaches. For\nshared memory scenarios $\\lambda(\\omega)$ was the fastest approach achieving\n$7\\%$ of performance improvement while preserving thread locality. The results\nobtained in this work make $\\lambda(\\omega)$ an interesting map for efficient\nGPU computing on parallel problems that define a triangular domain with or\nwithout neighborhood interactions. The extension to tetrahedral domains is\nanalyzed, with applications to triplet-interaction n-body applications.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 11:23:13 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Navarro", "Crist\u00f3bal A.", ""], ["Bustos", "Benjam\u00edn", ""], ["Hitschfeld", "Nancy", ""]]}, {"id": "1609.01507", "submitter": "Nicolay Hammer", "authors": "Nicolay Hammer, Ferdinand Jamitzky, Helmut Satzger, Momme Allalen,\n  Alexander Block, Anupam Karmakar, Matthias Brehm, Reinhold Bader, Luigi\n  Iapichino, Antonio Ragagnin, Vasilios Karakasis, Dieter Kranzlm\\\"uller, Arndt\n  Bode, Herbert Huber, Martin K\\\"uhn, Rui Machado, Daniel Gr\\\"unewald, Philipp\n  V. F. Edelmann, Friedrich K. R\\\"opke, Markus Wittmann, Thomas Zeiser, Gerhard\n  Wellein, Gerald Mathias, Magnus Schw\\\"orer, Konstantin Lorenzen, Christoph\n  Federrath, Ralf Klessen, Karl-Ulrich Bamberg, Hartmut Ruhl, Florian\n  Schornbaum, Martin Bauer, Anand Nikhil, Jiaxing Qi, Harald Klimach, Hinnerk\n  St\\\"uben, Abhishek Deshmukh, Tobias Falkenstein, Klaus Dolag, Margarita\n  Petkova", "title": "Extreme Scale-out SuperMUC Phase 2 - lessons learned", "comments": "10 pages, 5 figures, presented at ParCo2015 - Advances in Parallel\n  Computing, held in Edinburgh, September 2015. The final publication is\n  available at IOS Press through\n  http://dx.doi.org/10.3233/978-1-61499-621-7-827", "journal-ref": "Advances in Parallel Computing, vol. 27: Parallel Computing: On\n  the Road to Exascale, eds. G.R. Joubert et al., p. 827, 2016", "doi": "10.3233/978-1-61499-621-7-827", "report-no": null, "categories": "cs.DC astro-ph.IM physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In spring 2015, the Leibniz Supercomputing Centre (Leibniz-Rechenzentrum,\nLRZ), installed their new Peta-Scale System SuperMUC Phase2. Selected users\nwere invited for a 28 day extreme scale-out block operation during which they\nwere allowed to use the full system for their applications. The following\nprojects participated in the extreme scale-out workshop: BQCD (Quantum\nPhysics), SeisSol (Geophysics, Seismics), GPI-2/GASPI (Toolkit for HPC),\nSeven-League Hydro (Astrophysics), ILBDC (Lattice Boltzmann CFD), Iphigenie\n(Molecular Dynamic), FLASH (Astrophysics), GADGET (Cosmological Dynamics), PSC\n(Plasma Physics), waLBerla (Lattice Boltzmann CFD), Musubi (Lattice Boltzmann\nCFD), Vertex3D (Stellar Astrophysics), CIAO (Combustion CFD), and LS1-Mardyn\n(Material Science). The projects were allowed to use the machine exclusively\nduring the 28 day period, which corresponds to a total of 63.4 million\ncore-hours, of which 43.8 million core-hours were used by the applications,\nresulting in a utilization of 69%. The top 3 users were using 15.2, 6.4, and\n4.7 million core-hours, respectively.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 12:01:26 GMT"}], "update_date": "2016-09-07", "authors_parsed": [["Hammer", "Nicolay", ""], ["Jamitzky", "Ferdinand", ""], ["Satzger", "Helmut", ""], ["Allalen", "Momme", ""], ["Block", "Alexander", ""], ["Karmakar", "Anupam", ""], ["Brehm", "Matthias", ""], ["Bader", "Reinhold", ""], ["Iapichino", "Luigi", ""], ["Ragagnin", "Antonio", ""], ["Karakasis", "Vasilios", ""], ["Kranzlm\u00fcller", "Dieter", ""], ["Bode", "Arndt", ""], ["Huber", "Herbert", ""], ["K\u00fchn", "Martin", ""], ["Machado", "Rui", ""], ["Gr\u00fcnewald", "Daniel", ""], ["Edelmann", "Philipp V. F.", ""], ["R\u00f6pke", "Friedrich K.", ""], ["Wittmann", "Markus", ""], ["Zeiser", "Thomas", ""], ["Wellein", "Gerhard", ""], ["Mathias", "Gerald", ""], ["Schw\u00f6rer", "Magnus", ""], ["Lorenzen", "Konstantin", ""], ["Federrath", "Christoph", ""], ["Klessen", "Ralf", ""], ["Bamberg", "Karl-Ulrich", ""], ["Ruhl", "Hartmut", ""], ["Schornbaum", "Florian", ""], ["Bauer", "Martin", ""], ["Nikhil", "Anand", ""], ["Qi", "Jiaxing", ""], ["Klimach", "Harald", ""], ["St\u00fcben", "Hinnerk", ""], ["Deshmukh", "Abhishek", ""], ["Falkenstein", "Tobias", ""], ["Dolag", "Klaus", ""], ["Petkova", "Margarita", ""]]}, {"id": "1609.01567", "submitter": "Jan Broulim", "authors": "Jan Broulim, Alexander Ayriyan, Vjaceslav Georgiev, Hovik Grigorian", "title": "OpenCL/CUDA algorithms for parallel decoding of any irregular LDPC code\n  using GPU", "comments": null, "journal-ref": "TELFOR Journal, vol. 11(2), pp. 90-95 (2019)", "doi": "10.5937/telfor1902090B", "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of multicore architectures supporting parallel data\nprocessing has led to a paradigm shift, which affects communication systems\nsignificantly. This article provides a scalable parallel approach of an\niterative LDPC decoder, presented in a tutorial-based style. It is suitable for\ndecoding any irregular LDPC code without the limitation of the maximum node\ndegree, and it includes a parallel calculation of the syndrome. This is the\nmain difference from algorithms presented so far. The proposed approach can be\nimplemented in applications supporting massive parallel computing, such as GPU\nor FPGA devices. The implementation of the LDPC decoder with the use the OpenCL\nand CUDA frameworks is discussed and the performance evaluation is given at the\nend of this contribution.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 14:18:32 GMT"}, {"version": "v2", "created": "Tue, 26 Sep 2017 18:37:37 GMT"}], "update_date": "2020-01-31", "authors_parsed": [["Broulim", "Jan", ""], ["Ayriyan", "Alexander", ""], ["Georgiev", "Vjaceslav", ""], ["Grigorian", "Hovik", ""]]}, {"id": "1609.01690", "submitter": "Songze Li", "authors": "Songze Li, Mohammad Ali Maddah-Ali, A. Salman Avestimehr", "title": "A Unified Coding Framework for Distributed Computing with Straggling\n  Servers", "comments": "a shorter version to appear in NetCod 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a unified coded framework for distributed computing with\nstraggling servers, by introducing a tradeoff between \"latency of computation\"\nand \"load of communication\" for some linear computation tasks. We show that the\ncoded scheme of [1]-[3] that repeats the intermediate computations to create\ncoded multicasting opportunities to reduce communication load, and the coded\nscheme of [4], [5] that generates redundant intermediate computations to combat\nagainst straggling servers can be viewed as special instances of the proposed\nframework, by considering two extremes of this tradeoff: minimizing either the\nload of communication or the latency of computation individually. Furthermore,\nthe latency-load tradeoff achieved by the proposed coded framework allows to\nsystematically operate at any point on that tradeoff to perform distributed\ncomputing tasks. We also prove an information-theoretic lower bound on the\nlatency-load tradeoff, which is shown to be within a constant multiplicative\ngap from the achieved tradeoff at the two end points.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2016 18:37:56 GMT"}], "update_date": "2016-10-26", "authors_parsed": [["Li", "Songze", ""], ["Maddah-Ali", "Mohammad Ali", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "1609.01967", "submitter": "Blesson Varghese", "authors": "Blesson Varghese and Nan Wang and Sakil Barbhuiya and Peter Kilpatrick\n  and Dimitrios S. Nikolopoulos", "title": "Challenges and Opportunities in Edge Computing", "comments": "6 pages, accepted to IEEE SmartCloud 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many cloud-based applications employ a data centre as a central server to\nprocess data that is generated by edge devices, such as smartphones, tablets\nand wearables. This model places ever increasing demands on communication and\ncomputational infrastructure with inevitable adverse effect on\nQuality-of-Service and Experience. The concept of Edge Computing is predicated\non moving some of this computational load towards the edge of the network to\nharness computational capabilities that are currently untapped in edge nodes,\nsuch as base stations, routers and switches. This position paper considers the\nchallenges and opportunities that arise out of this new direction in the\ncomputing landscape.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 12:54:22 GMT"}], "update_date": "2016-09-08", "authors_parsed": [["Varghese", "Blesson", ""], ["Wang", "Nan", ""], ["Barbhuiya", "Sakil", ""], ["Kilpatrick", "Peter", ""], ["Nikolopoulos", "Dimitrios S.", ""]]}, {"id": "1609.02035", "submitter": "Tom Z. J. Fu", "authors": "Meihua Wang, Jiaming Mai, Yun Liang, Tom Z. J. Fu, Zhenjie Zhang,\n  Ruichu Cai", "title": "Component-Based Distributed Framework for Coherent and Real-Time Video\n  Dehazing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional dehazing techniques, as a well studied topic in image processing,\nare now widely used to eliminate the haze effects from individual images.\nHowever, even the state-of-the-art dehazing algorithms may not provide\nsufficient support to video analytics, as a crucial pre-processing step for\nvideo-based decision making systems (e.g., robot navigation), due to the\nlimitations of these algorithms on poor result coherence and low processing\nefficiency. This paper presents a new framework, particularly designed for\nvideo dehazing, to output coherent results in real time, with two novel\ntechniques. Firstly, we decompose the dehazing algorithms into three generic\ncomponents, namely transmission map estimator, atmospheric light estimator and\nhaze-free image generator. They can be simultaneously processed by multiple\nthreads in the distributed system, such that the processing efficiency is\noptimized by automatic CPU resource allocation based on the workloads.\nSecondly, a cross-frame normalization scheme is proposed to enhance the\ncoherence among consecutive frames, by sharing the parameters of atmospheric\nlight from consecutive frames in the distributed computation platform. The\ncombination of these techniques enables our framework to generate highly\nconsistent and accurate dehazing results in real-time, by using only 3 PCs\nconnected by Ethernet.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 15:56:09 GMT"}, {"version": "v2", "created": "Fri, 9 Sep 2016 16:14:01 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Wang", "Meihua", ""], ["Mai", "Jiaming", ""], ["Liang", "Yun", ""], ["Fu", "Tom Z. J.", ""], ["Zhang", "Zhenjie", ""], ["Cai", "Ruichu", ""]]}, {"id": "1609.02104", "submitter": "Yue Wang", "authors": "Yue Wang, Alexandra Meliou, Gerome Miklau", "title": "A Consumer-Centric Market for Database Computation in the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of public computing resources in the cloud has\nrevolutionized data analysis, but requesting cloud resources often involves\ncomplex decisions for consumers. Under the current pricing mechanisms, cloud\nservice providers offer several service options and charge consumers based on\nthe resources they use. Before they can decide which cloud resources to\nrequest, consumers have to estimate the completion time and cost of their\ncomputational tasks for different service options and possibly for different\nservice providers. This estimation is challenging even for expert cloud users.\nWe propose a new market-based framework for pricing computational tasks in the\ncloud. Our framework introduces an agent between consumers and cloud providers.\nThe agent takes data and computational tasks from users, estimates time and\ncost for evaluating the tasks, and returns to consumers contracts that specify\nthe price and completion time. Our framework can be applied directly to\nexisting cloud markets without altering the way cloud providers offer and price\nservices. In addition, it simplifies cloud use for consumers by allowing them\nto compare contracts, rather than choose resources directly. We present design,\nanalytical, and algorithmic contributions focusing on pricing computation\ncontracts, analyzing their properties, and optimizing them in complex\nworkflows. We conduct an experimental evaluation of our market framework over a\nreal-world cloud service and demonstrate empirically that our market ensures\nthree key properties: competitiveness, fairness, and resilience. Finally, we\npresent a fine-grained pricing mechanism for complex workflows and show that it\ncan increase agent profits by more than an order of magnitude in some cases.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2016 18:42:09 GMT"}, {"version": "v2", "created": "Sun, 11 Sep 2016 06:25:36 GMT"}, {"version": "v3", "created": "Fri, 16 Sep 2016 14:19:02 GMT"}, {"version": "v4", "created": "Thu, 17 Nov 2016 19:55:15 GMT"}, {"version": "v5", "created": "Tue, 22 Nov 2016 02:31:53 GMT"}, {"version": "v6", "created": "Fri, 16 Jun 2017 20:40:04 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Wang", "Yue", ""], ["Meliou", "Alexandra", ""], ["Miklau", "Gerome", ""]]}, {"id": "1609.02305", "submitter": "Klaus-Tycho Foerster", "authors": "Klaus-Tycho Foerster, Stefan Schmid, Stefano Vissicchio", "title": "Survey of Consistent Software-Defined Network Updates", "comments": null, "journal-ref": "IEEE Communications Surveys & Tutorials 2019", "doi": "10.1109/COMST.2018.2876749", "report-no": null, "categories": "cs.NI cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer networks have become a critical infrastructure. In fact, networks\nshould not only meet strict requirements in terms of correctness, availability,\nand performance, but they should also be very flexible and support fast\nupdates, e.g., due to policy changes, increasing traffic, or failures. This\npaper presents a structured survey of mechanism and protocols to update\ncomputer networks in a fast and consistent manner. In particular, we identify\nand discuss the different desirable consistency properties that should be\nprovided throughout a network update, the algorithmic techniques which are\nneeded to meet these consistency properties, and the implications on the speed\nand costs at which updates can be performed. We also explain the relationship\nbetween consistent network update problems and classic algorithmic optimization\nones. While our survey is mainly motivated by the advent of Software-Defined\nNetworks (SDNs) and their primary need for correct and efficient update\ntechniques, the fundamental underlying problems are not new, and we provide a\nhistorical perspective of the subject as well.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 07:34:39 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 15:42:18 GMT"}, {"version": "v3", "created": "Tue, 26 Mar 2019 13:33:38 GMT"}], "update_date": "2019-03-27", "authors_parsed": [["Foerster", "Klaus-Tycho", ""], ["Schmid", "Stefan", ""], ["Vissicchio", "Stefano", ""]]}, {"id": "1609.02434", "submitter": "Dragos-Adrian Seredinschi M.Sc.", "authors": "Rachid Guerraoui and Matej Pavlovic and Dragos-Adrian Seredinschi", "title": "Incremental Consistency Guarantees for Replicated Objects", "comments": "16 total pages, 12 figures. OSDI'16 (to appear)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Programming with replicated objects is difficult. Developers must face the\nfundamental trade-off between consistency and performance head on, while\nstruggling with the complexity of distributed storage stacks. We introduce\nCorrectables, a novel abstraction that hides most of this complexity, allowing\ndevelopers to focus on the task of balancing consistency and performance. To\naid developers with this task, Correctables provide incremental consistency\nguarantees, which capture successive refinements on the result of an ongoing\noperation on a replicated object. In short, applications receive both a\npreliminary---fast, possibly inconsistent---result, as well as a\nfinal---consistent---result that arrives later.\n  We show how to leverage incremental consistency guarantees by speculating on\npreliminary values, trading throughput and bandwidth for improved latency. We\nexperiment with two popular storage systems (Cassandra and ZooKeeper) and three\napplications: a Twissandra-based microblogging service, an ad serving system,\nand a ticket selling system. Our evaluation on the Amazon EC2 platform with\nYCSB workloads A, B, and C shows that we can reduce the latency of strongly\nconsistent operations by up to 40% (from 100ms to 60ms) at little cost (10%\nbandwidth increase, 6% throughput drop) in the ad system. Even if the\npreliminary result is frequently inconsistent (25% of accesses), incremental\nconsistency incurs a bandwidth overhead of only 27%.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 14:05:05 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["Guerraoui", "Rachid", ""], ["Pavlovic", "Matej", ""], ["Seredinschi", "Dragos-Adrian", ""]]}, {"id": "1609.02450", "submitter": "Katina Kralevska", "authors": "Katina Kralevska, Danilo Gligoroski, Rune E. Jensen, and Harald\n  {\\O}verby", "title": "HashTag Erasure Codes: From Theory to Practice", "comments": "Submitted to IEEE Transactions on Big Data", "journal-ref": "Published in: IEEE Transactions on Big Data Volume: 4 , Issue: 4 ,\n  Dec. 1 2018", "doi": "10.1109/TBDATA.2017.2749255", "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Minimum-Storage Regenerating (MSR) codes have emerged as a viable alternative\nto Reed-Solomon (RS) codes as they minimize the repair bandwidth while they are\nstill optimal in terms of reliability and storage overhead. Although several\nMSR constructions exist, so far they have not been practically implemented\nmainly due to the big number of I/O operations. In this paper, we analyze\nhigh-rate MDS codes that are simultaneously optimized in terms of storage,\nreliability, I/O operations, and repair-bandwidth for single and multiple\nfailures of the systematic nodes. The codes were recently introduced in\n\\cite{7463553} without any specific name. Due to the resemblance between the\nhashtag sign \\# and the procedure of the code construction, we call them in\nthis paper \\emph{HashTag Erasure Codes (HTECs)}. HTECs provide the lowest\ndata-read and data-transfer, and thus the lowest repair time for an arbitrary\nsub-packetization level $\\alpha$, where $\\alpha \\leq r^{\\lceil \\sfrac{k}{r}\n\\rceil}$, among all existing MDS codes for distributed storage including MSR\ncodes. The repair process is linear and highly parallel. Additionally, we show\nthat HTECs are the first high-rate MDS codes that reduce the repair bandwidth\nfor more than one failure. Practical implementations of HTECs in Hadoop release\n3.0.0-alpha2 demonstrate their great potentials.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2016 14:53:41 GMT"}, {"version": "v2", "created": "Sat, 22 Apr 2017 11:52:56 GMT"}, {"version": "v3", "created": "Mon, 26 Jun 2017 07:58:36 GMT"}, {"version": "v4", "created": "Mon, 3 Jul 2017 10:24:15 GMT"}], "update_date": "2020-02-14", "authors_parsed": [["Kralevska", "Katina", ""], ["Gligoroski", "Danilo", ""], ["Jensen", "Rune E.", ""], ["\u00d8verby", "Harald", ""]]}, {"id": "1609.02694", "submitter": "Antonella Del Pozzo", "authors": "Silvia Bonomi (DIAG), Antonella Del Pozzo (DIAG, NPA), Maria\n  Potop-Butucaru (NPA), S\\'ebastien Tixeuil (NPA, IUF, LINCS)", "title": "Optimal Self-Stabilizing Mobile Byzantine-Tolerant Regular Register with\n  bounded timestamp", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes the first implementation of a self-stabilizing regular\nregister emulated by $n$ servers that is tolerant to both mobile Byzantine\nagents, and \\emph{transient failures} in a round-free synchronous model.\nDifferently from existing Mobile Byzantine tolerant register implementations,\nthis paper considers a more powerful adversary where (i) the message delay\n(i.e., $\\delta$) and the period of mobile Byzantine agents movement (i.e.,\n$\\Delta$) are completely decoupled and (ii) servers are not aware of their\nstate i.e., they do not know if they have been corrupted or not by a mobile\nByzantine agent.The proposed protocol tolerates \\emph{(i)} any number of\ntransient failures, and \\emph{(ii)} up to $f$ Mobile Byzantine agents. In\naddition, our implementation uses bounded timestamps from the\n$\\mathcal{Z}\\_{13}$ domain and it is optimal with respect to the number of\nservers needed to tolerate $f$ mobile Byzantine agents in the given model.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 08:34:31 GMT"}, {"version": "v2", "created": "Tue, 23 Oct 2018 06:36:50 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Bonomi", "Silvia", "", "DIAG"], ["Del Pozzo", "Antonella", "", "DIAG, NPA"], ["Potop-Butucaru", "Maria", "", "NPA"], ["Tixeuil", "S\u00e9bastien", "", "NPA, IUF, LINCS"]]}, {"id": "1609.02845", "submitter": "Shahin Shahrampour", "authors": "Shahin Shahrampour, Ali Jadbabaie", "title": "Distributed Online Optimization in Dynamic Environments Using Mirror\n  Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work addresses decentralized online optimization in non-stationary\nenvironments. A network of agents aim to track the minimizer of a global\ntime-varying convex function. The minimizer evolves according to a known\ndynamics corrupted by an unknown, unstructured noise. At each time, the global\nfunction can be cast as a sum of a finite number of local functions, each of\nwhich is assigned to one agent in the network. Moreover, the local functions\nbecome available to agents sequentially, and agents do not have a prior\nknowledge of the future cost functions. Therefore, agents must communicate with\neach other to build an online approximation of the global function. We propose\na decentralized variation of the celebrated Mirror Descent, developed by\nNemirovksi and Yudin. Using the notion of Bregman divergence in lieu of\nEuclidean distance for projection, Mirror Descent has been shown to be a\npowerful tool in large-scale optimization. Our algorithm builds on Mirror\nDescent, while ensuring that agents perform a consensus step to follow the\nglobal function and take into account the dynamics of the global minimizer. To\nmeasure the performance of the proposed online algorithm, we compare it to its\noffline counterpart, where the global functions are available a priori. The gap\nbetween the two is called dynamic regret. We establish a regret bound that\nscales inversely in the spectral gap of the network, and more notably it\nrepresents the deviation of minimizer sequence with respect to the given\ndynamics. We then show that our results subsume a number of results in\ndistributed optimization. We demonstrate the application of our method to\ndecentralized tracking of dynamic parameters and verify the results via\nnumerical experiments.\n", "versions": [{"version": "v1", "created": "Fri, 9 Sep 2016 16:00:04 GMT"}], "update_date": "2016-09-12", "authors_parsed": [["Shahrampour", "Shahin", ""], ["Jadbabaie", "Ali", ""]]}, {"id": "1609.02982", "submitter": "Haoyu Song", "authors": "Haoyu Song and Jun Gong and Hongfei Chen", "title": "Network Map Reduce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Networking data analytics is increasingly used for enhanced network\nvisibility and controllability. We draw the similarities between the Software\nDefined Networking (SDN) architecture and the MapReduce programming model.\nInspired by the similarity, we suggest the necessary data plane innovations to\nmake network data plane devices function as distributed mappers and optionally,\nreducers. A streaming network data MapReduce architecture can therefore\nconveniently solve a series of network monitoring and management problems.\nUnlike the traditional networking data analytical system, our proposed system\nembeds the data analytics engine directly in the network infrastructure. The\naffinity leads to a concise system architecture and better cost performance\nratio. On top of this architecture, we propose a general MapReduce-like\nprogramming model for real-time and one-pass networking data analytics, which\ninvolves joint in-network and out-of-network computing. We show this model can\naddress a wide range of interactive queries from various network applications.\nThis position paper strives to make a point that the white-box trend does not\nnecessarily lead to simple and dumb networking devices. Rather, the defining\ncharacteristics of the next generation white-box are open and programmable, so\nthat the network devices can be made smart and versatile to support new\nservices and applications.\n", "versions": [{"version": "v1", "created": "Sat, 10 Sep 2016 00:56:04 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Song", "Haoyu", ""], ["Gong", "Jun", ""], ["Chen", "Hongfei", ""]]}, {"id": "1609.03157", "submitter": "Milad Moradi Vastegani", "authors": "Milad Moradi", "title": "A centralized reinforcement learning method for multi-agent job\n  scheduling in Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the main challenges in Grid systems is designing an adaptive,\nscalable, and model-independent method for job scheduling to achieve a\ndesirable degree of load balancing and system efficiency. Centralized job\nscheduling methods have some drawbacks, such as single point of failure and\nlack of scalability. Moreover, decentralized methods require a coordination\nmechanism with limited communications. In this paper, we propose a multi-agent\napproach to job scheduling in Grid, named Centralized Learning Distributed\nScheduling (CLDS), by utilizing the reinforcement learning framework. The CLDS\nis a model free approach that uses the information of jobs and their completion\ntime to estimate the efficiency of resources. In this method, there are a\nlearner agent and several scheduler agents that perform the task of learning\nand job scheduling with the use of a coordination strategy that maintains the\ncommunication cost at a limited level. We evaluated the efficiency of the CLDS\nmethod by designing and performing a set of experiments on a simulated Grid\nsystem under different system scales and loads. The results show that the CLDS\ncan effectively balance the load of system even in large scale and heavy loaded\nGrids, while maintains its adaptive performance and scalability.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2016 13:03:21 GMT"}], "update_date": "2016-09-13", "authors_parsed": [["Moradi", "Milad", ""]]}, {"id": "1609.03590", "submitter": "Tao Chen", "authors": "Tao Chen, Rami Bahsoon, Xin Yao", "title": "A Survey and Taxonomy of Self-Aware and Self-Adaptive Cloud Autoscaling\n  Systems", "comments": "This paper has been accepted by ACM Computing Surveys (CSUR), please\n  use the following citation information: Tao Chen, Rami Bahsoon, and Xin Yao.\n  2018. A Survey and Taxonomy of Self-Aware and Self-Adaptive Cloud Autoscaling\n  Systems. ACM Computing Surveys, 51, 3, Article 61 (April 2018), 40 pages", "journal-ref": "ACM Computing Surveys, vol. 51, no. 3, 2018", "doi": "10.1145/3190507", "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoscaling system can reconfigure cloud-based services and applications,\nthrough various configurations of cloud software and provisions of hardware\nresources, to adapt to the changing environment at runtime. Such a behavior\noffers the foundation for achieving elasticity in modern cloud computing\nparadigm. Given the dynamic and uncertain nature of the shared cloud\ninfrastructure, cloud autoscaling system has been engineered as one of the most\ncomplex, sophisticated and intelligent artifacts created by human, aiming to\nachieve self-aware, self-adaptive and dependable runtime scaling. Yet, existing\nSelf-aware and Self-adaptive Cloud Autoscaling System (SSCAS) is not mature to\na state that it can be reliably exploited in the cloud. In this article, we\nsurvey the state-of-the-art research studies on SSCAS and provide a\ncomprehensive taxonomy for this field. We present detailed analysis of the\nresults and provide insights on open challenges, as well as the promising\ndirections that are worth investigated in the future work of this area of\nresearch. Our survey and taxonomy contribute to the fundamentals of engineering\nmore intelligent autoscaling systems in the cloud.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2016 20:15:13 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 22:26:39 GMT"}, {"version": "v3", "created": "Wed, 4 Apr 2018 23:02:23 GMT"}, {"version": "v4", "created": "Wed, 25 Apr 2018 13:05:23 GMT"}], "update_date": "2018-04-26", "authors_parsed": [["Chen", "Tao", ""], ["Bahsoon", "Rami", ""], ["Yao", "Xin", ""]]}, {"id": "1609.03647", "submitter": "Andre Luckow", "authors": "Shantenu Jha, Daniel S. Katz, Andre Luckow, Omer Rana, Yogesh Simmhan,\n  Neil Chue Hong", "title": "Introducing Distributed Dynamic Data-intensive (D3) Science:\n  Understanding Applications and Infrastructure", "comments": "38 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A common feature across many science and engineering applications is the\namount and diversity of data and computation that must be integrated to yield\ninsights. Data sets are growing larger and becoming distributed; and their\nlocation, availability and properties are often time-dependent. Collectively,\nthese characteristics give rise to dynamic distributed data-intensive\napplications. While \"static\" data applications have received significant\nattention, the characteristics, requirements, and software systems for the\nanalysis of large volumes of dynamic, distributed data, and data-intensive\napplications have received relatively less attention. This paper surveys\nseveral representative dynamic distributed data-intensive application\nscenarios, provides a common conceptual framework to understand them, and\nexamines the infrastructure used in support of applications.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 00:26:03 GMT"}], "update_date": "2016-09-14", "authors_parsed": [["Jha", "Shantenu", ""], ["Katz", "Daniel S.", ""], ["Luckow", "Andre", ""], ["Rana", "Omer", ""], ["Simmhan", "Yogesh", ""], ["Hong", "Neil Chue", ""]]}, {"id": "1609.03750", "submitter": "Lars Ailo Bongo", "authors": "Inge Alexander Raknes, Bj{\\o}rn Fjukstad, Lars Ailo Bongo", "title": "nsroot: Minimalist Process Isolation Tool Implemented With Linux\n  Namespaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data analyses in the life sciences are moving from tools run on a personal\ncomputer to services run on large computing platforms. This creates a need to\npackage tools and dependencies for easy installation, configuration and\ndeployment on distributed platforms. In addition, for secure execution there is\na need for process isolation on a shared platform. Existing virtual machine and\ncontainer technologies are often more complex than traditional Unix utilities,\nlike chroot, and often require root privileges in order to set up or use. This\nis especially challenging on HPC systems where users typically do not have root\naccess. We therefore present nsroot, a lightweight Linux namespaces based\nprocess isolation tool. It allows restricting the runtime environment of data\nanalysis tools that may not have been designed with security as a top priority,\nin order to reduce the risk and consequences of security breaches, without\nrequiring any special privileges. The codebase of nsroot is small, and it\nprovides a command line interface similar to chroot. It can be used on all\nLinux kernels that implement user namespaces. In addition, we propose combining\nnsroot with the AppImage format for secure execution of packaged applications.\nnsroot is open sourced and available at: https://github.com/uit-no/nsroot\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 10:12:05 GMT"}], "update_date": "2017-12-27", "authors_parsed": [["Raknes", "Inge Alexander", ""], ["Fjukstad", "Bj\u00f8rn", ""], ["Bongo", "Lars Ailo", ""]]}, {"id": "1609.03784", "submitter": "Jinshan Zeng", "authors": "Jinshan Zeng, Tao He and Mingwen Wang", "title": "A Fast Proximal Gradient Algorithm for Decentralized Composite\n  Optimization over Directed Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes a fast decentralized algorithm for solving a consensus\noptimization problem defined in a directed networked multi-agent system, where\nthe local objective functions have the smooth+nonsmooth composite form, and are\npossibly nonconvex. Examples of such problems include decentralized compressed\nsensing and constrained quadratic programming problems, as well as many\ndecentralized regularization problems. We extend the existing algorithms\nPG-EXTRA and ExtraPush to a new algorithm PG-ExtraPush for composite consensus\noptimization over a directed network. This algorithm takes advantage of the\nproximity operator like in PG-EXTRA to deal with the nonsmooth term, and\nemploys the push-sum protocol like in ExtraPush to tackle the bias introduced\nby the directed network. With a proper step size, we show that PG-ExtraPush\nconverges to an optimal solution at a linear rate under some regular\nassumptions. We conduct a series of numerical experiments to show the\neffectiveness of the proposed algorithm. Specifically, with a proper step size,\nPG-ExtraPush performs linear rates in most of cases, even in some nonconvex\ncases, and is significantly faster than Subgradient-Push, even if the latter\nuses a hand-optimized step size. The established theoretical results are also\nverified by the numerical results.\n", "versions": [{"version": "v1", "created": "Tue, 13 Sep 2016 11:49:36 GMT"}, {"version": "v2", "created": "Sat, 17 Sep 2016 00:23:00 GMT"}, {"version": "v3", "created": "Sun, 13 Nov 2016 09:18:14 GMT"}, {"version": "v4", "created": "Sun, 26 Mar 2017 12:10:35 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Zeng", "Jinshan", ""], ["He", "Tao", ""], ["Wang", "Mingwen", ""]]}, {"id": "1609.04453", "submitter": "Terrell Mundhenk", "authors": "T. Nathan Mundhenk, Goran Konjevod, Wesam A. Sakla, Kofi Boakye", "title": "A Large Contextual Dataset for Classification, Detection and Counting of\n  Cars with Deep Learning", "comments": "ECCV 2016 Pre-press revision", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have created a large diverse set of cars from overhead images, which are\nuseful for training a deep learner to binary classify, detect and count them.\nThe dataset and all related material will be made publically available. The set\ncontains contextual matter to aid in identification of difficult targets. We\ndemonstrate classification and detection on this dataset using a neural network\nwe call ResCeption. This network combines residual learning with\nInception-style layers and is used to count cars in one look. This is a new way\nto count objects rather than by localization or density estimation. It is\nfairly accurate, fast and easy to implement. Additionally, the counting method\nis not car or scene specific. It would be easy to train this method to count\nother kinds of objects and counting over new scenes requires no extra set up or\nassumptions about object locations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2016 21:44:58 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Mundhenk", "T. Nathan", ""], ["Konjevod", "Goran", ""], ["Sakla", "Wesam A.", ""], ["Boakye", "Kofi", ""]]}, {"id": "1609.04567", "submitter": "Maurizio Drocco", "authors": "M. Aldinucci, M. Danelutto, M. Drocco, P. Kilpatrick, C. Misale, G.\n  Peretti Pezzi, M. Torquati", "title": "A parallel pattern for iterative stencil + reduce", "comments": null, "journal-ref": null, "doi": "10.1007/s11227-016-1871-z", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We advocate the Loop-of-stencil-reduce pattern as a means of simplifying the\nimplementation of data-parallel programs on heterogeneous multi-core platforms.\nLoop-of-stencil-reduce is general enough to subsume map, reduce, map-reduce,\nstencil, stencil-reduce, and, crucially, their usage in a loop in both\ndata-parallel and streaming applications, or a combination of both. The pattern\nmakes it possible to deploy a single stencil computation kernel on different\nGPUs. We discuss the implementation of Loop-of-stencil-reduce in FastFlow, a\nframework for the implementation of applications based on the parallel\npatterns. Experiments are presented to illustrate the use of\nLoop-of-stencil-reduce in developing data-parallel kernels running on\nheterogeneous systems.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 10:42:42 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Aldinucci", "M.", ""], ["Danelutto", "M.", ""], ["Drocco", "M.", ""], ["Kilpatrick", "P.", ""], ["Misale", "C.", ""], ["Pezzi", "G. Peretti", ""], ["Torquati", "M.", ""]]}, {"id": "1609.04569", "submitter": "Masoom Nazari", "authors": "Masoom Nazari, Mina Zolfy Lighvan, Ziaeddin Daie Koozekonani, Ali\n  Sadeghi", "title": "FPGA Implementation of a Novel Image Steganography for Hiding Images", "comments": "please withdraw this paper because of crucial equation error in Table\n  1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the complexity of current data flow systems and according infrastructure\nnetworks increases, the security of data transition through such platforms\nbecomes more important. Thus, different areas of steganography turn to one of\nthe most challengeable topics of current researches. In this paper a novel\nmethod is presented to hide an image into the host image and Hardware/Software\ndesign is proposed to implement our stagenography system on FPGA- DE2 70 Altera\nboard. The size of the secret image is quadrant of the host image. Host image\nworks as a cipher key to completely distort and encrypt the secret image using\nXOR operand. Each pixel of the secret image is composed of 8 bits (4 bit-pair)\nin which each bit-pair is distorted by XORing it with two LSB bits of the host\nimage and putting the results in the location of two LSB bits of host image.\nThe experimental results show the effectiveness of the proposed method compared\nto the most recently proposed algorithms by considering that the obtained\ninformation entropy for encrypt image is approximately equal to 8.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 10:50:45 GMT"}, {"version": "v2", "created": "Thu, 29 Sep 2016 05:38:07 GMT"}, {"version": "v3", "created": "Sat, 1 Oct 2016 15:00:39 GMT"}], "update_date": "2016-10-04", "authors_parsed": [["Nazari", "Masoom", ""], ["Lighvan", "Mina Zolfy", ""], ["Koozekonani", "Ziaeddin Daie", ""], ["Sadeghi", "Ali", ""]]}, {"id": "1609.04603", "submitter": "Antonio Virdis", "authors": "Antonio Virdis, Carlo Vallati, Giovanni Nardini", "title": "Automating Large-Scale Simulation and Data Analysis with OMNeT++:\n  Lession Learned and Future Perspectives", "comments": "Published in: A. Foerster, V. Vesely, A. Virdis, M. Kirsche (Eds.),\n  Proc. of the 3rd OMNeT++ Community Summit, Brno University of Technology -\n  Czech Republic - September 15-16, 2016", "journal-ref": null, "doi": null, "report-no": "OMNET/2016/05", "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulation is widely adopted in the study of modern computer networks. In\nthis context, OMNeT++ provides a set of very effective tools that span from the\ndefinition of the network, to the automation of simulation execution and quick\nresult representation. However, as network models become more and more complex\nto cope with the evolution of network systems, the amount of simulation\nfactors, the number of simulated nodes and the size of results grow\nconsequently, leading to simulations with larger scale. In this work, we\nperform a critical analysis of the tools provided by OMNeT++ in case of such\nlarge-scale simulations. We then propose a unified and flexible software\narchitecture to support simulation automation.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 12:41:41 GMT"}], "update_date": "2016-09-16", "authors_parsed": [["Virdis", "Antonio", ""], ["Vallati", "Carlo", ""], ["Nardini", "Giovanni", ""]]}, {"id": "1609.04746", "submitter": "Robert Hannah", "authors": "Robert Hannah, Wotao Yin", "title": "On Unbounded Delays in Asynchronous Parallel Fixed-Point Algorithms", "comments": "27 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The need for scalable numerical solutions has motivated the development of\nasynchronous parallel algorithms, where a set of nodes run in parallel with\nlittle or no synchronization, thus computing with delayed information. This\npaper studies the convergence of the asynchronous parallel algorithm ARock\nunder potentially unbounded delays.\n  ARock is a general asynchronous algorithm that has many applications. It\nparallelizes fixed-point iterations by letting a set of nodes randomly choose\nsolution coordinates and update them in an asynchronous parallel fashion. ARock\ntakes some recent asynchronous coordinate descent algorithms as special cases\nand gives rise to new asynchronous operator-splitting algorithms. Existing\nanalysis of ARock assumes the delays to be bounded, and uses this bound to set\na step size that is important to both convergence and efficiency. Other work,\nthough allowing unbounded delays, imposes strict conditions on the underlying\nfixed-point operator, resulting in limited applications.\n  In this paper, convergence is established under unbounded delays, which can\nbe either stochastic or deterministic. The proposed step sizes are more\npractical and generally larger than those in the existing work. The step size\nadapts to the delay distribution or the current delay being experienced in the\nsystem. New Lyapunov functions, which are the key to analyzing asynchronous\nalgorithms, are generated to obtain our results. A set of applicable\noptimization algorithms with large-scale applications are given, including\nmachine learning and scientific computing algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 17:30:28 GMT"}, {"version": "v2", "created": "Thu, 17 Aug 2017 05:20:28 GMT"}], "update_date": "2017-08-18", "authors_parsed": [["Hannah", "Robert", ""], ["Yin", "Wotao", ""]]}, {"id": "1609.04809", "submitter": "Sashikumaar Ganesan", "authors": "Sashikumaar Ganesan, Volker John, Gunar Matthies, Raviteja Meesala,\n  Shamim Abdus, Ulrich Wilbrandt", "title": "An object oriented parallel finite element scheme for computations of\n  PDEs: Design and implementation", "comments": "10 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel finite element algorithms based on object-oriented concepts are\npresented. Moreover, the design and implementation of a data structure proposed\nare utilized in realizing a parallel geometric multigrid method. The\nParFEMapper and the ParFECommunicator are the key components of the data\nstructure in the proposed parallel scheme. These classes are constructed based\non the type of finite elements (continuous or nonconforming or discontinuous)\nused. The proposed solver is compared with the open source direct solvers,\nMUMPS and PasTiX. Further, the performance of the parallel multigrid solver is\nanalyzed up to 1080 processors. The solver shows a very good speedup up to 960\nprocessors and the problem size has to be increased in order to maintain the\ngood speedup when the number of processors are increased further. As a result,\nthe parallel solver is able to handle large scale problems on massively\nparallel supercomputers. The proposed parallel finite element algorithms and\nmultigrid solver are implemented in our in-house package ParMooN.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2016 05:05:29 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Ganesan", "Sashikumaar", ""], ["John", "Volker", ""], ["Matthies", "Gunar", ""], ["Meesala", "Raviteja", ""], ["Abdus", "Shamim", ""], ["Wilbrandt", "Ulrich", ""]]}, {"id": "1609.05002", "submitter": "Marco Danelutto", "authors": "Marco Danelutto, Massimo Torquati and Peter Kilpatrick", "title": "State access patterns in embarrassingly parallel computations", "comments": "8 pages, accepted and presented at HLPGPU 2016 (Prague, Czech\n  Republic, Tuesday, Jan 19th 2016. Co-Located with HiPEAC 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a set of state access patterns suitable for managing state in\nembarrassingly parallel computations on streams. The state access patterns are\nuseful to model typical stream parallel applications. We present a\nclassification of the patterns according to the extent and way in which the\nstate is modified. We define precisely the state access patterns and discuss\npossible implementation schemas, performances and possibilities to manage\nadaptivity (parallelism degree) in the patterns. We present experimental\nresults relative to an implementations on top of the structured parallel\nprogramming framework FastFlow that demonstrate the feasibility and efficiency\nof the proposed access patterns.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 11:25:37 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Danelutto", "Marco", ""], ["Torquati", "Massimo", ""], ["Kilpatrick", "Peter", ""]]}, {"id": "1609.05087", "submitter": "Jie Xu", "authors": "Jie Xu, Shaolei Ren", "title": "Online Learning for Offloading and Autoscaling in Renewable-Powered\n  Mobile Edge Computing", "comments": "IEEE Globecom 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge computing (a.k.a. fog computing) has recently emerged to enable\n\\emph{in-situ} processing of delay-sensitive applications at the edge of mobile\nnetworks. Providing grid power supply in support of mobile edge computing,\nhowever, is costly and even infeasible (in certain rugged or under-developed\nareas), thus mandating on-site renewable energy as a major or even sole power\nsupply in increasingly many scenarios. Nonetheless, the high intermittency and\nunpredictability of renewable energy make it very challenging to deliver a high\nquality of service to users in renewable-powered mobile edge computing systems.\nIn this paper, we address the challenge of incorporating renewables into mobile\nedge computing and propose an efficient reinforcement learning-based resource\nmanagement algorithm, which learns on-the-fly the optimal policy of dynamic\nworkload offloading (to centralized cloud) and edge server provisioning to\nminimize the long-term system cost (including both service delay and\noperational cost). Our online learning algorithm uses a decomposition of the\n(offline) value iteration and (online) reinforcement learning, thus achieving a\nsignificant improvement of learning rate and run-time performance when compared\nto standard reinforcement learning algorithms such as Q-learning.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 14:38:39 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Xu", "Jie", ""], ["Ren", "Shaolei", ""]]}, {"id": "1609.05096", "submitter": "Yongchao Tian", "authors": "Yongchao Tian, Ioannis Alagiannis, Erietta Liarou, Anastasia Ailamaki,\n  Pietro Michiardi, Marko Vukolic", "title": "DiNoDB: an Interactive-speed Query Engine for Ad-hoc Queries on\n  Temporary Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As data sets grow in size, analytics applications struggle to get instant\ninsight into large datasets. Modern applications involve heavy batch processing\njobs over large volumes of data and at the same time require efficient ad-hoc\ninteractive analytics on temporary data. Existing solutions, however, typically\nfocus on one of these two aspects, largely ignoring the need for synergy\nbetween the two. Consequently, interactive queries need to re-iterate costly\npasses through the entire dataset (e.g., data loading) that may provide\nmeaningful return on investment only when data is queried over a long period of\ntime. In this paper, we propose DiNoDB, an interactive-speed query engine for\nad-hoc queries on temporary data. DiNoDB avoids the expensive loading and\ntransformation phase that characterizes both traditional RDBMSs and current\ninteractive analytics solutions. It is tailored to modern workflows found in\nmachine learning and data exploration use cases, which often involve iterations\nof cycles of batch and interactive analytics on data that is typically useful\nfor a narrow processing window. The key innovation of DiNoDB is to piggyback on\nthe batch processing phase the creation of metadata that DiNoDB exploits to\nexpedite the interactive queries. Our experimental analysis demonstrates that\nDiNoDB achieves very good performance for a wide range of ad-hoc queries\ncompared to alternatives %such as Hive, Stado, SparkSQL and Impala.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 14:56:31 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Tian", "Yongchao", ""], ["Alagiannis", "Ioannis", ""], ["Liarou", "Erietta", ""], ["Ailamaki", "Anastasia", ""], ["Michiardi", "Pietro", ""], ["Vukolic", "Marko", ""]]}, {"id": "1609.05113", "submitter": "Yongchao Tian", "authors": "Yongchao Tian, Pietro Michiardi, Marko Vukolic", "title": "Bleach: A Distributed Stream Data Cleaning System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we address the problem of rule-based stream data cleaning,\nwhich sets stringent requirements on latency, rule dynamics and ability to cope\nwith the unbounded nature of data streams.\n  We design a system, called Bleach, which achieves real-time violation\ndetection and data repair on a dirty data stream. Bleach relies on efficient,\ncompact and distributed data structures to maintain the necessary state to\nrepair data, using an incremental version of the equivalence class algorithm.\nAdditionally, it supports rule dynamics and uses a \"cumulative\" sliding window\noperation to improve cleaning accuracy.\n  We evaluate a prototype of Bleach using a TPC-DS derived dirty data stream\nand observe its high throughput, low latency and high cleaning accuracy, even\nwith rule dynamics. Experimental results indicate superior performance of\nBleach compared to a baseline system built on the micro-batch streaming\nparadigm.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 15:52:44 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Tian", "Yongchao", ""], ["Michiardi", "Pietro", ""], ["Vukolic", "Marko", ""]]}, {"id": "1609.05181", "submitter": "Ravi  Tandon", "authors": "Mohamed Attia, Ravi Tandon", "title": "Information Theoretic Limits of Data Shuffling for Distributed Learning", "comments": "To be presented at IEEE GLOBECOM, December 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data shuffling is one of the fundamental building blocks for distributed\nlearning algorithms, that increases the statistical gain for each step of the\nlearning process. In each iteration, different shuffled data points are\nassigned by a central node to a distributed set of workers to perform local\ncomputations, which leads to communication bottlenecks. The focus of this paper\nis on formalizing and understanding the fundamental information-theoretic\ntrade-off between storage (per worker) and the worst-case communication\noverhead for the data shuffling problem. We completely characterize the\ninformation theoretic trade-off for $K=2$, and $K=3$ workers, for any value of\nstorage capacity, and show that increasing the storage across workers can\nreduce the communication overhead by leveraging coding. We propose a novel and\nsystematic data delivery and storage update strategy for each data shuffle\niteration, which preserves the structural properties of the storage across the\nworkers, and aids in minimizing the communication overhead in subsequent data\nshuffling iterations.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2016 19:12:42 GMT"}], "update_date": "2016-09-19", "authors_parsed": [["Attia", "Mohamed", ""], ["Tandon", "Ravi", ""]]}, {"id": "1609.05713", "submitter": "Ivano Notarnicola", "authors": "Ivano Notarnicola, Giuseppe Notarstefano", "title": "Randomized dual proximal gradient for large-scale distributed\n  optimization", "comments": "arXiv admin note: substantial text overlap with arXiv:1509.08373", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider distributed optimization problems in which the cost\nfunction is separable (i.e., a sum of possibly non-smooth functions all sharing\na common variable) and can be split into a strongly convex term and a convex\none. The second term is typically used to encode constraints or to regularize\nthe solution. We propose an asynchronous, distributed optimization algorithm\nover an undirected topology, based on a proximal gradient update on the dual\nproblem. We show that by means of a proper choice of primal variables, the dual\nproblem is separable and the dual variables can be stacked into separate\nblocks. This allows us to show that a distributed gossip update can be obtained\nby means of a randomized block-coordinate proximal gradient on the dual\nfunction.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 13:26:05 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Notarnicola", "Ivano", ""], ["Notarstefano", "Giuseppe", ""]]}, {"id": "1609.05767", "submitter": "Nguyen Quang-Hung", "authors": "Nguyen Quang-Hung, Nam Thoai", "title": "Minimizing Total Busy Time with Application to Energy-efficient\n  Scheduling of Virtual Machines in IaaS clouds", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Infrastructure-as-a-Service (IaaS) clouds have become more popular enabling\nusers to run applications under virtual machines. Energy efficiency for IaaS\nclouds is still challenge. This paper investigates the energy-efficient\nscheduling problems of virtual machines (VMs) onto physical machines (PMs) in\nIaaS clouds along characteristics: multiple resources, fixed intervals and\nnon-preemption of virtual machines. The scheduling problems are NP-hard. Most\nof existing works on VM placement reduce the total energy consumption by using\nthe minimum number of active physical machines. There, however, are cases using\nthe minimum number of physical machines results in longer the total busy time\nof the physical machines. For the scheduling problems, minimizing the total\nenergy consumption of all physical machines is equivalent to minimizing total\nbusy time of all physical machines. In this paper, we propose an scheduling\nalgorithm, denoted as EMinTRE-LFT, for minimizing the total energy consumption\nof physical machines in the scheduling problems. Our extensive simulations\nusing parallel workload models in Parallel Workload Archive show that the\nproposed algorithm has the least total energy consumption compared to the\nstate-of-the art algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 15:09:20 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Quang-Hung", "Nguyen", ""], ["Thoai", "Nam", ""]]}, {"id": "1609.05830", "submitter": "Fabrizio Montesi", "authors": "Fabrizio Montesi, Janine Weber", "title": "Circuit Breakers, Discovery, and API Gateways in Microservices", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We review some of the most widely used patterns for the programming of\nmicroservices: circuit breaker, service discovery, and API gateway. By\nsystematically analysing different deployment strategies for these patterns, we\nreach new insight especially for the application of circuit breakers. We also\nevaluate the applicability of Jolie, a language for the programming of\nmicroservices, for these patterns and report on other standard frameworks\noffering similar solutions. Finally, considerations for future developments are\npresented.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2016 17:09:14 GMT"}, {"version": "v2", "created": "Wed, 21 Sep 2016 10:36:43 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Montesi", "Fabrizio", ""], ["Weber", "Janine", ""]]}, {"id": "1609.06161", "submitter": "Marjorie Bournat", "authors": "Marjorie Bournat (Regal), Ajoy K. Datta (SCV), Swan Dubois (Regal)", "title": "Self-Stabilizing Robots in Highly Dynamic Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the classical problem of exploring a ring by a cohort\nof synchronous robots. We focus on the perpetual version of this problem in\nwhich it is required that each node of the ring is visited by a robot\ninfinitely often. The challenge in this paper is twofold. First, we assume that\nthe robots evolve in a highly dynamic ring, \\ie edges may appear and disappear\nunpredictably without any recurrence, periodicity, nor stability assumption.\nThe only assumption we made (known as temporal connectivity assumption) is that\neach node is infinitely often reachable from any other node. Second, we aim at\nproviding a self-stabilizing algorithm to the robots, i.e., the algorithm must\nguarantee an eventual correct behavior regardless of the initial state and\npositions of the robots.In this harsh environment, our contribution is to fully\ncharacterize, for each size of the ring, the necessary and sufficient number of\nrobots to solve deterministically the problem.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 13:34:51 GMT"}, {"version": "v2", "created": "Fri, 23 Sep 2016 11:30:00 GMT"}, {"version": "v3", "created": "Mon, 7 Aug 2017 13:23:18 GMT"}], "update_date": "2017-08-08", "authors_parsed": [["Bournat", "Marjorie", "", "Regal"], ["Datta", "Ajoy K.", "", "SCV"], ["Dubois", "Swan", "", "Regal"]]}, {"id": "1609.06221", "submitter": "Avnish Chandra Suman", "authors": "Saraswati Mishra, Avnish Chandra Suman", "title": "An Efficient Method of Partitioning High Volumes of Multidimensional\n  Data for Parallel Clustering Algorithms", "comments": "5 pages, 6 figures", "journal-ref": "Int. Journal of Engineering Research and Application ISSN :\n  2248-9622, Vol. 6, Issue 8, August 2016, pp.67-71", "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An optimal data partitioning in parallel & distributed implementation of\nclustering algorithms is a necessary computation as it ensures independent task\ncompletion, fair distribution, less number of affected points and better &\nfaster merging. Though partitioning using Kd Tree is being conventionally used\nin academia, it suffers from performance drenches and bias (non equal\ndistribution) as dimensionality of data increases and hence is not suitable for\npractical use in industry where dimensionality can be of order of 100s to\n1000s. To address these issues we propose two new partitioning techniques using\nexisting mathematical models & study their feasibility, performance (bias and\npartitioning speed) & possible variants in choosing initial seeds. First method\nuses an n dimensional hashed grid based approach which is based on mapping the\npoints in space to a set of cubes which hashes the points. Second method uses a\ntree of voronoi planes where each plane corresponds to a partition. We found\nthat grid based approach was computationally impractical, while using a tree of\nvoronoi planes (using scalable K-Means++ initial seeds) drastically\noutperformed the Kd-tree tree method as dimensionality increased.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2016 15:26:37 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Mishra", "Saraswati", ""], ["Suman", "Avnish Chandra", ""]]}, {"id": "1609.06430", "submitter": "Shrisha Rao", "authors": "Pragati Agrawal, Shrisha Rao", "title": "Energy-Efficient Scheduling: Classification, Bounds, and Algorithms", "comments": "41 pages", "journal-ref": "S{\\a}dhan{\\a} (2021) 46:46", "doi": "10.1007/s12046-021-01564-w", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of attaining energy efficiency in distributed systems is of\nimportance, but a general, non-domain-specific theory of energy-minimal\nscheduling is far from developed. In this paper, we classify the problems of\nenergy-minimal scheduling and present theoretical foundations of the same. We\nderive results concerning energy-minimal scheduling of independent jobs in a\ndistributed system with functionally similar machines with different working\nand idle power ratings. The machines considered in our system can have\nidentical as well as different speeds. If the jobs can be divided into\narbitrary parts, we show that the minimum-energy schedule can be generated in\nlinear time and give exact scheduling algorithms. For the cases where jobs are\nnon-divisible, we prove that the scheduling problems are NP-hard and also give\napproximation algorithms for the same along with their bounds.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 06:43:20 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 11:27:16 GMT"}], "update_date": "2021-03-10", "authors_parsed": [["Agrawal", "Pragati", ""], ["Rao", "Shrisha", ""]]}, {"id": "1609.06508", "submitter": "Mika\\\"el Rabie", "authors": "Rabie Mika\\\"el", "title": "Global Versus Local Computations: Fast Computing with Identifiers", "comments": "Long version of SSS 2016 publication, appendixed version of SIROCCO\n  2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies what can be computed by using probabilistic local\ninteractions with agents with a very restricted power in polylogarithmic\nparallel time. It is known that if agents are only finite state (corresponding\nto the Population Protocol model by Angluin et al.), then only semilinear\npredicates over the global input can be computed. In fact, if the population\nstarts with a unique leader, these predicates can even be computed in a\npolylogarithmic parallel time. If identifiers are added (corresponding to the\nCommunity Protocol model by Guerraoui and Ruppert), then more global predicates\nover the input multiset can be computed. Local predicates over the input sorted\naccording to the identifiers can also be computed, as long as the identifiers\nare ordered. The time of some of those predicates might require exponential\nparallel time. In this paper, we consider what can be computed with Community\nProtocol in a polylogarithmic number of parallel interactions. We introduce the\nclass CPPL corresponding to protocols that use $O(n\\log^k n)$, for some k,\nexpected interactions to compute their predicates, or equivalently a\npolylogarithmic number of parallel expected interactions. We provide some\ncomputable protocols, some boundaries of the class, using the fact that the\npopulation can compute its size. We also prove two impossibility results\nproviding some arguments showing that local computations are no longer easy:\nthe population does not have the time to compare a linear number of consecutive\nidentifiers. The Linearly Local languages, such that the rational language\n$(ab)^*$, are not computable.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 11:44:25 GMT"}, {"version": "v2", "created": "Mon, 29 May 2017 11:39:14 GMT"}], "update_date": "2017-05-30", "authors_parsed": [["Mika\u00ebl", "Rabie", ""]]}, {"id": "1609.06670", "submitter": "Natacha Crooks", "authors": "Natacha Crooks and Youer Pu and Lorenzo Alvisi and Allen Clement", "title": "Seeing is Believing: A Unified Model for Consistency and Isolation via\n  States", "comments": "11 pages with 29 pages appendix", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a unified model of consistency and isolation that\nminimizes the gap between how these guarantees are defined and how they are\nperceived. Our approach is premised on a simple observation: applications view\nstorage systems as black-boxes that transition through a series of states, a\nsubset of which are observed by applications. For maximum clarity, isolation\nand consistency guarantees should be expressed as constraints on those states.\nInstead, these properties are currently expressed as constraints on operation\nhistories that are not visible to the application. We show that adopting a\nstate-based approach to expressing these guarantees brings forth several\nbenefits. First, it makes it easier to focus on the anomalies that a given\nisolation or consistency level allows (and that applications must deal with),\nrather than those that it proscribes. Second, it unifies the often disparate\ntheories of isolation and consistency and provides a structure for composing\nthese guarantees. We leverage this modularity to apply to transactions\n(independently of the isolation level under which they execute) the equivalence\nbetween causal consistency and session guarantees that Chockler et al. had\nproved for single operations. Third, it brings clarity to the increasingly\ncrowded field of proposed consistency and isolation properties by winnowing\nspurious distinctions: we find that the recently proposed parallel snapshot\nisolation introduced by Sovran et al. is in fact a specific implementation of\nan older guarantee, lazy consistency (or PL-2+), introduced by Adya et al.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2016 18:34:54 GMT"}], "update_date": "2016-09-22", "authors_parsed": [["Crooks", "Natacha", ""], ["Pu", "Youer", ""], ["Alvisi", "Lorenzo", ""], ["Clement", "Allen", ""]]}, {"id": "1609.06841", "submitter": "Volker Turau", "authors": "Gerry Siegemund and Volker Turau", "title": "PSVR - Self-stabilizing Publish/Subscribe Communication for Ad-hoc\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the novel routing algorithm PSVR for pub/sub systems in\nad-hoc networks. Its focus is on scenarios where communications links are\nunstable and nodes frequently change subscriptions. PSVR presents a compromise\nof size and maintenance effort for routing tables due to sub- and\nunsubscriptions and the length of routing paths. Designed in a self-stabilizing\nmanner it scales well with network size. The evaluation reveals that PSVR only\nneeds slightly more messages than a close to optimal routing structure for\npublication delivery, and creates shorter routing paths than an existing\nself-stabilizing algorithm. A real world deployment shows the usability of the\napproach\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 07:12:43 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Siegemund", "Gerry", ""], ["Turau", "Volker", ""]]}, {"id": "1609.06978", "submitter": "\\'Attila Rodrigues", "authors": "\\'Attila L. Rodrigues, Jo\\~ao Felipe C. L. Costa", "title": "Gridlan: a Multi-purpose Local Grid Computing Framework", "comments": "6 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In scientific computing, more computational power generally implies faster\nand possibly more detailed results. The goal of this study was to develop a\nframework to submit computational jobs to powerful workstations underused by\nnonintensive tasks. This is achieved by using a virtual machine in each of\nthese workstations, where the computations are done. This group of virtual\nmachines is called the Gridlan. The Gridlan framework is intermediate between\nthe cluster and grid computing paradigms. The Gridlan is able to profit from\nexisting cluster software tools, such as resource managers like Torque, so a\nuser with previous experience in cluster operation can dispatch jobs\nseamlessly. A benchmark test of the Gridlan implementation shows the system's\nsuitability for computational tasks, principally in embarrassingly parallel\ncomputations.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 13:50:16 GMT"}], "update_date": "2016-09-23", "authors_parsed": [["Rodrigues", "\u00c1ttila L.", ""], ["Costa", "Jo\u00e3o Felipe C. L.", ""]]}, {"id": "1609.07008", "submitter": "Edgar Solomonik", "authors": "Edgar Solomonik, Maciej Besta, Flavio Vella, and Torsten Hoefler", "title": "Scaling betweenness centrality using communication-efficient sparse\n  matrix multiplication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Betweenness centrality (BC) is a crucial graph problem that measures the\nsignificance of a vertex by the number of shortest paths leading through it. We\npropose Maximal Frontier Betweenness Centrality (MFBC): a succinct BC algorithm\nbased on novel sparse matrix multiplication routines that performs a factor of\n$p^{1/3}$ less communication on $p$ processors than the best known\nalternatives, for graphs with $n$ vertices and average degree $k=n/p^{2/3}$. We\nformulate, implement, and prove the correctness of MFBC for weighted graphs by\nleveraging monoids instead of semirings, which enables a surprisingly succinct\nformulation. MFBC scales well for both extremely sparse and relatively dense\ngraphs. It automatically searches a space of distributed data decompositions\nand sparse matrix multiplication algorithms for the most advantageous\nconfiguration. The MFBC implementation outperforms the well-known CombBLAS\nlibrary by up to 8x and shows more robust performance. Our design methodology\nis readily extensible to other graph problems.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 15:01:30 GMT"}, {"version": "v2", "created": "Wed, 9 Aug 2017 15:30:00 GMT"}], "update_date": "2017-08-10", "authors_parsed": [["Solomonik", "Edgar", ""], ["Besta", "Maciej", ""], ["Vella", "Flavio", ""], ["Hoefler", "Torsten", ""]]}, {"id": "1609.07192", "submitter": "Balajee Vamanan", "authors": "Yiyang Chang, Ashkan Rezaei, Balajee Vamanan, Jahangir Hasan, Sanjay\n  Rao and T. N. Vijaykumar", "title": "Hydra: Leveraging Functional Slicing for Efficient Distributed SDN\n  Controllers", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conventional approach to scaling Software Defined Networking (SDN)\ncontrollers today is to partition switches based on network topology, with each\npartition being controlled by a single physical controller, running all SDN\napplications. However, topological partitioning is limited by the fact that (i)\nperformance of latency-sensitive (e.g., monitoring) SDN applications associated\nwith a given partition may be impacted by co-located compute-intensive (e.g.,\nroute computation) applications; (ii) simultaneously achieving low convergence\ntime and response times might be challenging; and (iii) communication between\ninstances of an application across partitions may increase latencies. To tackle\nthese issues, in this paper, we explore functional slicing, a complementary\napproach to scaling, where multiple SDN applications belonging to the same\ntopological partition may be placed in physically distinct servers. We present\nHydra, a framework for distributed SDN controllers based on functional slicing.\nHydra chooses partitions based on convergence time as the primary metric, but\nplaces application instances across partitions in a manner that keeps response\ntimes low while considering communication between applications of a partition,\nand instances of an application across partitions. Evaluations using the\nFloodlight controller show the importance and effectiveness of Hydra in\nsimultaneously keeping convergence times on failures small, while sustaining\nhigher throughput per partition and ensuring responsiveness to\nlatency-sensitive applications.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 00:12:25 GMT"}], "update_date": "2016-09-26", "authors_parsed": [["Chang", "Yiyang", ""], ["Rezaei", "Ashkan", ""], ["Vamanan", "Balajee", ""], ["Hasan", "Jahangir", ""], ["Rao", "Sanjay", ""], ["Vijaykumar", "T. N.", ""]]}, {"id": "1609.07354", "submitter": "Shrisha Rao", "authors": "Mohammed Haroon Dupty, Pragati Agrawal, Shrisha Rao", "title": "Scheduling Under Power and Energy Constraints", "comments": "26 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a system model where machines have distinct speeds and power ratings\nbut are otherwise compatible, we consider various problems of scheduling under\nresource constraints on the system which place the restriction that not all\nmachines can be run at once. These can be power, energy, or makespan\nconstraints on the system. Given such constraints, there are problems with\ndivisible as well as non-divisible jobs. In the setting where there is a\nconstraint on power, we show that the problem of minimizing makespan for a set\nof divisible jobs is NP-hard by reduction to the knapsack problem. We then show\nthat scheduling to minimize energy with power constraints is also NP-hard. We\nthen consider scheduling with energy and makespan constraints with divisible\njobs and show that these can be solved in polynomial time, and the problems\nwith non-divisible jobs are NP-hard. We give exact and approximation algorithms\nfor these problems as required.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2016 18:04:15 GMT"}, {"version": "v2", "created": "Thu, 7 Feb 2019 11:59:13 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Dupty", "Mohammed Haroon", ""], ["Agrawal", "Pragati", ""], ["Rao", "Shrisha", ""]]}, {"id": "1609.07441", "submitter": "Matthias Hoelzl", "authors": "S. Mochalskyy, M. Hoelzl, R. Hatzky", "title": "Parallelization of JOREK-STARWALL for non-linear MHD simulations\n  including resistive walls (Report of the EUROfusion High Level Support Team\n  Projects JORSTAR/JORSTAR2)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large scale plasma instabilities inside a tokamak can be influenced by the\ncurrents flowing in the conducting vessel wall. This involves non linear plasma\ndynamics and its interaction with the wall current. In order to study this\nproblem the code that solves the magneto-hydrodynamic (MHD) equations, called\nJOREK [Huysmans G.T.A. and Czarny O. NF 47, 659 (2007); Czarny O. and Huysmans\nG. JCP 227, 7423 (2008)], was coupled [Hoelzl M., et al. Journal of Physics:\nConference Series, 401, 012010 (2012)] with the model for the vacuum region and\nthe resistive conducting structure named STARWALL [Merkel P., Strumberger E.,\narXiv:150804911 (2015)]. The JOREK-STARWALL model has been already applied to\nperform simulations of Vertical Displacement Events (VDEs), Resistive Wall\nModes (RWMs), Quiescent H-Mode, and vertical kick ELM triggering. At the\nbeginning of the project it was not possible to resolve the realistic wall\nstructure with a large number of finite element triangles due to the huge\nconsumption of memory and wall clock time by STARWALL and the corresponding\ncoupling routine in JOREK. Moreover, both the STARWALL code and the JOREK\ncoupling routine were only partially parallelized via OpenMP. The aim of this\nproject is to implement an MPI parallelization to reduce memory consumption and\nexecution time such that simulations with large resolutions become possible.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2016 17:35:31 GMT"}, {"version": "v2", "created": "Mon, 5 Feb 2018 13:59:43 GMT"}], "update_date": "2018-02-06", "authors_parsed": [["Mochalskyy", "S.", ""], ["Hoelzl", "M.", ""], ["Hatzky", "R.", ""]]}, {"id": "1609.07545", "submitter": "Jeremy Kepner", "authors": "Siddharth Samsi, Laura Brattain, William Arcand, David Bestor, Bill\n  Bergeron, Chansup Byun, Vijay Gadepally, Michael Houle, Matthew Hubbell,\n  Michael Jones, Anna Klein, Peter Michaleas, Lauren Milechin, Julie Mullen,\n  Andrew Prout, Antonio Rosa, Charles Yee, Jeremy Kepner, Albert Reuther", "title": "Benchmarking SciDB Data Import on HPC Systems", "comments": "5 pages, 4 figures, IEEE High Performance Extreme Computing (HPEC)\n  2016, best paper finalist", "journal-ref": null, "doi": "10.1109/HPEC.2016.7761617", "report-no": null, "categories": "cs.DB cs.DC cs.PF q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SciDB is a scalable, computational database management system that uses an\narray model for data storage. The array data model of SciDB makes it ideally\nsuited for storing and managing large amounts of imaging data. SciDB is\ndesigned to support advanced analytics in database, thus reducing the need for\nextracting data for analysis. It is designed to be massively parallel and can\nrun on commodity hardware in a high performance computing (HPC) environment. In\nthis paper, we present the performance of SciDB using simulated image data. The\nDynamic Distributed Dimensional Data Model (D4M) software is used to implement\nthe benchmark on a cluster running the MIT SuperCloud software stack. A peak\nperformance of 2.2M database inserts per second was achieved on a single node\nof this system. We also show that SciDB and the D4M toolbox provide more\nefficient ways to access random sub-volumes of massive datasets compared to the\ntraditional approaches of reading volumetric data from individual files. This\nwork describes the D4M and SciDB tools we developed and presents the initial\nperformance results. This performance was achieved by using parallel inserts, a\nin-database merging of arrays as well as supercomputing techniques, such as\ndistributed arrays and single-program-multiple-data programming.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 01:01:30 GMT"}], "update_date": "2016-12-13", "authors_parsed": [["Samsi", "Siddharth", ""], ["Brattain", "Laura", ""], ["Arcand", "William", ""], ["Bestor", "David", ""], ["Bergeron", "Bill", ""], ["Byun", "Chansup", ""], ["Gadepally", "Vijay", ""], ["Houle", "Michael", ""], ["Hubbell", "Matthew", ""], ["Jones", "Michael", ""], ["Klein", "Anna", ""], ["Michaleas", "Peter", ""], ["Milechin", "Lauren", ""], ["Mullen", "Julie", ""], ["Prout", "Andrew", ""], ["Rosa", "Antonio", ""], ["Yee", "Charles", ""], ["Kepner", "Jeremy", ""], ["Reuther", "Albert", ""]]}, {"id": "1609.07589", "submitter": "Won-Yong Shin", "authors": "Won-Yong Shin, Vien V. Mai, Bang Chul Jung, Hyun Jong Yang", "title": "Opportunistic Network Decoupling With Virtual Full-Duplex Operation in\n  Multi-Source Interfering Relay Networks", "comments": "22 pages, 5 figures, To appear in IEEE Transactions on Mobile\n  Computing", "journal-ref": null, "doi": "10.1109/TMC.2016.2614979", "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a new achievability scheme, termed opportunistic network\ndecoupling (OND), operating in virtual full-duplex mode. In the scheme, a novel\nrelay scheduling strategy is utilized in the $K\\times N\\times K$ channel with\ninterfering relays, consisting of $K$ source--destination pairs and $N$\nhalf-duplex relays in-between them. A subset of relays using alternate relaying\nis opportunistically selected in terms of producing the minimum total\ninterference level, thereby resulting in network decoupling. As our main\nresult, it is shown that under a certain relay scaling condition, the OND\nprotocol achieves $K$ degrees of freedom even in the presence of interfering\nlinks among relays. Numerical evaluation is also shown to validate the\nperformance of the proposed OND. Our protocol basically operates in a fully\ndistributed fashion along with local channel state information, thereby\nresulting in a relatively easy implementation.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 09:36:49 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Shin", "Won-Yong", ""], ["Mai", "Vien V.", ""], ["Jung", "Bang Chul", ""], ["Yang", "Hyun Jong", ""]]}, {"id": "1609.07603", "submitter": "Claus Brenner", "authors": "Claus Brenner", "title": "Scalable Estimation of Precision Maps in a MapReduce Framework", "comments": "ACM SIGSPATIAL'16, October 31-November 03, 2016, Burlingame, CA, USA", "journal-ref": null, "doi": "10.1145/2996913.2996990", "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a large-scale strip adjustment method for LiDAR mobile\nmapping data, yielding highly precise maps. It uses several concepts to achieve\nscalability. First, an efficient graph-based pre-segmentation is used, which\ndirectly operates on LiDAR scan strip data, rather than on point clouds.\nSecond, observation equations are obtained from a dense matching, which is\nformulated in terms of an estimation of a latent map. As a result of this\nformulation, the number of observation equations is not quadratic, but rather\nlinear in the number of scan strips. Third, the dynamic Bayes network, which\nresults from all observation and condition equations, is partitioned into two\nsub-networks. Consequently, the estimation matrices for all position and\norientation corrections are linear instead of quadratic in the number of\nunknowns and can be solved very efficiently using an alternating least squares\napproach. It is shown how this approach can be mapped to a standard key/value\nMapReduce implementation, where each of the processing nodes operates\nindependently on small chunks of data, leading to essentially linear\nscalability. Results are demonstrated for a dataset of one billion measured\nLiDAR points and 278,000 unknowns, leading to maps with a precision of a few\nmillimeters.\n", "versions": [{"version": "v1", "created": "Sat, 24 Sep 2016 11:24:30 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Brenner", "Claus", ""]]}, {"id": "1609.08114", "submitter": "Amit Gurung", "authors": "Amit Gurung and Rajarshi Ray", "title": "Solving Batched Linear Programs on GPU and Multicore CPU", "comments": "contains 31 pages in double line spacing, 11 figures with 2 tables. A\n  preliminary work has been accepted in the 8th IEEE International Student\n  Research Symposim on High Performance Computing, HiPC'2015, Bangalore,\n  December 16-19, 2015.\n  http://www.hipc.org/hipc2015/documents/HiPC-SRS-Paper/1570220654.pdf", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linear Programs (LPs) appear in a large number of applications and offloading\nthem to the GPU is viable to gain performance. Existing work on offloading and\nsolving an LP on GPU suggests that performance is gained from large sized LPs\n(typically 500 constraints, 500 variables and above). In order to gain\nperformance from GPU for applications involving small to medium sized LPs, we\npropose batched solving of a large number of LPs in parallel. In this paper, we\npresent the design and CUDA implementation of our batched LP solver library,\nkeeping memory coalescent access, reduced CPU-GPU memory transfer latency and\nload balancing as the goals. The performance of the batched LP solver is\ncompared against sequential solving in the CPU using an open source solver GLPK\n(GNU Linear Programming Kit). The performance is evaluated for three types of\nLPs. The first type is the initial basic solution as feasible, the second type\nis the initial basic solution as infeasible and the third type is the feasible\nregion as a Hyperbox. For the first type, we show a maximum speedup of\n$18.3\\times$ when running a batch of $50k$ LPs of size $100$ ($100$ variables,\n$100$ constraints). For the second type, a maximum speedup of $12\\times$ is\nobtained with a batch of $10k$ LPs of size $200$. For the third type, we show a\nsignificant speedup of $63\\times$ in solving a batch of nearly $4$ million LPs\nof size 5 and $34\\times$ in solving 6 million LPs of size $28$. In addition, we\nshow that the open source library for solving linear programs-GLPK, can be\neasily extended to solve many LPs in parallel with multi-threading. The thread\nparallel GLPK implementation runs $9.6\\times$ faster in solving a batch of\n$1e5$ LPs of size $100$, on a $12$-core Intel Xeon processor. We demonstrate\nthe application of our batched LP solver in the domain of state-space\nexploration of mathematical models of control systems design.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2016 18:51:09 GMT"}], "update_date": "2016-09-27", "authors_parsed": [["Gurung", "Amit", ""], ["Ray", "Rajarshi", ""]]}, {"id": "1609.08326", "submitter": "Shuxin Zheng", "authors": "Shuxin Zheng, Qi Meng, Taifeng Wang, Wei Chen, Nenghai Yu, Zhi-Ming\n  Ma, Tie-Yan Liu", "title": "Asynchronous Stochastic Gradient Descent with Delay Compensation", "comments": "20 pages, 5 figures", "journal-ref": "International Conference on Machine Learning. 2017: 4120-4129", "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the fast development of deep learning, it has become common to learn big\nneural networks using massive training data. Asynchronous Stochastic Gradient\nDescent (ASGD) is widely adopted to fulfill this task for its efficiency, which\nis, however, known to suffer from the problem of delayed gradients. That is,\nwhen a local worker adds its gradient to the global model, the global model may\nhave been updated by other workers and this gradient becomes \"delayed\". We\npropose a novel technology to compensate this delay, so as to make the\noptimization behavior of ASGD closer to that of sequential SGD. This is\nachieved by leveraging Taylor expansion of the gradient function and efficient\napproximation to the Hessian matrix of the loss function. We call the new\nalgorithm Delay Compensated ASGD (DC-ASGD). We evaluated the proposed algorithm\non CIFAR-10 and ImageNet datasets, and the experimental results demonstrate\nthat DC-ASGD outperforms both synchronous SGD and asynchronous SGD, and nearly\napproaches the performance of sequential SGD.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 09:22:03 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 17:53:10 GMT"}, {"version": "v3", "created": "Tue, 13 Jun 2017 09:02:32 GMT"}, {"version": "v4", "created": "Wed, 14 Jun 2017 12:45:50 GMT"}, {"version": "v5", "created": "Wed, 21 Aug 2019 12:34:15 GMT"}, {"version": "v6", "created": "Tue, 18 Feb 2020 15:04:38 GMT"}], "update_date": "2020-02-19", "authors_parsed": [["Zheng", "Shuxin", ""], ["Meng", "Qi", ""], ["Wang", "Taifeng", ""], ["Chen", "Wei", ""], ["Yu", "Nenghai", ""], ["Ma", "Zhi-Ming", ""], ["Liu", "Tie-Yan", ""]]}, {"id": "1609.08486", "submitter": "Yi-Jun Chang", "authors": "Yi-Jun Chang, Tsvi Kopelowitz, Seth Pettie, Ruosong Wang, Wei Zhan", "title": "Exponential Separations in the Energy Complexity of Leader Election", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Energy is often the most constrained resource for battery-powered wireless\ndevices and the lion's share of energy is often spent on transceiver usage\n(sending/receiving packets), not on computation. In this paper we study the\nenergy complexity of LeaderElection and ApproximateCounting in several models\nof wireless radio networks. It turns out that energy complexity is very\nsensitive to whether the devices can generate random bits and their ability to\ndetect collisions. We consider four collision-detection models: Strong-CD (in\nwhich transmitters and listeners detect collisions), Sender-CD and Receiver-CD\n(in which only transmitters or only listeners detect collisions), and No-CD (in\nwhich no one detects collisions.)\n  The take-away message of our results is quite surprising. For randomized\nLeaderElection algorithms, there is an exponential gap between the energy\ncomplexity of Sender-CD and Receiver-CD, and for deterministic LeaderElection\nalgorithms there is another exponential gap, but in the reverse direction.\n  In particular, the randomized energy complexity of LeaderElection is\n$\\Theta(\\log^* n)$ in Sender-CD but $\\Theta(\\log(\\log^* n))$ in Receiver-CD,\nwhere $n$ is the (unknown) number of devices. Its deterministic complexity is\n$\\Theta(\\log N)$ in Receiver-CD but $\\Theta(\\log\\log N)$ in Sender-CD, where\n$N$ is the (known) size of the devices' ID space.\n  There is a tradeoff between time and energy. We give a new upper bound on the\ntime-energy tradeoff curve for randomized LeaderElection and\nApproximateCounting. A critical component of this algorithm is a new\ndeterministic LeaderElection algorithm for dense instances, when $n=\\Theta(N)$,\nwith inverse-Ackermann-type ($O(\\alpha(N))$) energy complexity.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 14:58:35 GMT"}, {"version": "v2", "created": "Thu, 3 Nov 2016 14:05:57 GMT"}, {"version": "v3", "created": "Wed, 5 Sep 2018 19:34:48 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Chang", "Yi-Jun", ""], ["Kopelowitz", "Tsvi", ""], ["Pettie", "Seth", ""], ["Wang", "Ruosong", ""], ["Zhan", "Wei", ""]]}, {"id": "1609.08574", "submitter": "Jose Gracia", "authors": "Huan Zhou, Jose Gracia", "title": "Asynchronous progress design for a MPI-based PGAS one-sided\n  communication system", "comments": "8 pages, accepted for publication in International Conference on\n  Parallel and Distributed Systems (ICPADS 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Remote-memory-access models, also known as one-sided communication models,\nare becoming an interesting alternative to traditional two-sided communication\nmodels in the field of High Performance Computing. In this paper we extend\nprevious work on an MPI-based, locality-aware remote-memory-access model with a\nasynchronous progress-engine for non-blocking communication operations. Most\nprevious related work suggests to drive progression on communication through an\nadditional thread within the application process. In contrast, our scheme uses\nan arbitrary number of dedicated processes to drive asynchronous progression.\nFurther, we describe a prototypical library implementation of our concepts,\nnamely DART, which is used to quantitatively evaluate our design against a\nMPI-3 baseline reference. The evaluation consists of micro-benchmark to measure\noverlap of communication and computation and a scientific application kernel to\nassess total performance impact on realistic use-cases. Our benchmarks shows,\nthat our asynchronous progression scheme can overlap computation and\ncommunication efficiently and lead to substantially shorter communication cost\nin real applications.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 18:47:37 GMT"}], "update_date": "2016-09-28", "authors_parsed": [["Zhou", "Huan", ""], ["Gracia", "Jose", ""]]}, {"id": "1609.08686", "submitter": "Sukru Burc Eryilmaz", "authors": "S. Burc Eryilmaz, Emre Neftci, Siddharth Joshi, SangBum Kim, Matthew\n  BrightSky, Hsiang-Lan Lung, Chung Lam, Gert Cauwenberghs, H.-S. Philip Wong", "title": "Training a Probabilistic Graphical Model with Resistive Switching\n  Electronic Synapses", "comments": "Accepted for publication in IEEE Transactions on Electron Devices.\n  This version is the submitted version", "journal-ref": null, "doi": "10.1109/TED.2016.2616483", "report-no": null, "categories": "cs.NE cs.DC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current large scale implementations of deep learning and data mining require\nthousands of processors, massive amounts of off-chip memory, and consume\ngigajoules of energy. Emerging memory technologies such as nanoscale\ntwo-terminal resistive switching memory devices offer a compact, scalable and\nlow power alternative that permits on-chip co-located processing and memory in\nfine-grain distributed parallel architecture. Here we report first use of\nresistive switching memory devices for implementing and training a Restricted\nBoltzmann Machine (RBM), a generative probabilistic graphical model as a key\ncomponent for unsupervised learning in deep networks. We experimentally\ndemonstrate a 45-synapse RBM realized with 90 resistive switching phase change\nmemory (PCM) elements trained with a bio-inspired variant of the Contrastive\nDivergence (CD) algorithm, implementing Hebbian and anti-Hebbian weight\nupdates. The resistive PCM devices show a two-fold to ten-fold reduction in\nerror rate in a missing pixel pattern completion task trained over 30 epochs,\ncompared to untrained case. Measured programming energy consumption is 6.1 nJ\nper epoch with the resistive switching PCM devices, a factor of ~150 times\nlower than conventional processor-memory systems. We analyze and discuss the\ndependence of learning performance on cycle-to-cycle variations as well as\nnumber of gradual levels in the PCM analog memory devices.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2016 22:07:48 GMT"}, {"version": "v2", "created": "Mon, 10 Oct 2016 03:20:46 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Eryilmaz", "S. Burc", ""], ["Neftci", "Emre", ""], ["Joshi", "Siddharth", ""], ["Kim", "SangBum", ""], ["BrightSky", "Matthew", ""], ["Lung", "Hsiang-Lan", ""], ["Lam", "Chung", ""], ["Cauwenberghs", "Gert", ""], ["Wong", "H. -S. Philip", ""]]}, {"id": "1609.08893", "submitter": "R\\'emi Cresson", "authors": "Remi Cresson", "title": "A generic framework for the development of geospatial processing\n  pipelines on clusters", "comments": null, "journal-ref": "IEEE journal of geoscience and remote sensing letters, 2016", "doi": "10.1109/LGRS.2016.2605138", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  The amount of remote sensing data available to applications is constantly\ngrowing due to the rise of very-high-resolution sensors and short repeat cycle\nsatellites. Consequently, tackling computational complexity in Earth\nObservation information extraction is rising as a major challenge. Resorting to\nHigh Performance Computing (HPC) is becoming a common practice, since it\nprovides environments and programming facilities able to speed-up processes. In\nparticular, clusters are flexible, cost-effective systems able to perform\ndata-intensive tasks ideally fulfilling any computational requirement. However,\ntheir use typically implies a significant coding effort to build proper\nimplementations of specific processing pipelines. This paper presents a generic\nframework for the development of RS images processing applications targeting\ncluster computing. It is based on common open sources libraries, and leverages\nthe parallelization of a wide variety of image processing pipelines in a\ntransparent way. Performances on typical RS tasks implemented using the\nproposed framework demonstrate a great potential for the effective and timely\nprocessing of large amount of data.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 12:48:44 GMT"}], "update_date": "2016-09-29", "authors_parsed": [["Cresson", "Remi", ""]]}, {"id": "1609.09154", "submitter": "Grey Ballard", "authors": "Ramakrishnan Kannan, Grey Ballard, Haesun Park", "title": "MPI-FAUN: An MPI-Based Framework for Alternating-Updating Nonnegative\n  Matrix Factorization", "comments": "arXiv admin note: text overlap with arXiv:1509.09313", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NA stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) is the problem of determining two\nnon-negative low rank factors $W$ and $H$, for the given input matrix $A$, such\nthat $A \\approx W H$. NMF is a useful tool for many applications in different\ndomains such as topic modeling in text mining, background separation in video\nanalysis, and community detection in social networks. Despite its popularity in\nthe data mining community, there is a lack of efficient parallel algorithms to\nsolve the problem for big data sets.\n  The main contribution of this work is a new, high-performance parallel\ncomputational framework for a broad class of NMF algorithms that iteratively\nsolves alternating non-negative least squares (NLS) subproblems for $W$ and\n$H$. It maintains the data and factor matrices in memory (distributed across\nprocessors), uses MPI for interprocessor communication, and, in the dense case,\nprovably minimizes communication costs (under mild assumptions). The framework\nis flexible and able to leverage a variety of NMF and NLS algorithms, including\nMultiplicative Update, Hierarchical Alternating Least Squares, and Block\nPrincipal Pivoting. Our implementation allows us to benchmark and compare\ndifferent algorithms on massive dense and sparse data matrices of size that\nspans for few hundreds of millions to billions. We demonstrate the scalability\nof our algorithm and compare it with baseline implementations, showing\nsignificant performance improvements. The code and the datasets used for\nconducting the experiments are available online.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2016 23:31:45 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Kannan", "Ramakrishnan", ""], ["Ballard", "Grey", ""], ["Park", "Haesun", ""]]}, {"id": "1609.09206", "submitter": "Zhirong Qiu", "authors": "Zhirong Qiu, Lihua Xie, Yiguang Hong", "title": "Data Rate for Distributed Consensus of Multi-agent Systems with High\n  Order Oscillator Dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed consensus with data rate constraint is an important research\ntopic of multi-agent systems. Some results have been obtained for consensus of\nmulti-agent systems with integrator dynamics, but it remains challenging for\ngeneral high-order systems, especially in the presence of unmeasurable states.\nIn this paper, we study the quantized consensus problem for a special kind of\nhigh-order systems and investigate the corresponding data rate required for\nachieving consensus. The state matrix of each agent is a 2m-th order real\nJordan block admitting m identical pairs of conjugate poles on the unit circle;\neach agent has a single input, and only the first state variable can be\nmeasured. The case of harmonic oscillators corresponding to m=1 is first\ninvestigated under a directed communication topology which contains a spanning\ntree, while the general case of m >= 2 is considered for a connected and\nundirected network. In both cases it is concluded that the sufficient number of\ncommunication bits to guarantee the consensus at an exponential convergence\nrate is an integer between $m$ and $2m$, depending on the location of the\npoles.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 05:14:02 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Qiu", "Zhirong", ""], ["Xie", "Lihua", ""], ["Hong", "Yiguang", ""]]}, {"id": "1609.09211", "submitter": "Rohit Verma", "authors": "Rohit Verma and Abhishek Srivastava", "title": "A Dynamic Web Service Registry Framework for Mobile Environments", "comments": "Preprint Submitted to Arxiv", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advancements in technology have transformed mobile devices from being mere\ncommunication widgets to versatile computing devices. Proliferation of these\nhand held devices has made them a common means to access and process digital\ninformation. Most web based applications are today available in a form that can\nconveniently be accessed over mobile devices. However, webservices\n(applications meant for consumption by other applications rather than humans)\nare not as commonly provided and consumed over mobile devices. Facilitating\nthis and in effect realizing a service-oriented system over mobile devices has\nthe potential to further enhance the potential of mobile devices. One of the\nmajor challenges in this integration is the lack of an efficient service\nregistry system that caters to issues associated with the dynamic and volatile\nmobile environments. Existing service registry technologies designed for\ntraditional systems fall short of accommodating such issues. In this paper, we\npropose a novel approach to manage service registry systems provided 'solely'\nover mobile devices, and thus realising an SOA without the need for high-end\ncomputing systems. The approach manages a dynamic service registry system in\nthe form of light weight and distributed registries. We assess the feasibility\nof our approach by engineering and deploying a working prototype of the\nproposed registry system over actual mobile devices. A comparative study of the\nproposed approach and the traditional UDDI (Universal Description, Discovery,\nand Integration) registry is also included. The evaluation of our framework has\nshown propitious results in terms of battery cost, scalability, hindrance with\nnative applications.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 06:09:15 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Verma", "Rohit", ""], ["Srivastava", "Abhishek", ""]]}, {"id": "1609.09224", "submitter": "Chenhao Qu", "authors": "Chenhao Qu, Rodrigo N. Calheiros, Rajkumar Buyya", "title": "Auto-scaling Web Applications in Clouds: A Taxonomy and Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Web application providers have been migrating their applications to cloud\ndata centers, attracted by the emerging cloud computing paradigm. One of the\nappealing features of the cloud is elasticity. It allows cloud users to acquire\nor release computing resources on-demand, which enables web application\nproviders to automatically scale the resources provisioned to their\napplications without human intervention under a dynamic workload to minimize\nresource cost while satisfying Quality of Service (QoS) requirements. In this\npaper, we comprehensively analyze the challenges that remain in auto-scaling\nweb applications in clouds and review the developments in this field. We\npresent a taxonomy of auto-scalers according to the identified challenges and\nkey properties. We analyze the surveyed works and map them to the taxonomy to\nidentify the weaknesses in this field. Moreover, based on the analysis, we\npropose new future directions that can be explored in this area.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 06:59:03 GMT"}, {"version": "v2", "created": "Thu, 13 Oct 2016 03:57:05 GMT"}, {"version": "v3", "created": "Sun, 27 Nov 2016 02:27:34 GMT"}, {"version": "v4", "created": "Mon, 12 Dec 2016 01:06:32 GMT"}, {"version": "v5", "created": "Mon, 10 Apr 2017 01:34:28 GMT"}, {"version": "v6", "created": "Thu, 14 Sep 2017 16:19:03 GMT"}], "update_date": "2017-09-15", "authors_parsed": [["Qu", "Chenhao", ""], ["Calheiros", "Rodrigo N.", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1609.09281", "submitter": "Pankaj Khanchandani", "authors": "Pankaj Khanchandani, Christoph Lenzen", "title": "Self-stabilizing Byzantine Clock Synchronization with Optimal Precision", "comments": "35 pages, 3 figures, full version of the paper in proceedings of SSS\n  2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the approach to Byzantine fault-tolerant clock synchronization\nbased on approximate agreement introduced by Lynch and Welch. Our contribution\nis threefold:\n  (1) We provide a slightly refined variant of the algorithm yielding improved\nbounds on the skew that can be achieved and the sustainable frequency offsets.\n  (2) We show how to extend the technique to also synchronize clock rates. This\npermits less frequent communication without significant loss of precision,\nprovided that clock rates change sufficiently slowly.\n  (3) We present a coupling scheme that allows to make these algorithms\nself-stabilizing while preserving their high precision. The scheme utilizes a\nlow-precision, but self-stabilizing algorithm for the purpose of recovery.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 10:03:49 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Khanchandani", "Pankaj", ""], ["Lenzen", "Christoph", ""]]}, {"id": "1609.09294", "submitter": "Pengfei Xuan", "authors": "Pengfei Xuan, Feng Luo, Rong Ge, Pradip K Srimani", "title": "DynIMS: A Dynamic Memory Controller for In-memory Storage on HPC Systems", "comments": "5 pages, 8 figures, short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to boost the performance of data-intensive computing on HPC systems,\nin-memory computing frameworks, such as Apache Spark and Flink, use local DRAM\nfor data storage. Optimizing the memory allocation to data storage is critical\nto delivering performance to traditional HPC compute jobs and throughput to\ndata-intensive applications sharing the HPC resources. Current practices that\nstatically configure in-memory storage may leave inadequate space for compute\njobs or lose the opportunity to utilize more available space for data-intensive\napplications. In this paper, we explore techniques to dynamically adjust\nin-memory storage and make the right amount of space for compute jobs. We have\ndeveloped a dynamic memory controller, DynIMS, which infers memory demands of\ncompute tasks online and employs a feedback-based control model to adapt the\ncapacity of in-memory storage. We test DynIMS using mixed HPCC and Spark\nworkloads on a HPC cluster. Experimental results show that DynIMS can achieve\nup to 5X performance improvement compared to systems with static memory\nallocations.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 10:41:26 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Xuan", "Pengfei", ""], ["Luo", "Feng", ""], ["Ge", "Rong", ""], ["Srimani", "Pradip K", ""]]}, {"id": "1609.09296", "submitter": "Alejandro Linares-Barranco A. Linares-Barranco", "authors": "R. Tapiador, A. Rios-Navarro, A. Linares-Barranco, Minkyu Kim, Deepak\n  Kadetotad, Jae-sun Seo", "title": "Comprehensive Evaluation of OpenCL-based Convolutional Neural Network\n  Accelerators in Xilinx and Altera FPGAs", "comments": "6 pages, 6 figures. Robotic and Technology of Computers Lab report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning has significantly advanced the state of the art in artificial\nintelligence, gaining wide popularity from both industry and academia. Special\ninterest is around Convolutional Neural Networks (CNN), which take inspiration\nfrom the hierarchical structure of the visual cortex, to form deep layers of\nconvolutional operations, along with fully connected classifiers. Hardware\nimplementations of these deep CNN architectures are challenged with memory\nbottlenecks that require many convolution and fully-connected layers demanding\nlarge amount of communication for parallel computation. Multi-core CPU based\nsolutions have demonstrated their inadequacy for this problem due to the memory\nwall and low parallelism. Many-core GPU architectures show superior performance\nbut they consume high power and also have memory constraints due to\ninconsistencies between cache and main memory. FPGA design solutions are also\nactively being explored, which allow implementing the memory hierarchy using\nembedded BlockRAM. This boosts the parallel use of shared memory elements\nbetween multiple processing units, avoiding data replicability and\ninconsistencies. This makes FPGAs potentially powerful solutions for real-time\nclassification of CNNs. Both Altera and Xilinx have adopted OpenCL co-design\nframework from GPU for FPGA designs as a pseudo-automatic development solution.\nIn this paper, a comprehensive evaluation and comparison of Altera and Xilinx\nOpenCL frameworks for a 5-layer deep CNN is presented. Hardware resources,\ntemporal performance and the OpenCL architecture for CNNs are discussed. Xilinx\ndemonstrates faster synthesis, better FPGA resource utilization and more\ncompact boards. Altera provides multi-platforms tools, mature design community\nand better execution times.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 11:03:21 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Tapiador", "R.", ""], ["Rios-Navarro", "A.", ""], ["Linares-Barranco", "A.", ""], ["Kim", "Minkyu", ""], ["Kadetotad", "Deepak", ""], ["Seo", "Jae-sun", ""]]}, {"id": "1609.09333", "submitter": "Jose Gracia", "authors": "Huan Zhou, Jose Gracia", "title": "Towards performance portability through locality-awareness for\n  applications using one-sided communication primitives", "comments": "7 pages, accepted for publication in International Workshop on Legacy\n  HPC Application Migration (LHAM16) held in conjunction with CANDAR16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MPI is the most widely used data transfer and communication model in High\nPerformance Computing. The latest version of the standard, MPI-3, allows\nskilled programmers to exploit all hardware capabilities of the latest and\nfuture supercomputing systems. The revised asynchronous remote-memory-access\nmodel in combination with the shared-memory window extension, in particular,\nallow writing code that hides communication latencies and optimizes\ncommunication paths according to the locality of data origin and destination.\nThe latter is particularly important for today's multi- and many-core systems.\nHowever, writing such efficient code is highly complex and error-prone. In this\npaper we evaluate a recent remote-memory-access model, namely DART-MPI. This\nmodel claims to hide the aforementioned complexities from the programmer, but\ndeliver locality-aware remote-memory-access semantics which outperforms MPI-3\none-sided communication primitives on multi-core systems. Conceptually, the\nDART-MPI interface is simple; at the same time it takes care of the\ncomplexities of the underlying MPI-3 and system topology. This makes DART-MPI\nan interesting candidate for porting legacy applications. We evaluate these\nclaims using a realistic scientific application, specifically a\nfinite-difference stencil code which solves the heat diffusion equation, on a\nlarge-scale Cray XC40 installation.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2016 13:39:50 GMT"}], "update_date": "2016-09-30", "authors_parsed": [["Zhou", "Huan", ""], ["Gracia", "Jose", ""]]}, {"id": "1609.09563", "submitter": "Ming Yan", "authors": "Inci M. Baytas and Ming Yan and Anil K. Jain and Jiayu Zhou", "title": "Asynchronous Multi-Task Learning", "comments": "IEEE International Conference on Data Mining (ICDM) 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many real-world machine learning applications involve several learning tasks\nwhich are inter-related. For example, in healthcare domain, we need to learn a\npredictive model of a certain disease for many hospitals. The models for each\nhospital may be different because of the inherent differences in the\ndistributions of the patient populations. However, the models are also closely\nrelated because of the nature of the learning tasks modeling the same disease.\nBy simultaneously learning all the tasks, multi-task learning (MTL) paradigm\nperforms inductive knowledge transfer among tasks to improve the generalization\nperformance. When datasets for the learning tasks are stored at different\nlocations, it may not always be feasible to transfer the data to provide a\ndata-centralized computing environment due to various practical issues such as\nhigh data volume and privacy. In this paper, we propose a principled MTL\nframework for distributed and asynchronous optimization to address the\naforementioned challenges. In our framework, gradient update does not wait for\ncollecting the gradient information from all the tasks. Therefore, the proposed\nmethod is very efficient when the communication delay is too high for some task\nnodes. We show that many regularized MTL formulations can benefit from this\nframework, including the low-rank MTL for shared subspace learning. Empirical\nstudies on both synthetic and real-world datasets demonstrate the efficiency\nand effectiveness of the proposed framework.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 01:23:15 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Baytas", "Inci M.", ""], ["Yan", "Ming", ""], ["Jain", "Anil K.", ""], ["Zhou", "Jiayu", ""]]}, {"id": "1609.09654", "submitter": "Matev\\v{z} Jekovec", "authors": "Matev\\v{z} Jekovec, Andrej Brodnik", "title": "ERA Revisited: Theoretical and Experimental Evaluation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient construction of the suffix tree given an input text is an active\narea of research from the time it was first introduced. Both theoretical\ncomputer scientists and engineers tackled the problem. In this paper we focus\non the fastest practical suffix tree construction algorithm to date, ERA. We\nfirst provide a theoretical analysis of the algorithm assuming the uniformly\nrandom text as an input and using the PEM model of computation with respect to\nthe lower bounds. Secondly, we empirically confirm the theoretical results in\ndifferent test scenarios exposing the critical terms. Thirdly, we discuss the\nfundamental characteristics of the input text where the fastest suffix tree\nconstruction algorithms in practice fail. This paper serves as a foundation for\nfurther research in the parallel text indexing area.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 09:51:36 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Jekovec", "Matev\u017e", ""], ["Brodnik", "Andrej", ""]]}, {"id": "1609.09671", "submitter": "Roberto DiCecco", "authors": "Roberto DiCecco, Griffin Lacey, Jasmina Vasiljevic, Paul Chow, Graham\n  Taylor and Shawki Areibi", "title": "Caffeinated FPGAs: FPGA Framework For Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional Neural Networks (CNNs) have gained significant traction in the\nfield of machine learning, particularly due to their high accuracy in visual\nrecognition. Recent works have pushed the performance of GPU implementations of\nCNNs to significantly improve their classification and training times. With\nthese improvements, many frameworks have become available for implementing CNNs\non both CPUs and GPUs, with no support for FPGA implementations. In this work\nwe present a modified version of the popular CNN framework Caffe, with FPGA\nsupport. This allows for classification using CNN models and specialized FPGA\nimplementations with the flexibility of reprogramming the device when\nnecessary, seamless memory transactions between host and device, simple-to-use\ntest benches, and the ability to create pipelined layer implementations. To\nvalidate the framework, we use the Xilinx SDAccel environment to implement an\nFPGA-based Winograd convolution engine and show that the FPGA layer can be used\nalongside other layers running on a host processor to run several popular CNNs\n(AlexNet, GoogleNet, VGG A, Overfeat). The results show that our framework\nachieves 50 GFLOPS across 3x3 convolutions in the benchmarks. This is achieved\nwithin a practical framework, which will aid in future development of\nFPGA-based CNNs.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 11:13:21 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["DiCecco", "Roberto", ""], ["Lacey", "Griffin", ""], ["Vasiljevic", "Jasmina", ""], ["Chow", "Paul", ""], ["Taylor", "Graham", ""], ["Areibi", "Shawki", ""]]}, {"id": "1609.09823", "submitter": "Ravi  Tandon", "authors": "Mohamed Attia and Ravi Tandon", "title": "On the Worst-case Communication Overhead for Distributed Data Shuffling", "comments": "To appear in Allerton 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed learning platforms for processing large scale data-sets are\nbecoming increasingly prevalent. In typical distributed implementations, a\ncentralized master node breaks the data-set into smaller batches for parallel\nprocessing across distributed workers to achieve speed-up and efficiency.\nSeveral computational tasks are of sequential nature, and involve multiple\npasses over the data. At each iteration over the data, it is common practice to\nrandomly re-shuffle the data at the master node, assigning different batches\nfor each worker to process. This random re-shuffling operation comes at the\ncost of extra communication overhead, since at each shuffle, new data points\nneed to be delivered to the distributed workers.\n  In this paper, we focus on characterizing the information theoretically\noptimal communication overhead for the distributed data shuffling problem. We\npropose a novel coded data delivery scheme for the case of no excess storage,\nwhere every worker can only store the assigned data batches under processing.\nOur scheme exploits a new type of coding opportunity and is applicable to any\narbitrary shuffle, and for any number of workers. We also present an\ninformation theoretic lower bound on the minimum communication overhead for\ndata shuffling, and show that the proposed scheme matches this lower bound for\nthe worst-case communication overhead.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 17:23:03 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Attia", "Mohamed", ""], ["Tandon", "Ravi", ""]]}, {"id": "1609.09827", "submitter": "Vaneet Aggarwal", "authors": "Vaneet Aggarwal, Yih-Farn R. Chen, Tian Lan and Yu Xiang", "title": "Sprout: A functional caching approach to minimize service latency in\n  erasure-coded storage", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern distributed storage systems often use erasure codes to protect against\ndisk and node failures to increase reliability, while trying to meet the\nlatency requirements of the applications and clients. Storage systems may have\ncaches at the proxy or client ends in order to reduce the latency. In this\npaper, we consider a novel caching framework with erasure code called\nfunctional caching. Functional Caching involves using erasure-coded chunks in\nthe cache such that the code formed by the chunks in storage nodes and cache\ncombined are maximal-distance-separable (MDS) erasure codes. Based on the\narrival rates of different files, placement of file chunks on the servers, and\nservice time distribution of storage servers, an optimal functional caching\nplacement and the access probabilities of the file request from different disks\nare considered. The proposed algorithm gives significant latency improvement in\nboth simulations and a prototyped solution in an open-source, cloud storage\ndeployment.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2016 17:31:21 GMT"}, {"version": "v2", "created": "Wed, 19 Jul 2017 14:59:35 GMT"}, {"version": "v3", "created": "Fri, 21 Jul 2017 03:44:17 GMT"}], "update_date": "2017-07-24", "authors_parsed": [["Aggarwal", "Vaneet", ""], ["Chen", "Yih-Farn R.", ""], ["Lan", "Tian", ""], ["Xiang", "Yu", ""]]}]