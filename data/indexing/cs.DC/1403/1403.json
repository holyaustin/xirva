[{"id": "1403.0486", "submitter": "Grigory Yaroslavtsev", "authors": "Nikhil Devanur, Konstantin Makarychev, Debmalya Panigrahi, Grigory\n  Yaroslavtsev", "title": "Online Algorithms for Machine Minimization", "comments": "After the first version of the manuscript was posted online, it was\n  brought to our attention that Theorem 1.1 also follows from the results of\n  Bansal, Kimbrel and Pruhs, \"Speed Scaling to Minimize Energy and Temperature\"\n  (JACM'07), who consider energy-minimizing scheduling problems. This result\n  follows from Lemma 4.7 and Lemma 4.8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the online version of the machine minimization\nproblem (introduced by Chuzhoy et al., FOCS 2004), where the goal is to\nschedule a set of jobs with release times, deadlines, and processing lengths on\na minimum number of identical machines. Since the online problem has strong\nlower bounds if all the job parameters are arbitrary, we focus on jobs with\nuniform length. Our main result is a complete resolution of the deterministic\ncomplexity of this problem by showing that a competitive ratio of $e$ is\nachievable and optimal, thereby improving upon existing lower and upper bounds\nof 2.09 and 5.2 respectively. We also give a constant-competitive online\nalgorithm for the case of uniform deadlines (but arbitrary job lengths); to the\nbest of our knowledge, no such algorithm was known previously. Finally, we\nconsider the complimentary problem of throughput maximization where the goal is\nto maximize the sum of weights of scheduled jobs on a fixed set of identical\nmachines (introduced by Bar-Noy et al. STOC 1999). We give a randomized online\nalgorithm for this problem with a competitive ratio of e/e-1; previous results\nachieved this bound only for the case of a single machine or in the limit of an\ninfinite number of machines.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2014 16:59:18 GMT"}, {"version": "v2", "created": "Wed, 5 Mar 2014 04:52:59 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Devanur", "Nikhil", ""], ["Makarychev", "Konstantin", ""], ["Panigrahi", "Debmalya", ""], ["Yaroslavtsev", "Grigory", ""]]}, {"id": "1403.0500", "submitter": "Blesson Varghese", "authors": "Blesson Varghese and Gerard McKee and Vassil Alexandrov", "title": "Automating Fault Tolerance in High-Performance Computational Biological\n  Jobs Using Multi-Agent Approaches", "comments": "Computers in Biology and Medicine", "journal-ref": null, "doi": "10.1016/j.compbiomed.2014.02.005", "report-no": null, "categories": "cs.DC cs.CE cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Background: Large-scale biological jobs on high-performance computing systems\nrequire manual intervention if one or more computing cores on which they\nexecute fail. This places not only a cost on the maintenance of the job, but\nalso a cost on the time taken for reinstating the job and the risk of losing\ndata and execution accomplished by the job before it failed. Approaches which\ncan proactively detect computing core failures and take action to relocate the\ncomputing core's job onto reliable cores can make a significant step towards\nautomating fault tolerance.\n  Method: This paper describes an experimental investigation into the use of\nmulti-agent approaches for fault tolerance. Two approaches are studied, the\nfirst at the job level and the second at the core level. The approaches are\ninvestigated for single core failure scenarios that can occur in the execution\nof parallel reduction algorithms on computer clusters. A third approach is\nproposed that incorporates multi-agent technology both at the job and core\nlevel. Experiments are pursued in the context of genome searching, a popular\ncomputational biology application.\n  Result: The key conclusion is that the approaches proposed are feasible for\nautomating fault tolerance in high-performance computing systems with minimal\nhuman intervention. In a typical experiment in which the fault tolerance is\nstudied, centralised and decentralised checkpointing approaches on an average\nadd 90% to the actual time for executing the job. On the other hand, in the\nsame experiment the multi-agent approaches add only 10% to the overall\nexecution time.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2014 17:42:24 GMT"}], "update_date": "2014-03-04", "authors_parsed": [["Varghese", "Blesson", ""], ["McKee", "Gerard", ""], ["Alexandrov", "Vassil", ""]]}, {"id": "1403.0603", "submitter": "Michael Rabbat", "authors": "Konstantinos I. Tsianos and Michael G. Rabbat", "title": "Efficient Distributed Online Prediction and Stochastic Optimization with\n  Approximate Distributed Averaging", "comments": "30 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.SY math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed methods for online prediction and stochastic\noptimization. Our approach is iterative: in each round nodes first perform\nlocal computations and then communicate in order to aggregate information and\nsynchronize their decision variables. Synchronization is accomplished through\nthe use of a distributed averaging protocol. When an exact distributed\naveraging protocol is used, it is known that the optimal regret bound of\n$\\mathcal{O}(\\sqrt{m})$ can be achieved using the distributed mini-batch\nalgorithm of Dekel et al. (2012), where $m$ is the total number of samples\nprocessed across the network. We focus on methods using approximate distributed\naveraging protocols and show that the optimal regret bound can also be achieved\nin this setting. In particular, we propose a gossip-based optimization method\nwhich achieves the optimal regret bound. The amount of communication required\ndepends on the network topology through the second largest eigenvalue of the\ntransition matrix of a random walk on the network. In the setting of stochastic\noptimization, the proposed gossip-based approach achieves nearly-linear\nscaling: the optimization error is guaranteed to be no more than $\\epsilon$\nafter $\\mathcal{O}(\\frac{1}{n \\epsilon^2})$ rounds, each of which involves\n$\\mathcal{O}(\\log n)$ gossip iterations, when nodes communicate over a\nwell-connected graph. This scaling law is also observed in numerical\nexperiments on a cluster.\n", "versions": [{"version": "v1", "created": "Mon, 3 Mar 2014 21:32:53 GMT"}, {"version": "v2", "created": "Wed, 5 Mar 2014 08:22:48 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Tsianos", "Konstantinos I.", ""], ["Rabbat", "Michael G.", ""]]}, {"id": "1403.0734", "submitter": "Emanuele Guido Fusco", "authors": "Irene Finocchi, Marco Finocchi, Emanuele G. Fusco", "title": "Clique counting in MapReduce: theory and experiments", "comments": null, "journal-ref": "ACM Journal of Experimental Algorithmics 20: 1.7:1-1.7:20 (2015)", "doi": "10.1145/2794080", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We tackle the problem of counting the number of $k$-cliques in large-scale\ngraphs, for any constant $k \\ge 3$. Clique counting is essential in a variety\nof applications, among which social network analysis. Due to its\ncomputationally intensive nature, we settle for parallel solutions in the\nMapReduce framework, which has become in the last few years a {\\em de facto}\nstandard for batch processing of massive data sets. We give both theoretical\nand experimental contributions.\n  On the theory side, we design the first exact scalable algorithm for counting\n(and listing) $k$-cliques. Our algorithm uses $O(m^{3/2})$ total space and\n$O(m^{k/2})$ work, where $m$ is the number of graph edges. This matches the\nbest-known bounds for triangle listing when $k=3$ and is work-optimal in the\nworst case for any $k$, while keeping the communication cost independent of\n$k$. We also design a sampling-based estimator that can dramatically reduce the\nrunning time and space requirements of the exact approach, while providing very\naccurate solutions with high probability.\n  We then assess the effectiveness of different clique counting approaches\nthrough an extensive experimental analysis over the Amazon EC2 platform,\nconsidering both our algorithms and their state-of-the-art competitors. The\nexperimental results clearly highlight the algorithm of choice in different\nscenarios and prove our exact approach to be the most effective when the number\nof $k$-cliques is large, gracefully scaling to non-trivial values of $k$ even\non clusters of small/medium size. Our approximation algorithm achieves\nextremely accurate estimates and large speedups, especially on the toughest\ninstances for the exact algorithms. As a side effect, our study also sheds\nlight on the number of $k$-cliques of several real-world graphs, mainly social\nnetworks, and on its growth rate as a function of $k$.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 10:36:35 GMT"}, {"version": "v2", "created": "Tue, 8 Jul 2014 15:38:22 GMT"}], "update_date": "2018-04-13", "authors_parsed": [["Finocchi", "Irene", ""], ["Finocchi", "Marco", ""], ["Fusco", "Emanuele G.", ""]]}, {"id": "1403.0750", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "Recent Developments with the licas System 2", "comments": "White paper / pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The licas (lightweight Internet-based communication for autonomic services)\nsystem is a Java-based open source framework for building service-based\nnetworks, similar to what you would use a Cloud or SOA platform for. The\nframework comes with a server for running the services on, mechanisms for\nadding services to the server, mechanisms for linking services with each other,\nand mechanisms for allowing the services to communicate with each other. The\ngeneral architecture of the system is now fairly well set, where this paper\ndescribes recent developments that have focused on making the framework more\nrobust and additional features for easier programming.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 11:54:01 GMT"}, {"version": "v2", "created": "Mon, 5 May 2014 11:35:14 GMT"}], "update_date": "2014-05-06", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1403.0753", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "Recent Developments with the licas System", "comments": "White paper / pre-print", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes recent developments with the licas (lightweight\nInternet-based communication for autonomic services) software package. In\nparticular, it describes how the architecture and functionality have changed\nfrom the first version release. The autonomous nature of the system is focused\non, which requires independent behaviour and metadata descriptions of each\nservice. The system has now also been ported to the Java mobile environment.\nThen some open questions or problems will be discussed in the areas of metadata\nconsistency, security and trust. Finally, some solutions to these problems will\nalso be suggested.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 11:58:32 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1403.0762", "submitter": "Kieran Greer Dr", "authors": "Kieran Greer", "title": "Evaluating Dynamic Linking through the Query Process using the Licas\n  Test Platform", "comments": "White paper / pre-print", "journal-ref": "IOSR Journal of Engineering (IOSRJEN), Vol. 5, issue 2, February,\n  pp. 45 - 52, 2015. ISSN (e): 2250-3021, ISSN (p): 2278-8719", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A novel linking mechanism has been described previously [4] that can be used\nto autonomously link sources that provide related answers to queries executed\nover an information network. The test query platform has now been re-written\nresulting in essentially a new test platform using the same basic query\nmechanism, but with a slightly different algorithm. This paper describes recent\ntest results on the same query test process that supports the original findings\nand also shows the effectiveness of the linking mechanism in a new set of test\nscenarios.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 12:33:38 GMT"}], "update_date": "2015-03-17", "authors_parsed": [["Greer", "Kieran", ""]]}, {"id": "1403.0802", "submitter": "Jianting Zhang", "authors": "Jianting Zhang Simin You", "title": "Large-Scale Geospatial Processing on Multi-Core and Many-Core\n  Processors: Evaluations on CPUs, GPUs and MICs", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geospatial Processing, such as queries based on point-to-polyline shortest\ndistance and point-in-polygon test, are fundamental to many scientific and\nengineering applications, including post-processing large-scale environmental\nand climate model outputs and analyzing traffic and travel patterns from\nmassive GPS collections in transportation engineering and urban studies.\nCommodity parallel hardware, such as multi-core CPUs, many-core GPUs and Intel\nMIC accelerators, provide enormous computing power which can potentially\nachieve significant speedups on existing geospatial processing and open the\nopportunities for new applications. However, the realizable potential for\ngeospatial processing on these new hardware devices is largely unknown due to\nthe complexity in porting serial algorithms to diverse parallel hardware\nplatforms. In this study, we aim at experimenting our data-parallel designs and\nimplementations of point-to-polyline shortest distance computation (P2P) and\npoint-in-polygon topological test (PIP) on different commodity hardware using\nreal large-scale geospatial data, comparing their performance and discussing\nimportant factors that may significantly affect the performance. Our\nexperiments have shown that, while GPUs can be several times faster than\nmulti-core CPUs without utilizing the increasingly available SIMD computing\npower on Vector Processing Units (VPUs) that come with multi-core CPUs and\nMICs, multi-core CPUs and MICs can be several times faster than GPUs when VPUs\nare utilized. By adopting a Domain Specific Language (DSL) approach to\nexploiting the VPU computing power in geospatial processing, we are free from\nprogramming SIMD intrinsic functions directly which makes the new approach more\neffective, portable and scalable. Our designs, implementations and experiments\ncan serve as case studies for parallel geospatial computing on modern commodity\nparallel hardware.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 14:46:29 GMT"}], "update_date": "2014-03-05", "authors_parsed": [["You", "Jianting Zhang Simin", ""]]}, {"id": "1403.0949", "submitter": "Ilya Baldin", "authors": "Yufeng Xin, Ilya Baldin, Jeff Chase, Kemafor Ogan", "title": "Leveraging Semantic Web Technologies for Managing Resources in a\n  Multi-Domain Infrastructure-as-a-Service Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": "RENCI TR-14-01", "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reports on experience with using semantically-enabled network\nresource models to construct an operational multi-domain networked\ninfrastructure-as-a-service (NIaaS) testbed called ExoGENI, recently funded\nthrough NSF's GENI project. A defining property of NIaaS is the deep\nintegration of network provisioning functions alongside the more common storage\nand computation provisioning functions. Resource provider topologies and user\nrequests can be described using network resource models with common base\nclasses for fundamental cyber-resources (links, nodes, interfaces) specialized\nvia virtualization and adaptations between networking layers to specific\ntechnologies.\n  This problem space gives rise to a number of application areas where semantic\nweb technologies become highly useful - common information models and resource\nclass hierarchies simplify resource descriptions from multiple providers,\npathfinding and topology embedding algorithms rely on query abstractions as\nbuilding blocks.\n  The paper describes how the semantic resource description models enable\nExoGENI to autonomously instantiate on-demand virtual topologies of virtual\nmachines provisioned from cloud providers and are linked by on-demand virtual\nconnections acquired from multiple autonomous network providers to serve a\nvariety of applications ranging from distributed system experiments to\nhigh-performance computing.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 21:08:44 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Xin", "Yufeng", ""], ["Baldin", "Ilya", ""], ["Chase", "Jeff", ""], ["Ogan", "Kemafor", ""]]}, {"id": "1403.0968", "submitter": "David Medina", "authors": "David S Medina, Amik St-Cyr, T. Warburton", "title": "OCCA: A unified approach to multi-threading languages", "comments": "25 pages, 6 figures, 9 code listings, 8 tables, Submitted to the SIAM\n  Journal on Scientific Computing (SISC), presented at the Oil & Gas Workshop\n  2014 at Rice University", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The inability to predict lasting languages and architectures led us to\ndevelop OCCA, a C++ library focused on host-device interaction. Using run-time\ncompilation and macro expansions, the result is a novel single kernel language\nthat expands to multiple threading languages. Currently, OCCA supports device\nkernel expansions for the OpenMP, OpenCL, and CUDA platforms. Computational\nresults using finite difference, spectral element and discontinuous Galerkin\nmethods show OCCA delivers portable high performance in different architectures\nand platforms.\n", "versions": [{"version": "v1", "created": "Tue, 4 Mar 2014 22:30:49 GMT"}], "update_date": "2014-03-06", "authors_parsed": [["Medina", "David S", ""], ["St-Cyr", "Amik", ""], ["Warburton", "T.", ""]]}, {"id": "1403.1180", "submitter": "Nikos Chondros", "authors": "Nikos Chondros, Mema Roussopoulos", "title": "A distributed Integrity Catalog for digital repositories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.DL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Digital repositories, either digital preservation systems or archival\nsystems, periodically check the integrity of stored objects to assure users of\ntheir correctness. To do so, prior solutions calculate integrity metadata and\nrequire the repository to store it alongside the actual data objects. This\nintegrity metadata is essential for regularly verifying the correctness of the\nstored data objects. To safeguard and detect damage to this metadata, prior\nsolutions rely on widely visible media, that is unaffiliated third parties, to\nstore and provide back digests of the metadata to verify it is intact. However,\nthey do not address recovery of the integrity metadata in case of damage or\nattack by an adversary. In essence, they do not preserve this metadata. We\nintroduce IntegrityCatalog, a system that collects all integrity related\nmetadata in a single component, and treats them as first class objects,\nmanaging both their integrity and their preservation. We introduce a\ntreap-based persistent authenticated dictionary managing arbitrary length\nkey/value pairs, which we use to store all integrity metadata, accessible\nsimply by object name. Additionally, IntegrityCatalog is a distributed system\nthat includes a network protocol that manages both corruption detection and\npreservation of this metadata, using administrator-selected network peers with\ntwo possible roles. Verifiers store and offer attestations on digests and have\nminimal storage requirements, while preservers efficiently synchronize a\ncomplete copy of the catalog to assist in recovery in case of a detected\ncatalog compromise on the local system. We describe our prototype\nimplementation of IntegrityCatalog, measure its performance empirically, and\ndemonstrate its effectiveness in real-world situations, with worst measured\nthroughput of approximately 1K insertions per second, and 2K verified search\noperations per second.\n", "versions": [{"version": "v1", "created": "Tue, 4 Feb 2014 17:52:22 GMT"}, {"version": "v2", "created": "Thu, 25 Sep 2014 09:13:02 GMT"}], "update_date": "2014-09-26", "authors_parsed": [["Chondros", "Nikos", ""], ["Roussopoulos", "Mema", ""]]}, {"id": "1403.1289", "submitter": "Yong Fu", "authors": "Yong Fu and Anne Holler and Chenyang Lu", "title": "CloudPowerCap: Integrating Power Budget and Resource Management across a\n  Virtualized Server Cluster", "comments": "Tech report for USENIX ICAC", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In many datacenters, server racks are highly underutilized. Rack slots are\nleft empty to keep the sum of the server nameplate maximum power below the\npower provisioned to the rack. And the servers that are placed in the rack\ncannot make full use of available rack power. The root cause of this rack\nunderutilization is that the server nameplate power is often much higher than\ncan be reached in practice. To address rack underutilization, server vendors\nare shipping support for per-host power caps, which provide a server-enforced\nlimit on the amount of power that the server can draw. Using this feature,\ndatacenter operators can set power caps on the hosts in the rack to ensure that\nthe sum of those caps does not exceed the rack's provisioned power. While this\napproach improves rack utilization, it burdens the operator with managing the\nrack power budget across the hosts and does not lend itself to flexible\nallocation of power to handle workload usage spikes or to respond to changes in\nthe amount of powered-on server capacity in the rack. In this paper we present\nCloudPowerCap, a practical and scalable solution for power budget management in\na virtualized environment. CloudPowerCap manages the power budget for a cluster\nof virtualized servers, dynamically adjusting the per-host power caps for hosts\nin the cluster. We show how CloudPowerCap can provide better use of power than\nper-host static settings, while respecting virtual machine resource\nentitlements and constraints.\n", "versions": [{"version": "v1", "created": "Wed, 5 Mar 2014 22:44:31 GMT"}, {"version": "v2", "created": "Tue, 11 Mar 2014 13:52:07 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["Fu", "Yong", ""], ["Holler", "Anne", ""], ["Lu", "Chenyang", ""]]}, {"id": "1403.1305", "submitter": "Roshan Ragel", "authors": "S. Arudchutha, T. Nishanthy and R. G. Ragel", "title": "String Matching with Multicore CPUs: Performing Better with the\n  Aho-Corasick Algorithm", "comments": null, "journal-ref": "8th IEEE International Conference on Industrial and Information\n  Systems (ICIIS), 2013, pp. 231-236, 17-20 Dec. 2013", "doi": "10.1109/ICIInfS.2013.6731987", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple string matching is known as locating all the occurrences of a given\nnumber of patterns in an arbitrary string. It is used in bio-computing\napplications where the algorithms are commonly used for retrieval of\ninformation such as sequence analysis and gene/protein identification.\nExtremely large amount of data in the form of strings has to be processed in\nsuch bio-computing applications. Therefore, improving the performance of\nmultiple string matching algorithms is always desirable. Multicore\narchitectures are capable of providing better performance by parallelizing the\nmultiple string matching algorithms. The Aho-Corasick algorithm is the one that\nis commonly used in exact multiple string matching algorithms. The focus of\nthis paper is the acceleration of Aho-Corasick algorithm through a multicore\nCPU based software implementation. Through our implementation and evaluation of\nresults, we prove that our method performs better compared to the state of the\nart.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 00:53:36 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Arudchutha", "S.", ""], ["Nishanthy", "T.", ""], ["Ragel", "R. G.", ""]]}, {"id": "1403.1313", "submitter": "Roshan Ragel", "authors": "P. Perera and R. G. Ragel", "title": "Accelerating motif finding in DNA sequences with multicore CPUs", "comments": null, "journal-ref": "Industrial and Information Systems (ICIIS), 2013 8th IEEE\n  International Conference on, pp. 242-247, 17-20 Dec. 2013", "doi": "10.1109/ICIInfS.2013.6731989", "report-no": null, "categories": "cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motif discovery in DNA sequences is a challenging task in molecular biology.\nIn computational motif discovery, Planted (l, d) motif finding is a widely\nstudied problem and numerous algorithms are available to solve it. Both\nhardware and software accelerators have been introduced to accelerate the motif\nfinding algorithms. However, the use of hardware accelerators such as FPGAs\nneeds hardware specialists to design such systems. Software based acceleration\nmethods on the other hand are easier to implement than hardware acceleration\ntechniques. Grid computing is one such software based acceleration technique\nwhich has been used in acceleration of motif finding. However, drawbacks such\nas network communication delays and the need of fast interconnection between\nnodes in the grid can limit its usage and scalability. As using multicore CPUs\nto accelerate CPU intensive tasks are becoming increasingly popular and common\nnowadays, we can employ it to accelerate motif finding and it can be a faster\nmethod than grid based acceleration. In this paper, we have explored the use of\nmulticore CPUs to accelerate motif finding. We have accelerated the Skip-Brute\nForce algorithm on multicore CPUs parallelizing it using the POSIX thread\nlibrary. Our method yielded an average speed up of 34x on a 32-core processor\ncompared to a speed up of 21x on a grid based implementation of 32 nodes.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 01:24:13 GMT"}], "update_date": "2014-03-07", "authors_parsed": [["Perera", "P.", ""], ["Ragel", "R. G.", ""]]}, {"id": "1403.1528", "submitter": "Andre Luckow", "authors": "Shantenu Jha, Judy Qiu, Andre Luckow, Pradeep Mantha, Geoffrey C.Fox", "title": "A Tale of Two Data-Intensive Paradigms: Applications, Abstractions, and\n  Architectures", "comments": "8 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific problems that depend on processing large amounts of data require\novercoming challenges in multiple areas: managing large-scale data\ndistribution, co-placement and scheduling of data with compute resources, and\nstoring and transferring large volumes of data. We analyze the ecosystems of\nthe two prominent paradigms for data-intensive applications, hereafter referred\nto as the high-performance computing and the Apache-Hadoop paradigm. We propose\na basis, common terminology and functional factors upon which to analyze the\ntwo approaches of both paradigms. We discuss the concept of \"Big Data Ogres\"\nand their facets as means of understanding and characterizing the most common\napplication workloads found across the two paradigms. We then discuss the\nsalient features of the two paradigms, and compare and contrast the two\napproaches. Specifically, we examine common implementation/approaches of these\nparadigms, shed light upon the reasons for their current \"architecture\" and\ndiscuss some typical workloads that utilize them. In spite of the significant\nsoftware distinctions, we believe there is architectural similarity. We discuss\nthe potential integration of different implementations, across the different\nlevels and components. Our comparison progresses from a fully qualitative\nexamination of the two paradigms, to a semi-quantitative methodology. We use a\nsimple and broadly used Ogre (K-means clustering), characterize its performance\non a range of representative platforms, covering several implementations from\nboth paradigms. Our experiments provide an insight into the relative strengths\nof the two paradigms. We propose that the set of Ogres will serve as a\nbenchmark to evaluate the two paradigms along different dimensions.\n", "versions": [{"version": "v1", "created": "Thu, 6 Mar 2014 18:48:55 GMT"}, {"version": "v2", "created": "Mon, 23 Jun 2014 01:56:34 GMT"}], "update_date": "2014-06-24", "authors_parsed": [["Jha", "Shantenu", ""], ["Qiu", "Judy", ""], ["Luckow", "Andre", ""], ["Mantha", "Pradeep", ""], ["Fox", "Geoffrey C.", ""]]}, {"id": "1403.1642", "submitter": "Soheil Eshghi", "authors": "Soheil Eshghi, MHR. Khouzani, Saswati Sarkar, Ness B. Shroff, Santosh\n  S. Venkatesh", "title": "Optimal Energy-Aware Epidemic Routing in DTNs", "comments": "17 pages, 9 figures", "journal-ref": null, "doi": "10.1109/TAC.2015.2396641", "report-no": null, "categories": "cs.SY cs.DC cs.NI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we investigate the use of epidemic routing in energy\nconstrained Delay Tolerant Networks (DTNs). In epidemic routing, messages are\nrelayed by intermediate nodes at contact opportunities, i.e., when pairs of\nnodes come within the transmission range of each other. Each node needs to\ndecide whether to forward its message upon contact with a new node based on its\nown residual energy level and the age of that message. We mathematically\ncharacterize the fundamental trade-off between energy conservation and a\nmeasure of Quality of Service as a dynamic energy-dependent optimal control\nproblem. We prove that in the mean-field regime, the optimal dynamic forwarding\ndecisions follow simple threshold-based structures in which the forwarding\nthreshold for each node depends on its current remaining energy. We then\ncharacterize the nature of this dependence. Our simulations reveal that the\noptimal dynamic policy significantly outperforms heuristics.\n", "versions": [{"version": "v1", "created": "Fri, 7 Mar 2014 03:15:17 GMT"}, {"version": "v2", "created": "Tue, 2 Jun 2015 10:31:33 GMT"}], "update_date": "2018-09-06", "authors_parsed": [["Eshghi", "Soheil", ""], ["Khouzani", "MHR.", ""], ["Sarkar", "Saswati", ""], ["Shroff", "Ness B.", ""], ["Venkatesh", "Santosh S.", ""]]}, {"id": "1403.1706", "submitter": "Johannes K\\\"oster", "authors": "Johannes K\\\"oster, Sven Rahmann", "title": "Massively parallel read mapping on GPUs with PEANUT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present PEANUT (ParallEl AligNment UTility), a highly parallel GPU-based\nread mapper with several distinguishing features, including a novel q-gram\nindex (called the q-group index) with small memory footprint built on-the-fly\nover the reads and the possibility to output both the best hits or all hits of\na read. Designing the algorithm particularly for the GPU architecture, we were\nable to reach maximum core occupancy for several key steps. Our benchmarks show\nthat PEANUT outperforms other state-of- the-art mappers in terms of speed and\nsensitivity. The software is available at http://peanut.readthedocs.org.\n", "versions": [{"version": "v1", "created": "Fri, 7 Mar 2014 10:10:07 GMT"}], "update_date": "2014-03-10", "authors_parsed": [["K\u00f6ster", "Johannes", ""], ["Rahmann", "Sven", ""]]}, {"id": "1403.1824", "submitter": "Florian Meyer", "authors": "Florian Meyer, Ondrej Hlinka, Henk Wymeersch, Erwin Riegler, and Franz\n  Hlawatsch", "title": "Distributed Localization and Tracking of Mobile Networks Including\n  Noncooperative Objects - Extended Version", "comments": "16 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Bayesian method for distributed sequential localization of\nmobile networks composed of both cooperative agents and noncooperative objects.\nOur method provides a consistent combination of cooperative self-localization\n(CS) and distributed tracking (DT). Multiple mobile agents and objects are\nlocalized and tracked using measurements between agents and objects and between\nagents. For a distributed operation and low complexity, we combine\nparticle-based belief propagation with a consensus or gossip scheme. High\nlocalization accuracy is achieved through a probabilistic information transfer\nbetween the CS and DT parts of the underlying factor graph. Simulation results\ndemonstrate significant improvements in both agent self-localization and object\nlocalization performance compared to separate CS and DT, and very good scaling\nproperties with respect to the numbers of agents and objects.\n", "versions": [{"version": "v1", "created": "Fri, 7 Mar 2014 17:44:27 GMT"}, {"version": "v2", "created": "Wed, 17 Dec 2014 10:31:09 GMT"}, {"version": "v3", "created": "Fri, 18 Sep 2015 17:53:21 GMT"}, {"version": "v4", "created": "Wed, 23 Sep 2015 14:22:07 GMT"}, {"version": "v5", "created": "Thu, 31 Dec 2015 16:16:56 GMT"}], "update_date": "2016-01-01", "authors_parsed": [["Meyer", "Florian", ""], ["Hlinka", "Ondrej", ""], ["Wymeersch", "Henk", ""], ["Riegler", "Erwin", ""], ["Hlawatsch", "Franz", ""]]}, {"id": "1403.2043", "submitter": "Ruhi Gupta", "authors": "Ruhi Gupta", "title": "Implementation of an efficient RBAC in Cloud Computing using .NET\n  environment", "comments": "6 pages, 5 figures, 1 flowchart, published By International Journal\n  of Computer Trends and Technology(IJCTT)", "journal-ref": "Ruhi Gupta. \"Implementation of an Efficient RBAC Technique of\n  Cloud Computing In .NET Environment in\n  (IJCTT)V8(3):120125,February2014.ISSN:22312803.www.ijcttjournal.org.Published\n  by Seventh Sense Research Group", "doi": "10.14445/22312803/IJCTT-V8P122", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Computing is flourishing day by day and it will continue in developing\nphase until computers and internet era is in existence. While dealing with\ncloud computing, a number of security and traffic related issues are\nconfronted. Load Balancing is one of the answers to these issues. RBAC deals\nwith such an answer. The proposed technique involves the hybrid of FCFS with\nRBAC technique. RBAC will assign roles to the clients and clients with a\nparticular role can only access the particular document. Hence identity\nmanagement and access management are fully implemented using this technique.\n", "versions": [{"version": "v1", "created": "Sun, 9 Mar 2014 09:59:32 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Gupta", "Ruhi", ""]]}, {"id": "1403.2056", "submitter": "Timo Bingmann", "authors": "Timo Bingmann, Andreas Eberle, Peter Sanders", "title": "Engineering Parallel String Sorting", "comments": "46 pages, extension of \"Parallel String Sample Sort\" arXiv:1305.1157", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss how string sorting algorithms can be parallelized on modern\nmulti-core shared memory machines. As a synthesis of the best sequential string\nsorting algorithms and successful parallel sorting algorithms for atomic\nobjects, we first propose string sample sort. The algorithm makes effective use\nof the memory hierarchy, uses additional word level parallelism, and largely\navoids branch mispredictions. Then we focus on NUMA architectures, and develop\nparallel multiway LCP-merge and -mergesort to reduce the number of random\nmemory accesses to remote nodes. Additionally, we parallelize variants of\nmultikey quicksort and radix sort that are also useful in certain situations.\nComprehensive experiments on five current multi-core platforms are then\nreported and discussed. The experiments show that our implementations scale\nvery well on real-world inputs and modern machines.\n", "versions": [{"version": "v1", "created": "Sun, 9 Mar 2014 13:43:32 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Bingmann", "Timo", ""], ["Eberle", "Andreas", ""], ["Sanders", "Peter", ""]]}, {"id": "1403.2187", "submitter": "Dou El Kefel Mansouri", "authors": "Dou El Kefel Mansouri, Mohamed Benyettou", "title": "A study of risk management in cloud computing bank", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing apparently helps in reducing costs and providing the\nscheduling optimal level. In practice however it may confront the problem of\nunavailability of resources. Taking into consideration the cloud computing bank\nwith its somehow commercial nature, the resources unavailability, such as\nliquidity risk, remains. In this paper, an attempt to show through a solution\nso far applied in economy, how would it be possible to predict such a liquidity\nrisk in cloud computing bank. The proposed solution can especially be adapted\nto stock management. To reduce the risk we will also make use of a method\ninspired from physics based on the fluids mechanics; it is an application of\nBernoulli's theorem called Torricelli. The resource bank will be considered as\na reservoir of liquid, and the availability of resources then will depend on\nthe liquid flow velocity and the replacement.\n", "versions": [{"version": "v1", "created": "Mon, 10 Mar 2014 09:30:11 GMT"}], "update_date": "2014-03-11", "authors_parsed": [["Mansouri", "Dou El Kefel", ""], ["Benyettou", "Mohamed", ""]]}, {"id": "1403.2404", "submitter": "Long Cheng", "authors": "Long Cheng, Avinash Malik, Spyros Kotoulas, Tomas E Ward, Georgios\n  Theodoropoulos", "title": "Scalable RDF Data Compression using X10", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Semantic Web comprises enormous volumes of semi-structured data elements.\nFor interoperability, these elements are represented by long strings. Such\nrepresentations are not efficient for the purposes of Semantic Web applications\nthat perform computations over large volumes of information. A typical method\nfor alleviating the impact of this problem is through the use of compression\nmethods that produce more compact representations of the data. The use of\ndictionary encoding for this purpose is particularly prevalent in Semantic Web\ndatabase systems. However, centralized implementations present performance\nbottlenecks, giving rise to the need for scalable, efficient distributed\nencoding schemes. In this paper, we describe an encoding implementation based\non the asynchronous partitioned global address space (APGAS) parallel\nprogramming model. We evaluate performance on a cluster of up to 384 cores and\ndatasets of up to 11 billion triples (1.9 TB). Compared to the state-of-art\nMapReduce algorithm, we demonstrate a speedup of 2.6-7.4x and excellent\nscalability. These results illustrate the strong potential of the APGAS model\nfor efficient implementation of dictionary encoding and contributes to the\nengineering of larger scale Semantic Web applications.\n", "versions": [{"version": "v1", "created": "Mon, 10 Mar 2014 20:48:08 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["Cheng", "Long", ""], ["Malik", "Avinash", ""], ["Kotoulas", "Spyros", ""], ["Ward", "Tomas E", ""], ["Theodoropoulos", "Georgios", ""]]}, {"id": "1403.2508", "submitter": "Rajib Das", "authors": "Sunirmal Khatua, Preetam K. Sur, Rajib K. Das and Nandini Mukherjee", "title": "Heuristic-based Optimal Resource Provisioning in Application-centric\n  Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Service Providers (CSPs) adapt different pricing models for their\noffered services. Some of the models are suitable for short term requirement\nwhile others may be suitable for the Cloud Service User's (CSU) long term\nrequirement. In this paper, we look at the problem of finding the amount of\nresources to be reserved to satisfy the CSU's long term demands with the aim of\nminimizing the total cost. Finding the optimal resource requirement to satisfy\nthe the CSU's demand for resources needs sufficient research effort. Various\nalgorithms were discussed in the last couple of years for finding the optimal\nresource requirement but most of them are based on IPP which is NP in nature.\nIn this paper, we derive some heuristic-based polynomial time algorithms to\nfind some near optimal solution to the problem. We show that the cost for CSU\nusing our approach is comparable to the solution obtained using optimal Integer\nProgramming Problem(IPP).\n", "versions": [{"version": "v1", "created": "Tue, 11 Mar 2014 09:07:16 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["Khatua", "Sunirmal", ""], ["Sur", "Preetam K.", ""], ["Das", "Rajib K.", ""], ["Mukherjee", "Nandini", ""]]}, {"id": "1403.2625", "submitter": "Sruti   S", "authors": "Sruti Gan Chaudhuri, Swapnil Ghike, Shrainik Jain and Krishnendu\n  Mukhopadhyaya", "title": "Pattern Formation for Asynchronous Robots without Agreement in Chirality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a deterministic algorithm for forming a given asymmetric\npattern in finite time by a set of autonomous, homogeneous, oblivious mobile\nrobots under the CORDA model. The robots are represented as points on the 2D\nplane. There is no explicit communication between the robots. The robots\ncoordinate among themselves by observing the positions of the other robots on\nthe plane. Initially all the robots are assumed to be stationary. The robots\nhave local coordinate systems defined by Sense of Direction (SoD), orientation\nor chirality and scale. Initially the robots are in asymmetric configuration.\nWe show that these robots can form any given asymmetric pattern in finite time.\n", "versions": [{"version": "v1", "created": "Tue, 11 Mar 2014 16:12:58 GMT"}], "update_date": "2014-03-12", "authors_parsed": [["Chaudhuri", "Sruti Gan", ""], ["Ghike", "Swapnil", ""], ["Jain", "Shrainik", ""], ["Mukhopadhyaya", "Krishnendu", ""]]}, {"id": "1403.2660", "submitter": "Stanislav Minsker", "authors": "Stanislav Minsker, Sanvesh Srivastava, Lizhen Lin and David B. Dunson", "title": "Robust and Scalable Bayes via a Median of Subset Posterior Measures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.ST cs.DC cs.LG stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a novel approach to Bayesian analysis that is provably robust to\noutliers in the data and often has computational advantages over standard\nmethods. Our technique is based on splitting the data into non-overlapping\nsubgroups, evaluating the posterior distribution given each independent\nsubgroup, and then combining the resulting measures. The main novelty of our\napproach is the proposed aggregation step, which is based on the evaluation of\na median in the space of probability measures equipped with a suitable\ncollection of distances that can be quickly and efficiently evaluated in\npractice. We present both theoretical and numerical evidence illustrating the\nimprovements achieved by our method.\n", "versions": [{"version": "v1", "created": "Tue, 11 Mar 2014 17:37:18 GMT"}, {"version": "v2", "created": "Tue, 20 May 2014 21:56:34 GMT"}, {"version": "v3", "created": "Thu, 2 Jun 2016 00:59:28 GMT"}], "update_date": "2016-06-03", "authors_parsed": [["Minsker", "Stanislav", ""], ["Srivastava", "Sanvesh", ""], ["Lin", "Lizhen", ""], ["Dunson", "David B.", ""]]}, {"id": "1403.2800", "submitter": "Peng Qin", "authors": "Peng Qin and Bin Dai and Benxiong Huang and Guan Xu", "title": "Bandwidth-Aware Scheduling with SDN in Hadoop: A New Trend for Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Software Defined Networking (SDN) is a revolutionary network architecture\nthat separates out network control functions from the underlying equipment and\nis an increasingly trend to help enterprises build more manageable data centers\nwhere big data processing emerges as an important part of applications. To\nconcurrently process large-scale data, MapReduce with an open source\nimplementation named Hadoop is proposed. In practical Hadoop systems one kind\nof issue that vitally impacts the overall performance is know as the\nNP-complete minimum make span problem. One main solution is to assign tasks on\ndata local nodes to avoid link occupation since network bandwidth is a scarce\nresource. Many methodologies for enhancing data locality are proposed such as\nthe HDS and state-of-the-art scheduler BAR. However, all of them either ignore\nallocating tasks in a global view or disregard available bandwidth as the basis\nfor scheduling. In this paper we propose a heuristic bandwidth-aware task\nscheduler BASS to combine Hadoop with SDN. It is not only able to guarantee\ndata locality in a global view but also can efficiently assign tasks in an\noptimized way. Both examples and experiments demonstrate that BASS has the best\nperformance in terms of job completion time. To our knowledge, BASS is the\nfirst to exploit talent of SDN for big data processing and we believe it points\nout a new trend for large-scale data processing.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2014 03:31:52 GMT"}], "update_date": "2014-03-13", "authors_parsed": [["Qin", "Peng", ""], ["Dai", "Bin", ""], ["Huang", "Benxiong", ""], ["Xu", "Guan", ""]]}, {"id": "1403.2914", "submitter": "Mayanka Katyal Miss", "authors": "Mayanka Katyal and Atul Mishra", "title": "Application of Selective Algorithm for Effective Resource Provisioning\n  in Cloud Computing Environment", "comments": "10 Pages, International Journal on Cloud Computing: Services and\n  Architecture (IJCCSA) ,Vol. 4, No. 1, February 2014", "journal-ref": "International Journal on Cloud Computing: Services and\n  Architecture (IJCCSA) ,Vol. 4, No. 1, February 2014", "doi": "10.5121/ijccsa.2014.4101", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern day continued demand for resource hungry services and applications in\nIT sector has led to development of Cloud computing. Cloud computing\nenvironment involves high cost infrastructure on one hand and need high scale\ncomputational resources on the other hand. These resources need to be\nprovisioned (allocation and scheduling) to the end users in most efficient\nmanner so that the tremendous capabilities of cloud are utilized effectively\nand efficiently. In this paper we discuss a selective algorithm for allocation\nof cloud resources to end-users on-demand basis. This algorithm is based on\nmin-min and max-min algorithms. These are two conventional task scheduling\nalgorithm. The selective algorithm uses certain heuristics to select between\nthe two algorithms so that overall makespan of tasks on the machines is\nminimized. The tasks are scheduled on machines in either space shared or time\nshared manner. We evaluate our provisioning heuristics using a cloud simulator,\ncalled CloudSim. We also compared our approach to the statistics obtained when\nprovisioning of resources was done in First-Cum-First- Serve(FCFS) manner. The\nexperimental results show that overall makespan of tasks on given set of VMs\nminimizes significantly in different scenarios.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2014 12:50:04 GMT"}], "update_date": "2014-03-18", "authors_parsed": [["Katyal", "Mayanka", ""], ["Mishra", "Atul", ""]]}, {"id": "1403.3005", "submitter": "Christian Lorenz Staudt", "authors": "Christian L. Staudt, Aleksejs Sazonovs, Henning Meyerhenke", "title": "NetworKit: A Tool Suite for Large-scale Complex Network Analysis", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC physics.soc-ph", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We introduce NetworKit, an open-source software package for analyzing the\nstructure of large complex networks. Appropriate algorithmic solutions are\nrequired to handle increasingly common large graph data sets containing up to\nbillions of connections. We describe the methodology applied to develop\nscalable solutions to network analysis problems, including techniques like\nparallelization, heuristics for computationally expensive problems, efficient\ndata structures, and modular software architecture. Our goal for the software\nis to package results of our algorithm engineering efforts and put them into\nthe hands of domain experts. NetworKit is implemented as a hybrid combining the\nkernels written in C++ with a Python front end, enabling integration into the\nPython ecosystem of tested tools for data analysis and scientific computing.\nThe package provides a wide range of functionality (including common and novel\nanalytics algorithms and graph generators) and does so via a convenient\ninterface. In an experimental comparison with related software, NetworKit shows\nthe best performance on a range of typical analysis tasks.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2014 16:22:09 GMT"}, {"version": "v2", "created": "Thu, 17 Apr 2014 15:27:54 GMT"}, {"version": "v3", "created": "Fri, 13 Nov 2015 19:48:12 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Staudt", "Christian L.", ""], ["Sazonovs", "Aleksejs", ""], ["Meyerhenke", "Henning", ""]]}, {"id": "1403.3007", "submitter": "Aubin Jarry", "authors": "Aubin Jarry", "title": "The Four Principles of Geographic Routing", "comments": "This manuscript on geographic routing incoporates team feedback and\n  expanded experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Geographic routing consists in using the position information of nodes to\nassist in the routing process, and has been a widely studied subject in sensor\nnetworks. One of the outstanding challenges facing geographic routing has been\nits applicability. Authors either make some broad assumptions on an idealized\nversion of wireless networks which are often unverifiable, or they use costly\nmethods to planarize the communication graph.\n  The overarching questions that drive us are the following. When, and how\nshould we use geographic routing? Is there a criterion to tell whether a\ncommunication network is fit for geographic routing? When exactly does\ngeographic routing make sense?\n  In this paper we formulate the four principles that define geographic routing\nand explore their topological consequences. Given a localized communication\nnetwork, we then define and compute its geographic eccentricity, which measures\nits fitness for geographic routing. Finally we propose a distributed algorithm\nthat either enables geographic routing on the network or proves that its\ngeographic eccentricity is too high.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2014 16:26:59 GMT"}, {"version": "v2", "created": "Thu, 20 Mar 2014 11:08:46 GMT"}, {"version": "v3", "created": "Mon, 14 Apr 2014 12:50:38 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Jarry", "Aubin", ""]]}, {"id": "1403.3017", "submitter": "Stefano Ferretti Stefano Ferretti", "authors": "Stefano Ferretti", "title": "Searching in Unstructured Overlays Using Local Knowledge and Gossip", "comments": "A revised version of the paper appears in Proc. of the 5th\n  International Workshop on Complex Networks (CompleNet 2014) - Studies in\n  Computational Intelligence Series, Springer-Verlag, Bologna (Italy), March\n  2014", "journal-ref": null, "doi": "10.1007/978-3-319-05401-8_7", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper analyzes a class of dissemination algorithms for the discovery of\ndistributed contents in Peer-to-Peer unstructured overlay networks. The\nalgorithms are a mix of protocols employing local knowledge of peers'\nneighborhood and gossip. By tuning the gossip probability and the depth k of\nthe k-neighborhood of which nodes have information, we obtain different\ndissemination protocols employed in literature over unstructured P2P overlays.\nThe provided analysis and simulation results confirm that, when properly\nconfigured, these schemes represent a viable approach to build effective P2P\nresource discovery in large-scale, dynamic distributed systems.\n", "versions": [{"version": "v1", "created": "Wed, 12 Mar 2014 16:41:54 GMT"}], "update_date": "2014-03-13", "authors_parsed": [["Ferretti", "Stefano", ""]]}, {"id": "1403.3253", "submitter": "Ranjan Kumar", "authors": "Ranjan Kumar and G. Sahoo", "title": "Cloud Computing Simulation Using CloudSim", "comments": "5 pages, 2 figures,\"Published with International Journal of\n  Engineering Trends and Technology (IJETT)\". http://www.ijettjournal.org.\n  published by seventh sense research group", "journal-ref": "International Journal of Engineering Trends and Technology(IJETT),\n  8(2),82-86 February 2014. ISSN:2231-5381", "doi": "10.14445/22315381/IJETT-V8P216", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  As we know that Cloud Computing is a new paradigm in IT. It has many\nadvantages and disadvantages. But in future it will spread in the whole world.\nMany researches are going on for securing the cloud services. Simulation is the\nact of imitating or pretending. It is a situation in which a particular set of\ncondition is created artificially in order to study that could exit in reality.\nWe need only a simple Operating System with some memory to startup our\nComputer. All our resources will be available in the cloud.\n", "versions": [{"version": "v1", "created": "Fri, 21 Feb 2014 16:07:01 GMT"}], "update_date": "2014-03-14", "authors_parsed": [["Kumar", "Ranjan", ""], ["Sahoo", "G.", ""]]}, {"id": "1403.3255", "submitter": "Venugopal K r", "authors": "P Beaulah Soundarabai, Ritesh Sahai, Thriveni J, K R Venugopal, L M\n  Patnaik", "title": "Improved Bully Election Algorithm for Distributed Systems", "comments": "12 pages", "journal-ref": "International Journal of Information Processing, 7(4), 43-54, 2013", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electing a leader is a classical problem in distributed computing system.\nSynchronization between processes often requires one process acting as a\ncoordinator. If an elected leader node fails, the other nodes of the system\nneed to elect another leader without much wasting of time. The bully algorithm\nis a classical approach for electing a leader in a synchronous distributed\ncomputing system, which is used to determine the process with highest priority\nnumber as the coordinator. In this paper, we have discussed the limitations of\nBully algorithm and proposed a simple and efficient method for the Bully\nalgorithm which reduces the number of messages during the election. Our\nanalytical simulation shows that, our proposed algorithm is more efficient than\nthe Bully algorithm with fewer messages passing and fewer stages.\n", "versions": [{"version": "v1", "created": "Fri, 28 Feb 2014 10:10:39 GMT"}], "update_date": "2014-03-14", "authors_parsed": [["Soundarabai", "P Beaulah", ""], ["Sahai", "Ritesh", ""], ["J", "Thriveni", ""], ["Venugopal", "K R", ""], ["Patnaik", "L M", ""]]}, {"id": "1403.3375", "submitter": "Saeed Shahrivari", "authors": "Saeed Shahrivari and Saeed Jalili", "title": "Beyond Batch Processing: Towards Real-Time and Streaming Big Data", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, big data is generated from many sources and there is a huge demand for\nstoring, managing, processing, and querying on big data. The MapReduce model\nand its counterpart open source implementation Hadoop, has proven itself as the\nde facto solution to big data processing. Hadoop is inherently designed for\nbatch and high throughput processing jobs. Although Hadoop is very suitable for\nbatch jobs but there is an increasing demand for non-batch processes on big\ndata like: interactive jobs, real-time queries, and big data streams. Since\nHadoop is not proper for these non-batch workloads, new solutions are proposed\nto these new challenges. In this article, we discuss two categories of these\nsolutions: real-time processing, and stream processing for big data. For each\ncategory, we discuss paradigms, strengths and differences to Hadoop. We also\nintroduce some practical systems and frameworks for each category. Finally,\nsome simple experiments are done to show effectiveness of some solutions\ncompared to available Hadoop-based solutions.\n", "versions": [{"version": "v1", "created": "Thu, 13 Mar 2014 19:22:13 GMT"}, {"version": "v2", "created": "Fri, 1 Aug 2014 07:54:55 GMT"}], "update_date": "2014-08-04", "authors_parsed": [["Shahrivari", "Saeed", ""], ["Jalili", "Saeed", ""]]}, {"id": "1403.3455", "submitter": "Lewis Tseng", "authors": "Lewis Tseng and Nitin Vaidya", "title": "Asynchronous Convex Consensus in the Presence of Crash Faults", "comments": "A version of this work is published in PODC 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a new consensus problem, convex consensus. Similar to\nvector consensus [13, 20, 19], the input at each process is a d-dimensional\nvector of reals (or, equivalently, a point in the d-dimensional Euclidean\nspace). However, for convex consensus, the output at each process is a convex\npolytope contained within the convex hull of the inputs at the fault-free\nprocesses. We explore the convex consensus problem under crash faults with\nincorrect inputs, and present an asynchronous approximate convex consensus\nalgorithm with optimal fault tolerance that reaches consensus on an optimal\noutput polytope. Convex consensus can be used to solve other related problems.\nFor instance, a solution for convex consensus trivially yields a solution for\nvector consensus. More importantly, convex consensus can potentially be used to\nsolve other more interesting problems, such as convex function optimization [5,\n4].\n", "versions": [{"version": "v1", "created": "Thu, 13 Mar 2014 23:01:39 GMT"}, {"version": "v2", "created": "Mon, 31 Aug 2015 17:27:44 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Tseng", "Lewis", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1403.3480", "submitter": "Fan Liang", "authors": "Fan Liang, Chen Feng, Xiaoyi Lu, Zhiwei Xu", "title": "Performance Benefits of DataMPI: A Case Study with BigDataBench", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Apache Hadoop and Spark are gaining prominence in Big Data processing and\nanalytics. Both of them are widely deployed on Internet companies. On the other\nhand, high-performance data analysis requirements are causing academical and\nindustrial communities to adopt state-of-the-art technologies in HPC to solve\nBig Data problems. Recently, we have proposed a key-value pair based\ncommunication library, DataMPI, which is extending MPI to support\nHadoop/Spark-like Big Data Computing jobs. In this paper, we use BigDataBench,\na Big Data benchmark suite, to do comprehensive studies on performance and\nresource utilization characterizations of Hadoop, Spark and DataMPI. From our\nexperiments, we observe that the job execution time of DataMPI has up to 55%\nand 39% speedups compared with those of Hadoop and Spark, respectively. Most of\nthe benefits come from the high-efficiency communication mechanisms in DataMPI.\nWe also notice that the resource (CPU, memory, disk and network I/O)\nutilizations of DataMPI are also more efficient than those of the other two\nframeworks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Mar 2014 03:06:34 GMT"}], "update_date": "2014-03-17", "authors_parsed": [["Liang", "Fan", ""], ["Feng", "Chen", ""], ["Lu", "Xiaoyi", ""], ["Xu", "Zhiwei", ""]]}, {"id": "1403.3649", "submitter": "Alexander Ngenzi", "authors": "Alexander Ngenzi", "title": "Applying mathematical models in cloud computing: A survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As more and more information on individuals and companies are placed in the\ncloud, concerns are beginning to grow about just how safe an environment it is.\nIt is better to prevent security threats before they enter into the systems and\nthere is no way how this can be prevented without knowing where they come from.\nThe issue of resource allocation and revenue maximization is also equally\nimportant especially when it comes to cloud security. This brings about the\nnecessity of different modelling techniques including but not limited; security\nthreat, resource allocation and revenue maximization models. This survey paper\nwill try to analyse security threats and risk mitigation in cloud computing. It\ngives introduction of how viral attack can invade the virtual machines on the\ncloud, discusses the top security threats and countermeasures by providing the\nviral threat modelling in virtual machines and risk mitigation. Resource\nallocation models and revenue maximization techniques are also discussed.\n", "versions": [{"version": "v1", "created": "Fri, 14 Mar 2014 17:23:54 GMT"}], "update_date": "2014-03-17", "authors_parsed": [["Ngenzi", "Alexander", ""]]}, {"id": "1403.3759", "submitter": "Guohui Wang", "authors": "Guohui Wang, Hao Shen, Yang Sun, Joseph R. Cavallaro, Aida Vosoughi\n  and Yuanbin Guo", "title": "Parallel Interleaver Design for a High Throughput HSPA+/LTE\n  Multi-Standard Turbo Decoder", "comments": "14 pages, 15 figures. Accepted for publication by IEEE Transactions\n  on Circuits and Systems I: Regular Papers", "journal-ref": null, "doi": "10.1109/TCSI.2014.2309810", "report-no": null, "categories": "cs.IT cs.AR cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To meet the evolving data rate requirements of emerging wireless\ncommunication technologies, many parallel architectures have been proposed to\nimplement high throughput turbo decoders. However, concurrent memory\nreading/writing in parallel turbo decoding architectures leads to severe memory\nconflict problem, which has become a major bottleneck for high throughput turbo\ndecoders. In this paper, we propose a flexible and efficient VLSI architecture\nto solve the memory conflict problem for highly parallel turbo decoders\ntargeting multi-standard 3G/4G wireless communication systems. To demonstrate\nthe effectiveness of the proposed parallel interleaver architecture, we\nimplemented an HSPA+/LTE/LTE-Advanced multi-standard turbo decoder with a 45nm\nCMOS technology. The implemented turbo decoder consists of 16 Radix-4 MAP\ndecoder cores, and the chip core area is 2.43 mm^2. When clocked at 600 MHz,\nthis turbo decoder can achieve a maximum decoding throughput of 826 Mbps in the\nHSPA+ mode and 1.67 Gbps in the LTE/LTE-Advanced mode, exceeding the peak data\nrate requirements for both standards.\n", "versions": [{"version": "v1", "created": "Sat, 15 Mar 2014 06:23:28 GMT"}, {"version": "v2", "created": "Sun, 23 Mar 2014 06:44:39 GMT"}, {"version": "v3", "created": "Wed, 26 Mar 2014 04:48:54 GMT"}], "update_date": "2014-03-27", "authors_parsed": [["Wang", "Guohui", ""], ["Shen", "Hao", ""], ["Sun", "Yang", ""], ["Cavallaro", "Joseph R.", ""], ["Vosoughi", "Aida", ""], ["Guo", "Yuanbin", ""]]}, {"id": "1403.3881", "submitter": "Seyed Rasoul Etesami", "authors": "Seyed Rasoul Etesami, Tamer Basar", "title": "Complexity of Equilibrium in Diffusion Games on Social Networks", "comments": "A shorter version of this paper has been appeared in 2014 American\n  Control Conference (ACC2014)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.CC cs.DC cs.DM cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider the competitive diffusion game, and study the\nexistence of its pure-strategy Nash equilibrium when defined over general\nundirected networks. We first determine the set of pure-strategy Nash\nequilibria for two special but well-known classes of networks, namely the\nlattice and the hypercube. Characterizing the utility of the players in terms\nof graphical distances of their initial seed placements to other nodes in the\nnetwork, we show that in general networks the decision process on the existence\nof pure-strategy Nash equilibrium is an NP-hard problem. Following this, we\nprovide some necessary conditions for a given profile to be a Nash equilibrium.\nFurthermore, we study players' utilities in the competitive diffusion game over\nErdos-Renyi random graphs and show that as the size of the network grows, the\nutilities of the players are highly concentrated around their expectation, and\nare bounded below by some threshold based on the parameters of the network.\nFinally, we obtain a lower bound for the maximum social welfare of the game\nwith two players, and study sub-modularity of the players' utilities.\n", "versions": [{"version": "v1", "created": "Sun, 16 Mar 2014 04:12:57 GMT"}, {"version": "v2", "created": "Mon, 29 Dec 2014 18:50:10 GMT"}, {"version": "v3", "created": "Sun, 7 Jun 2015 14:49:34 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Etesami", "Seyed Rasoul", ""], ["Basar", "Tamer", ""]]}, {"id": "1403.4075", "submitter": "Alexandre Proutiere", "authors": "Se-Young Yun and Alexandre Proutiere", "title": "Distributed Load Balancing in Heterogeneous Systems", "comments": "Removed due to a technical issue in one of the results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of distributed load balancing in heterogenous\nparallel server systems, where the service rate achieved by a user at a server\ndepends on both the user and the server. Such heterogeneity typically arises in\nwireless networks (e.g., servers may represent frequency bands, and the service\nrate of a user varies across bands). Users select servers in a distributed\nmanner. They initially attach to an arbitrary server. However, at random\ninstants of time, they may probe the load at a new server and migrate there to\nimprove their service rate. We analyze the system dynamics under the natural\nRandom Local Search (RLS) migration scheme, introduced in \\cite{sig10}. Under\nthis scheme, when a user has the opportunity to switch servers, she does it\nonly if this improves her service rate. The dynamics under RLS may be\ninterpreted as those generated by strategic players updating their strategy in\na load balancing game. In closed systems, where the user population is fixed,\nwe show that this game has pure Nash Equilibriums (NEs), and we analyze their\nefficiency. We further prove that when the user population grows large, pure\nNEs get closer to a Proportionally Fair (PF) allocation of users to servers,\nand we characterize the gap between equilibriums and this ideal allocation\ndepending on user population. Under the RLS algorithm, the system converges to\npure NEs: we study the time it takes for the system to reach the PF allocation\nwithin a certain margin. In open systems, where users randomly enter the system\nand leave upon service completion, we establish that the RLS algorithm\nstabilizes the system whenever this it at all possible, i.e., it is\nthroughput-optimal.\n", "versions": [{"version": "v1", "created": "Mon, 17 Mar 2014 11:51:29 GMT"}, {"version": "v2", "created": "Sat, 6 Dec 2014 20:40:27 GMT"}], "update_date": "2014-12-09", "authors_parsed": [["Yun", "Se-Young", ""], ["Proutiere", "Alexandre", ""]]}, {"id": "1403.4099", "submitter": "Dieter Hendricks", "authors": "Dieter Hendricks, Diane Wilcox, Tim Gebbie", "title": "High-speed detection of emergent market clustering via an unsupervised\n  parallel genetic algorithm", "comments": "10 pages, 5 figures, 4 tables, More thorough discussion of\n  implementation", "journal-ref": "S Afr J Sci. 2016;112(1/2), Art. #2014-0340, 9 pages", "doi": "10.17159/sajs.2016/20140340", "report-no": null, "categories": "q-fin.CP cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implement a master-slave parallel genetic algorithm (PGA) with a bespoke\nlog-likelihood fitness function to identify emergent clusters within price\nevolutions. We use graphics processing units (GPUs) to implement a PGA and\nvisualise the results using disjoint minimal spanning trees (MSTs). We\ndemonstrate that our GPU PGA, implemented on a commercially available general\npurpose GPU, is able to recover stock clusters in sub-second speed, based on a\nsubset of stocks in the South African market. This represents a pragmatic\nchoice for low-cost, scalable parallel computing and is significantly faster\nthan a prototype serial implementation in an optimised C-based\nfourth-generation programming language, although the results are not directly\ncomparable due to compiler differences. Combined with fast online intraday\ncorrelation matrix estimation from high frequency data for cluster\nidentification, the proposed implementation offers cost-effective,\nnear-real-time risk assessment for financial practitioners.\n", "versions": [{"version": "v1", "created": "Mon, 17 Mar 2014 14:02:33 GMT"}, {"version": "v2", "created": "Fri, 25 Jul 2014 17:09:24 GMT"}, {"version": "v3", "created": "Fri, 3 Oct 2014 08:24:40 GMT"}, {"version": "v4", "created": "Sun, 2 Aug 2015 20:25:09 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Hendricks", "Dieter", ""], ["Wilcox", "Diane", ""], ["Gebbie", "Tim", ""]]}, {"id": "1403.4238", "submitter": "Guohui Wang", "authors": "Guohui Wang, Yingen Xiong, Jay Yun, and Joseph R. Cavallaro", "title": "Computer Vision Accelerators for Mobile Systems based on OpenCL GPGPU\n  Co-Processing", "comments": "15 pages, 15 figures. Submitted and accepted for publication in\n  Journal of Signal Processing Systems, 2014", "journal-ref": null, "doi": "10.1007/s11265-014-0878-z", "report-no": null, "categories": "cs.DC cs.CV cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present an OpenCL-based heterogeneous implementation of a\ncomputer vision algorithm -- image inpainting-based object removal algorithm --\non mobile devices. To take advantage of the computation power of the mobile\nprocessor, the algorithm workflow is partitioned between the CPU and the GPU\nbased on the profiling results on mobile devices, so that the\ncomputationally-intensive kernels are accelerated by the mobile GPGPU\n(general-purpose computing using graphics processing units). By exploring the\nimplementation trade-offs and utilizing the proposed optimization strategies at\ndifferent levels including algorithm optimization, parallelism optimization,\nand memory access optimization, we significantly speed up the algorithm with\nthe CPU-GPU heterogeneous implementation, while preserving the quality of the\noutput images. Experimental results show that heterogeneous computing based on\nGPGPU co-processing can significantly speed up the computer vision algorithms\nand makes them practical on real-world mobile devices.\n", "versions": [{"version": "v1", "created": "Mon, 17 Mar 2014 18:26:41 GMT"}], "update_date": "2014-03-19", "authors_parsed": [["Wang", "Guohui", ""], ["Xiong", "Yingen", ""], ["Yun", "Jay", ""], ["Cavallaro", "Joseph R.", ""]]}, {"id": "1403.4321", "submitter": "Naftaly Minsky", "authors": "Naftaly Minsky", "title": "Dependable Management of Untrusted Distributed Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The conventional approach to the online management of distributed\nsystems---represented by such standards as SNMP for network management, and\nWSDM for systems based on service oriented computing (SOC)---relies on the\ncomponents of the managed system to cooperate in the management process, by\nproviding the managers with the means to monitor their state and activities,\nand to control their behavior. Unfortunately, the trust thus placed in the\ncooperation of the managed components is unwarranted for many types of\nsystems---such as systems based on SOA---making the conventional management of\nsuch systems unreliable and insecure.\n  This paper introduces a radically new approach to the management of\ndistributed systems, called governance-based management (GBM), which is based\non a middleware that can govern the exchange of messages between system\ncomponents. GBM has a substantial ability to manage distributed systems, in a\nreliable and secure manner, even without any trustworthy cooperation of the\nmanaged components.\n  And it can fully incorporate the conventional management techniques wherever\nsuch cooperation can be trusted. GBM also supports a reflexive mode of\nmanagement, which manages the management process itself, making it safer.\nHowever, GBM is still a work in progress, as it raises several open problems\nthat needs to be addressed before this management technique can be put to\npractice.\n", "versions": [{"version": "v1", "created": "Tue, 18 Mar 2014 02:35:30 GMT"}], "update_date": "2014-03-19", "authors_parsed": [["Minsky", "Naftaly", ""]]}, {"id": "1403.4813", "submitter": "Xianjin Fu", "authors": "Xianjin Fu, Zhenbang Chen, Yufeng Zhang, Chun Huang, Wei Dong and Ji\n  Wang", "title": "MPISE: Symbolic Execution of MPI Programs", "comments": "25pages, extended version (unpublished!) of paper submitted to ictac\n  2014. Version 0.2, we carry out experiments using release llvm istead of a\n  debug version one, which makes mpise 10 times faster", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Message Passing Interfaces (MPI) plays an important role in parallel\ncomputing. Many parallel applications are implemented as MPI programs. The\nexisting methods of bug detection for MPI programs have the shortage of\nproviding both input and non-determinism coverage, leading to missed bugs. In\nthis paper, we employ symbolic execution to ensure the input coverage, and\npropose an on-the-fly schedule algorithm to reduce the interleaving\nexplorations for non-determinism coverage, while ensuring the soundness and\ncompleteness. We have implemented our approach as a tool, called MPISE, which\ncan automatically detect the deadlock and runtime bugs in MPI programs. The\nresults of the experiments on benchmark programs and real world MPI programs\nindicate that MPISE finds bugs effectively and efficiently. In addition, our\ntool also provides diagnostic information and replay mechanism to help\nunderstanding bugs.\n", "versions": [{"version": "v1", "created": "Wed, 19 Mar 2014 14:23:24 GMT"}, {"version": "v2", "created": "Tue, 8 Apr 2014 11:49:01 GMT"}, {"version": "v3", "created": "Mon, 15 Sep 2014 08:21:28 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Fu", "Xianjin", ""], ["Chen", "Zhenbang", ""], ["Zhang", "Yufeng", ""], ["Huang", "Chun", ""], ["Dong", "Wei", ""], ["Wang", "Ji", ""]]}, {"id": "1403.4988", "submitter": "Naftaly Minsky", "authors": "Naftaly Minsky", "title": "Bracing Heterogeneous Distributed Systems via Built-in Frameworks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a novel architecture of distributed systems--called\nframed distributed system, or FDS--that braces a given system via a built-in\nvirtual framework that controls the flow of messages between system components\nand between them and their environment, while being oblivious of the code of\nthe communicating components. This control is carried out in a decentralized,\nand thus scalable, manner. The FDS architecture is expected to have a\nsignificant impact on the dependability and security of distributed systems,\nand on the whole life cycle of such systems. Although this architecture has\nbeen designed specifically for SOA-like heterogeneous and open systems--whose\ncomponents may be written in different languages, may run on different\nplatforms, and may be designed, constructed, and even maintained under\ndifferent administrative domains--it should be useful for distributed systems\nin general.\n", "versions": [{"version": "v1", "created": "Wed, 19 Mar 2014 21:39:53 GMT"}], "update_date": "2014-03-21", "authors_parsed": [["Minsky", "Naftaly", ""]]}, {"id": "1403.5007", "submitter": "Guanfeng Liang", "authors": "Guanfeng Liang and Ulas C. Kozat", "title": "On Throughput-Delay Optimal Access to Storage Clouds via Load Adaptive\n  Coding and Chunking", "comments": "arXiv admin note: substantial text overlap with arXiv:1307.8083", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent literature including our past work provide analysis and solutions for\nusing (i) erasure coding, (ii) parallelism, or (iii) variable slicing/chunking\n(i.e., dividing an object of a specific size into a variable number of smaller\nchunks) in speeding the I/O performance of storage clouds. However, a\ncomprehensive approach that considers all three dimensions together to achieve\nthe best throughput-delay trade-off curve had been lacking. This paper presents\nthe first set of solutions that can pick the best combination of coding rate\nand object chunking/slicing options as the load dynamically changes. Our\nspecific contributions are as follows: (1) We establish via measurement that\ncombining variable coding rate and chunking is mostly feasible over a popular\npublic cloud. (2) We relate the delay optimal values for chunking level and\ncode rate to the queue backlogs via an approximate queueing analysis. (3) Based\non this analysis, we propose TOFEC that adapts the chunking level and coding\nrate against the queue backlogs. Our trace-driven simulation results show that\nTOFEC's adaptation mechanism converges to an appropriate code that provides the\noptimal throughput-delay trade-off without reducing system capacity. Compared\nto a non-adaptive strategy optimized for throughput, TOFEC delivers $2.5\\times$\nlower latency under light workloads; compared to a non-adaptive strategy\noptimized for latency, TOFEC can scale to support over $3\\times$ as many\nrequests. (4) We propose a simpler greedy solution that performs on a par with\nTOFEC in average delay performance, but exhibits significantly more performance\nvariations.\n", "versions": [{"version": "v1", "created": "Thu, 20 Mar 2014 00:23:05 GMT"}], "update_date": "2014-03-21", "authors_parsed": [["Liang", "Guanfeng", ""], ["Kozat", "Ulas C.", ""]]}, {"id": "1403.5012", "submitter": "Yong Wang", "authors": "Kai Li, Yong Wang, Meilin Liu", "title": "A Non-Cooperative Game Model for Reliability-Based Task Scheduling in\n  Cloud Computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is a newly emerging distributed system which is evolved from\nGrid computing. Task scheduling is the core research of cloud computing which\nstudies how to allocate the tasks among the physical nodes, so that the tasks\ncan get a balanced allocation or each task's execution cost decreases to the\nminimum, or the overall system performance is optimal. Unlike task scheduling\nbased on time or cost before, aiming at the special reliability requirements in\ncloud computing, we propose a non-cooperative game model for reliability-based\ntask scheduling approach. This model takes the steady-state availability that\ncomputing nodes provide as the target, takes the task slicing strategy of the\nschedulers as the game strategy, then finds the Nash equilibrium solution. And\nalso, we design a task scheduling algorithm based on this model. The\nexperiments can be seen that our task scheduling algorithm is better than the\nso-called balanced scheduling algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 20 Mar 2014 00:48:42 GMT"}, {"version": "v2", "created": "Fri, 18 Apr 2014 03:36:23 GMT"}], "update_date": "2014-04-21", "authors_parsed": [["Li", "Kai", ""], ["Wang", "Yong", ""], ["Liu", "Meilin", ""]]}, {"id": "1403.5128", "submitter": "Parul Pandey ms", "authors": "Parul Pandey, Mahshwari Tripathi", "title": "A Novel Quorum Protocol", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the traditional mechanisms used in distributed systems for maintaining\nthe consistency of replicated data is voting.\n  A problem involved in voting mechanisms is the size of the Quorums needed on\neach access to the data. In this paper, we present a novel and efficient\ndistributed algorithm for managing replicated data. We impose a logical wheel\nstructure on the set of copies of an object. The protocol ensures minimum read\nquorum size of one, by reading one copy of an object while guaranteeing\nfault-tolerance of write operations.Wheel structure has a wider application\narea as it can be imposed in a network with any number of nodes.\n", "versions": [{"version": "v1", "created": "Thu, 20 Mar 2014 13:20:07 GMT"}], "update_date": "2014-03-21", "authors_parsed": [["Pandey", "Parul", ""], ["Tripathi", "Mahshwari", ""]]}, {"id": "1403.5392", "submitter": "Gita Shah", "authors": "Gita Shah, Annappa and K. C. Shet", "title": "Design Architecture-Based on Web Server and Application Cluster in Cloud\n  Environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud has been a computational and storage solution for many data centric\norganizations. The problem today those organizations are facing from the cloud\nis in data searching in an efficient manner. A framework is required to\ndistribute the work of searching and fetching from thousands of computers. The\ndata in HDFS is scattered and needs lots of time to retrieve. The major idea is\nto design a web server in the map phase using the jetty web server which will\ngive a fast and efficient way of searching data in MapReduce paradigm. For real\ntime processing on Hadoop, a searchable mechanism is implemented in HDFS by\ncreating a multilevel index in web server with multi-level index keys. The web\nserver uses to handle traffic throughput. By web clustering technology we can\nimprove the application performance. To keep the work down, the load balancer\nshould automatically be able to distribute load to the newly added nodes in the\nserver.\n", "versions": [{"version": "v1", "created": "Fri, 21 Mar 2014 08:02:57 GMT"}], "update_date": "2014-03-24", "authors_parsed": [["Shah", "Gita", ""], ["Annappa", "", ""], ["Shet", "K. C.", ""]]}, {"id": "1403.5524", "submitter": "Brendan McLaughlin Dr", "authors": "Brendan M. McLaughlin and Connor P. Ballance", "title": "Petascale computations for Large-scale Atomic and Molecular collisions", "comments": "14 pages, 5 figures, 3 tables, Chapter in: Workshop on Sustained\n  Simulated Performance 2013, Published by Springer, 2014, edited by Michael\n  Resch, Yevgeniya Kovalenko, Eric Focht, Wolfgang Bez and Hiroaki Kobaysahi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC physics.atom-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Petaflop architectures are currently being utilized efficiently to perform\nlarge scale computations in Atomic, Molecular and Optical Collisions. We solve\nthe Schroedinger or Dirac equation for the appropriate collision problem using\nthe R-matrix or R-matrix with pseudo-states approach. We briefly outline the\nparallel methodology used and implemented for the current suite of Breit-Pauli\nand DARC codes. Various examples are shown of our theoretical results compared\nwith those obtained from Synchrotron Radiation facilities and from Satellite\nobservations. We also indicate future directions and implementation of the\nR-matrix codes on emerging GPU architectures.\n", "versions": [{"version": "v1", "created": "Fri, 21 Mar 2014 17:38:25 GMT"}, {"version": "v2", "created": "Fri, 15 Aug 2014 09:40:57 GMT"}], "update_date": "2014-08-18", "authors_parsed": [["McLaughlin", "Brendan M.", ""], ["Ballance", "Connor P.", ""]]}, {"id": "1403.5605", "submitter": "Krishnan Gopalakrishnan", "authors": "Yuan He, Krishnan Gopalakrishnan and Eli Gafni", "title": "Group Mutual Exclusion in Linear Time and Space", "comments": "A total of 21 pages including 5 figures and 3 appendices. The bounded\n  shared registers algorithm in the old version has a subtle error (that has no\n  easy fix) necessitating replacement. A correct, but fundamentally different,\n  bounded shared registers algorithm, which has the same properties claimed in\n  the old version is presented in this new version. Also, this version has an\n  additional author", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two algorithms for the Group Mutual Exclusion (GME) Problem that\nsatisfy the properties of Mutual Exclusion, Starvation Freedom, Bounded Exit,\nConcurrent Entry and First Come First Served. Both our algorithms use only\nsimple read and write instructions, have O(N) Shared Space complexity and O(N)\nRemote Memory Reference (RMR) complexity in the Cache Coherency (CC) model. Our\nfirst algorithm is developed by generalizing the well-known Lamport's Bakery\nAlgorithm for the classical mutual exclusion problem, while preserving its\nsimplicity and elegance. However, it uses unbounded shared registers. Our\nsecond algorithm uses only bounded registers and is developed by generalizing\nTaubenfeld's Black and White Bakery Algorithm to solve the classical mutual\nexclusion problem using only bounded shared registers. We show that contrary to\ncommon perception our algorithms are the first to achieve these properties with\nthese combination of complexities.\n", "versions": [{"version": "v1", "created": "Sat, 22 Mar 2014 03:07:20 GMT"}, {"version": "v2", "created": "Thu, 28 May 2015 03:04:39 GMT"}], "update_date": "2015-05-29", "authors_parsed": [["He", "Yuan", ""], ["Gopalakrishnan", "Krishnan", ""], ["Gafni", "Eli", ""]]}, {"id": "1403.5627", "submitter": "Shubhanjali  SHARMA", "authors": "Shubhanjali Sharma, Garima Gupta, P.R.Laxmi", "title": "A Survey on Cloud Security Issues and Techniques", "comments": "8 pages, 5 figures, SCNDS Ajmer", "journal-ref": "International Journal on Computational Sciences & Applications\n  (IJCSA) Vol.4, No.1, February 2014", "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, cloud computing is an emerging way of computing in computer science.\nCloud computing is a set of resources and services that are offered by the\nnetwork or internet. Cloud computing extends various computing techniques like\ngrid computing, distributed computing. Today cloud computing is used in both\nindustrial field and academic field. Cloud facilitates its users by providing\nvirtual resources via internet. As the field of cloud computing is spreading\nthe new techniques are developing. This increase in cloud computing environment\nalso increases security challenges for cloud developers. Users of cloud save\ntheir data in the cloud hence the lack of security in cloud can lose the users\ntrust. In this paper we will discuss some of the cloud security issues in\nvarious aspects like multi-tenancy, elasticity, availability etc. The paper\nalso discuss existing security techniques and approaches for a secure cloud.\nThis paper will enable researchers and professionals to know about different\nsecurity threats and models and tools proposed.\n", "versions": [{"version": "v1", "created": "Sat, 22 Mar 2014 08:49:30 GMT"}], "update_date": "2014-03-25", "authors_parsed": [["Sharma", "Shubhanjali", ""], ["Gupta", "Garima", ""], ["Laxmi", "P. R.", ""]]}, {"id": "1403.5791", "submitter": "Neil Lutz", "authors": "Aaron D. Jaggard, Neil Lutz, Michael Schapira, Rebecca N. Wright", "title": "Self-stabilizing uncoupled dynamics", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dynamics in a distributed system are self-stabilizing if they are guaranteed\nto reach a stable state regardless of how the system is initialized. Game\ndynamics are uncoupled if each player's behavior is independent of the other\nplayers' preferences. Recognizing an equilibrium in this setting is a\ndistributed computational task. Self-stabilizing uncoupled dynamics, then, have\nboth resilience to arbitrary initial states and distribution of knowledge. We\nstudy these dynamics by analyzing their behavior in a bounded-recall\nsynchronous environment. We determine, for every \"size\" of game, the minimum\nnumber of periods of play that stochastic (randomized) players must recall in\norder for uncoupled dynamics to be self-stabilizing. We also do this for the\nspecial case when the game is guaranteed to have unique best replies. For\ndeterministic players, we demonstrate two self-stabilizing uncoupled protocols.\nOne applies to all games and uses three steps of recall. The other uses two\nsteps of recall and applies to games where each player has at least four\navailable actions. For uncoupled deterministic players, we prove that a single\nstep of recall is insufficient to achieve self-stabilization, regardless of the\nnumber of available actions.\n", "versions": [{"version": "v1", "created": "Sun, 23 Mar 2014 19:24:53 GMT"}, {"version": "v2", "created": "Tue, 6 May 2014 01:50:50 GMT"}], "update_date": "2014-05-07", "authors_parsed": [["Jaggard", "Aaron D.", ""], ["Lutz", "Neil", ""], ["Schapira", "Michael", ""], ["Wright", "Rebecca N.", ""]]}, {"id": "1403.5805", "submitter": "Athanasios Margaris Dr", "authors": "Athanasios Margaris and Stauros Souravlas and Manos Roumeliotis", "title": "Parallel Implementations of the Jacobi Linear Algebraic Systems Solve", "comments": "Balkan Conference on Informatics (BCI2007), Sofia, Bulgaria", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The objective of this research is to construct parallel implementations of\nthe Jacobi algorithm used for the solution of linear algebraic systems, to\nmeasure their speedup with respect to the serial case and to compare each\nother, regarding their efficiency. The programming paradigm used in this\nimplementation is the message passing model, while, the used MPI implementation\nis the MPICH implementation of the Argonne National Laboratory.\n", "versions": [{"version": "v1", "created": "Sun, 23 Mar 2014 21:41:37 GMT"}], "update_date": "2014-03-27", "authors_parsed": [["Margaris", "Athanasios", ""], ["Souravlas", "Stauros", ""], ["Roumeliotis", "Manos", ""]]}, {"id": "1403.6270", "submitter": "Alessio Guerrieri", "authors": "Alessio Guerrieri, Alberto Montresor", "title": "Distributed Edge Partitioning for Graph Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The availability of larger and larger graph datasets, growing exponentially\nover the years, has created several new algorithmic challenges to be addressed.\nSequential approaches have become unfeasible, while interest on parallel and\ndistributed algorithms has greatly increased.\n  Appropriately partitioning the graph as a preprocessing step can improve the\ndegree of parallelism of its analysis. A number of heuristic algorithms have\nbeen developed to solve this problem, but many of them subdivide the graph on\nits vertex set, thus obtaining a vertex-partitioned graph.\n  Aim of this paper is to explore a completely different approach based on edge\npartitioning, in which edges, rather than vertices, are partitioned into\ndisjoint subsets. Contribution of this paper is twofold: first, we introduce a\ngraph processing framework based on edge partitioning, that is flexible enough\nto be applied to several different graph problems. Second, we show the\nfeasibility of these ideas by presenting a distributed edge partitioning\nalgorithm called d-fep.\n  Our framework is thoroughly evaluated, using both simulations and an Hadoop\nimplementation running on the Amazon EC2 cloud. The experiments show that d-fep\nis efficient, scalable and obtains consistently good partitions. The resulting\nedge-partitioned graph can be exploited to obtain more efficient\nimplementations of graph analysis algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 25 Mar 2014 09:38:12 GMT"}], "update_date": "2014-03-26", "authors_parsed": [["Guerrieri", "Alessio", ""], ["Montresor", "Alberto", ""]]}, {"id": "1403.6918", "submitter": "Mayanka Katyal Miss", "authors": "Mayanka Katyal and Atul Mishra", "title": "A Comparative Study of Load Balancing Algorithms in Cloud Computing\n  Environment", "comments": "14 pages,International Journal of Distributed and Cloud\n  Computing,PublishingIndia.com,\n  http://www.publishingindia.com/IJDCC/68/a-comparative-study-of-load-balancing-algorithms-in-cloud-computing-environment/277/2041/", "journal-ref": "International Journal of Distributed and Cloud Computing, Volume 1\n  Issue 2 December 2013", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Computing is a new trend emerging in IT environment with huge\nrequirements of infrastructure and resources. Load Balancing is an important\naspect of cloud computing environment. Efficient load balancing scheme ensures\nefficient resource utilization by provisioning of resources to cloud users on\ndemand basis in pay as you say manner. Load Balancing may even support\nprioritizing users by applying appropriate scheduling criteria. This paper\npresents various load balancing schemes in different cloud environment based on\nrequirements specified in Service Level Agreement (SLA).\n", "versions": [{"version": "v1", "created": "Thu, 27 Mar 2014 05:07:28 GMT"}], "update_date": "2014-03-28", "authors_parsed": [["Katyal", "Mayanka", ""], ["Mishra", "Atul", ""]]}, {"id": "1403.7294", "submitter": "Roshan Ragel", "authors": "D. Herath, C. Lakmali, and R. G. Ragel", "title": "Accelerating string matching for bio-computing applications on\n  multi-core CPUs", "comments": null, "journal-ref": "Industrial and Information Systems (ICIIS), 2012 7th IEEE\n  International Conference on, 6-9 Aug. 2012, pp. 1-6, Chennai", "doi": "10.1109/ICIInfS.2012.6304784", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Huge amount of data in the form of strings are being handled in bio-computing\napplications and searching algorithms are quite frequently used in them. Many\nmethods utilizing on both software and hardware are being proposed to\naccelerate processing of such data. The typical hardware-based acceleration\ntechniques either require special hardware such as general purpose graphics\nprocessing units (GPGPUs) or need building a new hardware such as an FPGA based\ndesign. On the other hard, software-based acceleration techniques are easier\nsince they only require some changes in the software code or the software\narchitecture. Typical software-based techniques make use of computers connected\nover a network, also known as a network grid to accelerate the processing. In\nthis paper, we test the hypothesis that multi-core architectures should provide\nbetter performance in this kind of computation, but still it would depend on\nthe algorithm selected as well as the programming model being utilized. We\npresent the acceleration of a string-searching algorithm on a multi-core CPU\nvia a POSIX thread based implementation. Our implementation on an 8-core\nprocessor (that supports 16-threads) resulted in 9x throughput improvement\ncompared to a single thread implementation.\n", "versions": [{"version": "v1", "created": "Fri, 28 Mar 2014 07:44:23 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Herath", "D.", ""], ["Lakmali", "C.", ""], ["Ragel", "R. G.", ""]]}, {"id": "1403.7295", "submitter": "Roshan Ragel", "authors": "A. Barnes, R. Fernando, K. Mettananda, and R. G. Ragel", "title": "Improving the throughput of the AES algorithm with multicore processors", "comments": null, "journal-ref": "Industrial and Information Systems (ICIIS), 2012 7th IEEE\n  International Conference on, 6-9 Aug. 2012, Chennai", "doi": "10.1109/ICIInfS.2012.6304791", "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  AES, Advanced Encryption Standard, can be considered the most widely used\nmodern symmetric key encryption standard. To encrypt/decrypt a file using the\nAES algorithm, the file must undergo a set of complex computational steps.\nTherefore a software implementation of AES algorithm would be slow and consume\nlarge amount of time to complete. The immense increase of both stored and\ntransferred data in the recent years had made this problem even more daunting\nwhen the need to encrypt/decrypt such data arises. As a solution to this\nproblem, in this paper, we present an extensive study of enhancing the\nthroughput of AES encryption algorithm by utilizing the state of the art\nmulticore architectures. We take a sequential program that implements the AES\nalgorithm and convert the same to run on multicore architectures with minimum\neffort. We implement two different parallel programmes, one with the fork\nsystem call in Linux and the other with the pthreads, the POSIX standard for\nthreads. Later, we ran both the versions of the parallel programs on different\nmulticore architectures and compared and analysed the throughputs between the\nimplementations and among different architectures. The pthreads implementation\noutperformed in all the experiments we conducted and the best throughput\nobtained is around 7Gbps on a 32-core processor (the largest number of cores we\nhad) with the pthreads implementation.\n", "versions": [{"version": "v1", "created": "Fri, 28 Mar 2014 07:47:11 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Barnes", "A.", ""], ["Fernando", "R.", ""], ["Mettananda", "K.", ""], ["Ragel", "R. G.", ""]]}, {"id": "1403.7394", "submitter": "Rana Haber", "authors": "Dillon Mark Rose, Jean Michel Rouly, Rana Haber, Nenad Mijatovic,\n  Adrian M. Peter", "title": "Parallel Hierarchical Affinity Propagation with MapReduce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accelerated evolution and explosion of the Internet and social media is\ngenerating voluminous quantities of data (on zettabyte scales). Paramount\namongst the desires to manipulate and extract actionable intelligence from vast\nbig data volumes is the need for scalable, performance-conscious analytics\nalgorithms. To directly address this need, we propose a novel MapReduce\nimplementation of the exemplar-based clustering algorithm known as Affinity\nPropagation. Our parallelization strategy extends to the multilevel\nHierarchical Affinity Propagation algorithm and enables tiered aggregation of\nunstructured data with minimal free parameters, in principle requiring only a\nsimilarity measure between data points. We detail the linear run-time\ncomplexity of our approach, overcoming the limiting quadratic complexity of the\noriginal algorithm. Experimental validation of our clustering methodology on a\nvariety of synthetic and real data sets (e.g. images and point data)\ndemonstrates our competitiveness against other state-of-the-art MapReduce\nclustering techniques.\n", "versions": [{"version": "v1", "created": "Fri, 28 Mar 2014 14:37:29 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Rose", "Dillon Mark", ""], ["Rouly", "Jean Michel", ""], ["Haber", "Rana", ""], ["Mijatovic", "Nenad", ""], ["Peter", "Adrian M.", ""]]}, {"id": "1403.7429", "submitter": "Aivar Sootla", "authors": "Wei Pan, Aivar Sootla and Guy-Bart Stan", "title": "Distributed Reconstruction of Nonlinear Networks: An ADMM Approach", "comments": "To appear in the Preprints of 19th IFAC World Congress 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a distributed algorithm for the reconstruction of\nlarge-scale nonlinear networks. In particular, we focus on the identification\nfrom time-series data of the nonlinear functional forms and associated\nparameters of large-scale nonlinear networks. Recently, a nonlinear network\nreconstruction problem was formulated as a nonconvex optimisation problem based\non the combination of a marginal likelihood maximisation procedure with\nsparsity inducing priors. Using a convex-concave procedure (CCCP), an iterative\nreweighted lasso algorithm was derived to solve the initial nonconvex\noptimisation problem. By exploiting the structure of the objective function of\nthis reweighted lasso algorithm, a distributed algorithm can be designed. To\nthis end, we apply the alternating direction method of multipliers (ADMM) to\ndecompose the original problem into several subproblems. To illustrate the\neffectiveness of the proposed methods, we use our approach to identify a\nnetwork of interconnected Kuramoto oscillators with different network sizes\n(500~100,000 nodes).\n", "versions": [{"version": "v1", "created": "Fri, 28 Mar 2014 16:11:57 GMT"}], "update_date": "2014-03-31", "authors_parsed": [["Pan", "Wei", ""], ["Sootla", "Aivar", ""], ["Stan", "Guy-Bart", ""]]}, {"id": "1403.7579", "submitter": "EPTCS", "authors": "Benedikt L\\\"owe, Glynn Winskel", "title": "Proceedings 8th International Workshop on Developments in Computational\n  Models", "comments": null, "journal-ref": "EPTCS 143, 2014", "doi": "10.4204/EPTCS.143", "report-no": null, "categories": "cs.LO cs.DC cs.DS cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of the workshop series Developments in Computational Models (DCM) is\nto bring together researchers who are currently developing new computational\nmodels or new features for traditional computational models, in order to foster\ntheir interaction, to provide a forum for presenting new ideas and work in\nprogress, and to enable newcomers to learn about current activities in this\narea. The eighth workshop in the series, DCM 2012, was part of the celebrations\nof the Turing Centenary and was held as a satellite event of the Turing\ncentenary conference Computability in Europe 2012 (CiE 2012) in Cambridge. It\ntook place at Corpus Christi College in Cambridge on Sunday, 17 June 2013.\n  This electronic proceedings volume includes one of the keynote papers as well\nas revised versions of papers accepted for presentation by the programme\ncommittee.\n", "versions": [{"version": "v1", "created": "Sat, 29 Mar 2014 01:54:28 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["L\u00f6we", "Benedikt", ""], ["Winskel", "Glynn", ""]]}, {"id": "1403.7791", "submitter": "Camille Coti", "authors": "Camille Coti", "title": "POSH: Paris OpenSHMEM: A High-Performance OpenSHMEM Implementation for\n  Shared Memory Systems", "comments": "This is an extended version (featuring the full proofs) of a paper\n  accepted at ICCS'14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present the design and implementation of POSH, an\nOpen-Source implementation of the OpenSHMEM standard. We present a model for\nits communications, and prove some properties on the memory model defined in\nthe OpenSHMEM specification. We present some performance measurements of the\ncommunication library featured by POSH and compare them with an existing\none-sided communication library. POSH can be downloaded from\n\\url{http://www.lipn.fr/~coti/POSH}. % 9 - 67\n", "versions": [{"version": "v1", "created": "Sun, 30 Mar 2014 17:43:21 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["Coti", "Camille", ""]]}, {"id": "1403.8006", "submitter": "Ashkan Tousimojarad Mr", "authors": "Ashkan Tousimojarad and Wim Vanderbauwhede", "title": "Cache-aware Parallel Programming for Manycore Processors", "comments": "This work was presented at the international symposium on Highly-\n  Efficient Accelerators and Reconfigurable Technologies (HEART2013),\n  Edinburgh, Scotland, June 13-14, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With rapidly evolving technology, multicore and manycore processors have\nemerged as promising architectures to benefit from increasing transistor\nnumbers. The transition towards these parallel architectures makes today an\nexciting time to investigate challenges in parallel computing. The TILEPro64 is\na manycore accelerator, composed of 64 tiles interconnected via multiple 8x8\nmesh networks. It contains per-tile caches and supports cache-coherent shared\nmemory by default. In this paper we present a programming technique to take\nadvantages of distributed caching facilities in manycore processors. However,\nunlike other work in this area, our approach does not use architecture-specific\nlibraries. Instead, we provide the programmer with a novel technique on how to\nprogram future Non-Uniform Cache Architecture (NUCA) manycore systems, bearing\nin mind their caching organisation. We show that our localised programming\napproach can result in a significant improvement of the parallelisation\nefficiency (speed-up).\n", "versions": [{"version": "v1", "created": "Mon, 31 Mar 2014 14:13:13 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["Tousimojarad", "Ashkan", ""], ["Vanderbauwhede", "Wim", ""]]}, {"id": "1403.8020", "submitter": "Ashkan Tousimojarad Mr", "authors": "Ashkan Tousimojarad and Wim Vanderbauwhede", "title": "An Efficient Thread Mapping Strategy for Multiprogramming on Manycore\n  Processors", "comments": "ParCo Conference, Munich, Germany, 2013", "journal-ref": "Parallel Computing: Accelerating Computational Science and\n  Engineering (CSE) 25 (2014) 63-71", "doi": "10.3233/978-1-61499-381-0-63", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of multicore and manycore processors is set to change the\nparallel computing world. Applications are shifting towards increased\nparallelism in order to utilise these architectures efficiently. This leads to\na situation where every application creates its desirable number of threads,\nbased on its parallel nature and the system resources allowance. Task\nscheduling in such a multithreaded multiprogramming environment is a\nsignificant challenge. In task scheduling, not only the order of the execution,\nbut also the mapping of threads to the execution resources is of a great\nimportance. In this paper we state and discuss some fundamental rules based on\nresults obtained from selected applications of the BOTS benchmarks on the\n64-core TILEPro64 processor. We demonstrate how previously efficient mapping\npolicies such as those of the SMP Linux scheduler become inefficient when the\nnumber of threads and cores grows. We propose a novel, low-overhead technique,\na heuristic based on the amount of time spent by each CPU doing some useful\nwork, to fairly distribute the workloads amongst the cores in a\nmultiprogramming environment. Our novel approach could be implemented as a\npragma similar to those in the new task-based OpenMP versions, or can be\nincorporated as a distributed thread mapping mechanism in future manycore\nprogramming frameworks. We show that our thread mapping scheme can outperform\nthe native GNU/Linux thread scheduler in both single-programming and\nmultiprogramming environments.\n", "versions": [{"version": "v1", "created": "Mon, 31 Mar 2014 14:40:02 GMT"}], "update_date": "2014-04-01", "authors_parsed": [["Tousimojarad", "Ashkan", ""], ["Vanderbauwhede", "Wim", ""]]}]