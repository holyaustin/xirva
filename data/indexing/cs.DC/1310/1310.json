[{"id": "1310.0346", "submitter": "Matthias Rost", "authors": "Matthias Rost, Stefan Schmid", "title": "The Constrained Virtual Steiner Arborescence Problem: Formal Definition,\n  Single-Commodity Integer Programming Formulation and Computational Evaluation", "comments": "A conference version of this Paper will appear in the proceedings of\n  OPODIS 2013, (c) Springer LNCS. It will be available at link.springer.com", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the Internet becomes more virtualized and software-defined, new\nfunctionality is introduced in the network core: the distributed resources\navailable in ISP central offices, universal nodes, or datacenter middleboxes\ncan be used to process (e.g., filter, aggregate or duplicate) data. Based on\nthis new networking paradigm, we formulate the Constrained Virtual Steiner\nArborescence Problem (CVSAP) which asks for optimal locations to perform\nIn-network processing, in order to jointly minimize processing costs and\nnetwork traffic while respecting link and node capacities.\n  We prove that CVSAP cannot be approximated (unless P = NP), and accordingly,\ndevelop the exact algorithm VirtuCast to compute (near) optimal solutions.\nVirtuCast consists of: (1) a compact single-commodity flow Integer Programming\n(IP) formulation; (2) a flow decomposition algorithm to reconstruct individual\nroutes from the IP solution. The compactness of the IP formulation allows for\ncomputing lower bounds even on large instances quickly, speeding up the\nalgorithm. We rigorously prove VirtuCast's correctness.\n  To complement our theoretical findings, we have implemented VirtuCast and\npresent an extensive computational evaluation, showing that using VirtuCast\nrealistically sized instances can be solved (close to) optimality. We show that\nVirtuCast significantly improves upon naive multi-commodity formulations and\nalso initiate the study of primal heuristics to generate feasible solutions\nduring the branch-and-bound process.\n", "versions": [{"version": "v1", "created": "Tue, 1 Oct 2013 15:33:30 GMT"}], "update_date": "2013-10-02", "authors_parsed": [["Rost", "Matthias", ""], ["Schmid", "Stefan", ""]]}, {"id": "1310.0710", "submitter": "Ulrich Bauer", "authors": "Ulrich Bauer, Michael Kerber, Jan Reininghaus", "title": "Distributed computation of persistent homology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DC math.AT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Persistent homology is a popular and powerful tool for capturing topological\nfeatures of data. Advances in algorithms for computing persistent homology have\nreduced the computation time drastically -- as long as the algorithm does not\nexhaust the available memory. Following up on a recently presented parallel\nmethod for persistence computation on shared memory systems, we demonstrate\nthat a simple adaption of the standard reduction algorithm leads to a variant\nfor distributed systems. Our algorithmic design ensures that the data is\ndistributed over the nodes without redundancy; this permits the computation of\nmuch larger instances than on a single machine. Moreover, we observe that the\nparallelism at least compensates for the overhead caused by communication\nbetween nodes, and often even speeds up the computation compared to sequential\nand even parallel shared memory algorithms. In our experiments, we were able to\ncompute the persistent homology of filtrations with more than a billion (10^9)\nelements within seconds on a cluster with 32 nodes using less than 10GB of\nmemory per node.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2013 14:08:33 GMT"}], "update_date": "2013-10-03", "authors_parsed": [["Bauer", "Ulrich", ""], ["Kerber", "Michael", ""], ["Reininghaus", "Jan", ""]]}, {"id": "1310.0883", "submitter": "Srikumar Venugopal", "authors": "Freddie Sunarso, Srikumar Venugopal and Federico Lauro", "title": "Scalable Protein Sequence Similarity Search using Locality-Sensitive\n  Hashing and MapReduce", "comments": null, "journal-ref": null, "doi": null, "report-no": "UNSW CSE TR 201325", "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Metagenomics is the study of environments through genetic sampling of their\nmicrobiota. Metagenomic studies produce large datasets that are estimated to\ngrow at a faster rate than the available computational capacity. A key step in\nthe study of metagenome data is sequence similarity searching which is\ncomputationally intensive over large datasets. Tools such as BLAST require\nlarge dedicated computing infrastructure to perform such analysis and may not\nbe available to every researcher.\n  In this paper, we propose a novel approach called ScalLoPS that performs\nsearching on protein sequence datasets using LSH (Locality-Sensitive Hashing)\nthat is implemented using the MapReduce distributed framework. ScalLoPS is\ndesigned to scale across computing resources sourced from cloud computing\nproviders. We present the design and implementation of ScalLoPS followed by\nevaluation with datasets derived from both traditional as well as metagenomic\nstudies. Our experiments show that with this method approximates the quality of\nBLAST results while improving the scalability of protein sequence search.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2013 03:11:06 GMT"}], "update_date": "2013-10-04", "authors_parsed": [["Sunarso", "Freddie", ""], ["Venugopal", "Srikumar", ""], ["Lauro", "Federico", ""]]}, {"id": "1310.1050", "submitter": "Dharshana Kasthurirathna", "authors": "Dharshana Kasthurirathna, Andy Dong, Mahendrarajah Piraveenan, Irem Y.\n  Tumer", "title": "The failure tolerance of mechatronic software systems to random and\n  targeted attacks", "comments": "Proceedings of the 2013 ASME International Design Engineering\n  Technical Conferences & Computers and Information in Engineering Conference\n  IDETC/CIE 2013 August 4-7, 2013, Portland, Oregon, USA (In Print)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a complex networks approach to study the failure\ntolerance of mechatronic software systems under various types of hardware\nand/or software failures. We produce synthetic system architectures based on\nevidence of modular and hierarchical modular product architectures and known\nmotifs for the interconnection of physical components to software. The system\narchitectures are then subject to various forms of attack. The attacks simulate\nfailure of critical hardware or software. Four types of attack are\ninvestigated: degree centrality, betweenness centrality, closeness centrality\nand random attack. Failure tolerance of the system is measured by a 'robustness\ncoefficient', a topological 'size' metric of the connectedness of the attacked\nnetwork. We find that the betweenness centrality attack results in the most\nsignificant reduction in the robustness coefficient, confirming betweenness\ncentrality, rather than the number of connections (i.e. degree), as the most\nconservative metric of component importance. A counter-intuitive finding is\nthat \"designed\" system architectures, including a bus, ring, and star\narchitecture, are not significantly more failure-tolerant than interconnections\nwith no prescribed architecture, that is, a random architecture. Our research\nprovides a data-driven approach to engineer the architecture of mechatronic\nsoftware systems for failure tolerance.\n", "versions": [{"version": "v1", "created": "Fri, 27 Sep 2013 11:07:31 GMT"}], "update_date": "2013-10-04", "authors_parsed": [["Kasthurirathna", "Dharshana", ""], ["Dong", "Andy", ""], ["Piraveenan", "Mahendrarajah", ""], ["Tumer", "Irem Y.", ""]]}, {"id": "1310.1485", "submitter": "Markus Rampp", "authors": "Tilman Dannert and Andreas Marek and Markus Rampp", "title": "Porting Large HPC Applications to GPU Clusters: The Codes GENE and\n  VERTEX", "comments": "10 pages, accepted for publication in ParCo 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph astro-ph.SR cs.DC physics.plasm-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have developed GPU versions for two major high-performance-computing (HPC)\napplications originating from two different scientific domains. GENE is a\nplasma microturbulence code which is employed for simulations of nuclear fusion\nplasmas. VERTEX is a neutrino-radiation hydrodynamics code for \"first\nprinciples\"-simulations of core-collapse supernova explosions. The codes are\nconsidered state of the art in their respective scientific domains, both\nconcerning their scientific scope and functionality as well as the achievable\ncompute performance, in particular parallel scalability on all relevant HPC\nplatforms. GENE and VERTEX were ported by us to HPC cluster architectures with\ntwo NVidia Kepler GPUs mounted in each node in addition to two Intel Xeon CPUs\nof the Sandy Bridge family. On such platforms we achieve up to twofold gains in\nthe overall application performance in the sense of a reduction of the time to\nsolution for a given setup with respect to a pure CPU cluster. The paper\ndescribes our basic porting strategies and benchmarking methodology, and\ndetails the main algorithmic and technical challenges we faced on the new,\nheterogeneous architecture.\n", "versions": [{"version": "v1", "created": "Sat, 5 Oct 2013 15:12:58 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Dannert", "Tilman", ""], ["Marek", "Andreas", ""], ["Rampp", "Markus", ""]]}, {"id": "1310.1537", "submitter": "Alireza Mahani", "authors": "Alireza S. Mahani, Mansour T.A. Sharabiani", "title": "SIMD Parallel MCMC Sampling with Applications for Big-Data Bayesian\n  Analytics", "comments": null, "journal-ref": null, "doi": "10.1016/j.csda.2015.02.010", "report-no": null, "categories": "stat.CO cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational intensity and sequential nature of estimation techniques for\nBayesian methods in statistics and machine learning, combined with their\nincreasing applications for big data analytics, necessitate both the\nidentification of potential opportunities to parallelize techniques such as\nMCMC sampling, and the development of general strategies for mapping such\nparallel algorithms to modern CPUs in order to elicit the performance up the\ncompute-based and/or memory-based hardware limits. Two opportunities for\nSingle-Instruction Multiple-Data (SIMD) parallelization of MCMC sampling for\nprobabilistic graphical models are presented. In exchangeable models with many\nobservations such as Bayesian Generalized Linear Models, child-node\ncontributions to the conditional posterior of each node can be calculated\nconcurrently. In undirected graphs with discrete nodes, concurrent sampling of\nconditionally-independent nodes can be transformed into a SIMD form.\nHigh-performance libraries with multi-threading and vectorization capabilities\ncan be readily applied to such SIMD opportunities to gain decent speedup, while\na series of high-level source-code and runtime modifications provide further\nperformance boost by reducing parallelization overhead and increasing data\nlocality for NUMA architectures. For big-data Bayesian GLM graphs, the\nend-result is a routine for evaluating the conditional posterior and its\ngradient vector that is 5 times faster than a naive implementation using\n(built-in) multi-threaded Intel MKL BLAS, and reaches within the striking\ndistance of the memory-bandwidth-induced hardware limit. The proposed\noptimization strategies improve the scaling of performance with number of cores\nand width of vector units (applicable to many-core SIMD processors such as\nIntel Xeon Phi and GPUs), resulting in cost-effectiveness, energy efficiency,\nand higher speed on multi-core x86 processors.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2013 04:02:35 GMT"}, {"version": "v2", "created": "Wed, 19 Nov 2014 22:40:39 GMT"}], "update_date": "2015-03-02", "authors_parsed": [["Mahani", "Alireza S.", ""], ["Sharabiani", "Mansour T. A.", ""]]}, {"id": "1310.1553", "submitter": "Andrey Gritsenko", "authors": "Andrey Gritsenko", "title": "A Workflow-Forecast Approach To The Task Scheduling Problem In\n  Distributed Computing Systems", "comments": "7 pages, 5 tables, 7 figures", "journal-ref": "International Journal of Advanced Studies in Computer Science and\n  Engineering, Volume 2, Special Issue 2, pp. 1-7. September 2013", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to provide a description of deep-learning-based\nscheduling approach for academic-purpose high-performance computing systems.\nThe share of academic-purpose distributed computing systems (DCS) reaches 17.4\npercents amongst TOP500 supercomputer sites (15.6 percents in performance\nscale) that makes them a valuable object of research. The core of this approach\nis to predict the future workflow of the system depending on the previously\nsubmitted tasks using deep learning algorithm. Information on predicted tasks\nis used by the resource management system (RMS) to perform efficient schedule.\n", "versions": [{"version": "v1", "created": "Sun, 6 Oct 2013 07:40:58 GMT"}], "update_date": "2013-10-08", "authors_parsed": [["Gritsenko", "Andrey", ""]]}, {"id": "1310.1761", "submitter": "Petr  Kuznetsov", "authors": "Eli Gafni and Petr Kuznetsov", "title": "Simple CHT: A New Derivation of the Weakest Failure Detector for\n  Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes an alternative proof that Omega, an oracle that outputs a\nprocess identifier and guarantees that eventually the same correct process\nidentifier is output at all correct processes, provides minimal information\nabout failures for solving consensus in read-write shared-memory systems: every\noracle that gives enough failure information to solve consensus can be used to\nimplement Omega.\n  Unlike the original proof by Chandra, Hadzilacos and Toueg (CHT), the proof\npresented in this paper builds upon the very fact that 2-process wait-free\nconsensus is impossible. Also, since the oracle that is used to implement can\nsolve consensus, the implementation is allowed to directly access consensus\nobjects. As a result, the proposed proof is shorter and conceptually simpler\nthan the original one.\n", "versions": [{"version": "v1", "created": "Mon, 7 Oct 2013 12:53:03 GMT"}, {"version": "v2", "created": "Tue, 8 Oct 2013 16:56:57 GMT"}, {"version": "v3", "created": "Thu, 18 Sep 2014 09:35:04 GMT"}], "update_date": "2014-09-19", "authors_parsed": [["Gafni", "Eli", ""], ["Kuznetsov", "Petr", ""]]}, {"id": "1310.2059", "submitter": "Peter Richtarik", "authors": "Peter Richt\\'arik and Martin Tak\\'a\\v{c}", "title": "Distributed Coordinate Descent Method for Learning with Big Data", "comments": "11 two-column pages, 1 algorithm, 4 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop and analyze Hydra: HYbriD cooRdinAte descent method\nfor solving loss minimization problems with big data. We initially partition\nthe coordinates (features) and assign each partition to a different node of a\ncluster. At every iteration, each node picks a random subset of the coordinates\nfrom those it owns, independently from the other computers, and in parallel\ncomputes and applies updates to the selected coordinates based on a simple\nclosed-form formula. We give bounds on the number of iterations sufficient to\napproximately solve the problem with high probability, and show how it depends\non the data and on the partitioning. We perform numerical experiments with a\nLASSO instance described by a 3TB matrix.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2013 09:31:27 GMT"}], "update_date": "2013-10-09", "authors_parsed": [["Richt\u00e1rik", "Peter", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1310.2148", "submitter": "Gary McGilvary Mr", "authors": "Gary A. McGilvary, Josep Rius, \\'I\\~nigo Goiri, Francesc Solsona, Adam\n  Barker and Malcolm Atkinson", "title": "C2MS: Dynamic Monitoring and Management of Cloud Infrastructures", "comments": "Proceedings of the The 5th IEEE International Conference on Cloud\n  Computing Technology and Science (CloudCom 2013), 8 pages", "journal-ref": null, "doi": "10.1109/CloudCom.2013.45", "report-no": null, "categories": "cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Server clustering is a common design principle employed by many organisations\nwho require high availability, scalability and easier management of their\ninfrastructure. Servers are typically clustered according to the service they\nprovide whether it be the application(s) installed, the role of the server or\nserver accessibility for example. In order to optimize performance, manage load\nand maintain availability, servers may migrate from one cluster group to\nanother making it difficult for server monitoring tools to continuously monitor\nthese dynamically changing groups. Server monitoring tools are usually\nstatically configured and with any change of group membership requires manual\nreconfiguration; an unreasonable task to undertake on large-scale cloud\ninfrastructures.\n  In this paper we present the Cloudlet Control and Management System (C2MS); a\nsystem for monitoring and controlling dynamic groups of physical or virtual\nservers within cloud infrastructures. The C2MS extends Ganglia - an open source\nscalable system performance monitoring tool - by allowing system administrators\nto define, monitor and modify server groups without the need for server\nreconfiguration. In turn administrators can easily monitor group and individual\nserver metrics on large-scale dynamic cloud infrastructures where roles of\nservers may change frequently. Furthermore, we complement group monitoring with\na control element allowing administrator-specified actions to be performed over\nservers within service groups as well as introduce further customized\nmonitoring metrics. This paper outlines the design, implementation and\nevaluation of the C2MS.\n", "versions": [{"version": "v1", "created": "Thu, 3 Oct 2013 22:49:06 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["McGilvary", "Gary A.", ""], ["Rius", "Josep", ""], ["Goiri", "\u00cd\u00f1igo", ""], ["Solsona", "Francesc", ""], ["Barker", "Adam", ""], ["Atkinson", "Malcolm", ""]]}, {"id": "1310.2274", "submitter": "Blesson Varghese", "authors": "Blesson Varghese and Andrew Rau-Chaplin", "title": "Accounting for Secondary Uncertainty: Efficient Computation of Portfolio\n  Risk Measures on Multi and Many Core Architectures", "comments": "10 pages, Workshop on High Performance Computational Finance at SC\n  2013, Denver, Colorado, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aggregate Risk Analysis is a computationally intensive and a data intensive\nproblem, thereby making the application of high-performance computing\ntechniques interesting. In this paper, the design and implementation of a\nparallel Aggregate Risk Analysis algorithm on multi-core CPU and many-core GPU\nplatforms are explored. The efficient computation of key risk measures,\nincluding Probable Maximum Loss (PML) and the Tail Value-at-Risk (TVaR) in the\npresence of both primary and secondary uncertainty for a portfolio of property\ncatastrophe insurance treaties is considered. Primary Uncertainty is the the\nuncertainty associated with whether a catastrophe event occurs or not in a\nsimulated year, while Secondary Uncertainty is the uncertainty in the amount of\nloss when the event occurs.\n  A number of statistical algorithms are investigated for computing secondary\nuncertainty. Numerous challenges such as loading large data onto hardware with\nlimited memory and organising it are addressed. The results obtained from\nexperimental studies are encouraging. Consider for example, an aggregate risk\nanalysis involving 800,000 trials, with 1,000 catastrophic events per trial, a\nmillion locations, and a complex contract structure taking into account\nsecondary uncertainty. The analysis can be performed in just 41 seconds on a\nGPU, that is 24x faster than the sequential counterpart on a fast multi-core\nCPU. The results indicate that GPUs can be used to efficiently accelerate\naggregate risk analysis even in the presence of secondary uncertainty.\n", "versions": [{"version": "v1", "created": "Tue, 8 Oct 2013 20:36:49 GMT"}], "update_date": "2013-10-10", "authors_parsed": [["Varghese", "Blesson", ""], ["Rau-Chaplin", "Andrew", ""]]}, {"id": "1310.2369", "submitter": "Dhanamma Jagli", "authors": "Dhanamma Jagli, Ramesh Solanki, Rohini Temkar, Laxmi Veshapogu", "title": "Semi Symmetric Method Of SAN Storage Virtualization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualization is one of the biggest buzzwords of the technology industry\nright at this moment. The fast growth in storage capacity and processing power\nin enterprise installations coupled with the need for high availability,\nrequires Storage Area Network (SAN) architecture to provide seamless addition\nof storage and performance elements without downtime. The usual goal of\nvirtualization is to centralize administrative tasks while improving\nscalability and work loads. This paper, describing about new proposed method\nfor virtualization, which would be overcome limitations of existed methods for\nstorage virtualization\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2013 06:30:21 GMT"}], "update_date": "2013-10-10", "authors_parsed": [["Jagli", "Dhanamma", ""], ["Solanki", "Ramesh", ""], ["Temkar", "Rohini", ""], ["Veshapogu", "Laxmi", ""]]}, {"id": "1310.2494", "submitter": "Lelia Blin", "authors": "L\\'elia Blin", "title": "Algorithmes auto-stabilisants pour la construction d'arbres couvrants et\n  la gestion d'entit\\'es autonomes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In the context of large-scale networks, the consideration of faults is an\nevident necessity. This document is focussing on the self-stabilizing approach\nwhich aims at conceiving algorithms \"repairing themselves\" in case of transient\nfaults, that is of faults implying an arbitrary modification of the states of\nthe processes. The document focuses on two different contexts, covering the\nmajor part of my research work these last years. The first part of the document\nis dedicated to the design and analysis of self-stabilizing algorithms for\nnetworks of processes. The second part of the document is dedicated to the\ndesign and analysis of self-stabilizing algorithms for autonomous entities\n(i.e., software agents, robots, etc.) moving in a network.\n", "versions": [{"version": "v1", "created": "Wed, 9 Oct 2013 14:27:43 GMT"}], "update_date": "2013-10-10", "authors_parsed": [["Blin", "L\u00e9lia", ""]]}, {"id": "1310.2814", "submitter": "Suyash Gupta", "authors": "Suyash Gupta, V. Krishna Nandivada", "title": "IMSuite: A Benchmark Suite for Simulating Distributed Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considering the diverse nature of real-world distributed applications that\nmakes it hard to identify a representative subset of distributed benchmarks, we\nfocus on their underlying distributed algorithms. We present and characterize a\nnew kernel benchmark suite (named IMSuite) that simulates some of the classical\ndistributed algorithms in task parallel languages. We present multiple\nvariations of our kernels, broadly categorized under two heads: (a) varying\nsynchronization primitives (with and without fine grain synchronization\nprimitives); and (b) varying forms of parallelization (data parallel and\nrecursive task parallel). Our characterization covers interesting aspects of\ndistributed applications such as distribution of remote communication requests,\nnumber of synchronization, task creation, task termination and atomic\noperations. We study the behavior (execution time) of our kernels by varying\nthe problem size, the number of compute threads, and the input configurations.\nWe also present an involved set of input generators and output validators.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2013 13:40:51 GMT"}], "update_date": "2013-10-11", "authors_parsed": [["Gupta", "Suyash", ""], ["Nandivada", "V. Krishna", ""]]}, {"id": "1310.2858", "submitter": "Emanuele Natale", "authors": "Luca Becchetti, Andrea Clementi, Emanuele Natale, Francesco Pasquale,\n  Riccardo Silvestri, and Luca Trevisan", "title": "Simple Dynamics for Plurality Consensus", "comments": "Preprint of journal version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a \\emph{Plurality-Consensus} process in which each of $n$ anonymous\nagents of a communication network initially supports an opinion (a color chosen\nfrom a finite set $[k]$). Then, in every (synchronous) round, each agent can\nrevise his color according to the opinions currently held by a random sample of\nhis neighbors. It is assumed that the initial color configuration exhibits a\nsufficiently large \\emph{bias} $s$ towards a fixed plurality color, that is,\nthe number of nodes supporting the plurality color exceeds the number of nodes\nsupporting any other color by $s$ additional nodes. The goal is having the\nprocess to converge to the \\emph{stable} configuration in which all nodes\nsupport the initial plurality. We consider a basic model in which the network\nis a clique and the update rule (called here the \\emph{3-majority dynamics}) of\nthe process is the following: each agent looks at the colors of three random\nneighbors and then applies the majority rule (breaking ties uniformly).\n  We prove that the process converges in time $\\mathcal{O}( \\min\\{ k, (n/\\log\nn)^{1/3} \\} \\, \\log n )$ with high probability, provided that $s \\geqslant c\n\\sqrt{ \\min\\{ 2k, (n/\\log n)^{1/3} \\}\\, n \\log n}$.\n  We then prove that our upper bound above is tight as long as $k \\leqslant\n(n/\\log n)^{1/4}$. This fact implies an exponential time-gap between the\nplurality-consensus process and the \\emph{median} process studied by Doerr et\nal. in [ACM SPAA'11].\n  A natural question is whether looking at more (than three) random neighbors\ncan significantly speed up the process. We provide a negative answer to this\nquestion: In particular, we show that samples of polylogarithmic size can speed\nup the process by a polylogarithmic factor only.\n", "versions": [{"version": "v1", "created": "Thu, 10 Oct 2013 15:43:04 GMT"}, {"version": "v2", "created": "Mon, 14 Oct 2013 10:06:01 GMT"}, {"version": "v3", "created": "Mon, 27 Jul 2015 15:25:31 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Becchetti", "Luca", ""], ["Clementi", "Andrea", ""], ["Natale", "Emanuele", ""], ["Pasquale", "Francesco", ""], ["Silvestri", "Riccardo", ""], ["Trevisan", "Luca", ""]]}, {"id": "1310.2994", "submitter": "Haipeng Cai", "authors": "Haipeng Cai, Jian Chen and Alexander P. Auchus", "title": "Depth-dependent Parallel Visualization with 3D Stylized Dense Tubes", "comments": "10 pages, 9 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a parallel visualization algorithm for the illustrative rendering\nof depth-dependent stylized dense tube data at interactive frame rates. While\nthis computation could be efficiently performed on a GPU device, we target a\nparallel framework to enable it to be efficiently running on an ordinary\nmulti-core CPU platform which is much more available than GPUs for common\nusers. Our approach is to map the depth information in each tube onto each of\nthe visual dimensions of shape, color, texture, value, and size on the basis of\nBertin's semiology theory. The purpose is to enable more legible displays in\nthe dense tube environments. A major contribution of our work is an efficient\nand effective parallel depthordering algorithm that makes use of the message\npassing interface (MPI) with VTK. We evaluated our framework with\nvisualizations of depth-stylized tubes derived from 3D diffusion tensor MRI\ndata by comparing its efficiency with several other alternative parallelization\nplatforms running the same computations. As our results show, the\nparallelization framework we proposed can efficiently render highly dense 3D\ndata sets like the tube data and thus is useful as a complement to parallel\nvisualization environments that rely on GPUs.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2013 00:38:49 GMT"}, {"version": "v2", "created": "Tue, 15 Oct 2013 01:31:31 GMT"}], "update_date": "2013-10-16", "authors_parsed": [["Cai", "Haipeng", ""], ["Chen", "Jian", ""], ["Auchus", "Alexander P.", ""]]}, {"id": "1310.3107", "submitter": "Marek Zawirski", "authors": "Marek Zawirski (INRIA Rocquencourt, LIP6), Annette Bieniusa, Valter\n  Balegas (CITI), S\\'ergio Duarte (CITI), Carlos Baquero (Universidade do Minho\n  Departamento de Inform\\'atica), Marc Shapiro (INRIA Rocquencourt, LIP6), Nuno\n  Pregui\\c{c}a (CITI)", "title": "SwiftCloud: Fault-Tolerant Geo-Replication Integrated all the Way to the\n  Client Machine", "comments": null, "journal-ref": "N&deg; RR-8347 (2013)", "doi": null, "report-no": "RR-8347", "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Client-side logic and storage are increasingly used in web and mobile\napplications to improve response time and availability. Current approaches tend\nto be ad-hoc and poorly integrated with the server-side logic. We present a\nprincipled approach to integrate client- and server-side storage. We support\nmergeable and strongly consistent transactions that target either client or\nserver replicas and provide access to causally-consistent snapshots\nefficiently. In the presence of infrastructure faults, a client-assisted\nfailover solution allows client execution to resume immediately and seamlessly\naccess consistent snapshots without waiting. We implement this approach in\nSwiftCloud, the first transactional system to bring geo-replication all the way\nto the client machine. Example applications show that our programming model is\nuseful across a range of application areas. Our experimental evaluation shows\nthat SwiftCloud provides better fault tolerance and at the same time can\nimprove both latency and throughput by up to an order of magnitude, compared to\nclassical geo-replication techniques.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2013 12:38:58 GMT"}], "update_date": "2013-10-14", "authors_parsed": [["Zawirski", "Marek", "", "INRIA Rocquencourt, LIP6"], ["Bieniusa", "Annette", "", "CITI"], ["Balegas", "Valter", "", "CITI"], ["Duarte", "S\u00e9rgio", "", "CITI"], ["Baquero", "Carlos", "", "Universidade do Minho\n  Departamento de Inform\u00e1tica"], ["Shapiro", "Marc", "", "INRIA Rocquencourt, LIP6"], ["Pregui\u00e7a", "Nuno", "", "CITI"]]}, {"id": "1310.3309", "submitter": "Alexander Pokluda", "authors": "Alexander Pokluda", "title": "Dynamic Resource Management using Operating System-Level Virtualization", "comments": "Undergraduate Honors Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This thesis expands upon an existing system called Golondrina that performs\nautonomic workload management among a cluster of hardware nodes running\noperating system-level virtualization. Golondrina works by identifying\nlocalized resource stress situations and attempting to dissipate them by\nreallocating system resources and, if necessary, migrating or replicating\nvirtual machines. It is predicted that, using Golondrina, efficiency of similar\nsystems can be further improved by achieving greater resource utilization on\nthe hardware nodes while maintaining resource availability for each virtual\nmachine.\n  The following topics are discussed: virtualization technologies and\nassociated challenges relating to resource management, the architecture and\ndesign of Golondrina, intelligent resource reallocation based on predefined\npolicies, and preliminary results demonstrating the effects of a memory\nresource management policy on the performance of a web application hosted in a\nvirtual environment.\n  This research makes a significant contribution to the study of virtualized\ndata centres since currently no other system considers virtual machine\nreplication and dynamic memory reallocation as an approach to workload\nmanagement.\n", "versions": [{"version": "v1", "created": "Fri, 11 Oct 2013 23:09:57 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Pokluda", "Alexander", ""]]}, {"id": "1310.3322", "submitter": "Mohamed Elhoseiny Mohamed Elhoseiny", "authors": "Mohamed Elhoseiny, Hossam Faheem, Taymour Nazmy, and Eman Shaaban", "title": "GPU-Framework for Teamwork Action Recognition", "comments": "7 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real time processing for teamwork action recognition is a challenge, due to\ncomplex computational models to achieve high system performance. Hence, this\npaper proposes a framework based on Graphical Processing Units (GPUs) to\nachieve a significant speed up in the performance of role based activity\nrecognition of teamwork. The framework can be applied in various fields,\nespecially athletic and military applications. Furthermore, the framework can\nbe customized for many action recognition applications. The paper presents the\nstages of the framework where GPUs are the main tool for performance\nimprovement. The speedup is achieved by performing video processing and Machine\nlearning algorithms on GPU. Video processing and machine learning algorithms\ncovers all computations involved in our framework. Video processing tasks on\ninvolves GPU implementation of Motion detection, segmentation and object\ntracking algorithms. In addition, our framework is integrated with GPUCV, a GPU\nversion of OpenCV functions. Machine learning tasks are supported under our\nframework with GPU implementations of Support Vector Machine (SVM) for object\nclassification and feature discretization, Hidden Marcov Model (HMM) for\nactivity recognition phase, and ID3 algorithm for role recognition of team\nmembers. The system was tested against UC-Teamwork dataset and speedup of 20X\nhas been achieved on NVidia 9500GT graphics card (32 500MHZ processors).\n", "versions": [{"version": "v1", "created": "Sat, 12 Oct 2013 01:16:32 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Elhoseiny", "Mohamed", ""], ["Faheem", "Hossam", ""], ["Nazmy", "Taymour", ""], ["Shaaban", "Eman", ""]]}, {"id": "1310.3438", "submitter": "Peter Richtarik", "authors": "Peter Richt\\'arik and Martin Tak\\'a\\v{c}", "title": "On Optimal Probabilities in Stochastic Coordinate Descent Methods", "comments": "5 pages, 1 algorithm (`NSync), 2 theorems, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose and analyze a new parallel coordinate descent method---`NSync---in\nwhich at each iteration a random subset of coordinates is updated, in parallel,\nallowing for the subsets to be chosen non-uniformly. We derive convergence\nrates under a strong convexity assumption, and comment on how to assign\nprobabilities to the sets to optimize the bound. The complexity and practical\nperformance of the method can outperform its uniform variant by an order of\nmagnitude. Surprisingly, the strategy of updating a single randomly selected\ncoordinate per iteration---with optimal probabilities---may require less\niterations, both in theory and practice, than the strategy of updating all\ncoordinates at every iteration.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2013 00:12:25 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Richt\u00e1rik", "Peter", ""], ["Tak\u00e1\u010d", "Martin", ""]]}, {"id": "1310.3486", "submitter": "Varsha Dani", "authors": "Varsha Dani, Valerie King, Mahnush Movahedi and Jared Saia", "title": "Quorums Quicken Queries: Efficient Asynchronous Secure Multiparty\n  Computation", "comments": "ICDCN version: 15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe an asynchronous algorithm to solve secure multiparty computation\n(MPC) over n players, when strictly less than a 1/8 fraction of the players are\ncontrolled by a static adversary. For any function f over a field that can be\ncomputed by a circuit with m gates, our algorithm requires each player to send\na number of field elements and perform an amount of computation that is O (m/n\n+ \\sqrt{n}). This significantly improves over traditional algorithms, which\nrequire each player to both send a number of messages and perform computation\nthat is {\\Omega}(nm). Additionally, we define the threshold counting problem\nand present a distributed algorithm to solve it in the asynchronous\ncommunication model. Our algorithm is load balanced, with computation,\ncommunication and latency complexity of O(log n), and may be of independent\ninterest to other applications with a load balancing goal in mind.\n", "versions": [{"version": "v1", "created": "Sun, 13 Oct 2013 14:29:24 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Dani", "Varsha", ""], ["King", "Valerie", ""], ["Movahedi", "Mahnush", ""], ["Saia", "Jared", ""]]}, {"id": "1310.3609", "submitter": "Sean Sedwards", "authors": "Axel Legay, Sean Sedwards and Louis-Marie Traonouez", "title": "Scalable Verification of Markov Decision Processes", "comments": "V4: FMDS version, 12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.LG cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Markov decision processes (MDP) are useful to model concurrent process\noptimisation problems, but verifying them with numerical methods is often\nintractable. Existing approximative approaches do not scale well and are\nlimited to memoryless schedulers. Here we present the basis of scalable\nverification for MDPSs, using an O(1) memory representation of\nhistory-dependent schedulers. We thus facilitate scalable learning techniques\nand the use of massively parallel verification.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2013 09:50:49 GMT"}, {"version": "v2", "created": "Mon, 10 Feb 2014 13:17:58 GMT"}, {"version": "v3", "created": "Tue, 11 Feb 2014 07:31:27 GMT"}, {"version": "v4", "created": "Wed, 17 Sep 2014 11:07:09 GMT"}], "update_date": "2014-09-18", "authors_parsed": [["Legay", "Axel", ""], ["Sedwards", "Sean", ""], ["Traonouez", "Louis-Marie", ""]]}, {"id": "1310.3623", "submitter": "Yu Huang", "authors": "Yiling Yang, Yu Huang, Xiaoxing Ma, Jian Lu", "title": "Enabling Context-awareness by Predicate Detection in Asynchronous\n  Pervasive Computing Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pervasive applications are involving more and more autonomous computing and\ncommunicating devices, augmented with the abilities of sensing and controlling\nthe logical / physical environment. To enable context-awareness for such\napplications, we are challenged by the intrinsic asynchrony among the context\ncollecting devices. To this end, we introduce the predicate detection theory\nand propose the Predicate-Detection-based Context-Awareness (PD-CA) framework,\nin which: a) logical time is used to explicitly cope with the asynchrony; b)\nspecification of predicates enables the applications to express contextual\nproperties of their concerns; c) online and incremental predicate detection\nalgorithms effectively enable context-awareness at runtime. Under the guidance\nof the PD-CA framework, we present the design and implementation of the MIPA\nmiddleware, which shields the applications from the burden of processing the\nasynchronous contexts. We also demonstrate how PD-CA simplifies the development\nof context-aware applications. Experimental evaluations show the performance of\nMIPA in supporting context-aware applications despite of the asynchrony.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2013 10:49:49 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Yang", "Yiling", ""], ["Huang", "Yu", ""], ["Ma", "Xiaoxing", ""], ["Lu", "Jian", ""]]}, {"id": "1310.3723", "submitter": "Jean Quilbeuf", "authors": "Jean Quilbeuf, Georgeta Igna, Denis Bytschkow, Harald Ruess", "title": "Security policies for distributed systems", "comments": "Submitted to POST14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A security policy specifies a security property as the maximal information\nflow. A distributed system composed of interacting processes implicitly defines\nan intransitive security policy by repudiating direct information flow between\nprocesses that do not exchange messages directly. We show that implicitly\ndefined security policies in distributed systems are enforced, provided that\nprocesses run in separation, and possible process communication on a technical\nplatform is restricted to specified message paths of the system. Furthermore,\nwe propose to further restrict the allowable information flow by adding filter\nfunctions for controlling which messages may be transmitted between processes,\nand we prove that locally checking filter functions is sufficient for ensuring\nglobal security policies. Altogether, global intransitive security policies are\nestablished by means of local verification conditions for the (trusted)\nprocesses of the distributed system. Moreover, security policies may be\nimplemented securely on distributed integration platforms which ensure\npartitioning. We illustrate our results with a smart grid case study, where we\nuse CTL model checking for discharging local verification conditions for each\nprocess under consideration.\n", "versions": [{"version": "v1", "created": "Mon, 14 Oct 2013 15:35:42 GMT"}], "update_date": "2013-10-15", "authors_parsed": [["Quilbeuf", "Jean", ""], ["Igna", "Georgeta", ""], ["Bytschkow", "Denis", ""], ["Ruess", "Harald", ""]]}, {"id": "1310.3990", "submitter": "Subhasis Bhattacharjee", "authors": "Subhasis Bhattacharjee", "title": "Distributed Algorithm for Dynamic Data-Gathering in Sensor Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In WSN, each sensor is responsible for sensing environmental conditions and\nsending them to the one or more base stations. Battery-operated sensors are\nseverely constrained by the amount of energy that can be spend for transmitting\nthese sensed data. However, aggregation of data (including removal of redundant\ndata) at intermediate sensors and forwarding of aggregate data reduce overall\nenergy consumptions in WSN. In general, data gathering refers to the process of\nperiodic collection of sensed data from various sensors to one or more base\nstations (BS). Energy efficient data gathering scheduling is essential for\nimproving the lifetime of WSN. In this paper, we propose a distributed\nalgorithm to compute data-gathering schedule that aim to improve the lifetime\nof WSN by suitably selecting energy-efficient data-flow paths from various\nsensors to the base station. For a multihop WSN with $n$ sensors, the proposed\nalgorithm first computes a schedule in $O(n^2)$ time steps, and then this\nschedule is periodically updated based the residual energy and the feedback\nreceived from the BS. The system performs approximately $\\log(\\mathcal{L})$\nschedule updates where $\\mathcal{L}$ is the expected lifetime of the system in\nnumber of data-gathering rounds. Moreover, each updation process uses the\nexisting active schedule (data-flow path) - thus consuming only a small\nfraction of a single data gathering round activity. Such an algorithm thus\ncould precisely incorporate the energy consumptions due to updates and related\nactivities. Moreover, our algorithm does not assume any global knowledge of the\ntopology or the positions of various sensors. Through simulation study, we\nfound that our proposed algorithm achieves significantly higher network\nlifetime compared to existing data-flow schedules based on the Minimum Spanning\nTree (MST), the Shortest Path Tree (SPT), the Weighted Rooted Tree (WRT).\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2013 10:25:06 GMT"}], "update_date": "2013-10-16", "authors_parsed": [["Bhattacharjee", "Subhasis", ""]]}, {"id": "1310.4019", "submitter": "EPTCS", "authors": "Marco Carbone (ITU, Denmark), Ivan Lanese (University of\n  Bologna/INRIA, Italy), Alberto Lluch Lafuente (IMT Institute for Advanced\n  Studies Lucca, Italy), Ana Sokolova (University of Salzburg, Austria)", "title": "Proceedings 6th Interaction and Concurrency Experience", "comments": null, "journal-ref": "EPTCS 131, 2013", "doi": "10.4204/EPTCS.131", "report-no": null, "categories": "cs.PL cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the proceedings of ICE 2013, the 6th Interaction and\nConcurrency Experience workshop, which was held in Florence, Italy on the 6th\nof June 2013 as a satellite event of DisCoTec 2013. The ICE procedure for paper\nselection allows PC members to interact, anonymously, with authors. During the\nreview phase, each submitted paper is published on a Wiki and associated with a\ndiscussion forum whose access is restricted to the authors and to all the PC\nmembers not declaring a conflict of interests. The PC members post comments and\nquestions that the authors reply to. Each paper was reviewed by three PC\nmembers, and altogether 6 papers were accepted for publication. We were proud\nto host two invited talks, Davide Sangiorgi and Filippo Bonchi, whose abstracts\nare included in this volume together with the regular papers. The workshop also\nfeatured a brief announcement of an already published paper.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2013 12:04:04 GMT"}], "update_date": "2013-10-16", "authors_parsed": [["Carbone", "Marco", "", "ITU, Denmark"], ["Lanese", "Ivan", "", "University of\n  Bologna/INRIA, Italy"], ["Lafuente", "Alberto Lluch", "", "IMT Institute for Advanced\n  Studies Lucca, Italy"], ["Sokolova", "Ana", "", "University of Salzburg, Austria"]]}, {"id": "1310.4038", "submitter": "Charith Perera", "authors": "Charith Perera, Prem Prakash Jayaraman, Arkady Zaslavsky, Peter\n  Christen, Dimitrios Georgakopoulos", "title": "MOSDEN: An Internet of Things Middleware for Resource Constrained Mobile\n  Devices", "comments": null, "journal-ref": "Proceedings of the 47th Hawaii International Conference on System\n  Sciences (HICSS), Kona, Hawaii, USA, January, 2014", "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is part of Future Internet and will comprise\nmany billions of Internet Connected Objects (ICO) or `things' where things can\nsense, communicate, compute and potentially actuate as well as have\nintelligence, multi-modal interfaces, physical/ virtual identities and\nattributes. Collecting data from these objects is an important task as it\nallows software systems to understand the environment better. Many different\nhardware devices may involve in the process of collecting and uploading sensor\ndata to the cloud where complex processing can occur. Further, we cannot expect\nall these objects to be connected to the computers due to technical and\neconomical reasons. Therefore, we should be able to utilize resource\nconstrained devices to collect data from these ICOs. On the other hand, it is\ncritical to process the collected sensor data before sending them to the cloud\nto make sure the sustainability of the infrastructure due to energy\nconstraints. This requires to move the sensor data processing tasks towards the\nresource constrained computational devices (e.g. mobile phones). In this paper,\nwe propose Mobile Sensor Data Processing Engine (MOSDEN), an plug-in-based IoT\nmiddleware for mobile devices, that allows to collect and process sensor data\nwithout programming efforts. Our architecture also supports sensing as a\nservice model. We present the results of the evaluations that demonstrate its\nsuitability towards real world deployments. Our proposed middleware is built on\nAndroid platform.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2013 12:50:44 GMT"}], "update_date": "2013-10-16", "authors_parsed": [["Perera", "Charith", ""], ["Jayaraman", "Prem Prakash", ""], ["Zaslavsky", "Arkady", ""], ["Christen", "Peter", ""], ["Georgakopoulos", "Dimitrios", ""]]}, {"id": "1310.4052", "submitter": "Charith Perera", "authors": "Prem Prakash Jayaraman and Charith Perera and Dimitrios Georgakopoulos\n  and Arkady Zaslavsky", "title": "Efficient Opportunistic Sensing using Mobile Collaborative Platform\n  MOSDEN", "comments": null, "journal-ref": "9th IEEE International Conference on Collaborative Computing:\n  Networking, Applications and Worksharing (COLLABORATECOM), Austin, Texas,\n  United States, October, 2013", "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile devices are rapidly becoming the primary computing device in people's\nlives. Application delivery platforms like Google Play, Apple App Store have\ntransformed mobile phones into intelligent computing devices by the means of\napplications that can be downloaded and installed instantly. Many of these\napplications take advantage of the plethora of sensors installed on the mobile\ndevice to deliver enhanced user experience. The sensors on the smartphone\nprovide the opportunity to develop innovative mobile opportunistic sensing\napplications in many sectors including healthcare, environmental monitoring and\ntransportation. In this paper, we present a collaborative mobile sensing\nframework namely Mobile Sensor Data EngiNe (MOSDEN) that can operate on\nsmartphones capturing and sharing sensed data between multiple distributed\napplications and users. MOSDEN follows a component-based design philosophy\npromoting reuse for easy and quick opportunistic sensing application\ndeployments. MOSDEN separates the application-specific processing from the\nsensing, storing and sharing. MOSDEN is scalable and requires minimal\ndevelopment effort from the application developer. We have implemented our\nframework on Android-based mobile platforms and evaluate its performance to\nvalidate the feasibility and efficiency of MOSDEN to operate collaboratively in\nmobile opportunistic sensing applications. Experimental outcomes and lessons\nlearnt conclude the paper.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2013 13:53:05 GMT"}], "update_date": "2013-10-16", "authors_parsed": [["Jayaraman", "Prem Prakash", ""], ["Perera", "Charith", ""], ["Georgakopoulos", "Dimitrios", ""], ["Zaslavsky", "Arkady", ""]]}, {"id": "1310.4136", "submitter": "Thiago S. F. X. Teixeira", "authors": "Thiago S. F. X. Teixeira, George Teodoro, Eduardo Valle, Joel H. Saltz", "title": "Scalable Locality-Sensitive Hashing for Similarity Search in\n  High-Dimensional, Large-Scale Multimedia Datasets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.IR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Similarity search is critical for many database applications, including the\nincreasingly popular online services for Content-Based Multimedia Retrieval\n(CBMR). These services, which include image search engines, must handle an\noverwhelming volume of data, while keeping low response times. Thus,\nscalability is imperative for similarity search in Web-scale applications, but\nmost existing methods are sequential and target shared-memory machines. Here we\naddress these issues with a distributed, efficient, and scalable index based on\nLocality-Sensitive Hashing (LSH). LSH is one of the most efficient and popular\ntechniques for similarity search, but its poor referential locality properties\nhas made its implementation a challenging problem. Our solution is based on a\nwidely asynchronous dataflow parallelization with a number of optimizations\nthat include a hierarchical parallelization to decouple indexing and data\nstorage, locality-aware data partition strategies to reduce message passing,\nand multi-probing to limit memory usage. The proposed parallelization attained\nan efficiency of 90% in a distributed system with about 800 CPU cores. In\nparticular, the original locality-aware data partition reduced the number of\nmessages exchanged in 30%. Our parallel LSH was evaluated using the largest\npublic dataset for similarity search (to the best of our knowledge) with $10^9$\n128-d SIFT descriptors extracted from Web images. This is two orders of\nmagnitude larger than datasets that previous LSH parallelizations could handle.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2013 18:21:39 GMT"}], "update_date": "2013-10-16", "authors_parsed": [["Teixeira", "Thiago S. F. X.", ""], ["Teodoro", "George", ""], ["Valle", "Eduardo", ""], ["Saltz", "Joel H.", ""]]}, {"id": "1310.4218", "submitter": "Alvaro Fazenda", "authors": "Alvaro Luiz Fazenda, Celso L. Mendes, Laxmikant V. Kale, Jairo\n  Panetta, Eduardo Rocha Rodrigues", "title": "Dynamic Load Balancing in GPU-Based Systems - Early Experiments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The dynamic load-balancing framework in Charm++/AMPI, developed at the\nUniversity of Illinois, is based on using processor virtualization to allow\nthread migration across processors. This framework has been successfully\napplied to many scientific applications in the past, such as BRAMS, NAMD,\nChaNGa, and others. Most of these applications use only CPUs to perform their\noperations. However, the use of GPUs to improve computational performance is\nquickly getting massively disseminated in the high-performance computing\ncommunity. This paper aims to investigate how the same Charm++/AMPI framework\ncan be extended to balance load in a synthetic application inspired by the\nBRAMS numerical forecast model, running mostly on GPUs rather than on CPUs.\nMany major questions involving the use of GPUs with AMPI where handled in this\nwork, including: how to measure the GPU's load, how to use and share GPUs among\nuser-level threads, and what results are obtained when applying the mandatory\nover-decomposition technique to a GPU-accelerated program.\n", "versions": [{"version": "v1", "created": "Tue, 15 Oct 2013 21:47:57 GMT"}], "update_date": "2013-10-17", "authors_parsed": [["Fazenda", "Alvaro Luiz", ""], ["Mendes", "Celso L.", ""], ["Kale", "Laxmikant V.", ""], ["Panetta", "Jairo", ""], ["Rodrigues", "Eduardo Rocha", ""]]}, {"id": "1310.4502", "submitter": "Michael Warren", "authors": "Michael S. Warren", "title": "2HOT: An Improved Parallel Hashed Oct-Tree N-Body Algorithm for\n  Cosmological Simulation", "comments": "12 pages, 8 figures, 77 references; To appear in Proceedings of SC\n  '13", "journal-ref": null, "doi": "10.1145/2503210.2503220", "report-no": "LA-UR-13-22336", "categories": "astro-ph.IM astro-ph.CO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We report on improvements made over the past two decades to our adaptive\ntreecode N-body method (HOT). A mathematical and computational approach to the\ncosmological N-body problem is described, with performance and scalability\nmeasured up to 256k ($2^{18}$) processors. We present error analysis and\nscientific application results from a series of more than ten 69 billion\n($4096^3$) particle cosmological simulations, accounting for $4 \\times 10^{20}$\nfloating point operations. These results include the first simulations using\nthe new constraints on the standard model of cosmology from the Planck\nsatellite. Our simulations set a new standard for accuracy and scientific\nthroughput, while meeting or exceeding the computational efficiency of the\nlatest generation of hybrid TreePM N-body methods.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2013 20:00:05 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Warren", "Michael S.", ""]]}, {"id": "1310.4573", "submitter": "EPTCS", "authors": "Julien Lange (University of Leicester, UK), Alceste Scalas (University\n  of Cagliari, Italy)", "title": "Choreography Synthesis as Contract Agreement", "comments": "In Proceedings ICE 2013, arXiv:1310.4019", "journal-ref": "EPTCS 131, 2013, pp. 52-67", "doi": "10.4204/EPTCS.131.6", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a formal model for distributed systems, where each participant\nadvertises its requirements and obligations as behavioural contracts, and where\nmultiparty sessions are started when a set of contracts allows to synthesise a\nchoreography. Our framework is based on the CO2 calculus for contract-oriented\ncomputing, and borrows concepts and results from the session type literature.\n  It supports sessions where the number of participants is not determined\nbeforehand, and keeps CO2's ability to rule out participants that are culpable\nif contracts are not fulfilled at runtime. We show that we have progress and\nsession fidelity in CO2, as a result of the honesty of participants - i.e.,\ntheir ability to always adhere to their contracts.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 03:48:09 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Lange", "Julien", "", "University of Leicester, UK"], ["Scalas", "Alceste", "", "University\n  of Cagliari, Italy"]]}, {"id": "1310.4574", "submitter": "EPTCS", "authors": "Kyriakos Poyias (University of Leicester, UK), Emilio Tuosto\n  (University of Leicester, UK)", "title": "On Recovering from Run-time Misbehaviour in ADR", "comments": "In Proceedings ICE 2013, arXiv:1310.4019", "journal-ref": "EPTCS 131, 2013, pp. 68-84", "doi": "10.4204/EPTCS.131.7", "report-no": null, "categories": "cs.SE cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a monitoring mechanism for recording the evolution of systems\nafter certain computations, maintaining the history in a tree-like structure.\nTechnically, we develop the monitoring mechanism in a variant of ADR (after\nArchitectural Design Rewriting), a rule-based formal framework for modelling\nthe evolution of architectures of systems.\n  The hierarchical nature of ADR allows us to take full advantage of the\ntree-like structure of the monitoring mechanism. We exploit this mechanism to\nformally define new rewriting mechanisms for ADR reconfiguration rules. Also,\nby monitoring the evolution we propose a way of identifying which part of a\nsystem has been affected when unexpected run-time behaviours emerge. Moreover,\nwe propose a methodology to suggest reconfigurations that could potentially\nlead the system in a non-erroneous state.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 03:48:22 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Poyias", "Kyriakos", "", "University of Leicester, UK"], ["Tuosto", "Emilio", "", "University of Leicester, UK"]]}, {"id": "1310.4575", "submitter": "EPTCS", "authors": "Karl Palmskog (KTH Royal Institute of Technology), Mads Dam (KTH Royal\n  Institute of Technology), Andreas Lundblad (KTH Royal Institute of\n  Technology), Ali Jafari (Reykjavik University)", "title": "ABS-NET: Fully Decentralized Runtime Adaptation for Distributed Objects", "comments": "In Proceedings ICE 2013, arXiv:1310.4019", "journal-ref": "EPTCS 131, 2013, pp. 85-100", "doi": "10.4204/EPTCS.131.8", "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a formalized, fully decentralized runtime semantics for a core\nsubset of ABS, a language and framework for modelling distributed\nobject-oriented systems. The semantics incorporates an abstract graph\nrepresentation of a network infrastructure, with network endpoints represented\nas graph nodes, and links as arcs with buffers, corresponding to OSI layer 2\ninterconnects. The key problem we wish to address is how to allocate\ncomputational tasks to nodes so that certain performance objectives are met. To\nthis end, we use the semantics as a foundation for performing network-adaptive\ntask execution via object migration between nodes. Adaptability is analyzed in\nterms of three Quality of Service objectives: node load, arc load and message\nlatency. We have implemented the key parts of our semantics in a simulator and\nevaluated how well objectives are achieved for some application-relevant\nchoices of network topology, migration procedure and ABS program. The\nevaluation suggests that it is feasible in a decentralized setting to\ncontinually meet both the objective of a node-balanced task allocation and make\nheadway towards minimizing communication, and thus arc load and message\nlatency.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 03:48:39 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Palmskog", "Karl", "", "KTH Royal Institute of Technology"], ["Dam", "Mads", "", "KTH Royal\n  Institute of Technology"], ["Lundblad", "Andreas", "", "KTH Royal Institute of\n  Technology"], ["Jafari", "Ali", "", "Reykjavik University"]]}, {"id": "1310.4595", "submitter": "EPTCS", "authors": "Keren Censor-Hillel (Technion), Valerie King (University of Victoria)", "title": "Proceedings Ninth International Workshop on Foundations of Mobile\n  Computing", "comments": null, "journal-ref": "EPTCS 132, 2013", "doi": "10.4204/EPTCS.132", "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile communication has become a vigorous field of research in computer\nscience, due to the wide spreading of mobile technologies, applications and\nservices. The intertwining of communication, computation and mobility\nconstantly poses new challenges to algorithmic design in this area. The\nFoundations of Mobile Computing (FOMC) workshop is dedicated to all aspects\nthat cover contributions both in the design and analysis of\ndiscrete/distributed algorithms, and in the system modeling of mobile, wireless\nand similarly dynamic networks. It aims to bring together the practitioners and\ntheoreticians of the field to foster cooperation between research in mobile\ncomputing and algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 07:16:35 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Censor-Hillel", "Keren", "", "Technion"], ["King", "Valerie", "", "University of Victoria"]]}, {"id": "1310.4645", "submitter": "Bradley Lowery", "authors": "Bradley R. Lowery and Julien Langou", "title": "A Greedy Algorithm for Optimally Pipelining a Reduction", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collective communications are ubiquitous in parallel applications. We present\ntwo new algorithms for performing a reduction. The operation associated with\nour reduction needs to be associative and commutative. The two algorithms are\ndeveloped under two different communication models (unidirectional and\nbidirectional). Both algorithms use a greedy scheduling scheme. For a\nunidirectional, fully connected network, we prove that our greedy algorithm is\noptimal when some realistic assumptions are respected. Previous algorithms fit\nthe same assumptions and are only appropriate for some given configurations.\nOur algorithm is optimal for all configurations. We note that there are some\nconfiguration where our greedy algorithm significantly outperform any existing\nalgorithms. This result represents a contribution to the state-of-the art. For\na bidirectional, fully connected network, we present a different greedy\nalgorithm. We verify by experimental simulations that our algorithm matches the\ntime complexity of an optimal broadcast (with addition of the computation).\nBeside reversing an optimal broadcast algorithm, the greedy algorithm is the\nfirst known reduction algorithm to experimentally attain this time complexity.\nSimulations show that this greedy algorithm performs well in practice,\noutperforming any state-of-the-art reduction algorithms. Positive experiments\non a parallel distributed machine are also presented.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 10:12:25 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Lowery", "Bradley R.", ""], ["Langou", "Julien", ""]]}, {"id": "1310.4664", "submitter": "Burak Bayramli", "authors": "Burak Bayramli", "title": "SVD Factorization for Tall-and-Fat Matrices on Map/Reduce Architectures", "comments": "There are mistakes in the approach", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  We demonstrate an implementation for an approximate rank-k SVD factorization,\ncombining well-known randomized projection techniques with previously\nimplemented map/reduce solutions in order to compute steps of the random\nprojection based SVD procedure, such QR and SVD. We structure the problem in a\nway that it reduces to Cholesky and SVD factorizations on $k \\times k$ matrices\ncomputed on a single machine, greatly easing the computability of the problem.\n", "versions": [{"version": "v1", "created": "Thu, 17 Oct 2013 11:52:26 GMT"}, {"version": "v2", "created": "Sun, 20 Oct 2013 14:21:06 GMT"}, {"version": "v3", "created": "Thu, 7 Nov 2013 07:26:57 GMT"}, {"version": "v4", "created": "Tue, 19 Nov 2013 14:03:53 GMT"}, {"version": "v5", "created": "Mon, 15 Sep 2014 09:16:26 GMT"}, {"version": "v6", "created": "Wed, 17 Sep 2014 06:57:10 GMT"}, {"version": "v7", "created": "Wed, 25 Oct 2017 07:10:30 GMT"}], "update_date": "2017-10-26", "authors_parsed": [["Bayramli", "Burak", ""]]}, {"id": "1310.4702", "submitter": "Jason Resch", "authors": "Jason Resch, Ilya Volvovski", "title": "Reliability Models for Highly Fault-tolerant Storage Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We found that a reliability model commonly used to estimate\nMean-Time-To-Data-Loss (MTTDL), while suitable for modeling RAID 0 and RAID 5,\nfails to accurately model systems having a fault-tolerance greater than 1.\nTherefore, to model the reliability of RAID 6, Triple-Replication, or k-of-n\nsystems requires an alternate technique. In this paper, we explore some\nalternatives, and evaluate their efficacy by comparing their predictions to\nsimulations. Our main result is a new formula which more accurately models\nstorage system reliability.\n", "versions": [{"version": "v1", "created": "Wed, 2 Oct 2013 22:43:12 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Resch", "Jason", ""], ["Volvovski", "Ilya", ""]]}, {"id": "1310.4802", "submitter": "Xavier Martinez-Palau", "authors": "Xavier Martinez-Palau, David Dominguez-Sal, Reza Akbarinia, Patrick\n  Valduriez, Josep Llu\\'is Larriba-Pey", "title": "On Demand Memory Specialization for Distributed Graph Databases", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the DN-tree that is a data structure to build lossy\nsummaries of the frequent data access patterns of the queries in a distributed\ngraph data management system. These compact representations allow us an\nefficient communication of the data structure in distributed systems. We\nexploit this data structure with a new \\textit{Dynamic Data Partitioning}\nstrategy (DYDAP) that assigns the portions of the graph according to historical\ndata access patterns, and guarantees a small network communication and a\ncomputational load balance in distributed graph queries. This method is able to\nadapt dynamically to new workloads and evolve when the query distribution\nchanges. Our experiments show that DYDAP yields a throughput up to an order of\nmagnitude higher than previous methods based on cache specialization, in a\nvariety of scenarios, and the average response time of the system is divided by\ntwo.\n", "versions": [{"version": "v1", "created": "Wed, 16 Oct 2013 15:04:06 GMT"}], "update_date": "2013-10-18", "authors_parsed": [["Martinez-Palau", "Xavier", ""], ["Dominguez-Sal", "David", ""], ["Akbarinia", "Reza", ""], ["Valduriez", "Patrick", ""], ["Larriba-Pey", "Josep Llu\u00eds", ""]]}, {"id": "1310.4906", "submitter": "EPTCS", "authors": "Gokarna Sharma (Louisiana State University), Costas Busch (Louisiana\n  State University)", "title": "Distributed Queuing in Dynamic Networks", "comments": "In Proceedings FOMC 2013, arXiv:1310.4595", "journal-ref": "EPTCS 132, 2013, pp. 1-19", "doi": "10.4204/EPTCS.132.1", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of forming a distributed queue in the adversarial\ndynamic network model of Kuhn, Lynch, and Oshman (STOC 2010) in which the\nnetwork topology changes from round to round but the network stays connected.\nThis is a synchronous model in which network nodes are assumed to be fixed, the\ncommunication links for each round are chosen by an adversary, and nodes do not\nknow who their neighbors are for the current round before they broadcast their\nmessages. Queue requests may arrive over rounds at arbitrary nodes and the goal\nis to eventually enqueue them in a distributed queue. We present two algorithms\nthat give a total distributed ordering of queue requests in this model. We\nmeasure the performance of our algorithms through round complexity, which is\nthe total number of rounds needed to solve the distributed queuing problem. We\nshow that in 1-interval connected graphs, where the communication links change\narbitrarily between every round, it is possible to solve the distributed\nqueueing problem in O(nk) rounds using O(log n) size messages, where n is the\nnumber of nodes in the network and k <= n is the number of queue requests.\nFurther, we show that for more stable graphs, e.g. T-interval connected graphs\nwhere the communication links change in every T rounds, the distributed queuing\nproblem can be solved in O(n+ (nk/min(alpha,T))) rounds using the same O(log n)\nsize messages, where alpha > 0 is the concurrency level parameter that captures\nthe minimum number of active queue requests in the system in any round. These\nresults hold in any arbitrary (sequential, one-shot concurrent, or dynamic)\narrival of k queue requests in the system. Moreover, our algorithms ensure\ncorrectness in the sense that each queue request is eventually enqueued in the\ndistributed queue after it is issued and each queue request is enqueued exactly\nonce. We also provide an impossibility result for this distributed queuing\nproblem in this model. To the best of our knowledge, these are the first\nsolutions to the distributed queuing problem in adversarial dynamic networks.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 04:10:43 GMT"}], "update_date": "2013-10-21", "authors_parsed": [["Sharma", "Gokarna", "", "Louisiana State University"], ["Busch", "Costas", "", "Louisiana\n  State University"]]}, {"id": "1310.4907", "submitter": "EPTCS", "authors": "Liron Levin (Communication Systems Engineering Department, Ben-Gurion\n  University of the Negev, Israel), Dariusz R. Kowalski (Department of Computer\n  Science, University of Liverpool, UK), Michael Segal (Communication Systems\n  Engineering Department, Ben-Gurion University of the Negev, Israel)", "title": "Message and time efficient multi-broadcast schemes", "comments": "In Proceedings FOMC 2013, arXiv:1310.4595", "journal-ref": "EPTCS 132, 2013, pp. 21-37", "doi": "10.4204/EPTCS.132.3", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider message and time efficient broadcasting and multi-broadcasting in\nwireless ad-hoc networks, where a subset of nodes, each with a unique rumor,\nwish to broadcast their rumors to all destinations while minimizing the total\nnumber of transmissions and total time until all rumors arrive to their\ndestination. Under centralized settings, we introduce a novel approximation\nalgorithm that provides almost optimal results with respect to the number of\ntransmissions and total time, separately. Later on, we show how to efficiently\nimplement this algorithm under distributed settings, where the nodes have only\nlocal information about their surroundings. In addition, we show multiple\napproximation techniques based on the network collision detection capabilities\nand explain how to calibrate the algorithms' parameters to produce optimal\nresults for time and messages.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 04:10:54 GMT"}], "update_date": "2013-10-21", "authors_parsed": [["Levin", "Liron", "", "Communication Systems Engineering Department, Ben-Gurion\n  University of the Negev, Israel"], ["Kowalski", "Dariusz R.", "", "Department of Computer\n  Science, University of Liverpool, UK"], ["Segal", "Michael", "", "Communication Systems\n  Engineering Department, Ben-Gurion University of the Negev, Israel"]]}, {"id": "1310.4908", "submitter": "EPTCS", "authors": "John Augustine (Indian Institute of Technology Madras), Tejas Kulkarni\n  (Indian Institute of Technology Madras), Paresh Nakhe (Indian Institute of\n  Technology Madras), Peter Robinson (Nanyang Technological University)", "title": "Robust Leader Election in a Fast-Changing World", "comments": "In Proceedings FOMC 2013, arXiv:1310.4595", "journal-ref": "EPTCS 132, 2013, pp. 38-49", "doi": "10.4204/EPTCS.132.4", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of electing a leader among nodes in a highly dynamic\nnetwork where the adversary has unbounded capacity to insert and remove nodes\n(including the leader) from the network and change connectivity at will. We\npresent a randomized Las Vegas algorithm that (re)elects a leader in O(D\\log n)\nrounds with high probability, where D is a bound on the dynamic diameter of the\nnetwork and n is the maximum number of nodes in the network at any point in\ntime. We assume a model of broadcast-based communication where a node can send\nonly 1 message of O(\\log n) bits per round and is not aware of the receivers in\nadvance. Thus, our results also apply to mobile wireless ad-hoc networks,\nimproving over the optimal (for deterministic algorithms) O(Dn) solution\npresented at FOMC 2011. We show that our algorithm is optimal by proving that\nany randomized Las Vegas algorithm takes at least omega(D\\log n) rounds to\nelect a leader with high probability, which shows that our algorithm yields the\nbest possible (up to constants) termination time.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 04:11:02 GMT"}], "update_date": "2013-10-21", "authors_parsed": [["Augustine", "John", "", "Indian Institute of Technology Madras"], ["Kulkarni", "Tejas", "", "Indian Institute of Technology Madras"], ["Nakhe", "Paresh", "", "Indian Institute of\n  Technology Madras"], ["Robinson", "Peter", "", "Nanyang Technological University"]]}, {"id": "1310.4919", "submitter": "Veena Rawat", "authors": "Veena Rawat", "title": "Reducing Failure Probability of cloud storage services using\n  Multi-Clouds", "comments": "51 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Any information is valuable as long as it has related data. If related data\nare not put together, the information is meaningless as unrelated data has no\nvalue. The mapped information is required only by authenticated users. So there\nis no necessity to store related information together. If the relations of a\ndatabase are fragmented into chunks and these chunks are stored at different\ncloud service providers, it could prevent from any privacy breach and the data\nstored will be secure. It would also reduce the data transfer costs as the\nentire data is not always required, for e.g. during updates. Also, instead of\nstorage of chunks at a single CSP, if each chunk or fragment is stored at\nmultiple CSPs it ensures availability and also permits concurrent access.\nAdditionally, it would prevent financial loss during cloud outages and also\nprevent data lock-in. Replicating data chunks at multiple clouds situated at\ngeographically different locations would also have an additional decrease in\nresponse time. The work attempts to select multiple cloud service providers\nwithin a given budget so as to ensure maximum availability of data. The entire\ndata can be stored at each of the data centers selected depending on the budget\nwhen there is no security or privacy issue. Data can also be stored in chunks\nby replicating each data chunk at two or more cloud service providers.\nDifferent chunks can be replicated at different service providers. The work\nalso attempts to select various cloud service providers to ensure maximum valid\ndata chunks within a given budget.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 05:42:43 GMT"}], "update_date": "2013-10-21", "authors_parsed": [["Rawat", "Veena", ""]]}, {"id": "1310.4935", "submitter": "Tomasz Jurdzinski", "authors": "Tomasz Jurdzinski and Dariusz R. Kowalski and Krzysztof Lorys", "title": "Online Packet Scheduling under Adversarial Jamming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of scheduling packets of different lengths via a\ndirected communication link prone to jamming errors. Dynamic packet arrivals\nand errors are modelled by an adversary. We focus on estimating relative\nthroughput of online scheduling algorithms, that is, the ratio between the\nthroughputs achieved by the algorithm and the best scheduling for the same\narrival and error patterns. This framework allows more accurate analysis of\nperformance of online scheduling algorithms, even in worst-case arrival and\nerror scenarios. We design an online algorithm for scheduling packets of\narbitrary lengths, achieving optimal relative throughput in the range (1/3,1/2]\n(the exact value depends on packet lengths). In other words, for any arrival\nand jamming patterns, our solution gives throughput which is no more than c\ntimes worse than the best possible scheduling for these patters, where c in [2;\n3) is the inverse of relative throughput. Another algorithm we design makes use\nof additional resources in order to achieve relative throughput 1, that is, it\nachieves at least as high throughput as the best schedule without such\nresources, for any arrival and jamming patterns. More precisely, we show that\nif the algorithm can run with double speed, i.e., with twice higher frequency,\nthen its relative throughput is 1. This demonstrates that throughput of the\nbest online scheduling algorithms scales well with resource augmentation.\n  Keywords: Packet scheduling, Dynamic packet arrivals, Adversarial jamming,\nOnline algorithms, Relative throughput, Resource augmentation.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 08:00:06 GMT"}], "update_date": "2013-10-21", "authors_parsed": [["Jurdzinski", "Tomasz", ""], ["Kowalski", "Dariusz R.", ""], ["Lorys", "Krzysztof", ""]]}, {"id": "1310.5045", "submitter": "\\\"Omer Demirel", "authors": "\\\"Omer Demirel, Ihor Smal, Wiro Niessen, Erik Meijering, Ivo F.\n  Sbalzarini", "title": "PPF - A Parallel Particle Filtering Library", "comments": "8 pages, 8 figures; will appear in the proceedings of the IET Data\n  Fusion & Target Tracking Conference 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the parallel particle filtering (PPF) software library, which\nenables hybrid shared-memory/distributed-memory parallelization of particle\nfiltering (PF) algorithms combining the Message Passing Interface (MPI) with\nmultithreading for multi-level parallelism. The library is implemented in Java\nand relies on OpenMPI's Java bindings for inter-process communication. It\nincludes dynamic load balancing, multi-thread balancing, and several\nalgorithmic improvements for PF, such as input-space domain decomposition. The\nPPF library hides the difficulties of efficient parallel programming of PF\nalgorithms and provides application developers with the necessary tools for\nparallel implementation of PF methods. We demonstrate the capabilities of the\nPPF library using two distributed PF algorithms in two scenarios with different\nnumbers of particles. The PPF library runs a 38 million particle problem,\ncorresponding to more than 1.86 GB of particle data, on 192 cores with 67%\nparallel efficiency. To the best of our knowledge, the PPF library is the first\nopen-source software that offers a parallel framework for PF applications.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 14:55:38 GMT"}, {"version": "v2", "created": "Fri, 4 Apr 2014 13:07:47 GMT"}], "update_date": "2014-04-07", "authors_parsed": [["Demirel", "\u00d6mer", ""], ["Smal", "Ihor", ""], ["Niessen", "Wiro", ""], ["Meijering", "Erik", ""], ["Sbalzarini", "Ivo F.", ""]]}, {"id": "1310.5182", "submitter": "Robert B. Gramacy", "authors": "Robert B. Gramacy, Jarad Niemi, Robin M. Weiss", "title": "Massively parallel approximate Gaussian process regression", "comments": "24 pages, 6 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.CO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explore how the big-three computing paradigms -- symmetric multi-processor\n(SMC), graphical processing units (GPUs), and cluster computing -- can together\nbe brought to bare on large-data Gaussian processes (GP) regression problems\nvia a careful implementation of a newly developed local approximation scheme.\nOur methodological contribution focuses primarily on GPU computation, as this\nrequires the most care and also provides the largest performance boost.\nHowever, in our empirical work we study the relative merits of all three\nparadigms to determine how best to combine them. The paper concludes with two\ncase studies. One is a real data fluid-dynamics computer experiment which\nbenefits from the local nature of our approximation; the second is a synthetic\ndata example designed to find the largest design for which (accurate) GP\nemulation can performed on a commensurate predictive set under an hour.\n", "versions": [{"version": "v1", "created": "Fri, 18 Oct 2013 23:13:59 GMT"}, {"version": "v2", "created": "Wed, 4 Jun 2014 15:01:38 GMT"}], "update_date": "2014-06-05", "authors_parsed": [["Gramacy", "Robert B.", ""], ["Niemi", "Jarad", ""], ["Weiss", "Robin M.", ""]]}, {"id": "1310.5255", "submitter": "Olivier Beaumont", "authors": "Olivier Beaumont (INRIA Bordeaux - Sud-Ouest, LaBRI), Lionel\n  Eyraud-Dubois (INRIA Bordeaux - Sud-Ouest, LaBRI), Paul Renaud-Goud (INRIA\n  Bordeaux - Sud-Ouest, LaBRI)", "title": "Efficient and Robust Allocation Algorithms in Clouds under Memory\n  Constraints", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider robust resource allocation of services in Clouds. More\nspecifically, we consider the case of a large public or private Cloud platform\nthat runs a relatively small set of large and independent services. These\nservices are characterized by their demand along several dimensions (CPU,\nmemory,...) and by their quality of service requirements, that have been\ndefined through an SLA in the case of a public Cloud or fixed by the\nadministrator in the case of a private Cloud. This quality of service defines\nthe required robustness of the service, by setting an upper limit on the\nprobability that the provider fails to allocate the required quantity of\nresources. This maximum probability of failure can be transparently turned into\na pair (price,penalty). Failures can indeed hit the platform, and resilience is\nprovided through service replication. Our contribution is two-fold. First, we\npropose a resource allocation strategy whose complexity is logarithmic in the\nnumber of resources, what makes it very efficient for large platforms. Second,\nwe propose an efficient algorithm based on rare events detection techniques in\norder to estimate the robustness of an allocation, a problem that has been\nproven to be P-complete. Finally, we provide an analysis of the proposed\nstrategy through an extensive set of simulations, both in terms of the overall\nnumber of allocated resources and in terms of time necessary to compute the\nallocation.\n", "versions": [{"version": "v1", "created": "Sat, 19 Oct 2013 17:32:17 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Beaumont", "Olivier", "", "INRIA Bordeaux - Sud-Ouest, LaBRI"], ["Eyraud-Dubois", "Lionel", "", "INRIA Bordeaux - Sud-Ouest, LaBRI"], ["Renaud-Goud", "Paul", "", "INRIA\n  Bordeaux - Sud-Ouest, LaBRI"]]}, {"id": "1310.5407", "submitter": "Anisur Molla Rahaman", "authors": "Atish Das Sarma, Anisur Rahaman Molla, Gopal Pandurangan", "title": "Distributed Computation of Sparse Cuts", "comments": "19 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding sparse cuts is an important tool in analyzing large-scale distributed\nnetworks such as the Internet and Peer-to-Peer networks, as well as large-scale\ngraphs such as the web graph, online social communities, and VLSI circuits. In\ndistributed communication networks, they are useful for topology maintenance\nand for designing better search and routing algorithms.\n  In this paper, we focus on developing fast distributed algorithms for\ncomputing sparse cuts in networks. Given an undirected $n$-node network $G$\nwith conductance $\\phi$, the goal is to find a cut set whose conductance is\nclose to $\\phi$. We present two distributed algorithms that find a cut set with\nsparsity $\\tilde O(\\sqrt{\\phi})$ ($\\tilde{O}$ hides $\\polylog{n}$ factors).\nBoth our algorithms work in the CONGEST distributed computing model and output\na cut of conductance at most $\\tilde O(\\sqrt{\\phi})$ with high probability, in\n$\\tilde O(\\frac{1}{b}(\\frac{1}{\\phi} + n))$ rounds, where $b$ is balance of the\ncut of given conductance. In particular, to find a sparse cut of constant\nbalance, our algorithms take $\\tilde O(\\frac{1}{\\phi} + n)$ rounds.\n  Our algorithms can also be used to output a {\\em local} cluster, i.e., a\nsubset of vertices near a given source node, and whose conductance is within a\nquadratic factor of the best possible cluster around the specified node. Both\nour distributed algorithm can work without knowledge of the optimal $\\phi$\nvalue and hence can be used to find approximate conductance values both\nglobally and with respect to a given source node. We also give a lower bound on\nthe time needed for any distributed algorithm to compute any non-trivial sparse\ncut --- any distributed approximation algorithm (for any non-trivial\napproximation ratio) for computing sparsest cut will take $\\tilde\n\\Omega(\\sqrt{n} + D)$ rounds, where $D$ is the diameter of the graph.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 03:02:51 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Sarma", "Atish Das", ""], ["Molla", "Anisur Rahaman", ""], ["Pandurangan", "Gopal", ""]]}, {"id": "1310.5426", "submitter": "Evan Sparks", "authors": "Evan R. Sparks, Ameet Talwalkar, Virginia Smith, Jey Kottalam, Xinghao\n  Pan, Joseph Gonzalez, Michael J. Franklin, Michael I. Jordan, Tim Kraska", "title": "MLI: An API for Distributed Machine Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MLI is an Application Programming Interface designed to address the\nchallenges of building Machine Learn- ing algorithms in a distributed setting\nbased on data-centric computing. Its primary goal is to simplify the\ndevelopment of high-performance, scalable, distributed algorithms. Our initial\nresults show that, relative to existing systems, this interface can be used to\nbuild distributed implementations of a wide variety of common Machine Learning\nalgorithms with minimal complexity and highly competitive performance and\nscalability.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 04:58:11 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2013 22:08:12 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Sparks", "Evan R.", ""], ["Talwalkar", "Ameet", ""], ["Smith", "Virginia", ""], ["Kottalam", "Jey", ""], ["Pan", "Xinghao", ""], ["Gonzalez", "Joseph", ""], ["Franklin", "Michael J.", ""], ["Jordan", "Michael I.", ""], ["Kraska", "Tim", ""]]}, {"id": "1310.5603", "submitter": "Jie Yan", "authors": "Jie Yan, Guangming Tan, Ninghui Sun", "title": "GRE: A Graph Runtime Engine for Large-Scale Distributed Graph-Parallel\n  Applications", "comments": "12 pages, also submitted to PVLDB", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Large-scale distributed graph-parallel computing is challenging. On one hand,\ndue to the irregular computation pattern and lack of locality, it is hard to\nexpress parallelism efficiently. On the other hand, due to the scale-free\nnature, real-world graphs are hard to partition in balance with low cut. To\naddress these challenges, several graph-parallel frameworks including Pregel\nand GraphLab (PowerGraph) have been developed recently. In this paper, we\npresent an alternative framework, Graph Runtime Engine (GRE). While retaining\nthe vertex-centric programming model, GRE proposes two new abstractions: 1) a\nScatter-Combine computation model based on active message to exploit massive\nfined-grained edge-level parallelism, and 2) a Agent-Graph data model based on\nvertex factorization to partition and represent directed graphs. GRE is\nimplemented on commercial off-the-shelf multi-core cluster. We experimentally\nevaluate GRE with three benchmark programs (PageRank, Single Source Shortest\nPath and Connected Components) on real-world and synthetic graphs of millions\nbillion of vertices. Compared to PowerGraph, GRE shows 2.5~17 times better\nperformance on 8~16 machines (192 cores). Specifically, the PageRank in GRE is\nthe fastest when comparing to counterparts of other frameworks (PowerGraph,\nSpark,Twister) reported in public literatures. Besides, GRE significantly\noptimizes memory usage so that it can process a large graph of 1 billion\nvertices and 17 billion edges on our cluster with totally 768GB memory, while\nPowerGraph can only process less than half of this graph scale.\n", "versions": [{"version": "v1", "created": "Mon, 21 Oct 2013 15:32:16 GMT"}], "update_date": "2013-10-22", "authors_parsed": [["Yan", "Jie", ""], ["Tan", "Guangming", ""], ["Sun", "Ninghui", ""]]}, {"id": "1310.5839", "submitter": "Volker Weinberg", "authors": "David Brayford, Momme Allalen and Volker Weinberg", "title": "Extreme Scaling of Lattice Quantum Chromodynamics", "comments": "5 pages, 2 figures, talk given at the \"Extreme Scaling on SuperMUC\"\n  Minisymposium during ParCo 2013, International Conference on Parallel\n  Computing, 10-13 September 2013, Munich", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF hep-lat physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the complexity and size of challenges in science and engineering are\ncontinually increasing, it is highly important that applications are able to\nscale strongly to very large numbers of cores (>100,000 cores) to enable HPC\nsystems to be utilised efficiently. This paper presents results of strong\nscaling tests performed with an MPI only and a hybrid MPI + OpenMP version of\nthe Lattice QCD application BQCD on the European Tier-0 system SuperMUC at LRZ.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2013 08:48:03 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Brayford", "David", ""], ["Allalen", "Momme", ""], ["Weinberg", "Volker", ""]]}, {"id": "1310.5842", "submitter": "Jianbin Fang", "authors": "Jianbin Fang, Ana Lucia Varbanescu, Henk Sips, Lilun Zhang, Yonggang\n  Che, Chuanfu Xu", "title": "An Empirical Study of Intel Xeon Phi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With at least 50 cores, Intel Xeon Phi is a true many-core architecture.\nFeaturing fairly powerful cores, two cache levels, and very fast\ninterconnections, the Xeon Phi can get a theoretical peak of 1000 GFLOPs and\nover 240 GB/s. These numbers, as well as its flexibility - it can be used both\nas a coprocessor or as a stand-alone processor - are very tempting for parallel\napplications looking for new performance records.\n  In this paper, we present an empirical study of Xeon Phi, stressing its\nperformance limits and relevant performance factors, ultimately aiming to\npresent a simplified view of the machine for regular programmers in search for\nperformance.\n  To do so, we have micro-benchmarked the main hardware components of the\nprocessor - the cores, the memory hierarchies, the ring interconnect, and the\nPCIe connection. We show that, in ideal microbenchmarking conditions, the\nperformance that can be achieved is very close to the theoretical peak, as\ngiven in the official programmer's guide. We have also identified and\nquantified several causes for significant performance penalties. Our findings\nhave been captured in four optimization guidelines, and used to build a\nsimplified programmer's view of Xeon Phi, eventually enable the design and\nprototyping of applications on a functionality-based model of the architecture.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2013 08:53:15 GMT"}, {"version": "v2", "created": "Fri, 20 Dec 2013 09:05:07 GMT"}], "update_date": "2013-12-23", "authors_parsed": [["Fang", "Jianbin", ""], ["Varbanescu", "Ana Lucia", ""], ["Sips", "Henk", ""], ["Zhang", "Lilun", ""], ["Che", "Yonggang", ""], ["Xu", "Chuanfu", ""]]}, {"id": "1310.5985", "submitter": "Ruchir Gupta", "authors": "Ruchir Gupta, Abhijeet C. Maali, Yatindra Nath Singh", "title": "Adaptive Push-Then-Pull Gossip Algorithm for Scale-free Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real life networks are generally modelled as scale free networks. Information\ndiffusion in such networks in decentralised environment is a difficult and\nresource consuming affair. Gossip algorithms have come up as a good solution to\nthis problem. In this paper, we have proposed Adaptive First Push Then Pull\ngossip algorithm. We show that algorithm works with minimum cost when the\ntransition round to switch from Adaptive Push to Adaptive Pull is close to\nRound(log(N)). Furthermore, we compare our algorithm with Push, Pull and First\nPush Then Pull and show that the proposed algorithm is the most cost efficient\nin Scale Free networks.\n", "versions": [{"version": "v1", "created": "Tue, 22 Oct 2013 17:07:38 GMT"}], "update_date": "2013-10-23", "authors_parsed": [["Gupta", "Ruchir", ""], ["Maali", "Abhijeet C.", ""], ["Singh", "Yatindra Nath", ""]]}, {"id": "1310.6407", "submitter": "Burkhard C. Schipper", "authors": "Ido Ben-Zvi, Yoram Moses", "title": "The Shape of Reactive Coordination Tasks", "comments": "10 pages, Contributed talk presented at TARK 2013 (arXiv:1310.6382)\n  http://www.tark.org", "journal-ref": null, "doi": null, "report-no": "TARK/2013/p29", "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the interaction between knowledge, time and coordination\nin systems in which timing information is available. Necessary conditions are\ngiven for the causal structure in coordination problems consisting of\norchestrating a set of actions in a manner that satisfies a variety of temporal\nordering assumptions. Results are obtained in two main steps: A specification\nof coordination is shown to require epistemic properties, and the causal\nstructure required to obtain these properties is characterised via \"knowledge\ngain\" theorems. A new causal structure called a centibroom structure is\npresented, generalising previous causal structures for this model. It is shown\nto capture coordination tasks in which a sequence of clusters of events is\nperformed in linear order, while within each cluster all actions must take\nplace simultaneously. This form of coordination is shown to require the agents\nto gain a nested common knowledge of particular facts, which in turn requires a\ncentibroom. Altogether, the results presented provide a broad view of the\ncausal shape underlying partially ordered coordinated actions. This, in turn,\nprovides insight into and can enable the design of efficient solutions to the\ncoordination tasks in question.\n", "versions": [{"version": "v1", "created": "Wed, 23 Oct 2013 22:04:15 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Ben-Zvi", "Ido", ""], ["Moses", "Yoram", ""]]}, {"id": "1310.6502", "submitter": "Yingjie Shi", "authors": "Runlin Zhou, Yingjie Shi, Chunge Zhu, Fan Liu", "title": "AxPUE: Application Level Metrics for Power Usage Effectiveness in Data\n  Centers", "comments": "8 pages, 4 figures, The First Workshop on Big Data Benchmarks,\n  Performance Optimization, and Emerging hardware (BPOE 2013) In conjunction\n  with 2013 IEEE International Conference on Big Data (IEEE Big Data 2013)", "journal-ref": null, "doi": "10.1109/BigData.2013.6691705", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of data volume brings big challenges to the data center\ncomputing, and energy efficiency is one of the most concerned problems.\nResearchers from various fields are now proposing solutions to green the data\ncenter operations. Power usage effectiveness metric plays an important role in\nthe energy saving research. However, the exising usage effectiveness metrics\nfocus on measuring the relationship between the total facility energy consumed\nand the IT equipment energy consumed, without reflecting the energy efficiency\nof applications. In this paper, we analyze the requirements of\napplication-level metrics for power usage efficiency of the data centers, and\npropose two novel energy efficiency metrics to provide strong guidance and\nuseful insight to data center design and optimization. We conduct comprehensive\nexperiments in the practical data centers using BigDataBench, a big data\nbenchmark suite, and the results demonstrate the rationality and efficiency of\nAxPUE in measuring the actual computation energy consumption in data centers.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 07:09:50 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Zhou", "Runlin", ""], ["Shi", "Yingjie", ""], ["Zhu", "Chunge", ""], ["Liu", "Fan", ""]]}, {"id": "1310.6542", "submitter": "Martin Henze", "authors": "Michael Eggert, Roger H\\\"au{\\ss}ling, Martin Henze, Lars\n  Hermerschmidt, Ren\\'e Hummen, Daniel Kerpen, Antonio Navarro P\\'erez,\n  Bernhard Rumpe, Dirk Thi{\\ss}en, Klaus Wehrle", "title": "SensorCloud: Towards the Interdisciplinary Development of a Trustworthy\n  Platform for Globally Interconnected Sensors and Actuators", "comments": "14 pages, 3 figures, published as technical report of the Department\n  of Computer Science of RWTH Aachen University", "journal-ref": null, "doi": null, "report-no": "AIB-2013-13", "categories": "cs.DC cs.CR cs.CY cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although Cloud Computing promises to lower IT costs and increase users'\nproductivity in everyday life, the unattractive aspect of this new technology\nis that the user no longer owns all the devices which process personal data. To\nlower scepticism, the project SensorCloud investigates techniques to understand\nand compensate these adoption barriers in a scenario consisting of cloud\napplications that utilize sensors and actuators placed in private places. This\nwork provides an interdisciplinary overview of the social and technical core\nresearch challenges for the trustworthy integration of sensor and actuator\ndevices with the Cloud Computing paradigm. Most importantly, these challenges\ninclude i) ease of development, ii) security and privacy, and iii) social\ndimensions of a cloud-based system which integrates into private life. When\nthese challenges are tackled in the development of future cloud systems, the\nattractiveness of new use cases in a sensor-enabled world will considerably be\nincreased for users who currently do not trust the Cloud.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 09:51:18 GMT"}, {"version": "v2", "created": "Fri, 25 Oct 2013 09:41:32 GMT"}], "update_date": "2013-10-28", "authors_parsed": [["Eggert", "Michael", ""], ["H\u00e4u\u00dfling", "Roger", ""], ["Henze", "Martin", ""], ["Hermerschmidt", "Lars", ""], ["Hummen", "Ren\u00e9", ""], ["Kerpen", "Daniel", ""], ["P\u00e9rez", "Antonio Navarro", ""], ["Rumpe", "Bernhard", ""], ["Thi\u00dfen", "Dirk", ""], ["Wehrle", "Klaus", ""]]}, {"id": "1310.6546", "submitter": "Yingjie Shi", "authors": "Jing Quan, Yingjie Shi, Ming Zhao, Wei Yang", "title": "The Implications from Benchmarking Three Big Data Systems", "comments": "8 pages, 10 figures, The First Workshop on Big Data Benchmarks,\n  Performance Optimization, and Emerging hardware (BPOE 2013) In conjunction\n  with 2013 IEEE International Conference on Big Data (IEEE Big Data 2013)", "journal-ref": null, "doi": "10.1109/BigData.2013.6691706", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Along with today's data explosion and application diversification, a variety\nof hardware platforms for big data are emerging, attracting interests from both\nindustry and academia. The existing hardware platforms represent a wide range\nof implementation approaches, and different hardware platforms have different\nstrengths. In this paper, we conduct comprehensive evaluations on three\nrepresentative big data systems: Intel Xeon, Atom (low power processors), and\nmany-core Tilera using BigDataBench - a big data benchmark suite. Then we\nexplore the relative performance of the three implementation approaches by\nrunning BigDataBench, and provide strong guidance for the big data systems\nconstruction. Through our experiments, we have inferred that a big data system\nbased on specific hardware has different performance in the context of\ndifferent applications and data volumes. When we construct a system, we should\ntake into account not only the performance or energy consumption of the pure\nhardware, but also the characteristics of applications running on them. Data\nscale, application type and complexity should be considered comprehensively\nwhen researchers or architects plan to choose fundamental components for their\nbig data systems.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 10:12:07 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Quan", "Jing", ""], ["Shi", "Yingjie", ""], ["Zhao", "Ming", ""], ["Yang", "Wei", ""]]}, {"id": "1310.6564", "submitter": "J\\\"urgen M\\\"unch", "authors": "Nilay Oza (1), J\\\"urgen M\\\"unch (1), Juan Garbajosa (2), Agustin Yague\n  (3), Eloy Gonzalez Ortega (3) ((1) University of Helsinki, Finland, (2)\n  Universidad Politecnica Madrid, Spain, (3) Indra Software Labs, Spain)", "title": "Identifying Potential Risks and Benefits of Using Cloud in Distributed\n  Software Development", "comments": "11 pages, 2 figures. The final publication is available at\n  link.springer.com. Link:\n  http://link.springer.com/chapter/10.1007%2F978-3-642-39259-7_19\n  DOI:10.1007/978-3-642-39259-7_19", "journal-ref": "Proceedings of the 14th International Conference on\n  Product-Focused Software Development and Process Improvement (PROFES 2013),\n  LNCS 7983, Springer-Verlag, pp. 229-239, 2013", "doi": "10.1007/978-3-642-39259-7_19", "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud-based infrastructure has been increasingly adopted by the industry in\ndistributed software development (DSD) environments. Its proponents claim that\nits several benefits include reduced cost, increased speed and greater\nproductivity in software development. Empirical evaluations, however, are in\nthe nascent stage of examining both the benefits and the risks of cloud-based\ninfrastructure. The objective of this paper is to identify potential benefits\nand risks of using cloud in a DSD project conducted by teams based in Helsinki\nand Madrid. A cross-case qualitative analysis is performed based on focus\ngroups conducted at the Helsinki and Madrid sites. Participants' observations\nare used to supplement the analysis. The results of the analysis indicated that\nthe main benefits of using cloud are rapid development, continuous integration,\ncost savings, code sharing, and faster ramp-up. The key risks determined by the\nproject are dependencies, unavailability of access to the cloud, code\ncommitment and integration, technical debt, and additional support costs. The\nresults revealed that if such environments are not planned and set up\ncarefully, the benefits of using cloud in DSD projects might be overshadowed by\nthe risks associated with it.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 11:01:35 GMT"}], "update_date": "2013-10-25", "authors_parsed": [["Oza", "Nilay", ""], ["M\u00fcnch", "J\u00fcrgen", ""], ["Garbajosa", "Juan", ""], ["Yague", "Agustin", ""], ["Ortega", "Eloy Gonzalez", ""]]}, {"id": "1310.6670", "submitter": "Matteo Camilli M.Sc.", "authors": "Carlo Bellettini, Matteo Camilli, Lorenzo Capra, Mattia Monga", "title": "Distributed CTL Model Checking in the Cloud", "comments": "8 pages", "journal-ref": null, "doi": "10.1109/SYNASC.2014.52", "report-no": null, "categories": "cs.SE cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The recent extensive availability of \"big data\" platforms calls for a more\nwidespread adoption by the formal verification community. In fact, formal\nverification requires high performance data processing software for extracting\nknowledge from the unprecedented amount of data which come from analyzed\nsystems. Since cloud based computing resources have became easily accessible,\nthere is an opportunity for verification techniques and tools to undergo a deep\ntechnological transition to exploit the new available architectures. This has\ncreated an increasing interest in parallelizing and distributing verification\ntechniques. In this paper we introduce a distributed approach which exploits\ntechniques typically used by the \"big data\" community to enable verification of\nComputation Tree Logic (CTL) formulas on very large state spaces using\ndistributed systems and cloud computing facilities. The outcome of several\ntests performed on benchmark specifications are presented, thus showing the\nconvenience of the proposed approach.\n", "versions": [{"version": "v1", "created": "Thu, 24 Oct 2013 16:54:37 GMT"}], "update_date": "2015-02-16", "authors_parsed": [["Bellettini", "Carlo", ""], ["Camilli", "Matteo", ""], ["Capra", "Lorenzo", ""], ["Monga", "Mattia", ""]]}, {"id": "1310.7205", "submitter": "Moritz Schattka", "authors": "Moritz Schattka", "title": "Algorithms for Timed Consistency Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the major challenges in distributed systems is establishing\nconsistency among replicated data in a timely fashion. While the consistent\nordering of events has been extensively researched, the time span to reach a\nconsistent state is mostly considered an effect of the chosen consistency\nmodel, rather than being considered a parameter itself. This paper argues that\nit is possible to give guarantees on the timely consistency of an operation.\nSubsequent to an update the cloud and all connected clients will either be\nconsistent with the update within the defined upper bound of time or the update\nwill be returned. This paper suggests the respective algorithms and protocols\ncapable of producing such comprehensive Timed Consistency, as conceptually\nproposed by Torres-Rojas et al. The solution offers business customers an\nincreasing level of predictability and adjustability. The temporal certainty\nconcerning the execution makes the cloud a more attractive tool for\ntime-critical or mission-critical applications fearing the poor availability of\nStrong Consistency in cloud environments.\n", "versions": [{"version": "v1", "created": "Sun, 27 Oct 2013 15:39:18 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Schattka", "Moritz", ""]]}, {"id": "1310.7376", "submitter": "Rajib Das", "authors": "Rajib K Das", "title": "Eccentricity of the nodes of OTIS-cube and Enhanced OTIS-cube", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we have classified the nodes of OTIS-cube based on their\neccentricities. OTIS (optical transpose interconnection system) is a large\nscale optoelectronic computer architecture, proposed in \\cite{KMKE92}, that\nbenefit from both optical and electronic technologies. We show that radius and\ndiameter of OTIS-$Q_n$ is $n+1$ and $2n+1$ respectively. We also show that\naverage eccentricity of OTIS-cube is $(3n/2+1)$.\n  In \\cite{D05}, a variant of OTIS-cube, called Enhanced OTIS-cube\n(E-OTIS-$Q_n$) was proposed.\n  E-OTIS-$Q_n$ is regular of degree $n+1$ and maximally fault-tolerant.\n  In this paper we have given a classification of the nodes of E-OTIS cube and\nderived expressions for the eccentricities of the nodes in each class. Based on\nthese results we show that radius and diameter of E-OTIS-$Q_n$ is $n+1$ and\n$\\lfloor {4n+4/3} \\rfloor$ respectively. We have also computed the average\neccentricity of E-OTIS-$Q_n$ for values of $n$ upto 20.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2013 11:06:25 GMT"}], "update_date": "2013-10-29", "authors_parsed": [["Das", "Rajib K", ""]]}, {"id": "1310.7397", "submitter": "Wojciech Golab", "authors": "Wojciech Golab", "title": "Deconstructing Queue-Based Mutual Exclusion", "comments": null, "journal-ref": null, "doi": null, "report-no": "HPL-2012-100", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We formulate a modular approach to the design and analysis of a particular\nclass of mutual exclusion algorithms for shared memory multiprocessor systems.\nSpecifically, we consider algorithms that organize waiting processes into a\nqueue. Such algorithms can achieve O(1) remote memory reference (RMR)\ncomplexity, which minimizes (asymptotically) the amount of traffic through the\nprocessor-memory interconnect. We first describe a generic mutual exclusion\nalgorithm that relies on a linearizable implementation of a particular\nqueue-like data structure that we call MutexQueue. Next, we show two\nimplementations of MutexQueue using O(1) RMRs per operation based on\nsynchronization primitives commonly available in multiprocessors. These\nimplementations follow closely the queuing code embedded in previously\npublished mutual exclusion algorithms. We provide rigorous correctness proofs\nand RMR complexity analyses of the algorithms we present.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2013 12:18:39 GMT"}, {"version": "v2", "created": "Wed, 30 Oct 2013 01:50:48 GMT"}], "update_date": "2013-10-31", "authors_parsed": [["Golab", "Wojciech", ""]]}, {"id": "1310.7453", "submitter": "Francesco Versaci", "authors": "Francesco Versaci", "title": "OutFlank Routing: Increasing Throughput in Toroidal Interconnection\n  Networks", "comments": "9 pages, 5 figures, to be presented at ICPADS 2013", "journal-ref": null, "doi": "10.1109/ICPADS.2013.40", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new, deadlock-free, routing scheme for toroidal interconnection\nnetworks, called OutFlank Routing (OFR). OFR is an adaptive strategy which\nexploits non-minimal links, both in the source and in the destination nodes.\nWhen minimal links are congested, OFR deroutes packets to carefully chosen\nintermediate destinations, in order to obtain travel paths which are only an\nadditive constant longer than the shortest ones. Since routing performance is\nvery sensitive to changes in the traffic model or in the router parameters, an\naccurate discrete-event simulator of the toroidal network has been developed to\nempirically validate OFR, by comparing it against other relevant routing\nstrategies, over a range of typical real-world traffic patterns. On the\n16x16x16 (4096 nodes) simulated network OFR exhibits improvements of the\nmaximum sustained throughput between 14% and 114%, with respect to Adaptive\nBubble Routing.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2013 15:11:57 GMT"}], "update_date": "2014-05-22", "authors_parsed": [["Versaci", "Francesco", ""]]}, {"id": "1310.7556", "submitter": "Valerie Halyo", "authors": "V. Halyo, P. LeGresley, P. Lujan, V. Karpusenko, A. Vladimirov", "title": "First Evaluation of the CPU, GPGPU and MIC Architectures for Real Time\n  Particle Tracking based on Hough Transform at the LHC", "comments": "13 pages, 4 figures, Accepted to JINST", "journal-ref": null, "doi": "10.1088/1748-0221/9/04/P04005", "report-no": null, "categories": "physics.comp-ph cs.DC hep-ex", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent innovations focused around {\\em parallel} processing, either through\nsystems containing multiple processors or processors containing multiple cores,\nhold great promise for enhancing the performance of the trigger at the LHC and\nextending its physics program. The flexibility of the CMS/ATLAS trigger system\nallows for easy integration of computational accelerators, such as NVIDIA's\nTesla Graphics Processing Unit (GPU) or Intel's \\xphi, in the High Level\nTrigger. These accelerators have the potential to provide faster or more energy\nefficient event selection, thus opening up possibilities for new complex\ntriggers that were not previously feasible. At the same time, it is crucial to\nexplore the performance limits achievable on the latest generation multicore\nCPUs with the use of the best software optimization methods. In this article, a\nnew tracking algorithm based on the Hough transform will be evaluated for the\nfirst time on a multi-core Intel Xeon E5-2697v2 CPU, an NVIDIA Tesla K20c GPU,\nand an Intel \\xphi\\ 7120 coprocessor. Preliminary time performance will be\npresented.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2013 19:52:33 GMT"}, {"version": "v2", "created": "Sun, 3 Nov 2013 23:48:49 GMT"}, {"version": "v3", "created": "Mon, 3 Feb 2014 22:04:07 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Halyo", "V.", ""], ["LeGresley", "P.", ""], ["Lujan", "P.", ""], ["Karpusenko", "V.", ""], ["Vladimirov", "A.", ""]]}, {"id": "1310.7610", "submitter": "Adwaitvedant Mathkar", "authors": "Adwaitvedant S. Mathkar and Vivek S. Borkar", "title": "Distributed Reinforcement Learning via Gossip", "comments": "18 pages, 3 figures, Submitted to Discrete Event Dynamic Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the classical TD(0) algorithm implemented on a network of agents\nwherein the agents also incorporate the updates received from neighboring\nagents using a gossip-like mechanism. The combined scheme is shown to converge\nfor both discounted and average cost problems.\n", "versions": [{"version": "v1", "created": "Mon, 28 Oct 2013 20:23:57 GMT"}], "update_date": "2013-10-30", "authors_parsed": [["Mathkar", "Adwaitvedant S.", ""], ["Borkar", "Vivek S.", ""]]}, {"id": "1310.7801", "submitter": "Quang-Hung Nguyen", "authors": "Nguyen Quang-Hung, Nam Thoai, Nguyen Thanh Son", "title": "EPOBF: Energy Efficient Allocation of Virtual Machines in High\n  Performance Computing Cloud", "comments": "10 pages, in Procedings of International Conference on Advanced\n  Computing and Applications, Journal of Science and Technology, Vietnamese\n  Academy of Science and Technology, ISSN 0866-708X, Vol. 51, No. 4B, 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Cloud computing has become more popular in provision of computing resources\nunder virtual machine (VM) abstraction for high performance computing (HPC)\nusers to run their applications. A HPC cloud is such cloud computing\nenvironment. One of challenges of energy efficient resource allocation for VMs\nin HPC cloud is tradeoff between minimizing total energy consumption of\nphysical machines (PMs) and satisfying Quality of Service (e.g. performance).\nOn one hand, cloud providers want to maximize their profit by reducing the\npower cost (e.g. using the smallest number of running PMs). On the other hand,\ncloud customers (users) want highest performance for their applications. In\nthis paper, we focus on the scenario that scheduler does not know global\ninformation about user jobs and user applications in the future. Users will\nrequest shortterm resources at fixed start times and non interrupted durations.\nWe then propose a new allocation heuristic (named Energy-aware and Performance\nper watt oriented Bestfit (EPOBF)) that uses metric of performance per watt to\nchoose which most energy-efficient PM for mapping each VM (e.g. maximum of MIPS\nper Watt). Using information from Feitelson's Parallel Workload Archive to\nmodel HPC jobs, we compare the proposed EPOBF to state of the art heuristics on\nheterogeneous PMs (each PM has multicore CPU). Simulations show that the EPOBF\ncan reduce significant total energy consumption in comparison with state of the\nart allocation heuristics.\n", "versions": [{"version": "v1", "created": "Tue, 29 Oct 2013 13:42:01 GMT"}, {"version": "v2", "created": "Tue, 5 Nov 2013 04:49:00 GMT"}, {"version": "v3", "created": "Mon, 15 Sep 2014 01:54:45 GMT"}], "update_date": "2014-09-16", "authors_parsed": [["Quang-Hung", "Nguyen", ""], ["Thoai", "Nam", ""], ["Son", "Nguyen Thanh", ""]]}, {"id": "1310.8211", "submitter": "Erwan Le Merrer", "authors": "Le Merrer Erwan and Liang Yizhong and Tr\\'edan Gilles", "title": "(Re)partitioning for stream-enabled computation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partitioning an input graph over a set of workers is a complex operation.\nObjectives are twofold: split the work evenly, so that every worker gets an\nequal share, and minimize edge cut to achieve a good work locality (i.e.\nworkers can work independently). Partitioning a graph accessible from memory is\na notorious NP-complete problem. Motivated by the regain of interest for the\nstream processing paradigm (where nodes and edges arrive as a flow to the\ndatacenter), we propose in this paper a stream-enabled graph partitioning\nsystem that constantly seeks an optimum between those two objectives. We first\nexpose the hardness of partitioning using classic and static methods; we then\nexhibit the cut versus load balancing tradeoff, from an application point of\nview. With this tradeoff in mind, our approach translates the online\npartitioning problem into a standard optimization problem. A greedy algorithm\nhandles the stream of incoming graph updates while optimizations are triggered\non demand to improve upon the greedy decisions. Using simulations, we show that\nthis approach is very efficient, turning a basic optimization strategy such as\nhill climbing into an online partitioning solution that compares favorably to\nliterature's recent stream partitioning solutions.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2013 16:11:20 GMT"}, {"version": "v2", "created": "Wed, 27 Nov 2013 14:44:03 GMT"}], "update_date": "2013-11-28", "authors_parsed": [["Erwan", "Le Merrer", ""], ["Yizhong", "Liang", ""], ["Gilles", "Tr\u00e9dan", ""]]}, {"id": "1310.8232", "submitter": "Cristina Boeres", "authors": "Alexandre Sena and Aline Nascimento and Cristina Boeres and Vinod E.\n  F. Rebello and Andr\\'e Bulc\\~ao", "title": "Improving Memory Hierarchy Utilisation for Stencil Computations on\n  Multicore Machines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Although modern supercomputers are composed of multicore machines, one can\nfind scientists that still execute their legacy applications which were\ndeveloped to monocore cluster where memory hierarchy is dedicated to a sole\ncore. The main objective of this paper is to propose and evaluate an algorithm\nthat identify an efficient blocksize to be applied on MPI stencil computations\non multicore machines. Under the light of an extensive experimental analysis,\nthis work shows the benefits of identifying blocksizes that will dividing data\non the various cores and suggest a methodology that explore the memory\nhierarchy available in modern machines.\n", "versions": [{"version": "v1", "created": "Wed, 30 Oct 2013 17:02:56 GMT"}], "update_date": "2013-10-31", "authors_parsed": [["Sena", "Alexandre", ""], ["Nascimento", "Aline", ""], ["Boeres", "Cristina", ""], ["Rebello", "Vinod E. F.", ""], ["Bulc\u00e3o", "Andr\u00e9", ""]]}, {"id": "1310.8381", "submitter": "Edith Cohen", "authors": "Edith Cohen, Amos Fiat, Haim Kaplan, Liam Roditty", "title": "A Labeling Approach to Incremental Cycle Detection", "comments": "15 pages, one figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the \\emph{incremental cycle detection} problem arcs are added to a\ndirected acyclic graph and the algorithm has to report if the new arc closes a\ncycle. One seeks to minimize the total time to process the entire sequence of\narc insertions, or until a cycle appears.\n  In a recent breakthrough, Bender, Fineman, Gilbert and Tarjan\n\\cite{BeFiGiTa11} presented two different algorithms, with time complexity\n$O(n^2 \\log n)$ and $O(m \\cdot \\min \\{m^{1/2}, n^{2/3} \\})$, respectively.\n  In this paper we introduce a new technique for incremental cycle detection\nthat allows us to obtain both bounds (up to a logarithmic factor). Furthermore,\nour approach seems more amiable for distributed implementation.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2013 04:41:06 GMT"}], "update_date": "2013-11-01", "authors_parsed": [["Cohen", "Edith", ""], ["Fiat", "Amos", ""], ["Kaplan", "Haim", ""], ["Roditty", "Liam", ""]]}, {"id": "1310.8392", "submitter": "Geethu Thomas", "authors": "Geethu Thomas, Prem Jose V, P.Afsar", "title": "Cloud computing security using encryption technique", "comments": "7 Pages, 3 Figures. arXiv admin note: text overlap with\n  arXiv:1303.4814 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Computing has been envisioned as the next generation architecture of IT\nEnterprise. The Cloud computing concept offers dynamically scalable resources\nprovisioned as a service over the Internet. Economic benefits are the main\ndriver for the Cloud, since it promises the reduction of capital expenditure\nand operational expenditure. In order for this to become reality, however,\nthere are still some challenges to be solved. Most important among these are\nsecurity and trust issues,since the users data has to be released to the Cloud\nand thus leaves the protection sphere of the data owner.In contrast to\ntraditional solutions, where the IT services are under proper physical,logical\nand personnel controls, Cloud Computing moves the application software and\ndatabases to the large data centers, where the management of the data and\nservices may not be fully trustworthy. This unique attribute, however, poses\nmany new security challenges which have not been well understood. Security is\nto save data from danger and vulnerability. There are so many dangers and\nvulnerabilities to be handled. Various security issues and some of their\nsolution are explained and are concentrating mainly on public cloud security\nissues and their solutions. Data should always be encrypted when stored(using\nseparate symmetric encryption keys)and transmitted. If this is implemented\nappropriately, even if another tenant can access the data, all that will appear\nis gibberish. So a method is proposed such that we are encrypting the whole\ndata along with the cryptographic key.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2013 06:11:24 GMT"}], "update_date": "2013-11-01", "authors_parsed": [["Thomas", "Geethu", ""], ["Jose", "Prem", "V"], ["Afsar", "P.", ""]]}, {"id": "1310.8456", "submitter": "Guillaume Aupy", "authors": "Guillaume Aupy, Anne Benoit, Thomas H\\'erault, Yves Robert and Jack\n  Dongarra", "title": "Optimal Checkpointing Period: Time vs. Energy", "comments": "To be published in PMBS'13 (satellite workshop of SC'13). This work\n  was supported in part by ANR RESCUE", "journal-ref": null, "doi": null, "report-no": "Inria RR-8387", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short paper deals with parallel scientific applications using\nnon-blocking and periodic coordinated checkpointing to enforce resilience. We\nprovide a model and detailed formulas for total execution time and consumed\nenergy. We characterize the optimal period for both objectives, and we assess\nthe range of time/energy trade-offs to be made by instantiating the model with\na set of realistic scenarios for Exascale systems. We give a particular\nemphasis to I/O transfers, because the relative cost of communication is\nexpected to dramatically increase, both in terms of latency and consumed\nenergy, for future Exascale platforms.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2013 10:57:39 GMT"}], "update_date": "2013-11-01", "authors_parsed": [["Aupy", "Guillaume", ""], ["Benoit", "Anne", ""], ["H\u00e9rault", "Thomas", ""], ["Robert", "Yves", ""], ["Dongarra", "Jack", ""]]}, {"id": "1310.8478", "submitter": "Pier Stanislao Paolucci", "authors": "Pier Stanislao Paolucci, Roberto Ammendola, Andrea Biagioni, Ottorino\n  Frezza, Francesca Lo Cicero, Alessandro Lonardo, Elena Pastorelli, Francesco\n  Simula, Laura Tosoratto, Piero Vicini", "title": "Distributed simulation of polychronous and plastic spiking neural\n  networks: strong and weak scaling of a representative mini-application\n  benchmark executed on a small-scale commodity cluster", "comments": "Added detailed profiling of computational and communication\n  components. Improved speed and size of simulated networks. 15 pages, 5\n  figures, 3 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a natively distributed mini-application benchmark representative\nof plastic spiking neural network simulators. It can be used to measure\nperformances of existing computing platforms and to drive the development of\nfuture parallel/distributed computing systems dedicated to the simulation of\nplastic spiking networks. The mini-application is designed to generate spiking\nbehaviors and synaptic connectivity that do not change when the number of\nhardware processing nodes is varied, simplifying the quantitative study of\nscalability on commodity and custom architectures. Here, we present the strong\nand weak scaling and the profiling of the computational/communication\ncomponents of the DPSNN-STDP benchmark (Distributed Simulation of Polychronous\nSpiking Neural Network with synaptic Spike-Timing Dependent Plasticity). In\nthis first test, we used the benchmark to exercise a small-scale cluster of\ncommodity processors (varying the number of used physical cores from 1 to 128).\nThe cluster was interconnected through a commodity network. Bidimensional grids\nof columns composed of Izhikevich neurons projected synapses locally and toward\nfirst, second and third neighboring columns. The size of the simulated network\nvaried from 6.6 Giga synapses down to 200 K synapses. The code demonstrated to\nbe fast and scalable: 10 wall clock seconds were required to simulate one\nsecond of activity and plasticity (per Hertz of average firing rate) of a\nnetwork composed by 3.2 G synapses running on 128 hardware cores clocked @ 2.4\nGHz. The mini-application has been designed to be easily interfaced with\nstandard and custom software and hardware communication interfaces. It has been\ndesigned from its foundation to be natively distributed and parallel, and\nshould not pose major obstacles against distribution and parallelization on\nseveral platforms.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2013 12:44:20 GMT"}, {"version": "v2", "created": "Mon, 14 Apr 2014 14:01:42 GMT"}], "update_date": "2014-04-15", "authors_parsed": [["Paolucci", "Pier Stanislao", ""], ["Ammendola", "Roberto", ""], ["Biagioni", "Andrea", ""], ["Frezza", "Ottorino", ""], ["Cicero", "Francesca Lo", ""], ["Lonardo", "Alessandro", ""], ["Pastorelli", "Elena", ""], ["Simula", "Francesco", ""], ["Tosoratto", "Laura", ""], ["Vicini", "Piero", ""]]}, {"id": "1310.8486", "submitter": "Guillaume Aupy", "authors": "Guillaume Aupy, Anne Benoit, Thomas H\\'erault, Yves Robert,\n  Fr\\'ed\\'eric Vivien and Dounia Zaidouni", "title": "On the Combination of Silent Error Detection and Checkpointing", "comments": "This work was accepted to be published in PRDC'13. Work supported by\n  ANR Rescue", "journal-ref": null, "doi": null, "report-no": "INRIA RR-8319", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit traditional checkpointing and rollback recovery\nstrategies, with a focus on silent data corruption errors. Contrarily to\nfail-stop failures, such latent errors cannot be detected immediately, and a\nmechanism to detect them must be provided. We consider two models: (i) errors\nare detected after some delays following a probability distribution (typically,\nan Exponential distribution); (ii) errors are detected through some\nverification mechanism. In both cases, we compute the optimal period in order\nto minimize the waste, i.e., the fraction of time where nodes do not perform\nuseful computations. In practice, only a fixed number of checkpoints can be\nkept in memory, and the first model may lead to an irrecoverable failure. In\nthis case, we compute the minimum period required for an acceptable risk. For\nthe second model, there is no risk of irrecoverable failure, owing to the\nverification mechanism, but the corresponding overhead is included in the\nwaste. Finally, both models are instantiated using realistic scenarios and\napplication/architecture parameters.\n", "versions": [{"version": "v1", "created": "Thu, 31 Oct 2013 13:08:08 GMT"}], "update_date": "2013-11-01", "authors_parsed": [["Aupy", "Guillaume", ""], ["Benoit", "Anne", ""], ["H\u00e9rault", "Thomas", ""], ["Robert", "Yves", ""], ["Vivien", "Fr\u00e9d\u00e9ric", ""], ["Zaidouni", "Dounia", ""]]}]