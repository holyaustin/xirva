[{"id": "1506.00074", "submitter": "Yibin Huang", "authors": "Yi-bin Huang, Kang Li, Ge Wang, Min Cao, Pin Li, Yu-jia Zhang", "title": "Recognition of convolutional neural network based on CUDA Technology", "comments": "The novelty is too limited, we don't want to mislead others anymore", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  For the problem whether Graphic Processing Unit(GPU),the stream processor\nwith high performance of floating-point computing is applicable to neural\nnetworks, this paper proposes the parallel recognition algorithm of\nConvolutional Neural Networks(CNNs).It adopts Compute Unified Device\nArchitecture(CUDA)technology, definite the parallel data structures, and\ndescribes the mapping mechanism for computing tasks on CUDA. It compares the\nparallel recognition algorithm achieved on GPU of GTX200 hardware architecture\nwith the serial algorithm on CPU. It improves speed by nearly 60 times. Result\nshows that GPU based the stream processor architecture ate more applicable to\nsome related applications about neural networks than CPU.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2015 05:38:00 GMT"}, {"version": "v2", "created": "Mon, 27 Aug 2018 14:48:55 GMT"}], "update_date": "2018-08-28", "authors_parsed": [["Huang", "Yi-bin", ""], ["Li", "Kang", ""], ["Wang", "Ge", ""], ["Cao", "Min", ""], ["Li", "Pin", ""], ["Zhang", "Yu-jia", ""]]}, {"id": "1506.00130", "submitter": "Guo Qing Pei", "authors": "Qingpei Guo, Chao Xu, Yang Song", "title": "The Implementation of Hadoop-based Crawler System and Graphlite-based\n  PageRank-Calculation In Search Engine", "comments": "8 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, the size of the Internet is experiencing rapid growth. As of\nDecember 2014, the number of global Internet websites has more than 1 billion\nand all kinds of information resources are integrated together on the Internet,\nhowever,the search engine is to be a necessary tool for all users to retrieve\nuseful information from vast amounts of web data. Generally speaking, a\ncomplete search engine includes the crawler system, index building systems,\nsorting systems and retrieval system. At present there are many open source\nimplementation of search engine, such as lucene, solr, katta, elasticsearch,\nsolandra and so on. The crawler system and sorting system is indispensable for\nany kind of search engine and in order to guarantee its efficiency, the former\nneeds to update crawled vast amounts of data and the latter requires real-time\nto build index on newly crawled web pages and calculae its corresponding\nPageRank value. It is unlikely to accomplish such huge computation tasks\ndepending on a single hardware implementation of the crawler system and sorting\nsystem,from which aspect, the distributed cluster technology is brought to the\nfront. In this paper, we use the hadoop Map - Reduce computing framework to\nimplement a distributed crawler system, and use the GraphLite, a distributed\nsynchronous graph-computing framework, to achieve the real-time computation in\ngetting the PageRank value of the new crawled web page.\n", "versions": [{"version": "v1", "created": "Sat, 30 May 2015 15:44:58 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Guo", "Qingpei", ""], ["Xu", "Chao", ""], ["Song", "Yang", ""]]}, {"id": "1506.00204", "submitter": "Xiao Lv", "authors": "Zhuang Wang, Xiao Lv, Mingyu Yan, Wei Yang, Ge Li", "title": "Fair Packet Scheduling in Network on Chip", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interconnection networks of parallel systems are used for servicing traf- fic\ngenerated by different applications, often belonging to different users. When\nmultiple traffic flows contend for channel bandwidth, the scheduling algorithm\nregulating the access to that channel plays a key role in ensur- ing that each\nflow obtains the required quality of service. Fairness is a highly desirable\nproperty for a scheduling algorithm. We show that using the Relative Fairness\nBound as a fairness measure may lead to decrease in throughput and increase in\nlatency. We propose an alternative metric to evaluate the fairness and avoid\nthe drawback of Relative Fairness Bound.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 08:52:34 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Wang", "Zhuang", ""], ["Lv", "Xiao", ""], ["Yan", "Mingyu", ""], ["Yang", "Wei", ""], ["Li", "Ge", ""]]}, {"id": "1506.00227", "submitter": "YaJun Cui", "authors": "Yajun Cui, Yang Zhao, Kafei Xiao, Chenglong Zhang, Lei Wang", "title": "Parallel Spectral Clustering Algorithm Based on Hadoop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spectral clustering and cloud computing is emerging branch of computer\nscience or related discipline. It overcome the shortcomings of some traditional\nclustering algorithm and guarantee the convergence to the optimal solution,\nthus have to the widespread attention. This article first introduced the\nparallel spectral clustering algorithm research background and significance,\nand then to Hadoop the cloud computing Framework has carried on the detailed\nintroduction, then has carried on the related to spectral clustering is\nintroduced, then introduces the spectral clustering arithmetic Method of\nparallel and relevant steps, finally made the related experiments, and the\nexperiment are summarized.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 13:39:41 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Cui", "Yajun", ""], ["Zhao", "Yang", ""], ["Xiao", "Kafei", ""], ["Zhang", "Chenglong", ""], ["Wang", "Lei", ""]]}, {"id": "1506.00272", "submitter": "Andre Merzky", "authors": "Andre Merzky and Shantenu Jha", "title": "Synapse: Synthetic Application Profiler and Emulator", "comments": null, "journal-ref": "2016 IEEE International Parallel and Distributed Processing\n  Symposium Workshops, Chicago, IL, USA, May 23-27, 2016", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce Synapse motivated by the needs to estimate and emulate workload\nexecution characteristics on high-performance and distributed heterogeneous\nresources. Synapse has a platform independent application profiler, and the\nability to emulate profiled workloads on a variety of heterogeneous resources.\nSynapse is used as a proxy application (or \"representative application\") for\nreal workloads, with the added advantage that it can be tuned at arbitrary\nlevels of granularity in ways that are simply not possible using real\napplications. Experiments show that automated profiling using Synapse\nrepresents application characteristics with high fidelity. Emulation using\nSynapse can reproduce the application behavior in the original runtime\nenvironment, as well as reproducing properties when used in a different\nrun-time environments.\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 19:02:02 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2016 03:11:53 GMT"}, {"version": "v3", "created": "Mon, 15 Feb 2016 11:31:48 GMT"}], "update_date": "2018-08-03", "authors_parsed": [["Merzky", "Andre", ""], ["Jha", "Shantenu", ""]]}, {"id": "1506.00290", "submitter": "Ilan Komargodski", "authors": "Yael Tauman Kalai and Ilan Komargodski", "title": "Compressing Communication in Distributed Protocols", "comments": "21 pages + 1 title page", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show how to compress communication in selection protocols, where the goal\nis to agree on a sequence of random bits using only a broadcast channel. More\nspecifically, we present a generic method for converting any selection\nprotocol, into another selection protocol where each message is ``short'' while\npreserving the same number of rounds, the same output distribution, and the\nsame resilience to error. Assuming that the output of the protocol lies in some\nuniverse of size $M$, in our resulting protocol each message consists of only\n$\\mathsf{polylog}(M,n,d)$ many bits, where $n$ is the number of parties and $d$\nis the number of rounds. Our transformation works in the presence of either\nstatic or adaptive Byzantine faults.\n  As a corollary, we conclude that for any $\\mathsf{poly}(n)$-round collective\ncoin-flipping protocol, leader election protocol, or general selection\nprotocols, messages of length $\\mathsf{polylog}(n)$ suffice (in the presence of\neither static or adaptive Byzantine faults).\n", "versions": [{"version": "v1", "created": "Sun, 31 May 2015 21:00:39 GMT"}, {"version": "v2", "created": "Tue, 4 Aug 2015 10:18:20 GMT"}, {"version": "v3", "created": "Thu, 10 May 2018 19:14:51 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Kalai", "Yael Tauman", ""], ["Komargodski", "Ilan", ""]]}, {"id": "1506.00391", "submitter": "Nitinder Mohan", "authors": "Nitinder Mohan and Pushpendra Singh", "title": "CCNCheck: Enabling Checkpointed Distributed Applications in Content\n  Centric Networks", "comments": "2 pages technical talk abstract, CCNxCon-2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of checkpointing a distributed application\nefficiently in Content Centric Networks so that it can withstand transient\nfailures. We present CCNCheck, a system which enables a sender optimized way of\ncheckpointing distributed applications in CCN's and provides an efficient\nmechanism for failure recovery in such applications. CCNCheck's checkpointing\nmechanism is a fork of DMTCP repository CCNCheck is capable of running any\ndistributed application written in C/C++ language.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 08:43:55 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Mohan", "Nitinder", ""], ["Singh", "Pushpendra", ""]]}, {"id": "1506.00425", "submitter": "Bo Jiang", "authors": "Bo Jiang and Jiaying Wu and Xiuyu Shi and Ruhuan Huang", "title": "Hadoop Scheduling Base On Data Locality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In hadoop, the job scheduling is an independent module, users can design\ntheir own job scheduler based on their actual application requirements, thereby\nmeet their specific business needs. Currently, hadoop has three schedulers:\nFIFO, computing capacity scheduling and fair scheduling policy, all of them are\ntake task allocation strategy that considerate data locality simply. They\nneither support data locality well nor fully apply to all cases of jobs\nscheduling. In this paper, we took the concept of resources-prefetch into\nconsideration, and proposed a job scheduling algorithm based on data locality.\nBy estimate the remaining time to complete a task, compared with the time to\ntransfer a resources block, to preselect candidate nodes for task allocation.\nThen we preselect a non-local map tasks from the unfinished job queue as\nresources-prefetch tasks. Getting information of resources blocks of\npreselected map task, select a nearest resources blocks from the candidate node\nand transferred to local through network. Thus we would ensure data locality\ngood enough. Eventually, we design a experiment and proved resources-prefetch\nmethod can guarantee good job data locality and reduce the time to complete the\njob to a certain extent.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 10:25:09 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Jiang", "Bo", ""], ["Wu", "Jiaying", ""], ["Shi", "Xiuyu", ""], ["Huang", "Ruhuan", ""]]}, {"id": "1506.00449", "submitter": "Longlong Tian", "authors": "Zhuo Wang, Longlong Tian, Dianjie Guo, Xiaoming Jiang", "title": "Optimization and analysis of large scale data sorting algorithm based on\n  Hadoop", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When dealing with massive data sorting, we usually use Hadoop which is a\nframework that allows for the distributed processing of large data sets across\nclusters of computers using simple programming models. A common approach in\nimplement of big data sorting is to use shuffle and sort phase in MapReduce\nbased on Hadoop. However, if we use it directly, the efficiency could be very\nlow and the load imbalance can be a big problem. In this paper we carry out an\nexperimental study of an optimization and analysis of large scale data sorting\nalgorithm based on hadoop. In order to reach optimization, we use more than 2\nrounds MapReduce. In the first round, we use a MapReduce to take sample\nrandomly. Then we use another MapReduce to order the data uniformly, according\nto the results of the first round. If the data is also too big, it will turn\nback to the first round and keep on. The experiments show that, it is better to\nuse the optimized algorithm than shuffle of MapReduce to sort large scale data.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 11:23:20 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Wang", "Zhuo", ""], ["Tian", "Longlong", ""], ["Guo", "Dianjie", ""], ["Jiang", "Xiaoming", ""]]}, {"id": "1506.00485", "submitter": "Adam Barker", "authors": "Adam Barker, Blesson Varghese and Long Thai", "title": "Cloud Services Brokerage: A Survey and Research Roadmap", "comments": "Paper published in the 8th IEEE International Conference on Cloud\n  Computing (CLOUD 2015)", "journal-ref": null, "doi": "10.1109/CLOUD.2015.144", "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Cloud Services Brokerage (CSB) acts as an intermediary between cloud\nservice providers (e.g., Amazon and Google) and cloud service end users,\nproviding a number of value adding services. CSBs as a research topic are in\nthere infancy. The goal of this paper is to provide a concise survey of\nexisting CSB technologies in a variety of areas and highlight a roadmap, which\ndetails five future opportunities for research.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 13:21:31 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Barker", "Adam", ""], ["Varghese", "Blesson", ""], ["Thai", "Long", ""]]}, {"id": "1506.00590", "submitter": "Long Thai MSc", "authors": "Long Thai, Blesson Varghese, Adam Barker", "title": "Executing Bag of Distributed Tasks on Virtually Unlimited Cloud\n  Resources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bag-of-Distributed-Tasks (BoDT) application is the collection of identical\nand independent tasks each of which requires a piece of input data located\naround the world. As a result, Cloud computing offers an ef- fective way to\nexecute BoT application as it not only consists of multiple geographically\ndistributed data centres but also allows a user to pay for what she actually\nuses only. In this paper, BoDT on the Cloud using virtually unlimited cloud\nresources. A heuristic algorithm is proposed to find an execution plan that\ntakes budget constraints into account. Compared with other approaches, with the\nsame given budget, our algorithm is able to reduce the overall execution time\nup to 50%.\n", "versions": [{"version": "v1", "created": "Mon, 1 Jun 2015 17:57:09 GMT"}], "update_date": "2015-06-02", "authors_parsed": [["Thai", "Long", ""], ["Varghese", "Blesson", ""], ["Barker", "Adam", ""]]}, {"id": "1506.00744", "submitter": "Hai Liu", "authors": "Zhiyong Lin, Hai Liu, Lu Yu, Yiu-Wing Leung, and Xiaowen Chu", "title": "ZOS: A Fast Rendezvous Algorithm Based on Set of Available Channels for\n  Cognitive Radios", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of existing rendezvous algorithms generate channel-hopping sequences\nbased on the whole channel set. They are inefficient when the set of available\nchannels is a small subset of the whole channel set. We propose a new algorithm\ncalled ZOS which uses three types of elementary sequences (namely, Zero-type,\nOne-type, and S-type) to generate channel-hopping sequences based on the set of\navailable channels. ZOS provides guaranteed rendezvous without any additional\nrequirements. The maximum time-to-rendezvous of ZOS is upper-bounded by\nO(m1*m2*log2M) where M is the number of all channels and m1 and m2 are the\nnumbers of available channels of two users.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 04:13:00 GMT"}], "update_date": "2015-06-03", "authors_parsed": [["Lin", "Zhiyong", ""], ["Liu", "Hai", ""], ["Yu", "Lu", ""], ["Leung", "Yiu-Wing", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1506.00828", "submitter": "Yannic Maus", "authors": "Sebastian Daum, Fabian Kuhn, Yannic Maus", "title": "Rumor Spreading with Bounded In-Degree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the classic gossip-based model of communication for disseminating\ninformation in a network, in each time unit, every node $u$ is allowed to\ncontact a single random neighbor $v$. If $u$ knows the data (rumor) to be\ndisseminated, it disperses it to $v$ (known as PUSH) and if it does not, it\nrequests it from $v$ (known as PULL). While in the classic gossip model, each\nnode is only allowed to contact a single neighbor in each time unit, each node\ncan possibly be contacted by many neighboring nodes.\n  In the present paper, we consider a restricted model where at each node only\none incoming request can be served. As long as only a single piece of\ninformation needs to be disseminated, this does not make a difference for push\nrequests. It however has a significant effect on pull requests. In the paper,\nwe therefore concentrate on this weaker pull version, which we call 'restricted\npull'.\n  We distinguish two versions of the restricted pull protocol depending on\nwhether the request to be served among a set of pull requests at a given node\nis chosen adversarially or uniformly at random. As a first result, we prove an\nexponential separation between the two variants. We show that there are\ninstances where if an adversary picks the request to be served, the restricted\npull protocol requires a polynomial number of rounds whereas if the winning\nrequest is chosen uniformly at random, the restricted pull protocol only\nrequires a polylogarithmic number of rounds to inform the whole network.\nFurther, as the main technical contribution, we show that if the request to be\nserved is chosen randomly, the slowdown of using restricted pull versus using\nthe classic pull protocol can w.h.p. be upper bounded by $O(\\Delta / \\delta\n\\log n)$, where $\\Delta$ and $\\delta$ are the largest and smallest degree of\nthe network.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 10:24:31 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2015 20:27:09 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Daum", "Sebastian", ""], ["Kuhn", "Fabian", ""], ["Maus", "Yannic", ""]]}, {"id": "1506.00842", "submitter": "Thomas Falch", "authors": "Thomas L. Falch, Anne C. Elster", "title": "Machine Learning Based Auto-tuning for Enhanced OpenCL Performance\n  Portability", "comments": "This is a pre-print version an article to be published in the\n  Proceedings of the 2015 IEEE International Parallel and Distributed\n  Processing Symposium Workshops (IPDPSW). For personal use only", "journal-ref": null, "doi": "10.1109/IPDPSW.2015.85", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous computing, which combines devices with different architectures,\nis rising in popularity, and promises increased performance combined with\nreduced energy consumption. OpenCL has been proposed as a standard for\nprograming such systems, and offers functional portability. It does, however,\nsuffer from poor performance portability, code tuned for one device must be\nre-tuned to achieve good performance on another device. In this paper, we use\nmachine learning-based auto-tuning to address this problem. Benchmarks are run\non a random subset of the entire tuning parameter configuration space, and the\nresults are used to build an artificial neural network based model. The model\ncan then be used to find interesting parts of the parameter space for further\nsearch. We evaluate our method with different benchmarks, on several devices,\nincluding an Intel i7 3770 CPU, an Nvidia K40 GPU and an AMD Radeon HD 7970\nGPU. Our model achieves a mean relative error as low as 6.1%, and is able to\nfind configurations as little as 1.3% worse than the global minimum.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 11:19:56 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Falch", "Thomas L.", ""], ["Elster", "Anne C.", ""]]}, {"id": "1506.00853", "submitter": "Peter Davies", "authors": "Artur Czumaj, Peter Davies", "title": "Deterministic Communication in Radio Networks", "comments": null, "journal-ref": "SIAM Journal on Computing 2018 47:1, 218-240", "doi": "10.1137/17M1111322", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we improve the deterministic complexity of two fundamental\ncommunication primitives in the classical model of ad-hoc radio networks with\nunknown topology: broadcasting and wake-up. We consider an unknown radio\nnetwork, in which all nodes have no prior knowledge about network topology, and\nknow only the size of the network $n$, the maximum in-degree of any node\n$\\Delta$, and the eccentricity of the network $D$.\n  For such networks, we first give an algorithm for wake-up, based on the\nexistence of small universal synchronizers. This algorithm runs in\n$O(\\frac{\\min\\{n, D \\Delta\\} \\log n \\log \\Delta}{\\log\\log \\Delta})$ time, the\nfastest known in both directed and undirected networks, improving over the\nprevious best $O(n \\log^2n)$-time result across all ranges of parameters, but\nparticularly when maximum in-degree is small.\n  Next, we introduce a new combinatorial framework of block synchronizers and\nprove the existence of such objects of low size. Using this framework, we\ndesign a new deterministic algorithm for the fundamental problem of\nbroadcasting, running in $O(n \\log D \\log\\log\\frac{D \\Delta}{n})$ time. This is\nthe fastest known algorithm for the problem in directed networks, improving\nupon the $O(n \\log n \\log \\log n)$-time algorithm of De Marco (2010) and the\n$O(n \\log^2 D)$-time algorithm due to Czumaj and Rytter (2003). It is also the\nfirst to come within a log-logarithmic factor of the $\\Omega(n \\log D)$ lower\nbound due to Clementi et al.\\ (2003).\n  Our results also have direct implications on the fastest \\emph{deterministic\nleader election} and \\emph{clock synchronization} algorithms in both directed\nand undirected radio networks, tasks which are commonly used as building blocks\nfor more complex procedures.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jun 2015 12:08:32 GMT"}, {"version": "v2", "created": "Fri, 10 Jul 2015 21:44:47 GMT"}, {"version": "v3", "created": "Mon, 14 Mar 2016 21:54:02 GMT"}, {"version": "v4", "created": "Mon, 25 Apr 2016 16:36:16 GMT"}, {"version": "v5", "created": "Mon, 30 May 2016 09:23:57 GMT"}, {"version": "v6", "created": "Mon, 6 Mar 2017 13:31:19 GMT"}, {"version": "v7", "created": "Sat, 16 Mar 2019 14:25:58 GMT"}], "update_date": "2019-03-19", "authors_parsed": [["Czumaj", "Artur", ""], ["Davies", "Peter", ""]]}, {"id": "1506.01106", "submitter": "Minxian  Xu", "authors": "Wenhong Tian, Minxian Xu, Aiguo Chen, Guozhong Li, Xinyang Wang, Yu\n  Chen", "title": "Open-Source Simulators for Cloud Computing: Comparative Study and\n  Challenging Issues", "comments": "15 pages, 11 figures, accepted for publication in Journal: Simulation\n  Modelling Practice and Theory", "journal-ref": null, "doi": "10.1016/j.simpat.2015.06.002", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Resource scheduling in infrastructure as a service (IaaS) is one of the keys\nfor large-scale Cloud applications. Extensive research on all issues in real\nenvironment is extremely difficult because it requires developers to consider\nnetwork infrastructure and the environment, which may be beyond the control. In\naddition, the network conditions cannot be controlled or predicted. Performance\nevaluations of workload models and Cloud provisioning algorithms in a\nrepeatable manner under different configurations are difficult. Therefore,\nsimulators are developed. To understand and apply better the state-of-the-art\nof cloud computing simulators, and to improve them, we study four known\nopen-source simulators. They are compared in terms of architecture, modeling\nelements, simulation process, performance metrics and scalability in\nperformance. Finally, a few challenging issues as future research trends are\noutlined.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jun 2015 01:57:56 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Tian", "Wenhong", ""], ["Xu", "Minxian", ""], ["Chen", "Aiguo", ""], ["Li", "Guozhong", ""], ["Wang", "Xinyang", ""], ["Chen", "Yu", ""]]}, {"id": "1506.01446", "submitter": "Liqing Cui", "authors": "Qi Mu, Liqing Cui, Yufei Song", "title": "The implementation and optimization of Bitonic sort algorithm based on\n  CUDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  This paper describes in detail the bitonic sort algorithm,and implements the\nbitonic sort algorithm based on cuda architecture.At the same time,we conduct\ntwo effective optimization of implementation details according to the\ncharacteristics of the GPU,which greatly improve the efficiency. Finally,we\nsurvey the optimized Bitonic sort algorithm on the GPU with the speedup of\nquick sort algorithm on the CPU.Since Quick Sort is not suitable to be\nimplemented in parallel,but it is more efficient than other sorting algorithms\non CPU to some extend.Hence,to see the speedup and performance,we compare\nbitonic sort on GPU with quick Sort on CPU. For a series of 32-bit random\ninteger,the experimental results show that the acceleration of our work is\nnearly 20 times.When array size is about 216,the speedup ratio is even up to\n30.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 02:01:43 GMT"}], "update_date": "2016-10-31", "authors_parsed": [["Mu", "Qi", ""], ["Cui", "Liqing", ""], ["Song", "Yufei", ""]]}, {"id": "1506.01509", "submitter": "Fabio Lopez-Pires", "authors": "Fabio Lopez-Pires and Benjamin Baran", "title": "Virtual Machine Placement Literature Review", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Computing Datacenters host millions of virtual machines (VMs) on real\nworld scenarios. In this context, Virtual Machine Placement (VMP) is one of the\nmost challenging problems in cloud infrastructure management, considering also\nthe large number of possible optimization criteria and different formulations\nthat could be studied. VMP literature include relevant topics such as\nenergy-efficiency, Service Level Agreements (SLA), cloud service markets,\nQuality of Service (QoS) and carbon dioxide emissions, all of them with high\neconomical and ecological impact. This work presents an extensive up-to-date\nreview of the most relevant VMP literature in order to identify research\nopportunities.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 08:32:34 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Lopez-Pires", "Fabio", ""], ["Baran", "Benjamin", ""]]}, {"id": "1506.01603", "submitter": "Sebastien Tixeuil", "authors": "Pierre Courtieu (CEDRIC), Lionel Rieg, S\\'ebastien Tixeuil (NPA,\n  LINCS, IUF, LIP6), Xavier Urbain (ENSIIE, LRI, CEDRIC)", "title": "A Certified Universal Gathering Algorithm for Oblivious Mobile Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CG cs.DS cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new algorithm for the problem of universal gathering mobile\noblivious robots (that is, starting from any initial configuration that is not\nbivalent, using any number of robots, the robots reach in a finite number of\nsteps the same position, not known beforehand) without relying on a common\nchirality. We give very strong guaranties on the correctness of our algorithm\nby proving formally that it is correct, using the COQ proof assistant. To our\nknowledge, this is the first certified positive (and constructive) result in\nthe context of oblivious mobile robots. It demonstrates both the effectiveness\nof the approach to obtain new algorithms that are truly generic, and its\nmanagability since the amount of developped code remains human readable.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 14:23:19 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Courtieu", "Pierre", "", "CEDRIC"], ["Rieg", "Lionel", "", "NPA,\n  LINCS, IUF, LIP6"], ["Tixeuil", "S\u00e9bastien", "", "NPA,\n  LINCS, IUF, LIP6"], ["Urbain", "Xavier", "", "ENSIIE, LRI, CEDRIC"]]}, {"id": "1506.01684", "submitter": "Martin Bauer", "authors": "Martin Bauer, Johannes H\\\"otzer, Philipp Steinmetz, Marcus Jainta,\n  Marco Berghoff, Florian Schornbaum, Christian Godenschwager, Harald\n  K\\\"ostler, Britta Nestler, Ulrich R\\\"ude", "title": "Massively Parallel Phase-Field Simulations for Ternary Eutectic\n  Directional Solidification", "comments": "submitted to Supercomputing 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microstructures forming during ternary eutectic directional solidification\nprocesses have significant influence on the macroscopic mechanical properties\nof metal alloys. For a realistic simulation, we use the well established\nthermodynamically consistent phase-field method and improve it with a new grand\npotential formulation to couple the concentration evolution. This extension is\nvery compute intensive due to a temperature dependent diffusive concentration.\nWe significantly extend previous simulations that have used simpler phase-field\nmodels or were performed on smaller domain sizes. The new method has been\nimplemented within the massively parallel HPC framework waLBerla that is\ndesigned to exploit current supercomputers efficiently. We apply various\noptimization techniques, including buffering techniques, explicit SIMD kernel\nvectorization, and communication hiding. Simulations utilizing up to 262,144\ncores have been run on three different supercomputing architectures and weak\nscalability results are shown. Additionally, a hierarchical, mesh-based data\nreduction strategy is developed to keep the I/O problem manageable at scale.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 19:10:31 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Bauer", "Martin", ""], ["H\u00f6tzer", "Johannes", ""], ["Steinmetz", "Philipp", ""], ["Jainta", "Marcus", ""], ["Berghoff", "Marco", ""], ["Schornbaum", "Florian", ""], ["Godenschwager", "Christian", ""], ["K\u00f6stler", "Harald", ""], ["Nestler", "Britta", ""], ["R\u00fcde", "Ulrich", ""]]}, {"id": "1506.01688", "submitter": "Andrew Berns", "authors": "Andrew Berns", "title": "Avatar: A Time- and Space-Efficient Self-Stabilizing Overlay Network", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Overlay networks present an interesting challenge for fault-tolerant\ncomputing. Many overlay networks operate in dynamic environments (e.g. the\nInternet), where faults are frequent and widespread, and the number of\nprocesses in a system may be quite large. Recently, self-stabilizing overlay\nnetworks have been presented as a method for managing this complexity.\n\\emph{Self-stabilizing overlay networks} promise that, starting from any\nweakly-connected configuration, a correct overlay network will eventually be\nbuilt. To date, this guarantee has come at a cost: nodes may either have high\ndegree during the algorithm's execution, or the algorithm may take a long time\nto reach a legal configuration. In this paper, we present the first\nself-stabilizing overlay network algorithm that does not incur this penalty.\nSpecifically, we (i) present a new locally-checkable overlay network based upon\na binary search tree, and (ii) provide a randomized algorithm for\nself-stabilization that terminates in an expected polylogarithmic number of\nrounds \\emph{and} increases a node's degree by only a polylogarithmic factor in\nexpectation.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 19:24:42 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Berns", "Andrew", ""]]}, {"id": "1506.01739", "submitter": "Flavio Lombardi", "authors": "Roberto Battistoni, Roberto Di Pietro, Flavio Lombardi", "title": "CloRoFor: Cloud Robust Forensics", "comments": "12 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The malicious alteration of machine time is a big challenge in computer\nforensics. Detecting such changes and reconstructing the actual timeline of\nevents is of paramount importance. However, this can be difficult since the\nattacker has many opportunities and means to hide such changes. In particular,\ncloud computing, host and guest machine time can be manipulated in various ways\nby an attacker. Guest virtual machines are especially vulnerable to attacks\ncoming from their (more privileged) host. As such, it is important to guarantee\nthe timeline integrity of both hosts and guests in a cloud, or at least to\nensure that the alteration of such timeline does not go undetected. In this\npaper we survey the issues related to host and guest machine time integrity in\nthe cloud. Further, we describe a novel architecture for host and guest time\nalteration detection and correction/resilience with respect to compromised\nhosts and guests. The proposed framework has been implemented on an especially\nbuilt simulator. Collected results are evaluated and discussed. Performance\nfigures show the feasibility of our proposal.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jun 2015 22:12:31 GMT"}], "update_date": "2015-06-08", "authors_parsed": [["Battistoni", "Roberto", ""], ["Di Pietro", "Roberto", ""], ["Lombardi", "Flavio", ""]]}, {"id": "1506.02226", "submitter": "Lianhe Zhao", "authors": "Bingchen Wang, Chenglong Zhang, Lei Song, Lianhe Zhao, Yu Dou, and\n  Zihao Yu", "title": "Design and optimization of DBSCAN Algorithm based on CUDA", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DBSCAN is a very classic algorithm for data clus- tering, which is widely\nused in many fields. However, with the data scale growing much more bigger than\nbefore, the traditional serial algorithm can not meet the performance\nrequirement. Recently, parallel computing based on CUDA has developed very fast\nand has great advantage on big data. This paper summarizes the algorithms\nproposed before and improves the performance of the old DBSCAN algorithm by\nusing CUDA and parallel computing. The algorithm uses shared memory as much as\npossible compared with other algorithms and it has very good scalability. A\ndata set is tested on the new version of DBSCAN. Finally, we analyze the\nresults and give a conclusion that our algorithm is approximately 97 times\nfaster than the serial version.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2015 06:30:27 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Wang", "Bingchen", ""], ["Zhang", "Chenglong", ""], ["Song", "Lei", ""], ["Zhao", "Lianhe", ""], ["Dou", "Yu", ""], ["Yu", "Zihao", ""]]}, {"id": "1506.02288", "submitter": "Vincenzo De Florio", "authors": "Vincenzo De Florio and Chris Blondia", "title": "Robust and Tuneable Family of Gossiping Algorithms", "comments": "Paper presented at the 20th Euromicro International Conference on\n  Parallel, Distributed and Network-Based Processing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a family of gossiping algorithms whose members share the same\nstructure though they vary their performance in function of a combinatorial\nparameter. We show that such parameter may be considered as a \"knob\"\ncontrolling the amount of communication parallelism characterizing the\nalgorithms. After this we introduce procedures to operate the knob and choose\nparameters matching the amount of communication channels currently provided by\nthe available communication system(s). In so doing we provide a robust\nmechanism to tune the production of requests for communication after the\ncurrent operational conditions of the consumers of such requests. This can be\nused to achieve high performance and programmatic avoidance of undesirable\nevents such as message collisions.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jun 2015 17:40:23 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["De Florio", "Vincenzo", ""], ["Blondia", "Chris", ""]]}, {"id": "1506.02396", "submitter": "Zhimin Peng", "authors": "Zhimin Peng, Yangyang Xu, Ming Yan, Wotao Yin", "title": "ARock: an Algorithmic Framework for Asynchronous Parallel Coordinate\n  Updates", "comments": "updated the linear convergence proofs", "journal-ref": "SIAM Journal on Scientific Computing, 38 (2016), A2851-A2879", "doi": "10.1137/15M1024950", "report-no": null, "categories": "math.OC cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Finding a fixed point to a nonexpansive operator, i.e., $x^*=Tx^*$, abstracts\nmany problems in numerical linear algebra, optimization, and other areas of\nscientific computing. To solve fixed-point problems, we propose ARock, an\nalgorithmic framework in which multiple agents (machines, processors, or cores)\nupdate $x$ in an asynchronous parallel fashion. Asynchrony is crucial to\nparallel computing since it reduces synchronization wait, relaxes communication\nbottleneck, and thus speeds up computing significantly. At each step of ARock,\nan agent updates a randomly selected coordinate $x_i$ based on possibly\nout-of-date information on $x$. The agents share $x$ through either global\nmemory or communication. If writing $x_i$ is atomic, the agents can read and\nwrite $x$ without memory locks.\n  Theoretically, we show that if the nonexpansive operator $T$ has a fixed\npoint, then with probability one, ARock generates a sequence that converges to\na fixed points of $T$. Our conditions on $T$ and step sizes are weaker than\ncomparable work. Linear convergence is also obtained.\n  We propose special cases of ARock for linear systems, convex optimization,\nmachine learning, as well as distributed and decentralized consensus problems.\nNumerical experiments of solving sparse logistic regression problems are\npresented.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 08:31:53 GMT"}, {"version": "v2", "created": "Thu, 9 Jul 2015 05:57:35 GMT"}, {"version": "v3", "created": "Sun, 12 Jul 2015 04:05:15 GMT"}, {"version": "v4", "created": "Mon, 25 Jan 2016 20:06:08 GMT"}, {"version": "v5", "created": "Fri, 27 May 2016 03:55:31 GMT"}], "update_date": "2016-10-03", "authors_parsed": [["Peng", "Zhimin", ""], ["Xu", "Yangyang", ""], ["Yan", "Ming", ""], ["Yin", "Wotao", ""]]}, {"id": "1506.02531", "submitter": "Cl\\'ement Duhart Mr", "authors": "Cl\\'ement Duhart and Pierre Sauvage and Cyrille Bertelle", "title": "EMMA: A Resource Oriented Framework for Service Choreography over\n  Wireless Sensor and Actor Networks", "comments": "23 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current Internet of Things (IoT) development requires service distribution\nover Wireless Sensor and Actor Networks (WSAN) to deal with the drastic\nincreasing of network management complexity. Because of the specific\nconstraints of WSAN, centralized approaches are strongly limited. Multi-hop\ncommunication used by WSAN introduces transmission latency, packet errors,\nrouter congestion and security issues. As it uses local services, a\ndecentralized service model avoid long path communications between nodes and\napplications. But the main issue is then to have such local services installed\non the desired nodes. Environment Monitoring and Management Agent (EMMA) system\nproposes a set of software to deploy and to execute such services over Wireless\nSensor and Actor Networks (WSAN) through a middleware based on Resource\nOriented Architecture (ROA). Its Internet integration and the local management\nof data heterogeneity are facilitated through the use of current standard\nprotocols such as IPv6 LoW Power Wireless Area Networks (6LoWPAN) and\nConstrained Application Protocol (CoAP). This contribution presents EMMA\nmiddleware, methodology and tools used to determine efficient service mapping\nand its deployment.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 14:54:24 GMT"}], "update_date": "2015-06-09", "authors_parsed": [["Duhart", "Cl\u00e9ment", ""], ["Sauvage", "Pierre", ""], ["Bertelle", "Cyrille", ""]]}, {"id": "1506.02554", "submitter": "Christina Heinze", "authors": "Christina Heinze, Brian McWilliams, Nicolai Meinshausen", "title": "DUAL-LOCO: Distributing Statistical Estimation Using Random Projections", "comments": "13 pages", "journal-ref": "Proceedings of the 19th International Conference on Artificial\n  Intelligence and Statistics, 51, 2016, 12 pages", "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present DUAL-LOCO, a communication-efficient algorithm for distributed\nstatistical estimation. DUAL-LOCO assumes that the data is distributed\naccording to the features rather than the samples. It requires only a single\nround of communication where low-dimensional random projections are used to\napproximate the dependences between features available to different workers. We\nshow that DUAL-LOCO has bounded approximation error which only depends weakly\non the number of workers. We compare DUAL-LOCO against a state-of-the-art\ndistributed optimization method on a variety of real world datasets and show\nthat it obtains better speedups while retaining good accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 15:35:24 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 16:44:27 GMT"}], "update_date": "2016-08-04", "authors_parsed": [["Heinze", "Christina", ""], ["McWilliams", "Brian", ""], ["Meinshausen", "Nicolai", ""]]}, {"id": "1506.02620", "submitter": "Ching-pei Lee", "authors": "Ching-pei Lee, Kai-Wei Chang, Shyam Upadhyay, Dan Roth", "title": "Distributed Training of Structured SVM", "comments": "NIPS Workshop on Optimization for Machine Learning, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training structured prediction models is time-consuming. However, most\nexisting approaches only use a single machine, thus, the advantage of computing\npower and the capacity for larger data sets of multiple machines have not been\nexploited. In this work, we propose an efficient algorithm for distributedly\ntraining structured support vector machines based on a distributed\nblock-coordinate descent method. Both theoretical and experimental results\nindicate that our method is efficient.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jun 2015 19:12:24 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2016 12:15:45 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Lee", "Ching-pei", ""], ["Chang", "Kai-Wei", ""], ["Upadhyay", "Shyam", ""], ["Roth", "Dan", ""]]}, {"id": "1506.02822", "submitter": "Ludovic Courtes", "authors": "Ludovic Court\\`es (INRIA Bordeaux - Sud-Ouest), Ricardo Wurmus", "title": "Reproducible and User-Controlled Software Environments in HPC with Guix", "comments": "2nd International Workshop on Reproducibility in Parallel Computing\n  (RepPar), Aug 2015, Vienne, Austria. http://reppar.org/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Support teams of high-performance computing (HPC) systems often find\nthemselves between a rock and a hard place: on one hand, they understandably\nadministrate these large systems in a conservative way, but on the other hand,\nthey try to satisfy their users by deploying up-to-date tool chains as well as\nlibraries and scientific software. HPC system users often have no guarantee\nthat they will be able to reproduce results at a later point in time, even on\nthe same system-software may have been upgraded, removed, or recompiled under\ntheir feet, and they have little hope of being able to reproduce the same\nsoftware environment elsewhere. We present GNU Guix and the functional package\nmanagement paradigm and show how it can improve reproducibility and sharing\namong researchers with representative use cases.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 08:30:23 GMT"}, {"version": "v2", "created": "Sun, 26 Jul 2015 18:50:32 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Court\u00e8s", "Ludovic", "", "INRIA Bordeaux - Sud-Ouest"], ["Wurmus", "Ricardo", ""]]}, {"id": "1506.02833", "submitter": "Albert Saa-Garriga", "authors": "Albert Sa\\`a-Garriga and David Castells-Rufas and Jordi Carrabina", "title": "OMP2HMPP: Compiler Framework for Energy Performance Trade-off Analysis\n  of Automatically Generated Codes", "comments": null, "journal-ref": "IJCSI International Journal of Computer Science Issues, Volume 12,\n  Issue 2, March 2015", "doi": null, "report-no": null, "categories": "cs.DC cs.PF cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present OMP2HMPP, a tool that, in a first step, automatically translates\nOpenMP code into various possible transformations of HMPP. In a second step\nOMP2HMPP executes all variants to obtain the performance and power consumption\nof each transformation. The resulting trade-off can be used to choose the more\nconvenient version. After running the tool on a set of codes from the Polybench\nbenchmark we show that the best automatic transformation is equivalent to a\nmanual one done by an expert. Compared with original OpenMP code running in 2\nquad-core processors we obtain an average speed-up of 31x and 5.86x factor in\noperations per watt.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 09:24:38 GMT"}], "update_date": "2015-06-10", "authors_parsed": [["Sa\u00e0-Garriga", "Albert", ""], ["Castells-Rufas", "David", ""], ["Carrabina", "Jordi", ""]]}, {"id": "1506.03004", "submitter": "Xiaotian Wang", "authors": "Yingjie Guo, Linzhi Wu, Wei Yu, Bin Wu, Xiaotian Wang", "title": "The Improved Job Scheduling Algorithm of Hadoop Platform", "comments": "12 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper discussed some job scheduling algorithms for Hadoop platform, and\nproposed a jobs scheduling optimization algorithm based on Bayes Classification\nviewing the shortcoming of those algorithms which are used. The proposed\nalgorithm can be summarized as follows. In the scheduling algorithm based on\nBayes Classification, the jobs in job queue will be classified into bad job and\ngood job by Bayes Classification, when JobTracker gets task request, it will\nselect a good job from job queue, and select tasks from good job to allocate\nJobTracker, then the execution result will feedback to the JobTracker.\nTherefore the scheduling algorithm based on Bayes Classification influence the\njob classification via learning the result of feedback with the JobTracker will\nselect the most appropriate job to execute on TaskTracker every time. We need\nto consider the feature usage of job resource and the influence of TaskTracker\nresource on task execution, the former of which we call it job feature, for\ninstance, the average usage rate of CPU and average usage rate of memory, the\nlatter node feature, such as the usage rate of CPU and the size of idle\nphysical memory, the two are called feature variables. Results show that it has\na significant improvement in execution efficiency and stability of job\nscheduling.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 17:00:52 GMT"}], "update_date": "2015-06-10", "authors_parsed": [["Guo", "Yingjie", ""], ["Wu", "Linzhi", ""], ["Yu", "Wei", ""], ["Wu", "Bin", ""], ["Wang", "Xiaotian", ""]]}, {"id": "1506.03265", "submitter": "Matteo Ceccarello", "authors": "Matteo Ceccarello, Andrea Pietracaprina, Geppino Pucci and Eli Upfal", "title": "A Practical Parallel Algorithm for Diameter Approximation of Massive\n  Weighted Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a space and time efficient practical parallel algorithm for\napproximating the diameter of massive weighted undirected graphs on distributed\nplatforms supporting a MapReduce-like abstraction. The core of the algorithm is\na weighted graph decomposition strategy generating disjoint clusters of bounded\nweighted radius. Theoretically, our algorithm uses linear space and yields a\npolylogarithmic approximation guarantee; moreover, for important practical\nclasses of graphs, it runs in a number of rounds asymptotically smaller than\nthose required by the natural approximation provided by the state-of-the-art\n$\\Delta$-stepping SSSP algorithm, which is its only practical linear-space\ncompetitor in the aforementioned computational scenario. We complement our\ntheoretical findings with an extensive experimental analysis on large benchmark\ngraphs, which demonstrates that our algorithm attains substantial improvements\non a number of key performance indicators with respect to the aforementioned\ncompetitor, while featuring a similar approximation ratio (a small constant\nless than 1.4, as opposed to the polylogarithmic theoretical bound).\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 11:43:41 GMT"}, {"version": "v2", "created": "Tue, 14 Jul 2015 08:03:19 GMT"}, {"version": "v3", "created": "Mon, 9 Nov 2015 13:15:40 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Ceccarello", "Matteo", ""], ["Pietracaprina", "Andrea", ""], ["Pucci", "Geppino", ""], ["Upfal", "Eli", ""]]}, {"id": "1506.03471", "submitter": "Guy Zyskind", "authors": "Guy Zyskind, Oz Nathan, Alex Pentland", "title": "Enigma: Decentralized Computation Platform with Guaranteed Privacy", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A peer-to-peer network, enabling different parties to jointly store and run\ncomputations on data while keeping the data completely private. Enigma's\ncomputational model is based on a highly optimized version of secure\nmulti-party computation, guaranteed by a verifiable secret-sharing scheme. For\nstorage, we use a modified distributed hashtable for holding secret-shared\ndata. An external blockchain is utilized as the controller of the network,\nmanages access control, identities and serves as a tamper-proof log of events.\nSecurity deposits and fees incentivize operation, correctness and fairness of\nthe system. Similar to Bitcoin, Enigma removes the need for a trusted third\nparty, enabling autonomous control of personal data. For the first time, users\nare able to share their data with cryptographic guarantees regarding their\nprivacy.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 20:34:12 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Zyskind", "Guy", ""], ["Nathan", "Oz", ""], ["Pentland", "Alex", ""]]}, {"id": "1506.03506", "submitter": "Vikram Saraph", "authors": "Maurice Herlihy, Vikram Saraph", "title": "The Relative Power of Composite Loop Agreement Tasks", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loop agreement is a family of wait-free tasks that includes set agreement and\nsimplex agreement, and was used to prove the undecidability of wait-free\nsolvability of distributed tasks by read/write memory. Herlihy and Rajsbaum\ndefined the algebraic signature of a loop agreement task, which consists of a\ngroup and a distinguished element. They used the algebraic signature to\ncharacterize the relative power of loop agreement tasks. In particular, they\nshowed that one task implements another exactly when there is a homomorphism\nbetween their respective signatures sending one distinguished element to the\nother. In this paper, we extend the previous result by defining the composition\nof multiple loop agreement tasks to create a new one with the same combined\npower. We generalize the original algebraic characterization of relative power\nto compositions of tasks. In this way, we can think of loop agreement tasks in\nterms of their basic building blocks. We also investigate a category-theoretic\nperspective of loop agreement by defining a category of loops, showing that the\nalgebraic signature is a functor, and proving that our definition of task\ncomposition is the \"correct\" one, in a categorical sense.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jun 2015 23:28:59 GMT"}], "update_date": "2015-06-12", "authors_parsed": [["Herlihy", "Maurice", ""], ["Saraph", "Vikram", ""]]}, {"id": "1506.03883", "submitter": "Dietmar Berwanger", "authors": "Dietmar Berwanger, Anup Basil Mathew, Marie van den Bogaard", "title": "Hierarchical Information and the Synthesis of Distributed Strategies", "comments": "35 pages, 6 figures; extended version of a paper presented at ATVA\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Infinite games with imperfect information are known to be undecidable unless\nthe information flow is severely restricted. One fundamental decidable case\noccurs when there is a total ordering among players, such that each player has\naccess to all the information that the following ones receive.\n  In this paper we consider variations of this hierarchy principle for\nsynchronous games with perfect recall, and identify new decidable classes for\nwhich the distributed synthesis problem is solvable with finite-state\nstrategies. In particular, we show that decidability is maintained when the\ninformation hierarchy may change along the play, or when transient phases\nwithout hierarchical information are allowed. Finally, we interpret our result\nin terms of distributed system architectures.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 01:11:24 GMT"}, {"version": "v2", "created": "Sat, 16 Jul 2016 12:14:37 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Berwanger", "Dietmar", ""], ["Mathew", "Anup Basil", ""], ["Bogaard", "Marie van den", ""]]}, {"id": "1506.03944", "submitter": "Dmitry N. Kozlov", "authors": "D.N. Kozlov", "title": "Combinatorial topology of the standard chromatic subdivision and Weak\n  Symmetry Breaking for 6 processes", "comments": "updated references, in Configuration Spaces, Springer INdAM series\n  14, F. Callegaro et al. (eds.), Springer International Publishing\n  Switzerland, 2016", "journal-ref": null, "doi": "10.1007/978-3-319-31580-5_7", "report-no": null, "categories": "cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study a family of discrete configuration spaces, the\nso-called protocol complexes, which are of utmost importance in theoretical\ndistributed computing. Specifically, we consider questions of the existance of\ncompliant binary labelings on the vertices of iterated standard chromatic\nsubdivisions of an n-simplex. The existance of such labelings is equivalent to\nthe existance of distributed protocols solving Weak Symmetry Breaking task in\nthe standard computational model.\n  As a part of our formal model, we introduce function sb(n), defined for\nnatural numbers n, called the symmetry breaking function. From the geometric\npoint of view sb(n) denotes the minimal number of iterations of the standard\nchromatic subdivision of an (n-1)-simplex, which is needed for the compliant\nbinary labeling to exist. From the point of distributed computing, the function\nsb(n) measures the minimal number of rounds in a protocol solving the Weak\nSymmetry Breaking task.\n  In addition to the development of combinatorial topology, which is applicable\nin a broader context, our main contribution is the proof of new bounds for the\nfunction sb(n). Accordingly, the bulk of the paper is taken up by in-depth\nanalysis of the structure of adjacency graph on the set of n-simplices in\niterated standard chromatic subdivision of an n-simplex. On the algorithmic\nside, we provide the first distributed protocol solving Weak Symmetry Breaking\ntask in the layered immediate snapshot computational model for some number of\nprocesses.\n  It is well known, that the smallest number of processes for which Weak\nSymmetry Breaking task is solvable is 6. Based on our analysis, we are able to\nfind a very fast explicit protocol, solving the Weak Symmetry Breaking for 6\nprocesses using only 3 rounds. Furthermore, we show that no protocol can solve\nWeak Symmetry Breaking in fewer than 2 rounds.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 09:05:36 GMT"}, {"version": "v2", "created": "Tue, 26 Apr 2016 09:26:46 GMT"}], "update_date": "2016-04-27", "authors_parsed": [["Kozlov", "D. N.", ""]]}, {"id": "1506.04130", "submitter": "Harsh Agrawal", "authors": "Harsh Agrawal, Clint Solomon Mathialagan, Yash Goyal, Neelima Chavali,\n  Prakriti Banik, Akrit Mohapatra, Ahmed Osman, Dhruv Batra", "title": "CloudCV: Large Scale Distributed Computer Vision as a Cloud Service", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We are witnessing a proliferation of massive visual data. Unfortunately\nscaling existing computer vision algorithms to large datasets leaves\nresearchers repeatedly solving the same algorithmic, logistical, and\ninfrastructural problems. Our goal is to democratize computer vision; one\nshould not have to be a computer vision, big data and distributed computing\nexpert to have access to state-of-the-art distributed computer vision\nalgorithms. We present CloudCV, a comprehensive system to provide access to\nstate-of-the-art distributed computer vision algorithms as a cloud service\nthrough a Web Interface and APIs.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 19:50:07 GMT"}, {"version": "v2", "created": "Wed, 15 Jun 2016 22:01:51 GMT"}, {"version": "v3", "created": "Mon, 13 Feb 2017 07:30:56 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Agrawal", "Harsh", ""], ["Mathialagan", "Clint Solomon", ""], ["Goyal", "Yash", ""], ["Chavali", "Neelima", ""], ["Banik", "Prakriti", ""], ["Mohapatra", "Akrit", ""], ["Osman", "Ahmed", ""], ["Batra", "Dhruv", ""]]}, {"id": "1506.04182", "submitter": "Jonathan Passerat-Palmbach", "authors": "Romain Reuillon (ISC-PIF), Mathieu Leclaire (ISC-PIF, GC), Jonathan\n  Passerat-Palmbach (BioMedIA)", "title": "Model Exploration Using OpenMOLE - a workflow engine for large scale\n  distributed design of experiments and parameter tuning", "comments": "IEEE High Performance Computing and Simulation conference 2015, Jun\n  2015, Amsterdam, Netherlands", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  OpenMOLE is a scientific workflow engine with a strong emphasis on workload\ndistribution. Workflows are designed using a high level Domain Specific\nLanguage (DSL) built on top of Scala. It exposes natural parallelism constructs\nto easily delegate the workload resulting from a workflow to a wide range of\ndistributed computing environments. In this work, we briefly expose the strong\nassets of OpenMOLE and demonstrate its efficiency at exploring the parameter\nset of an agent simulation model. We perform a multi-objective optimisation on\nthis model using computationally expensive Genetic Algorithms (GA). OpenMOLE\nhides the complexity of designing such an experiment thanks to its DSL, and\ntransparently distributes the optimisation process. The example shows how an\ninitialisation of the GA with a population of 200,000 individuals can be\nevaluated in one hour on the European Grid Infrastructure.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jun 2015 21:08:35 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Reuillon", "Romain", "", "ISC-PIF"], ["Leclaire", "Mathieu", "", "ISC-PIF, GC"], ["Passerat-Palmbach", "Jonathan", "", "BioMedIA"]]}, {"id": "1506.04215", "submitter": "Daniel Roche", "authors": "Mohamed Khochtali, Daniel S. Roche, Xisen Tian", "title": "Parallel sparse interpolation using small primes", "comments": "Accepted to PASCO 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SC cs.DC", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  To interpolate a supersparse polynomial with integer coefficients, two\nalternative approaches are the Prony-based \"big prime\" technique, which acts\nover a single large finite field, or the more recently-proposed \"small primes\"\ntechnique, which reduces the unknown sparse polynomial to many low-degree dense\npolynomials. While the latter technique has not yet reached the same\ntheoretical efficiency as Prony-based methods, it has an obvious potential for\nparallelization. We present a heuristic \"small primes\" interpolation algorithm\nand report on a low-level C implementation using FLINT and MPI.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2015 03:41:43 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Khochtali", "Mohamed", ""], ["Roche", "Daniel S.", ""], ["Tian", "Xisen", ""]]}, {"id": "1506.04322", "submitter": "Nesreen Ahmed", "authors": "Nesreen K. Ahmed, Jennifer Neville, Ryan A. Rossi, Nick Duffield, and\n  Theodore L. Willke", "title": "Graphlet Decomposition: Framework, Algorithms, and Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC cs.IR stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  From social science to biology, numerous applications often rely on graphlets\nfor intuitive and meaningful characterization of networks at both the global\nmacro-level as well as the local micro-level. While graphlets have witnessed a\ntremendous success and impact in a variety of domains, there has yet to be a\nfast and efficient approach for computing the frequencies of these subgraph\npatterns. However, existing methods are not scalable to large networks with\nmillions of nodes and edges, which impedes the application of graphlets to new\nproblems that require large-scale network analysis. To address these problems,\nwe propose a fast, efficient, and parallel algorithm for counting graphlets of\nsize k={3,4}-nodes that take only a fraction of the time to compute when\ncompared with the current methods used. The proposed graphlet counting\nalgorithms leverages a number of proven combinatorial arguments for different\ngraphlets. For each edge, we count a few graphlets, and with these counts along\nwith the combinatorial arguments, we obtain the exact counts of others in\nconstant time. On a large collection of 300+ networks from a variety of\ndomains, our graphlet counting strategies are on average 460x faster than\ncurrent methods. This brings new opportunities to investigate the use of\ngraphlets on much larger networks and newer applications as we show in the\nexperiments. To the best of our knowledge, this paper provides the largest\ngraphlet computations to date as well as the largest systematic investigation\non over 300+ networks from a variety of domains.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jun 2015 21:32:12 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2016 23:23:31 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Ahmed", "Nesreen K.", ""], ["Neville", "Jennifer", ""], ["Rossi", "Ryan A.", ""], ["Duffield", "Nick", ""], ["Willke", "Theodore L.", ""]]}, {"id": "1506.04391", "submitter": "Thomas Pasquier", "authors": "Thomas F. J.-M. Pasquier and Jatinder Singh and David Eyers and Jean\n  Bacon", "title": "CamFlow: Managed Data-sharing for Cloud Services", "comments": "14 pages, 8 figures", "journal-ref": null, "doi": "10.1109/TCC.2015.2489211", "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A model of cloud services is emerging whereby a few trusted providers manage\nthe underlying hardware and communications whereas many companies build on this\ninfrastructure to offer higher level, cloud-hosted PaaS services and/or SaaS\napplications. From the start, strong isolation between cloud tenants was seen\nto be of paramount importance, provided first by virtual machines (VM) and\nlater by containers, which share the operating system (OS) kernel. Increasingly\nit is the case that applications also require facilities to effect isolation\nand protection of data managed by those applications. They also require\nflexible data sharing with other applications, often across the traditional\ncloud-isolation boundaries; for example, when government provides many related\nservices for its citizens on a common platform. Similar considerations apply to\nthe end-users of applications. But in particular, the incorporation of cloud\nservices within `Internet of Things' architectures is driving the requirements\nfor both protection and cross-application data sharing.\n  These concerns relate to the management of data. Traditional access control\nis application and principal/role specific, applied at policy enforcement\npoints, after which there is no subsequent control over where data flows; a\ncrucial issue once data has left its owner's control by cloud-hosted\napplications and within cloud-services. Information Flow Control (IFC), in\naddition, offers system-wide, end-to-end, flow control based on the properties\nof the data. We discuss the potential of cloud-deployed IFC for enforcing\nowners' dataflow policy with regard to protection and sharing, as well as\nsafeguarding against malicious or buggy software. In addition, the audit log\nassociated with IFC provides transparency, giving configurable system-wide\nvisibility over data flows. [...]\n", "versions": [{"version": "v1", "created": "Sun, 14 Jun 2015 13:20:42 GMT"}, {"version": "v2", "created": "Fri, 11 Sep 2015 12:30:26 GMT"}, {"version": "v3", "created": "Mon, 21 Dec 2015 15:35:09 GMT"}], "update_date": "2018-05-09", "authors_parsed": [["Pasquier", "Thomas F. J. -M.", ""], ["Singh", "Jatinder", ""], ["Eyers", "David", ""], ["Bacon", "Jean", ""]]}, {"id": "1506.04512", "submitter": "Stefano Ferretti Stefano Ferretti", "authors": "Stefano Ferretti", "title": "Self-Healing Protocols for Connectivity Maintenance in Unstructured\n  Overlays", "comments": "The paper has been accepted to the journal Peer-to-Peer Networking\n  and Applications. The final publication is available at Springer via\n  http://dx.doi.org/10.1007/s12083-015-0384-5", "journal-ref": null, "doi": "10.1007/s12083-015-0384-5", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we discuss on the use of self-organizing protocols to improve\nthe reliability of dynamic Peer-to-Peer (P2P) overlay networks. Two similar\napproaches are studied, which are based on local knowledge of the nodes' 2nd\nneighborhood. The first scheme is a simple protocol requiring interactions\namong nodes and their direct neighbors. The second scheme adds a check on the\nEdge Clustering Coefficient (ECC), a local measure that allows determining\nedges connecting different clusters in the network. The performed simulation\nassessment evaluates these protocols over uniform networks, clustered networks\nand scale-free networks. Different failure modes are considered. Results\ndemonstrate the effectiveness of the proposal.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 08:40:48 GMT"}], "update_date": "2015-06-16", "authors_parsed": [["Ferretti", "Stefano", ""]]}, {"id": "1506.04651", "submitter": "Max Duarte", "authors": "St\\'ephane Descombes, Max Duarte (LBNL), Thierry Dumont (ICJ), Thomas\n  Guillet, Violaine Louvet (ICJ), Marc Massot (EM2C)", "title": "Task-based adaptive multiresolution for time-space multi-scale\n  reaction-diffusion systems on multi-core architectures", "comments": null, "journal-ref": "SMAI Journal of Computational Mathematics, Vol. 3 (2017) 29-51", "doi": "10.5802/smai-jcm.19", "report-no": null, "categories": "cs.NA cs.DC math.AP math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new solver featuring time-space adaptation and error control has been\nrecently introduced to tackle the numerical solution of stiff\nreaction-diffusion systems. Based on operator splitting, finite volume adaptive\nmultiresolution and high order time integrators with specific stability\nproperties for each operator, this strategy yields high computational\nefficiency for large multidimensional computations on standard architectures\nsuch as powerful workstations. However, the data structure of the original\nimplementation, based on trees of pointers, provides limited opportunities for\nefficiency enhancements, while posing serious challenges in terms of parallel\nprogramming and load balancing. The present contribution proposes a new\nimplementation of the whole set of numerical methods including Radau5 and\nROCK4, relying on a fully different data structure together with the use of a\nspecific library, TBB, for shared-memory, task-based parallelism with\nwork-stealing. The performance of our implementation is assessed in a series of\ntest-cases of increasing difficulty in two and three dimensions on multi-core\nand many-core architectures, demonstrating high scalability.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jun 2015 12:53:48 GMT"}, {"version": "v2", "created": "Wed, 18 Nov 2015 07:58:57 GMT"}, {"version": "v3", "created": "Tue, 18 Oct 2016 12:28:12 GMT"}], "update_date": "2018-09-07", "authors_parsed": [["Descombes", "St\u00e9phane", "", "LBNL"], ["Duarte", "Max", "", "LBNL"], ["Dumont", "Thierry", "", "ICJ"], ["Guillet", "Thomas", "", "ICJ"], ["Louvet", "Violaine", "", "ICJ"], ["Massot", "Marc", "", "EM2C"]]}, {"id": "1506.04681", "submitter": "Lili Su", "authors": "Lili Su, Nitin Vaidya", "title": "Byzantine Multi-Agent Optimization: Part I", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study Byzantine fault-tolerant distributed optimization of a sum of convex\n(cost) functions with real-valued scalar input/ouput. In particular, the goal\nis to optimize a global cost function $\\frac{1}{|\\mathcal{N}|}\\sum_{i\\in\n\\mathcal{N}} h_i(x)$, where $\\mathcal{N}$ is the set of non-faulty agents, and\n$h_i(x)$ is agent $i$'s local cost function, which is initially known only to\nagent $i$. In general, when some of the agents may be Byzantine faulty, the\nabove goal is unachievable, because the identity of the faulty agents is not\nnecessarily known to the non-faulty agents, and the faulty agents may behave\narbitrarily. Since the above global cost function cannot be optimized exactly\nin presence of Byzantine agents, we define a weaker version of the problem.\n  The goal for the weaker problem is to generate an output that is an optimum\nof a function formed as a convex combination of local cost functions of the\nnon-faulty agents. More precisely, for some choice of weights $\\alpha_i$ for\n$i\\in \\mathcal{N}$ such that $\\alpha_i\\geq 0$ and $\\sum_{i\\in\n\\mathcal{N}}\\alpha_i=1$, the output must be an optimum of the cost function\n$\\sum_{i\\in \\mathcal{N}} \\alpha_ih_i(x)$. Ideally, we would like\n$\\alpha_i=\\frac{1}{|\\mathcal{N}|}$ for all $i\\in \\mathcal{N}$ -- however, this\ncannot be guaranteed due to the presence of faulty agents. In fact, we show\nthat the maximum achievable number of nonzero weights ($\\alpha_i$'s) is\n$|\\mathcal{N}|-f$, where $f$ is the upper bound on the number of Byzantine\nagents. In addition, we present algorithms that ensure that at least\n$|\\mathcal{N}|-f$ agents have weights that are bounded away from 0. We also\npropose a low-complexity suboptimal algorithm, which ensures that at least\n$\\lceil \\frac{n}{2}\\rceil-\\phi$ agents have weights that are bounded away from\n0, where $n$ is the total number of agents, and $\\phi$ ($\\phi\\le f$) is the\nactual number of Byzantine agents.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jun 2015 17:47:22 GMT"}, {"version": "v2", "created": "Fri, 31 Jul 2015 16:22:56 GMT"}], "update_date": "2015-08-03", "authors_parsed": [["Su", "Lili", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1506.04910", "submitter": "Ali Sezgin", "authors": "Ali Sezgin", "title": "Sequential Consistency and Concurrent Data Structures", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linearizability, the de facto correctness condition for concurrent data\nstructure implementations, despite its intuitive appeal is known to lead to\npoor scalability. This disadvantage has led researchers to design scalable data\nstructures satisfying consistency conditions weaker than linearizability.\nDespite this recent trend, sequential consistency as a strictly weaker\nconsistency condition than linearizability has received no interest.\n  In this paper, we investigate the applicability of sequential consistency as\nan alternative correctness criterion for concurrent data structure\nimplementations. Our first finding formally justifies the reluctance in moving\ntowards sequentially consistent data structures: Implementations in which each\nthread modifies only its thread-local variables are sequentially consistent for\nvarious standard data structures such as pools, queues and stacks. We also show\nthat for almost all data structures, and the data structures we consider in\nthis paper, it is possible to have sequentially consistent behaviors in which a\ndesignated thread does not synchronize at all. As a potential remedy, we define\na hierarchy of quantitatively strengthened variants of sequential consistency\nsuch that the stronger the variant the more synchronization it enforces which\nat the limit is equal to that enforced by linearizability.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 10:55:04 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Sezgin", "Ali", ""]]}, {"id": "1506.04986", "submitter": "Eric Cao Ni", "authors": "Eric C. Ni, Dragos F. Ciocan, Shane G. Henderson, Susan R. Hunter", "title": "Efficient Ranking and Selection in Parallel Computing Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The goal of ranking and selection (R&S) procedures is to identify the best\nstochastic system from among a finite set of competing alternatives. Such\nprocedures require constructing estimates of each system's performance, which\ncan be obtained simultaneously by running multiple independent replications on\na parallel computing platform. However, nontrivial statistical and\nimplementation issues arise when designing R&S procedures for a parallel\ncomputing environment. Thus we propose several design principles for parallel\nR&S procedures that preserve statistical validity and maximize core\nutilization, especially when large numbers of alternatives or cores are\ninvolved. These principles are followed closely by our parallel Good Selection\nProcedure (GSP), which, under the assumption of normally distributed output,\n(i) guarantees to select a system in the indifference zone with high\nprobability, (ii) runs efficiently on up to 1,024 parallel cores, and (iii) in\nan example uses smaller sample sizes compared to existing parallel procedures,\nparticularly for large problems (over $10^6$ alternatives). In our\ncomputational study we discuss two methods for implementing GSP on parallel\ncomputers, namely the Message-Passing Interface (MPI) and Hadoop MapReduce and\nshow that the latter provides good protection against core failures at the\nexpense of a significant drop in utilization due to periodic unavoidable\nsynchronization.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 14:27:15 GMT"}], "update_date": "2015-06-17", "authors_parsed": [["Ni", "Eric C.", ""], ["Ciocan", "Dragos F.", ""], ["Henderson", "Shane G.", ""], ["Hunter", "Susan R.", ""]]}, {"id": "1506.05157", "submitter": "Martin Schreiber", "authors": "Martin Schreiber, Adam Peddle, Terry Haut, Beth Wingate", "title": "A Decentralized Parallelization-in-Time Approach with Parareal", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With steadily increasing parallelism for high-performance architectures,\nsimulations requiring a good strong scalability are prone to be limited in\nscalability with standard spatial-decomposition strategies at a certain amount\nof parallel processors. This can be a show-stopper if the simulation results\nhave to be computed with wallclock time restrictions (e.g.\\,for weather\nforecasts) or as fast as possible (e.g. for urgent computing). Here, the\ntime-dimension is the only one left for parallelization and we focus on\nParareal as one particular parallelization-in-time method.\n  We discuss a software approach for making Parareal parallelization\ntransparent for application developers, hence allowing fast prototyping for\nParareal. Further, we introduce a decentralized Parareal which results in\nautonomous simulation instances which only require communicating with the\nprevious and next simulation instances, hence with strong locality for\ncommunication. This concept is evaluated by a prototypical solver for the\nrotational shallow-water equations which we use as a representative black-box\nsolver.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 21:46:19 GMT"}, {"version": "v2", "created": "Sat, 27 Feb 2016 14:51:22 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Schreiber", "Martin", ""], ["Peddle", "Adam", ""], ["Haut", "Terry", ""], ["Wingate", "Beth", ""]]}, {"id": "1506.05158", "submitter": "Taylor Arnold", "authors": "Taylor Arnold", "title": "An Entropy Maximizing Geohash for Distributed Spatiotemporal Database\n  Indexing", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a modification of the standard geohash algorithm based on maximum\nentropy encoding in which the data volume is approximately constant for a given\nhash prefix length. Distributed spatiotemporal databases, which typically\nrequire interleaving spatial and temporal elements into a single key, reap\nlarge benefits from a balanced geohash by creating a consistent ratio between\nspatial and temporal precision even across areas of varying data density. This\nproperty is also useful for indexing purely spatial datasets, where the load\ndistribution of large range scans is an important aspect of query performance.\nWe apply our algorithm to data generated proportional to population as given by\ncensus block population counts provided from the US Census Bureau.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 21:54:12 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Arnold", "Taylor", ""]]}, {"id": "1506.05172", "submitter": "Jaimie Kelley", "authors": "Jaimie Kelley, Christopher Stewart, Nathaniel Morris, Devesh Tiwari,\n  Yuxiong He, and Sameh Elnikety", "title": "Measuring and Managing Answer Quality for Online Data-Intensive Services", "comments": "Technical Report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online data-intensive services parallelize query execution across distributed\nsoftware components. Interactive response time is a priority, so online query\nexecutions return answers without waiting for slow running components to\nfinish. However, data from these slow components could lead to better answers.\nWe propose Ubora, an approach to measure the effect of slow running components\non the quality of answers. Ubora randomly samples online queries and executes\nthem twice. The first execution elides data from slow components and provides\nfast online answers; the second execution waits for all components to complete.\nUbora uses memoization to speed up mature executions by replaying network\nmessages exchanged between components. Our systems-level implementation works\nfor a wide range of platforms, including Hadoop/Yarn, Apache Lucene, the\nEasyRec Recommendation Engine, and the OpenEphyra question answering system.\nUbora computes answer quality much faster than competing approaches that do not\nuse memoization. With Ubora, we show that answer quality can and should be used\nto guide online admission control. Our adaptive controller processed 37% more\nqueries than a competing controller guided by the rate of timeouts.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 00:04:35 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Kelley", "Jaimie", ""], ["Stewart", "Christopher", ""], ["Morris", "Nathaniel", ""], ["Tiwari", "Devesh", ""], ["He", "Yuxiong", ""], ["Elnikety", "Sameh", ""]]}, {"id": "1506.05261", "submitter": "Shiqiang Wang", "authors": "Shiqiang Wang, Rahul Urgaonkar, Murtaza Zafer, Ting He, Kevin Chan,\n  Kin K. Leung", "title": "Dynamic Service Migration in Mobile Edge Computing Based on Markov\n  Decision Process", "comments": "Journal version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In mobile edge computing, local edge servers can host cloud-based services,\nwhich reduces network overhead and latency but requires service migrations as\nusers move to new locations. It is challenging to make migration decisions\noptimally because of the uncertainty in such a dynamic cloud environment. In\nthis paper, we formulate the service migration problem as a Markov Decision\nProcess (MDP). Our formulation captures general cost models and provides a\nmathematical framework to design optimal service migration policies. In order\nto overcome the complexity associated with computing the optimal policy, we\napproximate the underlying state space by the distance between the user and\nservice locations. We show that the resulting MDP is exact for uniform\none-dimensional user mobility while it provides a close approximation for\nuniform two-dimensional mobility with a constant additive error. We also\npropose a new algorithm and a numerical technique for computing the optimal\nsolution which is significantly faster than traditional methods based on\nstandard value or policy iteration. We illustrate the application of our\nsolution in practical scenarios where many theoretical assumptions are relaxed.\nOur evaluations based on real-world mobility traces of San Francisco taxis show\nsuperior performance of the proposed solution compared to baseline solutions.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 09:53:23 GMT"}, {"version": "v2", "created": "Wed, 8 May 2019 21:06:15 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Wang", "Shiqiang", ""], ["Urgaonkar", "Rahul", ""], ["Zafer", "Murtaza", ""], ["He", "Ting", ""], ["Chan", "Kevin", ""], ["Leung", "Kin K.", ""]]}, {"id": "1506.05323", "submitter": "Michael Brim", "authors": "Neena Imam, Michael Brim, Sarp Oral", "title": "Proceedings of the 2015 International Workshop on the Lustre Ecosystem:\n  Challenges and Opportunities", "comments": "International Workshop on the Lustre Ecosystem: Challenges and\n  Opportunities, March 2015, Annapolis MD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Lustre parallel file system has been widely adopted by high-performance\ncomputing (HPC) centers as an effective system for managing large-scale storage\nresources. Lustre achieves unprecedented aggregate performance by parallelizing\nI/O over file system clients and storage targets at extreme scales. Today, 7\nout of 10 fastest supercomputers in the world use Lustre for high-performance\nstorage. To date, Lustre development has focused on improving the performance\nand scalability of large-scale scientific workloads. In particular, large-scale\ncheckpoint storage and retrieval, which is characterized by bursty I/O from\ncoordinated parallel clients, has been the primary driver of Lustre development\nover the last decade. With the advent of extreme scale computing and Big Data\ncomputing, many HPC centers are seeing increased user interest in running\ndiverse workloads that place new demands on Lustre. In March 2015, the\nInternational Workshop on the Lustre Ecosystem: Challenges and Opportunities\nwas held in Annapolis, Maryland at the Historic Inns of Annapolis Governor\nCalvert House. This workshop series is intended to help explore improvements in\nthe performance and flexibility of Lustre for supporting diverse application\nworkloads. The 2015 workshop was the inaugural edition, and the goal was to\ninitiate a discussion on the open challenges associated with enhancing Lustre\nfor diverse applications, the technological advances necessary, and the\nassociated impacts to the Lustre ecosystem. The workshop program featured a day\nof tutorials and a day of technical paper presentations.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 13:21:48 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Imam", "Neena", ""], ["Brim", "Michael", ""], ["Oral", "Sarp", ""]]}, {"id": "1506.05348", "submitter": "John Marshall", "authors": "J. S. Marshall, M. A. Thomson", "title": "The Pandora Software Development Kit for Pattern Recognition", "comments": "Accepted by European Physical Journal C, 4 September 2015", "journal-ref": null, "doi": "10.1140/epjc/s10052-015-3659-3", "report-no": null, "categories": "physics.data-an cs.DC hep-ex physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of automated solutions to pattern recognition problems is\nimportant in many areas of scientific research and human endeavour. This paper\ndescribes the implementation of the Pandora Software Development Kit, which\naids the process of designing, implementing and running pattern recognition\nalgorithms. The Pandora Application Programming Interfaces ensure simple\nspecification of the building-blocks defining a pattern recognition problem.\nThe logic required to solve the problem is implemented in algorithms. The\nalgorithms request operations to create or modify data structures and the\noperations are performed by the Pandora framework. This design promotes an\napproach using many decoupled algorithms, each addressing specific topologies.\nDetails of algorithms addressing two pattern recognition problems in High\nEnergy Physics are presented: reconstruction of events at a high-energy e+e-\nlinear collider and reconstruction of cosmic ray or neutrino events in a liquid\nargon time projection chamber.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jun 2015 15:06:59 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2015 15:31:06 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Marshall", "J. S.", ""], ["Thomson", "M. A.", ""]]}, {"id": "1506.05442", "submitter": "James Ross", "authors": "James A. Ross, David A. Richie, Song J. Park, Dale R. Shires", "title": "Parallel Programming Model for the Epiphany Many-Core Coprocessor Using\n  Threaded MPI", "comments": "7 pages, 6 figures, presented at ISCA'15, Third ACM International\n  Workshop on Manycore Embedded Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The Adapteva Epiphany many-core architecture comprises a 2D tiled mesh\nNetwork-on-Chip (NoC) of low-power RISC cores with minimal uncore\nfunctionality. It offers high computational energy efficiency for both integer\nand floating point calculations as well as parallel scalability. Yet despite\nthe interesting architectural features, a compelling programming model has not\nbeen presented to date. This paper demonstrates an efficient parallel\nprogramming model for the Epiphany architecture based on the Message Passing\nInterface (MPI) standard. Using MPI exploits the similarities between the\nEpiphany architecture and a conventional parallel distributed cluster of serial\ncores. Our approach enables MPI codes to execute on the RISC array processor\nwith little modification and achieve high performance. We report benchmark\nresults for the threaded MPI implementation of four algorithms (dense\nmatrix-matrix multiplication, N-body particle interaction, a five-point 2D\nstencil update, and 2D FFT) and highlight the importance of fast inter-core\ncommunication for the architecture.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 19:39:41 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Ross", "James A.", ""], ["Richie", "David A.", ""], ["Park", "Song J.", ""], ["Shires", "Dale R.", ""]]}, {"id": "1506.05443", "submitter": "Marco  Netto", "authors": "Andre Abrantes D. P. Souza, Marco A. S. Netto", "title": "Using Application Data for SLA-aware Auto-scaling in Cloud Environments", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the establishment of cloud computing as the environment of choice for\nmost modern applications, auto-scaling is an economic matter of great\nimportance. For applications like stream computing that process ever changing\namounts of data, modifying the number and configuration of resources to meet\nperformance requirements becomes essential. Current solutions on auto-scaling\nare mostly rule-based using infrastructure level metrics such as\nCPU/memory/network utilization, and system level metrics such as throughput and\nresponse time. In this paper, we introduce a study on how effective\nauto-scaling can be using data generated by the application itself. To make\nthis assessment, two algorithms are proposed that use a priori knowledge of the\ndata stream and use sentiment analysis from soccer-related tweets, triggering\nauto-scaling operations according to rapid changes in the public sentiment\nabout the soccer players that happens just before big bursts of messages. Our\napplication-based auto-scaling was able to reduce the number of SLA violations\nby up to 95% and reduce resource requirements by up to 33%.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jun 2015 19:52:04 GMT"}], "update_date": "2015-06-18", "authors_parsed": [["Souza", "Andre Abrantes D. P.", ""], ["Netto", "Marco A. S.", ""]]}, {"id": "1506.05579", "submitter": "Qingyuan Gong", "authors": "Qingyuan Gong, Jiaqi Wang, Yan Wang, Dongsheng Wei, Jin Wang, Xin Wang", "title": "Topology-Aware Node Selection for Data Regeneration in Heterogeneous\n  Distributed Storage Systems", "comments": "14pages, 7 pages, 4 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed storage systems introduce redundancy to protect data from node\nfailures. After a storage node fails, the lost data should be regenerated at a\nreplacement storage node as soon as possible to maintain the same level of\nredundancy. Minimizing such a regeneration time is critical to the reliability\nof distributed storage systems. Existing work commits to reduce the\nregeneration time by either minimizing the regenerating traffic, or adjusting\nthe regenerating traffic patterns, whereas nodes participating data\nregeneration are generally assumed to be given beforehand. However, such\nregeneration time also depends heavily on the selection of the participating\nnodes. Selecting different participating nodes actually involve different data\nlinks between the nodes. Real-world distributed storage systems usually exhibit\nheterogeneous link capacities. It is possible to further reduce the\nregeneration time via exploiting such link capacity differences and avoiding\nthe link bottlenecks. In this paper, we consider the minimization of the\nregeneration time by selecting the participating nodes in heterogeneous\nnetworks. We analyze the regeneration time and propose node selection\nalgorithms for overlay networks and real-world topologies. Considering that the\nflexible amount of data blocks from each provider may deeply influence the\nregeneration time, several techniques are designed to enhance our schemes in\noverlay networks. Experimental results show that our node selection schemes can\nsignificantly reduce the regeneration time for each topology, especially in\npractical networks with heterogeneous link capacities.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jun 2015 08:12:12 GMT"}], "update_date": "2015-06-19", "authors_parsed": [["Gong", "Qingyuan", ""], ["Wang", "Jiaqi", ""], ["Wang", "Yan", ""], ["Wei", "Dongsheng", ""], ["Wang", "Jin", ""], ["Wang", "Xin", ""]]}, {"id": "1506.05996", "submitter": "Rajesh Gandham", "authors": "J.-F. Remacle, R. Gandham, T. Warburton", "title": "GPU accelerated spectral finite elements on all-hex meshes", "comments": "23 pages, 7 figures", "journal-ref": null, "doi": "10.1016/j.jcp.2016.08.005", "report-no": null, "categories": "cs.CE cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a spectral element finite element scheme that efficiently\nsolves elliptic problems on unstructured hexahedral meshes. The discrete\nequations are solved using a matrix-free preconditioned conjugate gradient\nalgorithm. An additive Schwartz two-scale preconditioner is employed that\nallows h-independence convergence. An extensible multi-threading programming\nAPI is used as a common kernel language that allows runtime selection of\ndifferent computing devices (GPU and CPU) and different threading interfaces\n(CUDA, OpenCL and OpenMP). Performance tests demonstrate that problems with\nover 50 million degrees of freedom can be solved in a few seconds on an\noff-the-shelf GPU.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jun 2015 13:27:05 GMT"}], "update_date": "2016-09-21", "authors_parsed": [["Remacle", "J. -F.", ""], ["Gandham", "R.", ""], ["Warburton", "T.", ""]]}, {"id": "1506.06194", "submitter": "Matthew Knepley", "authors": "Matthew G. Knepley and Michael Lange and Gerard J. Gorman", "title": "Unstructured Overlapping Mesh Distribution in Parallel", "comments": "14 pages, 6 figures, submitted to TOMS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple mathematical framework and API for parallel mesh and data\ndistribution, load balancing, and overlap generation. It relies on viewing the\nmesh as a Hasse diagram, abstracting away information such as cell shape,\ndimension, and coordinates. The high level of abstraction makes our interface\nboth concise and powerful, as the same algorithm applies to any representable\nmesh, such as hybrid meshes, meshes embedded in higher dimension, and\noverlapped meshes in parallel. We present evidence, both theoretical and\nexperimental, that the algorithms are scalable and efficient. A working\nimplementation can be found in the latest release of the PETSc libraries.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2015 02:25:14 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Knepley", "Matthew G.", ""], ["Lange", "Michael", ""], ["Gorman", "Gerard J.", ""]]}, {"id": "1506.06275", "submitter": "Konrad Siek", "authors": "Konrad Siek and Pawe{\\l} T. Wojciechowski", "title": "Last-use Opacity: A Strong Safety Property for Transactional Memory with\n  Early Release Support", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transaction Memory (TM) is a concurrency control abstraction that allows the\nprogrammer to specify blocks of code to be executed atomically as transactions.\nHowever, since transactional code can contain just about any operation\nattention must be paid to the state of shared variables at any given time.\nE.g., contrary to a database transaction, if a TM transaction reads a stale\nvalue it may execute dangerous operations, like attempt to divide by zero,\naccess an illegal memory address, or enter an infinite loop. Thus\nserializability is insufficient, and stronger safety properties are required in\nTM, which regulate what values can be read, even by transactions that abort.\nHence, a number of TM safety properties were developed, including opacity, and\nTMS1 and TMS2. However, such strong properties preclude using early release as\na technique for optimizing TM, because they virtually forbid reading from live\ntransactions. On the other hand, properties that do allow early release are\neither not strong enough to prevent any of the problems mentioned above\n(recoverability), or add additional conditions on transactions with early\nrelease that limit their applicability (elastic opacity, live opacity, virtual\nworld consistency). This paper introduces last-use opacity, a new TM safety\nproperty that is meant to be a compromise between strong properties like\nopacity and serializability. The property eliminates all but a small class of\ninconsistent views and poses no stringent conditions on transactions. For\nillustration, we present a last-use opaque TM algorithm and show that it\nsatisfies the new safety property.\n", "versions": [{"version": "v1", "created": "Sat, 20 Jun 2015 18:09:09 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2015 09:13:28 GMT"}, {"version": "v3", "created": "Fri, 25 Mar 2016 13:18:39 GMT"}], "update_date": "2016-03-28", "authors_parsed": [["Siek", "Konrad", ""], ["Wojciechowski", "Pawe\u0142 T.", ""]]}, {"id": "1506.06648", "submitter": "Chetan Chawla", "authors": "Chetan Chawla and Inderveer Chana", "title": "Strategy-proof Pricing Approach for Cloud Market", "comments": "Includes 2 Figures, 2 Tables and 4 Pages. Presented in International\n  Conference on Communication, Information and Computing Technology (ICCICT-15)\n  held in Amritsar on 12-13 May, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  In this paper, we design and develop a pricing model applicable to strategy\nproof pricing. To provide an economic stability towards its consumers. The\neconomic model we use is Vickrey-Clarke-Groves (VCG). By this each service\nprovider has to provide a true cost of its services in the cloud market. For\nthe selection of suitable service for the consumer we adopt a dynamic\nprograming based algorithm and VCG is used to calculate the payment. Strategy\nproof pricing offers a unique cloud pricing service that takes the complexity\nout of traditional pricing and enables cloud providers to price accurately,\nconsistently and competitively\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 15:23:54 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Chawla", "Chetan", ""], ["Chana", "Inderveer", ""]]}, {"id": "1506.06671", "submitter": "Ethan R. Elenberg", "authors": "Ethan R. Elenberg, Karthikeyan Shanmugam, Michael Borokhovich,\n  Alexandros G. Dimakis", "title": "Beyond Triangles: A Distributed Framework for Estimating 3-profiles of\n  Large Graphs", "comments": "To appear in part at KDD'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC cs.DS cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of approximating the $3$-profile of a large graph.\n$3$-profiles are generalizations of triangle counts that specify the number of\ntimes a small graph appears as an induced subgraph of a large graph. Our\nalgorithm uses the novel concept of $3$-profile sparsifiers: sparse graphs that\ncan be used to approximate the full $3$-profile counts for a given large graph.\nFurther, we study the problem of estimating local and ego $3$-profiles, two\ngraph quantities that characterize the local neighborhood of each vertex of a\ngraph.\n  Our algorithm is distributed and operates as a vertex program over the\nGraphLab PowerGraph framework. We introduce the concept of edge pivoting which\nallows us to collect $2$-hop information without maintaining an explicit\n$2$-hop neighborhood list at each vertex. This enables the computation of all\nthe local $3$-profiles in parallel with minimal communication.\n  We test out implementation in several experiments scaling up to $640$ cores\non Amazon EC2. We find that our algorithm can estimate the $3$-profile of a\ngraph in approximately the same time as triangle counting. For the harder\nproblem of ego $3$-profiles, we introduce an algorithm that can estimate\nprofiles of hundreds of thousands of vertices in parallel, in the timescale of\nminutes.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 16:34:16 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Elenberg", "Ethan R.", ""], ["Shanmugam", "Karthikeyan", ""], ["Borokhovich", "Michael", ""], ["Dimakis", "Alexandros G.", ""]]}, {"id": "1506.06684", "submitter": "Gordon Inggs", "authors": "Gordon Inggs, David B. Thomas, George Constantinides, Wayne Luk", "title": "Seeing Shapes in Clouds: On the Performance-Cost trade-off for\n  Heterogeneous Infrastructure-as-a-Service", "comments": "Presented at Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015) (arXiv:1508.06320)", "journal-ref": null, "doi": null, "report-no": "FSP/2015/10", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the near future FPGAs will be available by the hour, however this new\nInfrastructure as a Service (IaaS) usage mode presents both an opportunity and\na challenge: The opportunity is that programmers can potentially trade\nresources for performance on a much larger scale, for much shorter periods of\ntime than before. The challenge is in finding and traversing the trade-off for\nheterogeneous IaaS that guarantees increased resources result in the greatest\npossible increased performance. Such a trade-off is Pareto optimal. The Pareto\noptimal trade-off for clusters of heterogeneous resources can be found by\nsolving multiple, multi-objective optimisation problems, resulting in an\noptimal allocation of tasks to the available platforms. Solving these\noptimisation programs can be done using simple heuristic approaches or formal\nMixed Integer Linear Programming (MILP) techniques. When pricing 128 financial\noptions using a Monte Carlo algorithm upon a heterogeneous cluster of Multicore\nCPU, GPU and FPGA platforms, the MILP approach produces a trade-off that is up\nto 110% faster than a heuristic approach, and over 50% cheaper. These results\nsuggest that high quality performance-resource trade-offs of heterogeneous IaaS\nare best realised through a formal optimisation approach.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 17:14:59 GMT"}, {"version": "v2", "created": "Tue, 23 Jun 2015 16:00:04 GMT"}, {"version": "v3", "created": "Fri, 14 Aug 2015 07:30:43 GMT"}, {"version": "v4", "created": "Thu, 27 Aug 2015 15:55:26 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Inggs", "Gordon", ""], ["Thomas", "David B.", ""], ["Constantinides", "George", ""], ["Luk", "Wayne", ""]]}, {"id": "1506.06715", "submitter": "Morteza Zadimoghaddam", "authors": "Vahab Mirrokni and Morteza Zadimoghaddam", "title": "Randomized Composable Core-sets for Distributed Submodular Maximization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An effective technique for solving optimization problems over massive data\nsets is to partition the data into smaller pieces, solve the problem on each\npiece and compute a representative solution from it, and finally obtain a\nsolution inside the union of the representative solutions for all pieces. This\ntechnique can be captured via the concept of {\\em composable core-sets}, and\nhas been recently applied to solve diversity maximization problems as well as\nseveral clustering problems. However, for coverage and submodular maximization\nproblems, impossibility bounds are known for this technique \\cite{IMMM14}. In\nthis paper, we focus on efficient construction of a randomized variant of\ncomposable core-sets where the above idea is applied on a {\\em random\nclustering} of the data. We employ this technique for the coverage, monotone\nand non-monotone submodular maximization problems. Our results significantly\nimprove upon the hardness results for non-randomized core-sets, and imply\nimproved results for submodular maximization in a distributed and streaming\nsettings.\n  In summary, we show that a simple greedy algorithm results in a\n$1/3$-approximate randomized composable core-set for submodular maximization\nunder a cardinality constraint. This is in contrast to a known $O({\\log k\\over\n\\sqrt{k}})$ impossibility result for (non-randomized) composable core-set. Our\nresult also extends to non-monotone submodular functions, and leads to the\nfirst 2-round MapReduce-based constant-factor approximation algorithm with\n$O(n)$ total communication complexity for either monotone or non-monotone\nfunctions. Finally, using an improved analysis technique and a new algorithm\n$\\mathsf{PseudoGreedy}$, we present an improved $0.545$-approximation algorithm\nfor monotone submodular maximization, which is in turn the first\nMapReduce-based algorithm beating factor $1/2$ in a constant number of rounds.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 18:50:41 GMT"}], "update_date": "2015-06-23", "authors_parsed": [["Mirrokni", "Vahab", ""], ["Zadimoghaddam", "Morteza", ""]]}, {"id": "1506.06817", "submitter": "Rati Gelashvili", "authors": "Rati Gelashvili", "title": "On the Optimal Space Complexity of Consensus for Anonymous Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The optimal space complexity of consensus in shared memory is a decades-old\nopen problem. For a system of $n$ processes, no algorithm is known that uses a\nsublinear number of registers. However, the best known lower bound due to Fich,\nHerlihy, and Shavit requires $\\Omega(\\sqrt{n})$ registers.\n  The special symmetric case of the problem where processes are anonymous (run\nthe same algorithm) has also attracted attention. Even in this case, the best\nlower and upper bounds are still $\\Omega(\\sqrt{n})$ and $O(n)$. Moreover, Fich,\nHerlihy, and Shavit first proved their lower bound for anonymous processes, and\nthen extended it to the general case. As such, resolving the anonymous case\nmight be a significant step towards understanding and solving the general\nproblem.\n  In this work, we show that in a system of anonymous processes, any consensus\nalgorithm satisfying nondeterministic solo termination has to use $\\Omega(n)$\nread-write registers in some execution. This implies an $\\Omega(n)$ lower bound\non the space complexity of deterministic obstruction-free and randomized\nwait-free consensus, matching the upper bound and closing the symmetric case of\nthe open problem.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jun 2015 23:31:27 GMT"}, {"version": "v2", "created": "Mon, 17 Aug 2015 01:31:38 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Gelashvili", "Rati", ""]]}, {"id": "1506.07020", "submitter": "Mayank Mishra", "authors": "Mayank Mishra and Umesh Bellur", "title": "De-Fragmenting the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing VM placement schemes have measured their effectiveness solely by\nlooking either Physical Machine's resources(CPU, memory) or network resource.\nHowever, real applications use all resource types to varying degrees. The\nresult of applying existing placement schemes to VMs running real applications\nis a fragmented data center where resources along one dimension become unusable\neven though they are available because of the unavailability of resources along\nother dimensions. An example of this fragmentation is unusable CPU because of a\nbottlenecked network link from the physical machine which has available CPU. To\ndate, evaluations of the efficacy of VM placement schemes has not recognized\nthis fragmentation and it's ill effects, let alone try to measure it and avoid\nit. In this paper, we first define the notion of what we term \"relative\nresource fragmentation\" and illustrate how it can be measured in a data center.\nThe metric we put forth for capturing the degree of fragmentation is\ncomprehensive and includes all key data center resource types. We then propose\na scheme of minimizing this fragmentation so as to maximize the availability of\nexisting set of data center resources. Results of empirical evaluations of our\nplacement scheme compared to existing network based placement schemes show a\nreduction of fragmentation by as much as 15% and increase in number of\nsuccessfully placed applications by upto 20%.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 14:16:34 GMT"}], "update_date": "2015-06-24", "authors_parsed": [["Mishra", "Mayank", ""], ["Bellur", "Umesh", ""]]}, {"id": "1506.07118", "submitter": "Moshe Sulamy", "authors": "Yehuda Afek, Deborah M. Gordon, and Moshe Sulamy", "title": "Idle Ants Have a Role", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using elementary distributed computing techniques we suggest an explanation\nfor two unexplained phenomena in regards to ant colonies, (a) a substantial\namount of ants in an ant colony are idle, and (b) the observed low\nsurvivability of new ant colonies in nature. Ant colonies employ task\nallocation, in which ants progress from one task to the other, to meet changing\ndemands introduced by the environment. Extending the biological task allocation\nmodel given in [Pacala, Gordon and Godfray 1996] we present a distributed\nalgorithm which mimics the mechanism ants use to solve task allocation\nefficiently in nature. Analyzing the time complexity of the algorithm reveals\nan exponential gap on the time it takes an ant colony to satisfy a certain work\ndemand with and without idle ants. We provide an $O(\\ln n)$ upper bound when a\nconstant fraction of the colony are idle ants, and a contrasting lower bound of\n$\\Omega(n)$ when there are no idle ants, where $n$ is the total number of ants\nin the colony.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jun 2015 18:06:14 GMT"}, {"version": "v2", "created": "Fri, 20 May 2016 15:50:47 GMT"}], "update_date": "2016-05-23", "authors_parsed": [["Afek", "Yehuda", ""], ["Gordon", "Deborah M.", ""], ["Sulamy", "Moshe", ""]]}, {"id": "1506.07584", "submitter": "Jaderick Pabico", "authors": "Jaderick P. Pabico", "title": "Synchronization of ad hoc Clock Networks", "comments": "11 pages, 9 figures, appeared in H.N. Adorna and A.A. Sioson (eds.)\n  Proceedings of the 7th National Symposium on Mathematical Aspects of Computer\n  Science (SMACS 2014), Ateneo de Naga University, Naga City, Philippines,\n  24-28 November 2014, pp. 33-43. Paper submitted to Philippine Computing\n  Journal (ISSN 1908-1995)", "journal-ref": "Philippine Computing Journal 10(1):22-32, August 2015", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a graph-theoretic approach to synchronizing clocks in an {\\em ad\nhoc} network of $N$~timepieces. Clocks naturally drift away from being\nsynchronized because of many physical factors. The manual way of clock\nsynchronization suffers from an inherrent propagation of the so called \"clock\ndrift\" due to \"word-of-mouth effect.\" The current standard way of automated\nclock synchronization is either via radio band transmission of the global clock\nor via the software-based Network Time Protocol (NTP). Synchronization via\nradio band transmission suffers from the wave transmission delay, while the\nclient-server-based NTP does not scale to increased number of clients as well\nas to unforeseen server overload conditions (e.g., flash crowd and time-of-day\neffects). Further, the trivial running time of NTP for synchronizing an\n$N$-node network, where each node is a clock and the NTP server follows a\nsingle-port communication model, is~$\\bigO(N)$. We introduce in this paper a\n$\\bigO(\\log N)$ time for synchronizing the clocks in exchange for an increase\nof $\\bigO(N)$ in space complexity, though through creative \"tweaking,\" we later\nreduced the space requirement to~$\\bigO(1)$. Our graph-theoretic protocol\nassumes that the network is $\\K_N$, while the subset of clocks are in an\nembedded circulant graph $\\C_{n<N}^q$ with $q$~jumps and clock information is\ncommunicated through circular shifts within the $\\C_{n<N}^q$. All $N$~nodes\ncommunicate via a single-port duplex channel model. Theoretically, this\nsynchronization protocol allows for $N(\\log N)^{-1} - 1$ more synchronizations\nthan the client-server-based one. Empirically through statistically replicated\nmulti-agent-based microsimulation runs, our protocol allows at most 80\\% of the\nclocks synchronized compared to the current protocol which only allows up to\n30\\% after some steady-state time.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jun 2015 23:50:40 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Pabico", "Jaderick P.", ""]]}, {"id": "1506.07723", "submitter": "Jin Wang", "authors": "Chengjin Jia, Jin Wang, Yanqin Zhu, Xin Wang, Kejie Lu, Xiumin Wang,\n  Zhengqing Wen", "title": "On the Optimal Provider Selection for Repair in Distributed Storage\n  System with Network Coding", "comments": "This paper has been withdrawn by the author due to several crucial\n  errors in formulations", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In large-scale distributed storage systems (DSS), reliability is provided by\nredundancy spread over storage servers across the Internet. Network coding (NC)\nhas been widely studied in DSS because it can improve the reliability with low\nrepair time. To maintain reliability, an unavailable storage server should be\nfirstly replaced by a new server, named new comer. Then, multiple storage\nservers, called providers, should be selected from surviving servers and send\ntheir coded data through the Internet to the new comer for regenerating the\nlost data. Therefore, in a large-scale DSS, provider selection and data routing\nduring the regeneration phase have great impact on the performance of\nregeneration time. In this paper, we investigate a problem of optimal provider\nselection and data routing for minimizing the regeneration time in the DSS with\nNC. Specifically, we first define the problem in the DSS with NC. For the case\nthat the providers are given, we model the problem as a mathematical\nprogramming. Based on the mathematical programming, we then formulate the\noptimal provider selection and data routing problem as an integer linear\nprogramming problem and develop an efficient near-optimal algorithm based on\nlinear programming relaxation (BLP). Finally, extensive simulation experiments\nhave been conducted, and the results show the effectiveness of the proposed\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 12:24:57 GMT"}, {"version": "v2", "created": "Sun, 15 Nov 2015 00:50:18 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Jia", "Chengjin", ""], ["Wang", "Jin", ""], ["Zhu", "Yanqin", ""], ["Wang", "Xin", ""], ["Lu", "Kejie", ""], ["Wang", "Xiumin", ""], ["Wen", "Zhengqing", ""]]}, {"id": "1506.07742", "submitter": "Ahsan Javed Awan", "authors": "Ahsan Javed Awan, Mats Brorsson, Vladimir Vlassov and Eduard Ayguade", "title": "Performance Characterization of In-Memory Data Analytics on a Modern\n  Cloud Server", "comments": "Accepted to The 5th IEEE International Conference on Big Data and\n  Cloud Computing (BDCloud 2015)", "journal-ref": null, "doi": "10.1109/BDCloud.2015.37", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In last decade, data analytics have rapidly progressed from traditional\ndisk-based processing to modern in-memory processing. However, little effort\nhas been devoted at enhancing performance at micro-architecture level. This\npaper characterizes the performance of in-memory data analytics using Apache\nSpark framework. We use a single node NUMA machine and identify the bottlenecks\nhampering the scalability of workloads. We also quantify the inefficiencies at\nmicro-architecture level for various data analysis workloads. Through empirical\nevaluation, we show that spark workloads do not scale linearly beyond twelve\nthreads, due to work time inflation and thread level load imbalance. Further,\nat the micro-architecture level, we observe memory bound latency to be the\nmajor cause of work time inflation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 13:23:54 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Awan", "Ahsan Javed", ""], ["Brorsson", "Mats", ""], ["Vlassov", "Vladimir", ""], ["Ayguade", "Eduard", ""]]}, {"id": "1506.07895", "submitter": "Sebastien Tixeuil", "authors": "Jordan Adamek, Mikhail Nesterenko, S\\'ebastien Tixeuil (NPA, LINCS,\n  IUF, LIP6)", "title": "Stateless Geocasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present two stateless algorithms that guarantee to deliver the message to\nevery device in a designated geographic area: flooding and planar geocasting.\nDue to the algorithms' statelessness, intermediate devices do not have to keep\nmessage data between message transmissions. We formally prove the algorithms\ncorrect, estimate their message complexity and evaluate their performance\nthrough simulation.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jun 2015 20:39:32 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Adamek", "Jordan", "", "NPA, LINCS,\n  IUF, LIP6"], ["Nesterenko", "Mikhail", "", "NPA, LINCS,\n  IUF, LIP6"], ["Tixeuil", "S\u00e9bastien", "", "NPA, LINCS,\n  IUF, LIP6"]]}, {"id": "1506.07933", "submitter": "Amir Gholami", "authors": "Amir Gholami, Judith Hill, Dhairya Malhotra, George Biros", "title": "AccFFT: A library for distributed-memory FFT on CPU and GPU\n  architectures", "comments": "Parallel FFT Library", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new library for parallel distributed Fast Fourier Transforms\n(FFT). The importance of FFT in science and engineering and the advances in\nhigh performance computing necessitate further improvements. AccFFT extends\nexisting FFT libraries for CUDA-enabled Graphics Processing Units (GPUs) to\ndistributed memory clusters. We use overlapping communication method to reduce\nthe overhead of PCIe transfers from/to GPU. We present numerical results on the\nMaverick platform at the Texas Advanced Computing Center (TACC) and on the\nTitan system at the Oak Ridge National Laboratory (ORNL). We present the\nscaling of the library up to 4,096 K20 GPUs of Titan.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 01:19:31 GMT"}, {"version": "v2", "created": "Tue, 22 Sep 2015 19:58:27 GMT"}, {"version": "v3", "created": "Wed, 25 May 2016 20:06:16 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Gholami", "Amir", ""], ["Hill", "Judith", ""], ["Malhotra", "Dhairya", ""], ["Biros", "George", ""]]}, {"id": "1506.07943", "submitter": "Lei Wang", "authors": "Lei Wang, Jianfeng Zhan, Zhen Jia, Rui Han", "title": "Characterization and Architectural Implications of Big Data Workloads", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data areas are expanding in a fast way in terms of increasing workloads\nand runtime systems, and this situation imposes a serious challenge to workload\ncharacterization, which is the foundation of innovative system and architecture\ndesign. The previous major efforts on big data benchmarking either propose a\ncomprehensive but a large amount of workloads, or only select a few workloads\naccording to so-called popularity, which may lead to partial or even biased\nobservations. In this paper, on the basis of a comprehensive big data benchmark\nsuite---BigDataBench, we reduced 77 workloads to 17 representative workloads\nfrom a micro-architectural perspective. On a typical state-of-practice\nplatform---Intel Xeon E5645, we compare the representative big data workloads\nwith SPECINT, SPECCFP, PARSEC, CloudSuite and HPCC. After a comprehensive\nworkload characterization, we have the following observations. First, the big\ndata workloads are data movement dominated computing with more branch\noperations, taking up to 92% percentage in terms of instruction mix, which\nplaces them in a different class from Desktop (SPEC CPU2006), CMP (PARSEC), HPC\n(HPCC) workloads. Second, corroborating the previous work, Hadoop and Spark\nbased big data workloads have higher front-end stalls. Comparing with the\ntraditional workloads i. e. PARSEC, the big data workloads have larger\ninstructions footprint. But we also note that, in addition to varied\ninstruction-level parallelism, there are significant disparities of front-end\nefficiencies among different big data workloads. Third, we found complex\nsoftware stacks that fail to use state-of-practise processors efficiently are\none of the main factors leading to high front-end stalls. For the same\nworkloads, the L1I cache miss rates have one order of magnitude differences\namong diverse implementations with different software stacks.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 02:29:22 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Wang", "Lei", ""], ["Zhan", "Jianfeng", ""], ["Jia", "Zhen", ""], ["Han", "Rui", ""]]}, {"id": "1506.07952", "submitter": "Avery Miller", "authors": "Avery Miller, Andrzej Pelc", "title": "Tradeoffs Between Cost and Information for Rendezvous and Treasure Hunt", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In rendezvous, two agents traverse network edges in synchronous rounds and\nhave to meet at some node. In treasure hunt, a single agent has to find a\nstationary target situated at an unknown node of the network. We study\ntradeoffs between the amount of information ($\\mathit{advice}$) available\n$\\mathit{a\\ priori}$ to the agents and the cost (number of edge traversals) of\nrendezvous and treasure hunt. Our goal is to find the smallest size of advice\nwhich enables the agents to solve these tasks at some cost $C$ in a network\nwith $e$ edges. This size turns out to depend on the initial distance $D$ and\non the ratio $\\frac{e}{C}$, which is the $\\mathit{relative\\ cost\\ gain}$ due to\nadvice. For arbitrary graphs, we give upper and lower bounds of $O(D\\log(D\\cdot\n\\frac{e}{C}) +\\log\\log e)$ and $\\Omega(D\\log \\frac{e}{C})$, respectively, on\nthe optimal size of advice. For the class of trees, we give nearly tight upper\nand lower bounds of $O(D\\log \\frac{e}{C} + \\log\\log e)$ and $\\Omega (D\\log\n\\frac{e}{C})$, respectively.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 04:12:25 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Miller", "Avery", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1506.07957", "submitter": "Reza Hajisheykhi", "authors": "Reza Hajisheykhi, Mohammad Roohitavaf, Sandeep Kulkarni", "title": "Auditable Restoration of Distributed Programs", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on a protocol for auditable restoration of distributed systems. The\nneed for such protocol arises due to conflicting requirements (e.g., access to\nthe system should be restricted but emergency access should be provided). One\ncan design such systems with a tamper detection approach (based on the\nintuition of \"break the glass door\"). However, in a distributed system, such\ntampering, which are denoted as auditable events, is visible only for a single\nnode. This is unacceptable since the actions they take in these situations can\nbe different than those in the normal mode. Moreover, eventually, the auditable\nevent needs to be cleared so that system resumes the normal operation.\n  With this motivation, in this paper, we present a protocol for auditable\nrestoration, where any process can potentially identify an auditable event.\nWhenever a new auditable event occurs, the system must reach an \"auditable\nstate\" where every process is aware of the auditable event. Only after the\nsystem reaches an auditable state, it can begin the operation of restoration.\nAlthough any process can observe an auditable event, we require that only\n\"authorized\" processes can begin the task of restoration. Moreover, these\nprocesses can begin the restoration only when the system is in an auditable\nstate. Our protocol is self-stabilizing and has bounded state space. It can\neffectively handle the case where faults or auditable events occur during the\nrestoration protocol. Moreover, it can be used to provide auditable restoration\nto other distributed protocol.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 04:52:24 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Hajisheykhi", "Reza", ""], ["Roohitavaf", "Mohammad", ""], ["Kulkarni", "Sandeep", ""]]}, {"id": "1506.07964", "submitter": "Jaderick Pabico", "authors": "Jaderick P. Pabico", "title": "A Framework for a Multiagent-based Scheduling of Parallel Jobs", "comments": "8 pages, 8 figures, in R.P. Salda\\~na (ed.) Proceedings of the 6th\n  Philippine Computing Science Congress (PCSC 2006), Ateneo De Manila\n  University, Loyola Heights, Quezon City, Philippines, 28-29 March 2006, pp.\n  81-88 (CDROM ISSN 1908-1146)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a multiagent approach as a paradigm for scheduling\nparallel jobs in a parallel system. Scheduling parallel jobs is performed as a\nmeans to balance the load of a system in order to improve the performance of a\nparallel application. Parallel job scheduling is presented as a mapping between\ntwo graphs: one represents the dependency of jobs and the other represents the\ninterconnection among processors. The usual implementation of parallel job\nscheduling algorithms is via the master-slave paradigm. The master-slave\nparadigm has inherent communication bottleneck that reduces the performance of\nthe system when more processors are needed to process the jobs. The multiagent\napproach attempts to distribute the communication latency among the processors\nwhich improves the performance of the system as the number of participating\nprocessors increases. Presented in this paper is a framework for the behavior\nof an autonomous agent that cooperates with other agents to achieve a community\ngoal of minimizing the processing time. Achieving this goal means an agent must\ntruthfully share information with other agents via {\\em normalization}, {\\em\ntask sharing}, and {\\em result sharing} procedures. The agents consider a\nparallel scientific application as a finite-horizon game where truthful\ninformation sharing results into performance improvement for the parallel\napplication. The performance of the multiagent-based algorithm is compared to\nthat of an existing one via a simulation of the wavepacket dynamics using the\nquantum trajectory method (QTM) as a test application. The average parallel\ncost of running the QTM using the multiagent-based system is lower at higher\nnumber of processors.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jun 2015 06:23:11 GMT"}], "update_date": "2015-06-29", "authors_parsed": [["Pabico", "Jaderick P.", ""]]}, {"id": "1506.08258", "submitter": "Ali Pinar", "authors": "Janine C. Bennett, Ankit Bhagatwala, Jacqueline H. Chen, C. Seshadhri,\n  Ali Pinar, Maher Salloum", "title": "Trigger detection for adaptive scientific workflows using percentile\n  sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Increasing complexity of scientific simulations and HPC architectures are\ndriving the need for adaptive workflows, where the composition and execution of\ncomputational and data manipulation steps dynamically depend on the\nevolutionary state of the simulation itself. Consider for example, the\nfrequency of data storage. Critical phases of the simulation should be captured\nwith high frequency and with high fidelity for post-analysis, however we cannot\nafford to retain the same frequency for the full simulation due to the high\ncost of data movement. We can instead look for triggers, indicators that the\nsimulation will be entering a critical phase and adapt the workflow\naccordingly.\n  We present a method for detecting triggers and demonstrate its use in direct\nnumerical simulations of turbulent combustion using S3D. We show that chemical\nexplosive mode analysis (CEMA) can be used to devise a noise-tolerant indicator\nfor rapid increase in heat release. However, exhaustive computation of CEMA\nvalues dominates the total simulation, thus is prohibitively expensive. To\novercome this bottleneck, we propose a quantile-sampling approach. Our\nalgorithm comes with provable error/confidence bounds, as a function of the\nnumber of samples. Most importantly, the number of samples is independent of\nthe problem size, thus our proposed algorithm offers perfect scalability. Our\nexperiments on homogeneous charge compression ignition (HCCI) and reactivity\ncontrolled compression ignition (RCCI) simulations show that the proposed\nmethod can detect rapid increases in heat release, and its computational\noverhead is negligible. Our results will be used for dynamic workflow decisions\nabout data storage and mesh resolution in future combustion simulations.\nProposed framework is generalizable and we detail how it could be applied to a\nbroad class of scientific simulation workflows.\n", "versions": [{"version": "v1", "created": "Sat, 27 Jun 2015 04:34:26 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Bennett", "Janine C.", ""], ["Bhagatwala", "Ankit", ""], ["Chen", "Jacqueline H.", ""], ["Seshadhri", "C.", ""], ["Pinar", "Ali", ""], ["Salloum", "Maher", ""]]}, {"id": "1506.08505", "submitter": "Jeremy Kepner", "authors": "Matthew Hubbell, Andrew Moran, William Arcand, David Bestor, Bill\n  Bergeron, Chansup Byun, Vijay Gadepally, Peter Michaleas, Julie Mullen,\n  Andrew Prout, Albert Reuther, Antonio Rosa, Charles Yee, Jeremy Kepner", "title": "Big Data Strategies for Data Center Infrastructure Management Using a 3D\n  Gaming Platform", "comments": "6 pages; accepted to IEEE High Peformance Extreme Computing (HPEC)\n  conference 2015", "journal-ref": null, "doi": "10.1109/HPEC.2015.7322471", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High Performance Computing (HPC) is intrinsically linked to effective Data\nCenter Infrastructure Management (DCIM). Cloud services and HPC have become key\ncomponents in Department of Defense and corporate Information Technology\ncompetitive strategies in the global and commercial spaces. As a result, the\nreliance on consistent, reliable Data Center space is more critical than ever.\nThe costs and complexity of providing quality DCIM are constantly being tested\nand evaluated by the United States Government and companies such as Google,\nMicrosoft and Facebook. This paper will demonstrate a system where Big Data\nstrategies and 3D gaming technology is leveraged to successfully monitor and\nanalyze multiple HPC systems and a lights-out modular HP EcoPOD 240a Data\nCenter on a singular platform. Big Data technology and a 3D gaming platform\nenables the relative real time monitoring of 5000 environmental sensors, more\nthan 3500 IT data points and display visual analytics of the overall operating\ncondition of the Data Center from a command center over 100 miles away. In\naddition, the Big Data model allows for in depth analysis of historical trends\nand conditions to optimize operations achieving even greater efficiencies and\nreliability.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 04:42:04 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Hubbell", "Matthew", ""], ["Moran", "Andrew", ""], ["Arcand", "William", ""], ["Bestor", "David", ""], ["Bergeron", "Bill", ""], ["Byun", "Chansup", ""], ["Gadepally", "Vijay", ""], ["Michaleas", "Peter", ""], ["Mullen", "Julie", ""], ["Prout", "Andrew", ""], ["Reuther", "Albert", ""], ["Rosa", "Antonio", ""], ["Yee", "Charles", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1506.08506", "submitter": "Jeremy Kepner", "authors": "Andrew Prout, Jeremy Kepner, Peter Michaleas, William Arcand, David\n  Bestor, Bill Bergeron, Chansup Byun, Lauren Edwards, Vijay Gadepally, Matthew\n  Hubbell, Julie Mullen, Antonio Rosa, Charles Yee, Albert Reuther", "title": "Enabling On-Demand Database Computing with MIT SuperCloud Database\n  Management System", "comments": "6 pages; accepted to IEEE High Performance Extreme Computing (HPEC)\n  conference 2015. arXiv admin note: text overlap with arXiv:1406.4923", "journal-ref": null, "doi": "10.1109/HPEC.2015.7322482", "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The MIT SuperCloud database management system allows for rapid creation and\nflexible execution of a variety of the latest scientific databases, including\nApache Accumulo and SciDB. It is designed to permit these databases to run on a\nHigh Performance Computing Cluster (HPCC) platform as seamlessly as any other\nHPCC job. It ensures the seamless migration of the databases to the resources\nassigned by the HPCC scheduler and centralized storage of the database files\nwhen not running. It also permits snapshotting of databases to allow\nresearchers to experiment and push the limits of the technology without\nconcerns for data or productivity loss if the database becomes unstable.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 04:47:20 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Prout", "Andrew", ""], ["Kepner", "Jeremy", ""], ["Michaleas", "Peter", ""], ["Arcand", "William", ""], ["Bestor", "David", ""], ["Bergeron", "Bill", ""], ["Byun", "Chansup", ""], ["Edwards", "Lauren", ""], ["Gadepally", "Vijay", ""], ["Hubbell", "Matthew", ""], ["Mullen", "Julie", ""], ["Rosa", "Antonio", ""], ["Yee", "Charles", ""], ["Reuther", "Albert", ""]]}, {"id": "1506.08603", "submitter": "Paris Carbone", "authors": "Paris Carbone, Gyula F\\'ora, Stephan Ewen, Seif Haridi, Kostas Tzoumas", "title": "Lightweight Asynchronous Snapshots for Distributed Dataflows", "comments": "8 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": "ISBN 978-91-7595-651-0", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed stateful stream processing enables the deployment and execution\nof large scale continuous computations in the cloud, targeting both low latency\nand high throughput. One of the most fundamental challenges of this paradigm is\nproviding processing guarantees under potential failures. Existing approaches\nrely on periodic global state snapshots that can be used for failure recovery.\nThose approaches suffer from two main drawbacks. First, they often stall the\noverall computation which impacts ingestion. Second, they eagerly persist all\nrecords in transit along with the operation states which results in larger\nsnapshots than required. In this work we propose Asynchronous Barrier\nSnapshotting (ABS), a lightweight algorithm suited for modern dataflow\nexecution engines that minimises space requirements. ABS persists only operator\nstates on acyclic execution topologies while keeping a minimal record log on\ncyclic dataflows. We implemented ABS on Apache Flink, a distributed analytics\nengine that supports stateful stream processing. Our evaluation shows that our\nalgorithm does not have a heavy impact on the execution, maintaining linear\nscalability and performing well with frequent snapshots.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 12:33:49 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Carbone", "Paris", ""], ["F\u00f3ra", "Gyula", ""], ["Ewen", "Stephan", ""], ["Haridi", "Seif", ""], ["Tzoumas", "Kostas", ""]]}, {"id": "1506.08612", "submitter": "Sabri Pllana", "authors": "Suejb Memeti and Sabri Pllana", "title": "Accelerating DNA Sequence Analysis using Intel Xeon Phi", "comments": "PBio at ISPA-2015, Helsinki, Finland, 20-22 August, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Genetic information is increasing exponentially, doubling every 18 months.\nAnalyzing this information within a reasonable amount of time requires parallel\ncomputing resources. While considerable research has addressed DNA analysis\nusing GPUs, so far not much attention has been paid to the Intel Xeon Phi\ncoprocessor. In this paper we present an algorithm for large-scale DNA analysis\nthat exploits thread-level and the SIMD parallelism of the Intel Xeon Phi. We\nevaluate our approach for various numbers of cores and thread allocation\naffinities in the context of real-world DNA sequences of mouse, cat, dog,\nchicken, human and turkey. The experimental results on Intel Xeon Phi show\nspeed-ups of up to 10x compared to a sequential implementation running on an\nIntel Xeon processor E5.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jun 2015 13:27:13 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Memeti", "Suejb", ""], ["Pllana", "Sabri", ""]]}, {"id": "1506.08907", "submitter": "Sidharth Kashyap N", "authors": "Sidharth N. Kashyap, Ade J. Fewings, Jay Davies, Ian Morris, Andrew\n  Thomas Thomas Green, Martyn F. Guest", "title": "Big Data at HPC Wales", "comments": "Accepted for publication at the 'Big Data Analytics Workshop' - 2014\n  http://web.ornl.gov/sci/knowledgediscovery/CloudComputing/PDAC-SC14/BDAC-14-Agenda.htm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an automated approach to handling Big Data workloads on\nHPC systems. We describe a solution that dynamically creates a unified cluster\nbased on YARN in an HPC Environment, without the need to configure and allocate\na dedicated Hadoop cluster. The end user can choose to write the solution in\nany combination of supported frameworks, a solution that scales seamlessly from\na few cores to thousands of cores. This coupling of environments creates a\nplatform for applications to utilize the native HPC solutions along with the\nBig Data Frameworks. The user will be provided with HPC Wales APIs in multiple\nlanguages that will let them integrate this flow into their environment,\nthereby ensuring that the traditional means of HPC access do not become a\nbottleneck. We describe the behavior of the cluster creation and performance\nresults on Terasort.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 00:18:11 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Kashyap", "Sidharth N.", ""], ["Fewings", "Ade J.", ""], ["Davies", "Jay", ""], ["Morris", "Ian", ""], ["Green", "Andrew Thomas Thomas", ""], ["Guest", "Martyn F.", ""]]}, {"id": "1506.08953", "submitter": "Sufian Hameed", "authors": "Sufian Hameed and Usman Ali", "title": "On the Efficacy of Live DDoS Detection with Hadoop", "comments": null, "journal-ref": null, "doi": "10.1109/NOMS.2016.7502848", "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Denial of Service flooding attacks are one of the biggest\nchallenges to the availability of online services today. These DDoS attacks\noverwhelm the victim with huge volume of traffic and render it incapable of\nperforming normal communication or crashes it completely. If there are delays\nin detecting the flooding attacks, nothing much can be done except to manually\ndisconnect the victim and fix the problem. With the rapid increase of DDoS\nvolume and frequency, the current DDoS detection technologies are challenged to\ndeal with huge attack volume in reasonable and affordable response time.\n  In this paper, we propose HADEC, a Hadoop based Live DDoS Detection framework\nto tackle efficient analysis of flooding attacks by harnessing MapReduce and\nHDFS. We implemented a counter-based DDoS detection algorithm for four major\nflooding attacks (TCP-SYN, HTTP GET, UDP and ICMP) in MapReduce, consisting of\nmap and reduce functions. We deployed a testbed to evaluate the performance of\nHADEC framework for live DDoS detection. Based on the experiments we showed\nthat HADEC is capable of processing and detecting DDoS attacks in affordable\ntime.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 06:35:59 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Hameed", "Sufian", ""], ["Ali", "Usman", ""]]}, {"id": "1506.08978", "submitter": "Michael Bar-Sinai", "authors": "Michael Bar-Sinai", "title": "Big Data Technology Literature Review", "comments": "10 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  A short overview of various algorithms and technologies that are helpful for\nbig data storage and manipulation. Includes pointers to papers for further\nreading, and, where applicable, pointers to open source projects implementing a\ndescribed storage type.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 07:55:46 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2015 21:30:41 GMT"}], "update_date": "2015-12-04", "authors_parsed": [["Bar-Sinai", "Michael", ""]]}, {"id": "1506.08988", "submitter": "Francisco Igual", "authors": "Sandra Catal\\'an, Francisco D. Igual, Rafael Mayo, Rafael\n  Rodr\\'iguez-S\\'anchez and Enrique S. Quintana-Ort\\'i", "title": "Architecture-Aware Configuration and Scheduling of Matrix Multiplication\n  on Asymmetric Multicore Processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Asymmetric multicore processors (AMPs) have recently emerged as an appealing\ntechnology for severely energy-constrained environments, especially in mobile\nappliances where heterogeneity in applications is mainstream. In addition,\ngiven the growing interest for low-power high performance computing, this type\nof architectures is also being investigated as a means to improve the\nthroughput-per-Watt of complex scientific applications.\n  In this paper, we design and embed several architecture-aware optimizations\ninto a multi-threaded general matrix multiplication (gemm), a key operation of\nthe BLAS, in order to obtain a high performance implementation for ARM\nbig.LITTLE AMPs. Our solution is based on the reference implementation of gemm\nin the BLIS library, and integrates a cache-aware configuration as well as\nasymmetric--static and dynamic scheduling strategies that carefully tune and\ndistribute the operation's micro-kernels among the big and LITTLE cores of the\ntarget processor. The experimental results on a Samsung Exynos 5422, a\nsystem-on-chip with ARM Cortex-A15 and Cortex-A7 clusters that implements the\nbig.LITTLE model, expose that our cache-aware versions of gemm with asymmetric\nscheduling attain important gains in performance with respect to its\narchitecture-oblivious counterparts while exploiting all the resources of the\nAMP to deliver considerable energy efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 08:35:15 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Catal\u00e1n", "Sandra", ""], ["Igual", "Francisco D.", ""], ["Mayo", "Rafael", ""], ["Rodr\u00edguez-S\u00e1nchez", "Rafael", ""], ["Quintana-Ort\u00ed", "Enrique S.", ""]]}, {"id": "1506.09067", "submitter": "Sabri Pllana", "authors": "Andre Viebke and Sabri Pllana", "title": "The Potential of the Intel Xeon Phi for Supervised Deep Learning", "comments": "The 17th IEEE International Conference on High Performance Computing\n  and Communications (HPCC 2015), Aug. 24 - 26, 2015, New York, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Supervised learning of Convolutional Neural Networks (CNNs), also known as\nsupervised Deep Learning, is a computationally demanding process. To find the\nmost suitable parameters of a network for a given application, numerous\ntraining sessions are required. Therefore, reducing the training time per\nsession is essential to fully utilize CNNs in practice. While numerous research\ngroups have addressed the training of CNNs using GPUs, so far not much\nattention has been paid to the Intel Xeon Phi coprocessor. In this paper we\ninvestigate empirically and theoretically the potential of the Intel Xeon Phi\nfor supervised learning of CNNs. We design and implement a parallelization\nscheme named CHAOS that exploits both the thread- and SIMD-parallelism of the\ncoprocessor. Our approach is evaluated on the Intel Xeon Phi 7120P using the\nMNIST dataset of handwritten digits for various thread counts and CNN\narchitectures. Results show a 103.5x speed up when training our large network\nfor 15 epochs using 244 threads, compared to one thread on the coprocessor.\nMoreover, we develop a performance model and use it to assess our\nimplementation and answer what-if questions.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jun 2015 12:54:09 GMT"}], "update_date": "2015-07-01", "authors_parsed": [["Viebke", "Andre", ""], ["Pllana", "Sabri", ""]]}]