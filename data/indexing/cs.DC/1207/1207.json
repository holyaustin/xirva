[{"id": "1207.0203", "submitter": "Rajkumar Buyya", "authors": "Jayavardhana Gubbi, Rajkumar Buyya, Slaven Marusic, and Marimuthu\n  Palaniswami", "title": "Internet of Things (IoT): A Vision, Architectural Elements, and Future\n  Directions", "comments": "19 pages, 8 figures", "journal-ref": null, "doi": null, "report-no": "Technical Report CLOUDS-TR-2012-2, Cloud Computing and Distributed\n  Systems Laboratory, The University of Melbourne, June 29, 2012", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ubiquitous sensing enabled by Wireless Sensor Network (WSN) technologies cuts\nacross many areas of modern day living. This offers the ability to measure,\ninfer and understand environmental indicators, from delicate ecologies and\nnatural resources to urban environments. The proliferation of these devices in\na communicating-actuating network creates the Internet of Things (IoT),\nwherein, sensors and actuators blend seamlessly with the environment around us,\nand the information is shared across platforms in order to develop a common\noperating picture (COP). Fuelled by the recent adaptation of a variety of\nenabling device technologies such as RFID tags and readers, near field\ncommunication (NFC) devices and embedded sensor and actuator nodes, the IoT has\nstepped out of its infancy and is the the next revolutionary technology in\ntransforming the Internet into a fully integrated Future Internet. As we move\nfrom www (static pages web) to web2 (social networking web) to web3 (ubiquitous\ncomputing web), the need for data-on-demand using sophisticated intuitive\nqueries increases significantly. This paper presents a cloud centric vision for\nworldwide implementation of Internet of Things. The key enabling technologies\nand application domains that are likely to drive IoT research in the near\nfuture are discussed. A cloud implementation using Aneka, which is based on\ninteraction of private and public clouds is presented. We conclude our IoT\nvision by expanding on the need for convergence of WSN, the Internet and\ndistributed computing directed at technological research community.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2012 13:10:15 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Gubbi", "Jayavardhana", ""], ["Buyya", "Rajkumar", ""], ["Marusic", "Slaven", ""], ["Palaniswami", "Marimuthu", ""]]}, {"id": "1207.0226", "submitter": "Shantanu Das", "authors": "Zohir Bouzid, Shantanu Das, S\\'ebastien Tixeuil", "title": "Wait-Free Gathering of Mobile Robots", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of gathering multiple mobile robots to a single location, is one\nof the fundamental problems in distributed coordination between autonomous\nrobots. The problem has been studied and solved even for robots that are\nanonymous, disoriented, memoryless and operate in the semi-synchronous (ATOM)\nmodel. However all known solutions require the robots to be faulty-free except\nfor the results of [Agmon and Peleg 2006] who solve the gathering problem in\npresence of one crash fault. This leaves open the question of whether gathering\nof correct robots can be achieved in the presence of multiple crash failures.\nWe resolve the question in this paper and show how to solve gathering, when any\nnumber of robots may crash at any time during the algorithm, assuming strong\nmultiplicity detection and chirality. In contrast it is known that for the more\nstronger byzantine faults, it is impossible to gather even in a 3-robot system\nif one robot is faulty. Our algorithm solves the gathering of correct robots in\nthe semi-synchronous model where an adversary may stop any robot before\nreaching its desired destination. Further the algorithm is self-stabilizing as\nit achieves gathering starting from any configuration (except the bivalent\nconfiguration where deterministic gathering is impossible).\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2012 16:27:42 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Bouzid", "Zohir", ""], ["Das", "Shantanu", ""], ["Tixeuil", "S\u00e9bastien", ""]]}, {"id": "1207.0252", "submitter": "Amos Korman", "authors": "Pierre Fraigniaud and Amos Korman and Merav Parter and David Peleg", "title": "Randomized Distributed Decision", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper tackles the power of randomization in the context of locality by\nanalyzing the ability to`boost' the success probability of deciding a\ndistributed language. The main outcome of this analysis is that the distributed\ncomputing setting contrasts significantly with the sequential one as far as\nrandomization is concerned. Indeed, we prove that in some cases, the ability to\nincrease the success probability for deciding distributed languages is rather\nlimited. Informally, a (p,q)-decider for a language L is a distributed\nrandomized algorithm which accepts instances in L with probability at least p\nand rejects instances outside of L with probability at least q. It is known\nthat every hereditary language that can be decided in t rounds by a\n(p,q)-decider, where p^2+q>1, can actually be decided deterministically in O(t)\nrounds. In one of our results we give evidence supporting the conjecture that\nthe above statement holds for all distributed languages. This is achieved by\nconsidering the restricted case of path topologies. We then turn our attention\nto the range below the aforementioned threshold, namely, the case where\np^2+q\\leq1. We define B_k(t) to be the set of all languages decidable in at\nmost t rounds by a (p,q)-decider, where p^{1+1/k}+q>1. It is easy to see that\nevery language is decidable (in zero rounds) by a (p,q)-decider satisfying\np+q=1. Hence, the hierarchy B_k provides a spectrum of complexity classes\nbetween determinism and complete randomization. We prove that all these classes\nare separated: for every integer k\\geq 1, there exists a language L satisfying\nL\\in B_{k+1}(0) but L\\notin B_k(t) for any t=o(n). In addition, we show that\nB_\\infty(t) does not contain all languages, for any t=o(n). Finally, we show\nthat if the inputs can be restricted in certain ways, then the ability to boost\nthe success probability becomes almost null.\n", "versions": [{"version": "v1", "created": "Sun, 1 Jul 2012 23:16:12 GMT"}], "update_date": "2012-07-03", "authors_parsed": [["Fraigniaud", "Pierre", ""], ["Korman", "Amos", ""], ["Parter", "Merav", ""], ["Peleg", "David", ""]]}, {"id": "1207.0602", "submitter": "Tomasz Jurdzinski", "authors": "Tomasz Jurdzinski and Dariusz R. Kowalski", "title": "Distributed backbone structure for deterministic algorithms in the SINR\n  model of wireless networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Signal-to-Interference-and-Noise-Ratio (SINR) physical model is one of\nthe legitimate models of wireless networks. Despite of the vast amount of study\ndone in design and analysis of centralized algorithms supporting wireless\ncommunication under the SINR physical model, little is known about distributed\nalgorithms in this model, especially deterministic ones. In this work we\nconstruct, in a deterministic distributed way, a backbone structure on the top\nof a given wireless network, which can be used for transforming many algorithms\ndesigned in a simpler model of ad hoc broadcast networks without interference\ninto the SINR physical model with uniform power of stations, without increasing\ntheir asymptotic time complexity. The time cost of the backbone data structure\nconstruction is only O(Delta polylog n) rounds, where Delta is roughly the\ninverse of network density and n is the number of nodes in the whole network.\nThe core of the construction is a novel combinatorial structure called\nSINR-selector, which is introduced and constructed in this paper. We\ndemonstrate the power of the backbone data structure by using it for obtaining\nefficient O(D+Delta polylog n)-round and O(D+k+Delta polylog n)-round\ndeterministic distributed solutions for leader election and multi-broadcast,\nrespectively, where D is the network diameter and k is the number of messages\nto be disseminated.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 08:10:21 GMT"}, {"version": "v2", "created": "Mon, 16 Jul 2012 14:53:15 GMT"}], "update_date": "2012-07-17", "authors_parsed": [["Jurdzinski", "Tomasz", ""], ["Kowalski", "Dariusz R.", ""]]}, {"id": "1207.0753", "submitter": "Deng Li", "authors": "Jiaqi Liu, Zhong Ren, Deng Li", "title": "MPO: An Efficient and Low-cost Peer-to-Peer Overlay for Autonomic\n  Communications", "comments": "37 pages,9 figures,37 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The term Autonomic Communication (AC) refers to self-managing systems which\nare capable of supporting self-configuration, self-healing and\nself-optimization. However, information reflection and collection, lack of\ncentralized control, non-cooperation and so on are just some of the challenges\nwithin AC systems. We have considered these problems in theory and practice and\nreached the following conclusion; in order to build an ideal system for\nautonomic communication, there are three key problems to be solved. Motivated\nby the need for AC, we have designed an efficient and low-cost Peer-to-Peer\n(P2P) overlay called Maya-Pyramid overlay (MPO) and combined merits of\nunstructured P2P with those of structured P2P overlays. Differing from the\ntraditional hierarchical P2P (i.e. tree-like structure) overlay, (1) MPO is\ncomposed of levels and layers, which uses small world characteristic to improve\nefficiency, and the maintenance cost is decreased because update and backup\nonly take place in two neighboring levels or layers instead of recursively\nperform in higher levels. (2) Unlike normal redundant mechanisms for solving\nthe single fault problem: Tri-Information Center (Tri-IC) mechanism is\npresented in order to improve robustness by alleviating the load of cluster\nheads in a hierarchical P2P overlay. (3) A source ranking mechanism is proposed\nin order to discourage free riding and whitewashing and to encourage frequent\ninformation exchanges between peers. (4) Inspired by Pastry's ID structure for\na structured DHT algorithm, a 3D unique ID structure is presented in the\nunstructured P2P overlay. This will guarantee anonymity in routing, and will\nbe, not only more efficient because it applies the DHT-like routing algorithm\nin the unstructured P2P overlay, but also more adaptive to suit AC. Evaluation\nproved that MPO is robust, highly efficient and of a low-cost.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 17:14:01 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Liu", "Jiaqi", ""], ["Ren", "Zhong", ""], ["Li", "Deng", ""]]}, {"id": "1207.0780", "submitter": "Thirumala Rao B", "authors": "B. Thirumala Rao, L. S. S. Reddy", "title": "Survey on Improved Scheduling in Hadoop MapReduce in Cloud Environments", "comments": "5 Pages, 2 figures; International Journal of Computer Applications,\n  November 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Cloud Computing is emerging as a new computational paradigm shift.\nHadoop-MapReduce has become a powerful Computation Model for processing large\ndata on distributed commodity hardware clusters such as Clouds. In all Hadoop\nimplementations, the default FIFO scheduler is available where jobs are\nscheduled in FIFO order with support for other priority based schedulers also.\nIn this paper we study various scheduler improvements possible with Hadoop and\nalso provided some guidelines on how to improve the scheduling in Hadoop in\nCloud Environments.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 19:01:26 GMT"}], "update_date": "2012-07-04", "authors_parsed": [["Rao", "B. Thirumala", ""], ["Reddy", "L. S. S.", ""]]}, {"id": "1207.0790", "submitter": "H M N Dilum Bandara", "authors": "H. M. N. Dilum Bandara and Anura P. Jayasumana", "title": "Collaborative Applications over Peer-to-Peer Systems - Challenges and\n  Solutions", "comments": "Keywords - Collaborative applications, multi-attribute resources,\n  peer-to-peer, resource discovery; H. M. N. D. Bandara and A. P. Jayasumana,\n  \"Collaborative applications over peer-to-peer systems - Challenges and\n  solutions,\" Peer-to-Peer Networking and Applications, Springer, 2012", "journal-ref": null, "doi": "10.1007/s12083-012-0157-3", "report-no": null, "categories": "cs.DC cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Emerging collaborative Peer-to-Peer (P2P) systems require discovery and\nutilization of diverse, multi-attribute, distributed, and dynamic groups of\nresources to achieve greater tasks beyond conventional file and processor cycle\nsharing. Collaborations involving application specific resources and dynamic\nquality of service goals are stressing current P2P architectures. Salient\nfeatures and desirable characteristics of collaborative P2P systems are\nhighlighted. Resource advertising, selecting, matching, and binding, the\ncritical phases in these systems, and their associated challenges are reviewed\nusing examples from distributed collaborative adaptive sensing systems, cloud\ncomputing, and mobile social networks. State-of-the-art resource\ndiscovery/aggregation solutions are compared with respect to their\narchitecture, lookup overhead, load balancing, etc., to determine their ability\nto meet the goals and challenges of each critical phase. Incentives, trust,\nprivacy, and security issues are also discussed, as they will ultimately\ndetermine the success of a collaborative P2P system. Open issues and research\nopportunities that are essential to achieve the true potential of collaborative\nP2P systems are discussed.\n", "versions": [{"version": "v1", "created": "Tue, 3 Jul 2012 19:17:53 GMT"}, {"version": "v2", "created": "Sat, 7 Jul 2012 06:29:36 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Bandara", "H. M. N. Dilum", ""], ["Jayasumana", "Anura P.", ""]]}, {"id": "1207.0894", "submitter": "Thirumala Rao B", "authors": "B.Thirumala Rao, N.V.Sridevi, V.Krishna Reddy, L.S.S.Reddy", "title": "Performance Issues of Heterogeneous Hadoop Clusters in Cloud Computing", "comments": "6 Pages", "journal-ref": "Global Journal of Computer Science and Technology, Volume XI Issue\n  VIII May 2011", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Nowadays most of the cloud applications process large amount of data to\nprovide the desired results. Data volumes to be processed by cloud applications\nare growing much faster than computing power. This growth demands new\nstrategies for processing and analyzing information. Dealing with large data\nvolumes requires two things: 1) Inexpensive, reliable storage 2) New tools for\nanalyzing unstructured and structured data. Hadoop is a powerful open source\nsoftware platform that addresses both of these problems. The current Hadoop\nimplementation assumes that computing nodes in a cluster are homogeneous in\nnature. Hadoop lacks performance in heterogeneous clusters where the nodes have\ndifferent computing capacity. In this paper we address the issues that affect\nthe performance of hadoop in heterogeneous clusters and also provided some\nguidelines on how to overcome these bottlenecks\n", "versions": [{"version": "v1", "created": "Wed, 4 Jul 2012 04:18:03 GMT"}], "update_date": "2012-07-05", "authors_parsed": [["Rao", "B. Thirumala", ""], ["Sridevi", "N. V.", ""], ["Reddy", "V. Krishna", ""], ["Reddy", "L. S. S.", ""]]}, {"id": "1207.1337", "submitter": "Anissa Lamani", "authors": "Eddy Caron (LIP), Florent Chuffart (LIP), Anissa Lamani (MIS), Franck\n  Petit (LIP6)", "title": "Optimization in a Self-Stabilizing Service Discovery Framework for Large\n  Scale Systems", "comments": "(2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ability to find and get services is a key requirement in the development of\nlarge-scale distributed sys- tems. We consider dynamic and unstable\nenvironments, namely Peer-to-Peer (P2P) systems. In previous work, we designed\na service discovery solution called Distributed Lexicographic Placement Table\n(DLPT), based on a hierar- chical overlay structure. A self-stabilizing version\nwas given using the Propagation of Information with Feedback (PIF) paradigm. In\nthis paper, we introduce the self-stabilizing COPIF (for Collaborative PIF)\nscheme. An algo- rithm is provided with its correctness proof. We use this\napproach to improve a distributed P2P framework designed for the services\ndiscovery. Significantly efficient experimental results are presented.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jul 2012 19:38:00 GMT"}], "update_date": "2012-07-06", "authors_parsed": [["Caron", "Eddy", "", "LIP"], ["Chuffart", "Florent", "", "LIP"], ["Lamani", "Anissa", "", "MIS"], ["Petit", "Franck", "", "LIP6"]]}, {"id": "1207.1571", "submitter": "Tadeusz Tomczak", "authors": "Tadeusz Tomczak, Katarzyna Zadarnowska, Zbigniew Koza, Maciej Matyka,\n  {\\L}ukasz Miros{\\l}aw", "title": "Complete PISO and SIMPLE solvers on Graphics Processing Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We implemented the pressure-implicit with splitting of operators (PISO) and\nsemi-implicit method for pressure-linked equations (SIMPLE) solvers of the\nNavier-Stokes equations on Fermi-class graphics processing units (GPUs) using\nthe CUDA technology. We also introduced a new format of sparse matrices\noptimized for performing elementary CFD operations, like gradient or divergence\ndiscretization, on GPUs. We verified the validity of the implementation on\nseveral standard, steady and unsteady problems. Computational effciency of the\nGPU implementation was examined by comparing its double precision run times\nwith those of essentially the same algorithms implemented in OpenFOAM. The\nresults show that a GPU (Tesla C2070) can outperform a server-class 6-core,\n12-thread CPU (Intel Xeon X5670) by a factor of 4.2.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2012 10:02:26 GMT"}], "update_date": "2012-10-01", "authors_parsed": [["Tomczak", "Tadeusz", ""], ["Zadarnowska", "Katarzyna", ""], ["Koza", "Zbigniew", ""], ["Matyka", "Maciej", ""], ["Miros\u0142aw", "\u0141ukasz", ""]]}, {"id": "1207.1746", "submitter": "Mauro Bianco", "authors": "Mauro Bianco, Ugo Varetto", "title": "A Generic Library for Stencil Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this era of diverse and heterogeneous computer architectures, the\nprogrammability issues, such as productivity and portable efficiency, are\ncrucial to software development and algorithm design. One way to approach the\nproblem is to step away from traditional sequential programming languages and\nmove toward domain specific programming environments to balance between\nexpressivity and efficiency. In order to demonstrate this principle, we\ndeveloped a domain specific C++ generic library for stencil computations, like\nPDE solvers. The library features high level constructs to specify computation\nand allows the development of parallel stencil computations with very limited\neffort. The high abstraction constructs (like do_all and do_reduce) make the\nprogram shorter and cleaner with increased contextual information for better\nperformance exploitation. The results show good performance from Windows\nmulticores, to HPC clusters and machines with accelerators, like GPUs.\n", "versions": [{"version": "v1", "created": "Fri, 6 Jul 2012 23:30:06 GMT"}], "update_date": "2012-07-10", "authors_parsed": [["Bianco", "Mauro", ""], ["Varetto", "Ugo", ""]]}, {"id": "1207.1836", "submitter": "Pradipta Mitra", "authors": "Magnus M. Halldorsson and Pradipta Mitra", "title": "Towards Tight Bounds for Local Broadcasting", "comments": "15 pages, 1 figure, FOMC 2012, minor edits", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the local broadcasting problem in the SINR model, which is a\nbasic primitive for gathering initial information among $n$ wireless nodes.\nAssuming that nodes can measure received power, we achieve an essentially\noptimal constant approximate algorithm (with a $\\log^2 n$ additive term). This\nimproves upon the previous best $O(\\log n)$-approximate algorithm. Without\npower measurement, our algorithm achieves $O(\\log n)$-approximation, matching\nthe previous best result, but with a simpler approach that works under harsher\nconditions, such as arbitrary node failures. We give complementary lower bounds\nunder reasonable assumptions.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2012 02:51:21 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2012 14:51:07 GMT"}], "update_date": "2012-10-18", "authors_parsed": [["Halldorsson", "Magnus M.", ""], ["Mitra", "Pradipta", ""]]}, {"id": "1207.1852", "submitter": "Christoph Lenzen", "authors": "Christoph Lenzen", "title": "Optimal Deterministic Routing and Sorting on the Congested Clique", "comments": "16 pages, no figures; published at PODC 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a clique of n nodes, where in each synchronous round each pair of\nnodes can exchange O(log n) bits. We provide deterministic constant-time\nsolutions for two problems in this model. The first is a routing problem where\neach node is source and destination of n messages of size O(log n). The second\nis a sorting problem where each node i is given n keys of size O(log n) and\nneeds to receive the ith batch of n keys according to the global order of the\nkeys. The latter result also implies deterministic constant-round solutions for\nrelated problems such as selection or determining modes.\n", "versions": [{"version": "v1", "created": "Sun, 8 Jul 2012 07:49:22 GMT"}, {"version": "v2", "created": "Mon, 5 Nov 2012 15:56:59 GMT"}, {"version": "v3", "created": "Wed, 9 Jan 2013 17:26:25 GMT"}, {"version": "v4", "created": "Fri, 10 May 2013 18:04:50 GMT"}], "update_date": "2013-05-13", "authors_parsed": [["Lenzen", "Christoph", ""]]}, {"id": "1207.2367", "submitter": "Roberto Capuzzo-Dolcetta", "authors": "R. Capuzzo-Dolcetta (1), M. Spera (1) and D. Punzo (1) ((1) Dep. of\n  Physics, Sapienza, University of Roma, Roma, Italy)", "title": "A fully parallel, high precision, N-body code running on hybrid\n  computing platforms", "comments": "Paper submitted to Journal of Computational Physics consisting in 28\n  pages, 9 figures.The previous submitted version was lacking of the\n  bibliography, for a Tex problem", "journal-ref": null, "doi": "10.1016/j.jcp.2012.11.013", "report-no": null, "categories": "astro-ph.IM cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new implementation of the numerical integration of the\nclassical, gravitational, N-body problem based on a high order Hermite's\nintegration scheme with block time steps, with a direct evaluation of the\nparticle-particle forces. The main innovation of this code (called HiGPUs) is\nits full parallelization, exploiting both OpenMP and MPI in the use of the\nmulticore Central Processing Units as well as either Compute Unified Device\nArchitecture (CUDA) or OpenCL for the hosted Graphic Processing Units. We\ntested both performance and accuracy of the code using up to 256 GPUs in the\nsupercomputer IBM iDataPlex DX360M3 Linux Infiniband Cluster provided by the\nitalian supercomputing consortium CINECA, for values of N up to 8 millions. We\nwere able to follow the evolution of a system of 8 million bodies for few\ncrossing times, task previously unreached by direct summation codes. The code\nis freely available to the scientific community.\n", "versions": [{"version": "v1", "created": "Tue, 10 Jul 2012 14:30:05 GMT"}, {"version": "v2", "created": "Wed, 11 Jul 2012 07:58:33 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Capuzzo-Dolcetta", "R.", ""], ["Spera", "M.", ""], ["Punzo", "D.", ""]]}, {"id": "1207.2530", "submitter": "Gugan Thoppe", "authors": "Gugan Thoppe", "title": "Generalized Network Tomography", "comments": "8 Pages, Corrected Typos in Lemma 1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC math.ST stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For successful estimation, the usual network tomography algorithms crucially\nrequire i) end-to-end data generated using multicast probe packets, real or\nemulated, and ii) the network to be a tree rooted at a single sender with\ndestinations at leaves. These requirements, consequently, limit their scope of\napplication. In this paper, we address successfully a general problem,\nhenceforth called generalized network tomography, wherein the objective is to\nestimate the link performance parameters for networks with arbitrary topologies\nusing only end-to-end measurements of pure unicast probe packets.\nMathematically, given a binary matrix $A,$ we propose a novel algorithm to\nuniquely estimate the distribution of $X,$ a vector of independent non-negative\nrandom variables, given only IID samples of the components of the random vector\n$Y = AX.$ This algorithm, in fact, does not even require any prior knowledge of\nthe unknown distributions. The idea is to approximate the distribution of each\ncomponent of $X$ using linear combinations of known exponential bases and\nestimate the unknown weights. These weights are obtained by solving a set of\npolynomial systems based on the moment generating function of the components of\n$Y.$ For unique identifiability, it is only required that every pair of columns\nof the matrix $A$ be linearly independent, a property that holds true for the\nrouting matrices of all multicast tree networks. Matlab based simulations have\nbeen included to illustrate the potential of the proposed scheme.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 02:09:47 GMT"}, {"version": "v2", "created": "Thu, 1 Nov 2012 09:58:38 GMT"}], "update_date": "2012-11-02", "authors_parsed": [["Thoppe", "Gugan", ""]]}, {"id": "1207.2604", "submitter": "Peizhong Shi", "authors": "Yun Wang, Peizhong Shi, Kai Li and Jie Wu", "title": "DQSB: A Reliable Broadcast Protocol Based on Distributed\n  Quasi-Synchronized Mechanism for Low Duty-Cycled Wireless Sensor Networks", "comments": "21 pages with 13 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In duty-cycled wireless sensor networks, deployed sensor nodes are usually\nput to sleep for energy efficiency according to sleep scheduling approaches.\nAny sleep scheduling scheme with its supporting protocols ensures that data can\nalways be routed from source to sink. In this paper, we investigate a problem\nof multi-hop broadcast and routing in random sleep scheduling scheme, and\npropose a novel protocol, called DQSB, by quasi-synchronization mechanism to\nachieve reliable broadcast and less latency routing. DQSB neither assumes time\nsynchronization which requires all neighboring nodes wake up at the same time,\nnor assumes duty-cycled awareness which makes it difficult to use in\nasynchronous WSNs. Furthermore, the benefit of quasi-synchronized mechanism for\nbroadcast from sink to other nodes is the less latency routing paths for\nreverse data collection to sink because of no or less sleep waiting time.\nSimulation results show that DQSB outperforms the existing protocols in\nbroadcast times performance and keeps relative tolerant broadcast latency\nperformance, even in the case of unreliable links. The proposed DQSB protocol,\nin this paper, can be recognized as a tradeoff between broadcast times and\nbroadcast latency. We also explore the impact of parameters in the assumption\nand the approach to get proper values for supporting DQSB.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 11:34:30 GMT"}], "update_date": "2012-07-12", "authors_parsed": [["Wang", "Yun", ""], ["Shi", "Peizhong", ""], ["Li", "Kai", ""], ["Wu", "Jie", ""]]}, {"id": "1207.2704", "submitter": "Gaurav Raj", "authors": "Gaurav Raj, Ankit Nischal", "title": "Efficient Resource Allocation in Resource provisioning policies over\n  Resource Cloud Communication Paradigm", "comments": "8 pages, 4 Figures, International Journal on Cloud Computing:\n  Services and Architecture(IJCCSA),Vol.2, No.3, June 2012", "journal-ref": null, "doi": "10.5121/ijccsa.2012.2302", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Optimal resource utilization for executing tasks within the cloud is one of\nthe biggest challenges. In executing the task over a cloud, the resource\nprovisioner is responsible for providing the resources to create virtual\nmachines. To utilize the resources optimally, the resource provisioner has to\ntake care of the process of allocating resources to Virtual Machine Manager\n(VMM). In this paper, an efficient way to utilize the resources, within the\ncloud, to create virtual machines has been proposed considering optimum cost\nbased on performance factor. This performance factor depends upon the overall\ncost of the resource, communication channel cost, reliability and popularity\nfactor. We have proposed a framework for communication between resource owner\nand cloud using Resource Cloud Communication Paradigm (RCCP). We extend the\nCloudSim[2] adding provisioner policies and Efficient Resource Allocation (ERA)\nalgorithm in VMM allocation policy as a decision support for resource\nprovisioner.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 16:37:51 GMT"}], "update_date": "2012-07-12", "authors_parsed": [["Raj", "Gaurav", ""], ["Nischal", "Ankit", ""]]}, {"id": "1207.2706", "submitter": "Gaurav Raj", "authors": "Gaurav Raj, Kamaljit Kaur", "title": "Secure Cloud Communication for Effective Cost Management System through\n  MSBE", "comments": "12 pages, 3 figures, International Journal on Cloud Computing:\n  Services and Architecture(IJCCSA),Vol.2, No.3, June 2012", "journal-ref": null, "doi": "10.5121/ijccsa.2012.2303", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In Cloud Computing Architecture, Brokers are responsible to provide services\nto the end users. An Effective Cost Management System (ECMS) which works over\nSecure Cloud Communication Paradigm (SCCP) helps in finding a communication\nlink with overall minimum cost of links. We propose an improved Broker Cloud\nCommunication Paradigm (BCCP) with integration of security issues. Two\nalgorithms are included, first is Secure Optimized Route Cost Finder (S-ORCF)\nto find optimum route between broker and cloud on the behalf of cost factor and\nsecond is Secure Optimized Route Management (S-ORM) to maintain optimum route.\nThese algorithms proposed with cryptographic integrity of the secure route\ndiscovery process in efficient routing approaches between broker and cloud.\nThere is lack in Dynamic Source Routing Approach to verify whether any\nintermediate node has been deleted, inserted or modified with no valid\nauthentication. We use symmetric cryptographic primitives, which is made\npossible due to multisource broadcast encryption scheme. This paper outlines\nthe use of secure route discovery protocol (SRDP)that employs such a security\nparadigm in cloud computing.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 16:51:01 GMT"}], "update_date": "2012-07-12", "authors_parsed": [["Raj", "Gaurav", ""], ["Kaur", "Kamaljit", ""]]}, {"id": "1207.2708", "submitter": "Gaurav Raj", "authors": "Gaurav Raj, Sonika Setia", "title": "Effective Cost Mechanism for Cloudlet Retransmission and Prioritized VM\n  Scheduling Mechanism over Broker Virtual Machine Communication Framework", "comments": "10 pages, 5 figures, International Journal on Cloud Computing:\n  Services and Architecture(IJCCSA),Vol.2, No.3, June 2012", "journal-ref": null, "doi": "10.5121/ijccsa.2012.2305", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current scenario cloud computing is most widely increasing platform for\ntask execution. Lot of research is going on to cut down the cost and execution\ntime. In this paper, we propose an efficient algorithm to have an effective and\nfast execution of task assigned by the user. We proposed an effective\ncommunication framework between broker and virtual machine for assigning the\ntask and fetching the results in optimum time and cost using Broker Virtual\nMachine Communication Framework (BVCF). We implement it over cloudsim under VM\nscheduling policies by modification based on Virtual Machine Cost. Scheduling\nover Virtual Machine as well as over Cloudlets and Retransmission of Cloudlets\nare the basic building blocks of the proposed work on which the whole\narchitecture is dependent. Execution of cloudlets is being analyzed over Round\nRobin and FCFS scheduling policy.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 16:57:18 GMT"}], "update_date": "2012-07-12", "authors_parsed": [["Raj", "Gaurav", ""], ["Setia", "Sonika", ""]]}, {"id": "1207.2847", "submitter": "Kai Liu", "authors": "Kai Liu, Hock Beng Lim", "title": "Positioning Accuracy Improvement via Distributed Location Estimate in\n  Cooperative Vehicular Networks", "comments": "To appear in Proc. of the 15th International IEEE Conference on\n  Intelligent Transportation Systems (IEEE ITSC'12)", "journal-ref": null, "doi": "10.1109/ITSC.2012.6338743", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The development of cooperative vehicle safety (CVS) applications, such as\ncollision warnings, turning assistants, and speed advisories, etc., has\nreceived great attention in the past few years. Accurate vehicular localization\nis essential to enable these applications. In this study, motivated by the\nproliferation of the Global Positioning System (GPS) devices, and the\nincreasing sophistication of wireless communication technologies in vehicular\nnetworks, we propose a distributed location estimate algorithm to improve the\npositioning accuracy via cooperative inter-vehicle distance measurement. In\nparticular, we compute the inter-vehicle distance based on raw GPS pseudorange\nmeasurements, instead of depending on traditional radio-based ranging\ntechniques, which usually either suffer from high hardware cost or have\ninadequate positioning accuracy. In addition, we improve the estimation of the\nvehicles' locations only based on the inaccurate GPS fixes, without using any\nanchors with known exact locations. The algorithm is decentralized, which\nenhances its practicability in highly dynamic vehicular networks. We have\ndeveloped a simulation model to evaluate the performance of the proposed\nalgorithm, and the results demonstrate that the algorithm can significantly\nimprove the positioning accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 05:27:16 GMT"}, {"version": "v2", "created": "Sat, 14 Jul 2012 06:32:37 GMT"}, {"version": "v3", "created": "Fri, 20 Jul 2012 08:33:23 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Liu", "Kai", ""], ["Lim", "Hock Beng", ""]]}, {"id": "1207.2867", "submitter": "Ajay Kumar", "authors": "Ajay Kumar, Seema Bawa", "title": "Distributed and Big Data Storage Management in Grid Computing", "comments": "Data, Data Locality, DSSM, GOS, GRID, Virtualization, Web Services,\n  Virtual Organization", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Big data storage management is one of the most challenging issues for Grid\ncomputing environments, since large amount of data intensive applications\nfrequently involve a high degree of data access locality. Grid applications\ntypically deal with large amounts of data. In traditional approaches\nhigh-performance computing consists dedicated servers that are used to data\nstorage and data replication. In this paper we present a new mechanism for\ndistributed and big data storage and resource discovery services. Here we\nproposed an architecture named Dynamic and Scalable Storage Management (DSSM)\narchitecture in grid environments. This allows in grid computing not only\nsharing the computational cycles, but also share the storage space. The storage\ncan be transparently accessed from any grid machine, allowing easy data sharing\namong grid users and applications. The concept of virtual ids that, allows the\ncreation of virtual spaces has been introduced and used. The DSSM divides all\nGrid Oriented Storage devices (nodes) into multiple geographically distributed\ndomains and to facilitate the locality and simplify the intra-domain storage\nmanagement. Grid service based storage resources are adopted to stack simple\nmodular service piece by piece as demand grows. To this end, we propose four\naxes that define: DSSM architecture and algorithms description, Storage\nresources and resource discovery into Grid service, Evaluate purpose prototype\nsystem, dynamically, scalability, and bandwidth, and Discuss results.\nAlgorithms at bottom and upper level for standardization dynamic and scalable\nstorage management, along with higher bandwidths have been designed.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 07:55:50 GMT"}], "update_date": "2012-07-13", "authors_parsed": [["Kumar", "Ajay", ""], ["Bawa", "Seema", ""]]}, {"id": "1207.2878", "submitter": "Ghobad Zarrinchian", "authors": "Mohsen Soryani, Morteza Analoui, Ghobad Zarrinchian", "title": "A Novel Process Mapping Strategy in Clustered Environments", "comments": "14 pages; International Journal of Grid Computing and Applications\n  (IJGCA), 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Nowadays the number of available processing cores within computing nodes\nwhich are used in recent clustered environments, are growing up with a rapid\nrate. Despite this trend, the number of available network interfaces in such\ncomputing nodes has almost been remained unchanged. This issue can lead to high\nusage of network interface in many workloads, especially in heavy-communicating\nworkloads. As a result, network interface may raise as a performance bottleneck\nand can drastically degrade the performance. The goal of this paper is to\nintroduce a new process mapping strategy in multi-core clusters aimed at\nreducing network interface contention and improving inter-node communication\nperformance of parallel applications. Performance evaluation of the new mapping\nalgorithm in synthetic and real workloads indicates that the new strategy can\nachieve 5% to 90% performance improvement in heavy communicating workloads,\ncompared to other well-known methods.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 08:44:48 GMT"}], "update_date": "2012-07-13", "authors_parsed": [["Soryani", "Mohsen", ""], ["Analoui", "Morteza", ""], ["Zarrinchian", "Ghobad", ""]]}, {"id": "1207.3031", "submitter": "Konstantinos Tsianos", "authors": "Konstantinos I. Tsianos and Michael G. Rabbat", "title": "Distributed Strongly Convex Optimization", "comments": "18 pages single column draftcls format, 1 figure, Submitted to\n  Allerton 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A lot of effort has been invested into characterizing the convergence rates\nof gradient based algorithms for non-linear convex optimization. Recently,\nmotivated by large datasets and problems in machine learning, the interest has\nshifted towards distributed optimization. In this work we present a distributed\nalgorithm for strongly convex constrained optimization. Each node in a network\nof n computers converges to the optimum of a strongly convex, L-Lipchitz\ncontinuous, separable objective at a rate O(log (sqrt(n) T) / T) where T is the\nnumber of iterations. This rate is achieved in the online setting where the\ndata is revealed one at a time to the nodes, and in the batch setting where\neach node has access to its full local dataset from the start. The same\nconvergence rate is achieved in expectation when the subgradients used at each\nnode are corrupted with additive zero-mean noise.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 17:38:46 GMT"}, {"version": "v2", "created": "Fri, 20 Jul 2012 03:08:51 GMT"}], "update_date": "2012-07-23", "authors_parsed": [["Tsianos", "Konstantinos I.", ""], ["Rabbat", "Michael G.", ""]]}, {"id": "1207.3037", "submitter": "Nandan Mirajkar Mr", "authors": "Nandan Mirajkar, Mohan Barde, Harshal Kamble, Dr.Rahul Athale, Kumud\n  Singh", "title": "Implementation of Private Cloud using Eucalyptus and an open source\n  Operating System", "comments": null, "journal-ref": "IJCSI International Journal of Computer Science Issues, Vol. 9,\n  Issue 3, No 3, May 2012 ISSN (Online): 1694-0814", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Cloud computing is bringing a revolution in computing environment replacing\ntraditional software installations, licensing issues into complete on-demand\nservices through internet. Microsoft office 365 a cloud based office\napplication is available to clients online hence no need to buy and install the\nsoftware. On Facebook a social networking website, users upload videos which\nuses cloud provider's storage service so less hardware cost for\nclients.Virtualization technology has great contribution in advent of cloud\ncomputing. Paper describes implementation of Private Cloud using open source\noperating system Ubuntu 10.04 server edition, installation of Ubuntu Enterprise\nCloud with Eucalyptus 1.6.2 and providing CentOS 5.3 operating system through\ncloud.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 15:57:29 GMT"}], "update_date": "2012-07-13", "authors_parsed": [["Mirajkar", "Nandan", ""], ["Barde", "Mohan", ""], ["Kamble", "Harshal", ""], ["Athale", "Dr. Rahul", ""], ["Singh", "Kumud", ""]]}, {"id": "1207.3051", "submitter": "Gonzalo Travieso", "authors": "Gonzalo Travieso, Carlos A. Ruggiero, Odemir M. Bruno, Luciano da F.\n  Costa", "title": "Predicting Efficiency in master-slave grid computing systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work reports a quantitative analysis to predicting the efficiency of\ndistributed computing running in three models of complex networks:\nBarab\\'asi-Albert, Erd\\H{o}s-R\\'enyi and Watts-Strogatz. A master/slave\ncomputing model is simulated. A node is selected as master and distributes\ntasks among the other nodes (the clients). Topological measurements associated\nwith the master node (e.g. its degree or betwenness centrality) are extracted\nand considered as predictors of the total execution time. It is found that the\ncloseness centrality provides the best alternative. The effect of network size\nwas also investigated.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 18:33:23 GMT"}], "update_date": "2012-07-13", "authors_parsed": [["Travieso", "Gonzalo", ""], ["Ruggiero", "Carlos A.", ""], ["Bruno", "Odemir M.", ""], ["Costa", "Luciano da F.", ""]]}, {"id": "1207.3099", "submitter": "Kishore Kothapalli", "authors": "Kishore Kothapalli, Sriram Pemmaraju", "title": "Super-Fast 3-Ruling Sets", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A $t$-ruling set of a graph $G = (V, E)$ is a vertex-subset $S \\subseteq V$\nthat is independent and satisfies the property that every vertex $v \\in V$ is\nat a distance of at most $t$ from some vertex in $S$. A \\textit{maximal\nindependent set (MIS)} is a 1-ruling set. The problem of computing an MIS on a\nnetwork is a fundamental problem in distributed algorithms and the fastest\nalgorithm for this problem is the $O(\\log n)$-round algorithm due to Luby\n(SICOMP 1986) and Alon et al. (J. Algorithms 1986) from more than 25 years ago.\nSince then the problem has resisted all efforts to yield to a sub-logarithmic\nalgorithm. There has been recent progress on this problem, most importantly an\n$O(\\log \\Delta \\cdot \\sqrt{\\log n})$-round algorithm on graphs with $n$\nvertices and maximum degree $\\Delta$, due to Barenboim et al. (Barenboim,\nElkin, Pettie, and Schneider, April 2012, arxiv 1202.1983; to appear FOCS\n2012).\n  We approach the MIS problem from a different angle and ask if O(1)-ruling\nsets can be computed much more efficiently than an MIS? As an answer to this\nquestion, we show how to compute a 2-ruling set of an $n$-vertex graph in\n$O((\\log n)^{3/4})$ rounds. We also show that the above result can be improved\nfor special classes of graphs such as graphs with high girth, trees, and graphs\nof bounded arboricity.\n  Our main technique involves randomized sparsification that rapidly reduces\nthe graph degree while ensuring that every deleted vertex is close to some\nvertex that remains. This technique may have further applications in other\ncontexts, e.g., in designing sub-logarithmic distributed approximation\nalgorithms. Our results raise intriguing questions about how quickly an MIS (or\n1-ruling sets) can be computed, given that 2-ruling sets can be computed in\nsub-logarithmic rounds.\n", "versions": [{"version": "v1", "created": "Thu, 12 Jul 2012 21:02:17 GMT"}], "update_date": "2012-07-16", "authors_parsed": [["Kothapalli", "Kishore", ""], ["Pemmaraju", "Sriram", ""]]}, {"id": "1207.3732", "submitter": "Aurojit Panda Aurojit Panda", "authors": "Joan Feigenbaum and Brighten Godfrey and Aurojit Panda and Michael\n  Schapira and Scott Shenker and Ankit Singla", "title": "On the Resilience of Routing Tables", "comments": "Brief announcement, PODC 2012", "journal-ref": null, "doi": "10.1145/2332432.2332478", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Many modern network designs incorporate \"failover\" paths into routers'\nforwarding tables. We initiate the theoretical study of the conditions under\nwhich such resilient routing tables can guarantee delivery of packets.\n", "versions": [{"version": "v1", "created": "Mon, 16 Jul 2012 17:17:36 GMT"}, {"version": "v2", "created": "Sat, 4 Aug 2012 02:45:24 GMT"}], "update_date": "2012-08-07", "authors_parsed": [["Feigenbaum", "Joan", ""], ["Godfrey", "Brighten", ""], ["Panda", "Aurojit", ""], ["Schapira", "Michael", ""], ["Shenker", "Scott", ""], ["Singla", "Ankit", ""]]}, {"id": "1207.3962", "submitter": "Ludmila Scharf", "authors": "Helmut Alt and Ludmila Scharf", "title": "Computation of the Hausdorff distance between sets of line segments in\n  parallel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that the Hausdorff distance for two sets of non-intersecting line\nsegments can be computed in parallel in $O(\\log^2 n)$ time using O(n)\nprocessors in a CREW-PRAM computation model. We discuss how some parts of the\nsequential algorithm can be performed in parallel using previously known\nparallel algorithms; and identify the so-far unsolved part of the problem for\nthe parallel computation, which is the following: Given two sets of\n$x$-monotone curve segments, red and blue, for each red segment find its\nextremal intersection points with the blue set, i.e. points with the minimal\nand maximal $x$-coordinate. Each segment set is assumed to be intersection\nfree. For this intersection problem we describe a parallel algorithm which\ncompletes the Hausdorff distance computation within the stated time and\nprocessor bounds.\n", "versions": [{"version": "v1", "created": "Tue, 17 Jul 2012 11:58:08 GMT"}], "update_date": "2012-07-18", "authors_parsed": [["Alt", "Helmut", ""], ["Scharf", "Ludmila", ""]]}, {"id": "1207.4174", "submitter": "Mark Paskin", "authors": "Mark Paskin, Carlos E. Guestrin", "title": "Robust Probabilistic Inference in Distributed Systems", "comments": "Appears in Proceedings of the Twentieth Conference on Uncertainty in\n  Artificial Intelligence (UAI2004)", "journal-ref": null, "doi": null, "report-no": "UAI-P-2004-PG-436-445", "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic inference problems arise naturally in distributed systems such\nas sensor networks and teams of mobile robots. Inference algorithms that use\nmessage passing are a natural fit for distributed systems, but they must be\nrobust to the failure situations that arise in real-world settings, such as\nunreliable communication and node failures. Unfortunately, the popular\nsum-product algorithm can yield very poor estimates in these settings because\nthe nodes' beliefs before convergence can be arbitrarily different from the\ncorrect posteriors. In this paper, we present a new message passing algorithm\nfor probabilistic inference which provides several crucial guarantees that the\nstandard sum-product algorithm does not. Not only does it converge to the\ncorrect posteriors, but it is also guaranteed to yield a principled\napproximation at any point before convergence. In addition, the computational\ncomplexity of the message passing updates depends only upon the model, and is\ndependent of the network topology of the distributed system. We demonstrate the\napproach with detailed experimental results on a distributed sensor calibration\ntask using data from an actual sensor network deployment.\n", "versions": [{"version": "v1", "created": "Wed, 11 Jul 2012 15:08:33 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Paskin", "Mark", ""], ["Guestrin", "Carlos E.", ""]]}, {"id": "1207.4262", "submitter": "Sayan Mitra Sayan Mitra", "authors": "Zhenqi Huang and Sayan Mitra and Geir Dullerud", "title": "Differentially Private Iterative Synchronous Consensus", "comments": "The original manuscript from 18th July was updated with new proofs\n  for Lemmas 3, 6, and 8", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The iterative consensus problem requires a set of processes or agents with\ndifferent initial values, to interact and update their states to eventually\nconverge to a common value. Protocols solving iterative consensus serve as\nbuilding blocks in a variety of systems where distributed coordination is\nrequired for load balancing, data aggregation, sensor fusion, filtering, clock\nsynchronization and platooning of autonomous vehicles. In this paper, we\nintroduce the private iterative consensus problem where agents are required to\nconverge while protecting the privacy of their initial values from honest but\ncurious adversaries. Protecting the initial states, in many applications,\nsuffice to protect all subsequent states of the individual participants.\n  First, we adapt the notion of differential privacy in this setting of\niterative computation. Next, we present a server-based and a completely\ndistributed randomized mechanism for solving private iterative consensus with\nadversaries who can observe the messages as well as the internal states of the\nserver and a subset of the clients. Finally, we establish the tradeoff between\nprivacy and the accuracy of the proposed randomized mechanism.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2012 04:36:50 GMT"}, {"version": "v2", "created": "Wed, 8 Aug 2012 22:34:30 GMT"}], "update_date": "2012-08-10", "authors_parsed": [["Huang", "Zhenqi", ""], ["Mitra", "Sayan", ""], ["Dullerud", "Geir", ""]]}, {"id": "1207.4371", "submitter": "Klaus Berberich", "authors": "Klaus Berberich and Srikanta Bedathur", "title": "Computing n-Gram Statistics in MapReduce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IR cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Statistics about n-grams (i.e., sequences of contiguous words or other tokens\nin text documents or other string data) are an important building block in\ninformation retrieval and natural language processing. In this work, we study\nhow n-gram statistics, optionally restricted by a maximum n-gram length and\nminimum collection frequency, can be computed efficiently harnessing MapReduce\nfor distributed data processing. We describe different algorithms, ranging from\nan extension of word counting, via methods based on the Apriori principle, to a\nnovel method Suffix-\\sigma that relies on sorting and aggregating suffixes. We\nexamine possible extensions of our method to support the notions of\nmaximality/closedness and to perform aggregations beyond occurrence counting.\nAssuming Hadoop as a concrete MapReduce implementation, we provide insights on\nan efficient implementation of the methods. Extensive experiments on The New\nYork Times Annotated Corpus and ClueWeb09 expose the relative benefits and\ntrade-offs of the methods.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jul 2012 13:21:10 GMT"}], "update_date": "2012-07-19", "authors_parsed": [["Berberich", "Klaus", ""], ["Bedathur", "Srikanta", ""]]}, {"id": "1207.4821", "submitter": "Angus Macdonald", "authors": "Angus Macdonald", "title": "The Architecture of an Autonomic, Resource-Aware, Workstation-Based\n  Distributed Database System", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Distributed software systems that are designed to run over workstation\nmachines within organisations are termed workstation-based. Workstation-based\nsystems are characterised by dynamically changing sets of machines that are\nused primarily for other, user-centric tasks. They must be able to adapt to and\nutilize spare capacity when and where it is available, and ensure that the\nnon-availability of an individual machine does not affect the availability of\nthe system. This thesis focuses on the requirements and design of a\nworkstation-based database system, which is motivated by an analysis of\nexisting database architectures that are typically run over static, specially\nprovisioned sets of machines. A typical clustered database system -- one that\nis run over a number of specially provisioned machines -- executes queries\ninteractively, returning a synchronous response to applications, with its data\nmade durable and resilient to the failure of machines. There are no existing\nworkstation-based databases. Furthermore, other workstation-based systems do\nnot attempt to achieve the requirements of interactivity and durability,\nbecause they are typically used to execute asynchronous batch processing jobs\nthat tolerate data loss -- results can be re-computed. These systems use\nexternal servers to store the final results of computations rather than\nworkstation machines. This thesis describes the design and implementation of a\nworkstation-based database system and investigates its viability by evaluating\nits performance against existing clustered database systems and testing its\navailability during machine failures.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jul 2012 22:01:39 GMT"}], "update_date": "2012-07-23", "authors_parsed": [["Macdonald", "Angus", ""]]}, {"id": "1207.4978", "submitter": "Tuhin Sahai", "authors": "Esha Sahai and Tuhin Sahai", "title": "Mapping and Reducing the Brain on the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emergence of cloud computing has enabled an incredible growth in\navailable hardware resources at very low costs. These resources are being\nincreasingly utilized by corporations for scalable analysis of \"big data\"\nproblems. In this work, we explore the possibility of using commodity hardware\nsuch as Amazon EC2 for performing large scale scientific computation. In\nparticular, we simulate interconnected cortical neurons using MapReduce. We\nbuild and model a network of 1000 spiking cortical neurons in Hadoop, an\nopensource implementation of MapReduce, and present results.\n", "versions": [{"version": "v1", "created": "Fri, 20 Jul 2012 15:22:30 GMT"}, {"version": "v2", "created": "Sun, 12 Aug 2012 05:32:47 GMT"}], "update_date": "2012-08-14", "authors_parsed": [["Sahai", "Esha", ""], ["Sahai", "Tuhin", ""]]}, {"id": "1207.5211", "submitter": "Danupon Nanongkai", "authors": "Michael Elkin and Hartmut Klauck and Danupon Nanongkai and Gopal\n  Pandurangan", "title": "Can Quantum Communication Speed Up Distributed Computation?", "comments": "Full version of PODC 2014 paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS quant-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The focus of this paper is on {\\em quantum distributed} computation, where we\ninvestigate whether quantum communication can help in {\\em speeding up}\ndistributed network algorithms. Our main result is that for certain fundamental\nnetwork problems such as minimum spanning tree, minimum cut, and shortest\npaths, quantum communication {\\em does not} help in substantially speeding up\ndistributed algorithms for these problems compared to the classical setting.\n  In order to obtain this result, we extend the technique of Das Sarma et al.\n[SICOMP 2012] to obtain a uniform approach to prove non-trivial lower bounds\nfor quantum distributed algorithms for several graph optimization (both exact\nand approximate versions) as well as verification problems, some of which are\nnew even in the classical setting, e.g. tight randomized lower bounds for\nHamiltonian cycle and spanning tree verification, answering an open problem of\nDas Sarma et al., and a lower bound in terms of the weight aspect ratio,\nmatching the upper bounds of Elkin [STOC 2004]. Our approach introduces the\n{\\em Server model} and {\\em Quantum Simulation Theorem} which together provide\na connection between distributed algorithms and communication complexity. The\nServer model is the standard two-party communication complexity model augmented\nwith additional power; yet, most of the hardness in the two-party model is\ncarried over to this new model. The Quantum Simulation Theorem carries this\nhardness further to quantum distributed computing. Our techniques, except the\nproof of the hardness in the Server model, require very little knowledge in\nquantum computing, and this can help overcoming a usual impediment in proving\nbounds on quantum distributed algorithms.\n", "versions": [{"version": "v1", "created": "Sun, 22 Jul 2012 09:55:59 GMT"}, {"version": "v2", "created": "Tue, 6 Nov 2012 07:15:40 GMT"}, {"version": "v3", "created": "Mon, 11 Feb 2013 03:27:09 GMT"}, {"version": "v4", "created": "Thu, 14 Nov 2013 12:09:07 GMT"}, {"version": "v5", "created": "Fri, 9 May 2014 01:19:39 GMT"}], "update_date": "2014-05-12", "authors_parsed": [["Elkin", "Michael", ""], ["Klauck", "Hartmut", ""], ["Nanongkai", "Danupon", ""], ["Pandurangan", "Gopal", ""]]}, {"id": "1207.5345", "submitter": "Lian Luo", "authors": "Gang Liao, Lei Liu, Lian Luo", "title": "A New P2N Approach to Software Development Under the Clustering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this computer era of rapid development, software development can be seen\neverywhere, but a lot of softwares are dead in modern development of software.\nJust as The Mythical Man-Month said, it exists a problem in the software\ndevelopment, and the problem is interflow.A lock of interflow can be said great\ncalamity. Clustering is a environment to breed new life. In this thesis, we\nelaborate how P2N can be used to thinking, planning, developing, collaborating,\nreleasing. And the approach that make your team and organization more perfect.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2012 10:41:28 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Liao", "Gang", ""], ["Liu", "Lei", ""], ["Luo", "Lian", ""]]}, {"id": "1207.5480", "submitter": "Nadir Salih nks", "authors": "Nadir K. Salih, Tianyi Zang", "title": "Survey and comparison for Open and closed sources in cloud computing", "comments": "6pages, 3figures; International Journal of Computer Science Issues\n  (\"IJCSI\"),2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is a new technology widely studied in recent years. Now there\nare many cloud platforms both in industry and in academic circle. How to\nunderstand and use these platforms is a big issue. A detailed comparison has\nbeen presented in this paper focused on the aspects such as the architecture,\ncharacteristics, application and so on. To know the differences between open\nsource and close source in cloud environment we mention some examples for\nSoftware-as-a-Service, Platform-as-a-Service, and Infrastructure-as-a-Service.\nWe made comparison between them. Before conclusion we demonstrate some\nconvergences and differences between open and closed platform, but we realized\nopen source should be the best option.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jul 2012 18:39:49 GMT"}], "update_date": "2012-07-24", "authors_parsed": [["Salih", "Nadir K.", ""], ["Zang", "Tianyi", ""]]}, {"id": "1207.5839", "submitter": "Konstantinos Tsianos", "authors": "Konstantinos I. Tsianos and Michael G. Rabbat", "title": "The Impact of Communication Delays on Distributed Consensus Algorithms", "comments": "15 pages double column, 5 figures, Submitted to Transactions on\n  Automatic Control, Preliminary results published at the 49th Allerton", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect of communication delays on distributed consensus\nalgorithms. Two ways to model delays on a network are presented. The first\nmodel assumes that each link delivers messages with a fixed (constant) amount\nof delay, and the second model is more realistic, allowing for i.i.d.\ntime-varying bounded delays. In contrast to previous work studying the effects\nof delays on consensus algorithms, the models studied here allow for a node to\nreceive multiple messages from the same neighbor in one iteration. The analysis\nof the fixed delay model shows that convergence to a consensus is guaranteed\nand the rate of convergence is reduced by no more than a factor O(B^2) where B\nis the maximum delay on any link. For the time-varying delay model we also give\na convergence proof which, for row-stochastic consensus protocols, is not a\ntrivial consequence of ergodic matrix products. In both delay models, the\nconsensus value is no longer the average, even if the original protocol was an\naveraging protocol. For this reason, we propose the use of a different\nconsensus algorithm called Push-Sum [Kempe et al. 2003]. We model delays in the\nPush-Sum framework and show that convergence to the average consensus is\nguaranteed. This suggests that Push-Sum might be a better choice from a\npractical standpoint.\n", "versions": [{"version": "v1", "created": "Tue, 24 Jul 2012 22:15:10 GMT"}], "update_date": "2012-07-26", "authors_parsed": [["Tsianos", "Konstantinos I.", ""], ["Rabbat", "Michael G.", ""]]}, {"id": "1207.5949", "submitter": "Piyush Harsh", "authors": "Piyush Harsh (INRIA - IRISA), Florian Dudouet (INRIA - IRISA), Roberto\n  G. Cascella (INRIA - IRISA), Yvon J\\'egou (INRIA - IRISA), Christine Morin\n  (INRIA - IRISA)", "title": "Using Open Standards for Interoperability - Issues, Solutions, and\n  Challenges facing Cloud Computing", "comments": null, "journal-ref": "6th International DMTF Academic Alliance Workshop on Systems and\n  Virtualization Management: Standards and the Cloud (2012)", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualization offers several benefits for optimal resource utilization over\ntraditional non-virtualized server farms. With improvements in internetworking\ntechnologies and increase in network bandwidth speeds, a new era of computing\nhas been ushered in, that of grids and clouds. With several commercial cloud\nproviders coming up, each with their own APIs, application description formats,\nand varying support for SLAs, vendor lock-in has become a serious issue for end\nusers. This article attempts to describe the problem, issues, possible\nsolutions and challenges in achieving cloud interoperability. These issues will\nbe analyzed in the ambit of the European project Contrail that is trying to\nadopt open standards with available virtualization solutions to enhance users'\ntrust in the clouds by attempting to prevent vendor lock-ins, supporting and\nenforcing SLAs together with adequate data protection for sensitive data.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2012 10:54:08 GMT"}], "update_date": "2012-07-26", "authors_parsed": [["Harsh", "Piyush", "", "INRIA - IRISA"], ["Dudouet", "Florian", "", "INRIA - IRISA"], ["Cascella", "Roberto G.", "", "INRIA - IRISA"], ["J\u00e9gou", "Yvon", "", "INRIA - IRISA"], ["Morin", "Christine", "", "INRIA - IRISA"]]}, {"id": "1207.5990", "submitter": "Mehdi Ahmed-Nacer", "authors": "Mehdi Ahmed-Nacer (INRIA Lorraine - LORIA), St\\'ephane Martin (INRIA\n  Lorraine - LORIA), Pascal Urso (INRIA Lorraine - LORIA)", "title": "File system on CRDT", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we show how to manage a distributed hierarchical structure\nrepresenting a file system. This structure is optimistically replicated, each\nuser work on his local replica, and updates are sent to other replica. The\ndifferent replicas eventually observe same view of file systems. At this stage,\nconflicts between updates are very common. We claim that conflict resolution\nshould rely as little as possible on users. In this report we propose a simple\nand modular solution to resolve these problems and maintain data consistency.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2012 13:50:08 GMT"}], "update_date": "2012-07-26", "authors_parsed": [["Ahmed-Nacer", "Mehdi", "", "INRIA Lorraine - LORIA"], ["Martin", "St\u00e9phane", "", "INRIA\n  Lorraine - LORIA"], ["Urso", "Pascal", "", "INRIA Lorraine - LORIA"]]}, {"id": "1207.6011", "submitter": "Maurizio Naldi", "authors": "Loretta Mastroeni, Maurizio Naldi", "title": "Analysis of cloud storage prices", "comments": "17 pages, 17 figures, 17 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud storage is fast securing its role as a major repository for both\nconsumers and business customers. Many companies now offer storage solutions,\nsometimes for free for limited amounts of capacity. We have surveyed the\npricing plans of a selection of major cloud providers and compared them using\nthe unit price as the means of comparison. All the providers, excepting Amazon,\nadopt a bundling pricing scheme; Amazon follows instead a block-declining\npricing policy. We compare the pricing plans through a double approach: a\npointwise comparison for each value of capacity, and an overall comparison\nusing a two-part tariff approximation and a Pareto-dominance criterion. Under\nboth approaches, most providers appear to offer pricing plans that are more\nexpensive and can be excluded from a procurement selection in favour of a\nlimited number of dominant providers.\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2012 14:45:55 GMT"}], "update_date": "2012-07-26", "authors_parsed": [["Mastroeni", "Loretta", ""], ["Naldi", "Maurizio", ""]]}, {"id": "1207.6045", "submitter": "Agustin Santos Mendez", "authors": "Agust\\'in Santos M\\'endez, Antonio Fern\\'andez Anta, Luis L\\'opez\n  Fern\\'andez", "title": "Quid Pro Quo: A Mechanism for Fair Collaboration in Networked Systems", "comments": "23 pages, 5 figures, 3 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Collaboration may be understood as the execution of coordinated tasks (in the\nmost general sense) by groups of users, who cooperate for achieving a common\ngoal. Collaboration is a fundamental assumption and requirement for the correct\noperation of many communication systems. The main challenge when creating\ncollaborative systems in a decentralized manner is dealing with the fact that\nusers may behave in selfish ways, trying to obtain the benefits of the tasks\nbut without participating in their execution. In this context, Game Theory has\nbeen instrumental to model collaborative systems and the task allocation\nproblem, and to design mechanisms for optimal allocation of tasks. In this\npaper, we revise the classical assumptions and propose a new approach to this\nproblem. First, we establish a system model based on heterogenous nodes (users,\nplayers), and propose a basic distributed mechanism so that, when a new task\nappears, it is assigned to the most suitable node. The classical technique for\ncompensating a node that executes a task is the use of payments (which in most\nnetworks are hard or impossible to implement). Instead, we propose a\ndistributed mechanism for the optimal allocation of tasks without payments. We\nprove this mechanism to be robust event in the presence of independent selfish\nor rationally limited players. Additionally, our model is based on very weak\nassumptions, which makes the proposed mechanisms susceptible to be implemented\nin networked systems (e.g., the Internet).\n", "versions": [{"version": "v1", "created": "Wed, 25 Jul 2012 16:29:55 GMT"}], "update_date": "2012-07-26", "authors_parsed": [["M\u00e9ndez", "Agust\u00edn Santos", ""], ["Anta", "Antonio Fern\u00e1ndez", ""], ["Fern\u00e1ndez", "Luis L\u00f3pez", ""]]}, {"id": "1207.6188", "submitter": "Mahyuddin K. M.  Nasution", "authors": "Mahyuddin K. M. Nasution", "title": "Kolmogorov Complexity: Clustering Objects and Similarity", "comments": "13 pages; Bulletin of Mathematics, Vol. 3 (2011), No. 1: 1-16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The clustering objects has become one of themes in many studies, and do not\nfew researchers use the similarity to cluster the instances automatically.\nHowever, few research consider using Kommogorov Complexity to get information\nabout objects from documents, such as Web pages, where the rich information\nfrom an approach proved to be difficult to. In this paper, we proposed a\nsimilarity measure from Kolmogorov Complexity, and we demonstrate the\npossibility of exploiting features from Web based on hit counts for objects of\nIndonesia Intellectual.\n", "versions": [{"version": "v1", "created": "Thu, 26 Jul 2012 07:35:53 GMT"}], "update_date": "2012-07-27", "authors_parsed": [["Nasution", "Mahyuddin K. M.", ""]]}, {"id": "1207.6644", "submitter": "Andre Luckow", "authors": "Andre Luckow, Mark Santcroos, Ole Weidner, Andre Merzky, Pradeep\n  Mantha, Shantenu Jha", "title": "P*: A Model of Pilot-Abstractions", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pilot-Jobs support effective distributed resource utilization, and are\narguably one of the most widely-used distributed computing abstractions - as\nmeasured by the number and types of applications that use them, as well as the\nnumber of production distributed cyberinfrastructures that support them. In\nspite of broad uptake, there does not exist a well-defined, unifying conceptual\nmodel of Pilot-Jobs which can be used to define, compare and contrast different\nimplementations. Often Pilot-Job implementations are strongly coupled to the\ndistributed cyber-infrastructure they were originally designed for. These\nfactors present a barrier to extensibility and interoperability. This pa- per\nis an attempt to (i) provide a minimal but complete model (P*) of Pilot-Jobs,\n(ii) establish the generality of the P* Model by mapping various existing and\nwell known Pilot-Job frameworks such as Condor and DIANE to P*, (iii) derive an\ninteroperable and extensible API for the P* Model (Pilot-API), (iv) validate\nthe implementation of the Pilot-API by concurrently using multiple distinct\nPilot-Job frameworks on distinct production distributed cyberinfrastructures,\nand (v) apply the P* Model to Pilot-Data.\n", "versions": [{"version": "v1", "created": "Fri, 27 Jul 2012 20:08:12 GMT"}], "update_date": "2015-03-20", "authors_parsed": [["Luckow", "Andre", ""], ["Santcroos", "Mark", ""], ["Weidner", "Ole", ""], ["Merzky", "Andre", ""], ["Mantha", "Pradeep", ""], ["Jha", "Shantenu", ""]]}, {"id": "1207.6732", "submitter": "Tomasz Jurdzinski", "authors": "Tomasz Jurdzinski and Dariusz R.Kowalski and Tomasz Maciejewski and\n  Grzegorz Stachowiak", "title": "Distributed Broadcasting in Wireless Networks under the SINR Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the advent of large-scale multi-hop wireless technologies, such as MANET,\nVANET, iThings, it is of utmost importance to devise efficient distributed\nprotocols to maintain network architecture and provide basic communication\ntools. One of such fundamental communication tasks is broadcast, also known as\na 1-to-all communication. We propose several new efficient distributed\nalgorithms and evaluate their time performance both theoretically and by\nsimulations. First randomized algorithm accomplishes broadcast in O(D+log(1/d))\nrounds with probability at least 1-d on any uniform-power network of n nodes\nand diameter D, when equipped with local estimate of network density.\nAdditionally, we evaluate average performance of this protocols by simulations\non two classes of generated networks - uniform and social - and compare the\nresults with performance of exponential backoff heuristic. Ours is the first\nprovably efficient and well-scalable distributed solution for the (global)\nbroadcast task. The second randomized protocol developed in this paper does not\nrely on the estimate of local density, and achieves only slightly higher time\nperformance O((D+log(1/d))log n). Finally, we provide a deterministic algorithm\nachieving similar time O(D log^2 n), supported by theoretical analysis.\n", "versions": [{"version": "v1", "created": "Sat, 28 Jul 2012 21:21:21 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2013 11:36:26 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Jurdzinski", "Tomasz", ""], ["Kowalski", "Dariusz R.", ""], ["Maciejewski", "Tomasz", ""], ["Stachowiak", "Grzegorz", ""]]}, {"id": "1207.6744", "submitter": "Lluis Pamies-Juarez", "authors": "Lluis Pamies-Juarez, Anwitaman Datta and Frederique Oggier", "title": "RapidRAID: Pipelined Erasure Codes for Fast Data Archival in Distributed\n  Storage Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To achieve reliability in distributed storage systems, data has usually been\nreplicated across different nodes. However the increasing volume of data to be\nstored has motivated the introduction of erasure codes, a storage efficient\nalternative to replication, particularly suited for archival in data centers,\nwhere old datasets (rarely accessed) can be erasure encoded, while replicas are\nmaintained only for the latest data. Many recent works consider the design of\nnew storage-centric erasure codes for improved repairability. In contrast, this\npaper addresses the migration from replication to encoding: traditionally\nerasure coding is an atomic operation in that a single node with the whole\nobject encodes and uploads all the encoded pieces. Although large datasets can\nbe concurrently archived by distributing individual object encodings among\ndifferent nodes, the network and computing capacity of individual nodes\nconstrain the archival process due to such atomicity.\n  We propose a new pipelined coding strategy that distributes the network and\ncomputing load of single-object encodings among different nodes, which also\nspeeds up multiple object archival. We further present RapidRAID codes, an\nexplicit family of pipelined erasure codes which provides fast archival without\ncompromising either data reliability or storage overheads. Finally, we provide\na real implementation of RapidRAID codes and benchmark its performance using\nboth a cluster of 50 nodes and a set of Amazon EC2 instances. Experiments show\nthat RapidRAID codes reduce a single object's coding time by up to 90%, while\nwhen multiple objects are encoded concurrently, the reduction is up to 20%.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jul 2012 04:27:44 GMT"}, {"version": "v2", "created": "Fri, 3 Aug 2012 07:02:25 GMT"}], "update_date": "2012-08-06", "authors_parsed": [["Pamies-Juarez", "Lluis", ""], ["Datta", "Anwitaman", ""], ["Oggier", "Frederique", ""]]}, {"id": "1207.6936", "submitter": "Guillaume Aupy", "authors": "Guillaume Aupy, Yves Robert, Fr\\'ed\\'eric Vivien and Dounia Zaidouni", "title": "Impact of fault prediction on checkpointing strategies", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": "INRIA Report 8023", "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper deals with the impact of fault prediction techniques on\ncheckpointing strategies. We extend the classical analysis of Young and Daly in\nthe presence of a fault prediction system, which is characterized by its recall\nand its precision, and which provides either exact or window-based time\npredictions. We succeed in deriving the optimal value of the checkpointing\nperiod (thereby minimizing the waste of resource usage due to checkpoint\noverhead) in all scenarios. These results allow to analytically assess the key\nparameters that impact the performance of fault predictors at very large scale.\nIn addition, the results of this analytical evaluation are nicely corroborated\nby a comprehensive set of simulations, thereby demonstrating the validity of\nthe model and the accuracy of the results.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 13:36:20 GMT"}, {"version": "v2", "created": "Tue, 9 Oct 2012 13:47:38 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Aupy", "Guillaume", ""], ["Robert", "Yves", ""], ["Vivien", "Fr\u00e9d\u00e9ric", ""], ["Zaidouni", "Dounia", ""]]}, {"id": "1207.7055", "submitter": "Benjamin Heintz", "authors": "Benjamin Heintz and Abhishek Chandra and Ramesh K. Sitaraman", "title": "Optimizing MapReduce for Highly Distributed Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MapReduce, the popular programming paradigm for large-scale data processing,\nhas traditionally been deployed over tightly-coupled clusters where the data is\nalready locally available. The assumption that the data and compute resources\nare available in a single central location, however, no longer holds for many\nemerging applications in commercial, scientific and social networking domains,\nwhere the data is generated in a geographically distributed manner. Further,\nthe computational resources needed for carrying out the data analysis may be\ndistributed across multiple data centers or community resources such as Grids.\nIn this paper, we develop a modeling framework to capture MapReduce execution\nin a highly distributed environment comprising distributed data sources and\ndistributed computational resources. This framework is flexible enough to\ncapture several design choices and performance optimizations for MapReduce\nexecution. We propose a model-driven optimization that has two key features:\n(i) it is end-to-end as opposed to myopic optimizations that may only make\nlocally optimal but globally suboptimal decisions, and (ii) it can control\nmultiple MapReduce phases to achieve low runtime, as opposed to single-phase\noptimizations that may control only individual phases. Our model results show\nthat our optimization can provide nearly 82% and 64% reduction in execution\ntime over myopic and single-phase optimizations, respectively. We have modified\nHadoop to implement our model outputs, and using three different MapReduce\napplications over an 8-node emulated PlanetLab testbed, we show that our\noptimized Hadoop execution plan achieves 31-41% reduction in runtime over a\nvanilla Hadoop execution. Our model-driven optimization also provides several\ninsights into the choice of techniques and execution parameters based on\napplication and platform characteristics.\n", "versions": [{"version": "v1", "created": "Mon, 30 Jul 2012 19:42:31 GMT"}], "update_date": "2012-07-31", "authors_parsed": [["Heintz", "Benjamin", ""], ["Chandra", "Abhishek", ""], ["Sitaraman", "Ramesh K.", ""]]}, {"id": "1207.7241", "submitter": "Anissa Lamani", "authors": "Sayaka Kamei, Anissa Lamani (MIS), Fukuhito Ooshita, S\\'ebastien\n  Tixeuil", "title": "Gathering an even number of robots in an odd ring without global\n  multiplicity detection", "comments": "arXiv admin note: text overlap with arXiv:1104.5660", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a gathering protocol for an even number of robots in a ring-shaped\nnetwork that allows symmetric but not periodic configurations as initial\nconfigurations, yet uses only local weak multiplicity detection. Robots are\nassumed to be anonymous and oblivious, and the execution model is the non-\natomic CORDA model with asynchronous fair scheduling. In our scheme, the number\nof robots k must be greater than 8, the number of nodes n on a network must be\nodd and greater than k+3. The running time of our protocol is O(n2)\nasynchronous rounds.\n", "versions": [{"version": "v1", "created": "Sun, 17 Jun 2012 20:05:09 GMT"}], "update_date": "2012-08-01", "authors_parsed": [["Kamei", "Sayaka", "", "MIS"], ["Lamani", "Anissa", "", "MIS"], ["Ooshita", "Fukuhito", ""], ["Tixeuil", "S\u00e9bastien", ""]]}]