[{"id": "1109.0264", "submitter": "Dimitris S. Papailiopoulos", "authors": "Dimitris S. Papailiopoulos, Jianqiang Luo, Alexandros G. Dimakis,\n  Cheng Huang, and Jin Li", "title": "Simple Regenerating Codes: Network Coding for Cloud Storage", "comments": "9 pages, 10 figures, submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network codes designed specifically for distributed storage systems have the\npotential to provide dramatically higher storage efficiency for the same\navailability. One main challenge in the design of such codes is the exact\nrepair problem: if a node storing encoded information fails, in order to\nmaintain the same level of reliability we need to create encoded information at\na new node. One of the main open problems in this emerging area has been the\ndesign of simple coding schemes that allow exact and low cost repair of failed\nnodes and have high data rates. In particular, all prior known explicit\nconstructions have data rates bounded by 1/2.\n  In this paper we introduce the first family of distributed storage codes that\nhave simple look-up repair and can achieve arbitrarily high rates. Our\nconstructions are very simple to implement and perform exact repair by simple\nXORing of packets. We experimentally evaluate the proposed codes in a realistic\ncloud storage simulator and show significant benefits in both performance and\nreliability compared to replication and standard Reed-Solomon codes.\n", "versions": [{"version": "v1", "created": "Thu, 1 Sep 2011 19:10:38 GMT"}], "update_date": "2011-09-02", "authors_parsed": [["Papailiopoulos", "Dimitris S.", ""], ["Luo", "Jianqiang", ""], ["Dimakis", "Alexandros G.", ""], ["Huang", "Cheng", ""], ["Li", "Jin", ""]]}, {"id": "1109.0397", "submitter": "Gabriele D'Angelo", "authors": "Moreno Marzolla, Stefano Ferretti, Gabriele D'Angelo", "title": "Auction-Based Resource Allocation in Digital Ecosystems", "comments": "Proceedings of the 6th International Conference on MOBILe Wireless\n  MiddleWARE, Operating Systems, and Applications (MobilWare 2013). Bologna,\n  Italy, November 11-12, 2013", "journal-ref": null, "doi": "10.1109/Mobilware.2013.16", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of portable devices (PDAs, smartphones, digital multimedia\nplayers, and so forth) allows mobile users to carry around a pool of computing,\nstorage and communication resources. Sharing these resources with other users\n(\"Digital Organisms\" -- DOs) opens the door to novel interesting scenarios,\nwhere people trade resources to allow the execution, anytime and anywhere, of\napplications that require a mix of capabilities. In this paper we present a\nfully distributed approach for resource sharing among multiple devices owned by\ndifferent mobile users. Our scheme enables DOs to trade computing/networking\nfacilities through an auction-based mechanism, without the need of a central\ncontrol. We use a set of numerical experiments to compare our approach with an\noptimal (centralized) allocation strategy that, given the set of resource\ndemands and offers, maximizes the number of matches. Results confirm the\neffectiveness of our approach since it produces a fair allocation of resources\nwith low computational cost, providing DOs with the means to form an altruistic\ndigital ecosystem.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2011 10:08:38 GMT"}, {"version": "v2", "created": "Wed, 30 Jul 2014 12:22:44 GMT"}], "update_date": "2014-07-31", "authors_parsed": [["Marzolla", "Moreno", ""], ["Ferretti", "Stefano", ""], ["D'Angelo", "Gabriele", ""]]}, {"id": "1109.0545", "submitter": "Jan Verschelde", "authors": "Jan Verschelde and Genady Yoffe", "title": "Quality Up in Polynomial Homotopy Continuation by Multithreaded Path\n  Tracking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NA cs.SC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Speedup measures how much faster we can solve the same problem using many\ncores. If we can afford to keep the execution time fixed, then quality up\nmeasures how much better the solution will be computed using many cores. In\nthis paper we describe our multithreaded implementation to track one solution\npath defined by a polynomial homotopy. Limiting quality to accuracy and\nconfusing accuracy with precision, we strive to offset the cost of\nmultiprecision arithmetic running multithreaded code on many cores.\n", "versions": [{"version": "v1", "created": "Fri, 2 Sep 2011 20:06:55 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Verschelde", "Jan", ""], ["Yoffe", "Genady", ""]]}, {"id": "1109.0687", "submitter": "Ashwin Ganesan", "authors": "Ashwin Ganesan", "title": "Performance of distributed mechanisms for flow admission in wireless\n  adhoc networks", "comments": "21 pages, submitted. Journal version of arXiv:0906.3782", "journal-ref": "Wireless Networks, vol. 20, pp. 1321-1334, August 2014", "doi": "10.1007/s11276-013-0680-z", "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a wireless network where some pairs of communication links interfere\nwith each other, we study sufficient conditions for determining whether a given\nset of minimum bandwidth quality-of-service (QoS) requirements can be\nsatisfied. We are especially interested in algorithms which have low\ncommunication overhead and low processing complexity. The interference in the\nnetwork is modeled using a conflict graph whose vertices correspond to the\ncommunication links in the network. Two links are adjacent in this graph if and\nonly if they interfere with each other due to being in the same vicinity and\nhence cannot be simultaneously active. The problem of scheduling the\ntransmission of the various links is then essentially a fractional, weighted\nvertex coloring problem, for which upper bounds on the fractional chromatic\nnumber are sought using only localized information. We recall some distributed\nalgorithms for this problem, and then assess their worst-case performance. Our\nresults on this fundamental problem imply that for some well known classes of\nnetworks and interference models, the performance of these distributed\nalgorithms is within a bounded factor away from that of an optimal, centralized\nalgorithm. The performance bounds are simple expressions in terms of graph\ninvariants. It is seen that the induced star number of a network plays an\nimportant role in the design and performance of such networks.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2011 08:54:21 GMT"}, {"version": "v2", "created": "Wed, 16 Nov 2011 19:05:23 GMT"}, {"version": "v3", "created": "Tue, 29 Nov 2011 18:05:49 GMT"}, {"version": "v4", "created": "Wed, 31 Oct 2012 06:49:52 GMT"}], "update_date": "2015-12-11", "authors_parsed": [["Ganesan", "Ashwin", ""]]}, {"id": "1109.0742", "submitter": "Robert Cloud", "authors": "Robert Louis Cloud", "title": "Problems in Modern High Performance Parallel I/O Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the past couple of decades, the computational abilities of supercomput-\ners have increased tremendously. Leadership scale supercomputers now are\ncapable of petaflops. Likewise, the problem size targeted by applications\nrunning on such computers has also scaled. These large applications have I/O\nthroughput requirements on the order of tens of gigabytes per second. For a\nvariety of reasons, the I/O subsystems of such computers have not kept pace\nwith the computational increases, and the time required for I/O in an\napplication has become one of the dominant bottlenecks. Also troublesome is the\nfact that scientific applications do not attain near the peak theoretical\nbandwidth of the I/O subsystems. In addressing the two prior issues, one must\nalso question the nature of the data itself; one can ask whether contem- porary\npractices of data dumping and analysis are optimal and whether they will\ncontinue to be applicable as computers continue to scale. These three topics,\nthe I/O subsystem, the nature of scientific data output, and future possible\noptimizations are discussed in this report.\n", "versions": [{"version": "v1", "created": "Sun, 4 Sep 2011 19:28:43 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Cloud", "Robert Louis", ""]]}, {"id": "1109.0775", "submitter": "EPTCS", "authors": "Azer Bestavros (Boston University), Assaf Kfoury (Boston University)", "title": "A Domain-Specific Language for Incremental and Modular Design of\n  Large-Scale Verifiably-Safe Flow Networks (Preliminary Report)", "comments": "In Proceedings DSL 2011, arXiv:1109.0323", "journal-ref": "EPTCS 66, 2011, pp. 24-47", "doi": "10.4204/EPTCS.66.2", "report-no": null, "categories": "cs.PL cs.DC cs.LO cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a domain-specific language (DSL) to inductively assemble flow\nnetworks from small networks or modules to produce arbitrarily large ones, with\ninterchangeable functionally-equivalent parts. Our small networks or modules\nare \"small\" only as the building blocks in this inductive definition (there is\nno limit on their size). Associated with our DSL is a type theory, a system of\nformal annotations to express desirable properties of flow networks together\nwith rules that enforce them as invariants across their interfaces, i.e, the\nrules guarantee the properties are preserved as we build larger networks from\nsmaller ones. A prerequisite for a type theory is a formal semantics, i.e, a\nrigorous definition of the entities that qualify as feasible flows through the\nnetworks, possibly restricted to satisfy additional efficiency or safety\nrequirements. This can be carried out in one of two ways, as a denotational\nsemantics or as an operational (or reduction) semantics; we choose the first in\npreference to the second, partly to avoid exponential-growth rewriting in the\noperational approach. We set up a typing system and prove its soundness for our\nDSL.\n", "versions": [{"version": "v1", "created": "Mon, 5 Sep 2011 01:56:15 GMT"}], "update_date": "2011-09-06", "authors_parsed": [["Bestavros", "Azer", "", "Boston University"], ["Kfoury", "Assaf", "", "Boston University"]]}, {"id": "1109.1146", "submitter": "Alexander Shekhovtsov", "authors": "Alexander Shekhovtsov and Vaclav Hlavac", "title": "A Distributed Mincut/Maxflow Algorithm Combining Path Augmentation and\n  Push-Relabel", "comments": "40 pages, 15 figures", "journal-ref": null, "doi": null, "report-no": "K333-43/11, CTU-CMP-2011-03", "categories": "cs.DC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a novel distributed algorithm for the minimum cut problem. We\nprimarily aim at solving large sparse problems. Assuming vertices of the graph\nare partitioned into several regions, the algorithm performs path augmentations\ninside the regions and updates of the push-relabel style between the regions.\nThe interaction between regions is considered expensive (regions are loaded\ninto the memory one-by-one or located on separate machines in a network). The\nalgorithm works in sweeps - passes over all regions. Let $B$ be the set of\nvertices incident to inter-region edges of the graph. We present a sequential\nand parallel versions of the algorithm which terminate in at most $2|B|^2+1$\nsweeps. The competing algorithm by Delong and Boykov uses push-relabel updates\ninside regions. In the case of a fixed partition we prove that this algorithm\nhas a tight $O(n^2)$ bound on the number of sweeps, where $n$ is the number of\nvertices. We tested sequential versions of the algorithms on instances of\nmaxflow problems in computer vision. Experimentally, the number of sweeps\nrequired by the new algorithm is much lower than for the Delong and Boykov's\nvariant. Large problems (up to $10^8$ vertices and $6\\cdot 10^8$ edges) are\nsolved using under 1GB of memory in about 10 sweeps.\n", "versions": [{"version": "v1", "created": "Tue, 6 Sep 2011 11:19:13 GMT"}], "update_date": "2011-09-07", "authors_parsed": [["Shekhovtsov", "Alexander", ""], ["Hlavac", "Vaclav", ""]]}, {"id": "1109.1396", "submitter": "R\\'obert Orm\\'andi", "authors": "R\\'obert Orm\\'andi, Istv\\'an Heged\\\"us, M\\'ark Jelasity", "title": "Gossip Learning with Linear Models on Fully Distributed Data", "comments": "The paper was published in the journal Concurrency and Computation:\n  Practice and Experience\n  http://onlinelibrary.wiley.com/journal/10.1002/%28ISSN%291532-0634 (DOI:\n  http://dx.doi.org/10.1002/cpe.2858). The modifications are based on the\n  suggestions from the reviewers", "journal-ref": null, "doi": "10.1002/cpe.2858", "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Machine learning over fully distributed data poses an important problem in\npeer-to-peer (P2P) applications. In this model we have one data record at each\nnetwork node, but without the possibility to move raw data due to privacy\nconsiderations. For example, user profiles, ratings, history, or sensor\nreadings can represent this case. This problem is difficult, because there is\nno possibility to learn local models, the system model offers almost no\nguarantees for reliability, yet the communication cost needs to be kept low.\nHere we propose gossip learning, a generic approach that is based on multiple\nmodels taking random walks over the network in parallel, while applying an\nonline learning algorithm to improve themselves, and getting combined via\nensemble learning methods. We present an instantiation of this approach for the\ncase of classification with linear models. Our main contribution is an ensemble\nlearning method which---through the continuous combination of the models in the\nnetwork---implements a virtual weighted voting mechanism over an exponential\nnumber of models at practically no extra cost as compared to independent random\nwalks. We prove the convergence of the method theoretically, and perform\nextensive experiments on benchmark datasets. Our experimental analysis\ndemonstrates the performance and robustness of the proposed approach.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 09:16:37 GMT"}, {"version": "v2", "created": "Tue, 5 Jun 2012 09:55:07 GMT"}, {"version": "v3", "created": "Wed, 6 Jun 2012 09:26:30 GMT"}], "update_date": "2012-06-07", "authors_parsed": [["Orm\u00e1ndi", "R\u00f3bert", ""], ["Heged\u00fcs", "Istv\u00e1n", ""], ["Jelasity", "M\u00e1rk", ""]]}, {"id": "1109.1420", "submitter": "Paul Bone", "authors": "Paul Bone, Zoltan Somogyi and Peter Schachte", "title": "Estimating the overlap between dependent computations for automatic\n  parallelization", "comments": null, "journal-ref": "Theory and Practice of Logic Programming, 27th Int'l. Conference\n  on Logic Programming (ICLP'11) Special Issue, volume 11, issue 4-5, pages\n  575-587. July 2011", "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Researchers working on the automatic parallelization of programs have long\nknown that too much parallelism can be even worse for performance than too\nlittle, because spawning a task to be run on another CPU incurs overheads.\nAutoparallelizing compilers have therefore long tried to use granularity\nanalysis to ensure that they only spawn off computations whose cost will\nprobably exceed the spawn-off cost by a comfortable margin. However, this is\nnot enough to yield good results, because data dependencies may \\emph{also}\nlimit the usefulness of running computations in parallel. If one computation\nblocks almost immediately and can resume only after another has completed its\nwork, then the cost of parallelization again exceeds the benefit.\n  We present a set of algorithms for recognizing places in a program where it\nis worthwhile to execute two or more computations in parallel that pay\nattention to the second of these issues as well as the first. Our system uses\nprofiling information to compute the times at which a procedure call consumes\nthe values of its input arguments and the times at which it produces the values\nof its output arguments. Given two calls that may be executed in parallel, our\nsystem uses the times of production and consumption of the variables they share\nto determine how much their executions would overlap if they were run in\nparallel, and therefore whether executing them in parallel is a good idea or\nnot.\n  We have implemented this technique for Mercury in the form of a tool that\nuses profiling data to generate recommendations about what to parallelize, for\nthe Mercury compiler to apply on the next compilation of the program. We\npresent preliminary results that show that this technique can yield useful\nparallelization speedups, while requiring nothing more from the programmer than\nrepresentative input data for the profiling run.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 11:19:55 GMT"}], "update_date": "2011-09-08", "authors_parsed": [["Bone", "Paul", ""], ["Somogyi", "Zoltan", ""], ["Schachte", "Peter", ""]]}, {"id": "1109.1421", "submitter": "Paul Bone", "authors": "Paul Bone and Zoltan Somogyi", "title": "Profiling parallel Mercury programs with ThreadScope", "comments": "21st Workshop on Logic-based methods in Programming Environments.\n  Lexington, Kentucky, July 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The behavior of parallel programs is even harder to understand than the\nbehavior of sequential programs. Parallel programs may suffer from any of the\nperformance problems affecting sequential programs, as well as from several\nproblems unique to parallel systems. Many of these problems are quite hard (or\neven practically impossible) to diagnose without help from specialized tools.\nWe present a proposal for a tool for profiling the parallel execution of\nMercury programs, a proposal whose implementation we have already started. This\ntool is an adaptation and extension of the ThreadScope profiler that was first\nbuilt to help programmers visualize the execution of parallel Haskell programs.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 11:20:46 GMT"}], "update_date": "2011-09-08", "authors_parsed": [["Bone", "Paul", ""], ["Somogyi", "Zoltan", ""]]}, {"id": "1109.1579", "submitter": "Benjmain Moseley", "authors": "Alina Ene, Sungjin Im, Benjamin Moseley", "title": "Fast Clustering using MapReduce", "comments": "Accepted to KDD 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering problems have numerous applications and are becoming more\nchallenging as the size of the data increases. In this paper, we consider\ndesigning clustering algorithms that can be used in MapReduce, the most popular\nprogramming environment for processing large datasets. We focus on the\npractical and popular clustering problems, $k$-center and $k$-median. We\ndevelop fast clustering algorithms with constant factor approximation\nguarantees. From a theoretical perspective, we give the first analysis that\nshows several clustering algorithms are in $\\mathcal{MRC}^0$, a theoretical\nMapReduce class introduced by Karloff et al. \\cite{KarloffSV10}. Our algorithms\nuse sampling to decrease the data size and they run a time consuming clustering\nalgorithm such as local search or Lloyd's algorithm on the resulting data set.\nOur algorithms have sufficient flexibility to be used in practice since they\nrun in a constant number of MapReduce rounds. We complement these results by\nperforming experiments using our algorithms. We compare the empirical\nperformance of our algorithms to several sequential and parallel algorithms for\nthe $k$-median problem. The experiments show that our algorithms' solutions are\nsimilar to or better than the other algorithms' solutions. Furthermore, on data\nsets that are sufficiently large, our algorithms are faster than the other\nparallel algorithms that we tested.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 21:10:36 GMT"}], "update_date": "2011-09-09", "authors_parsed": [["Ene", "Alina", ""], ["Im", "Sungjin", ""], ["Moseley", "Benjamin", ""]]}, {"id": "1109.1583", "submitter": "Trong Duong Quoc", "authors": "Trong Duong Quoc, Heiko Perkuhn, Daniel Catrein, Uwe Naumann and Toni\n  Anwar", "title": "Optimization and Evaluation of a Multimedia Streaming Service on Hybrid\n  Telco cloud", "comments": "20 pages; International Journal on Cloud Computing: Services and\n  Architecture (IJCCSA), 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With recent developments in cloud computing, a paradigm shift from rather\nstatic deployment of resources to more dynamic, on-demand practices means more\nflexibility and better utilization of resources. This demands new ways to\nefficiently configure networks.\n  In this paper, we will characterize a class of competitive cloud services\nthat telecom operators could provide based on the characteristics of telecom\ninfrastructure through an applicable streaming service architecture. Then, we\nwill model this architecture as a cost-based mathematic model. This model\nprovides a tool to evaluate and compare the cost of software services for\ndifferent telecom network topologies and deployment strategies. Additionally,\nwith each topology it acts as a means to characterize the deployment solution\nthat yields the lowest resource usage over the entire network. These\napplications are illustrated through numerical analysis. Finally, a\nproof-of-concept prototype is deployed to shows dynamic properties of the\nservice in the architecture and the model above.\n", "versions": [{"version": "v1", "created": "Wed, 7 Sep 2011 21:34:26 GMT"}], "update_date": "2011-09-09", "authors_parsed": [["Quoc", "Trong Duong", ""], ["Perkuhn", "Heiko", ""], ["Catrein", "Daniel", ""], ["Naumann", "Uwe", ""], ["Anwar", "Toni", ""]]}, {"id": "1109.1650", "submitter": "Ardhendu Mandal", "authors": "Ardhendu Mandal and Subhas Chandra Pal", "title": "An Empirical Study and Analysis of the Dynamic Load Balancing Techniques\n  Used in Parallel Computing Systems", "comments": "6 Pages", "journal-ref": "Proceedings of ICCS-2010, 19-20 Nov, 2010", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  A parallel computer system is a collection of processing elements that\ncommunicate and cooperate to solve large computational problems efficiently. To\nachieve this, at first the large computational problem is partitioned into\nseveral tasks with different work-loads and then are assigned to the different\nprocessing elements for computation. Distribution of the work load is known as\nLoad Balancing. An appropriate distribution of work-loads across the various\nprocessing elements is very important as disproportional workloads can\neliminate the performance benefit of parallelizing the job. Hence, load\nbalancing on parallel systems is a critical and challenging activity. Load\nbalancing algorithms can be broadly categorized as static or dynamic. Static\nload balancing algorithms distribute the tasks to processing elements at\ncompile time, while dynamic algorithms bind tasks to processing elements at run\ntime. This paper explains only the different dynamic load balancing techniques\nin brief used in parallel systems and concluding with the comparative\nperformance analysis result of these algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2011 08:04:06 GMT"}], "update_date": "2011-09-09", "authors_parsed": [["Mandal", "Ardhendu", ""], ["Pal", "Subhas Chandra", ""]]}, {"id": "1109.1693", "submitter": "Oded Schwartz", "authors": "Grey Ballard, James Demmel, Olga Holtz, Oded Schwartz", "title": "Graph Expansion and Communication Costs of Fast Matrix Multiplication", "comments": null, "journal-ref": "Proceedings of the 23rd annual symposium on parallelism in\n  algorithms and architectures. ACM, 1-12. 2011 (a shorter conference version)", "doi": "10.1145/1989493.1989495", "report-no": "UCB/EECS-2011-40", "categories": "cs.DS cs.CC cs.DC cs.NA math.CO math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The communication cost of algorithms (also known as I/O-complexity) is shown\nto be closely related to the expansion properties of the corresponding\ncomputation graphs. We demonstrate this on Strassen's and other fast matrix\nmultiplication algorithms, and obtain first lower bounds on their communication\ncosts.\n  In the sequential case, where the processor has a fast memory of size $M$,\ntoo small to store three $n$-by-$n$ matrices, the lower bound on the number of\nwords moved between fast and slow memory is, for many of the matrix\nmultiplication algorithms, $\\Omega((\\frac{n}{\\sqrt M})^{\\omega_0}\\cdot M)$,\nwhere $\\omega_0$ is the exponent in the arithmetic count (e.g., $\\omega_0 = \\lg\n7$ for Strassen, and $\\omega_0 = 3$ for conventional matrix multiplication).\nWith $p$ parallel processors, each with fast memory of size $M$, the lower\nbound is $p$ times smaller.\n  These bounds are attainable both for sequential and for parallel algorithms\nand hence optimal. These bounds can also be attained by many fast algorithms in\nlinear algebra (e.g., algorithms for LU, QR, and solving the Sylvester\nequation).\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2011 11:36:00 GMT"}], "update_date": "2011-09-12", "authors_parsed": [["Ballard", "Grey", ""], ["Demmel", "James", ""], ["Holtz", "Olga", ""], ["Schwartz", "Oded", ""]]}, {"id": "1109.1706", "submitter": "Esha Ghosh", "authors": "Esha Ghosh, Subhas K. Ghosh, C. Pandu Rangan", "title": "On the Fault Tolerance and Hamiltonicity of the Optical Transpose\n  Interconnection System of Non-Hamiltonian Base Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hamiltonicity is an important property in parallel and distributed\ncomputation. Existence of Hamiltonian cycle allows efficient emulation of\ndistributed algorithms on a network wherever such algorithm exists for\nlinear-array and ring, and can ensure deadlock freedom in some routing\nalgorithms in hierarchical interconnection networks. Hamiltonicity can also be\nused for construction of independent spanning tree and leads to designing fault\ntolerant protocols. Optical Transpose Interconnection Systems or OTIS (also\nreferred to as two-level swapped network) is a widely studied interconnection\nnetwork topology which is popular due to high degree of scalability,\nregularity, modularity and package ability. Surprisingly, to our knowledge,\nonly one strong result is known regarding Hamiltonicity of OTIS - showing that\nOTIS graph built of Hamiltonian base graphs are Hamiltonian. In this work we\nconsider Hamiltonicity of OTIS networks, built on Non-Hamiltonian base and\nanswer some important questions. First, we prove that Hamiltonicity of base\ngraph is not a necessary condition for the OTIS to be Hamiltonian. We present\nan infinite family of Hamiltonian OTIS graphs composed on Non-Hamiltonian base\ngraphs. We further show that, it is not sufficient for the base graph to have\nHamiltonian path for the OTIS constructed on it to be Hamiltonian. We give\nconstructive proof of Hamiltonicity for a large family of Butterfly-OTIS. This\nproof leads to an alternate efficient algorithm for independent spanning trees\nconstruction on this class of OTIS graphs. Our algorithm is linear in the\nnumber of vertices as opposed to the generalized algorithm, which is linear in\nthe number of edges of the graph.\n", "versions": [{"version": "v1", "created": "Thu, 8 Sep 2011 12:50:38 GMT"}], "update_date": "2011-09-09", "authors_parsed": [["Ghosh", "Esha", ""], ["Ghosh", "Subhas K.", ""], ["Rangan", "C. Pandu", ""]]}, {"id": "1109.2317", "submitter": "Anwitaman Datta", "authors": "Anwitaman Datta, Frederique Oggier", "title": "An Overview of Codes Tailor-made for Better Repairability in Networked\n  Distributed Storage Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The continuously increasing amount of digital data generated by today's\nsociety asks for better storage solutions. This survey looks at a new\ngeneration of coding techniques designed specifically for the needs of\ndistributed networked storage systems, trying to reach the best compromise\namong storage space efficiency, fault tolerance, and maintenance overheads.\nFour families of codes tailor-made for distributed settings, namely - pyramid,\nhierarchical, regenerating and self-repairing codes - are presented at a high\nlevel, emphasizing the main ideas behind each of these codes, and discussing\ntheir pros and cons, before concluding with a quantitative comparison among\nthem. This survey deliberately excluded technical details for the codes, nor\ndoes it provide an exhaustive summary of the numerous works. Instead, it\nprovides an overview of the major code families in a manner easily accessible\nto a broad audience, by presenting the big picture of advances in coding\ntechniques for distributed storage solutions.\n", "versions": [{"version": "v1", "created": "Sun, 11 Sep 2011 14:27:20 GMT"}, {"version": "v2", "created": "Wed, 30 Jan 2013 03:08:32 GMT"}], "update_date": "2013-01-31", "authors_parsed": [["Datta", "Anwitaman", ""], ["Oggier", "Frederique", ""]]}, {"id": "1109.2425", "submitter": "Anastasia Analyti", "authors": "Carlo Meghini, Yannis Tzitzikas, Veronica Coltella, Anastasia Analyti", "title": "Query processing in distributed, taxonomy-based information sources", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We address the problem of answering queries over a distributed information\nsystem, storing objects indexed by terms organized in a taxonomy. The taxonomy\nconsists of subsumption relationships between negation-free DNF formulas on\nterms and negation-free conjunctions of terms. In the first part of the paper,\nwe consider the centralized case, deriving a hypergraph-based algorithm that is\nefficient in data complexity. In the second part of the paper, we consider the\ndistributed case, presenting alternative ways implementing the centralized\nalgorithm. These ways descend from two basic criteria: direct vs. query\nre-writing evaluation, and centralized vs. distributed data or taxonomy\nallocation. Combinations of these criteria allow to cover a wide spectrum of\narchitectures, ranging from client-server to peer-to-peer. We evaluate the\nperformance of the various architectures by simulation on a network with\nO(10^4) nodes, and derive final results. An extensive review of the relevant\nliterature is finally included.\n", "versions": [{"version": "v1", "created": "Mon, 12 Sep 2011 10:20:31 GMT"}], "update_date": "2011-09-13", "authors_parsed": [["Meghini", "Carlo", ""], ["Tzitzikas", "Yannis", ""], ["Coltella", "Veronica", ""], ["Analyti", "Anastasia", ""]]}, {"id": "1109.3056", "submitter": "Petr  Kuznetsov", "authors": "Carole Delporte-Gallet, Hugues Fauconnier, Eli Gafni, Petr Kuznetsov", "title": "Wait-Freedom with Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We motivate and propose a new way of thinking about failure detectors which\nallows us to define, quite surprisingly, what it means to solve a distributed\ntask \\emph{wait-free} \\emph{using a failure detector}. In our model, the system\nis composed of \\emph{computation} processes that obtain inputs and are supposed\nto output in a finite number of steps and \\emph{synchronization} processes that\nare subject to failures and can query a failure detector. We assume that, under\nthe condition that \\emph{correct} synchronization processes take sufficiently\nmany steps, they provide the computation processes with enough \\emph{advice} to\nsolve the given task wait-free: every computation process outputs in a finite\nnumber of its own steps, regardless of the behavior of other computation\nprocesses. Every task can thus be characterized by the \\emph{weakest} failure\ndetector that allows for solving it, and we show that every such failure\ndetector captures a form of set agreement. We then obtain a complete\nclassification of tasks, including ones that evaded comprehensible\ncharacterization so far, such as renaming or weak symmetry breaking.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2011 11:36:29 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2012 09:56:09 GMT"}, {"version": "v3", "created": "Sun, 13 May 2012 17:33:31 GMT"}], "update_date": "2012-05-15", "authors_parsed": [["Delporte-Gallet", "Carole", ""], ["Fauconnier", "Hugues", ""], ["Gafni", "Eli", ""], ["Kuznetsov", "Petr", ""]]}, {"id": "1109.3074", "submitter": "Alexey Lastovetsky", "authors": "Alexey Lastovetsky, Ravi Reddy, Vladimir Rychkov, David Clarke", "title": "Design and implementation of self-adaptable parallel algorithms for\n  scientific computing on highly heterogeneous HPC platforms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional heterogeneous parallel algorithms, designed for heterogeneous\nclusters of workstations, are based on the assumption that the absolute speed\nof the processors does not depend on the size of the computational task. This\nassumption proved inaccurate for modern and perspective highly heterogeneous\nHPC platforms. New class of algorithms based on the functional performance\nmodel (FPM), representing the speed of the processor by a function of problem\nsize, has been recently proposed. These algorithms cannot be however employed\nin self-adaptable applications because of very high cost of construction of the\nfunctional performance model. The paper presents a new class of parallel\nalgorithms for highly heterogeneous HPC platforms. Like traditional FPM-based\nalgorithms, these algorithms assume that the speed of the processors is\ncharacterized by speed functions rather than speed constants. Unlike the\ntraditional algorithms, they do not assume the speed functions to be given.\nInstead, they estimate the speed functions of the processors for different\nproblem sizes during their execution. These algorithms do not construct the\nfull speed function for each processor but rather build and use their partial\nestimates sufficient for optimal distribution of computations with a given\naccuracy. The low execution cost of distribution of computations between\nheterogeneous processors in these algorithms make them suitable for employment\nin self-adaptable applications. Experiments with parallel matrix multiplication\napplications based on this approach are performed on local and global\nheterogeneous computational clusters. The results show that the execution time\nof optimal matrix distribution between processors is significantly less, by\norders of magnitude, than the total execution time of the optimized\napplication.\n", "versions": [{"version": "v1", "created": "Wed, 14 Sep 2011 13:25:35 GMT"}], "update_date": "2011-09-15", "authors_parsed": [["Lastovetsky", "Alexey", ""], ["Reddy", "Ravi", ""], ["Rychkov", "Vladimir", ""], ["Clarke", "David", ""]]}, {"id": "1109.3277", "submitter": "Jens Harting", "authors": "Florian G\\\"unther, Florian Janoschek, Stefan Frijters, and Jens\n  Harting", "title": "Lattice Boltzmann simulations of anisotropic particles at liquid\n  interfaces", "comments": "10 pages, 5 figures; ParCFD 2011 proceedings contribution", "journal-ref": null, "doi": "10.1016/j.compfluid.2012.03.020", "report-no": null, "categories": "cond-mat.soft cs.DC physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Complex colloidal fluids, such as emulsions stabilized by complex shaped\nparticles, play an important role in many industrial applications. However,\nunderstanding their physics requires a study at sufficiently large length\nscales while still resolving the microscopic structure of a large number of\nparticles and of the local hydrodynamics. Due to its high degree of locality,\nthe lattice Boltzmann method, when combined with a molecular dynamics solver\nand parallelized on modern supercomputers, provides a tool that allows such\nstudies. Still, running simulations on hundreds of thousands of cores is not\ntrivial. We report on our practical experiences when employing large fractions\nof an IBM Blue Gene/P system for our simulations. Then, we extend our model for\nspherical particles in multicomponent flows to anisotropic ellipsoidal objects\nrendering the shape of e.g. clay particles. The model is applied to a number of\ntest cases including the adsorption of single particles at fluid interfaces and\nthe formation and stabilization of Pickering emulsions or bijels.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2011 07:29:28 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2012 14:20:52 GMT"}], "update_date": "2012-04-27", "authors_parsed": [["G\u00fcnther", "Florian", ""], ["Janoschek", "Florian", ""], ["Frijters", "Stefan", ""], ["Harting", "Jens", ""]]}, {"id": "1109.3401", "submitter": "\\\"Ozg\\\"ur  \\\"Ozkan", "authors": "Lisa Hellerstein, \\\"Ozg\\\"ur \\\"Ozkan, Linda Sellie", "title": "Max-Throughput for (Conservative) k-of-n Testing", "comments": "17 pages. An extended abstract of this paper appeared in the\n  Proceedings of the 22nd International Symposium on Algorithms and Computation\n  (ISAAC 2011)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a variant of k-of-n testing that we call conservative k-of-n\ntesting. We present a polynomial-time, combinatorial algorithm for the problem\nof maximizing throughput of conservative k-of-n testing, in a parallel setting.\nThis extends previous work of Kodialam and Condon et al., who presented\ncombinatorial algorithms for parallel pipelined filter ordering, which is the\nspecial case where k=1 (or k = n). We also consider the problem of maximizing\nthroughput for standard k-of-n testing, and show how to obtain a\npolynomial-time algorithm based on the ellipsoid method using previous\ntechniques.\n", "versions": [{"version": "v1", "created": "Thu, 15 Sep 2011 16:58:28 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2012 02:38:45 GMT"}], "update_date": "2012-10-31", "authors_parsed": [["Hellerstein", "Lisa", ""], ["\u00d6zkan", "\u00d6zg\u00fcr", ""], ["Sellie", "Linda", ""]]}, {"id": "1109.3555", "submitter": "Francesco Pagano", "authors": "Francesco Pagano and Davide Pagano", "title": "Using In-Memory Encrypted Databases on the Cloud", "comments": "8 pages, 8 figures", "journal-ref": "2011 1st International Workshop on Securing Ser vices on the Cloud\n  IWSSC 2011", "doi": null, "report-no": null, "categories": "cs.CR cs.DB cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Storing data in the cloud poses a number of privacy issues. A way to handle\nthem is supporting data replication and distribution on the cloud via a local,\ncentrally synchronized storage. In this paper we propose to use an in-memory\nRDBMS with row-level data encryption for granting and revoking access rights to\ndistributed data. This type of solution is rarely adopted in conventional\nRDBMSs because it requires several complex steps. In this paper we focus on\nimplementation and benchmarking of a test system, which shows that our simple\nyet effective solution overcomes most of the problems.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2011 09:20:23 GMT"}], "update_date": "2011-09-19", "authors_parsed": [["Pagano", "Francesco", ""], ["Pagano", "Davide", ""]]}, {"id": "1109.3561", "submitter": "Alain Bui", "authors": "Thibault Bernard, Alain Bui, Devan Sohier", "title": "Universal adaptive self-stabilizing traversal scheme: random walk and\n  reloading wave", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate random walk based token circulation in dynamic\nenvironments subject to failures. We describe hypotheses on the dynamic\nenvironment that allow random walks to meet the important property that the\ntoken visits any node infinitely often. The randomness of this scheme allows it\nto work on any topology, and require no adaptation after a topological change,\nwhich is a desirable property for applications to dynamic systems. For random\nwalks to be a traversal scheme and to answer the concurrence problem, one needs\nto guarantee that exactly one token circulates in the system. In the presence\nof transient failures, configurations with multiple tokens or with no token can\noccur. The meeting property of random walks solves the cases with multiple\ntokens. The reloading wave mechanism we propose, together with timeouts, allows\nto detect and solve cases with no token. This traversal scheme is\nself-stabilizing, and universal, meaning that it needs no assumption on the\nsystem topology. We describe conditions on the dynamicity (with a local\ndetection criterion) under which the algorithm is tolerant to dynamic\nreconfigurations. We conclude by a study on the time between two visits of the\ntoken to a node, which we use to tune the parameters of the reloading wave\nmechanism according to some system characteristics.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2011 09:38:20 GMT"}], "update_date": "2011-09-19", "authors_parsed": [["Bernard", "Thibault", ""], ["Bui", "Alain", ""], ["Sohier", "Devan", ""]]}, {"id": "1109.3739", "submitter": "Aydin Buluc", "authors": "Aydin Buluc and John Gilbert", "title": "Parallel Sparse Matrix-Matrix Multiplication and Indexing:\n  Implementation and Experiments", "comments": null, "journal-ref": "SIAM J. Sci. Comput., 34(4), 170 - 191, 2012", "doi": "10.1137/110848244", "report-no": null, "categories": "cs.DC cs.MS cs.NA cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Generalized sparse matrix-matrix multiplication (or SpGEMM) is a key\nprimitive for many high performance graph algorithms as well as for some linear\nsolvers, such as algebraic multigrid. Here we show that SpGEMM also yields\nefficient algorithms for general sparse-matrix indexing in distributed memory,\nprovided that the underlying SpGEMM implementation is sufficiently flexible and\nscalable. We demonstrate that our parallel SpGEMM methods, which use\ntwo-dimensional block data distributions with serial hypersparse kernels, are\nindeed highly flexible, scalable, and memory-efficient in the general case.\nThis algorithm is the first to yield increasing speedup on an unbounded number\nof processors; our experiments show scaling up to thousands of processors in a\nvariety of test scenarios.\n", "versions": [{"version": "v1", "created": "Fri, 16 Sep 2011 23:25:28 GMT"}, {"version": "v2", "created": "Thu, 26 Apr 2012 20:41:41 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Buluc", "Aydin", ""], ["Gilbert", "John", ""]]}, {"id": "1109.3987", "submitter": "Damianos Gavalas", "authors": "Damianos Gavalas, Grammati Pantziou, Charalampos Konstantopoulos,\n  Basilis Mamalis", "title": "Clustering of Mobile Ad Hoc Networks: An Adaptive Broadcast Period\n  Approach", "comments": "7 pages, 9 figures; IEEE International Conference on Communications,\n  2006. ICC '06", "journal-ref": null, "doi": "10.1109/ICC.2006.255712", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Organization, scalability and routing have been identified as key problems\nhindering viability and commercial success of mobile ad hoc networks.\nClustering of mobile nodes among separate domains has been proposed as an\nefficient approach to address those issues. In this work, we introduce an\nefficient distributed clustering algorithm that uses both location and energy\nmetrics for cluster formation. Our proposed solution mainly addresses cluster\nstability, manageability and energy efficiency issues. Also, unlike existing\nactive clustering methods, our algorithm relieves the network from the\nunnecessary burden of control messages broadcasting, especially for relatively\nstatic network topologies. This is achieved through adapting broadcast period\naccording to mobile nodes mobility pattern. The efficiency, scalability and\ncompetence of our algorithm against alternative approaches have been\ndemonstrated through simulation results.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2011 10:14:29 GMT"}], "update_date": "2011-09-20", "authors_parsed": [["Gavalas", "Damianos", ""], ["Pantziou", "Grammati", ""], ["Konstantopoulos", "Charalampos", ""], ["Mamalis", "Basilis", ""]]}, {"id": "1109.3997", "submitter": "Damianos Gavalas", "authors": "Damianos Gavalas, Grammati Pantziou, Charalampos Konstantopoulos,\n  Basilis Mamalis", "title": "Lowest-ID with Adaptive ID Reassignment: A Novel Mobile Ad-Hoc Networks\n  Clustering Algorithm", "comments": "5 pages, 4 figures; Proceedings of the 1st IEEE International\n  Symposium on Wireless Pervasive Computing (ISWPC'2006)", "journal-ref": null, "doi": "10.1109/ISWPC.2006.1613559", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a promising approach for building hierarchies and simplifying\nthe routing process in mobile ad-hoc network environments. The main objective\nof clustering is to identify suitable node representatives, i.e. cluster heads\n(CHs), to store routing and topology information and maximize clusters\nstability. Traditional clustering algorithms suggest CH election exclusively\nbased on node IDs or location information and involve frequent broadcasting of\ncontrol packets, even when network topology remains unchanged. More recent\nworks take into account additional metrics (such as energy and mobility) and\noptimize initial clustering. However, in many situations (e.g. in relatively\nstatic topologies) re-clustering procedure is hardly ever invoked; hence\ninitially elected CHs soon reach battery exhaustion. Herein, we introduce an\nefficient distributed clustering algorithm that uses both mobility and energy\nmetrics to provide stable cluster formations. CHs are initially elected based\non the time and cost-efficient lowest-ID method. During clustering maintenance\nphase though, node IDs are re-assigned according to nodes mobility and energy\nstatus, ensuring that nodes with low-mobility and sufficient energy supply are\nassigned low IDs and, hence, are elected as CHs. Our algorithm also reduces\ncontrol traffic volume since broadcast period is adjusted according to nodes\nmobility pattern: we employ infrequent broadcasting for relative static network\ntopologies, and increase broadcast frequency for highly mobile network\nconfigurations. Simulation results verify that energy consumption is uniformly\ndistributed among network nodes and that signaling overhead is significantly\ndecreased.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2011 11:11:57 GMT"}], "update_date": "2011-09-20", "authors_parsed": [["Gavalas", "Damianos", ""], ["Pantziou", "Grammati", ""], ["Konstantopoulos", "Charalampos", ""], ["Mamalis", "Basilis", ""]]}, {"id": "1109.4114", "submitter": "Ramesh Sitaraman", "authors": "Konstantin Andreev, Bruce M. Maggs, Adam Meyerson, Jevan Saks, Ramesh\n  K. Sitaraman", "title": "Algorithms for Constructing Overlay Networks For Live Streaming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a polynomial time approximation algorithm for constructing an\noverlay multicast network for streaming live media events over the Internet.\nThe class of overlay networks constructed by our algorithm include networks\nused by Akamai Technologies to deliver live media events to a global audience\nwith high fidelity. We construct networks consisting of three stages of nodes.\nThe nodes in the first stage are the entry points that act as sources for the\nlive streams. Each source forwards each of its streams to one or more nodes in\nthe second stage that are called reflectors. A reflector can split an incoming\nstream into multiple identical outgoing streams, which are then sent on to\nnodes in the third and final stage that act as sinks and are located in edge\nnetworks near end-users. As the packets in a stream travel from one stage to\nthe next, some of them may be lost. A sink combines the packets from multiple\ninstances of the same stream (by reordering packets and discarding duplicates)\nto form a single instance of the stream with minimal loss. Our primary\ncontribution is an algorithm that constructs an overlay network that provably\nsatisfies capacity and reliability constraints to within a constant factor of\noptimal, and minimizes cost to within a logarithmic factor of optimal. Further\nin the common case where only the transmission costs are minimized, we show\nthat our algorithm produces a solution that has cost within a factor of 2 of\noptimal. We also implement our algorithm and evaluate it on realistic traces\nderived from Akamai's live streaming network. Our empirical results show that\nour algorithm can be used to efficiently construct large-scale overlay networks\nin practice with near-optimal cost.\n", "versions": [{"version": "v1", "created": "Mon, 19 Sep 2011 18:27:18 GMT"}], "update_date": "2011-09-20", "authors_parsed": [["Andreev", "Konstantin", ""], ["Maggs", "Bruce M.", ""], ["Meyerson", "Adam", ""], ["Saks", "Jevan", ""], ["Sitaraman", "Ramesh K.", ""]]}, {"id": "1109.4240", "submitter": "Stefan Plantikow", "authors": "Stefan Plantikow", "title": "Actor Continuation Passing: Efficient and Extensible Request Routing for\n  Event-Driven Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The logic for handling of application requests to a staged, event-driven\narchitecture is often distributed over different portions of the source code.\nThis complicates changing and understanding the flow of events in the system.\nThe article presents an approach that extracts request handling logic from\nregular stage functionality into a set of request scripts. These scripts are\nexecuted step-wise by sending continuations that encapsulate their request's\ncurrent execution state to stages for local processing and optional forwarding\nof follow-up continuations. A new internal domain specific language (DSL) that\naims to simplify writing of request scripts is described along with its\nimplementation for the scala actors library. Evaluation results indicate that\nrequest handling with actor continuations performs about equally or better\ncompared to using separate stages for request handling logic for scripts of at\nleast 3 sequential steps.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2011 08:55:10 GMT"}], "update_date": "2011-09-21", "authors_parsed": [["Plantikow", "Stefan", ""]]}, {"id": "1109.4373", "submitter": "Miguel Mosteiro", "authors": "Paulo S. Almeida, Carlos Baquero, Martin Farach-Colton, Paulo Jesus,\n  and Miguel A. Mosteiro", "title": "Fault-Tolerant Aggregation: Flow-Updating Meets Mass-Distribution", "comments": "18 pages, 5 figures, To appear in OPODIS 2011", "journal-ref": null, "doi": "10.1007/978-3-642-25873-2_35", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Flow-Updating (FU) is a fault-tolerant technique that has proved to be\nefficient in practice for the distributed computation of aggregate functions in\ncommunication networks where individual processors do not have access to global\ninformation. Previous distributed aggregation protocols, based on repeated\nsharing of input values (or mass) among processors, sometimes called\nMass-Distribution (MD) protocols, are not resilient to communication failures\n(or message loss) because such failures yield a loss of mass. In this paper, we\npresent a protocol which we call Mass-Distribution with Flow-Updating (MDFU).\nWe obtain MDFU by applying FU techniques to classic MD. We analyze the\nconvergence time of MDFU showing that stochastic message loss produces low\noverhead. This is the first convergence proof of an FU-based algorithm. We\nevaluate MDFU experimentally, comparing it with previous MD and FU protocols,\nand verifying the behavior predicted by the analysis. Finally, given that MDFU\nincurs a fixed deviation proportional to the message-loss rate, we adjust the\naccuracy of MDFU heuristically in a new protocol called MDFU with Linear\nPrediction (MDFU-LP). The evaluation shows that both MDFU and MDFU-LP behave\nvery well in practice, even under high rates of message loss and even changing\nthe input values dynamically.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2011 17:30:49 GMT"}], "update_date": "2012-11-16", "authors_parsed": [["Almeida", "Paulo S.", ""], ["Baquero", "Carlos", ""], ["Farach-Colton", "Martin", ""], ["Jesus", "Paulo", ""], ["Mosteiro", "Miguel A.", ""]]}, {"id": "1109.4433", "submitter": "Johanne Cohen", "authors": "Olivier Bournez, J\\'er\\'emie Chalopin, Johanne Cohen, Xavier Koegler,\n  Mikael Rabie", "title": "Asymetric Pavlovian Populations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population protocols have been introduced by Angluin et al. as a model of\nnetworks consisting of very limited mobile agents that interact in pairs but\nwith no control over their own movement. A collection of anonymous agents,\nmodeled by finite automata, interact pairwise according to some rules that\nupdate their states. Predicates on the initial configurations that can be\ncomputed by such protocols have been characterized as semi-linear predicates.\nIn an orthogonal way, several distributed systems have been termed in\nliterature as being realizations of games in the sense of game theory. We\ninvestigate under which conditions population protocols, or more generally\npairwise interaction rules, correspond to games. We show that restricting to\nasymetric games is not really a restric- tion: all predicates computable by\nprotocols can actually be computed by protocols corresponding to games, i.e.\nany semi-linear predicate can be computed by a Pavlovian population\nmulti-protocol.\n", "versions": [{"version": "v1", "created": "Tue, 20 Sep 2011 21:17:02 GMT"}], "update_date": "2011-09-22", "authors_parsed": [["Bournez", "Olivier", ""], ["Chalopin", "J\u00e9r\u00e9mie", ""], ["Cohen", "Johanne", ""], ["Koegler", "Xavier", ""], ["Rabie", "Mikael", ""]]}, {"id": "1109.4925", "submitter": "Leandro Marzulo", "authors": "Leandro A. J. Marzulo, Tiago A. O. Alves, Felipe M. G. Fran\\c{c}a,\n  V\\'itor Santos Costa", "title": "Couillard: Parallel Programming via Coarse-Grained Data-Flow Compilation", "comments": "10 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-flow is a natural approach to parallelism. However, describing\ndependencies and control between fine-grained data-flow tasks can be complex\nand present unwanted overheads. TALM (TALM is an Architecture and Language for\nMulti-threading) introduces a user-defined coarse-grained parallel data-flow\nmodel, where programmers identify code blocks, called super-instructions, to be\nrun in parallel and connect them in a data-flow graph. TALM has been\nimplemented as a hybrid Von Neumann/data-flow execution system: the\n\\emph{Trebuchet}. We have observed that TALM's usefulness largely depends on\nhow programmers specify and connect super-instructions. Thus, we present\n\\emph{Couillard}, a full compiler that creates, based on an annotated\nC-program, a data-flow graph and C-code corresponding to each\nsuper-instruction. We show that our toolchain allows one to benefit from\ndata-flow execution and explore sophisticated parallel programming techniques,\nwith small effort. To evaluate our system we have executed a set of real\napplications on a large multi-core machine. Comparison with popular parallel\nprogramming methods shows competitive speedups, while providing an easier\nparallel programing approach.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 19:44:19 GMT"}], "update_date": "2011-09-23", "authors_parsed": [["Marzulo", "Leandro A. J.", ""], ["Alves", "Tiago A. O.", ""], ["Fran\u00e7a", "Felipe M. G.", ""], ["Costa", "V\u00edtor Santos", ""]]}, {"id": "1109.4974", "submitter": "William Voorsluys", "authors": "William Voorsluys, James Broberg, Srikumar Venugopal, Rajkumar Buyya", "title": "Cost of Virtual Machine Live Migration in Clouds: A Performance\n  Evaluation", "comments": "CloudCom 2009", "journal-ref": null, "doi": "10.1007/978-3-642-10665-1_23", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualization has become commonplace in modern data centers, often referred\nas \"computing clouds\". The capability of virtual machine live migration brings\nbenefits such as improved performance, manageability and fault tolerance, while\nallowing workload movement with a short service downtime. However, service\nlevels of applications are likely to be negatively affected during a live\nmigration. For this reason, a better understanding of its effects on system\nperformance is desirable. In this paper, we evaluate the effects of live\nmigration of virtual machines on the performance of applications running inside\nXen VMs. Results show that, in most cases, migration overhead is acceptable but\ncannot be disregarded, especially in systems where availability and\nresponsiveness are governed by strict Service Level Agreements. Despite that,\nthere is a high potential for live migration applicability in data centers\nserving modernInternet applications. Our results are based on a workload\ncovering the domain of multi-tier Web 2.0 applications.\n", "versions": [{"version": "v1", "created": "Thu, 22 Sep 2011 23:52:18 GMT"}, {"version": "v2", "created": "Fri, 9 Dec 2011 08:07:58 GMT"}], "update_date": "2011-12-12", "authors_parsed": [["Voorsluys", "William", ""], ["Broberg", "James", ""], ["Venugopal", "Srikumar", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1109.5111", "submitter": "Robbert Van Renesse", "authors": "Robbert van Renesse, Fred B. Schneider, Johannes Gehrke", "title": "Nerio: Leader Election and Edict Ordering", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coordination in a distributed system is facilitated if there is a unique\nprocess, the leader, to manage the other processes. The leader creates edicts\nand sends them to other processes for execution or forwarding to other\nprocesses. The leader may fail, and when this occurs a leader election protocol\nselects a replacement. This paper describes Nerio, a class of such leader\nelection protocols.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2011 15:27:43 GMT"}, {"version": "v2", "created": "Mon, 26 Sep 2011 13:05:27 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["van Renesse", "Robbert", ""], ["Schneider", "Fred B.", ""], ["Gehrke", "Johannes", ""]]}, {"id": "1109.5153", "submitter": "Wojciech Golab", "authors": "Wojciech Golab", "title": "A Complexity Separation Between the Cache-Coherent and Distributed\n  Shared Memory Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider asynchronous multiprocessor systems where processes communicate\nby accessing shared memory. Exchange of information among processes in such a\nmultiprocessor necessitates costly memory accesses called \\emph{remote memory\nreferences} (RMRs), which generate communication on the interconnect joining\nprocessors and main memory. In this paper we compare two popular shared memory\narchitecture models, namely the \\emph{cache-coherent} (CC) and\n\\emph{distributed shared memory} (DSM) models, in terms of their power for\nsolving synchronization problems efficiently with respect to RMRs. The\nparticular problem we consider entails one process sending a \"signal\" to a\nsubset of other processes. We show that a variant of this problem can be solved\nvery efficiently with respect to RMRs in the CC model, but not so in the DSM\nmodel, even when we consider amortized RMR complexity.\n  To our knowledge, this is the first separation in terms of amortized RMR\ncomplexity between the CC and DSM models. It is also the first separation in\nterms of RMR complexity (for asynchronous systems) that does not rely in any\nway on wait-freedom---the requirement that a process makes progress in a\nbounded number of its own steps.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2011 18:39:18 GMT"}], "update_date": "2011-09-26", "authors_parsed": [["Golab", "Wojciech", ""]]}, {"id": "1109.5190", "submitter": "Matthew Anderson", "authors": "Chirag Dekate, Matthew Anderson, Maciej Brodowicz, Hartmut Kaiser,\n  Bryce Adelstein-Lelbach, Thomas Sterling", "title": "Improving the scalability of parallel N-body applications with an event\n  driven constraint based execution model", "comments": "11 figures", "journal-ref": "International Journal of High Performance Computing Applications,\n  April 11, 2012", "doi": "10.1177/1094342012440585", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scalability and efficiency of graph applications are significantly\nconstrained by conventional systems and their supporting programming models.\nTechnology trends like multicore, manycore, and heterogeneous system\narchitectures are introducing further challenges and possibilities for emerging\napplication domains such as graph applications. This paper explores the space\nof effective parallel execution of ephemeral graphs that are dynamically\ngenerated using the Barnes-Hut algorithm to exemplify dynamic workloads. The\nworkloads are expressed using the semantics of an Exascale computing execution\nmodel called ParalleX. For comparison, results using conventional execution\nmodel semantics are also presented. We find improved load balancing during\nruntime and automatic parallelism discovery improving efficiency using the\nadvanced semantics for Exascale computing.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2011 20:14:24 GMT"}], "update_date": "2012-05-22", "authors_parsed": [["Dekate", "Chirag", ""], ["Anderson", "Matthew", ""], ["Brodowicz", "Maciej", ""], ["Kaiser", "Hartmut", ""], ["Adelstein-Lelbach", "Bryce", ""], ["Sterling", "Thomas", ""]]}, {"id": "1109.5201", "submitter": "Matthew Anderson", "authors": "Matthew Anderson, Maciej Brodowicz, Hartmut Kaiser, Thomas Sterling", "title": "An Application Driven Analysis of the ParalleX Execution Model", "comments": "9 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exascale systems, expected to emerge by the end of the next decade, will\nrequire the exploitation of billion-way parallelism at multiple hierarchical\nlevels in order to achieve the desired sustained performance. The task of\nassessing future machine performance is approached by identifying the factors\nwhich currently challenge the scalability of parallel applications. It is\nsuggested that the root cause of these challenges is the incoherent coupling\nbetween the current enabling technologies, such as Non-Uniform Memory Access of\npresent multicore nodes equipped with optional hardware accelerators and the\ndecades older execution model, i.e., the Communicating Sequential Processes\n(CSP) model best exemplified by the message passing interface (MPI) application\nprogramming interface. A new execution model, ParalleX, is introduced as an\nalternative to the CSP model. In this paper, an overview of the ParalleX\nexecution model is presented along with details about a ParalleX-compliant\nruntime system implementation called High Performance ParalleX (HPX). Scaling\nand performance results for an adaptive mesh refinement numerical relativity\napplication developed using HPX are discussed. The performance results of this\nHPX-based application are compared with a counterpart MPI-based mesh refinement\ncode. The overheads associated with HPX are explored and hardware solutions are\nintroduced for accelerating the runtime system.\n", "versions": [{"version": "v1", "created": "Fri, 23 Sep 2011 21:00:36 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Anderson", "Matthew", ""], ["Brodowicz", "Maciej", ""], ["Kaiser", "Hartmut", ""], ["Sterling", "Thomas", ""]]}, {"id": "1109.5559", "submitter": "Derek Groen", "authors": "Derek Groen (UCL), Steven Rieder (Leiden Observatory), Simon Portegies\n  Zwart (Leiden Observatory)", "title": "High performance cosmological simulations on a grid of supercomputers", "comments": "Accepted for the INFOCOMP 2011 conference, 6 pages, 2 figures, 4\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC astro-ph.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present results from our cosmological N-body simulation which consisted of\n2048x2048x2048 particles and ran distributed across three supercomputers\nthroughout Europe. The run, which was performed as the concluding phase of the\nGravitational Billion Body Problem DEISA project, integrated a 30 Mpc box of\ndark matter using an optimized Tree/Particle Mesh N-body integrator. We ran the\nsimulation up to the present day (z=0), and obtained an efficiency of about\n0.93 over 2048 cores compared to a single supercomputer run. In addition, we\nshare our experiences on using multiple supercomputers for high performance\ncomputing and provide several recommendations for future projects.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 13:36:22 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Groen", "Derek", "", "UCL"], ["Rieder", "Steven", "", "Leiden Observatory"], ["Zwart", "Simon Portegies", "", "Leiden Observatory"]]}, {"id": "1109.5641", "submitter": "Ramesh Sitaraman", "authors": "Vimal Mathew, Ramesh K. Sitaraman and Prashant Shenoy", "title": "Energy-Aware Load Balancing in Content Delivery Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet-scale distributed systems such as content delivery networks (CDNs)\noperate hundreds of thousands of servers deployed in thousands of data center\nlocations around the globe. Since the energy costs of operating such a large IT\ninfrastructure are a significant fraction of the total operating costs, we\nargue for redesigning CDNs to incorporate energy optimizations as a first-order\nprinciple. We propose techniques to turn off CDN servers during periods of low\nload while seeking to balance three key design goals: maximize energy\nreduction, minimize the impact on client-perceived service availability (SLAs),\nand limit the frequency of on-off server transitions to reduce wear-and-tear\nand its impact on hardware reliability. We propose an optimal offline algorithm\nand an online algorithm to extract energy savings both at the level of local\nload balancing within a data center and global load balancing across data\ncenters. We evaluate our algorithms using real production workload traces from\na large commercial CDN. Our results show that it is possible to reduce the\nenergy consumption of a CDN by more than 55% while ensuring a high level of\navailability that meets customer SLA requirements and incurring an average of\none on-off transition per server per day. Further, we show that keeping even\n10% of the servers as hot spares helps absorb load spikes due to global flash\ncrowds with little impact on availability SLAs. Finally, we show that\nredistributing load across proximal data centers can enhance service\navailability significantly, but has only a modest impact on energy savings.\n", "versions": [{"version": "v1", "created": "Mon, 26 Sep 2011 17:12:12 GMT"}], "update_date": "2011-09-27", "authors_parsed": [["Mathew", "Vimal", ""], ["Sitaraman", "Ramesh K.", ""], ["Shenoy", "Prashant", ""]]}, {"id": "1109.5770", "submitter": "Mei Leng", "authors": "Mei Leng, Wee Peng Tay, and Tony Q.S. Quek", "title": "Cooperative and Distributed Localization for Wireless Sensor Networks in\n  Multipath Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of sensor localization in a wireless network in a\nmultipath environment, where time and angle of arrival information are\navailable at each sensor. We propose a distributed algorithm based on belief\npropagation, which allows sensors to cooperatively self-localize with respect\nto one single anchor in a multihop network. The algorithm has low overhead and\nis scalable. Simulations show that although the network is loopy, the proposed\nalgorithm converges, and achieves good localization accuracy.\n", "versions": [{"version": "v1", "created": "Tue, 27 Sep 2011 04:38:33 GMT"}], "update_date": "2011-09-28", "authors_parsed": [["Leng", "Mei", ""], ["Tay", "Wee Peng", ""], ["Quek", "Tony Q. S.", ""]]}, {"id": "1109.6191", "submitter": "Ondrej Hlinka", "authors": "Ondrej Hlinka, Franz Hlawatsch, and Petar M. Djuric", "title": "Likelihood Consensus-Based Distributed Particle Filtering with\n  Distributed Proposal Density Adaptation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.AP cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a consensus-based distributed particle filter (PF) for wireless\nsensor networks. Each sensor runs a local PF to compute a global state estimate\nthat takes into account the measurements of all sensors. The local PFs use the\njoint (all-sensors) likelihood function, which is calculated in a distributed\nway by a novel generalization of the likelihood consensus scheme. A performance\nimprovement (or a reduction of the required number of particles) is achieved by\na novel distributed, consensus-based method for adapting the proposal densities\nof the local PFs. The performance of the proposed distributed PF is\ndemonstrated for a target tracking problem.\n", "versions": [{"version": "v1", "created": "Wed, 28 Sep 2011 12:58:56 GMT"}], "update_date": "2011-09-29", "authors_parsed": [["Hlinka", "Ondrej", ""], ["Hlawatsch", "Franz", ""], ["Djuric", "Petar M.", ""]]}, {"id": "1109.6460", "submitter": "Sergii Zub", "authors": "P.I.Neyezhmakov, S.I.Zub, S.S.Zub", "title": "The Grid: Prospects for Application in Metrology", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.ins-det cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Global system of distributing computing - Grid - created as reply for\nchallenges, connected with the qualitative progress of complexity of\nexperimental physical assemblies and information systems, is presented as\noptimal IT platform for assurance of measurement traceability in geographically\nremote regions and measurement data protection in global networks. The new\ncomponent grid - Instrument Element (IE) - is intended for secure, remote,\njoint team work on monitoring and managing instruments generated and stored on\ndistributed scientific equipment using conventional grid resources. The article\ndescribes the variety of all possible IE applications within grid technology\nfor the tasks of metrology demanding IT support. Expanded by the new component\nIE grid becomes an optimal environment for effective monitoring, management and\nservicing of measuring resources which has the highest level of measurement\ndata transfer, storage and processing safety and reveals new opportunities to\ntrack measurement procedures and assure a high level of confidence to these\nmeasurements.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2011 10:11:13 GMT"}], "update_date": "2011-09-30", "authors_parsed": [["Neyezhmakov", "P. I.", ""], ["Zub", "S. I.", ""], ["Zub", "S. S.", ""]]}, {"id": "1109.6534", "submitter": "Karol Suchan", "authors": "Florent Becker, Adrian Kosowski, Nicolas Nisse, Ivan Rapaport, Karol\n  Suchan", "title": "Interconnection network with a shared whiteboard: Impact of\n  (a)synchronicity on computing power", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we study the computational power of graph-based models of\ndistributed computing in which each node additionally has access to a global\nwhiteboard. A node can read the contents of the whiteboard and, when activated,\ncan write one message of O(log n) bits on it. When the protocol terminates,\neach node computes the output based on the final contents of the whiteboard. We\nconsider several scheduling schemes for nodes, providing a strict ordering of\ntheir power in terms of the problems which can be solved with exactly one\nactivation per node. The problems used to separate the models are related to\nMaximal Independent Set, detection of cycles of length 4, and BFS spanning tree\nconstructions.\n", "versions": [{"version": "v1", "created": "Thu, 29 Sep 2011 14:16:24 GMT"}], "update_date": "2015-03-19", "authors_parsed": [["Becker", "Florent", ""], ["Kosowski", "Adrian", ""], ["Nisse", "Nicolas", ""], ["Rapaport", "Ivan", ""], ["Suchan", "Karol", ""]]}, {"id": "1109.6646", "submitter": "Abbas Kiani", "authors": "Abbas Kiani, Soroush Akhlaghi", "title": "A Non-MDS Erasure Code Scheme For Storage Applications", "comments": "6 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the use of redundancy and self repairing against node\nfailures in distributed storage systems, using various strategies. In\nreplication method, access to one replication node is sufficient to reconstruct\na lost node, while in MDS erasure coded systems which are optimal in terms of\nredundancy-reliability tradeoff, a single node failure is repaired after\nrecovering the entire stored data. Moreover, regenerating codes yield a\ntradeoff curve between storage capacity and repair bandwidth. The current paper\naims at investigating a new storage code. Specifically, we propose a non-MDS\n(2k, k) code that tolerates any three node failures and more importantly, it is\nshown using our code a single node failure can be repaired through access to\nonly three nodes.\n", "versions": [{"version": "v1", "created": "Wed, 21 Sep 2011 08:02:18 GMT"}], "update_date": "2011-10-03", "authors_parsed": [["Kiani", "Abbas", ""], ["Akhlaghi", "Soroush", ""]]}, {"id": "1109.6925", "submitter": "Clemens P J Adolphs", "authors": "C. P. J. Adolphs and P. Berenbrink", "title": "Distributed Selfish Load Balancing with Weights and Speeds", "comments": "29 pages, submitted to STACS 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider neighborhood load balancing in the context of\nselfish clients. We assume that a network of n processors and m tasks is given.\nThe processors may have different speeds and the tasks may have different\nweights. Every task is controlled by a selfish user. The objective of the user\nis to allocate his/her task to a processor with minimum load. We revisit the\nconcurrent probabilistic protocol introduced in [6], which works in sequential\nrounds. In each round every task is allowed to query the load of one randomly\nchosen neighboring processor. If that load is smaller the task will migrate to\nthat processor with a suitably chosen probability. Using techniques from\nspectral graph theory we obtain upper bounds on the expected convergence time\ntowards approximate and exact Nash equilibria that are significantly better\nthan the previous results in [6]. We show results for uniform tasks on\nnon-uniform processors and the general case where the tasks have different\nweights and the machines have speeds. To the best of our knowledge, these are\nthe first results for this general setting.\n", "versions": [{"version": "v1", "created": "Fri, 30 Sep 2011 18:49:41 GMT"}], "update_date": "2011-10-03", "authors_parsed": [["Adolphs", "C. P. J.", ""], ["Berenbrink", "P.", ""]]}]