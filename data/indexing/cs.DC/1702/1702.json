[{"id": "1702.00208", "submitter": "Peter Boyle", "authors": "Peter A Boyle", "title": "Machines and Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "hep-lat cs.AR cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  I discuss the evolution of computer architectures with a focus on QCD and\nwith reference to the interplay between architecture, engineering, data motion\nand algorithms. New architectures are discussed and recent performance results\nare displayed. I also review recent progress in multilevel solver and\nintegation algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 11:04:34 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Boyle", "Peter A", ""]]}, {"id": "1702.00259", "submitter": "Mei-Mei Gu", "authors": "Mei-Mei Gu, Rong-Xia Hao, Shuming Zhou", "title": "Fault diagnosability of data center networks", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The data center networks $D_{n,k}$, proposed in 2008, has many desirable\nfeatures such as high network capacity. A kind of generalization of\ndiagnosability for network $G$ is $g$-good-neighbor diagnosability which is\ndenoted by $t_g(G)$. Let $\\kappa^g(G)$ be the $R^g$-connectivity. Lin et. al.\nin [IEEE Trans. on Reliability, 65 (3) (2016) 1248--1262] and Xu et. al in\n[Theor. Comput. Sci. 659 (2017) 53--63] gave the same problem independently\nthat: the relationship between the $R^g$-connectivity $\\kappa^g(G)$ and\n$t_g(G)$ of a general graph $G$ need to be studied in the future. In this\npaper, this open problem is solved for general regular graphs. We firstly\nestablish the relationship of $\\kappa^g(G)$ and $t_g(G)$, and obtain that\n$t_g(G)=\\kappa^g(G)+g$ under some conditions. Secondly, we obtain the\n$g$-good-neighbor diagnosability of $D_{k,n}$ which are\n$t_g(D_{k,n})=(g+1)(k-1)+n+g$ for $1\\leq g\\leq n-1$ under the PMC model and the\nMM model, respectively. Further more, we show that $D_{k,n}$ is tightly super\n$(n+k-1)$-connected for $n\\geq 2$ and $k\\geq 2$ and we also prove that the\nlargest connected component of the survival graph contains almost all of the\nremaining vertices in $D_{k,n}$ when $2k+n-2$ vertices removed.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2017 08:37:44 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Gu", "Mei-Mei", ""], ["Hao", "Rong-Xia", ""], ["Zhou", "Shuming", ""]]}, {"id": "1702.00311", "submitter": "Yuqing Zhu", "authors": "Yuqing Zhu, Jianxun Liu, Mengying Guo, Wenlong Ma, Yungang Bao", "title": "Transaction Support over Redis: An Overview", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document outlines the approach to supporting cross-node transactions\nover a Redis cluster.\n", "versions": [{"version": "v1", "created": "Sun, 29 Jan 2017 16:49:30 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Zhu", "Yuqing", ""], ["Liu", "Jianxun", ""], ["Guo", "Mengying", ""], ["Ma", "Wenlong", ""], ["Bao", "Yungang", ""]]}, {"id": "1702.00312", "submitter": "Hui Liu Mr", "authors": "Hui Liu, Tao Cui, Wei Leng, Linbo Zhang", "title": "Dynamic load balancing for large-scale adaptive finite element\n  computation", "comments": "in Chinese", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the parallel computation of partial differential equations, one key is\nthe grid partitioning. It requires that each process owns the same amount of\ncomputations, and also, the partitioning quality should be proper to reduce the\ncommunications among processes. When calculating the partial differential\nequations using adaptive finite element methods, the grid and the basis\nfunctions adjust in each iteration, which introduce load balancing issues. The\ngrid should be redistributed dynamically. This paper studies dynamic load\nbalancing algorithms and the implementation on the adaptive finite element\nplatform PHG. The numerical experiments show that algorithms studied in this\npaper have good partitioning quality, and they are efficient.\n", "versions": [{"version": "v1", "created": "Mon, 23 Jan 2017 03:17:31 GMT"}], "update_date": "2017-02-02", "authors_parsed": [["Liu", "Hui", ""], ["Cui", "Tao", ""], ["Leng", "Wei", ""], ["Zhang", "Linbo", ""]]}, {"id": "1702.00361", "submitter": "Thibault Rieutord", "authors": "Petr Kuznetsov and Thibault Rieutord", "title": "Agreement Functions for Distributed Computing Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper proposes a surprisingly simple characterization of a large class of\nmodels of distributed computing, via an agreement function: for each set of\nprocesses, the function determines the best level of set consensus these\nprocesses can reach. We show that the task computability of a large class of\nfair adversaries that includes, in particular superset-closed and symmetric\none, is precisely captured by agreement functions.\n", "versions": [{"version": "v1", "created": "Wed, 1 Feb 2017 17:16:47 GMT"}, {"version": "v2", "created": "Tue, 14 Feb 2017 16:14:13 GMT"}, {"version": "v3", "created": "Fri, 10 Mar 2017 16:40:06 GMT"}], "update_date": "2017-03-13", "authors_parsed": [["Kuznetsov", "Petr", ""], ["Rieutord", "Thibault", ""]]}, {"id": "1702.00505", "submitter": "Luigi Nardi", "authors": "Luigi Nardi, Bruno Bodin, Sajad Saeedi, Emanuele Vespa, Andrew J.\n  Davison, Paul H. J. Kelly", "title": "Algorithmic Performance-Accuracy Trade-off in 3D Vision Applications\n  Using HyperMapper", "comments": "10 pages, Keywords: design space exploration, machine learning,\n  computer vision, SLAM, embedded systems, GPU, crowd-sourcing", "journal-ref": "31st IEEE International Parallel and Distributed Processing\n  Symposium May 29 - June 2, 2017 Orlando, Florida USA", "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we investigate an emerging application, 3D scene understanding,\nlikely to be significant in the mobile space in the near future. The goal of\nthis exploration is to reduce execution time while meeting our quality of\nresult objectives. In previous work we showed for the first time that it is\npossible to map this application to power constrained embedded systems,\nhighlighting that decision choices made at the algorithmic design-level have\nthe most impact.\n  As the algorithmic design space is too large to be exhaustively evaluated, we\nuse a previously introduced multi-objective Random Forest Active Learning\nprediction framework dubbed HyperMapper, to find good algorithmic designs. We\nshow that HyperMapper generalizes on a recent cutting edge 3D scene\nunderstanding algorithm and on a modern GPU-based computer architecture.\nHyperMapper is able to beat an expert human hand-tuning the algorithmic\nparameters of the class of Computer Vision applications taken under\nconsideration in this paper automatically. In addition, we use crowd-sourcing\nusing a 3D scene understanding Android app to show that the Pareto front\nobtained on an embedded system can be used to accelerate the same application\non all the 83 smart-phones and tablets crowd-sourced with speedups ranging from\n2 to over 12.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 00:01:46 GMT"}, {"version": "v2", "created": "Tue, 21 Mar 2017 21:58:41 GMT"}], "update_date": "2017-03-23", "authors_parsed": [["Nardi", "Luigi", ""], ["Bodin", "Bruno", ""], ["Saeedi", "Sajad", ""], ["Vespa", "Emanuele", ""], ["Davison", "Andrew J.", ""], ["Kelly", "Paul H. J.", ""]]}, {"id": "1702.00787", "submitter": "Shrisha Rao", "authors": "Ananth Murthy, Chandan Yeshwanth and Shrisha Rao", "title": "Distributed Approximation Algorithms for the Multiple Knapsack Problem", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the distributed version of the Multiple Knapsack Problem (MKP),\nwhere $m$ items are to be distributed amongst $n$ processors, each with a\nknapsack. We propose different distributed approximation algorithms with a\ntradeoff between time and message complexities. The algorithms are based on the\ngreedy approach of assigning the best item to the knapsack with the largest\ncapacity. These algorithms obtain a solution with a bound of $\\frac{1}{n+1}$\ntimes the optimum solution, with either $\\mathcal{O}\\left(m\\log n\\right)$ time\nand $\\mathcal{O}\\left(m n\\right)$ messages, or $\\mathcal{O}\\left(m\\right)$ time\nand $\\mathcal{O}\\left(mn^{2}\\right)$ messages.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 09:55:43 GMT"}], "update_date": "2017-02-06", "authors_parsed": [["Murthy", "Ananth", ""], ["Yeshwanth", "Chandan", ""], ["Rao", "Shrisha", ""]]}, {"id": "1702.00841", "submitter": "Guoqiang Zhang", "authors": "G. Zhang and R. Heusdens", "title": "Distributed Optimization Using the Primal-Dual Method of Multipliers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose the primal-dual method of multipliers (PDMM) for\ndistributed optimization over a graph. In particular, we optimize a sum of\nconvex functions defined over a graph, where every edge in the graph carries a\nlinear equality constraint. In designing the new algorithm, an augmented\nprimal-dual Lagrangian function is constructed which smoothly captures the\ngraph topology. It is shown that a saddle point of the constructed function\nprovides an optimal solution of the original problem. Further under both the\nsynchronous and asynchronous updating schemes, PDMM has the convergence rate of\nO(1/K) (where K denotes the iteration index) for general closed, proper and\nconvex functions. Other properties of PDMM such as convergence speeds versus\ndifferent parameter- settings and resilience to transmission failure are also\ninvestigated through the experiments of distributed averaging.\n", "versions": [{"version": "v1", "created": "Thu, 2 Feb 2017 22:05:53 GMT"}], "update_date": "2017-02-06", "authors_parsed": [["Zhang", "G.", ""], ["Heusdens", "R.", ""]]}, {"id": "1702.01396", "submitter": "Buyang Cao", "authors": "Yinhao Lu, Buyang Cao, Cesar Rego, Fred Glover", "title": "A Tabu Search based clustering algorithm and its parallel implementation\n  on Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-known K-means clustering algorithm has been employed widely in\ndifferent application domains ranging from data analytics to logistics\napplications. However, the K-means algorithm can be affected by factors such as\nthe initial choice of centroids and can readily become trapped in a local\noptimum. In this paper, we propose an improved K-means clustering algorithm\nthat is augmented by a Tabu Search strategy, and which is better adapted to\nmeet the needs of big data applications. Our design is further enhanced to take\nadvantage of parallel processing based on the Spark framework. Computational\nexperiments demonstrate the superiority of our Tabu Search based clustering\nalgorithm over a widely used version of the K-means approach embodied in Spark\nMLlib, comparing the algorithms in terms of scalability, accuracy, and\neffectiveness.\n", "versions": [{"version": "v1", "created": "Sun, 5 Feb 2017 13:03:12 GMT"}, {"version": "v2", "created": "Sun, 1 Oct 2017 14:40:55 GMT"}, {"version": "v3", "created": "Thu, 30 Nov 2017 23:47:36 GMT"}], "update_date": "2017-12-04", "authors_parsed": [["Lu", "Yinhao", ""], ["Cao", "Buyang", ""], ["Rego", "Cesar", ""], ["Glover", "Fred", ""]]}, {"id": "1702.01443", "submitter": "Ashraf Shahin", "authors": "Ashraf A. Shahin", "title": "Enhancing Elasticity of SaaS Applications using Queuing Theory", "comments": "http://thesai.org/Downloads/Volume8No1/Paper_36-Enhancing_Elasticity_of_SaaS_Applications_using_Queuing_Theory.pdf", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications(IJACSA), 8(1), 2017", "doi": "10.14569/IJACSA.2017.080136", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  Elasticity is one of key features of cloud computing. Elasticity allows\nSoftware as a Service (SaaS) applications' provider to reduce cost of running\napplications. In large SaaS applications that are developed using\nservice-oriented architecture model, each service is deployed in a separated\nvirtual machine and may use one or more services to complete its task.\nAlthough, scaling service independently from its required services propagates\nscaling problem to other services, most of current elasticity approaches do not\nconsider functional dependencies between services, which increases the\nprobability of violating service level agreement. In this paper, architecture\nof SaaS application is modeled as multi-class M/M/m processor sharing queuing\nmodel with deadline to take into account functional dependencies between\nservices during estimating required scaling resources. Experimental results\nshow effectiveness of the proposed model in estimating required resources\nduring scaling virtual resources.\n", "versions": [{"version": "v1", "created": "Sun, 5 Feb 2017 19:18:58 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Shahin", "Ashraf A.", ""]]}, {"id": "1702.01508", "submitter": "Yong Wang", "authors": "Yong Wang, Ya Wei Zhao", "title": "Transplantation of Data Mining Algorithms to Cloud Computing Platform\n  when Dealing Big Data", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper made a short review of Cloud Computing and Big Data, and discussed\nthe portability of general data mining algorithms to Cloud Computing platform.\nIt revealed the Cloud Computing platform based on Map-Reduce cannot solve all\nthe Big Data and data mining problems. Transplanting the general data mining\nalgorithms to the real-time Cloud Computing platform will be one of the\nresearch focuses in Cloud Computing and Big Data.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 06:37:39 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Wang", "Yong", ""], ["Zhao", "Ya Wei", ""]]}, {"id": "1702.01692", "submitter": "Christian Schulz", "authors": "Peter Sanders, Christian Schulz, Darren Strash and Robert Williger", "title": "Distributed Evolutionary k-way Node Separators", "comments": "arXiv admin note: text overlap with arXiv:1509.01190, arXiv:1110.0477", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computing high quality node separators in large graphs is necessary for a\nvariety of applications, ranging from divide-and-conquer algorithms to VLSI\ndesign. In this work, we present a novel distributed evolutionary algorithm\ntackling the k-way node separator problem. A key component of our contribution\nincludes new k-way local search algorithms based on maximum flows. We combine\nour local search with a multilevel approach to compute an initial population\nfor our evolutionary algorithm, and further show how to modify the coarsening\nstage of our multilevel algorithm to create effective combine and mutation\noperations. Lastly, we combine these techniques with a scalable communication\nprotocol, producing a system that is able to compute high quality solutions in\na short amount of time. Our experiments against competing algorithms show that\nour advanced evolutionary algorithm computes the best result on 94% of the\nchosen benchmark instances.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 16:34:27 GMT"}], "update_date": "2017-02-07", "authors_parsed": [["Sanders", "Peter", ""], ["Schulz", "Christian", ""], ["Strash", "Darren", ""], ["Williger", "Robert", ""]]}, {"id": "1702.01785", "submitter": "Anshu Shukla", "authors": "Anshu Shukla and Yogesh Simmhan", "title": "Model-driven Scheduling for Distributed Stream Processing Systems", "comments": "54 pages", "journal-ref": "Elsevier Journal of Parallel and Distributed Computing Volume 117,\n  July 2018, Pages 98-114", "doi": "10.1016/j.jpdc.2018.02.003", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Stream Processing frameworks are being commonly used with the\nevolution of Internet of Things(IoT). These frameworks are designed to adapt to\nthe dynamic input message rate by scaling in/out.Apache Storm, originally\ndeveloped by Twitter is a widely used stream processing engine while others\nincludes Flink, Spark streaming. For running the streaming applications\nsuccessfully there is need to know the optimal resource requirement, as\nover-estimation of resources adds extra cost.So we need some strategy to come\nup with the optimal resource requirement for a given streaming application. In\nthis article, we propose a model-driven approach for scheduling streaming\napplications that effectively utilizes a priori knowledge of the applications\nto provide predictable scheduling behavior. Specifically, we use application\nperformance models to offer reliable estimates of the resource allocation\nrequired. Further, this intuition also drives resource mapping, and helps\nnarrow the estimated and actual dataflow performance and resource utilization.\nTogether, this model-driven scheduling approach gives a predictable application\nperformance and resource utilization behavior for executing a given DSPS\napplication at a target input stream rate on distributed resources.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 20:19:35 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Shukla", "Anshu", ""], ["Simmhan", "Yogesh", ""]]}, {"id": "1702.01786", "submitter": "Manuel Bravo", "authors": "Chathuri Gunawardhana, Manuel Bravo, Lu\\'is Rodrigues", "title": "Unobtrusive Deferred Update Stabilization for Efficient Geo-Replication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we propose a novel approach to manage the throughput vs latency\ntradeoff that emerges when managing updates in geo-replicated systems. Our\napproach consists in allowing full concurrency when processing local updates\nand using a deferred local serialisation procedure before shipping updates to\nremote datacenters. This strategy allows to implement inexpensive mechanisms to\nensure system consistency requirements while avoiding intrusive effects on\nupdate operations, a major performance limitation of previous systems. We have\nimplemented our approach as a variant of Riak KV. Our extensive evaluation\nshows that we outperform sequencer-based approaches by almost an order of\nmagnitude in the maximum achievable throughput. Furthermore, unlike previous\nsequencer-free solutions, our approach reaches nearly optimal remote update\nvisibility latencies without limiting throughput.\n", "versions": [{"version": "v1", "created": "Mon, 6 Feb 2017 20:21:32 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Gunawardhana", "Chathuri", ""], ["Bravo", "Manuel", ""], ["Rodrigues", "Lu\u00eds", ""]]}, {"id": "1702.01846", "submitter": "Masatoshi Hidaka", "authors": "Masatoshi Hidaka, Ken Miura and Tatsuya Harada", "title": "Development of JavaScript-based deep learning platform and application\n  to distributed training", "comments": "Workshop paper for ICLR2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is increasingly attracting attention for processing big data.\nExisting frameworks for deep learning must be set up to specialized computer\nsystems. Gaining sufficient computing resources therefore entails high costs of\ndeployment and maintenance. In this work, we implement a matrix library and\ndeep learning framework that uses JavaScript. It can run on web browsers\noperating on ordinary personal computers and smartphones. Using JavaScript,\ndeep learning can be accomplished in widely diverse environments without the\nnecessity for software installation. Using GPGPU from WebCL framework, our\nframework can train large scale convolutional neural networks such as VGGNet\nand ResNet. In the experiments, we demonstrate their practicality by training\nVGGNet in a distributed manner using web browsers as the client.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 02:02:08 GMT"}, {"version": "v2", "created": "Thu, 16 Feb 2017 03:30:49 GMT"}, {"version": "v3", "created": "Mon, 27 Mar 2017 09:28:06 GMT"}], "update_date": "2017-03-28", "authors_parsed": [["Hidaka", "Masatoshi", ""], ["Miura", "Ken", ""], ["Harada", "Tatsuya", ""]]}, {"id": "1702.01973", "submitter": "William Moses Jr.", "authors": "William K. Moses Jr. and Shailesh Vaya", "title": "Achieving Dilution without Knowledge of Coordinates in the SINR Model", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Considerable literature has been developed for various fundamental\ndistributed problems in the SINR (Signal-to-Interference-plus-Noise-Ratio)\nmodel for radio transmission. A setting typically studied is when all nodes\ntransmit a signal of the same strength, and each device only has access to\nknowledge about the total number of nodes in the network $n$, the range from\nwhich each node's label is taken $[1,\\dots,N]$, and the label of the device\nitself. In addition, an assumption is made that each node also knows its\ncoordinates in the Euclidean plane. In this paper, we create a technique which\nallows algorithm designers to remove that last assumption. The assumption about\nthe unavailability of the knowledge of the physical coordinates of the nodes\ntruly captures the `ad-hoc' nature of wireless networks.\n  Previous work in this area uses a flavor of a technique called dilution, in\nwhich nodes transmit in a (predetermined) round-robin fashion, and are able to\nreach all their neighbors. However, without knowing the physical coordinates,\nit's not possible to know the coordinates of their containing (pivotal) grid\nbox and seemingly not possible to use dilution (to coordinate their\ntransmissions). We propose a new technique to achieve dilution without using\nthe knowledge of physical coordinates. This technique exploits the\nunderstanding that the transmitting nodes lie in 2-D space, segmented by an\nappropriate pivotal grid, without explicitly referring to the actual physical\ncoordinates of these nodes. Using this technique, it is possible for every weak\ndevice to successfully transmit its message to all of its neighbors in\n$\\Theta(\\lg N)$ rounds, as long as the density of transmitting nodes in any\nphysical grid box is bounded by a known constant. This technique, we feel, is\nan important generic tool for devising practical protocols when physical\ncoordinates of the nodes are not known.\n", "versions": [{"version": "v1", "created": "Tue, 7 Feb 2017 11:58:21 GMT"}], "update_date": "2017-02-08", "authors_parsed": [["Moses", "William K.", "Jr."], ["Vaya", "Shailesh", ""]]}, {"id": "1702.02204", "submitter": "Boleslaw Szymanski", "authors": "Travis Desell, Malik Magdon-Ismail, Heidi Newberg, Lee A. Newberg,\n  Boleslaw K. Szymanski, Carlos A. Varela", "title": "A Robust Asynchronous Newton Method for Massive Scale Computing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volunteer computing grids offer super-computing levels of computing power at\nthe relatively low cost of operating a server. In previous work, the authors\nhave shown that it is possible to take traditionally iterative evolutionary\nalgorithms and execute them on volunteer computing grids by performing them\nasynchronously. The asynchronous implementations dramatically increase\nscalability and decrease the time taken to converge to a solution. Iterative\nand asynchronous optimization algorithms implemented using MPI on clusters and\nsupercomputers, and BOINC on volunteer computing grids have been packaged\ntogether in a framework for generic distributed optimization (FGDO). This paper\npresents a new extension to FGDO for an asynchronous Newton method (ANM) for\nlocal optimization. ANM is resilient to heterogeneous, faulty and unreliable\ncomputing nodes and is extremely scalable. Preliminary results show that it can\nconverge to a local optimum significantly faster than conjugate gradient\ndescent does.\n", "versions": [{"version": "v1", "created": "Fri, 30 Dec 2016 19:37:29 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Desell", "Travis", ""], ["Magdon-Ismail", "Malik", ""], ["Newberg", "Heidi", ""], ["Newberg", "Lee A.", ""], ["Szymanski", "Boleslaw K.", ""], ["Varela", "Carlos A.", ""]]}, {"id": "1702.02207", "submitter": "Anas Al-Oraiqat Dr.", "authors": "Anas M. Al-Oraiqat", "title": "Parallel implementation of the coupled harmonic oscillator", "comments": "7 pages, 5 Figures, International Journal of Engineering Science and\n  Technology 2009", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents the parallel implementation of the coupled harmonic\noscillator. From the analytical solution of the coupled harmonic oscillator,\nthe design parameters are obtained. After that, a numerical integration of the\nsystem with MATLAB, which is used as a tool of benchmark evaluation, is\nperformed. Next, parallel implementation is performed using a well-known\napproach like OpenMP and WinAPI. Taking into account the errors of basic\nparameters of the simulated process, the generated oscillations of the proposed\nparallel realization are almost identical to the actual solution of the\nharmonic oscillator model. Test ways to optimize the parallel architecture of\ncomputing processes for software implementations of the considered application\nis carried out. The developed model is used to study a fixed priority\nscheduling algorithm for real-time parallel threads execution. The proposed\nparallel implementation of the considered dynamic system has an independent\nvalue and can be considered as a test for determining the characteristics of\nmulti-core systems for time-critical simulation problems. Keywords: Harmonic\noscillator, model, SMP, parallel programming, OpenMP;\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 13:42:30 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Al-Oraiqat", "Anas M.", ""]]}, {"id": "1702.02256", "submitter": "Zhihui Du", "authors": "Xiangyu Guo, Qi Chu, Shin Kee Chung, Zhihui Du, Linqing Wen", "title": "Acceleration of low-latency gravitational wave searches using\n  Maxwell-microarchitecture GPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Low-latency detections of gravitational waves (GWs) are crucial to enable\nprompt follow-up observations to astrophysical transients by conventional\ntelescopes. We have developed a low-latency pipeline using a technique called\nSummed Parallel Infinite Impulse Response (SPIIR) filtering, realized by a\nGraphic Processing Unit (GPU). In this paper, we exploit the new\n\\textit{Maxwell} memory access architecture in NVIDIA GPUs, namely the\nread-only data cache, warp-shuffle, and cross-warp atomic techniques. We report\na 3-fold speed-up over our previous implementation of this filtering technique.\nTo tackle SPIIR with relatively few filters, we develop a new GPU thread\nconfiguration with a nearly 10-fold speedup. In addition, we implement a\nmulti-rate scheme of SPIIR filtering using Maxwell GPUs. We achieve more than\n100-fold speed-up over a single core CPU for the multi-rate filtering scheme.\nThis results in an overall of 21-fold CPU usage reduction for the entire SPIIR\npipeline.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 02:43:03 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Guo", "Xiangyu", ""], ["Chu", "Qi", ""], ["Chung", "Shin Kee", ""], ["Du", "Zhihui", ""], ["Wen", "Linqing", ""]]}, {"id": "1702.02422", "submitter": "Anas Al-Oraiqat Dr.", "authors": "Anas M. Al-Oraiqat", "title": "Parallel implementation of a vehicle rail dynamical model for multi-core\n  systems", "comments": "8 pages, 9 Figures", "journal-ref": "International Journal of advanced studies in Computer Science and\n  Engineering (IJASCSE) 2012", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This research presents a model of a complex dynamic object running on a\nmulti-core system. Discretization and numerical integration for multibody\nmodels of vehicle rail elements in the vertical longitudinal plane fluctuations\nis considered. The implemented model and solution of the motion differential\nequations allow estimating the basic processes occurring in the system with\nvarious external influences. Hence the developed programming model can be used\nfor performing analysis and comparing new vehicle designs.\n  Keywords-dynamic model; multi-core system; SMP system; rolling stock.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 13:45:50 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Al-Oraiqat", "Anas M.", ""]]}, {"id": "1702.02439", "submitter": "Ond\\v{r}ej Leng\\'al", "authors": "Yu-Fang Chen, Chih-Duo Hong, Ond\\v{r}ej Leng\\'al, Shin-Cheng Mu,\n  Nishant Sinha, Bow-Yaw Wang", "title": "An Executable Sequential Specification for Spark Aggregation", "comments": "an extended version of a paper accepted at NETYS'17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spark is a new promising platform for scalable data-parallel computation. It\nprovides several high-level application programming interfaces (APIs) to\nperform parallel data aggregation. Since execution of parallel aggregation in\nSpark is inherently non-deterministic, a natural requirement for Spark programs\nis to give the same result for any execution on the same data set. We present\nPureSpark, an executable formal Haskell specification for Spark aggregate\ncombinators. Our specification allows us to deduce the precise condition for\ndeterministic outcomes from Spark aggregation. We report case studies analyzing\ndeterministic outcomes and correctness of Spark programs.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 14:33:07 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Chen", "Yu-Fang", ""], ["Hong", "Chih-Duo", ""], ["Leng\u00e1l", "Ond\u0159ej", ""], ["Mu", "Shin-Cheng", ""], ["Sinha", "Nishant", ""], ["Wang", "Bow-Yaw", ""]]}, {"id": "1702.02455", "submitter": "William Moses Jr.", "authors": "William K. Moses Jr. and Shailesh Vaya", "title": "Deterministic Protocols in the SINR Model without Knowledge of\n  Coordinates", "comments": "This is the author version of the paper which will appear in the\n  Journal of Computer and System Sciences. 36 pages, 1 table, 4 figures; v3\n  improves the presentation, style, and some technical matter of the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Much work has been developed for studying the classical broadcasting problem\nin the SINR (Signal-to-Interference-plus-Noise-Ratio) model for wireless device\ntransmission. The setting typically studied is when all radio nodes transmit a\nsignal of the same strength. This work studies the challenging problem of\ndevising a distributed algorithm for multi-broadcasting, assuming a subset of\nnodes are initially awake, for the SINR model when each device only has access\nto knowledge about the total number of nodes in the network $n$, the range from\nwhich each node's label is taken $\\lbrace 1,\\dots,N \\rbrace$, and the label of\nthe device itself. Specifically, we assume no knowledge of the physical\ncoordinates of devices and also no knowledge of the neighborhood of each node.\n  We present a deterministic protocol for this problem in $O(n \\lg N \\lg n)$\nrounds. There is no known polynomial time deterministic algorithm in literature\nfor this setting, and it remains the principle open problem in this domain. A\nlower bound of $\\Omega(n \\lg N)$ rounds is known for deterministic broadcasting\nwithout local knowledge.\n  In addition to the above result, we present algorithms to achieve\nmulti-broadcast in $O(n \\lg N)$ rounds and create a backbone in $O(n \\lg N)$\nrounds, assuming that all nodes are initially awake. For a given backbone,\nmessages can be exchanged between every pair of connected nodes in the backbone\nin $O(\\lg N)$ rounds and between any node and its designated contact node in\nthe backbone in $O(\\Delta \\lg N)$ rounds.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 14:56:25 GMT"}, {"version": "v2", "created": "Sat, 6 May 2017 20:20:24 GMT"}, {"version": "v3", "created": "Sat, 15 Aug 2020 11:14:16 GMT"}], "update_date": "2020-08-18", "authors_parsed": [["Moses", "William K.", "Jr."], ["Vaya", "Shailesh", ""]]}, {"id": "1702.02460", "submitter": "William Moses Jr.", "authors": "Dariusz R. Kowalski, William K. Moses Jr., Shailesh Vaya", "title": "Deterministic Backbone Creation in an SINR Network without Knowledge of\n  Location", "comments": "12 pages, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For a given network, a backbone is an overlay network consisting of a\nconnected dominating set with additional accessibility properties. Once a\nbackbone is created for a network, it can be utilized for fast communication\namongst the nodes of the network.\n  The Signal-to-Interference-plus-Noise-Ratio (SINR) model has become the\nstandard for modeling communication among devices in wireless networks. For\nthis model, the community has pondered what the most realistic solutions for\ncommunication problems in wireless networks would look like. Such solutions\nwould have the characteristic that they would make the least number of\nassumptions about the availability of information about the participating\nnodes. Solving problems when nothing at all is known about the network and\nhaving nodes just start participating would be ideal. However, this is quite\nchallenging and most likely not feasible. The pragmatic approach is then to\nmake meaningful assumptions about the available information and present\nefficient solutions based on this information.\n  We present a solution for creation of backbone in the SINR model, when nodes\ndo not have access to their physical coordinates or the coordinates of other\nnodes in the network. This restriction models the deployment of nodes in\nvarious situations for sensing hurricanes, cyclones, and so on, where only\ninformation about nodes prior to their deployment may be known but not their\nactual locations post deployment. We assume that nodes have access to knowledge\nof their label, the labels of nodes within their neighborhood, the range from\nwhich labels are taken $[N]$ and the total number of participating nodes $n$.\nWe also assume that nodes wake up spontaneously. We present an efficient\ndeterministic protocol to create a backbone with a round complexity of\n$O(\\Delta \\lg^2 N)$.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 15:14:05 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Kowalski", "Dariusz R.", ""], ["Moses", "William K.", "Jr."], ["Vaya", "Shailesh", ""]]}, {"id": "1702.02482", "submitter": "Petros Giannakopoulos", "authors": "Petros Giannakopoulos, Michail Gkoumas, Ioannis Diplas, Georgios\n  Voularinos, Theofanis Vlachos, Konstantia Balasi, Ekaterini Tzamariudaki,\n  Christos Filippidis, Yiannis Cotronis, Christos Markou", "title": "A study on implementing a multithreaded version of the SIRENE detector\n  simulation software for high energy neutrinos", "comments": null, "journal-ref": null, "doi": "10.1051/epjconf/201611607005", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The primary objective of SIRENE is to simulate the response to neutrino\nevents of any type of high energy neutrino telescope. Additionally, it\nimplements different geometries for a neutrino detector and different\nconfigurations and characteristics of photo-multiplier tubes (PMTs) inside the\noptical modules of the detector through a library of C+ + classes. This could\nbe considered a massive statistical analysis of photo-electrons. Aim of this\nwork is the development of a multithreaded version of the SIRENE detector\nsimulation software for high energy neutrinos. This approach allows utilization\nof multiple CPU cores leading to a potentially significant decrease in the\nrequired execution time compared to the sequential code. We are making use of\nthe OpenMP framework for the production of multithreaded code running on the\nCPU. Finally, we analyze the feasibility of a GPU-accelerated implementation.\n", "versions": [{"version": "v1", "created": "Wed, 8 Feb 2017 15:49:15 GMT"}], "update_date": "2017-02-09", "authors_parsed": [["Giannakopoulos", "Petros", ""], ["Gkoumas", "Michail", ""], ["Diplas", "Ioannis", ""], ["Voularinos", "Georgios", ""], ["Vlachos", "Theofanis", ""], ["Balasi", "Konstantia", ""], ["Tzamariudaki", "Ekaterini", ""], ["Filippidis", "Christos", ""], ["Cotronis", "Yiannis", ""], ["Markou", "Christos", ""]]}, {"id": "1702.02799", "submitter": "Sheng Wang", "authors": "Anh Dinh, Ji Wang, Sheng Wang, Gang Chen, Wei-Ngan Chin, Qian Lin,\n  Beng Chin Ooi, Pingcheng Ruan, Kian-Lee Tan, Zhongle Xie, Hao Zhang, and\n  Meihui Zhang", "title": "UStore: A Distributed Storage With Rich Semantics", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's storage systems expose abstractions which are either too low-level\n(e.g., key-value store, raw-block store) that they require developers to\nre-invent the wheels, or too high-level (e.g., relational databases, Git) that\nthey lack generality to support many classes of applications. In this work, we\npropose and implement a general distributed data storage system, called UStore,\nwhich has rich semantics. UStore delivers three key properties, namely\nimmutability, sharing and security, which unify and add values to many classes\nof today's applications, and which also open the door for new applications. By\nkeeping the core properties within the storage, UStore helps reduce application\ndevelopment efforts while offering high performance at hand. The storage\nembraces current hardware trends as key enablers. It is built around a\ndata-structure similar to that of Git, a popular source code versioning system,\nbut it also synthesizes many designs from distributed systems and databases.\nOur current implementation of UStore has better performance than general\nin-memory key-value storage systems, especially for version scan operations. We\nport and evaluate four applications on top of UStore: a Git-like application, a\ncollaborative data science application, a transaction management application,\nand a blockchain application. We demonstrate that UStore enables faster\ndevelopment and the UStore-backed applications can have better performance than\nthe existing implementations.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 12:06:37 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Dinh", "Anh", ""], ["Wang", "Ji", ""], ["Wang", "Sheng", ""], ["Chen", "Gang", ""], ["Chin", "Wei-Ngan", ""], ["Lin", "Qian", ""], ["Ooi", "Beng Chin", ""], ["Ruan", "Pingcheng", ""], ["Tan", "Kian-Lee", ""], ["Xie", "Zhongle", ""], ["Zhang", "Hao", ""], ["Zhang", "Meihui", ""]]}, {"id": "1702.02848", "submitter": "Patrice Ossona de Mendez", "authors": "Saeed Akhoondian Amiri, Patrice Ossona de Mendez, Roman Rabinovich,\n  Sebastian Siebertz", "title": "Distributed Domination on Graph Classes of Bounded Expansion", "comments": "presented at the 30th ACM Symposium on Parallelism in Algorithms and\n  Architectures (SPAA 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We provide a new constant factor approximation algorithm for the (connected)\ndistance-$r$ dominating set problem on graph classes of bounded expansion.\nClasses of bounded expansion include many familiar classes of sparse graphs\nsuch as planar graphs and graphs with excluded (topological) minors, and\nnotably, these classes form the most general subgraph closed classes of graphs\nfor which a sequential constant factor approximation algorithm for the\ndistance-$r$ dominating set problem is currently known. Our algorithm can be\nimplemented in the \\congestbc model of distributed computing and uses\n$\\mathcal{O}(r^2 \\log n)$ communication rounds.\n  Our techniques, which may be of independent interest, are based on a\ndistributed computation of sparse neighborhood covers of small radius on\nbounded expansion classes. We show how to compute an $r$-neighborhood cover of\nradius~$2r$ and overlap $f(r)$ on every class of bounded expansion in\n$\\mathcal{O}(r^2 \\log n)$ communication rounds for some function~$f$.% in the\n$\\mathcal{CONGEST}_{\\mathrm{BC}}$ model.\n  Finally, we show how to use the greater power of the $\\mathcal{LOCAL}$ model\nto turn any distance-$r$ dominating set into a constantly larger connected\ndistance-$r$ dominating set in $3r+1$ rounds on any class of bounded expansion.\nCombining this algorithm, e.g., with the constant factor approximation\nalgorithm for dominating sets on planar graphs of Lenzen et al.\\ gives a\nconstant factor approximation algorithm for connected dominating sets on planar\ngraphs in a constant number of rounds in the $\\mathcal{LOCAL}$ model, where the\napproximation ratio is only $6$ times larger than that of Lenzen et al.'s\nalgorithm.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 14:32:14 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 20:54:35 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Amiri", "Saeed Akhoondian", ""], ["de Mendez", "Patrice Ossona", ""], ["Rabinovich", "Roman", ""], ["Siebertz", "Sebastian", ""]]}, {"id": "1702.02903", "submitter": "Parul Pandey", "authors": "Parul Pandey, Hariharasudhan Viswanathan, and Dario Pompili", "title": "Robust Orchestration of Concurrent Application Workflows in Mobile\n  Device Clouds", "comments": "25 pages, 6 figures, 2 tables, 2 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hybrid mobile/fixed device cloud that harnesses sensing, computing,\ncommunication, and storage capabilities of mobile and fixed devices in the\nfield as well as those of computing and storage servers in remote datacenters\nis envisioned. Mobile device clouds can be harnessed to enable innovative\npervasive applications that rely on real-time, in-situ processing of sensor\ndata collected in the field. To support concurrent mobile applications on the\ndevice cloud, a robust and secure distributed computing framework, called\nMaestro, is proposed. The key components of Maestro are (i) a task scheduling\nmechanism that employs controlled task replication in addition to task\nreallocation for robustness and (ii) Dedup for task deduplication among\nconcurrent pervasive workflows. An architecture-based solution that relies on\ntask categorization and authorized access to the categories of tasks is\nproposed for different levels of protection. Experimental evaluation through\nprototype testbed of Android- and Linux-based mobile devices as well as\nsimulations is performed to demonstrate Maestro's capabilities.\n", "versions": [{"version": "v1", "created": "Thu, 5 Jan 2017 21:18:55 GMT"}], "update_date": "2017-02-10", "authors_parsed": [["Pandey", "Parul", ""], ["Viswanathan", "Hariharasudhan", ""], ["Pompili", "Dario", ""]]}, {"id": "1702.02968", "submitter": "Timur Bazhirov", "authors": "Mohammad Mohammadi, Timur Bazhirov", "title": "Comparative benchmarking of cloud computing vendors with High\n  Performance Linpack", "comments": null, "journal-ref": null, "doi": "10.1145/3195612.3195613", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a comparative analysis of the maximum performance achieved by the\nLinpack benchmark on compute intensive hardware publicly available from\nmultiple cloud providers. We study both performance within a single compute\nnode, and speedup for distributed memory calculations with up to 32 nodes or at\nleast 512 computing cores. We distinguish between hyper-threaded and\nnon-hyper-threaded scenarios and estimate the performance per single computing\ncore. We also compare results with a traditional supercomputing system for\nreference. Our findings provide a way to rank the cloud providers and\ndemonstrate the viability of the cloud for high performance computing\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 20:11:26 GMT"}], "update_date": "2018-07-17", "authors_parsed": [["Mohammadi", "Mohammad", ""], ["Bazhirov", "Timur", ""]]}, {"id": "1702.02978", "submitter": "Ioannis Konstantinou", "authors": "Konstantinos Lolos, Ioannis Konstantinou, Verena Kantere and Nectarios\n  Koziris", "title": "Elastic Resource Management with Adaptive State Space Partitioning of\n  Markov Decision Processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern large-scale computing deployments consist of complex applications\nrunning over machine clusters. An important issue in these is the offering of\nelasticity, i.e., the dynamic allocation of resources to applications to meet\nfluctuating workload demands. Threshold based approaches are typically\nemployed, yet they are difficult to configure and optimize. Approaches based on\nreinforcement learning have been proposed, but they require a large number of\nstates in order to model complex application behavior. Methods that adaptively\npartition the state space have been proposed, but their partitioning criteria\nand strategies are sub-optimal. In this work we present MDP_DT, a novel\nfull-model based reinforcement learning algorithm for elastic resource\nmanagement that employs adaptive state space partitioning. We propose two novel\nstatistical criteria and three strategies and we experimentally prove that they\ncorrectly decide both where and when to partition, outperforming existing\napproaches. We experimentally evaluate MDP_DT in a real large scale cluster\nover variable not-encountered workloads and we show that it takes more informed\ndecisions compared to static and model-free approaches, while requiring a\nminimal amount of training data.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 20:53:57 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Lolos", "Konstantinos", ""], ["Konstantinou", "Ioannis", ""], ["Kantere", "Verena", ""], ["Koziris", "Nectarios", ""]]}, {"id": "1702.03008", "submitter": "K. Alex Mills", "authors": "K. Alex Mills and James Smith", "title": "Finer-grained Locking in Concurrent Dynamic Planar Convex Hulls", "comments": "4 pages; 2 figures; brief announcement submitted to SPAA 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The convex hull of a planar point set is the smallest convex polygon\ncontaining each point in the set. The dynamic convex hull problem concerns\nefficiently maintaining the convex hull of a set of points subject to additions\nand removals. One algorithm for this problem uses two external balanced binary\nsearch trees (BSTs) (M. H. Overmars, J. van Leeuwen 1981). We present the first\nconcurrent solution for this problem, which uses a single BST that stores\nreferences to intermediate convex hull solutions at each node. We implement and\nevaluate two lock-based approaches: a) fine-grained locking, where each node of\nthe tree is protected by a lock, and b) \"finer-grained locking\", where each\nnode contains a separate lock for each of the left and right chains. In our\nthroughput experiments, we observe that finer-grained locking yields an 8-60%\nimprovement over fine-grained locking, and a 38-61x improvement over\ncoarsegrained locking and software transactional memory (STM). When applied to\nfind the convex hull of static point sets, our approach outperforms a parallel\ndivide-and-conquer implementation by 2-4x using an equivalent number of\nthreads.\n", "versions": [{"version": "v1", "created": "Thu, 9 Feb 2017 22:51:07 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Mills", "K. Alex", ""], ["Smith", "James", ""]]}, {"id": "1702.03068", "submitter": "Tyler Crain", "authors": "Tyler Crain, Vincent Gramoli, Mikel Larrea, Michel Raynal", "title": "DBFT: Efficient Byzantine Consensus with a Weak Coordinator and its\n  Application to Consortium Blockchains", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a deterministic Byzantine consensus algorithm that\nrelies on a new weak coordinator. As opposed to previous algorithms that cannot\nterminate in the presence of a faulty or slow coordinator, our algorithm can\nterminate even when its coordinator is faulty, hence the name weak coordinator.\nThe key idea is to allow processes to complete asynchronous rounds as soon as\nthey receive a threshold of messages, instead of having to wait for a message\nfrom a coordinator that may be slow.\n  The resulting algorithm assumes partial synchrony, is resilience optimal,\ntime optimal and does not need signatures. Our presentation is didactic: we\nfirst present a simple safe binary Byzantine consensus algorithm, modify it to\nensure termination, and finally present an optimized reduction from multivalue\nconsensus to binary consensus that may terminate in 4 message delays. To\nevaluate our algorithm, we deployed it on 100 machines distributed in 5\ndatacenters across different continents and compared its performance against\nthe randomized solution from Mostefaoui, Moumem and Raynal [PODC14] that\nterminates in O(1) rounds in expectation. Our algorithm always outperforms the\nlatter even in the presence of Byzantine behaviors. Our algorithm has a\nsubsecond average latency in most of our geo-distributed experiments, even when\nattacked by a well-engineered coalition of Byzantine processes.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 05:21:43 GMT"}, {"version": "v2", "created": "Wed, 22 Feb 2017 07:28:01 GMT"}, {"version": "v3", "created": "Wed, 25 Jul 2018 07:49:14 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Crain", "Tyler", ""], ["Gramoli", "Vincent", ""], ["Larrea", "Mikel", ""], ["Raynal", "Michel", ""]]}, {"id": "1702.03192", "submitter": "Shaohuai Shi", "authors": "Shaohuai Shi, Pengfei Xu, Xiaowen Chu", "title": "Supervised Learning Based Algorithm Selection for Deep Neural Networks", "comments": "In review for a conference paper of ICPP2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many recent deep learning platforms rely on third-party libraries (such as\ncuBLAS) to utilize the computing power of modern hardware accelerators (such as\nGPUs). However, we observe that they may achieve suboptimal performance because\nthe library functions are not used appropriately. In this paper, we target at\noptimizing the operations of multiplying a matrix with the transpose of another\nmatrix (referred to as NT operation hereafter), which contribute about half of\nthe training time of fully connected deep neural networks. Rather than directly\ncalling the library function, we propose a supervised learning based algorithm\nselection approach named MTNN, which uses a gradient boosted decision tree to\nselect one from two alternative NT implementations intelligently: (1) calling\nthe cuBLAS library function; (2) calling our proposed algorithm TNN that uses\nan efficient out-of-place matrix transpose. We evaluate the performance of MTNN\non two modern GPUs: NVIDIA GTX 1080 and NVIDIA Titan X Pascal. MTNN can achieve\n96\\% of prediction accuracy with very low computational overhead, which results\nin an average of 54\\% performance improvement on a range of NT operations. To\nfurther evaluate the impact of MTNN on the training process of deep neural\nnetworks, we have integrated MTNN into a popular deep learning platform Caffe.\nOur experimental results show that the revised Caffe can outperform the\noriginal one by an average of 28\\%. Both MTNN and the revised Caffe are\nopen-source.\n", "versions": [{"version": "v1", "created": "Fri, 10 Feb 2017 14:51:42 GMT"}, {"version": "v2", "created": "Fri, 17 Mar 2017 02:06:06 GMT"}], "update_date": "2017-03-20", "authors_parsed": [["Shi", "Shaohuai", ""], ["Xu", "Pengfei", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1702.03253", "submitter": "Vijay Gadepally", "authors": "Lauren Milechin, Alexander Chen, Vijay Gadepally, Dylan Hutchison,\n  Siddharth Samsi, Jeremy Kepner", "title": "D4M 3.0", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The D4M tool is used by hundreds of researchers to perform complex analytics\non unstructured data. Over the past few years, the D4M toolbox has evolved to\nsupport connectivity with a variety of database engines, graph analytics in the\nApache Accumulo database, and an implementation using the Julia programming\nlanguage. In this article, we describe some of our latest additions to the D4M\ntoolbox and our upcoming D4M 3.0 release.\n", "versions": [{"version": "v1", "created": "Thu, 19 Jan 2017 00:37:12 GMT"}], "update_date": "2017-02-13", "authors_parsed": [["Milechin", "Lauren", ""], ["Chen", "Alexander", ""], ["Gadepally", "Vijay", ""], ["Hutchison", "Dylan", ""], ["Samsi", "Siddharth", ""], ["Kepner", "Jeremy", ""]]}, {"id": "1702.03289", "submitter": "Ali Vatankhah Barenji Dr", "authors": "Ali Vatankhah Barenji, Reza Vatankhah Barenji", "title": "Efficient Resource Allocation in Mass Customization based on Service\n  Oriented Architecture", "comments": "6", "journal-ref": null, "doi": null, "report-no": "978-1-5090-2702-6/16", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mass customization explains the phenomenon to provide a unique designed\nproducts and services to all customer by achieving a high process integration\nand flexibility. It has been used as a competitive approach by many companies.\nAdequate resource implementation in mass customization-particularly in terms of\nresource usage, it is therefore important to meet customer's requirement in\nterms effective responsiveness and meeting deadlines, at the same time offering\nhigh scalability. An architecture for solving the resource allocation issue in\nmass customized flexible manufacturing system was illustrated, by putting in\nplace a couple of advance reservation systems and scheduling algorithms for\neffective usage of the product.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 20:29:50 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Barenji", "Ali Vatankhah", ""], ["Barenji", "Reza Vatankhah", ""]]}, {"id": "1702.03380", "submitter": "Guoqiang Zhang", "authors": "Guoqiang Zhang and W. Bastiaan Kleijn", "title": "Training Deep Neural Networks via Optimization Over Graphs", "comments": "5 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we propose to train a deep neural network by distributed\noptimization over a graph. Two nonlinear functions are considered: the\nrectified linear unit (ReLU) and a linear unit with both lower and upper\ncutoffs (DCutLU). The problem reformulation over a graph is realized by\nexplicitly representing ReLU or DCutLU using a set of slack variables. We then\napply the alternating direction method of multipliers (ADMM) to update the\nweights of the network layerwise by solving subproblems of the reformulated\nproblem. Empirical results suggest that the ADMM-based method is less sensitive\nto overfitting than the stochastic gradient descent (SGD) and Adam methods.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 04:02:40 GMT"}, {"version": "v2", "created": "Sat, 17 Jun 2017 11:18:48 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Zhang", "Guoqiang", ""], ["Kleijn", "W. Bastiaan", ""]]}, {"id": "1702.03400", "submitter": "Daniel Jung", "authors": "Matthias Fischer, Daniel Jung, Friedhelm Meyer auf der Heide", "title": "Gathering Anonymous, Oblivious Robots on a Grid", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a swarm of $n$ autonomous mobile robots, distributed on a\n2-dimensional grid. A basic task for such a swarm is the gathering process: All\nrobots have to gather at one (not predefined) place. A common local model for\nextremely simple robots is the following: The robots do not have a common\ncompass, only have a constant viewing radius, are autonomous and\nindistinguishable, can move at most a constant distance in each step, cannot\ncommunicate, are oblivious and do not have flags or states. The only gathering\nalgorithm under this robot model, with known runtime bounds, needs\n$\\mathcal{O}(n^2)$ rounds and works in the Euclidean plane. The underlying time\nmodel for the algorithm is the fully synchronous $\\mathcal{FSYNC}$ model. On\nthe other side, in the case of the 2-dimensional grid, the only known gathering\nalgorithms for the same time and a similar local model additionally require a\nconstant memory, states and \"flags\" to communicate these states to neighbors in\nviewing range. They gather in time $\\mathcal{O}(n)$.\n  In this paper we contribute the (to the best of our knowledge) first\ngathering algorithm on the grid that works under the same simple local model as\nthe above mentioned Euclidean plane strategy, i.e., without memory (oblivious),\n\"flags\" and states. We prove its correctness and an $\\mathcal{O}(n^2)$ time\nbound in the fully synchronous $\\mathcal{FSYNC}$ time model. This time bound\nmatches the time bound of the best known algorithm for the Euclidean plane\nmentioned above. We say gathering is done if all robots are located within a\n$2\\times 2$ square, because in $\\mathcal{FSYNC}$ such configurations cannot be\nsolved.\n", "versions": [{"version": "v1", "created": "Sat, 11 Feb 2017 09:34:13 GMT"}, {"version": "v2", "created": "Wed, 22 Feb 2017 12:34:24 GMT"}, {"version": "v3", "created": "Thu, 3 Aug 2017 11:05:52 GMT"}], "update_date": "2017-08-04", "authors_parsed": [["Fischer", "Matthias", ""], ["Jung", "Daniel", ""], ["der Heide", "Friedhelm Meyer auf", ""]]}, {"id": "1702.03534", "submitter": "Barun Gorain", "authors": "Barun Gorain and Andrzej Pelc", "title": "Leader Election in Trees with Customized Advice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Leader election is a basic symmetry breaking problem in distributed\ncomputing. All nodes of a network have to agree on a single node, called the\nleader. If the nodes of the network have distinct labels, then agreeing on a\nsingle node means that all nodes have to output the label of the elected\nleader.\n  If the nodes are anonymous, the task of leader election is formulated as\nfollows: every node of the network must output a simple path starting at it,\nwhich is coded as a sequence of port numbers, such that all these paths end at\na common node, the leader. In this paper, we study deterministic leader\nelection in anonymous trees.\n  Our goal is to establish tradeoffs between the allocated time $\\tau$ and the\namount of information that has to be given {\\em a priori} to the nodes of a\nnetwork to enable leader election in time $\\tau$. Following the framework of\n{\\em algorithms with advice}, this information is provided to all nodes at the\nstart by an oracle knowing the entire tree, in form of binary strings assigned\nto all nodes. There are two possible variants of formulating this advice\nassignment. Either the strings provided to all nodes are identical, or strings\nassigned to different nodes may be potentially different, i.e., advice can be\n{\\em customized}. As opposed to previous papers on leader election with advice,\nin this paper we consider the latter option.\n  The maximum length of all assigned binary strings is called the {\\em size of\nadvice}.\n  For a given time $\\tau$ allocated to leader election, we give upper and lower\nbounds on the minimum size of advice sufficient to perform leader election in\ntime $\\tau$. All our bounds except one pair are tight up to multiplicative\nconstants, and in this one exceptional case, the gap between the upper and the\nlower bound is very small.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 15:46:24 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Gorain", "Barun", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1702.03563", "submitter": "Wiktor Daszczuk", "authors": "Wiktor B. Daszczuk, Waldemar Grabski, Jerzy Mie\\'scicki, Jacek\n  Wytr\\k{e}bowicz", "title": "System Modeling in the COSMA Environment", "comments": "6 pages, 3 figures, 1 table", "journal-ref": "Proc. Euromicro Symposium on Digital Systems Design -\n  Architectures, Methods and Tools, September 4-6 2001, Warsaw, Poland, pp.\n  152-157", "doi": "10.1109/DSD.2001.952264", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The aim of this paper is to demonstrate how the COSMA environment can be used\nfor system modeling. This environment is a set of tools based on Concurrent\nState Machines paradigm and is developed in the Institute of Computer Science\nat the Warsaw University of Technology. Our demonstration example is a\ndistributed brake control system dedicated for a railway transport. The paper\nshortly introduces COSMA. Next it shows how the example model can be validated\nby our temporal logic analyzer.\n", "versions": [{"version": "v1", "created": "Sun, 12 Feb 2017 19:28:22 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Daszczuk", "Wiktor B.", ""], ["Grabski", "Waldemar", ""], ["Mie\u015bcicki", "Jerzy", ""], ["Wytr\u0119bowicz", "Jacek", ""]]}, {"id": "1702.03657", "submitter": "Xavier Bellekens", "authors": "Xavier Bellekens and Amar Seeam and Christos Tachtatzis and Robert\n  Atkinson", "title": "Trie Compression for GPU Accelerated Multi-Pattern Matching", "comments": "4 pages, 6 figures. Accepted and Published in The Ninth International\n  Conferences on Pervasive Patterns and Applications PATTERNS 2017 (19 - 23/02,\n  2017 - Athens, Greece)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Graphics Processing Units allow for running massively parallel applications\noffloading the CPU from computationally intensive resources, however GPUs have\na limited amount of memory. In this paper a trie compression algorithm for\nmassively parallel pattern matching is presented demonstrating 85% less space\nrequirements than the original highly efficient parallel failure-less\naho-corasick, whilst demonstrating over 22 Gbps throughput. The algorithm\npresented takes advantage of compressed row storage matrices as well as shared\nand texture memory on the GPU.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 07:18:13 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Bellekens", "Xavier", ""], ["Seeam", "Amar", ""], ["Tachtatzis", "Christos", ""], ["Atkinson", "Robert", ""]]}, {"id": "1702.03741", "submitter": "Iqra Altaf Gillani", "authors": "Iqra Altaf Gillani, Pooja Vyavahare and Amitabha Bagchi", "title": "Random walk based in-network computation of arbitrary functions", "comments": null, "journal-ref": "Distributed Computing 34(3), 181-193, April 2021", "doi": "10.1007/s00446-021-00394-7", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study in-network computation on general network topologies. Specifically,\nwe are given the description of a function, and a network with distinct nodes\nat which the operands of the function are made available, and a designated sink\nwhere the computed value of the function is to be consumed. We want to compute\nthe function during the process of moving the data towards the sink. Such\nsettings have been studied in the literature, but mainly for symmetric\nfunctions, e.g. average, parity etc., which have the specific property that the\noutput is invariant to permutation of the operands. To the best of our\nknowledge, we present the first fully decentralised algorithms for arbitrary\nfunctions, which we model as those functions whose computation schema is\nstructured as a binary tree. We propose two algorithms, Fixed Random-Compute\nand Flexible Random-Compute, for this problem, both of which use simple random\nwalks on the network as their basic primitive. Assuming a stochastic model for\nthe generation of streams of data at each source, we provide a lower and an\nupper bound on the rate at which Fixed Random-Compute can compute the stream of\nassociated function values. Note that the lower bound on rate though computed\nfor our algorithm serves as a general lower bound for the function computation\nproblem and to the best of our knowledge is first such lower bound for\nasymmetric functions. We also provide upper bounds on the average time taken to\ncompute the function, characterising this time in terms of the fundamental\nparameters of the random walk on the network: the hitting time in the case of\nFixed Random-Compute, and the mixing time in the case of Flexible\nRandom-Compute.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 12:35:50 GMT"}, {"version": "v2", "created": "Thu, 19 Oct 2017 11:24:04 GMT"}, {"version": "v3", "created": "Mon, 19 Feb 2018 14:31:50 GMT"}], "update_date": "2021-06-22", "authors_parsed": [["Gillani", "Iqra Altaf", ""], ["Vyavahare", "Pooja", ""], ["Bagchi", "Amitabha", ""]]}, {"id": "1702.03886", "submitter": "Mushfiqur Sarker", "authors": "Mushfiqur R. Sarker, Jianhui Wang", "title": "Unit Commitment on the Cloud", "comments": "2 pages, 1 figure, 1 table, IEEE Letter", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of High Performance Computing (HPC) has provided the computational\ncapacity required for power system operators (SO) to obtain solutions in the\nleast time to highly-complex applications, i.e., Unit Commitment (UC). The UC\nproblem, which attempts to schedule the least-cost combination of generating\nunits to meet the load, is increasing in complexity and problem size due to\ndeployments of renewable resources and smart grid technologies. The current\napproach to solving the UC problem consists of in-house HPC infrastructures,\nwhich experience issues at scale, and demands high maintenance and capital\nexpenditures. On the other hand, cloud computing is an ideal substitute due to\nits powerful computational capacity, rapid scalability, and high\ncost-effectiveness. In this work, the benefits and challenges of outsourcing\nthe UC application to the cloud are explored. A quantitative analysis of the\ncomputational performance gain is explored for a large-scale UC problem solved\non the cloud and compared to traditional in-house HPC infrastructure. The\nresults show substantial reduction in solve time when outsourced to the cloud.\n", "versions": [{"version": "v1", "created": "Wed, 18 Jan 2017 19:15:15 GMT"}], "update_date": "2017-02-14", "authors_parsed": [["Sarker", "Mushfiqur R.", ""], ["Wang", "Jianhui", ""]]}, {"id": "1702.03935", "submitter": "Michael Warren", "authors": "Michael S. Warren, Samuel W. Skillman, Rick Chartrand, Tim Kelton,\n  Ryan Keisler, David Raleigh, Matthew Turk", "title": "Data-Intensive Supercomputing in the Cloud: Global Analytics for\n  Satellite Imagery", "comments": "8 pages, 9 figures. Copyright 2016 IEEE. DataCloud 2016: The Seventh\n  International Workshop on Data-Intensive Computing in the Clouds. In\n  conjunction with SC16. Salt Lake City, Utah", "journal-ref": "Proceedings of the 7th International Workshop on Data-Intensive\n  Computing in the Cloud (DataCloud '16). IEEE Press, Piscataway, NJ, USA,\n  24-31, 2016", "doi": "10.1109/DataCloud.2016.7", "report-no": null, "categories": "cs.DC cs.AI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our experiences using cloud computing to support data-intensive\nanalytics on satellite imagery for commercial applications. Drawing from our\nbackground in high-performance computing, we draw parallels between the early\ndays of clustered computing systems and the current state of cloud computing\nand its potential to disrupt the HPC market. Using our own virtual file system\nlayer on top of cloud remote object storage, we demonstrate aggregate read\nbandwidth of 230 gigabytes per second using 512 Google Compute Engine (GCE)\nnodes accessing a USA multi-region standard storage bucket. This figure is\ncomparable to the best HPC storage systems in existence. We also present\nseveral of our application results, including the identification of field\nboundaries in Ukraine, and the generation of a global cloud-free base layer\nfrom Landsat imagery.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 19:00:04 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Warren", "Michael S.", ""], ["Skillman", "Samuel W.", ""], ["Chartrand", "Rick", ""], ["Kelton", "Tim", ""], ["Keisler", "Ryan", ""], ["Raleigh", "David", ""], ["Turk", "Matthew", ""]]}, {"id": "1702.04024", "submitter": "Eric Jonas", "authors": "Eric Jonas, Qifan Pu, Shivaram Venkataraman, Ion Stoica, Benjamin\n  Recht", "title": "Occupy the Cloud: Distributed Computing for the 99%", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed computing remains inaccessible to a large number of users, in\nspite of many open source platforms and extensive commercial offerings. While\ndistributed computation frameworks have moved beyond a simple map-reduce model,\nmany users are still left to struggle with complex cluster management and\nconfiguration tools, even for running simple embarrassingly parallel jobs. We\nargue that stateless functions represent a viable platform for these users,\neliminating cluster management overhead, fulfilling the promise of elasticity.\nFurthermore, using our prototype implementation, PyWren, we show that this\nmodel is general enough to implement a number of distributed computing models,\nsuch as BSP, efficiently. Extrapolating from recent trends in network bandwidth\nand the advent of disaggregated storage, we suggest that stateless functions\nare a natural fit for data processing in future computing environments.\n", "versions": [{"version": "v1", "created": "Mon, 13 Feb 2017 23:40:11 GMT"}, {"version": "v2", "created": "Wed, 7 Jun 2017 22:41:43 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Jonas", "Eric", ""], ["Pu", "Qifan", ""], ["Venkataraman", "Shivaram", ""], ["Stoica", "Ion", ""], ["Recht", "Benjamin", ""]]}, {"id": "1702.04028", "submitter": "Alan David", "authors": "Alan David", "title": "Scheduling Algorithms for Asymmetric Multi-core Processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Growing power dissipation due to high performance requirement of processor\nsuggests multicore processor technology, which has become the technology for\npresent and next decade. Research advocates asymmetric multi-core processor\nsystem for better utilization of chip real state. However, asymmetric multi\ncore architecture poses a new challenge to operating system scheduler, which\ntraditionally assumes homogeneous hardware. So, scheduling threads to core has\nbecome a major issue to operating system kernel. In this paper, proposed\nscheduling algorithms for asymmetric multicore processors have been\ncategorized. This paper explores some representative algorithms of these\nclasses to get an overview of scheduling algorithms for asymmetric multicore\nsystem.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 00:11:12 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["David", "Alan", ""]]}, {"id": "1702.04164", "submitter": "Christian Schulz", "authors": "Christian Schulz and Jesper Larsson Tr\\\"aff and Konrad von Kirchbach", "title": "Better Process Mapping and Sparse Quadratic Assignment", "comments": "additional algorithms and experiments", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Communication and topology aware process mapping is a powerful approach to\nreduce communication time in parallel applications with known communication\npatterns on large, distributed memory systems. We address the problem as a\nquadratic assignment problem (QAP), and present algorithms to construct initial\nmappings of processes to processors, and fast local search algorithms to\nfurther improve the mappings. By exploiting assumptions that typically hold for\napplications and modern supercomputer systems such as sparse communication\npatterns and hierarchically organized communication systems, we obtain\nsignificantly more powerful algorithms for these special QAPs. Our multilevel\nconstruction algorithms employ perfectly balanced graph partitioning techniques\nand exploit the given communication system hierarchy in significant ways. We\npresent improvements to a local search algorithm of Brandfass et al. (2013),\nand further decrease the running time by reducing the time needed to perform\nswaps in the assignment as well as by carefully constraining local search\nneighborhoods. We also investigate different algorithms to create the\ncommunication graph that is mapped onto the processor network. Experiments\nindicate that our algorithms not only dramatically speed up local search, but\ndue to the multilevel approach also find much better solutions in practice.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 11:40:21 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2019 11:19:56 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Schulz", "Christian", ""], ["Tr\u00e4ff", "Jesper Larsson", ""], ["von Kirchbach", "Konrad", ""]]}, {"id": "1702.04242", "submitter": "Ezra N. Hoch", "authors": "Ezra N. Hoch, Yaniv Ben-Yehuda, Noam Lewis, Avi Vigder", "title": "Bizur: A Key-value Consensus Algorithm for Scalable File-systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bizur is a consensus algorithm exposing a key-value interface. It is used by\na distributed file-system that scales to 100s of servers, delivering millions\nof IOPS, both data and metadata, with consistent low-latency.\n  Bizur is aimed for services that require strongly consistent state, but do\nnot require a distributed log; for example, a distributed lock manager or a\ndistributed service locator. By avoiding a distributed log scheme, Bizur\noutperforms distributed log based consensus algorithms, producing more IOPS and\nguaranteeing lower latencies during normal operation and especially during\nfailures.\n  Paxos-like algorithms (e.g., Zab and Raft) which are used by existing\ndistributed file-systems, can have artificial contention points due to their\ndependence on a distributed log. The distributed log is needed when replicating\na general service, but when the desired service is key-value based, the\ncontention points created by the distributed log can be avoided.\n  Bizur does exactly that, by reaching consensus independently on independent\nkeys. This independence allows Bizur to handle failures more efficiently and to\nscale much better than other consensus algorithms, allowing the file-system\nthat utilizes Bizur to scale with it.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 14:51:45 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Hoch", "Ezra N.", ""], ["Ben-Yehuda", "Yaniv", ""], ["Lewis", "Noam", ""], ["Vigder", "Avi", ""]]}, {"id": "1702.04250", "submitter": "William McDoniel", "authors": "William McDoniel (1), Markus H\\\"ohnerbach (1), Rodrigo Canales (1),\n  Ahmed E. Ismail (2), Paolo Bientinesi (2) ((1) RWTH Aachen University, (2)\n  West Virginia University)", "title": "LAMMPS' PPPM Long-Range Solver for the Second Generation Xeon Phi", "comments": "18 pages, 8 figures, submitted to ISC High Performance 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular Dynamics is an important tool for computational biologists,\nchemists, and materials scientists, consuming a sizable amount of\nsupercomputing resources. Many of the investigated systems contain charged\nparticles, which can only be simulated accurately using a long-range solver,\nsuch as PPPM. We extend the popular LAMMPS molecular dynamics code with an\nimplementation of PPPM particularly suitable for the second generation Intel\nXeon Phi. Our main target is the optimization of computational kernels by means\nof vectorization, and we observe speedups in these kernels of up to 12x. These\nimprovements carry over to LAMMPS users, with overall speedups ranging between\n2-3x, without requiring users to retune input parameters. Furthermore, our\noptimizations make it easier for users to determine optimal input parameters\nfor attaining top performance.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 15:03:05 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["McDoniel", "William", ""], ["H\u00f6hnerbach", "Markus", ""], ["Canales", "Rodrigo", ""], ["Ismail", "Ahmed E.", ""], ["Bientinesi", "Paolo", ""]]}, {"id": "1702.04263", "submitter": "Diego Didona Dr", "authors": "Diego Didona, Kristina Spirovska, Willy Zwaenepoel", "title": "Okapi: Causally Consistent Geo-Replication Made Faster, Cheaper and More\n  Available", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Okapi is a new causally consistent geo-replicated key- value store. Okapi\nleverages two key design choices to achieve high performance. First, it relies\non hybrid logical/physical clocks to achieve low latency even in the presence\nof clock skew. Second, Okapi achieves higher resource efficiency and better\navailability, at the expense of a slight increase in update visibility latency.\nTo this end, Okapi implements a new stabilization protocol that uses a\ncombination of vector and scalar clocks and makes a remote update visible when\nits delivery has been acknowledged by every data center. We evaluate Okapi with\ndifferent workloads on Amazon AWS, using three geographically distributed\nregions and 96 nodes. We compare Okapi with two recent approaches to causal\nconsistency, Cure and GentleRain. We show that Okapi delivers up to two orders\nof magnitude better performance than GentleRain and that Okapi achieves up to\n3.5x lower latency and a 60% reduction of the meta-data overhead with respect\nto Cure.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 15:34:56 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Didona", "Diego", ""], ["Spirovska", "Kristina", ""], ["Zwaenepoel", "Willy", ""]]}, {"id": "1702.04323", "submitter": "Calin Iorgulescu", "authors": "Calin Iorgulescu, Florin Dinu, Aunn Raza, Wajih Ul Hassan, and Willy\n  Zwaenepoel", "title": "Don't cry over spilled records: Memory elasticity of data-parallel\n  applications and its application to cluster scheduling", "comments": "13 pages (11 without references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the performance of data-parallel workloads when\nresource-constrained has significant practical importance but unfortunately has\nreceived only limited attention. This paper identifies, quantifies and\ndemonstrates memory elasticity, an intrinsic property of data-parallel tasks.\nMemory elasticity allows tasks to run with significantly less memory that they\nwould ideally want while only paying a moderate performance penalty. For\nexample, we find that given as little as 10% of ideal memory, PageRank and\nNutchIndexing Hadoop reducers become only 1.2x/1.75x and 1.08x slower. We show\nthat memory elasticity is prevalent in the Hadoop, Spark, Tez and Flink\nframeworks. We also show that memory elasticity is predictable in nature by\nbuilding simple models for Hadoop and extending them to Tez and Spark.\n  To demonstrate the potential benefits of leveraging memory elasticity, this\npaper further explores its application to cluster scheduling. In this setting,\nwe observe that the resource vs. time trade-off enabled by memory elasticity\nbecomes a task queuing time vs task runtime trade-off. Tasks may complete\nfaster when scheduled with less memory because their waiting time is reduced.\nWe show that a scheduler can turn this task-level trade-off into improved job\ncompletion time and cluster-wide memory utilization. We have integrated memory\nelasticity into Apache YARN. We show gains of up to 60% in average job\ncompletion time on a 50-node Hadoop cluster. Extensive simulations show similar\nimprovements over a large number of scenarios.\n", "versions": [{"version": "v1", "created": "Tue, 14 Feb 2017 18:21:31 GMT"}], "update_date": "2017-02-15", "authors_parsed": [["Iorgulescu", "Calin", ""], ["Dinu", "Florin", ""], ["Raza", "Aunn", ""], ["Hassan", "Wajih Ul", ""], ["Zwaenepoel", "Willy", ""]]}, {"id": "1702.04441", "submitter": "Vitaly Aksenov", "authors": "Vitaly Aksenov and Vincent Gramoli and Petr Kuznetsov and Anna Malova\n  and Srivatsan Ravi", "title": "A Concurrency-Optimal Binary Search Tree", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents the first \\emph{concurrency-optimal} implementation of a\nbinary search tree (BST). The implementation, based on a standard sequential\nimplementation of an internal tree, ensures that every \\emph{schedule} is\naccepted, i.e., interleaving of steps of the sequential code, unless\nlinearizability is violated. To ensure this property, we use a novel read-write\nlocking scheme that protects tree \\emph{edges} in addition to nodes.\n  Our implementation outperforms the state-of-the art BSTs on most basic\nworkloads, which suggests that optimizing the set of accepted schedules of the\nsequential code can be an adequate design principle for efficient concurrent\ndata structures.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 02:10:34 GMT"}, {"version": "v2", "created": "Fri, 17 Feb 2017 00:10:36 GMT"}, {"version": "v3", "created": "Thu, 2 Mar 2017 14:16:56 GMT"}], "update_date": "2017-03-03", "authors_parsed": [["Aksenov", "Vitaly", ""], ["Gramoli", "Vincent", ""], ["Kuznetsov", "Petr", ""], ["Malova", "Anna", ""], ["Ravi", "Srivatsan", ""]]}, {"id": "1702.04467", "submitter": "Paul Gazzillo", "authors": "Thomas Dickerson, Paul Gazzillo, Maurice Herlihy, Eric Koskinen", "title": "Adding Concurrency to Smart Contracts", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern cryptocurrency systems, such as Ethereum, permit complex financial\ntransactions through scripts called smart contracts. These smart contracts are\nexecuted many, many times, always without real concurrency. First, all smart\ncontracts are serially executed by miners before appending them to the\nblockchain. Later, those contracts are serially re-executed by validators to\nverify that the smart contracts were executed correctly by miners.\n  Serial execution limits system throughput and fails to exploit today's\nconcurrent multicore and cluster architectures. Nevertheless, serial execution\nappears to be required: contracts share state, and contract programming\nlanguages have a serial semantics.\n  This paper presents a novel way to permit miners and validators to execute\nsmart contracts in parallel, based on techniques adapted from software\ntransactional memory. Miners execute smart contracts speculatively in parallel,\nallowing non-conflicting contracts to proceed concurrently, and \"discovering\" a\nserializable concurrent schedule for a block's transactions, This schedule is\ncaptured and encoded as a deterministic fork-join program used by validators to\nre-execute the miner's parallel schedule deterministically but concurrently.\n  Smart contract benchmarks run on a JVM with ScalaSTM show that a speedup of\nof 1.33x can be obtained for miners and 1.69x for validators with just three\nconcurrent threads.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 05:38:37 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Dickerson", "Thomas", ""], ["Gazzillo", "Paul", ""], ["Herlihy", "Maurice", ""], ["Koskinen", "Eric", ""]]}, {"id": "1702.04474", "submitter": "Mohammad Shorfuzzaman", "authors": "Mohammad Shorfuzzaman", "title": "Leveraging cloud based big data analytics in knowledge management for\n  enhanced decision making in organizations", "comments": null, "journal-ref": "International Journal of Distributed and Parallel Systems (IJDPS)\n  Vol.8, No.1, January 2017", "doi": "10.5121/ijdps.2017.8101", "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent past, big data opportunities have gained much momentum to enhance\nknowledge management in organizations. However, big data due to its various\nproperties like high volume, variety, and velocity can no longer be effectively\nstored and analyzed with traditional data management techniques to generate\nvalues for knowledge development. Hence, new technologies and architectures are\nrequired to store and analyze this big data through advanced data analytics and\nin turn generate vital real-time knowledge for effective decision making by\norganizations. More specifically, it is necessary to have a single\ninfrastructure which provides common functionality of knowledge management, and\nflexible enough to handle different types of big data and big data analysis\ntasks. Cloud computing infrastructures capable of storing and processing large\nvolume of data can be used for efficient big data processing because it\nminimizes the initial cost for the large-scale computing infrastructure\ndemanded by big data analytics. This paper aims to explore the impact of big\ndata analytics on knowledge management and proposes a cloud-based conceptual\nframework that can analyze big data in real time to facilitate enhanced\ndecision making intended for competitive advantage. Thus, this framework will\npave the way for organizations to explore the relationship between big data\nanalytics and knowledge management which are mostly deemed as two distinct\nentities.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 06:29:34 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Shorfuzzaman", "Mohammad", ""]]}, {"id": "1702.04645", "submitter": "Benjamin Chi\\^em", "authors": "Benjamin Chi\\^em, Andine Havelange, Paul Van Dooren", "title": "A parallel implementation of the Synchronised Louvain method", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Community detection in networks is a very actual and important field of\nresearch with applications in many areas. But, given that the amount of\nprocessed data increases more and more, existing algorithms need to be adapted\nfor very large graphs. The objective of this project was to parallelise the\nSynchronised Louvain Method, a community detection algorithm developed by\nArnaud Browet, in order to improve its performances in terms of computation\ntime and thus be able to faster detect communities in very large graphs. To\nreach this goal, we used the API OpenMP to parallelise the algorithm and then\ncarried out performance tests. We studied the computation time and speedup of\nthe parallelised algorithm and were able to bring out some qualitative trends.\nWe obtained a great speedup, compared with the theoretical prediction of Amdahl\nlaw. To conclude, using the parallel implementation of the algorithm of Browet\non large graphs seems to give good results, both in terms of computation time\nand speedup. Further tests should be carried out in order to obtain more\nquantitative results.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 15:09:15 GMT"}], "update_date": "2017-02-16", "authors_parsed": [["Chi\u00eam", "Benjamin", ""], ["Havelange", "Andine", ""], ["Van Dooren", "Paul", ""]]}, {"id": "1702.04739", "submitter": "Saleh Ashkboos", "authors": "Ramin Javadi, Saleh Ashkboos", "title": "An Efficient Parallel Data Clustering Algorithm Using Isoperimetric\n  Number of Trees", "comments": "16 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a parallel graph-based data clustering algorithm using CUDA GPU,\nbased on exact clustering of the minimum spanning tree in terms of a minimum\nisoperimetric criteria. We also provide a comparative performance analysis of\nour algorithm with other related ones which demonstrates the general\nsuperiority of this parallel algorithm over other competing algorithms in terms\nof accuracy and speed.\n", "versions": [{"version": "v1", "created": "Wed, 15 Feb 2017 19:14:54 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Javadi", "Ramin", ""], ["Ashkboos", "Saleh", ""]]}, {"id": "1702.04850", "submitter": "A. Salman Avestimehr", "authors": "Songze Li, Sucha Supittayapornpong, Mohammad Ali Maddah-Ali, and A.\n  Salman Avestimehr", "title": "Coded TeraSort", "comments": "to appear in proceedings of 2017 International Workshop on Parallel\n  and Distributed Computing for Large Scale Machine Learning and Big Data\n  Analytics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on sorting, which is the building block of many machine learning\nalgorithms, and propose a novel distributed sorting algorithm, named Coded\nTeraSort, which substantially improves the execution time of the TeraSort\nbenchmark in Hadoop MapReduce. The key idea of Coded TeraSort is to impose\nstructured redundancy in data, in order to enable in-network coding\nopportunities that overcome the data shuffling bottleneck of TeraSort. We\nempirically evaluate the performance of CodedTeraSort algorithm on Amazon EC2\nclusters, and demonstrate that it achieves 1.97x - 3.39x speedup, compared with\nTeraSort, for typical settings of interest.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 03:44:44 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Li", "Songze", ""], ["Supittayapornpong", "Sucha", ""], ["Maddah-Ali", "Mohammad Ali", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "1702.04866", "submitter": "Paul Gazzillo", "authors": "Thomas D. Dickerson, Paul Gazzillo, Maurice Herlihy, Eric Koskinen", "title": "Proust: A Design Space for Highly-Concurrent Transactional Data\n  Structures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most STM systems are poorly equipped to support libraries of concurrent data\nstructures. One reason is that they typically detect conflicts by tracking\ntransactions' read sets and write sets, an approach that often leads to false\nconflicts. A second is that existing data structures and libraries often need\nto be rewritten from scratch to support transactional conflict detection and\nrollback. This paper introduces Proust, a framework for the design and\nimplementation of transactional data structures. Proust is designed to maximize\nre-use of existing well-engineered by providing transactional \"wrappers\" to\nmake existing thread-safe concurrent data structures transactional. Proustian\nobjects are also integrated with an underling STM system, allowing them to take\nadvantage of well-engineered STM conflict detection mechanisms. Proust\ngeneralizes and unifies prior approaches such as boosting and predication.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 06:07:25 GMT"}, {"version": "v2", "created": "Mon, 26 Jun 2017 14:38:14 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Dickerson", "Thomas D.", ""], ["Gazzillo", "Paul", ""], ["Herlihy", "Maurice", ""], ["Koskinen", "Eric", ""]]}, {"id": "1702.04921", "submitter": "Frederik Mallmann-Trenn", "authors": "Petra Berenbrink, Andrea Clementi, Robert Els\\\"asser, Peter Kling,\n  Frederik Mallmann-Trenn, Emanuele Natale", "title": "Ignore or Comply? On Breaking Symmetry in Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study consensus processes on the complete graph of $n$ nodes. Initially,\neach node supports one from up to n opinions. Nodes randomly and in parallel\nsample the opinions of constant many nodes. Based on these samples, they use an\nupdate rule to change their own opinion.\n  The goal is to reach consensus, a configuration where all nodes support the\nsame opinion. We compare two well-known update rules: 2-Choices and 3-Majority.\nIn the former, each node samples two nodes and adopts their opinion if they\nagree. In the latter, each node samples three nodes: If an opinion is supported\nby at least two samples the node adopts it, otherwise it randomly adopts one of\nthe sampled opinions. Known results for these update rules focus on initial\nconfigurations with a limited number of colors (say $n^{1/3}$ ), or typically\nassume a bias, where one opinion has a much larger support than any other. For\nsuch biased configurations, the time to reach consensus is roughly the same for\n2-Choices and 3-Majority.\n  Interestingly, we prove that this is no longer true for configurations with a\nlarge number of initial colors. In particular, we show that 3-Majority reaches\nconsensus with high probability in $O(n^{3/4}\\log^{7/8}n)$ rounds, while\n2-Choices can need $\\Omega(n/\\log n)$ rounds. We thus get the first\nunconditional sublinear bound for 3-Majority and the first result separating\nthe consensus time of these processes. Along the way, we develop a framework\nthat allows a fine-grained comparison between consensus processes from a\nspecific class. We believe that this framework might help to classify the\nperformance of more consensus processes.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 11:08:20 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Berenbrink", "Petra", ""], ["Clementi", "Andrea", ""], ["Els\u00e4sser", "Robert", ""], ["Kling", "Peter", ""], ["Mallmann-Trenn", "Frederik", ""], ["Natale", "Emanuele", ""]]}, {"id": "1702.04966", "submitter": "Abdellah Idrissi", "authors": "Manar Abourezq and Abdellah Idrissi", "title": "Integration of QoS aspects in the Cloud Computing Research and Selection\n  System", "comments": null, "journal-ref": "International Journal of Advanced Computer Science and Application\n  (IJACSA) Vol. 6, No. 6, 2015", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud Computing is a business model revolution more than a technological one.\nIt capitalized on various technologies that have proved themselves and reshaped\nthe use of computers by replacing their local use by a centralized one where\nshared resources are stored and managed by a third-party in a way transparent\nto end-users. With this new use came new needs and one of them is the need to\nsearch through Cloud services and select the ones that meet certain\nrequirements. To address this need, we have developed, in a previous work, the\nCloud Service Research and Selection System (CSRSS) which aims to allow Cloud\nusers to search through Cloud services in the database and find the ones that\nmatch their requirements. It is based on the Skyline and ELECTRE IS. In this\npaper, we improve the system by introducing 7 new dimensions related to QoS\nconstraints. Our work's main contribution is conceiving an Agent that uses both\nthe Skyline and an outranking method, called ELECTREIsSkyline, to determine\nwhich Cloud services meet better the users' requirements while respecting QoS\nproperties. We programmed and tested this method for a total of 10 dimensions\nand for 50 000 cloud services. The first results are very promising and show\nthe effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Sun, 27 Dec 2015 20:51:34 GMT"}], "update_date": "2017-02-17", "authors_parsed": [["Abourezq", "Manar", ""], ["Idrissi", "Abdellah", ""]]}, {"id": "1702.05156", "submitter": "Peter Henderson", "authors": "Peter Henderson and Matthew Vertescher", "title": "An Analysis of Parallelized Motion Masking Using Dual-Mode Single\n  Gaussian Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motion detection in video is important for a number of applications and\nfields. In video surveillance, motion detection is an essential accompaniment\nto activity recognition for early warning systems. Robotics also has much to\ngain from motion detection and segmentation, particularly in high speed motion\ntracking for tactile systems. There are a myriad of techniques for detecting\nand masking motion in an image. Successful systems have used Gaussian Models to\ndiscern background from foreground in an image (motion from static imagery).\nHowever, particularly in the case of a moving camera or frame of reference, it\nis necessary to compensate for the motion of the camera when attempting to\ndiscern objects moving in the foreground. For example, it is possible to\nestimate motion of the camera through optical flow methods or temporal\ndifferencing and then compensate for this motion in a background subtraction\nmodel. We selection a method by Yi et al. using Dual-Mode Single Gaussian\nModels which does just this. We implement the technique in Intel's Thread\nBuilding Blocks (TBB) and NVIDIA's CUDA libraries. We then compare\nparallelization improvements with a theoretical analysis of speedups based on\nthe characteristics of our selected model and attributes of both TBB and CUDA.\nWe make our implementation available to the public.\n", "versions": [{"version": "v1", "created": "Thu, 16 Feb 2017 21:10:13 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Henderson", "Peter", ""], ["Vertescher", "Matthew", ""]]}, {"id": "1702.05262", "submitter": "Nikita Kazeev", "authors": "D. Derkach, N. Kazeev, R. Neychev, A. Panin, I. Trofimov, A.\n  Ustyuzhanin and M. Vesterinen", "title": "LHCb trigger streams optimization", "comments": "Submitted to CHEP-2016 proceedings", "journal-ref": "Journal of Physics: Conference Series. Vol. 898. No. 6. IOP\n  Publishing, 2017", "doi": "10.1088/1742-6596/898/6/062026", "report-no": null, "categories": "cs.DC hep-ex", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The LHCb experiment stores around $10^{11}$ collision events per year. A\ntypical physics analysis deals with a final sample of up to $10^7$ events.\nEvent preselection algorithms (lines) are used for data reduction. Since the\ndata are stored in a format that requires sequential access, the lines are\ngrouped into several output file streams, in order to increase the efficiency\nof user analysis jobs that read these data. The scheme efficiency heavily\ndepends on the stream composition. By putting similar lines together and\nbalancing the stream sizes it is possible to reduce the overhead. We present a\nmethod for finding an optimal stream composition. The method is applied to a\npart of the LHCb data (Turbo stream) on the stage where it is prepared for user\nphysics analysis. This results in an expected improvement of 15% in the speed\nof user analysis jobs, and will be applied on data to be recorded in 2017.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 09:09:25 GMT"}, {"version": "v2", "created": "Tue, 6 Jun 2017 19:56:54 GMT"}], "update_date": "2019-02-08", "authors_parsed": [["Derkach", "D.", ""], ["Kazeev", "N.", ""], ["Neychev", "R.", ""], ["Panin", "A.", ""], ["Trofimov", "I.", ""], ["Ustyuzhanin", "A.", ""], ["Vesterinen", "M.", ""]]}, {"id": "1702.05412", "submitter": "Ioannis Lamprou", "authors": "Ioannis Lamprou, Russell Martin, Paul Spirakis", "title": "Cover Time in Edge-Uniform Stochastically-Evolving Graphs", "comments": "removed a few erroneous proofs, refreshed related work and\n  experimental results", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a general model of stochastically-evolving graphs, namely the\n\\emph{Edge-Uniform Stochastically-Evolving Graphs}. In this model, each\npossible edge of an underlying general static graph evolves independently being\neither alive or dead at each discrete time step of evolution following a\n(Markovian) stochastic rule. The stochastic rule is identical for each possible\nedge and may depend on the past $k \\ge 0$ observations of the edge's state. We\nexamine two kinds of random walks for a single agent taking place in such a\ndynamic graph: (i) The \\emph{Random Walk with a Delay} (\\emph{RWD}), where at\neach step the agent chooses (uniformly at random) an incident possible edge,\ni.e., an incident edge in the underlying static graph, and then it waits till\nthe edge becomes alive to traverse it. (ii) The more natural \\emph{Random Walk\non what is Available} (\\emph{RWA}) where the agent only looks at alive incident\nedges at each time step and traverses one of them uniformly at random. Our\nstudy is on bounding the \\emph{cover time}, i.e., the expected time until each\nnode is visited at least once by the agent. For \\emph{RWD}, we provide a first\nupper bound for the cases $k = 0, 1$ by correlating \\emph{RWD} with a simple\nrandom walk on a static graph. Moreover, we present a modified electrical\nnetwork theory capturing the $k = 0$ case. For \\emph{RWA}, we derive some first\nbounds for the case $k = 0$, by reducing \\emph{RWA} to an \\emph{RWD}-equivalent\nwalk with a modified delay. Further, we also provide a framework, which is\nshown to compute the exact value of the cover time for a general family of\nstochastically-evolving graphs in exponential time. Finally, we conduct\nexperiments on the cover time of \\emph{RWA} in Edge-Uniform graphs and compare\nthe experimental findings with our theoretical bounds.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 15:53:54 GMT"}, {"version": "v2", "created": "Mon, 8 May 2017 18:11:47 GMT"}, {"version": "v3", "created": "Sat, 15 Jul 2017 11:00:23 GMT"}, {"version": "v4", "created": "Wed, 28 Feb 2018 16:45:47 GMT"}, {"version": "v5", "created": "Wed, 18 Jul 2018 15:41:55 GMT"}], "update_date": "2018-07-19", "authors_parsed": [["Lamprou", "Ioannis", ""], ["Martin", "Russell", ""], ["Spirakis", "Paul", ""]]}, {"id": "1702.05456", "submitter": "Janne H. Korhonen", "authors": "Sebastian Brandt, Juho Hirvonen, Janne H. Korhonen, Tuomo\n  Lempi\\\"ainen, Patric R. J. \\\"Osterg{\\aa}rd, Christopher Purcell, Joel\n  Rybicki, Jukka Suomela, Przemys{\\l}aw Uzna\\'nski", "title": "LCL problems on grids", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  LCLs or locally checkable labelling problems (e.g. maximal independent set,\nmaximal matching, and vertex colouring) in the LOCAL model of computation are\nvery well-understood in cycles (toroidal 1-dimensional grids): every problem\nhas a complexity of $O(1)$, $\\Theta(\\log^* n)$, or $\\Theta(n)$, and the design\nof optimal algorithms can be fully automated.\n  This work develops the complexity theory of LCL problems for toroidal\n2-dimensional grids. The complexity classes are the same as in the\n1-dimensional case: $O(1)$, $\\Theta(\\log^* n)$, and $\\Theta(n)$. However, given\nan LCL problem it is undecidable whether its complexity is $\\Theta(\\log^* n)$\nor $\\Theta(n)$ in 2-dimensional grids.\n  Nevertheless, if we correctly guess that the complexity of a problem is\n$\\Theta(\\log^* n)$, we can completely automate the design of optimal\nalgorithms. For any problem we can find an algorithm that is of a normal form\n$A' \\circ S_k$, where $A'$ is a finite function, $S_k$ is an algorithm for\nfinding a maximal independent set in $k$th power of the grid, and $k$ is a\nconstant.\n  Finally, partially with the help of automated design tools, we classify the\ncomplexity of several concrete LCL problems related to colourings and\norientations.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 17:48:41 GMT"}, {"version": "v2", "created": "Wed, 24 May 2017 11:01:44 GMT"}], "update_date": "2017-05-25", "authors_parsed": [["Brandt", "Sebastian", ""], ["Hirvonen", "Juho", ""], ["Korhonen", "Janne H.", ""], ["Lempi\u00e4inen", "Tuomo", ""], ["\u00d6sterg\u00e5rd", "Patric R. J.", ""], ["Purcell", "Christopher", ""], ["Rybicki", "Joel", ""], ["Suomela", "Jukka", ""], ["Uzna\u0144ski", "Przemys\u0142aw", ""]]}, {"id": "1702.05459", "submitter": "Mustafa Abduljabbar", "authors": "Mustafa Abduljabbar, George Markomanolis, Huda Ibeid, Rio Yokota,\n  David Keyes", "title": "Communication Reducing Algorithms for Distributed Hierarchical N-Body\n  Problems with Boundary Distributions", "comments": "arXiv admin note: text overlap with arXiv:1405.7487", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reduction of communication and efficient partitioning are key issues for\nachieving scalability in hierarchical $N$-Body algorithms like FMM. In the\npresent work, we propose four independent strategies to improve partitioning\nand reduce communication. First of all, we show that the conventional wisdom of\nusing space-filling curve partitioning may not work well for boundary integral\nproblems, which constitute about 50% of FMM's application user base. We propose\nan alternative method which modifies orthogonal recursive bisection to solve\nthe cell-partition misalignment that has kept it from scaling previously.\nSecondly, we optimize the granularity of communication to find the optimal\nbalance between a bulk-synchronous collective communication of the local\nessential tree and an RDMA per task per cell. Finally, we take the dynamic\nsparse data exchange proposed by Hoefler et al. and extend it to a hierarchical\nsparse data exchange, which is demonstrated at scale to be faster than the MPI\nlibrary's MPI_Alltoallv that is commonly used.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 17:57:20 GMT"}], "update_date": "2017-02-20", "authors_parsed": [["Abduljabbar", "Mustafa", ""], ["Markomanolis", "George", ""], ["Ibeid", "Huda", ""], ["Yokota", "Rio", ""], ["Keyes", "David", ""]]}, {"id": "1702.05510", "submitter": "Josef Spillner", "authors": "Josef Spillner and Serhii Dorodko", "title": "Java Code Analysis and Transformation into AWS Lambda Functions", "comments": "12 pages, 3 figures, 7 tables, repeatable, unreviewed", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software developers are faced with the issue of either adapting their\nprogramming model to the execution model (e.g. cloud platforms) or finding\nappropriate tools to adapt the model and code automatically. A recent execution\nmodel which would benefit from automated enablement is Function-as-a-Service.\nAutomating this process requires a pipeline which includes steps for code\nanalysis, transformation and deployment. In this paper, we outline the design\nand runtime characteristics of Podilizer, a tool which implements the pipeline\nspecifically for Java source code as input and AWS Lambda as output. We\ncontribute technical and economic metrics about this concrete 'FaaSification'\nprocess by observing the behaviour of Podilizer with two representative Java\nsoftware projects.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 20:06:58 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Spillner", "Josef", ""], ["Dorodko", "Serhii", ""]]}, {"id": "1702.05511", "submitter": "Ilya Sergey", "authors": "Ilya Sergey, Aquinas Hobor", "title": "A Concurrent Perspective on Smart Contracts", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we explore remarkable similarities between multi-transactional\nbehaviors of smart contracts in cryptocurrencies such as Ethereum and classical\nproblems of shared-memory concurrency. We examine two real-world examples from\nthe Ethereum blockchain and analyzing how they are vulnerable to bugs that are\nclosely reminiscent to those that often occur in traditional concurrent\nprograms. We then elaborate on the relation between observable contract\nbehaviors and well-studied concurrency topics, such as atomicity, interference,\nsynchronization, and resource ownership. The described\ncontracts-as-concurrent-objects analogy provides deeper understanding of\npotential threats for smart contracts, indicate better engineering practices,\nand enable applications of existing state-of-the-art formal verification\ntechniques.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 20:21:14 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Sergey", "Ilya", ""], ["Hobor", "Aquinas", ""]]}, {"id": "1702.05513", "submitter": "Ole Weidner", "authors": "Ole Weidner, Malcolm Atkinson, Adam Barker, Rosa Filgueira", "title": "Rethinking High Performance Computing Platforms: Challenges,\n  Opportunities and Recommendations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new class of Second generation high-performance computing applications with\nheterogeneous, dynamic and data-intensive properties have an extended set of\nrequirements, which cover application deployment, resource allocation,\n-control, and I/O scheduling. These requirements are not met by the current\nproduction HPC platform models and policies. This results in a loss of\nopportunity, productivity and innovation for new computational methods and\ntools. It also decreases effective system utilization for platform providers\ndue to unsupervised workarounds and rogue resource management strategies\nimplemented in application space. In this paper we critically discuss the\ndominant HPC platform model and describe the challenges it creates for second\ngeneration applications because of its asymmetric resource view, interfaces and\nsoftware deployment policies. We present an extended, more symmetric and\napplication-centric platform model that adds decentralized deployment,\nintrospection, bidirectional control and information flow and more\ncomprehensive resource scheduling. We describe cHPC: an early prototype of a\nnon-disruptive implementation based on Linux Containers (LXC). It can operate\nalongside existing batch queuing systems and exposes a symmetric platform API\nwithout interfering with existing applications and usage modes. We see our\napproach as a viable, incremental next step in HPC platform evolution that\nbenefits applications and platform providers alike. To demonstrate this\nfurther, we layout out a roadmap for future research and experimental\nevaluation.\n", "versions": [{"version": "v1", "created": "Fri, 17 Feb 2017 20:31:50 GMT"}, {"version": "v2", "created": "Mon, 27 Feb 2017 18:53:28 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Weidner", "Ole", ""], ["Atkinson", "Malcolm", ""], ["Barker", "Adam", ""], ["Filgueira", "Rosa", ""]]}, {"id": "1702.05800", "submitter": "Xinghao Pan", "authors": "Xinghao Pan, Jianmin Chen, Rajat Monga, Samy Bengio, Rafal Jozefowicz", "title": "Revisiting Distributed Synchronous SGD", "comments": "This article will be superseded by arXiv:1604.00981", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed training of deep learning models on large-scale training data is\ntypically conducted with asynchronous stochastic optimization to maximize the\nrate of updates, at the cost of additional noise introduced from asynchrony. In\ncontrast, the synchronous approach is often thought to be impractical due to\nidle time wasted on waiting for straggling workers. We revisit these\nconventional beliefs in this paper, and examine the weaknesses of both\napproaches. We demonstrate that a third approach, synchronous optimization with\nbackup workers, can avoid asynchronous noise while mitigating for the worst\nstragglers. Our approach is empirically validated and shown to converge faster\nand to better test accuracies.\n", "versions": [{"version": "v1", "created": "Sun, 19 Feb 2017 21:51:48 GMT"}, {"version": "v2", "created": "Sat, 18 Mar 2017 23:02:17 GMT"}], "update_date": "2017-03-21", "authors_parsed": [["Pan", "Xinghao", ""], ["Chen", "Jianmin", ""], ["Monga", "Rajat", ""], ["Bengio", "Samy", ""], ["Jozefowicz", "Rafal", ""]]}, {"id": "1702.05865", "submitter": "Xinghao Pan", "authors": "Xinghao Pan, Shivaram Venkataraman, Zizheng Tai, Joseph Gonzalez", "title": "Hemingway: Modeling Distributed Optimization Algorithms", "comments": "Presented at ML Systems Workshop at NIPS, Dec 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed optimization algorithms are widely used in many industrial\nmachine learning applications. However choosing the appropriate algorithm and\ncluster size is often difficult for users as the performance and convergence\nrate of optimization algorithms vary with the size of the cluster. In this\npaper we make the case for an ML-optimizer that can select the appropriate\nalgorithm and cluster size to use for a given problem. To do this we propose\nbuilding two models: one that captures the system level characteristics of how\ncomputation, communication change as we increase cluster sizes and another that\ncaptures how convergence rates change with cluster sizes. We present\npreliminary results from our prototype implementation called Hemingway and\ndiscuss some of the challenges involved in developing such a system.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 05:51:18 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Pan", "Xinghao", ""], ["Venkataraman", "Shivaram", ""], ["Tai", "Zizheng", ""], ["Gonzalez", "Joseph", ""]]}, {"id": "1702.05967", "submitter": "Jesper Larsson Tr\\\"aff", "authors": "Jesper Larsson Tr\\\"aff", "title": "Practical, Linear-time, Fully Distributed Algorithms for Irregular\n  Gather and Scatter", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present new, simple, fully distributed, practical algorithms with linear\ntime communication cost for irregular gather and scatter operations in which\nprocessors contribute or consume possibly different amounts of data. In a\nlinear cost transmission model with start-up latency $\\alpha$ and cost per unit\n$\\beta$, the new algorithms take time $3|{\\log_2 p}|\\alpha+\\beta \\sum_{i\\neq\nr}m_i$ where $p$ is the number of processors, $m_i$ the amount of data for\nprocessor $i, 0\\leq i<p$, and processor $r, 0\\leq r<p$ a root processor\ndetermined by the algorithm. For a fixed, externally given root processor $r$,\nthere is an additive penalty of at most $\\beta(M_{d'}-m_{r_{d'}}-\\sum_{0\\leq\nj<d'}M_j)$ time steps where each $M_j$ is the total amount of data in a tree of\n$2^j$ different processors with roots $r_j$ as constructed by the algorithm.\nThe worst-case penalty is less than $\\beta \\sum_{i\\neq r}m_i$ time steps. The\nalgorithms have attractive properties for implementing the operations for MPI\n(the Message-Passing Interface). Standard algorithms using fixed trees take\ntime either $|{\\log_2 p}|(\\alpha+\\beta \\sum_{i\\neq r} m_i)$ in the worst case,\nor $\\sum_{i\\neq r}(\\alpha+\\beta m_i)$. We have used the new algorithms to give\nprototype implementations for the MPI_Gatherv and MPI_Scatterv collectives of\nMPI, and present benchmark results from a small and a medium-large InfiniBand\ncluster. In order to structure the experimental evaluation we formulate new\nperformance guidelines for irregular collectives that can be used to assess the\nperformance in relation to the corresponding regular collectives. We show that\nthe new algorithms can fulfill these performance expectations with a large\nmargin, and that standard implementations do not.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 13:50:52 GMT"}, {"version": "v2", "created": "Tue, 28 Feb 2017 13:40:48 GMT"}, {"version": "v3", "created": "Wed, 12 Apr 2017 12:41:11 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Tr\u00e4ff", "Jesper Larsson", ""]]}, {"id": "1702.06082", "submitter": "Songze Li", "authors": "Songze Li, Mohammad Ali Maddah-Ali, A. Salman Avestimehr", "title": "Coding for Distributed Fog Computing", "comments": "To appear in IEEE Communications Magazine, Issue on Fog Computing and\n  Networking", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Redundancy is abundant in Fog networks (i.e., many computing and storage\npoints) and grows linearly with network size. We demonstrate the\ntransformational role of coding in Fog computing for leveraging such redundancy\nto substantially reduce the bandwidth consumption and latency of computing. In\nparticular, we discuss two recently proposed coding concepts, namely Minimum\nBandwidth Codes and Minimum Latency Codes, and illustrate their impacts in Fog\ncomputing. We also review a unified coding framework that includes the above\ntwo coding techniques as special cases, and enables a tradeoff between\ncomputation latency and communication load to optimize system performance. At\nthe end, we will discuss several open problems and future research directions.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 17:56:01 GMT"}], "update_date": "2017-02-21", "authors_parsed": [["Li", "Songze", ""], ["Maddah-Ali", "Mohammad Ali", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "1702.06167", "submitter": "Gustavo Maciel Dias Vieira", "authors": "Islene C. Garcia, Gustavo M. D. Vieira, Luiz E. Buzato", "title": "A Rollback in the History of Communication-Induced Checkpointing", "comments": "Revised manuscript", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The literature on communication-induced checkpointing presents a family of\nprotocols that use logical clocks to control whether forced checkpoints must be\ntaken. Efficiency of these protocols is measured by how many forced checkpoints\nare needed to ensure no checkpoint will be useless to the application; the\nfewer forced checkpoints the better. For many years, HMNR, also called Fully\nInformed (FI), was the most complex and efficient protocol of this family. The\nLazy-FI protocol applies a lazy strategy that defers the increase of logical\nclocks, resulting in a protocol with better efficiency for distributed systems\nwhere processes can take basic checkpoints at different rates. Recently, the\nFully Informed aNd Efficient (FINE) protocol was proposed using the same\ncontrol structures as FI, but with a stronger and, presumably better,\ncheckpoint-inducing condition. FINE and its lazy version, called Lazy-FINE,\nwould now be the most efficient checkpointing protocols based on logical\nclocks. This paper reviews this family of protocols, proves a theorem on a\ncondition that must be enforced by all stronger versions of FI, and proves that\nboth FINE and Lazy-FINE do not guarantee the absence of useless checkpoints. As\na consequence, FI and Lazy-FI can be rolled back to the position of most\nefficient protocols of this family of index-based checkpointing protocols.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 20:35:33 GMT"}, {"version": "v2", "created": "Mon, 10 Jun 2019 18:33:15 GMT"}], "update_date": "2019-06-12", "authors_parsed": [["Garcia", "Islene C.", ""], ["Vieira", "Gustavo M. D.", ""], ["Buzato", "Luiz E.", ""]]}, {"id": "1702.06284", "submitter": "Sudhakar Singh", "authors": "Sudhakar Singh, Rakhi Garg, and P. K. Mishra", "title": "Review of Apriori Based Algorithms on MapReduce Framework", "comments": "12 pages, 3 figures, ICC-2014", "journal-ref": null, "doi": null, "report-no": "115", "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Apriori algorithm that mines frequent itemsets is one of the most popular\nand widely used data mining algorithms. Now days many algorithms have been\nproposed on parallel and distributed platforms to enhance the performance of\nApriori algorithm. They differ from each other on the basis of load balancing\ntechnique, memory system, data decomposition technique and data layout used to\nimplement them. The problems with most of the distributed framework are\noverheads of managing distributed system and lack of high level parallel\nprogramming language. Also with grid computing there is always potential\nchances of node failures which cause multiple re-executions of tasks. These\nproblems can be overcome by the MapReduce framework introduced by Google.\nMapReduce is an efficient, scalable and simplified programming model for large\nscale distributed data processing on a large cluster of commodity computers and\nalso used in cloud computing. In this paper, we present the overview of\nparallel Apriori algorithm implemented on MapReduce framework. They are\ncategorized on the basis of Map and Reduce functions used to implement them\ne.g. 1-phase vs. k-phase, I/O of Mapper, Combiner and Reducer, using\nfunctionality of Combiner inside Mapper etc. This survey discusses and analyzes\nthe various implementations of Apriori on MapReduce framework on the basis of\ntheir distinguishing characteristics. Moreover, it also includes the advantages\nand limitations of MapReduce framework.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 07:34:06 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Singh", "Sudhakar", ""], ["Garg", "Rakhi", ""], ["Mishra", "P. K.", ""]]}, {"id": "1702.06298", "submitter": "Md Saiful Islam", "authors": "Md. Saiful Islam, Wenny Rahayu, Chengfei Liu, Tarique Anwar and Bela\n  Stantic", "title": "Computing Influence of a Product through Uncertain Reverse Skyline", "comments": "12 pages, 3 tables, 12 figures, submitted to SSDBM 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Understanding the influence of a product is crucially important for making\ninformed business decisions. This paper introduces a new type of skyline\nqueries, called uncertain reverse skyline, for measuring the influence of a\nprobabilistic product in uncertain data settings. More specifically, given a\ndataset of probabilistic products P and a set of customers C, an uncertain\nreverse skyline of a probabilistic product q retrieves all customers c in C\nwhich include q as one of their preferred products. We present efficient\npruning ideas and techniques for processing the uncertain reverse skyline query\nof a probabilistic product using R-Tree data index. We also present an\nefficient parallel approach to compute the uncertain reverse skyline and\ninfluence score of a probabilistic product. Our approach significantly\noutperforms the baseline approach derived from the existing literature. The\nefficiency of our approach is demonstrated by conducting extensive experiments\nwith both real and synthetic datasets.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 09:06:04 GMT"}], "update_date": "2017-02-22", "authors_parsed": [["Islam", "Md. Saiful", ""], ["Rahayu", "Wenny", ""], ["Liu", "Chengfei", ""], ["Anwar", "Tarique", ""], ["Stantic", "Bela", ""]]}, {"id": "1702.06331", "submitter": "Prateeksha Varshney", "authors": "Prateeksha Varshney and Yogesh Simmhan", "title": "Demystifying Fog Computing: Characterizing Architectures, Applications\n  and Abstractions", "comments": null, "journal-ref": "Proceedings of the IEEE 1st International Conference on Fog and\n  Edge Computing (ICFEC), Madrid, Spain, 2017", "doi": "10.1109/ICFEC.2017.20", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things (IoT) has accelerated the deployment of millions of\nsensors at the edge of the network, through Smart City infrastructure and\nlifestyle devices. Cloud computing platforms are often tasked with handling\nthese large volumes and fast streams of data from the edge. Recently, Fog\ncomputing has emerged as a concept for low-latency and resource-rich processing\nof these observation streams, to complement Edge and Cloud computing. In this\npaper, we review various dimensions of system architecture, application\ncharacteristics and platform abstractions that are manifest in this Edge, Fog\nand Cloud eco-system. We highlight novel capabilities of the Edge and Fog\nlayers, such as physical and application mobility, privacy sensitivity, and a\nnascent runtime environment. IoT application case studies based on first-hand\nexperiences across diverse domains drive this categorization. We also highlight\nthe gap between the potential and the reality of Fog computing, and identify\nchallenges that need to be overcome for the solution to be sustainable.\nTogether, our article can help platform and application developers bridge the\ngap that remains in making Fog computing viable.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 11:22:54 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Varshney", "Prateeksha", ""], ["Simmhan", "Yogesh", ""]]}, {"id": "1702.06335", "submitter": "Nitinder Mohan", "authors": "Nitinder Mohan and Jussi Kangasharju", "title": "Edge-Fog Cloud: A Distributed Cloud for Internet of Things Computations", "comments": "Published in IEEE 2nd Conference on Cloudification of Internet of\n  Things (CIoT) - 2016, Paris, France", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet of Things typically involves a significant number of smart sensors\nsensing information from the environment and sharing it to a cloud service for\nprocessing. Various architectural abstractions, such as Fog and Edge computing,\nhave been proposed to localize some of the processing near the sensors and away\nfrom the central cloud servers. In this paper, we propose Edge-Fog Cloud which\ndistributes task processing on the participating cloud resources in the\nnetwork. We develop the Least Processing Cost First (LPCF) method for assigning\nthe processing tasks to nodes which provide the optimal processing time and\nnear optimal networking costs. We evaluate LPCF in a variety of scenarios and\ndemonstrate its effectiveness in finding the processing task assignments.\n", "versions": [{"version": "v1", "created": "Tue, 21 Feb 2017 11:32:34 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 10:39:51 GMT"}], "update_date": "2017-03-08", "authors_parsed": [["Mohan", "Nitinder", ""], ["Kangasharju", "Jussi", ""]]}, {"id": "1702.06392", "submitter": "Yixing Li", "authors": "Yixing Li, Zichuan Liu, Kai Xu, Hao Yu and Fengbo Ren", "title": "A GPU-Outperforming FPGA Accelerator Architecture for Binary\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  FPGA-based hardware accelerators for convolutional neural networks (CNNs)\nhave obtained great attentions due to their higher energy efficiency than GPUs.\nHowever, it is challenging for FPGA-based solutions to achieve a higher\nthroughput than GPU counterparts. In this paper, we demonstrate that FPGA\nacceleration can be a superior solution in terms of both throughput and energy\nefficiency when a CNN is trained with binary constraints on weights and\nactivations. Specifically, we propose an optimized FPGA accelerator\narchitecture tailored for bitwise convolution and normalization that features\nmassive spatial parallelism with deep pipelines stages. A key advantage of the\nFPGA accelerator is that its performance is insensitive to data batch size,\nwhile the performance of GPU acceleration varies largely depending on the batch\nsize of the data. Experiment results show that the proposed accelerator\narchitecture for binary CNNs running on a Virtex-7 FPGA is 8.3x faster and 75x\nmore energy-efficient than a Titan X GPU for processing online individual\nrequests in small batch sizes. For processing static data in large batch sizes,\nthe proposed solution is on a par with a Titan X GPU in terms of throughput\nwhile delivering 9.5x higher energy efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 20 Feb 2017 05:21:34 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 16:09:55 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Li", "Yixing", ""], ["Liu", "Zichuan", ""], ["Xu", "Kai", ""], ["Yu", "Hao", ""], ["Ren", "Fengbo", ""]]}, {"id": "1702.06865", "submitter": "Marina Krstic Marinkovic", "authors": "Marina Krstic Marinkovic (CERN), Luka Stanisic (Inria)", "title": "Platform independent profiling of a QCD code", "comments": null, "journal-ref": "34th annual International Symposium on Lattice Field Theory, Jul\n  2016, Southampton, United Kingdom. 2017, PoS", "doi": null, "report-no": null, "categories": "hep-lat cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The supercomputing platforms available for high performance computing based\nresearch evolve at a great rate. However, this rapid development of novel\ntechnologies requires constant adaptations and optimizations of the existing\ncodes for each new machine architecture. In such context, minimizing time of\nefficiently porting the code on a new platform is of crucial importance. A\npossible solution for this common challenge is to use simulations of the\napplication that can assist in detecting performance bottlenecks. Due to\nprohibitive costs of classical cycle-accurate simulators, coarse-grain\nsimulations are more suitable for large parallel and distributed systems. We\npresent a procedure of implementing the profiling for openQCD code [1] through\nsimulation, which will enable the global reduction of the cost of profiling and\noptimizing this code commonly used in the lattice QCD community. Our approach\nis based on well-known SimGrid simulator [2], which allows for fast and\naccurate performance predictions of HPC codes. Additionally, accurate\nestimations of the program behavior on some future machines, not yet accessible\nto us, are anticipated.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 15:53:00 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Marinkovic", "Marina Krstic", "", "CERN"], ["Stanisic", "Luka", "", "Inria"]]}, {"id": "1702.06898", "submitter": "Jose A. Fonseca", "authors": "Carsten Burstedde, Jose A. Fonseca, Stefan Kollet", "title": "Enhancing speed and scalability of the ParFlow simulation code", "comments": "The final publication is available at link.springer.com", "journal-ref": "Computational Geosciences 2017", "doi": "10.1007/s10596-017-9696-2", "report-no": null, "categories": "cs.MS cs.DC physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Regional hydrology studies are often supported by high resolution simulations\nof subsurface flow that require expensive and extensive computations. Efficient\nusage of the latest high performance parallel computing systems becomes a\nnecessity. The simulation software ParFlow has been demonstrated to meet this\nrequirement and shown to have excellent solver scalability for up to 16,384\nprocesses. In the present work we show that the code requires further\nenhancements in order to fully take advantage of current petascale machines. We\nidentify ParFlow's way of parallelization of the computational mesh as a\ncentral bottleneck. We propose to reorganize this subsystem using fast mesh\npartition algorithms provided by the parallel adaptive mesh refinement library\np4est. We realize this in a minimally invasive manner by modifying selected\nparts of the code to reinterpret the existing mesh data structures. We evaluate\nthe scaling performance of the modified version of ParFlow, demonstrating good\nweak and strong scaling up to 458k cores of the Juqueen supercomputer, and test\nan example application at large scale.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 17:12:49 GMT"}, {"version": "v2", "created": "Mon, 2 Oct 2017 18:51:52 GMT"}], "update_date": "2017-10-04", "authors_parsed": [["Burstedde", "Carsten", ""], ["Fonseca", "Jose A.", ""], ["Kollet", "Stefan", ""]]}, {"id": "1702.06900", "submitter": "Guillaume Aupy", "authors": "Guillaume Aupy and Ana Gainaru and Valentin Le F\\`evre", "title": "Periodic I/O scheduling for super-computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the ever-growing need of data in HPC applications, the congestion at the\nI/O level becomes critical in super-computers. Architectural enhancement such\nas burst-buffers and pre-fetching are added to machines, but are not sufficient\nto prevent congestion. Recent online I/O scheduling strategies have been put in\nplace, but they add an additional congestion point and overheads in the\ncomputation of applications.\n  In this work, we show how to take advantage of the periodic nature of HPC\napplications in order to develop efficient periodic scheduling strategies for\ntheir I/O transfers. Our strategy computes once during the job scheduling phase\na pattern where it defines the I/O behavior for each application, after which\nthe applications run independently, transferring their I/O at the specified\ntimes. Our strategy limits the amount of I/O congestion at the I/O node level\nand can be easily integrated into current job schedulers. We validate this\nmodel through extensive simulations and experiments by comparing it to\nstate-of-the-art online solutions, showing that not only our scheduler has the\nadvantage of being de-centralized and thus overcoming the overhead of online\nschedulers, but also that it performs better than these solutions, improving\nthe application dilation up to 13% and the maximum system efficiency up to 18%.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 17:18:20 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Aupy", "Guillaume", ""], ["Gainaru", "Ana", ""], ["F\u00e8vre", "Valentin Le", ""]]}, {"id": "1702.06970", "submitter": "William Kluegel", "authors": "William Kluegel, Muhammad Aamir Iqbal, Ferdinando Fioretto, William\n  Yeoh, and Enrico Pontelli", "title": "A Realistic Dataset for the Smart Home Device Scheduling Problem for\n  DCOPs", "comments": "15 pages, OPTMAS17", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The field of Distributed Constraint Optimization has gained momentum in\nrecent years thanks to its ability to address various applications related to\nmulti-agent cooperation. While techniques to solve Distributed Constraint\nOptimization Problems (DCOPs) are abundant and have matured substantially since\nthe field inception, the number of DCOP realistic applications and benchmark\nused to asses the performance of DCOP algorithms is lagging behind. To contrast\nthis background we (i) introduce the Smart Home Device Scheduling (SHDS)\nproblem, which describe the problem of coordinating smart devices schedules\nacross multiple homes as a multi-agent system, (ii) detail the physical models\nadopted to simulate smart sensors, smart actuators, and homes environments, and\n(iii) introduce a DCOP realistic benchmark for SHDS problems.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 19:10:30 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Kluegel", "William", ""], ["Iqbal", "Muhammad Aamir", ""], ["Fioretto", "Ferdinando", ""], ["Yeoh", "William", ""], ["Pontelli", "Enrico", ""]]}, {"id": "1702.07005", "submitter": "Thomas Parnelll", "authors": "Thomas Parnell, Celestine D\\\"unner, Kubilay Atasu, Manolis Sifalakis\n  and Haris Pozidis", "title": "Large-Scale Stochastic Learning using GPUs", "comments": "Accepted for publication in ParLearning 2017: The 6th International\n  Workshop on Parallel and Distributed Computing for Large Scale Machine\n  Learning and Big Data Analytics, Orlando, Florida, May 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we propose an accelerated stochastic learning system for very\nlarge-scale applications. Acceleration is achieved by mapping the training\nalgorithm onto massively parallel processors: we demonstrate a parallel,\nasynchronous GPU implementation of the widely used stochastic coordinate\ndescent/ascent algorithm that can provide up to 35x speed-up over a sequential\nCPU implementation. In order to train on very large datasets that do not fit\ninside the memory of a single GPU, we then consider techniques for distributed\nstochastic learning. We propose a novel method for optimally aggregating model\nupdates from worker nodes when the training data is distributed either by\nexample or by feature. Using this technique, we demonstrate that one can scale\nout stochastic learning across up to 8 worker nodes without any significant\nloss of training time. Finally, we combine GPU acceleration with the optimized\ndistributed method to train on a dataset consisting of 200 million training\nexamples and 75 million features. We show by scaling out across 4 GPUs, one can\nattain a high degree of training accuracy in around 4 seconds: a 20x speed-up\nin training time compared to a multi-threaded, distributed implementation\nacross 4 CPUs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 21:03:11 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Parnell", "Thomas", ""], ["D\u00fcnner", "Celestine", ""], ["Atasu", "Kubilay", ""], ["Sifalakis", "Manolis", ""], ["Pozidis", "Haris", ""]]}, {"id": "1702.07081", "submitter": "Mohammad Qayum", "authors": "Mohammad Qayum and Abdel-Hameed Badawy and Jeanine Cook", "title": "DyAdHyTM: A Low Overhead Dynamically Adaptive Hybrid Transactional\n  Memory on Big Data Graphs", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data is a buzzword used to describe massive volumes of data that provides\nopportunities of exploring new insights through data analytics. However, big\ndata is mostly structured but can be semi-structured or unstructured. It is\nnormally so large that it is not only difficult but also slow to process using\ntraditional computing systems. One of the solutions is to format the data as\ngraph data structures and process them on shared memory architecture to use\nfast and novel policies such as transactional memory. In most graph\napplications in big data type problems such as bioinformatics, social networks,\nand cyber security, graphs are sparse in nature. Due to this sparsity, we have\nthe opportunity to use Transactional Memory (TM) as the synchronization policy\nfor critical sections to speedup applications. At low conflict probability TM\nperforms better than most synchronization policies due to its inherent\nnon-blocking characteristics. TM can be implemented in Software, Hardware or a\ncombination of both. However, hardware TM implementations are fast but limited\nby scarce hardware resources while software implementations have high overheads\nwhich can degrade performance. In this paper, we develop a low overhead, yet\nsimple, dynamically adaptive (i.e. at runtime) hybrid (i.e. combines hardware\nand software) TM (DyAdHyTM) scheme that combines the best features of both\nHardware TM (HTM) and Software TM (STM) while adapting to application\nrequirements. It performs better than coarse grain lock by up to 8.12x, a low\noverhead STM by up to 2.68x, a couple of implementations of HTMs (by up to\n2.59x), and other HyTMs (by up to 1.55x) for SSCA2 graph benchmark running on a\nmulticore machine with a large shared memory.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 03:21:21 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 19:05:08 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Qayum", "Mohammad", ""], ["Badawy", "Abdel-Hameed", ""], ["Cook", "Jeanine", ""]]}, {"id": "1702.07083", "submitter": "Jianfei Chen", "authors": "Jianfei Chen, Jun Zhu, Jie Lu, Shixia Liu", "title": "Scalable Inference for Nested Chinese Restaurant Process Topic Models", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.IR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nested Chinese Restaurant Process (nCRP) topic models are powerful\nnonparametric Bayesian methods to extract a topic hierarchy from a given text\ncorpus, where the hierarchical structure is automatically determined by the\ndata. Hierarchical Latent Dirichlet Allocation (hLDA) is a popular instance of\nnCRP topic models. However, hLDA has only been evaluated at small scale,\nbecause the existing collapsed Gibbs sampling and instantiated weight\nvariational inference algorithms either are not scalable or sacrifice inference\nquality with mean-field assumptions. Moreover, an efficient distributed\nimplementation of the data structures, such as dynamically growing count\nmatrices and trees, is challenging.\n  In this paper, we propose a novel partially collapsed Gibbs sampling (PCGS)\nalgorithm, which combines the advantages of collapsed and instantiated weight\nalgorithms to achieve good scalability as well as high model quality. An\ninitialization strategy is presented to further improve the model quality.\nFinally, we propose an efficient distributed implementation of PCGS through\nvectorization, pre-processing, and a careful design of the concurrent data\nstructures and communication strategy.\n  Empirical studies show that our algorithm is 111 times more efficient than\nthe previous open-source implementation for hLDA, with comparable or even\nbetter model quality. Our distributed implementation can extract 1,722 topics\nfrom a 131-million-document corpus with 28 billion tokens, which is 4-5 orders\nof magnitude larger than the previous largest corpus, with 50 machines in 7\nhours.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 03:34:07 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Chen", "Jianfei", ""], ["Zhu", "Jun", ""], ["Lu", "Jie", ""], ["Liu", "Shixia", ""]]}, {"id": "1702.07195", "submitter": "Carlos Garcia", "authors": "Enzo Rucci, Carlos Garcia, Guillermo Botella, Armando De Giusti,\n  Marcelo Naiouf, Manuel Prieto-Matias", "title": "First Experiences Optimizing Smith-Waterman on Intel's Knights Landing\n  Processor", "comments": "Submitted to Euro-Par 2017 Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The well-known Smith-Waterman (SW) algorithm is the most commonly used method\nfor local sequence alignments. However, SW is very computationally demanding\nfor large protein databases. There exist several implementations that take\nadvantage of computing parallelization on many-cores, FPGAs or GPUs, in order\nto increase the alignment throughtput. In this paper, we have explored SW\nacceleration on Intel KNL processor. The novelty of this architecture requires\nthe revision of previous programming and optimization techniques on many-core\narchitectures. To the best of authors knowledge, this is the first KNL\narchitecture assessment for SW algorithm. Our evaluation, using the renowned\nEnvironmental NR database as benchmark, has shown that multi-threading and SIMD\nexploitation reports competitive performance (351 GCUPS) in comparison with\nother implementations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 12:37:54 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Rucci", "Enzo", ""], ["Garcia", "Carlos", ""], ["Botella", "Guillermo", ""], ["De Giusti", "Armando", ""], ["Naiouf", "Marcelo", ""], ["Prieto-Matias", "Manuel", ""]]}, {"id": "1702.07213", "submitter": "Etienne Lozes", "authors": "Alain Finkel (LSV), Etienne Lozes (LSV)", "title": "Synchronizability of Communicating Finite State Machines is not\n  Decidable", "comments": "Long version (resubmitted)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.FL", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  A system of communicating finite state machines is synchronizable if its send\ntrace semantics, i.e.the set of sequences of sendings it can perform, is the\nsame when its communications are FIFO asynchronous and when they are just\nrendez-vous synchronizations. This property was claimed to be decidable in\nseveral conference and journal papers for either mailboxes or peer-to-peer\ncommunications, thanks to a form of small model property. In this paper, we\nshow that this small model property does not hold neither for mailbox\ncommunications, nor for peer-to-peer communications, therefore the decidability\nof synchronizability becomes an open question. We close this question for\npeer-to-peer communications, and we show that synchronizability is actually\nundecidable. We show that synchronizability is decidable if the topology of\ncommunications is an oriented ring. We also show that, in this case,\nsynchronizability implies the absence of unspecified receptions and orphan\nmessages, and the channel-recognizability of the reachability set.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 13:55:46 GMT"}, {"version": "v2", "created": "Tue, 7 Mar 2017 10:26:21 GMT"}, {"version": "v3", "created": "Thu, 4 May 2017 08:36:04 GMT"}, {"version": "v4", "created": "Fri, 10 Aug 2018 06:49:58 GMT"}, {"version": "v5", "created": "Thu, 9 Apr 2020 13:04:48 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Finkel", "Alain", "", "LSV"], ["Lozes", "Etienne", "", "LSV"]]}, {"id": "1702.07297", "submitter": "Qian Yu", "authors": "Qian Yu, Songze Li, Mohammad Ali Maddah-Ali, A. Salman Avestimehr", "title": "How to Optimally Allocate Resources for Coded Distributed Computing?", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's data centers have an abundance of computing resources, hosting server\nclusters consisting of as many as tens or hundreds of thousands of machines. To\nexecute a complex computing task over a data center, it is natural to\ndistribute computations across many nodes to take advantage of parallel\nprocessing. However, as we allocate more and more computing resources to a\ncomputation task and further distribute the computations, large amounts of\n(partially) computed data must be moved between consecutive stages of\ncomputation tasks among the nodes, hence the communication load can become the\nbottleneck. In this paper, we study the optimal allocation of computing\nresources in distributed computing, in order to minimize the total execution\ntime in distributed computing accounting for both the duration of computation\nand communication phases. In particular, we consider a general MapReduce-type\ndistributed computing framework, in which the computation is decomposed into\nthree stages: \\emph{Map}, \\emph{Shuffle}, and \\emph{Reduce}. We focus on a\nrecently proposed \\emph{Coded Distributed Computing} approach for MapReduce and\nstudy the optimal allocation of computing resources in this framework. For all\nvalues of problem parameters, we characterize the optimal number of servers\nthat should be used for distributed processing, provide the optimal placements\nof the Map and Reduce tasks, and propose an optimal coded data shuffling\nscheme, in order to minimize the total execution time. To prove the optimality\nof the proposed scheme, we first derive a matching information-theoretic\nconverse on the execution time, then we prove that among all possible resource\nallocation schemes that achieve the minimum execution time, our proposed scheme\nuses the exactly minimum possible number of servers.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 17:06:39 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Yu", "Qian", ""], ["Li", "Songze", ""], ["Maddah-Ali", "Mohammad Ali", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "1702.07311", "submitter": "Gali Noti", "authors": "Moshe Babaioff, Yishay Mansour, Noam Nisan, Gali Noti, Carlo Curino,\n  Nar Ganapathy, Ishai Menache, Omer Reingold, Moshe Tennenholtz and Erez\n  Timnat", "title": "ERA: A Framework for Economic Resource Allocation for the Cloud", "comments": null, "journal-ref": null, "doi": "10.1145/3041021.3054186", "report-no": null, "categories": "cs.GT cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has reached significant maturity from a systems perspective,\nbut currently deployed solutions rely on rather basic economics mechanisms that\nyield suboptimal allocation of the costly hardware resources. In this paper we\npresent Economic Resource Allocation (ERA), a complete framework for scheduling\nand pricing cloud resources, aimed at increasing the efficiency of cloud\nresources usage by allocating resources according to economic principles. The\nERA architecture carefully abstracts the underlying cloud infrastructure,\nenabling the development of scheduling and pricing algorithms independently of\nthe concrete lower-level cloud infrastructure and independently of its\nconcerns. Specifically, ERA is designed as a flexible layer that can sit on top\nof any cloud system and interfaces with both the cloud resource manager and\nwith the users who reserve resources to run their jobs. The jobs are scheduled\nbased on prices that are dynamically calculated according to the predicted\ndemand. Additionally, ERA provides a key internal API to pluggable algorithmic\nmodules that include scheduling, pricing and demand prediction. We provide a\nproof-of-concept software and demonstrate the effectiveness of the architecture\nby testing ERA over both public and private cloud systems -- Azure Batch of\nMicrosoft and Hadoop/YARN. A broader intent of our work is to foster\ncollaborations between economics and system communities. To that end, we have\ndeveloped a simulation platform via which economics and system experts can test\ntheir algorithmic implementations.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 17:54:28 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Babaioff", "Moshe", ""], ["Mansour", "Yishay", ""], ["Nisan", "Noam", ""], ["Noti", "Gali", ""], ["Curino", "Carlo", ""], ["Ganapathy", "Nar", ""], ["Menache", "Ishai", ""], ["Reingold", "Omer", ""], ["Tennenholtz", "Moshe", ""], ["Timnat", "Erez", ""]]}, {"id": "1702.07403", "submitter": "Ran Gelles", "authors": "Keren Censor-Hillel, Ran Gelles, Bernhard Haeupler", "title": "Making Asynchronous Distributed Computations Robust to Noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of making distributed computations robust to noise,\nin particular to worst-case (adversarial) corruptions of messages. We give a\ngeneral distributed interactive coding scheme which simulates any asynchronous\ndistributed protocol while tolerating an optimal corruption of a $\\Theta(1/n)$\nfraction of all messages while incurring a moderate blowup of $O(n\\log^2 n)$ in\nthe communication complexity.\n  Our result is the first fully distributed interactive coding scheme in which\nthe topology of the communication network is not known in advance. Prior work\nrequired either a coordinating node to be connected to all other nodes in the\nnetwork or assumed a synchronous network in which all nodes already know the\ncomplete topology of the network.\n", "versions": [{"version": "v1", "created": "Thu, 23 Feb 2017 21:49:52 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Gelles", "Ran", ""], ["Haeupler", "Bernhard", ""]]}, {"id": "1702.07425", "submitter": "Daniel S. Katz", "authors": "Justin M Wozniak, Jonathan Ozik, Daniel S. Katz, Michael Wilde", "title": "Streaming supercomputing needs workflow-enabled programming-in-the-large", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This is a position paper, submitted to the Future Online Analysis Platform\nWorkshop (https://press3.mcs.anl.gov/futureplatform/), which argues that simple\ndata analysis applications are common today, but future online supercomputing\nworkloads will need to couple multiple advanced technologies (streams, caches,\nanalysis, and simulations) to rapidly deliver scientific results. Each of these\ntechnologies are active research areas when integrated with high-performance\ncomputing. These components will interact in complex ways, therefore coupling\nthem needs to be programmed. Programming in the large, on top of existing\napplications, enables us to build much more capable applications and to\nproductively manage this complexity.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 00:05:11 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Wozniak", "Justin M", ""], ["Ozik", "Jonathan", ""], ["Katz", "Daniel S.", ""], ["Wilde", "Michael", ""]]}, {"id": "1702.07431", "submitter": "Carlos Mera", "authors": "Carlos Mera-G\\'omez, Francisco Ram\\'irez, Rami Bahsoon and Rajkumar\n  Buyya", "title": "A Debt-Aware Learning Approach for Resource Adaptations in Cloud\n  Elasticity Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Elasticity is a cloud property that enables applications and its execution\nsystems to dynamically acquire and release shared computational resources on\ndemand. Moreover, it unfolds the advantage of economies of scale in the cloud\nthrough a drop in the average costs of these shared resources. However, it is\nstill an open challenge to achieve a perfect match between resource demand and\nprovision in autonomous elasticity management. Resource adaptation decisions\nessentially involve a trade-off between economics and performance, which\nproduces a gap between the ideal and actual resource provisioning. This gap, if\nnot properly managed, can negatively impact the aggregate utility of a cloud\ncustomer in the long run. To address this limitation, we propose a technical\ndebt-aware learning approach for autonomous elasticity management based on a\nreinforcement learning of elasticity debts in resource provisioning; the\nadaptation pursues strategic decisions that trades off economics against\nperformance. We extend CloudSim and Burlap to evaluate our approach. The\nevaluation shows that a reinforcement learning of technical debts in elasticity\nobtains a higher utility for a cloud customer, while conforming expected levels\nof performance.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 00:58:02 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Mera-G\u00f3mez", "Carlos", ""], ["Ram\u00edrez", "Francisco", ""], ["Bahsoon", "Rami", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1702.07514", "submitter": "Salah Attiya", "authors": "Hesham Arafat Ali, Salah Attiya, Ibrahim El-henawy", "title": "Medical Image Retrieval Based On the Parallelization of the Cluster\n  Sampling Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop parallel cluster sampling algorithms and show that a\nmulti-chain version is embarrassingly parallel and can be used efficiently for\nmedical image retrieval among other applications.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 09:44:41 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Ali", "Hesham Arafat", ""], ["Attiya", "Salah", ""], ["El-henawy", "Ibrahim", ""]]}, {"id": "1702.07605", "submitter": "Lelia Blin", "authors": "L\\'elia Blin and S\\'ebastien Tixeuil", "title": "Compact Self-Stabilizing Leader Election for Arbitrary Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  We present a self-stabilizing leader election algorithm for arbitrary\nnetworks, with space-complexity $O(\\max\\{\\log \\Delta, \\log \\log n\\})$ bits per\nnode in $n$-node networks with maximum degree~$\\Delta$. This space complexity\nis sub-logarithmic in $n$ as long as $\\Delta = n^{o(1)}$. The best\nspace-complexity known so far for arbitrary networks was $O(\\log n)$ bits per\nnode, and algorithms with sub-logarithmic space-complexities were known for the\nring only. To our knowledge, our algorithm is the first algorithm for\nself-stabilizing leader election to break the $\\Omega(\\log n)$ bound for silent\nalgorithms in arbitrary networks. Breaking this bound was obtained via the\ndesign of a (non-silent) self-stabilizing algorithm using sophisticated tools\nsuch as solving the distance-2 coloring problem in a silent self-stabilizing\nmanner, with space-complexity $O(\\max\\{\\log \\Delta, \\log \\log n\\})$ bits per\nnode. Solving this latter coloring problem allows us to implement a\nsub-logarithmic encoding of spanning trees --- storing the IDs of the neighbors\nrequires $\\Omega(\\log n)$ bits per node, while we encode spanning trees using\n$O(\\max\\{\\log \\Delta, \\log \\log n\\})$ bits per node. Moreover, we show how to\nconstruct such compactly encoded spanning trees without relying on variables\nencoding distances or number of nodes, as these two types of variables would\nalso require $\\Omega(\\log n)$ bits per node.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 14:35:57 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Blin", "L\u00e9lia", ""], ["Tixeuil", "S\u00e9bastien", ""]]}, {"id": "1702.07617", "submitter": "Chen Wu", "authors": "Chen Wu, Rodrigo Tobar, Kevin Vinsen, Andreas Wicenec, Dave Pallot,\n  Baoqiang Lao, Ruonan Wang, Tao An, Mark Boulton, Ian Cooper, Richard Dodson,\n  Markus Dolensky, Ying Mei, Feng Wang", "title": "DALiuGE: A Graph Execution Framework for Harnessing the Astronomical\n  Data Deluge", "comments": "31 pages, 12 figures, currently under review by Astronomy and\n  Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Data Activated Liu Graph Engine - DALiuGE - is an execution framework for\nprocessing large astronomical datasets at a scale required by the Square\nKilometre Array Phase 1 (SKA1). It includes an interface for expressing complex\ndata reduction pipelines consisting of both data sets and algorithmic\ncomponents and an implementation run-time to execute such pipelines on\ndistributed resources. By mapping the logical view of a pipeline to its\nphysical realisation, DALiuGE separates the concerns of multiple stakeholders,\nallowing them to collectively optimise large-scale data processing solutions in\na coherent manner. The execution in DALiuGE is data-activated, where each\nindividual data item autonomously triggers the processing on itself. Such\ndecentralisation also makes the execution framework very scalable and flexible,\nsupporting pipeline sizes ranging from less than ten tasks running on a laptop\nto tens of millions of concurrent tasks on the second fastest supercomputer in\nthe world. DALiuGE has been used in production for reducing interferometry data\nsets from the Karl E. Jansky Very Large Array and the Mingantu Ultrawide\nSpectral Radioheliograph; and is being developed as the execution framework\nprototype for the Science Data Processor (SDP) consortium of the Square\nKilometre Array (SKA) telescope. This paper presents a technical overview of\nDALiuGE and discusses case studies from the CHILES and MUSER projects that use\nDALiuGE to execute production pipelines. In a companion paper, we provide\nin-depth analysis of DALiuGE's scalability to very large numbers of tasks on\ntwo supercomputing facilities.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 14:54:45 GMT"}], "update_date": "2017-02-27", "authors_parsed": [["Wu", "Chen", ""], ["Tobar", "Rodrigo", ""], ["Vinsen", "Kevin", ""], ["Wicenec", "Andreas", ""], ["Pallot", "Dave", ""], ["Lao", "Baoqiang", ""], ["Wang", "Ruonan", ""], ["An", "Tao", ""], ["Boulton", "Mark", ""], ["Cooper", "Ian", ""], ["Dodson", "Richard", ""], ["Dolensky", "Markus", ""], ["Mei", "Ying", ""], ["Wang", "Feng", ""]]}, {"id": "1702.07748", "submitter": "Panagiota Nikolaou", "authors": "Panagiota Nikolaou, Yiannakis Sazeides, Antoni Portero, Radim Vavrik,\n  Vit Vondrak", "title": "A Methodology for Oracle Selection of Monitors and Knobs for Configuring\n  an HPC System running a Flood Management Application", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper defines a methodology for the oracle selection of the monitors and\nknobs to use to configure an HPC system running a scientific application while\nsatisfying the application's requirements and not violating any system\nconstraints. This methodology relies on a heuristic correlation analysis\nbetween requirements, monitors and knobs to determine the minimum subset of\nmonitors to observe and knobs to explore, to determine the optimal system\nconfiguration for the HPC application. At the end of this analysis, we reduce\nan 11-dimensional space to a 3-dimensional space for monitors and a\n6-dimensional space to a 3-dimensional space for knobs. This reduction shows\nthe potential and highlights the need for a realistic methodology to help\nidentify such minimum set of monitors and knobs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Feb 2017 08:43:07 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Nikolaou", "Panagiota", ""], ["Sazeides", "Yiannakis", ""], ["Portero", "Antoni", ""], ["Vavrik", "Radim", ""], ["Vondrak", "Vit", ""]]}, {"id": "1702.07802", "submitter": "Ali Yekkehkhany", "authors": "Ali Yekkehkhany", "title": "Near-Data Scheduling for Data Centers with Multiple Levels of Data\n  Locality", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data locality is a fundamental issue for data-parallel applications.\nConsidering MapReduce in Hadoop, the map task scheduling part requires an\nefficient algorithm which takes data locality into consideration; otherwise,\nthe system may become unstable under loads inside the system's capacity region\nand jobs may experience longer completion times which are not of interest. The\ndata chunk needed for any map task can be in memory, on a local disk, in a\nlocal rack, in the same cluster or even in another data center. Hence, unless\nthere has been much work on improving the speed of data center networks,\ndifferent levels of service rates still exist for a task depending on where its\ndata chunk is saved and from which server it receives service. Most of the\ntheoretical work on load balancing is for systems with two levels of data\nlocality including the Pandas algorithm by Xie et al. and the JSQ-MW algorithm\nby Wang et al., where the former is both throughput and heavy-traffic optimal,\nwhile the latter is only throughput optimal, but heavy-traffic optimal in only\na special traffic load. We show that an extension of the JSQ-MW algorithm for a\nsystem with thee levels of data locality is throughput optimal, but not\nheavy-traffic optimal for all loads, only for a special traffic scenario.\nFurthermore, we show that the Pandas algorithm is not even throughput optimal\nfor a system with three levels of data locality. We then propose a novel\nalgorithm, Balanced-Pandas, which is both throughput and heavy-traffic optimal.\nTo the best of our knowledge, this is the first theoretical work on load\nbalancing for a system with more than two levels of data locality. This is more\nchallenging than two levels of data locality as a dilemma between performance\nand throughput emerges.\n", "versions": [{"version": "v1", "created": "Fri, 24 Feb 2017 23:36:26 GMT"}, {"version": "v2", "created": "Thu, 13 Apr 2017 17:39:36 GMT"}], "update_date": "2017-04-14", "authors_parsed": [["Yekkehkhany", "Ali", ""]]}, {"id": "1702.07908", "submitter": "Sabri Pllana", "authors": "Andre Viebke, Suejb Memeti, Sabri Pllana, Ajith Abraham", "title": "CHAOS: A Parallelization Scheme for Training Convolutional Neural\n  Networks on Intel Xeon Phi", "comments": "The Journal of Supercomputing, 2017", "journal-ref": null, "doi": "10.1007/s11227-017-1994-x", "report-no": null, "categories": "cs.DC cs.CV cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning is an important component of big-data analytic tools and\nintelligent applications, such as, self-driving cars, computer vision, speech\nrecognition, or precision medicine. However, the training process is\ncomputationally intensive, and often requires a large amount of time if\nperformed sequentially. Modern parallel computing systems provide the\ncapability to reduce the required training time of deep neural networks. In\nthis paper, we present our parallelization scheme for training convolutional\nneural networks (CNN) named Controlled Hogwild with Arbitrary Order of\nSynchronization (CHAOS). Major features of CHAOS include the support for thread\nand vector parallelism, non-instant updates of weight parameters during\nback-propagation without a significant delay, and implicit synchronization in\narbitrary order. CHAOS is tailored for parallel computing systems that are\naccelerated with the Intel Xeon Phi. We evaluate our parallelization approach\nempirically using measurement techniques and performance modeling for various\nnumbers of threads and CNN architectures. Experimental results for the MNIST\ndataset of handwritten digits using the total number of threads on the Xeon Phi\nshow speedups of up to 103x compared to the execution on one thread of the Xeon\nPhi, 14x compared to the sequential execution on Intel Xeon E5, and 58x\ncompared to the sequential execution on Intel Core i5.\n", "versions": [{"version": "v1", "created": "Sat, 25 Feb 2017 15:48:44 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Viebke", "Andre", ""], ["Memeti", "Suejb", ""], ["Pllana", "Sabri", ""], ["Abraham", "Ajith", ""]]}, {"id": "1702.08065", "submitter": "Baosen Zhang", "authors": "Yuanyuan Shi and Bolun Xu and Di Wang and Baosen Zhang", "title": "Using Battery Storage for Peak Shaving and Frequency Regulation: Joint\n  Optimization for Superlinear Gains", "comments": "To Appear in IEEE Transaction on Power Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider using a battery storage system simultaneously for peak shaving\nand frequency regulation through a joint optimization framework which captures\nbattery degradation, operational constraints and uncertainties in customer load\nand regulation signals. Under this framework, using real data we show the\nelectricity bill of users can be reduced by up to 15\\%. Furthermore, we\ndemonstrate that the saving from joint optimization is often larger than the\nsum of the optimal savings when the battery is used for the two individual\napplications. A simple threshold real-time algorithm is proposed and achieves\nthis super-linear gain. Compared to prior works that focused on using battery\nstorage systems for single applications, our results suggest that batteries can\nachieve much larger economic benefits than previously thought if they jointly\nprovide multiple services.\n", "versions": [{"version": "v1", "created": "Sun, 26 Feb 2017 18:07:36 GMT"}, {"version": "v2", "created": "Wed, 15 Mar 2017 14:58:56 GMT"}, {"version": "v3", "created": "Tue, 5 Sep 2017 02:59:25 GMT"}], "update_date": "2017-09-06", "authors_parsed": [["Shi", "Yuanyuan", ""], ["Xu", "Bolun", ""], ["Wang", "Di", ""], ["Zhang", "Baosen", ""]]}, {"id": "1702.08153", "submitter": "Huijun Wu", "authors": "Huijun Wu, Chen Wang, Yinjin Fu, Sherif Sakr, Liming Zhu and Kai Lu", "title": "HPDedup: A Hybrid Prioritized Data Deduplication Mechanism for Primary\n  Storage in the Cloud", "comments": "14 pages, 11 figures, submitted to MSST2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eliminating duplicate data in primary storage of clouds increases the\ncost-efficiency of cloud service providers as well as reduces the cost of users\nfor using cloud services. Existing primary deduplication techniques either use\ninline caching to exploit locality in primary workloads or use post-processing\ndeduplication running in system idle time to avoid the negative impact on I/O\nperformance. However, neither of them works well in the cloud servers running\nmultiple services or applications for the following two reasons: Firstly, the\ntemporal locality of duplicate data writes may not exist in some primary\nstorage workloads thus inline caching often fails to achieve good deduplication\nratio. Secondly, the post-processing deduplication allows duplicate data to be\nwritten into disks, therefore does not provide the benefit of I/O deduplication\nand requires high peak storage capacity. This paper presents HPDedup, a Hybrid\nPrioritized data Deduplication mechanism to deal with the storage system shared\nby applications running in co-located virtual machines or containers by fusing\nan inline and a post-processing process for exact deduplication. In the inline\ndeduplication phase, HPDedup gives a fingerprint caching mechanism that\nestimates the temporal locality of duplicates in data streams from different\nVMs or applications and prioritizes the cache allocation for these streams\nbased on the estimation. HPDedup also allows different deduplication threshold\nfor streams based on their spatial locality to reduce the disk fragmentation.\nThe post-processing phase removes duplicates whose fingerprints are not able to\nbe cached due to the weak temporal locality from disks. Our experimental\nresults show that HPDedup clearly outperforms the state-of-the-art primary\nstorage deduplication techniques in terms of inline cache efficiency and\nprimary deduplication efficiency.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 05:41:59 GMT"}, {"version": "v2", "created": "Sun, 16 Apr 2017 05:31:34 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Wu", "Huijun", ""], ["Wang", "Chen", ""], ["Fu", "Yinjin", ""], ["Sakr", "Sherif", ""], ["Zhu", "Liming", ""], ["Lu", "Kai", ""]]}, {"id": "1702.08172", "submitter": "Wanchun Jiang", "authors": "Wanchun Jiang, Liyuan Fang, Haiming Xie, Xiangqian Zhou, Jianxin Wang", "title": "Tars: Timeliness-aware Adaptive Replica Selection for Key-Value Stores", "comments": "10pages,submitted to ICDCS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In current large-scale distributed key-value stores, a single end-user\nrequest may lead to key-value access across tens or hundreds of servers. The\ntail latency of these key-value accesses is crucial to the user experience and\ngreatly impacts the revenue. To cut the tail latency, it is crucial for clients\nto choose the fastest replica server as much as possible for the service of\neach key-value access. Aware of the challenges on the time varying performance\nacross servers and the herd behaviors, an adaptive replica selection scheme C3\nis proposed recently. In C3, feedback from individual servers is brought into\nreplica ranking to reflect the time-varying performance of servers, and the\ndistributed rate control and backpressure mechanism is invented. Despite of\nC3's good performance, we reveal the timeliness issue of C3, which has large\nimpacts on both the replica ranking and the rate control, and propose the Tars\n(timeliness-aware adaptive replica selection) scheme. Following the same\nframework as C3, Tars improves the replica ranking by taking the timeliness of\nthe feedback information into consideration, as well as revises the rate\ncontrol of C3. Simulation results confirm that Tars outperforms C3.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 08:02:23 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Jiang", "Wanchun", ""], ["Fang", "Liyuan", ""], ["Xie", "Haiming", ""], ["Zhou", "Xiangqian", ""], ["Wang", "Jianxin", ""]]}, {"id": "1702.08176", "submitter": "Matthieu Perrin", "authors": "Damien Imbs (LIF), Achour Mostefaoui (GDD), Matthieu Perrin, Michel\n  Raynal (ASAP)", "title": "Another Look at the Implementation of Read/write Registers in\n  Crash-prone Asynchronous Message-Passing Systems (Extended Version)", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \" Yet another paper on \" the implementation of read/write registers in\ncrash-prone asynchronous message-passing systems! Yes..., but, differently from\nits predecessors, this paper looks for a communication abstraction which\ncaptures the essence of such an implementation in the same sense that total\norder broadcast can be associated with consensus, or message causal delivery\ncan be associated with causal read/write registers. To this end, the paper\nintroduces a new communication abstraction, named SCD-broadcast (SCD standing\nfor \" Set Constrained Delivery \"), which, instead of a single message, delivers\nto processes sets of messages (whose size can be arbitrary), such that the\nsequences of message sets delivered to any two processes satisfies some\nconstraints. The paper then shows that: (a) SCD-broadcast allows for a very\nsimple implementation of a snapshot object (and consequently also of atomic\nread/write registers) in crash-prone asynchronous message-passing systems, (b)\nSCD-broadcast can be built from snapshot objects (hence SCD-broadcast and\nsnapshot objects --or read/write registers-- are \" computationally equivalent\n\"), (c) SCD-broadcast can be built in message-passing systems where any\nminority of processes may crash (which is the weakest assumption on the number\nof possible process crashes needed to implement a read/write register).\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 08:07:03 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Imbs", "Damien", "", "LIF"], ["Mostefaoui", "Achour", "", "GDD"], ["Perrin", "Matthieu", "", "ASAP"], ["Raynal", "Michel", "", "ASAP"]]}, {"id": "1702.08248", "submitter": "Olivier Bachem", "authors": "Olivier Bachem, Mario Lucic, Andreas Krause", "title": "Scalable k-Means Clustering via Lightweight Coresets", "comments": "To appear in the 24th ACM SIGKDD International Conference on\n  Knowledge Discovery & Data Mining (KDD)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.DS cs.LG stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coresets are compact representations of data sets such that models trained on\na coreset are provably competitive with models trained on the full data set. As\nsuch, they have been successfully used to scale up clustering models to massive\ndata sets. While existing approaches generally only allow for multiplicative\napproximation errors, we propose a novel notion of lightweight coresets that\nallows for both multiplicative and additive errors. We provide a single\nalgorithm to construct lightweight coresets for k-means clustering as well as\nsoft and hard Bregman clustering. The algorithm is substantially faster than\nexisting constructions, embarrassingly parallel, and the resulting coresets are\nsmaller. We further show that the proposed approach naturally generalizes to\nstatistical k-means clustering and that, compared to existing results, it can\nbe used to compute smaller summaries for empirical risk minimization. In\nextensive experiments, we demonstrate that the proposed algorithm outperforms\nexisting data summarization strategies in practice.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 12:03:01 GMT"}, {"version": "v2", "created": "Wed, 6 Jun 2018 21:49:52 GMT"}], "update_date": "2018-06-08", "authors_parsed": [["Bachem", "Olivier", ""], ["Lucic", "Mario", ""], ["Krause", "Andreas", ""]]}, {"id": "1702.08377", "submitter": "Pavel Skvortsov", "authors": "Pavel Skvortsov, Bj\\\"orn Schembera, Frank D\\\"urr, Kurt Rothermel", "title": "Optimized Secure Position Sharing with Non-trusted Servers", "comments": "26 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, location-based applications and services such as friend finders and\ngeo-social networks are very popular. However, storing private position\ninformation on third-party location servers leads to privacy problems. In our\nprevious work, we proposed a position sharing approach for secure management of\npositions on non-trusted servers, which distributes position shares of limited\nprecision among servers of several providers. In this paper, we propose two\nnovel contributions to improve the original approach. First, we optimize the\nplacement of shares among servers by taking their trustworthiness into account.\nSecond, we optimize the location update protocols to minimize the number of\nmessages between mobile device and location servers.\n", "versions": [{"version": "v1", "created": "Mon, 27 Feb 2017 17:02:45 GMT"}], "update_date": "2017-02-28", "authors_parsed": [["Skvortsov", "Pavel", ""], ["Schembera", "Bj\u00f6rn", ""], ["D\u00fcrr", "Frank", ""], ["Rothermel", "Kurt", ""]]}, {"id": "1702.08817", "submitter": "Stefano Bennati", "authors": "Stefano Bennati, Evangelos Pournaras", "title": "Privacy-enhancing Aggregation of Internet of Things Data via Sensors\n  Grouping", "comments": null, "journal-ref": null, "doi": "10.1016/j.scs.2018.02.013", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data collection practices using Internet of Things (IoT) pervasive\ntechnologies are often privacy-intrusive and result in surveillance, profiling,\nand discriminatory actions over citizens that in turn undermine the\nparticipation of citizens to the development of sustainable smart cities.\nNevertheless, real-time data analytics and aggregate information from IoT\ndevices open up tremendous opportunities for managing smart city\ninfrastructures. The privacy-enhancing aggregation of distributed sensor data,\nsuch as residential energy consumption or traffic information, is the research\nfocus of this paper. Citizens have the option to choose their privacy level by\nreducing the quality of the shared data at a cost of a lower accuracy in data\nanalytics services. A baseline scenario is considered in which IoT sensor data\nare shared directly with an untrustworthy central aggregator. A grouping\nmechanism is introduced that improves privacy by sharing data aggregated first\nat a group level compared as opposed to sharing data directly to the central\naggregator. Group-level aggregation obfuscates sensor data of individuals, in a\nsimilar fashion as differential privacy and homomorphic encryption schemes,\nthus inference of privacy-sensitive information from single sensors becomes\ncomputationally harder compared to the baseline scenario. The proposed system\nis evaluated using real-world data from two smart city pilot projects. Privacy\nunder grouping increases, while preserving the accuracy of the baseline\nscenario. Intra-group influences of privacy by one group member on the other\nones are measured and fairness on privacy is found to be maximized between\ngroup members with similar privacy choices. Several grouping strategies are\ncompared. Grouping by proximity of privacy choices provides the highest privacy\ngains. The implications of the strategy on the design of incentives mechanisms\nare discussed.\n", "versions": [{"version": "v1", "created": "Tue, 28 Feb 2017 15:14:24 GMT"}, {"version": "v2", "created": "Wed, 16 Aug 2017 09:56:58 GMT"}, {"version": "v3", "created": "Sun, 24 Dec 2017 11:27:47 GMT"}, {"version": "v4", "created": "Thu, 1 Mar 2018 10:34:01 GMT"}], "update_date": "2018-05-24", "authors_parsed": [["Bennati", "Stefano", ""], ["Pournaras", "Evangelos", ""]]}]