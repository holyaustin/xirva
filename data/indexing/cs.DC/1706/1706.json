[{"id": "1706.00095", "submitter": "Janis Keuper", "authors": "Martin Kuehn, Janis Keuper and Franz-Josef Pfreundt", "title": "Using GPI-2 for Distributed Memory Paralleliziation of the Caffe Toolbox\n  to Speed up Deep Neural Network Training", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Deep Neural Network (DNN) are currently of great inter- est in research and\napplication. The training of these net- works is a compute intensive and time\nconsuming task. To reduce training times to a bearable amount at reasonable\ncost we extend the popular Caffe toolbox for DNN with an efficient distributed\nmemory communication pattern. To achieve good scalability we emphasize the\noverlap of computation and communication and prefer fine granu- lar\nsynchronization patterns over global barriers. To im- plement these\ncommunication patterns we rely on the the Global address space Programming\nInterface version 2 (GPI-2) communication library. This interface provides a\nlight-weight set of asynchronous one-sided communica- tion primitives\nsupplemented by non-blocking fine gran- ular data synchronization mechanisms.\nTherefore, Caf- feGPI is the name of our parallel version of Caffe. First\nbenchmarks demonstrate better scaling behavior com- pared with other\nextensions, e.g., the Intel TM Caffe. Even within a single symmetric\nmultiprocessing machine with four graphics processing units, the CaffeGPI\nscales bet- ter than the standard Caffe toolbox. These first results\ndemonstrate that the use of standard High Performance Computing (HPC) hardware\nis a valid cost saving ap- proach to train large DDNs. I/O is an other\nbottleneck to work with DDNs in a standard parallel HPC setting, which we will\nconsider in more detail in a forthcoming paper.\n", "versions": [{"version": "v1", "created": "Wed, 31 May 2017 21:20:16 GMT"}, {"version": "v2", "created": "Fri, 18 Aug 2017 12:24:45 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Kuehn", "Martin", ""], ["Keuper", "Janis", ""], ["Pfreundt", "Franz-Josef", ""]]}, {"id": "1706.00266", "submitter": "Andrew Mironov", "authors": "Andrew M. Mironov", "title": "A graph model of message passing processes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the paper we consider a graph model of message passing processes and\npresent a method verification of message passing processes. The method is\nillustrated by an example of a verification of sliding window protocol.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 12:23:56 GMT"}], "update_date": "2017-06-02", "authors_parsed": [["Mironov", "Andrew M.", ""]]}, {"id": "1706.00517", "submitter": "Ardavan Pedram", "authors": "Yuanfang Li and Ardavan Pedram", "title": "CATERPILLAR: Coarse Grain Reconfigurable Architecture for Accelerating\n  the Training of Deep Neural Networks", "comments": "ASAP 2017: The 28th Annual IEEE International Conference on\n  Application-specific Systems, Architectures and Processors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Accelerating the inference of a trained DNN is a well studied subject. In\nthis paper we switch the focus to the training of DNNs. The training phase is\ncompute intensive, demands complicated data communication, and contains\nmultiple levels of data dependencies and parallelism. This paper presents an\nalgorithm/architecture space exploration of efficient accelerators to achieve\nbetter network convergence rates and higher energy efficiency for training\nDNNs. We further demonstrate that an architecture with hierarchical support for\ncollective communication semantics provides flexibility in training various\nnetworks performing both stochastic and batched gradient descent based\ntechniques. Our results suggest that smaller networks favor non-batched\ntechniques while performance for larger networks is higher using batched\noperations. At 45nm technology, CATERPILLAR achieves performance efficiencies\nof 177 GFLOPS/W at over 80% utilization for SGD training on small networks and\n211 GFLOPS/W at over 90% utilization for pipelined SGD/CP training on larger\nnetworks using a total area of 103.2 mm$^2$ and 178.9 mm$^2$ respectively.\n", "versions": [{"version": "v1", "created": "Thu, 1 Jun 2017 22:58:37 GMT"}, {"version": "v2", "created": "Thu, 8 Jun 2017 15:30:54 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Li", "Yuanfang", ""], ["Pedram", "Ardavan", ""]]}, {"id": "1706.00878", "submitter": "Qingqing Cao", "authors": "Qingqing Cao, Niranjan Balasubramanian, Aruna Balasubramanian", "title": "MobiRNN: Efficient Recurrent Neural Network Execution on Mobile GPU", "comments": "Published at 1st International Workshop on Embedded and Mobile Deep\n  Learning colocated with MobiSys 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper, we explore optimizations to run Recurrent Neural Network (RNN)\nmodels locally on mobile devices. RNN models are widely used for Natural\nLanguage Processing, Machine Translation, and other tasks. However, existing\nmobile applications that use RNN models do so on the cloud. To address privacy\nand efficiency concerns, we show how RNN models can be run locally on mobile\ndevices. Existing work on porting deep learning models to mobile devices focus\non Convolution Neural Networks (CNNs) and cannot be applied directly to RNN\nmodels. In response, we present MobiRNN, a mobile-specific optimization\nframework that implements GPU offloading specifically for mobile GPUs.\nEvaluations using an RNN model for activity recognition shows that MobiRNN does\nsignificantly decrease the latency of running RNN models on phones.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jun 2017 00:48:12 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Cao", "Qingqing", ""], ["Balasubramanian", "Niranjan", ""], ["Balasubramanian", "Aruna", ""]]}, {"id": "1706.00955", "submitter": "Marcel Rieger", "authors": "Marcel Rieger, Martin Erdmann, Benjamin Fischer, Robert Fischer", "title": "Design and Execution of make-like, distributed Analyses based on\n  Spotify's Pipelining Package Luigi", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.data-an cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In high-energy particle physics, workflow management systems are primarily\nused as tailored solutions in dedicated areas such as Monte Carlo production.\nHowever, physicists performing data analyses are usually required to steer\ntheir individual workflows manually which is time-consuming and often leads to\nundocumented relations between particular workloads. We present a generic\nanalysis design pattern that copes with the sophisticated demands of end-to-end\nHEP analyses and provides a make-like execution system. It is based on the\nopen-source pipelining package Luigi which was developed at Spotify and enables\nthe definition of arbitrary workloads, so-called Tasks, and the dependencies\nbetween them in a lightweight and scalable structure. Further features are\nmulti-user support, automated dependency resolution and error handling, central\nscheduling, and status visualization in the web. In addition to already\nbuilt-in features for remote jobs and file systems like Hadoop and HDFS, we\nadded support for WLCG infrastructure such as LSF and CREAM job submission, as\nwell as remote file access through the Grid File Access Library. Furthermore,\nwe implemented automated resubmission functionality, software sandboxing, and a\ncommand line interface with auto-completion for a convenient working\nenvironment. For the implementation of a $t\\bar{t}H$ cross section measurement,\nwe created a generic Python interface that provides programmatic access to all\nexternal information such as datasets, physics processes, statistical models,\nand additional files and values. In summary, the setup enables the execution of\nthe entire analysis in a parallelized and distributed fashion with a single\ncommand.\n", "versions": [{"version": "v1", "created": "Sat, 3 Jun 2017 13:58:41 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Rieger", "Marcel", ""], ["Erdmann", "Martin", ""], ["Fischer", "Benjamin", ""], ["Fischer", "Robert", ""]]}, {"id": "1706.01022", "submitter": "Zhengwei Ren", "authors": "Zhengwei Ren, Ying Chen, Shaowei Huang, Shuang Sheng, Huiping Zheng,\n  Xinyuan Liu", "title": "Distributed Contingency Analysis over Wide Area Network among Dispatch\n  Centers", "comments": "5 pages, 6 figures, 2017 IEEE PES General Meeting", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditionally, a regional dispatch center uses the equivalent method to deal\nwith external grids, which fails to reflect the interactions among regions.\nThis paper proposes a distributed N-1 contingency analysis (DCA) solution,\nwhere dispatch centers join a coordinated computation using their private data\nand computing resources. A distributed screening method is presented to\ndetermine the Critical Contingency Set (DCCS) in DCA. Then, the distributed\npower flow is formulated as a set of boundary equations, which is solved by a\nJacobi-Free Newton-GMRES (JFNG) method. During solving the distributed power\nflow, only boundary conditions are exchanged. Acceleration techniques are also\nintroduced, including reusing preconditioners and optimal resource scheduling\nduring parallel processing of multiple contingencies. The proposed method is\nimplemented on a real EMS platform, where tests using the Southwest Regional\nGrid of China are carried out to validate its feasibility.\n", "versions": [{"version": "v1", "created": "Sun, 4 Jun 2017 03:34:18 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Ren", "Zhengwei", ""], ["Chen", "Ying", ""], ["Huang", "Shaowei", ""], ["Sheng", "Shuang", ""], ["Zheng", "Huiping", ""], ["Liu", "Xinyuan", ""]]}, {"id": "1706.01382", "submitter": "Cameron Musco", "authors": "Nancy Lynch, Cameron Musco, Merav Parter", "title": "Neuro-RAM Unit with Applications to Similarity Testing and Compression\n  in Spiking Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.DS q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study distributed algorithms implemented in a simplified biologically\ninspired model for stochastic spiking neural networks. We focus on tradeoffs\nbetween computation time and network complexity, along with the role of\nrandomness in efficient neural computation.\n  It is widely accepted that neural computation is inherently stochastic. In\nrecent work, we explored how this stochasticity could be leveraged to solve the\n`winner-take-all' leader election task. Here, we focus on using randomness in\nneural algorithms for similarity testing and compression. In the most basic\nsetting, given two $n$-length patterns of firing neurons, we wish to\ndistinguish if the patterns are equal or $\\epsilon$-far from equal.\n  Randomization allows us to solve this task with a very compact network, using\n$O \\left (\\frac{\\sqrt{n}\\log n}{\\epsilon}\\right)$ auxiliary neurons, which is\nsublinear in the input size. At the heart of our solution is the design of a\n$t$-round neural random access memory, or indexing network, which we call a\nneuro-RAM. This module can be implemented with $O(n/t)$ auxiliary neurons and\nis useful in many applications beyond similarity testing.\n  Using a VC dimension-based argument, we show that the tradeoff between\nruntime and network size in our neuro-RAM is nearly optimal. Our result has\nseveral implications -- since our neuro-RAM can be implemented with\ndeterministic threshold gates, it shows that, in contrast to similarity\ntesting, randomness does not provide significant computational advantages for\nthis problem. It also establishes a separation between feedforward networks\nwhose gates spike with sigmoidal probability functions, and well-studied\ndeterministic sigmoidal networks, whose gates output real number sigmoidal\nvalues, and which can implement a neuro-RAM much more efficiently.\n", "versions": [{"version": "v1", "created": "Mon, 5 Jun 2017 15:43:40 GMT"}, {"version": "v2", "created": "Mon, 21 Aug 2017 17:34:32 GMT"}], "update_date": "2017-08-22", "authors_parsed": [["Lynch", "Nancy", ""], ["Musco", "Cameron", ""], ["Parter", "Merav", ""]]}, {"id": "1706.01730", "submitter": "Benoit Darties", "authors": "Axel Moinet and Beno\\^it Darties and Jean-Luc Baril", "title": "Blockchain based trust & authentication for decentralized sensor\n  networks", "comments": "6 pages, double-column. Preprint version submitted to IEEE Security &\n  Privacy, Special Issue on Blockchain", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sensor networks and Wireless Sensor Networks (WSN) are key components for the\ndevelopment of the Internet of Things. These networks are subject of two kinds\nof constraints. Adaptability by the mean of mutability and evolutivity, and\nconstrained node resources such as energy consumption, computational complexity\nor memory usage. In this context, none of the existing protocols and models\nallows reliable peer authentication and trust level management. In the field of\nvirtual economic transactions, Bitcoin has proposed a new decentralized and\nevolutive way to model and acknowledge trust and data validity in a peer\nnetwork by the mean of the blockchain. We propose a new security model and its\nprotocol based on the blockchain technology to ensure validity and integrity of\ncryptographic authentication data and associate peer trust level, from the\nbeginning to the end of the sensor network lifetime.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 12:30:28 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["Moinet", "Axel", ""], ["Darties", "Beno\u00eet", ""], ["Baril", "Jean-Luc", ""]]}, {"id": "1706.01762", "submitter": "Klaus-Dieter Schewe", "authors": "Egon B\\\"orger, Klaus-Dieter Schewe", "title": "Specifying Transaction Control to Serialize Concurrent Program\n  Executions", "comments": "14 pages, 1 figure", "journal-ref": "LNCS, vol. 8477, Springer 2014, pp. 142-157", "doi": "10.1007/978-3-662-43652-3_13", "report-no": null, "categories": "cs.DB cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a programming language independent transaction controller and an\noperator which when applied to concurrent programs with shared locations turns\ntheir behavior with respect to some abstract termination criterion into a\ntransactional behavior. We prove the correctness property that concurrent runs\nunder the transaction controller are serialisable. We specify the transaction\ncontroller TaCtl and the operator TA in terms of Abstract State Machines. This\nmakes TaCtl applicable to a wide range of programs and in particular provides\nthe possibility to use it as a plug-in when specifying concurrent system\ncomponents in terms of Abstract State Machines.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 13:43:08 GMT"}], "update_date": "2017-06-07", "authors_parsed": [["B\u00f6rger", "Egon", ""], ["Schewe", "Klaus-Dieter", ""]]}, {"id": "1706.02086", "submitter": "Christian M. Fuchs", "authors": "Christian M. Fuchs, Todor Stefanov, Nadia Murillo, and Aske Plaat", "title": "Preliminary Performance Estimations and Benchmark Results for a\n  Software-based Fault-Tolerance Approach aboard Miniaturized Satellite\n  Computers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern embedded technology is a driving factor in satellite miniaturization,\ncontributing to a massive boom in satellite launches and a rapidly evolving new\nspace industry. Miniaturized satellites however suffer from low reliability, as\ntraditional hardware-based fault-tolerance (FT) concepts are ineffective for\non-board computers (OBCs) utilizing modern systems-on-a-chip (SoC). Larger\nsatellites therefore continue to rely on proven processors with large feature\nsizes. Software-based concepts have largely been ignored by the space industry\nas they were researched only in theory, and have not yet reached the level of\nmaturity necessary for implementation. In related work, we presented the first\nintegral, real-world solution to enable fault-tolerant general-purpose\ncomputing with modern multiprocessor-SoCs (MPSoCs) for spaceflight, thereby\nenabling their use in future high-priority space missions. The presented\nmulti-stage approach consists of three FT stages, combining coarse-grained\nthread-level distributed self-validation, FPGA reconfiguration, and mixed\ncriticality to assure long-term FT and excellent scalability for both resource\nconstrained and critical high-priority space missions. As part of the ongoing\nimplementation effort towards a hardware prototype, several software\nimplementations were achieved and tested. This document contains an outline of\nthe conducted tests, performance evaluation results, and supplementary\ninformation not included in the actual paper. It is being continuously expanded\nand updated.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 08:30:46 GMT"}, {"version": "v2", "created": "Sun, 23 Jul 2017 01:16:01 GMT"}], "update_date": "2017-07-25", "authors_parsed": [["Fuchs", "Christian M.", ""], ["Stefanov", "Todor", ""], ["Murillo", "Nadia", ""], ["Plaat", "Aske", ""]]}, {"id": "1706.02113", "submitter": "Minxian Xu", "authors": "Minxian Xu and Rajkumar Buyya", "title": "Energy Efficient Scheduling of Application Components via Brownout and\n  Approximate Markov Decision Process", "comments": "In the proceedings of 15th International Conference on\n  Service-Oriented Computing (ICSOC'2017) 15 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Unexpected loads in Cloud data centers may trigger overloaded situation and\nperformance degradation. To guarantee system performance, cloud computing\nenvironment is required to have the ability to handle overloads. The existing\napproaches, like Dynamic Voltage Frequency Scaling and VM consolidation, are\neffective in handling partial overloads, however, they cannot function when the\nwhole data center is overloaded. Brownout has been proved to be a promising\napproach to relieve the overloads through deactivating application\nnon-mandatory components or microservices temporarily. Moreover, brownout has\nbeen applied to reduce data center energy consumption. It shows that there are\ntrade-offs between energy saving and discount offered to users (revenue loss)\nwhen one or more services are not provided temporarily. In this paper, we\npropose a brownout-based approximate Markov Decision Process approach to\nimprove the aforementioned trade-offs. The results based on real trace\ndemonstrate that our approach saves 20% energy consumption than VM\nconsolidation approach. Compared with existing energy-efficient brownout\napproach, our approach reduces the discount amount given to users while saving\nsimilar energy consumption.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 10:19:13 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 00:11:15 GMT"}, {"version": "v3", "created": "Sat, 29 Jul 2017 18:31:20 GMT"}], "update_date": "2017-08-01", "authors_parsed": [["Xu", "Minxian", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1706.02149", "submitter": "Yoji Yamato", "authors": "Yoji Yamato", "title": "Experiments of posture estimation on vehicles using wearable\n  acceleration sensors", "comments": "4 pages, 4 figures, The 3rd IEEE International Conference on Big Data\n  Security on Cloud (BigDataSecurity 2017), pp.14-17, Beijing, May 2017", "journal-ref": "The 3rd IEEE International Conference on Big Data Security on\n  Cloud (BigDataSecurity 2017), pp.14-17, May 2017. (c) 2017\n  BigDataSecurity2017", "doi": null, "report-no": null, "categories": "cs.HC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study methods to estimate drivers' posture in vehicles\nusing acceleration data of wearable sensor and conduct a field test. Recently,\nsensor technologies have been progressed. Solutions of safety management to\nanalyze vital data acquired from wearable sensor and judge work status are\nproposed. To prevent huge accidents, demands for safety management of bus and\ntaxi are high. However, acceleration of vehicles is added to wearable sensor in\nvehicles, and there is no guarantee to estimate drivers' posture accurately.\nTherefore, in this paper, we study methods to estimate driving posture using\nacceleration data acquired from T-shirt type wearable sensor hitoe, conduct\nfield tests and implement a sample application.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 05:48:11 GMT"}, {"version": "v2", "created": "Tue, 20 Jun 2017 04:16:07 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Yamato", "Yoji", ""]]}, {"id": "1706.02248", "submitter": "Yuri G. Gordienko", "authors": "Yuriy Kochura, Sergii Stirenko, Anis Rojbi, Oleg Alienin, Michail\n  Novotarskiy, and Yuri Gordienko", "title": "Comparative Analysis of Open Source Frameworks for Machine Learning with\n  Use Case in Single-Threaded and Multi-Threaded Modes", "comments": "4 pages, 6 figures, 4 tables; XIIth International Scientific and\n  Technical Conference on Computer Sciences and Information Technologies (CSIT\n  2017), Lviv, Ukraine", "journal-ref": "Proceedings of 12th International Scientific and Technical\n  Conference on Computer Sciences and Information Technologies (CSIT), 5-8\n  Sept. 2017, (Lviv, Ukraine), vol.1, pp. 373-376, IEEE", "doi": "10.1109/STC-CSIT.2017.8098808", "report-no": null, "categories": "cs.LG cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The basic features of some of the most versatile and popular open source\nframeworks for machine learning (TensorFlow, Deep Learning4j, and H2O) are\nconsidered and compared. Their comparative analysis was performed and\nconclusions were made as to the advantages and disadvantages of these\nplatforms. The performance tests for the de facto standard MNIST data set were\ncarried out on H2O framework for deep learning algorithms designed for CPU and\nGPU platforms for single-threaded and multithreaded modes of operation.\n", "versions": [{"version": "v1", "created": "Wed, 7 Jun 2017 16:41:21 GMT"}], "update_date": "2017-11-30", "authors_parsed": [["Kochura", "Yuriy", ""], ["Stirenko", "Sergii", ""], ["Rojbi", "Anis", ""], ["Alienin", "Oleg", ""], ["Novotarskiy", "Michail", ""], ["Gordienko", "Yuri", ""]]}, {"id": "1706.02474", "submitter": "Alfredo Navarra", "authors": "Serafino Cicerone, Gabriele Di Stefano, Alfredo Navarra", "title": "Asynchronous Arbitrary Pattern Formation: the effects of a rigorous\n  approach", "comments": "To appear in Distributed Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given any multiset F of points in the Euclidean plane and a set R of robots\nsuch that |R|=|F|, the Arbitrary Pattern Formation (APF) problem asks for a\ndistributed algorithm that moves robots so as to reach a configuration similar\nto F. Similarity means that robots must be disposed as F regardless of\ntranslations, rotations, reflections, uniform scalings. Initially, each robot\noccupies a distinct position. When active, a robot operates in standard LCM\ncycles. Robots are asynchronous, oblivious, anonymous, silent and execute the\nsame distributed algorithm. So far, the problem has been mainly addressed by\nassuming chirality, that is robots share a common left-right orientation. We\nare interested in removing such a restriction. While working on the subject, we\nfaced several issues that required close attention. We deeply investigated how\nsuch difficulties were overcome in the literature, revealing that crucial\narguments for the correctness proof of the existing algorithms have been\nneglected. The systematic lack of rigorous arguments with respect to necessary\nconditions required for providing correctness proofs deeply affects the\nvalidity as well as the relevance of strategies proposed in the literature.\nHere we design a new deterministic distributed algorithm that fully\ncharacterizes APF showing its equivalence with the well-known Leader Election\nproblem in the asynchronous model without chirality. Our approach is\ncharacterized by the use of logical predicates in order to formally describe\nour algorithm as well as its correctness. In addition to the relevance of our\nachievements, our techniques might help in revising previous results. In fact,\nit comes out that well-established results like [Fujinaga et al, SIAM J. Comp.\n44(3) 2015], more recent approaches like [Bramas et al, PODC and SSS 2016] and\n'unofficial' results like [Dieudonne et al, arXiv:0902.2851] revealed to be not\ncorrect.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 08:26:10 GMT"}, {"version": "v2", "created": "Tue, 6 Feb 2018 15:38:15 GMT"}], "update_date": "2018-02-07", "authors_parsed": [["Cicerone", "Serafino", ""], ["Di Stefano", "Gabriele", ""], ["Navarra", "Alfredo", ""]]}, {"id": "1706.02540", "submitter": "Guodong Shi", "authors": "Yang Liu, Bo Li, Brian Anderson, Guodong Shi", "title": "Clique Gossiping", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes and investigates a framework for clique gossip protocols.\nAs complete subnetworks, the existence of cliques is ubiquitous in various\nsocial, computer, and engineering networks. By clique gossiping, nodes interact\nwith each other along a sequence of cliques. Clique-gossip protocols are\ndefined as arbitrary linear node interactions where node states are vectors\nevolving as linear dynamical systems. Such protocols become clique-gossip\naveraging algorithms when node states are scalars under averaging rules. We\ngeneralize the classical notion of line graph to capture the essential node\ninteraction structure induced by both the underlying network and the specific\nclique sequence. We prove a fundamental eigenvalue invariance principle for\nperiodic clique-gossip protocols, which implies that any permutation of the\nclique sequence leads to the same spectrum for the overall state transition\nwhen the generalized line graph contains no cycle. We also prove that for a\nnetwork with $n$ nodes, cliques with smaller sizes determined by factors of $n$\ncan always be constructed leading to finite-time convergent clique-gossip\naveraging algorithms, provided $n$ is not a prime number. Particularly, such\nfinite-time convergence can be achieved with cliques of equal size $m$ if and\nonly if $n$ is divisible by $m$ and they have exactly the same prime factors. A\nproven fastest finite-time convergent clique-gossip algorithm is constructed\nfor clique-gossiping using size-$m$ cliques. Additionally, the acceleration\neffects of clique-gossiping are illustrated via numerical examples.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 12:20:25 GMT"}], "update_date": "2017-06-09", "authors_parsed": [["Liu", "Yang", ""], ["Li", "Bo", ""], ["Anderson", "Brian", ""], ["Shi", "Guodong", ""]]}, {"id": "1706.02557", "submitter": "Yoji Yamato", "authors": "Yoji Yamato", "title": "Study of Vital Data Analysis Platform Using Wearable Sensor", "comments": "5 pages, 2 figures, IEICE Technical Report, SC2016-34, Mar. 2017.\n  arXiv admin note: substantial text overlap with arXiv:1704.05573", "journal-ref": "IEICE Technical Report, SC2016-34, Mar. 2017. (c) 2017 IEICE", "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a vital data analysis platform which resolves\nexisting problems to utilize vital data for real-time actions. Recently, IoT\ntechnologies have been progressed but in the healthcare area, real-time actions\nbased on analyzed vital data are not considered sufficiently yet. The causes\nare proper use of analyzing methods of stream / micro batch processing and\nnetwork cost. To resolve existing problems, we propose our vital data analysis\nplatform. Our platform collects vital data of Electrocardiograph and\nacceleration using an example of wearable vital sensor and analyzes them to\nextract posture, fatigue and relaxation in smart phones or cloud. Our platform\ncan show analyzed dangerous posture or fatigue level change. We implemented the\nplatform and we are now preparing a field test.\n", "versions": [{"version": "v1", "created": "Tue, 6 Jun 2017 23:37:07 GMT"}], "update_date": "2018-09-17", "authors_parsed": [["Yamato", "Yoji", ""]]}, {"id": "1706.02677", "submitter": "Ross Girshick", "authors": "Priya Goyal, Piotr Doll\\'ar, Ross Girshick, Pieter Noordhuis, Lukasz\n  Wesolowski, Aapo Kyrola, Andrew Tulloch, Yangqing Jia, Kaiming He", "title": "Accurate, Large Minibatch SGD: Training ImageNet in 1 Hour", "comments": "Tech report (v2: correct typos)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CV cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning thrives with large neural networks and large datasets. However,\nlarger networks and larger datasets result in longer training times that impede\nresearch and development progress. Distributed synchronous SGD offers a\npotential solution to this problem by dividing SGD minibatches over a pool of\nparallel workers. Yet to make this scheme efficient, the per-worker workload\nmust be large, which implies nontrivial growth in the SGD minibatch size. In\nthis paper, we empirically show that on the ImageNet dataset large minibatches\ncause optimization difficulties, but when these are addressed the trained\nnetworks exhibit good generalization. Specifically, we show no loss of accuracy\nwhen training with large minibatch sizes up to 8192 images. To achieve this\nresult, we adopt a hyper-parameter-free linear scaling rule for adjusting\nlearning rates as a function of minibatch size and develop a new warmup scheme\nthat overcomes optimization challenges early in training. With these simple\ntechniques, our Caffe2-based system trains ResNet-50 with a minibatch size of\n8192 on 256 GPUs in one hour, while matching small minibatch accuracy. Using\ncommodity hardware, our implementation achieves ~90% scaling efficiency when\nmoving from 8 to 256 GPUs. Our findings enable training visual recognition\nmodels on internet-scale data with high efficiency.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 16:51:53 GMT"}, {"version": "v2", "created": "Mon, 30 Apr 2018 21:53:41 GMT"}], "update_date": "2018-05-02", "authors_parsed": [["Goyal", "Priya", ""], ["Doll\u00e1r", "Piotr", ""], ["Girshick", "Ross", ""], ["Noordhuis", "Pieter", ""], ["Wesolowski", "Lukasz", ""], ["Kyrola", "Aapo", ""], ["Tulloch", "Andrew", ""], ["Jia", "Yangqing", ""], ["He", "Kaiming", ""]]}, {"id": "1706.02785", "submitter": "Ophir Lojkine", "authors": "Ophir Lojkine", "title": "Optimal parameters for bloom-filtered joins in Spark", "comments": "The article is in Russian, but an analysis of the data used in it is\n  available in english at the following address:\n  https://github.com/lovasoa/spark-bloomfiltered-join-analysis/blob/master/analysis.ipynb", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  In this paper, we present an algorithm that joins relational database tables\nefficiently in a distributed environment using Bloom filters of an optimal\nsize. We propose not to use fixed-size bloom filters as in previous research,\nbut to find an optimal size for the bloom filters, by creating a mathematical\nmodel of the join algorithm, and then finding the optimal parameters using\ntraditional mathematical optimization.\n  This algorithm with optimal parameters beats both previous approaches using\nbloom filters and the default SparkSQL engine not only on star-joins, but also\non traditional database schema. The experiments were conducted on a standard\nTPC-H database stored as parquet files on a distributed file system.\n", "versions": [{"version": "v1", "created": "Thu, 8 Jun 2017 22:29:41 GMT"}, {"version": "v2", "created": "Mon, 12 Jun 2017 12:49:15 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Lojkine", "Ophir", ""]]}, {"id": "1706.02970", "submitter": "Nicolas Offermans", "authors": "Nicolas Offermans, Oana Marin, Michel Schanen, Jing Gong, Paul\n  Fischer, Philipp Schlatter, Aleks Obabko, Adam Peplinksi, Maxwell Hutchinson,\n  Elia Merzari", "title": "On the Strong Scaling of the Spectral Element Solver Nek5000 on\n  Petascale Systems", "comments": "10 pages, 9 figures, Proceedings of the Exascale Applications and\n  Software Conference 2016 (EASC '16, Stockholm)", "journal-ref": null, "doi": "10.1145/2938615.2938617", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The present work is targeted at performing a strong scaling study of the\nhigh-order spectral element fluid dynamics solver Nek5000. Prior studies\nindicated a recommendable metric for strong scalability from a theoretical\nviewpoint, which we test here extensively on three parallel machines with\ndifferent performance characteristics and interconnect networks, namely Mira\n(IBM Blue Gene/Q), Beskow (Cray XC40) and Titan (Cray XK7). The test cases\nconsidered for the simulations correspond to a turbulent flow in a straight\npipe at four different friction Reynolds numbers $Re_{\\tau}$ = 180, 360, 550\nand 1000. Considering the linear model for parallel communication we quantify\nthe machine characteristics in order to better assess the scaling behaviors of\nthe code. Subsequently sampling and profiling tools are used to measure the\ncomputation and communication times over a large range of compute cores. We\nalso study the effect of the two coarse grid solvers XXT and AMG on the\ncomputational time. Super-linear scaling due to a reduction in cache misses is\nobserved on each computer. The strong scaling limit is attained for roughly\n5000 - 10,000 degrees of freedom per core on Mira, 30,000 - 50,0000 on Beskow,\nwith only a small impact of the problem size for both machines, and ranges\nbetween 10,000 and 220,000 depending on the problem size on Titan. This work\naims at being a reference for Nek5000 users and also serves as a basis for\npotential issues to address as the community heads towards exascale\nsupercomputers.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 14:27:48 GMT"}], "update_date": "2017-06-12", "authors_parsed": [["Offermans", "Nicolas", ""], ["Marin", "Oana", ""], ["Schanen", "Michel", ""], ["Gong", "Jing", ""], ["Fischer", "Paul", ""], ["Schlatter", "Philipp", ""], ["Obabko", "Aleks", ""], ["Peplinksi", "Adam", ""], ["Hutchinson", "Maxwell", ""], ["Merzari", "Elia", ""]]}, {"id": "1706.03105", "submitter": "Haisheng Xu", "authors": "Haisheng Xu, Chen Gong, Haipeng Yao and Xiaodong Wang", "title": "LEOS-assisted Inter-GEOS Communication via Distributed-storage Coding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a space communication network consisting of Geosynchronous Earth\nOrbit satellites (GEOSs) and Low Earth Orbit satellites (LEOSs). In case of no\ndirect communication link between two GEOSs, the data exchange between them is\nthrough relay by the LEOSs. In particular, the source GEOS sends coded data to\nmultiple LEOSs based on the distributed storage framework. The destination GEOS\nthen retrieves certain amount of data from each LEOS for data reconstruction.\nFor the GEOS-LEOS downlink, a regenerating-code-based transmission scheme is\noptimized to guarantee data reconstructability, where the transmission power\nallocation to the LEOSs is proposed to minimize the total transmission energy.\nWe also consider the power allocation to minimize the total transmission time\ngiven the total transmission energy. For the LEOS-GEOS uplink, a flexible\npartial-downloading coding transmission scheme is proposed to guarantee data\nreconstructability, where the joint uploaded-data size and power allocations\nare proposed to minimize the total transmission energy or the total\ntransmission time. Extensive simulation results are presented to evaluate the\nproposed algorithms and show that regenerating code can achieve lower\ntransmission energy and shorter transmission time for data regeneration than\nconventional maximum-distance separable (MDS) code.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 20:00:23 GMT"}, {"version": "v2", "created": "Mon, 23 Jul 2018 15:47:51 GMT"}], "update_date": "2018-07-25", "authors_parsed": [["Xu", "Haisheng", ""], ["Gong", "Chen", ""], ["Yao", "Haipeng", ""], ["Wang", "Xiaodong", ""]]}, {"id": "1706.03107", "submitter": "Pedro Montealegre", "authors": "Pedro Montealegre, Sebastian Perez-Salazar, Ivan Rapaport, Ioan\n  Todinca", "title": "Graph Reconstruction in the Congested Clique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The congested clique model is a message-passing model of distributed\ncomputation where the underlying communication network is the complete graph of\n$n$ nodes. In this paper we consider the situation where the joint input to the\nnodes is an $n$-node labeled graph $G$, i.e., the local input received by each\nnode is the indicator function of its neighborhood in $G$. Nodes execute an\nalgorithm, communicating with each other in synchronous rounds and their goal\nis to compute some function that depends on $G$. In every round, each of the\n$n$ nodes may send up to $n-1$ different $b$-bit messages through each of its\n$n-1$ communication links. We denote by $R$ the number of rounds of the\nalgorithm. The product $Rb$, that is, the total number of bits received by a\nnode through one link, is the cost of the algorithm.\n  The most difficult problem we could attempt to solve is the reconstruction\nproblem, where nodes are asked to recover all the edges of the input graph $G$.\nFormally, given a class of graphs $\\mathcal G$, the problem is defined as\nfollows: if $G \\notin {\\mathcal G}$, then every node must reject; on the other\nhand, if $G \\in {\\mathcal G}$, then every node must end up, after the $R$\nrounds, knowing all the edges of $G$. It is not difficult to see that the cost\n$Rb$ of any algorithm that solves this problem (even with public coins) is at\nleast $\\Omega(\\log|\\mathcal{G}_n|/n)$, where $\\mathcal{G}_n$ is the subclass of\nall $n$-node labeled graphs in $\\mathcal G$. In this paper we prove that\nprevious bound is tight and that it is possible to achieve it with only $R=2$\nrounds. More precisely, we exhibit (i) a one-round algorithm that achieves this\nbound for hereditary graph classes; and (ii) a two-round algorithm that\nachieves this bound for arbitrary graph classes.\n", "versions": [{"version": "v1", "created": "Fri, 9 Jun 2017 20:00:32 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Montealegre", "Pedro", ""], ["Perez-Salazar", "Sebastian", ""], ["Rapaport", "Ivan", ""], ["Todinca", "Ioan", ""]]}, {"id": "1706.03178", "submitter": "Vatche Ishakian", "authors": "Ioana Baldini, Paul Castro, Kerry Chang, Perry Cheng, Stephen Fink,\n  Vatche Ishakian, Nick Mitchell, Vinod Muthusamy, Rodric Rabbah, Aleksander\n  Slominski, Philippe Suter", "title": "Serverless Computing: Current Trends and Open Problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serverless computing has emerged as a new compelling paradigm for the\ndeployment of applications and services. It represents an evolution of cloud\nprogramming models, abstractions, and platforms, and is a testament to the\nmaturity and wide adoption of cloud technologies. In this chapter, we survey\nexisting serverless platforms from industry, academia, and open source\nprojects, identify key characteristics and use cases, and describe technical\nchallenges and open problems.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 04:00:41 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Baldini", "Ioana", ""], ["Castro", "Paul", ""], ["Chang", "Kerry", ""], ["Cheng", "Perry", ""], ["Fink", "Stephen", ""], ["Ishakian", "Vatche", ""], ["Mitchell", "Nick", ""], ["Muthusamy", "Vinod", ""], ["Rabbah", "Rodric", ""], ["Slominski", "Aleksander", ""], ["Suter", "Philippe", ""]]}, {"id": "1706.03184", "submitter": "Warut Suksompong", "authors": "Charles E. Leiserson, Tao B. Schardl, Warut Suksompong", "title": "Upper Bounds on Number of Steals in Rooted Trees", "comments": "18 pages, 5 figures", "journal-ref": "Theory of Computing Systems, 58(2):223-240 (2016)", "doi": "10.1007/s00224-015-9613-9", "report-no": null, "categories": "cs.DC cs.DM cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Inspired by applications in parallel computing, we analyze the setting of\nwork stealing in multithreaded computations. We obtain tight upper bounds on\nthe number of steals when the computation can be modeled by rooted trees. In\nparticular, we show that if the computation with $n$ processors starts with one\nprocessor having a complete $k$-ary tree of height $h$ (and the remaining $n-1$\nprocessors having nothing), the maximum possible number of steals is\n$\\sum_{i=1}^n(k-1)^i\\binom{h}{i}$.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 05:38:20 GMT"}, {"version": "v2", "created": "Thu, 15 Jun 2017 16:28:29 GMT"}], "update_date": "2018-04-19", "authors_parsed": [["Leiserson", "Charles E.", ""], ["Schardl", "Tao B.", ""], ["Suksompong", "Warut", ""]]}, {"id": "1706.03254", "submitter": "Yuu Jinnai", "authors": "Yuu Jinnai, Alex Fukunaga", "title": "On Hash-Based Work Distribution Methods for Parallel Best-First Search", "comments": "Source code of domain-specific solvers in multicore environment:\n  https://github.com/jinnaiyuu/Parallel-Best-First-Searches Source code of\n  classical planning in distributed environment:\n  https://github.com/jinnaiyuu/distributed-fast-downward", "journal-ref": "Yuu Jinnai and Alex Fukunaga. (2017). On Hash-Based Work\n  Distribution Methods for Parallel Best-First Search. Journal of Artificial\n  Intelligence Research (JAIR), 60, 491-548", "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Parallel best-first search algorithms such as Hash Distributed A* (HDA*)\ndistribute work among the processes using a global hash function. We analyze\nthe search and communication overheads of state-of-the-art hash-based parallel\nbest-first search algorithms, and show that although Zobrist hashing, the\nstandard hash function used by HDA*, achieves good load balance for many\ndomains, it incurs significant communication overhead since almost all\ngenerated nodes are transferred to a different processor than their parents. We\npropose Abstract Zobrist hashing, a new work distribution method for parallel\nsearch which, instead of computing a hash value based on the raw features of a\nstate, uses a feature projection function to generate a set of abstract\nfeatures which results in a higher locality, resulting in reduced\ncommunications overhead. We show that Abstract Zobrist hashing outperforms\nprevious methods on search domains using hand-coded, domain specific feature\nprojection functions. We then propose GRAZHDA*, a graph-partitioning based\napproach to automatically generating feature projection functions. GRAZHDA*\nseeks to approximate the partitioning of the actual search space graph by\npartitioning the domain transition graph, an abstraction of the state space\ngraph. We show that GRAZHDA* outperforms previous methods on domain-independent\nplanning.\n", "versions": [{"version": "v1", "created": "Sat, 10 Jun 2017 17:05:46 GMT"}, {"version": "v2", "created": "Thu, 9 Nov 2017 23:27:48 GMT"}], "update_date": "2017-11-13", "authors_parsed": [["Jinnai", "Yuu", ""], ["Fukunaga", "Alex", ""]]}, {"id": "1706.03292", "submitter": "Hao Zhang", "authors": "Hao Zhang, Zeyu Zheng, Shizhen Xu, Wei Dai, Qirong Ho, Xiaodan Liang,\n  Zhiting Hu, Jinliang Wei, Pengtao Xie, Eric P. Xing", "title": "Poseidon: An Efficient Communication Architecture for Distributed Deep\n  Learning on GPU Clusters", "comments": "To appear in 2017 USENIX Annual Technical Conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.CV cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models can take weeks to train on a single GPU-equipped\nmachine, necessitating scaling out DL training to a GPU-cluster. However,\ncurrent distributed DL implementations can scale poorly due to substantial\nparameter synchronization over the network, because the high throughput of GPUs\nallows more data batches to be processed per unit time than CPUs, leading to\nmore frequent network synchronization. We present Poseidon, an efficient\ncommunication architecture for distributed DL on GPUs. Poseidon exploits the\nlayered model structures in DL programs to overlap communication and\ncomputation, reducing bursty network communication. Moreover, Poseidon uses a\nhybrid communication scheme that optimizes the number of bytes required to\nsynchronize each layer, according to layer properties and the number of\nmachines. We show that Poseidon is applicable to different DL frameworks by\nplugging Poseidon into Caffe and TensorFlow. We show that Poseidon enables\nCaffe and TensorFlow to achieve 15.5x speed-up on 16 single-GPU machines, even\nwith limited bandwidth (10GbE) and the challenging VGG19-22K network for image\nclassification. Moreover, Poseidon-enabled TensorFlow achieves 31.5x speed-up\nwith 32 single-GPU machines on Inception-V3, a 50% improvement over the\nopen-source TensorFlow (20x speed-up).\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 01:11:06 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Zhang", "Hao", ""], ["Zheng", "Zeyu", ""], ["Xu", "Shizhen", ""], ["Dai", "Wei", ""], ["Ho", "Qirong", ""], ["Liang", "Xiaodan", ""], ["Hu", "Zhiting", ""], ["Wei", "Jinliang", ""], ["Xie", "Pengtao", ""], ["Xing", "Eric P.", ""]]}, {"id": "1706.03317", "submitter": "Marius Rafailescu", "authors": "Marius Rafailescu", "title": "Fault Tolerant Consensus Agreement Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Recently a new fault tolerant and simple mechanism was designed for solving\ncommit consensus problem. It is based on replicated validation of messages sent\nbetween transaction participants and a special dispatcher validator manager\nnode. This paper presents a correctness, safety proofs and performance analysis\nof this algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 11 Jun 2017 07:28:48 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Rafailescu", "Marius", ""]]}, {"id": "1706.03539", "submitter": "Pascal Costanza", "authors": "Pascal Costanza, Charlotte Herzeel, Wolfgang De Meuter, Roel Wuyts", "title": "Resilient Work Stealing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Future generations of processors will exhibit an increase of faults over\ntheir lifetime, and it becomes increasingly expensive to solve the resulting\nreliability issues purely at the hardware level. We propose to model\ncomputations in terms of restartable task graphs in order to improve\nreliability at the software level. As a proof of concept, we present Cobra, a\nnovel design for a shared-memory work-stealing scheduler that realizes this\nnotion of restartable task graphs, and enables computations to survive hardware\nfailures due to soft errors. A comparison with the work-stealing scheduler of\nThreading Building Blocks on the PARSEC benchmark suite shows that Cobra incurs\nno performance overhead in the absence of failures, and low performance\noverheads in the presence of single and multiple failures.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 09:53:32 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Costanza", "Pascal", ""], ["Herzeel", "Charlotte", ""], ["De Meuter", "Wolfgang", ""], ["Wuyts", "Roel", ""]]}, {"id": "1706.03721", "submitter": "Jara Uitto", "authors": "Yuval Emek, Jara Uitto", "title": "Dynamic Networks of Finite State Machines", "comments": "Licensed under CC-BY-NC-ND 4.0", "journal-ref": null, "doi": "10.1016/j.tcs.2017.05.025", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Like distributed systems, biological multicellular processes are subject to\ndynamic changes and a biological system will not pass the\nsurvival-of-the-fittest test unless it exhibits certain features that enable\nfast recovery from these changes. In particular, a question that is crucial in\nthe context of biological cellular networks, is whether the system can keep the\nchanging components \\emph{confined} so that only nodes in their vicinity may be\naffected by the changes, but nodes sufficiently far away from any changing\ncomponent remain unaffected.\n  Based on this notion of confinement, we propose a new metric for measuring\nthe dynamic changes recovery performance in distributed network algorithms\noperating under the \\emph{Stone Age} model (Emek \\& Wattenhofer, PODC 2013),\nwhere the class of dynamic topology changes we consider includes\ninserting/deleting an edge, deleting a node together with its incident edges,\nand inserting a new isolated node. Our main technical contribution is a\ndistributed algorithm for maximal independent set (MIS) in synchronous networks\nsubject to these topology changes that performs well in terms of the\naforementioned new metric. Specifically, our algorithm guarantees that nodes\nwhich do not experience a topology change in their immediate vicinity are not\naffected and that all surviving nodes (including the affected ones) perform\n$\\mathcal{O}((C + 1) \\log^{2} n)$ computationally-meaningful steps, where $C$\nis the number of topology changes; in other words, each surviving node performs\n$\\mathcal{O}(\\log^{2} n)$ steps when amortized over the number of topology\nchanges. This is accompanied by a simple example demonstrating that the linear\ndependency on $C$ cannot be avoided.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 16:47:19 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Emek", "Yuval", ""], ["Uitto", "Jara", ""]]}, {"id": "1706.03968", "submitter": "Alexander Krause", "authors": "Alexander Krause, Annett Ungeth\\\"um, Thomas Kissinger, Dirk Habich,\n  Wolfgang Lehner", "title": "Asynchronous Graph Pattern Matching on Multiprocessor Systems", "comments": "14 Pages, Extended version for ADBIS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pattern matching on large graphs is the foundation for a variety of\napplication domains. Strict latency requirements and continuously increasing\ngraph sizes demand the usage of highly parallel in-memory graph processing\nengines that need to consider non-uniform memory access (NUMA) and concurrency\nissues to scale up on modern multiprocessor systems. To tackle these aspects,\ngraph partitioning becomes increasingly important. Hence, we present a\ntechnique to process graph pattern matching on NUMA systems in this paper. As a\nscalable pattern matching processing infrastructure, we leverage a\ndata-oriented architecture that preserves data locality and minimizes\nconcurrency-related bottlenecks on NUMA systems. We show in detail, how graph\npattern matching can be asynchronously processed on a multiprocessor system.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 09:32:37 GMT"}, {"version": "v2", "created": "Wed, 14 Jun 2017 13:58:32 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Krause", "Alexander", ""], ["Ungeth\u00fcm", "Annett", ""], ["Kissinger", "Thomas", ""], ["Habich", "Dirk", ""], ["Lehner", "Wolfgang", ""]]}, {"id": "1706.03992", "submitter": "Dennis Olivetti", "authors": "Pierre Fraigniaud and Dennis Olivetti", "title": "Distributed Detection of Cycles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Distributed property testing in networks has been introduced by Brakerski and\nPatt-Shamir (2011), with the objective of detecting the presence of large dense\nsub-networks in a distributed manner. Recently, Censor-Hillel et al. (2016)\nhave shown how to detect 3-cycles in a constant number of rounds by a\ndistributed algorithm. In a follow up work, Fraigniaud et al. (2016) have shown\nhow to detect 4-cycles in a constant number of rounds as well. However, the\ntechniques in these latter works were shown not to generalize to larger cycles\n$C_k$ with $k\\geq 5$. In this paper, we completely settle the problem of cycle\ndetection, by establishing the following result. For every $k\\geq 3$, there\nexists a distributed property testing algorithm for $C_k$-freeness, performing\nin a constant number of rounds. All these results hold in the classical CONGEST\nmodel for distributed network computing. Our algorithm is 1-sided error. Its\nround-complexity is $O(1/\\epsilon)$ where $\\epsilon\\in(0,1)$ is the property\ntesting parameter measuring the gap between legal and illegal instances.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 10:41:52 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Fraigniaud", "Pierre", ""], ["Olivetti", "Dennis", ""]]}, {"id": "1706.03996", "submitter": "Dennis Olivetti", "authors": "Pierre Fraigniaud, Pedro Montealegre, Dennis Olivetti, Ivan Rapaport,\n  Ioan Todinca", "title": "Distributed Subgraph Detection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In the standard CONGEST model for distributed network computing, it is known\nthat \"global\" tasks such as minimum spanning tree, diameter, and all-pairs\nshortest paths, consume large bandwidth, for their running-time is\n$\\Omega(\\mbox{poly}(n))$ rounds in $n$-node networks with constant diameter.\nSurprisingly, \"local\" tasks such as detecting the presence of a 4-cycle as a\nsubgraph also requires $\\widetilde{\\Omega}(\\sqrt{n})$ rounds, even using\nrandomized algorithms, and the best known upper bound for detecting the\npresence of a 3-cycle is $\\widetilde{O}(n^{\\frac{2}{3}})$ rounds. The objective\nof this paper is to better understand the landscape of such subgraph detection\ntasks. We show that, in contrast to \\emph{cycles}, which are hard to detect in\nthe CONGEST model, there exists a deterministic algorithm for detecting the\npresence of a subgraph isomorphic to $T$ running in a \\emph{constant} number of\nrounds, for every tree $T$. Our algorithm provides a distributed implementation\nof a combinatorial technique due to Erd\\H{o}s et al. for sparsening the set of\npartial solutions kept by the nodes at each round. Our result has important\nconsequences to \\emph{distributed property-testing}, i.e., to randomized\nalgorithms whose aim is to distinguish between graphs satisfying a property,\nand graphs far from satisfying that property. In particular, we get that, for\nevery graph pattern $H$ composed of an edge and a tree connected in an\narbitrary manner, there exists a distributed testing algorithm for\n$H$-freeness, performing in a constant number of rounds. Although the class of\ngraph patterns $H$ formed by a tree and an edge connected arbitrarily may look\nartificial, all previous results of the literature concerning testing\n$H$-freeness for classical patterns such as cycles and cliques can be viewed as\ndirect consequences of our result, while our algorithm enables testing more\ncomplex patterns.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 11:00:35 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Fraigniaud", "Pierre", ""], ["Montealegre", "Pedro", ""], ["Olivetti", "Dennis", ""], ["Rapaport", "Ivan", ""], ["Todinca", "Ioan", ""]]}, {"id": "1706.04043", "submitter": "Klaus-Dieter Schewe", "authors": "Egon B\\\"orger, Klaus-Dieter Schewe, Qing Wang", "title": "Serialisable Multi-Level Transaction Control: A Specification and\n  Verification", "comments": "25 pages, 1 figure. arXiv admin note: substantial text overlap with\n  arXiv:1706.01762", "journal-ref": "Sci. Comput. Program. 131: 42-58 (2016)", "doi": "10.1016/j.scico.2016.03.008", "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define a programming language independent controller TaCtl for multi-level\ntransactions and an operator $TA$, which when applied to concurrent programs\nwith multi-level shared locations containing hierarchically structured complex\nvalues, turns their behavior with respect to some abstract termination\ncriterion into a transactional behavior. We prove the correctness property that\nconcurrent runs under the transaction controller are serialisable, assuming an\nInverse Operation Postulate to guarantee recoverability. For its applicability\nto a wide range of programs we specify the transaction controller TaCtl and the\noperator $TA$ in terms of Abstract State Machines (ASMs). This allows us to\nmodel concurrent updates at different levels of nested locations in a precise\nyet simple manner, namely in terms of partial ASM updates. It also provides the\npossibility to use the controller TaCtl and the operator $TA$ as a plug-in when\nspecifying concurrent system components in terms of sequential ASMs.\n", "versions": [{"version": "v1", "created": "Mon, 12 Jun 2017 08:34:35 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["B\u00f6rger", "Egon", ""], ["Schewe", "Klaus-Dieter", ""], ["Wang", "Qing", ""]]}, {"id": "1706.04118", "submitter": "Shiqiang Wang", "authors": "Andrew Machen, Shiqiang Wang, Kin K. Leung, Bong Jun Ko, Theodoros\n  Salonidis", "title": "Live Service Migration in Mobile Edge Clouds", "comments": "This is the author's version of the paper accepted for publication in\n  IEEE Wireless Communications", "journal-ref": null, "doi": "10.1109/MWC.2017.1700011", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile edge clouds (MECs) bring the benefits of the cloud closer to the user,\nby installing small cloud infrastructures at the network edge. This enables a\nnew breed of real-time applications, such as instantaneous object recognition\nand safety assistance in intelligent transportation systems, that require very\nlow latency. One key issue that comes with proximity is how to ensure that\nusers always receive good performance as they move across different locations.\nMigrating services between MECs is seen as the means to achieve this. This\narticle presents a layered framework for migrating active service applications\nthat are encapsulated either in virtual machines (VMs) or containers. This\nlayering approach allows a substantial reduction in service downtime. The\nframework is easy to implement using readily available technologies, and one of\nits key advantages is that it supports containers, which is a promising\nemerging technology that offers tangible benefits over VMs. The migration\nperformance of various real applications is evaluated by experiments under the\npresented framework. Insights drawn from the experimentation results are\ndiscussed.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 15:21:32 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 14:19:05 GMT"}], "update_date": "2018-09-25", "authors_parsed": [["Machen", "Andrew", ""], ["Wang", "Shiqiang", ""], ["Leung", "Kin K.", ""], ["Ko", "Bong Jun", ""], ["Salonidis", "Theodoros", ""]]}, {"id": "1706.04178", "submitter": "Jerry Li", "authors": "Dan Alistarh, Justin Kopinsky, Jerry Li, Giorgi Nadiradze", "title": "The Power of Choice in Priority Scheduling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider the following random process: we are given $n$ queues, into which\nelements of increasing labels are inserted uniformly at random. To remove an\nelement, we pick two queues at random, and remove the element of lower label\n(higher priority) among the two. The cost of a removal is the rank of the label\nremoved, among labels still present in any of the queues, that is, the distance\nfrom the optimal choice at each step. Variants of this strategy are prevalent\nin state-of-the-art concurrent priority queue implementations. Nonetheless, it\nis not known whether such implementations provide any rank guarantees, even in\na sequential model.\n  We answer this question, showing that this strategy provides surprisingly\nstrong guarantees: Although the single-choice process, where we always insert\nand remove from a single randomly chosen queue, has degrading cost, going to\ninfinity as we increase the number of steps, in the two choice process, the\nexpected rank of a removed element is $O( n )$ while the expected worst-case\ncost is $O( n \\log n )$. These bounds are tight, and hold irrespective of the\nnumber of steps for which we run the process.\n  The argument is based on a new technical connection between \"heavily loaded\"\nballs-into-bins processes and priority scheduling.\n  Our analytic results inspire a new concurrent priority queue implementation,\nwhich improves upon the state of the art in terms of practical performance.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 17:45:20 GMT"}], "update_date": "2017-06-14", "authors_parsed": [["Alistarh", "Dan", ""], ["Kopinsky", "Justin", ""], ["Li", "Jerry", ""], ["Nadiradze", "Giorgi", ""]]}, {"id": "1706.04235", "submitter": "Lili Wang", "authors": "L. Wang, A. S. Morse, D. Fullmer, and J. Liu", "title": "A Hybrid Observer for a Distributed Linear System with a Changing\n  Neighbor Graph", "comments": "7 pages, the 56th IEEE Conference on Decision and Control", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A hybrid observer is described for estimating the state of an $m>0$ channel,\n$n$-dimensional, continuous-time, distributed linear system of the form\n$\\dot{x} = Ax,\\;y_i = C_ix,\\;i\\in\\{1,2,\\ldots, m\\}$. The system's state $x$ is\nsimultaneously estimated by $m$ agents assuming each agent $i$ senses $y_i$ and\nreceives appropriately defined data from each of its current neighbors.\nNeighbor relations are characterized by a time-varying directed graph\n$\\mathbb{N}(t)$ whose vertices correspond to agents and whose arcs depict\nneighbor relations. Agent $i$ updates its estimate $x_i$ of $x$ at \"event\ntimes\" $t_1,t_2,\\ldots $ using a local observer and a local parameter\nestimator. The local observer is a continuous time linear system whose input is\n$y_i$ and whose output $w_i$ is an asymptotically correct estimate of $L_ix$\nwhere $L_i$ a matrix with kernel equaling the unobservable space of $(C_i,A)$.\nThe local parameter estimator is a recursive algorithm designed to estimate,\nprior to each event time $t_j$, a constant parameter $p_j$ which satisfies the\nlinear equations $w_k(t_j-\\tau) =\nL_kp_j+\\mu_k(t_j-\\tau),\\;k\\in\\{1,2,\\ldots,m\\}$, where $\\tau$ is a small\npositive constant and $\\mu_k$ is the state estimation error of local observer\n$k$. Agent $i$ accomplishes this by iterating its parameter estimator state\n$z_i$, $q$ times within the interval $[t_j-\\tau, t_j)$, and by making use of\nthe state of each of its neighbors' parameter estimators at each iteration. The\nupdated value of $x_i$ at event time $t_j$ is then $x_i(t_j) =\ne^{A\\tau}z_i(q)$. Subject to the assumptions that (i) the neighbor graph\n$\\mathbb{N}(t)$ is strongly connected for all time, (ii) the system whose state\nis to be estimated is jointly observable, (iii) $q$ is sufficiently large, it\nis shown that each estimate $x_i$ converges to $x$ exponentially fast as\n$t\\rightarrow \\infty$ at a rate which can be controlled.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 19:38:31 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Wang", "L.", ""], ["Morse", "A. S.", ""], ["Fullmer", "D.", ""], ["Liu", "J.", ""]]}, {"id": "1706.04337", "submitter": "Siavash Ghiasvand", "authors": "Siavash Ghiasvand and Florina M. Ciorba", "title": "Anonymization of System Logs for Privacy and Storage Benefits", "comments": "8 pages, 5 figures, for demonstration see\n  https://www.ghiasvand.net/u/hpcmaspa17", "journal-ref": null, "doi": "10.1007/978-3-030-03405-4_11", "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  System logs constitute valuable information for analysis and diagnosis of\nsystem behavior. The size of parallel computing systems and the number of their\ncomponents steadily increase. The volume of generated logs by the system is in\nproportion to this increase. Hence, long-term collection and storage of system\nlogs is challenging. The analysis of system logs requires advanced text\nprocessing techniques. For very large volumes of logs, the analysis is highly\ntime-consuming and requires a high level of expertise. For many parallel\ncomputing centers, outsourcing the analysis of system logs to third parties is\nthe only affordable option. The existence of sensitive data within system log\nentries obstructs, however, the transmission of system logs to third parties.\nMoreover, the analytical tools for processing system logs and the solutions\nprovided by such tools are highly system specific. Achieving a more general\nsolution is only possible through the access and analysis system of logs of\nmultiple computing systems. The privacy concerns impede, however, the sharing\nof system logs across institutions as well as in the public domain. This work\nproposes a new method for the anonymization of the information within system\nlogs that employs de-identification and encoding to provide sharable system\nlogs, with the highest possible data quality and of reduced size. The results\npresented in this work indicate that apart from eliminating the sensitive data\nwithin system logs and converting them into shareable data, the proposed\nanonymization method provides 25% performance improvement in post-processing of\nthe anonymized system logs, and more than 50% reduction in their required\nstorage space.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 07:33:07 GMT"}], "update_date": "2019-01-23", "authors_parsed": [["Ghiasvand", "Siavash", ""], ["Ciorba", "Florina M.", ""]]}, {"id": "1706.04345", "submitter": "Siavash Ghiasvand", "authors": "Siavash Ghiasvand and Florina M. Ciorba", "title": "Towards Adaptive Resilience in High Performance Computing", "comments": "2 pages, to be published in Proceedings of the Work in Progress\n  Session held in connection with the 25th EUROMICRO International Conference\n  on Parallel, Distributed and Network-based Processing, PDP 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Failure rates in high performance computers rapidly increase due to the\ngrowth in system size and complexity. Hence, failures became the norm rather\nthan the exception. Different approaches on high performance computing (HPC)\nsystems have been introduced, to prevent failures (e. g., redundancy) or at\nleast minimize their impacts (e. g., checkpoint and restart). In most cases,\nwhen these approaches are employed to increase the resilience of certain parts\nof a system, energy consumption rapidly increases, or performance significantly\ndegrades. To address this challenge, we propose on-demand resilience as an\napproach to achieve adaptive resilience in HPC systems. In this work, the HPC\nsystem is considered in its entirety and resilience mechanisms such as\ncheckpointing, isolation, and migration, are activated on-demand. Using the\nproposed approach, the unavoidable increase in total energy consumption and\nsystem performance degradation is decreased compared to the typical\ncheckpoint/restart and redundant resilience mechanisms. Our work aims to\nmitigate a large number of failures occurring at various layers in the system,\nto prevent their propagation, and to minimize their impact, all of this in an\nenergy-saving manner. In the case of failures that are estimated to occur but\ncannot be mitigated using the proposed on-demand resilience approach, the\nsystem administrators will be notified in view of performing further\ninvestigations into the causes of these failures and their impacts.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 07:49:49 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Ghiasvand", "Siavash", ""], ["Ciorba", "Florina M.", ""]]}, {"id": "1706.04404", "submitter": "Stefan Schulte", "authors": "Christoph Prybila and Stefan Schulte and Christoph Hochreiner and Ingo\n  Weber", "title": "Runtime Verification for Business Processes Utilizing the Bitcoin\n  Blockchain", "comments": null, "journal-ref": null, "doi": "10.1016/j.future.2017.08.024", "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The usage of process choreographies and decentralized Business Process\nManagement Systems has been named as an alternative to centralized business\nprocess orchestration. In choreographies, control over a process instance is\nshared between independent parties, and no party has full control or knowledge\nduring process runtime. Nevertheless, it is necessary to monitor and verify\nprocess instances during runtime for purposes of documentation, accounting, or\ncompensation.\n  To achieve business process runtime verification, this work explores the\nsuitability of the Bitcoin blockchain to create a novel solution for\nchoreographies. The resulting approach is realized in a fully-functional\nsoftware prototype. This software solution is evaluated in a qualitative\ncomparison. Findings show that our blockchain-based approach enables a seamless\nexecution monitoring and verification of choreographies, while at the same time\npreserving anonymity and independence of the process participants. Furthermore,\nthe prototype is evaluated in a performance analysis.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 10:53:36 GMT"}, {"version": "v2", "created": "Fri, 18 Aug 2017 08:07:53 GMT"}], "update_date": "2017-08-21", "authors_parsed": [["Prybila", "Christoph", ""], ["Schulte", "Stefan", ""], ["Hochreiner", "Christoph", ""], ["Weber", "Ingo", ""]]}, {"id": "1706.04552", "submitter": "Crist\\'obal A. Navarro", "authors": "Crist\\'obal A. Navarro, Benjam\\'in Bustos, Raimundo Vega, Nancy\n  Hitschfeld", "title": "Block-space GPU Mapping for Embedded Sierpi\\'nski Gasket Fractals", "comments": "7 pages, 8 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work studies the problem of GPU thread mapping for a Sierpi\\'nski gasket\nfractal embedded in a discrete Euclidean space of $n \\times n$. A block-space\nmap $\\lambda: \\mathbb{Z}_{\\mathbb{E}}^{2} \\mapsto \\mathbb{Z}_{\\mathbb{F}}^{2}$\nis proposed, from Euclidean parallel space $\\mathbb{E}$ to embedded fractal\nspace $\\mathbb{F}$, that maps in $\\mathcal{O}(\\log_2 \\log_2(n))$ time and uses\nno more than $\\mathcal{O}(n^\\mathbb{H})$ threads with $\\mathbb{H} \\approx\n1.58...$ being the Hausdorff dimension, making it parallel space efficient.\nWhen compared to a bounding-box map, $\\lambda(\\omega)$ offers a sub-exponential\nimprovement in parallel space and a monotonically increasing speedup once $n >\nn_0$. Experimental performance tests show that in practice $\\lambda(\\omega)$\ncan produce performance improvement at any block-size once $n > n_0 = 2^8$,\nreaching approximately $10\\times$ of speedup for $n=2^{16}$ under optimal block\nconfigurations.\n", "versions": [{"version": "v1", "created": "Wed, 14 Jun 2017 15:54:32 GMT"}], "update_date": "2017-06-15", "authors_parsed": [["Navarro", "Crist\u00f3bal A.", ""], ["Bustos", "Benjam\u00edn", ""], ["Vega", "Raimundo", ""], ["Hitschfeld", "Nancy", ""]]}, {"id": "1706.04722", "submitter": "Hung Cao", "authors": "Hung Cao and Monica Wachowicz", "title": "The design of a streaming analytical workflow for processing massive\n  transit feeds", "comments": "data ingestion, data contextualization, Hadoop MapReduce, transit\n  networks, streaming data analytics, mobility context. Present at the 2nd\n  International Symposium on Spatiotemporal Computing August 7-9 2017 at\n  Harvard University, Cambridge, Massachusetts", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Retrieving and analyzing transit feeds relies on working with analytical\nworkflows that can handle the massive volume of data streams that are relevant\nto understand the dynamics of transit networks which are entirely deterministic\nin the geographical space in which they takes place. In this paper, we consider\nthe fundamental issues in developing a streaming analytical workflow for\nanalyzing the continuous arrival of multiple, unbounded transit data feeds for\nautomatically processing and enriching them with additional information\ncontaining higher level concepts accordingly to a particular mobility context.\nThis workflow consists of three tasks: (1) stream data retrieval for creating\ntime windows; (2) data cleaning for handling missing data, overlap data or\nredundant data; and (3) data contextualization for computing actual arrival and\ndeparture times as well as the stops and moves during a bus trip, and also\nperforming mobility context computation. The workflow was implemented in a\nHadoop cloud ecosystem using data streams from the CODIAC Transit System of the\ncity of Moncton, NB. The Map() function of MapReduce is used to retrieve and\nbundle data streams into numerous clusters which are subsequently handled in a\nparallel manner by the Reduce() function in order to execute the data\ncontextualization step. The results validate the need for cloud computing for\nachieving high performance and scalability, however, due to the delay in\ncomputing and networking, it is clear that data cleaning tasks should not only\nbe deployed using a cloud environment, paving the way to combine it with fog\ncomputing in the near future.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 02:23:51 GMT"}, {"version": "v2", "created": "Fri, 8 Jun 2018 16:36:17 GMT"}], "update_date": "2018-06-11", "authors_parsed": [["Cao", "Hung", ""], ["Wachowicz", "Monica", ""]]}, {"id": "1706.04746", "submitter": "Yannic Maus", "authors": "Mohsen Ghaffari, Juho Hirvonen, Fabian Kuhn, Yannic Maus, Jukka\n  Suomela, Jara Uitto", "title": "Improved Distributed Degree Splitting and Edge Coloring", "comments": null, "journal-ref": null, "doi": "10.1007/s00446-018-00346-8", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The degree splitting problem requires coloring the edges of a graph red or\nblue such that each node has almost the same number of edges in each color, up\nto a small additive discrepancy. The directed variant of the problem requires\norienting the edges such that each node has almost the same number of incoming\nand outgoing edges, again up to a small additive discrepancy.\n  We present deterministic distributed algorithms for both variants, which\nimprove on their counterparts presented by Ghaffari and Su [SODA'17]: our\nalgorithms are significantly simpler and faster, and have a much smaller\ndiscrepancy. This also leads to a faster and simpler deterministic algorithm\nfor $(2+o(1))\\Delta$-edge-coloring, improving on that of Ghaffari and Su.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 06:00:07 GMT"}, {"version": "v2", "created": "Thu, 3 Jan 2019 20:00:00 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Ghaffari", "Mohsen", ""], ["Hirvonen", "Juho", ""], ["Kuhn", "Fabian", ""], ["Maus", "Yannic", ""], ["Suomela", "Jukka", ""], ["Uitto", "Jara", ""]]}, {"id": "1706.05039", "submitter": "Rui Zhang", "authors": "Rui Zhang, Quanyan Zhu", "title": "Consensus-Based Transfer Linear Support Vector Machines for\n  Decentralized Multi-Task Multi-Agent Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transfer learning has been developed to improve the performances of different\nbut related tasks in machine learning. However, such processes become less\nefficient with the increase of the size of training data and the number of\ntasks. Moreover, privacy can be violated as some tasks may contain sensitive\nand private data, which are communicated between nodes and tasks. We propose a\nconsensus-based distributed transfer learning framework, where several tasks\naim to find the best linear support vector machine (SVM) classifiers in a\ndistributed network. With alternating direction method of multipliers, tasks\ncan achieve better classification accuracies more efficiently and privately, as\neach node and each task train with their own data, and only decision variables\nare transferred between different tasks and nodes. Numerical experiments on\nMNIST datasets show that the knowledge transferred from the source tasks can be\nused to decrease the risks of the target tasks that lack training data or have\nunbalanced training labels. We show that the risks of the target tasks in the\nnodes without the data of the source tasks can also be reduced using the\ninformation transferred from the nodes who contain the data of the source\ntasks. We also show that the target tasks can enter and leave in real-time\nwithout rerunning the whole algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 18:53:11 GMT"}, {"version": "v2", "created": "Tue, 27 Mar 2018 13:45:06 GMT"}], "update_date": "2018-03-28", "authors_parsed": [["Zhang", "Rui", ""], ["Zhu", "Quanyan", ""]]}, {"id": "1706.05151", "submitter": "Shaikh Arifuzzaman", "authors": "Shaikh Arifuzzaman, Maleq Khan, Madhav Marathe", "title": "Distributed-Memory Parallel Algorithms for Counting and Listing\n  Triangles in Big Graphs", "comments": "30 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big graphs (networks) arising in numerous application areas pose significant\nchallenges for graph analysts as these graphs grow to billions of nodes and\nedges and are prohibitively large to fit in the main memory. Finding the number\nof triangles in a graph is an important problem in the mining and analysis of\ngraphs. In this paper, we present two efficient MPI-based distributed memory\nparallel algorithms for counting triangles in big graphs. The first algorithm\nemploys overlapping partitioning and efficient load balancing schemes to\nprovide a very fast parallel algorithm. The algorithm scales well to networks\nwith billions of nodes and can compute the exact number of triangles in a\nnetwork with 10 billion edges in 16 minutes. The second algorithm divides the\nnetwork into non-overlapping partitions leading to a space-efficient algorithm.\nOur results on both artificial and real-world networks demonstrate a\nsignificant space saving with this algorithm. We also present a novel approach\nthat reduces communication cost drastically leading the algorithm to both a\nspace- and runtime-efficient algorithm. Further, we demonstrate how our\nalgorithms can be used to list all triangles in a graph and compute clustering\ncoefficients of nodes. Our algorithm can also be adapted to a parallel\napproximation algorithm using an edge sparsification method.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 05:54:58 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Arifuzzaman", "Shaikh", ""], ["Khan", "Maleq", ""], ["Marathe", "Madhav", ""]]}, {"id": "1706.05193", "submitter": "Sebastien Tixeuil", "authors": "Arnaud Sangnier (IRIF), Nathalie Sznajder (MoVe), Maria Potop-Butucaru\n  (NPA, LINCS), S\\'ebastien Tixeuil (NPA, IUF, LINCS)", "title": "Parameterized Verification of Algorithms for Oblivious Robots on a Ring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study verification problems for autonomous swarms of mobile robots that\nself-organize and cooperate to solve global objectives. In particular, we focus\nin this paper on the model proposed by Suzuki and Yamashita of anonymous robots\nevolving in a discrete space with a finite number of locations (here, a ring).\nA large number of algorithms have been proposed working for rings whose size is\nnot a priori fixed and can be hence considered as a parameter. Handmade\ncorrectness proofs of these algorithms have been shown to be error-prone, and\nrecent attention had been given to the application of formal methods to\nautomatically prove those. Our work is the first to study the verification\nproblem of such algorithms in the parameter-ized case. We show that safety and\nreachability problems are undecidable for robots evolving asynchronously. On\nthe positive side, we show that safety properties are decidable in the\nsynchronous case, as well as in the asynchronous case for a particular class of\nalgorithms. Several properties on the protocol can be decided as well. Decision\nprocedures rely on an encoding in Presburger arithmetics formulae that can be\nverified by an SMT-solver. Feasibility of our approach is demonstrated by the\nencoding of several case studies.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 09:38:21 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Sangnier", "Arnaud", "", "IRIF"], ["Sznajder", "Nathalie", "", "MoVe"], ["Potop-Butucaru", "Maria", "", "NPA, LINCS"], ["Tixeuil", "S\u00e9bastien", "", "NPA, IUF, LINCS"]]}, {"id": "1706.05263", "submitter": "Sebastien Tixeuil", "authors": "Jordan Adamek, Mikhail Nesterenko, James Robinson, S\\'ebastien Tixeuil\n  (NPA, IUF, LINCS)", "title": "Concurrent Geometric Multicasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CG cs.DM cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present MCFR, a multicasting concurrent face routing algorithm that uses\ngeometric routing to deliver a message from source to multiple targets. We\ndescribe the algorithm's operation, prove it correct, estimate its performance\nbounds and evaluate its performance using simulation. Our estimate shows that\nMCFR is the first geometric multicast routing algorithm whose message delivery\nlatency is independent of network size and only proportional to the distance\nbetween the source and the targets. Our simulation indicates that MCFR has\nsignificantly better reliability than existing algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 13:16:54 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Adamek", "Jordan", "", "NPA, IUF, LINCS"], ["Nesterenko", "Mikhail", "", "NPA, IUF, LINCS"], ["Robinson", "James", "", "NPA, IUF, LINCS"], ["Tixeuil", "S\u00e9bastien", "", "NPA, IUF, LINCS"]]}, {"id": "1706.05267", "submitter": "Matthieu Perrin", "authors": "Damien Imbs (LIF), Achour Mostefaoui (GDD), Matthieu Perrin, Michel\n  Raynal (ASAP, IUF)", "title": "Set-Constrained Delivery Broadcast: Definition, Abstraction Power, and\n  Computability Limits", "comments": "arXiv admin note: substantial text overlap with arXiv:1702.08176", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces a new communication abstraction, called Set-Constrained\nDelivery Broadcast (SCD-broadcast), whose aim is to provide its users with an\nappropriate abstraction level when they have to implement objects or\ndistributed tasks in an asynchronous message-passing system prone to process\ncrash failures. This abstraction allows each process to broadcast messages and\ndeliver a sequence of sets of messages in such a way that, if a process\ndelivers a set of messages including a message m and later delivers a set of\nmessages including a message m ' , no process delivers first a set of messages\nincluding m ' and later a set of message including m. After having presented an\nalgorithm implementing SCD-broadcast, the paper investigates its programming\npower and its computability limits. On the \"power\" side it presents\nSCD-broadcast-based algorithms, which are both simple and efficient, building\nobjects (such as snapshot and conflict-free replicated data), and distributed\ntasks. On the \"computability limits\" side it shows that SCD-broadcast and\nread/write registers are computationally equivalent.\n", "versions": [{"version": "v1", "created": "Thu, 15 Jun 2017 14:20:40 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Imbs", "Damien", "", "LIF"], ["Mostefaoui", "Achour", "", "GDD"], ["Perrin", "Matthieu", "", "ASAP, IUF"], ["Raynal", "Michel", "", "ASAP, IUF"]]}, {"id": "1706.05272", "submitter": "Giuseppe Attardi", "authors": "Giuseppe Attardi, Alex Barchiesi, Alberto Colla, Fulvio Galeazzi,\n  Giovanni Marzulli, Mario Reale", "title": "Declarative Modeling for Building a Cloud Federation and Cloud\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper illustrates how we built a federated cloud computing platform\ndedicated to the Italian research community. Building a cloud platform is a\ndaunting task, that requires coordinating the deployment of many services,\ninterrelated and dependent on each other. Provisioning, servicing and\nmaintaining the platform must be automated. For our deployment, we chose a\ndeclarative modeling tool, that allows describing the parts that compose the\nsystem and their relations of supplier/consumer of specific interfaces. The\ntool arranges the steps to bring the deployment to convergence by transforming\nthe state of the system until it reaches a configuration that satisfies all\nconstraints. We chose a declarative service modeling approach for orchestrating\nboth the deployment of the platform by the administrators and the deployment of\napplications by users. The cloud platform has been designed so that it can be\nmanaged by this kind of automation, facilitating the deployment of federated\nregions by anyone wishing to join and to contribute resources to the\nfederation. Federated resources are integrated into a single cloud platform\navailable to any user of the federation. The federation can also seamlessly\ninclude public clouds. We describe the architectural choices, how we adapted\nthe OpenStack basic facilities to the needs of a federation of multiple\nindependent organizations, how we control resource allocation according to\ncommitted plans and correspondingly how we handle accounting and billing of\nresource usage. Besides providing traditional IaaS services, the cloud supports\nself-service deployment of cloud applications. The cloud thus addresses the\nlong tail of science, allowing researchers of any discipline, without expertise\nin system or cloud administration, to deploy applications readily available for\ntheir perusal.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 13:36:04 GMT"}], "update_date": "2017-06-19", "authors_parsed": [["Attardi", "Giuseppe", ""], ["Barchiesi", "Alex", ""], ["Colla", "Alberto", ""], ["Galeazzi", "Fulvio", ""], ["Marzulli", "Giovanni", ""], ["Reale", "Mario", ""]]}, {"id": "1706.05297", "submitter": "Shakhar Smorodinsky", "authors": "Rann Smorodinsky and Shakhar Smorodinsky", "title": "Hypergraphical Clustering Games of Mis-Coordination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.CO cs.DC cs.DM cs.GT cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce and motivate the study of hypergraphical clustering games of\nmis-coordination. For two specific variants we prove the existence of a pure\nNash equilibrium and provide bounds on the price of anarchy as a function of\nthe cardinality of the action set and the size of the hyperedges.\n", "versions": [{"version": "v1", "created": "Tue, 13 Jun 2017 06:30:23 GMT"}, {"version": "v2", "created": "Wed, 2 Aug 2017 09:53:51 GMT"}, {"version": "v3", "created": "Sat, 2 Dec 2017 07:32:31 GMT"}], "update_date": "2017-12-05", "authors_parsed": [["Smorodinsky", "Rann", ""], ["Smorodinsky", "Shakhar", ""]]}, {"id": "1706.05436", "submitter": "Wael Halbawi", "authors": "Wael Halbawi, Navid Azizan-Ruhi, Fariborz Salehi, Babak Hassibi", "title": "Improving Distributed Gradient Descent Using Reed-Solomon Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's massively-sized datasets have made it necessary to often perform\ncomputations on them in a distributed manner. In principle, a computational\ntask is divided into subtasks which are distributed over a cluster operated by\na taskmaster. One issue faced in practice is the delay incurred due to the\npresence of slow machines, known as \\emph{stragglers}. Several schemes,\nincluding those based on replication, have been proposed in the literature to\nmitigate the effects of stragglers and more recently, those inspired by coding\ntheory have begun to gain traction. In this work, we consider a distributed\ngradient descent setting suitable for a wide class of machine learning\nproblems. We adapt the framework of Tandon et al. (arXiv:1612.03301) and\npresent a deterministic scheme that, for a prescribed per-machine computational\neffort, recovers the gradient from the least number of machines $f$\ntheoretically permissible, via an $O(f^2)$ decoding algorithm. We also provide\na theoretical delay model which can be used to minimize the expected waiting\ntime per computation by optimally choosing the parameters of the scheme.\nFinally, we supplement our theoretical findings with numerical results that\ndemonstrate the efficacy of the method and its advantages over competing\nschemes.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 21:45:31 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Halbawi", "Wael", ""], ["Azizan-Ruhi", "Navid", ""], ["Salehi", "Fariborz", ""], ["Hassibi", "Babak", ""]]}, {"id": "1706.05441", "submitter": "Wei Shi", "authors": "Angelia Nedi\\'c, Alex Olshevsky, and Wei Shi", "title": "Improved Convergence Rates for Distributed Resource Allocation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we develop a class of decentralized algorithms for solving a\nconvex resource allocation problem in a network of $n$ agents, where the agent\nobjectives are decoupled while the resource constraints are coupled. The agents\ncommunicate over a connected undirected graph, and they want to collaboratively\ndetermine a solution to the overall network problem, while each agent only\ncommunicates with its neighbors. We first study the connection between the\ndecentralized resource allocation problem and the decentralized consensus\noptimization problem. Then, using a class of algorithms for solving consensus\noptimization problems, we propose a novel class of decentralized schemes for\nsolving resource allocation problems in a distributed manner. Specifically, we\nfirst propose an algorithm for solving the resource allocation problem with an\n$o(1/k)$ convergence rate guarantee when the agents' objective functions are\ngenerally convex (could be nondifferentiable) and per agent local convex\nconstraints are allowed; We then propose a gradient-based algorithm for solving\nthe resource allocation problem when per agent local constraints are absent and\nshow that such scheme can achieve geometric rate when the objective functions\nare strongly convex and have Lipschitz continuous gradients. We have also\nprovided scalability/network dependency analysis. Based on these two\nalgorithms, we have further proposed a gradient projection-based algorithm\nwhich can handle smooth objective and simple constraints more efficiently.\nNumerical experiments demonstrates the viability and performance of all the\nproposed algorithms.\n", "versions": [{"version": "v1", "created": "Fri, 16 Jun 2017 22:07:05 GMT"}, {"version": "v2", "created": "Sun, 16 Dec 2018 16:59:27 GMT"}], "update_date": "2018-12-18", "authors_parsed": [["Nedi\u0107", "Angelia", ""], ["Olshevsky", "Alex", ""], ["Shi", "Wei", ""]]}, {"id": "1706.05699", "submitter": "Dong Yin", "authors": "Dong Yin, Ashwin Pananjady, Max Lam, Dimitris Papailiopoulos, Kannan\n  Ramchandran, Peter Bartlett", "title": "Gradient Diversity: a Key Ingredient for Scalable Distributed Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has been experimentally observed that distributed implementations of\nmini-batch stochastic gradient descent (SGD) algorithms exhibit speedup\nsaturation and decaying generalization ability beyond a particular batch-size.\nIn this work, we present an analysis hinting that high similarity between\nconcurrently processed gradients may be a cause of this performance\ndegradation. We introduce the notion of gradient diversity that measures the\ndissimilarity between concurrent gradient updates, and show its key role in the\nperformance of mini-batch SGD. We prove that on problems with high gradient\ndiversity, mini-batch SGD is amenable to better speedups, while maintaining the\ngeneralization performance of serial (one sample) SGD. We further establish\nlower bounds on convergence where mini-batch SGD slows down beyond a particular\nbatch-size, solely due to the lack of gradient diversity. We provide\nexperimental evidence indicating the key role of gradient diversity in\ndistributed learning, and discuss how heuristics like dropout, Langevin\ndynamics, and quantization can improve it.\n", "versions": [{"version": "v1", "created": "Sun, 18 Jun 2017 18:37:12 GMT"}, {"version": "v2", "created": "Thu, 17 Aug 2017 19:37:48 GMT"}, {"version": "v3", "created": "Sun, 7 Jan 2018 02:35:40 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Yin", "Dong", ""], ["Pananjady", "Ashwin", ""], ["Lam", "Max", ""], ["Papailiopoulos", "Dimitris", ""], ["Ramchandran", "Kannan", ""], ["Bartlett", "Peter", ""]]}, {"id": "1706.05760", "submitter": "Thejaka Kanewala", "authors": "Thejaka Kanewala, Marcin Zalewski, Martina Barnas, Andrew Lumsdaine", "title": "Families of Distributed Memory Parallel Graph Algorithms from\n  Self-Stabilizing Kernels-An SSSP Case Study", "comments": "10 pages, including references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Self-stabilizing algorithms are an important because of their robustness and\nguaranteed convergence. Starting from any arbitrary state, a self-stabilizing\nalgorithm is guaranteed to converge to a legitimate state.Those algorithms are\nnot directly amenable to solving distributed graph processing problems when\nperformance and scalability are important. In this paper, we show the \"Abstract\nGraph Machine\" (AGM) model that can be used to convert self-stabilizing\nalgorithms into forms suitable for distributed graph processing. An AGM is a\nmathematical model of parallel computation on graphs that adds work dependency\nand ordering to self-stabilizing algorithms. Using the AGM model we show that\nsome of the existing distributed Single Source Shortest Path (SSSP) algorithms\nare actually specializations of self-stabilizing SSSP. We extend the AGM model\nto apply more fine-grained orderings at different spatial levels to derive\nadditional scalable variants of SSSP algorithms, essentially enabling the\nalgorithm to be generated for a specific target architecture. Experimental\nresults show that this approach can generate new algorithmic variants that\nout-perform standard distributed algorithms for SSSP.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 01:33:37 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Kanewala", "Thejaka", ""], ["Zalewski", "Marcin", ""], ["Barnas", "Martina", ""], ["Lumsdaine", "Andrew", ""]]}, {"id": "1706.05893", "submitter": "Simon Wacker", "authors": "Simon Wacker", "title": "Signal Machine And Cellular Automaton Time-Optimal Quasi-Solutions Of\n  The Firing Squad/Mob Synchronisation Problem On Connected Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We construct a time-optimal quasi-solution of the firing mob synchronisation\nproblem over finite, connected, and undirected multigraphs whose maximum\ndegrees are uniformly bounded by a constant. It is only a quasi-solution\nbecause its number of states depends on the graph or, from another perspective,\ndoes not depend on the graph but is countably infinite. To construct this\nquasi-solution we introduce signal machines over continuum representations of\nsuch multigraphs and construct a signal machine whose discretisation is a\ncellular automaton that quasi-solves the problem. This automaton uses a\ntime-optimal solution of the firing squad synchronisation problem in dimension\none with one general at one end to synchronise edges, and freezes and thaws the\nsynchronisation of edges in such a way that all edges synchronise at the same\ntime.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 11:47:45 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Wacker", "Simon", ""]]}, {"id": "1706.06035", "submitter": "Dr Md Hasanul Ferdaus Hasanul", "authors": "Md Hasanul Ferdaus, Manzur Murshed, Rodrigo N. Calheiros, and Rajkumar\n  Buyya", "title": "An Algorithm for Network and Data-aware Placement of Multi-Tier\n  Applications in Cloud Data Centers", "comments": "Submitted for publication consideration for the Journal of Network\n  and Computer Applications (JNCA). Total page: 28. Number of figures: 15\n  figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's Cloud applications are dominated by composite applications comprising\nmultiple computing and data components with strong communication correlations\namong them. Although Cloud providers are deploying large number of computing\nand storage devices to address the ever increasing demand for computing and\nstorage resources, network resource demands are emerging as one of the key\nareas of performance bottleneck. This paper addresses network-aware placement\nof virtual components (computing and data) of multi-tier applications in data\ncenters and formally defines the placement as an optimization problem. The\nsimultaneous placement of Virtual Machines and data blocks aims at reducing the\nnetwork overhead of the data center network infrastructure. A greedy heuristic\nis proposed for the on-demand application components placement that localizes\nnetwork traffic in the data center interconnect. Such optimization helps\nreducing communication overhead in upper layer network switches that will\neventually reduce the overall traffic volume across the data center. This, in\nturn, will help reducing packet transmission delay, increasing network\nperformance, and minimizing the energy consumption of network components.\nExperimental results demonstrate performance superiority of the proposed\nalgorithm over other approaches where it outperforms the state-of-the-art\nnetwork-aware application placement algorithm across all performance metrics by\nreducing the average network cost up to 67% and network usage at core switches\nup to 84%, as well as increasing the average number of application deployments\nup to 18%.\n", "versions": [{"version": "v1", "created": "Mon, 19 Jun 2017 16:16:10 GMT"}], "update_date": "2017-06-20", "authors_parsed": [["Ferdaus", "Md Hasanul", ""], ["Murshed", "Manzur", ""], ["Calheiros", "Rodrigo N.", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1706.06333", "submitter": "Soumen Kanrar", "authors": "Soumen Kanrar", "title": "Fast Load Balancing Approach for Growing Clusters by Bioinformatics", "comments": "4 Pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Fast load balancing technique inspired by Bioinformatics\nis a special case to assign a particular patient with a specialist physician\ncluster at real time. The work is considered soft presentation of the Gaussian\nmixture model based on the extracted features supplied by patients. Based on\nthe likelihood ratio test, the patient is assigned to a specialist physician\ncluster. The presented algorithms efficiently handle any size and any numbers\nof incoming patient requests and rapidly placed them to the specialist\nphysician cluster. Hence it smoothly balances the traffic load of patients even\nat a hazard situation in the case of natural calamities. The simulation results\nare presented with variable size of specialist physician clusters that well\naddress the issue for randomly growing patient size.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 09:23:11 GMT"}], "update_date": "2017-06-21", "authors_parsed": [["Kanrar", "Soumen", ""]]}, {"id": "1706.06535", "submitter": "Hung Cao", "authors": "Ikechukwu Maduako, Hung Cao, Lilian Hernandez, Monica Wachowicz", "title": "Combining edge and cloud computing for mobility analytics", "comments": "Edge Computing, Cloud Computing, Mobility Analytics, Internet of\n  Mobile Things, Edge Fog Fabric", "journal-ref": null, "doi": "10.1145/3132211.3132452", "report-no": null, "categories": "cs.DC cs.CY cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobility analytics using data generated from the Internet of Mobile Things\n(IoMT) is facing many challenges which range from the ingestion of data streams\ncoming from a vast number of fog nodes and IoMT devices to avoiding overflowing\nthe cloud with useless massive data streams that can trigger bottlenecks [1].\nManaging data flow is becoming an important part of the IoMT because it will\ndictate in which platform analytical tasks should run in the future. Data flows\nare usually a sequence of out-of-order tuples with a high data input rate, and\nmobility analytics requires a real-time flow of data in both directions, from\nthe edge to the cloud, and vice-versa. Before pulling the data streams to the\ncloud, edge data stream processing is needed for detecting missing, broken, and\nduplicated tuples in addition to recognize tuples whose arrival time is out of\norder. Analytical tasks such as data filtering, data cleaning and low-level\ndata contextualization can be executed at the edge of a network. In contrast,\nmore complex analytical tasks such as graph processing can be deployed in the\ncloud, and the results of ad-hoc queries and streaming graph analytics can be\npushed to the edge as needed by a user application. Graphs are efficient\nrepresentations used in mobility analytics because they unify knowledge about\nconnectivity, proximity and interaction among moving things. This poster\ndescribes the preliminary results from our experimental prototype developed for\nsupporting transit systems, in which edge and cloud computing are combined to\nprocess transit data streams forwarded from fog nodes into a cloud. The\nmotivation of this research is to understand how to perform meaningfulness\nmobility analytics on transit feeds by combining cloud and fog computing\narchitectures in order to improve fleet management, mass transit and remote\nasset monitoring\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 16:18:07 GMT"}], "update_date": "2018-03-13", "authors_parsed": [["Maduako", "Ikechukwu", ""], ["Cao", "Hung", ""], ["Hernandez", "Lilian", ""], ["Wachowicz", "Monica", ""]]}, {"id": "1706.06646", "submitter": "Md Hasanul Ferdaus Hasanul", "authors": "Md Hasanul Ferdaus, Manzur Murshed, Rodrigo N. Calheiros, and Rajkumar\n  Buyya", "title": "Multi-objective, Decentralized Dynamic Virtual Machine Consolidation\n  using ACO Metaheuristic in Computing Clouds", "comments": "Submitted for publication consideration in Journal Concurrency and\n  Computation: Practice and Experience. Number of pages: 40. Number of figures:\n  15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Underutilization of computing resources and high power consumption are two\nprimary challenges in the domain of Cloud resource management. This paper deals\nwith these challenges through offline, migration impact-aware, multi-objective\ndynamic Virtual Machine (VM) consolidation in the context of large-scale\nvirtualized data center environments. The problem is formulated as an NP-hard\ndiscrete combinatorial optimization problem with simultaneous objectives of\nminimizing resource wastage, power consumption, and the associated VM migration\noverhead. Since dynamic VM consolidation through VM live migrations have\nnegative impacts on hosted applications performance and data center components,\na VM live migration overhead estimation technique is proposed, which takes into\naccount pragmatic migration parameters and overhead factors. In order to tackle\nscalability issues, a hierarchical, decentralized dynamic VM consolidation\nframework is presented that helps to localize migration-related network traffic\nand reduce network cost. Moreover, a multi-objective, dynamic VM consolidation\nalgorithm is proposed by utilizing the Ant Colony Optimization (ACO)\nmetaheuristic, with integration of the proposed VM migration overhead\nestimation technique. Comprehensive performance evaluation makes it evident\nthat the proposed dynamic VM consolidation approach outpaces the\nstate-of-the-art offline, migration-aware dynamic VM consolidation algorithm\nacross all performance metrics by reducing the overall power consumption by up\nto 47%, resource wastage by up to 64%, and migration overhead by up to 83%.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 19:57:00 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Ferdaus", "Md Hasanul", ""], ["Murshed", "Manzur", ""], ["Calheiros", "Rodrigo N.", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1706.06687", "submitter": "Jose Fontanari", "authors": "Jos\\'e F. Fontanari", "title": "Reputation blackboard systems", "comments": null, "journal-ref": "Cognitive Systems Research 50, 29-35 (2018)", "doi": "10.1016/j.cogsys.2018.03.008", "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blackboard systems are motivated by the popular view of task forces as\nbrainstorming groups in which specialists write promising ideas to solve a\nproblem in a central blackboard. Here we study a minimal model of blackboard\nsystem designed to solve cryptarithmetic puzzles, where hints are posted\nanonymously on a public display (standard blackboard) or are posted together\nwith information about the reputations of the agents that posted them\n(reputation blackboard). We find that the reputation blackboard always\noutperforms the standard blackboard, which, in turn, always outperforms the\nindependent search. The asymptotic distribution of the computational cost of\nthe search, which is proportional to the total number of agent updates required\nto find the solution of the puzzle, is an exponential distribution for those\nthree search heuristics. Only for the reputation blackboard we find a\nnontrivial dependence of the mean computational cost on the system size and, in\nthat case, the optimal performance is achieved by a single agent working alone,\nindicating that, though the blackboard organization can produce impressive\nperformance gains when compared with the independent search, it is not very\nsupportive of cooperative work.\n", "versions": [{"version": "v1", "created": "Tue, 20 Jun 2017 22:25:14 GMT"}], "update_date": "2018-04-16", "authors_parsed": [["Fontanari", "Jos\u00e9 F.", ""]]}, {"id": "1706.06789", "submitter": "Chris Dowden", "authors": "Chris Dowden", "title": "Agreement Protocols on an Arbitrary Network in the Presence of a Mobile\n  Adversary", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We investigate the problem of obtaining agreement protocols in the presence\nof a mobile adversary, who can control an ever-changing selection of\nprocessors. We make improvements to previous results for the case when the\ncommunications network forms a complete graph, and also adapt these to the\ngeneral case when the network is not complete.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 08:38:03 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Dowden", "Chris", ""]]}, {"id": "1706.07035", "submitter": "Ravi  Tandon", "authors": "Ravi Tandon", "title": "The Capacity of Cache Aided Private Information Retrieval", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.CR cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of cache enabled private information retrieval (PIR) is\nconsidered in which a user wishes to privately retrieve one out of $K$\nmessages, each of size $L$ bits from $N$ distributed databases. The user has a\nlocal cache of storage $SL$ bits which can be used to store any function of the\n$K$ messages. The main contribution of this work is the exact characterization\nof the capacity of cache aided PIR as a function of the storage parameter $S$.\nIn particular, for a given cache storage parameter $S$, the\ninformation-theoretically optimal download cost $D^{*}(S)/L$ (or the inverse of\ncapacity) is shown to be equal to $(1- \\frac{S}{K})\\left(1+ \\frac{1}{N}+ \\ldots\n+ \\frac{1}{N^{K-1}}\\right)$. Special cases of this result correspond to the\nsettings when $S=0$, for which the optimal download cost was shown by Sun and\nJafar to be $\\left(1+ \\frac{1}{N}+ \\ldots + \\frac{1}{N^{K-1}}\\right)$, and the\ncase when $S=K$, i.e., cache size is large enough to store all messages\nlocally, for which the optimal download cost is $0$. The intermediate points\n$S\\in (0, K)$ can be readily achieved through a simple memory-sharing based PIR\nscheme. The key technical contribution of this work is the converse, i.e., a\nlower bound on the download cost as a function of storage $S$ which shows that\nmemory sharing is information-theoretically optimal.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 17:56:11 GMT"}], "update_date": "2017-06-22", "authors_parsed": [["Tandon", "Ravi", ""]]}, {"id": "1706.07098", "submitter": "Liang Zhao", "authors": "Lei Shi, Liang Zhao, Wen-Zhan Song, Goutham Kamath, Yuan Wu, Xuefeng\n  Liu", "title": "Distributed Least-Squares Iterative Methods in Networks: A Survey", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many science and engineering applications involve solving a linear\nleast-squares system formed from some field measurements. In the distributed\ncyber-physical systems (CPS), often each sensor node used for measurement only\nknows partial independent rows of the least-squares system. To compute the\nleast-squares solution they need to gather all these measurement at a\ncentralized location and then compute the solution. These data collection and\ncomputation are inefficient because of bandwidth and time constraints and\nsometimes are infeasible because of data privacy concerns. Thus distributed\ncomputations are strongly preferred or demanded in many of the real world\napplications e.g.: smart-grid, target tracking etc. To compute least squares\nfor the large sparse system of linear equation iterative methods are natural\ncandidates and there are a lot of studies regarding this, however, most of them\nare related to the efficiency of centralized/parallel computations while and\nonly a few are explicitly about distributed computation or have the potential\nto apply in distributed networks. This paper surveys the representative\niterative methods from several research communities. Some of them were not\noriginally designed for this need, so we slightly modified them to suit our\nrequirement and maintain the consistency. In this survey, we sketch the\nskeleton of the algorithm first and then analyze its time-to-completion and\ncommunication cost. To our best knowledge, this is the first survey of\ndistributed least-squares in distributed networks.\n", "versions": [{"version": "v1", "created": "Wed, 21 Jun 2017 19:37:27 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Shi", "Lei", ""], ["Zhao", "Liang", ""], ["Song", "Wen-Zhan", ""], ["Kamath", "Goutham", ""], ["Wu", "Yuan", ""], ["Liu", "Xuefeng", ""]]}, {"id": "1706.07191", "submitter": "Yuechao Lu", "authors": "Yuechao Lu, Fumihiko Ino, Yasuyuki Matsushita", "title": "High-Performance Out-of-core Block Randomized Singular Value\n  Decomposition on GPU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fast computation of singular value decomposition (SVD) is of great interest\nin various machine learning tasks. Recently, SVD methods based on randomized\nlinear algebra have shown significant speedup in this regime. This paper\nattempts to further accelerate the computation by harnessing a modern computing\narchitecture, namely graphics processing unit (GPU), with the goal of\nprocessing large-scale data that may not fit in the GPU memory. It leads to a\nnew block randomized algorithm that fully utilizes the power of GPUs and\nefficiently processes large-scale data in an out-of- core fashion. Our\nexperiment shows that the proposed block randomized SVD (BRSVD) method\noutperforms existing randomized SVD methods in terms of speed with retaining\nthe same accuracy. We also show its application to convex robust principal\ncomponent analysis, which shows significant speedup in computer vision\napplications.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 07:35:02 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Lu", "Yuechao", ""], ["Ino", "Fumihiko", ""], ["Matsushita", "Yasuyuki", ""]]}, {"id": "1706.07221", "submitter": "Bo Suo", "authors": "Qun Chen, Song Bai, Zhanhuai Li, Zhiying Gou, Bo Suo, Wei Pan", "title": "GraphHP: A Hybrid Platform for Iterative Graph Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Bulk Synchronous Parallel(BSP) computational model has emerged as the\ndominant distributed framework to build large-scale iterative graph processing\nsystems. While its implementations(e.g., Pregel, Giraph, and Hama) achieve high\nscalability, frequent synchronization and communication among the workers can\ncause substantial parallel inefficiency. To help address this critical concern,\nthis paper introduces the GraphHP(Graph Hybrid Processing) platform which\ninherits the friendly vertex-centric BSP programming interface and optimizes\nits synchronization and communication overhead.\n  To achieve the goal, we first propose a hybrid execution model which\ndifferentiates between the computations within a graph partition and across the\npartitions, and decouples the computations within a partition from distributed\nsynchronization and communication. By implementing the computations within a\npartition by pseudo-superstep iteration in memory, the hybrid execution model\ncan effectively reduce synchronization and communication overhead while not\nrequiring heavy scheduling overhead or graph-centric sequential algorithms. We\nthen demonstrate how the hybrid execution model can be easily implemented\nwithin the BSP abstraction to preserve its simple programming interface.\nFinally, we evaluate our implementation of the GraphHP platform on classical\nBSP applications and show that it performs significantly better than the\nstate-of-the-art BSP implementations. Our GraphHP implementation is based on\nHama, but can easily generalize to other BSP platforms.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 09:26:41 GMT"}], "update_date": "2017-06-23", "authors_parsed": [["Chen", "Qun", ""], ["Bai", "Song", ""], ["Li", "Zhanhuai", ""], ["Gou", "Zhiying", ""], ["Suo", "Bo", ""], ["Pan", "Wei", ""]]}, {"id": "1706.07429", "submitter": "Mohamed Hassan Dr.", "authors": "Mohamed Hassan", "title": "Heterogeneous MPSoCs for Mixed Criticality Systems: Challenges and\n  Opportunities", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Due to their cost, performance, area, and energy efficiency, MPSoCs offer\nappealing architecture for emerging mixed criticality systems (MCS) such as\ndriverless cars, smart power grids, and healthcare devices. Furthermore,\nheterogeneity of MPSoCs presents exceptional opportunities to satisfy the\nconflicting requirements of MCS. Seizing these opportunities is unattainable\nwithout addressing the associated challenges. We focus on four aspects of MCS\nthat we believe are of most importance upon adopting MPSoCs: theoretical model,\ninterference, data sharing, and security. We outline existing solutions,\nhighlight the necessary considerations for MPSoCs including both opportunities\nthey create and research directions yet to be explored.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 05:30:02 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Hassan", "Mohamed", ""]]}, {"id": "1706.07519", "submitter": "Piotr Luszczek", "authors": "Micah Beck, Terry Moore, Piotr Luszczek, and Anthony Danalis", "title": "Interoperable Convergence of Storage, Networking, and Computation", "comments": "15 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In every form of digital store-and-forward communication, intermediate\nforwarding nodes are computers, with attendant memory and processing resources.\nThis has inevitably stimulated efforts to create a wide-area infrastructure\nthat goes beyond simple store-and-forward to create a platform that makes more\ngeneral and varied use of the potential of this collection of increasingly\npowerful nodes. Historically, these efforts predate the advent of globally\nrouted packet networking. The desire for a converged infrastructure of this\nkind has only intensified over the last 30 years, as memory, storage, and\nprocessing resources have increased in both density and speed while\nsimultaneously decreasing in cost. Although there is a general consensus that\nit should be possible to define and deploy such a dramatically more capable\nwide-area platform, a great deal of investment in research prototypes has yet\nto produce a credible candidate architecture. Drawing on technical analysis,\nhistorical examples, and case studies, we present an argument for the\nhypothesis that in order to realize a distributed system with the kind of\nconvergent generality and deployment scalability that might qualify as\n\"future-defining,\" we must build it from a small set of simple, generic, and\nlimited abstractions of the low level resources (processing, storage and\nnetwork) of its intermediate nodes.\n", "versions": [{"version": "v1", "created": "Thu, 22 Jun 2017 22:58:11 GMT"}, {"version": "v2", "created": "Mon, 7 Aug 2017 19:14:21 GMT"}, {"version": "v3", "created": "Sat, 12 Aug 2017 14:32:20 GMT"}, {"version": "v4", "created": "Tue, 7 Aug 2018 19:35:28 GMT"}, {"version": "v5", "created": "Sun, 18 Nov 2018 03:42:45 GMT"}], "update_date": "2018-11-20", "authors_parsed": [["Beck", "Micah", ""], ["Moore", "Terry", ""], ["Luszczek", "Piotr", ""], ["Danalis", "Anthony", ""]]}, {"id": "1706.07772", "submitter": "H. Metin Aktulga", "authors": "Hasan Metin Aktulga, Christopher Knight, Paul Coffman, Kurt A.\n  O'Hearn, Tzu-Ray Shan, and Wei Jiang", "title": "Optimizing the Performance of Reactive Molecular Dynamics Simulations\n  for Multi-Core Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reactive molecular dynamics simulations are computationally demanding.\nReaching spatial and temporal scales where interesting scientific phenomena can\nbe observed requires efficient and scalable implementations on modern hardware.\nIn this paper, we focus on optimizing the performance of the widely used\nLAMMPS/ReaxC package for multi-core architectures. As hybrid parallelism allows\nbetter leverage of the increasing on-node parallelism, we adopt thread\nparallelism in the construction of bonded and nonbonded lists, and in the\ncomputation of complex ReaxFF interactions. To mitigate the I/O overheads due\nto large volumes of trajectory data produced and to save users the burden of\npost-processing, we also develop a novel in-situ tool for molecular species\nanalysis. We analyze the performance of the resulting ReaxC-OMP package on\nMira, an IBM Blue Gene/Q supercomputer. For PETN systems of sizes ranging from\n32 thousand to 16.6 million particles, we observe speedups in the range of\n1.5-4.5x. We observe sustained performance improvements for up to 262,144 cores\n(1,048,576 processes) of Mira and a weak scaling efficiency of 91.5% in large\nsimulations containing 16.6 million particles. The in-situ molecular species\nanalysis tool incurs only insignificant overheads across various system sizes\nand run configurations.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 16:30:54 GMT"}], "update_date": "2017-06-26", "authors_parsed": [["Aktulga", "Hasan Metin", ""], ["Knight", "Christopher", ""], ["Coffman", "Paul", ""], ["O'Hearn", "Kurt A.", ""], ["Shan", "Tzu-Ray", ""], ["Jiang", "Wei", ""]]}, {"id": "1706.07831", "submitter": "Bernadette Charron-Bost", "authors": "Bernadette Charron-Bost and Shlomo Moran", "title": "Synchronization in Dynamic Networks", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we study algorithms for dynamic networks with asynchronous\nstart, i.e., each node may start running the algorithm in a different round.\nInactive nodes transmit only heartbeats, which contain no information but can\nbe detected by active nodes. We make no assumption on the way the nodes are\nawakened, except that for each node u there is a time $s_u$ in which it is\nawakened and starts to run the algorithm. The identities of the nodes are not\nmutually known, and the network size is unknown as well.\n  We present synchronization algorithms, which guarantee that after a finite\nnumber of rounds, all nodes hold the same round number, which is incremented by\none each round thereafter. We study the time complexity and message size\nrequired for synchronization, and specifically for simultaneous\nsynchronization, in which all nodes synchronize their round numbers at exactly\nthe same round.\n  We show that there is a strong relation between the complexity of\nsimultaneous synchronization and the connectivity of the dynamic graphs: With\nhigh connectivity which guarantees that messages can be broadcasted in a\nconstant number of rounds, simultaneous synchronization by all nodes can be\nobtained by a deterministic algorithm within a constant number of rounds, and\nwith messages of constant size. With a weaker connectivity, which only\nguarantees that the broadcast time is proportional to the network size, our\nalgorithms still achieve simultaneous synchronization, but within linear time\nand long messages.\n  We also discuss how information on the network size and randomization may\nimprove synchronization algorithms, and show related impossibility results.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 18:41:12 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Charron-Bost", "Bernadette", ""], ["Moran", "Shlomo", ""]]}, {"id": "1706.07853", "submitter": "Sayeh Sharify", "authors": "Sayeh Sharify, Alberto Delmas Lascorz, Kevin Siu, Patrick Judd,\n  Andreas Moshovos", "title": "Loom: Exploiting Weight and Activation Precisions to Accelerate\n  Convolutional Neural Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Loom (LM), a hardware inference accelerator for Convolutional Neural Networks\n(CNNs) is presented. In LM every bit of data precision that can be saved\ntranslates to proportional performance gains. Specifically, for convolutional\nlayers LM's execution time scales inversely proportionally with the precisions\nof both weights and activations. For fully-connected layers LM's performance\nscales inversely proportionally with the precision of the weights. LM targets\narea- and bandwidth-constrained System-on-a-Chip designs such as those found on\nmobile devices that cannot afford the multi-megabyte buffers that would be\nneeded to store each layer on-chip. Accordingly, given a data bandwidth budget,\nLM boosts energy efficiency and performance over an equivalent bit-parallel\naccelerator. For both weights and activations LM can exploit profile-derived\nperlayer precisions. However, at runtime LM further trims activation precisions\nat a much smaller than a layer granularity. Moreover, it can naturally exploit\nweight precision variability at a smaller granularity than a layer. On average,\nacross several image classification CNNs and for a configuration that can\nperform the equivalent of 128 16b x 16b multiply-accumulate operations per\ncycle LM outperforms a state-of-the-art bit-parallel accelerator [1] by 4.38x\nwithout any loss in accuracy while being 3.54x more energy efficient. LM can\ntrade-off accuracy for additional improvements in execution performance and\nenergy efficiency and compares favorably to an accelerator that targeted only\nactivation precisions. We also study 2- and 4-bit LM variants and find the the\n2-bit per cycle variant is the most energy efficient.\n", "versions": [{"version": "v1", "created": "Fri, 23 Jun 2017 20:35:42 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 19:31:40 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Sharify", "Sayeh", ""], ["Lascorz", "Alberto Delmas", ""], ["Siu", "Kevin", ""], ["Judd", "Patrick", ""], ["Moshovos", "Andreas", ""]]}, {"id": "1706.08012", "submitter": "Harishchandra Dubey", "authors": "Harishchandra Dubey, Admir Monteiro, Nicholas Constant, Mohammadreza\n  Abtahi, Debanjan Borthakur, Leslie Mahler, Yan Sun, Qing Yang, Umer Akbar,\n  Kunal Mankodiya", "title": "Fog Computing in Medical Internet-of-Things: Architecture,\n  Implementation, and Applications", "comments": "29 pages, 30 figures, 5 tables. Keywords: Big Data, Body Area\n  Network, Body Sensor Network, Edge Computing, Fog Computing, Medical\n  Cyberphysical Systems, Medical Internet-of-Things, Telecare, Tele-treatment,\n  Wearable Devices, Chapter in Handbook of Large-Scale Distributed Computing in\n  Smart Healthcare (2017), Springer", "journal-ref": null, "doi": "10.1007/978-3-319-58280-1_11", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the era when the market segment of Internet of Things (IoT) tops the chart\nin various business reports, it is apparently envisioned that the field of\nmedicine expects to gain a large benefit from the explosion of wearables and\ninternet-connected sensors that surround us to acquire and communicate\nunprecedented data on symptoms, medication, food intake, and daily-life\nactivities impacting one's health and wellness. However, IoT-driven healthcare\nwould have to overcome many barriers, such as: 1) There is an increasing demand\nfor data storage on cloud servers where the analysis of the medical big data\nbecomes increasingly complex, 2) The data, when communicated, are vulnerable to\nsecurity and privacy issues, 3) The communication of the continuously collected\ndata is not only costly but also energy hungry, 4) Operating and maintaining\nthe sensors directly from the cloud servers are non-trial tasks. This book\nchapter defined Fog Computing in the context of medical IoT. Conceptually, Fog\nComputing is a service-oriented intermediate layer in IoT, providing the\ninterfaces between the sensors and cloud servers for facilitating connectivity,\ndata transfer, and queryable local database. The centerpiece of Fog computing\nis a low-power, intelligent, wireless, embedded computing node that carries out\nsignal conditioning and data analytics on raw data collected from wearables or\nother medical sensors and offers efficient means to serve telehealth\ninterventions. We implemented and tested an fog computing system using the\nIntel Edison and Raspberry Pi that allows acquisition, computing, storage and\ncommunication of the various medical data such as pathological speech data of\nindividuals with speech disorders, Phonocardiogram (PCG) signal for heart rate\nestimation, and Electrocardiogram (ECG)-based Q, R, S detection.\n", "versions": [{"version": "v1", "created": "Sat, 24 Jun 2017 23:33:07 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Dubey", "Harishchandra", ""], ["Monteiro", "Admir", ""], ["Constant", "Nicholas", ""], ["Abtahi", "Mohammadreza", ""], ["Borthakur", "Debanjan", ""], ["Mahler", "Leslie", ""], ["Sun", "Yan", ""], ["Yang", "Qing", ""], ["Akbar", "Umer", ""], ["Mankodiya", "Kunal", ""]]}, {"id": "1706.08018", "submitter": "Harishchandra Dubey", "authors": "Noopur Gupta, Rakesh K. Lenka, Rabindra K. Barik, Harishchandra Dubey", "title": "FAIR: A Hadoop-based Hybrid Model for Faculty Information Retrieval\n  System", "comments": "6 pages, 11 figures, 2017 International Conference on Intelligent\n  Computing and Control(I2C2'17), IEEE, June 23-24, 2017, Coimbatore, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In era of ever-expanding data and knowledge, we lack a centralized system\nthat maps all the faculties to their research works. This problem has not been\naddressed in the past and it becomes challenging for students to connect with\nthe right faculty of their domain. Since we have so many colleges and faculties\nthis lies in the category of big data problem. In this paper, we present a\nmodel which works on the distributed computing environment to tackle big data.\nThe proposed model uses apache spark as an execution engine and hive as\ndatabase. The results are visualized with the help of Tableau that is connected\nto Apache Hive to achieve distributed computing.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 01:17:46 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Gupta", "Noopur", ""], ["Lenka", "Rakesh K.", ""], ["Barik", "Rabindra K.", ""], ["Dubey", "Harishchandra", ""]]}, {"id": "1706.08093", "submitter": "Christophe Guyeux", "authors": "Mohammed Bakiri and Jean-Fran\\c{c}ois Couchot and Christophe Guyeux", "title": "One random jump and one permutation: sufficient conditions to chaotic,\n  statistically faultless, and large throughput PRNG for FPGA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sub-categories of mathematical topology, like the mathematical theory of\nchaos, offer interesting applications devoted to information security. In this\nresearch work, we have introduced a new chaos-based pseudorandom number\ngenerator implemented in FPGA, which is mainly based on the deletion of a\nHamilton cycle within the $n$-cube (or on the vectorial negation), plus one\nsingle permutation. By doing so, we produce a kind of post-treatment on\nhardware pseudorandom generators, but the obtained generator has usually a\nbetter statistical profile than its input, while running at a similar speed. We\ntested 6 combinations of Boolean functions and strategies that all achieve to\npass the most stringent TestU01 battery of tests. This generation can reach a\nthroughput/latency ratio equal to 6.7 Gbps, being thus the second fastest FPGA\ngenerator that can pass TestU01.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 12:57:02 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Bakiri", "Mohammed", ""], ["Couchot", "Jean-Fran\u00e7ois", ""], ["Guyeux", "Christophe", ""]]}, {"id": "1706.08133", "submitter": "Christophe Guyeux", "authors": "Christophe Guyeux, Abdallah Makhoul, Jacques M. Bahi", "title": "A Security Framework for Wireless Sensor Networks: Theory and Practice", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless sensor networks are often deployed in public or otherwise untrusted\nand even hostile environments, which prompts a number of security issues.\nAlthough security is a necessity in other types of networks, it is much more so\nin sensor networks due to the resource-constraint, susceptibility to physical\ncapture, and wireless nature. In this work we emphasize two security issues:\n(1) secure communication infrastructure and (2) secure nodes scheduling\nalgorithm. Due to resource constraints, specific strategies are often necessary\nto preserve the network's lifetime and its quality of service. For instance, to\nreduce communication costs nodes can go to sleep mode periodically (nodes\nscheduling). These strategies must be proven as secure, but protocols used to\nguarantee this security must be compatible with the resource preservation\nrequirement. To achieve this goal, secure communications in such networks will\nbe defined, together with the notions of secure scheduling. Finally, some of\nthese security properties will be evaluated in concrete case studies.\n", "versions": [{"version": "v1", "created": "Sun, 25 Jun 2017 16:17:25 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Guyeux", "Christophe", ""], ["Makhoul", "Abdallah", ""], ["Bahi", "Jacques M.", ""]]}, {"id": "1706.08210", "submitter": "Fei Wang", "authors": "Fei Wang, Jun Ye, Weichen Li, Guihai Chen", "title": "IS-ASGD: Accelerating Asynchronous SGD using Importance Sampling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Variance reduction (VR) techniques for convergence rate acceleration of\nstochastic gradient descent (SGD) algorithm have been developed with great\nefforts recently. VR's two variants, stochastic variance-reduced-gradient\n(SVRG-SGD) and importance sampling (IS-SGD) have achieved remarkable\nprogresses. Meanwhile, asynchronous SGD (ASGD) is becoming more critical due to\nthe ever-increasing scale of the optimization problems. The application of VR\nin ASGD to accelerate its convergence rate has therefore attracted much\ninterest and SVRG-ASGDs are therefore proposed. However, we found that SVRG\nsuffers dissatisfying performance in accelerating ASGD when the datasets are\nsparse and large-scale. In such case, SVRG-ASGD's iterative computation cost is\nmagnitudes higher than ASGD which makes it very slow. On the other hand, IS\nachieves improved convergence rate with few extra computation cost and is\ninvariant to the sparsity of dataset. This advantage makes it very suitable for\nthe acceleration of ASGD for large-scale sparse datasets. In this paper we\npropose a novel IS-combined ASGD for effective convergence rate acceleration,\nnamely, IS-ASGD. We theoretically prove the superior convergence bound of\nIS-ASGD. Experimental results also demonstrate our statements.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 02:38:44 GMT"}, {"version": "v2", "created": "Sun, 10 Dec 2017 04:21:43 GMT"}, {"version": "v3", "created": "Tue, 10 Apr 2018 16:05:10 GMT"}], "update_date": "2018-04-11", "authors_parsed": [["Wang", "Fei", ""], ["Ye", "Jun", ""], ["Li", "Weichen", ""], ["Chen", "Guihai", ""]]}, {"id": "1706.08302", "submitter": "Jo\\~ao Paulo de Araujo", "authors": "Jo\\~ao Paulo de Araujo and Luciana Arantes and Elias P. Duarte Jr. and\n  Luiz A. Rodrigues and Pierre Sens", "title": "VCube-PS: A Causal Broadcast Topic-based Publish/Subscribe System", "comments": "Improved text and performance evaluation. Added proof for the\n  algorithms (Section 3.4)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we present VCube-PS, a topic-based Publish/Subscribe system\nbuilt on the top of a virtual hypercube-like topology. Membership information\nand published messages are broadcast to subscribers (members) of a topic group\nover dynamically built spanning trees rooted at the publisher. For a given\ntopic, the delivery of published messages respects the causal order. VCube-PS\nwas implemented on the PeerSim simulator, and experiments are reported\nincluding a comparison with the traditional Publish/Subscribe approach that\nemploys a single rooted static spanning-tree for message distribution. Results\nconfirm the efficiency of VCube-PS in terms of scalability, latency, number and\nsize of messages.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 09:57:12 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 21:48:16 GMT"}], "update_date": "2018-07-06", "authors_parsed": [["de Araujo", "Jo\u00e3o Paulo", ""], ["Arantes", "Luciana", ""], ["Duarte", "Elias P.", "Jr."], ["Rodrigues", "Luiz A.", ""], ["Sens", "Pierre", ""]]}, {"id": "1706.08359", "submitter": "Huan Zhang", "authors": "Huan Zhang, Si Si, Cho-Jui Hsieh", "title": "GPU-acceleration for Large-scale Tree Boosting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present a novel massively parallel algorithm for\naccelerating the decision tree building procedure on GPUs (Graphics Processing\nUnits), which is a crucial step in Gradient Boosted Decision Tree (GBDT) and\nrandom forests training. Previous GPU based tree building algorithms are based\non parallel multi-scan or radix sort to find the exact tree split, and thus\nsuffer from scalability and performance issues. We show that using a histogram\nbased algorithm to approximately find the best split is more efficient and\nscalable on GPU. By identifying the difference between classical GPU-based\nimage histogram construction and the feature histogram construction in decision\ntree training, we develop a fast feature histogram building kernel on GPU with\ncarefully designed computational and memory access sequence to reduce atomic\nupdate conflict and maximize GPU utilization. Our algorithm can be used as a\ndrop-in replacement for histogram construction in popular tree boosting systems\nto improve their scalability. As an example, to train GBDT on epsilon dataset,\nour method using a main-stream GPU is 7-8 times faster than histogram based\nalgorithm on CPU in LightGBM and 25 times faster than the exact-split finding\nalgorithm in XGBoost on a dual-socket 28-core Xeon server, while achieving\nsimilar prediction accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 13:27:29 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Zhang", "Huan", ""], ["Si", "Si", ""], ["Hsieh", "Cho-Jui", ""]]}, {"id": "1706.08362", "submitter": "Guillaume Latu", "authors": "Marc Sauget and Guillaume Latu", "title": "Dynamic Load Balancing for PIC code using Eulerian/Lagrangian\n  partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document presents an analysis of different load balance strategies for a\nPlasma physics code that models high energy particle beams with PIC method. A\ncomparison of different load balancing algorithms is given: static or dynamic\nones. Lagrangian and Eulerian partitioning techniques have been investigated.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 13:29:46 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Sauget", "Marc", ""], ["Latu", "Guillaume", ""]]}, {"id": "1706.08366", "submitter": "Jaros{\\l}aw Mirek", "authors": "Marek Klonowski and Dariusz R. Kowalski and Jaroslaw Mirek", "title": "Ordered and Delayed Adversaries and How to Work against Them on a Shared\n  Channel", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work we define a class of ordered adversaries causing distractions\naccording to some partial order fixed by the adversary before the execution,\nand study how they affect performance of algorithms. We focus on the Do-All\nproblem of performing t tasks on a shared channel consisting of p crash-prone\nstations. The channel restricts communication: no message is delivered to the\nalive stations if more than one station transmits at the same time. The\nperformance measure for the Do-All problem is work: the total number of\navailable processor steps during the whole execution. We address the question\nof how the ordered adversaries controlling crashes of stations influence work\nperformance of Do-All algorithms. The first presented algorithm solves Do-All\nwith work O(t+p\\sqrt{t}\\log p) against the Linearly-Ordered adversary,\nrestricted by some pre-defined linear order of crashing stations. Another\nalgorithm runs against the Weakly-Adaptive adversary, restricted by some\npre-defined set of f crash-prone stations (it can be seen as restricted by the\norder being an anti-chain of crashing stations). The work done by this\nalgorithm is O(t+p\\sqrt{t}+p\\min{p/(p-f),t}\\log p). Both results are close to\nthe corresponding lower bounds from [CKL]. We generalize this result to the\nclass of adversaries restricted by a partial order with a maximum anti-chain of\nsize k and complement with the lower bound. We also consider a class of delayed\nadaptive adversaries, who could see random choices with some delay. We give an\nalgorithm that runs against the 1-RD adversary (seeing random choices of\nstations with one round delay), achieving close to optimal O(t+p\\sqrt{t}\\log^2\np) work complexity. This shows that restricting adversary by even 1 round delay\nresults in (almost) optimal work on a shared channel.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 13:34:50 GMT"}, {"version": "v2", "created": "Fri, 29 Dec 2017 16:46:06 GMT"}, {"version": "v3", "created": "Tue, 24 Jul 2018 20:33:58 GMT"}], "update_date": "2018-07-26", "authors_parsed": [["Klonowski", "Marek", ""], ["Kowalski", "Dariusz R.", ""], ["Mirek", "Jaroslaw", ""]]}, {"id": "1706.08420", "submitter": "Ruben Mayer", "authors": "Christian Mayer, Ruben Mayer, Majd Abdo", "title": "StreamLearner: Distributed Incremental Machine Learning on Event\n  Streams: Grand Challenge", "comments": "Christian Mayer, Ruben Mayer, and Majd Abdo. 2017. StreamLearner:\n  Distributed Incremental Machine Learning on Event Streams: Grand Challenge.\n  In Proceedings of the 11th ACM International Conference on Distributed and\n  Event-based Systems (DEBS '17), 298-303", "journal-ref": null, "doi": "10.1145/3093742.3095103", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today, massive amounts of streaming data from smart devices need to be\nanalyzed automatically to realize the Internet of Things. The Complex Event\nProcessing (CEP) paradigm promises low-latency pattern detection on event\nstreams. However, CEP systems need to be extended with Machine Learning (ML)\ncapabilities such as online training and inference in order to be able to\ndetect fuzzy patterns (e.g., outliers) and to improve pattern recognition\naccuracy during runtime using incremental model training. In this paper, we\npropose a distributed CEP system denoted as StreamLearner for ML-enabled\ncomplex event detection. The proposed programming model and data-parallel\nsystem architecture enable a wide range of real-world applications and allow\nfor dynamically scaling up and out system resources for low-latency,\nhigh-throughput event processing. We show that the DEBS Grand Challenge 2017\ncase study (i.e., anomaly detection in smart factories) integrates seamlessly\ninto the StreamLearner API. Our experiments verify scalability and high event\nthroughput of StreamLearner.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 14:54:18 GMT"}], "update_date": "2017-06-27", "authors_parsed": [["Mayer", "Christian", ""], ["Mayer", "Ruben", ""], ["Abdo", "Majd", ""]]}, {"id": "1706.08569", "submitter": "Saverio Perugini", "authors": "Tyler M. Masthay and Saverio Perugini", "title": "Parareal Algorithm Implementation and Simulation in Julia", "comments": "6 pages, 2 figures, 2 listings", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a full implementation of the parareal algorithm---an integration\ntechnique to solve differential equations in parallel---in the Julia\nprogramming language for a fully general, first-order, initial-value problem.\nWe provide a brief overview of Julia---a concurrent programming language for\nscientific computing. Our implementation of the parareal algorithm accepts both\ncoarse and fine integrators as functional arguments. We use Euler's method and\nanother Runge-Kutta integration technique as the integrators in our\nexperiments. We also present a simulation of the algorithm for purposes of\npedagogy and as a tool for investigating the performance of the algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 26 Jun 2017 19:27:58 GMT"}, {"version": "v2", "created": "Thu, 13 Dec 2018 20:21:25 GMT"}], "update_date": "2018-12-17", "authors_parsed": [["Masthay", "Tyler M.", ""], ["Perugini", "Saverio", ""]]}, {"id": "1706.08700", "submitter": "Claudio Sanhueza", "authors": "Claudio Sanhueza, Francia Jimenez, Regina Berretta, and Pablo Moscato", "title": "PasMoQAP: A Parallel Asynchronous Memetic Algorithm for solving the\n  Multi-Objective Quadratic Assignment Problem", "comments": "8 pages, 3 figures, 2 tables. Accepted at Conference on Evolutionary\n  Computation 2017 (CEC 2017)", "journal-ref": null, "doi": "10.1109/CEC.2017.7969430", "report-no": null, "categories": "cs.NE cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Multi-Objective Optimization Problems (MOPs) have attracted growing attention\nduring the last decades. Multi-Objective Evolutionary Algorithms (MOEAs) have\nbeen extensively used to address MOPs because are able to approximate a set of\nnon-dominated high-quality solutions. The Multi-Objective Quadratic Assignment\nProblem (mQAP) is a MOP. The mQAP is a generalization of the classical QAP\nwhich has been extensively studied, and used in several real-life applications.\nThe mQAP is defined as having as input several flows between the facilities\nwhich generate multiple cost functions that must be optimized simultaneously.\nIn this study, we propose PasMoQAP, a parallel asynchronous memetic algorithm\nto solve the Multi-Objective Quadratic Assignment Problem. PasMoQAP is based on\nan island model that structures the population by creating sub-populations. The\nmemetic algorithm on each island individually evolve a reduced population of\nsolutions, and they asynchronously cooperate by sending selected solutions to\nthe neighboring islands. The experimental results show that our approach\nsignificatively outperforms all the island-based variants of the\nmulti-objective evolutionary algorithm NSGA-II. We show that PasMoQAP is a\nsuitable alternative to solve the Multi-Objective Quadratic Assignment Problem.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 07:42:31 GMT"}], "update_date": "2018-04-03", "authors_parsed": [["Sanhueza", "Claudio", ""], ["Jimenez", "Francia", ""], ["Berretta", "Regina", ""], ["Moscato", "Pablo", ""]]}, {"id": "1706.08884", "submitter": "El Mahdi El Mhamdi", "authors": "El Mahdi El Mhamdi and Rachid Guerraoui", "title": "When Neurons Fail", "comments": "2017 IEEE International Parallel and Distributed Processing\n  Symposium, Orlando, Florida", "journal-ref": null, "doi": "10.1109/IPDPS.2017.66", "report-no": null, "categories": "stat.ML cs.DC cs.NE q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We view a neural network as a distributed system of which neurons can fail\nindependently, and we evaluate its robustness in the absence of any (recovery)\nlearning phase. We give tight bounds on the number of neurons that can fail\nwithout harming the result of a computation. To determine our bounds, we\nleverage the fact that neural activation functions are Lipschitz-continuous.\nOur bound is on a quantity, we call the \\textit{Forward Error Propagation},\ncapturing how much error is propagated by a neural network when a given number\nof components is failing, computing this quantity only requires looking at the\ntopology of the network, while experimentally assessing the robustness of a\nnetwork requires the costly experiment of looking at all the possible inputs\nand testing all the possible configurations of the network corresponding to\ndifferent failure situations, facing a discouraging combinatorial explosion.\n  We distinguish the case of neurons that can fail and stop their activity\n(crashed neurons) from the case of neurons that can fail by transmitting\narbitrary values (Byzantine neurons). Interestingly, as we show in the paper,\nour bound can easily be extended to the case where synapses can fail.\n  We show how our bound can be leveraged to quantify the effect of memory cost\nreduction on the accuracy of a neural network, to estimate the amount of\ninformation any neuron needs from its preceding layer, enabling thereby a\nboosting scheme that prevents neurons from waiting for unnecessary signals. We\nfinally discuss the trade-off between neural networks robustness and learning\ncost.\n", "versions": [{"version": "v1", "created": "Tue, 27 Jun 2017 14:31:09 GMT"}], "update_date": "2017-06-28", "authors_parsed": [["Mhamdi", "El Mahdi El", ""], ["Guerraoui", "Rachid", ""]]}, {"id": "1706.09305", "submitter": "Michael Emmi", "authors": "Michael Emmi and Constantin Enea", "title": "Exposing Non-Atomic Methods of Concurrent Objects", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multithreaded software is typically built with specialized concurrent objects\nlike atomic integers, queues, and maps. These objects' methods are designed to\nbehave according to certain consistency criteria like atomicity, despite being\noptimized to avoid blocking and exploit parallelism, e.g., by using atomic\nmachine instructions like compare and exchange (cmpxchg). Exposing atomicity\nviolations is important since they generally lead to elusive bugs that are\ndifficult to identify, reproduce, and ultimately repair.\n  In this work we expose atomicity violations in concurrent object\nimplementations from the most widely-used software development kit: The Java\nDevelopment Kit (JDK). We witness atomicity violations via simple test\nharnesses containing few concurrent method invocations. While stress testing is\neffective at exposing violations given catalytic test harnesses and lightweight\nmeans of falsifying atomicity, divining effectual catalysts can be difficult,\nand atomicity checks are generally cumbersome. We overcome these problems by\nautomating test-harness search, and establishing atomicity via membership in\nprecomputed sets of acceptable return-value outcomes. Our approach enables\ntesting millions of executions of each harness each second (per processor\ncore). This scale is important since atomicity violations are observed in very\nfew executions (tens to hundreds out of millions) of very few harnesses (one\nout of hundreds to thousands). Our implementation is open source and publicly\navailable.\n", "versions": [{"version": "v1", "created": "Wed, 28 Jun 2017 14:10:38 GMT"}], "update_date": "2017-06-29", "authors_parsed": [["Emmi", "Michael", ""], ["Enea", "Constantin", ""]]}, {"id": "1706.09937", "submitter": "Przemys{\\l}aw Uzna\\'nski", "authors": "Dan Alistarh, Bart{\\l}omiej Dudek, Adrian Kosowski, David Soloveichik,\n  Przemys{\\l}aw Uzna\\'nski", "title": "Robust Detection in Leak-Prone Population Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In contrast to electronic computation, chemical computation is noisy and\nsusceptible to a variety of sources of error, which has prevented the\nconstruction of robust complex systems. To be effective, chemical algorithms\nmust be designed with an appropriate error model in mind. Here we consider the\nmodel of chemical reaction networks that preserve molecular count (population\nprotocols), and ask whether computation can be made robust to a natural model\nof unintended \"leak\" reactions. Our definition of leak is motivated by both the\nparticular spurious behavior seen when implementing chemical reaction networks\nwith DNA strand displacement cascades, as well as the unavoidable side\nreactions in any implementation due to the basic laws of chemistry. We develop\na new \"Robust Detection\" algorithm for the problem of fast (logarithmic time)\nsingle molecule detection, and prove that it is robust to this general model of\nleaks. Besides potential applications in single molecule detection, the\nerror-correction ideas developed here might enable a new class of\nrobust-by-design chemical algorithms. Our analysis is based on a non-standard\nhybrid argument, combining ideas from discrete analysis of population protocols\nwith classic Markov chain techniques.\n", "versions": [{"version": "v1", "created": "Thu, 29 Jun 2017 19:52:17 GMT"}, {"version": "v2", "created": "Fri, 16 Aug 2019 13:32:21 GMT"}], "update_date": "2019-08-19", "authors_parsed": [["Alistarh", "Dan", ""], ["Dudek", "Bart\u0142omiej", ""], ["Kosowski", "Adrian", ""], ["Soloveichik", "David", ""], ["Uzna\u0144ski", "Przemys\u0142aw", ""]]}, {"id": "1706.09997", "submitter": "Abbas Mehrabian", "authors": "Petra Berenbrink and Peter Kling and Christopher Liaw and Abbas\n  Mehrabian", "title": "Tight Load Balancing via Randomized Local Search", "comments": "24 pages, 3 figures, preliminary version appeared in proceedings of\n  2017 IEEE International Parallel and Distributed Processing Symposium\n  (IPDPS'17)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following balls-into-bins process with $n$ bins and $m$\nballs: each ball is equipped with a mutually independent exponential clock of\nrate 1. Whenever a ball's clock rings, the ball samples a random bin and moves\nthere if the number of balls in the sampled bin is smaller than in its current\nbin. This simple process models a typical load balancing problem where users\n(balls) seek a selfish improvement of their assignment to resources (bins).\nFrom a game theoretic perspective, this is a randomized approach to the\nwell-known Koutsoupias-Papadimitriou model, while it is known as randomized\nlocal search (RLS) in load balancing literature. Up to now, the best bound on\nthe expected time to reach perfect balance was $O\\left({(\\ln n)}^2+\\ln(n)\\cdot\nn^2/m\\right)$ due to Ganesh, Lilienthal, Manjunath, Proutiere, and Simatos\n(Load balancing via random local search in closed and open systems, Queueing\nSystems, 2012). We improve this to an asymptotically tight\n$O\\left(\\ln(n)+n^2/m\\right)$. Our analysis is based on the crucial observation\nthat performing \"destructive moves\" (reversals of RLS moves) cannot decrease\nthe balancing time. This allows us to simplify problem instances and to ignore\n\"inconvenient moves\" in the analysis.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 01:42:53 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Berenbrink", "Petra", ""], ["Kling", "Peter", ""], ["Liaw", "Christopher", ""], ["Mehrabian", "Abbas", ""]]}, {"id": "1706.10086", "submitter": "Alexander Matthes", "authors": "Alexander Matthes, Ren\\'e Widera, Erik Zenker, Benjamin Worpitz, Axel\n  Huebl, Michael Bussmann", "title": "Tuning and optimization for a variety of many-core architectures without\n  changing a single line of implementation code using the Alpaka library", "comments": "Accepted paper for the P\\^{}3MA workshop at the ISC 2017 in Frankfurt", "journal-ref": "J.M. Kunkel et al. (Eds.): ISC High Performance Workshops 2017,\n  LNCS 10524, pp. 496-514, 2017", "doi": "10.1007/978-3-319-67630-2_36", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an analysis on optimizing performance of a single C++11 source\ncode using the Alpaka hardware abstraction library. For this we use the general\nmatrix multiplication (GEMM) algorithm in order to show that compilers can\noptimize Alpaka code effectively when tuning key parameters of the algorithm.\nWe do not intend to rival existing, highly optimized DGEMM versions, but merely\nchoose this example to prove that Alpaka allows for platform-specific tuning\nwith a single source code. In addition we analyze the optimization potential\navailable with vendor-specific compilers when confronted with the heavily\ntemplated abstractions of Alpaka. We specifically test the code for bleeding\nedge architectures such as Nvidia's Tesla P100, Intel's Knights Landing (KNL)\nand Haswell architecture as well as IBM's Power8 system. On some of these we\nare able to reach almost 50\\% of the peak floating point operation performance\nusing the aforementioned means. When adding compiler-specific #pragmas we are\nable to reach 5 TFLOPS/s on a P100 and over 1 TFLOPS/s on a KNL system.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 09:41:51 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Matthes", "Alexander", ""], ["Widera", "Ren\u00e9", ""], ["Zenker", "Erik", ""], ["Worpitz", "Benjamin", ""], ["Huebl", "Axel", ""], ["Bussmann", "Michael", ""]]}, {"id": "1706.10098", "submitter": "Stefan Eilemann", "authors": "Stefan Eilemann, Marwan Abdellah, Nicolas Antille, Ahmet Bilgili,\n  Grigory Chevtchenko, Raphael Dumusc, Cyrille Favreau, Juan Hernando, Daniel\n  Nachbaur, Pawel Podhajski, Jafet Villafranca, Felix Sch\\\"urmann", "title": "From Big Data to Big Displays: High-Performance Visualization at Blue\n  Brain", "comments": "ISC 2017 Visualization at Scale workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Blue Brain has pushed high-performance visualization (HPV) to complement its\nHPC strategy since its inception in 2007. In 2011, this strategy has been\naccelerated to develop innovative visualization solutions through increased\nfunding and strategic partnerships with other research institutions.\n  We present the key elements of this HPV ecosystem, which integrates C++\nvisualization applications with novel collaborative display systems. We\nmotivate how our strategy of transforming visualization engines into services\nenables a variety of use cases, not only for the integration with high-fidelity\ndisplays, but also to build service oriented architectures, to link into web\napplications and to provide remote services to Python applications.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 10:08:11 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Eilemann", "Stefan", ""], ["Abdellah", "Marwan", ""], ["Antille", "Nicolas", ""], ["Bilgili", "Ahmet", ""], ["Chevtchenko", "Grigory", ""], ["Dumusc", "Raphael", ""], ["Favreau", "Cyrille", ""], ["Hernando", "Juan", ""], ["Nachbaur", "Daniel", ""], ["Podhajski", "Pawel", ""], ["Villafranca", "Jafet", ""], ["Sch\u00fcrmann", "Felix", ""]]}, {"id": "1706.10209", "submitter": "Mahdi Jafari Siavoshani", "authors": "Mahdi Jafari Siavoshani, Ali Pourmiri, Seyed Pooya Shariatpanahi", "title": "Storage, Communication, and Load Balancing Trade-off in Distributed\n  Cache Networks", "comments": "This is the journal version of our earlier work [arXiv:1610.05961]\n  presented at International Parallel & Distributed Processing Symposium\n  (IPDPS), 2017. This manuscript is 15 pages and contains 15 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.DS cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider load balancing in a network of caching servers delivering\ncontents to end users. Randomized load balancing via the so-called power of two\nchoices is a well-known approach in parallel and distributed systems. In this\nframework, we investigate the tension between storage resources, communication\ncost, and load balancing performance. To this end, we propose a randomized load\nbalancing scheme which simultaneously considers cache size limitation and\nproximity in the server redirection process.\n  In contrast to the classical power of two choices setup, since the memory\nlimitation and the proximity constraint cause correlation in the server\nselection process, we may not benefit from the power of two choices. However,\nwe prove that in certain regimes of problem parameters, our scheme results in\nthe maximum load of order $\\Theta(\\log\\log n)$ (here $n$ is the network size).\nThis is an exponential improvement compared to the scheme which assigns each\nrequest to the nearest available replica. Interestingly, the extra\ncommunication cost incurred by our proposed scheme, compared to the nearest\nreplica strategy, is small. Furthermore, our extensive simulations show that\nthe trade-off trend does not depend on the network topology and library\npopularity profile details.\n", "versions": [{"version": "v1", "created": "Fri, 30 Jun 2017 14:12:32 GMT"}], "update_date": "2017-07-03", "authors_parsed": [["Siavoshani", "Mahdi Jafari", ""], ["Pourmiri", "Ali", ""], ["Shariatpanahi", "Seyed Pooya", ""]]}]