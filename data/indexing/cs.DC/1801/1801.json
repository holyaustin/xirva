[{"id": "1801.00237", "submitter": "Bogdan Chlebus", "authors": "Bogdan S. Chlebus and Leszek Gasieniec and Andrzej Pelc", "title": "Deterministic Computations on a PRAM with Static Processor and Memory\n  Faults", "comments": null, "journal-ref": "Fundamenta Informaticae, 55(3-4): 285--306, 2003", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider Parallel Random Access Machine (PRAM) which has some processors\nand memory cells faulty. The faults considered are static, i.e., once the\nmachine starts to operate, the operational/faulty status of PRAM components\ndoes not change. We develop a deterministic simulation of a fully operational\nPRAM on a similar faulty machine which has constant fractions of faults among\nprocessors and memory cells. The simulating PRAM has $n$ processors and $m$\nmemory cells, and simulates a PRAM with $n$ processors and a constant fraction\nof $m$ memory cells. The simulation is in two phases: it starts with\npreprocessing, which is followed by the simulation proper performed in a\nstep-by-step fashion. Preprocessing is performed in time $O((\\frac{m}{n}+ \\log\nn)\\log n)$. The slowdown of a step-by-step part of the simulation is $O(\\log\nm)$.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 05:08:02 GMT"}, {"version": "v2", "created": "Wed, 10 Jan 2018 21:41:07 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Chlebus", "Bogdan S.", ""], ["Gasieniec", "Leszek", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1801.00246", "submitter": "Ali Karakus", "authors": "Ali Karakus, Noel Chalmers, Kasia Swirydowicz, Timothy Warburton", "title": "A GPU Accelerated Discontinuous Galerkin Incompressible Flow Solver", "comments": "33 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC cs.PF physics.comp-ph physics.flu-dyn", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a GPU-accelerated version of a high-order discontinuous Galerkin\ndiscretization of the unsteady incompressible Navier-Stokes equations. The\nequations are discretized in time using a semi-implicit scheme with explicit\ntreatment of the nonlinear term and implicit treatment of the split Stokes\noperators. The pressure system is solved with a conjugate gradient method\ntogether with a fully GPU-accelerated multigrid preconditioner which is\ndesigned to minimize memory requirements and to increase overall performance. A\nsemi-Lagrangian subcycling advection algorithm is used to shift the\ncomputational load per timestep away from the pressure Poisson solve by\nallowing larger timestep sizes in exchange for an increased number of advection\nsteps. Numerical results confirm we achieve the design order accuracy in time\nand space. We optimize the performance of the most time-consuming kernels by\ntuning the fine-grain parallelism, memory utilization, and maximizing\nbandwidth. To assess overall performance we present an empirically calibrated\nroofline performance model for a target GPU to explain the achieved efficiency.\nWe demonstrate that, in the most cases, the kernels used in the solver are\nclose to their empirically predicted roofline performance.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 06:48:37 GMT"}, {"version": "v2", "created": "Tue, 24 Apr 2018 22:27:04 GMT"}, {"version": "v3", "created": "Mon, 7 May 2018 15:31:41 GMT"}], "update_date": "2018-05-08", "authors_parsed": [["Karakus", "Ali", ""], ["Chalmers", "Noel", ""], ["Swirydowicz", "Kasia", ""], ["Warburton", "Timothy", ""]]}, {"id": "1801.00297", "submitter": "Herv\\'e Paulino", "authors": "Jo\\~ao A. Silva, Herv\\'e Paulino, Jo\\~ao M. Louren\\c{c}o, Jo\\~ao\n  Leit\\~ao and Nuno Pregui\\c{c}a", "title": "Time-Aware Publish/Subscribe for Networks of Mobile Devices", "comments": "19 pages, 9 figures, preprint of paper submitted to Mobihoc 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Smart mobile devices are increasingly ubiquitous and are the primary source\nof user-generated content, and current communication infrastructures are\nfailing in keeping up with the rising demand for the avid sharing of such\ncontent. To alleviate this problem and fully harness the amount of resources\ncurrently available at the network edge, mobile edge paradigms started to\nemerge. Though, application developers still struggle to tap that potential at\nthe edge due to the lack of adequate communication and interaction\nabstractions. Thus, we propose a high-level abstraction that can be easily\nexploited by developers to design mobile edge applications focused on data\ndissemination. In this paper, we propose Thyme, a novel extended topic-based,\ntime-aware publish/subscribe system for networks of mobile devices. In Thyme,\ntime is a rst order dimension. Each subscription has an associated time frame,\nstarting and ending either in the future, present, or past. Making the past\navailable requires both subscriptions and publications to be persistently\nstored. We present the design of Thyme and evaluate it using simulation,\ndiscussing and characterizing the scenarios best suited for its use.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 14:53:51 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Silva", "Jo\u00e3o A.", ""], ["Paulino", "Herv\u00e9", ""], ["Louren\u00e7o", "Jo\u00e3o M.", ""], ["Leit\u00e3o", "Jo\u00e3o", ""], ["Pregui\u00e7a", "Nuno", ""]]}, {"id": "1801.00322", "submitter": "Erich Schikuta", "authors": "Christian Vorhemus and Erich Schikuta", "title": "Blackboard Meets Dijkstra for Optimization of Web Service Workflows", "comments": "17 pages, 10 figures, paper submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents the integration of Dijkstra's algorithm within a\nBlackboard framework to optimize the selection of web services from service\nproviders. In addition, methods are presented how dynamic changes during the\nworkflow execution can be handled; specifically, how changes of the service\nparameters have effects on the system. For justification of our approach, and\nto show practical feasibility, a sample implementation is presented.\n", "versions": [{"version": "v1", "created": "Sun, 31 Dec 2017 17:26:23 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Vorhemus", "Christian", ""], ["Schikuta", "Erich", ""]]}, {"id": "1801.00540", "submitter": "Apoorve Mohan", "authors": "Apoorve Mohan, Ata Turk, Ravi S. Gudimetla, Sahil Tikale, Jason\n  Hennesey, Ugur Kaynar, Gene Cooperman, Peter Desnoyers, and Orran Krieger", "title": "M2: Malleable Metal as a Service", "comments": "IEEE International Conference on Cloud Engineering 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing bare-metal cloud services that provide users with physical nodes\nhave a number of serious disadvantage over their virtual alternatives,\nincluding slow provisioning times, difficulty for users to release nodes and\nthen reuse them to handle changes in demand, and poor tolerance to failures. We\nintroduce M2, a bare-metal cloud service that uses network-mounted boot drives\nto overcome these disadvantages. We describe the architecture and\nimplementation of M2 and compare its agility, scalability, and performance to\nexisting systems. We show that M2 can reduce provisioning time by over 50%\nwhile offering richer functionality, and comparable run-time performance with\nrespect to tools that provision images into local disks. M2 is open source and\navailable at https://github.com/CCI-MOC/ims.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 03:25:28 GMT"}], "update_date": "2018-01-03", "authors_parsed": [["Mohan", "Apoorve", ""], ["Turk", "Ata", ""], ["Gudimetla", "Ravi S.", ""], ["Tikale", "Sahil", ""], ["Hennesey", "Jason", ""], ["Kaynar", "Ugur", ""], ["Cooperman", "Gene", ""], ["Desnoyers", "Peter", ""], ["Krieger", "Orran", ""]]}, {"id": "1801.00742", "submitter": "Stefan Jaax", "authors": "Michael Blondin, Javier Esparza, Stefan Jaax", "title": "Large Flocks of Small Birds: On the Minimal Size of Population Protocols", "comments": null, "journal-ref": null, "doi": "10.4230/LIPIcs.STACS.2018.16", "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population protocols are a well established model of distributed computation\nby mobile finite-state agents with very limited storage. A classical result\nestablishes that population protocols compute exactly predicates definable in\nPresburger arithmetic. We initiate the study of the minimal amount of memory\nrequired to compute a given predicate as a function of its size. We present\nresults on the predicates $x \\geq n$ for $n \\in \\mathbb{N}$, and more generally\non the predicates corresponding to systems of linear inequalities. We show that\nthey can be computed by protocols with $O(\\log n)$ states (or, more generally,\nlogarithmic in the coefficients of the predicate), and that, surprisingly, some\nfamilies of predicates can be computed by protocols with $O(\\log\\log n)$\nstates. We give essentially matching lower bounds for the class of 1-aware\nprotocols.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 17:44:33 GMT"}], "update_date": "2018-03-08", "authors_parsed": [["Blondin", "Michael", ""], ["Esparza", "Javier", ""], ["Jaax", "Stefan", ""]]}, {"id": "1801.00837", "submitter": "Mohammad Noormohammadpour", "authors": "Mohammad Noormohammadpour, Cauligi S. Raghavendra, Srikanth Kandula,\n  Sriram Rao", "title": "QuickCast: Fast and Efficient Inter-Datacenter Transfers using\n  Forwarding Tree Cohorts", "comments": "[Extended Version] Accepted for presentation in IEEE INFOCOM 2018,\n  Honolulu, HI", "journal-ref": "INFOCOM (2018) 225-233", "doi": "10.1109/INFOCOM.2018.8486324", "report-no": null, "categories": "cs.NI cs.DC cs.PF cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large inter-datacenter transfers are crucial for cloud service efficiency and\nare increasingly used by organizations that have dedicated wide area networks\nbetween datacenters. A recent work uses multicast forwarding trees to reduce\nthe bandwidth needs and improve completion times of point-to-multipoint\ntransfers. Using a single forwarding tree per transfer, however, leads to poor\nperformance because the slowest receiver dictates the completion time for all\nreceivers. Using multiple forwarding trees per transfer alleviates this\nconcern--the average receiver could finish early; however, if done naively,\nbandwidth usage would also increase and it is apriori unclear how best to\npartition receivers, how to construct the multiple trees and how to determine\nthe rate and schedule of flows on these trees. This paper presents QuickCast, a\nfirst solution to these problems. Using simulations on real-world network\ntopologies, we see that QuickCast can speed up the average receiver's\ncompletion time by as much as $10\\times$ while only using $1.04\\times$ more\nbandwidth; further, the completion time for all receivers also improves by as\nmuch as $1.6\\times$ faster at high loads.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 21:10:52 GMT"}], "update_date": "2018-10-15", "authors_parsed": [["Noormohammadpour", "Mohammad", ""], ["Raghavendra", "Cauligi S.", ""], ["Kandula", "Srikanth", ""], ["Rao", "Sriram", ""]]}, {"id": "1801.00936", "submitter": "Yixin Bao", "authors": "Yixin Bao, Yanghua Peng, Chuan Wu, Zongpeng Li", "title": "Online Job Scheduling in Distributed Machine Learning Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays large-scale distributed machine learning systems have been deployed\nto support various analytics and intelligence services in IT firms. To train a\nlarge dataset and derive the prediction/inference model, e.g., a deep neural\nnetwork, multiple workers are run in parallel to train partitions of the input\ndataset, and update shared model parameters. In a shared cluster handling\nmultiple training jobs, a fundamental issue is how to efficiently schedule jobs\nand set the number of concurrent workers to run for each job, such that server\nresources are maximally utilized and model training can be completed in time.\nTargeting a distributed machine learning system using the parameter server\nframework, we design an online algorithm for scheduling the arriving jobs and\ndeciding the adjusted numbers of concurrent workers and parameter servers for\neach job over its course, to maximize overall utility of all jobs, contingent\non their completion times. Our online algorithm design utilizes a primal-dual\nframework coupled with efficient dual subroutines, achieving good long-term\nperformance guarantees with polynomial time complexity. Practical effectiveness\nof the online algorithm is evaluated using trace-driven simulation and testbed\nexperiments, which demonstrate its outperformance as compared to commonly\nadopted scheduling algorithms in today's cloud systems.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 09:37:37 GMT"}], "update_date": "2018-01-04", "authors_parsed": [["Bao", "Yixin", ""], ["Peng", "Yanghua", ""], ["Wu", "Chuan", ""], ["Li", "Zongpeng", ""]]}, {"id": "1801.01037", "submitter": "Ryan LaRose", "authors": "Ryan LaRose", "title": "Distributed Memory Techniques for Classical Simulation of Quantum\n  Circuits", "comments": "Fixed typos, minor reformatting", "journal-ref": null, "doi": null, "report-no": null, "categories": "quant-ph cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe, implement, and test the performance of distributed\nmemory simulations of quantum circuits on the MSU Laconia Top500 supercomputer.\nUsing OpenMP and MPI hybrid parallelization, we first use a distributed\nmatrix-vector multiplication with one-dimensional partitioning and discuss the\nshortcomings of this method due to the exponential memory requirements in\nsimulating quantum computers. We then describe a more efficient method that\nstores only the $2^n$ amplitudes of the $n$ qubit state vector $|\\psi\\rangle$\nand optimize its single node performance. In our multi-node implementation, we\nuse a single amplitude communication protocol that maximizes the number of\nqubits able to be simulated and minimizes the ratio of qubits that require\ncommunication to those that do not, and we present an algorithm for efficiently\ndetermining communication pairs among processors. We simulate up to 30 qubits\non a single node and 33 qubits with the state vector partitioned across 64\nnodes. Lastly, we discuss the advantages and disadvantages of our communication\nscheme, propose potential improvements, and describe other optimizations such\nas storing the state vector non-sequentially in memory to map communication\nrequirements to idle qubits in the circuit.\n", "versions": [{"version": "v1", "created": "Tue, 2 Jan 2018 02:14:31 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 22:37:02 GMT"}], "update_date": "2018-06-25", "authors_parsed": [["LaRose", "Ryan", ""]]}, {"id": "1801.01087", "submitter": "Siva Prakash Reddy Komma", "authors": "Rajrup Ghosh, Siva Prakash Reddy Komma and Yogesh Simmhan", "title": "Adaptive Energy-aware Scheduling of Dynamic Event Analytics across Edge\n  and Cloud Resources", "comments": "11 pages, 7 figures", "journal-ref": "Proceedings of the 18th IEEE/ACM International Symposium on\n  Cluster, Cloud and Grid Computing, Washington DC, 2018, Pages 72-82", "doi": "10.1109/CCGRID.2018.00022", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing deployment of sensors as part of Internet of Things (IoT) is\ngenerating thousands of event streams. Complex Event Processing (CEP) queries\noffer a useful paradigm for rapid decision-making over such data sources. While\noften centralized in the Cloud, the deployment of capable edge devices on the\nfield motivates the need for cooperative event analytics that span Edge and\nCloud computing. Here, we identify a novel problem of query placement on edge\nand Cloud resources for dynamically arriving and departing analytic dataflows.\nWe define this as an optimization problem to minimize the total makespan for\nall event analytics, while meeting energy and compute constraints of the\nresources. We propose 4 adaptive heuristics and 3 rebalancing strategies for\nsuch dynamic dataflows, and validate them using detailed simulations for 100 -\n1000 edge devices and VMs. The results show that our heuristics offer\nO(seconds) planning time, give a valid and high quality solution in all cases,\nand reduce the number of query migrations. Furthermore, rebalance strategies\nwhen applied in these heuristics have significantly reduced the makespan by\naround 20 - 25%.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 17:18:05 GMT"}], "update_date": "2019-05-10", "authors_parsed": [["Ghosh", "Rajrup", ""], ["Komma", "Siva Prakash Reddy", ""], ["Simmhan", "Yogesh", ""]]}, {"id": "1801.01134", "submitter": "B\\'erenger Bramas", "authors": "Berenger Bramas, Pavel Kus", "title": "Computing the sparse matrix vector product using block-based kernels\n  without zero padding on processors with AVX-512 instructions", "comments": "Published in Peer J CS", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The sparse matrix-vector product (SpMV) is a fundamental operation in many\nscientific applications from various fields. The High Performance Computing\n(HPC) community has therefore continuously invested a lot of effort to provide\nan efficient SpMV kernel on modern CPU architectures. Although it has been\nshown that block-based kernels help to achieve high performance, they are\ndifficult to use in practice because of the zero padding they require. In the\ncurrent paper, we propose new kernels using the AVX-512 instruction set, which\nmakes it possible to use a blocking scheme without any zero padding in the\nmatrix memory storage. We describe mask-based sparse matrix formats and their\ncorresponding SpMV kernels highly optimized in assembly language. Considering\nthat the optimal blocking size depends on the matrix, we also provide a method\nto predict the best kernel to be used utilizing a simple interpolation of\nresults from previous executions. We compare the performance of our approach to\nthat of the Intel MKL CSR kernel and the CSR5 open-source package on a set of\nstandard benchmark matrices. We show that we can achieve significant\nimprovements in many cases, both for sequential and for parallel executions.\nFinally, we provide the corresponding code in an open source library, called\nSPC5.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 19:00:06 GMT"}, {"version": "v2", "created": "Fri, 11 May 2018 10:05:38 GMT"}], "update_date": "2018-05-14", "authors_parsed": [["Bramas", "Berenger", ""], ["Kus", "Pavel", ""]]}, {"id": "1801.01174", "submitter": "Jumana Dakka", "authors": "Jumana Dakka, Kristof Farkas-Pall, Matteo Turilli, David W Wright,\n  Peter V Coveney, Shantenu Jha", "title": "Concurrent and Adaptive Extreme Scale Binding Free Energy Calculations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The efficacy of drug treatments depends on how tightly small molecules bind\nto their target proteins. The rapid and accurate quantification of the strength\nof these interactions (as measured by binding affinity) is a grand challenge of\ncomputational chemistry, surmounting which could revolutionize drug design and\nprovide the platform for patient-specific medicine. Recent evidence suggests\nthat molecular dynamics (MD) can achieve useful predictive accuracy (< 1\nkcal/mol). For this predictive accuracy to impact clinical decision making,\nbinding free energy computational campaigns must provide results rapidly and\nwithout loss of accuracy. This demands advances in algorithms, scalable\nsoftware systems, and efficient utilization of supercomputing resources. We\nintroduce a framework called HTBAC, designed to support accurate and scalable\ndrug binding affinity calculations, while marshaling large simulation\ncampaigns. We show that HTBAC supports the specification and execution of\nfree-energy protocols at scale. This paper makes three main contributions: (1)\nshows the importance of adaptive execution for ensemble-based free energy\nprotocols to improve binding affinity accuracy; (2) presents and characterizes\nHTBAC -- a software system that enables the scalable and adaptive execution of\nbinding affinity protocols at scale; and (3) for a widely used free-energy\nprotocol (TIES), shows improvements in the accuracy of simulations for a fixed\namount of resource, or reduced resource consumption for a fixed accuracy as a\nconsequence of adaptive execution.\n", "versions": [{"version": "v1", "created": "Wed, 3 Jan 2018 21:08:23 GMT"}, {"version": "v2", "created": "Thu, 21 Jun 2018 21:24:54 GMT"}, {"version": "v3", "created": "Sat, 27 Oct 2018 16:04:19 GMT"}], "update_date": "2018-10-30", "authors_parsed": [["Dakka", "Jumana", ""], ["Farkas-Pall", "Kristof", ""], ["Turilli", "Matteo", ""], ["Wright", "David W", ""], ["Coveney", "Peter V", ""], ["Jha", "Shantenu", ""]]}, {"id": "1801.01421", "submitter": "Kazuyuki Shudo", "authors": "Kazuyuki Shudo, Reiki Kanda, Kenji Saito", "title": "Towards Application Portability on Blockchains", "comments": "Proc. IEEE HotICN 2018, August 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the issue of what we call {\\em incentive mismatch}, a fundamental\nproblem with public blockchains supported by economic incentives. This is an\nopen problem, but one potential solution is to make application portable.\nPortability is desirable for applications on private blockchains. Then, we\npresent examples of middleware designs that enable application portability and,\nin particular, support migration between blockchains.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 16:17:20 GMT"}, {"version": "v2", "created": "Mon, 25 Jun 2018 16:44:21 GMT"}, {"version": "v3", "created": "Tue, 26 Jun 2018 20:22:44 GMT"}], "update_date": "2018-06-28", "authors_parsed": [["Shudo", "Kazuyuki", ""], ["Kanda", "Reiki", ""], ["Saito", "Kenji", ""]]}, {"id": "1801.01554", "submitter": "Michael Witbrock", "authors": "Michael Witbrock and Marco Zagha", "title": "An Implementation of Back-Propagation Learning on GF11, a Large SIMD\n  Parallel Computer", "comments": null, "journal-ref": "Witbrock, M., and Zagha, M. (1989). \"An Implementation of\n  Back-Propagation Learning on GF11, a Large SIMD Parallel Computer.\" School of\n  Computer Science, Carnegie Mellon University, Pittsburgh, PA, Technical\n  Report CMU-CS-89-208", "doi": null, "report-no": "CMU-CS-89-208", "categories": "cs.LG cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current connectionist simulations require huge computational resources. We\ndescribe a neural network simulator for the IBM GF11, an experimental SIMD\nmachine with 566 processors and a peak arithmetic performance of 11 Gigaflops.\nWe present our parallel implementation of the backpropagation learning\nalgorithm, techniques for increasing efficiency, performance measurements on\nthe NetTalk text-to-speech benchmark, and a performance model for the\nsimulator. Our simulator currently runs the back-propagation learning algorithm\nat 900 million connections per second, where each \"connection per second\"\nincludes both a forward and backward pass. This figure was obtained on the\nmachine when only 356 processors were working; with all 566 processors\noperational, our simulation will run at over one billion connections per\nsecond. We conclude that the GF11 is well-suited to neural network simulation,\nand we analyze our use of the machine to determine which features are the most\nimportant for high performance.\n", "versions": [{"version": "v1", "created": "Thu, 4 Jan 2018 21:52:28 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Witbrock", "Michael", ""], ["Zagha", "Marco", ""]]}, {"id": "1801.01843", "submitter": "Matteo Turilli", "authors": "Andre Merzky and Matteo Turilli and Manuel Maldonado and Shantenu Jha", "title": "Design and Performance Characterization of RADICAL-Pilot on Titan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many extreme scale scientific applications have workloads comprised of a\nlarge number of individual high-performance tasks. The Pilot abstraction\ndecouples workload specification, resource management, and task execution via\njob placeholders and late-binding. As such, suitable implementations of the\nPilot abstraction can support the collective execution of large number of tasks\non supercomputers. We introduce RADICAL-Pilot (RP) as a portable, modular and\nextensible Python-based Pilot system. We describe RP's design, architecture and\nimplementation. We characterize its performance and show its ability to\nscalably execute workloads comprised of thousands of MPI tasks on Titan--a DOE\nleadership class facility. Specifically, we investigate RP's weak (strong)\nscaling properties up to 131K (65K) cores and 4096 (16384) 32 core tasks.\nRADICAL-Pilot can be used stand-alone, as well as integrated with other tools\nas a runtime system.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 17:07:57 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Merzky", "Andre", ""], ["Turilli", "Matteo", ""], ["Maldonado", "Manuel", ""], ["Jha", "Shantenu", ""]]}, {"id": "1801.01875", "submitter": "Mohamed Attia", "authors": "Mohamed A. Attia and Ravi Tandon", "title": "Near Optimal Coded Data Shuffling for Distributed Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data shuffling between distributed cluster of nodes is one of the critical\nsteps in implementing large-scale learning algorithms. Randomly shuffling the\ndata-set among a cluster of workers allows different nodes to obtain fresh data\nassignments at each learning epoch. This process has been shown to provide\nimprovements in the learning process. However, the statistical benefits of\ndistributed data shuffling come at the cost of extra communication overhead\nfrom the master node to worker nodes, and can act as one of the major\nbottlenecks in the overall time for computation. There has been significant\nrecent interest in devising approaches to minimize this communication overhead.\nOne approach is to provision for extra storage at the computing nodes. The\nother emerging approach is to leverage coded communication to minimize the\noverall communication overhead.\n  The focus of this work is to understand the fundamental trade-off between the\namount of storage and the communication overhead for distributed data\nshuffling. In this work, we first present an information theoretic formulation\nfor the data shuffling problem, accounting for the underlying problem\nparameters (number of workers, $K$, number of data points, $N$, and the\navailable storage, $S$ per node). We then present an information theoretic\nlower bound on the communication overhead for data shuffling as a function of\nthese parameters. We next present a novel coded communication scheme and show\nthat the resulting communication overhead of the proposed scheme is within a\nmultiplicative factor of at most $\\frac{K}{K-1}$ from the information-theoretic\nlower bound. Furthermore, we present the aligned coded shuffling scheme for\nsome storage values, which achieves the optimal storage vs communication\ntrade-off for $K<5$, and further reduces the maximum multiplicative gap down to\n$\\frac{K-\\frac{1}{3}}{K-1}$, for $K\\geq 5$.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 18:58:24 GMT"}], "update_date": "2018-01-08", "authors_parsed": [["Attia", "Mohamed A.", ""], ["Tandon", "Ravi", ""]]}, {"id": "1801.01903", "submitter": "Anisur Molla Rahaman", "authors": "Anisur Rahaman Molla and Gopal Pandurangan", "title": "Local Mixing Time: Distributed Computation and Applications", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The mixing time of a graph is an important metric, which is not only useful\nin analyzing connectivity and expansion properties of the network, but also\nserves as a key parameter in designing efficient algorithms. We introduce a new\nnotion of mixing of a random walk on a (undirected) graph, called local mixing.\nInformally, the local mixing with respect to a given node $s$, is the mixing of\na random walk probability distribution restricted to a large enough subset of\nnodes --- say, a subset of size at least $n/\\beta$ for a given parameter\n$\\beta$ --- containing $s$. The time to mix over such a subset by a random walk\nstarting from a source node $s$ is called the local mixing time with respect to\n$s$. The local mixing time captures the local connectivity and expansion\nproperties around a given source node and is a useful parameter that determines\nthe running time of algorithms for partial information spreading, gossip etc.\n  Our first contribution is formally defining the notion of local mixing time\nin an undirected graph. We then present an efficient distributed algorithm\nwhich computes a constant factor approximation to the local mixing time with\nrespect to a source node $s$ in $\\tilde{O}(\\tau_s)$ rounds, where $\\tau_s$ is\nthe local mixing time w.r.t $s$ in an $n$-node regular graph. This bound holds\nwhen $\\tau_s$ is significantly smaller than the conductance of the local mixing\nset (i.e., the set where the walk mixes locally); this is typically the\ninteresting case where the local mixing time is significantly smaller than the\nmixing time (with respect to $s$). We also present a distributed algorithm that\ncomputes the exact local mixing time in $\\tilde{O}(\\tau_s \\mathcal{D})$ rounds,\nwhere $\\mathcal{D} =\\min\\{\\tau_s, D\\}$ and $D$ is the diameter of the graph. We\nfurther show that local mixing time tightly characterizes the complexity of\npartial information spreading.\n", "versions": [{"version": "v1", "created": "Fri, 5 Jan 2018 19:24:34 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Molla", "Anisur Rahaman", ""], ["Pandurangan", "Gopal", ""]]}, {"id": "1801.02147", "submitter": "Lican Huang", "authors": "Lican Huang", "title": "Authorization Policies and Co-Operating Strategies of DSCloud Platform", "comments": "4 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the services of DSCloud Platform is to provide the global directory\nservice to solve the problems of dispersed, difficult retrieved and isolated\ninformation. In this paper, we describe DSCloud Platform's authorization\npolicies and co-operating strategies for articles and comments, and usage\nscenery for co-editing posts and tables in the platform.\n", "versions": [{"version": "v1", "created": "Sun, 7 Jan 2018 06:32:46 GMT"}, {"version": "v2", "created": "Sat, 13 Jan 2018 22:36:17 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Huang", "Lican", ""]]}, {"id": "1801.02362", "submitter": "Jana Paz\\'urikov\\'a", "authors": "Jana Paz\\'urikov\\'a and Jaroslav O\\v{l}ha and Ale\\v{s} K\\v{r}enek and\n  Vojt\\v{e}ch Spiwok", "title": "Acceleration of Mean Square Distance Calculations with Floating Close\n  Structure in Metadynamics Simulations", "comments": "22 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Molecular dynamics simulates the~movements of atoms. Due to its high cost,\nmany methods have been developed to \"push the~simulation forward\". One of them,\nmetadynamics, can hasten the~molecular dynamics with the~help of variables\ndescribing the~simulated process. However, the~evaluation of these variables\ncan include numerous mean square distance calculations that introduce\nsubstantial computational demands, thus jeopardize the~benefit of the~approach.\nRecently, we proposed an~approximative method that significantly reduces\nthe~number of these distance calculations. Here we evaluate the~performance and\nthe~scalability on two molecular systems. We assess the~maximal theoretical\nspeed-up based on the reduction of distance computations and Ahmdal's law and\ncompare it to the~practical speed-up achieved with our implementation.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 09:55:08 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["Paz\u00farikov\u00e1", "Jana", ""], ["O\u013eha", "Jaroslav", ""], ["K\u0159enek", "Ale\u0161", ""], ["Spiwok", "Vojt\u011bch", ""]]}, {"id": "1801.02507", "submitter": "Primavera De Filippi", "authors": "Primavera De Filippi (CERSA), Samer Hassan (UCM)", "title": "Blockchain Technology as a Regulatory Technology: From Code is Law to\n  Law is Code", "comments": null, "journal-ref": "First Monday, University of Illinois at Chicago Library, 2016", "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  \"Code is law\" refers to the idea that, with the advent of digital technology,\ncode has progressively established itself as the predominant way to regulate\nthe behavior of Internet users. Yet, while computer code can enforce rules more\nefficiently than legal code, it also comes with a series of limitations, mostly\nbecause it is difficult to transpose the ambiguity and flexibility of legal\nrules into a formalized language which can be interpreted by a machine. With\nthe advent of blockchain technology and associated smart contracts, code is\nassuming an even stronger role in regulating people's interactions over the\nInternet, as many contractual transactions get transposed into smart contract\ncode. In this paper, we describe the shift from the traditional notion of \"code\nis law\" (i.e. code having the effect of law) to the new conception of \"law is\ncode\" (i.e. law being defined as code).\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 15:33:51 GMT"}], "update_date": "2018-01-09", "authors_parsed": [["De Filippi", "Primavera", "", "CERSA"], ["Hassan", "Samer", "", "UCM"]]}, {"id": "1801.02531", "submitter": "Zhijie Ren", "authors": "Zhijie Ren, Kelong Cong, Taico V. Aerts, Bart A.P. de Jonge, Alejandro\n  F. Morais, Zekeriya Erkin", "title": "A Scale-out Blockchain for Value Transfer with Spontaneous Sharding", "comments": "Accepted by Crypto Valley Conference for Blockchain Technology 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bitcoin, as well as many of its successors, require the whole transaction\nrecord to be reliably acquired by all nodes to prevent double-spending.\nRecently, many blockchains have been proposed to achieve scale-out throughput\nby letting nodes only acquire a fraction of the whole transaction set. However,\nthese schemes, e.g., sharding and off-chain techniques, suffer from a\ndegradation in decentralization or the capacity of fault tolerance.\n  In this paper, we show that the complete set of transactions is not a\nnecessity for the prevention of double-spending if the properties of value\ntransfers is fully explored. In other words, we show that a value-transfer\nledger like Bitcoin has the potential to scale-out by its nature without\nsacrificing security or decentralization. Firstly, we give a formal definition\nfor the value-transfer ledger and its distinct features from a generic\ndatabase. Then, we introduce an off-chain based scheme with a shared main chain\nfor consensus and an individual chain for each node for recording transactions.\nA locally executable validation scheme is proposed with uncompromising validity\nand consistency. A beneficial consequence of our design is that nodes will\nspontaneously try to reduce their transmission cost by only providing the\ntransactions needed to show that their transactions are double-spending-proof.\nAs a result, the network is sharded as each node only acquires part of the\ntransaction record and a scale-out throughput could be achieved, which we call\n\"spontaneous sharding\".\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 16:10:38 GMT"}, {"version": "v2", "created": "Thu, 17 May 2018 11:55:10 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Ren", "Zhijie", ""], ["Cong", "Kelong", ""], ["Aerts", "Taico V.", ""], ["de Jonge", "Bart A. P.", ""], ["Morais", "Alejandro F.", ""], ["Erkin", "Zekeriya", ""]]}, {"id": "1801.02651", "submitter": "Matteo Turilli", "authors": "Ming Tai Ha, Matteo Turilli, Andre Merzky and Shantenu Jha", "title": "Towards General Distributed Resource Selection", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advantages of distributing workloads and utilizing multiple distributed\nresources are now well established. The type and degree of heterogeneity of\ndistributed resources is increasing, and thus determining how to distribute the\nworkloads becomes increasingly difficult, in particular with respect to the\nselection of suitable resources. We formulate and investigate the resource\nselection problem in a way that it is agnostic of specific task and resource\nproperties, and which is generalizable to range of metrics. Specifically, we\ndeveloped a model to describe the requirements of tasks and to estimate the\ncost of running that task on an arbitrary resource using baseline measurements\nfrom a reference machine. We integrated our cost model with the Condor\nmatchmaking algorithm to enable resource selection. Experimental validation of\nour model shows that it provides execution time estimates with 157-171% error\non XSEDE resources and 18-31% on OSG resources. We use the task execution cost\nmodel to select resources for a bag-of-tasks of up to 1024 GROMACS MD\nsimulations across the target resources. Experiments show that using the\nmodel's estimates reduces the workload's time-to-completion up to ~85% when\ncompared to the random distribution of workload across the same resources.\n", "versions": [{"version": "v1", "created": "Mon, 8 Jan 2018 19:22:52 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Ha", "Ming Tai", ""], ["Turilli", "Matteo", ""], ["Merzky", "Andre", ""], ["Jha", "Shantenu", ""]]}, {"id": "1801.02793", "submitter": "Sepehr Assadi", "authors": "Sepehr Assadi and Sanjeev Khanna", "title": "Tight Bounds on the Round Complexity of the Distributed Maximum Coverage\n  Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the maximum $k$-set coverage problem in the following distributed\nsetting. A collection of sets $S_1,\\ldots,S_m$ over a universe $[n]$ is\npartitioned across $p$ machines and the goal is to find $k$ sets whose union\ncovers the most number of elements. The computation proceeds in synchronous\nrounds. In each round, all machines simultaneously send a message to a central\ncoordinator who then communicates back to all machines a summary to guide the\ncomputation for the next round. At the end, the coordinator outputs the answer.\nThe main measures of efficiency in this setting are the approximation ratio of\nthe returned solution, the communication cost of each machine, and the number\nof rounds of computation.\n  Our main result is an asymptotically tight bound on the tradeoff between\nthese measures for the distributed maximum coverage problem. We first show that\nany $r$-round protocol for this problem either incurs a communication cost of $\nk \\cdot m^{\\Omega(1/r)}$ or only achieves an approximation factor of\n$k^{\\Omega(1/r)}$. This implies that any protocol that simultaneously achieves\ngood approximation ratio ($O(1)$ approximation) and good communication cost\n($\\widetilde{O}(n)$ communication per machine), essentially requires\nlogarithmic (in $k$) number of rounds. We complement our lower bound result by\nshowing that there exist an $r$-round protocol that achieves an\n$\\frac{e}{e-1}$-approximation (essentially best possible) with a communication\ncost of $k \\cdot m^{O(1/r)}$ as well as an $r$-round protocol that achieves a\n$k^{O(1/r)}$-approximation with only $\\widetilde{O}(n)$ communication per each\nmachine (essentially best possible).\n  We further use our results in this distributed setting to obtain new bounds\nfor the maximum coverage problem in two other main models of computation for\nmassive datasets, namely, the dynamic streaming model and the MapReduce model.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 04:35:28 GMT"}, {"version": "v2", "created": "Thu, 23 Aug 2018 01:44:36 GMT"}], "update_date": "2018-08-24", "authors_parsed": [["Assadi", "Sepehr", ""], ["Khanna", "Sanjeev", ""]]}, {"id": "1801.02974", "submitter": "Dimitrios Vasilas", "authors": "Dimitrios Vasilas", "title": "Search on Secondary Attributes in Geo-Distributed Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the age of big data, more and more applications need to query and analyse\nlarge volumes of continuously updated data in real-time. In response,\ncloud-scale storage systems can extend their interface that allows fast lookups\non the primary key with the ability to retrieve data based on non-primary\nattributes. However, the need to ingest content rapidly and make it searchable\nimmediately while supporting low-latency, high-throughput query evaluation, as\nwell as the geo-distributed nature and weak consistency guarantees of modern\nstorage systems pose several challenges to the implementation of indexing and\nsearch systems. We present our early-stage work on the design and\nimplementation of an indexing and query processing system that enables realtime\nqueries on secondary attributes of data stored in geo-distributed, weakly\nconsistent storage systems.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 15:01:52 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Vasilas", "Dimitrios", ""]]}, {"id": "1801.03065", "submitter": "Mehmet Deveci", "authors": "Mehmet Deveci, Christian Trott, Sivasankaran Rajamanickam", "title": "Multi-threaded Sparse Matrix-Matrix Multiplication for Many-Core and GPU\n  Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": "SAND2018-0186 R", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse Matrix-Matrix multiplication is a key kernel that has applications in\nseveral domains such as scientific computing and graph analysis. Several\nalgorithms have been studied in the past for this foundational kernel. In this\npaper, we develop parallel algorithms for sparse matrix-matrix multiplication\nwith a focus on performance portability across different high performance\ncomputing architectures. The performance of these algorithms depend on the data\nstructures used in them. We compare different types of accumulators in these\nalgorithms and demonstrate the performance difference between these data\nstructures. Furthermore, we develop a meta-algorithm, kkSpGEMM, to choose the\nright algorithm and data structure based on the characteristics of the problem.\nWe show performance comparisons on three architectures and demonstrate the need\nfor the community to develop two phase sparse matrix-matrix multiplication\nimplementations for efficient reuse of the data structures involved.\n", "versions": [{"version": "v1", "created": "Tue, 9 Jan 2018 18:07:40 GMT"}], "update_date": "2018-01-10", "authors_parsed": [["Deveci", "Mehmet", ""], ["Trott", "Christian", ""], ["Rajamanickam", "Sivasankaran", ""]]}, {"id": "1801.03314", "submitter": "Zhou Honggang", "authors": "Honggang Zhou, Yunchun Li, Hailong Yang, Jie Jia, Wei Li", "title": "BigRoots: An Effective Approach for Root-cause Analysis of Stragglers in\n  Big Data System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stragglers are commonly believed to have a great impact on the performance of\nbig data system. However, the reason to cause straggler is complicated.\nPrevious works mostly focus on straggler detection, schedule level optimization\nand coarse-grained cause analysis. These methods cannot provide valuable\ninsights to help users optimize their programs. In this paper, we propose\nBigRoots, a general method incorporating both framework and system features for\nroot-cause analysis of stragglers in big data system. BigRoots considers\nfeatures from big data framework such as shuffle read/write bytes and JVM\ngarbage collection time, as well as system resource utilization such as CPU,\nI/O and network, which is able to detect both internal and external root causes\nof stragglers. We verify BigRoots by injecting high resource utilization across\ndifferent system components and perform case studies to analyze different\nworkloads in Hibench. The experimental results demonstrate that BigRoots is\neffective to identify the root cause of stragglers and provide useful guidance\nfor performance optimization.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 11:24:05 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Zhou", "Honggang", ""], ["Li", "Yunchun", ""], ["Yang", "Hailong", ""], ["Jia", "Jie", ""], ["Li", "Wei", ""]]}, {"id": "1801.03493", "submitter": "Kevin Hsieh", "authors": "Kevin Hsieh, Ganesh Ananthanarayanan, Peter Bodik, Paramvir Bahl,\n  Matthai Philipose, Phillip B. Gibbons, Onur Mutlu", "title": "Focus: Querying Large Video Datasets with Low Latency and Low Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.CV cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Large volumes of videos are continuously recorded from cameras deployed for\ntraffic control and surveillance with the goal of answering \"after the fact\"\nqueries: identify video frames with objects of certain classes (cars, bags)\nfrom many days of recorded video. While advancements in convolutional neural\nnetworks (CNNs) have enabled answering such queries with high accuracy, they\nare too expensive and slow. We build Focus, a system for low-latency and\nlow-cost querying on large video datasets. Focus uses cheap ingestion\ntechniques to index the videos by the objects occurring in them. At\ningest-time, it uses compression and video-specific specialization of CNNs.\nFocus handles the lower accuracy of the cheap CNNs by judiciously leveraging\nexpensive CNNs at query-time. To reduce query time latency, we cluster similar\nobjects and hence avoid redundant processing. Using experiments on video\nstreams from traffic, surveillance and news channels, we see that Focus uses\n58X fewer GPU cycles than running expensive ingest processors and is 37X faster\nthan processing all the video at query time.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 18:52:25 GMT"}], "update_date": "2018-01-11", "authors_parsed": [["Hsieh", "Kevin", ""], ["Ananthanarayanan", "Ganesh", ""], ["Bodik", "Peter", ""], ["Bahl", "Paramvir", ""], ["Philipose", "Matthai", ""], ["Gibbons", "Phillip B.", ""], ["Mutlu", "Onur", ""]]}, {"id": "1801.03513", "submitter": "David Castells-Rufas", "authors": "David Castells-Rufas, C\\'edric Bastoul", "title": "Proceedings of the Workshop on High Performance Energy Efficient\n  Embedded Systems (HIP3ES) 2018", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Proceedings of the Workshop on High Performance Energy Efficient Embedded\nSystems (HIP3ES) 2018. Manchester, United Kingdom, January 22nd. Collocated\nwith HIPEAC 2018 Conference.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 19:01:22 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Castells-Rufas", "David", ""], ["Bastoul", "C\u00e9dric", ""]]}, {"id": "1801.03578", "submitter": "Afshin Zafari", "authors": "Afshin Zafari, Elisabeth Larsson, Martin Tillenius", "title": "DuctTeip: An efficient programming model for distributed task based\n  parallel computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current high-performance computer systems used for scientific computing\ntypically combine shared memory computational nodes in a distributed memory\nenvironment. Extracting high performance from these complex systems requires\ntailored approaches. Task based parallel programming has been successful both\nin simplifying the programming and in exploiting the available hardware\nparallelism for shared memory systems. In this paper we focus on how to extend\ntask parallel programming to distributed memory systems. We use a hierarchical\ndecomposition of tasks and data in order to accommodate the different levels of\nhardware. We test the proposed programming model on two different applications,\na Cholesky factorization, and a solver for the Shallow Water Equations. We also\ncompare the performance of our implementation with that of other frameworks for\ndistributed task parallel programming, and show that it is competitive.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 22:50:01 GMT"}], "update_date": "2018-01-14", "authors_parsed": [["Zafari", "Afshin", ""], ["Larsson", "Elisabeth", ""], ["Tillenius", "Martin", ""]]}, {"id": "1801.03589", "submitter": "Afshin Zafari", "authors": "Afshin Zafari, Elisabeth Larsson, Marco Righero, M. Alessandro\n  Francavilla, Giorgio Giordanengo, Francesca Vipiana, Giuseppe Vecchi", "title": "Task parallel implementation of a solver for electromagnetic scattering\n  problems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electromagnetic computations, where the wavelength is small in relation to\nthe geometry of interest, become computationally demanding. In order to manage\ncomputations for realistic problems like electromagnetic scattering from\naircraft, the use of parallel computing is essential. In this paper, we\ndescribe how a solver based on a hierarchical nested equivalent source\napproximation can be implemented in parallel using a task based programming\nmodel. We show that the effort for moving from the serial implementation to a\nparallel implementation is modest due to the task based programming paradigm,\nand that the performance achieved on a multicore system is excellent provided\nthat the task size, depending on the method parameters, is large enough.\n", "versions": [{"version": "v1", "created": "Wed, 10 Jan 2018 23:45:18 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Zafari", "Afshin", ""], ["Larsson", "Elisabeth", ""], ["Righero", "Marco", ""], ["Francavilla", "M. Alessandro", ""], ["Giordanengo", "Giorgio", ""], ["Vipiana", "Francesca", ""], ["Vecchi", "Giuseppe", ""]]}, {"id": "1801.03710", "submitter": "Rodrigo Mart\\'inez-Casta\\~no", "authors": "Rodrigo Mart\\'inez-Casta\\~no, Juan C. Pichel and Pablo Gamallo", "title": "Polypus: a Big Data Self-Deployable Architecture for Microblogging Text\n  Extraction and Real-Time Sentiment Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  In this paper we propose a new parallel architecture based on Big Data\ntechnologies for real-time sentiment analysis on microblogging posts. Polypus\nis a modular framework that provides the following functionalities: (1) massive\ntext extraction from Twitter, (2) distributed non-relational storage optimized\nfor time range queries, (3) memory-based intermodule buffering, (4) real-time\nsentiment classification, (5) near real-time keyword sentiment aggregation in\ntime series, (6) a HTTP API to interact with the Polypus cluster and (7) a web\ninterface to analyze results visually. The whole architecture is\nself-deployable and based on Docker containers.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 11:11:31 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Mart\u00ednez-Casta\u00f1o", "Rodrigo", ""], ["Pichel", "Juan C.", ""], ["Gamallo", "Pablo", ""]]}, {"id": "1801.03734", "submitter": "Polina Zilberman", "authors": "Bronislav Sidik, Rami Puzis, Polina Zilberman, and Yuval Elovici", "title": "PALE: Partially Asynchronous Agile Leader Election", "comments": "This work has been submitted to the IEEE for possible publication.\n  Copyright may be transferred without notice, after which this version may no\n  longer be accessible", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many tasks executed in dynamic distributed systems, such as sensor networks\nor enterprise environments with bring-your-own-device policy, require central\ncoordination by a leader node. In the past it has been proven that distributed\nleader election in dynamic environments with constant changes and asynchronous\ncommunication is not possible. Thus, state-of-the-art leader election\nalgorithms are not applicable in asynchronous environments with constant\nnetwork changes. Some algorithms converge only after the network stabilizes (an\nunrealistic requirement in many dynamic environments). Other algorithms reach\nconsensus in the presence of network changes but require a global clock or some\nlevel of communication synchronization.\n  Determining the weakest assumptions, under which leader election is possible,\nremains an unresolved problem. In this study we present a leader election\nalgorithm that operates in the presence of changes and under weak (realistic)\nassumptions regarding message delays and regarding the clock drifts of the\ndistributed nodes. The proposed algorithm is self-sufficient, easy to implement\nand can be extended to support multiple regions, self-stabilization, and\nwireless ad-hoc networks. We prove the algorithm's correctness and provide a\ncomplexity analysis of the time, space, and number of messages required to\nelect a leader.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 12:24:19 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Sidik", "Bronislav", ""], ["Puzis", "Rami", ""], ["Zilberman", "Polina", ""], ["Elovici", "Yuval", ""]]}, {"id": "1801.03855", "submitter": "Amith Rajith Mamidala", "authors": "Amith R Mamidala, Georgios Kollias, Chris Ward, Fausto Artico", "title": "MXNET-MPI: Embedding MPI parallelism in Parameter Server Task Model for\n  scaling Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing Deep Learning frameworks exclusively use either Parameter Server(PS)\napproach or MPI parallelism. In this paper, we discuss the drawbacks of such\napproaches and propose a generic framework supporting both PS and MPI\nprogramming paradigms, co-existing at the same time. The key advantage of the\nnew model is to embed the scaling benefits of MPI parallelism into the loosely\ncoupled PS task model. Apart from providing a practical usage model of MPI in\ncloud, such framework allows for novel communication avoiding algorithms that\ndo parameter averaging in Stochastic Gradient Descent(SGD) approaches. We show\nhow MPI and PS models can synergestically apply algorithms such as Elastic SGD\nto improve the rate of convergence against existing approaches. These new\nalgorithms directly help scaling SGD clusterwide. Further, we also optimize the\ncritical component of the framework, namely global aggregation or allreduce\nusing a novel concept of tensor collectives. These treat a group of vectors on\na node as a single object allowing for the existing single vector algorithms to\nbe directly applicable. We back our claims with sufficient emperical evidence\nusing large scale ImageNet 1K data. Our framework is built upon MXNET but the\ndesign is generic and can be adapted to other popular DL infrastructures.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 16:32:10 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Mamidala", "Amith R", ""], ["Kollias", "Georgios", ""], ["Ward", "Chris", ""], ["Artico", "Fausto", ""]]}, {"id": "1801.03898", "submitter": "Richard Henwood Mr", "authors": "R. Henwood, N. W. Watkins, S. C. Chapman, R. McLay", "title": "A parallel workload has extreme variability in a production environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Writing data in parallel is a common operation in some computing environments\nand a good proxy for a number of other parallel processing patterns. The\nduration of time taken to write data in large-scale compute environments can\nvary considerably. This variation comes from a number of sources, both\nsystematic and transient. The result is a highly complex behavior that is\ndifficult to characterize. This paper further develops the model for parallel\ntask variability proposed in the paper \"A parallel workload has extreme\nvariability\" (Henwood et. al 2016). This model is the Generalized Extreme Value\n(GEV) distribution. This paper further develops the systematic analysis that\nleads to the GEV model with the addition of a traffic congestion term.\nObservations of a parallel workload are presented from a High Performance\nComputing environment under typical production conditions, which include\ntraffic congestion. An analysis of the workload is performed and shows the\nvariability tends towards GEV as the order of parallelism is increased. The\nresults are presented in the context of Amdahl's law and the predictive\nproperties of a GEV models are discussed. A optimization for certain machine\ndesigns is also suggested.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 17:45:12 GMT"}], "update_date": "2018-01-12", "authors_parsed": [["Henwood", "R.", ""], ["Watkins", "N. W.", ""], ["Chapman", "S. C.", ""], ["McLay", "R.", ""]]}, {"id": "1801.03915", "submitter": "Luiz Gadelha Jr.", "authors": "Maria Luiza Mondelli, Thiago Magalh\\~aes, Guilherme Loss, Michael\n  Wilde, Ian Foster, Marta Mattoso, Daniel S. Katz, Helio J. C. Barbosa, Ana\n  Tereza R. Vasconcelos, Kary Oca\\~na, Luiz M. R. Gadelha Jr", "title": "BioWorkbench: A High-Performance Framework for Managing and Analyzing\n  Bioinformatics Experiments", "comments": null, "journal-ref": "PeerJ, 6 (2018), e5551", "doi": "10.7717/peerj.5551", "report-no": null, "categories": "cs.DC cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Advances in sequencing techniques have led to exponential growth in\nbiological data, demanding the development of large-scale bioinformatics\nexperiments. Because these experiments are computation- and data-intensive,\nthey require high-performance computing (HPC) techniques and can benefit from\nspecialized technologies such as Scientific Workflow Management Systems (SWfMS)\nand databases. In this work, we present BioWorkbench, a framework for managing\nand analyzing bioinformatics experiments. This framework automatically collects\nprovenance data, including both performance data from workflow execution and\ndata from the scientific domain of the workflow application. Provenance data\ncan be analyzed through a web application that abstracts a set of queries to\nthe provenance database, simplifying access to provenance information. We\nevaluate BioWorkbench using three case studies: SwiftPhylo, a phylogenetic tree\nassembly workflow; SwiftGECKO, a comparative genomics workflow; and RASflow, a\nRASopathy analysis workflow. We analyze each workflow from both computational\nand scientific domain perspectives, by using queries to a provenance and\nannotation database. Some of these queries are available as a pre-built feature\nof the BioWorkbench web application. Through the provenance data, we show that\nthe framework is scalable and achieves high-performance, reducing up to 98% of\nthe case studies execution time. We also show how the application of machine\nlearning techniques can enrich the analysis process.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 18:35:50 GMT"}], "update_date": "2018-09-03", "authors_parsed": [["Mondelli", "Maria Luiza", ""], ["Magalh\u00e3es", "Thiago", ""], ["Loss", "Guilherme", ""], ["Wilde", "Michael", ""], ["Foster", "Ian", ""], ["Mattoso", "Marta", ""], ["Katz", "Daniel S.", ""], ["Barbosa", "Helio J. C.", ""], ["Vasconcelos", "Ana Tereza R.", ""], ["Oca\u00f1a", "Kary", ""], ["Gadelha", "Luiz M. R.", "Jr"]]}, {"id": "1801.04179", "submitter": "Andres Gomez Ramirez", "authors": "A. Gomez Ramirez and C. Lara and L. Betev and D. Bilanovic and U.\n  Kebschull (and for the ALICE Collaboration)", "title": "Arhuaco: Deep Learning and Isolation Based Security for Distributed\n  High-Throughput Computing", "comments": "Manuscript submitted to the Journal of Grid Computing", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Grid computing systems require innovative methods and tools to identify\ncybersecurity incidents and perform autonomous actions i.e. without\nadministrator intervention. They also require methods to isolate and trace job\npayload activity in order to protect users and find evidence of malicious\nbehavior. We introduce an integrated approach of security monitoring via\nSecurity by Isolation with Linux Containers and Deep Learning methods for the\nanalysis of real time data in Grid jobs running inside virtualized\nHigh-Throughput Computing infrastructure in order to detect and prevent\nintrusions. A dataset for malware detection in Grid computing is described. We\nshow in addition the utilization of generative methods with Recurrent Neural\nNetworks to improve the collected dataset. We present Arhuaco, a prototype\nimplementation of the proposed methods. We empirically study the performance of\nour technique. The results show that Arhuaco outperforms other methods used in\nIntrusion Detection Systems for Grid Computing. The study is carried out in the\nALICE Collaboration Grid, part of the Worldwide LHC Computing Grid.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 14:35:19 GMT"}], "update_date": "2018-07-01", "authors_parsed": [["Ramirez", "A. Gomez", "", "and for the ALICE Collaboration"], ["Lara", "C.", "", "and for the ALICE Collaboration"], ["Betev", "L.", "", "and for the ALICE Collaboration"], ["Bilanovic", "D.", "", "and for the ALICE Collaboration"], ["Kebschull", "U.", "", "and for the ALICE Collaboration"]]}, {"id": "1801.04242", "submitter": "Martin Flasskamp", "authors": "Christian Klarhorst, Martin Flasskamp, Johannes Ax, Thorsten\n  Jungeblut, Wayne Kelly, Mario Porrmann, Ulrich R\\\"uckert", "title": "Development of Energy Models for Design Space Exploration of Embedded\n  Many-Core Systems", "comments": "Presented at HIP3ES, 2018", "journal-ref": null, "doi": null, "report-no": "HIP3ES/2018/1", "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  This paper introduces a methodology to develop energy models for the design\nspace exploration of embedded many-core systems. The design process of such\nsystems can benefit from sophisticated models. Software and hardware can be\nspecifically optimized based on comprehensive knowledge about application\nscenario and hardware behavior. The contribution of our work is an automated\nframework to estimate the energy consumption at an arbitrary abstraction level\nwithout the need to provide further information about the system. We validated\nour framework with the configurable many-core system CoreVA-MPSoC. Compared to\na simulation of the CoreVA-MPSoC on gate level in a 28nm FD-SOI standard cell\ntechnology, our framework shows an average estimation error of about 4%.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 17:23:03 GMT"}, {"version": "v2", "created": "Mon, 15 Jan 2018 10:57:34 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Klarhorst", "Christian", ""], ["Flasskamp", "Martin", ""], ["Ax", "Johannes", ""], ["Jungeblut", "Thorsten", ""], ["Kelly", "Wayne", ""], ["Porrmann", "Mario", ""], ["R\u00fcckert", "Ulrich", ""]]}, {"id": "1801.04249", "submitter": "Alexey Gotsman", "authors": "Artem Khyzha, Hagit Attiya, Alexey Gotsman, and Noam Rinetzky", "title": "Safe Privatization in Transactional Memory", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Transactional memory (TM) facilitates the development of concurrent\napplications by letting the programmer designate certain code blocks as atomic.\nProgrammers using a TM often would like to access the same data both inside and\noutside transactions, e.g., to improve performance or to support legacy code.\nIn this case, programmers would ideally like the TM to guarantee strong\natomicity, where transactions can be viewed as executing atomically also with\nrespect to non-transactional accesses. Since guaranteeing strong atomicity for\narbitrary programs is prohibitively expensive, researchers have suggested\nguaranteeing it only for certain data-race free (DRF) programs, particularly\nthose that follow the privatization idiom: from some point on, threads agree\nthat a given object can be accessed non-transactionally. Supporting\nprivatization safely in a TM is nontrivial, because this often requires\ncorrectly inserting transactional fences, which wait until all active\ntransactions complete.\n  Unfortunately, there is currently no consensus on a single definition of\ntransactional DRF, in particular, because no existing notion of DRF takes into\naccount transactional fences. In this paper we propose such a notion and prove\nthat, if a TM satisfies a certain condition generalizing opacity and a program\nusing it is DRF assuming strong atomicity, then the program indeed has strongly\natomic semantics. We show that our DRF notion allows the programmer to use\nprivatization idioms. We also propose a method for proving our generalization\nof opacity and apply it to the TL2 TM.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 17:54:24 GMT"}], "update_date": "2018-01-15", "authors_parsed": [["Khyzha", "Artem", ""], ["Attiya", "Hagit", ""], ["Gotsman", "Alexey", ""], ["Rinetzky", "Noam", ""]]}, {"id": "1801.04289", "submitter": "Saad Mohamad", "authors": "Saad Mohamad, Abdelhamid Bouchachia, Moamar Sayed-Mouchaweh", "title": "Asynchronous Stochastic Variational Inference", "comments": "7 pages, 8 figures, 1 table, 2 algorithms, The paper has been\n  submitted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stochastic variational inference (SVI) employs stochastic optimization to\nscale up Bayesian computation to massive data. Since SVI is at its core a\nstochastic gradient-based algorithm, horizontal parallelism can be harnessed to\nallow larger scale inference. We propose a lock-free parallel implementation\nfor SVI which allows distributed computations over multiple slaves in an\nasynchronous style. We show that our implementation leads to linear speed-up\nwhile guaranteeing an asymptotic ergodic convergence rate $O(1/\\sqrt(T)$ )\ngiven that the number of slaves is bounded by $\\sqrt(T)$ ($T$ is the total\nnumber of iterations). The implementation is done in a high-performance\ncomputing (HPC) environment using message passing interface (MPI) for python\n(MPI4py). The extensive empirical evaluation shows that our parallel SVI is\nlossless, performing comparably well to its counterpart serial SVI with linear\nspeed-up.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 19:05:09 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Mohamad", "Saad", ""], ["Bouchachia", "Abdelhamid", ""], ["Sayed-Mouchaweh", "Moamar", ""]]}, {"id": "1801.04306", "submitter": "Matthew D. Jones", "authors": "Nikolay A. Simakov, Joseph P. White, Robert L. DeLeon, Steven M.\n  Gallo, Matthew D. Jones, Jeffrey T. Palmer, Benjamin Plessinger, Thomas R.\n  Furlani", "title": "A Workload Analysis of NSF's Innovative HPC Resources Using XDMoD", "comments": "93 pages, 82 figures, 19 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Workload characterization is an integral part of performance analysis of high\nperformance computing (HPC) systems. An understanding of workload properties\nsheds light on resource utilization and can be used to inform performance\noptimization both at the software and system configuration levels. It can\nprovide information on how computational science usage modalities are changing\nthat could potentially aid holistic capacity planning for the wider HPC\necosystem. Here, we report on the results of a detailed workload analysis of\nthe portfolio of supercomputers comprising the NSF Innovative HPC program in\norder to characterize its past and current workload and look for trends to\nunderstand the nature of how the broad portfolio of computational science\nresearch is being supported and how it is changing over time. The workload\nanalysis also sought to illustrate a wide variety of usage patterns and\nperformance requirements for jobs running on these systems. File system\nperformance, memory utilization and the types of parallelism employed by users\n(MPI, threads, etc) were also studied for all systems for which job level\nperformance data was available.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 20:30:46 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Simakov", "Nikolay A.", ""], ["White", "Joseph P.", ""], ["DeLeon", "Robert L.", ""], ["Gallo", "Steven M.", ""], ["Jones", "Matthew D.", ""], ["Palmer", "Jeffrey T.", ""], ["Plessinger", "Benjamin", ""], ["Furlani", "Thomas R.", ""]]}, {"id": "1801.04335", "submitter": "Greg Slepak", "authors": "Greg Slepak, Anya Petrova", "title": "The DCS Theorem", "comments": "9 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Blockchain design involves many tradeoffs, and much debate has focused on\ntradeoffs related to scaling parameters such as blocksize. To address some of\nthe confusion around this subject, we present a probability proof of the DCS\nTriangle. We use the triangle to show decentralized consensus systems, like\nblockchains, can have Decentralization, Consensus, or Scale, but not all three\nproperties simultaneously. We then describe two methods for getting around the\nlimitations suggested by the triangle.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 22:09:22 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Slepak", "Greg", ""], ["Petrova", "Anya", ""]]}, {"id": "1801.04348", "submitter": "Marc Moreno Maza", "authors": "Xiaohui Chen, Marc Moreno-Maza, Jeeva Paudel, Ning Xie", "title": "Comprehensive Optimization of Parametric Kernels for Graphics Processing\n  Units", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This work deals with the optimization of computer programs targeting Graphics\nProcessing Units (GPUs). The goal is to lift, from programmers to optimizing\ncompilers, the heavy burden of determining program details that are dependent\non the hardware characteristics. The expected benefit is to improve robustness,\nportability and efficiency of the generated computer programs. We address these\nrequirements by: (1) treating machine and program parameters as unknown symbols\nduring code generation, and (2) generating optimized programs in the form of a\ncase discussion, based on the possible values of the machine and program\nparameters. By taking advantage of recent advances in the area of computer\nalgebra, preliminary experimentation yield promising results.\n", "versions": [{"version": "v1", "created": "Fri, 12 Jan 2018 22:53:10 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Chen", "Xiaohui", ""], ["Moreno-Maza", "Marc", ""], ["Paudel", "Jeeva", ""], ["Xie", "Ning", ""]]}, {"id": "1801.04357", "submitter": "Yasaman Keshtkarjahromi", "authors": "Yasaman Keshtkarjahromi, Yuxuan Xing, Hulya Seferoglu", "title": "Dynamic Heterogeneity-Aware Coded Cooperative Computation at the Edge", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cooperative computation is a promising approach for localized data processing\nat the edge, e.g. for Internet of Things (IoT). Cooperative computation\nadvocates that computationally intensive tasks in a device could be divided\ninto sub-tasks, and offloaded to other devices or servers in close proximity.\nHowever, exploiting the potential of cooperative computation is challenging\nmainly due to the heterogeneous and time-varying nature of edge devices. Coded\ncomputation, which advocates mixing data in sub-tasks by employing erasure\ncodes and offloading these sub-tasks to other devices for computation, is\nrecently gaining interest, thanks to its higher reliability, smaller delay, and\nlower communication costs. In this paper, we develop a coded cooperative\ncomputation framework, which we name Coded Cooperative Computation Protocol\n(C3P), by taking into account the heterogeneous resources of edge devices. C3P\ndynamically offloads coded sub-tasks to helpers and is adaptive to time-varying\nresources. We show that (i) task completion delay of C3P is very close to\noptimal coded cooperative computation solutions, (ii) the efficiency of C3P in\nterms of resource utilization is higher than $99\\%$, and (iii) C3P improves\ntask completion delay significantly as compared to baselines via both\nsimulations and in a testbed consisting of real Android-based smartphones.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 01:04:50 GMT"}, {"version": "v2", "created": "Wed, 18 Jul 2018 17:54:03 GMT"}, {"version": "v3", "created": "Mon, 22 Oct 2018 14:40:32 GMT"}], "update_date": "2018-10-24", "authors_parsed": [["Keshtkarjahromi", "Yasaman", ""], ["Xing", "Yuxuan", ""], ["Seferoglu", "Hulya", ""]]}, {"id": "1801.04380", "submitter": "Linnan Wang", "authors": "Linnan Wang, Jinmian Ye, Yiyang Zhao, Wei Wu, Ang Li, Shuaiwen Leon\n  Song, Zenglin Xu, Tim Kraska", "title": "SuperNeurons: Dynamic GPU Memory Management for Training Deep Neural\n  Networks", "comments": "PPoPP '2018: 23nd ACM SIGPLAN Symposium on Principles and Practice of\n  Parallel Programming", "journal-ref": null, "doi": "10.1145/3178487.3178491", "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Going deeper and wider in neural architectures improves the accuracy, while\nthe limited GPU DRAM places an undesired restriction on the network design\ndomain. Deep Learning (DL) practitioners either need change to less desired\nnetwork architectures, or nontrivially dissect a network across multiGPUs.\nThese distract DL practitioners from concentrating on their original machine\nlearning tasks. We present SuperNeurons: a dynamic GPU memory scheduling\nruntime to enable the network training far beyond the GPU DRAM capacity.\nSuperNeurons features 3 memory optimizations, \\textit{Liveness Analysis},\n\\textit{Unified Tensor Pool}, and \\textit{Cost-Aware Recomputation}, all\ntogether they effectively reduce the network-wide peak memory usage down to the\nmaximal memory usage among layers. We also address the performance issues in\nthose memory saving techniques. Given the limited GPU DRAM, SuperNeurons not\nonly provisions the necessary memory for the training, but also dynamically\nallocates the memory for convolution workspaces to achieve the high\nperformance. Evaluations against Caffe, Torch, MXNet and TensorFlow have\ndemonstrated that SuperNeurons trains at least 3.2432 deeper network than\ncurrent ones with the leading performance. Particularly, SuperNeurons can train\nResNet2500 that has $10^4$ basic network layers on a 12GB K40c.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 04:11:41 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Wang", "Linnan", ""], ["Ye", "Jinmian", ""], ["Zhao", "Yiyang", ""], ["Wu", "Wei", ""], ["Li", "Ang", ""], ["Song", "Shuaiwen Leon", ""], ["Xu", "Zenglin", ""], ["Kraska", "Tim", ""]]}, {"id": "1801.04453", "submitter": "Da Yan", "authors": "Da Yan, Hongzhi Chen, James Cheng, Zhenkun Cai, Bin Shao", "title": "Scalable De Novo Genome Assembly Using Pregel", "comments": "This is the long version of our ICDE'18 short paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  De novo genome assembly is the process of stitching short DNA sequences to\ngenerate longer DNA sequences, without using any reference sequence for\nalignment. It enables high-throughput genome sequencing and thus accelerates\nthe discovery of new genomes. In this paper, we present a toolkit, called\nPPA-assembler, for de novo genome assembly in a distributed setting. The\noperations in our toolkit provide strong performance guarantees, and can be\nassembled to implement various sequencing strategies. PPA-assembler adopts the\npopular {\\em de Bruijn graph} based approach for sequencing, and each operation\nis implemented as a program in Google's Pregel framework for big graph\nprocessing. Experiments on large real and simulated datasets demonstrate that\nPPA-assembler is much more efficient than the state-of-the-arts and provides\ngood sequencing quality.\n", "versions": [{"version": "v1", "created": "Sat, 13 Jan 2018 15:15:08 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Yan", "Da", ""], ["Chen", "Hongzhi", ""], ["Cheng", "James", ""], ["Cai", "Zhenkun", ""], ["Shao", "Bin", ""]]}, {"id": "1801.04523", "submitter": "Saurabh Hukerikar", "authors": "Rizwan A. Ashraf, Saurabh Hukerikar, Christian Engelmann", "title": "Shrink or Substitute: Handling Process Failures in HPC Systems using\n  In-situ Recovery", "comments": "26th Euromicro International Conference on Parallel, Distributed and\n  network-based Processing (PDP 2018)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient utilization of today's high-performance computing (HPC) systems\nwith complex hardware and software components requires that the HPC\napplications are designed to tolerate process failures at runtime. With low\nmean time to failure (MTTF) of current and future HPC systems, long running\nsimulations on these systems require capabilities for gracefully handling\nprocess failures by the applications themselves. In this paper, we explore the\nuse of fault tolerance extensions to Message Passing Interface (MPI) called\nuser-level failure mitigation (ULFM) for handling process failures without the\nneed to discard the progress made by the application. We explore two\nalternative recovery strategies, which use ULFM along with application-driven\nin-memory checkpointing. In the first case, the application is recovered with\nonly the surviving processes, and in the second case, spares are used to\nreplace the failed processes, such that the original configuration of the\napplication is restored. Our experimental results demonstrate that graceful\ndegradation is a viable alternative for recovery in environments where spares\nmay not be available.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 07:31:17 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Ashraf", "Rizwan A.", ""], ["Hukerikar", "Saurabh", ""], ["Engelmann", "Christian", ""]]}, {"id": "1801.04546", "submitter": "Andr\\'es G\\'omez Tato", "authors": "Andres Gomez Tato", "title": "Evaluation of Machine Learning Fameworks on Finis Terrae II", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Machine Learning (ML) and Deep Learning (DL) are two technologies used to\nextract representations of the data for a specific purpose. ML algorithms take\na set of data as input to generate one or several predictions. To define the\nfinal version of one model, usually there is an initial step devoted to train\nthe algorithm (get the right final values of the parameters of the model).\nThere are several techniques, from supervised learning to reinforcement\nlearning, which have different requirements. On the market, there are some\nframeworks or APIs that reduce the effort for designing a new ML model. In this\nreport, using the benchmark DLBENCH, we will analyse the performance and the\nexecution modes of some well-known ML frameworks on the Finis Terrae II\nsupercomputer when supervised learning is used. The report will show that\nplacement of data and allocated hardware can have a large influence on the\nfinal timeto-solution.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 12:50:00 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Tato", "Andres Gomez", ""]]}, {"id": "1801.04582", "submitter": "Afshin Zafari", "authors": "Afshin Zafari, Elisabeth Larsson", "title": "Distributed dynamic load balancing for task parallel programming", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we derive and investigate approaches to dynamically load\nbalance a distributed task parallel application software. The load balancing\nstrategy is based on task migration. Busy processes export parts of their ready\ntask queue to idle processes. Idle--busy pairs of processes find each other\nthrough a random search process that succeeds within a few steps with high\nprobability. We evaluate the load balancing approach for a block Cholesky\nfactorization implementation and observe a reduction in execution time on the\norder of 5\\% in the selected test cases.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 16:47:52 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Zafari", "Afshin", ""], ["Larsson", "Elisabeth", ""]]}, {"id": "1801.04601", "submitter": "Daniel Moore", "authors": "Daniel Moore, Alexander Dean", "title": "PACER: Peripheral Activity Completion Estimation and Recognition", "comments": "8 pages, 12 figures, Presented at HIP3ES, 2018", "journal-ref": null, "doi": null, "report-no": "HIP3ES/2018/3", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded peripheral devices such as memories, sensors and communications\ninterfaces are used to perform a function external to a host microcontroller.\nThe device manufacturer typically specifies worst-case current consumption and\nlatency estimates for each of these peripheral actions. Peripheral Activity\nCompletion, Estimation and Recognition (PACER) is introduced as a suite of\nalgorithms that can be applied to detect completed peripheral operations in\nreal-time. By detecting activity completion, PACER enables the host to exploit\nslack between the worst-case estimate and the actual response time. These\nmethods were tested independently and in conjunction with IODVS on multiple\ncommon peripheral devices. For the peripheral devices under test, the test\nfixture confirmed decreases in energy expenditures of up to 80% and latency\nreductions of up to 67%.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 19:33:50 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Moore", "Daniel", ""], ["Dean", "Alexander", ""]]}, {"id": "1801.04618", "submitter": "Adrien Guatto", "authors": "Adrien Guatto, Sam Westrick, Ram Raghunathan, Umut Acar, Matthew Fluet", "title": "Hierarchical Memory Management for Mutable State", "comments": "15 pages, 14 figures, PPoPP 2018", "journal-ref": null, "doi": "10.1145/3178487.3178494", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well known that modern functional programming languages are naturally\namenable to parallel programming. Achieving efficient parallelism using\nfunctional languages, however, remains difficult. Perhaps the most important\nreason for this is their lack of support for efficient in-place updates, i.e.,\nmutation, which is important for the implementation of both parallel algorithms\nand the run-time system services (e.g., schedulers and synchronization\nprimitives) used to execute them.\n  In this paper, we propose techniques for efficient mutation in parallel\nfunctional languages. To this end, we couple the memory manager with the thread\nscheduler to make reading and updating data allocated by nested threads\nefficient. We describe the key algorithms behind our technique, implement them\nin the MLton Standard ML compiler, and present an empirical evaluation. Our\nexperiments show that the approach performs well, significantly improving\nefficiency over existing functional language implementations.\n", "versions": [{"version": "v1", "created": "Sun, 14 Jan 2018 22:25:44 GMT"}, {"version": "v2", "created": "Sun, 18 Feb 2018 11:00:48 GMT"}], "update_date": "2018-02-20", "authors_parsed": [["Guatto", "Adrien", ""], ["Westrick", "Sam", ""], ["Raghunathan", "Ram", ""], ["Acar", "Umut", ""], ["Fluet", "Matthew", ""]]}, {"id": "1801.04686", "submitter": "Jy-yong Sohn", "authors": "Hyegyeong Park, Kangwook Lee, Jy-yong Sohn, Changho Suh and Jaekyun\n  Moon", "title": "Hierarchical Coding for Distributed Computing", "comments": "7 pages, part of the paper is submitted to ISIT2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Coding for distributed computing supports low-latency computation by\nrelieving the burden of straggling workers. While most existing works assume a\nsimple master-worker model, we consider a hierarchical computational structure\nconsisting of groups of workers, motivated by the need to reflect the\narchitectures of real-world distributed computing systems. In this work, we\npropose a hierarchical coding scheme for this model, as well as analyze its\ndecoding cost and expected computation time. Specifically, we first provide\nupper and lower bounds on the expected computing time of the proposed scheme.\nWe also show that our scheme enables efficient parallel decoding, thus reducing\ndecoding costs by orders of magnitude over non-hierarchical schemes. When\nconsidering both decoding cost and computing time, the proposed hierarchical\ncoding is shown to outperform existing schemes in many practical scenarios.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 07:51:15 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Park", "Hyegyeong", ""], ["Lee", "Kangwook", ""], ["Sohn", "Jy-yong", ""], ["Suh", "Changho", ""], ["Moon", "Jaekyun", ""]]}, {"id": "1801.04723", "submitter": "Chandan Misra", "authors": "Chandan Misra, Sourangshu Bhattacharya and Soumya K. Ghosh", "title": "SPIN: A Fast and Scalable Matrix Inversion Method in Apache Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growth of big data in domains such as Earth Sciences, Social Networks,\nPhysical Sciences, etc. has lead to an immense need for efficient and scalable\nlinear algebra operations, e.g. Matrix inversion. Existing methods for\nefficient and distributed matrix inversion using big data platforms rely on LU\ndecomposition based block-recursive algorithms. However, these algorithms are\ncomplex and require a lot of side calculations, e.g. matrix multiplication, at\nvarious levels of recursion. In this paper, we propose a different scheme based\non Strassen's matrix inversion algorithm (mentioned in Strassen's original\npaper in 1969), which uses far fewer operations at each level of recursion. We\nimplement the proposed algorithm, and through extensive experimentation, show\nthat it is more efficient than the state of the art methods. Furthermore, we\nprovide a detailed theoretical analysis of the proposed algorithm, and derive\ntheoretical running times which match closely with the empirically observed\nwall clock running times, thus explaining the U-shaped behaviour w.r.t.\nblock-sizes.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 10:28:09 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Misra", "Chandan", ""], ["Bhattacharya", "Sourangshu", ""], ["Ghosh", "Soumya K.", ""]]}, {"id": "1801.04728", "submitter": "Siegfried Cools", "authors": "Jeffrey Cornelis, Siegfried Cools, Wim Vanroose", "title": "The Communication-Hiding Conjugate Gradient Method with Deep Pipelines", "comments": "34 pages (incl. 6 pages appendix), 12 figures, 2 tables, 5 algorithms", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Krylov subspace methods are among the most efficient solvers for large scale\nlinear algebra problems. Nevertheless, classic Krylov subspace algorithms do\nnot scale well on massively parallel hardware due to synchronization\nbottlenecks. Communication-hiding pipelined Krylov subspace methods offer\nincreased parallel scalability by overlapping the time-consuming global\ncommunication phase with computations such as spmvs, hence reducing the impact\nof the global synchronization and avoiding processor idling. One of the first\npublished methods in this class is the pipelined Conjugate Gradient method\n(p-CG). However, on large numbers of processors the communication phase may\ntake much longer than the computation of a single spmv. This work extends the\npipelined CG method to deeper pipelines, denoted as p(l)-CG, which allows\nfurther scaling when the global communication phase is the dominant\ntime-consuming factor. By overlapping the global all-to-all reduction phase in\neach CG iteration with the next l spmvs (deep pipelining), the method hides\ncommunication latency behind additional computational work. The p(l)-CG\nalgorithm is derived from similar principles as the existing p(l)-GMRES method\nand by exploiting operator symmetry. The p(l)-CG method is also compared to\nother Krylov subspace methods, including the closely related classic CG and\nD-Lanczos methods and the pipelined CG method by Ghysels et al.. By analyzing\nthe maximal accuracy attainable by the p(l)-CG method it is shown that the\npipelining technique induces a trade-off between performance and numerical\nstability. A preconditioned version of the algorithm is also proposed and\nstorage requirements and performance estimates are discussed. Experimental\nresults demonstrate the possible performance gains and the attainable accuracy\nof deeper pipelined CG for solving large scale symmetric linear systems.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 10:44:09 GMT"}, {"version": "v2", "created": "Tue, 21 Aug 2018 13:40:26 GMT"}, {"version": "v3", "created": "Mon, 28 Jan 2019 15:26:22 GMT"}], "update_date": "2019-01-29", "authors_parsed": [["Cornelis", "Jeffrey", ""], ["Cools", "Siegfried", ""], ["Vanroose", "Wim", ""]]}, {"id": "1801.04821", "submitter": "Christophe Alias", "authors": "Christophe Alias", "title": "Improving Communication Patterns in Polyhedral Process Networks", "comments": "Presented at HIP3ES, 2018", "journal-ref": null, "doi": null, "report-no": "HIP3ES/2018/4", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded system performances are bounded by power consumption. The trend is\nto offload greedy computations on hardware accelerators as GPU, Xeon Phi or\nFPGA. FPGA chips combine both flexibility of programmable chips and\nenergy-efficiency of specialized hardware and appear as a natural solution.\nHardware compilers from high-level languages (High-level synthesis, HLS) are\nrequired to exploit all the capabilities of FPGA while satisfying tight\ntime-to-market constraints. Compiler optimizations for parallelism and data\nlocality restructure deeply the execution order of the processes, hence the\nread/write patterns in communication channels. This breaks most FIFO channels,\nwhich have to be implemented with addressable buffers. Expensive hardware is\nrequired to enforce synchronizations, which often results in dramatic\nperformance loss. In this paper, we present an algorithm to partition the\ncommunications so that most FIFO channels can be recovered after a loop tiling,\na key optimization for parallelism and data locality. Experimental results show\na drastic improvement of FIFO detection for regular kernels at the cost of a\nfew additional storage. As a bonus, the storage can even be reduced in some\ncases.\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 14:34:06 GMT"}], "update_date": "2018-01-16", "authors_parsed": [["Alias", "Christophe", ""]]}, {"id": "1801.04886", "submitter": "Khaza Anuarul Hoque", "authors": "Khaza Anuarul Hoque, Otmane Ait Mohamed, Yvon Savaria", "title": "Dependability modeling and optimization of triple modular redundancy\n  partitioning for SRAM-based FPGAs", "comments": "Published in Reliability Engineering & System Safety Volume 182,\n  February 2019, Pages 107-119", "journal-ref": "Reliability Engineering & System Safety Volume 182, February 2019,\n  Pages 107-119", "doi": "10.1016/j.ress.2018.10.011", "report-no": null, "categories": "cs.DC cs.AR cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  SRAM-based FPGAs are popular in the aerospace industry for their field\nprogrammability and low cost. However, they suffer from cosmic\nradiation-induced Single Event Upsets (SEUs). Triple Modular Redundancy (TMR)\nis a well-known technique to mitigate SEUs in FPGAs that is often used with\nanother SEU mitigation technique known as configuration scrubbing. Traditional\nTMR provides protection against a single fault at a time, while partitioned TMR\nprovides improved reliability and availability. In this paper, we present a\nmethodology to analyze TMR partitioning at early design stage using\nprobabilistic model checking. The proposed formal model can capture both single\nand multiple-cell upset scenarios, regardless of any assumption of equal\npartition sizes. Starting with a high-level description of a design, a Markov\nmodel is constructed from the Data Flow Graph (DFG) using a specified number of\npartitions, a component characterization library and a user defined scrub rate.\nSuch a model and exhaustive analysis captures all the considered failures and\nrepairs possible in the system within the radiation environment. Various\nreliability and availability properties are then verified automatically using\nthe PRISM model checker exploring the relationship between the scrub frequency\nand the number of TMR partitions required to meet the design requirements.\nAlso, the reported results show that based on a known voter failure rate, it is\npossible to find an optimal number of partitions at early design stages using\nour proposed method.\n", "versions": [{"version": "v1", "created": "Thu, 11 Jan 2018 19:00:22 GMT"}, {"version": "v2", "created": "Mon, 12 Mar 2018 20:38:27 GMT"}, {"version": "v3", "created": "Tue, 8 Oct 2019 17:11:31 GMT"}], "update_date": "2019-10-09", "authors_parsed": [["Hoque", "Khaza Anuarul", ""], ["Mohamed", "Otmane Ait", ""], ["Savaria", "Yvon", ""]]}, {"id": "1801.04928", "submitter": "Yatin Saraiya", "authors": "Yatin Saraiya", "title": "Leapfrogging for parallelism in deep neural networks", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a technique, which we term leapfrogging, to parallelize back-\npropagation in deep neural networks. We show that this technique yields a\nsavings of $1-1/k$ of a dominant term in backpropagation, where k is the number\nof threads (or gpus).\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 00:51:29 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Saraiya", "Yatin", ""]]}, {"id": "1801.04984", "submitter": "Uwe K\\\"ocher", "authors": "Uwe K\\\"ocher", "title": "Space-Time-Parallel Poroelasticity Simulation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The accurate, reliable and efficient numerical approximation of multi-physics\nprocesses in heterogeneous porous media with varying media coefficients that\ninclude fluid flow and structure interactions is of fundamental importance in\nenergy, environmental, petroleum and biomedical engineering applications fields\nfor instance. Important applications include subsurface compaction drive,\ncarbon sequestration, hydraulic and thermal fracturing and oil recovery.\nBiomedical applications include the simulation of vibration therapy for\nosteoporosis processes of trabeculae bones, estimating stress levels induced by\ntumour growth within the brain or next-generation spinal disc prostheses.\n  Variational space-time methods offers some appreciable advantages such as the\nflexibility of the triangulation for complex geometries in space and natural\nlocal time stepping, the straightforward construction of higher-order\napproximations and the application of efficient goal-oriented (duality-based)\nadaptivity concepts. In addition to that, uniform space-time variational\nmethods appear to be advantageous for stability and a priori error analyses of\nthe discrete schemes. Especially (high-order) discontinuous in time approaches\nappear to have favourable properties due to the weak application of the initial\nconditions.\n  The development of monolithic multi-physics schemes, instead of iterative\ncoupling methods between the physical problems, is a key component of the\nresearch to reduce the modeling error. Special emphasis is on the development\nof efficient multi-physics and multigrid preconditioning technologies and their\nimplementation.\n  The simulation software DTM++ is a modularised framework written in C++11 and\nbuilds on top of deal.II toolchains. The implementation allows parallel\nsimulations from notebooks up to cluster scale.\n", "versions": [{"version": "v1", "created": "Wed, 20 Dec 2017 10:01:14 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["K\u00f6cher", "Uwe", ""]]}, {"id": "1801.05064", "submitter": "Mohammad Roohitavaf", "authors": "Mohammad Roohitavaf and Sandeep Kulkarni", "title": "DKVF: A Framework for Rapid Prototyping and Evaluating Distributed\n  Key-value Stores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present our framework DKVF that enables one to quickly prototype and\nevaluate new protocols for key-value stores and compare them with existing\nprotocols based on selected benchmarks. Due to limitations of CAP theorem, new\nprotocols must be developed that achieve the desired trade-off between\nconsistency and availability for the given application at hand. Hence, both\nacademic and industrial communities focus on developing new protocols that\nidentify a different (and hopefully better in one or more aspect) point on this\ntrade-off curve. While these protocols are often based on a simple intuition,\nevaluating them to ensure that they indeed provide increased availability,\nconsistency, or performance is a tedious task. Our framework, DKVF, enables one\nto quickly prototype a new protocol as well as identify how it performs\ncompared to existing protocols for pre-specified benchmarks. Our framework\nrelies on YCSB (Yahoo! Cloud Servicing Benchmark) for benchmarking. We\ndemonstrate DKVF by implementing four existing protocols --eventual\nconsistency, COPS, GentleRain and CausalSpartan-- with it. We compare the\nperformance of these protocols against different loading conditions. We find\nthat the performance is similar to our implementation of these protocols from\nscratch. And, the comparison of these protocols is consistent with what has\nbeen reported in the literature. Moreover, implementation of these protocols\nwas much more natural as we only needed to translate the pseudocode into Java\n(and add the necessary error handling). Hence, it was possible to achieve this\nin just 1-2 days per protocol. Finally, our framework is extensible. It is\npossible to replace individual components in the framework (e.g., the storage\ncomponent).\n", "versions": [{"version": "v1", "created": "Mon, 15 Jan 2018 23:09:59 GMT"}], "update_date": "2018-01-17", "authors_parsed": [["Roohitavaf", "Mohammad", ""], ["Kulkarni", "Sandeep", ""]]}, {"id": "1801.05127", "submitter": "David Wajc", "authors": "Bernhard Haeupler, D. Ellis Hershkowitz, David Wajc", "title": "Round- and Message-Optimal Distributed Graph Algorithms", "comments": "To appear in PODC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed graph algorithms that separately optimize for either the number\nof rounds used or the total number of messages sent have been studied\nextensively. However, algorithms simultaneously efficient with respect to both\nmeasures have been elusive. For example, only very recently was it shown that\nfor Minimum Spanning Tree (MST), an optimal message and round complexity is\nachievable (up to polylog terms) by a single algorithm in the CONGEST model of\ncommunication.\n  In this paper we provide algorithms that are simultaneously round- and\nmessage-optimal for a number of well-studied distributed optimization problems.\nOur main result is such a distributed algorithm for the fundamental primitive\nof computing simple functions over each part of a graph partition. From this\nalgorithm we derive round- and message-optimal algorithms for multiple\nproblems, including MST, Approximate Min-Cut and Approximate Single Source\nShortest Paths, among others. On general graphs all of our algorithms achieve\nworst-case optimal $\\tilde{O}(D+\\sqrt n)$ round complexity and $\\tilde{O}(m)$\nmessage complexity. Furthermore, our algorithms require an optimal\n$\\tilde{O}(D)$ rounds and $\\tilde{O}(n)$ messages on planar, genus-bounded,\ntreewidth-bounded and pathwidth-bounded graphs.\n", "versions": [{"version": "v1", "created": "Tue, 16 Jan 2018 06:22:32 GMT"}, {"version": "v2", "created": "Tue, 27 Feb 2018 20:43:48 GMT"}, {"version": "v3", "created": "Thu, 17 May 2018 02:53:45 GMT"}], "update_date": "2018-05-18", "authors_parsed": [["Haeupler", "Bernhard", ""], ["Hershkowitz", "D. Ellis", ""], ["Wajc", "David", ""]]}, {"id": "1801.05522", "submitter": "Saurav Prakash", "authors": "Saurav Prakash, Amirhossein Reisizadeh, Ramtin Pedarsani, Amir Salman\n  Avestimehr", "title": "Coded Computing for Distributed Graph Analytics", "comments": "Accepted for publication in the IEEE Transactions on Information\n  Theory", "journal-ref": null, "doi": "10.1109/TIT.2020.2999675", "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Performance of distributed graph processing systems significantly suffers\nfrom 'communication bottleneck' as a large number of messages are exchanged\namong servers at each step of the computation. Motivated by graph based\nMapReduce, we propose a coded computing framework that leverages computation\nredundancy to alleviate the communication bottleneck in distributed graph\nprocessing. We develop a novel 'coding' scheme that systematically injects\nstructured redundancy in computation phase to enable 'coded' multicasting\nopportunities during message exchange between servers, reducing communication\nload substantially in large-scale graph processing. For theoretical analysis,\nwe consider random graph models, and prove that our proposed scheme enables an\n(asymptotically) inverse-linear trade-off between 'computation load' and\n'average communication load' for two popular random graph models -- Erdos-Renyi\nmodel, and power law model. Particularly, for a given computation load r, (i.e.\nwhen each graph vertex is carefully stored at r servers), the proposed scheme\nslashes the average communication load by (nearly) a multiplicative factor of\nr. For the Erdos-Renyi model, our proposed scheme is optimal asymptotically as\nthe graph size increases by providing an information-theoretic converse. To\nillustrate the benefits of our scheme in practice, we implement PageRank over\nAmazon EC2, using artificial as well as real-world datasets, demonstrating\nsignificant gains over conventional PageRank. We also specialize our scheme and\nextend our theoretical results to two other random graph models -- random\nbi-partite model, and stochastic block model. They asymptotically enable\ninverse-linear trade-offs between computation and communication loads in\ndistributed graph processing for these popular random graph models as well. We\ncomplement the achievability results with converse bounds for both of these\nmodels.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 01:43:10 GMT"}, {"version": "v2", "created": "Wed, 4 Jul 2018 12:29:48 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2019 03:39:16 GMT"}, {"version": "v4", "created": "Tue, 9 Jun 2020 14:43:15 GMT"}], "update_date": "2020-06-11", "authors_parsed": [["Prakash", "Saurav", ""], ["Reisizadeh", "Amirhossein", ""], ["Pedarsani", "Ramtin", ""], ["Avestimehr", "Amir Salman", ""]]}, {"id": "1801.05610", "submitter": "Klervie Tocz\\'e", "authors": "Klervie Tocz\\'e, Simin Nadjm-Tehrani", "title": "A Taxonomy for Management and Optimization of Multiple Resources in Edge\n  Computing", "comments": "Accepted in the Special Issue Mobile Edge Computing of the Wireless\n  Communications and Mobile Computing journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Edge computing is promoted to meet increasing performance needs of\ndata-driven services using computational and storage resources close to the end\ndevices, at the edge of the current network. To achieve higher performance in\nthis new paradigm one has to consider how to combine the efficiency of resource\nusage at all three layers of architecture: end devices, edge devices, and the\ncloud. While cloud capacity is elastically extendable, end devices and edge\ndevices are to various degrees resource-constrained. Hence, an efficient\nresource management is essential to make edge computing a reality. In this\nwork, we first present terminology and architectures to characterize current\nworks within the field of edge computing. Then, we review a wide range of\nrecent articles and categorize relevant aspects in terms of 4 perspectives:\nresource type, resource management objective, resource location, and resource\nuse. This taxonomy and the ensuing analysis is used to identify some gaps in\nthe existing research. Among several research gaps, we found that research is\nless prevalent on data, storage, and energy as a resource, and less extensive\ntowards the estimation, discovery and sharing objectives. As for resource\ntypes, the most well-studied resources are computation and communication\nresources. Our analysis shows that resource management at the edge requires a\ndeeper understanding of how methods applied at different levels and geared\ntowards different resource types interact. Specifically, the impact of mobility\nand collaboration schemes requiring incentives are expected to be different in\nedge architectures compared to the classic cloud solutions. Finally, we find\nthat fewer works are dedicated to the study of non-functional properties or to\nquantifying the footprint of resource management techniques, including\nedge-specific means of migrating data and services.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 09:55:01 GMT"}, {"version": "v2", "created": "Fri, 16 Mar 2018 10:36:57 GMT"}, {"version": "v3", "created": "Thu, 19 Apr 2018 08:06:51 GMT"}], "update_date": "2018-04-20", "authors_parsed": [["Tocz\u00e9", "Klervie", ""], ["Nadjm-Tehrani", "Simin", ""]]}, {"id": "1801.05731", "submitter": "Roberto Bifulco", "authors": "Giuseppe Siracusano, Roberto Bifulco", "title": "In-network Neural Networks", "comments": "Accepted at SysML 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present N2Net, a system that implements binary neural networks using\ncommodity switching chips deployed in network switches and routers. Our system\nshows that these devices can run simple neural network models, whose input is\nencoded in the network packets' header, at packet processing speeds (billions\nof packets per second). Furthermore, our experience highlights that switching\nchips could support even more complex models, provided that some minor and\ncheap modifications to the chip's design are applied. We believe N2Net provides\nan interesting building block for future end-to-end networked systems.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 16:17:28 GMT"}], "update_date": "2018-01-18", "authors_parsed": [["Siracusano", "Giuseppe", ""], ["Bifulco", "Roberto", ""]]}, {"id": "1801.05857", "submitter": "EPTCS", "authors": "Nathan Cassee (Eindhoven University of Technology, Eindhoven, The\n  Netherlands), Thomas Neele (Eindhoven University of Technology, Eindhoven,\n  The Netherlands), Anton Wijs (Eindhoven University of Technology, Eindhoven,\n  The Netherlands)", "title": "On the Scalability of the GPUexplore Explicit-State Model Checker", "comments": "In Proceedings GaM 2017, arXiv:1712.08345", "journal-ref": "EPTCS 263, 2017, pp. 38-52", "doi": "10.4204/EPTCS.263.4", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The use of graphics processors (GPUs) is a promising approach to speed up\nmodel checking to such an extent that it becomes feasible to instantly verify\nsoftware systems during development. GPUexplore is an explicit-state model\nchecker that runs all its computations on the GPU. Over the years it has been\nextended with various techniques, and the possibilities to further improve its\nperformance have been continuously investigated. In this paper, we discuss how\nthe hash table of the tool works, which is at the heart of its functionality.\nWe propose an alteration of the hash table that in isolated experiments seems\npromising, and analyse its effect when integrated in the tool. Furthermore, we\ninvestigate the current scalability of GPUexplore, by experimenting both with\ninput models of varying sizes and running the tool on one of the latest GPUs of\nNVIDIA.\n", "versions": [{"version": "v1", "created": "Wed, 27 Dec 2017 05:16:04 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Cassee", "Nathan", "", "Eindhoven University of Technology, Eindhoven, The\n  Netherlands"], ["Neele", "Thomas", "", "Eindhoven University of Technology, Eindhoven,\n  The Netherlands"], ["Wijs", "Anton", "", "Eindhoven University of Technology, Eindhoven,\n  The Netherlands"]]}, {"id": "1801.05868", "submitter": "Jie Xu", "authors": "Jie Xu, Lixing Chen, Pan Zhou", "title": "Joint Service Caching and Task Offloading for Mobile Edge Computing in\n  Dense Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile Edge Computing (MEC) pushes computing functionalities away from the\ncentralized cloud to the network edge, thereby meeting the latency requirements\nof many emerging mobile applications and saving backhaul network bandwidth.\nAlthough many existing works have studied computation offloading policies,\nservice caching is an equally, if not more important, design topic of MEC, yet\nreceives much less attention. Service caching refers to caching application\nservices and their related databases/libraries in the edge server (e.g.\nMEC-enabled BS), thereby enabling corresponding computation tasks to be\nexecuted. Because only a small number of application services can be cached in\nresource-limited edge server at the same time, which services to cache has to\nbe judiciously decided to maximize the edge computing performance. In this\npaper, we investigate the extremely compelling but much less studied problem of\ndynamic service caching in MEC-enabled dense cellular networks. We propose an\nefficient online algorithm, called OREO, which jointly optimizes dynamic\nservice caching and task offloading to address a number of key challenges in\nMEC systems, including service heterogeneity, unknown system dynamics, spatial\ndemand coupling and decentralized coordination. Our algorithm is developed\nbased on Lyapunov optimization and Gibbs sampling, works online without\nrequiring future information, and achieves provable close-to-optimal\nperformance. Simulation results show that our algorithm can effectively reduce\ncomputation latency for end users while keeping energy consumption low.\n", "versions": [{"version": "v1", "created": "Wed, 17 Jan 2018 21:20:16 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Xu", "Jie", ""], ["Chen", "Lixing", ""], ["Zhou", "Pan", ""]]}, {"id": "1801.05896", "submitter": "Lin Ma", "authors": "Lin Ma and Ruiting Zhou and Zongpeng Li", "title": "Batch Auction Design For Cloud Container Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud containers represent a new, light-weight alternative to virtual\nmachines in cloud computing. A user job may be described by a container graph\nthat specifies the resource profile of each container and container dependence\nrelations. This work is the first in the cloud computing literature that\ndesigns efficient market mechanisms for container based cloud jobs. Our design\ntargets simultaneously incentive compatibility, computational efficiency, and\neconomic efficiency. It further adapts the idea of batch online optimization\ninto the paradigm of mechanism design, leveraging agile creation of cloud\ncontainers and exploiting delay tolerance of elastic cloud jobs. The new and\nclassic techniques we employ include: (i) compact exponential optimization for\nexpressing and handling non-traditional constraints that arise from container\ndependence and job deadlines; (ii) the primal-dual schema for designing\nefficient approximation algorithms for social welfare maximization; and (iii)\nposted price mechanisms for batch decision making and truthful payment design.\nTheoretical analysis and trace-driven empirical evaluation verify the efficacy\nof our container auction algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 01:14:37 GMT"}], "update_date": "2018-01-19", "authors_parsed": [["Ma", "Lin", ""], ["Zhou", "Ruiting", ""], ["Li", "Zongpeng", ""]]}, {"id": "1801.05997", "submitter": "Jung-Woo Chang", "authors": "Jung-Woo Chang, Keon-Woo Kang, and Suk-Ju Kang", "title": "An Energy-Efficient FPGA-based Deconvolutional Neural Networks\n  Accelerator for Single Image Super-Resolution", "comments": "Accepted for publication in IEEE Transactions on Circuits and Systems\n  for Video Technology (TCSVT)", "journal-ref": null, "doi": "10.1109/TCSVT.2018.2888898", "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Convolutional neural networks (CNNs) demonstrate excellent performance in\nvarious computer vision applications. In recent years, FPGA-based CNN\naccelerators have been proposed for optimizing performance and power\nefficiency. Most accelerators are designed for object detection and recognition\nalgorithms that are performed on low-resolution (LR) images. However, real-time\nimage super-resolution (SR) cannot be implemented on a typical accelerator\nbecause of the long execution cycles required to generate high-resolution (HR)\nimages, such as those used in ultra-high-definition (UHD) systems. In this\npaper, we propose a novel CNN accelerator with efficient parallelization\nmethods for SR applications. First, we propose a new methodology for optimizing\nthe deconvolutional neural networks (DCNNs) used for increasing feature maps.\nSecondly, we propose a novel method to optimize CNN dataflow so that the SR\nalgorithm can be driven at low power in display applications. Finally, we\nquantize and compress a DCNN-based SR algorithm into an optimal model for\nefficient inference using on-chip memory. We present an energy-efficient\narchitecture for SR and validate our architecture on a mobile panel with\nquad-high-definition (QHD) resolution. Our experimental results show that, with\nthe same hardware resources, the proposed DCNN accelerator achieves a\nthroughput up to 108 times greater than that of a conventional DCNN\naccelerator. In addition, our SR system achieves an energy efficiency of 144.9\nGOPS/W, 293.0 GOPS/W, and 500.2 GOPS/W at SR scale factors of 2, 3, and 4,\nrespectively. Furthermore, we demonstrate that our system can restore HR images\nto a high quality while greatly reducing the data bit-width and the number of\nparameters compared to conventional SR algorithms.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 13:04:53 GMT"}, {"version": "v2", "created": "Wed, 25 Apr 2018 00:50:24 GMT"}, {"version": "v3", "created": "Thu, 10 May 2018 15:52:43 GMT"}, {"version": "v4", "created": "Tue, 18 Dec 2018 14:00:40 GMT"}], "update_date": "2018-12-19", "authors_parsed": [["Chang", "Jung-Woo", ""], ["Kang", "Keon-Woo", ""], ["Kang", "Suk-Ju", ""]]}, {"id": "1801.06237", "submitter": "Goran \\v{Z}u\\v{z}i\\'c", "authors": "Bernhard Haeupler, Jason Li, Goran Zuzic", "title": "Minor Excluded Network Families Admit Fast Distributed Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed network optimization algorithms, such as minimum spanning tree,\nminimum cut, and shortest path, are an active research area in distributed\ncomputing. This paper presents a fast distributed algorithm for such problems\nin the CONGEST model, on networks that exclude a fixed minor.\n  On general graphs, many optimization problems, including the ones mentioned\nabove, require $\\tilde\\Omega(\\sqrt n)$ rounds of communication in the CONGEST\nmodel, even if the network graph has a much smaller diameter. Naturally, the\nnext step in algorithm design is to design efficient algorithms which bypass\nthis lower bound on a restricted class of graphs. Currently, the only known\nmethod of doing so uses the low-congestion shortcut framework of Ghaffari and\nHaeupler [SODA'16]. Building off of their work, this paper proves that excluded\nminor graphs admit high-quality shortcuts, leading to an $\\tilde O(D^2)$ round\nalgorithm for the aforementioned problems, where $D$ is the diameter of the\nnetwork graph. To work with excluded minor graph families, we utilize the Graph\nStructure Theorem of Robertson and Seymour. To the best of our knowledge, this\nis the first time the Graph Structure Theorem has been used for an algorithmic\nresult in the distributed setting.\n  Even though the proof is involved, merely showing the existence of good\nshortcuts is sufficient to obtain simple, efficient distributed algorithms. In\nparticular, the shortcut framework can efficiently construct near-optimal\nshortcuts and then use them to solve the optimization problems. This, combined\nwith the very general family of excluded minor graphs, which includes most\nother important graph classes, makes this result of significant interest.\n", "versions": [{"version": "v1", "created": "Thu, 18 Jan 2018 20:58:04 GMT"}], "update_date": "2018-05-29", "authors_parsed": [["Haeupler", "Bernhard", ""], ["Li", "Jason", ""], ["Zuzic", "Goran", ""]]}, {"id": "1801.06340", "submitter": "Marc Shapiro", "authors": "Marc Shapiro (1), Annette Bieniusa, Nuno Pregui\\c{c}a (2), Valter\n  Balegas (2), Christopher Meiklejohn (3) ((1) DELYS, (2) NOVA-LINCS, (3) UCL)", "title": "Just-Right Consistency: reconciling availability and safety", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  By the CAP Theorem, a distributed data storage system can ensure either\nConsistency under Partition (CP) or Availability under Partition (AP), but not\nboth. This has led to a split between CP databases, in which updates are\nsynchronous, and AP databases, where they are asynchronous. However, there is\nno inherent reason to treat all updates identically: simply, the system should\nbe as available as possible, and synchronised just enough for the application\nto be correct. We offer a principled Just-Right Consistency approach to\ndesigning such applications, reconciling correctness with availability and\nperformance, based on the following insights:(i) The Conflict-Free Replicated\nData Type (CRDTs) data model supports asynchronous updates in an intuitive and\nprincipled way.(ii) Invariants involving joint or mutually-ordered updates are\ncompatible with AP and can be guaranteed by Transactional Causal Consistency,\nthe strongest consistency model that does not compromise availability.\nRegarding the remaining, \"CAP-sensitive\" invariants:(iii) For the common\npattern of Bounded Counters, we provide encapsulated data type that is proven\ncorrect and is efficient; (iv) in the general case, static analysis can\nidentify when synchronisation is not necessary for correctness.Our Antidote\ncloud database system supports CRDTs, Transactional Causal Consistency and the\nBounded Counter data type. Support tools help design applications by static\nanalysis and proof of CAP-sensitive invariants. This system supports\nindustrial-grade applications and has been tested experimentally with hundreds\nof servers across several geo-distributed data centres.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 09:32:54 GMT"}], "update_date": "2018-01-22", "authors_parsed": [["Shapiro", "Marc", "", "DELYS"], ["Bieniusa", "Annette", "", "NOVA-LINCS"], ["Pregui\u00e7a", "Nuno", "", "NOVA-LINCS"], ["Balegas", "Valter", "", "NOVA-LINCS"], ["Meiklejohn", "Christopher", "", "UCL"]]}, {"id": "1801.06541", "submitter": "Sizhuo Zhang", "authors": "Sizhuo Zhang, Hari Angepat, Derek Chiou", "title": "HGum: Messaging Framework for Hardware Accelerators", "comments": null, "journal-ref": "ReConFigurable Computing and FPGAs (ReConFig), 2017 International\n  Conference on, pp. 1-8. IEEE, 2017", "doi": "10.1109/RECONFIG.2017.8279799", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Software messaging frameworks help avoid errors and reduce engineering\nefforts in building distributed systems by (1) providing an interface\ndefinition language (IDL) to specify precisely the structure of the message\n(i.e., the message schema), and (2) automatically generating the serialization\nand deserialization functions that transform user data structures into binary\ndata for sending across the network and vice versa. Similarly, a\nhardware-accelerated system, which consists of host software and multiple\nFPGAs, could also benefit from a messaging framework to handle messages both\nbetween software and FPGA and also between different FPGAs. The key challenge\nfor a hardware messaging framework is that it must be able to support large\nmessages with complex schema while meeting critical constraints such as clock\nfrequency, area, and throughput.\n  In this paper, we present HGum, a messaging framework for hardware\naccelerators that meets all the above requirements. HGum is able to generate\nhigh-performance and low-cost hardware logic by employing a novel design that\nalgorithmically parses the message schema to perform serialization and\ndeserialization. Our evaluation of HGum shows that it not only significantly\nreduces engineering efforts but also generates hardware with comparable quality\nto manual implementation.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 12:43:30 GMT"}], "update_date": "2018-09-11", "authors_parsed": [["Zhang", "Sizhuo", ""], ["Angepat", "Hari", ""], ["Chiou", "Derek", ""]]}, {"id": "1801.07168", "submitter": "Lachlan Urquhart Ph.D", "authors": "Lachlan Urquhart, Tom Lodge, Andy Crabtree", "title": "Demonstrably Doing Accountability in the Internet of Things", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.HC cs.CY cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the importance of accountability to data protection, and\nhow it can be built into the Internet of Things (IoT). The need to build\naccountability into the IoT is motivated by the opaque nature of distributed\ndata flows, inadequate consent mechanisms, and lack of interfaces enabling\nend-user control over the behaviours of internet-enabled devices. The lack of\naccountability precludes meaningful engagement by end-users with their personal\ndata and poses a key challenge to creating user trust in the IoT and the\nreciprocal development of the digital economy. The EU General Data Protection\nRegulation 2016 (GDPR) seeks to remedy this particular problem by mandating\nthat a rapidly developing technological ecosystem be made accountable. In doing\nso it foregrounds new responsibilities for data controllers, including data\nprotection by design and default, and new data subject rights such as the right\nto data portability. While GDPR is technologically neutral, it is nevertheless\nanticipated that realising the vision will turn upon effective technological\ndevelopment. Accordingly, this paper examines the notion of accountability, how\nit has been translated into systems design recommendations for the IoT, and how\nthe IoT Databox puts key data protection principles into practice.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 16:12:19 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Urquhart", "Lachlan", ""], ["Lodge", "Tom", ""], ["Crabtree", "Andy", ""]]}, {"id": "1801.07184", "submitter": "Bernd Hartke", "authors": "Florian Spenke, Karsten Balzer, Sascha Frick, Bernd Hartke, Johannes\n  M. Dieterich", "title": "Adaptive parallelism with RMI: Idle high-performance computing resources\n  can be completely avoided", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC physics.chem-ph physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In practice, standard scheduling of parallel computing jobs almost always\nleaves significant portions of the available hardware unused, even with many\njobs still waiting in the queue. The simple reason is that the resource\nrequests of these waiting jobs are fixed and do not match the available, unused\nresources. However, with alternative but existing and well-established\ntechniques it is possible to achieve a fully automated, adaptive parallelism\nthat does not need pre-set, fixed resources. Here, we demonstrate that such an\nadaptively parallel program can indeed fill in all such scheduling gaps, even\nin real-life situations on large supercomputers.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 16:27:09 GMT"}, {"version": "v2", "created": "Fri, 1 Feb 2019 15:07:22 GMT"}], "update_date": "2019-02-04", "authors_parsed": [["Spenke", "Florian", ""], ["Balzer", "Karsten", ""], ["Frick", "Sascha", ""], ["Hartke", "Bernd", ""], ["Dieterich", "Johannes M.", ""]]}, {"id": "1801.07189", "submitter": "Lachlan Urquhart Ph.D", "authors": "Lachlan Urquhart, Neelima Sailaja, Derek McAuley", "title": "Realising the Right to Data Portability for the Domestic Internet of\n  Things", "comments": null, "journal-ref": "Personal and Ubiquitous Computing, Springer, 2017", "doi": "10.1007/s00779-017-1069-2", "report-no": null, "categories": "cs.HC cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There is an increasing role for the IT design community to play in regulation\nof emerging IT. Article 25 of the EU General Data Protection Regulation (GDPR)\n2016 puts this on a strict legal basis by establishing the need for information\nprivacy by design and default (PbD) for personal data-driven technologies.\nAgainst this backdrop, we examine legal, commercial and technical perspectives\naround the newly created legal right to data portability (RTDP) in GDPR. We are\nmotivated by a pressing need to address regulatory challenges stemming from the\nInternet of Things (IoT). We need to find channels to support the protection of\nthese new legal rights for users in practice. In Part I we introduce the\ninternet of things and information PbD in more detail. We briefly consider\nregulatory challenges posed by the IoT and the nature and practical challenges\nsurrounding the regulatory response of information privacy by design. In Part\nII, we look in depth at the legal nature of the RTDP, determining what it\nrequires from IT designers in practice but also limitations on the right and\nhow it relates to IoT. In Part III we focus on technical approaches that can\nsupport the realisation of the right. We consider the state of the art in data\nmanagement architectures, tools and platforms that can provide portability,\nincreased transparency and user control over the data flows. In Part IV, we\nbring our perspectives together to reflect on the technical, legal and business\nbarriers and opportunities that will shape the implementation of the RTDP in\npractice, and how the relationships may shape emerging IoT innovation and\nbusiness models. We finish with brief conclusions about the future for the RTDP\nand PbD in the IoT.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 16:49:18 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Urquhart", "Lachlan", ""], ["Sailaja", "Neelima", ""], ["McAuley", "Derek", ""]]}, {"id": "1801.07207", "submitter": "Lachlan Urquhart Ph.D", "authors": "Lachlan Urquhart, Derek McAuley", "title": "Avoiding the Internet of Insecure Industrial Things", "comments": null, "journal-ref": "Computer Law and Security Review, 2018", "doi": "10.1016/j.clsr.2017.12.004", "report-no": null, "categories": "cs.HC cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security incidents such as targeted distributed denial of service (DDoS)\nattacks on power grids and hacking of factory industrial control systems (ICS)\nare on the increase. This paper unpacks where emerging security risks lie for\nthe industrial internet of things, drawing on both technical and regulatory\nperspectives. Legal changes are being ushered by the European Union (EU)\nNetwork and Information Security (NIS) Directive 2016 and the General Data\nProtection Regulation 2016 (GDPR) (both to be enforced from May 2018). We use\nthe case study of the emergent smart energy supply chain to frame, scope out\nand consolidate the breadth of security concerns at play, and the regulatory\nresponses. We argue the industrial IoT brings four security concerns to the\nfore, namely: appreciating the shift from offline to online infrastructure;\nmanaging temporal dimensions of security; addressing the implementation gap for\nbest practice; and engaging with infrastructural complexity. Our goal is to\nsurface risks and foster dialogue to avoid the emergence of an Internet of\nInsecure Industrial Things\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 17:19:18 GMT"}], "update_date": "2018-01-23", "authors_parsed": [["Urquhart", "Lachlan", ""], ["McAuley", "Derek", ""]]}, {"id": "1801.07319", "submitter": "Duong Nguyen", "authors": "Duong Nguyen, Aleksey Charapko, Sandeep Kulkarni, Murat Demirbas", "title": "Optimistic Execution in Key-Value Store", "comments": "This paper is submitted to ICDCS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Limitations of CAP theorem imply that if availability is desired in the\npresence of network partitions, one must sacrifice sequential consistency, a\nconsistency model that is more natural for system design. We focus on the\nproblem of what a designer should do if she has an algorithm that works\ncorrectly with sequential consistency but is faced with an underlying key-value\nstore that provides a weaker (e.g., eventual or causal) consistency. We propose\na detect-rollback based approach: The designer identifies a correctness\npredicate, say P , and continue to run the protocol, as our system monitors P .\nIf P is violated (because the underlying key-value store provides a weaker\nconsistency), the system rolls back and resumes the computation at a state\nwhere P holds.\n  We evaluate this approach in the Voldemort key-value store. Our experiments\nwith deployment of Voldemort on Amazon AWS shows that using eventual\nconsistency with monitoring can provide 20 - 40% increase in throughput when\ncompared with sequential consistency. We also show that the overhead of the\nmonitor itself is small (typically less than 8%) and the latency of detecting\nviolations is very low. For example, more than 99.9% violations are detected in\nless than 1 second.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 20:58:37 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Nguyen", "Duong", ""], ["Charapko", "Aleksey", ""], ["Kulkarni", "Sandeep", ""], ["Demirbas", "Murat", ""]]}, {"id": "1801.07399", "submitter": "Pan Xu", "authors": "Pan Xu, Cuong Nguyen and Srikanta Tirthapura", "title": "Onion Curve: A Space Filling Curve with Near-Optimal Clustering", "comments": "The short version is published in ICDE 18", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CG cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Space filling curves (SFCs) are widely used in the design of indexes for\nspatial and temporal data. Clustering is a key metric for an SFC, that measures\nhow well the curve preserves locality in moving from higher dimensions to a\nsingle dimension. We present the {\\em onion curve}, an SFC whose clustering\nperformance is provably close to optimal for the cube and near-cube shaped\nquery sets, irrespective of the side length of the query. We show that in\ncontrast, the clustering performance of the widely used Hilbert curve can be\nfar from optimal, even for cube-shaped queries. Since the clustering\nperformance of an SFC is critical to the efficiency of multi-dimensional\nindexes based on the SFC, the onion curve can deliver improved performance for\ndata structures involving multi-dimensional data.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 05:35:00 GMT"}, {"version": "v2", "created": "Sun, 3 Jun 2018 17:44:15 GMT"}], "update_date": "2018-06-05", "authors_parsed": [["Xu", "Pan", ""], ["Nguyen", "Cuong", ""], ["Tirthapura", "Srikanta", ""]]}, {"id": "1801.07487", "submitter": "Qian Yu", "authors": "Qian Yu, Mohammad Ali Maddah-Ali, A. Salman Avestimehr", "title": "Straggler Mitigation in Distributed Matrix Multiplication: Fundamental\n  Limits and Optimal Coding", "comments": null, "journal-ref": "Published in: IEEE Transactions on Information Theory (Jan. 2020)", "doi": "10.1109/TIT.2019.2963864", "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of massive matrix multiplication, which underlies\nmany data analytic applications, in a large-scale distributed system comprising\na group of worker nodes. We target the stragglers' delay performance\nbottleneck, which is due to the unpredictable latency in waiting for slowest\nnodes (or stragglers) to finish their tasks. We propose a novel coding\nstrategy, named \\emph{entangled polynomial code}, for designing the\nintermediate computations at the worker nodes in order to minimize the recovery\nthreshold (i.e., the number of workers that we need to wait for in order to\ncompute the final output). We demonstrate the optimality of entangled\npolynomial code in several cases, and show that it provides orderwise\nimprovement over the conventional schemes for straggler mitigation.\nFurthermore, we characterize the optimal recovery threshold among all linear\ncoding strategies within a factor of $2$ using \\emph{bilinear complexity}, by\ndeveloping an improved version of the entangled polynomial code. In particular,\nwhile evaluating bilinear complexity is a well-known challenging problem, we\nshow that optimal recovery threshold for linear coding strategies can be\napproximated within a factor of $2$ of this fundamental quantity. On the other\nhand, the improved version of the entangled polynomial code enables further and\norderwise reduction in the recovery threshold, compared to its basic version.\nFinally, we show that the techniques developed in this paper can also be\nextended to several other problems such as coded convolution and fault-tolerant\ncomputing, leading to tight characterizations.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 11:34:59 GMT"}, {"version": "v2", "created": "Sat, 5 May 2018 08:39:27 GMT"}, {"version": "v3", "created": "Wed, 18 Dec 2019 12:50:21 GMT"}, {"version": "v4", "created": "Wed, 22 Jan 2020 10:45:56 GMT"}, {"version": "v5", "created": "Thu, 9 Apr 2020 17:50:03 GMT"}], "update_date": "2020-04-10", "authors_parsed": [["Yu", "Qian", ""], ["Maddah-Ali", "Mohammad Ali", ""], ["Avestimehr", "A. Salman", ""]]}, {"id": "1801.07548", "submitter": "Changhua Li", "authors": "Changhua Li, Chenzhou Cui, Boliang He, Dongwei Fan, Linying Mi,\n  Shanshan Li, Sisi Yang, Yunfei Xu, Jun Han, Junyi Chen, Hailong Zhang, Ce Yu,\n  Jian Xiao, Chuanjun Wang, Zihuang Cao, Yufeng Fan, Liang Liu, Xiao Chen,\n  Wenming Song, Kangyu Du", "title": "A hybrid architecture for astronomical computing", "comments": "4 pages, 2 figures, ADASS XXVI conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With many large science equipment constructing and putting into use,\nastronomy has stepped into the big data era. The new method and infrastructure\nof big data processing has become a new requirement of many astronomers. Cloud\ncomputing, Map/Reduce, Hadoop, Spark, etc. many new technology has sprung up in\nrecent years. Comparing to the high performance computing(HPC), Data is the\ncenter of these new technology. So, a new computing architecture infrastructure\nis necessary, which can be shared by both HPC and big data processing. Based on\nAstronomy Cloud project of Chinese Virtual Observatory (China-VO), we have made\nmuch efforts to optimize the designation of the hybrid computing platform.\nwhich include the hardware architecture, cluster management, Job and Resource\nscheduling.\n", "versions": [{"version": "v1", "created": "Fri, 19 Jan 2018 03:01:49 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Li", "Changhua", ""], ["Cui", "Chenzhou", ""], ["He", "Boliang", ""], ["Fan", "Dongwei", ""], ["Mi", "Linying", ""], ["Li", "Shanshan", ""], ["Yang", "Sisi", ""], ["Xu", "Yunfei", ""], ["Han", "Jun", ""], ["Chen", "Junyi", ""], ["Zhang", "Hailong", ""], ["Yu", "Ce", ""], ["Xiao", "Jian", ""], ["Wang", "Chuanjun", ""], ["Cao", "Zihuang", ""], ["Fan", "Yufeng", ""], ["Liu", "Liang", ""], ["Chen", "Xiao", ""], ["Song", "Wenming", ""], ["Du", "Kangyu", ""]]}, {"id": "1801.07549", "submitter": "Johannes Bund", "authors": "Johannes Bund and Christoph Lenzen and Moti Medina", "title": "Optimal Metastability-Containing Sorting Networks", "comments": "The paper will be published during DATE 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When setup/hold times of bistable elements are violated, they may become\nmetastable, i.e., enter a transient state that is neither digital 0 nor 1. In\ngeneral, metastability cannot be avoided, a problem that manifests whenever\ntaking discrete measurements of analog values. Metastability of the output then\nreflects uncertainty as to whether a measurement should be rounded up or down\nto the next possible measurement outcome.\n  Surprisingly, Lenzen and Medina (ASYNC 2016) showed that metastability can be\ncontained, i.e., measurement values can be correctly sorted without resolving\nmetastability first. However, both their work and the state of the art by Bund\net al. (DATE 2017) leave open whether such a solution can be as small and fast\nas standard sorting networks. We show that this is indeed possible, by\nproviding a circuit that sorts Gray code inputs (possibly containing a\nmetastable bit) and has asymptotically optimal depth and size. Concretely, for\n10-channel sorting networks and 16-bit wide inputs, we improve by 48.46% in\ndelay and by 71.58% in area over Bund et al. Our simulations indicate that\nstraightforward transistor-level optimization is likely to result in\nperformance on par with standard (non-containing) solutions.\n", "versions": [{"version": "v1", "created": "Mon, 22 Jan 2018 10:29:02 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Bund", "Johannes", ""], ["Lenzen", "Christoph", ""], ["Medina", "Moti", ""]]}, {"id": "1801.07624", "submitter": "Michal Zasadzinski", "authors": "Micha{\\l} Zasadzi\\'nski, Victor Munt\\'es-Mulero, Marc Sol\\'e, Thomas\n  Ludwig", "title": "Mistral Supercomputer Job History Analysis", "comments": "16 pages, 14 figures, 5 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report, we show insights and results of operational data\nanalysis from petascale supercomputer Mistral, which is ranked as 42nd most\npowerful in the world as of January 2018. Data sources include hardware\nmonitoring data, job scheduler history, topology, and hardware information. We\nexplore job state sequences, spatial distribution, and electric power patterns.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 15:51:50 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Zasadzi\u0144ski", "Micha\u0142", ""], ["Munt\u00e9s-Mulero", "Victor", ""], ["Sol\u00e9", "Marc", ""], ["Ludwig", "Thomas", ""]]}, {"id": "1801.07630", "submitter": "Ioannis Paraskevakos", "authors": "Ioannis Paraskevakos and Andre Luckow and Mahzad Khoshlessan and\n  George Chantzialexiou and Thomas E. Cheatham and Oliver Beckstein and\n  Geoffrey C. Fox and Shantenu Jha", "title": "Task-parallel Analysis of Molecular Dynamics Trajectories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Different parallel frameworks for implementing data analysis applications\nhave been proposed by the HPC and Big Data communities. In this paper, we\ninvestigate three task-parallel frameworks: Spark, Dask and RADICAL-Pilot with\nrespect to their ability to support data analytics on HPC resources and compare\nthem with MPI. We investigate the data analysis requirements of Molecular\nDynamics (MD) simulations which are significant consumers of supercomputing\ncycles, producing immense amounts of data. A typical large-scale MD simulation\nof a physical system of O(100k) atoms over {\\mu}secs can produce from O(10) GB\nto O(1000) GBs of data. We propose and evaluate different approaches for\nparallelization of a representative set of MD trajectory analysis algorithms,\nin particular the computation of path similarity and leaflet identification. We\nevaluate Spark, Dask and RADICAL-Pilot with respect to their abstractions and\nruntime engine capabilities to support these algorithms. We provide a\nconceptual basis for comparing and understanding different frameworks that\nenable users to select the optimal system for each application. We also provide\na quantitative performance analysis of the different algorithms across the\nthree frameworks.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 16:01:12 GMT"}, {"version": "v2", "created": "Wed, 11 Apr 2018 16:58:04 GMT"}, {"version": "v3", "created": "Mon, 11 Jun 2018 00:51:10 GMT"}], "update_date": "2018-06-12", "authors_parsed": [["Paraskevakos", "Ioannis", ""], ["Luckow", "Andre", ""], ["Khoshlessan", "Mahzad", ""], ["Chantzialexiou", "George", ""], ["Cheatham", "Thomas E.", ""], ["Beckstein", "Oliver", ""], ["Fox", "Geoffrey C.", ""], ["Jha", "Shantenu", ""]]}, {"id": "1801.07656", "submitter": "Yoann Dieudonn\\'e", "authors": "S\\'ebastien Bouchard, Yoann Dieudonn\\'e, Anissa Lamani", "title": "Byzantine Gathering in Polynomial Time", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the task of Byzantine gathering in a network modeled as a graph.\nDespite the presence of Byzantine agents, all the other (good) agents, starting\nfrom possibly different nodes and applying the same deterministic algorithm,\nhave to meet at the same node in finite time and stop moving. An adversary\nchooses the initial nodes of the agents and assigns a different label to each\nof them. The agents move in synchronous rounds and communicate with each other\nonly when located at the same node. Within the team, f of the agents are\nByzantine. A Byzantine agent acts in an unpredictable way: in particular it may\nforge the label of another agent or create a completely new one. Besides its\nlabel, which corresponds to a local knowledge, an agent is assigned some global\nknowledge GK that is common to all agents. In literature, the Byzantine\ngathering problem has been analyzed in arbitrary n-node graphs by considering\nthe scenario when GK=(n,f) and the scenario when GK=f. In the first (resp.\nsecond) scenario, it has been shown that the minimum number of good agents\nguaranteeing deterministic gathering of all of them is f+1 (resp. f+2). For\nboth these scenarios, all the existing deterministic algorithms, whether or not\nthey are optimal in terms of required number of good agents, have a time\ncomplexity that is exponential in n and L, where L is the largest label\nbelonging to a good agent.\n  In this paper, we seek to design a deterministic solution for Byzantine\ngathering that makes a concession on the proportion of Byzantine agents within\nthe team, but that offers a significantly lower complexity. We also seek to use\na global knowledge whose the length of the binary representation is small.\nAssuming that the agents are in a strong team i.e., a team in which the number\nof good agents is at least some prescribed value that is quadratic in f, we\ngive positive and negative results.\n", "versions": [{"version": "v1", "created": "Tue, 23 Jan 2018 16:53:19 GMT"}], "update_date": "2018-01-24", "authors_parsed": [["Bouchard", "S\u00e9bastien", ""], ["Dieudonn\u00e9", "Yoann", ""], ["Lamani", "Anissa", ""]]}, {"id": "1801.08030", "submitter": "Srinivas Sridharan", "authors": "Srinivas Sridharan, Karthikeyan Vaidyanathan, Dhiraj Kalamkar,\n  Dipankar Das, Mikhail E. Smorkalov, Mikhail Shiryaev, Dheevatsa Mudigere,\n  Naveen Mellempudi, Sasikanth Avancha, Bharat Kaul, Pradeep Dubey", "title": "On Scale-out Deep Learning Training for Cloud and HPC", "comments": "Accepted in SysML 2018 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The exponential growth in use of large deep neural networks has accelerated\nthe need for training these deep neural networks in hours or even minutes. This\ncan only be achieved through scalable and efficient distributed training, since\na single node/card cannot satisfy the compute, memory, and I/O requirements of\ntoday's state-of-the-art deep neural networks. However, scaling synchronous\nStochastic Gradient Descent (SGD) is still a challenging problem and requires\ncontinued research/development. This entails innovations spanning algorithms,\nframeworks, communication libraries, and system design. In this paper, we\ndescribe the philosophy, design, and implementation of Intel Machine Learning\nScalability Library (MLSL) and present proof-points demonstrating scaling DL\ntraining on 100s to 1000s of nodes across Cloud and HPC systems.\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 15:38:17 GMT"}], "update_date": "2018-01-25", "authors_parsed": [["Sridharan", "Srinivas", ""], ["Vaidyanathan", "Karthikeyan", ""], ["Kalamkar", "Dhiraj", ""], ["Das", "Dipankar", ""], ["Smorkalov", "Mikhail E.", ""], ["Shiryaev", "Mikhail", ""], ["Mudigere", "Dheevatsa", ""], ["Mellempudi", "Naveen", ""], ["Avancha", "Sasikanth", ""], ["Kaul", "Bharat", ""], ["Dubey", "Pradeep", ""]]}, {"id": "1801.08058", "submitter": "David Cyphers", "authors": "Scott Cyphers, Arjun K. Bansal, Anahita Bhiwandiwalla, Jayaram Bobba,\n  Matthew Brookhart, Avijit Chakraborty, Will Constable, Christian Convey,\n  Leona Cook, Omar Kanawi, Robert Kimball, Jason Knight, Nikolay Korovaiko,\n  Varun Kumar, Yixing Lao, Christopher R. Lishka, Jaikrishnan Menon, Jennifer\n  Myers, Sandeep Aswath Narayana, Adam Procter, Tristan J. Webb", "title": "Intel nGraph: An Intermediate Representation, Compiler, and Executor for\n  Deep Learning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Deep Learning (DL) community sees many novel topologies published each\nyear. Achieving high performance on each new topology remains challenging, as\neach requires some level of manual effort. This issue is compounded by the\nproliferation of frameworks and hardware platforms. The current approach, which\nwe call \"direct optimization\", requires deep changes within each framework to\nimprove the training performance for each hardware backend (CPUs, GPUs, FPGAs,\nASICs) and requires $\\mathcal{O}(fp)$ effort; where $f$ is the number of\nframeworks and $p$ is the number of platforms. While optimized kernels for\ndeep-learning primitives are provided via libraries like Intel Math Kernel\nLibrary for Deep Neural Networks (MKL-DNN), there are several compiler-inspired\nways in which performance can be further optimized. Building on our experience\ncreating neon (a fast deep learning library on GPUs), we developed Intel\nnGraph, a soon to be open-sourced C++ library to simplify the realization of\noptimized deep learning performance across frameworks and hardware platforms.\nInitially-supported frameworks include TensorFlow, MXNet, and Intel neon\nframework. Initial backends are Intel Architecture CPUs (CPU), the Intel(R)\nNervana Neural Network Processor(R) (NNP), and NVIDIA GPUs. Currently supported\ncompiler optimizations include efficient memory management and data layout\nabstraction. In this paper, we describe our overall architecture and its core\ncomponents. In the future, we envision extending nGraph API support to a wider\nrange of frameworks, hardware (including FPGAs and ASICs), and compiler\noptimizations (training versus inference optimizations, multi-node and\nmulti-device scaling via efficient sub-graph partitioning, and HW-specific\ncompounding of operations).\n", "versions": [{"version": "v1", "created": "Wed, 24 Jan 2018 16:17:53 GMT"}, {"version": "v2", "created": "Tue, 30 Jan 2018 00:14:49 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Cyphers", "Scott", ""], ["Bansal", "Arjun K.", ""], ["Bhiwandiwalla", "Anahita", ""], ["Bobba", "Jayaram", ""], ["Brookhart", "Matthew", ""], ["Chakraborty", "Avijit", ""], ["Constable", "Will", ""], ["Convey", "Christian", ""], ["Cook", "Leona", ""], ["Kanawi", "Omar", ""], ["Kimball", "Robert", ""], ["Knight", "Jason", ""], ["Korovaiko", "Nikolay", ""], ["Kumar", "Varun", ""], ["Lao", "Yixing", ""], ["Lishka", "Christopher R.", ""], ["Menon", "Jaikrishnan", ""], ["Myers", "Jennifer", ""], ["Narayana", "Sandeep Aswath", ""], ["Procter", "Adam", ""], ["Webb", "Tristan J.", ""]]}, {"id": "1801.08618", "submitter": "Amir Erfan Eshratifar", "authors": "Amir Erfan Eshratifar, Mohammad Saeed Abrishami, Massoud Pedram", "title": "JointDNN: An Efficient Training and Inference Engine for Intelligent\n  Mobile Cloud Computing Services", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AI cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deep learning models are being deployed in many mobile intelligent\napplications. End-side services, such as intelligent personal assistants,\nautonomous cars, and smart home services often employ either simple local\nmodels on the mobile or complex remote models on the cloud. However, recent\nstudies have shown that partitioning the DNN computations between the mobile\nand cloud can increase the latency and energy efficiencies. In this paper, we\npropose an efficient, adaptive, and practical engine, JointDNN, for\ncollaborative computation between a mobile device and cloud for DNNs in both\ninference and training phase. JointDNN not only provides an energy and\nperformance efficient method of querying DNNs for the mobile side but also\nbenefits the cloud server by reducing the amount of its workload and\ncommunications compared to the cloud-only approach. Given the DNN architecture,\nwe investigate the efficiency of processing some layers on the mobile device\nand some layers on the cloud server. We provide optimization formulations at\nlayer granularity for forward- and backward-propagations in DNNs, which can\nadapt to mobile battery limitations and cloud server load constraints and\nquality of service. JointDNN achieves up to 18 and 32 times reductions on the\nlatency and mobile energy consumption of querying DNNs compared to the\nstatus-quo approaches, respectively.\n", "versions": [{"version": "v1", "created": "Thu, 25 Jan 2018 22:20:11 GMT"}, {"version": "v2", "created": "Tue, 4 Feb 2020 20:53:08 GMT"}], "update_date": "2020-02-06", "authors_parsed": [["Eshratifar", "Amir Erfan", ""], ["Abrishami", "Mohammad Saeed", ""], ["Pedram", "Massoud", ""]]}, {"id": "1801.08648", "submitter": "Andre Luckow", "authors": "Andre Luckow and George Chantzialexiou and Shantenu Jha", "title": "Pilot-Streaming: A Stream Processing Framework for High-Performance\n  Computing", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of scientific applications rely on stream processing for\ngenerating timely insights from data feeds of scientific instruments,\nsimulations, and Internet-of-Thing (IoT) sensors. The development of streaming\napplications is a complex task and requires the integration of heterogeneous,\ndistributed infrastructure, frameworks, middleware and application components.\nDifferent application components are often written in different languages using\ndifferent abstractions and frameworks. Often, additional components, such as a\nmessage broker (e.g. Kafka), are required to decouple data production and\nconsumptions and avoiding issues, such as back-pressure. Streaming applications\nmay be extremely dynamic due to factors, such as variable data rates caused by\nthe data source, adaptive sampling techniques or network congestions, variable\nprocessing loads caused by usage of different machine learning algorithms. As a\nresult application-level resource management that can respond to changes in one\nof these factors is critical. We propose Pilot-Streaming, a framework for\nsupporting streaming frameworks, applications and their resource management\nneeds on HPC infrastructure. Pilot-Streaming is based on the Pilot-Job concept\nand enables developers to manage distributed computing and data resources for\ncomplex streaming applications. It enables applications to dynamically respond\nto resource requirements by adding/removing resources at runtime. This\ncapability is critical for balancing complex streaming pipelines. To address\nthe complexity in developing and characterization of streaming applications, we\npresent the Streaming Mini- App framework, which supports different plug-able\nalgorithms for data generation and processing, e.g., for reconstructing light\nsource images using different techniques. We utilize the Mini-App framework to\nconduct an evaluation of Pilot-Streaming.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 01:50:20 GMT"}, {"version": "v2", "created": "Sun, 11 Nov 2018 12:05:33 GMT"}], "update_date": "2018-11-13", "authors_parsed": [["Luckow", "Andre", ""], ["Chantzialexiou", "George", ""], ["Jha", "Shantenu", ""]]}, {"id": "1801.08710", "submitter": "Sathya Chinnathambi", "authors": "C Sathya, S Agilan, A G Aruna", "title": "Enhancing Byzantine fault tolerance using MD5 checksum and delay\n  variation in Cloud services", "comments": "22 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing management are beyond typical human narratives. However if a\nvirtual system is not effectively designed to tolerate Byzantine faults, it\ncould lead to a faultily executed mission rather than a cloud crash. The cloud\ncould recover from the crash but it could not recover from the loss of\ncredibility. Moreover no amount of replication or fault handling measures can\nbe helpful in facing a Byzantine fault unless the virtual system is designed to\ndetect, tolerate and eliminate such faults. However research efforts that are\nmade to address Byzantine faults have not provided convincing solutions vastly\ndue to their limited capabilities in detecting the Byzantine faults. As a\nresult, in this paper the Cloud system is modeled as a discrete system to\ndetermine the virtual system behavior at varying time intervals. A delay\nvariation variable as a measure of deviation for the expected processing delay\nassociated with the virtual nodes takes values from the set of P {low, normal,\nhigh, extreme}. Similarly, a check sum error variable which is even computed\nfor intra nodes that have no attachment to TCP/IP stack takes values from the\nset of P {no error, error}. These conditions are then represented by the\noccurrence of faulty events that cause specific component mode transition from\nfail safe to fail-stop or byzantine prone.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 08:25:22 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Sathya", "C", ""], ["Agilan", "S", ""], ["Aruna", "A G", ""]]}, {"id": "1801.08761", "submitter": "Vi Tran", "authors": "Phuong Hoai Ha, Vi Ngoc-Nha Tran, Ibrahim Umar, Aras Atalar, Anders\n  Gidenstam, Paul Renaud-Goud, Philippas Tsigas", "title": "D2.2 White-box methodologies, programming abstractions and libraries", "comments": "Execution Models for Energy-Efficient Computing Systems, an EU\n  Project, ID: 611183, 108 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This deliverable reports the results of white-box methodologies and early\nresults of the first prototype of libraries and programming abstractions as\navailable by project month 18 by Work Package 2 (WP2). It reports i) the latest\nresults of Task 2.2 on white-box methodologies, programming abstractions and\nlibraries for developing energy-efficient data structures and algorithms and\nii) the improved results of Task 2.1 on investigating and modeling the\ntrade-off between energy and performance of concurrent data structures and\nalgorithms. The work has been conducted on two main EXCESS platforms: Intel\nplatforms with recent Intel multicore CPUs and Movidius Myriad1 platform.\nRegarding white-box methodologies, we have devised new relaxed cache-oblivious\nmodels and proposed a new power model for Myriad1 platform and an energy model\nfor lock-free queues on CPU platforms. For Myriad1 platform, the im- proved\nmodel now considers both computation and data movement cost as well as\narchitecture and application properties. The model has been evaluated with a\nset of micro-benchmarks and application benchmarks. For Intel platforms, we\nhave generalized the model for concurrent queues on CPU platforms to offer more\nflexibility according to the workers calling the data structure (parallel\nsection sizes of enqueuers and dequeuers are decoupled). Regarding programming\nabstractions and libraries, we have continued investigat- ing the trade-offs\nbetween energy consumption and performance of data structures such as\nconcurrent queues and concurrent search trees based on the early results of\nTask 2.1.The preliminary results show that our concurrent trees are faster and\nmore energy efficient than the state-of-the-art on commodity HPC and embedded\nplatforms.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 11:29:48 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 08:59:14 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Ha", "Phuong Hoai", ""], ["Tran", "Vi Ngoc-Nha", ""], ["Umar", "Ibrahim", ""], ["Atalar", "Aras", ""], ["Gidenstam", "Anders", ""], ["Renaud-Goud", "Paul", ""], ["Tsigas", "Philippas", ""]]}, {"id": "1801.08873", "submitter": "Alexander Thomasian", "authors": "Alexander Thomasian", "title": "Mirrored and Hybrid Disk Arrays: Organization, Scheduling, Reliability,\n  and Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS cs.PF", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Basic mirroring (BM) classified as RAID level 1 replicates data on two disks,\nthus doubling disk access bandwidth for read requests. RAID1/0 is an array of\nBM pairs with balanced loads due to striping. When a disk fails the read load\non its pair is doubled, which results in halving the maximum attainable\nbandwidth. We review RAID1 organizations which attain a balanced load upon disk\nfailure, but as shown by reliability analysis tend to be less reliable than\nRAID1/0. Hybrid disk arrays which store XORed instead of replicated data tend\nto have a higher reliability than mirrored disks, but incur a higher overhead\nin updating data. Read request response time can be improved by processing them\nat a higher priority than writes, since they have a direct effect on\napplication response time. Shortest seek distance and affinity based routing\nboth shorten seek time. Anticipatory arm placement places arms optimally to\nminimize the seek distance. The analysis of RAID1 in normal, degraded, and\nrebuild mode is provided to quantify RAID1/0 performance. We compare the\nreliability of mirrored disk organizations against each other and hybrid disks\nand erasure coded disk arrays.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 15:59:51 GMT"}], "update_date": "2018-01-29", "authors_parsed": [["Thomasian", "Alexander", ""]]}, {"id": "1801.09444", "submitter": "Suejb Memeti", "authors": "Suejb Memeti, Sabri Pllana, Alecio Binotto, Joanna Kolodziej, and\n  Ivona Brandic", "title": "Using Meta-heuristics and Machine Learning for Software Optimization of\n  Parallel Computing Systems: A Systematic Literature Review", "comments": "Preprint", "journal-ref": null, "doi": "10.1007/s00607-018-0614-9", "report-no": null, "categories": "cs.DC cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While modern parallel computing systems offer high performance, utilizing\nthese powerful computing resources to the highest possible extent demands\nadvanced knowledge of various hardware architectures and parallel programming\nmodels. Furthermore, optimized software execution on parallel computing systems\ndemands consideration of many parameters at compile-time and run-time.\nDetermining the optimal set of parameters in a given execution context is a\ncomplex task, and therefore to address this issue researchers have proposed\ndifferent approaches that use heuristic search or machine learning. In this\npaper, we undertake a systematic literature review to aggregate, analyze and\nclassify the existing software optimization methods for parallel computing\nsystems. We review approaches that use machine learning or meta-heuristics for\nsoftware optimization at compile-time and run-time. Additionally, we discuss\nchallenges and future research directions. The results of this study may help\nto better understand the state-of-the-art techniques that use machine learning\nand meta-heuristics to deal with the complexity of software optimization for\nparallel computing systems. Furthermore, it may aid in understanding the\nlimitations of existing approaches and identification of areas for improvement.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 11:03:37 GMT"}, {"version": "v2", "created": "Sat, 28 Apr 2018 16:22:04 GMT"}, {"version": "v3", "created": "Wed, 2 May 2018 15:37:30 GMT"}], "update_date": "2018-05-03", "authors_parsed": [["Memeti", "Suejb", ""], ["Pllana", "Sabri", ""], ["Binotto", "Alecio", ""], ["Kolodziej", "Joanna", ""], ["Brandic", "Ivona", ""]]}, {"id": "1801.09504", "submitter": "E. Wes Bethel", "authors": "E. Wes Bethel and Brian Tierney and Jason Lee and Dan Gunther and\n  Stephen Lau", "title": "Using High-Speed WANs and Network Data Caches to Enable Remote and\n  Distributed Visualization", "comments": "Proceedings of the 2000 ACM/IEEE Conference on Supercomputing,\n  November 2000", "journal-ref": null, "doi": null, "report-no": "LBNL 45365", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Visapult is a prototype application and framework for remote visualization of\nlarge scientific datasets. We approach the technical challenges of tera-scale\nvisualization with a unique architecture that employs high speed WANs and\nnetwork data caches for data staging and transmission. This architecture allows\nfor the use of available cache and compute resources at arbitrary locations on\nthe network. High data throughput rates and network utilization are achieved by\nparallelizing I/O at each stage in the application, and by pipelining the\nvisualization process. On the desktop, the graphics interactivity is\neffectively decoupled from the latency inherent in network applications. We\npresent a detailed performance analysis of the application, and improvements\nresulting from field-test analysis conducted as part of the DOE Combustion\nCorridor project.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 13:55:19 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Bethel", "E. Wes", ""], ["Tierney", "Brian", ""], ["Lee", "Jason", ""], ["Gunther", "Dan", ""], ["Lau", "Stephen", ""]]}, {"id": "1801.09515", "submitter": "Maurice Herlihy", "authors": "Maurice Herlihy", "title": "Atomic Cross-Chain Swaps", "comments": "To appear, PODC 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  An atomic cross-chain swap is a distributed coordination task where multiple\nparties exchange assets across multiple blockchains, for example, trading\nbitcoin for ether.\n  An atomic swap protocol guarantees (1) if all parties conform to the\nprotocol, then all swaps take place, (2) if some coalition deviates from the\nprotocol, then no conforming party ends up worse off, and (3) no coalition has\nan incentive to deviate from the protocol.\n  A cross-chain swap is modeled as a directed graph ${\\cal D}$, whose vertexes\nare parties and whose arcs are proposed asset transfers. For any pair $({\\cal\nD},L)$, where ${\\cal D} = (V,A)$ is a strongly-connected directed graph and $L\n\\subset V$ a feedback vertex set for ${\\cal D}$, we give an atomic cross-chain\nswap protocol for ${\\cal D}$, using a form of hashed timelock contracts, where\nthe vertexes in $L$ generate the hashlocked secrets. We show that no such\nprotocol is possible if ${\\cal D}$ is not strongly connected, or if ${\\cal D}$\nis strongly connected but $L$ is not a feedback vertex set. The protocol has\ntime complexity $O(diam({\\cal D}))$ and space complexity (bits stored on all\nblockchains) $O(|A|^2)$.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 14:10:22 GMT"}, {"version": "v2", "created": "Thu, 12 Apr 2018 18:04:27 GMT"}, {"version": "v3", "created": "Tue, 8 May 2018 01:30:49 GMT"}, {"version": "v4", "created": "Fri, 18 May 2018 11:54:44 GMT"}], "update_date": "2018-05-21", "authors_parsed": [["Herlihy", "Maurice", ""]]}, {"id": "1801.09535", "submitter": "Dominik Harz", "authors": "Dominik Harz and Magnus Boman", "title": "The Scalability of Trustless Trust", "comments": "16 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Permission-less blockchains can realise trustless trust, albeit at the cost\nof limiting the complexity of computation tasks. To explain the implications\nfor scalability, we have implemented a trust model for smart contracts,\ndescribed as agents in an open multi-agent system. Agent intentions are not\nnecessarily known and autonomous agents have to be able to make decisions under\nrisk. The ramifications of these general conditions for scalability are\nanalysed for Ethereum and then generalised to other current and future\nplatforms.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 14:47:28 GMT"}], "update_date": "2018-01-30", "authors_parsed": [["Harz", "Dominik", ""], ["Boman", "Magnus", ""]]}, {"id": "1801.09747", "submitter": "Sarod Yatawatta", "authors": "Sarod Yatawatta", "title": "Distributed Model Construction in Radio Interferometric Calibration", "comments": "Draft, to be published in the Proceedings of the 2018 International\n  Conference on Acoustics, Speech and Signal Processing (IEEE ICASSP 2018),\n  published by IEEE", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Calibration of a typical radio interferometric array yields thousands of\nparameters as solutions. These solutions contain valuable information about the\nsystematic errors in the data (ionosphere and beam shape). This information\ncould be reused in calibration to improve the accuracy and also can be fed into\nimaging to improve the fidelity. We propose a distributed optimization strategy\nto construct models for the systematic errors in the data using the calibration\nsolutions. We formulate this as an elastic net regularized distributed\noptimization problem which we solve using the alternating direction method of\nmultipliers (ADMM) algorithm. We give simulation results to show the\nfeasibility of the proposed distributed model construction scheme.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 20:38:29 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Yatawatta", "Sarod", ""]]}, {"id": "1801.09802", "submitter": "Maaz Bin Safeer Ahmad", "authors": "Maaz Bin Safeer Ahmad and Alvin Cheung", "title": "Automatically Leveraging MapReduce Frameworks for Data-Intensive\n  Applications", "comments": "12 pages, additional 4 pages of references and appendix", "journal-ref": "SIGMOD '18 Proceedings of the 2018 International Conference on\n  Management of Data, Pages 1205-1220", "doi": "10.1145/3183713.3196891", "report-no": null, "categories": "cs.DB cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MapReduce is a popular programming paradigm for developing large-scale,\ndata-intensive computation. Many frameworks that implement this paradigm have\nrecently been developed. To leverage these frameworks, however, developers must\nbecome familiar with their APIs and rewrite existing code. Casper is a new tool\nthat automatically translates sequential Java programs into the MapReduce\nparadigm. Casper identifies potential code fragments to rewrite and translates\nthem in two steps: (1) Casper uses program synthesis to search for a program\nsummary (i.e., a functional specification) of each code fragment. The summary\nis expressed using a high-level intermediate language resembling the MapReduce\nparadigm and verified to be semantically equivalent to the original using a\ntheorem prover. (2) Casper generates executable code from the summary, using\neither the Hadoop, Spark, or Flink API. We evaluated Casper by automatically\nconverting real-world, sequential Java benchmarks to MapReduce. The resulting\nbenchmarks perform up to 48.2x faster compared to the original.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 00:02:57 GMT"}, {"version": "v2", "created": "Tue, 19 Jun 2018 05:01:08 GMT"}], "update_date": "2018-06-20", "authors_parsed": [["Ahmad", "Maaz Bin Safeer", ""], ["Cheung", "Alvin", ""]]}, {"id": "1801.09805", "submitter": "Liang Luo", "authors": "Liang Luo, Jacob Nelson, Luis Ceze, Amar Phanishayee, Arvind\n  Krishnamurthy", "title": "Parameter Box: High Performance Parameter Servers for Efficient\n  Distributed Deep Neural Network Training", "comments": null, "journal-ref": "SysML 2018", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most work in the deep learning systems community has focused on faster\ninference, but arriving at a trained model requires lengthy experiments.\nAccelerating training lets developers iterate faster and come up with better\nmodels. DNN training is often seen as a compute-bound problem, best done in a\nsingle large compute node with many GPUs. As DNNs get bigger, training requires\ngoing distributed. Distributed deep neural network (DDNN) training constitutes\nan important workload on the cloud. Larger DNN models and faster compute\nengines shift the training performance bottleneck from computation to\ncommunication. Our experiments show existing DNN training frameworks do not\nscale in a typical cloud environment due to insufficient bandwidth and\ninefficient parameter server software stacks.We propose PBox, a balanced,\nscalable central PS hardware that balances compute and communication resources,\nand PHub, a high performance parameter server (PS) software design that\nprovides an optimized network stack and a streamlined gradient processing\npipeline to benefit common PS setups to utilize PBox. We show that in a typical\ncloud environment, PBox can achieve up to 3.8x speedup over state-of-the-art\ndesigns when training ImageNet. We discuss future directions of integrating\nPBox with programmable switches for in-network aggregation during training,\nleveraging the datacenter network topology to reduce bandwidth usage and\nlocalize data movement.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 00:10:18 GMT"}, {"version": "v2", "created": "Fri, 24 May 2019 21:15:05 GMT"}, {"version": "v3", "created": "Fri, 17 Jan 2020 21:19:42 GMT"}], "update_date": "2020-01-22", "authors_parsed": [["Luo", "Liang", ""], ["Nelson", "Jacob", ""], ["Ceze", "Luis", ""], ["Phanishayee", "Amar", ""], ["Krishnamurthy", "Arvind", ""]]}, {"id": "1801.09809", "submitter": "Ariful Azad", "authors": "Ariful Azad, Ayd{\\i}n Buluc, Xiaoye S. Li, Xinliang Wang, Johannes\n  Langguth", "title": "A Distributed-Memory Algorithm for Computing a Heavy-Weight Perfect\n  Matching on Bipartite Graphs", "comments": "28 pages, 9 figures", "journal-ref": "SIAM Journal on Scientific Computing. 2020;42(4):C143-68", "doi": "10.1137/18M1189348", "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We design and implement an efficient parallel algorithm for finding a perfect\nmatching in a weighted bipartite graph such that weights on the edges of the\nmatching are large. This problem differs from the maximum weight matching\nproblem, for which scalable approximation algorithms are known. It is primarily\nmotivated by finding good pivots in scalable sparse direct solvers before\nfactorization. Due to the lack of scalable alternatives, distributed solvers\nuse sequential implementations of maximum weight perfect matching algorithms,\nsuch as those available in MC64. To overcome this limitation, we propose a\nfully parallel distributed memory algorithm that first generates a perfect\nmatching and then iteratively improves the weight of the perfect matching by\nsearching for weight-increasing cycles of length four in parallel. For most\npractical problems the weights of the perfect matchings generated by our\nalgorithm are very close to the optimum. An efficient implementation of the\nalgorithm scales up to 256 nodes (17,408 cores) on a Cray XC40 supercomputer\nand can solve instances that are too large to be handled by a single node using\nthe sequential algorithm.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 00:18:06 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2020 04:27:27 GMT"}], "update_date": "2020-09-07", "authors_parsed": [["Azad", "Ariful", ""], ["Buluc", "Ayd\u0131n", ""], ["Li", "Xiaoye S.", ""], ["Wang", "Xinliang", ""], ["Langguth", "Johannes", ""]]}, {"id": "1801.09992", "submitter": "Vi Tran", "authors": "Phuong Hoai Ha, Vi Ngoc-Nha Tran, Ibrahim Umar, Philippas Tsigas,\n  Anders Gidenstam, Paul Renaud-Goud, Ivan Walulya, Aras Atalar", "title": "D2.1 Models for energy consumption of data structures and algorithms", "comments": "108 pages. arXiv admin note: text overlap with arXiv:1801.08761", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This deliverable reports our early energy models for data structures and\nalgorithms based on both micro-benchmarks and concurrent algorithms. It reports\nthe early results of Task 2.1 on investigating and modeling the trade-off\nbetween energy and performance in concurrent data structures and algorithms,\nwhich forms the basis for the whole work package 2 (WP2). The work has been\nconducted on the two main EXCESS platforms: (1) Intel platform with recent\nIntel multi-core CPUs and (2) Movidius embedded platform.\n", "versions": [{"version": "v1", "created": "Mon, 29 Jan 2018 06:52:47 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 08:55:56 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Ha", "Phuong Hoai", ""], ["Tran", "Vi Ngoc-Nha", ""], ["Umar", "Ibrahim", ""], ["Tsigas", "Philippas", ""], ["Gidenstam", "Anders", ""], ["Renaud-Goud", "Paul", ""], ["Walulya", "Ivan", ""], ["Atalar", "Aras", ""]]}, {"id": "1801.10022", "submitter": "Dahlia Malkhi", "authors": "Ittai Abraham, Guy Gueta, Dahlia Malkhi, Jean-Philippe Martin", "title": "Revisiting Fast Practical Byzantine Fault Tolerance: Thelma, Velma, and\n  Zelma", "comments": "arXiv admin note: text overlap with arXiv:1712.01367", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a previous note (arXiv:1712.01367 [cs.DC]) , we observed a safety\nviolation in Zyzzyva and a liveness violation in FaB. In this manuscript, we\nsketch fixes to both. The same view-change core is applied in the two schemes,\nand additionally, applied to combine them and create a single, enhanced scheme\nthat has the benefits of both approaches.\n", "versions": [{"version": "v1", "created": "Fri, 26 Jan 2018 20:32:06 GMT"}], "update_date": "2018-01-31", "authors_parsed": [["Abraham", "Ittai", ""], ["Gueta", "Guy", ""], ["Malkhi", "Dahlia", ""], ["Martin", "Jean-Philippe", ""]]}, {"id": "1801.10228", "submitter": "Christian Cachin", "authors": "Elli Androulaki, Artem Barger, Vita Bortnikov, Christian Cachin,\n  Konstantinos Christidis, Angelo De Caro, David Enyeart, Christopher Ferris,\n  Gennady Laventman, Yacov Manevich, Srinivasan Muralidharan, Chet Murthy, Binh\n  Nguyen, Manish Sethi, Gari Singh, Keith Smith, Alessandro Sorniotti,\n  Chrysoula Stathakopoulou, Marko Vukoli\\'c, Sharon Weed Cocco, Jason Yellick", "title": "Hyperledger Fabric: A Distributed Operating System for Permissioned\n  Blockchains", "comments": "Appears in proceedings of EuroSys 2018 conference", "journal-ref": null, "doi": "10.1145/3190508.3190538", "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fabric is a modular and extensible open-source system for deploying and\noperating permissioned blockchains and one of the Hyperledger projects hosted\nby the Linux Foundation (www.hyperledger.org).\n  Fabric is the first truly extensible blockchain system for running\ndistributed applications. It supports modular consensus protocols, which allows\nthe system to be tailored to particular use cases and trust models. Fabric is\nalso the first blockchain system that runs distributed applications written in\nstandard, general-purpose programming languages, without systemic dependency on\na native cryptocurrency. This stands in sharp contrast to existing blockchain\nplatforms that require \"smart-contracts\" to be written in domain-specific\nlanguages or rely on a cryptocurrency. Fabric realizes the permissioned model\nusing a portable notion of membership, which may be integrated with\nindustry-standard identity management. To support such flexibility, Fabric\nintroduces an entirely novel blockchain design and revamps the way blockchains\ncope with non-determinism, resource exhaustion, and performance attacks.\n  This paper describes Fabric, its architecture, the rationale behind various\ndesign decisions, its most prominent implementation aspects, as well as its\ndistributed application programming model. We further evaluate Fabric by\nimplementing and benchmarking a Bitcoin-inspired digital currency. We show that\nFabric achieves end-to-end throughput of more than 3500 transactions per second\nin certain popular deployment configurations, with sub-second latency, scaling\nwell to over 100 peers.\n", "versions": [{"version": "v1", "created": "Tue, 30 Jan 2018 21:22:06 GMT"}, {"version": "v2", "created": "Tue, 17 Apr 2018 09:34:27 GMT"}], "update_date": "2018-04-18", "authors_parsed": [["Androulaki", "Elli", ""], ["Barger", "Artem", ""], ["Bortnikov", "Vita", ""], ["Cachin", "Christian", ""], ["Christidis", "Konstantinos", ""], ["De Caro", "Angelo", ""], ["Enyeart", "David", ""], ["Ferris", "Christopher", ""], ["Laventman", "Gennady", ""], ["Manevich", "Yacov", ""], ["Muralidharan", "Srinivasan", ""], ["Murthy", "Chet", ""], ["Nguyen", "Binh", ""], ["Sethi", "Manish", ""], ["Singh", "Gari", ""], ["Smith", "Keith", ""], ["Sorniotti", "Alessandro", ""], ["Stathakopoulou", "Chrysoula", ""], ["Vukoli\u0107", "Marko", ""], ["Cocco", "Sharon Weed", ""], ["Yellick", "Jason", ""]]}, {"id": "1801.10263", "submitter": "Vi Tran", "authors": "Vi Ngoc-Nha Tran, Tommy Oines, Alexander Horsch, and Phuong Hoai Ha", "title": "REOH: Using Probabilistic Network for Runtime Energy Optimization of\n  Heterogeneous Systems", "comments": "21 pages, 6 figures, 4 tables", "journal-ref": null, "doi": null, "report-no": "IFI-UiT Technical Report 2018-81", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Significant efforts have been devoted to choosing the best configuration of a\ncomputing system to run an application energy efficiently. However, available\ntuning approaches mainly focus on homogeneous systems and are inextensible for\nheterogeneous systems which include several components (e.g., CPUs, GPUs) with\ndifferent architectures. This study proposes a holistic tuning approach called\nREOH using probabilistic network to predict the most energy-efficient\nconfiguration (i.e., which platform and its setting) of a heterogeneous system\nfor running a given application. Based on the computation and communication\npatterns from Berkeley dwarfs, we conduct experiments to devise the training\nset including 7074 data samples covering varying application patterns and\ncharacteristics. Validating the REOH approach on heterogeneous systems\nincluding CPUs and GPUs shows that the energy consumption by the REOH approach\nis close to the optimal energy consumption by the Brute Force approach while\nsaving 17% of sampling runs compared to the previous (homogeneous) approach\nusing probabilistic network. Based on the REOH approach, we develop an\nopen-source energy-optimizing runtime framework for selecting an energy\nefficient configuration of a heterogeneous system for a given application at\nruntime.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 01:05:34 GMT"}, {"version": "v2", "created": "Sun, 16 Sep 2018 11:54:32 GMT"}], "update_date": "2018-09-18", "authors_parsed": [["Tran", "Vi Ngoc-Nha", ""], ["Oines", "Tommy", ""], ["Horsch", "Alexander", ""], ["Ha", "Phuong Hoai", ""]]}, {"id": "1801.10277", "submitter": "Jeffrey Regier", "authors": "Jeffrey Regier, Kiran Pamnany, Keno Fischer, Andreas Noack, Maximilian\n  Lam, Jarrett Revels, Steve Howard, Ryan Giordano, David Schlegel, Jon\n  McAuliffe, Rollin Thomas, and Prabhat", "title": "Cataloging the Visible Universe through Bayesian Inference at Petascale", "comments": "accepted to IPDPS 2018", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Astronomical catalogs derived from wide-field imaging surveys are an\nimportant tool for understanding the Universe. We construct an astronomical\ncatalog from 55 TB of imaging data using Celeste, a Bayesian variational\ninference code written entirely in the high-productivity programming language\nJulia. Using over 1.3 million threads on 650,000 Intel Xeon Phi cores of the\nCori Phase II supercomputer, Celeste achieves a peak rate of 1.54 DP PFLOP/s.\nCeleste is able to jointly optimize parameters for 188M stars and galaxies,\nloading and processing 178 TB across 8192 nodes in 14.6 minutes. To achieve\nthis, Celeste exploits parallelism at multiple levels (cluster, node, and\nthread) and accelerates I/O through Cori's Burst Buffer. Julia's native\nperformance enables Celeste to employ high-level constructs without resorting\nto hand-written or generated low-level code (C/C++/Fortran), and yet achieve\npetascale performance.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 02:17:43 GMT"}], "update_date": "2018-02-01", "authors_parsed": [["Regier", "Jeffrey", ""], ["Pamnany", "Kiran", ""], ["Fischer", "Keno", ""], ["Noack", "Andreas", ""], ["Lam", "Maximilian", ""], ["Revels", "Jarrett", ""], ["Howard", "Steve", ""], ["Giordano", "Ryan", ""], ["Schlegel", "David", ""], ["McAuliffe", "Jon", ""], ["Thomas", "Rollin", ""], ["Prabhat", "", ""]]}, {"id": "1801.10292", "submitter": "Haewon Jeong", "authors": "Sanghamitra Dutta, Mohammad Fahim, Farzin Haddadpour, Haewon Jeong,\n  Viveck Cadambe, Pulkit Grover", "title": "On the Optimal Recovery Threshold of Coded Matrix Multiplication", "comments": "Extended version of the paper that appeared at Allerton 2017 (October\n  2017), including full proofs and further results. Submitted to IEEE\n  Transactions on Information Theory", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide novel coded computation strategies for distributed matrix-matrix\nproducts that outperform the recent \"Polynomial code\" constructions in recovery\nthreshold, i.e., the required number of successful workers. When $m$-th\nfraction of each matrix can be stored in each worker node, Polynomial codes\nrequire $m^2$ successful workers, while our MatDot codes only require $2m-1$\nsuccessful workers, albeit at a higher communication cost from each worker to\nthe fusion node. We also provide a systematic construction of MatDot codes.\nFurther, we propose \"PolyDot\" coding that interpolates between Polynomial codes\nand MatDot codes to trade off communication cost and recovery threshold.\nFinally, we demonstrate a coding technique for multiplying $n$ matrices ($n\n\\geq 3$) by applying MatDot and PolyDot coding ideas.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 04:13:09 GMT"}, {"version": "v2", "created": "Wed, 16 May 2018 17:04:14 GMT"}], "update_date": "2018-05-17", "authors_parsed": [["Dutta", "Sanghamitra", ""], ["Fahim", "Mohammad", ""], ["Haddadpour", "Farzin", ""], ["Jeong", "Haewon", ""], ["Cadambe", "Viveck", ""], ["Grover", "Pulkit", ""]]}, {"id": "1801.10323", "submitter": "Shantanu Sharma", "authors": "Shlomi Dolev, Peeyush Gupta, Yin Li, Sharad Mehrotra, Shantanu Sharma", "title": "Privacy-Preserving Secret Shared Computations using MapReduce", "comments": "IEEE Transactions on Dependable and Secure Computing, Accepted 01\n  Aug. 2019", "journal-ref": null, "doi": "10.1109/TDSC.2019.2933844", "report-no": null, "categories": "cs.DB cs.CR cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data outsourcing allows data owners to keep their data at \\emph{untrusted}\nclouds that do not ensure the privacy of data and/or computations. One useful\nframework for fault-tolerant data processing in a distributed fashion is\nMapReduce, which was developed for \\emph{trusted} private clouds. This paper\npresents algorithms for data outsourcing based on Shamir's secret-sharing\nscheme and for executing privacy-preserving SQL queries such as count,\nselection including range selection, projection, and join while using MapReduce\nas an underlying programming model. Our proposed algorithms prevent an\nadversary from knowing the database or the query while also preventing\noutput-size and access-pattern attacks. Interestingly, our algorithms do not\ninvolve the database owner, which only creates and distributes secret-shares\nonce, in answering any query, and hence, the database owner also cannot learn\nthe query. Logically and experimentally, we evaluate the efficiency of the\nalgorithms on the following parameters: (\\textit{i}) the number of\ncommunication rounds (between a user and a server), (\\textit{ii}) the total\namount of bit flow (between a user and a server), and (\\textit{iii}) the\ncomputational load at the user and the server.\\B\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 07:02:10 GMT"}, {"version": "v2", "created": "Tue, 26 Jun 2018 05:23:30 GMT"}, {"version": "v3", "created": "Tue, 6 Aug 2019 03:15:04 GMT"}], "update_date": "2019-08-07", "authors_parsed": [["Dolev", "Shlomi", ""], ["Gupta", "Peeyush", ""], ["Li", "Yin", ""], ["Mehrotra", "Sharad", ""], ["Sharma", "Shantanu", ""]]}, {"id": "1801.10556", "submitter": "Vi Tran", "authors": "Phuong Hoai Ha, Vi Ngoc-Nha Tran, Ibrahim Umar, Aras Atalar, Anders\n  Gidenstam, Paul Renaud-Goud, Philippas Tsigas, Ivan Walulya", "title": "D2.3 Power models, energy models and libraries for energy-efficient\n  concurrent data structures and algorithms", "comments": "142 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This deliverable reports the results of the power models, energy models and\nlibraries for energy-efficient concurrent data structures and algorithms as\navailable by project month 30 of Work Package 2 (WP2). It reports i) the latest\nresults of Task 2.2-2.4 on providing programming abstractions and libraries for\ndeveloping energy-efficient data structures and algorithms and ii) the improved\nresults of Task 2.1 on investigating and modeling the trade-off between energy\nand performance of concurrent data structures and algorithms. The work has been\nconducted on two main EXCESS platforms: Intel platforms with recent Intel\nmulticore CPUs and Movidius Myriad platforms.\n", "versions": [{"version": "v1", "created": "Wed, 31 Jan 2018 17:17:30 GMT"}, {"version": "v2", "created": "Thu, 8 Feb 2018 08:51:50 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Ha", "Phuong Hoai", ""], ["Tran", "Vi Ngoc-Nha", ""], ["Umar", "Ibrahim", ""], ["Atalar", "Aras", ""], ["Gidenstam", "Anders", ""], ["Renaud-Goud", "Paul", ""], ["Tsigas", "Philippas", ""], ["Walulya", "Ivan", ""]]}]