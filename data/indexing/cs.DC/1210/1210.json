[{"id": "1210.0056", "submitter": "Xiao Li", "authors": "Xiao Li, Anna Scaglione", "title": "Convergence and Applications of a Gossip-based Gauss-Newton Algorithm", "comments": "accepted by IEEE Transactions on Signal Processing", "journal-ref": null, "doi": "10.1109/TSP.2013.2276440", "report-no": null, "categories": "math.NA cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Gauss-Newton algorithm is a popular and efficient centralized method for\nsolving non-linear least squares problems. In this paper, we propose a\nmulti-agent distributed version of this algorithm, named Gossip-based\nGauss-Newton (GGN) algorithm, which can be applied in general problems with\nnon-convex objectives. Furthermore, we analyze and present sufficient\nconditions for its convergence and show numerically that the GGN algorithm\nachieves performance comparable to the centralized algorithm, with graceful\ndegradation in case of network failures. More importantly, the GGN algorithm\nprovides significant performance gains compared to other distributed first\norder methods.\n", "versions": [{"version": "v1", "created": "Fri, 28 Sep 2012 23:14:20 GMT"}, {"version": "v2", "created": "Tue, 25 Jun 2013 18:56:45 GMT"}], "update_date": "2016-08-24", "authors_parsed": [["Li", "Xiao", ""], ["Scaglione", "Anna", ""]]}, {"id": "1210.0187", "submitter": "Sandeep Gupta", "authors": "Sandeep Gupta", "title": "External Memory based Distributed Generation of Massive Scale Social\n  Networks on Small Clusters", "comments": "8 pages, 4 pics", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Small distributed systems are limited by their main memory to generate\nmassively large graphs. Trivial extension to current graph generators to\nutilize external memory leads to large amount of random I/O hence do not scale\nwith size. In this work we offer a technique to generate massive scale graphs\non small cluster of compute nodes with limited main memory. We develop several\ndistributed and external memory algorithms, primarily, shuffle, relabel,\nredistribute, and, compressed-sparse-row (csr) convert. The algorithms are\nimplemented in MPI/pthread model to help parallelize the operations across\nmulticores within each core. Using our scheme it is feasible to generate a\ngraph of size $2^{38}$ nodes (scale 38) using only 64 compute nodes. This can\nbe compared with the current scheme would require at least 8192 compute node,\nassuming 64GB of main memory.\n  Our work has broader implications for external memory graph libraries such as\nSTXXL and graph processing on SSD-based supercomputers such as Dash and Gordon\n[1][2].\n", "versions": [{"version": "v1", "created": "Sun, 30 Sep 2012 11:14:21 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Gupta", "Sandeep", ""]]}, {"id": "1210.0340", "submitter": "Andrzej Lingas", "authors": "Andrzej Lingas and Mia Persson", "title": "A fast parallel algorithm for minimum-cost small integral flows", "comments": "This is an improved version of a preliminary version which appeared\n  in proc. EUROPAR 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new approach to the minimum-cost integral flow problem for small\nvalues of the flow. It reduces the problem to the tests of simple multi-variate\npolynomials over a finite field of characteristic two for non-identity with\nzero. In effect, we show that a minimum-cost flow of value k in a network with\nn vertices, a sink and a source, integral edge capacities and positive integral\nedge costs polynomially bounded in n can be found by a randomized PRAM, with\nerrors of exponentially small probability in n, running in O(k\\log (kn)+\\log^2\n(kn)) time and using 2^{k}(kn)^{O(1)} processors. Thus, in particular, for the\nminimum-cost flow of value O(\\log n), we obtain an RNC^2 algorithm.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 10:25:50 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Lingas", "Andrzej", ""], ["Persson", "Mia", ""]]}, {"id": "1210.0477", "submitter": "Christian Schulz", "authors": "Peter Sanders and Christian Schulz", "title": "Think Locally, Act Globally: Perfectly Balanced Graph Partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel local improvement scheme for the perfectly balanced graph\npartitioning problem. This scheme encodes local searches that are not\nrestricted to a balance constraint into a model allowing us to find\ncombinations of these searches maintaining balance by applying a negative cycle\ndetection algorithm. We combine this technique with an algorithm to balance\nunbalanced solutions and integrate it into a parallel multi-level evolutionary\nalgorithm, KaFFPaE, to tackle the problem. Overall, we obtain a system that is\nfast on the one hand and on the other hand is able to improve or reproduce most\nof the best known perfectly balanced partitioning results ever reported in the\nliterature.\n", "versions": [{"version": "v1", "created": "Mon, 1 Oct 2012 17:30:47 GMT"}], "update_date": "2012-10-02", "authors_parsed": [["Sanders", "Peter", ""], ["Schulz", "Christian", ""]]}, {"id": "1210.0800", "submitter": "Jan Verschelde", "authors": "Jan Verschelde and Genady Yoffe", "title": "Orthogononalization on a general purpose graphics processing unit with\n  double double and quad double arithmetic", "comments": "replaced with revised version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Our problem is to accurately solve linear systems on a general purpose\ngraphics processing unit with double double and quad double arithmetic. The\nlinear systems originate from the application of Newton's method on polynomial\nsystems. Newton's method is applied as a corrector in a path following method,\nso the linear systems are solved in sequence and not simultaneously. One\nsolution path may require the solution of thousands of linear systems. In\nprevious work we reported good speedups with our implementation to evaluate and\ndifferentiate polynomial systems on the NVIDIA Tesla C2050. Although the cost\nof evaluation and differentiation often dominates the cost of linear system\nsolving in Newton's method, because of the limited bandwidth of the\ncommunication between CPU and GPU, we cannot afford to send the linear system\nto the CPU for solving during path tracking.\n  Because of large degrees, the Jacobian matrix may contain extreme values,\nrequiring extended precision, leading to a significant overhead. This overhead\nof multiprecision arithmetic is our main motivation to develop a massively\nparallel algorithm. To allow overdetermined linear systems we solve linear\nsystems in the least squares sense, computing the QR decomposition of the\nmatrix by the modified Gram-Schmidt algorithm. We describe our implementation\nof the modified Gram-Schmidt orthogonalization method for the NVIDIA Tesla\nC2050, using double double and quad double arithmetic. Our experimental results\nshow that the achieved speedups are sufficiently high to compensate for the\noverhead of one extra level of precision.\n", "versions": [{"version": "v1", "created": "Tue, 2 Oct 2012 15:08:27 GMT"}, {"version": "v2", "created": "Sun, 13 Jan 2013 21:42:07 GMT"}], "update_date": "2013-01-15", "authors_parsed": [["Verschelde", "Jan", ""], ["Yoffe", "Genady", ""]]}, {"id": "1210.1026", "submitter": "Quang-Hung Nguyen", "authors": "Nguyen Quang-Hung, Nam Thoai, Nguyen Thanh Son", "title": "Performance Constraint and Power-Aware Allocation For User Requests In\n  Virtual Computing Lab", "comments": "10 pages", "journal-ref": "Journal of Science and Technology, Special on International\n  Conference on Advanced Computing and Applications 49 4A (2011) 383-392", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Cloud computing is driven by economies of scale. A cloud system uses\nvirtualization technology to provide cloud resources (e.g. CPU, memory) to\nusers in form of virtual machines. Virtual machine (VM), which is a sandbox for\nuser application, fits well in the education environment to provide\ncomputational resources for teaching and research needs. In resource\nmanagement, they want to reduce costs in operations by reducing expensive cost\nof electronic bill of large-scale data center system. A lease-based model is\nsuitable for our Virtual Computing Lab, in which users ask resources on a lease\nof virtual machines. This paper proposes two host selection policies, named MAP\n(minimum of active physical hosts) and MAP-H2L, and four algorithms solving the\nlease scheduling problem. FF-MAP, FF-MAP-H2L algorithms meet a trade-off\nbetween the energy consumption and Quality of Service (e.g. performance). The\nsimulation on 7-day workload, which converted from LLNL Atlas log, showed the\nFF-MAP and FF-MAP-H2L algorithms reducing 7.24% and 7.42% energy consumption\nthan existing greedy mapping algorithm in the leasing scheduler Haizea. In\naddition, we introduce a ratio \\theta of consolidation in HalfPI-FF-MAP and\nPI-FF-MAP algorithms, in which \\theta is \\pi/2 and \\pi, and results on their\nsimulations show that energy consumption decreased by 34.87% and 63.12%\nrespectively.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 08:38:53 GMT"}, {"version": "v2", "created": "Wed, 26 Dec 2012 12:39:21 GMT"}], "update_date": "2012-12-27", "authors_parsed": [["Quang-Hung", "Nguyen", ""], ["Thoai", "Nam", ""], ["Son", "Nguyen Thanh", ""]]}, {"id": "1210.1157", "submitter": "James Hanlon", "authors": "James Hanlon, Simon J. Hollis and David May", "title": "Scalable data abstractions for distributed parallel computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The ability to express a program as a hierarchical composition of parts is an\nessential tool in managing the complexity of software and a key abstraction\nthis provides is to separate the representation of data from the computation.\nMany current parallel programming models use a shared memory model to provide\ndata abstraction but this doesn't scale well with large numbers of cores due to\nnon-determinism and access latency. This paper proposes a simple programming\nmodel that allows scalable parallel programs to be expressed with distributed\nrepresentations of data and it provides the programmer with the flexibility to\nemploy shared or distributed styles of data-parallelism where applicable. It is\ncapable of an efficient implementation, and with the provision of a small set\nof primitive capabilities in the hardware, it can be compiled to operate\ndirectly on the hardware, in the same way stack-based allocation operates for\nsubroutines in sequential machines.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 15:57:01 GMT"}], "update_date": "2012-10-04", "authors_parsed": [["Hanlon", "James", ""], ["Hollis", "Simon J.", ""], ["May", "David", ""]]}, {"id": "1210.1158", "submitter": "James Hanlon", "authors": "James Hanlon", "title": "Emulating a large memory with a collection of small ones", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sequential computation is well understood but does not scale well with\ncurrent technology. Within the next decade, systems will contain large numbers\nof processors with potentially thousands of processors per chip. Despite this,\nmany computational problems exhibit little or no parallelism and many existing\nformulations are sequential. It is therefore essential that highly-parallel\narchitectures can support sequential computation by emulating large memories\nwith collections of smaller ones, thus supporting efficient execution of\nsequential programs or sequential components of parallel programs.\n  This paper demonstrates that a realistic parallel architecture with scalable\nlow-latency communications can execute large-memory sequential programs with a\nfactor of only 2 to 3 slowdown, when compared to a conventional sequential\narchitecture. This overhead seems an acceptable price to pay to be able to\nswitch between executing highly-parallel programs and sequential programs with\nlarge memory requirements. Efficient emulation of large memories could\ntherefore facilitate a transition from sequential machines by allowing existing\nprograms to be compiled directly to a highly-parallel architecture and then for\ntheir performance to be improved by exploiting parallelism in memory accesses\nand computation.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 15:57:49 GMT"}, {"version": "v2", "created": "Wed, 25 Feb 2015 14:51:10 GMT"}, {"version": "v3", "created": "Sat, 14 Nov 2015 15:02:29 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Hanlon", "James", ""]]}, {"id": "1210.1185", "submitter": "Bita Azimdoost", "authors": "Bita Azimdoost, Cedric Westphal, Hamid R. Sadjadpour", "title": "Scaling Laws of the Throughput Capacity and Latency in\n  Information-Centric Networks", "comments": "12 pages, 6 figures, This is the journal version of the paper\n  presented in ITC25 under the name \"On the throughput capacity of\n  information-centric networks\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Wireless information-centric networks consider storage as one of the network\nprimitives, and propose to cache data within the network in order to improve\nlatency and reduce bandwidth consumption. We study the throughput capacity and\ndelay in an information-centric network when the data cached in each node has a\nlimited lifetime. The results show that with some fixed request and cache\nexpiration rates, the order of the data access time does not change with\nnetwork growth, and the maximum throughput order is inversely proportional to\nthe square root and logarithm of the network size $n$ in cases of grid and\nrandom networks, respectively. Comparing these values with the corresponding\nthroughput and latency with no cache capability (throughput inversely\nproportional to the network size, and latency of order $\\sqrt{n}$ and\n$\\sqrt{\\frac{n}{\\log n}}$ in grid and random networks, respectively), we can\nactually quantify the asymptotic advantage of caching. Moreover, we compare\nthese scaling laws for different content discovery mechanisms and illustrate\nthat not much gain is lost when a simple path search is used.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 18:09:11 GMT"}, {"version": "v2", "created": "Tue, 16 Oct 2012 21:59:47 GMT"}, {"version": "v3", "created": "Thu, 30 Apr 2015 05:19:23 GMT"}], "update_date": "2015-05-01", "authors_parsed": [["Azimdoost", "Bita", ""], ["Westphal", "Cedric", ""], ["Sadjadpour", "Hamid R.", ""]]}, {"id": "1210.1193", "submitter": "Bernhard Haeupler", "authors": "Bernhard Haeupler", "title": "Simple, Fast and Deterministic Gossip and Rumor Spreading", "comments": null, "journal-ref": null, "doi": "10.1137/1.9781611973105.51", "report-no": null, "categories": "cs.DS cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study gossip algorithms for the rumor spreading problem which asks each\nnode to deliver a rumor to all nodes in an unknown network. Gossip algorithms\nallow nodes only to call one neighbor per round and have recently attracted\nattention as message efficient, simple and robust solutions to the rumor\nspreading problem.\n  Recently, non-uniform random gossip schemes were devised to allow efficient\nrumor spreading in networks with bottlenecks. In particular, [Censor-Hillel et\nal., STOC'12] gave an O(log^3 n) algorithm to solve the 1-local broadcast\nproblem in which each node wants to exchange rumors locally with its\n1-neighborhood. By repeatedly applying this protocol one can solve the global\nrumor spreading quickly for all networks with small diameter, independently of\nthe conductance.\n  This and all prior gossip algorithms for the rumor spreading problem have\nbeen inherently randomized in their design and analysis. This resulted in a\nparallel research direction trying to reduce and determine the amount of\nrandomness needed for efficient rumor spreading. This has been done via lower\nbounds for restricted models and by designing gossip algorithms with a reduced\nneed for randomness. The general intuition and consensus of these results has\nbeen that randomization plays a important role in effectively spreading rumors.\n  In this paper we improves over this state of the art in several ways by\npresenting a deterministic gossip algorithm that solves the the k-local\nbroadcast problem in 2(k+log n)log n rounds. Besides being the first efficient\ndeterministic solution to the rumor spreading problem this algorithm is\ninteresting in many aspects: It is simpler, more natural, more robust and\nfaster than its randomized pendant and guarantees success with certainty\ninstead of with high probability. Its analysis is furthermore simple,\nself-contained and fundamentally different from prior works.\n", "versions": [{"version": "v1", "created": "Wed, 3 Oct 2012 19:17:42 GMT"}, {"version": "v2", "created": "Sat, 5 Apr 2014 02:26:18 GMT"}], "update_date": "2014-04-08", "authors_parsed": [["Haeupler", "Bernhard", ""]]}, {"id": "1210.1593", "submitter": "Lukasz Swierczewski", "authors": "Lukasz Swierczewski", "title": "The Distributed Computing Model Based on The Capabilities of The\n  Internet", "comments": "6 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Paper describes the theoretical and practical aspects of the proposed model\nthat uses distributed computing to a global network of Internet communication.\nDistributed computing are widely used in modern solutions such as research,\nwhere the requirement is very high processing power, which can not be placed in\none centralized point. The presented solution is based on open technologies and\ncomputers to perform calculations provided mainly by Internet users who are\nvolunteers.\n", "versions": [{"version": "v1", "created": "Thu, 4 Oct 2012 21:01:35 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Swierczewski", "Lukasz", ""]]}, {"id": "1210.1686", "submitter": "Abdulrahman Alazmi Mr.", "authors": "Mohammad H. Al Shayeji, AbdulRahman R. Al-Azmi, AbdulAziz R. Al-Azmi\n  and M. D. Samrajesh", "title": "Analysis and Enhancements of Leader Elections algorithms in Mobile Ad\n  Hoc Networks", "comments": "5 Pages, 4 Figures, 1 Table, 2011 Second International Conference on\n  Advances in Information and Communication Technologies; ACEEE International\n  Journal on Network Security, Vol. 02, No. 04, Oct 2011", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Mobile Ad Hoc networks (MANET), distinct from traditional distributed\nsystems, are dynamic and self-organizing networks. MANET requires a leader to\ncoordinate and organize tasks. The challenge is to have the right election\nalgorithm that chooses the right leader based on various factors in MANET. In\nthis paper, we analyze four leader election algorithms used in mobile Ad Hoc\nNetworks. Factors considered in our analysis are time complexity, message\ncomplexity, assumptions considered, fault tolerance and timing model. Our\nproposed enhancements include recovered nodes inquiring about the current\nleader and the use of candidates during election to reduce the overhead of\nstarting a new election session. In addition, better election criteria specific\nto MANET, such as battery life and signal strength, are proposed. Our\nevaluation and discussion shows that the proposed enhancements are effective.\nThe analysis can be used as a reference for system designers in choosing the\nright election algorithm for MANET.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2012 09:39:48 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Shayeji", "Mohammad H. Al", ""], ["Al-Azmi", "AbdulRahman R.", ""], ["Al-Azmi", "AbdulAziz R.", ""], ["Samrajesh", "M. D.", ""]]}, {"id": "1210.1745", "submitter": "Golnoosh Keshani", "authors": "Arash Ghorbannia Delavar, Golnoosh Keshani", "title": "Providing an Object Allocation Algorithm in Distributed Databases Using\n  Efficient Factors", "comments": "IJCSI International Journal of Computer Science Issues, Vol. 9, Issue\n  4, No 3, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data replication is a common method used to improve the performance of data\naccess in distributed database systems. In this paper, we present an object\nreplication algorithm in distributed database systems (ORAD). We optimize the\ncreated replicated data in distributed database systems by using activity\nfunctions of previous algorithms, changing them with new technical ways and\napplying ORAD algorithm for making decisions. We propose ORAD algorithm with\nusing effective factors and observe its results in several valid situations.\nOur objective is to propose an optimum method that replies read and write\nrequests with less cost in distributed database systems. Finally, we implement\nORAD and ADRW algorithms in a PC based network system and demonstrate that ORAD\nalgorithm is superior to ADRW algorithm in the field of average request\nservicing cost.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2012 13:05:29 GMT"}], "update_date": "2012-10-08", "authors_parsed": [["Delavar", "Arash Ghorbannia", ""], ["Keshani", "Golnoosh", ""]]}, {"id": "1210.1804", "submitter": "Tomasz Jurdzinski", "authors": "Tomasz Jurdzinski and Dariusz R. Kowalski and Grzegorz Stachowiak", "title": "Distributed Deterministic Broadcasting in Wireless Networks of Weak\n  Devices under the SINR Model", "comments": "33 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we initiate a study of distributed deterministic broadcasting\nin ad-hoc wireless networks with uniform transmission powers under the SINR\nmodel. We design algorithms in two settings: with and without local knowledge\nabout immediate neighborhood. In the former setting, our solution has almost\noptimal O(Dlog2 n) time cost, where n is the size of a network, D is the\neccentricity of the network and {1,...,N} is the set of possible node IDs. In\nthe latter case, we prove an Omega(n log N) lower bound and develop an\nalgorithm matching this formula, where n is the number of network nodes. As one\nof the conclusions, we derive that the inherited cost of broadcasting\ntechniques in wireless networks is much smaller, by factor around\nmin{n/D,Delta}, than the cost of learning the immediate neighborhood. Finally,\nwe develop a O(D Delta log2 N) algorithm for the setting without local\nknowledge, where Delta is the upper bound on the degree of the communication\ngraph of a network. This algorithm is close to a lower bound Omega(D Delta).\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2012 16:21:03 GMT"}, {"version": "v2", "created": "Sun, 17 Feb 2013 11:36:42 GMT"}], "update_date": "2013-02-19", "authors_parsed": [["Jurdzinski", "Tomasz", ""], ["Kowalski", "Dariusz R.", ""], ["Stachowiak", "Grzegorz", ""]]}, {"id": "1210.2047", "submitter": "Miranda Zhang", "authors": "Miranda Zhang, Rajiv Ranjan, Surya Nepal, Michael Menzel, Armin Haller", "title": "A Declarative Recommender System for Cloud Infrastructure Services\n  Selection", "comments": "Supplement document to the conference paper accepted at the 9th\n  International Conference on Economics of Grids, Clouds, Systems, and\n  Services, Berlin, Germany, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The cloud infrastructure services landscape advances steadily leaving users\nin the agony of choice...\n", "versions": [{"version": "v1", "created": "Sun, 7 Oct 2012 12:16:09 GMT"}, {"version": "v2", "created": "Thu, 29 Nov 2012 09:54:30 GMT"}], "update_date": "2012-11-30", "authors_parsed": [["Zhang", "Miranda", ""], ["Ranjan", "Rajiv", ""], ["Nepal", "Surya", ""], ["Menzel", "Michael", ""], ["Haller", "Armin", ""]]}, {"id": "1210.2276", "submitter": "Igor Melatti", "authors": "Vadim Alimguzhin, Federico Mari, Igor Melatti, Ivano Salvo, Enrico\n  Tronci", "title": "A Map-Reduce Parallel Approach to Automatic Synthesis of Control\n  Software", "comments": "To be submitted to TACAS 2013. arXiv admin note: substantial text\n  overlap with arXiv:1207.4474, arXiv:1207.4098", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many Control Systems are indeed Software Based Control Systems, i.e. control\nsystems whose controller consists of control software running on a\nmicrocontroller device. This motivates investigation on Formal Model Based\nDesign approaches for automatic synthesis of control software.\n  Available algorithms and tools (e.g., QKS) may require weeks or even months\nof computation to synthesize control software for large-size systems. This\nmotivates search for parallel algorithms for control software synthesis.\n  In this paper, we present a Map-Reduce style parallel algorithm for control\nsoftware synthesis when the controlled system (plant) is modeled as discrete\ntime linear hybrid system. Furthermore we present an MPI-based implementation\nPQKS of our algorithm. To the best of our knowledge, this is the first parallel\napproach for control software synthesis.\n  We experimentally show effectiveness of PQKS on two classical control\nsynthesis problems: the inverted pendulum and the multi-input buck DC/DC\nconverter. Experiments show that PQKS efficiency is above 65%. As an example,\nPQKS requires about 16 hours to complete the synthesis of control software for\nthe pendulum on a cluster with 60 processors, instead of the 25 days needed by\nthe sequential algorithm in QKS.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 13:38:55 GMT"}, {"version": "v2", "created": "Thu, 11 Oct 2012 08:42:09 GMT"}, {"version": "v3", "created": "Fri, 22 Feb 2013 13:53:27 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Alimguzhin", "Vadim", ""], ["Mari", "Federico", ""], ["Melatti", "Igor", ""], ["Salvo", "Ivano", ""], ["Tronci", "Enrico", ""]]}, {"id": "1210.2289", "submitter": "Annie I-An Chen", "authors": "Annie I. Chen and Asuman Ozdaglar", "title": "A Fast Distributed Proximal-Gradient Method", "comments": "10 pages (including 2-page appendix); 1 figure; submitted to Allerton\n  2012 on July 10, 2012; accepted by Allerton 2012, October 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a distributed proximal-gradient method for optimizing the average\nof convex functions, each of which is the private local objective of an agent\nin a network with time-varying topology. The local objectives have distinct\ndifferentiable components, but they share a common nondifferentiable component,\nwhich has a favorable structure suitable for effective computation of the\nproximal operator. In our method, each agent iteratively updates its estimate\nof the global minimum by optimizing its local objective function, and\nexchanging estimates with others via communication in the network. Using\nNesterov-type acceleration techniques and multiple communication steps per\niteration, we show that this method converges at the rate 1/k (where k is the\nnumber of communication rounds between the agents), which is faster than the\nconvergence rate of the existing distributed methods for solving this problem.\nThe superior convergence rate of our method is also verified by numerical\nexperiments.\n", "versions": [{"version": "v1", "created": "Mon, 8 Oct 2012 14:14:13 GMT"}], "update_date": "2012-10-09", "authors_parsed": [["Chen", "Annie I.", ""], ["Ozdaglar", "Asuman", ""]]}, {"id": "1210.2401", "submitter": "Biao Xu", "authors": "Biao Xu, Ruair\\'i de Fr\\'ein, Eric Robson and M\\'iche\\'al \\'O Foghl\\'u", "title": "Distributed Formal Concept Analysis Algorithms Based on an Iterative\n  MapReduce Framework", "comments": "17 pages, ICFCA 201, Formal Concept Analysis 2012", "journal-ref": null, "doi": "10.1007/978-3-642-29892-9_26", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While many existing formal concept analysis algorithms are efficient, they\nare typically unsuitable for distributed implementation. Taking the MapReduce\n(MR) framework as our inspiration we introduce a distributed approach for\nperforming formal concept mining. Our method has its novelty in that we use a\nlight-weight MapReduce runtime called Twister which is better suited to\niterative algorithms than recent distributed approaches. First, we describe the\ntheoretical foundations underpinning our distributed formal concept analysis\napproach. Second, we provide a representative exemplar of how a classic\ncentralized algorithm can be implemented in a distributed fashion using our\nmethodology: we modify Ganter's classic algorithm by introducing a family of\nMR* algorithms, namely MRGanter and MRGanter+ where the prefix denotes the\nalgorithm's lineage. To evaluate the factors that impact distributed algorithm\nperformance, we compare our MR* algorithms with the state-of-the-art.\nExperiments conducted on real datasets demonstrate that MRGanter+ is efficient,\nscalable and an appealing algorithm for distributed problems.\n", "versions": [{"version": "v1", "created": "Fri, 5 Oct 2012 10:28:24 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Xu", "Biao", ""], ["de Fr\u00e9in", "Ruair\u00ed", ""], ["Robson", "Eric", ""], ["Foghl\u00fa", "M\u00edche\u00e1l \u00d3", ""]]}, {"id": "1210.2536", "submitter": "Jiajia Li", "authors": "Jiajia Li, Xiuxia Zhang, Guangming Tan, Mingyu Chen", "title": "SMAT: An Input Adaptive Sparse Matrix-Vector Multiplication Auto-Tuner", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Sparse matrix vector multiplication (SpMV) is an important kernel in\nscientific and engineering applications. The previous optimizations are sparse\nmatrix format specific and expose the choice of the best format to application\nprogrammers. In this work we develop an auto-tuning framework to bridge gap\nbetween the specific optimized kernels and their general-purpose use. We\npropose an SpMV auto-tuner (SMAT) that provides an unified interface based on\ncompressed sparse row (CSR) to programmers by implicitly choosing the best\nformat and the fastest implementation of any input sparse matrix in runtime.\nSMAT leverage a data mining model, which is formulated based on a set of\nperformance parameters extracted from 2373 matrices in UF sparse matrix\ncollection, to fast search the best combination. The experiments show that SMAT\nachieves the maximum performance of 75 GFLOP/s in single-precision and 33\nGFLOP/s in double-precision on Intel, and 41 GFLOP/s in single-precision and 34\nGFLOP/s in double-precision on AMD. Compared with the sparse functions in MKL\nlibrary, SMAT runs faster by more than 3 times.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 09:19:43 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Li", "Jiajia", ""], ["Zhang", "Xiuxia", ""], ["Tan", "Guangming", ""], ["Chen", "Mingyu", ""]]}, {"id": "1210.2580", "submitter": "Loris Marchal", "authors": "Loris Marchal, Oliver Sinnen and Fr\\'ed\\'eric Vivien", "title": "Scheduling tree-shaped task graphs to minimize memory and makespan", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the execution of tree-shaped task graphs using\nmultiple processors. Each edge of such a tree represents a large IO file. A\ntask can only be executed if all input and output files fit into memory, and a\nfile can only be removed from memory after it has been consumed. Such trees\narise, for instance, in the multifrontal method of sparse matrix factorization.\nThe maximum amount of memory needed depends on the execution order of the\ntasks. With one processor the objective of the tree traversal is to minimize\nthe required memory. This problem was well studied and optimal polynomial\nalgorithms were proposed.\n  Here, we extend the problem by considering multiple processors, which is of\nobvious interest in the application area of matrix factorization. With the\nmultiple processors comes the additional objective to minimize the time needed\nto traverse the tree, i.e., to minimize the makespan. Not surprisingly, this\nproblem proves to be much harder than the sequential one. We study the\ncomputational complexity of this problem and provide an inapproximability\nresult even for unit weight trees. Several heuristics are proposed, each with a\ndifferent optimization focus, and they are analyzed in an extensive\nexperimental evaluation using realistic trees.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 12:16:36 GMT"}], "update_date": "2012-10-10", "authors_parsed": [["Marchal", "Loris", ""], ["Sinnen", "Oliver", ""], ["Vivien", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1210.2857", "submitter": "Nasrin Jaberi", "authors": "Nasrin Jaberi", "title": "An Introduction on Dependency Between Hardware Life Time Components and\n  Dynamic Voltage Scaling", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main open question is how to calculate the effect of switching between\nfrequencies in DVFS technique on the lifetime of the cluster components. As\nmoving from one frequency to another in DVFS technique always gives a shock to\nthe component and consequently decreases the component lifetime, therefore, it\nbecomes interesting to answer the question of how fast a component can change\nits speed in order to decrease power without changing its lifetime.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 10:07:59 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Jaberi", "Nasrin", ""]]}, {"id": "1210.2967", "submitter": "Mario Goldenbaum", "authors": "Mario Goldenbaum and S{\\l}awomir Sta\\'nczak", "title": "Robust Analog Function Computation via Wireless Multiple-Access Channels", "comments": "30 pages (onecolumn), 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.MA math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Various wireless sensor network applications involve the computation of a\npre-defined function of the measurements without the need for reconstructing\neach individual sensor reading. Widely-considered examples of such functions\ninclude the arithmetic mean and the maximum value. Standard approaches to the\ncomputation problem separate computation from communication: quantized sensor\nreadings are transmitted interference-free to a fusion center that reconstructs\neach sensor reading and subsequently computes the sought function value. Such\nseparation-based computation schemes are generally highly inefficient as a\ncomplete reconstruction of individual sensor readings is not necessary for the\nfusion center to compute a function of them. In particular, if the mathematical\nstructure of the wireless channel is suitably matched (in some sense) to the\nfunction, then channel collisions induced by concurrent transmissions of\ndifferent nodes can be beneficially exploited for computation purposes.\nTherefore, in this paper a practically relevant analog computation scheme is\nproposed that allows for an efficient estimate of linear and nonlinear\nfunctions over the wireless multiple-access channel. After analyzing the\nasymptotic properties of the estimation error, numerical simulations are\npresented to show the potential for huge performance gains when compared with\ntime-division multiple-access based computation schemes.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 16:14:48 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Goldenbaum", "Mario", ""], ["Sta\u0144czak", "S\u0142awomir", ""]]}, {"id": "1210.3012", "submitter": "Yanpei Liu", "authors": "Gauri Joshi, Yanpei Liu, Emina Soljanin", "title": "Coding for Fast Content Download", "comments": "8 pages, 6 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the fundamental trade-off between storage and content download time.\nWe show that the download time can be significantly reduced by dividing the\ncontent into chunks, encoding it to add redundancy and then distributing it\nacross multiple disks. We determine the download time for two content access\nmodels - the fountain and fork-join models that involve simultaneous content\naccess, and individual access from enqueued user requests respectively. For the\nfountain model we explicitly characterize the download time, while in the\nfork-join model we derive the upper and lower bounds. Our results show that\ncoding reduces download time, through the diversity of distributing the data\nacross more disks, even for the total storage used.\n", "versions": [{"version": "v1", "created": "Tue, 9 Oct 2012 00:22:06 GMT"}], "update_date": "2012-10-11", "authors_parsed": [["Joshi", "Gauri", ""], ["Liu", "Yanpei", ""], ["Soljanin", "Emina", ""]]}, {"id": "1210.3061", "submitter": "Elad Michael Schiller (PhD)", "authors": "Pierre Leone and Elad M. Schiller", "title": "Self-Stabilizing TDMA Algorithms for Dynamic Wireless Ad-hoc Networks", "comments": null, "journal-ref": null, "doi": "10.1155/2013/639761", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In dynamic wireless ad-hoc networks (DynWANs), autonomous computing devices\nset up a network for the communication needs of the moment. These networks\nrequire the implementation of a medium access control (MAC) layer. We consider\nMAC protocols for DynWANs that need to be autonomous and robust as well as have\nhigh bandwidth utilization, high predictability degree of bandwidth allocation,\nand low communication delay in the presence of frequent topological changes to\nthe communication network. Recent studies have shown that existing\nimplementations cannot guarantee the necessary satisfaction of these timing\nrequirements. We propose a self-stabilizing MAC algorithm for DynWANs that\nguarantees a short convergence period, and by that, it can facilitate the\nsatisfaction of severe timing requirements, such as the above. Besides the\ncontribution in the algorithmic front of research, we expect that our proposal\ncan enable quicker adoption by practitioners and faster deployment of DynWANs\nthat are subject changes in the network topology.\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 21:02:09 GMT"}, {"version": "v2", "created": "Thu, 24 Jan 2013 23:33:59 GMT"}], "update_date": "2013-08-30", "authors_parsed": [["Leone", "Pierre", ""], ["Schiller", "Elad M.", ""]]}, {"id": "1210.3077", "submitter": "Miranda Zhang", "authors": "Miranda Zhang, Rajiv Ranjan, Armin Haller, Dimitrios Georgakopoulos,\n  Peter Strazdins", "title": "Investigating Decision Support Techniques for Automating Cloud Service\n  Selection", "comments": "Accepted by IEEE Cloudcom 2012 - PhD consortium track", "journal-ref": null, "doi": "10.1109/CloudCom.2012.6427501", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The compass of Cloud infrastructure services advances steadily leaving users\nin the agony of choice. To be able to select the best mix of service offering\nfrom an abundance of possibilities, users must consider complex dependencies\nand heterogeneous sets of criteria. Therefore, we present a PhD thesis proposal\non investigating an intelligent decision support system for selecting Cloud\nbased infrastructure services (e.g. storage, network, CPU).\n", "versions": [{"version": "v1", "created": "Wed, 10 Oct 2012 22:12:26 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Zhang", "Miranda", ""], ["Ranjan", "Rajiv", ""], ["Haller", "Armin", ""], ["Georgakopoulos", "Dimitrios", ""], ["Strazdins", "Peter", ""]]}, {"id": "1210.3171", "submitter": "Hadassa Daltrophe", "authors": "Hadassa Daltrophe, Shlomi Dolev and Zvi Lotker", "title": "Data Interpolation: An Efficient Sampling Alternative for Big Data\n  Aggregation", "comments": "The Lynne and William Frankel Center for Computer Science, Ben-Gurion\n  University of the Negev, 2012 #13-01", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Given a large set of measurement sensor data, in order to identify a simple\nfunction that captures the essence of the data gathered by the sensors, we\nsuggest representing the data by (spatial) functions, in particular by\npolynomials. Given a (sampled) set of values, we interpolate the datapoints to\ndefine a polynomial that would represent the data. The interpolation is\nchallenging, since in practice the data can be noisy and even Byzantine, where\nthe Byzantine data represents an adversarial value that is not limited to being\nclose to the correct measured data. We present two solutions, one that extends\nthe Welch-Berlekamp technique in the case of multidimensional data, and copes\nwith discrete noise and Byzantine data, and the other based on Arora and Khot\ntechniques, extending them in the case of multidimensional noisy and Byzantine\ndata.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 10:25:44 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Daltrophe", "Hadassa", ""], ["Dolev", "Shlomi", ""], ["Lotker", "Zvi", ""]]}, {"id": "1210.3265", "submitter": "Martin Gebser", "authors": "Martin Gebser, Benjamin Kaufmann, Torsten Schaub", "title": "Multi-threaded ASP Solving with clasp", "comments": "19 pages, 5 figures, to appear in Theory and Practice of Logic\n  Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the new multi-threaded version of the state-of-the-art answer set\nsolver clasp. We detail its component and communication architecture and\nillustrate how they support the principal functionalities of clasp. Also, we\nprovide some insights into the data representation used for different\nconstraint types handled by clasp. All this is accompanied by an extensive\nexperimental analysis of the major features related to multi-threading in\nclasp.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 15:06:28 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Gebser", "Martin", ""], ["Kaufmann", "Benjamin", ""], ["Schaub", "Torsten", ""]]}, {"id": "1210.3271", "submitter": "Daniel S. Katz", "authors": "Jarek Nabrzyski and Krzysztof Kurowski and Daniel S. Katz and Andre\n  Merzky", "title": "Grid Computing: The Next Decade -- Report and Summary", "comments": "17 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  The evolution of the global scientific cyberinfrastructure (CI) has, over the\nlast 10+ years, led to a large diversity of CI instances. While specialized,\ncompeting and alternative CI building blocks are inherent to a healthy\necosystem, it also becomes apparent that the increasing degree of fragmentation\nis hindering interoperation, and thus limiting collaboration, which is\nessential for modern science communities often spanning international groups\nand multiple disciplines (but even 'small sciences', with smaller and localized\ncommunities, are often embedded into the larger scientific ecosystem, and are\nincreasingly dependent on the availability of CI.)\n  There are different reasons why fragmentation occurs, on technical and social\nlevel. But also, it is apparent that the current funding model for creating CI\ncomponents largely fails to aid the transition from research to production, by\nmixing CS research and IT engineering challenges into the same funding\nstrategies.\n  The 10th anniversary of the EU funded project 'Grid Lab' (which was an early\nand ambitious attempt on providing a consolidated and science oriented\ncyberinfrastructure software stack to a specific science community) was taken\nas an opportunity to invite international leaders and early stage researchers\nin grid computing and e-Science from Europe, America and Asia, and, together\nwith representatives of the EU and US funding agencies, to discuss the\nfundamental aspects of CI evolution, and to contemplate the options for a more\ncoherent, more coordinated approach to the global evolution of CI.\n  This open document represents the results of that workshop - including a\ndraft of a mission statement and a proposal for a blueprint process - to inform\nthe wider community as well as to encourage external experts to provide their\nfeedback and comments.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 15:27:21 GMT"}], "update_date": "2012-10-12", "authors_parsed": [["Nabrzyski", "Jarek", ""], ["Kurowski", "Krzysztof", ""], ["Katz", "Daniel S.", ""], ["Merzky", "Andre", ""]]}, {"id": "1210.3277", "submitter": "Arnaud Casteigts", "authors": "Arnaud Casteigts, Paola Flocchini, Bernard Mans, Nicola Santoro", "title": "Shortest, Fastest, and Foremost Broadcast in Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly dynamic networks rarely offer end-to-end connectivity at a given time.\nYet, connectivity in these networks can be established over time and space,\nbased on temporal analogues of multi-hop paths (also called {\\em journeys}).\nAttempting to optimize the selection of the journeys in these networks\nnaturally leads to the study of three cases: shortest (minimum hop), fastest\n(minimum duration), and foremost (earliest arrival) journeys. Efficient\ncentralized algorithms exists to compute all cases, when the full knowledge of\nthe network evolution is given.\n  In this paper, we study the {\\em distributed} counterparts of these problems,\ni.e. shortest, fastest, and foremost broadcast with termination detection\n(TDB), with minimal knowledge on the topology.\n  We show that the feasibility of each of these problems requires distinct\nfeatures on the evolution, through identifying three classes of dynamic graphs\nwherein the problems become gradually feasible: graphs in which the\nre-appearance of edges is {\\em recurrent} (class R), {\\em bounded-recurrent}\n(B), or {\\em periodic} (P), together with specific knowledge that are\nrespectively $n$ (the number of nodes), $\\Delta$ (a bound on the recurrence\ntime), and $p$ (the period). In these classes it is not required that all pairs\nof nodes get in contact -- only that the overall {\\em footprint} of the graph\nis connected over time.\n  Our results, together with the strict inclusion between $P$, $B$, and $R$,\nimplies a feasibility order among the three variants of the problem, i.e.\nTDB[foremost] requires weaker assumptions on the topology dynamics than\nTDB[shortest], which itself requires less than TDB[fastest]. Reversely, these\ndifferences in feasibility imply that the computational powers of $R_n$,\n$B_\\Delta$, and $P_p$ also form a strict hierarchy.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 15:51:25 GMT"}, {"version": "v2", "created": "Mon, 17 Jun 2013 21:21:18 GMT"}, {"version": "v3", "created": "Thu, 20 Jun 2013 10:02:14 GMT"}, {"version": "v4", "created": "Fri, 8 Nov 2013 06:58:53 GMT"}, {"version": "v5", "created": "Wed, 27 Aug 2014 12:58:54 GMT"}], "update_date": "2014-08-28", "authors_parsed": [["Casteigts", "Arnaud", ""], ["Flocchini", "Paola", ""], ["Mans", "Bernard", ""], ["Santoro", "Nicola", ""]]}, {"id": "1210.3283", "submitter": "George Athanasiou", "authors": "Pradeep Chathuranga Weeraddana, George Athanasiou, Martin Jakobsson,\n  Carlo Fischione, John S. Baras", "title": "On the Privacy of Optimization Approaches", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Ensuring privacy of sensitive data is essential in many contexts, such as\nhealthcare data, banks, e-commerce, wireless sensor networks, and social\nnetworks. It is common that different entities coordinate or want to rely on a\nthird party to solve a specific problem. At the same time, no entity wants to\npublish its problem data during the solution procedure unless there is a\nprivacy guarantee. Unlike cryptography and differential privacy based\napproaches, the methods based on optimization lack a quantification of the\nprivacy they can provide. The main contribution of this paper is to provide a\nmechanism to quantify the privacy of a broad class of optimization approaches.\nIn particular, we formally define a one-to-many relation, which relates a given\nadversarial observed message to an uncertainty set of the problem data. This\nrelation quantifies the potential ambiguity on problem data due to the employed\noptimization approaches. The privacy definitions are then formalized based on\nthe uncertainty sets. The properties of the proposed privacy measure is\nanalyzed. The key ideas are illustrated with examples, including localization,\naverage consensus, among others.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 16:10:03 GMT"}, {"version": "v2", "created": "Wed, 8 May 2013 09:33:29 GMT"}, {"version": "v3", "created": "Fri, 13 Jun 2014 06:30:40 GMT"}], "update_date": "2014-06-16", "authors_parsed": [["Weeraddana", "Pradeep Chathuranga", ""], ["Athanasiou", "George", ""], ["Jakobsson", "Martin", ""], ["Fischione", "Carlo", ""], ["Baras", "John S.", ""]]}, {"id": "1210.3292", "submitter": "Yasaman Keshtkarjahromi", "authors": "Yasaman Keshtkarjahromi, Rashid Ansari, and Ashfaq Khokhar", "title": "Energy Efficient Decentralized Detection Based on Bit-optimal Multi-hop\n  Transmission in One-dimensional Wireless Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing information theoretic work in decentralized detection is largely\nfocused on parallel configuration of Wireless Sensor Networks (WSNs), where an\nindividual hard or soft decision is computed at each sensor node and then\ntransmitted directly to the fusion node. Such an approach is not efficient for\nlarge networks, where communication structure is likely to comprise of multiple\nhops. On the other hand, decentralized detection problem investigated for\nmulti-hop networks is mainly concerned with reducing number and/or size of\nmessages by using compression and fusion of information at intermediate nodes.\nIn this paper an energy efficient multi-hop configuration of WSNs is proposed\nto solve the detection problem in large networks with two objectives:\nmaximizing network lifetime and minimizing probability of error in the fusion\nnode. This optimization problem is considered under the constraint of total\nconsumed energy. The two objectives mentioned are achieved simultaneously in\nthe multi-hop configuration by exploring tradeoffs between different path\nlengths and number of bits allocated to each node for quantization. Simulation\nresults show significant improvement in the proposed multi-hop configuration\ncompared with the parallel configuration in terms of energy efficiency and\ndetection accuracy for different size networks, especially in larger networks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 16:40:36 GMT"}, {"version": "v2", "created": "Mon, 15 Jul 2013 14:57:41 GMT"}, {"version": "v3", "created": "Thu, 5 Sep 2013 21:14:04 GMT"}], "update_date": "2013-09-09", "authors_parsed": [["Keshtkarjahromi", "Yasaman", ""], ["Ansari", "Rashid", ""], ["Khokhar", "Ashfaq", ""]]}, {"id": "1210.3368", "submitter": "Marc Shapiro", "authors": "Annette Bieniusa (INRIA Rocquencourt), Marek Zawirski (INRIA\n  Rocquencourt, LIP6), Nuno Pregui\\c{c}a (CITI), Marc Shapiro (INRIA\n  Rocquencourt, LIP6), Carlos Baquero (Universidade do Minho Departamento de\n  Inform\\'atica), Valter Balegas (CITI), S\\'ergio Duarte (CITI)", "title": "An optimized conflict-free replicated set", "comments": "No. RR-8083 (2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Eventual consistency of replicated data supports concurrent updates, reduces\nlatency and improves fault tolerance, but forgoes strong consistency.\nAccordingly, several cloud computing platforms implement eventually-consistent\ndata types. The set is a widespread and useful abstraction, and many replicated\nset designs have been proposed. We present a reasoning abstraction, permutation\nequivalence, that systematizes the characterization of the expected concurrency\nsemantics of concurrent types. Under this framework we present one of the\nexisting conflict-free replicated data types, Observed-Remove Set. Furthermore,\nin order to decrease the size of meta-data, we propose a new optimization to\navoid tombstones. This approach that can be transposed to other data types,\nsuch as maps, graphs or sequences.\n", "versions": [{"version": "v1", "created": "Thu, 11 Oct 2012 20:16:12 GMT"}], "update_date": "2012-10-15", "authors_parsed": [["Bieniusa", "Annette", "", "INRIA Rocquencourt"], ["Zawirski", "Marek", "", "INRIA\n  Rocquencourt, LIP6"], ["Pregui\u00e7a", "Nuno", "", "CITI"], ["Shapiro", "Marc", "", "INRIA\n  Rocquencourt, LIP6"], ["Baquero", "Carlos", "", "Universidade do Minho Departamento de\n  Inform\u00e1tica"], ["Balegas", "Valter", "", "CITI"], ["Duarte", "S\u00e9rgio", "", "CITI"]]}, {"id": "1210.3735", "submitter": "Vivek Sardeshmukh", "authors": "Kishore Kothapalli, Sriram V. Pemmaraju, Vivek Sardeshmukh", "title": "On the Analysis of a Label Propagation Algorithm for Community Detection", "comments": "17 pages. Submitted to ICDCN 2013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SI physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper initiates formal analysis of a simple, distributed algorithm for\ncommunity detection on networks. We analyze an algorithm that we call\n\\textsc{Max-LPA}, both in terms of its convergence time and in terms of the\n\"quality\" of the communities detected. \\textsc{Max-LPA} is an instance of a\nclass of community detection algorithms called \\textit{label propagation}\nalgorithms. As far as we know, most analysis of label propagation algorithms\nthus far has been empirical in nature and in this paper we seek a theoretical\nunderstanding of label propagation algorithms. In our main result, we define a\nclustered version of \\er random graphs with clusters $V_1, V_2,..., V_k$ where\nthe probability $p$, of an edge connecting nodes within a cluster $V_i$ is\nhigher than $p'$, the probability of an edge connecting nodes in distinct\nclusters. We show that even with fairly general restrictions on $p$ and $p'$\n($p = \\Omega(\\frac{1}{n^{1/4-\\epsilon}})$ for any $\\epsilon > 0$, $p' =\nO(p^2)$, where $n$ is the number of nodes), \\textsc{Max-LPA} detects the\nclusters $V_1, V_2,..., V_n$ in just two rounds. Based on this and on empirical\nresults, we conjecture that \\textsc{Max-LPA} can correctly and quickly identify\ncommunities on clustered \\er graphs even when the clusters are much sparser,\ni.e., with $p = \\frac{c\\log n}{n}$ for some $c > 1$.\n", "versions": [{"version": "v1", "created": "Sat, 13 Oct 2012 19:28:37 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Kothapalli", "Kishore", ""], ["Pemmaraju", "Sriram V.", ""], ["Sardeshmukh", "Vivek", ""]]}, {"id": "1210.3839", "submitter": "Josef Widder", "authors": "Annu John and Igor Konnov and Ulrich Schmid and Helmut Veith and Josef\n  Widder", "title": "Starting a Dialog between Model Checking and Fault-tolerant Distributed\n  Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault-tolerant distributed algorithms are central for building reliable\nspatially distributed systems. Unfortunately, the lack of a canonical precise\nframework for fault-tolerant algorithms is an obstacle for both verification\nand deployment. In this paper, we introduce a new domain-specific framework to\ncapture the behavior of fault-tolerant distributed algorithms in an adequate\nand precise way. At the center of our framework is a parameterized system model\nwhere control flow automata are used for process specification. To account for\nthe specific features and properties of fault-tolerant distributed algorithms\nfor message-passing systems, our control flow automata are extended to model\nthreshold guards as well as the inherent non-determinism stemming from\nasynchronous communication, interleavings of steps, and faulty processes.\n  We demonstrate the adequacy of our framework in a representative case study\nwhere we formalize a family of well-known fault-tolerant broadcasting\nalgorithms under a variety of failure assumptions. Our case study is supported\nby model checking experiments with safety and liveness specifications for a\nfixed number of processes. In the experiments, we systematically varied the\nassumptions on both the resilience condition and the failure model. In all\ncases, our experiments coincided with the theoretical results predicted in the\ndistributed algorithms literature. This is giving clear evidence for the\nadequacy of our model.\n  In a companion paper, we are addressing the new model checking techniques\nnecessary for parametric verification of the distributed algorithms captured in\nour framework.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2012 20:51:31 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["John", "Annu", ""], ["Konnov", "Igor", ""], ["Schmid", "Ulrich", ""], ["Veith", "Helmut", ""], ["Widder", "Josef", ""]]}, {"id": "1210.3846", "submitter": "Igor Konnov", "authors": "Annu John, Igor Konnov, Ulrich Schmid, Helmut Veith, Josef Widder", "title": "Counter Attack on Byzantine Generals: Parameterized Model Checking of\n  Fault-tolerant Distributed Algorithms", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce an automated parameterized verification method for\nfault-tolerant distributed algorithms (FTDA). FTDAs are parameterized by both\nthe number of processes and the assumed maximum number of Byzantine faulty\nprocesses. At the center of our technique is a parametric interval abstraction\n(PIA) where the interval boundaries are arithmetic expressions over parameters.\nUsing PIA for both data abstraction and a new form of counter abstraction, we\nreduce the parameterized problem to finite-state model checking. We demonstrate\nthe practical feasibility of our method by verifying several variants of the\nwell-known distributed algorithm by Srikanth and Toueg. Our semi-decision\nprocedures are complemented and motivated by an undecidability proof for FTDA\nverification which holds even in the absence of interprocess communication. To\nthe best of our knowledge, this is the first paper to achieve parameterized\nautomated verification of Byzantine FTDA.\n", "versions": [{"version": "v1", "created": "Sun, 14 Oct 2012 21:31:23 GMT"}, {"version": "v2", "created": "Sun, 3 Feb 2013 19:26:53 GMT"}], "update_date": "2013-02-05", "authors_parsed": [["John", "Annu", ""], ["Konnov", "Igor", ""], ["Schmid", "Ulrich", ""], ["Veith", "Helmut", ""], ["Widder", "Josef", ""]]}, {"id": "1210.3876", "submitter": "Xi Xu", "authors": "Xi Xu, Rashid Ansari, Ashfaq Khokhar", "title": "Power-efficient Hierarchical Data Aggregation using Compressive Sensing\n  in WSN", "comments": "6 pages,10 figures, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Compressive Sensing (CS) method is a burgeoning technique being applied to\ndiverse areas including wireless sensor networks (WSNs). In WSNs, it has been\nstudied in the context of data gathering and aggregation, particularly aimed at\nreducing data transmission cost and improving power efficiency. Existing CS\nbased data gathering work in WSNs assume fixed and uniform compression\nthreshold across the network, regard- less of the data field characteristics.\nIn this paper, we present a novel data aggregation architecture model that\ncombines a multi- resolution structure with compressed sensing. The compression\nthresholds vary over the aggregation hierarchy, reflecting the underlying data\nfield. Compared with previous relevant work, the proposed model shows its\nsignificant energy saving from theoretical analysis. We have also implemented\nthe proposed CS- based data aggregation framework on a SIDnet SWANS platform,\ndiscrete event simulator commonly used for WSN simulations. Our experiments\nshow substantial energy savings, ranging from 37% to 77% for different nodes in\nthe networking depending on the position of hierarchy.\n", "versions": [{"version": "v1", "created": "Mon, 15 Oct 2012 02:39:12 GMT"}], "update_date": "2012-10-16", "authors_parsed": [["Xu", "Xi", ""], ["Ansari", "Rashid", ""], ["Khokhar", "Ashfaq", ""]]}, {"id": "1210.4251", "submitter": "Arry Yanuar", "authors": "Heru Suhartanto, Arry Yanuar and Ari Wibisono", "title": "Performance Analysis Cluster and GPU Computing Environment on Molecular\n  Dynamic Simulation of BRV-1 and REM2 with GROMACS", "comments": "5 pages, 1 figure, 5 tables", "journal-ref": "Int. J. Comp. Sci. Issue (2011), Vol. 8, Issue 4, No 2, p131-135", "doi": null, "report-no": null, "categories": "cs.DC cs.CE q-bio.BM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of application that needs high performance computing resources is\nmolecular d ynamic. There is some software available that perform molecular\ndynamic, one of these is a well known GROMACS. Our previous experiment\nsimulating molecular dynamics of Indonesian grown herbal compounds show\nsufficient speed up on 32 n odes Cluster computing environment. In order to\nobtain a reliable simulation, one usually needs to run the experiment on the\nscale of hundred nodes. But this is expensive to develop and maintain. Since\nthe invention of Graphical Processing Units that is also useful for general\nprogramming, many applications have been developed to run on this. This paper\nreports our experiments that evaluate the performance of GROMACS that runs on\ntwo different environment, Cluster computing resources and GPU based PCs. We\nrun the experiment on BRV-1 and REM2 compounds. Four different GPUs are\ninstalled on the same type of PCs of quad cores; they are Gefore GTS 250, GTX\n465, GTX 470 and Quadro 4000. We build a cluster of 16 nodes based on these\nfour quad cores PCs. The preliminary experiment shows that those run on GTX 470\nis the best among the other type of GPUs and as well as the cluster computing\nresource. A speed up around 11 and 12 is gained, while the cost of computer\nwith GPU is only about 25 percent that of Cluster we built.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 05:15:17 GMT"}], "update_date": "2012-10-17", "authors_parsed": [["Suhartanto", "Heru", ""], ["Yanuar", "Arry", ""], ["Wibisono", "Ari", ""]]}, {"id": "1210.4400", "submitter": "Derek Groen", "authors": "Hywel B. Carver, Derek Groen, James Hetherington, Rupert W. Nash,\n  Miguel O. Bernabeu, Peter V. Coveney", "title": "Coalesced communication: a design pattern for complex parallel\n  scientific software", "comments": "Submitted to Parallel Computing, 7 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new design pattern for high-performance parallel scientific\nsoftware, named coalesced communication. This pattern allows for a structured\nway to improve the communication performance through coalescence of multiple\ncommunication needs using two communication management components. We apply the\ndesign pattern to several simulations of a lattice-Boltzmann blood flow solver\nwith streaming visualisation which engenders a reduction in the communication\noverhead of approximately 40%.\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 13:39:30 GMT"}], "update_date": "2012-10-17", "authors_parsed": [["Carver", "Hywel B.", ""], ["Groen", "Derek", ""], ["Hetherington", "James", ""], ["Nash", "Rupert W.", ""], ["Bernabeu", "Miguel O.", ""], ["Coveney", "Peter V.", ""]]}, {"id": "1210.4446", "submitter": "Pradipta Mitra", "authors": "Eyjolfur I. Asgeirsson, Magnus M. Halldorsson and Pradipta Mitra", "title": "Wireless Network Stability in the SINR Model", "comments": "10 pages, appeared in SIROCCO'12", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the stability of wireless networks under stochastic arrival\nprocesses of packets, and design efficient, distributed algorithms that achieve\nstability in the SINR (Signal to Interference and Noise Ratio) interference\nmodel.\n  Specifically, we make the following contributions. We give a distributed\nalgorithm that achieves $\\Omega(\\frac{1}{\\log^2 n})$-efficiency on all networks\n(where $n$ is the number of links in the network), for all length monotone,\nsub-linear power assignments. For the power control version of the problem, we\ngive a distributed algorithm with $\\Omega(\\frac{1}{\\log n(\\log n + \\log \\log\n\\Delta)})$-efficiency (where $\\Delta$ is the length diversity of the link set).\n", "versions": [{"version": "v1", "created": "Tue, 16 Oct 2012 15:09:47 GMT"}], "update_date": "2012-10-18", "authors_parsed": [["Asgeirsson", "Eyjolfur I.", ""], ["Halldorsson", "Magnus M.", ""], ["Mitra", "Pradipta", ""]]}, {"id": "1210.4640", "submitter": "Sebastien Tixeuil", "authors": "Alexandre Maurer (LIP6, LINCS), S\\'ebastien Tixeuil (LIP6, LINCS, IUF)", "title": "A Scalable Byzantine Grid", "comments": "17 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern networks assemble an ever growing number of nodes. However, it remains\ndifficult to increase the number of channels per node, thus the maximal degree\nof the network may be bounded. This is typically the case in grid topology\nnetworks, where each node has at most four neighbors. In this paper, we address\nthe following issue: if each node is likely to fail in an unpredictable manner,\nhow can we preserve some global reliability guarantees when the number of nodes\nkeeps increasing unboundedly ? To be more specific, we consider the problem or\nreliably broadcasting information on an asynchronous grid in the presence of\nByzantine failures -- that is, some nodes may have an arbitrary and potentially\nmalicious behavior. Our requirement is that a constant fraction of correct\nnodes remain able to achieve reliable communication. Existing solutions can\nonly tolerate a fixed number of Byzantine failures if they adopt a worst-case\nplacement scheme. Besides, if we assume a constant Byzantine ratio (each node\nhas the same probability to be Byzantine), the probability to have a fatal\nplacement approaches 1 when the number of nodes increases, and reliability\nguarantees collapse. In this paper, we propose the first broadcast protocol\nthat overcomes these difficulties. First, the number of Byzantine failures that\ncan be tolerated (if they adopt the worst-case placement) now increases with\nthe number of nodes. Second, we are able to tolerate a constant Byzantine\nratio, however large the grid may be. In other words, the grid becomes\nscalable. This result has important security applications in ultra-large\nnetworks, where each node has a given probability to misbehave.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2012 06:44:27 GMT"}], "update_date": "2012-10-18", "authors_parsed": [["Maurer", "Alexandre", "", "LIP6, LINCS"], ["Tixeuil", "S\u00e9bastien", "", "LIP6, LINCS, IUF"]]}, {"id": "1210.4690", "submitter": "Nikzad Babaii-Rizvandi", "authors": "Nikzad Babaii Rizvandi, Albert Y. Zomaya", "title": "A Primarily Survey on Energy Efficiency in Cloud and Distributed\n  Computing Systems", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A survey of available techniques in hardware to reduce energy consumption\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2012 10:55:56 GMT"}, {"version": "v2", "created": "Fri, 16 Nov 2012 04:55:41 GMT"}], "update_date": "2012-11-19", "authors_parsed": [["Rizvandi", "Nikzad Babaii", ""], ["Zomaya", "Albert Y.", ""]]}, {"id": "1210.4778", "submitter": "Themistoklis Charalambous", "authors": "Christoforos N. Hadjicostis and Themistoklis Charalambous", "title": "Average Consensus in the Presence of Delays and Dynamically Changing\n  Directed Graph Topologies", "comments": "37 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Classical approaches for asymptotic convergence to the global average in a\ndistributed fashion typically assume timely and reliable exchange of\ninformation between neighboring components of a given multi-component system.\nThese assumptions are not necessarily valid in practical settings due to\nvarying delays that might affect transmissions at different times, as well as\npossible changes in the underlying interconnection topology (e.g., due to\ncomponent mobility). In this work, we propose protocols to overcome these\nlimitations. We first consider a fixed interconnection topology (captured by a\n- possibly directed - graph) and propose a discrete-time protocol that can\nreach asymptotic average consensus in a distributed fashion, despite the\npresence of arbitrary (but bounded) delays in the communication links. The\nprotocol requires that each component has knowledge of the number of its\noutgoing links (i.e., the number of components to which it sends information).\nWe subsequently extend the protocol to also handle changes in the underlying\ninterconnection topology and describe a variety of rather loose conditions\nunder which the modified protocol allows the components to reach asymptotic\naverage consensus. The proposed algorithms are illustrated via examples.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2012 15:59:41 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2013 13:16:30 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Hadjicostis", "Christoforos N.", ""], ["Charalambous", "Themistoklis", ""]]}, {"id": "1210.4822", "submitter": "Amitabh Trehan", "authors": "Shay Kutten, Gopal Pandurangan, David Peleg, Peter Robinson, and\n  Amitabh Trehan", "title": "Sublinear Bounds for Randomized Leader Election", "comments": "Best Paper Award winner at ICDCN 2013, CDCN 2013 14th International\n  Conference on Distributed Computing and Networking. Tata Institute of\n  Fundamental Research, Mumbai, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper concerns {\\em randomized} leader election in synchronous\ndistributed networks. A distributed leader election algorithm is presented for\ncomplete $n$-node networks that runs in O(1) rounds and (with high probability)\nuses only $O(\\sqrt{n}\\log^{3/2} n)$ messages to elect a unique leader (with\nhigh probability). When considering the \"explicit\" variant of leader election\nwhere eventually every node knows the identity of the leader, our algorithm\nyields the asymptotically optimal bounds of O(1) rounds and O(n) messages. This\nalgorithm is then extended to one solving leader election on any connected\nnon-bipartite $n$-node graph $G$ in $O(\\tau(G))$ time and\n$O(\\tau(G)\\sqrt{n}\\log^{3/2} n)$ messages, where $\\tau(G)$ is the mixing time\nof a random walk on $G$. The above result implies highly efficient (sublinear\nrunning time and messages) leader election algorithms for networks with small\nmixing times, such as expanders and hypercubes. In contrast, previous leader\nelection algorithms had at least linear message complexity even in complete\ngraphs. Moreover, super-linear message lower bounds are known for\ntime-efficient {\\em deterministic} leader election algorithms.\n  Finally, we present an almost matching lower bound for randomized leader\nelection, showing that $\\Omega(\\sqrt n)$ messages are needed for any leader\nelection algorithm that succeeds with probability at least $1/e + \\eps$, for\nany small constant $\\eps > 0$.\n  We view our results as a step towards understanding the randomized complexity\nofleader election in distributed networks.\n", "versions": [{"version": "v1", "created": "Wed, 17 Oct 2012 19:03:21 GMT"}, {"version": "v2", "created": "Wed, 15 May 2013 14:18:18 GMT"}], "update_date": "2013-05-16", "authors_parsed": [["Kutten", "Shay", ""], ["Pandurangan", "Gopal", ""], ["Peleg", "David", ""], ["Robinson", "Peter", ""], ["Trehan", "Amitabh", ""]]}, {"id": "1210.5093", "submitter": "Yousun Ko", "authors": "Yousun Ko, Minyoung Jung, Yo-Sub Han and Bernd Burgstaller", "title": "A Speculative Parallel DFA Membership Test for Multicore, SIMD and Cloud\n  Computing Environments", "comments": null, "journal-ref": null, "doi": "10.1007/s10766-013-0258-5", "report-no": null, "categories": "cs.DC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present techniques to parallelize membership tests for Deterministic\nFinite Automata (DFAs). Our method searches arbitrary regular expressions by\nmatching multiple bytes in parallel using speculation. We partition the input\nstring into chunks, match chunks in parallel, and combine the matching results.\nOur parallel matching algorithm exploits structural DFA properties to minimize\nthe speculative overhead. Unlike previous approaches, our speculation is\nfailure-free, i.e., (1) sequential semantics are maintained, and (2)\nspeed-downs are avoided altogether. On architectures with a SIMD\ngather-operation for indexed memory loads, our matching operation is fully\nvectorized. The proposed load-balancing scheme uses an off-line profiling step\nto determine the matching capacity of each par- ticipating processor. Based on\nmatching capacities, DFA matches are load-balanced on inhomogeneous parallel\narchitectures such as cloud computing environments. We evaluated our\nspeculative DFA membership test for a representative set of benchmarks from the\nPerl-compatible Regular Expression (PCRE) library and the PROSITE protein\ndatabase. Evaluation was conducted on a 4 CPU (40 cores) shared-memory node of\nthe Intel Manycore Testing Lab (Intel MTL), on the Intel AVX2 SDE simulator for\n8-way fully vectorized SIMD execution, and on a 20-node (288 cores) cluster on\nthe Amazon EC2 computing cloud.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2012 11:17:23 GMT"}, {"version": "v2", "created": "Mon, 22 Jul 2013 15:32:29 GMT"}], "update_date": "2013-07-23", "authors_parsed": [["Ko", "Yousun", ""], ["Jung", "Minyoung", ""], ["Han", "Yo-Sub", ""], ["Burgstaller", "Bernd", ""]]}, {"id": "1210.5128", "submitter": "Yu Wang", "authors": "Yu Wang, Weikang Qian, Shuchang Zhang and Bo Yuan", "title": "A Novel Learning Algorithm for Bayesian Network and Its Efficient\n  Implementation on GPU", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational inference of causal relationships underlying complex networks,\nsuch as gene-regulatory pathways, is NP-complete due to its combinatorial\nnature when permuting all possible interactions. Markov chain Monte Carlo\n(MCMC) has been introduced to sample only part of the combinations while still\nguaranteeing convergence and traversability, which therefore becomes widely\nused. However, MCMC is not able to perform efficiently enough for networks that\nhave more than 15~20 nodes because of the computational complexity. In this\npaper, we use general purpose processor (GPP) and general purpose graphics\nprocessing unit (GPGPU) to implement and accelerate a novel Bayesian network\nlearning algorithm. With a hash-table-based memory-saving strategy and a novel\ntask assigning strategy, we achieve a 10-fold acceleration per iteration than\nusing a serial GPP. Specially, we use a greedy method to search for the best\ngraph from a given order. We incorporate a prior component in the current\nscoring function, which further facilitates the searching. Overall, we are able\nto apply this system to networks with more than 60 nodes, allowing inferences\nand modeling of bigger and more complex networks than current methods.\n", "versions": [{"version": "v1", "created": "Thu, 18 Oct 2012 14:02:12 GMT"}], "update_date": "2012-10-19", "authors_parsed": [["Wang", "Yu", ""], ["Qian", "Weikang", ""], ["Zhang", "Shuchang", ""], ["Yuan", "Bo", ""]]}, {"id": "1210.5774", "submitter": "Christoph Lenzen", "authors": "Christoph Lenzen and Boaz Patt-Shamir", "title": "Fast Routing Table Construction Using Small Messages", "comments": "40 pages, 2 figures, extended abstract submitted to STOC'13", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a distributed randomized algorithm computing approximate\ndistances and routes that approximate shortest paths. Let n denote the number\nof nodes in the graph, and let HD denote the hop diameter of the graph, i.e.,\nthe diameter of the graph when all edges are considered to have unit weight.\nGiven 0 < eps <= 1/2, our algorithm runs in weak-O(n^(1/2 + eps) + HD)\ncommunication rounds using messages of O(log n) bits and guarantees a stretch\nof O(eps^(-1) log eps^(-1)) with high probability. This is the first\ndistributed algorithm approximating weighted shortest paths that uses small\nmessages and runs in weak-o(n) time (in graphs where HD in weak-o(n)). The time\ncomplexity nearly matches the lower bounds of weak-Omega(sqrt(n) + HD) in the\nsmall-messages model that hold for stateless routing (where routing decisions\ndo not depend on the traversed path) as well as approximation of the weigthed\ndiameter. Our scheme replaces the original identifiers of the nodes by labels\nof size O(log eps^(-1) log n). We show that no algorithm that keeps the\noriginal identifiers and runs for weak-o(n) rounds can achieve a\npolylogarithmic approximation ratio.\n  Variations of our techniques yield a number of fast distributed approximation\nalgorithms solving related problems using small messages. Specifically, we\npresent algorithms that run in weak-O(n^(1/2 + eps) + HD) rounds for a given 0\n< eps <= 1/2, and solve, with high probability, the following problems:\n  - O(eps^(-1))-approximation for the Generalized Steiner Forest (the running\ntime in this case has an additive weak-O(t^(1 + 2eps)) term, where t is the\nnumber of terminals);\n  - O(eps^(-2))-approximation of weighted distances, using node labels of size\nO(eps^(-1) log n) and weak-O(n^(eps)) bits of memory per node;\n  - O(eps^(-1))-approximation of the weighted diameter;\n  - O(eps^(-3))-approximate shortest paths using the labels 1,...,n.\n", "versions": [{"version": "v1", "created": "Sun, 21 Oct 2012 23:01:59 GMT"}, {"version": "v2", "created": "Fri, 2 Nov 2012 12:54:01 GMT"}], "update_date": "2012-11-05", "authors_parsed": [["Lenzen", "Christoph", ""], ["Patt-Shamir", "Boaz", ""]]}, {"id": "1210.5802", "submitter": "Ryan Rossi", "authors": "Ryan A. Rossi, David F. Gleich, Assefaw H. Gebremedhin, Md. Mostofa\n  Ali Patwary", "title": "What if CLIQUE were fast? Maximum Cliques in Information Networks and\n  Strong Components in Temporal Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC cs.DM physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exact maximum clique finders have progressed to the point where we can\ninvestigate cliques in million-node social and information networks, as well as\nfind strongly connected components in temporal networks. We use one such finder\nto study a large collection of modern networks emanating from biological,\nsocial, and technological domains. We show inter-relationships between maximum\ncliques and several other common network properties, including network density,\nmaximum core, and number of triangles. In temporal networks, we find that the\nlargest temporal strong components have around 20-30% of the vertices of the\nentire network. These components represent groups of highly communicative\nindividuals. In addition, we discuss and improve the performance and utility of\nthe maximum clique finder itself.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2012 04:21:07 GMT"}, {"version": "v2", "created": "Tue, 30 Oct 2012 19:57:39 GMT"}], "update_date": "2012-10-31", "authors_parsed": [["Rossi", "Ryan A.", ""], ["Gleich", "David F.", ""], ["Gebremedhin", "Assefaw H.", ""], ["Patwary", "Md. Mostofa Ali", ""]]}, {"id": "1210.6052", "submitter": "Nicolas Kourtellis", "authors": "Nicolas Kourtellis and Adriana Iamnitchi", "title": "Leveraging Peer Centrality in the Design of Socially-Informed\n  Peer-to-Peer Systems", "comments": "18 double-column IEEE journal pages, 14 figures, shorter version\n  submitted to IEEE Transactions in Parallel and Distributed Systems for review", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Social applications mine user social graphs to improve performance in search,\nprovide recommendations, allow resource sharing and increase data privacy. When\nsuch applications are implemented on a peer-to-peer (P2P) architecture, the\nsocial graph is distributed on the P2P system: the traversal of the social\ngraph translates into a socially-informed routing in the peer-to-peer layer. In\nthis work we introduce the model of a projection graph that is the result of\ndecentralizing a social graph onto a peer-to-peer network. We focus on three\nsocial network metrics: degree, node betweenness and edge betweenness\ncentrality and analytically formulate the relation between metrics in the\nsocial graph and in the projection graph. Through experimental evaluation on\nreal networks, we demonstrate that when mapping user communities of sizes up to\n50-150 users on each peer, the association between the properties of the social\ngraph and the projection graph is high, and thus the properties of the\n(dynamic) projection graph can be inferred from the properties of the (slower\nchanging) social graph. Furthermore, we demonstrate with two application\nscenarios on large-scale social networks the usability of the projection graph\nin designing social search applications and unstructured P2P overlays.\n", "versions": [{"version": "v1", "created": "Mon, 22 Oct 2012 20:12:51 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Kourtellis", "Nicolas", ""], ["Iamnitchi", "Adriana", ""]]}, {"id": "1210.6119", "submitter": "Francis Cabarle", "authors": "Francis George C. Cabarle, Kelvin C. Bu\\~no, Henry N. Adorna", "title": "Time After Time: Notes on Delays In Spiking Neural P Systems", "comments": "11 pages, 9 figures, 4 lemmas, 1 theorem, preprint of Workshop on\n  Computation: Theory and Practice 2012 at DLSU, Manila together with UP\n  Diliman, DLSU, Tokyo Institute of Technology, and Osaka university", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC cs.ET", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Spiking Neural P systems, SNP systems for short, are biologically inspired\ncomputing devices based on how neurons perform computations. SNP systems use\nonly one type of symbol, the spike, in the computations. Information is encoded\nin the time differences of spikes or the multiplicity of spikes produced at\ncertain times. SNP systems with delays (associated with rules) and those\nwithout delays are two of several Turing complete SNP system variants in\nliterature. In this work we investigate how restricted forms of SNP systems\nwith delays can be simulated by SNP systems without delays. We show the\nsimulations for the following spike routing constructs: sequential, iteration,\njoin, and split.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 03:45:57 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Cabarle", "Francis George C.", ""], ["Bu\u00f1o", "Kelvin C.", ""], ["Adorna", "Henry N.", ""]]}, {"id": "1210.6134", "submitter": "Pooja Vyavahare", "authors": "Pooja Vyavahare and Nutan Limaye and D. Manjunath", "title": "In-Network Estimation of Frequency Moments", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  We consider the problem of estimating functions of distributed data using a\ndistributed algorithm over a network. The extant literature on computing\nfunctions in distributed networks such as wired and wireless sensor networks\nand peer-to-peer networks deals with computing linear functions of the\ndistributed data when the alphabet size of the data values is small, O(1). We\ndescribe a distributed randomized algorithm to estimate a class of non-linear\nfunctions of the distributed data which is over a large alphabet. We consider\nthree types of networks: point-to-point networks with gossip based\ncommunication, random planar networks in the connectivity regime and random\nplanar networks in the percolating regime both of which use the slotted Aloha\ncommunication protocol. For each network type, we estimate the scaled $k$-th\nfrequency moments, for $k \\geq 2$. Specifically, for every $k \\geq 2,$ we give\na distributed randomized algorithm that computes, with probability\n$(1-\\delta),$ an $\\epsilon$-approximation of the scaled $k$-th frequency\nmoment, $F_k/N^k$, using time $O(M^{1-\\frac{1}{k-1}} T)$ and\n$O(M^{1-\\frac{1}{k-1}} \\log N \\log (\\delta^{-1})/\\epsilon^2)$ bits of\ntransmission per communication step. Here, $N$ is the number of nodes in the\nnetwork, $T$ is the information spreading time and $M=o(N)$ is the alphabet\nsize.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 06:07:27 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Vyavahare", "Pooja", ""], ["Limaye", "Nutan", ""], ["Manjunath", "D.", ""]]}, {"id": "1210.6266", "submitter": "Rahul Sampath", "authors": "Rahul S. Sampath, Bobby Philip, Srikanth Allu and Srdjan Simunovic", "title": "Recursive Schur Decomposition", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present a parallel recursive algorithm based on\nmulti-level domain decomposition that can be used as a precondtioner to a\nKrylov subspace method to solve sparse linear systems of equations arising from\nthe discretization of partial differential equations (PDEs). We tested the\neffectiveness of the algorithm on several PDEs using different number of\nsub-domains (ranging from 8 to 32768) and various problem sizes (ranging from\nabout 2000 to over a billion degrees of freedom). We report the results from\nthese tests; the results show that the algorithm scales very well with the\nnumber of sub-domains.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 15:19:13 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Sampath", "Rahul S.", ""], ["Philip", "Bobby", ""], ["Allu", "Srikanth", ""], ["Simunovic", "Srdjan", ""]]}, {"id": "1210.6286", "submitter": "James Aspnes", "authors": "James Aspnes", "title": "A one-bit swap object using test-and-sets and a max register", "comments": null, "journal-ref": null, "doi": null, "report-no": "YALEU/DCS/TR-1464", "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a linearizable, wait-free implementation of a one-bit swap object\nfrom a single max register and an unbounded array of test-and-set bits. Each\nswap operation takes at most three steps. Using standard randomized\nconstructions, the max register and test-and-set bits can be replaced by\nread-write registers, at the price of raising the cost of a swap operation to\nan expected O(max(log n, min(log t, n))) steps, where t is the number of times\nthe swap object has previously changed its value and n is the number of\nprocesses.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 16:49:56 GMT"}], "update_date": "2012-10-24", "authors_parsed": [["Aspnes", "James", ""]]}, {"id": "1210.6378", "submitter": "Nikolai Krivulin", "authors": "Sergei M. Ermakov and Nikolai K. Krivulin", "title": "Efficient algorithms for tandem queueing system simulation", "comments": "7 pages, 1 figure", "journal-ref": "Applied Mathematics Letters, Volume 7, Issue 6, 1994, Pages 39-43", "doi": "10.1016/0893-9659(94)90092-2", "report-no": null, "categories": "math.NA cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Serial and parallel algorithms for simulation of tandem queueing systems with\ninfinite buffers are presented, and their performance is examined. It is shown\nthat the algorithms which are based on a simple computational procedure involve\nlow time and memory requirements.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 20:46:56 GMT"}], "update_date": "2012-10-25", "authors_parsed": [["Ermakov", "Sergei M.", ""], ["Krivulin", "Nikolai K.", ""]]}, {"id": "1210.6382", "submitter": "Nicolas Kourtellis", "authors": "Nicolas Kourtellis, Adriana Iamnitchi, Cristian Borcea and Robin\n  Murphy", "title": "Data Survivability in Networks of Mobile Robots in Urban Disaster\n  Environments", "comments": "16 double-column pages, 8 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile multi-robot teams deployed for monitoring or search-and-rescue\nmissions in urban disaster areas can greatly improve the quality of vital data\ncollected on-site. Analysis of such data can identify hazards and save lives.\nUnfortunately, such real deployments at scale are cost prohibitive and robot\nfailures lead to data loss. Moreover, scaled-down deployments do not capture\nsignificant levels of interaction and communication complexity. To tackle this\nproblem, we propose novel mobility and failure generation frameworks that allow\nrealistic simulations of mobile robot networks for large scale disaster\nscenarios. Furthermore, since data replication techniques can improve the\nsurvivability of data collected during the operation, we propose an adaptive,\nscalable data replication technique that achieves high data survivability with\nlow overhead. Our technique considers the anticipated robot failures and robot\nheterogeneity to decide how aggressively to replicate data. In addition, it\nconsiders survivability priorities, with some data requiring more effort to be\nsaved than others. Using our novel simulation generation frameworks, we compare\nour adaptive technique with flooding and broadcast-based replication techniques\nand show that for failure rates of up to 60% it ensures better data\nsurvivability with lower communication costs.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 21:09:08 GMT"}, {"version": "v2", "created": "Fri, 22 Feb 2013 10:26:13 GMT"}], "update_date": "2013-02-25", "authors_parsed": [["Kourtellis", "Nicolas", ""], ["Iamnitchi", "Adriana", ""], ["Borcea", "Cristian", ""], ["Murphy", "Robin", ""]]}, {"id": "1210.6384", "submitter": "Yuri Frota", "authors": "Rafaelli de C. Coutinho, L\\'ucia M. A. Drummond and Yuri Frota", "title": "A Distributed Transportation Simplex Applied to a Content Distribution\n  Network Problem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A Content Distribution Network (CDN) can be defined as an overlay system that\nreplicates copies of contents at multiple points of a network, close to the\nfinal users, with the objective of improving data access. CDN technology is\nwidely used for the distribution of large-sized contents, like in video\nstreaming. In this paper we address the problem of finding the best server for\neach customer request in CDNs, in order to minimize the overall cost. We\nconsider the problem as a transportation problem and a distributed algorithm is\nproposed to solve it. The algorithm is composed of two independent phases: a\ndistributed heuristic finds an initial solution that may be later improved by a\ndistributed transportation simplex algorithm. It is compared with the\nsequential version of the transportation simplex and with an auction-based\ndistributed algorithm. Computational experiments carried out on a set of\ninstances adapted from the literature revealed that our distributed approach\nhas a performance similar to its sequential counterpart, in spite of not\nrequiring global information about the contents requests. Moreover, the results\nalso showed that the new method outperforms the based-auction distributed\nalgorithm.\n", "versions": [{"version": "v1", "created": "Tue, 23 Oct 2012 21:21:06 GMT"}], "update_date": "2012-10-25", "authors_parsed": [["Coutinho", "Rafaelli de C.", ""], ["Drummond", "L\u00facia M. A.", ""], ["Frota", "Yuri", ""]]}, {"id": "1210.6411", "submitter": "EPTCS", "authors": "Andreas Beckmann (Goethe-Universit\\\"at Frankfurt), Jaroslaw Fedorowicz\n  (Goethe-Universit\\\"at Frankfurt), J\\\"org Keller (FernUniversit\\\"at in Hagen),\n  Ulrich Meyer (Goethe-Universit\\\"at Frankfurt)", "title": "A structural analysis of the A5/1 state transition graph", "comments": "In Proceedings GRAPHITE 2012, arXiv:1210.6118", "journal-ref": "EPTCS 99, 2012, pp. 5-19", "doi": "10.4204/EPTCS.99.4", "report-no": null, "categories": "cs.DC cs.CR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe efficient algorithms to analyze the cycle structure of the graph\ninduced by the state transition function of the A5/1 stream cipher used in GSM\nmobile phones and report on the results of the implementation. The analysis is\nperformed in five steps utilizing HPC clusters, GPGPU and external memory\ncomputation. A great reduction of this huge state transition graph of 2^64\nnodes is achieved by focusing on special nodes in the first step and removing\nleaf nodes that can be detected with limited effort in the second step. This\nstep does not break the overall structure of the graph and keeps at least one\nnode on every cycle. In the third step the nodes of the reduced graph are\nconnected by weighted edges. Since the number of nodes is still huge an\nefficient bitslice approach is presented that is implemented with NVIDIA's CUDA\nframework and executed on several GPUs concurrently. An external memory\nalgorithm based on the STXXL library and its parallel pipelining feature\nfurther reduces the graph in the fourth step. The result is a graph containing\nonly cycles that can be further analyzed in internal memory to count the number\nand size of the cycles. This full analysis which previously would take months\ncan now be completed within a few days and allows to present structural results\nfor the full graph for the first time. The structure of the A5/1 graph deviates\nnotably from the theoretical results for random mappings.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2012 00:32:55 GMT"}], "update_date": "2012-10-25", "authors_parsed": [["Beckmann", "Andreas", "", "Goethe-Universit\u00e4t Frankfurt"], ["Fedorowicz", "Jaroslaw", "", "Goethe-Universit\u00e4t Frankfurt"], ["Keller", "J\u00f6rg", "", "FernUniversit\u00e4t in Hagen"], ["Meyer", "Ulrich", "", "Goethe-Universit\u00e4t Frankfurt"]]}, {"id": "1210.6412", "submitter": "EPTCS", "authors": "Elise Cormie-Bowins", "title": "A Comparison of Sequential and GPU Implementations of Iterative Methods\n  to Compute Reachability Probabilities", "comments": "In Proceedings GRAPHITE 2012, arXiv:1210.6118", "journal-ref": "EPTCS 99, 2012, pp. 20-34", "doi": "10.4204/EPTCS.99.5", "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of computing reachability probabilities: given a\nMarkov chain, an initial state of the Markov chain, and a set of goal states of\nthe Markov chain, what is the probability of reaching any of the goal states\nfrom the initial state? This problem can be reduced to solving a linear\nequation Ax = b for x, where A is a matrix and b is a vector. We consider two\niterative methods to solve the linear equation: the Jacobi method and the\nbiconjugate gradient stabilized (BiCGStab) method. For both methods, a\nsequential and a parallel version have been implemented. The parallel versions\nhave been implemented on the compute unified device architecture (CUDA) so that\nthey can be run on a NVIDIA graphics processing unit (GPU). From our\nexperiments we conclude that as the size of the matrix increases, the CUDA\nimplementations outperform the sequential implementations. Furthermore, the\nBiCGStab method performs better than the Jacobi method for dense matrices,\nwhereas the Jacobi method does better for sparse ones. Since the reachability\nprobabilities problem plays a key role in probabilistic model checking, we also\ncompared the implementations for matrices obtained from a probabilistic model\nchecker. Our experiments support the conjecture by Bosnacki et al. that the\nJacobi method is superior to Krylov subspace methods, a class to which the\nBiCGStab method belongs, for probabilistic model checking.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2012 00:33:04 GMT"}], "update_date": "2012-10-25", "authors_parsed": [["Cormie-Bowins", "Elise", ""]]}, {"id": "1210.6685", "submitter": "Guodong Shi", "authors": "Guodong Shi, Alexandre Proutiere and Karl Henrik Johansson", "title": "Distributed Optimization: Convergence Conditions from a Dynamical System\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper explores the fundamental properties of distributed minimization of\na sum of functions with each function only known to one node, and a\npre-specified level of node knowledge and computational capacity. We define the\noptimization information each node receives from its objective function, the\nneighboring information each node receives from its neighbors, and the\ncomputational capacity each node can take advantage of in controlling its\nstate. It is proven that there exist a neighboring information way and a\ncontrol law that guarantee global optimal consensus if and only if the solution\nsets of the local objective functions admit a nonempty intersection set for\nfixed strongly connected graphs. Then we show that for any tolerated error, we\ncan find a control law that guarantees global optimal consensus within this\nerror for fixed, bidirectional, and connected graphs under mild conditions. For\ntime-varying graphs, we show that optimal consensus can always be achieved as\nlong as the graph is uniformly jointly strongly connected and the nonempty\nintersection condition holds. The results illustrate that nonempty intersection\nfor the local optimal solution sets is a critical condition for successful\ndistributed optimization for a large class of algorithms.\n", "versions": [{"version": "v1", "created": "Wed, 24 Oct 2012 21:28:36 GMT"}], "update_date": "2012-10-26", "authors_parsed": [["Shi", "Guodong", ""], ["Proutiere", "Alexandre", ""], ["Johansson", "Karl Henrik", ""]]}, {"id": "1210.6855", "submitter": "Michal \\v{C}\\'ap", "authors": "Michal \\v{C}\\'ap and Peter Nov\\'ak and Ji\\v{r}\\'i Vok\\v{r}\\'inek and\n  Michal P\\v{e}chou\\v{c}ek", "title": "Asynchronous Decentralized Algorithm for Space-Time Cooperative\n  Pathfinding", "comments": null, "journal-ref": "Spatio-Temporal Dynamics (STeDy 2012). Editors: Mehul Bhatt, Hans\n  Guesgen, and Ernest Davis. Workshop Proceedings of the European Conference on\n  Articial Intelligence (ECAI 2012), Montpellier, France", "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.RO", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Cooperative pathfinding is a multi-agent path planning problem where a group\nof vehicles searches for a corresponding set of non-conflicting space-time\ntrajectories. Many of the practical methods for centralized solving of\ncooperative pathfinding problems are based on the prioritized planning\nstrategy. However, in some domains (e.g., multi-robot teams of unmanned aerial\nvehicles, autonomous underwater vehicles, or unmanned ground vehicles) a\ndecentralized approach may be more desirable than a centralized one due to\ncommunication limitations imposed by the domain and/or privacy concerns.\n  In this paper we present an asynchronous decentralized variant of prioritized\nplanning ADPP and its interruptible version IADPP. The algorithm exploits the\ninherent parallelism of distributed systems and allows for a speed up of the\ncomputation process. Unlike the synchronized planning approaches, the algorithm\nallows an agent to react to updates about other agents' paths immediately and\ninvoke its local spatio-temporal path planner to find the best trajectory, as\nresponse to the other agents' choices. We provide a proof of correctness of the\nalgorithms and experimentally evaluate them on synthetic domains.\n", "versions": [{"version": "v1", "created": "Thu, 25 Oct 2012 14:35:27 GMT"}], "update_date": "2012-10-26", "authors_parsed": [["\u010c\u00e1p", "Michal", ""], ["Nov\u00e1k", "Peter", ""], ["Vok\u0159\u00ednek", "Ji\u0159\u00ed", ""], ["P\u011bchou\u010dek", "Michal", ""]]}, {"id": "1210.7057", "submitter": "Rajendra Shinde", "authors": "Bahman Bahmani, Ashish Goel, Rajendra Shinde", "title": "Efficient Distributed Locality Sensitive Hashing", "comments": "A short version of this paper will appear in CIKM 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed frameworks are gaining increasingly widespread use in\napplications that process large amounts of data. One important example\napplication is large scale similarity search, for which Locality Sensitive\nHashing (LSH) has emerged as the method of choice, specially when the data is\nhigh-dimensional. At its core, LSH is based on hashing the data points to a\nnumber of buckets such that similar points are more likely to map to the same\nbuckets. To guarantee high search quality, the LSH scheme needs a rather large\nnumber of hash tables. This entails a large space requirement, and in the\ndistributed setting, with each query requiring a network call per hash bucket\nlook up, this also entails a big network load. The Entropy LSH scheme proposed\nby Panigrahy significantly reduces the number of required hash tables by\nlooking up a number of query offsets in addition to the query itself. While\nthis improves the LSH space requirement, it does not help with (and in fact\nworsens) the search network efficiency, as now each query offset requires a\nnetwork call. In this paper, focusing on the Euclidian space under $l_2$ norm\nand building up on Entropy LSH, we propose the distributed Layered LSH scheme,\nand prove that it exponentially decreases the network cost, while maintaining a\ngood load balance between different machines. Our experiments also verify that\nour scheme results in a significant network traffic reduction that brings about\nlarge runtime improvement in real world applications.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 05:59:55 GMT"}], "update_date": "2012-10-29", "authors_parsed": [["Bahmani", "Bahman", ""], ["Goel", "Ashish", ""], ["Shinde", "Rajendra", ""]]}, {"id": "1210.7385", "submitter": "Omer Khalid Dr", "authors": "Omer Khalid, Arsalaan Sheikh, Brice Copy", "title": "Optimizing Infrastructures for Testing Using Virtualization", "comments": "13th International Conference on Accelerator and Large Experimental\n  Physics Control Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualization technology and cloud computing have brought a paradigm shift\nin the way we utilize, deploy and manage computer resources. They allow fast\ndeployment of multiple operating system as containers on physical ma- chines\nwhich can be either discarded after use or check- pointed for later\nre-deployment. At European Organization for Nuclear Research (CERN), we have\nbeen using virtualization technology to quickly setup virtual machines for our\ndevelopers with preconfigured software to enable them to quickly test/deploy a\nnew version of a software patch for a given application. This paper reports\nboth on the techniques that have been used to setup a private cloud on a\ncommodity hardware and also presents the optimization techniques we used to\nremove deployment specific performance bottlenecks.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2012 00:03:46 GMT"}], "update_date": "2012-10-30", "authors_parsed": [["Khalid", "Omer", ""], ["Sheikh", "Arsalaan", ""], ["Copy", "Brice", ""]]}, {"id": "1210.7427", "submitter": "Elias Rudberg", "authors": "Emanuel H. Rubensson and Elias Rudberg", "title": "Chunks and Tasks: a programming model for parallelization of dynamic\n  algorithms", "comments": "This manuscript was submitted to Parallel Computing (Elsevier) for\n  the special issue devoted to the conference Parallel Matrix Algorithms and\n  Applications (PMAA 2012). A presentation of this work was given at PMAA 2012\n  on June 29, 2012", "journal-ref": "Parallel Comput. 40 (2014) 328-343", "doi": "10.1016/j.parco.2013.09.006", "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose Chunks and Tasks, a parallel programming model built on\nabstractions for both data and work. The application programmer specifies how\ndata and work can be split into smaller pieces, chunks and tasks, respectively.\nThe Chunks and Tasks library maps the chunks and tasks to physical resources.\nIn this way we seek to combine user friendliness with high performance. An\napplication programmer can express a parallel algorithm using a few simple\nbuilding blocks, defining data and work objects and their relationships. No\nexplicit communication calls are needed; the distribution of both work and data\nis handled by the Chunks and Tasks library. This makes efficient implementation\nof complex applications that require dynamic distribution of work and data\neasier. At the same time, Chunks and Tasks imposes restrictions on data access\nand task dependencies that facilitates the development of high performance\nparallel back ends. We discuss the fundamental abstractions underlying the\nprogramming model, as well as performance and fault resilience considerations.\nWe also present a pilot C++ library implementation for clusters of multicore\nmachines and demonstrate its performance for sparse blocked matrix-matrix\nmultiplication.\n", "versions": [{"version": "v1", "created": "Sun, 28 Oct 2012 09:00:22 GMT"}], "update_date": "2014-07-29", "authors_parsed": [["Rubensson", "Emanuel H.", ""], ["Rudberg", "Elias", ""]]}, {"id": "1210.7624", "submitter": "Vivek Chalotra", "authors": "Vivek Chalotra (AIE), Anju Bhasin, Anik Gupta, Sanjeev Singh Sambyal", "title": "HEP Analysis Facility An Approach to Grid Computing", "comments": "4 pages, 4 figures, Indian Engineering Congress 2011, Bangalore,\n  India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HEP Analysis Facility is a cluster designed and implemented in Scientific\nLinux Cern 5.5 to grant High Energy Physics researchers one place where they\ncan go to undertake a particular task or to provide a parallel processing\narchitecture in which CPU resources are shared across a network and all\nmachines function as one large supercomputer.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2012 11:29:52 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Chalotra", "Vivek", "", "AIE"], ["Bhasin", "Anju", ""], ["Gupta", "Anik", ""], ["Sambyal", "Sanjeev Singh", ""]]}, {"id": "1210.7626", "submitter": "Vivek Chalotra", "authors": "Vivek Chalotra, Anju Bhasin, Anik Gupta, Sanjeev Singh Sambyal", "title": "Hep Cluster First Step Towards Grid Computing", "comments": "7th JK Science Congress 2011, Jammu, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  HEP Cluster is designed and implemented in Scientific Linux Cern 5.5 to grant\nHigh Energy Physics researchers one place where they can go to undertake a\nparticular task or to provide a parallel processing architecture in which CPU\nresources are shared across a network and all machines function as one large\nsupercomputer. It gives physicists a facility to access computers and data,\ntransparently, without having to consider location, operating system, account\nadministration, and other details. By using this facility researchers can\nprocess their jobs much faster than the stand alone desktop systems. Keywords:\nCluster, Network, Storage, Parallel Computing & Gris.\n", "versions": [{"version": "v1", "created": "Mon, 29 Oct 2012 11:36:32 GMT"}], "update_date": "2012-10-30", "authors_parsed": [["Chalotra", "Vivek", ""], ["Bhasin", "Anju", ""], ["Gupta", "Anik", ""], ["Sambyal", "Sanjeev Singh", ""]]}, {"id": "1210.7774", "submitter": "Mads Kristensen", "authors": "Mads Ruben Burgdorff Kristensen, Simon Andreas Frimann Lund, Troels\n  Blum, Brian Vinter", "title": "cphVB: A System for Automated Runtime Optimization and Parallelization\n  of Vectorized Applications", "comments": null, "journal-ref": "Proceedings of The 11th Python In Science Conference (SciPy 2012)", "doi": null, "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern processor architectures, in addition to having still more cores, also\nrequire still more consideration to memory-layout in order to run at full\ncapacity. The usefulness of most languages is deprecating as their\nabstractions, structures or objects are hard to map onto modern processor\narchitectures efficiently.\n  The work in this paper introduces a new abstract machine framework, cphVB,\nthat enables vector oriented high-level programming languages to map onto a\nbroad range of architectures efficiently. The idea is to close the gap between\nhigh-level languages and hardware optimized low-level implementations. By\ntranslating high-level vector operations into an intermediate vector bytecode,\ncphVB enables specialized vector engines to efficiently execute the vector\noperations.\n  The primary success parameters are to maintain a complete abstraction from\nlow-level details and to provide efficient code execution across different,\nmodern, processors. We evaluate the presented design through a setup that\ntargets multi-core CPU architectures. We evaluate the performance of the\nimplementation using Python implementations of well-known algorithms: a jacobi\nsolver, a kNN search, a shallow water simulation and a synthetic stencil\nsimulation. All demonstrate good performance.\n", "versions": [{"version": "v1", "created": "Fri, 26 Oct 2012 12:03:08 GMT"}, {"version": "v2", "created": "Mon, 25 Mar 2013 15:18:56 GMT"}], "update_date": "2013-03-26", "authors_parsed": [["Kristensen", "Mads Ruben Burgdorff", ""], ["Lund", "Simon Andreas Frimann", ""], ["Blum", "Troels", ""], ["Vinter", "Brian", ""]]}, {"id": "1210.7935", "submitter": "Vivek Chalotra", "authors": "Vivek Chalotra, Anju Bhasin, Anik Gupta, Sanjeev Singh Sambyal, Sanjay\n  Mahajan", "title": "Energy Efficient Algorithms and Power Consumption Techniques in High\n  Performance Computing", "comments": "5 pages, 4 figures & Presented at 8th JKSC,Srinagar, J&K, India", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High Performance Computing is an internet based computing which makes\ncomputer infrastructure and services available to the user for research\npurpose. However, an important issue which needs to be resolved before High\nPerformance Computing Cluster with large pool of servers gain widespread\nacceptance is the design of data centers with less energy consumption. It is\nonly possible when servers produce less heat and consume less power. Systems\nreliability decreases with increase in temperature due to heat generation\ncaused by large power consumption as computing in high temperature is more\nerror-prone. Here in this paper our approach is to design and implement a high\nperformance cluster for high-end research in the High Energy Physics stream.\nThis involves the usage of fine grained power gating technique in\nmicroprocessors and energy efficient algorithms that reduce the overall running\ncost of the data center.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2012 09:14:40 GMT"}], "update_date": "2015-03-13", "authors_parsed": [["Chalotra", "Vivek", ""], ["Bhasin", "Anju", ""], ["Gupta", "Anik", ""], ["Sambyal", "Sanjeev Singh", ""], ["Mahajan", "Sanjay", ""]]}, {"id": "1210.7954", "submitter": "Jakarin Chawachat", "authors": "Jakarin Chawachat, Jittat Fakcharoenphol", "title": "A simpler load-balancing algorithm for range-partitioned data in\n  peer-to-peer systems", "comments": "(21 pages, 3 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Random hashing is a standard method to balance loads among nodes in\nPeer-to-Peer networks. However, hashing destroys locality properties of object\nkeys, the critical properties to many applications, more specifically, those\nthat require range searching. To preserve a key order while keeping loads\nbalanced, Ganesan, Bawa and Garcia-Molina proposed a load-balancing algorithm\nthat supports both object insertion and deletion that guarantees a ratio of\n4.237 between the maximum and minimum loads among nodes in the network using\nconstant amortized costs. However, their algorithm is not straightforward to\nimplement in real networks because it is recursive. Their algorithm mostly uses\nlocal operations with global max-min load information. In this work, we present\na simple non-recursive algorithm using essentially the same primitive\noperations as in Ganesan {\\em et al.}'s work. We prove that for insertion and\ndeletion, our algorithm guarantees a constant max-min load ratio of 7.464 with\nconstant amortized costs.\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2012 10:39:58 GMT"}, {"version": "v2", "created": "Sun, 28 Apr 2013 14:19:29 GMT"}], "update_date": "2013-04-30", "authors_parsed": [["Chawachat", "Jakarin", ""], ["Fakcharoenphol", "Jittat", ""]]}, {"id": "1210.8129", "submitter": "Sunil K.  Narang", "authors": "Sunil K. Narang and Antonio Ortega", "title": "Compact Support Biorthogonal Wavelet Filterbanks for Arbitrary\n  Undirected Graphs", "comments": "Submitted for review in IEEE TSP", "journal-ref": null, "doi": "10.1109/TSP.2013.2273197", "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our recent work, we proposed the design of perfect reconstruction\northogonal wavelet filterbanks, called graph- QMF, for arbitrary undirected\nweighted graphs. In that formulation we first designed \"one-dimensional\"\ntwo-channel filterbanks on bipartite graphs, and then extended them to\n\"multi-dimensional\" separable two-channel filterbanks for arbitrary graphs via\na bipartite subgraph decomposition. We specifically designed wavelet filters\nbased on the spectral decomposition of the graph, and stated necessary and\nsufficient conditions for a two-channel graph filter-bank on bipartite graphs\nto provide aliasing-cancellation, perfect reconstruction and orthogonal set of\nbasis (orthogonality). While, the exact graph-QMF designs satisfy all the above\nconditions, they are not exactly k-hop localized on the graph. In this paper,\nwe relax the condition of orthogonality to design a biorthogonal pair of\ngraph-wavelets that can have compact spatial spread and still satisfy the\nperfect reconstruction conditions. The design is analogous to the standard\nCohen-Daubechies-Feauveau's (CDF) construction of factorizing a maximally-flat\nDaubechies half-band filter. Preliminary results demonstrate that the proposed\nfilterbanks can be useful for both standard signal processing applications as\nwell as for signals defined on arbitrary graphs.\n  Note: Code examples from this paper are available at\nhttp://biron.usc.edu/wiki/index.php/Graph Filterbanks\n", "versions": [{"version": "v1", "created": "Tue, 30 Oct 2012 19:33:35 GMT"}, {"version": "v2", "created": "Mon, 19 Nov 2012 19:29:19 GMT"}], "update_date": "2015-06-11", "authors_parsed": [["Narang", "Sunil K.", ""], ["Ortega", "Antonio", ""]]}, {"id": "1210.8242", "submitter": "Sandeep Gupta", "authors": "Sandeep Gupta", "title": "Pipelined Workflow in Hybrid MPI/Pthread runtime for External Memory\n  Graph Construction", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graph construction from a given set of edges is a data-intensive operator\nthat appears in social network analysis, ontology enabled databases, and, other\nanalytics processing. The operator represents an edge list to compressed sparse\nrow (CSR) representation (or sometimes in adjacency list, or as clustered\nB-Tree storage). In this work, we show how to scale CSR construction to massive\nscale on SSD-enabled supercomputers such as Gordon using pipelined processing.\nWe develop several abstraction and operations for external memory and parallel\nedge list and integer array processing that are utilized towards building a\nscalable algorithm for creating CSR representation.\n  Our experiments demonstrate that this scheme is four to six times faster than\ncurrently available implementation. Moreover, our scheme can handle up to 8\nbillion edges (128GB) by using external memory as compared to prior schemes\nwhere performance degrades considerably for edge list size 26 million and\nbeyond.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 06:29:10 GMT"}], "update_date": "2012-11-01", "authors_parsed": [["Gupta", "Sandeep", ""]]}, {"id": "1210.8439", "submitter": "Bernhard Haeupler", "authors": "Mohsen Ghaffari, Bernhard Haeupler", "title": "Near Optimal Leader Election in Multi-Hop Radio Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present distributed randomized leader election protocols for multi-hop\nradio networks that elect a leader in almost the same time $T_{BC}$ required\nfor broadcasting a message. For the setting without collision detection, our\nalgorithm runs with high probability in $O(D \\log \\frac{n}{D} + \\log^3 n)\n\\min\\{\\log\\log n,\\log \\frac{n}{D}\\}$ rounds on any $n$-node network with\ndiameter $D$. Since $T_{BC} = \\Theta(D \\log \\frac{n}{D} + \\log^2 n)$ is a lower\nbound, our upper bound is optimal up to a factor of at most $\\log \\log n$ and\nthe extra $\\log n$ factor on the additive term. This algorithm is furthermore\nthe first $O(n)$ time algorithm for this setting.\n  Our algorithms improve over a 25 year old simulation approach of Bar-Yehuda,\nGoldreich and Itai with a $O(T_{BC} \\log n)$ running time: In 1987 they\ndesigned a fast broadcast protocol and subsequently in 1989 they showed how it\ncan be used to simulate one round of a single-hop network that has collision\ndetection in $T_{BC}$ time. The prime application of this simulation was to\nsimulate Willards single-hop leader election protocol, which elects a leader in\n$O(\\log n)$ rounds with high probability and $O(\\log \\log n)$ rounds in\nexpectation. While it was subsequently shown that Willards bounds are tight, it\nwas unclear whether the simulation approach is optimal. Our results break this\nbarrier and essentially remove the logarithmic slowdown over the broadcast time\n$T_{BC}$ by going away from the simulation approach.\n  We also give a distributed randomized leader election algorithm for the\nsetting with collision detection that runs in $O(D + \\log n \\log \\log n) \\cdot\n\\min\\{\\log \\log n, \\log \\frac{n}{D}\\}$ rounds. This round complexity is optimal\nup to $O(\\log \\log n)$ factors and improves over a deterministic algorithm that\nrequires $\\Theta(n)$ rounds independently of the diameter $D$.\n", "versions": [{"version": "v1", "created": "Wed, 31 Oct 2012 18:55:48 GMT"}, {"version": "v2", "created": "Thu, 3 Apr 2014 06:18:23 GMT"}], "update_date": "2014-04-04", "authors_parsed": [["Ghaffari", "Mohsen", ""], ["Haeupler", "Bernhard", ""]]}]