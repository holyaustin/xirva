[{"id": "1504.00204", "submitter": "Alex Horn", "authors": "Alex Horn and Daniel Kroening", "title": "Faster linearizability checking via $P$-compositionality", "comments": "15 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Linearizability is a well-established consistency and correctness criterion\nfor concurrent data types. An important feature of linearizability is Herlihy\nand Wing's locality principle, which says that a concurrent system is\nlinearizable if and only if all of its constituent parts (so-called objects)\nare linearizable. This paper presents $P$-compositionality, which generalizes\nthe idea behind the locality principle to operations on the same concurrent\ndata type. We implement $P$-compositionality in a novel linearizability\nchecker. Our experiments with over nine implementations of concurrent sets,\nincluding Intel's TBB library, show that our linearizability checker is one\norder of magnitude faster and/or more space efficient than the state-of-the-art\nalgorithm.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2015 12:46:38 GMT"}], "update_date": "2015-04-02", "authors_parsed": [["Horn", "Alex", ""], ["Kroening", "Daniel", ""]]}, {"id": "1504.00316", "submitter": "Christos Filippidis", "authors": "Christos Filippidis, Yiannis Cotronis, Christos Markou", "title": "Using IKAROS to provide Scalable I/O bandwidth", "comments": "This paper has been withdrawn by the author, it needs more in-depth\n  analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present IKAROS as a utility that permit us to form scalable storage\nplatforms. IKAROS enable us to create ad-hoc nearby storage formations and use\na huge number of I/O nodes in order to increase the available bandwidth. We\nmeasure the performance and scalability of IKAROS versus the IBMs General\nParallel File System (GPFS) under a variety of conditions. The measurements are\nbased on benchmark programs that allow us to vary block sizes and to measure\naggregate throughput rates.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2015 17:58:23 GMT"}, {"version": "v2", "created": "Sat, 9 Apr 2016 06:38:46 GMT"}], "update_date": "2016-04-12", "authors_parsed": [["Filippidis", "Christos", ""], ["Cotronis", "Yiannis", ""], ["Markou", "Christos", ""]]}, {"id": "1504.00390", "submitter": "Lavanya Subramanian", "authors": "Lavanya Subramanian, Donghyuk Lee, Vivek Seshadri, Harsha Rastogi,\n  Onur Mutlu", "title": "The Blacklisting Memory Scheduler: Balancing Performance, Fairness and\n  Complexity", "comments": null, "journal-ref": null, "doi": null, "report-no": "SAFARI Technical Report No. 2015-004", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a multicore system, applications running on different cores interfere at\nmain memory. This inter-application interference degrades overall system\nperformance and unfairly slows down applications. Prior works have developed\napplication-aware memory schedulers to tackle this problem. State-of-the-art\napplication-aware memory schedulers prioritize requests of applications that\nare vulnerable to interference, by ranking individual applications based on\ntheir memory access characteristics and enforcing a total rank order.\n  In this paper, we observe that state-of-the-art application-aware memory\nschedulers have two major shortcomings. First, such schedulers trade off\nhardware complexity in order to achieve high performance or fairness, since\nranking applications with a total order leads to high hardware complexity.\nSecond, ranking can unfairly slow down applications that are at the bottom of\nthe ranking stack. To overcome these shortcomings, we propose the Blacklisting\nMemory Scheduler (BLISS), which achieves high system performance and fairness\nwhile incurring low hardware complexity, based on two observations. First, we\nfind that, to mitigate interference, it is sufficient to separate applications\ninto only two groups. Second, we show that this grouping can be efficiently\nperformed by simply counting the number of consecutive requests served from\neach application.\n  We evaluate BLISS across a wide variety of workloads/system configurations\nand compare its performance and hardware complexity, with five state-of-the-art\nmemory schedulers. Our evaluations show that BLISS achieves 5% better system\nperformance and 25% better fairness than the best-performing previous scheduler\nwhile greatly reducing critical path latency and hardware area cost of the\nmemory scheduler (by 79% and 43%, respectively), thereby achieving a good\ntrade-off between performance, fairness and hardware complexity.\n", "versions": [{"version": "v1", "created": "Wed, 1 Apr 2015 21:06:52 GMT"}], "update_date": "2015-04-03", "authors_parsed": [["Subramanian", "Lavanya", ""], ["Lee", "Donghyuk", ""], ["Seshadri", "Vivek", ""], ["Rastogi", "Harsha", ""], ["Mutlu", "Onur", ""]]}, {"id": "1504.00788", "submitter": "Gianmarco De Francisci Morales", "authors": "Muhammad Anis Uddin Nasir, Gianmarco De Francisci Morales, David\n  Garc\\'ia-Soriano, Nicolas Kourtellis, Marco Serafini", "title": "The Power of Both Choices: Practical Load Balancing for Distributed\n  Stream Processing Engines", "comments": "31st IEEE International Conference on Data Engineering (ICDE), 2015", "journal-ref": null, "doi": "10.1109/ICDE.2015.7113279", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of load balancing in distributed stream processing\nengines, which is exacerbated in the presence of skew. We introduce Partial Key\nGrouping (PKG), a new stream partitioning scheme that adapts the classical\n\"power of two choices\" to a distributed streaming setting by leveraging two\nnovel techniques: key splitting and local load estimation. In so doing, it\nachieves better load balancing than key grouping while being more scalable than\nshuffle grouping. We test PKG on several large datasets, both real-world and\nsynthetic. Compared to standard hashing, PKG reduces the load imbalance by up\nto several orders of magnitude, and often achieves nearly-perfect load balance.\nThis result translates into an improvement of up to 60% in throughput and up to\n45% in latency when deployed on a real Storm cluster.\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2015 09:24:22 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Nasir", "Muhammad Anis Uddin", ""], ["Morales", "Gianmarco De Francisci", ""], ["Garc\u00eda-Soriano", "David", ""], ["Kourtellis", "Nicolas", ""], ["Serafini", "Marco", ""]]}, {"id": "1504.00806", "submitter": "Yuri Gordienko G.", "authors": "Nikita Gordienko, Oleg Lodygensky, Gilles Fedak, Yuri Gordienko", "title": "Synergy of Volunteer Measurements and Volunteer Computing for Effective\n  Data Collecting, Processing, Simulating and Analyzing on a Worldwide Scale", "comments": "6 pages, 8 figures, 1 table. 38th International Convention on\n  Information and Communication Technology, Electronics and Microelectronics\n  (MIPRO 2015); Distributed Computing, Visualization and Biomedical Engineering\n  (DC VIS) May 25-29, 2015 (Opatija, Croatia)", "journal-ref": "38th International Convention on Information and Communication\n  Technology, Electronics and Microelectronics (MIPRO 2015); Distributed\n  Computing, Visualization and Biomedical Engineering (DC VIS) May 25-29, 2015\n  (Opatija, Croatia) 193-198", "doi": "10.1109/MIPRO.2015.7160263", "report-no": null, "categories": "cs.CY cs.DC physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper concerns the hype idea of \"Citizen Science\" and the related\nparadigm shift: to go from the passive \"volunteer computing\" to other volunteer\nactions like \"volunteer measurements\" under guidance of scientists. They can be\ncarried out by ordinary people with standard computing gadgets (smartphone,\ntablet, etc.) and the various standard sensors in them. Here the special\nattention is paid to the system of volunteer scientific measurements to study\nair showers caused by cosmic rays. The technical implementation is based on\nintegration of data about registered night flashes (by radiometric software) in\nshielded camera chip, synchronized time and GPS-data in ordinary gadgets: to\nidentify night \"air showers\" of elementary particles; to analyze the frequency\nand to map the distribution of \"air showers\" in the densely populated cities.\nThe project currently includes the students of the National Technical\nUniversity of Ukraine \"KPI\", which are compactly located in Kyiv city and\ncontribute their volunteer measurements. The technology would be very effective\nfor other applications also, especially if it will be automated (e.g., on the\nbasis of XtremWeb or/and BOINC technologies for distributed computing) and used\nin some small area with many volunteers, e.g. in local communities\n(Corporative/Community Crowd Computing).\n", "versions": [{"version": "v1", "created": "Fri, 3 Apr 2015 11:02:31 GMT"}], "update_date": "2019-07-23", "authors_parsed": [["Gordienko", "Nikita", ""], ["Lodygensky", "Oleg", ""], ["Fedak", "Gilles", ""], ["Gordienko", "Yuri", ""]]}, {"id": "1504.01039", "submitter": "Jeremy Kepner", "authors": "Jeremy Kepner, David Bade, Ayd{\\i}n Buluc, John Gilbert, Timothy\n  Mattson, Henning Meyerhenke", "title": "Graphs, Matrices, and the GraphBLAS: Seven Good Reasons", "comments": "10 pages; International Conference on Computational Science workshop\n  on the Applications of Matrix Computational Methods in the Analysis of Modern\n  Data", "journal-ref": "Procedia Computer Science Volume 51, 2015, Pages 2453-2462,\n  International Conference On Computational Science", "doi": "10.1016/j.procs.2015.05.353", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The analysis of graphs has become increasingly important to a wide range of\napplications. Graph analysis presents a number of unique challenges in the\nareas of (1) software complexity, (2) data complexity, (3) security, (4)\nmathematical complexity, (5) theoretical analysis, (6) serial performance, and\n(7) parallel performance. Implementing graph algorithms using matrix-based\napproaches provides a number of promising solutions to these challenges. The\nGraphBLAS standard (istc- bigdata.org/GraphBlas) is being developed to bring\nthe potential of matrix based graph algorithms to the broadest possible\naudience. The GraphBLAS mathematically defines a core set of matrix-based graph\noperations that can be used to implement a wide class of graph algorithms in a\nwide range of programming environments. This paper provides an introduction to\nthe GraphBLAS and describes how the GraphBLAS can be used to address many of\nthe challenges associated with analysis of graphs.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2015 19:11:38 GMT"}], "update_date": "2016-06-21", "authors_parsed": [["Kepner", "Jeremy", ""], ["Bade", "David", ""], ["Buluc", "Ayd\u0131n", ""], ["Gilbert", "John", ""], ["Mattson", "Timothy", ""], ["Meyerhenke", "Henning", ""]]}, {"id": "1504.01042", "submitter": "Xianghui Cao", "authors": "Wenlong Shen, Bo Yin, Xianghui Cao, and Yu Cheng", "title": "A Distributed Secure Outsourcing Scheme for Solving Linear Algebraic\n  Equations in Ad Hoc Clouds", "comments": "This paper has been withdrawn by the authors due to incompleteness of\n  the security analysis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The emerging ad hoc clouds form a new cloud computing paradigm by leveraging\nuntapped local computation and storage resources. An important application\napplication over ad hoc clouds is outsourcing computationally intensive\nproblems to nearby cloud agents to solve in a distributed manner.\n", "versions": [{"version": "v1", "created": "Sat, 4 Apr 2015 19:32:14 GMT"}, {"version": "v2", "created": "Fri, 14 Aug 2015 02:48:53 GMT"}, {"version": "v3", "created": "Tue, 16 Aug 2016 15:17:48 GMT"}, {"version": "v4", "created": "Mon, 29 Aug 2016 03:19:25 GMT"}], "update_date": "2016-08-30", "authors_parsed": [["Shen", "Wenlong", ""], ["Yin", "Bo", ""], ["Cao", "Xianghui", ""], ["Cheng", "Yu", ""]]}, {"id": "1504.01130", "submitter": "Radu Grigore", "authors": "Maria Bruna, Radu Grigore, Stefan Kiefer, Jo\\\"el Ouaknine, James\n  Worrell", "title": "Proving the Herman-Protocol Conjecture", "comments": "ICALP 2016", "journal-ref": null, "doi": "10.4230/LIPIcs.ICALP.2016.104", "report-no": null, "categories": "cs.DS cs.CC cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Herman's self-stabilisation algorithm, introduced 25 years ago, is a\nwell-studied synchronous randomised protocol for enabling a ring of $N$\nprocesses collectively holding any odd number of tokens to reach a stable state\nin which a single token remains. Determining the worst-case expected time to\nstabilisation is the central outstanding open problem about this protocol. It\nis known that there is a constant $h$ such that any initial configuration has\nexpected stabilisation time at most $h N^2$. Ten years ago, McIver and Morgan\nestablished a lower bound of $4/27 \\approx 0.148$ for $h$, achieved with three\nequally-spaced tokens, and conjectured this to be the optimal value of $h$. A\nseries of papers over the last decade gradually reduced the upper bound on $h$,\nwith the present record (achieved in 2014) standing at approximately $0.156$.\nIn this paper, we prove McIver and Morgan's conjecture and establish that $h =\n4/27$ is indeed optimal.\n", "versions": [{"version": "v1", "created": "Sun, 5 Apr 2015 15:55:55 GMT"}, {"version": "v2", "created": "Wed, 15 Jul 2015 15:17:53 GMT"}, {"version": "v3", "created": "Wed, 27 Apr 2016 22:34:01 GMT"}], "update_date": "2017-10-12", "authors_parsed": [["Bruna", "Maria", ""], ["Grigore", "Radu", ""], ["Kiefer", "Stefan", ""], ["Ouaknine", "Jo\u00ebl", ""], ["Worrell", "James", ""]]}, {"id": "1504.01257", "submitter": "Lakshmi H.N", "authors": "Lakshmi H N, Hrushikesha Mohanty", "title": "Usages of Composition Search Tree in Web Service Composition", "comments": "11 Pages ISSN : 0973-8215 IK International Publishing House Pvt.\n  Ltd., New Delhi, India", "journal-ref": "International Journal of Information Processing, 9(1), 28-37, 2015", "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The increasing availability of web services within an organization and on the\nWeb demands for efficient search and composition mechanisms to find services\nsatisfying user requirements. Often consumers may be unaware of exact service\nnames that is fixed by service providers. Rather consumers being well aware of\ntheir requirements would like to search a service based on their commitments\n(inputs) and expectations (outputs). Based on this concept we have explored the\nfeasibility of I/O based web service search and composition in our previous\nwork. The classical definition of service composition, i.e., one-to-one and\nonto mapping between input and output sets of composing services, is extended\nto give rise to three types of service match: Exact, Super and Partial match.\nBased on matches of all three types, different kinds of compositions are\ndefined: Exact, Super and Collaborative Composition. Process of composition,\nbeing a match between inputs and outputs of services, is hastened by making use\nof information on service dependency that is made available in repository as an\none time preprocessed information obtained from services populating the\nregistry. Adopting three schemes for matching for a desired service outputs,\nthe possibility of having different kinds of compositions is demonstrated in\nform of a Composition Search Tree. As an extension to our previous work, in\nthis paper, we propose the utility of Composition Search Tree for finding\ncompositions of interest like leanest and the shortest depth compositions.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 10:49:16 GMT"}], "update_date": "2015-04-07", "authors_parsed": [["N", "Lakshmi H", ""], ["Mohanty", "Hrushikesha", ""]]}, {"id": "1504.01352", "submitter": "Sai Praneeth Reddy K", "authors": "Sai Praneeth Reddy, Dariusz R. Kowalski, and Shailesh Vaya", "title": "Multi-Broadcasting under the SINR Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the multi-broadcast problem in multi-hop wireless networks under the\nSINR model deployed in the 2D Euclidean plane. In multi-broadcast, there are\n$k$ initial rumours, potentially belonging to different nodes, that must be\nforwarded to all $n$ nodes of the network. Furthermore, in each round a node\ncan only transmit a small message that could contain at most one initial rumor\nand $O(\\log n)$ control bits. In order to be successfully delivered to a node,\ntransmissions must satisfy the (Signal-to-Inference-and-Noise-Ratio) SINR\ncondition and have sufficiently strong signal at the receiver. We present\ndeterministic algorithms for multi-broadcast for different settings that\nreflect the different types of knowledge about the topology of the network\navailable to the nodes: (i) the whole network topology (ii) their own\ncoordinates and coordinates of their neighbors (iii) only their own\ncoordinates, and (iv) only their own ids and the ids of their neighbors. For\nthe former two settings, we present solutions that are scalable with respect to\nthe diameter of the network and the polylogarithm of the network size, i.e.,\n$\\log^c n$ for some constant $c> 0$, while the solutions for the latter two\nhave round complexity that is superlinear in the number of nodes. The last\nresult is of special significance, as it is the first result for the SINR model\nthat does not require nodes to know their coordinates in the plane (a very\nspecialized type of knowledge), but intricately exploits the understanding that\nnodes are implanted in the 2D Euclidean plane.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 18:55:28 GMT"}], "update_date": "2015-04-08", "authors_parsed": [["Reddy", "Sai Praneeth", ""], ["Kowalski", "Dariusz R.", ""], ["Vaya", "Shailesh", ""]]}, {"id": "1504.01381", "submitter": "Hyungmin Cho", "authors": "Hyungmin Cho, Chen-Yong Cher, Thomas Shepherd, Subhasish Mitra", "title": "Understanding Soft Errors in Uncore Components", "comments": "to be published in Proceedings of the 52nd Annual Design Automation\n  Conference", "journal-ref": null, "doi": "10.1145/2744769.2744923", "report-no": null, "categories": "cs.OH cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The effects of soft errors in processor cores have been widely studied.\nHowever, little has been published about soft errors in uncore components, such\nas memory subsystem and I/O controllers, of a System-on-a-Chip (SoC). In this\nwork, we study how soft errors in uncore components affect system-level\nbehaviors. We have created a new mixed-mode simulation platform that combines\nsimulators at two different levels of abstraction, and achieves 20,000x speedup\nover RTL-only simulation. Using this platform, we present the first study of\nthe system-level impact of soft errors inside various uncore components of a\nlarge-scale, multi-core SoC using the industrial-grade, open-source OpenSPARC\nT2 SoC design. Our results show that soft errors in uncore components can\nsignificantly impact system-level reliability. We also demonstrate that uncore\nsoft errors can create major challenges for traditional system-level checkpoint\nrecovery techniques. To overcome such recovery challenges, we present a new\nreplay recovery technique for uncore components belonging to the memory\nsubsystem. For the L2 cache controller and the DRAM controller components of\nOpenSPARC T2, our new technique reduces the probability that an application run\nfails to produce correct results due to soft errors by more than 100x with\n3.32% and 6.09% chip-level area and power impact, respectively.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 16:22:00 GMT"}, {"version": "v2", "created": "Wed, 8 Apr 2015 17:57:02 GMT"}, {"version": "v3", "created": "Fri, 8 May 2015 17:20:49 GMT"}], "update_date": "2015-05-11", "authors_parsed": [["Cho", "Hyungmin", ""], ["Cher", "Chen-Yong", ""], ["Shepherd", "Thomas", ""], ["Mitra", "Subhasish", ""]]}, {"id": "1504.01438", "submitter": "Seyed Rasoul Etesami", "authors": "Tamer Basar, Seyed Rasoul Etesami, Alex Olshevsky", "title": "Convergence Time of Quantized Metropolis Consensus Over Time-Varying\n  Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC cs.MA math.OC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the quantized consensus problem on undirected time-varying\nconnected graphs with n nodes, and devise a protocol with fast convergence time\nto the set of consensus points. Specifically, we show that when the edges of\neach network in a sequence of connected time-varying networks are activated\nbased on Poisson processes with Metropolis rates, the expected convergence time\nto the set of consensus points is at most O(n^2 log^2 n), where each node\nperforms a constant number of updates per unit time.\n", "versions": [{"version": "v1", "created": "Mon, 6 Apr 2015 23:28:08 GMT"}, {"version": "v2", "created": "Tue, 2 Feb 2016 22:27:32 GMT"}], "update_date": "2016-02-04", "authors_parsed": [["Basar", "Tamer", ""], ["Etesami", "Seyed Rasoul", ""], ["Olshevsky", "Alex", ""]]}, {"id": "1504.01623", "submitter": "Yoann Dieudonn\\'e", "authors": "S\\'ebastien Bouchard, Yoann Dieudonn\\'e and Bertrand Ducourthial", "title": "Byzantine Gathering in Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates an open problem introduced in [14]. Two or more\nmobile agents start from different nodes of a network and have to accomplish\nthe task of gathering which consists in getting all together at the same node\nat the same time. An adversary chooses the initial nodes of the agents and\nassigns a different positive integer (called label) to each of them. Initially,\neach agent knows its label but does not know the labels of the other agents or\ntheir positions relative to its own. Agents move in synchronous rounds and can\ncommunicate with each other only when located at the same node. Up to f of the\nagents are Byzantine. A Byzantine agent can choose an arbitrary port when it\nmoves, can convey arbitrary information to other agents and can change its\nlabel in every round, in particular by forging the label of another agent or by\ncreating a completely new one.\n  What is the minimum number M of good agents that guarantees deterministic\ngathering of all of them, with termination?\n  We provide exact answers to this open problem by considering the case when\nthe agents initially know the size of the network and the case when they do\nnot. In the former case, we prove M=f+1 while in the latter, we prove M=f+2.\nMore precisely, for networks of known size, we design a deterministic algorithm\ngathering all good agents in any network provided that the number of good\nagents is at least f+1. For networks of unknown size, we also design a\ndeterministic algorithm ensuring the gathering of all good agents in any\nnetwork but provided that the number of good agents is at least f+2. Both of\nour algorithms are optimal in terms of required number of good agents, as each\nof them perfectly matches the respective lower bound on M shown in [14], which\nis of f+1 when the size of the network is known and of f+2 when it is unknown.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2015 14:40:31 GMT"}, {"version": "v2", "created": "Thu, 9 Apr 2015 12:56:52 GMT"}, {"version": "v3", "created": "Mon, 27 Apr 2015 06:38:07 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Bouchard", "S\u00e9bastien", ""], ["Dieudonn\u00e9", "Yoann", ""], ["Ducourthial", "Bertrand", ""]]}, {"id": "1504.01650", "submitter": "Adam Strzelecki", "authors": "Piotr Bialas and Adam Strzelecki", "title": "Benchmarking the cost of thread divergence in CUDA", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  All modern processors include a set of vector instructions. While this gives\na tremendous boost to the performance, it requires a vectorized code that can\ntake advantage of such instructions. As an ideal vectorization is hard to\nachieve in practice, one has to decide when different instructions may be\napplied to different elements of the vector operand. This is especially\nimportant in implicit vectorization as in NVIDIA CUDA Single Instruction\nMultiple Threads (SIMT) model, where the vectorization details are hidden from\nthe programmer. In order to assess the costs incurred by incompletely\nvectorized code, we have developed a micro-benchmark that measures the\ncharacteristics of the CUDA thread divergence model on different architectures\nfocusing on the loops performance.\n", "versions": [{"version": "v1", "created": "Tue, 7 Apr 2015 15:53:48 GMT"}], "update_date": "2015-04-08", "authors_parsed": [["Bialas", "Piotr", ""], ["Strzelecki", "Adam", ""]]}, {"id": "1504.01828", "submitter": "Miranda Zhang", "authors": "Miranda Zhang, Rajiv Ranjan, Michael Menzel, Surya Nepal, Peter\n  Strazdins and Lizhe Wang", "title": "A Cloud Infrastructure Service Recommendation System for Optimizing\n  Real-time QoS Provisioning Constraints", "comments": "IEEE Systems Journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proliferation of cloud computing has revolutionized hosting and delivery of\nInternet-based application services. However, with the constant launch of new\ncloud services and capabilities almost every month by both big (e.g., Amazon\nWeb Service, Microsoft Azure) and small companies (e.g. Rackspace, Ninefold),\ndecision makers (e.g. application developers, CIOs) are likely to be\noverwhelmed by choices available. The decision making problem is further\ncomplicated due to heterogeneous service configurations and application\nprovisioning Quality of Service (QoS) constraints. To address this hard\nchallenge, in our previous work we developed a semi-automated, extensible, and\nontology-based approach to infrastructure service discovery and selection based\non only design time constraints (e.g., renting cost, datacentre location,\nservice feature, etc.). In this paper, we extend our approach to include the\nreal-time (run-time) QoS (endto- end message latency, end-to-end message\nthroughput) in the decision making process. Hosting of next generation\napplications in domain of on-line interactive gaming, large scale sensor\nanalytics, and real-time mobile applications on cloud services necessitates\noptimization of such real-time QoS constraints for meeting Service Level\nAgreements (SLAs). To this end, we present a real-time QoS aware multi-criteria\ndecision making technique that builds over well known Analytics Hierarchy\nProcess (AHP) method. The proposed technique is applicable to selecting\nInfrastructure as a Service (IaaS) cloud offers, and it allows users to define\nmultiple design-time and real-time QoS constraints or requirements. These\nrequirements are then matched against our knowledge base to compute possible\nbest fit combinations of cloud services at IaaS layer. We conducted extensive\nexperiments to prove the feasibility of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2015 04:32:18 GMT"}], "update_date": "2015-04-09", "authors_parsed": [["Zhang", "Miranda", ""], ["Ranjan", "Rajiv", ""], ["Menzel", "Michael", ""], ["Nepal", "Surya", ""], ["Strazdins", "Peter", ""], ["Wang", "Lizhe", ""]]}, {"id": "1504.02147", "submitter": "Thomas Goldstein", "authors": "Tom Goldstein, Gavin Taylor, Kawika Barabin, Kent Sayre", "title": "Unwrapping ADMM: Efficient Distributed Computing via Transpose Reduction", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent approaches to distributed model fitting rely heavily on consensus\nADMM, where each node solves small sub-problems using only local data. We\npropose iterative methods that solve {\\em global} sub-problems over an entire\ndistributed dataset. This is possible using transpose reduction strategies that\nallow a single node to solve least-squares over massive datasets without\nputting all the data in one place. This results in simple iterative methods\nthat avoid the expensive inner loops required for consensus methods. To\ndemonstrate the efficiency of this approach, we fit linear classifiers and\nsparse linear models to datasets over 5 Tb in size using a distributed\nimplementation with over 7000 cores in far less time than previous approaches.\n", "versions": [{"version": "v1", "created": "Wed, 8 Apr 2015 22:35:18 GMT"}], "update_date": "2015-04-10", "authors_parsed": [["Goldstein", "Tom", ""], ["Taylor", "Gavin", ""], ["Barabin", "Kawika", ""], ["Sayre", "Kent", ""]]}, {"id": "1504.02205", "submitter": "Rui Han", "authors": "Rui Han, Shulin Zhan, Chenrong Shao, Junwei Wang, Lizy K. John,\n  Jiangtao Xu, Gang Lu, Lei Wang", "title": "BigDataBench-MT: A Benchmark Tool for Generating Realistic Mixed Data\n  Center Workloads", "comments": "12 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-running service workloads (e.g. web search engine) and short-term data\nanalysis workloads (e.g. Hadoop MapReduce jobs) co-locate in today's data\ncenters. Developing realistic benchmarks to reflect such practical scenario of\nmixed workload is a key problem to produce trustworthy results when evaluating\nand comparing data center systems. This requires using actual workloads as well\nas guaranteeing their submissions to follow patterns hidden in real-world\ntraces. However, existing benchmarks either generate actual workloads based on\nprobability models, or replay real-world workload traces using basic I/O\noperations. To fill this gap, we propose a benchmark tool that is a first step\ntowards generating a mix of actual service and data analysis workloads on the\nbasis of real workload traces. Our tool includes a combiner that enables the\nreplaying of actual workloads according to the workload traces, and a\nmulti-tenant generator that flexibly scales the workloads up and down according\nto users' requirements. Based on this, our demo illustrates the workload\ncustomization and generation process using a visual interface. The proposed\ntool, called BigDataBench-MT, is a multi-tenant version of our comprehensive\nbenchmark suite BigDataBench and it is publicly available from\nhttp://prof.ict.ac.cn/BigDataBench/multi-tenancyversion/.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2015 07:15:24 GMT"}, {"version": "v2", "created": "Sun, 19 Apr 2015 10:45:53 GMT"}, {"version": "v3", "created": "Fri, 4 Dec 2015 09:41:03 GMT"}], "update_date": "2015-12-07", "authors_parsed": [["Han", "Rui", ""], ["Zhan", "Shulin", ""], ["Shao", "Chenrong", ""], ["Wang", "Junwei", ""], ["John", "Lizy K.", ""], ["Xu", "Jiangtao", ""], ["Lu", "Gang", ""], ["Wang", "Lei", ""]]}, {"id": "1504.02264", "submitter": "Wim Vanderbauwhede", "authors": "Wim Vanderbauwhede", "title": "Model Coupling between the Weather Research and Forecasting Model and\n  the DPRI Large Eddy Simulator for Urban Flows on GPU-accelerated Multicore\n  Systems", "comments": "This work was conducted during a research visit at the Disaster\n  Prevention Research Institute of Kyoto University, supported by an EPSRC\n  Overseas Travel Grant, EP/L026201/1", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we present a novel approach to model coupling for\nshared-memory multicore systems hosting OpenCL-compliant accelerators, which we\ncall The Glasgow Model Coupling Framework (GMCF). We discuss the implementation\nof a prototype of GMCF and its application to coupling the Weather Research and\nForecasting Model and an OpenCL-accelerated version of the Large Eddy Simulator\nfor Urban Flows (LES) developed at DPRI.\n  The first stage of this work concerned the OpenCL port of the LES. The\nmethodology used for the OpenCL port is a combination of automated analysis and\ncode generation and rule-based manual parallelization. For the evaluation, the\nnon-OpenCL LES code was compiled using gfortran, fort and pgfortran}, in each\ncase with auto-parallelization and auto-vectorization. The OpenCL-accelerated\nversion of the LES achieves a 7 times speed-up on a NVIDIA GeForce GTX 480\nGPGPU, compared to the fastest possible compilation of the original code\nrunning on a 12-core Intel Xeon E5-2640.\n  In the second stage of this work, we built the Glasgow Model Coupling\nFramework and successfully used it to couple an OpenMP-parallelized WRF\ninstance with an OpenCL LES instance which runs the LES code on the GPGPI. The\nsystem requires only very minimal changes to the original code. The report\ndiscusses the rationale, aims, approach and implementation details of this\nwork.\n", "versions": [{"version": "v1", "created": "Thu, 9 Apr 2015 11:22:46 GMT"}], "update_date": "2015-04-10", "authors_parsed": [["Vanderbauwhede", "Wim", ""]]}, {"id": "1504.02547", "submitter": "Ittai Abraham", "authors": "Ittai Abraham and Danny Dolev", "title": "Byzantine Agreement with Optimal Early Stopping, Optimal Resilience and\n  Polynomial Complexity", "comments": "full version of STOC 2015 abstract", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We provide the first protocol that solves Byzantine agreement with optimal\nearly stopping ($\\min\\{f+2,t+1\\}$ rounds) and optimal resilience ($n>3t$) using\npolynomial message size and computation.\n  All previous approaches obtained sub-optimal results and used resolve rules\nthat looked only at the immediate children in the EIG (\\emph{Exponential\nInformation Gathering}) tree. At the heart of our solution are new resolve\nrules that look at multiple layers of the EIG tree.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 04:04:31 GMT"}, {"version": "v2", "created": "Tue, 14 Apr 2015 20:45:40 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Abraham", "Ittai", ""], ["Dolev", "Danny", ""]]}, {"id": "1504.02555", "submitter": "Prerna Saini", "authors": "Prerna Saini, Ankit Bansal, Abhishek Sharma", "title": "Time Critical Multitasking for Multicore Microcontroller using XMOS Kit", "comments": "18 pages, 18 figure, 9 tables,", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  This paper presents the research work on multicore microcontrollers using\nparallel, and time critical programming for the embedded systems. Due to the\nhigh complexity and limitations, it is very hard to work on the application\ndevelopment phase on such architectures. The experimental results mentioned in\nthe paper are based on xCORE multicore microcontroller form XMOS. The paper\nalso imitates multi-tasking and parallel programming for the same platform. The\ntasks assigned to multiple cores are executed simultaneously, which saves the\ntime and energy. The relative study for multicore processor and multicore\ncontroller concludes that micro architecture based controller having multiple\ncores illustrates better performance in time critical multi-tasking\nenvironment. The research work mentioned here not only illustrates the\nfunctionality of multicore microcontroller, but also express the novel\ntechnique of programming, profiling and optimization on such platforms in real\ntime environments.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 06:01:21 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Saini", "Prerna", ""], ["Bansal", "Ankit", ""], ["Sharma", "Abhishek", ""]]}, {"id": "1504.02578", "submitter": "David Terei", "authors": "David Terei, Amit Levy", "title": "Blade: A Data Center Garbage Collector", "comments": "14 pages, 9 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of high-performance distributed systems are written in\ngarbage collected languages. This removes a large class of harmful bugs from\nthese systems. However, it also introduces high tail-latency do to garbage\ncollection pause times. We address this problem through a new technique of\ngarbage collection avoidance which we call Blade. Blade is an API between the\ncollector and application developer that allows developers to leverage existing\nfailure recovery mechanisms in distributed systems to coordinate collection and\nbound the latency impact. We describe Blade and implement it for the Go\nprogramming language. We also investigate two different systems that utilize\nBlade, a HTTP load-balancer and the Raft consensus algorithm. For the\nload-balancer, we eliminate any latency introduced by the garbage collector,\nfor Raft, we bound the latency impact to a single network round-trip, (48\n{\\mu}s in our setup). In both cases, latency at the tail using Blade is up to\nthree orders of magnitude better.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 08:05:40 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Terei", "David", ""], ["Levy", "Amit", ""]]}, {"id": "1504.02611", "submitter": "EPTCS", "authors": "Alexander Heu{\\ss}ner, Christopher M. Poskitt, Claudio Corrodi,\n  Benjamin Morandi", "title": "Towards Practical Graph-Based Verification for an Object-Oriented\n  Concurrency Model", "comments": "In Proceedings GaM 2015, arXiv:1504.02448", "journal-ref": "EPTCS 181, 2015, pp. 32-47", "doi": "10.4204/EPTCS.181.3", "report-no": null, "categories": "cs.SE cs.DC cs.LO cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To harness the power of multi-core and distributed platforms, and to make the\ndevelopment of concurrent software more accessible to software engineers,\ndifferent object-oriented concurrency models such as SCOOP have been proposed.\nDespite the practical importance of analysing SCOOP programs, there are\ncurrently no general verification approaches that operate directly on program\ncode without additional annotations. One reason for this is the multitude of\npartially conflicting semantic formalisations for SCOOP (either in theory or\nby-implementation). Here, we propose a simple graph transformation system (GTS)\nbased run-time semantics for SCOOP that grasps the most common features of all\nknown semantics of the language. This run-time model is implemented in the\nstate-of-the-art GTS tool GROOVE, which allows us to simulate, analyse, and\nverify a subset of SCOOP programs with respect to deadlocks and other\nbehavioural properties. Besides proposing the first approach to verify SCOOP\nprograms by automatic translation to GTS, we also highlight our experiences of\napplying GTS (and especially GROOVE) for specifying semantics in the form of a\nrun-time model, which should be transferable to GTS models for other concurrent\nlanguages and libraries.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 09:40:14 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Heu\u00dfner", "Alexander", ""], ["Poskitt", "Christopher M.", ""], ["Corrodi", "Claudio", ""], ["Morandi", "Benjamin", ""]]}, {"id": "1504.02656", "submitter": "Gonzalo Travieso", "authors": "Gonzalo Travieso, Carlos Antonio Ruggiero, Odemir Martinez Bruno,\n  Luciano da Fontoura Costa", "title": "A complex network approach to cloud computing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.soc-ph cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has become an important means to speed up computing. One\nproblem influencing heavily the performance of such systems is the choice of\nnodes as servers responsible for executing the users' tasks. In this article we\nreport how complex networks can be used to model such a problem. More\nspecifically, we investigate the performance of the processing respectively to\ncloud systems underlain by Erdos-Renyi and Barabasi-Albert topology containing\ntwo servers. Cloud networks involving two communities not necessarily of the\nsame size are also considered in our analysis. The performance of each\nconfiguration is quantified in terms of two indices: the cost of communication\nbetween the user and the nearest server, and the balance of the distribution of\ntasks between the two servers. Regarding the latter index, the ER topology\nprovides better performance than the BA case for smaller average degrees and\nopposite behavior for larger average degrees. With respect to the cost, smaller\nvalues are found in the BA topology irrespective of the average degree. In\naddition, we also verified that it is easier to find good servers in the ER\nthan in BA. Surprisingly, balance and cost are not too much affected by the\npresence of communities. However, for a well-defined community network, we\nfound that it is important to assign each server to a different community so as\nto achieve better performance.\n", "versions": [{"version": "v1", "created": "Fri, 10 Apr 2015 12:25:43 GMT"}], "update_date": "2015-04-13", "authors_parsed": [["Travieso", "Gonzalo", ""], ["Ruggiero", "Carlos Antonio", ""], ["Bruno", "Odemir Martinez", ""], ["Costa", "Luciano da Fontoura", ""]]}, {"id": "1504.03274", "submitter": "Yu Zhang", "authors": "Yu Zhang, Georgios B. Giannakis", "title": "Distributed Stochastic Market Clearing with High-Penetration Wind Power", "comments": "To appear in IEEE Transactions on Power Systems; 12 pages and 9\n  figures", "journal-ref": null, "doi": "10.1109/TPWRS.2015.2423151", "report-no": null, "categories": "math.OC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Integrating renewable energy into the modern power grid requires\nrisk-cognizant dispatch of resources to account for the stochastic availability\nof renewables. Toward this goal, day-ahead stochastic market clearing with\nhigh-penetration wind energy is pursued in this paper based on the DC optimal\npower flow (OPF). The objective is to minimize the social cost which consists\nof conventional generation costs, end-user disutility, as well as a risk\nmeasure of the system re-dispatching cost. Capitalizing on the conditional\nvalue-at-risk (CVaR), the novel model is able to mitigate the potentially high\nrisk of the recourse actions to compensate wind forecast errors. The resulting\nconvex optimization task is tackled via a distribution-free sample average\nbased approximation to bypass the prohibitively complex high-dimensional\nintegration. Furthermore, to cope with possibly large-scale dispatchable loads,\na fast distributed solver is developed with guaranteed convergence using the\nalternating direction method of multipliers (ADMM). Numerical results tested on\na modified benchmark system are reported to corroborate the merits of the novel\nframework and proposed approaches.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2015 17:45:49 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Zhang", "Yu", ""], ["Giannakis", "Georgios B.", ""]]}, {"id": "1504.03277", "submitter": "Vincenzo De Florio", "authors": "Vincenzo De Florio and Chris Blondia", "title": "The Algorithm of Pipelined Gossiping", "comments": "Paper published in the Journal of Systems Architecture, Vol. 52\n  (2006). Elsevier", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A family of gossiping algorithms depending on a parameter permutation is\nintroduced, formalized, and discussed. Several of its members are analyzed and\ntheir asymptotic behaviour is revealed, including a member whose model and\nperformance closely follows the one of hardware pipelined processors. This\nsimilarity is exposed. An optimizing algorithm is finally proposed and\ndiscussed as a general strategy to increase the performance of the base\nalgorithms.\n", "versions": [{"version": "v1", "created": "Mon, 13 Apr 2015 17:59:00 GMT"}], "update_date": "2015-04-14", "authors_parsed": [["De Florio", "Vincenzo", ""], ["Blondia", "Chris", ""]]}, {"id": "1504.03413", "submitter": "Bhavya Kailkhura", "authors": "Bhavya Kailkhura, Swastik Brahma, Pramod K. Varshney", "title": "Consensus based Detection in the Presence of Data Falsification Attacks", "comments": null, "journal-ref": null, "doi": "10.1109/TSIPN.2016.2607119", "report-no": null, "categories": "cs.SY cs.DC stat.AP stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of detection in distributed networks in the\npresence of data falsification (Byzantine) attacks. Detection approaches\nconsidered in the paper are based on fully distributed consensus algorithms,\nwhere all of the nodes exchange information only with their neighbors in the\nabsence of a fusion center. In such networks, we characterize the negative\neffect of Byzantines on the steady-state and transient detection performance of\nthe conventional consensus based detection algorithms. To address this issue,\nwe study the problem from the network designer's perspective. More\nspecifically, we first propose a distributed weighted average consensus\nalgorithm that is robust to Byzantine attacks. We show that, under reasonable\nassumptions, the global test statistic for detection can be computed locally at\neach node using our proposed consensus algorithm. We exploit the statistical\ndistribution of the nodes' data to devise techniques for mitigating the\ninfluence of data falsifying Byzantines on the distributed detection system.\nSince some parameters of the statistical distribution of the nodes' data might\nnot be known a priori, we propose learning based techniques to enable an\nadaptive design of the local fusion or update rules.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2015 03:43:05 GMT"}], "update_date": "2017-09-29", "authors_parsed": [["Kailkhura", "Bhavya", ""], ["Brahma", "Swastik", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1504.03449", "submitter": "Vincenzo De Florio", "authors": "Vincenzo De Florio and Chris Blondia", "title": "Design Tool To Express Failure Detection Protocols", "comments": "Published in IET Software, Vol. 4, No. 2, April 2010. Institution of\n  Engineering and Technology (IET). 14 pages", "journal-ref": null, "doi": "10.1049/iet-sen.2009.0043", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Failure detection protocols---a fundamental building block for crafting\nfault-tolerant distributed systems---are in many cases described by their\nauthors making use of informal pseudo-codes of their conception. Often these\npseudo-codes use syntactical constructs that are not available in COTS\nprogramming languages such as C or C++. This translates into informal\ndescriptions that call for ad hoc interpretations and implementations. Being\ninformal, these descriptions cannot be tested by their authors, which may\ntranslate into insufficiently detailed or even faulty specifications. This\npaper tackles this problem introducing a formal syntax for those constructs and\na C library that implements them---a tool-set to express and reason about\nfailure detection protocols. The resulting specifications are longer but non\nambiguous, and eligible for becoming a standard form.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2015 08:13:05 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["De Florio", "Vincenzo", ""], ["Blondia", "Chris", ""]]}, {"id": "1504.03539", "submitter": "Mansaf Alam Dr", "authors": "Mansaf Alam, Shuchi Sethi", "title": "Detection of Information leakage in cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent research shows that colluded malware in different VMs sharing a single\nphysical host may use a resource as a channel to leak critical information.\nCovert channels employ time or storage characteristics to transmit confidential\ninformation to attackers leaving no trail.These channels were not meant for\ncommunication and hence control mechanisms do not exist. This means these\nremain undetected by traditional security measures employed in firewalls etc in\na network. The comprehensive survey to address the issue highlights that\naccurate methods for fast detection in cloud are very expensive in terms of\nstorage and processing. The proposed framework builds signature by extracting\nfeatures which accurately classify the regular from covert traffic in cloud and\nestimates difference in distribution of data under analysis by means of scores.\nIt then adds context to the signature and finally using machine learning\n(Support Vector Machines),a model is built and trained for deploying in cloud.\nThe results show that the framework proposed is high in accuracy while being\nlow cost and robust as it is tested after adding noise which is likely to exist\nin public cloud environments.\n", "versions": [{"version": "v1", "created": "Tue, 14 Apr 2015 13:35:32 GMT"}, {"version": "v2", "created": "Fri, 6 Nov 2015 09:26:35 GMT"}], "update_date": "2015-11-09", "authors_parsed": [["Alam", "Mansaf", ""], ["Sethi", "Shuchi", ""]]}, {"id": "1504.03553", "submitter": "EPTCS", "authors": "Natallia Kokash (Leiden Institute of Advanced Computer Science\n  (LIACS))", "title": "Handshaking Protocol for Distributed Implementation of Reo", "comments": "In Proceedings FOCLASA 2014, arXiv:1502.03157", "journal-ref": "EPTCS 175, 2015, pp. 1-17", "doi": "10.4204/EPTCS.175.1", "report-no": null, "categories": "cs.DC cs.PL cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reo, an exogenous channel-based coordination language, is a model for service\ncoordination wherein services communicate through connectors formed by joining\nbinary communication channels. In order to establish transactional\ncommunication among services as prescribed by connector semantics, distributed\nports exchange handshaking messages signalling which parties are ready to\nprovide or consume data. In this paper, we present a formal implementation\nmodel for distributed Reo with communication delays and outline ideas for its\nproof of correctness. To reason about Reo implementation formally, we introduce\nTimed Action Constraint Automata (TACA) and explain how to compare TACA with\nexisting automata-based semantics for Reo. We use TACA to describe handshaking\nbehavior of Reo modeling primitives and argue that in any distributed circuit\nremote Reo nodes and channels exposing such behavior commit to perform\ntransitions envisaged by the network semantics.\n", "versions": [{"version": "v1", "created": "Thu, 12 Feb 2015 02:14:37 GMT"}], "update_date": "2015-04-15", "authors_parsed": [["Kokash", "Natallia", "", "Leiden Institute of Advanced Computer Science"]]}, {"id": "1504.03878", "submitter": "Yann Busnel", "authors": "Emmanuelle Anceaume (INRIA - SUPELEC, IRISA), Yann Busnel (ENSAI,\n  INRIA - IRISA), Ernst Schulte-Geers, Bruno Sericola (INRIA - IRISA)", "title": "Optimization results for a generalized coupon collector problem", "comments": "arXiv admin note: text overlap with arXiv:1402.5245", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.IT math.IT math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study in this paper a generalized coupon collector problem, which consists\nin analyzing the time needed to collect a given number of distinct coupons that\nare drawn from a set of coupons with an arbitrary probability distribution. We\nsuppose that a special coupon called the null coupon can be drawn but never\nbelongs to any collection. In this context, we prove that the almost uniform\ndistribution, for which all the non-null coupons have the same drawing\nprobability, is the distribution which stochastically minimizes the time needed\nto collect a fixed number of distinct coupons. Moreover, we show that in a\ngiven closed subset of probability distributions, the distribution with all its\nentries, but one, equal to the smallest possible value is the one, which\nstochastically maximizes the time needed to collect a fixed number of distinct\ncoupons. An computer science application shows the utility of these results.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2015 12:13:35 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Anceaume", "Emmanuelle", "", "INRIA - SUPELEC, IRISA"], ["Busnel", "Yann", "", "ENSAI,\n  INRIA - IRISA"], ["Schulte-Geers", "Ernst", "", "INRIA - IRISA"], ["Sericola", "Bruno", "", "INRIA - IRISA"]]}, {"id": "1504.03961", "submitter": "Tao Chen", "authors": "Tao Chen, Rami Bahsoon and Xin Yao", "title": "Online QoS Modeling in the Cloud: A Hybrid and Adaptive Multi-Learners\n  Approach", "comments": "In the proceeding of the 7th IEEE/ACM International Conference on\n  Utility and Cloud Computing (UCC), London, UK, 2014", "journal-ref": null, "doi": "10.1109/UCC.2014.42", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given the on-demand nature of cloud computing, managing cloud-based services\nrequires accurate modeling for the correlation between their Quality of Service\n(QoS) and cloud configurations/resources. The resulted models need to cope with\nthe dynamic fluctuation of QoS sensitivity and interference. However, existing\nQoS modeling in the cloud are limited in terms of both accuracy and\napplicability due to their static and semi- dynamic nature. In this paper, we\npresent a fully dynamic multi- learners approach for automated and online QoS\nmodeling in the cloud. We contribute to a hybrid learners solution, which\nimproves accuracy while keeping model complexity adequate. To determine the\ninputs of QoS model at runtime, we partition the inputs space into two\nsub-spaces, each of which applies different symmetric uncertainty based\nselection techniques, and we then combine the sub-spaces results. The learners\nare also adaptive; they simultaneously allow several machine learning\nalgorithms to model QoS function and dynamically select the best model for\nprediction on the fly. We experimentally evaluate our models using RUBiS\nbenchmark and realistic FIFA 98 workload. The results show that our\nmulti-learners approach is more accurate and effective in contrast to the other\nstate-of-the-art approaches.\n", "versions": [{"version": "v1", "created": "Wed, 15 Apr 2015 16:35:40 GMT"}], "update_date": "2015-04-16", "authors_parsed": [["Chen", "Tao", ""], ["Bahsoon", "Rami", ""], ["Yao", "Xin", ""]]}, {"id": "1504.04579", "submitter": "Syed Waqar Nabi Dr", "authors": "Syed Waqar Nabi and Wim Vanderbauwhede", "title": "An Intermediate Language and Estimator for Automated Design Space\n  Exploration on FPGAs", "comments": "Pre-print and extended version of poster paper accepted at\n  international symposium on Highly Efficient Accelerators and Reconfigurable\n  Technologies (HEART2015) Boston, MA, USA, June 1-2, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present the TyTra-IR, a new intermediate language intended as a\ncompilation target for high-level language compilers and a front-end for HDL\ncode generators. We develop the requirements of this new language based on the\ndesign-space of FPGAs that it should be able to express and the\nestimation-space in which each configuration from the design-space should be\nmappable in an automated design flow. We use a simple kernel to illustrate\nmultiple configurations using the semantics of TyTra-IR. The key novelty of\nthis work is the cost model for resource-costs and throughput for different\nconfigurations of interest for a particular kernel. Through the realistic\nexample of a Successive Over-Relaxation kernel implemented both in TyTra-IR and\nHDL, we demonstrate both the expressiveness of the IR and the accuracy of our\ncost model.\n", "versions": [{"version": "v1", "created": "Fri, 17 Apr 2015 17:13:23 GMT"}], "update_date": "2015-04-20", "authors_parsed": [["Nabi", "Syed Waqar", ""], ["Vanderbauwhede", "Wim", ""]]}, {"id": "1504.04714", "submitter": "Mathias Jacquelin", "authors": "Mathias Jacquelin and Lin Lin and Nathan Wichmann and Chao Yang", "title": "Enhancing the scalability and load balancing of the parallel selected\n  inversion algorithm via tree-based asynchronous communication", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We develop a method for improving the parallel scalability of the recently\ndeveloped parallel selected inversion algorithm [Jacquelin, Lin and Yang 2014],\nnamed PSelInv, on massively parallel distributed memory machines. In the\nPSelInv method, we compute selected elements of the inverse of a sparse matrix\nA that can be decomposed as A = LU, where L is lower triangular and U is upper\ntriangular. Updating these selected elements of A-1 requires restricted\ncollective communications among a subset of processors within each column or\nrow communication group created by a block cyclic distribution of L and U. We\ndescribe how this type of restricted collective communication can be\nimplemented by using asynchronous point-to-point MPI communication functions\ncombined with a binary tree based data propagation scheme. Because multiple\nrestricted collective communications may take place at the same time in the\nparallel selected inversion algorithm, we need to use a heuristic to prevent\nprocessors participating in multiple collective communications from receiving\ntoo many messages. This heuristic allows us to reduce communication load\nimbalance and improve the overall scalability of the selected inversion\nalgorithm. For instance, when 6,400 processors are used, we observe over 5x\nspeedup for test matrices. It also mitigates the performance variability\nintroduced by an inhomogeneous network topology.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2015 12:46:33 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Jacquelin", "Mathias", ""], ["Lin", "Lin", ""], ["Wichmann", "Nathan", ""], ["Yang", "Chao", ""]]}, {"id": "1504.04720", "submitter": "Matteo Turilli", "authors": "Matteo Turilli, Feng Liu, Zhao Zhang, Andre Merzky, Michael Wilde, Jon\n  Weissman, Daniel S. Katz, Shantenu Jha", "title": "Integrating Abstractions to Enhance the Execution of Distributed\n  Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the factors that limits the scale, performance, and sophistication of\ndistributed applications is the difficulty of concurrently executing them on\nmultiple distributed computing resources. In part, this is due to a poor\nunderstanding of the general properties and performance of the coupling between\napplications and dynamic resources. This paper addresses this issue by\nintegrating abstractions representing distributed applications, resources, and\nexecution processes into a pilot-based middleware. The middleware provides a\nplatform that can specify distributed applications, execute them on multiple\nresource and for different configurations, and is instrumented to support\ninvestigative analysis. We analyzed the execution of distributed applications\nusing experiments that measure the benefits of using multiple resources, the\nlate-binding of scheduling decisions, and the use of backfill scheduling.\n", "versions": [{"version": "v1", "created": "Sat, 18 Apr 2015 13:54:49 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2016 23:13:54 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Turilli", "Matteo", ""], ["Liu", "Feng", ""], ["Zhang", "Zhao", ""], ["Merzky", "Andre", ""], ["Wilde", "Michael", ""], ["Weissman", "Jon", ""], ["Katz", "Daniel S.", ""], ["Jha", "Shantenu", ""]]}, {"id": "1504.04804", "submitter": "Yuechao Pan", "authors": "Yuechao Pan, Yangzihao Wang, Yuduo Wu, Carl Yang and John D. Owens", "title": "Multi-GPU Graph Analytics", "comments": "12 pages. Final version submitted to IPDPS 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a single-node, multi-GPU programmable graph processing library\nthat allows programmers to easily extend single-GPU graph algorithms to achieve\nscalable performance on large graphs with billions of edges. Directly using the\nsingle-GPU implementations, our design only requires programmers to specify a\nfew algorithm-dependent concerns, hiding most multi-GPU related implementation\ndetails. We analyze the theoretical and practical limits to scalability in the\ncontext of varying graph primitives and datasets. We describe several\noptimizations, such as direction optimizing traversal, and a just-enough memory\nallocation scheme, for better performance and smaller memory consumption.\nCompared to previous work, we achieve best-of-class performance across\noperations and datasets, including excellent strong and weak scalability on\nmost primitives as we increase the number of GPUs in the system.\n", "versions": [{"version": "v1", "created": "Sun, 19 Apr 2015 07:12:04 GMT"}, {"version": "v2", "created": "Wed, 13 Apr 2016 01:27:31 GMT"}, {"version": "v3", "created": "Tue, 25 Oct 2016 22:21:07 GMT"}, {"version": "v4", "created": "Wed, 1 Mar 2017 09:07:57 GMT"}], "update_date": "2017-03-02", "authors_parsed": [["Pan", "Yuechao", ""], ["Wang", "Yangzihao", ""], ["Wu", "Yuduo", ""], ["Yang", "Carl", ""], ["Owens", "John D.", ""]]}, {"id": "1504.04942", "submitter": "Samuel Benz", "authors": "Samuel Benz, Leandro Pacheco de Sousa, Fernando Pedone", "title": "Stretching Multi-Ring Paxos", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Internet-scale services rely on data partitioning and replication to provide\nscalable performance and high availability. Moreover, to reduce user-perceived\nresponse times and tolerate disasters (i.e., the failure of a whole\ndatacenter), services are increasingly becoming geographically distributed.\nData partitioning and replication, combined with local and geographical\ndistribution, introduce daunting challenges, including the need to carefully\norder requests among replicas and partitions. One way to tackle this problem is\nto use group communication primitives that encapsulate order requirements. This\npaper presents a detailed performance evaluation of Multi-Ring Paxos, a\nscalable group communication primitive. We focus our analysis on \"extreme\nconditions\" with deployments including high-end 10 Gbps networks, a large\nnumber of combined rings (i.e., independent Paxos instances), a large number of\nreplicas in a ring, and a global deployment. We also report on the performance\nof recovery under peak load and present two novel extensions to boost\nMulti-Ring Paxos's performance.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 05:56:16 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Benz", "Samuel", ""], ["de Sousa", "Leandro Pacheco", ""], ["Pedone", "Fernando", ""]]}, {"id": "1504.04974", "submitter": "Zhen Jia", "authors": "Zhen Jia, Lei Wang, Jianfeng Zhan, Lixin Zhang, Chunjie Luo, Ninghui\n  Sun", "title": "Understanding Big Data Analytic Workloads on Modern Processors", "comments": "arXiv admin note: substantial text overlap with arXiv:1307.8013", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big data analytics applications play a significant role in data centers, and\nhence it has become increasingly important to understand their behaviors in\norder to further improve the performance of data center computer systems, in\nwhich characterizing representative workloads is a key practical problem. In\nthis paper, after investigating three most impor- tant application domains in\nterms of page views and daily visitors, we chose 11 repre- sentative data\nanalytics workloads and characterized their micro-architectural behaviors by\nusing hardware performance counters, so as to understand the impacts and\nimplications of data analytics workloads on the systems equipped with modern\nsuperscalar out-of-order processors. Our study reveals that big data analytics\napplications themselves share many inherent characteristics, which place them\nin a different class from traditional workloads and scale-out services. To\nfurther understand the characteristics of big data analytics work- loads we\nperformed a correlation analysis of CPI (cycles per instruction) with other\nmicro- architecture level characteristics and an investigation of the big data\nsoftware stack impacts on application behaviors. Our correlation analysis\nshowed that even though big data ana- lytics workloads own notable pipeline\nfront end stalls, the main factors affecting the CPI performance are long\nlatency data accesses rather than the front end stalls. Our software stack\ninvestigation found that the typical big data software stack significantly\ncontributes to the front end stalls and incurs bigger working set. Finally we\ngave several recommen- dations for architects, programmers and big data system\ndesigners with the knowledge acquired from this paper.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 08:55:06 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Jia", "Zhen", ""], ["Wang", "Lei", ""], ["Zhan", "Jianfeng", ""], ["Zhang", "Lixin", ""], ["Luo", "Chunjie", ""], ["Sun", "Ninghui", ""]]}, {"id": "1504.05022", "submitter": "Weifeng Liu", "authors": "Weifeng Liu, Brian Vinter", "title": "A Framework for General Sparse Matrix-Matrix Multiplication on GPUs and\n  Heterogeneous Processors", "comments": "25 pages, 12 figures, published at Journal of Parallel and\n  Distributed Computing (JPDC)", "journal-ref": null, "doi": "10.1016/j.jpdc.2015.06.010", "report-no": null, "categories": "cs.MS cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  General sparse matrix-matrix multiplication (SpGEMM) is a fundamental\nbuilding block for numerous applications such as algebraic multigrid method\n(AMG), breadth first search and shortest path problem. Compared to other sparse\nBLAS routines, an efficient parallel SpGEMM implementation has to handle extra\nirregularity from three aspects: (1) the number of nonzero entries in the\nresulting sparse matrix is unknown in advance, (2) very expensive parallel\ninsert operations at random positions in the resulting sparse matrix dominate\nthe execution time, and (3) load balancing must account for sparse data in both\ninput matrices.\n  In this work we propose a framework for SpGEMM on GPUs and emerging CPU-GPU\nheterogeneous processors. This framework particularly focuses on the above\nthree problems. Memory pre-allocation for the resulting matrix is organized by\na hybrid method that saves a large amount of global memory space and\nefficiently utilizes the very limited on-chip scratchpad memory. Parallel\ninsert operations of the nonzero entries are implemented through the GPU merge\npath algorithm that is experimentally found to be the fastest GPU merge\napproach. Load balancing builds on the number of necessary arithmetic\noperations on the nonzero entries and is guaranteed in all stages.\n  Compared with the state-of-the-art CPU and GPU SpGEMM methods, our approach\ndelivers excellent absolute performance and relative speedups on various\nbenchmarks multiplying matrices with diverse sparsity structures. Furthermore,\non heterogeneous processors, our SpGEMM approach achieves higher throughput by\nusing re-allocatable shared virtual memory.\n  The source code of this work is available at\nhttps://github.com/bhSPARSE/Benchmark_SpGEMM_using_CSR\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 11:58:05 GMT"}, {"version": "v2", "created": "Sun, 13 Sep 2015 07:38:29 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Liu", "Weifeng", ""], ["Vinter", "Brian", ""]]}, {"id": "1504.05046", "submitter": "Eduard Valeyev", "authors": "Justus A. Calvin and Edward F. Valeev", "title": "Task-Based Algorithm for Matrix Multiplication: A Step Towards\n  Block-Sparse Tensor Computing", "comments": "submitted to SC15 (9 pages, 8 figures)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed-memory matrix multiplication (MM) is a key element of algorithms\nin many domains (machine learning, quantum physics). Conventional algorithms\nfor dense MM rely on regular/uniform data decomposition to ensure load balance.\nThese traits conflict with the irregular structure (block-sparse or rank-sparse\nwithin blocks) that is increasingly relevant for fast methods in quantum\nphysics. To deal with such irregular data we present a new MM algorithm based\non Scalable Universal Matrix Multiplication Algorithm (SUMMA). The novel\nfeatures are: (1) multiple-issue scheduling of SUMMA iterations, and (2)\nfine-grained task-based formulation. The latter eliminates the need for\nexplicit internodal synchronization; with multiple-iteration scheduling this\nallows load imbalance due to nonuniform matrix structure. For square MM with\nuniform and nonuniform block sizes (the latter simulates matrices with general\nirregular structure) we found excellent performance in weak and strong-scaling\nregimes, on commodity and high-end hardware.\n", "versions": [{"version": "v1", "created": "Mon, 20 Apr 2015 13:18:10 GMT"}], "update_date": "2015-04-21", "authors_parsed": [["Calvin", "Justus A.", ""], ["Valeev", "Edward F.", ""]]}, {"id": "1504.05692", "submitter": "Elena Hadzieva", "authors": "Elena Hadzieva, Aleksandar Simevski", "title": "Theoretical Aspects of a Design Method for Programmable NMR Voters", "comments": "11 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Almost all dependable systems use some form of redundancy in order to\nincrease fault-tolerance. Very popular are the $N$-Modular Redundant (NMR)\nsystems in which a majority voter chooses the voting output. However, elaborate\nsystems require fault-tolerant voters which further give additional information\nbesides the voting output, e.g., how many module outputs agree. Dynamically\ndefining which set of inputs should be considered for voting is also crucial.\nEarlier we showed a practical implementation of programmable NMR voters that\nself-report the voting outcome and do self-checks. Our voter design method uses\na binary matrix with specific properties that enable easy scaling of the design\nregarding the number of voter inputs N. Thus, an automated construction of NMR\nsystems is possible, given the basic module and arbitrary redundancy $N$. In\nthis paper we present the mathematical aspects of the method, i.e., we analyze\nthe properties of the matrix that characterizes the method. We give the\ncharacteristic polynomials of the properly and erroneously built matrices in\ntheir explicit forms. We further give their eigenvalues and corresponding\neigenvectors, which reveal a lot of useful information about the system. At the\nend, we give relations between the voter outputs and eigenpairs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Apr 2015 08:32:01 GMT"}], "update_date": "2015-04-23", "authors_parsed": [["Hadzieva", "Elena", ""], ["Simevski", "Aleksandar", ""]]}, {"id": "1504.06316", "submitter": "Varsha Dani", "authors": "Varsha Dani, Thomas P. Hayes, Mahnush Movahedi, Jared Saia, Maxwell\n  Young", "title": "Interactive Communication with Unknown Noise Rate", "comments": "Made substantial improvements to the algorithm and analysis. Previous\n  version had a subtle error involving the adversary's ability to attack\n  fingerprints", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Alice and Bob want to run a protocol over a noisy channel, where a certain\nnumber of bits are flipped adversarially. Several results take a protocol\nrequiring $L$ bits of noise-free communication and make it robust over such a\nchannel. In a recent breakthrough result, Haeupler described an algorithm that\nsends a number of bits that is conjectured to be near optimal in such a model.\nHowever, his algorithm critically requires $a \\ priori$ knowledge of the number\nof bits that will be flipped by the adversary.\n  We describe an algorithm requiring no such knowledge. If an adversary flips\n$T$ bits, our algorithm sends $L + O\\left(\\sqrt{L(T+1)\\log L} + T\\right)$ bits\nin expectation and succeeds with high probability in $L$. It does so without\nany $a \\ priori$ knowledge of $T$. Assuming a conjectured lower bound by\nHaeupler, our result is optimal up to logarithmic factors.\n  Our algorithm critically relies on the assumption of a private channel. We\nshow that privacy is necessary when the amount of noise is unknown.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2015 19:57:46 GMT"}, {"version": "v2", "created": "Thu, 13 Aug 2015 23:11:29 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Dani", "Varsha", ""], ["Hayes", "Thomas P.", ""], ["Movahedi", "Mahnush", ""], ["Saia", "Jared", ""], ["Young", "Maxwell", ""]]}, {"id": "1504.06357", "submitter": "Simon Hollis", "authors": "Simon J. Hollis, Steve Kerrison", "title": "Overview of Swallow --- A Scalable 480-core System for Investigating the\n  Performance and Energy Efficiency of Many-core Applications and Operating\n  Systems", "comments": "An open source release of the Swallow system design and code will\n  follow and references to these will be added at a later date", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Swallow, a scalable many-core architecture, with a current\nconfiguration of 480 x 32-bit processors.\n  Swallow is an open-source architecture, designed from the ground up to\ndeliver scalable increases in usable computational power to allow\nexperimentation with many-core applications and the operating systems that\nsupport them.\n  Scalability is enabled by the creation of a tile-able system with a\nlow-latency interconnect, featuring an attractive communication-to-computation\nratio and the use of a distributed memory configuration.\n  We analyse the energy and computational and communication performances of\nSwallow. The system provides 240GIPS with each core consuming 71--193mW,\ndependent on workload. Power consumption per instruction is lower than almost\nall systems of comparable scale.\n  We also show how the use of a distributed operating system (nOS) allows the\neasy creation of scalable software to exploit Swallow's potential. Finally, we\nshow two use case studies: modelling neurons and the overlay of shared memory\non a distributed memory system.\n", "versions": [{"version": "v1", "created": "Thu, 23 Apr 2015 22:36:46 GMT"}], "update_date": "2015-04-27", "authors_parsed": [["Hollis", "Simon J.", ""], ["Kerrison", "Steve", ""]]}, {"id": "1504.06474", "submitter": "Weifeng Liu", "authors": "Weifeng Liu, Brian Vinter", "title": "Speculative Segmented Sum for Sparse Matrix-Vector Multiplication on\n  Heterogeneous Processors", "comments": "22 pages, 8 figures, Published at Parallel Computing (PARCO)", "journal-ref": null, "doi": "10.1016/j.parco.2015.04.004", "report-no": null, "categories": "cs.MS cs.DC math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse matrix-vector multiplication (SpMV) is a central building block for\nscientific software and graph applications. Recently, heterogeneous processors\ncomposed of different types of cores attracted much attention because of their\nflexible core configuration and high energy efficiency. In this paper, we\npropose a compressed sparse row (CSR) format based SpMV algorithm utilizing\nboth types of cores in a CPU-GPU heterogeneous processor. We first\nspeculatively execute segmented sum operations on the GPU part of a\nheterogeneous processor and generate a possibly incorrect results. Then the CPU\npart of the same chip is triggered to re-arrange the predicted partial sums for\na correct resulting vector. On three heterogeneous processors from Intel, AMD\nand nVidia, using 20 sparse matrices as a benchmark suite, the experimental\nresults show that our method obtains significant performance improvement over\nthe best existing CSR-based SpMV algorithms. The source code of this work is\ndownloadable at https://github.com/bhSPARSE/Benchmark_SpMV_using_CSR\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2015 11:23:38 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2015 09:59:24 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Liu", "Weifeng", ""], ["Vinter", "Brian", ""]]}, {"id": "1504.06736", "submitter": "Mayuresh Kunjir", "authors": "Mayuresh Kunjir, Brandon Fain, Kamesh Munagala, Shivnath Babu", "title": "ROBUS: Fair Cache Allocation for Multi-tenant Data-parallel Workloads", "comments": null, "journal-ref": null, "doi": "10.1145/3035918.3064018", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Systems for processing big data---e.g., Hadoop, Spark, and massively parallel\ndatabases---need to run workloads on behalf of multiple tenants simultaneously.\nThe abundant disk-based storage in these systems is usually complemented by a\nsmaller, but much faster, {\\em cache}. Cache is a precious resource: Tenants\nwho get to use cache can see two orders of magnitude performance improvement.\nCache is also a limited and hence shared resource: Unlike a resource like a CPU\ncore which can be used by only one tenant at a time, a cached data item can be\naccessed by multiple tenants at the same time. Cache, therefore, has to be\nshared by a multi-tenancy-aware policy across tenants, each having a unique set\nof priorities and workload characteristics.\n  In this paper, we develop cache allocation strategies that speed up the\noverall workload while being {\\em fair} to each tenant. We build a novel\nfairness model targeted at the shared resource setting that incorporates not\nonly the more standard concepts of Pareto-efficiency and sharing incentive, but\nalso define envy freeness via the notion of {\\em core} from cooperative game\ntheory. Our cache management platform, ROBUS, uses randomization over small\ntime batches, and we develop a proportionally fair allocation mechanism that\nsatisfies the core property in expectation. We show that this algorithm and\nrelated fair algorithms can be approximated to arbitrary precision in\npolynomial time. We evaluate these algorithms on a ROBUS prototype implemented\non Spark with RDD store used as cache. Our evaluation on a synthetically\ngenerated industry-standard workload shows that our algorithms provide a\nspeedup close to performance optimal algorithms while guaranteeing fairness\nacross tenants.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2015 14:56:30 GMT"}, {"version": "v2", "created": "Thu, 3 Sep 2015 17:21:13 GMT"}], "update_date": "2019-02-12", "authors_parsed": [["Kunjir", "Mayuresh", ""], ["Fain", "Brandon", ""], ["Munagala", "Kamesh", ""], ["Babu", "Shivnath", ""]]}, {"id": "1504.06793", "submitter": "Andrey Shchurov", "authors": "Andrey A. Shchurov, Radek Marik, Vladimir A. Khlevnoy", "title": "A Formal Approach to Network/Distributed Systems Complex Testing", "comments": "5 pages, 1 figure", "journal-ref": "International Journal of Computer Trends and Technology (IJCTT)\n  V22(2):76-80, April 2015. ISSN:2231-2803", "doi": "10.14445/22312803/IJCTT-V22P115", "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of network/distributed systems sets high requirements for\nprocedures, tools and approaches for the complex testing of these systems. This\nwork provides a survey of testing activities with regard to these systems based\non standards and actual practices for both software-based and distribution\n(network) aspects. On the basis of this survey, we determine formal testing\nprocedures/processes which cover these aspects, but which are not contrary to\nboth aspects. The next step, based on the analysis of the implementation phase\nof System Development Life Cycle, determines a formal model for these processes\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2015 07:34:42 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Shchurov", "Andrey A.", ""], ["Marik", "Radek", ""], ["Khlevnoy", "Vladimir A.", ""]]}, {"id": "1504.06833", "submitter": "Michael Brim", "authors": "Joel Reed, Jeremy Archuleta, Michael J. Brim, Joshua Lothian", "title": "Evaluating Dynamic File Striping For Lustre", "comments": "International Workshop on the Lustre Ecosystem: Challenges and\n  Opportunities, March 2015, Annapolis MD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We define dynamic striping as the ability to assign different Lustre striping\ncharacteristics to contiguous segments of a file as it grows. In this paper, we\nevaluate the effects of dynamic striping using a watermark-based strategy where\nthe stripe count or width is increased once a file's size exceeds one of the\nchosen watermarks. To measure the performance of this strategy we used a\nmodified version of the IOR benchmark, a netflow analysis workload, and the\nblastn algorithm from NCBI BLAST. The results indicate that dynamic striping is\nbeneficial to tasks with unpredictable data file size and large sequential\nreads, but are less conclusive for workloads with significant random read\nphases.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2015 14:44:00 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Reed", "Joel", ""], ["Archuleta", "Jeremy", ""], ["Brim", "Michael J.", ""], ["Lothian", "Joshua", ""]]}, {"id": "1504.06836", "submitter": "Michael Brim", "authors": "Michael J. Brim, Joshua K. Lothian", "title": "Monitoring Extreme-scale Lustre Toolkit", "comments": "International Workshop on the Lustre Ecosystem: Challenges and\n  Opportunities, March 2015, Annapolis MD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss the design and ongoing development of the Monitoring Extreme-scale\nLustre Toolkit (MELT), a unified Lustre performance monitoring and analysis\ninfrastructure that provides continuous, low-overhead summary information on\nthe health and performance of Lustre, as well as on-demand, in- depth problem\ndiagnosis and root-cause analysis. The MELT infrastructure leverages a\ndistributed overlay network to enable monitoring of center-wide Lustre\nfilesystems where clients are located across many network domains. We preview\ninteractive command-line utilities that help administrators and users to\nobserve Lustre performance at various levels of resolution, from individual\nservers or clients to whole filesystems, including job-level reporting.\nFinally, we discuss our future plans for automating the root-cause analysis of\ncommon Lustre performance problems.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2015 14:57:05 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Brim", "Michael J.", ""], ["Lothian", "Joshua K.", ""]]}, {"id": "1504.06846", "submitter": "Ashraf Shahin", "authors": "Ashraf A. Shahin", "title": "Memetic Elitist Pareto Evolutionary Algorithm for Virtual Network\n  Embedding", "comments": "URL: http://dx.doi.org/10.5539/cis.v8n2p73. ISSN 1913-8989 E-ISSN\n  1913-8997,Published by Canadian Center of Science and Education", "journal-ref": "Computer and Information Science journal; Vol. 8, No. 2; 2015, pg.\n  73-88", "doi": "10.5539/cis.v8n2p73", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Assigning virtual network resources to physical network components, called\nVirtual Network Embedding, is a major challenge in cloud computing platforms.\nIn this paper, we propose a memetic elitist pareto evolutionary algorithm for\nvirtual network embedding problem, which is called MEPE-VNE. MEPE-VNE applies a\nnon-dominated sorting-based multi-objective evolutionary algorithm, called\nNSGA-II, to reduce computational complexity of constructing a hierarchy of\nnon-dominated Pareto fronts and assign a rank value to each virtual network\nembedding solution based on its dominance level and crowding distance value.\nLocal search is applied to enhance virtual network embedding solutions and\nspeed up convergence of the proposed algorithm. To reduce loss of good\nsolutions, MEPE-VNE ensures elitism by passing virtual network embedding\nsolutions with best fitness values to next generation. Performance of the\nproposed algorithm is evaluated and compared with existing algorithms using\nextensive simulations, which show that the proposed algorithm improves virtual\nnetwork embedding by increasing acceptance ratio and revenue while decreasing\nthe cost incurred by substrate network.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2015 16:56:28 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2015 15:53:25 GMT"}], "update_date": "2015-04-30", "authors_parsed": [["Shahin", "Ashraf A.", ""]]}, {"id": "1504.06855", "submitter": "Ashraf Shahin", "authors": "Ashraf A. Shahin", "title": "Memetic Multi-Objective Particle Swarm Optimization-Based Energy-Aware\n  Virtual Network Embedding", "comments": "arXiv admin note: text overlap with arXiv:1504.06846", "journal-ref": "IJACSA Vol. 6, No. 4, 2015", "doi": "10.14569/IJACSA.2015.060405", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cloud infrastructure, accommodating multiple virtual networks on a single\nphysical network reduces power consumed by physical resources and minimizes\ncost of operating cloud data centers. However, mapping multiple virtual network\nresources to physical network components, called virtual network embedding\n(VNE), is known to be NP-hard. With considering energy efficiency, the problem\nbecomes more complicated. In this paper, we model energy-aware virtual network\nembedding, devise metrics for evaluating performance of energy aware virtual\nnetwork-embedding algorithms, and propose an energy aware virtual\nnetwork-embedding algorithm based on multi-objective particle swarm\noptimization augmented with local search to speed up convergence of the\nproposed algorithm and improve solutions quality. Performance of the proposed\nalgorithm is evaluated and compared with existing algorithms using extensive\nsimulations, which show that the proposed algorithm improves virtual network\nembedding by increasing revenue and decreasing energy consumption.\n", "versions": [{"version": "v1", "created": "Sun, 26 Apr 2015 17:38:24 GMT"}], "update_date": "2015-05-04", "authors_parsed": [["Shahin", "Ashraf A.", ""]]}, {"id": "1504.06963", "submitter": "Szabolcs M\\'esz\\'aros", "authors": "Endre Cs\\'oka, Szabolcs M\\'esz\\'aros", "title": "Generalized solution for the Herman Protocol Conjecture", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We have a cycle of $N$ nodes and there is a token on an odd number of nodes.\nAt each step, each token independently moves to its clockwise neighbor or stays\nat its position with probability $\\frac{1}{2}$. If two tokens arrive to the\nsame node, then we remove both of them. The process ends when only one token\nremains. The question is that for a fixed $N$, which is the initial\nconfiguration that maximizes the expected number of steps $E(T)$. The Herman\nProtocol Conjecture says that the $3$-token configuration with distances\n$\\lfloor\\frac{N}{3}\\rfloor$ and $\\lceil\\frac{N}{3}\\rceil$ maximizes $E(T)$. We\npresent a proof of this conjecture not only for $E(T)$ but also for\n$E\\big(f(T)\\big)$ for some function $f:\\mathbb{N}\\rightarrow\\mathbb{R}^{+}$\nwhich method applies for different generalizations of the problem.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 08:14:33 GMT"}, {"version": "v2", "created": "Wed, 6 May 2015 06:57:25 GMT"}, {"version": "v3", "created": "Sat, 27 Jun 2015 14:01:37 GMT"}], "update_date": "2015-06-30", "authors_parsed": [["Cs\u00f3ka", "Endre", ""], ["M\u00e9sz\u00e1ros", "Szabolcs", ""]]}, {"id": "1504.07056", "submitter": "Sebastian Forster", "authors": "Monika Henzinger, Sebastian Krinninger, Danupon Nanongkai", "title": "A Deterministic Almost-Tight Distributed Algorithm for Approximating\n  Single-Source Shortest Paths", "comments": "Accepted to SIAM Journal on Computing. A preliminary version of this\n  paper was presented at the 48th ACM Symposium on Theory of Computing (STOC\n  2016). Abstract shortened to respect the arXiv limit of 1920 characters", "journal-ref": null, "doi": "10.1145/2897518.2897638", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deterministic $(1+o(1))$-approximation\n$(n^{1/2+o(1)}+D^{1+o(1)})$-time algorithm for solving the single-source\nshortest paths problem on distributed weighted networks (the CONGEST model);\nhere $n$ is the number of nodes in the network and $D$ is its (hop) diameter.\nThis is the first non-trivial deterministic algorithm for this problem. It also\nimproves (i) the running time of the randomized $(1+o(1))$-approximation\n$\\tilde O(n^{1/2}D^{1/4}+D)$-time algorithm of Nanongkai [STOC 2014] by a\nfactor of as large as $n^{1/8}$, and (ii) the $O(\\epsilon^{-1}\\log\n\\epsilon^{-1})$-approximation factor of Lenzen and Patt-Shamir's $\\tilde\nO(n^{1/2+\\epsilon}+D)$-time algorithm [STOC 2013] within the same running time.\nOur running time matches the known time lower bound of $\\Omega(n^{1/2}/\\log n +\nD)$ [Elkin STOC 2004] up to subpolynomial factors, thus essentially settling\nthe status of this problem which was raised at least a decade ago [Elkin SIGACT\nNews 2004]. It also implies a $(2+o(1))$-approximation\n$(n^{1/2+o(1)}+D^{1+o(1)})$-time algorithm for approximating a network's\nweighted diameter which almost matches the lower bound by Holzer and Pinsker\n[OPODIS 2015]. In achieving this result, we develop two techniques which might\nbe of independent interest and useful in other settings: (i) a deterministic\nprocess that replaces the \"hitting set argument\" commonly used for shortest\npaths computation in various settings, and (ii) a simple, deterministic,\nconstruction of an $(n^{o(1)}, o(1))$-hop set of size $n^{1+o(1)}$. We combine\nthese techniques with many distributed algorithmic techniques, some of which\nfrom problems that are not directly related to shortest paths, e.g., ruling\nsets [Goldberg et al. STOC 1987], source detection [Lenzen and Peleg PODC\n2013], and partial distance estimation [Lenzen and Patt-Shamir PODC 2015].\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 12:33:50 GMT"}, {"version": "v2", "created": "Wed, 27 Jan 2016 10:36:51 GMT"}, {"version": "v3", "created": "Thu, 14 Apr 2016 16:30:02 GMT"}, {"version": "v4", "created": "Fri, 7 Oct 2016 10:15:17 GMT"}, {"version": "v5", "created": "Wed, 19 Sep 2018 17:04:54 GMT"}], "update_date": "2018-09-20", "authors_parsed": [["Henzinger", "Monika", ""], ["Krinninger", "Sebastian", ""], ["Nanongkai", "Danupon", ""]]}, {"id": "1504.07127", "submitter": "Russell Martin", "authors": "Leszek Gasieniec and Tomasz Jurdzinski and Russell Martin and Grzegorz\n  Stachowiak", "title": "Deterministic Symmetry Breaking in Ring Networks", "comments": "Conference version accepted to ICDCS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study a distributed coordination mechanism for uniform agents located on a\ncircle. The agents perform their actions in synchronised rounds. At the\nbeginning of each round an agent chooses the direction of its movement from\nclockwise, anticlockwise, or idle, and moves at unit speed during this round.\nAgents are not allowed to overpass, i.e., when an agent collides with another\nit instantly starts moving with the same speed in the opposite direction\n(without exchanging any information with the other agent). However, at the end\nof each round each agent has access to limited information regarding its\ntrajectory of movement during this round.\n  We assume that $n$ mobile agents are initially located on a circle unit\ncircumference at arbitrary but distinct positions unknown to other agents. The\nagents are equipped with unique identifiers from a fixed range. The {\\em\nlocation discovery} task to be performed by each agent is to determine the\ninitial position of every other agent.\n  Our main result states that, if the only available information about movement\nin a round is limited to %information about distance between the initial and\nthe final position, then there is a superlinear lower bound on time needed to\nsolve the location discovery problem. Interestingly, this result corresponds to\na combinatorial symmetry breaking problem, which might be of independent\ninterest. If, on the other hand, an agent has access to the distance to its\nfirst collision with another agent in a round, we design an asymptotically\nefficient and close to optimal solution for the location discovery problem.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 15:14:23 GMT"}], "update_date": "2015-04-28", "authors_parsed": [["Gasieniec", "Leszek", ""], ["Jurdzinski", "Tomasz", ""], ["Martin", "Russell", ""], ["Stachowiak", "Grzegorz", ""]]}, {"id": "1504.07281", "submitter": "Vincenzo De Florio", "authors": "Vincenzo De Florio", "title": "The DIR Net: A Distributed System for Detection, Isolation, and Recovery", "comments": "This is a revision of Technical Report ESAT/ACCA/1998/1, Katholieke\n  Universiteit Leuven, 1998", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This document describes the DIR net, a distributed environment which is part\nof the EFTOS fault tolerance framework. The DIR net is a system consisting of\ntwo components, called DIR Manager (or, shortly, the manager) and DIR Backup\nAgent (shortly, the backup). One manager and a set of backups is located in the\nsystem to be `guarded', one component per node. At this point the DIR net\nweaves a web which substantially does two things: 1) makes itself tolerant to a\nnumber of possible faults, and 2) gathers information pertaining the run of the\nuser application. As soon as an error occurs within the DIR net, the system\nexecutes built-in recovery actions that allow itself to continue processing\ndespite a number of hardware/software faults, possibly doing a graceful\ndegradation of its features; when an error occurs in the user application, the\nDIR net, by means of custom- and user-defined detection tools, is informed of\nsuch events and runs one or more recovery strategies, both built-in and coded\nby the user using an ancillary compile-time tool, the rl translator. Such tools\ntranslates the user-defined strategies into a binary `R-code', i.e., a\npseudo-code interpreted by a special component of the DIR net, the Recovery\nInterpreter, rint (in a sense, rint is a r-code virtual machine.) This document\ndescribes the generic component of the DIR net, a function which can behave\neither as manager or as backup.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 21:18:58 GMT"}, {"version": "v2", "created": "Wed, 29 Apr 2015 11:46:15 GMT"}], "update_date": "2015-04-30", "authors_parsed": [["De Florio", "Vincenzo", ""]]}, {"id": "1504.07283", "submitter": "Thomas Sandholm", "authors": "Thomas Sandholm, Julie Ward, Filippo Balestrieri and Bernardo A.\n  Huberman", "title": "QoS-Based Pricing and Scheduling of Batch Jobs in OpenStack Clouds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The current Cloud infrastructure services (IaaS) market employs a\nresource-based selling model: customers rent nodes from the provider and pay\nper-node per-unit-time. This selling model places the burden upon customers to\npredict their job resource requirements and durations. Inaccurate prediction by\ncustomers can result in over-provisioning of resources, or under-provisioning\nand poor job performance. Thanks to improved resource virtualization and\nmulti-tenant performance isolation, as well as common frameworks for batch\njobs, such as MapReduce, Cloud providers can predict job completion times more\naccurately. We offer a new definition of QoS-levels in terms of job completion\ntimes and we present a new QoS-based selling mechanism for batch jobs in a\nmulti-tenant OpenStack cluster. Our experiments show that the QoS-based\nsolution yields up to 40% improvement over the revenue of more standard selling\nmechanisms based on a fixed per-node price across various demand and supply\nconditions in a 240-VCPU OpenStack cluster.\n", "versions": [{"version": "v1", "created": "Mon, 27 Apr 2015 21:28:41 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Sandholm", "Thomas", ""], ["Ward", "Julie", ""], ["Balestrieri", "Filippo", ""], ["Huberman", "Bernardo A.", ""]]}, {"id": "1504.07325", "submitter": "Thomas Sandholm", "authors": "Thomas Sandholm and Dongman Lee", "title": "Notes on Cloud computing principles", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This letter provides a review of fundamental distributed systems and economic\nCloud computing principles. These principles are frequently deployed in their\nrespective fields, but their inter-dependencies are often neglected. Given that\nCloud Computing first and foremost is a new business model, a new model to sell\ncomputational resources, the understanding of these concepts is facilitated by\ntreating them in unison. Here, we review some of the most important concepts\nand how they relate to each other.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2015 01:40:35 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Sandholm", "Thomas", ""], ["Lee", "Dongman", ""]]}, {"id": "1504.07481", "submitter": "Blake Caldwell", "authors": "Blake Caldwell", "title": "Improving Block-level Efficiency with scsi-mq", "comments": "International Workshop on the Lustre Ecosystem: Challenges and\n  Opportunities, March 2015, Annapolis MD", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.OS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current generation solid-state storage devices are exposing a new bottlenecks\nin the SCSI and block layers of the Linux kernel, where IO throughput is\nlimited by lock contention, inefficient interrupt handling, and poor memory\nlocality. To address these limitations, the Linux kernel block layer underwent\na major rewrite with the blk-mq project to move from a single request queue to\na multi-queue model. The Linux SCSI subsystem rework to make use of this new\nmodel, known as scsi-mq, has been merged into the Linux kernel and work is\nunderway for dm-multipath support in the upcoming Linux 4.0 kernel. These\npieces were necessary to make use of the multi-queue block layer in a Lustre\nparallel filesystem with high availability requirements. We undertook adding\nsupport of the 3.18 kernel to Lustre with scsi-mq and dm-multipath patches to\nevaluate the potential of these efficiency improvements. In this paper we\nevaluate the block-level performance of scsi-mq with backing storage hardware\nrepresentative of a HPC-targerted Lustre filesystem. Our findings show that\nSCSI write request latency is reduced by as much as 13.6%. Additionally, when\nprofiling the CPU usage of our prototype Lustre filesystem, we found that CPU\nidle time increased by a factor of 7 with Linux 3.18 and blk-mq as compared to\na standard 2.6.32 Linux kernel. Our findings demonstrate increased efficiency\nof the multi-queue block layer even with disk-based caching storage arrays used\nin existing parallel filesystems.\n", "versions": [{"version": "v1", "created": "Tue, 28 Apr 2015 14:05:59 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Caldwell", "Blake", ""]]}, {"id": "1504.07563", "submitter": "Olayinka Olafare", "authors": "Olayinka Olafare, Hani Parhizkar, Silas Vem", "title": "A New Secure Mobile Cloud Architecture", "comments": "15 Pages, 8 Figures, 9 Tables, A New Secure Mobile Cloud Architecture\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The demand and use of mobile phones, PDAs and smart phones are constantly on\nthe rise as such, manufacturers of these devices are improving the technology\nand usability of these devices constantly. Due to the handy shape and size\nthese devices come in, their processing capabilities and functionalities, they\nare preferred by many over the conventional desktop or laptop computers. Mobile\ndevices are being used today to perform most tasks that a desktop or laptop\ncomputer could be used for. On this premise, mobile devices are also used to\nconnect to the resources of cloud computing hence, mobile cloud computing\n(MCC). The seemingly ubiquitous and pervasive nature of most mobile devices has\nmade it acceptable and adequate to match the ubiquitous and pervasive nature of\ncloud computing. Mobile cloud computing is said to have increased the\nchallenges known to cloud computing due to the security loop holes that most\nmobile devices have.\n", "versions": [{"version": "v1", "created": "Sat, 25 Apr 2015 08:28:46 GMT"}], "update_date": "2015-04-29", "authors_parsed": [["Olafare", "Olayinka", ""], ["Parhizkar", "Hani", ""], ["Vem", "Silas", ""]]}, {"id": "1504.07795", "submitter": "Derek Groen", "authors": "Mohamed A. Itani, Ulf D. Schiller, Sebastian Schmieschek, James\n  Hetherington, Miguel O. Bernabeu, Hoskote Chandrashekar, Fergus Robertson,\n  Peter V. Coveney and Derek Groen", "title": "An automated multiscale ensemble simulation approach for vascular blood\n  flow", "comments": "Journal of Computational Science (in press), 10 pages, 6 figures, 2\n  tables", "journal-ref": null, "doi": "10.1016/j.jocs.2015.04.008", "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cerebrovascular diseases such as brain aneurysms are a primary cause of adult\ndisability. The flow dynamics in brain arteries, both during periods of rest\nand increased activity, are known to be a major factor in the risk of aneurysm\nformation and rupture. The precise relation is however still an open field of\ninvestigation. We present an automated ensemble simulation method for modelling\ncerebrovascular blood flow under a range of flow regimes. By automatically\nconstructing and performing an ensemble of multiscale simulations, where we\nunidirectionally couple a 1D solver with a 3D lattice-Boltzmann code, we are\nable to model the blood flow in a patient artery over a range of flow regimes.\nWe apply the method to a model of a middle cerebral artery, and find that this\napproach helps us to fine-tune our modelling techniques, and opens up new ways\nto investigate cerebrovascular flow properties.\n", "versions": [{"version": "v1", "created": "Wed, 29 Apr 2015 10:22:56 GMT"}], "update_date": "2015-04-30", "authors_parsed": [["Itani", "Mohamed A.", ""], ["Schiller", "Ulf D.", ""], ["Schmieschek", "Sebastian", ""], ["Hetherington", "James", ""], ["Bernabeu", "Miguel O.", ""], ["Chandrashekar", "Hoskote", ""], ["Robertson", "Fergus", ""], ["Coveney", "Peter V.", ""], ["Groen", "Derek", ""]]}, {"id": "1504.08193", "submitter": "Bal\\'azs Gerencs\\'er", "authors": "Bal\\'azs Gerencs\\'er, Julien M. Hendrickx", "title": "Push sum with transmission failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The push-sum algorithm allows distributed computing of the average on a\ndirected graph, and is particularly relevant when one is restricted to one-way\nand/or asynchronous communications. We investigate its behavior in the presence\nof unreliable communication channels where messages can be lost. We show that\nexponential convergence still holds and deduce fundamental properties that\nimplicitly describe the distribution of the final value obtained. We analyze\nthe error of the final common value we get for the essential case of two nodes,\nboth theoretically and numerically. We provide performance comparison with a\nstandard consensus algorithm.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2015 12:31:42 GMT"}, {"version": "v2", "created": "Wed, 22 Jul 2015 09:49:25 GMT"}, {"version": "v3", "created": "Wed, 31 May 2017 13:25:43 GMT"}], "update_date": "2017-06-01", "authors_parsed": [["Gerencs\u00e9r", "Bal\u00e1zs", ""], ["Hendrickx", "Julien M.", ""]]}, {"id": "1504.08247", "submitter": "Amos Korman", "authors": "Ofer Feinerman and Amos Korman", "title": "Clock Synchronization and Distributed Estimation in Highly Dynamic\n  Networks: An Information Theoretic Approach", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the External Clock Synchronization problem in dynamic sensor\nnetworks. Initially, sensors obtain inaccurate estimations of an external time\nreference and subsequently collaborate in order to synchronize their internal\nclocks with the external time. For simplicity, we adopt the drift-free\nassumption, where internal clocks are assumed to tick at the same pace. Hence,\nthe problem is reduced to an estimation problem, in which the sensors need to\nestimate the initial external time. This work is further relevant to the\nproblem of collective approximation of environmental values by biological\ngroups.\n  Unlike most works on clock synchronization that assume static networks, this\npaper focuses on an extreme case of highly dynamic networks. Specifically, we\nassume a non-adaptive scheduler adversary that dictates in advance an\narbitrary, yet independent, meeting pattern. Such meeting patterns fit, for\nexample, with short-time scenarios in highly dynamic settings, where each\nsensor interacts with only few other arbitrary sensors.\n  We propose an extremely simple clock synchronization algorithm that is based\non weighted averages, and prove that its performance on any given independent\nmeeting pattern is highly competitive with that of the best possible algorithm,\nwhich operates without any resource or computational restrictions, and knows\nthe meeting pattern in advance. In particular, when all distributions involved\nare Gaussian, the performances of our scheme coincide with the optimal\nperformances. Our proofs rely on an extensive use of the concept of Fisher\ninformation. We use the Cramer-Rao bound and our definition of a Fisher Channel\nCapacity to quantify information flows and to obtain lower bounds on collective\nperformance. This opens the door for further rigorous quantifications of\ninformation flows within collaborative sensors.\n", "versions": [{"version": "v1", "created": "Thu, 30 Apr 2015 14:41:58 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2015 12:58:30 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Feinerman", "Ofer", ""], ["Korman", "Amos", ""]]}]