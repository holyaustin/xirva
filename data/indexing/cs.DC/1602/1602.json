[{"id": "1602.00345", "submitter": "Andre Luckow", "authors": "Andre Luckow and Ioannis Paraskevakos and George Chantzialexiou and\n  Shantenu Jha", "title": "Hadoop on HPC: Integrating Hadoop and Pilot-based Dynamic Resource\n  Management", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  High-performance computing platforms such as supercomputers have\ntraditionally been designed to meet the compute demands of scientific\napplications. Consequently, they have been architected as producers and not\nconsumers of data. The Apache Hadoop ecosystem has evolved to meet the\nrequirements of data processing applications and has addressed many of the\nlimitations of HPC platforms. There exist a class of scientific applications\nhowever, that need the collective capabilities of traditional high-performance\ncomputing environments and the Apache Hadoop ecosystem. For example, the\nscientific domains of bio-molecular dynamics, genomics and network science need\nto couple traditional computing with Hadoop/Spark based analysis. We\ninvestigate the critical question of how to present the capabilities of both\ncomputing environments to such scientific applications. Whereas this questions\nneeds answers at multiple levels, we focus on the design of resource management\nmiddleware that might support the needs of both. We propose extensions to the\nPilot-Abstraction to provide a unifying resource management layer. This is an\nimportant step that allows applications to integrate HPC stages (e.g.\nsimulations) to data analytics. Many supercomputing centers have started to\nofficially support Hadoop environments, either in a dedicated environment or in\nhybrid deployments using tools such as myHadoop. This typically involves many\nintrinsic, environment-specific details that need to be mastered, and often\nswamp conceptual issues like: How best to couple HPC and Hadoop application\nstages? How to explore runtime trade-offs (data localities vs. data movement)?\nThis paper provides both conceptual understanding and practical solutions to\nthe integrated use of HPC and Hadoop environments.\n", "versions": [{"version": "v1", "created": "Sun, 31 Jan 2016 23:43:11 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Luckow", "Andre", ""], ["Paraskevakos", "Ioannis", ""], ["Chantzialexiou", "George", ""], ["Jha", "Shantenu", ""]]}, {"id": "1602.00366", "submitter": "Tan Le Thanh", "authors": "Tan Le Thanh, Long Bao Le", "title": "Multi-Channel MAC Protocol for Full-Duplex Cognitive Radio Networks with\n  Optimized Access Control and Load Balancing", "comments": "To appear in 2016 IEEE International Conference on Communications\n  (IEEE ICC 2016). arXiv admin note: text overlap with arXiv:1512.03839", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT math.ST stat.AP stat.TH", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we propose a multi-channel full-duplex Medium Access Control\n(MAC) protocol for cognitive radio networks (MFDC-MAC). Our design exploits the\nfact that full-duplex (FD) secondary users (SUs) can perform spectrum sensing\nand access simultaneously, and we employ the randomized dynamic channel\nselection for load balancing among channels and the standard backoff mechanism\nfor contention resolution on each available channel. Then, we develop a\nmathematical model to analyze the throughput performance of the proposed\nMFDC-MAC protocol. Furthermore, we study the protocol configuration\noptimization to maximize the network throughput where we show that this\noptimization can be performed in two steps, namely optimization of access and\ntransmission parameters on each channel and optimization of channel selection\nprobabilities of the users. Such optimization aims at achieving efficient\nself-interference management for FD transceivers, sensing overhead control, and\nload balancing among the channels. Numerical results demonstrate the impacts of\ndifferent protocol parameters and the importance of parameter optimization on\nthe throughput performance as well as the significant performance gain of the\nproposed design compared to traditional design.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 02:50:13 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Thanh", "Tan Le", ""], ["Le", "Long Bao", ""]]}, {"id": "1602.00586", "submitter": "Mariza Ferro", "authors": "Mariza Ferro, Antonio R. Mury, Bruno Schulze", "title": "A Gain Function for Architectural Decision-Making in Scientific\n  Computing", "comments": "25 pages, 1 figure, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific Computing typically requires large computational needs which have\nbeen addressed with High Performance Distributed Computing. It is essential to\nefficiently deploy a number of complex scientific applications, which have\ndifferent characteristics, and so require distinct computational resources too.\nHowever, in many research laboratories, this high performance architecture is\nnot dedicated. So, the architecture must be shared to execute a set of\nscientific applications, with so many different execution times and relative\nimportance to research. Also, the high performance architectures have different\ncharacteristics and costs. When a new infrastructure has to be acquired to meet\nthe needs of this scenario, the decision-making is hard and complex. In this\nwork, we present a Gain Function as a model of an utility function, with which\nit is possible a decision-making with confidence. With the function is possible\nto evaluate the best architectural option taking into account aspects of\napplications and architectures, including the executions time, cost of\narchitecture, the relative importance of each application and also the relative\nimportance of performance and cost on the final evaluation. This paper presents\nthe Gain Function, examples, and a real case showing their applicabilities.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 16:36:58 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Ferro", "Mariza", ""], ["Mury", "Antonio R.", ""], ["Schulze", "Bruno", ""]]}, {"id": "1602.00591", "submitter": "Paolo Di Lorenzo", "authors": "Paolo Di Lorenzo and Gesualdo Scutari", "title": "NEXT: In-Network Nonconvex Optimization", "comments": "To appear on IEEE Transactions on Signal and Information Processing\n  over Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study nonconvex distributed optimization in multi-agent networks with\ntime-varying (nonsymmetric) connectivity. We introduce the first algorithmic\nframework for the distributed minimization of the sum of a smooth (possibly\nnonconvex and nonseparable) function - the agents' sum-utility - plus a convex\n(possibly nonsmooth and nonseparable) regularizer. The latter is usually\nemployed to enforce some structure in the solution, typically sparsity. The\nproposed method hinges on successive convex approximation techniques while\nleveraging dynamic consensus as a mechanism to distribute the computation among\nthe agents: each agent first solves (possibly inexactly) a local convex\napproximation of the nonconvex original problem, and then performs local\naveraging operations. Asymptotic convergence to (stationary) solutions of the\nnonconvex problem is established. Our algorithmic framework is then customized\nto a variety of convex and nonconvex problems in several fields, including\nsignal processing, communications, networking, and machine learning. Numerical\nresults show that the new method compares favorably to existing distributed\nalgorithms on both convex and nonconvex problems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 16:51:09 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Di Lorenzo", "Paolo", ""], ["Scutari", "Gesualdo", ""]]}, {"id": "1602.00596", "submitter": "Aryan Mokhtari", "authors": "Aryan Mokhtari and Wei Shi and Qing Ling and Alejandro Ribeiro", "title": "A Decentralized Second-Order Method with Exact Linear Convergence Rate\n  for Consensus Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers decentralized consensus optimization problems where\ndifferent summands of a global objective function are available at nodes of a\nnetwork that can communicate with neighbors only. The proximal method of\nmultipliers is considered as a powerful tool that relies on proximal primal\ndescent and dual ascent updates on a suitably defined augmented Lagrangian. The\nstructure of the augmented Lagrangian makes this problem non-decomposable,\nwhich precludes distributed implementations. This problem is regularly\naddressed by the use of the alternating direction method of multipliers. The\nexact second order method (ESOM) is introduced here as an alternative that\nrelies on: (i) The use of a separable quadratic approximation of the augmented\nLagrangian. (ii) A truncated Taylor's series to estimate the solution of the\nfirst order condition imposed on the minimization of the quadratic\napproximation of the augmented Lagrangian. The sequences of primal and dual\nvariables generated by ESOM are shown to converge linearly to their optimal\narguments when the aggregate cost function is strongly convex and its gradients\nare Lipschitz continuous. Numerical results demonstrate advantages of ESOM\nrelative to decentralized alternatives in solving least squares and logistic\nregression problems.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 17:08:43 GMT"}], "update_date": "2016-02-02", "authors_parsed": [["Mokhtari", "Aryan", ""], ["Shi", "Wei", ""], ["Ling", "Qing", ""], ["Ribeiro", "Alejandro", ""]]}, {"id": "1602.00678", "submitter": "Vivekanandan Balasubramanian", "authors": "Vivekanandan Balasubramanian, Antons Treikalis, Ole Weidner and\n  Shantenu Jha", "title": "Ensemble Toolkit: Scalable and Flexible Execution of Ensembles of Tasks", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There are many science applications that require scalable task-level\nparallelism and support for flexible execution and coupling of ensembles of\nsimulations. Most high-performance system software and middleware, however, are\ndesigned to support the execution and optimization of single tasks. Motivated\nby the missing capabilities of these computing systems and the increasing\nimportance of task-level parallelism, we introduce the Ensemble toolkit which\nhas the following application development features: (i) abstractions that\nenable the expression of ensembles as primary entities, and (ii) support for\nensemble-based execution patterns that capture the majority of application\nscenarios. Ensemble toolkit uses a scalable pilot-based runtime system that\ndecouples workload execution and resource management details from the\nexpression of the application, and enables the efficient and dynamic execution\nof ensembles on heterogeneous computing resources. We investigate three\nexecution patterns and characterize the scalability and overhead of Ensemble\ntoolkit for these patterns. We investigate scaling properties for up to O(1000)\nconcurrent ensembles and O(1000) cores and find linear weak and strong scaling\nbehaviour.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 20:52:43 GMT"}, {"version": "v2", "created": "Thu, 17 Mar 2016 23:39:18 GMT"}, {"version": "v3", "created": "Mon, 27 Jun 2016 20:19:57 GMT"}], "update_date": "2016-06-29", "authors_parsed": [["Balasubramanian", "Vivekanandan", ""], ["Treikalis", "Antons", ""], ["Weidner", "Ole", ""], ["Jha", "Shantenu", ""]]}, {"id": "1602.00729", "submitter": "Yixin Luo", "authors": "Yixin Luo, Sriram Govindan, Bikash Sharma, Mark Santaniello, Justin\n  Meza, Aman Kansal, Jie Liu, Badriddine Khessib, Kushagra Vaid, Onur Mutlu", "title": "Heterogeneous-Reliability Memory: Exploiting Application-Level Memory\n  Error Tolerance", "comments": "4 pages, 4 figures, summary report for DSN 2014 paper:\n  \"Characterizing Application Memory Error Vulnerability to Optimize Datacenter\n  Cost via Heterogeneous-Reliability Memory\"", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper summarizes our work on characterizing application memory error\nvulnerability to optimize datacenter cost via Heterogeneous-Reliability Memory\n(HRM), which was published in DSN 2014, and examines the work's significance\nand future potential. Memory devices represent a key component of datacenter\ntotal cost of ownership (TCO), and techniques used to reduce errors that occur\non these devices increase this cost. Existing approaches to providing\nreliability for memory devices pessimistically treat all data as equally\nvulnerable to memory errors. Our key insight is that there exists a diverse\nspectrum of tolerance to memory errors in new data-intensive applications, and\nthat traditional one-size-fits-all memory reliability techniques are\ninefficient in terms of cost. This presents an opportunity to greatly reduce\nserver hardware cost by provisioning the right amount of memory reliability for\ndifferent applications.\n  Toward this end, in our DSN 2014 paper, we make three main contributions to\nenable highly-reliable servers at low datacenter cost. First, we develop a new\nmethodology to quantify the tolerance of applications to memory errors. Second,\nusing our methodology, we perform a case study of three new data-intensive\nworkloads (an interactive web search application, an in-memory key--value\nstore, and a graph mining framework) to identify new insights into the nature\nof application memory error vulnerability. Third, based on our insights, we\npropose several new hardware/software heterogeneous-reliability memory system\ndesigns to lower datacenter cost while achieving high reliability and discuss\ntheir trade-offs. We show that our new techniques can reduce server hardware\ncost by 4.7% while achieving 99.90% single server availability.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 22:23:18 GMT"}, {"version": "v2", "created": "Thu, 10 May 2018 05:27:22 GMT"}], "update_date": "2018-05-11", "authors_parsed": [["Luo", "Yixin", ""], ["Govindan", "Sriram", ""], ["Sharma", "Bikash", ""], ["Santaniello", "Mark", ""], ["Meza", "Justin", ""], ["Kansal", "Aman", ""], ["Liu", "Jie", ""], ["Khessib", "Badriddine", ""], ["Vaid", "Kushagra", ""], ["Mutlu", "Onur", ""]]}, {"id": "1602.00773", "submitter": "Vera Moffitt", "authors": "Vera Zaychik Moffitt and Julia Stoyanovich", "title": "Querying Evolving Graphs with Portal", "comments": "12 pages plus appendix. Submitted to SIGMOD 2017", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Graphs are used to represent a plethora of phenomena, from the Web and social\nnetworks, to biological pathways, to semantic knowledge bases. Arguably the\nmost interesting and important questions one can ask about graphs have to do\nwith their evolution. Which Web pages are showing an increasing popularity\ntrend? How does influence propagate in social networks? How does knowledge\nevolve?\n  This paper proposes a logical model of an evolving graph called a TGraph,\nwhich captures evolution of graph topology and of its vertex and edge\nattributes. We present a compositional temporal graph algebra TGA, and show a\nreduction of TGA to temporal relational algebra with graph-specific primitives.\nWe formally study the properties of TGA, and also show that it is sufficient to\nconcisely express a wide range of common use cases. We describe an\nimplementation of our model and algebra in Portal, built on top of Apache Spark\n/ GraphX. We conduct extensive experiments on real datasets, and show that\nPortal scales.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 03:10:45 GMT"}, {"version": "v2", "created": "Tue, 13 Dec 2016 04:25:11 GMT"}], "update_date": "2016-12-14", "authors_parsed": [["Moffitt", "Vera Zaychik", ""], ["Stoyanovich", "Julia", ""]]}, {"id": "1602.00963", "submitter": "Flavio Vella", "authors": "Flavio Vella, Giancarlo Carbone and Massimo Bernaschi", "title": "Algorithms and Heuristics for Scalable Betweenness Centrality\n  Computation on Multi-GPU Systems", "comments": null, "journal-ref": "Journal of Experimental Algorithmics (JEA) 2018", "doi": "10.1145/3182656", "report-no": null, "categories": "cs.DC cs.DS cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Betweenness Centrality (BC) is steadily growing in popularity as a metrics of\nthe influence of a vertex in a graph. The BC score of a vertex is proportional\nto the number of all-pairs-shortest-paths passing through it. However, complete\nand exact BC computation for a large-scale graph is an extraordinary challenge\nthat requires high performance computing techniques to provide results in a\nreasonable amount of time. Our approach combines bi-dimensional (2-D)\ndecomposition of the graph and multi-level parallelism together with a suitable\ndata-thread mapping that overcomes most of the difficulties caused by the\nirregularity of the computation on GPUs. Furthermore, we propose novel\nheuristics which exploit the topology information of the graph in order to\nreduce time and space requirements of BC computation. Experimental results on\nsynthetic and real-world graphs show that the proposed techniques allow the BC\ncomputation of graphs which are too large to fit in the memory of a single\ncomputational node along with a significant reduction of the computing time.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 15:08:29 GMT"}], "update_date": "2018-06-19", "authors_parsed": [["Vella", "Flavio", ""], ["Carbone", "Giancarlo", ""], ["Bernaschi", "Massimo", ""]]}, {"id": "1602.01065", "submitter": "Quentin Bramas", "authors": "Quentin Bramas (NPA, LIP6, UPMC, LINCS), Toshimitsu Masuzawa\n  (Department of Information and Computer sciences Osaka University),\n  S\\'ebastien Tixeuil (NPA, LIP6, UPMC, LINCS)", "title": "Distributed Online Data Aggregation in Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of aggregating data in a dynamic graph, that is,\naggregating the data that originates from all nodes in the graph to a specific\nnode, the sink. We are interested in giving lower bounds for this problem,\nunder different kinds of adversaries. In our model, nodes are endowed with\nunlimited memory and unlimited computational power. Yet, we assume that\ncommunications between nodes are carried out with pairwise interactions, where\nnodes can exchange control information before deciding whether they transmit\ntheir data or not, given that each node is allowed to transmit its data at most\nonce. When a node receives a data from a neighbor, the node may aggregate it\nwith its own data. We consider three possible adversaries: the online adaptive\nadversary, the oblivious adversary , and the randomized adversary that chooses\nthe pairwise interactions uniformly at random. For the online adaptive and the\noblivious adversary, we give impossibility results when nodes have no knowledge\nabout the graph and are not aware of the future. Also, we give several tight\nbounds depending on the knowledge (be it topology related or time related) of\nthe nodes. For the randomized adversary, we show that the Gathering algorithm,\nwhich always commands a node to transmit, is optimal if nodes have no knowledge\nat all. Also, we propose an algorithm called Waiting Greedy, where a node\neither waits or transmits depending on some parameter, that is optimal when\neach node knows its future pairwise interactions with the sink.\n", "versions": [{"version": "v1", "created": "Tue, 2 Feb 2016 19:58:11 GMT"}, {"version": "v2", "created": "Fri, 7 Oct 2016 14:30:15 GMT"}], "update_date": "2016-10-10", "authors_parsed": [["Bramas", "Quentin", "", "NPA, LIP6, UPMC, LINCS"], ["Masuzawa", "Toshimitsu", "", "Department of Information and Computer sciences Osaka University"], ["Tixeuil", "S\u00e9bastien", "", "NPA, LIP6, UPMC, LINCS"]]}, {"id": "1602.01352", "submitter": "Simon Martiel", "authors": "Simon Martiel and Bruno Martin", "title": "Universality of causal graph dynamics", "comments": "long version", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Causal Graph Dynamics generalize Cellular Automata, extending them to bounded\ndegree, time varying graphs. The dynamics rewrite the graph at each time step\nwith respect to two physics-like symmetries: causality (bounded speed of\ninformation) and homogeneity (the rewriting acts the same everywhere on the\ngraph, at every time step). Universality is the ability simulating every other\ninstances of another (or the same) model of computation. In this work, we study\nthree different notions of simulation for Causal Graph Dynamics, each of them\nleading to a definition of universality.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 16:05:36 GMT"}], "update_date": "2016-02-04", "authors_parsed": [["Martiel", "Simon", ""], ["Martin", "Bruno", ""]]}, {"id": "1602.01412", "submitter": "Hang Qu", "authors": "Hang Qu, Omid Mashayekhi, David Terei, Philip Levis", "title": "Canary: A Scheduling Architecture for High Performance Cloud Computing", "comments": "We have some presentation issues with the paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present Canary, a scheduling architecture that allows high performance\nanalytics workloads to scale out to run on thousands of cores. Canary is\nmotivated by the observation that a central scheduler is a bottleneck for high\nperformance codes: a handful of multicore workers can execute tasks faster than\na controller can schedule them.\n  The key insight in Canary is to reverse the responsibilities between\ncontrollers and workers. Rather than dispatch tasks to workers, which then\nfetch data as necessary, in Canary the controller assigns data partitions to\nworkers, which then spawn and schedule tasks locally.\n  We evaluate three benchmark applications in Canary on up to 64 servers and\n1,152 cores on Amazon EC2. Canary achieves up to 9-90X speedup over Spark and\nup to 4X speedup over GraphX, a highly optimized graph analytics engine. While\ncurrent centralized schedulers can schedule 2,500 tasks/second, each Canary\nworker can schedule 136,000 tasks/second per core and experiments show this\nscales out linearly, with 64 workers scheduling over 120 million tasks per\nsecond, allowing Canary to support optimized jobs running on thousands of\ncores.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 18:58:25 GMT"}, {"version": "v2", "created": "Thu, 14 Apr 2016 17:28:06 GMT"}], "update_date": "2016-04-15", "authors_parsed": [["Qu", "Hang", ""], ["Mashayekhi", "Omid", ""], ["Terei", "David", ""], ["Levis", "Philip", ""]]}, {"id": "1602.01421", "submitter": "Da Zheng", "authors": "Da Zheng, Randal Burns, Joshua Vogelstein, Carey E. Priebe, Alexander\n  S. Szalay", "title": "An SSD-based eigensolver for spectral analysis on billion-node graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many eigensolvers such as ARPACK and Anasazi have been developed to compute\neigenvalues of a large sparse matrix. These eigensolvers are limited by the\ncapacity of RAM. They run in memory of a single machine for smaller eigenvalue\nproblems and require the distributed memory for larger problems.\n  In contrast, we develop an SSD-based eigensolver framework called FlashEigen,\nwhich extends Anasazi eigensolvers to SSDs, to compute eigenvalues of a graph\nwith hundreds of millions or even billions of vertices in a single machine.\nFlashEigen performs sparse matrix multiplication in a semi-external memory\nfashion, i.e., we keep the sparse matrix on SSDs and the dense matrix in\nmemory. We store the entire vector subspace on SSDs and reduce I/O to improve\nperformance through caching the most recent dense matrix. Our result shows that\nFlashEigen is able to achieve 40%-60% performance of its in-memory\nimplementation and has performance comparable to the Anasazi eigensolvers on a\nmachine with 48 CPU cores. Furthermore, it is capable of scaling to a graph\nwith 3.4 billion vertices and 129 billion edges. It takes about four hours to\ncompute eight eigenvalues of the billion-node graph using 120 GB memory.\n", "versions": [{"version": "v1", "created": "Wed, 3 Feb 2016 19:23:44 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2016 13:22:57 GMT"}, {"version": "v3", "created": "Fri, 26 Feb 2016 06:43:03 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Zheng", "Da", ""], ["Burns", "Randal", ""], ["Vogelstein", "Joshua", ""], ["Priebe", "Carey E.", ""], ["Szalay", "Alexander S.", ""]]}, {"id": "1602.01732", "submitter": "Ahlem Mifdaoui Ahlem Mifdaoui", "authors": "Ahlem Mifdaoui, Hamdi Ayed", "title": "Buffer-aware Worst Case Timing Analysis of Wormhole Network On Chip", "comments": "ISAE Technical report done during the master Thesis of Hamdi Ayed at\n  ISAE at 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A buffer-aware worst-case timing analysis of wormhole NoC is proposed in this\npaper to integrate the impact of buffer size on the different dependencies\nrelationship between flows, i.e. direct and indirect blocking flows, and\nconsequently the timing performance. First, more accurate definitions of direct\nand indirect blocking flows sets have been introduced to take into account the\nbuffer size impact. Then, the modeling and worst-case timing analysis of\nwormhole NoC have been detailed, based on Network Calculus formalism and the\nnewly defined blocking flows sets. This introduced approach has been\nillustrated in the case of a realistic NoC case study to show the trade off\nbetween latency and buffer size. The comparative analysis of our proposed\nBuffer-aware timing analysis with conventional approaches is conducted and\nnoticeable enhancements in terms of maximum latency have been proved.\n", "versions": [{"version": "v1", "created": "Thu, 4 Feb 2016 16:27:14 GMT"}, {"version": "v2", "created": "Wed, 25 May 2016 16:01:55 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Mifdaoui", "Ahlem", ""], ["Ayed", "Hamdi", ""]]}, {"id": "1602.01959", "submitter": "Lu Lu", "authors": "Lu Lu, Xuanhua Shi, Yongluan Zhou, Xiong Zhang, Hai Jin, Cheng Pei,\n  Ligang He, Yuanzhen Geng", "title": "Lifetime-Based Memory Management for Distributed Data Processing Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-memory caching of intermediate data and eager combining of data in shuffle\nbuffers have been shown to be very effective in minimizing the re-computation\nand I/O cost in distributed data processing systems like Spark and Flink.\nHowever, it has also been widely reported that these techniques would create a\nlarge amount of long-living data objects in the heap, which may quickly\nsaturate the garbage collector, especially when handling a large dataset, and\nhence would limit the scalability of the system. To eliminate this problem, we\npropose a lifetime-based memory management framework, which, by automatically\nanalyzing the user-defined functions and data types, obtains the expected\nlifetime of the data objects, and then allocates and releases memory space\naccordingly to minimize the garbage collection overhead. In particular, we\npresent Deca, a concrete implementation of our proposal on top of Spark, which\ntransparently decomposes and groups objects with similar lifetimes into byte\narrays and releases their space altogether when their lifetimes come to an end.\nAn extensive experimental study using both synthetic and real datasets shows\nthat, in comparing to Spark, Deca is able to 1) reduce the garbage collection\ntime by up to 99.9%, 2) to achieve up to 22.7x speed up in terms of execution\ntime in cases without data spilling and 41.6x speedup in cases with data\nspilling, and 3) to consume up to 46.6% less memory.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 09:13:00 GMT"}, {"version": "v2", "created": "Wed, 18 May 2016 15:55:24 GMT"}, {"version": "v3", "created": "Sun, 22 May 2016 16:33:39 GMT"}], "update_date": "2016-05-24", "authors_parsed": [["Lu", "Lu", ""], ["Shi", "Xuanhua", ""], ["Zhou", "Yongluan", ""], ["Zhang", "Xiong", ""], ["Jin", "Hai", ""], ["Pei", "Cheng", ""], ["He", "Ligang", ""], ["Geng", "Yuanzhen", ""]]}, {"id": "1602.02159", "submitter": "Yehia Elkhatib PhD", "authors": "Faiza Samreen, Yehia Elkhatib, Matthew Rowe, Gordon S. Blair", "title": "Daleel: Simplifying Cloud Instance Selection Using Machine Learning", "comments": "In the IEEE/IFIP Network Operations and Management Symposium (NOMS),\n  April 2016", "journal-ref": null, "doi": "10.1109/NOMS.2016.7502858", "report-no": null, "categories": "cs.DC cs.LG cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Decision making in cloud environments is quite challenging due to the\ndiversity in service offerings and pricing models, especially considering that\nthe cloud market is an incredibly fast moving one. In addition, there are no\nhard and fast rules, each customer has a specific set of constraints (e.g.\nbudget) and application requirements (e.g. minimum computational resources).\nMachine learning can help address some of the complicated decisions by carrying\nout customer-specific analytics to determine the most suitable instance type(s)\nand the most opportune time for starting or migrating instances. We employ\nmachine learning techniques to develop an adaptive deployment policy, providing\nan optimal match between the customer demands and the available cloud service\nofferings. We provide an experimental study based on extensive set of job\nexecutions over a major public cloud infrastructure.\n", "versions": [{"version": "v1", "created": "Fri, 5 Feb 2016 21:00:02 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Samreen", "Faiza", ""], ["Elkhatib", "Yehia", ""], ["Rowe", "Matthew", ""], ["Blair", "Gordon S.", ""]]}, {"id": "1602.02268", "submitter": "Max Alaluna", "authors": "Lu\\'is Ferrolho, Max Alaluna, Nuno Neves, Fernando M. V. Ramos", "title": "Secure and Dependable Virtual Network Embedding", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the fundamental problems in network virtualization is Virtual Network\nEmbedding (VNE). The VNE problem deals with finding an effective mapping of the\nvirtual nodes & links onto the substrate network. The recent advances in\nnetwork virtualization gave cloud operators the ability to extend their cloud\ncomputing offerings with virtual networks. This trend, jointly with the\nincreasing evidence of incidents in cloud facilities demonstrate that security\nand dependability is becoming a critical factor that should be considered by\nVNE algorithms. In this abstract we propose a VNE solution that considers\nsecurity and dependability as first class citizens. The resiliency properties\nof our solution are enhanced by assuming a multiple cloud provider model.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2016 15:51:52 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Ferrolho", "Lu\u00eds", ""], ["Alaluna", "Max", ""], ["Neves", "Nuno", ""], ["Ramos", "Fernando M. V.", ""]]}, {"id": "1602.02293", "submitter": "Ofer Neiman", "authors": "Michael Elkin, Ofer Neiman", "title": "On Efficient Distributed Construction of Near Optimal Routing Schemes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given a distributed network represented by a weighted undirected graph\n$G=(V,E)$ on $n$ vertices, and a parameter $k$, we devise a distributed\nalgorithm that computes a routing scheme in $(n^{1/2+1/k}+D)\\cdot n^{o(1)}$\nrounds, where $D$ is the hop-diameter of the network. The running time matches\nthe lower bound of $\\tilde{\\Omega}(n^{1/2}+D)$ rounds (which holds for any\nscheme with polynomial stretch), up to lower order terms. The routing tables\nare of size $\\tilde{O}(n^{1/k})$, the labels are of size $O(k\\log^2n)$, and\nevery packet is routed on a path suffering stretch at most $4k-5+o(1)$. Our\nconstruction nearly matches the state-of-the-art for routing schemes built in a\ncentralized sequential manner. The previous best algorithms for building\nrouting tables in a distributed small messages model were by \\cite[STOC\n2013]{LP13} and \\cite[PODC 2015]{LP15}. The former has similar properties but\nsuffers from substantially larger routing tables of size $O(n^{1/2+1/k})$,\nwhile the latter has sub-optimal running time of\n$\\tilde{O}(\\min\\{(nD)^{1/2}\\cdot n^{1/k},n^{2/3+2/(3k)}+D\\})$.\n", "versions": [{"version": "v1", "created": "Sat, 6 Feb 2016 19:34:26 GMT"}, {"version": "v2", "created": "Sun, 20 Nov 2016 09:26:22 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Elkin", "Michael", ""], ["Neiman", "Ofer", ""]]}, {"id": "1602.02339", "submitter": "Nikolay Grozev", "authors": "Nikolay Grozev, Rajkumar Buyya", "title": "Dynamic Selection of Virtual Machines for Application Servers in Cloud\n  Environments", "comments": null, "journal-ref": null, "doi": null, "report-no": "CLOUDS-TR-2016-1", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Autoscaling is a hallmark of cloud computing as it allows flexible\njust-in-time allocation and release of computational resources in response to\ndynamic and often unpredictable workloads. This is especially important for web\napplications whose workload is time dependent and prone to flash crowds. Most\nof them follow the 3-tier architectural pattern, and are divided into\npresentation, application/domain and data layers. In this work we focus on the\napplication layer. Reactive autoscaling policies of the type \"Instantiate a new\nVirtual Machine (VM) when the average server CPU utilisation reaches X%\" have\nbeen used successfully since the dawn of cloud computing. But which VM type is\nthe most suitable for the specific application at the moment remains an open\nquestion. In this work, we propose an approach for dynamic VM type selection.\nIt uses a combination of online machine learning techniques, works in real time\nand adapts to changes in the users' workload patterns, application changes as\nwell as middleware upgrades and reconfigurations. We have developed a\nprototype, which we tested with the CloudStone benchmark deployed on AWS EC2.\nResults show that our method quickly adapts to workload changes and reduces the\ntotal cost compared to the industry standard approach.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2016 04:01:55 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Grozev", "Nikolay", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1602.02409", "submitter": "Victor Eijkhout", "authors": "Victor Eijkhout", "title": "A mathematical formalization of data parallel operations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We give a mathematical formalization of `generalized data parallel'\noperations, a concept that covers such common scientific kernels as\nmatrix-vector multiplication, multi-grid coarsening, load distribution, and\nmany more. We show that from a compact specification such computational aspects\nas MPI messages or task dependencies can be automatically derived.\n", "versions": [{"version": "v1", "created": "Sun, 7 Feb 2016 18:58:22 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Eijkhout", "Victor", ""]]}, {"id": "1602.02575", "submitter": "Xiangyu Wang", "authors": "Xiangyu Wang, David Dunson, Chenlei Leng", "title": "DECOrrelated feature space partitioning for distributed sparse\n  regression", "comments": "Correct legend errors in Figure 3", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.DC stat.CO stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fitting statistical models is computationally challenging when the sample\nsize or the dimension of the dataset is huge. An attractive approach for\ndown-scaling the problem size is to first partition the dataset into subsets\nand then fit using distributed algorithms. The dataset can be partitioned\neither horizontally (in the sample space) or vertically (in the feature space).\nWhile the majority of the literature focuses on sample space partitioning,\nfeature space partitioning is more effective when $p\\gg n$. Existing methods\nfor partitioning features, however, are either vulnerable to high correlations\nor inefficient in reducing the model dimension. In this paper, we solve these\nproblems through a new embarrassingly parallel framework named DECO for\ndistributed variable selection and parameter estimation. In DECO, variables are\nfirst partitioned and allocated to $m$ distributed workers. The decorrelated\nsubset data within each worker are then fitted via any algorithm designed for\nhigh-dimensional problems. We show that by incorporating the decorrelation\nstep, DECO can achieve consistent variable selection and parameter estimation\non each subset with (almost) no assumptions. In addition, the convergence rate\nis nearly minimax optimal for both sparse and weakly sparse models and does NOT\ndepend on the partition number $m$. Extensive numerical experiments are\nprovided to illustrate the performance of the new framework.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 14:17:38 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2016 13:18:57 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Wang", "Xiangyu", ""], ["Dunson", "David", ""], ["Leng", "Chenlei", ""]]}, {"id": "1602.02695", "submitter": "Michel Raynal", "authors": "Achour Most\\'efaoui (LINA), Michel Raynal (ASAP)", "title": "Two-Bit Messages are Sufficient to Implement Atomic Read/Write Registers\n  in Crash-prone Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Atomic registers are certainly the most basic objects of computing science.\nTheir implementation on top of an n-process asynchronous message-passing system\nhas received a lot of attention. It has been shown that t \\textless{} n/2\n(where t is the maximal number of processes that may crash) is a necessary and\nsufficient requirement to build an atomic register on top of a crash-prone\nasynchronous message-passing system. Considering such a context, this paper\npresents an algorithm which implements a single-writer multi-reader atomic\nregister with four message types only, and where no message needs to carry\ncontrol information in addition to its type. Hence, two bits are sufficient to\ncapture all the control information carried by all the implementation messages.\nMoreover, the messages of two types need to carry a data value while the\nmessages of the two other types carry no value at all. As far as we know, this\nalgorithm is the first with such an optimality property on the size of control\ninformation carried by messages. It is also particularly efficient from a time\ncomplexity point of view.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 19:06:03 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Most\u00e9faoui", "Achour", "", "LINA"], ["Raynal", "Michel", "", "ASAP"]]}, {"id": "1602.02698", "submitter": "Yehia Elkhatib PhD", "authors": "Yehia Elkhatib", "title": "Defining Cross-Cloud Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recent years have seen an increasing number of cross-cloud architectures,\ni.e. systems that span across cloud provisioning boundaries. However, the cloud\ncomputing world still lacks any standards in terms of programming interfaces,\nwhich has a knock-on effect on the costs associated with interoperability and\nseverely limits the flexibility and portability of applications and virtual\ninfrastructures. This paper outlines the different types of cross-cloud\nsystems, and the associated design decisions.\n", "versions": [{"version": "v1", "created": "Mon, 8 Feb 2016 19:13:32 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Elkhatib", "Yehia", ""]]}, {"id": "1602.02794", "submitter": "Kyeong Soo (Joseph) Kim", "authors": "Kyeong Soo Kim", "title": "Comments on \"On Clock Synchronization Algorithms for Wireless Sensor\n  Networks Under Unknown Delay\"", "comments": "2 pages, 1 figure, submitted to IEEE Transactions on Vehicular\n  Technology", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The generalization of the maximum-likelihood-like estimator for clock skew by\nLeng and Wu in the above paper is erroneous because the correlation of the\nnoise components in the model is not taken into account in the derivation of\nthe maximum likelihood estimator, its performance bound, and the optimal\nselection of the gap between two subtracting time stamps. This comment\ninvestigates the issue of noise correlation in the model and provides the range\nof the gap for which the maximum likelihood estimator and its performance bound\nare valid and corrects the optimal selection of the gap based on the provided\nrange.\n", "versions": [{"version": "v1", "created": "Mon, 1 Feb 2016 16:27:53 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Kim", "Kyeong Soo", ""]]}, {"id": "1602.02864", "submitter": "Da Zheng", "authors": "Da Zheng, Disa Mhembere, Vince Lyzinski, Joshua Vogelstein, Carey E.\n  Priebe, and Randal Burns", "title": "Semi-External Memory Sparse Matrix Multiplication for Billion-Node\n  Graphs", "comments": "published in IEEE Transactions on Parallel and Distributed Systems", "journal-ref": null, "doi": "10.1109/TPDS.2016.2618791", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Sparse matrix multiplication is traditionally performed in memory and scales\nto large matrices using the distributed memory of multiple nodes. In contrast,\nwe scale sparse matrix multiplication beyond memory capacity by implementing\nsparse matrix dense matrix multiplication (SpMM) in a semi-external memory\n(SEM) fashion; i.e., we keep the sparse matrix on commodity SSDs and dense\nmatrices in memory. Our SEM-SpMM incorporates many in-memory optimizations for\nlarge power-law graphs. It outperforms the in-memory implementations of\nTrilinos and Intel MKL and scales to billion-node graphs, far beyond the\nlimitations of memory. Furthermore, on a single large parallel machine, our\nSEM-SpMM operates as fast as the distributed implementations of Trilinos using\nfive times as much processing power. We also run our implementation in memory\n(IM-SpMM) to quantify the overhead of keeping data on SSDs. SEM-SpMM achieves\nalmost 100% performance of IM-SpMM on graphs when the dense matrix has more\nthan four columns; it achieves at least 65% performance of IM-SpMM on all\ninputs. We apply our SpMM to three important data analysis tasks--PageRank,\neigensolving, and non-negative matrix factorization--and show that our SEM\nimplementations significantly advance the state of the art.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 05:30:30 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2016 01:14:13 GMT"}, {"version": "v3", "created": "Fri, 14 Oct 2016 14:46:57 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Zheng", "Da", ""], ["Mhembere", "Disa", ""], ["Lyzinski", "Vince", ""], ["Vogelstein", "Joshua", ""], ["Priebe", "Carey E.", ""], ["Burns", "Randal", ""]]}, {"id": "1602.02886", "submitter": "Fabien Rozar", "authors": "F Rozar (IRFM, MDLS), C Steiner (IRMA, TONUS), G Latu (IRFM), M\n  Mehrenberger (IRMA, TONUS), V Grandgirard (IRFM), Julien Bigot (MDLS), T\n  Cartier-Michaud (IRFM), Jean Roman (HiePACS)", "title": "Optilization of the gyroaverage operator based on hermite interpolation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gyrokinetic modeling is appropriate for describing Tokamak plasma turbulence,\nand the gyroaverage operator is a cornerstone of this approach. In a\ngyrokinetic code, the gyroaveraging scheme needs to be accurate enough to avoid\nspoiling the data but also requires a low computation cost because it is\napplied often on the main unknown, the 5D guiding-center distribution function,\nand on the 3D electric potentials. In the present paper, we improve a\ngyroaverage scheme based on Hermite interpolation used in the Gysela code. This\ninitial implementation represents a too large fraction of the total execution\ntime. The gyroaverage operator has been reformulated and is now expressed as a\nmatrix-vector product and a cache-friendly algorithm has been setup. Different\ntechniques have been investigated to quicken the computations by more than a\nfactor two. Description of the algorithms is given, together with an analysis\nof the achieved performance.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 08:08:34 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Rozar", "F", "", "IRFM, MDLS"], ["Steiner", "C", "", "IRMA, TONUS"], ["Latu", "G", "", "IRFM"], ["Mehrenberger", "M", "", "IRMA, TONUS"], ["Grandgirard", "V", "", "IRFM"], ["Bigot", "Julien", "", "MDLS"], ["Cartier-Michaud", "T", "", "IRFM"], ["Roman", "Jean", "", "HiePACS"]]}, {"id": "1602.02991", "submitter": "Saeed Akhoondian Amiri", "authors": "Saeed Akhoondian Amiri, Stefan Schmid, Sebastian Siebertz", "title": "A local constant factor approximation for the minimum dominating set\n  problem on bounded genus graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Minimum Dominating Set (MDS) problem is not only one of the most\nfundamental problems in distributed computing, it is also one of the most\nchallenging ones. While it is well-known that minimum dominating sets cannot be\napproximated locally on general graphs, over the last years, several\nbreakthroughs have been made on computing local approximations on sparse\ngraphs.\n  This paper presents a deterministic and local constant factor approximation\nfor minimum dominating sets on bounded genus graphs, a very large family of\nsparse graphs. Our main technical contribution is a new analysis of a slightly\nmodified, first-order definable variant of an existing algorithm by Lenzen et\nal. Interestingly, unlike existing proofs for planar graphs, our analysis does\nnot rely on any topological arguments. We believe that our techniques can be\nuseful for the study of local problems on sparse graphs beyond the scope of\nthis paper.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 14:17:55 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2016 09:11:16 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Amiri", "Saeed Akhoondian", ""], ["Schmid", "Stefan", ""], ["Siebertz", "Sebastian", ""]]}, {"id": "1602.03072", "submitter": "Sabeur Aridhi", "authors": "Sabeur Aridhi and Engelbert Mephu Nguifo", "title": "Big Graph Mining: Frameworks and Techniques", "comments": "Submitted to Big Data Research, Elsevier", "journal-ref": null, "doi": "10.1016/j.bdr.2016.07.002", "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Big graph mining is an important research area and it has attracted\nconsiderable attention. It allows to process, analyze, and extract meaningful\ninformation from large amounts of graph data. Big graph mining has been highly\nmotivated not only by the tremendously increasing size of graphs but also by\nits huge number of applications. Such applications include bioinformatics,\nchemoinformatics and social networks. One of the most challenging tasks in big\ngraph mining is pattern mining in big graphs. This task consists on using data\nmining algorithms to discover interesting, unexpected and useful patterns in\nlarge amounts of graph data. It aims also to provide deeper understanding of\ngraph data. In this context, several graph processing frameworks and scaling\ndata mining/pattern mining techniques have been proposed to deal with very big\ngraphs. This paper gives an overview of existing data mining and graph\nprocessing frameworks that deal with very big graphs. Then it presents a survey\nof current researches in the field of data mining / pattern mining in big\ngraphs and discusses the main research issues related to this field. It also\ngives a categorization of both distributed data mining and machine learning\ntechniques, graph processing frameworks and large scale pattern mining\napproaches.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 16:53:08 GMT"}], "update_date": "2018-05-07", "authors_parsed": [["Aridhi", "Sabeur", ""], ["Nguifo", "Engelbert Mephu", ""]]}, {"id": "1602.03084", "submitter": "Jing Wang", "authors": "Jing Wang, Zhiyuan Yan, Hongmei Xie", "title": "Local Codes with Cooperative Repair in Distributed Storage System", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Recently, the research on local repair codes is mainly confined to repair the\nfailed nodes within each repair group. But if the extreme cases occur that the\nentire repair group has failed, the local code stored in the failed group need\nto be recovered as a whole. In this paper, local codes with cooperative repair,\nin which the local codes are constructed based on minimum storage regeneration\n(MSR) codes, is proposed to achieve repairing the failed groups. Specifically,\nthe proposed local codes with cooperative repair construct a kind of mutual\ninterleaving structure among the parity symbols, that the parity symbols of\neach local code, named as distributed local parity, can be generated by the\nparity symbols of the MSR codes in its two adjacent local codes. Taking\nadvantage of the structure given, the failed local groups can be repaired\ncooperatively by their adjacent local groups with lower repair locality, and\nmeanwhile the minimum distance of local codes with cooperative repair is\nderived. Theoretical analysis and simulation experiments show that, compared\nwith codes with local regeneration (such as MSR-local codes and MBR-local\ncodes), the proposed local codes with cooperative repair have benefits in\nbandwidth overhead and repair locality for the case of local groups failure.\n", "versions": [{"version": "v1", "created": "Tue, 9 Feb 2016 17:26:26 GMT"}], "update_date": "2016-02-10", "authors_parsed": [["Wang", "Jing", ""], ["Yan", "Zhiyuan", ""], ["Xie", "Hongmei", ""]]}, {"id": "1602.03254", "submitter": "EPTCS", "authors": "Simon Gay (University of Glasgow, UK), Jade Alglave (University\n  College London, UK)", "title": "Proceedings Eighth International Workshop on Programming Language\n  Approaches to Concurrency- and Communication-cEntric Software", "comments": null, "journal-ref": "EPTCS 203, 2016", "doi": "10.4204/EPTCS.203", "report-no": null, "categories": "cs.PL cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  PLACES 2015 (full title: Programming Language Approaches to Concurrency- and\nCommunication-Centric Software) is the eighth edition of the PLACES workshop\nseries. After the first PLACES, which was affiliated to DisCoTec in 2008, the\nworkshop has been part of ETAPS every year since 2009 and is now an established\npart of the ETAPS satellite events. PLACES 2015 was held on 18th April in\nLondon, UK.\n  The workshop series was started in order to promote the application of novel\nprogramming language ideas to the increasingly important problem of developing\nsoftware for systems in which concurrency and communication are intrinsic\naspects. This includes software for both multi-core systems and large-scale\ndistributed and/or service-oriented systems. The scope of PLACES includes new\nprogramming language features, whole new programming language designs, new type\nsystems, new semantic approaches, new program analysis techniques, and new\nimplementation mechanisms.\n  This volume consists of revised versions of the papers that were presented at\nthe workshop.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 03:45:11 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Gay", "Simon", "", "University of Glasgow, UK"], ["Alglave", "Jade", "", "University\n  College London, UK"]]}, {"id": "1602.03273", "submitter": "Partha Kanuparthy", "authors": "Partha Kanuparthy, Yuchen Dai, Sudhir Pathak, Sambit Samal, Theophilus\n  Benson, Mojgan Ghasemi, P. P. S. Narayan", "title": "YTrace: End-to-end Performance Diagnosis in Large Cloud and Content\n  Providers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Content providers build serving stacks to deliver content to users. An\nimportant goal of a content provider is to ensure good user experience, since\nuser experience has an impact on revenue. In this paper, we describe a system\nat Yahoo called YTrace that diagnoses bad user experience in near real time. We\npresent the different components of YTrace for end-to-end multi-layer diagnosis\n(instrumentation, methods and backend system), and the system architecture for\ndelivering diagnosis in near real time across all user sessions at Yahoo.\nYTrace diagnoses problems across service and network layers in the end-to-end\npath spanning user host, Internet, CDN and the datacenters, and has three\ndiagnosis goals: detection, localization and root cause analysis (including\ncascading problems) of performance problems in user sessions with the cloud.\nThe key component of the methods in YTrace is capturing and discovering\ncausality, which we design based on a mix of instrumentation API, domain\nknowledge and blackbox methods. We show three case studies from production that\nspan a large-scale distributed storage system, a datacenter-wide network, and\nan end-to-end video serving stack at Yahoo. We end by listing a number of open\ndirections for performance diagnosis in cloud and content providers.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 06:08:57 GMT"}, {"version": "v2", "created": "Sun, 6 Mar 2016 06:11:52 GMT"}, {"version": "v3", "created": "Wed, 25 May 2016 06:30:56 GMT"}], "update_date": "2016-05-26", "authors_parsed": [["Kanuparthy", "Partha", ""], ["Dai", "Yuchen", ""], ["Pathak", "Sudhir", ""], ["Samal", "Sambit", ""], ["Benson", "Theophilus", ""], ["Ghasemi", "Mojgan", ""], ["Narayan", "P. P. S.", ""]]}, {"id": "1602.03303", "submitter": "Daniel Jung", "authors": "Andreas Cord-Landwehr, Matthias Fischer, Daniel Jung, Friedhelm Meyer\n  auf der Heide", "title": "Asymptotically Optimal Gathering on a Grid", "comments": "arXiv admin note: substantial text overlap with arXiv:1510.05454", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we solve the local gathering problem of a swarm of $n$\nindistinguishable, point-shaped robots on a two dimensional grid in\nasymptotically optimal time $\\mathcal{O}(n)$ in the fully synchronous\n$\\mathcal{FSYNC}$ time model. Given an arbitrarily distributed (yet connected)\nswarm of robots, the gathering problem on the grid is to locate all robots\nwithin a $2\\times 2$-sized area that is not known beforehand. Two robots are\nconnected if they are vertical or horizontal neighbors on the grid. The\nlocality constraint means that no global control, no compass, no global\ncommunication and only local vision is available; hence, a robot can only see\nits grid neighbors up to a constant $L_1$-distance, which also limits its\nmovements. A robot can move to one of its eight neighboring grid cells and if\ntwo or more robots move to the same location they are \\emph{merged} to be only\none robot. The locality constraint is the significant challenging issue here,\nsince robot movements must not harm the (only globally checkable) swarm\nconnectivity. For solving the gathering problem, we provide a synchronous\nalgorithm -- executed by every robot -- which ensures that robots merge without\nbreaking the swarm connectivity. In our model, robots can obtain a special\nstate, which marks such a robot to be performing specific connectivity\npreserving movements in order to allow later merge operations of the swarm.\nCompared to the grid, for gathering in the Euclidean plane for the same robot\nand time model the best known upper bound is $\\mathcal{O}(n^2)$.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 09:23:55 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Cord-Landwehr", "Andreas", ""], ["Fischer", "Matthias", ""], ["Jung", "Daniel", ""], ["der Heide", "Friedhelm Meyer auf", ""]]}, {"id": "1602.03404", "submitter": "David Castells-Rufas", "authors": "David Castells-Rufas, C\\'edric Bastoul", "title": "Proceedings of the Workshop on High Performance Energy Efficient\n  Embedded Systems (HIP3ES) 2016", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Proceedings of the Workshop on High Performance Energy Efficient Embedded\nSystems (HIP3ES) 2016. Prague, January 18th. Collocated with HIPEAC 2016\nConference.\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 15:20:54 GMT"}], "update_date": "2016-02-11", "authors_parsed": [["Castells-Rufas", "David", ""], ["Bastoul", "C\u00e9dric", ""]]}, {"id": "1602.03540", "submitter": "Olivier Bournez", "authors": "Olivier Bournez and Johanne Cohen and Mika\\\"el Rabie", "title": "Homonym Population Protocols", "comments": "arXiv admin note: substantial text overlap with arXiv:1412.2497", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The population protocol model was introduced by Angluin \\emph{et al.} as a\nmodel of passively mobile anonymous finite-state agents. This model computes a\npredicate on the multiset of their inputs via interactions by pairs. The\noriginal population protocol model has been proved to compute only semi-linear\npredicates and has been recently extended in various ways. In the community\nprotocol model by Guerraoui and Ruppert, agents have unique identifiers but may\nonly store a finite number of the identifiers they already heard about. The\ncommunity protocol model provides the power of a Turing machine with a $O(n\\log\nn)$ space. We consider variations on the two above models and we obtain a whole\nlandscape that covers and extends already known results. Namely, by considering\nthe case of homonyms, that is to say the case when several agents may share the\nsame identifier, we provide a hierarchy that goes from the case of no\nidentifier (population protocol model) to the case of unique identifiers\n(community protocol model). We obtain in particular that any Turing Machine on\nspace $O(\\log^{O(1)} n)$ can be simulated with at least $O(\\log^{O(1)} n)$\nidentifiers, a result filling a gap left open in all previous studies. Our\nresults also extend and revisit in particular the hierarchy provided by\nChatzigiannakis \\emph{et al.} on population protocols carrying Turing Machines\non limited space, solving the problem of the gap left by this work between\nper-agent space $o(\\log \\log n)$ (proved to be equivalent to population\nprotocols) and $O(\\log n)$ (proved to be equivalent to Turing machines).\n", "versions": [{"version": "v1", "created": "Wed, 10 Feb 2016 21:17:53 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Bournez", "Olivier", ""], ["Cohen", "Johanne", ""], ["Rabie", "Mika\u00ebl", ""]]}, {"id": "1602.03594", "submitter": "EPTCS", "authors": "Geoffrey Brown (Indiana University School of Informatics and\n  Computing), Amr Sabry (Indiana University School of Informatics and\n  Computing)", "title": "Reversible Communicating Processes", "comments": "In Proceedings PLACES 2015, arXiv:1602.03254", "journal-ref": "EPTCS 203, 2016, pp. 45-59", "doi": "10.4204/EPTCS.203.4", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reversible distributed programs have the ability to abort unproductive\ncomputation paths and backtrack, while unwinding communication that occurred in\nthe aborted paths. While it is natural to assume that reversibility implies\nfull state recovery (as with traditional roll-back recovery protocols), an\ninteresting alternative is to separate backtracking from local state recovery.\nFor example, such a model could be used to create complex transactions out of\nnested compensable transactions where a programmer-supplied compensation\ndefines the work required to \"unwind\" a transaction.\n  Reversible distributed computing has received considerable theoretical\nattention, but little reduction to practice; the few published implementations\nof languages supporting reversibility depend upon a high degree of central\ncontrol. The objective of this paper is to demonstrate that a practical\nreversible distributed language can be efficiently implemented in a fully\ndistributed manner.\n  We discuss such a language, supporting CSP-style synchronous communication,\nembedded in Scala. While this language provided the motivation for the work\ndescribed in this paper, our focus is upon the distributed implementation. In\nparticular, we demonstrate that a \"high-level\" semantic model can be\nimplemented using a simple point-to-point protocol.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 01:20:19 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Brown", "Geoffrey", "", "Indiana University School of Informatics and\n  Computing"], ["Sabry", "Amr", "", "Indiana University School of Informatics and\n  Computing"]]}, {"id": "1602.03598", "submitter": "EPTCS", "authors": "Philipp Haller (KTH Royal Institute of Technology), Heather Miller\n  (EPFL)", "title": "Distributed Programming via Safe Closure Passing", "comments": "In Proceedings PLACES 2015, arXiv:1602.03254", "journal-ref": "EPTCS 203, 2016, pp. 99-107", "doi": "10.4204/EPTCS.203.8", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Programming systems incorporating aspects of functional programming, e.g.,\nhigher-order functions, are becoming increasingly popular for large-scale\ndistributed programming. New frameworks such as Apache Spark leverage\nfunctional techniques to provide high-level, declarative APIs for in-memory\ndata analytics, often outperforming traditional \"big data\" frameworks like\nHadoop MapReduce. However, widely-used programming models remain rather ad-hoc;\naspects such as implementation trade-offs, static typing, and semantics are not\nyet well-understood. We present a new asynchronous programming model that has\nat its core several principles facilitating functional processing of\ndistributed data. The emphasis of our model is on simplicity, performance, and\nexpressiveness. The primary means of communication is by passing functions\n(closures) to distributed, immutable data. To ensure safe and efficient\ndistribution of closures, our model leverages both syntactic and type-based\nrestrictions. We report on a prototype implementation in Scala. Finally, we\npresent preliminary experimental results evaluating the performance impact of a\nstatic, type-based optimization of serialization.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 01:20:58 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Haller", "Philipp", "", "KTH Royal Institute of Technology"], ["Miller", "Heather", "", "EPFL"]]}, {"id": "1602.03638", "submitter": "Mikael Mortensen", "authors": "Mikael Mortensen and Hans Petter Langtangen", "title": "High performance Python for direct numerical simulations of turbulent\n  flows", "comments": null, "journal-ref": null, "doi": "10.1016/j.cpc.2016.02.005", "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Direct Numerical Simulations (DNS) of the Navier Stokes equations is an\ninvaluable research tool in fluid dynamics. Still, there are few publicly\navailable research codes and, due to the heavy number crunching implied,\navailable codes are usually written in low-level languages such as C/C++ or\nFortran. In this paper we describe a pure scientific Python pseudo-spectral DNS\ncode that nearly matches the performance of C++ for thousands of processors and\nbillions of unknowns. We also describe a version optimized through Cython, that\nis found to match the speed of C++. The solvers are written from scratch in\nPython, both the mesh, the MPI domain decomposition, and the temporal\nintegrators. The solvers have been verified and benchmarked on the Shaheen\nsupercomputer at the KAUST supercomputing laboratory, and we are able to show\nvery good scaling up to several thousand cores.\n  A very important part of the implementation is the mesh decomposition (we\nimplement both slab and pencil decompositions) and 3D parallel Fast Fourier\nTransforms (FFT). The mesh decomposition and FFT routines have been implemented\nin Python using serial FFT routines (either NumPy, pyFFTW or any other serial\nFFT module), NumPy array manipulations and with MPI communications handled by\nMPI for Python (mpi4py). We show how we are able to execute a 3D parallel FFT\nin Python for a slab mesh decomposition using 4 lines of compact Python code,\nfor which the parallel performance on Shaheen is found to be slightly better\nthan similar routines provided through the FFTW library. For a pencil mesh\ndecomposition 7 lines of code is required to execute a transform.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 08:12:37 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Mortensen", "Mikael", ""], ["Langtangen", "Hans Petter", ""]]}, {"id": "1602.03713", "submitter": "Keren Censor-Hillel", "authors": "Reuven Bar-Yehuda and Keren Censor-Hillel and Gregory Schwartzman", "title": "A Distributed $(2+\\epsilon)$-Approximation for Vertex Cover in\n  $O(\\log{\\Delta}/\\epsilon\\log\\log{\\Delta})$ Rounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple deterministic distributed $(2+\\epsilon)$-approximation\nalgorithm for minimum weight vertex cover, which completes in\n$O(\\log{\\Delta}/\\epsilon\\log\\log{\\Delta})$ rounds, where $\\Delta$ is the\nmaximum degree in the graph, for any $\\epsilon>0$ which is at most $O(1)$. For\na constant $\\epsilon$, this implies a constant approximation in\n$O(\\log{\\Delta}/\\log\\log{\\Delta})$ rounds, which contradicts the lower bound of\n[KMW10].\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 13:00:04 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2016 07:51:02 GMT"}], "update_date": "2016-02-15", "authors_parsed": [["Bar-Yehuda", "Reuven", ""], ["Censor-Hillel", "Keren", ""], ["Schwartzman", "Gregory", ""]]}, {"id": "1602.03718", "submitter": "Keren Censor-Hillel", "authors": "Keren Censor-Hillel and Eldar Fischer and Gregory Schwartzman and Yadu\n  Vasudev", "title": "Fast Distributed Algorithms for Testing Graph Properties", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We initiate a thorough study of \\emph{distributed property testing} --\nproducing algorithms for the approximation problems of property testing in the\nCONGEST model. In particular, for the so-called \\emph{dense} testing model we\nemulate sequential tests for nearly all graph properties having $1$-sided\ntests, while in the \\emph{sparse} and \\emph{general} models we obtain faster\ntests for triangle-freeness and bipartiteness respectively.\n  In most cases, aided by parallelism, the distributed algorithms have a much\nshorter running time as compared to their counterparts from the sequential\nquerying model of traditional property testing. The simplest property testing\nalgorithms allow a relatively smooth transitioning to the distributed model.\nFor the more complex tasks we develop new machinery that is of independent\ninterest. This includes a method for distributed maintenance of multiple random\nwalks.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 13:20:06 GMT"}, {"version": "v2", "created": "Mon, 15 Feb 2016 21:21:15 GMT"}, {"version": "v3", "created": "Mon, 2 May 2016 12:47:13 GMT"}], "update_date": "2016-05-03", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Fischer", "Eldar", ""], ["Schwartzman", "Gregory", ""], ["Vasudev", "Yadu", ""]]}, {"id": "1602.03770", "submitter": "Kasper Grud Skat Madsen", "authors": "Kasper Grud Skat Madsen and Yongluan Zhou and Jianneng Cao", "title": "Integrative Dynamic Reconfiguration in a Parallel Stream Processing\n  Engine", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Load balancing, operator instance collocations and horizontal scaling are\ncritical issues in Parallel Stream Processing Engines to achieve low data\nprocessing latency, optimized cluster utilization and minimized communication\ncost respectively. In previous work, these issues are typically tackled\nseparately and independently. We argue that these problems are tightly coupled\nin the sense that they all need to determine the allocations of workloads and\nmigrate computational states at runtime. Optimizing them independently would\nresult in suboptimal solutions. Therefore, in this paper, we investigate how\nthese three issues can be modeled as one integrated optimization problem. In\nparticular, we first consider jobs where workload allocations have little\neffect on the communication cost, and model the problem of load balance as a\nMixed-Integer Linear Program. Afterwards, we present an extended solution\ncalled ALBIC, which support general jobs. We implement the proposed techniques\non top of Apache Storm, an open-source Parallel Stream Processing Engine. The\nextensive experimental results over both synthetic and real datasets show that\nour techniques clearly outperform existing approaches.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 15:29:18 GMT"}], "update_date": "2016-02-12", "authors_parsed": [["Madsen", "Kasper Grud Skat", ""], ["Zhou", "Yongluan", ""], ["Cao", "Jianneng", ""]]}, {"id": "1602.03779", "submitter": "Raphael F\\'eraud", "authors": "Rapha\\\"el F\\'eraud", "title": "Network of Bandits insure Privacy of end-users", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to distribute the best arm identification task as close as possible\nto the user's devices, on the edge of the Radio Access Network, we propose a\nnew problem setting, where distributed players collaborate to find the best\narm. This architecture guarantees privacy to end-users since no events are\nstored. The only thing that can be observed by an adversary through the core\nnetwork is aggregated information across users. We provide a first algorithm,\nDistributed Median Elimination, which is optimal in term of number of\ntransmitted bits and near optimal in term of speed-up factor with respect to an\noptimal algorithm run independently on each player. In practice, this first\nalgorithm cannot handle the trade-off between the communication cost and the\nspeed-up factor, and requires some knowledge about the distribution of players.\nExtended Distributed Median Elimination overcomes these limitations, by playing\nin parallel different instances of Distributed Median Elimination and selecting\nthe best one. Experiments illustrate and complete the analysis. According to\nthe analysis, in comparison to Median Elimination performed on each player, the\nproposed algorithm shows significant practical improvements.\n", "versions": [{"version": "v1", "created": "Thu, 11 Feb 2016 15:55:59 GMT"}, {"version": "v10", "created": "Mon, 5 Dec 2016 15:10:40 GMT"}, {"version": "v11", "created": "Sat, 17 Dec 2016 17:24:05 GMT"}, {"version": "v12", "created": "Mon, 6 Feb 2017 13:09:27 GMT"}, {"version": "v13", "created": "Mon, 20 Mar 2017 14:04:42 GMT"}, {"version": "v14", "created": "Wed, 29 Mar 2017 09:42:40 GMT"}, {"version": "v2", "created": "Sun, 14 Feb 2016 16:28:45 GMT"}, {"version": "v3", "created": "Mon, 22 Feb 2016 12:26:15 GMT"}, {"version": "v4", "created": "Tue, 1 Mar 2016 17:03:16 GMT"}, {"version": "v5", "created": "Wed, 30 Mar 2016 15:32:59 GMT"}, {"version": "v6", "created": "Tue, 26 Apr 2016 07:37:45 GMT"}, {"version": "v7", "created": "Mon, 6 Jun 2016 12:56:21 GMT"}, {"version": "v8", "created": "Mon, 19 Sep 2016 14:10:21 GMT"}, {"version": "v9", "created": "Tue, 11 Oct 2016 07:28:28 GMT"}], "update_date": "2017-03-30", "authors_parsed": [["F\u00e9raud", "Rapha\u00ebl", ""]]}, {"id": "1602.04095", "submitter": "Pedro Montealegre", "authors": "Pedro Montealegre and Ioan Todinca", "title": "Deterministic graph connectivity in the broadcast congested clique", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present deterministic constant-round protocols for the graph connectivity\nproblem in the model where each of the $n$ nodes of a graph receives a row of\nthe adjacency matrix, and broadcasts a single sublinear size message to all\nother nodes. Communication rounds are synchronous. This model is sometimes\ncalled the broadcast congested clique. Specifically, we exhibit a deterministic\nprotocol that computes the connected components of the input graph in $\\lceil\n1/\\epsilon \\rceil$ rounds, each player communicating $\\mathcal{O}(n^{\\epsilon}\n\\cdot \\log n)$ bits per round, with $0 < \\epsilon \\leq 1$.\n  We also provide a deterministic one-round protocol for connectivity, in the\nmodel when each node receives as input the graph induced by the nodes at\ndistance at most $r>0$, and communicates $\\mathcal{O}(n^{1/r} \\cdot \\log n)$\nbits. This result is based on a $d$-pruning protocol, which consists in\nsuccessively removing nodes of degree at most $d$ until obtaining a graph with\nminimum degree larger than $d$. Our technical novelty is the introduction of\ndeterministic sparse linear sketches: a linear compression function that\npermits to recover sparse Boolean vectors deterministically.\n", "versions": [{"version": "v1", "created": "Fri, 12 Feb 2016 16:04:14 GMT"}, {"version": "v2", "created": "Tue, 29 Nov 2016 20:34:56 GMT"}, {"version": "v3", "created": "Fri, 9 Jun 2017 19:37:35 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Montealegre", "Pedro", ""], ["Todinca", "Ioan", ""]]}, {"id": "1602.04283", "submitter": "Griffin Lacey", "authors": "Griffin Lacey, Graham W. Taylor, Shawki Areibi", "title": "Deep Learning on FPGAs: Past, Present, and Future", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapid growth of data size and accessibility in recent years has\ninstigated a shift of philosophy in algorithm design for artificial\nintelligence. Instead of engineering algorithms by hand, the ability to learn\ncomposable systems automatically from massive amounts of data has led to\nground-breaking performance in important domains such as computer vision,\nspeech recognition, and natural language processing. The most popular class of\ntechniques used in these domains is called deep learning, and is seeing\nsignificant attention from industry. However, these models require incredible\namounts of data and compute power to train, and are limited by the need for\nbetter hardware acceleration to accommodate scaling beyond current data and\nmodel sizes. While the current solution has been to use clusters of graphics\nprocessing units (GPU) as general purpose processors (GPGPU), the use of field\nprogrammable gate arrays (FPGA) provide an interesting alternative. Current\ntrends in design tools for FPGAs have made them more compatible with the\nhigh-level software practices typically practiced in the deep learning\ncommunity, making FPGAs more accessible to those who build and deploy models.\nSince FPGA architectures are flexible, this could also allow researchers the\nability to explore model-level optimizations beyond what is possible on fixed\narchitectures such as GPUs. As well, FPGAs tend to provide high performance per\nwatt of power consumption, which is of particular importance for application\nscientists interested in large scale server-based deployment or\nresource-limited embedded applications. This review takes a look at deep\nlearning and FPGAs from a hardware acceleration perspective, identifying trends\nand innovations that make these technologies a natural fit, and motivates a\ndiscussion on how FPGAs may best serve the needs of the deep learning community\nmoving forward.\n", "versions": [{"version": "v1", "created": "Sat, 13 Feb 2016 03:50:37 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Lacey", "Griffin", ""], ["Taylor", "Graham W.", ""], ["Areibi", "Shawki", ""]]}, {"id": "1602.04419", "submitter": "Emanuele Natale", "authors": "Lucas Boczkowski and Amos Korman and Emanuele Natale", "title": "Minimizing Message Size in Stochastic Communication Patterns: Fast\n  Self-Stabilizing Protocols with 3 bits", "comments": "28 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the basic $\\mathcal{PULL}$ model of communication, in\nwhich in each round, each agent extracts information from few randomly chosen\nagents. We seek to identify the smallest amount of information revealed in each\ninteraction (message size) that nevertheless allows for efficient and robust\ncomputations of fundamental information dissemination tasks. We focus on the\nMajority Bit Dissemination problem that considers a population of $n$ agents,\nwith a designated subset of source agents. Each source agent holds an input bit\nand each agent holds an output bit. The goal is to let all agents converge\ntheir output bits on the most frequent input bit of the sources (the majority\nbit). Note that the particular case of a single source agent corresponds to the\nclassical problem of Broadcast. We concentrate on the severe fault-tolerant\ncontext of self-stabilization, in which a correct configuration must be reached\neventually, despite all agents starting the execution with arbitrary initial\nstates.\n  We first design a general compiler which can essentially transform any\nself-stabilizing algorithm with a certain property that uses $\\ell$-bits\nmessages to one that uses only $\\log \\ell$-bits messages, while paying only a\nsmall penalty in the running time. By applying this compiler recursively we\nthen obtain a self-stabilizing Clock Synchronization protocol, in which agents\nsynchronize their clocks modulo some given integer $T$, within $\\tilde O(\\log\nn\\log T)$ rounds w.h.p., and using messages that contain $3$ bits only.\n  We then employ the new Clock Synchronization tool to obtain a\nself-stabilizing Majority Bit Dissemination protocol which converges in $\\tilde\nO(\\log n)$ time, w.h.p., on every initial configuration, provided that the\nratio of sources supporting the minority opinion is bounded away from half.\nMoreover, this protocol also uses only 3 bits per interaction.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2016 05:35:30 GMT"}, {"version": "v2", "created": "Sat, 23 Jul 2016 20:58:08 GMT"}, {"version": "v3", "created": "Fri, 4 Nov 2016 00:57:36 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Boczkowski", "Lucas", ""], ["Korman", "Amos", ""], ["Natale", "Emanuele", ""]]}, {"id": "1602.04478", "submitter": "Michael Kapralov", "authors": "Venkatesan T. Chakaravarthy, Michael Kapralov, Prakash Murali,\n  Fabrizio Petrini, Xinyu Que, Yogish Sabharwal, Baruch Schieber", "title": "Subgraph Counting: Color Coding Beyond Trees", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The problem of counting occurrences of query graphs in a large data graph,\nknown as subgraph counting, is fundamental to several domains such as genomics\nand social network analysis. Many important special cases (e.g. triangle\ncounting) have received significant attention. Color coding is a very general\nand powerful algorithmic technique for subgraph counting. Color coding has been\nshown to be effective in several applications, but scalable implementations are\nonly known for the special case of {\\em tree queries} (i.e. queries of\ntreewidth one).\n  In this paper we present the first efficient distributed implementation for\ncolor coding that goes beyond tree queries: our algorithm applies to any query\ngraph of treewidth $2$. Since tree queries can be solved in time linear in the\nsize of the data graph, our contribution is the first step into the realm of\ncolour coding for queries that require superlinear running time in the worst\ncase. This superlinear complexity leads to significant load balancing problems\non graphs with heavy tailed degree distributions. Our algorithm structures the\ncomputation to work around high degree nodes in the data graph, and achieves\nvery good runtime and scalability on a diverse collection of data and query\ngraph pairs as a result. We also provide theoretical analysis of our\nalgorithmic techniques, showing asymptotic improvements in runtime on random\ngraphs with power law degree distributions, a popular model for real world\ngraphs.\n", "versions": [{"version": "v1", "created": "Sun, 14 Feb 2016 17:54:25 GMT"}, {"version": "v2", "created": "Sat, 2 Apr 2016 08:53:20 GMT"}], "update_date": "2016-04-05", "authors_parsed": [["Chakaravarthy", "Venkatesan T.", ""], ["Kapralov", "Michael", ""], ["Murali", "Prakash", ""], ["Petrini", "Fabrizio", ""], ["Que", "Xinyu", ""], ["Sabharwal", "Yogish", ""], ["Schieber", "Baruch", ""]]}, {"id": "1602.04536", "submitter": "Seyed Iman Mirrezaei", "authors": "Seyed Iman Mirrezaei, Javad Shahparian", "title": "Data Load Balancing in Heterogeneous Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data load balancing is a challenging task in the P2P systems.\n  Distributed hash table (DHT) abstraction, heterogeneous nodes, and non\nuniform distribution of objects are the reasons to cause load imbalance in\nstructured P2P overlay networks.\n  Previous works solved the load balancing problem by assuming the homogeneous\ncapabilities of nodes, unawareness of the link latency during transferring\nload, and imposing logical structures to collect and reassign load.\n  We propose a distributed load balancing algorithm with the topology awareness\nfeature by using the concept of virtual servers.\n  In our approach, each node collects neighborhood load information from\nphysically close nodes and reassigns virtual servers to overlay nodes based\nupon the topology of underlying network.\n  Consequently, our approach converges data load balancing quickly and it also\nreduces the load transfer cost between nodes.\n  Moreover, our approach increases the quality of load balancing among close\nnodes of overlay and it also introduces a new tradeoff between the quality of\nload balancing and load transfer cost among all overlay nodes.\n  Our simulations show that our approach reduces the load transfer cost and it\nsaves network bandwidth respectively.\n  Finally, we show that the in-degree imbalance of nodes, as a consequence of\ntopology awareness, cannot lead to a remarkable problem in topology aware\noverlays.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 01:18:02 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Mirrezaei", "Seyed Iman", ""], ["Shahparian", "Javad", ""]]}, {"id": "1602.04552", "submitter": "Harsha Vardhan  Simhadri", "authors": "David Dinh, Harsha Vardhan Simhadri, Yuan Tang", "title": "Extending the Nested Parallel Model to the Nested Dataflow Model with\n  Provably Efficient Schedulers", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The nested parallel (a.k.a. fork-join) model is widely used for writing\nparallel programs. However, the two composition constructs, i.e. \"$\\parallel$\"\n(parallel) and \"$;$\" (serial), are insufficient in expressing \"partial\ndependencies\" or \"partial parallelism\" in a program. We propose a new dataflow\ncomposition construct \"$\\leadsto$\" to express partial dependencies in\nalgorithms in a processor- and cache-oblivious way, thus extending the Nested\nParallel (NP) model to the \\emph{Nested Dataflow} (ND) model. We redesign\nseveral divide-and-conquer algorithms ranging from dense linear algebra to\ndynamic-programming in the ND model and prove that they all have optimal span\nwhile retaining optimal cache complexity. We propose the design of runtime\nschedulers that map ND programs to multicore processors with multiple levels of\npossibly shared caches (i.e, Parallel Memory Hierarchies) and provide\ntheoretical guarantees on their ability to preserve locality and load balance.\nFor this, we adapt space-bounded (SB) schedulers for the ND model. We show that\nour algorithms have increased \"parallelizability\" in the ND model, and that SB\nschedulers can use the extra parallelizability to achieve asymptotically\noptimal bounds on cache misses and running time on a greater number of\nprocessors than in the NP model. The running time for the algorithms in this\npaper is $O\\left(\\frac{\\sum_{i=0}^{h-1} Q^{*}({\\mathsf t};\\sigma\\cdot M_i)\\cdot\nC_i}{p}\\right)$, where $Q^{*}$ is the cache complexity of task ${\\mathsf t}$,\n$C_i$ is the cost of cache miss at level-$i$ cache which is of size $M_i$,\n$\\sigma\\in(0,1)$ is a constant, and $p$ is the number of processors in an\n$h$-level cache hierarchy.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 02:46:59 GMT"}], "update_date": "2016-02-16", "authors_parsed": [["Dinh", "David", ""], ["Simhadri", "Harsha Vardhan", ""], ["Tang", "Yuan", ""]]}, {"id": "1602.04667", "submitter": "Dominik Kaaser", "authors": "Robert Els\\\"asser, Tom Friedetzky, Dominik Kaaser, Frederik\n  Mallmann-Trenn, Horst Trinker", "title": "Rapid Asynchronous Plurality Consensus", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider distributed plurality consensus in a complete graph of size $n$\nwith $k$ initial opinions. We design an efficient and simple protocol in the\nasynchronous communication model that ensures that all nodes eventually agree\non the initially most frequent opinion. In this model, each node is equipped\nwith a random Poisson clock with parameter $\\lambda=1$. Whenever a node's clock\nticks, it samples some neighbors, uniformly at random and with replacement, and\nadjusts its opinion according to the sample.\n  A prominent example is the so-called two-choices algorithm in the synchronous\nmodel, where in each round, every node chooses two neighbors uniformly at\nrandom, and if the two sampled opinions coincide, then that opinion is adopted.\nThis protocol is very efficient and well-studied when $k=2$. If\n$k=O(n^\\varepsilon)$ for some small $\\varepsilon$, we show that it converges to\nthe initial plurality opinion within $O(k \\cdot \\log{n})$ rounds, w.h.p., as\nlong as the initial difference between the largest and second largest opinion\nis $\\Omega(\\sqrt{n \\log n})$. On the other side, we show that there are cases\nin which $\\Omega(k)$ rounds are needed, w.h.p.\n  One can beat this lower bound in the synchronous model by combining the\ntwo-choices protocol with randomized broadcasting. Our main contribution is a\nnon-trivial adaptation of this approach to the asynchronous model. If the\nsupport of the most frequent opinion is at least $(1+\\varepsilon)$ times that\nof the second-most frequent one and $k=O(\\exp(\\log{n}/\\log \\log{n}))$, then our\nprotocol achieves the best possible run time of $O(\\log n)$, w.h.p. We relax\nfull synchronicity by allowing $o(n)$ nodes to be poorly synchronized, and the\nwell synchronized nodes are only required to be within a certain time\ndifference from one another. We enforce this synchronicity by introducing a\nnovel gadget into the protocol.\n", "versions": [{"version": "v1", "created": "Mon, 15 Feb 2016 13:23:10 GMT"}, {"version": "v2", "created": "Wed, 17 Feb 2016 14:52:05 GMT"}, {"version": "v3", "created": "Sun, 6 Mar 2016 20:53:44 GMT"}, {"version": "v4", "created": "Tue, 31 May 2016 15:49:48 GMT"}, {"version": "v5", "created": "Wed, 22 Feb 2017 16:38:55 GMT"}], "update_date": "2017-02-23", "authors_parsed": [["Els\u00e4sser", "Robert", ""], ["Friedetzky", "Tom", ""], ["Kaaser", "Dominik", ""], ["Mallmann-Trenn", "Frederik", ""], ["Trinker", "Horst", ""]]}, {"id": "1602.04873", "submitter": "Hannah Morgan", "authors": "Hannah Morgan, Matthew G. Knepley, Patrick Sanan, L. Ridgway Scott", "title": "A Stochastic Performance Model for Pipelined Krylov Methods", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pipelined Krylov methods seek to ameliorate the latency due to inner products\nnecessary for projection by overlapping it with the computation associated with\nsparse matrix-vector multiplication. We clarify a folk theorem that this can\nonly result in a speedup of $2\\times$ over the naive implementation. Examining\nmany repeated runs, we show that stochastic noise also contributes to the\nlatency, and we model this using an analytical probability distribution. Our\nanalysis shows that speedups greater than $2\\times$ are possible with these\nalgorithms.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 00:39:33 GMT"}], "update_date": "2016-02-17", "authors_parsed": [["Morgan", "Hannah", ""], ["Knepley", "Matthew G.", ""], ["Sanan", "Patrick", ""], ["Scott", "L. Ridgway", ""]]}, {"id": "1602.04881", "submitter": "Giovanni Viglietta", "authors": "Paola Flocchini, Nicola Santoro, Giovanni Viglietta, Masafumi\n  Yamashita", "title": "Universal Systems of Oblivious Mobile Robots", "comments": "17 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DM math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An oblivious mobile robot is a stateless computational entity located in a\nspatial universe, capable of moving in that universe. When activated, the robot\nobserves the universe and the location of the other robots, chooses a\ndestination, and moves there. The computation of the destination is made by\nexecuting an algorithm, the same for all robots, whose sole input is the\ncurrent observation. No memory of all these actions is retained after the move.\nWhen the universe is a graph, distributed computations by oblivious mobile\nrobots have been intensively studied focusing on the conditions for feasibility\nof basic problems (e.g., gathering, exploration) in specific classes of graphs\nunder different schedulers. In this paper, we embark on a different, more\ngeneral, type of investigation.\n  With their movements from vertices to neighboring vertices, the robots make\nthe system transition from one configuration to another. Viewing this\ntransition as the computation of an abstract function, we ask which functions\nare computed by which systems. Our main interest is on identifying sets of\nsystems that are \"universal\", in the sense that they can collectively compute\nall finite functions. We are able to identify several such classes of fully\nsynchronous systems. In particular, among other results, we prove the\nuniversality of the set of all graphs with at least one robot, of any set of\ngraphs with at least two robots whose quotient graphs contain arbitrarily long\npaths, and of any set of graphs with at least three robots and arbitrarily\nlarge finite girths.\n  We then focus on the minimum size that a network must have for the robots to\nbe able to compute all functions on a given finite set. We are able to\napproximate the minimum size of such a network up to a factor that tends to 2\nas $n$ goes to infinity.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 01:28:03 GMT"}, {"version": "v2", "created": "Thu, 18 Feb 2016 16:56:04 GMT"}, {"version": "v3", "created": "Wed, 4 May 2016 11:37:53 GMT"}, {"version": "v4", "created": "Fri, 8 Jul 2016 18:46:17 GMT"}], "update_date": "2016-07-11", "authors_parsed": [["Flocchini", "Paola", ""], ["Santoro", "Nicola", ""], ["Viglietta", "Giovanni", ""], ["Yamashita", "Masafumi", ""]]}, {"id": "1602.04952", "submitter": "Yoav Rodeh", "authors": "Amos Korman and Yoav Rodeh", "title": "Parallel Linear Search with no Coordination for a Randomly Placed\n  Treasure", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In STOC'16, Fraigniaud et al. consider the problem of finding a treasure\nhidden in one of many boxes that are ordered by importance. That is, if a\ntreasure is in a more important box, then one would like to find it faster.\nAssuming there are many searchers, the authors suggest that using an algorithm\nthat requires no coordination between searchers can be highly beneficial.\nIndeed, besides saving the need for a communication and coordination mechanism,\nsuch algorithms enjoy inherent robustness. The authors proceed to solve this\nlinear search problem in the case of countably many boxes and an adversary\nplaced treasure, and prove that the best speed-up possible by $k$\nnon-coordinating searchers is precisely $\\frac{k}{4}(1+1/k)^2$. In particular,\nthis means that asymptotically, the speed-up is four times worse compared to\nthe case of full coordination.\n  We suggest an important variant of the problem, where the treasure is placed\nuniformly at random in one of a finite, large, number of boxes. We devise\nnon-coordinating algorithms that achieve a speed-up of $6/5$ for two searchers,\na speed-up of $3/2$ for three searchers, and in general, a speed-up of\n$k(k+1)/(3k-1)$ for any $k \\geq 1$ searchers. Thus, as $k$ grows to infinity,\nthe speed-up approaches three times worse compared to the case of full\ncoordination. Moreover, these bounds are tight in a strong sense as no\nnon-coordinating search algorithm for $k$ searchers can achieve better\nspeed-ups. We also devise non-coordinating algorithms that use only logarithmic\nmemory in the size of the search domain, and yet, asymptotically, achieve the\noptimal speed-up. Finally, we note that all our algorithms are extremely simple\nand hence applicable.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 09:12:12 GMT"}, {"version": "v2", "created": "Sun, 17 Apr 2016 10:55:38 GMT"}], "update_date": "2016-04-19", "authors_parsed": [["Korman", "Amos", ""], ["Rodeh", "Yoav", ""]]}, {"id": "1602.05163", "submitter": "K. Eric Harper", "authors": "K. Eric Harper, Thijmen de Gooijer, Karen Smiley", "title": "Composable Industrial Internet Applications for Tiered Architectures", "comments": "10 pages, 10 figures, 30 references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A single vendor cannot provide complete IIoT end-to-end solutions because\ncooperation is required from multiple parties. Interoperability is a key\narchitectural quality. Composability of capabilities, information and\nconfiguration is the prerequisite for interoperability, supported by a data\nstorage infrastructure and defined set of interfaces to build applications.\nSecure collection, transport and storage of data and algorithms are\nexpectations for collaborative participation in any IIoT solution. Participants\nrequire control of their data ownership and confidentiality. We propose an\nInternet of Things, Services and People (IoTSP) application development and\nmanagement framework which includes components for data storage, algorithm\ndesign and packaging, and computation execution. Applications use clusters of\nplatform services, organized in tiers, and local access to data to reduce\ncomplexity and enhance reliable data exchange. Since communication is less\nreliable across tiers, data is synchronized between storage replicas when\ncommunication is available. The platform services provide a common ecosystem to\nexchange data uniting data storage, applications, and components that process\nthe data. Configuration and orchestration of the tiers are managed using shared\ntools and facilities. The platform promotes the data storage components to be\npeers of the applications where each data owner is in control of when and how\nmuch information is shared with a service provider. The service components and\napplications are securely integrated using local event and data exchange\ncommunication channels. This tiered architecture reduces the cyber attack\nsurface and enables individual tiers to operate autonomously, while addressing\ninteroperability concerns. We present our framework using predictive\nmaintenance as an example, and evaluate compatibility of our vision with an\nemerging set of standards.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 20:16:17 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Harper", "K. Eric", ""], ["de Gooijer", "Thijmen", ""], ["Smiley", "Karen", ""]]}, {"id": "1602.05232", "submitter": "Srikanta Tirthapura", "authors": "Natcha Simsiri and Kanat Tangwongsan and Srikanta Tirthapura and\n  Kun-Lung Wu", "title": "Work-Efficient Parallel and Incremental Graph Connectivity", "comments": "18 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  On an evolving graph that is continuously updated by a high-velocity stream\nof edges, how can one efficiently maintain if two vertices are connected? This\nis the connectivity problem, a fundamental and widely studied problem on\ngraphs. We present the first shared-memory parallel algorithm for incremental\ngraph connectivity that is both provably work-efficient and has polylogarithmic\nparallel depth. We also present a simpler algorithm with slightly worse\ntheoretical properties, but which is easier to implement and has good practical\nperformance. Our experiments show a throughput of hundreds of millions of edges\nper second on a $20$-core machine.\n", "versions": [{"version": "v1", "created": "Tue, 16 Feb 2016 22:30:15 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Simsiri", "Natcha", ""], ["Tangwongsan", "Kanat", ""], ["Tirthapura", "Srikanta", ""], ["Wu", "Kun-Lung", ""]]}, {"id": "1602.05510", "submitter": "Francisco Igual", "authors": "Anton Rey, Francisco D. Igual, Manuel Prieto-Mat\\'ias", "title": "HeSP: a simulation framework for solving the task\n  scheduling-partitioning problem on heterogeneous architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe HeSP, a complete simulation framework to study a\ngeneral task scheduling-partitioning problem on heterogeneous architectures,\nwhich treats recursive task partitioning and scheduling decisions on equal\nfooting. Considering recursive partitioning as an additional degree of freedom,\ntasks can be dynamically partitioned or merged at runtime for each available\nprocessor type, exposing additional or reduced degrees of parallelism as\nneeded. Our simulations reveal that, for a specific class of dense linear\nalgebra algorithms taken as a driving example, simultaneous decisions on task\nscheduling and partitioning yield significant performance gains on two\ndifferent heterogeneous platforms: a highly heterogeneous CPU-GPU system and a\nlow-power asymmetric big.LITTLE ARM platform. The insights extracted from the\nframework can be further applied to actual runtime task schedulers in order to\nimprove performance on current or future architectures and for different\ntask-parallel codes.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 17:42:53 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["Rey", "Anton", ""], ["Igual", "Francisco D.", ""], ["Prieto-Mat\u00edas", "Manuel", ""]]}, {"id": "1602.05546", "submitter": "Maria Potop-Butucaru", "authors": "Xavier D\\'efago (JAIST), Maria Gradinariu Potop-Butucaru (LIP6),\n  Julien Cl\\'ement, St\\'ephane Messika (LRI), Philippe Raipin-Parv\\'edy, P\n  Raipin-Parv\\'edy", "title": "Fault and Byzantine Tolerant Self-stabilizing Mobile Robots Gathering -\n  Feasibility Study -", "comments": "A first version of this paper have been submitted to Distributed\n  Computing in February 2012 (the extended abstract has been published in\n  2006). The current version is the revised version sent in 2014. The most\n  important results of this paper have been diffused in MAC 2010 held in\n  Ottawa, Canada", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.RO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Gathering is a fundamental coordination problem in cooperative mobile\nrobotics. In short, given a set of robots with arbitrary initial locations and\nno initial agreement on a global coordinate system, gathering requires that all\nrobots, following their algorithm, reach the exact same but not predetermined\nlocation. Gathering is particularly challenging in networks where robots are\noblivious (i.e., stateless) and direct communication is replaced by\nobservations on their respective locations. Interestingly any algorithm that\nsolves gathering with oblivious robots is inherently self-stabilizing if no\nspecific assumption is made on the initial distribution of the robots. In this\npaper, we significantly extend the studies of de-terministic gathering\nfeasibility under different assumptions This manuscript considerably extends\npreliminary results presented as an extended abstract at the DISC 2006\nconference [7]. The current version is under review at Distributed Computing\nJournal since February 2012 (in a previous form) and since 2014 in the current\nform. The most important results have been also presented in MAC 2010 organized\nin Ottawa from August 15th to 17th 2010 related to synchrony and faults (crash\nand Byzantine). Unlike prior work, we consider a larger set of scheduling\nstrategies, such as bounded schedulers. In addition, we extend our study to the\nfeasibility of probabilistic self-stabilizing gathering in both fault-free and\nfault-prone environments.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 19:32:31 GMT"}], "update_date": "2016-02-18", "authors_parsed": [["D\u00e9fago", "Xavier", "", "JAIST"], ["Potop-Butucaru", "Maria Gradinariu", "", "LIP6"], ["Cl\u00e9ment", "Julien", "", "LRI"], ["Messika", "St\u00e9phane", "", "LRI"], ["Raipin-Parv\u00e9dy", "Philippe", ""], ["Raipin-Parv\u00e9dy", "P", ""]]}, {"id": "1602.05551", "submitter": "Vaneet Aggarwal", "authors": "Yu Xiang, Vaneet Aggarwal, Yih-Farn R. Chen, and Tian Lan", "title": "Differentiated latency in data center networks with erasure coded files\n  through traffic engineering", "comments": null, "journal-ref": "IEEE Transactions on Cloud Computing 2018", "doi": "10.1109/TCC.2017.2648785", "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper proposes an algorithm to minimize weighted service latency for\ndifferent classes of tenants (or service classes) in a data center network\nwhere erasure-coded files are stored on distributed disks/racks and access\nrequests are scattered across the network. Due to limited bandwidth available\nat both top-of-the-rack and aggregation switches and tenants in different\nservice classes need differentiated services, network bandwidth must be\napportioned among different intra- and inter-rack data flows for different\nservice classes in line with their traffic statistics. We formulate this\nproblem as weighted queuing and employ a class of probabilistic request\nscheduling policies to derive a closed-form upper-bound of service latency for\nerasure-coded storage with arbitrary file access patterns and service time\ndistributions. The result enables us to propose a joint weighted latency (over\ndifferent service classes) optimization over three entangled \"control knobs\":\nthe bandwidth allocation at top-of-the-rack and aggregation switches for\ndifferent service classes, dynamic scheduling of file requests, and the\nplacement of encoded file chunks (i.e., data locality). The joint optimization\nis shown to be a mixed-integer problem. We develop an iterative algorithm which\ndecouples and solves the joint optimization as 3 sub-problems, which are either\nconvex or solvable via bipartite matching in polynomial time. The proposed\nalgorithm is prototyped in an open-source, distributed file system, {\\em\nTahoe}, and evaluated on a cloud testbed with 16 separate physical hosts in an\nOpenstack cluster using 48-port Cisco Catalyst switches. Experiments validate\nour theoretical latency analysis and show significant latency reduction for\ndiverse file access patterns. The results provide valuable insights on\ndesigning low-latency data center networks with erasure coded storage.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 19:56:07 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Xiang", "Yu", ""], ["Aggarwal", "Vaneet", ""], ["Chen", "Yih-Farn R.", ""], ["Lan", "Tian", ""]]}, {"id": "1602.05573", "submitter": "Zhihui Du", "authors": "Hyung Mok Lee, Eric-Olivier Le Bigot, ZhiHui Du, ZhangXi Lin, XiangYu\n  Guo, LinQing Wen, Khun Sang Phukon, Vihan Pandey, Sukanta Bose, Xi-Long Fan,\n  Martin Hendry", "title": "Gravitational wave astrophysics, data analysis and multimessenger\n  astronomy", "comments": null, "journal-ref": "Sci China-Phys Mech Astron, 2015, 58(12): 120403", "doi": "10.1007/s11433-015-5740-1", "report-no": null, "categories": "astro-ph.IM cs.DC gr-qc physics.data-an", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper reviews gravitational wave sources and their detection. One of the\nmost exciting potential sources of gravitational waves are coalescing binary\nblack hole systems. They can occur on all mass scales and be formed in numerous\nways, many of which are not understood. They are generally invisible in\nelectromagnetic waves, and they provide opportunities for deep investigation of\nEinstein's general theory of relativity. Sect. 1 of this paper considers ways\nthat binary black holes can be created in the universe, and includes the\nprediction that binary black hole coalescence events are likely to be the first\ngravitational wave sources to be detected. The next parts of this paper address\nthe detection of chirp waveforms from coalescence events in noisy data. Such\nanalysis is computationally intensive. Sect. 2 reviews a new and powerful\nmethod of signal detection based on the GPU-implemented summed parallel\ninfinite impulse response filters. Such filters are intrinsically real time\nalorithms, that can be used to rapidly detect and localise signals. Sect. 3 of\nthe paper reviews the use of GPU processors for rapid searching for\ngravitational wave bursts that can arise from black hole births and\ncoalescences. In sect. 4 the use of GPU processors to enable fast efficient\nstatistical significance testing of gravitational wave event candidates is\nreviewed. Sect. 5 of this paper addresses the method of multimessenger\nastronomy where the discovery of electromagnetic counterparts of gravitational\nwave events can be used to identify sources, understand their nature and obtain\nmuch greater science outcomes from each identified event.\n", "versions": [{"version": "v1", "created": "Wed, 17 Feb 2016 15:50:27 GMT"}], "update_date": "2016-02-19", "authors_parsed": [["Lee", "Hyung Mok", ""], ["Bigot", "Eric-Olivier Le", ""], ["Du", "ZhiHui", ""], ["Lin", "ZhangXi", ""], ["Guo", "XiangYu", ""], ["Wen", "LinQing", ""], ["Phukon", "Khun Sang", ""], ["Pandey", "Vihan", ""], ["Bose", "Sukanta", ""], ["Fan", "Xi-Long", ""], ["Hendry", "Martin", ""]]}, {"id": "1602.05768", "submitter": "Nicolas Rivera Nicol\\'as Rivera", "authors": "Colin Cooper, Tomasz Radzik, Nicolas Rivera", "title": "The coalescing-branching random walk on expanders and the dual epidemic\n  process", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information propagation on graphs is a fundamental topic in distributed\ncomputing. One of the simplest models of information propagation is the push\nprotocol in which at each round each agent independently pushes the current\nknowledge to a random neighbour. In this paper we study the so-called\ncoalescing-branching random walk (COBRA), in which each vertex pushes the\ninformation to $k$ randomly selected neighbours and then stops passing\ninformation until it receives the information again. The aim of COBRA is to\npropagate information fast but with a limited number of transmissions per\nvertex per step. In this paper we study the cover time of the COBRA process\ndefined as the minimum time until each vertex has received the information at\nleast once. Our main result says that if $G$ is an $n$-vertex $r$-regular graph\nwhose transition matrix has second eigenvalue $\\lambda$, then the COBRA cover\ntime of $G$ is $\\mathcal O(\\log n )$, if $1-\\lambda$ is greater than a positive\nconstant, and $\\mathcal O((\\log n)/(1-\\lambda)^3))$, if $1-\\lambda \\gg\n\\sqrt{\\log( n)/n}$. These bounds are independent of $r$ and hold for $3 \\le r\n\\le n-1$. They improve the previous bound of $O(\\log^2 n)$ for expander graphs.\nOur main tool in analysing the COBRA process is a novel duality relation\nbetween this process and a discrete epidemic process, which we call a biased\ninfection with persistent source (BIPS). A fixed vertex $v$ is the source of an\ninfection and remains permanently infected. At each step each vertex $u$ other\nthan $v$ selects $k$ neighbours, independently and uniformly, and $u$ is\ninfected in this step if and only if at least one of the selected neighbours\nhas been infected in the previous step. We show the duality between COBRA and\nBIPS which says that the time to infect the whole graph in the BIPS process is\nof the same order as the cover time of the COBRA process\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 11:49:52 GMT"}, {"version": "v2", "created": "Thu, 26 May 2016 18:06:41 GMT"}], "update_date": "2016-05-27", "authors_parsed": [["Cooper", "Colin", ""], ["Radzik", "Tomasz", ""], ["Rivera", "Nicolas", ""]]}, {"id": "1602.05852", "submitter": "Kyrill Winkler", "authors": "Kyrill Winkler, Manfred Schwarz and Ulrich Schmid", "title": "Consensus in Rooted Dynamic Networks with Short-Lived Stability", "comments": "14 pages, 2 figures", "journal-ref": "Distrib. Comput. (2019)", "doi": "10.1007/s00446-019-00348-0", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the problem of solving consensus using deterministic algorithms\nin a synchronous dynamic network with unreliable, directional point-to-point\nlinks, which are under the control of a message adversary. In contrast to a\nlarge body of existing work that focuses on oblivious message adversaries where\nthe communication graphs are picked from a predefined set, we consider message\nadversaries where guarantees about stable periods that occur only eventually\ncan be expressed. We reveal to what extent such eventual stability is necessary\nand sufficient, that is, we present the shortest period of stability that\npermits solving consensus, a result that should prove quite useful in systems\nthat exhibit erratic boot-up phases or recover after repeatedly occurring,\nmassive transient faults. Contrary to the case of longer stability periods,\nwhere we show how standard algorithmic techniques for solving consensus can be\nemployed, the short-lived nature of the stability phase forces us to use more\nunusual algorithmic methods that avoid waiting explicitly for the stability\nperiod to occur.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 16:08:36 GMT"}, {"version": "v2", "created": "Fri, 3 Feb 2017 15:53:31 GMT"}, {"version": "v3", "created": "Fri, 10 Feb 2017 13:57:28 GMT"}], "update_date": "2019-04-10", "authors_parsed": [["Winkler", "Kyrill", ""], ["Schwarz", "Manfred", ""], ["Schmid", "Ulrich", ""]]}, {"id": "1602.06005", "submitter": "Rachata Ausavarungnirun", "authors": "Rachata Ausavarungnirun, Chris Fallin, Xiangyao Yu, Kevin Kai-Wei\n  Chang, Greg Nazario, Reetuparna Das, Gabriel H. Loh, Onur Mutlu", "title": "Achieving both High Energy Efficiency and High Performance in On-Chip\n  Communication using Hierarchical Rings with Deflection Routing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hierarchical ring networks, which hierarchically connect multiple levels of\nrings, have been proposed in the past to improve the scalability of ring\ninterconnects, but past hierarchical ring designs sacrifice some of the key\nbenefits of rings by introducing more complex in-ring buffering and buffered\nflow control. Our goal in this paper is to design a new hierarchical ring\ninterconnect that can maintain most of the simplicity of traditional ring\ndesigns (no in-ring buffering or buffered flow control) while achieving high\nscalability as more complex buffered hierarchical ring designs. Our design,\ncalled HiRD (Hierarchical Rings with Deflection), includes features that allow\nus to mostly maintain the simplicity of traditional simple ring topologies\nwhile providing higher energy efficiency and scalability. First, HiRD does not\nhave any buffering or buffered flow control within individual rings, and\nrequires only a small amount of buffering between the ring hierarchy levels.\nWhen inter-ring buffers are full, our design simply deflects flits so that they\ncircle the ring and try again, which eliminates the need for in-ring buffering.\nSecond, we introduce two simple mechanisms that provides an end-to-end delivery\nguarantee within the entire network without impacting the critical path or\nlatency of the vast majority of network traffic. HiRD attains equal or better\nperformance at better energy efficiency than multiple versions of both a\nprevious hierarchical ring design and a traditional single ring design. We also\nanalyze our design's characteristics and injection and delivery guarantees. We\nconclude that HiRD can be a compelling design point that allows higher energy\nefficiency and scalability while retaining the simplicity and appeal of\nconventional ring-based designs.\n", "versions": [{"version": "v1", "created": "Thu, 18 Feb 2016 23:37:57 GMT"}], "update_date": "2016-02-22", "authors_parsed": [["Ausavarungnirun", "Rachata", ""], ["Fallin", "Chris", ""], ["Yu", "Xiangyao", ""], ["Chang", "Kevin Kai-Wei", ""], ["Nazario", "Greg", ""], ["Das", "Reetuparna", ""], ["Loh", "Gabriel H.", ""], ["Mutlu", "Onur", ""]]}, {"id": "1602.06434", "submitter": "Severin Sadjina", "authors": "Severin Sadjina, Lars T. Kyllingstad, Eilif Pedersen, Stian Skjong", "title": "Energy Conservation and Power Bonds in Co-Simulations: Non-Iterative\n  Adaptive Step Size Control and Error Estimation", "comments": "14 pages, 11 figures, 12 tables", "journal-ref": "Engineering with Computers (2016)", "doi": "10.1007/s00366-016-0492-8", "report-no": null, "categories": "cs.SY cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Here, we study the flow of energy between coupled simulators in a\nco-simulation environment using the concept of power bonds. We introduce energy\nresiduals which are a direct expression of the coupling errors and hence the\naccuracy of co-simulation results. We propose a novel Energy-Conservation-based\nCo-Simulation method (ECCO) for adaptive macro step size control to improve\naccuracy and efficiency. In contrast to most other co-simulation algorithms,\nthis method is non-iterative and only requires knowledge of the current\ncoupling data. Consequently, it allows for significant speed ups and the\nprotection of sensitive information contained within simulator models. A\nquarter car model with linear and nonlinear damping serves as a co-simulation\nbenchmark and verifies the capabilities of the energy residual concept:\nReductions in the errors of up to 93% are achieved at no additional\ncomputational cost.\n", "versions": [{"version": "v1", "created": "Sat, 20 Feb 2016 17:25:02 GMT"}, {"version": "v2", "created": "Thu, 6 Oct 2016 19:45:29 GMT"}], "update_date": "2016-11-22", "authors_parsed": [["Sadjina", "Severin", ""], ["Kyllingstad", "Lars T.", ""], ["Pedersen", "Eilif", ""], ["Skjong", "Stian", ""]]}, {"id": "1602.06488", "submitter": "Saurabh Garg Dr", "authors": "Xuezhi Zeng, Saurabh Kumar Garg, Peter Strazdins, Prem Jayaraman,\n  Dimitrios Georgakopoulos, Rajiv Ranjan", "title": "IOTSim: a Cloud based Simulator for Analysing IoT Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A disruptive technology that is influencing not only computing paradigm but\nevery other business is the rise of big data. Internet of Things (IoT)\napplications are considered to be a major source of big data. Such IoT\napplications are in general supported through clouds where data is stored and\nprocessed by big data processing systems. In order to improve the efficiency of\ncloud infrastructure so that they can efficiently support IoT big data\napplications, it is important to understand how these applications and the\ncorresponding big data processing systems will perform in cloud computing\nenvironments. However, given the scalability and complex requirements of big\ndata processing systems, an empirical evaluation on actual cloud infrastructure\ncan hinder the development of timely and cost effective IoT solutions.\nTherefore, a simulator supporting IoT applications in cloud environment is\nhighly demanded, but such work is still in its infancy. To fill this gap, we\nhave designed and implemented IOTSim which supports and enables simulation of\nIoT big data processing using MapReduce model in cloud computing environment. A\nreal case study validates the efficacy of the simulator.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2016 02:32:03 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Zeng", "Xuezhi", ""], ["Garg", "Saurabh Kumar", ""], ["Strazdins", "Peter", ""], ["Jayaraman", "Prem", ""], ["Georgakopoulos", "Dimitrios", ""], ["Ranjan", "Rajiv", ""]]}, {"id": "1602.06489", "submitter": "Chencheng Li", "authors": "Chencheng Li and Pan Zhou and Yingxue Zhou and Kaigui Bian and Tao\n  Jiang and Susanto Rahardja", "title": "Distributed Private Online Learning for Social Big Data Computing over\n  Data Center Networks", "comments": "ICC2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the rapid growth of Internet technologies, cloud computing and social\nnetworks have become ubiquitous. An increasing number of people participate in\nsocial networks and massive online social data are obtained. In order to\nexploit knowledge from copious amounts of data obtained and predict social\nbehavior of users, we urge to realize data mining in social networks. Almost\nall online websites use cloud services to effectively process the large scale\nof social data, which are gathered from distributed data centers. These data\nare so large-scale, high-dimension and widely distributed that we propose a\ndistributed sparse online algorithm to handle them. Additionally,\nprivacy-protection is an important point in social networks. We should not\ncompromise the privacy of individuals in networks, while these social data are\nbeing learned for data mining. Thus we also consider the privacy problem in\nthis article. Our simulations shows that the appropriate sparsity of data would\nenhance the performance of our algorithm and the privacy-preserving method does\nnot significantly hurt the performance of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Sun, 21 Feb 2016 02:32:25 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Li", "Chencheng", ""], ["Zhou", "Pan", ""], ["Zhou", "Yingxue", ""], ["Bian", "Kaigui", ""], ["Jiang", "Tao", ""], ["Rahardja", "Susanto", ""]]}, {"id": "1602.06683", "submitter": "Yann Busnel", "authors": "Yann Busnel and Ilir Gashi", "title": "EDCC 2015 - Fast Abstracts & Student Forum Proceedings", "comments": "The Tenth European Dependable Computing Conference - EDCC 2015 -\n  Paris, France, September 7-11, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Fast Abstracts are short presentations of work in progress or opinion pieces\nand aim to serve as a rapid and flexible mechanism to (i) Report on current\nwork that may or may not be complete; (ii) Introduce new ideas to the\ncommunity; (iii) State positions on controversial issues or open problems.\n  On the other hand, the goal of the Student Forum is to encourage students to\nattend EDCC and present their work, exchange ideas with researchers and\npractitioners, and get early feedback on their research efforts.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 08:45:20 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Busnel", "Yann", ""], ["Gashi", "Ilir", ""]]}, {"id": "1602.06686", "submitter": "An Xie", "authors": "An Xie, Xiaoliang Wang, Guido Maier, Sanglu Lu", "title": "Designing a Disaster-resilient Network with Software Defined Networking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  With the wide deployment of network facilities and the increasing requirement\nof network reliability, the disruptive event like natural disaster, power\noutage or malicious attack has become a non-negligible threat to the current\ncommunication network. Such disruptive event can simultaneously destroy all\ndevices in a specific geographical area and affect many network based\napplications for a long time. Hence, it is essential to build\ndisaster-resilient network for future highly survivable communication services.\nIn this paper, we consider the problem of designing a highly resilient network\nthrough the technique of SDN (Software Defined Networking). In contrast to the\nconventional idea of handling all the failures on the control plane (the\ncontroller), we focus on an integrated design to mitigate disaster risks by\nadding some redundant functions on the data plane. Our design consists of a\nsub-graph based proactive protection approach on the data plane and a splicing\napproach at the controller for effective restoration on the control plane. Such\na systematic design is implemented in the OpenFlow framework through the\nMininet emulator and Nox controller. Numerical results show that our approach\ncan achieve high robustness with low control overhead.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 08:55:27 GMT"}, {"version": "v2", "created": "Tue, 23 Feb 2016 12:12:10 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Xie", "An", ""], ["Wang", "Xiaoliang", ""], ["Maier", "Guido", ""], ["Lu", "Sanglu", ""]]}, {"id": "1602.06709", "submitter": "Dheevatsa Mudigere", "authors": "Dipankar Das, Sasikanth Avancha, Dheevatsa Mudigere, Karthikeyan\n  Vaidynathan, Srinivas Sridharan, Dhiraj Kalamkar, Bharat Kaul, Pradeep Dubey", "title": "Distributed Deep Learning Using Synchronous Stochastic Gradient Descent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We design and implement a distributed multinode synchronous SGD algorithm,\nwithout altering hyper parameters, or compressing data, or altering algorithmic\nbehavior. We perform a detailed analysis of scaling, and identify optimal\ndesign points for different networks. We demonstrate scaling of CNNs on 100s of\nnodes, and present what we believe to be record training throughputs. A 512\nminibatch VGG-A CNN training run is scaled 90X on 128 nodes. Also 256 minibatch\nVGG-A and OverFeat-FAST networks are scaled 53X and 42X respectively on a 64\nnode cluster. We also demonstrate the generality of our approach via\nbest-in-class 6.5X scaling for a 7-layer DNN on 16 nodes. Thereafter we attempt\nto democratize deep-learning by training on an Ethernet based AWS cluster and\nshow ~14X scaling on 16 nodes.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 10:31:24 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["Das", "Dipankar", ""], ["Avancha", "Sasikanth", ""], ["Mudigere", "Dheevatsa", ""], ["Vaidynathan", "Karthikeyan", ""], ["Sridharan", "Srinivas", ""], ["Kalamkar", "Dhiraj", ""], ["Kaul", "Bharat", ""], ["Dubey", "Pradeep", ""]]}, {"id": "1602.06888", "submitter": "Maria Patterson", "authors": "Maria T Patterson, Nikolas Anderson, Collin Bennett, Jacob Bruggemann,\n  Robert Grossman, Matthew Handy, Vuong Ly, Dan Mandl, Shane Pederson, Jim\n  Pivarski, Ray Powell, Jonathan Spring and Walt Wells", "title": "The Matsu Wheel: A Cloud-based Framework for Efficient Analysis and\n  Reanalysis of Earth Satellite Imagery", "comments": "10 pages, accepted for presentation to IEEE BigDataService 2016", "journal-ref": null, "doi": "10.1109/BigDataService.2016.39", "report-no": null, "categories": "cs.DC astro-ph.IM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Project Matsu is a collaboration between the Open Commons Consortium and NASA\nfocused on developing open source technology for the cloud-based processing of\nEarth satellite imagery. A particular focus is the development of applications\nfor detecting fires and floods to help support natural disaster detection and\nrelief. Project Matsu has developed an open source cloud-based infrastructure\nto process, analyze, and reanalyze large collections of hyperspectral satellite\nimage data using OpenStack, Hadoop, MapReduce, Storm and related technologies.\n  We describe a framework for efficient analysis of large amounts of data\ncalled the Matsu \"Wheel.\" The Matsu Wheel is currently used to process incoming\nhyperspectral satellite data produced daily by NASA's Earth Observing-1 (EO-1)\nsatellite. The framework is designed to be able to support scanning queries\nusing cloud computing applications, such as Hadoop and Accumulo. A scanning\nquery processes all, or most of the data, in a database or data repository.\n  We also describe our preliminary Wheel analytics, including an anomaly\ndetector for rare spectral signatures or thermal anomalies in hyperspectral\ndata and a land cover classifier that can be used for water and flood\ndetection. Each of these analytics can generate visual reports accessible via\nthe web for the public and interested decision makers. The resultant products\nof the analytics are also made accessible through an Open Geospatial Compliant\n(OGC)-compliant Web Map Service (WMS) for further distribution. The Matsu Wheel\nallows many shared data services to be performed together to efficiently use\nresources for processing hyperspectral satellite image data and other, e.g.,\nlarge environmental datasets that may be analyzed for many purposes.\n", "versions": [{"version": "v1", "created": "Mon, 22 Feb 2016 18:51:14 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Patterson", "Maria T", ""], ["Anderson", "Nikolas", ""], ["Bennett", "Collin", ""], ["Bruggemann", "Jacob", ""], ["Grossman", "Robert", ""], ["Handy", "Matthew", ""], ["Ly", "Vuong", ""], ["Mandl", "Dan", ""], ["Pederson", "Shane", ""], ["Pivarski", "Jim", ""], ["Powell", "Ray", ""], ["Spring", "Jonathan", ""], ["Wells", "Walt", ""]]}, {"id": "1602.07031", "submitter": "Mohammad Abu Alsheikh", "authors": "Mohammad Abu Alsheikh, Dusit Niyato, Shaowei Lin, Hwee-Pink Tan, and\n  Zhu Han", "title": "Mobile Big Data Analytics Using Deep Learning and Apache Spark", "comments": null, "journal-ref": "IEEE Network, vol. 30, no. 3, pp. 22-29, June 2016", "doi": "10.1109/MNET.2016.7474340", "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The proliferation of mobile devices, such as smartphones and Internet of\nThings (IoT) gadgets, results in the recent mobile big data (MBD) era.\nCollecting MBD is unprofitable unless suitable analytics and learning methods\nare utilized for extracting meaningful information and hidden patterns from\ndata. This article presents an overview and brief tutorial of deep learning in\nMBD analytics and discusses a scalable learning framework over Apache Spark.\nSpecifically, a distributed deep learning is executed as an iterative MapReduce\ncomputing on many Spark workers. Each Spark worker learns a partial deep model\non a partition of the overall MBD, and a master deep model is then built by\naveraging the parameters of all partial models. This Spark-based framework\nspeeds up the learning of deep models consisting of many hidden layers and\nmillions of parameters. We use a context-aware activity recognition application\nwith a real-world dataset containing millions of samples to validate our\nframework and assess its speedup effectiveness.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 04:32:02 GMT"}], "update_date": "2016-08-16", "authors_parsed": [["Alsheikh", "Mohammad Abu", ""], ["Niyato", "Dusit", ""], ["Lin", "Shaowei", ""], ["Tan", "Hwee-Pink", ""], ["Han", "Zhu", ""]]}, {"id": "1602.07057", "submitter": "Bowen Zhou", "authors": "Bowen Zhou, Shahriar Shariat", "title": "Finding Needle in a Million Metrics: Anomaly Detection in a Large-scale\n  Computational Advertising Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AI cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Online media offers opportunities to marketers to deliver brand messages to a\nlarge audience. Advertising technology platforms enables the advertisers to\nfind the proper group of audiences and deliver ad impressions to them in real\ntime. The recent growth of the real time bidding has posed a significant\nchallenge on monitoring such a complicated system. With so many components we\nneed a reliable system that detects the possible changes in the system and\nalerts the engineering team. In this paper we describe the mechanism that we\ninvented for recovering the representative metrics and detecting the change in\ntheir behavior. We show that this mechanism is able to detect the possible\nproblems in time by describing some incident cases.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 07:07:26 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Zhou", "Bowen", ""], ["Shariat", "Shahriar", ""]]}, {"id": "1602.07106", "submitter": "Christian Schulz", "authors": "Peter Sanders and Christian Schulz", "title": "Scalable Generation of Scale-free Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We explain how massive instances of scale-free graphs following the\nBarabasi-Albert model can be generated very quickly in an embarrassingly\nparallel way. This makes this popular model available for studying big data\ngraph problems. As a demonstration, we generated a Petaedge graph in less than\nan hour.\n", "versions": [{"version": "v1", "created": "Tue, 23 Feb 2016 10:21:06 GMT"}], "update_date": "2016-02-24", "authors_parsed": [["Sanders", "Peter", ""], ["Schulz", "Christian", ""]]}, {"id": "1602.07919", "submitter": "Francesco Pace", "authors": "Francesco Pace, Marco Milanesio, Daniele Venzano, Damiano Carra and\n  Pietro Michiardi", "title": "Experimental Performance Evaluation of Cloud-Based\n  Analytics-as-a-Service", "comments": "Longer version of the paper in Submission at IEEE CLOUD'16", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An increasing number of Analytics-as-a-Service solutions has recently seen\nthe light, in the landscape of cloud-based services. These services allow\nflexible composition of compute and storage components, that create powerful\ndata ingestion and processing pipelines. This work is a first attempt at an\nexperimental evaluation of analytic application performance executed using a\nwide range of storage service configurations. We present an intuitive notion of\ndata locality, that we use as a proxy to rank different service compositions in\nterms of expected performance. Through an empirical analysis, we dissect the\nperformance achieved by analytic workloads and unveil problems due to the\nimpedance mismatch that arise in some configurations. Our work paves the way to\na better understanding of modern cloud-based analytic services and their\nperformance, both for its end-users and their providers.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 13:03:42 GMT"}, {"version": "v2", "created": "Tue, 1 Mar 2016 09:49:28 GMT"}, {"version": "v3", "created": "Wed, 15 Mar 2017 10:35:44 GMT"}], "update_date": "2017-03-16", "authors_parsed": [["Pace", "Francesco", ""], ["Milanesio", "Marco", ""], ["Venzano", "Daniele", ""], ["Carra", "Damiano", ""], ["Michiardi", "Pietro", ""]]}, {"id": "1602.08032", "submitter": "Rati Gelashvili", "authors": "Dan Alistarh, James Aspnes, David Eisenstat, Rati Gelashvili, Ronald\n  L. Rivest", "title": "Time-Space Trade-offs in Population Protocols", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Population protocols are a popular model of distributed computing, in which\nrandomly-interacting agents with little computational power cooperate to\njointly perform computational tasks. Inspired by developments in molecular\ncomputation, and in particular DNA computing, recent algorithmic work has\nfocused on the complexity of solving simple yet fundamental tasks in the\npopulation model, such as leader election (which requires stabilization to a\nsingle agent in a special \"leader\" state), and majority (in which agents must\nstabilize to a decision as to which of two possible initial states had higher\ninitial count). Known results point towards an inherent trade-off between the\ntime complexity of such algorithms, and the space complexity, i.e. size of the\nmemory available to each agent.\n  In this paper, we explore this trade-off and provide new upper and lower\nbounds for majority and leader election. First, we prove a unified lower bound,\nwhich relates the space available per node with the time complexity achievable\nby a protocol: for instance, our result implies that any protocol solving\neither of these tasks for $n$ agents using $O( \\log \\log n )$ states must take\n$\\Omega( n / \\rm{polylog} n )$ expected time. This is the first result to\ncharacterize time complexity for protocols which employ super-constant number\nof states per node, and proves that fast, poly-logarithmic running times\nrequire protocols to have relatively large space costs.\n  On the positive side, we give algorithms showing that fast, poly-logarithmic\nstabilization time can be achieved using $O( \\log^2 n )$ space per node, in the\ncase of both tasks. Overall, our results highlight a time complexity separation\nbetween $O(\\log \\log n)$ and $\\Theta( \\log^2 n )$ state space size for both\nmajority and leader election in population protocols, and introduce new\ntechniques, which should be applicable more broadly.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 18:54:50 GMT"}, {"version": "v2", "created": "Thu, 14 Jul 2016 09:31:52 GMT"}, {"version": "v3", "created": "Mon, 18 Jul 2016 20:55:58 GMT"}, {"version": "v4", "created": "Mon, 25 Jul 2016 12:21:34 GMT"}, {"version": "v5", "created": "Fri, 4 Nov 2016 21:34:24 GMT"}, {"version": "v6", "created": "Sat, 14 Jan 2017 17:04:02 GMT"}, {"version": "v7", "created": "Mon, 17 Apr 2017 14:24:41 GMT"}], "update_date": "2017-04-18", "authors_parsed": [["Alistarh", "Dan", ""], ["Aspnes", "James", ""], ["Eisenstat", "David", ""], ["Gelashvili", "Rati", ""], ["Rivest", "Ronald L.", ""]]}, {"id": "1602.08124", "submitter": "Minsoo Rhu", "authors": "Minsoo Rhu, Natalia Gimelshein, Jason Clemons, Arslan Zulfiqar,\n  Stephen W. Keckler", "title": "vDNN: Virtualized Deep Neural Networks for Scalable, Memory-Efficient\n  Neural Network Design", "comments": "Published as a conference paper at the 49th IEEE/ACM International\n  Symposium on Microarchitecture (MICRO-49), 2016", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most widely used machine learning frameworks require users to carefully\ntune their memory usage so that the deep neural network (DNN) fits into the\nDRAM capacity of a GPU. This restriction hampers a researcher's flexibility to\nstudy different machine learning algorithms, forcing them to either use a less\ndesirable network architecture or parallelize the processing across multiple\nGPUs. We propose a runtime memory manager that virtualizes the memory usage of\nDNNs such that both GPU and CPU memory can simultaneously be utilized for\ntraining larger DNNs. Our virtualized DNN (vDNN) reduces the average GPU memory\nusage of AlexNet by up to 89%, OverFeat by 91%, and GoogLeNet by 95%, a\nsignificant reduction in memory requirements of DNNs. Similar experiments on\nVGG-16, one of the deepest and memory hungry DNNs to date, demonstrate the\nmemory-efficiency of our proposal. vDNN enables VGG-16 with batch size 256\n(requiring 28 GB of memory) to be trained on a single NVIDIA Titan X GPU card\ncontaining 12 GB of memory, with 18% performance loss compared to a\nhypothetical, oracular GPU with enough memory to hold the entire DNN.\n", "versions": [{"version": "v1", "created": "Thu, 25 Feb 2016 21:31:55 GMT"}, {"version": "v2", "created": "Tue, 1 Mar 2016 03:52:59 GMT"}, {"version": "v3", "created": "Thu, 28 Jul 2016 23:19:03 GMT"}], "update_date": "2016-08-01", "authors_parsed": [["Rhu", "Minsoo", ""], ["Gimelshein", "Natalia", ""], ["Clemons", "Jason", ""], ["Zulfiqar", "Arslan", ""], ["Keckler", "Stephen W.", ""]]}, {"id": "1602.08166", "submitter": "Yi-Jun Chang", "authors": "Yi-Jun Chang and Tsvi Kopelowitz and Seth Pettie", "title": "An Exponential Separation Between Randomized and Deterministic\n  Complexity in the LOCAL Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Over the past 30 years numerous algorithms have been designed for symmetry\nbreaking problems in the LOCAL model, such as maximal matching, MIS, vertex\ncoloring, and edge-coloring. For most problems the best randomized algorithm is\nat least exponentially faster than the best deterministic algorithm. In this\npaper we prove that these exponential gaps are necessary and establish\nconnections between the deterministic and randomized complexities in the LOCAL\nmodel. Each result has a very compelling take-away message:\n  1. Fast $\\Delta$-coloring of trees requires random bits: Building on the\nrecent lower bounds of Brandt et al., we prove that the randomized complexity\nof $\\Delta$-coloring a tree with maximum degree $\\Delta\\ge 55$ is\n$\\Theta(\\log_\\Delta\\log n)$, whereas its deterministic complexity is\n$\\Theta(\\log_\\Delta n)$ for any $\\Delta\\ge 3$. This also establishes a large\nseparation between the deterministic complexity of $\\Delta$-coloring and\n$(\\Delta+1)$-coloring trees.\n  2. Randomized lower bounds imply deterministic lower bounds: We prove that\nany deterministic algorithm for a natural class of problems that runs in\n$O(1)+o(\\log_\\Delta n)$ rounds can be transformed to run in\n$O(\\log^*n-\\log^*\\Delta+1)$ rounds. If the transformed algorithm violates a\nlower bound (even allowing randomization), then one can conclude that the\nproblem requires $\\Omega(\\log_\\Delta n)$ time deterministically.\n  3. Deterministic lower bounds imply randomized lower bounds: We prove that\nthe randomized complexity of any natural problem on instances of size $n$ is at\nleast its deterministic complexity on instances of size $\\sqrt{\\log n}$. This\nshows that a deterministic $\\Omega(\\log_\\Delta n)$ lower bound for any problem\nimplies a randomized $\\Omega(\\log_\\Delta\\log n)$ lower bound. It also\nillustrates that the graph shattering technique is absolutely essential to the\nLOCAL model.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 01:31:56 GMT"}, {"version": "v2", "created": "Wed, 6 Apr 2016 00:11:49 GMT"}], "update_date": "2016-04-07", "authors_parsed": [["Chang", "Yi-Jun", ""], ["Kopelowitz", "Tsvi", ""], ["Pettie", "Seth", ""]]}, {"id": "1602.08361", "submitter": "Sebastien Tixeuil", "authors": "Pierre Courtieu (CEDRIC), Lionel Rieg, S\\'ebastien Tixeuil (LINCS,\n  NPA, IUF), Xavier Urbain (ENSIIE, LRI)", "title": "Certified Universal Gathering in $R^2$ for Oblivious Mobile Robots", "comments": "arXiv admin note: substantial text overlap with arXiv:1506.01603", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.LO cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a unified formal framework for expressing mobile robots models,\nprotocols, and proofs, and devise a protocol design/proof methodology dedicated\nto mobile robots that takes advantage of this formal framework. As a case\nstudy, we present the first formally certified protocol for oblivious mobile\nrobots evolving in a two-dimensional Euclidean space. In more details, we\nprovide a new algorithm for the problem of universal gathering mobile oblivious\nrobots (that is, starting from any initial configuration that is not bivalent,\nusing any number of robots, the robots reach in a finite number of steps the\nsame position, not known beforehand) without relying on a common orientation\nnor chirality. We give very strong guaranties on the correctness of our\nalgorithm by proving formally that it is correct, using the COQ proof\nassistant. This result demonstrates both the effectiveness of the approach to\nobtain new algorithms that use as few assumptions as necessary, and its\nmanageability since the amount of developed code remains human readable.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 15:16:21 GMT"}], "update_date": "2016-02-29", "authors_parsed": [["Courtieu", "Pierre", "", "CEDRIC"], ["Rieg", "Lionel", "", "LINCS,\n  NPA, IUF"], ["Tixeuil", "S\u00e9bastien", "", "LINCS,\n  NPA, IUF"], ["Urbain", "Xavier", "", "ENSIIE, LRI"]]}, {"id": "1602.08477", "submitter": "Erik Zenker", "authors": "Erik Zenker, Benjamin Worpitz, Ren\\'e Widera, Axel Huebl, Guido\n  Juckeland, Andreas Kn\\\"upfer, Wolfgang E. Nagel, Michael Bussmann", "title": "Alpaka - An Abstraction Library for Parallel Kernel Acceleration", "comments": "10 pages, 10 figures", "journal-ref": null, "doi": "10.1109/IPDPSW.2016.50", "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Porting applications to new hardware or programming models is a tedious and\nerror prone process. Every help that eases these burdens is saving developer\ntime that can then be invested into the advancement of the application itself\ninstead of preserving the status-quo on a new platform.\n  The Alpaka library defines and implements an abstract hierarchical redundant\nparallelism model. The model exploits parallelism and memory hierarchies on a\nnode at all levels available in current hardware. By doing so, it allows to\nachieve platform and performance portability across various types of\naccelerators by ignoring specific unsupported levels and utilizing only the\nones supported on a specific accelerator. All hardware types (multi- and\nmany-core CPUs, GPUs and other accelerators) are supported for and can be\nprogrammed in the same way. The Alpaka C++ template interface allows for\nstraightforward extension of the library to support other accelerators and\nspecialization of its internals for optimization.\n  Running Alpaka applications on a new (and supported) platform requires the\nchange of only one source code line instead of a lot of \\#ifdefs.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 20:49:37 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Zenker", "Erik", ""], ["Worpitz", "Benjamin", ""], ["Widera", "Ren\u00e9", ""], ["Huebl", "Axel", ""], ["Juckeland", "Guido", ""], ["Kn\u00fcpfer", "Andreas", ""], ["Nagel", "Wolfgang E.", ""], ["Bussmann", "Michael", ""]]}, {"id": "1602.08481", "submitter": "Peter Robinson", "authors": "Gopal Pandurangan, Peter Robinson, Michele Scquizzato", "title": "On the Distributed Complexity of Large-Scale Graph Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Motivated by the increasing need to understand the distributed algorithmic\nfoundations of large-scale graph computations, we study some fundamental graph\nproblems in a message-passing model for distributed computing where $k \\geq 2$\nmachines jointly perform computations on graphs with $n$ nodes (typically, $n\n\\gg k$). The input graph is assumed to be initially randomly partitioned among\nthe $k$ machines, a common implementation in many real-world systems.\nCommunication is point-to-point, and the goal is to minimize the number of\ncommunication {\\em rounds} of the computation.\n  Our main contribution is the {\\em General Lower Bound Theorem}, a theorem\nthat can be used to show non-trivial lower bounds on the round complexity of\ndistributed large-scale data computations. The General Lower Bound Theorem is\nestablished via an information-theoretic approach that relates the round\ncomplexity to the minimal amount of information required by machines to solve\nthe problem. Our approach is generic and this theorem can be used in a\n\"cookbook\" fashion to show distributed lower bounds in the context of several\nproblems, including non-graph problems. We present two applications by showing\n(almost) tight lower bounds for the round complexity of two fundamental graph\nproblems, namely {\\em PageRank computation} and {\\em triangle enumeration}. Our\napproach, as demonstrated in the case of PageRank, can yield tight lower bounds\nfor problems (including, and especially, under a stochastic partition of the\ninput) where communication complexity techniques are not obvious.\n  Our approach, as demonstrated in the case of triangle enumeration, can yield\nstronger round lower bounds as well as message-round tradeoffs compared to\napproaches that use communication complexity techniques.\n", "versions": [{"version": "v1", "created": "Fri, 26 Feb 2016 20:57:30 GMT"}, {"version": "v2", "created": "Thu, 3 Mar 2016 23:42:15 GMT"}, {"version": "v3", "created": "Fri, 4 Nov 2016 17:46:11 GMT"}, {"version": "v4", "created": "Mon, 24 Jul 2017 10:26:59 GMT"}, {"version": "v5", "created": "Sat, 25 Nov 2017 15:59:14 GMT"}, {"version": "v6", "created": "Thu, 17 May 2018 00:10:05 GMT"}, {"version": "v7", "created": "Thu, 26 Jul 2018 13:58:09 GMT"}], "update_date": "2018-07-27", "authors_parsed": [["Pandurangan", "Gopal", ""], ["Robinson", "Peter", ""], ["Scquizzato", "Michele", ""]]}, {"id": "1602.08735", "submitter": "Hosam AboElFotoh Dr.", "authors": "Qadha'a AlEnezi, Hosam AboElFotoh, Bader AlBdaiwi and Mohammad Ali\n  AlMulla", "title": "Heuristics for the Variable Sized Bin Packing Problem Using a Hybrid\n  P-System and CUDA Architecture", "comments": "20 pages; This paper is extracted from M.Sc. Thesis: Solution of the\n  Variable Sized Bin Packing Problem using the P System and Cuda Architecture,\n  by Qadhaa Al-Enezi, submitted March 2015, Computer Sc. Dept. Kuwait\n  University, Supervised by Hosam AboElFotoh and Bader AlBdaiwi", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Variable Sized Bin Packing Problem has a wide range of application areas\nincluding packing, scheduling, and manufacturing. Given a list of items and\nvariable sized bin types, the objective is to minimize the total size of the\nused bins. This problem is known to be NP-hard. In this article, we present two\nnew heuristics for solving the problem using a new variation of P systems with\nactive membranes, which we call a hybrid P system, implemented in CUDA. Our\nhybrid P-system model allows using the polarity and labels of membranes to\nrepresent object properties which results in reducing the complexity of\nimplementing the P-system. We examine the performance of the two heuristics,\nand compare the results with those of other known algorithms. The numerical\nresults show that good solutions for large instances (10000 items) of this\nproblem could be obtained in a very short time (seconds) using our CUDA\nsimulator.\n", "versions": [{"version": "v1", "created": "Sun, 28 Feb 2016 16:25:06 GMT"}, {"version": "v2", "created": "Tue, 1 Mar 2016 10:40:20 GMT"}], "update_date": "2016-03-02", "authors_parsed": [["AlEnezi", "Qadha'a", ""], ["AboElFotoh", "Hosam", ""], ["AlBdaiwi", "Bader", ""], ["AlMulla", "Mohammad Ali", ""]]}, {"id": "1602.08925", "submitter": "Juho Hirvonen", "authors": "Laurent Feuilloley, Pierre Fraigniaud, Juho Hirvonen", "title": "A hierarchy of local decision", "comments": "16 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the notion of distributed decision in the framework of distributed\nnetwork computing, inspired by recent results on so-called distributed graph\nautomata. We show that, by using distributed decision mechanisms based on the\ninteraction between a prover and a disprover, the size of the certificates\ndistributed to the nodes for certifying a given network property can be\ndrastically reduced. For instance, we prove that minimum spanning tree can be\ncertified with $O(\\log n)$-bit certificates in $n$-node graphs, with just one\ninteraction between the prover and the disprover, while it is known that\ncertifying MST requires $\\Omega(\\log^2 n)$-bit certificates if only the prover\ncan act. The improvement can even be exponential for some simple graph\nproperties. For instance, it is known that certifying the existence of a\nnontrivial automorphism requires $\\Omega(n^2)$ bits if only the prover can act.\nWe show that there is a protocol with two interactions between the prover and\nthe disprover enabling to certify nontrivial automorphism with $O(\\log n)$-bit\ncertificates. These results are achieved by defining and analysing a local\nhierarchy of decision which generalizes the classical notions of\nproof-labelling schemes and locally checkable proofs.\n", "versions": [{"version": "v1", "created": "Mon, 29 Feb 2016 12:04:26 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Feuilloley", "Laurent", ""], ["Fraigniaud", "Pierre", ""], ["Hirvonen", "Juho", ""]]}]