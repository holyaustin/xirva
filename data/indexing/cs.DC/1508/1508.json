[{"id": "1508.00036", "submitter": "Alexander Olshevsky", "authors": "Ali Jadbabaie, Alex Olshevsky", "title": "Scaling laws for consensus protocols subject to noise", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.SY math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the performance of discrete-time consensus protocols in the presence\nof additive noise. When the consensus dynamic corresponds to a reversible\nMarkov chain, we give an exact expression for a weighted version of\nsteady-state disagreement in terms of the stationary distribution and hitting\ntimes in an underlying graph. We then show how this result can be used to\ncharacterize the noise robustness of a class of protocols for formation control\nin terms of the Kemeny constant of an underlying graph.\n", "versions": [{"version": "v1", "created": "Fri, 31 Jul 2015 21:28:09 GMT"}, {"version": "v2", "created": "Mon, 10 Aug 2015 16:44:12 GMT"}, {"version": "v3", "created": "Tue, 7 Mar 2017 22:17:13 GMT"}], "update_date": "2017-03-09", "authors_parsed": [["Jadbabaie", "Ali", ""], ["Olshevsky", "Alex", ""]]}, {"id": "1508.00091", "submitter": "Yiling Yang", "authors": "Yiling Yang, Yu Huang, Jiannong Cao, Jian Lu", "title": "Understanding the Timed Distributed Trace of a Partially Synchronous\n  System at Runtime", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It has gained broad attention to understand the timed distributed trace of a\ncyber-physical system at runtime, which is often achieved by verifying\nproperties over the observed trace of system execution. However, this\nverification is facing severe challenges. First, in realistic settings, the\ncomputing entities only have imperfectly synchronized clocks. A proper timing\nmodel is essential to the interpretation of the trace of system execution.\nSecond, the specification should be able to express properties with real-time\nconstraints despite the asynchrony, and the semantics should be interpreted\nover the currently-observed and continuously-growing trace. To address these\nchallenges, we propose PARO - the partially synchronous system observation\nframework, which i) adopts the partially synchronous model of time, and\nintroduces the lattice and the timed automata theories to model the trace of\nsystem execution; ii) adopts a tailored subset of TCTL to specify temporal\nproperties, and defines the 3-valued semantics to interpret the properties over\nthe currently-observed finite trace; iii) constructs the timed automaton\ncorresponding to the trace at runtime, and reduces the satisfaction of the\n3-valued semantics over finite traces to that of the classical boolean\nsemantics over infinite traces. PARO is implemented over MIPA - the open-source\nmiddleware we developed. Performance measurements show the cost-effectiveness\nof PARO in different settings of key environmental factors.\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2015 07:00:42 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Yang", "Yiling", ""], ["Huang", "Yu", ""], ["Cao", "Jiannong", ""], ["Lu", "Jian", ""]]}, {"id": "1508.00115", "submitter": "Matthieu Schaller", "authors": "Tom Theuns (1), Aidan Chalk (2), Matthieu Schaller (1) and Pedro\n  Gonnet (2,3) ((1) ICC, Durham University, (2) ECS, Durham University, (3)\n  Google Switzerland)", "title": "SWIFT: task-based hydrodynamics and gravity for cosmological simulations", "comments": "Proceedings of the EASC 2015 conference, Edinburgh, UK, April 21-23,\n  2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "astro-ph.IM astro-ph.CO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Simulations of galaxy formation follow the gravitational and hydrodynamical\ninteractions between gas, stars and dark matter through cosmic time. The huge\ndynamic range of such calculations severely limits strong scaling behaviour of\nthe community codes in use, with load-imbalance, cache inefficiencies and poor\nvectorisation limiting performance. The new swift code exploits task-based\nparallelism designed for many-core compute nodes interacting via MPI using\nasynchronous communication to improve speed and scaling. A graph-based domain\ndecomposition schedules interdependent tasks over available resources. Strong\nscaling tests on realistic particle distributions yield excellent parallel\nefficiency, and efficient cache usage provides a large speed-up compared to\ncurrent codes even on a single core. SWIFT is designed to be easy to use by\nshielding the astronomer from computational details such as the construction of\nthe tasks or MPI communication. The techniques and algorithms used in SWIFT may\nbenefit other computational physics areas as well, for example that of\ncompressible hydrodynamics. For details of this open-source project, see\nwww.swiftsim.com\n", "versions": [{"version": "v1", "created": "Sat, 1 Aug 2015 12:26:30 GMT"}], "update_date": "2015-08-04", "authors_parsed": [["Theuns", "Tom", ""], ["Chalk", "Aidan", ""], ["Schaller", "Matthieu", ""], ["Gonnet", "Pedro", ""]]}, {"id": "1508.00691", "submitter": "Che Lin", "authors": "Po-Chun Fu, Pei-Rong Li, Li-Ming Wei, Chang-Lin Chen, and Che Lin", "title": "Deterministic Differential Search Algorithm for Distributed Sensor/Relay\n  Networks", "comments": "2 pages, 1 figure, conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For distributed sensor/relay networks, high reliability and power efficiency\nare often required. However, several implementation issues arise in practice.\nOne such problem is that all the distributed transmitters have limited power\nsupply since the power source of the transmitters cannot be recharged\ncontinually. To resolve this, distributed beamforming has been proposed as a\nviable solution where all distributed transmitters seek to align in phase at\nthe receiver end. However, it is difficult to implement such transmit\nbeamforming in a distributed fashion in practice since perfect channel state\ninformation (CSI) need to be made available at all distributed transmitters,\nrequiring tremendous overhead to feed back CSI from the receiver to all\ndistributed transmitters.\n  In this paper, we propose a novel algorithm that belongs to the category of\ndeterministic phase adjustment algorithm: the Deterministic Differential Search\nAlgorithm (DDSA), where the differences between the measured received signal\nstrength (RSS) are utilized judiciously to help us predict the deterministic\nphase adjustment done at distributed transmitters. Numerical simulations\ndemonstrate rapid convergence to a pre-determined threshold.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2015 08:00:25 GMT"}], "update_date": "2015-08-05", "authors_parsed": [["Fu", "Po-Chun", ""], ["Li", "Pei-Rong", ""], ["Wei", "Li-Ming", ""], ["Chen", "Chang-Lin", ""], ["Lin", "Che", ""]]}, {"id": "1508.00851", "submitter": "Kyrill Winkler", "authors": "Manfred Schwarz, Kyrill Winkler, Ulrich Schmid", "title": "Fast Consensus under Eventually Stabilizing Message Adversaries", "comments": "13 pages, 5 figures, updated references", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to deterministic consensus in synchronous dynamic\nnetworks with unidirectional links, which are under the control of an\nomniscient message adversary. Motivated by unpredictable node/system\ninitialization times and long-lasting periods of massive transient faults, we\nconsider message adversaries that guarantee periods of less erratic message\nloss only eventually: We present a tight bound of $2D+1$ for the termination\ntime of consensus under a message adversary that eventually guarantees a single\nvertex-stable root component with dynamic network diameter $D$, as well as a\nsimple algorithm that matches this bound. It effectively halves the termination\ntime $4D+1$ achieved by an existing consensus algorithm, which also works under\nour message adversary. We also introduce a generalized, considerably stronger\nvariant of our message adversary, and show that our new algorithm, unlike the\nexisting one, still works correctly under it.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2015 18:01:37 GMT"}, {"version": "v2", "created": "Wed, 5 Aug 2015 07:47:58 GMT"}], "update_date": "2015-08-06", "authors_parsed": [["Schwarz", "Manfred", ""], ["Winkler", "Kyrill", ""], ["Schmid", "Ulrich", ""]]}, {"id": "1508.00864", "submitter": "Mohammad Roohitavaf", "authors": "Mohammad Roohitavaf and Sandeep Kulkarni", "title": "Stabilization and Fault-Tolerance in Presence of Unchangeable\n  Environment Actions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We focus on the problem of adding fault-tolerance to an existing concurrent\nprotocol in the presence of {\\em unchangeable environment actions}. Such\nunchangeable actions occur in practice due to several reasons. One instance\nincludes the case where only a subset of the components/processes can be\nrevised and other components/processes must be as is. Another instance includes\ncyber-physical systems where revising physical components may be undesirable or\nimpossible. These actions differ from faults in that they are simultaneously\n{\\em assistive} and {\\em disruptive}, whereas faults are only disruptive. For\nexample, if these actions are a part of a physical component, their execution\nis essential for the normal operation of the system. However, they can\npotentially disrupt actions taken by other components for dealing with faults.\nAlso, one can typically assume that fault actions will stop for a long enough\ntime for the program to make progress. Such an assumption is impossible in this\ncontext.\n  We present algorithms for adding stabilizing fault-tolerance, failsafe\nfault-tolerance and masking fault-tolerance. Interestingly, we observe that the\nprevious approaches for adding stabilizing fault-tolerance and masking\nfault-tolerance cannot be easily extended in this context. However, we find\nthat the overall complexity of adding these levels of fault-tolerance remains\nin P (in the state space of the program). We also demonstrate that our\nalgorithms are sound and complete.\n", "versions": [{"version": "v1", "created": "Tue, 4 Aug 2015 18:46:19 GMT"}], "update_date": "2015-08-05", "authors_parsed": [["Roohitavaf", "Mohammad", ""], ["Kulkarni", "Sandeep", ""]]}, {"id": "1508.01171", "submitter": "Shantanu Sharma", "authors": "Foto Afrati, Shlomi Dolev, Shantanu Sharma, Jeffrey D. Ullman", "title": "Meta-MapReduce: A Technique for Reducing Communication in MapReduce\n  Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  MapReduce has proven to be one of the most useful paradigms in the revolution\nof distributed computing, where cloud services and cluster computing become the\nstandard venue for computing. The federation of cloud and big data activities\nis the next challenge where MapReduce should be modified to avoid (big) data\nmigration across remote (cloud) sites. This is exactly our scope of research,\nwhere only the very essential data for obtaining the result is transmitted,\nreducing communication, processing and preserving data privacy as much as\npossible. In this work, we propose an algorithmic technique for MapReduce\nalgorithms, called Meta-MapReduce, that decreases the communication cost by\nallowing us to process and move metadata to clouds and from the map phase to\nreduce phase. In Meta-MapReduce, the reduce phase fetches only the required\ndata at required iterations, which in turn, assists in preserving the data\nprivacy.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2015 18:54:32 GMT"}, {"version": "v2", "created": "Thu, 28 Jul 2016 16:48:26 GMT"}], "update_date": "2016-07-29", "authors_parsed": [["Afrati", "Foto", ""], ["Dolev", "Shlomi", ""], ["Sharma", "Shantanu", ""], ["Ullman", "Jeffrey D.", ""]]}, {"id": "1508.01182", "submitter": "Ying Li", "authors": "Ying Li, Katherine Guo, Xin Wang, Emina Soljanin, Thomas Woo", "title": "SEARS: Space Efficient And Reliable Storage System in the Cloud", "comments": "4 pages, IEEE LCN 2015", "journal-ref": null, "doi": "10.1109/LCN.2015.7366342", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Today's cloud storage services must offer storage reliability and fast data\nretrieval for large amount of data without sacrificing storage cost. We present\nSEARS, a cloud-based storage system which integrates erasure coding and data\ndeduplication to support efficient and reliable data storage with fast user\nresponse time. With proper association of data to storage server clusters,\nSEARS provides flexible mixing of different configurations, suitable for\nreal-time and archival applications.\n  Our prototype implementation of SEARS over Amazon EC2 shows that it\noutperforms existing storage systems in storage efficiency and file retrieval\ntime. For 3 MB files, SEARS delivers retrieval time of $2.5$ s compared to $7$\ns with existing systems.\n", "versions": [{"version": "v1", "created": "Wed, 5 Aug 2015 19:14:24 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Li", "Ying", ""], ["Guo", "Katherine", ""], ["Wang", "Xin", ""], ["Soljanin", "Emina", ""], ["Woo", "Thomas", ""]]}, {"id": "1508.01300", "submitter": "Emanuele Guido Fusco", "authors": "Emanuele G. Fusco and Andrzej Pelc", "title": "Knowledge, Level of Symmetry, and Time of Leader Election", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the time needed for deterministic leader election in the ${\\cal\nLOCAL}$ model, where in every round a node can exchange any messages with its\nneighbors and perform any local computations. The topology of the network is\nunknown and nodes are unlabeled, but ports at each node have arbitrary fixed\nlabelings which, together with the topology of the network, can create\nasymmetries to be exploited in leader election. We consider two versions of the\nleader election problem: strong LE in which exactly one leader has to be\nelected, if this is possible, while all nodes must terminate declaring that\nleader election is impossible otherwise, and weak LE, which differs from strong\nLE in that no requirement on the behavior of nodes is imposed, if leader\nelection is impossible. We show that the time of leader election depends on\nthree parameters of the network: its diameter $D$, its size $n$, and its level\nof symmetry $\\lambda$, which, when leader election is feasible, is the smallest\ndepth at which some node has a unique view of the network. It also depends on\nthe knowledge by the nodes, or lack of it, of parameters $D$ and $n$.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2015 07:42:31 GMT"}], "update_date": "2015-08-07", "authors_parsed": [["Fusco", "Emanuele G.", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1508.01326", "submitter": "Neda Abdollahi", "authors": "Neda Abdollahi, Mohammad Jafari, Morteza Bayat, Ali Amiri, Mahmood\n  Fathy", "title": "An efficient parallel algorithm for computing determinant of non square\n  matrices", "comments": "12 pages,4 tables in International journal of Distributed and\n  parallel systems(IJDPS),July 2015,vol 6, no 4", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most significant challenges in Computing Determinant of\nRectangular Matrices is high time complexity of its algorithm. Among all\ndefinitions of determinant of rectangular matrices, used definition has special\nfeatures which make it more notable. But in this definition, C(n m) sub\nmatrices of the order m*m needed to be generated that put this problem in NP\nhard class. On the other hand, any row or column reduction operation may hardly\nlead to diminish the volume of calculation. Therefore, in this paper we try to\npresent the parallel algorithm which can decrease the time complexity of\ncomputing the determinant of non-square matrices to O(pow(n,2)).\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2015 08:58:25 GMT"}], "update_date": "2015-08-07", "authors_parsed": [["Abdollahi", "Neda", ""], ["Jafari", "Mohammad", ""], ["Bayat", "Morteza", ""], ["Amiri", "Ali", ""], ["Fathy", "Mahmood", ""]]}, {"id": "1508.01412", "submitter": "Gary McGilvary Dr", "authors": "Gary A. McGilvary, Malcolm Atkinson, Sandra Gesing, Alvaro Aguilera,\n  Richard Grunzke and Eva Sciacca", "title": "Enhanced Usability of Managing Workflows in an Industrial Data Gateway", "comments": "Proceedings of the 1st International Workshop on Interoperable\n  Infrastructures for Interdisciplinary Big Data Sciences, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Grid and Cloud User Support Environment (gUSE) enables users convenient\nand easy access to grid and cloud infrastructures by providing a general\npurpose, workflow-oriented graphical user interface to create and run workflows\non various Distributed Computing Infrastructures (DCIs). Its arrangements for\ncreating and modifying existing workflows are, however, non-intuitive and\ncumbersome due to the technologies and architecture employed by gUSE. In this\npaper, we outline the first integrated web-based workflow editor for gUSE with\nthe aim of improving the user experience for those with industrial data\nworkflows and the wider gUSE community. We report initial assessments of the\neditor's utility based on users' feedback. We argue that combining access to\ndiverse scalable resources with improved workflow creation tools is important\nfor all big data applications and research infrastructures.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2015 14:16:31 GMT"}], "update_date": "2015-08-07", "authors_parsed": [["McGilvary", "Gary A.", ""], ["Atkinson", "Malcolm", ""], ["Gesing", "Sandra", ""], ["Aguilera", "Alvaro", ""], ["Grunzke", "Richard", ""], ["Sciacca", "Eva", ""]]}, {"id": "1508.01443", "submitter": "Ken Bloom", "authors": "Kenneth Bloom, Tommaso Boccali, Brian Bockelman, Daniel Bradley,\n  Sridhara Dasu, Jeff Dost, Federica Fanzago, Igor Sfiligoi, Alja Mrak Tadel,\n  Matevz Tadel, Carl Vuosalo, Frank W\\\"urthwein, Avi Yagil and Marian Zvada", "title": "Any Data, Any Time, Anywhere: Global Data Access for Science", "comments": "9 pages, 6 figures, submitted to 2nd IEEE/ACM International Symposium\n  on Big Data Computing (BDC) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC hep-ex physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data access is key to science driven by distributed high-throughput computing\n(DHTC), an essential technology for many major research projects such as High\nEnergy Physics (HEP) experiments. However, achieving efficient data access\nbecomes quite difficult when many independent storage sites are involved\nbecause users are burdened with learning the intricacies of accessing each\nsystem and keeping careful track of data location. We present an alternate\napproach: the Any Data, Any Time, Anywhere infrastructure. Combining several\nexisting software products, AAA presents a global, unified view of storage\nsystems - a \"data federation,\" a global filesystem for software delivery, and a\nworkflow management system. We present how one HEP experiment, the Compact Muon\nSolenoid (CMS), is utilizing the AAA infrastructure and some simple performance\nmetrics.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2015 16:01:36 GMT"}], "update_date": "2015-08-07", "authors_parsed": [["Bloom", "Kenneth", ""], ["Boccali", "Tommaso", ""], ["Bockelman", "Brian", ""], ["Bradley", "Daniel", ""], ["Dasu", "Sridhara", ""], ["Dost", "Jeff", ""], ["Fanzago", "Federica", ""], ["Sfiligoi", "Igor", ""], ["Tadel", "Alja Mrak", ""], ["Tadel", "Matevz", ""], ["Vuosalo", "Carl", ""], ["W\u00fcrthwein", "Frank", ""], ["Yagil", "Avi", ""], ["Zvada", "Marian", ""]]}, {"id": "1508.01504", "submitter": "Vijaya Ramachandran", "authors": "Richard Cole and Vijaya Ramachandran", "title": "Resource Oblivious Sorting on Multicores", "comments": "A version very similar to this appears in ACM Transactions on\n  Parallel Computing (TOPC), Vol. 3, No. 4, Article 23, 2017. The current\n  version adds some additional citations to earlier sorting algorithms, and a\n  comparison to Sharesort", "journal-ref": "ACM Transactions on Parallel Computing (TOPC), Vol. 3, No. 4,\n  Article 23, 2017", "doi": "10.1145/3040221", "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a deterministic sorting algorithm, SPMS (Sample, Partition, and\nMerge Sort), that interleaves the partitioning of a sample sort with merging.\nSequentially, it sorts $n$ elements in $O(n \\log n)$ time cache-obliviously\nwith an optimal number of cache misses. The parallel complexity (or critical\npath length) of the algorithm is $O(\\log n \\cdot \\log\\log n)$, which improves\non previous bounds for optimal cache oblivious sorting. The algorithm also has\nlow false sharing costs. When scheduled by a work-stealing scheduler in a\nmulticore computing environment with a global shared memory and $p$ cores, each\nhaving a cache of size $M$ organized in blocks of size $B$, the costs of the\nadditional cache misses and false sharing misses due to this parallel execution\nare bounded by the cost of $O(S\\cdot M/B)$ and $O(S \\cdot B)$ cache misses\nrespectively, where $S$ is the number of steals performed during the execution.\nFinally, SPMS is resource oblivious in Athat the dependence on machine\nparameters appear only in the analysis of its performance, and not within the\nalgorithm itself.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2015 19:32:53 GMT"}, {"version": "v2", "created": "Thu, 2 Nov 2017 14:45:19 GMT"}], "update_date": "2017-11-03", "authors_parsed": [["Cole", "Richard", ""], ["Ramachandran", "Vijaya", ""]]}, {"id": "1508.01549", "submitter": "Uday Kamath Dr.", "authors": "Uday Kamath, Carlotta Domeniconi and Kenneth De Jong", "title": "Theoretical and Empirical Analysis of a Parallel Boosting Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Many real-world problems involve massive amounts of data. Under these\ncircumstances learning algorithms often become prohibitively expensive, making\nscalability a pressing issue to be addressed. A common approach is to perform\nsampling to reduce the size of the dataset and enable efficient learning.\nAlternatively, one customizes learning algorithms to achieve scalability. In\neither case, the key challenge is to obtain algorithmic efficiency without\ncompromising the quality of the results. In this paper we discuss a\nmeta-learning algorithm (PSBML) which combines features of parallel algorithms\nwith concepts from ensemble and boosting methodologies to achieve the desired\nscalability property. We present both theoretical and empirical analyses which\nshow that PSBML preserves a critical property of boosting, specifically,\nconvergence to a distribution centered around the margin. We then present\nadditional empirical analyses showing that this meta-level algorithm provides a\ngeneral and effective framework that can be used in combination with a variety\nof learning classifiers. We perform extensive experiments to investigate the\ntradeoff achieved between scalability and accuracy, and robustness to noise, on\nboth synthetic and real-world data. These empirical results corroborate our\ntheoretical analysis, and demonstrate the potential of PSBML in achieving\nscalability without sacrificing accuracy.\n", "versions": [{"version": "v1", "created": "Thu, 6 Aug 2015 21:54:34 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Kamath", "Uday", ""], ["Domeniconi", "Carlotta", ""], ["De Jong", "Kenneth", ""]]}, {"id": "1508.01572", "submitter": "Yukio Hayashi", "authors": "Yukio Hayashi", "title": "Recoverable DTN Routing based on a Relay of Cyclic Message-Ferries on a\n  MSQ Network", "comments": "6 pages, 12 figures, The 3rd Workshop on the FoCAS(Fundamentals of\n  Collective Adaptive Systems) at The 9th IEEE International Conference on\n  SASO(Self-Adaptive and Self-Organizing systems), Boston, USA, Sept.21, 2015", "journal-ref": null, "doi": "10.1109/SASOW.2015.11", "report-no": null, "categories": "cs.DC cs.NI cs.SI nlin.AO physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An interrelation between a topological design of network and efficient\nalgorithm on it is important for its applications to communication or\ntransportation systems. In this paper, we propose a design principle for a\nreliable routing in a store-carry-forward manner based on autonomously moving\nmessage-ferries on a special structure of fractal-like network, which consists\nof a self-similar tiling of equilateral triangles. As a collective adaptive\nmechanism, the routing is realized by a relay of cyclic message-ferries\ncorresponded to a concatenation of the triangle cycles and using some good\nproperties of the network structure. It is recoverable for local accidents in\nthe hierarchical network structure. Moreover, the design principle is\ntheoretically supported with a calculation method for the optimal service rates\nof message-ferries derived from a tandem queue model for stochastic processes\non a chain of edges in the network. These results obtained from a combination\nof complex network science and computer science will be useful for developing a\nresilient network system.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 00:06:30 GMT"}, {"version": "v2", "created": "Wed, 19 Aug 2015 01:54:51 GMT"}, {"version": "v3", "created": "Tue, 1 Sep 2015 02:07:01 GMT"}], "update_date": "2016-11-18", "authors_parsed": [["Hayashi", "Yukio", ""]]}, {"id": "1508.01633", "submitter": "Ruiliang Zhang", "authors": "Ruiliang Zhang, Shuai Zheng, James T. Kwok", "title": "Asynchronous Distributed Semi-Stochastic Gradient Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the recent proliferation of large-scale learning problems,there have\nbeen a lot of interest on distributed machine learning algorithms, particularly\nthose that are based on stochastic gradient descent (SGD) and its variants.\nHowever, existing algorithms either suffer from slow convergence due to the\ninherent variance of stochastic gradients, or have a fast linear convergence\nrate but at the expense of poorer solution quality. In this paper, we combine\ntheir merits by proposing a fast distributed asynchronous SGD-based algorithm\nwith variance reduction. A constant learning rate can be used, and it is also\nguaranteed to converge linearly to the optimal solution. Experiments on the\nGoogle Cloud Computing Platform demonstrate that the proposed algorithm\noutperforms state-of-the-art distributed asynchronous algorithms in terms of\nboth wall clock time and solution quality.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 07:54:47 GMT"}, {"version": "v2", "created": "Fri, 4 Dec 2015 06:33:34 GMT"}], "update_date": "2015-12-07", "authors_parsed": [["Zhang", "Ruiliang", ""], ["Zheng", "Shuai", ""], ["Kwok", "James T.", ""]]}, {"id": "1508.01660", "submitter": "Iosif Salem", "authors": "Iosif Salem, Elad M. Schiller, Marina Papatriantafilou, Philippas\n  Tsigas", "title": "Shared-object System Equilibria: Delay and Throughput Analysis", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider shared-object systems that require their threads to fulfill the\nsystem jobs by first acquiring sequentially the objects needed for the jobs and\nthen holding on to them until the job completion. Such systems are in the core\nof a variety of shared-resource allocation and synchronization systems. This\nwork opens a new perspective to study the expected job delay and throughput\nanalytically, given the possible set of jobs that may join the system\ndynamically.\n  We identify the system dependencies that cause contention among the threads\nas they try to acquire the job objects. We use these observations to define the\nshared-object system equilibria. We note that the system is in equilibrium\nwhenever the rate in which jobs arrive at the system matches the job completion\nrate. These equilibria consider not only the job delay but also the job\nthroughput, as well as the time in which each thread blocks other threads in\norder to complete its job. We then further study in detail the thread work\ncycles and, by using a graph representation of the problem, we are able to\npropose procedures for finding and estimating equilibria, i.e., discovering the\njob delay and throughput, as well as the blocking time.\n  To the best of our knowledge, this is a new perspective, that can provide\nbetter analytical tools for the problem, in order to estimate performance\nmeasures similar to ones that can be acquired through experimentation on\nworking systems and simulations, e.g., as job delay and throughput in\n(distributed) shared-object systems.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 11:26:12 GMT"}, {"version": "v2", "created": "Tue, 3 Nov 2015 01:55:44 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Salem", "Iosif", ""], ["Schiller", "Elad M.", ""], ["Papatriantafilou", "Marina", ""], ["Tsigas", "Philippas", ""]]}, {"id": "1508.01703", "submitter": "Kasra Madadipouya", "authors": "Mohammad Ahmadi, Mostafa Vali, Farez Moghaddam, Aida Hakemi, Kasra\n  Madadipouya", "title": "A Reliable User Authentication and Data Protection Model in Cloud\n  Computing Environments", "comments": "4 pages in International Conference on Information, System and\n  Convergence Applications June 24-27, 2015 in Kuala Lumpur, Malaysia", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Security issues are the most challenging problems in cloud computing\nenvironments as an emerging technology. Regarding to this importance, an\nefficient and reliable user authentication and data protection model has been\npresented in this paper to increase the rate of reliability cloud-based\nenvironments. Accordingly, two encryption procedures have been established in\nan independent middleware (Agent) to perform the process of user\nauthentication, access control, and data protection in cloud servers. AES has\nbeen used as a symmetric cryptography algorithm in cloud servers and RSA has\nbeen used as an asymmetric cryptography algorithm in Agent servers. The\ntheoretical evaluation of the proposed model shows that the ability of\nresistance in face with possible attacks and unpredictable events has been\nenhanced considerably in comparison with similar models because of using dual\nencryption and an independent middleware during user authentication and data\nprotection procedures.\n", "versions": [{"version": "v1", "created": "Fri, 7 Aug 2015 14:24:14 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Ahmadi", "Mohammad", ""], ["Vali", "Mostafa", ""], ["Moghaddam", "Farez", ""], ["Hakemi", "Aida", ""], ["Madadipouya", "Kasra", ""]]}, {"id": "1508.01847", "submitter": "Pengfei Xuan", "authors": "Pengfei Xuan, Jeffrey Denton, Rong Ge, Pradip K. Srimani, Feng Luo", "title": "Big Data Analytics on Traditional HPC Infrastructure Using Two-Level\n  Storage", "comments": "Submitted to SC15, 8 pages, 7 figures, 3 tables", "journal-ref": null, "doi": "10.1145/2831244.2831253", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Data-intensive computing has become one of the major workloads on traditional\nhigh-performance computing (HPC) clusters. Currently, deploying data-intensive\ncomputing software framework on HPC clusters still faces performance and\nscalability issues. In this paper, we develop a new two-level storage system by\nintegrating Tachyon, an in-memory file system with OrangeFS, a parallel file\nsystem. We model the I/O throughputs of four storage structures: HDFS,\nOrangeFS, Tachyon and two-level storage. We conduct computational experiments\nto characterize I/O throughput behavior of two-level storage and compare its\nperformance to that of HDFS and OrangeFS, using TeraSort benchmark. Theoretical\nmodels and experimental tests both show that the two-level storage system can\nincrease the aggregate I/O throughputs. This work lays a solid foundation for\nfuture work in designing and building HPC systems that can provide a better\nsupport on I/O intensive workloads with preserving existing computing\nresources.\n", "versions": [{"version": "v1", "created": "Sat, 8 Aug 2015 02:23:27 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2015 22:55:55 GMT"}, {"version": "v3", "created": "Sat, 10 Oct 2015 01:50:57 GMT"}], "update_date": "2015-10-13", "authors_parsed": [["Xuan", "Pengfei", ""], ["Denton", "Jeffrey", ""], ["Ge", "Rong", ""], ["Srimani", "Pradip K.", ""], ["Luo", "Feng", ""]]}, {"id": "1508.02111", "submitter": "Yuqing Zhu", "authors": "Yuqing Zhu, Yilei Wang, Fan Wang", "title": "10 Observations on Google Cluster Trace + 2 Measures for Cluster\n  Utilization Enhancement", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Utilization enhancement is a key concern to cluster owners. Google's cluster\nmanager named Borg manages its clusters at an overall utilization higher than\nmany others' clusters. Recently, Google has disclosed the details of its\npowerful cluster manager Borg. Quite a few lessons are summarized from the Borg\nexperiences. Nevertheless, we find that more can be learned if the Borg design\nis correlated with the trace analysis of a Google cluster managed by Borg.\nThere is one such trace released four years ago. In this paper, we analyze the\nGoogle cluster trace and make 10 observations not found in previous analyses.\nWe also correlates the results of our analysis and previous analyses to the\nBorg design, such that we find two measures that can possibly further improve\ncluster utilization over Borg.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 02:40:17 GMT"}, {"version": "v2", "created": "Tue, 11 Aug 2015 08:51:08 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Zhu", "Yuqing", ""], ["Wang", "Yilei", ""], ["Wang", "Fan", ""]]}, {"id": "1508.02344", "submitter": "Jiaming Xu", "authors": "Elchanan Mossel and Jiaming Xu", "title": "Local Algorithms for Block Models with Side Information", "comments": "Due to the limitation \"The abstract field cannot be longer than 1,920\n  characters\", the abstract here is shorter than that in the PDF file", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.CC cs.DC math.PR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has been a recent interest in understanding the power of local\nalgorithms for optimization and inference problems on sparse graphs. Gamarnik\nand Sudan (2014) showed that local algorithms are weaker than global algorithms\nfor finding large independent sets in sparse random regular graphs. Montanari\n(2015) showed that local algorithms are suboptimal for finding a community with\nhigh connectivity in the sparse Erd\\H{o}s-R\\'enyi random graphs. For the\nsymmetric planted partition problem (also named community detection for the\nblock models) on sparse graphs, a simple observation is that local algorithms\ncannot have non-trivial performance.\n  In this work we consider the effect of side information on local algorithms\nfor community detection under the binary symmetric stochastic block model. In\nthe block model with side information each of the $n$ vertices is labeled $+$\nor $-$ independently and uniformly at random; each pair of vertices is\nconnected independently with probability $a/n$ if both of them have the same\nlabel or $b/n$ otherwise. The goal is to estimate the underlying vertex\nlabeling given 1) the graph structure and 2) side information in the form of a\nvertex labeling positively correlated with the true one. Assuming that the\nratio between in and out degree $a/b$ is $\\Theta(1)$ and the average degree $\n(a+b) / 2 = n^{o(1)}$, we characterize three different regimes under which a\nlocal algorithm, namely, belief propagation run on the local neighborhoods,\nmaximizes the expected fraction of vertices labeled correctly. Thus, in\ncontrast to the case of symmetric block models without side information, we\nshow that local algorithms can achieve optimal performance for the block model\nwith side information.\n", "versions": [{"version": "v1", "created": "Mon, 10 Aug 2015 18:23:27 GMT"}], "update_date": "2015-08-11", "authors_parsed": [["Mossel", "Elchanan", ""], ["Xu", "Jiaming", ""]]}, {"id": "1508.02471", "submitter": "Avery Miller", "authors": "Avery Miller, Andrzej Pelc", "title": "Time Versus Cost Tradeoffs for Deterministic Rendezvous in Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Two mobile agents, starting from different nodes of a network at possibly\ndifferent times, have to meet at the same node. This problem is known as\n$\\mathit{rendezvous}$. Agents move in synchronous rounds. Each agent has a\ndistinct integer label from the set $\\{1,\\dots,L\\}$. Two main efficiency\nmeasures of rendezvous are its $\\mathit{time}$ (the number of rounds until the\nmeeting) and its $\\mathit{cost}$ (the total number of edge traversals). We\ninvestigate tradeoffs between these two measures. A natural benchmark for both\ntime and cost of rendezvous in a network is the number of edge traversals\nneeded for visiting all nodes of the network, called the exploration time.\nHence we express the time and cost of rendezvous as functions of an upper bound\n$E$ on the time of exploration (where $E$ and a corresponding exploration\nprocedure are known to both agents) and of the size $L$ of the label space. We\npresent two natural rendezvous algorithms. Algorithm $\\mathtt{Cheap}$ has cost\n$O(E)$ (and, in fact, a version of this algorithm for the model where the\nagents start simultaneously has cost exactly $E$) and time $O(EL)$. Algorithm\n$\\mathtt{Fast}$ has both time and cost $O(E\\log L)$. Our main contributions are\nlower bounds showing that, perhaps surprisingly, these two algorithms capture\nthe tradeoffs between time and cost of rendezvous almost tightly. We show that\nany deterministic rendezvous algorithm of cost asymptotically $E$ (i.e., of\ncost $E+o(E)$) must have time $\\Omega(EL)$. On the other hand, we show that any\ndeterministic rendezvous algorithm with time complexity $O(E\\log L)$ must have\ncost $\\Omega (E\\log L)$.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 02:12:33 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Miller", "Avery", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1508.02535", "submitter": "Joel Rybicki", "authors": "Christoph Lenzen, Joel Rybicki, Jukka Suomela", "title": "Efficient counting with optimal resilience", "comments": "25 pages, 1 figure. Extended and revised version of two conference\n  reports", "journal-ref": null, "doi": "10.1137/16M107877X", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consider a complete communication network of $n$ nodes, where the nodes\nreceive a common clock pulse. We study the synchronous $c$-counting problem:\ngiven any starting state and up to $f$ faulty nodes with arbitrary behaviour,\nthe task is to eventually have all correct nodes labeling the pulses with\nincreasing values modulo $c$ in agreement. Thus, we are considering algorithms\nthat are self-stabilising despite Byzantine failures. In this work, we give new\nalgorithms for the synchronous counting problem that (1) are deterministic, (2)\nhave optimal resilience, (3) have a linear stabilisation time in $f$\n(asymptotically optimal), (4) use a small number of states, and consequently,\n(5) communicate a small number of bits per round. Prior algorithms either\nresort to randomisation, use a large number of states and need high\ncommunication bandwidth, or have suboptimal resilience. In particular, we\nachieve an exponential improvement in both state complexity and message size\nfor deterministic algorithms. Moreover, we present two complementary approaches\nfor reducing the number of bits communicated during and after stabilisation.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 09:39:32 GMT"}, {"version": "v2", "created": "Wed, 15 Jun 2016 09:42:51 GMT"}, {"version": "v3", "created": "Thu, 18 May 2017 14:43:57 GMT"}], "update_date": "2019-12-24", "authors_parsed": [["Lenzen", "Christoph", ""], ["Rybicki", "Joel", ""], ["Suomela", "Jukka", ""]]}, {"id": "1508.02558", "submitter": "Blesson Varghese", "authors": "Blesson Varghese and Javier Prades and Carlos Reano and Federico Silla", "title": "Acceleration-as-a-Service: Exploiting Virtualised GPUs for a Financial\n  Application", "comments": "11th IEEE International Conference on eScience (IEEE eScience) -\n  Munich, Germany, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  'How can GPU acceleration be obtained as a service in a cluster?' This\nquestion has become increasingly significant due to the inefficiency of\ninstalling GPUs on all nodes of a cluster. The research reported in this paper\nis motivated to address the above question by employing rCUDA (remote CUDA), a\nframework that facilitates Acceleration-as-a-Service (AaaS), such that the\nnodes of a cluster can request the acceleration of a set of remote GPUs on\ndemand. The rCUDA framework exploits virtualisation and ensures that multiple\nnodes can share the same GPU. In this paper we test the feasibility of the\nrCUDA framework on a real-world application employed in the financial risk\nindustry that can benefit from AaaS in the production setting. The results\nconfirm the feasibility of rCUDA and highlight that rCUDA achieves similar\nperformance compared to CUDA, provides consistent results, and more\nimportantly, allows for a single application to benefit from all the GPUs\navailable in the cluster without loosing efficiency.\n", "versions": [{"version": "v1", "created": "Tue, 11 Aug 2015 11:18:14 GMT"}], "update_date": "2015-08-12", "authors_parsed": [["Varghese", "Blesson", ""], ["Prades", "Javier", ""], ["Reano", "Carlos", ""], ["Silla", "Federico", ""]]}, {"id": "1508.03087", "submitter": "Lavanya Subramanian", "authors": "Lavanya Subramanian", "title": "Providing High and Controllable Performance in Multicore Systems Through\n  Shared Resource Management", "comments": "CMU PhD Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multiple applications executing concurrently on a multicore system interfere\nwith each other at different shared resources such as main memory and shared\ncaches. Such inter-application interference, if uncontrolled, results in high\nsystem performance degradation and unpredictable application slowdowns. While\nprevious work has proposed application-aware memory scheduling as a solution to\nmitigate inter-application interference and improve system performance,\npreviously proposed memory scheduling techniques incur high hardware complexity\nand unfairly slowdown some applications. Furthermore, previously proposed\nmemory-interference mitigation techniques are not designed to precisely control\napplication performance.\n  This dissertation seeks to achieve high and controllable performance in\nmulticore systems by mitigating and quantifying the impact of shared resource\ninterference. First, towards mitigating memory interference and achieving high\nperformance, we propose the Blacklisting memory scheduler that achieves high\nperformance and fairness at low complexity. Next, towards quantifying the\nimpact of memory interference and achieving controllable performance in the\npresence of memory bandwidth interference, we propose the Memory Interference\ninduced Slowdown Estimation (MISE) model. We propose and demonstrate two use\ncases that can leverage MISE to provide soft performance guarantees and high\noverall performance/fairness. Finally, we seek to quantify the impact of shared\ncache interference on application slowdowns, in addition to memory bandwidth\ninterference. Towards this end, we propose the Application Slowdown Model\n(ASM). We propose and demonstrate several use cases of ASM that leverage it to\nprovide soft performance guarantees and improve performance and fairness.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2015 22:39:13 GMT"}], "update_date": "2015-08-14", "authors_parsed": [["Subramanian", "Lavanya", ""]]}, {"id": "1508.03110", "submitter": "Michael B Hynes", "authors": "Manda Winlaw, Michael B. Hynes, Anthony Caterini, Hans De Sterck", "title": "Algorithmic Acceleration of Parallel ALS for Collaborative Filtering:\n  Speeding up Distributed Big Data Recommendation in Spark", "comments": "Proceedings of ICPADS 2015, Melbourne, AU. 10 pages; 6 figures; 4\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.NA cs.DC cs.IR cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Collaborative filtering algorithms are important building blocks in many\npractical recommendation systems. For example, many large-scale data processing\nenvironments include collaborative filtering models for which the Alternating\nLeast Squares (ALS) algorithm is used to compute latent factor matrix\ndecompositions. In this paper, we propose an approach to accelerate the\nconvergence of parallel ALS-based optimization methods for collaborative\nfiltering using a nonlinear conjugate gradient (NCG) wrapper around the ALS\niterations. We also provide a parallel implementation of the accelerated\nALS-NCG algorithm in the Apache Spark distributed data processing environment,\nand an efficient line search technique as part of the ALS-NCG implementation\nthat requires only one pass over the data on distributed datasets. In serial\nnumerical experiments on a linux workstation and parallel numerical experiments\non a 16 node cluster with 256 computing cores, we demonstrate that the combined\nALS-NCG method requires many fewer iterations and less time than standalone ALS\nto reach movie rankings with high accuracy on the MovieLens 20M dataset. In\nparallel, ALS-NCG can achieve an acceleration factor of 4 or greater in clock\ntime when an accurate solution is desired; furthermore, the acceleration factor\nincreases as greater numerical precision is required in the solution. In\naddition, the NCG acceleration mechanism is efficient in parallel and scales\nlinearly with problem size on synthetic datasets with up to nearly 1 billion\nratings. The acceleration mechanism is general and may also be applicable to\nother optimization methods for collaborative filtering.\n", "versions": [{"version": "v1", "created": "Thu, 13 Aug 2015 03:37:04 GMT"}, {"version": "v2", "created": "Wed, 28 Oct 2015 16:53:49 GMT"}, {"version": "v3", "created": "Sun, 10 Jan 2016 23:52:03 GMT"}], "update_date": "2016-01-12", "authors_parsed": [["Winlaw", "Manda", ""], ["Hynes", "Michael B.", ""], ["Caterini", "Anthony", ""], ["De Sterck", "Hans", ""]]}, {"id": "1508.03235", "submitter": "Aryabartta Sahu", "authors": "Navin Kumar, Aryabartta Sahu", "title": "Bufferless NOC Simulation of Large Multicore System on GPU Hardware", "comments": "14 pages, 6 figures, Indicon14", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  Last level cache management and core interconnection network play important\nroles in performance and power consumption in multicore system. Large scale\nchip multicore uses mesh interconnect widely due to scalability and simplicity\nof the mesh interconnection design. As interconnection network occupied\nsignificant area and consumes significant percent of system power, bufferless\nnetwork is an appealing alternative design to reduce power consumption and\nhardware cost. We have designed and implemented a simulator for simulation of\ndistributed cache management of large chip multicore where cores are connected\nusing bufferless interconnection network. Also, we have redesigned and\nimplemented the our simulator which is a GPU compatible parallel version of the\nsame simulator using CUDA programming model. We have simulated target large\nchip multicore with up to 43,000 cores and achieved up to 25 times speedup on\nNVIDIA GeForce GTX 690 GPU over serial simulation.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2015 04:55:44 GMT"}], "update_date": "2015-08-14", "authors_parsed": [["Kumar", "Navin", ""], ["Sahu", "Aryabartta", ""]]}, {"id": "1508.03236", "submitter": "Aryabartta Sahu", "authors": "T.K. Agrawal, R. Sharma, M. Ghose, A. Sahu", "title": "Scheduling Chained Multiprocessor Tasks onto Large Multiprocessor System", "comments": "14 pages, 21 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  In this paper, we proposed an effective approach for scheduling of\nmultiprocessor unit time tasks with chain precedence on to large multiprocessor\nsystem. The proposed longest chain maximum processor scheduling algorithm is\nproved to be optimal for uniform chains and monotone\n(non-increasing/non-decreasing) chains for both splitable and non-splitable\nmultiprocessor unit time tasks chain. Scheduling arbitrary chains of\nnon-splitable multiprocessor unit time tasks is proved to be NP-complete\nproblem. But scheduling arbitrary chains of splitable multiprocessor unit time\ntasks is still an open problem to be proved whether it is NP-complete or can be\nsolved in polynomial time. We have used three heuristics (a) maximum\ncriticality first, (b) longest chain maximum criticality first and (c) longest\nchain maximum processor first for scheduling of arbitrary chains. Also compared\nperformance of all three scheduling heuristics and found out that the proposed\nlongest chain maximum processor first performs better in most of the cases.\n", "versions": [{"version": "v1", "created": "Wed, 12 Aug 2015 08:07:57 GMT"}], "update_date": "2015-08-14", "authors_parsed": [["Agrawal", "T. K.", ""], ["Sharma", "R.", ""], ["Ghose", "M.", ""], ["Sahu", "A.", ""]]}, {"id": "1508.03519", "submitter": "Dominik Kaaser", "authors": "Dominik Kaaser, Frederik Mallmann-Trenn, Emanuele Natale", "title": "On the Voting Time of the Deterministic Majority Process", "comments": "full version of brief announcement accepted at DISC'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the deterministic binary majority process we are given a simple graph\nwhere each node has one out of two initial opinions. In every round, every node\nadopts the majority opinion among its neighbors. By using a potential argument\nfirst discovered by Goles and Olivos (1980), it is known that this process\nalways converges in $O(|E|)$ rounds to a two-periodic state in which every node\neither keeps its opinion or changes it in every round.\n  It has been shown by Frischknecht, Keller, and Wattenhofer (2013) that the\n$O(|E|)$ bound on the convergence time of the deterministic binary majority\nprocess is indeed tight even for dense graphs. However, in many graphs such as\nthe complete graph, from any initial opinion assignment, the process converges\nin just a constant number of rounds.\n  By carefully exploiting the structure of the potential function by Goles and\nOlivos (1980), we derive a new upper bound on the convergence time of the\ndeterministic binary majority process that accounts for such exceptional cases.\nWe show that it is possible to identify certain modules of a graph $G$ in order\nto obtain a new graph $G^\\Delta$ with the property that the worst-case\nconvergence time of $G^\\Delta$ is an upper bound on that of $G$. Moreover, even\nthough our upper bound can be computed in linear time, we show that, given an\ninteger $k$, it is NP-hard to decide whether there exists an initial opinion\nassignment for which it takes more than $k$ rounds to converge to the\ntwo-periodic state.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 14:42:14 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Kaaser", "Dominik", ""], ["Mallmann-Trenn", "Frederik", ""], ["Natale", "Emanuele", ""]]}, {"id": "1508.03566", "submitter": "Paul Renaud-Goud", "authors": "Aras Atalar and Paul Renaud-Goud and Philippas Tsigas", "title": "Analyzing the Performance of Lock-Free Data Structures: A Conflict-based\n  Model", "comments": "Short version to appear in DISC'15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the modeling and the analysis of the performance of\nlock-free concurrent data structures. Lock-free designs employ an optimistic\nconflict control mechanism, allowing several processes to access the shared\ndata object at the same time. They guarantee that at least one concurrent\noperation finishes in a finite number of its own steps regardless of the state\nof the operations. Our analysis considers such lock-free data structures that\ncan be represented as linear combinations of fixed size retry loops. Our main\ncontribution is a new way of modeling and analyzing a general class of\nlock-free algorithms, achieving predictions of throughput that are close to\nwhat we observe in practice. We emphasize two kinds of conflicts that shape the\nperformance: (i) hardware conflicts, due to concurrent calls to atomic\nprimitives; (ii) logical conflicts, caused by simultaneous operations on the\nshared data structure. We show how to deal with these hardware and logical\nconflicts separately, and how to combine them, so as to calculate the\nthroughput of lock-free algorithms. We propose also a common framework that\nenables a fair comparison between lock-free implementations by covering the\nwhole contention domain, together with a better understanding of the\nperformance impacting factors. This part of our analysis comes with a method\nfor calculating a good back-off strategy to finely tune the performance of a\nlock-free algorithm. Our experimental results, based on a set of widely used\nconcurrent data structures and on abstract lock-free designs, show that our\nanalysis follows closely the actual code behavior.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 16:43:56 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Atalar", "Aras", ""], ["Renaud-Goud", "Paul", ""], ["Tsigas", "Philippas", ""]]}, {"id": "1508.03579", "submitter": "Jeremy Fineman", "authors": "Michael Dinitz, Jeremy T. Fineman, Seth Gilbert, Calvin Newport", "title": "Smoothed Analysis of Dynamic Networks", "comments": "20 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We generalize the technique of smoothed analysis to distributed algorithms in\ndynamic network models. Whereas standard smoothed analysis studies the impact\nof small random perturbations of input values on algorithm performance metrics,\ndynamic graph smoothed analysis studies the impact of random perturbations of\nthe underlying changing network graph topologies. Similar to the original\napplication of smoothed analysis, our goal is to study whether known strong\nlower bounds in dynamic network models are robust or fragile: do they withstand\nsmall (random) perturbations, or do such deviations push the graphs far enough\nfrom a precise pathological instance to enable much better performance? Fragile\nlower bounds are likely not relevant for real-world deployment, while robust\nlower bounds represent a true difficulty caused by dynamic behavior. We apply\nthis technique to three standard dynamic network problems with known strong\nworst-case lower bounds: random walks, flooding, and aggregation. We prove that\nthese bounds provide a spectrum of robustness when subjected to\nsmoothing---some are extremely fragile (random walks), some are moderately\nfragile / robust (flooding), and some are extremely robust (aggregation).\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 17:53:55 GMT"}], "update_date": "2015-08-17", "authors_parsed": [["Dinitz", "Michael", ""], ["Fineman", "Jeremy T.", ""], ["Gilbert", "Seth", ""], ["Newport", "Calvin", ""]]}, {"id": "1508.03599", "submitter": "Gauri Joshi", "authors": "Gauri Joshi, Emina Soljanin, and Gregory Wornell", "title": "Efficient Redundancy Techniques for Latency Reduction in Cloud Systems", "comments": "accepted for publication in ACM Transactions on Modeling and\n  Performance Evaluation of Computing Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In cloud computing systems, assigning a task to multiple servers and waiting\nfor the earliest copy to finish is an effective method to combat the\nvariability in response time of individual servers, and reduce latency. But\nadding redundancy may result in higher cost of computing resources, as well as\nan increase in queueing delay due to higher traffic load. This work helps\nunderstand when and how redundancy gives a cost-efficient reduction in latency.\nFor a general task service time distribution, we compare different redundancy\nstrategies in terms of the number of redundant tasks, and time when they are\nissued and canceled. We get the insight that the log-concavity of the task\nservice time creates a dichotomy of when adding redundancy helps. If the\nservice time distribution is log-convex (i.e. log of the tail probability is\nconvex) then adding maximum redundancy reduces both latency and cost. And if it\nis log-concave (i.e. log of the tail probability is concave), then less\nredundancy, and early cancellation of redundant tasks is more effective. Using\nthese insights, we design a general redundancy strategy that achieves a good\nlatency-cost trade-off for an arbitrary service time distribution. This work\nalso generalizes and extends some results in the analysis of fork-join queues.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 18:37:10 GMT"}, {"version": "v2", "created": "Tue, 27 Oct 2015 17:28:35 GMT"}, {"version": "v3", "created": "Wed, 12 Apr 2017 14:13:34 GMT"}], "update_date": "2017-04-13", "authors_parsed": [["Joshi", "Gauri", ""], ["Soljanin", "Emina", ""], ["Wornell", "Gregory", ""]]}, {"id": "1508.03619", "submitter": "Scott Beamer", "authors": "Scott Beamer, Krste Asanovi\\'c, David Patterson", "title": "The GAP Benchmark Suite", "comments": "small revisions to correspond to v1.0", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a graph processing benchmark suite with the goal of helping to\nstandardize graph processing evaluations. Fewer differences between graph\nprocessing evaluations will make it easier to compare different research\nefforts and quantify improvements. The benchmark not only specifies graph\nkernels, input graphs, and evaluation methodologies, but it also provides\noptimized baseline implementations. These baseline implementations are\nrepresentative of state-of-the-art performance, and thus new contributions\nshould outperform them to demonstrate an improvement.\n  The input graphs are sized appropriately for shared memory platforms, but any\nimplementation on any platform that conforms to the benchmark's specifications\ncould be compared. This benchmark suite can be used in a variety of settings.\nGraph framework developers can demonstrate the generality of their programming\nmodel by implementing all of the benchmark's kernels and delivering competitive\nperformance on all of the benchmark's graphs. Algorithm designers can use the\ninput graphs and the baseline implementations to demonstrate their\ncontribution. Platform designers and performance analysts can use the suite as\na workload representative of graph processing.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 19:46:48 GMT"}, {"version": "v2", "created": "Fri, 2 Oct 2015 23:40:36 GMT"}, {"version": "v3", "created": "Tue, 6 Oct 2015 17:51:24 GMT"}, {"version": "v4", "created": "Tue, 16 May 2017 19:14:14 GMT"}], "update_date": "2017-05-18", "authors_parsed": [["Beamer", "Scott", ""], ["Asanovi\u0107", "Krste", ""], ["Patterson", "David", ""]]}, {"id": "1508.03660", "submitter": "Erez Kantor", "authors": "Keren Censor-Hillel, Erez Kantor, Nancy Lynch and Merav Parter", "title": "Computing in Additive Networks with Bounded-Information Codes", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IT cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper studies the theory of the additive wireless network model, in\nwhich the received signal is abstracted as an addition of the transmitted\nsignals. Our central observation is that the crucial challenge for computing in\nthis model is not high contention, as assumed previously, but rather\nguaranteeing a bounded amount of \\emph{information} in each neighborhood per\nround, a property that we show is achievable using a new random coding\ntechnique.\n  Technically, we provide efficient algorithms for fundamental distributed\ntasks in additive networks, such as solving various symmetry breaking problems,\napproximating network parameters, and solving an \\emph{asymmetry revealing}\nproblem such as computing a maximal input.\n  The key method used is a novel random coding technique that allows a node to\nsuccessfully decode the received information, as long as it does not contain\ntoo many distinct values. We then design our algorithms to produce a limited\namount of information in each neighborhood in order to leverage our enriched\ntoolbox for computing in additive networks.\n", "versions": [{"version": "v1", "created": "Fri, 14 Aug 2015 21:00:11 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Censor-Hillel", "Keren", ""], ["Kantor", "Erez", ""], ["Lynch", "Nancy", ""], ["Parter", "Merav", ""]]}, {"id": "1508.03714", "submitter": "Quentin Bramas", "authors": "Quentin Bramas (1), S\\'ebastien Tixeuil (1,2) ((1) NPA, LIP6, UPMC,\n  LINCS, (2) IUF)", "title": "Probabilistic Asynchronous Arbitrary Pattern Formation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MA cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a new probabilistic pattern formation algorithm for oblivious\nmobile robots that operates inthe ASYNC model. Unlike previous work, our\nalgorithm makes no assumptions about the local coordinatesystems of robots (the\nrobots do not share a common \"North\" nor a common \"Right\"), yet it preserves\ntheability from any initial configuration that contains at least 5 robots to\nform any general pattern (and not justpatterns that satisfy symmetricity\npredicates). Our proposal also gets rid of the previous assumption (in thesame\nmodel) that robots do not pause while moving (so, our robots really are fully\nasynchronous), and theamount of randomness is kept low -- a single random bit\nper robot per Look-Compute-Move cycle is used.Our protocol consists in the\ncombination of two phases, a probabilistic leader election phase, and a\ndeterministicpattern formation one. As the deterministic phase does not use\nchirality, it may be of independentinterest in the deterministic context. A\nnoteworthy feature of our algorithm is the ability to form patternswith\nmultiplicity points (except the gathering case due to impossibility results), a\nnew feature in the contextof pattern formation that we believe is an important\nasset of our approach.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2015 09:09:11 GMT"}, {"version": "v2", "created": "Mon, 14 Mar 2016 10:35:31 GMT"}, {"version": "v3", "created": "Wed, 20 Sep 2017 14:11:11 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Bramas", "Quentin", ""], ["Tixeuil", "S\u00e9bastien", ""]]}, {"id": "1508.03762", "submitter": "Gregory Chockler", "authors": "Gregory Chockler, Dan Dobre, Alexander Shraer, Alexander Spiegelman", "title": "Space Bounds for Reliable Multi-Writer Data Store: Inherent Cost of\n  Read/Write Primitives", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Reliable storage emulations from fault-prone components have established\nthemselves as an algorithmic foundation of modern storage services and\napplications. Most existing reliable storage emulations are built from storage\nservices supporting arbitrary read-modify-write primitives. Since such\nprimitives are not typically exposed by pre-existing or off-the-shelf\ncomponents (such as cloud storage services or network-attached disks) it is\nnatural to ask if they are indeed essential for efficient storage emulations.\nIn this paper, we answer this question in the affirmative. We show that\nrelaxing the underlying storage to only support read/write operations leads to\na linear blow-up in the emulation space requirements. We also show that the\nspace complexity is not adaptive to concurrency, which implies that the storage\ncannot be reliably reclaimed even in sequential runs. On a positive side, we\nshow that Compare-and-Swap primitives, which are commonly available with many\noff-the-shelf storage services, can be used to emulate a reliable multi-writer\natomic register with constant storage and adaptive time complexity.\n", "versions": [{"version": "v1", "created": "Sat, 15 Aug 2015 19:00:28 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Chockler", "Gregory", ""], ["Dobre", "Dan", ""], ["Shraer", "Alexander", ""], ["Spiegelman", "Alexander", ""]]}, {"id": "1508.03859", "submitter": "Calvin Newport", "authors": "Seth Gilbert and Calvin Newport", "title": "The Computational Power of Beeps", "comments": "Extended abstract to appear in the Proceedings of the International\n  Symposium on Distributed Computing (DISC 2015)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we study the quantity of computational resources (state\nmachine states and/or probabilistic transition precision) needed to solve\nspecific problems in a single hop network where nodes communicate using only\nbeeps. We begin by focusing on randomized leader election. We prove a lower\nbound on the states required to solve this problem with a given error bound,\nprobability precision, and (when relevant) network size lower bound. We then\nshow the bound tight with a matching upper bound. Noting that our optimal upper\nbound is slow, we describe two faster algorithms that trade some state\noptimality to gain efficiency. We then turn our attention to more general\nclasses of problems by proving that once you have enough states to solve leader\nelection with a given error bound, you have (within constant factors) enough\nstates to simulate correctly, with this same error bound, a logspace TM with a\nconstant number of unary input tapes: allowing you to solve a large and\nexpressive set of problems. These results identify a key simplicity threshold\nbeyond which useful distributed computation is possible in the beeping model.\n", "versions": [{"version": "v1", "created": "Sun, 16 Aug 2015 19:58:37 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Gilbert", "Seth", ""], ["Newport", "Calvin", ""]]}, {"id": "1508.03908", "submitter": "EPTCS", "authors": "Nosheen Gul (University of Leicester, England)", "title": "A Calculus of Mobility and Communication for Ubiquitous Computing", "comments": "In Proceedings WWV 2015, arXiv:1508.03389", "journal-ref": "EPTCS 188, 2015, pp. 6-22", "doi": "10.4204/EPTCS.188.3", "report-no": null, "categories": "cs.DC cs.LO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Calculus of Mobility and Communication (CMC) for the modelling\nof mobility, communication and context-awareness in the setting of ubiquitous\ncomputing. CMC is an ambient calculus with the in and out capabilities of\nCardelli and Gordon's Mobile Ambients. The calculus has a new form of global\ncommunication similar to that in Milner's CCS. In CMC an ambient is tagged with\na set of ports that agents executing inside the ambient are allowed to\ncommunicate on. It also has a new context-awareness feature that allows\nambients to query their location. We present reduction semantics and labelled\ntransition system semantics of CMC and prove that the semantics coincide. A new\nnotion of behavioural equivalence is given by defining capability barbed\nbisimulation and congruence which is proved to coincide with barbed\nbisimulation congruence. The expressiveness of the calculus is illustrated by\ntwo case studies.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 01:59:25 GMT"}], "update_date": "2015-08-18", "authors_parsed": [["Gul", "Nosheen", "", "University of Leicester, England"]]}, {"id": "1508.04180", "submitter": "Matteo Turilli", "authors": "Matteo Turilli, Mark Santcroos, Shantenu Jha", "title": "A Comprehensive Perspective on Pilot-Job Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Pilot-Job systems play an important role in supporting distributed scientific\ncomputing. They are used to consume more than 700 million CPU hours a year by\nthe Open Science Grid communities, and by processing up to 1 million jobs a day\nfor the ATLAS experiment on the Worldwide LHC Computing Grid. With the\nincreasing importance of task-level parallelism in high-performance computing,\nPilot-Job systems are also witnessing an adoption beyond traditional domains.\nNotwithstanding the growing impact on scientific research, there is no\nagreement upon a definition of Pilot-Job system and no clear understanding of\nthe underlying abstraction and paradigm. Pilot-Job implementations have\nproliferated with no shared best practices or open interfaces and little\ninteroperability. Ultimately, this is hindering the realization of the full\nimpact of Pilot-Jobs by limiting their robustness, portability, and\nmaintainability. This paper offers a comprehensive analysis of Pilot-Job\nsystems critically assessing their motivations, evolution, properties, and\nimplementation. The three main contributions of this paper are: (i) an analysis\nof the motivations and evolution of Pilot-Job systems; (ii) an outline of the\nPilot abstraction, its distinguishing logical components and functionalities,\nits terminology, and its architecture pattern; and (iii) the description of\ncore and auxiliary properties of Pilot-Jobs systems and the analysis of seven\nexemplar Pilot-Job implementations. Together, these contributions illustrate\nthe Pilot paradigm, its generality, and how it helps to address some challenges\nin distributed scientific computing.\n", "versions": [{"version": "v1", "created": "Mon, 17 Aug 2015 23:53:51 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2015 21:17:36 GMT"}, {"version": "v3", "created": "Sat, 5 Mar 2016 13:34:27 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Turilli", "Matteo", ""], ["Santcroos", "Mark", ""], ["Jha", "Shantenu", ""]]}, {"id": "1508.04186", "submitter": "Hao Yi Ong", "authors": "Hao Yi Ong, Kevin Chavez, Augustus Hong", "title": "Distributed Deep Q-Learning", "comments": "Updated figure of distributed deep learning architecture, updated\n  content throughout paper including dealing with minor grammatical issues and\n  highlighting differences of our paper with respect to prior work. arXiv admin\n  note: text overlap with arXiv:1312.5602 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.AI cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a distributed deep learning model to successfully learn control\npolicies directly from high-dimensional sensory input using reinforcement\nlearning. The model is based on the deep Q-network, a convolutional neural\nnetwork trained with a variant of Q-learning. Its input is raw pixels and its\noutput is a value function estimating future rewards from taking an action\ngiven a system state. To distribute the deep Q-network training, we adapt the\nDistBelief software framework to the context of efficiently training\nreinforcement learning agents. As a result, the method is completely\nasynchronous and scales well with the number of machines. We demonstrate that\nthe deep Q-network agent, receiving only the pixels and the game score as\ninputs, was able to achieve reasonable success on a simple game with minimal\nparameter tuning.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 01:00:32 GMT"}, {"version": "v2", "created": "Thu, 15 Oct 2015 09:06:38 GMT"}], "update_date": "2015-10-16", "authors_parsed": [["Ong", "Hao Yi", ""], ["Chavez", "Kevin", ""], ["Hong", "Augustus", ""]]}, {"id": "1508.04234", "submitter": "Amitabh Trehan", "authors": "Armando Castaneda, Danny Dolev and Amitabh Trehan", "title": "Compact Routing Messages in Self-Healing Trees", "comments": "Under Submission", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Existing compact routing schemes, e.g., Thorup and Zwick [SPAA 2001] and\nChechik [PODC 2013], often have no means to tolerate failures, once the system\nhas been setup and started. This paper presents, to our knowledge, the first\nself-healing compact routing scheme. Besides, our schemes are developed for low\nmemory nodes, i.e., nodes need only $O(\\log^2 n)$ memory, and are thus, compact\nschemes.\n  We introduce two algorithms of independent interest: The first is CompactFT,\na novel compact version (using only $O(\\log n)$ local memory) of the\nself-healing algorithm Forgiving Tree of Hayes et al. [PODC 2008]. The second\nalgorithm (CompactFTZ) combines CompactFT with Thorup-Zwick's tree-based\ncompact routing scheme [SPAA 2001] to produce a fully compact self-healing\nrouting scheme. In the self-healing model, the adversary deletes nodes one at a\ntime with the affected nodes self-healing locally by adding few edges.\nCompactFT recovers from each attack in only $O(1)$ time and $\\Delta$ messages,\nwith only +3 degree increase and $O(log \\Delta)$ graph diameter increase, over\nany sequence of deletions ($\\Delta$ is the initial maximum degree).\n  Additionally, CompactFTZ guarantees delivery of a packet sent from sender s\nas long as the receiver t has not been deleted, with only an additional $O(y\n\\log \\Delta)$ latency, where $y$ is the number of nodes that have been deleted\non the path between $s$ and $t$. If $t$ has been deleted, $s$ gets informed and\nthe packet removed from the network.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 07:47:55 GMT"}], "update_date": "2015-08-19", "authors_parsed": [["Castaneda", "Armando", ""], ["Dolev", "Danny", ""], ["Trehan", "Amitabh", ""]]}, {"id": "1508.04265", "submitter": "Ravikant Dindokar", "authors": "Ravikant Dindokar, Neel Choudhury, Yogesh Simmhan", "title": "A Meta-graph Approach to Analyze Subgraph-centric Distributed\n  Programming Models", "comments": null, "journal-ref": "Proceedings of the IEEE International Conference on Big Data (Big\n  Data), Washington DC, 2016", "doi": "10.1109/BigData.2016.7840587", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Component-centric distributed graph processing platforms that use a bulk\nsynchronous parallel (BSP) programming model have gained traction. These\naddress the short-comings of Big Data abstractions/platforms like\nMapReduce/Hadoop for large-scale graph processing. However, there is limited\nliterature on foundational aspects of the behavior of these component-centric\nabstractions for different graphs, graph partitioning, and graph algorithms.\nHere, we propose a analytical approach based on a meta-graph sketch to examine\nthe characteristics of component-centric graph programming models at a coarse\ngranularity. In particular, we apply this sketch to subgraph- and block-centric\nabstractions, and draw a comparison with vertex-centric models like Google's\nPregel. First, we explore the impact of various graph partitioning techniques\non the meta-graph, and next consider the impact of the meta-graph on graph\nalgorithms. This decouples the unwieldy large graph and their partitioning\nspecific artifacts from their algorithmic analysis. We use 5 spatial and\npowerlaw graphs as exemplars, four different partitioning strategies, and\nPageRank and Breadth First Search as canonical algorithms. These analysis over\nthe meta-graphs provide a reliable measure of the expected number of\nsupersteps, and the communication and computational complexity of the\nalgorithms for various graphs, and the relative merits of subgraph-centric\nmodels over vertex-centric ones.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 09:57:07 GMT"}, {"version": "v2", "created": "Mon, 31 Oct 2016 05:26:46 GMT"}], "update_date": "2019-05-13", "authors_parsed": [["Dindokar", "Ravikant", ""], ["Choudhury", "Neel", ""], ["Simmhan", "Yogesh", ""]]}, {"id": "1508.04278", "submitter": "Fabian Fuchs", "authors": "Fabian Fuchs, Matthias Wolf", "title": "On the Distributed Computation of Fractional Connected Dominating Set\n  Packings", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One of the most fundamental problems in wireless networks is to achieve high\nthroughput. Fractional Connected Dominating Set (FCDS) Packings can achieve a\nthroughput of ${\\Theta}(k/\\log n)$ messages for networks with node connectivity\n$k$, which is optimal regarding routing-based message transmission. FCDS were\nproposed by Censor-Hillel \\emph{et al.} [SODA'14,PODC'14] and are a natural\ngeneralization to Connected Dominating Sets (CDS), allowing each node to\nparticipate with a fraction of its weight in multiple FCDS. Thus, $\\Omega(k)$\nco-existing transmission backbones are established, taking full advantage of\nthe networks connectivity. We propose a modified distributed algorithm that\nimproves upon previous algorithms for $k\\Delta \\in o(\\min\\{\\frac{n \\log n}{k}\n,D,\\sqrt{n \\log n} \\log^* n\\}\\log n)$, where $\\Delta$ is the maximum node\ndegree, $D$ the diameter and $n$ the number of nodes in the network. We achieve\nthis by explicitly computing connections between tentative dominating sets.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 11:28:39 GMT"}], "update_date": "2015-08-19", "authors_parsed": [["Fuchs", "Fabian", ""], ["Wolf", "Matthias", ""]]}, {"id": "1508.04390", "submitter": "Sebastian Daum", "authors": "Sebastian Daum and Fabian Kuhn", "title": "Tight Bounds for MIS in Multichannel Radio Networks", "comments": "37 pages, to be published in DISC 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Daum et al. [PODC'13] presented an algorithm that computes a maximal\nindependent set (MIS) within $O(\\log^2 n/F+\\log n \\mathrm{polyloglog} n)$\nrounds in an $n$-node multichannel radio network with $F$ communication\nchannels. The paper uses a multichannel variant of the standard graph-based\nradio network model without collision detection and it assumes that the network\ngraph is a polynomially bounded independence graph (BIG), a natural\ncombinatorial generalization of well-known geographic families. The upper bound\nof that paper is known to be optimal up to a polyloglog factor.\n  In this paper, we adapt algorithm and analysis to improve the result in two\nways. Mainly, we get rid of the polyloglog factor in the runtime and we thus\nobtain an asymptotically optimal multichannel radio network MIS algorithm. In\naddition, our new analysis allows to generalize the class of graphs from those\nwith polynomially bounded local independence to graphs where the local\nindependence is bounded by an arbitrary function of the neighborhood radius.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 17:25:34 GMT"}], "update_date": "2015-08-19", "authors_parsed": [["Daum", "Sebastian", ""], ["Kuhn", "Fabian", ""]]}, {"id": "1508.04465", "submitter": "Cristina Lopes", "authors": "Arthur Valadares, Eugenia Gabrielova, Cristina V. Lopes", "title": "On Designing and Testing Distributed Virtual Environments", "comments": "Wiley Journal on Concurrency and Computation: Practice and\n  Experience, to appear (preprint)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed Real-Time (DRT) systems are among the most complex software\nsystems to design, test, maintain and evolve. The existence of components\ndistributed over a network often conflicts with real-time requirements, leading\nto design strategies that depend on domain- and even application-specific\nknowledge. Distributed Virtual Environment (DVE) systems are DRT systems that\nconnect multiple users instantly with each other and with a shared virtual\nspace over a network. DVE systems deviate from traditional DRT systems in the\nimportance of the quality of the end user experience. We present an analysis of\nimportant, but challenging, issues in the design, testing and evaluation of DVE\nsystems through the lens of experiments with a concrete DVE, OpenSimulator. We\nframe our observations within six dimensions of well-known design concerns:\ncorrectness, fault tolerance/prevention, scalability, time sensitivity,\nconsistency, and overhead of distribution. Furthermore, we place our\nexperimental work in a broader historical context, showing that these\nchallenges are intrinsic to DVEs and suggesting lines of future research.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 21:50:23 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Valadares", "Arthur", ""], ["Gabrielova", "Eugenia", ""], ["Lopes", "Cristina V.", ""]]}, {"id": "1508.04537", "submitter": "Jun He", "authors": "Hao Wu, Jun He, Bo Li, Yijian Pei", "title": "Personalized QoS Prediction of Cloud Services via Learning\n  Neighborhood-based Model", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The explosion of cloud services on the Internet brings new challenges in\nservice discovery and selection. Particularly, the demand for efficient\nquality-of-service (QoS) evaluation is becoming urgently strong. To address\nthis issue, this paper proposes neighborhood-based approach for QoS prediction\nof cloud services by taking advantages of collaborative intelligence. Different\nfrom heuristic collaborative filtering and matrix factorization, we define a\nformal neighborhood-based prediction framework which allows an efficient global\noptimization scheme, and then exploit different baseline estimate component to\nimprove predictive performance. To validate the proposed methods, a large-scale\nQoS-specific dataset which consists of invocation records from 339 service\nusers on 5,825 web services on a world-scale distributed network is used.\nExperimental results demonstrate that the learned neighborhood-based models can\novercome existing difficulties of heuristic collaborative filtering methods and\nachieve superior performance than state-of-the-art prediction methods.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2015 06:32:54 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Wu", "Hao", ""], ["He", "Jun", ""], ["Li", "Bo", ""], ["Pei", "Yijian", ""]]}, {"id": "1508.04544", "submitter": "Georgios Chasparis", "authors": "Georgios C. Chasparis, Martina Maggio, Enrico Bini, Karl-Eric\n  {\\AA}rz\\'en", "title": "Design and Implementation of Distributed Resource Management for Time\n  Sensitive Applications", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "math.OC cs.DC cs.MA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we address distributed convergence to fair allocations of CPU\nresources for time-sensitive applications. We propose a novel resource\nmanagement framework where a centralized objective for fair allocations is\ndecomposed into a pair of performance-driven recursive processes for updating:\n(a) the allocation of computing bandwidth to the applications (resource\nadaptation), executed by the resource manager, and (b) the service level of\neach application (service-level adaptation), executed by each application\nindependently. We provide conditions under which the distributed recursive\nscheme exhibits convergence to solutions of the centralized objective (i.e.,\nfair allocations). Contrary to prior work on centralized optimization schemes,\nthe proposed framework exhibits adaptivity and robustness to changes both in\nthe number and nature of applications, while it assumes minimum information\navailable to both applications and the resource manager. We finally validate\nour framework with simulations using the TrueTime toolbox in MATLAB/Simulink.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2015 07:09:47 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Chasparis", "Georgios C.", ""], ["Maggio", "Martina", ""], ["Bini", "Enrico", ""], ["\u00c5rz\u00e9n", "Karl-Eric", ""]]}, {"id": "1508.04731", "submitter": "Ali Pinar", "authors": "Maher Salloum, Janine C. Bennett, Ali Pinar, Ankit Bhagatwala,\n  Jacqueline H. Chen", "title": "Enabling adaptive scientific workflows via trigger detection", "comments": "arXiv admin note: substantial text overlap with arXiv:1506.08258", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Next generation architectures necessitate a shift away from traditional\nworkflows in which the simulation state is saved at prescribed frequencies for\npost-processing analysis. While the need to shift to in~situ workflows has been\nacknowledged for some time, much of the current research is focused on static\nworkflows, where the analysis that would have been done as a post-process is\nperformed concurrently with the simulation at user-prescribed frequencies.\nRecently, research efforts are striving to enable adaptive workflows, in which\nthe frequency, composition, and execution of computational and data\nmanipulation steps dynamically depend on the state of the simulation. Adapting\nthe workflow to the state of simulation in such a data-driven fashion puts\nextremely strict efficiency requirements on the analysis capabilities that are\nused to identify the transitions in the workflow. In this paper we build upon\nearlier work on trigger detection using sublinear techniques to drive adaptive\nworkflows. Here we propose a methodology to detect the time when sudden heat\nrelease occurs in simulations of turbulent combustion. Our proposed method\nprovides an alternative metric that can be used along with our former metric to\nincrease the robustness of trigger detection. We show the effectiveness of our\nmetric empirically for predicting heat release for two use cases.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2015 18:29:21 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Salloum", "Maher", ""], ["Bennett", "Janine C.", ""], ["Pinar", "Ali", ""], ["Bhagatwala", "Ankit", ""], ["Chen", "Jacqueline H.", ""]]}, {"id": "1508.04733", "submitter": "Mansaf Alam Dr", "authors": "Samiya Khan, Kashish Ara Shakil, and Mansaf Alam", "title": "Cloud based Big Data Analytics: A Survey of Current Research and Future\n  Directions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of the digital age has led to a rise in different types of data\nwith every passing day. In fact, it is expected that half of the total data\nwill be on the cloud by 2016. This data is complex and needs to be stored,\nprocessed and analyzed for information that can be used by organizations. Cloud\ncomputing provides an apt platform for big data analytics in view of the\nstorage and computing requirements of the latter. This makes cloud-based\nanalytics a viable research field. However, several issues need to be addressed\nand risks need to be mitigated before practical applications of this\nsynergistic model can be popularly used. This paper explores the existing\nresearch, challenges, open issues and future research direction for this field\nof study.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 15:38:09 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Khan", "Samiya", ""], ["Shakil", "Kashish Ara", ""], ["Alam", "Mansaf", ""]]}, {"id": "1508.04747", "submitter": "Fabian Kuhn", "authors": "Mohsen Ghaffari and Andreas Karrenbauer and Fabian Kuhn and Christoph\n  Lenzen and Boaz Patt-Shamir", "title": "Near-Optimal Distributed Maximum Flow", "comments": "34 pages, 5 figures, conference version appeared in ACM Symp. on\n  Principles of Distributed Computing (PODC) 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a near-optimal distributed algorithm for $(1+o(1))$-approximation\nof single-commodity maximum flow in undirected weighted networks that runs in\n$(D+ \\sqrt{n})\\cdot n^{o(1)}$ communication rounds in the \\Congest model. Here,\n$n$ and $D$ denote the number of nodes and the network diameter, respectively.\nThis is the first improvement over the trivial bound of $O(n^2)$, and it nearly\nmatches the $\\tilde{\\Omega}(D+ \\sqrt{n})$ round complexity lower bound.\n  The development of the algorithm contains two results of independent\ninterest:\n  (i) A $(D+\\sqrt{n})\\cdot n^{o(1)}$-round distributed construction of a\nspanning tree of average stretch $n^{o(1)}$.\n  (ii) A $(D+\\sqrt{n})\\cdot n^{o(1)}$-round distributed construction of an\n$n^{o(1)}$-congestion approximator consisting of the cuts induced by $O(\\log\nn)$ virtual trees. The distributed representation of the cut approximator\nallows for evaluation in $(D+\\sqrt{n})\\cdot n^{o(1)}$ rounds.\n  All our algorithms make use of randomization and succeed with high\nprobability.\n", "versions": [{"version": "v1", "created": "Wed, 19 Aug 2015 19:17:55 GMT"}], "update_date": "2015-08-20", "authors_parsed": [["Ghaffari", "Mohsen", ""], ["Karrenbauer", "Andreas", ""], ["Kuhn", "Fabian", ""], ["Lenzen", "Christoph", ""], ["Patt-Shamir", "Boaz", ""]]}, {"id": "1508.04856", "submitter": "EPTCS", "authors": "C\\'esar Santos (Lasige, Faculty of Sciences, University of Lisbon,\n  Portugal), Francisco Martins (Lasige, Faculty of Sciences, University of\n  Lisbon, Portugal), Vasco Thudichum Vasconcelos (Lasige, Faculty of Sciences,\n  University of Lisbon, Portugal)", "title": "Deductive Verification of Parallel Programs Using Why3", "comments": "In Proceedings ICE 2015, arXiv:1508.04595", "journal-ref": "EPTCS 189, 2015, pp. 128-142", "doi": "10.4204/EPTCS.189.11", "report-no": null, "categories": "cs.PL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Message Passing Interface specification (MPI) defines a portable\nmessage-passing API used to program parallel computers. MPI programs manifest a\nnumber of challenges on what concerns correctness: sent and expected values in\ncommunications may not match, resulting in incorrect computations possibly\nleading to crashes; and programs may deadlock resulting in wasted resources.\nExisting tools are not completely satisfactory: model-checking does not scale\nwith the number of processes; testing techniques wastes resources and are\nhighly dependent on the quality of the test set.\n  As an alternative, we present a prototype for a type-based approach to\nprogramming and verifying MPI like programs against protocols. Protocols are\nwritten in a dependent type language designed so as to capture the most common\nprimitives in MPI, incorporating, in addition, a form of primitive recursion\nand collective choice. Protocols are then translated into Why3, a deductive\nsoftware verification tool. Source code, in turn, is written in WhyML, the\nlanguage of the Why3 platform, and checked against the protocol. Programs that\npass verification are guaranteed to be communication safe and free from\ndeadlocks.\n  We verified several parallel programs from textbooks using our approach, and\nreport on the outcome.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 01:43:19 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Santos", "C\u00e9sar", "", "Lasige, Faculty of Sciences, University of Lisbon,\n  Portugal"], ["Martins", "Francisco", "", "Lasige, Faculty of Sciences, University of\n  Lisbon, Portugal"], ["Vasconcelos", "Vasco Thudichum", "", "Lasige, Faculty of Sciences,\n  University of Lisbon, Portugal"]]}, {"id": "1508.04863", "submitter": "Yustinus Soelistio Eko", "authors": "Yustinus Eko Soelistio", "title": "Application Distribution Model In Volunteer Computing Environment Using\n  Peer-to-Peer Torrent Like Approach", "comments": "6 pages, Published in proceeding of 2013 International Conference on\n  Computer, Control, Informatics and Its Applications (IC3INA)", "journal-ref": null, "doi": "10.1109/IC3INA.2013.6819184", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Volunteer computing has been known as an alternative solution to solve\ncomplex problems. It is acknowledged for its simplicity and its ability to work\non multiple operating systems. Nonetheless, setting up a server for volunteer\ncomputing can be time consuming and relatively complex to be implemented. This\npaper offer a model which can ease the effort of setting up a server by making\nthe agent works two ways, as seeder and leecher, like P2P torrent approaches.\nThe model consists of measurement units to manage applications to be\ndistributed, system hierarchy, and basic procedures for the server and the\nagent. The model has been tested in four scenarios using 2,000,000 to 3,000,000\ninteger data employing up to six nodes. The tests demonstrate speedup in three\nof the scenarios.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 03:15:23 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Soelistio", "Yustinus Eko", ""]]}, {"id": "1508.04907", "submitter": "Li Su", "authors": "Li Su, Yongluan Zhou", "title": "Tolerating Correlated Failures in Massively Parallel Stream Processing\n  Engines", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Fault-tolerance techniques for stream processing engines can be categorized\ninto passive and active approaches. A typical passive approach periodically\ncheckpoints a processing task's runtime states and can recover a failed task by\nrestoring its runtime state using its latest checkpoint. On the other hand, an\nactive approach usually employs backup nodes to run replicated tasks. Upon\nfailure, the active replica can take over the processing of the failed task\nwith minimal latency. However, both approaches have their own inadequacies in\nMassively Parallel Stream Processing Engines (MPSPE). The passive approach\nincurs a long recovery latency especially when a number of correlated nodes\nfail simultaneously, while the active approach requires extra replication\nresources. In this paper, we propose a new fault-tolerance framework, which is\nPassive and Partially Active (PPA). In a PPA scheme, the passive approach is\napplied to all tasks while only a selected set of tasks will be actively\nreplicated. The number of actively replicated tasks depends on the available\nresources. If tasks without active replicas fail, tentative outputs will be\ngenerated before the completion of the recovery process. We also propose\neffective and efficient algorithms to optimize a partially active replication\nplan to maximize the quality of tentative outputs. We implemented PPA on top of\nStorm, an open-source MPSPE and conducted extensive experiments using both real\nand synthetic datasets to verify the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 08:01:58 GMT"}, {"version": "v2", "created": "Thu, 4 Feb 2016 16:02:54 GMT"}], "update_date": "2016-02-05", "authors_parsed": [["Su", "Li", ""], ["Zhou", "Yongluan", ""]]}, {"id": "1508.04973", "submitter": "Srdjan Krstic", "authors": "Giovanni Paolo Gibilisco, Srdan Krstic", "title": "InstaCluster: Building A Big Data Cluster in Minutes", "comments": "5 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deploying, configuring, and managing large clusters is very a demanding and\ncumbersome task due to the complexity of such systems and the variety of skills\nneeded. One needs to perform low-level configuration of the cluster nodes to\nensure their interoperability and connectivity, as well as install, configure\nand provision the needed services.\n  In this paper we address this problem and demonstrate how to build a Big Data\nanalytic platform on Amazon EC2 in a matter of minutes. Moreover, to use our\ntool, embedded into a public Amazon Machine Image, the user does not need to be\nan expert in system administration or Big Data service configuration. Our tool\ndramatically reduces the time needed to provision clusters, as well as the cost\nof the infrastructure. Researchers enjoy an additional benefit of having a\nsimple way to specify the experimental environments they use, so that their\nexperiments can be easily reproduced by anyone using our tool.\n", "versions": [{"version": "v1", "created": "Thu, 20 Aug 2015 13:09:56 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Gibilisco", "Giovanni Paolo", ""], ["Krstic", "Srdan", ""]]}, {"id": "1508.05075", "submitter": "Volker Weinberg", "authors": "Momme Allalen, David Brayford, Daniele Tafani, Volker Weinberg (LRZ),\n  Bernd Mohr, Dirk Br\\\"ommel, Rene Halver, Jan Meinke, Sandipan Mohanty (JSC)", "title": "The Mont-Blanc Project: First Phase Successfully Finished", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Running from October 2011 to June 2015, the aim of the European project\nMont-Blanc has been to develop an approach to Exascale computing based on\nembedded power-efficient technology. The main goals of the project were to i)\nbuild an HPC prototype using currently available energy-efficient embedded\ntechnology, ii) design a Next Generation system to overcome the limitations of\nthe built prototype and iii) port a set of representative Exascale applications\nto the system. This article summarises the contributions from the Leibniz\nSupercomputing Centre (LRZ) and the Juelich Supercomputing Centre (JSC),\nGermany, to the Mont-Blanc project.\n", "versions": [{"version": "v1", "created": "Tue, 18 Aug 2015 16:26:30 GMT"}], "update_date": "2015-08-21", "authors_parsed": [["Allalen", "Momme", "", "LRZ"], ["Brayford", "David", "", "LRZ"], ["Tafani", "Daniele", "", "LRZ"], ["Weinberg", "Volker", "", "LRZ"], ["Mohr", "Bernd", "", "JSC"], ["Br\u00f6mmel", "Dirk", "", "JSC"], ["Halver", "Rene", "", "JSC"], ["Meinke", "Jan", "", "JSC"], ["Mohanty", "Sandipan", "", "JSC"]]}, {"id": "1508.05545", "submitter": "Christian Weilbach", "authors": "Christian Weilbach, Konrad K\\\"uhne, Annette Bieniusa", "title": "Decoupling conflicts for configurable resolution in an open replication\n  system", "comments": "6 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Replikativ is a replication middleware supporting a new kind of confluent\nreplicated datatype resembling a distributed version control system. It retains\nthe order of write operations at the trade-off of reduced availability with\nafter-the- fact conflict resolution. The system allows to develop applications\nwith distributed state in a similar fashion as native applications with\nexclusive local state, while transparently exposing the necessary compromises\nin terms of the CAP theorem. In this paper, we give a specification of the\nreplicated datatype and discuss its usage in the replikativ middleware.\nExperiments with the implementation show the feasibility of the concept as a\nfoundation for replication as a service (RaaS).\n", "versions": [{"version": "v1", "created": "Sat, 22 Aug 2015 20:19:53 GMT"}, {"version": "v2", "created": "Thu, 14 Jan 2016 08:40:06 GMT"}], "update_date": "2016-01-15", "authors_parsed": [["Weilbach", "Christian", ""], ["K\u00fchne", "Konrad", ""], ["Bieniusa", "Annette", ""]]}, {"id": "1508.05591", "submitter": "Muhammad Anis Uddin Nasir", "authors": "Muhammad Anis Uddin Nasir, Sarunas Girdzijauskas, Nicolas Kourtellis", "title": "Socially-Aware Distributed Hash Tables for Decentralized Online Social\n  Networks", "comments": "10 pages, p2p 2015 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many decentralized online social networks (DOSNs) have been proposed due to\nan increase in awareness related to privacy and scalability issues in\ncentralized social networks. Such decentralized networks transfer processing\nand storage functionalities from the service providers towards the end users.\nDOSNs require individualistic implementation for services, (i.e., search,\ninformation dissemination, storage, and publish/subscribe). However, many of\nthese services mostly perform social queries, where OSN users are interested in\naccessing information of their friends. In our work, we design a socially-aware\ndistributed hash table (DHTs) for efficient implementation of DOSNs. In\nparticular, we propose a gossip-based algorithm to place users in a DHT, while\nmaximizing the social awareness among them. Through a set of experiments, we\nshow that our approach reduces the lookup latency by almost 30% and improves\nthe reliability of the communication by nearly 10% via trusted contacts.\n", "versions": [{"version": "v1", "created": "Sun, 23 Aug 2015 10:15:01 GMT"}, {"version": "v2", "created": "Sat, 19 Sep 2015 17:01:47 GMT"}, {"version": "v3", "created": "Wed, 23 Sep 2015 13:53:40 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Nasir", "Muhammad Anis Uddin", ""], ["Girdzijauskas", "Sarunas", ""], ["Kourtellis", "Nicolas", ""]]}, {"id": "1508.05769", "submitter": "Miguel Mosteiro", "authors": "Antonio Fern\\'andez Anta, Chryssis Georgiou, Miguel A. Mosteiro, and\n  Daniel Pareja", "title": "Multi-round Master-Worker Computing: a Repeated Game Approach", "comments": "21 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a computing system where a master processor assigns tasks for\nexecution to worker processors through the Internet. We model the workers\ndecision of whether to comply (compute the task) or not (return a bogus result\nto save the computation cost) as a mixed extension of a strategic game among\nworkers. That is, we assume that workers are rational in a game-theoretic\nsense, and that they randomize their strategic choice. Workers are assigned\nmultiple tasks in subsequent rounds. We model the system as an infinitely\nrepeated game of the mixed extension of the strategic game. In each round, the\nmaster decides stochastically whether to accept the answer of the majority or\nverify the answers received, at some cost. Incentives and/or penalties are\napplied to workers accordingly. Under the above framework, we study the\nconditions in which the master can reliably obtain tasks results, exploiting\nthat the repeated games model captures the effect of long-term interaction.\nThat is, workers take into account that their behavior in one computation will\nhave an effect on the behavior of other workers in the future. Indeed, should a\nworker be found to deviate from some agreed strategic choice, the remaining\nworkers would change their own strategy to penalize the deviator. Hence, being\nrational, workers do not deviate. We identify analytically the parameter\nconditions to induce a desired worker behavior, and we evaluate experi-\nmentally the mechanisms derived from such conditions. We also compare the\nperformance of our mechanisms with a previously known multi-round mechanism\nbased on reinforcement learning.\n", "versions": [{"version": "v1", "created": "Mon, 24 Aug 2015 12:00:55 GMT"}], "update_date": "2015-08-25", "authors_parsed": [["Anta", "Antonio Fern\u00e1ndez", ""], ["Georgiou", "Chryssis", ""], ["Mosteiro", "Miguel A.", ""], ["Pareja", "Daniel", ""]]}, {"id": "1508.05808", "submitter": "Andreas Loukas", "authors": "Andreas Loukas and Andrea Simonetto and Geert Leus", "title": "Distributed Autoregressive Moving Average Graph Filters", "comments": "5 pages, 3 figures", "journal-ref": null, "doi": "10.1109/LSP.2015.2448655", "report-no": null, "categories": "cs.SI cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce the concept of autoregressive moving average (ARMA) filters on a\ngraph and show how they can be implemented in a distributed fashion. Our graph\nfilter design philosophy is independent of the particular graph, meaning that\nthe filter coefficients are derived irrespective of the graph. In contrast to\nfinite-impulse response (FIR) graph filters, ARMA graph filters are robust\nagainst changes in the signal and/or graph. In addition, when time-varying\nsignals are considered, we prove that the proposed graph filters behave as ARMA\nfilters in the graph domain and, depending on the implementation, as first or\nhigher ARMA filters in the time domain.\n", "versions": [{"version": "v1", "created": "Fri, 24 Apr 2015 17:45:51 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Loukas", "Andreas", ""], ["Simonetto", "Andrea", ""], ["Leus", "Geert", ""]]}, {"id": "1508.06119", "submitter": "Mathias Slawik", "authors": "Mathias Slawik, Beg\\\"um \\.Ilke Zilci, Fabian Knaack and Axel K\\\"upper", "title": "The Open Service Compendium. Business-pertinent Cloud Service Discovery,\n  Assessment, and Selection", "comments": "14 pages, to be presented at GECON 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When trying to discover, assess, and select cloud services, companies face\nmany challenges, such as fast-moving markets, vast numbers of offerings, and\nhighly ambiguous selection criteria. This publication presents the Open Service\nCompendium (OSC), an information system which supports businesses in their\ndiscovery, assessment and cloud service selection by offering a simple dynamic\nservice description language, business-pertinent vocabularies, as well as\nmatchmaking functionality. It contributes to the state of the art by offering a\nmore practical, mature, simple, and usable approach than related works.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 11:55:04 GMT"}], "update_date": "2015-08-26", "authors_parsed": [["Slawik", "Mathias", ""], ["Zilci", "Beg\u00fcm \u0130lke", ""], ["Knaack", "Fabian", ""], ["K\u00fcpper", "Axel", ""]]}, {"id": "1508.06268", "submitter": "Crist\\'obal A. Navarro", "authors": "C.A. Navarro, Wei Huang, Youjin Deng", "title": "Adaptive Multi-GPU Exchange Monte Carlo for the 3D Random Field Ising\n  Model", "comments": "15 pages, 10 figures", "journal-ref": "Computer Physics Communications, Volume 205, August 2016, pp 48-60", "doi": "10.1016/j.cpc.2016.04.007", "report-no": null, "categories": "physics.comp-ph cond-mat.stat-mech cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present an adaptive multi-GPU Exchange Monte Carlo method designed for the\nsimulation of the 3D Random Field Model. The algorithm design is based on a\ntwo-level parallelization scheme that allows the method to scale its\nperformance in the presence of faster and GPUs as well as multiple GPUs. The\nset of temperatures is adapted according to the exchange rate observed from\nshort trial runs, leading to an increased exchange rate at zones where the\nexchange process is sporadic. Performance results show that parallel tempering\nis an ideal strategy for being implemented on the GPU, and runs between one to\ntwo orders of magnitude with respect to a single-core CPU version, with\nmulti-GPU scaling being approximately $99\\%$ efficient. The results obtained\nextend the possibilities of simulation to sizes of $L = 32, 64$ for a\nworkstation with two GPUs.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 19:58:20 GMT"}, {"version": "v2", "created": "Wed, 26 Aug 2015 15:35:19 GMT"}, {"version": "v3", "created": "Thu, 27 Aug 2015 14:19:48 GMT"}, {"version": "v4", "created": "Fri, 4 Sep 2015 15:56:05 GMT"}, {"version": "v5", "created": "Tue, 22 Sep 2015 14:29:46 GMT"}], "update_date": "2016-08-10", "authors_parsed": [["Navarro", "C. A.", ""], ["Huang", "Wei", ""], ["Deng", "Youjin", ""]]}, {"id": "1508.06314", "submitter": "Maher Salloum", "authors": "Maher Salloum, Nathan Fabian, David M. Hensinger, Jeremy A. Templeton", "title": "Compressed Sensing and Reconstruction of Unstructured Mesh Datasets", "comments": "18 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": "SAND2015-4995C", "categories": "cs.IT cs.DC cs.SY math.IT math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Exascale computing promises quantities of data too large to efficiently store\nand transfer across networks in order to be able to analyze and visualize the\nresults. We investigate Compressive Sensing (CS) as a way to reduce the size of\nthe data as it is being stored. CS works by sampling the data on the\ncomputational cluster within an alternative function space such as wavelet\nbases, and then reconstructing back to the original space on visualization\nplatforms. While much work has gone into exploring CS on structured data sets,\nsuch as image data, we investigate its usefulness for point clouds such as\nunstructured mesh datasets found in many finite element simulations. We sample\nusing second generation wavelets (SGW) and reconstruct using the Stagewise\nOrthogonal Matching Pursuit (StOMP) algorithm. We analyze the compression\nratios achievable and quality of reconstructed results at each compression\nrate. We are able to achieve compression ratios between 10 and 30 on moderate\nsize datasets with minimal visual deterioration as a result of the lossy\ncompression.\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 21:46:30 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Salloum", "Maher", ""], ["Fabian", "Nathan", ""], ["Hensinger", "David M.", ""], ["Templeton", "Jeremy A.", ""]]}, {"id": "1508.06320", "submitter": "Frank Hannig", "authors": "Frank Hannig, Dirk Koch, Daniel Ziener", "title": "Proceedings of the Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015)", "comments": "Website of the workshop: https://www12.cs.fau.de/ws/fsp2015/", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This volume contains the papers accepted at the Second International Workshop\non FPGAs for Software Programmers (FSP 2015), held in London, United Kingdom,\nSeptember 1st, 2015. FSP 2015 was co-located with the International Conference\non Field Programmable Logic and Applications (FPL).\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 22:17:22 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Hannig", "Frank", ""], ["Koch", "Dirk", ""], ["Ziener", "Daniel", ""]]}, {"id": "1508.06329", "submitter": "Agnieszka Lupinska", "authors": "Agnieszka Lupinska", "title": "A Parallel Algorithm to Test Chordality of Graphs", "comments": "MSc thesis, promoter: dr Maciej \\'Slusarek", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a simple parallel algorithm to test chordality of graphs which is\nbased on the parallel Lexicographical Breadth-First Search algorithm. In total,\nthe algorithm takes time O(N ) on N-threads machine and it performs work O(N 2\n) , where N is the number of vertices in a graph. Our implementation of the\nalgorithm uses a GPU environment Nvidia CUDA C. The algorithm is implemented in\nCUDA 4.2 and it has been tested on Nvidia GeForce GTX 560 Ti of compute\ncapability 2.1. At the end of the thesis we present the results achieved by our\nimplementation and compare them with the results achieved by the sequential\nalgorithm\n", "versions": [{"version": "v1", "created": "Tue, 25 Aug 2015 23:51:04 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Lupinska", "Agnieszka", ""]]}, {"id": "1508.06350", "submitter": "Minxian  Xu", "authors": "Minxian Xu, Guangchun Luo, Ling Tian, Aiguo Chen, Yaqiu Jiang,\n  Guozhong Li, Wenhong Tian", "title": "Prepartition: Paradigm for the Load Balance of Virtual Machine\n  Allocation in Data Centers", "comments": "12 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is significant to apply load-balancing strategy to improve the performance\nand reliability of resource in data centers. One of the challenging scheduling\nproblems in Cloud data centers is to take the allocation and migration of\nreconfigurable virtual machines (VMs) as well as the integrated features of\nhosting physical machines (PMs) into consideration. In the reservation model,\nthe workload of data centers has fixed process interval characteristics. In\ngeneral, load-balance scheduling is NP-hard problem as proved in many open\nliteratures. Traditionally, for offline load balance without migration, one of\nthe best approaches is LPT (Longest Process Time first), which is well known to\nhave approximation ratio 4/3. With virtualization, reactive (post) migration of\nVMs after allocation is one popular way for load balance and traffic\nconsolidation. However, reactive migration has difficulty to reach predefined\nload balance objectives, and may cause interruption and instability of service\nand other associated costs. In view of this, we propose a new paradigm, called\nPrepartition, it proactively sets process-time bound for each request on each\nPM and prepares in advance to migrate VMs to achieve the predefined balance\ngoal. Prepartition can reduce process time by preparing VM migration in advance\nand therefore reduce instability and achieve better load balance as desired. We\nalso apply the Prepartition to online (PrepartitionOn) load balance and compare\nit with existing online scheduling algorithms. Both theoretical and\nexperimental results are provided.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 03:01:02 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Xu", "Minxian", ""], ["Luo", "Guangchun", ""], ["Tian", "Ling", ""], ["Chen", "Aiguo", ""], ["Jiang", "Yaqiu", ""], ["Li", "Guozhong", ""], ["Tian", "Wenhong", ""]]}, {"id": "1508.06460", "submitter": "Andrzej Pelc", "authors": "Kokouvi Hounkanli, Andrzej Pelc", "title": "Deterministic Broadcasting and Gossiping with Beeps", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Broadcasting and gossiping are fundamental communication tasks in networks.\nIn broadcasting,one node of a network has a message that must be learned by all\nother nodes. In gossiping, every node has a (possibly different) message, and\nall messages must be learned by all nodes. We study these well-researched tasks\nin a very weak communication model, called the {\\em beeping model}.\nCommunication proceeds in synchronous rounds. In each round, a node can either\nlisten, i.e., stay silent, or beep, i.e., emit a signal. A node hears a beep in\na round, if it listens in this round and if one or more adjacent nodes beep in\nthis round. All nodes have different labels from the set $\\{0,\\dots , L-1\\}$.\n  Our aim is to provide fast deterministic algorithms for broadcasting and\ngossiping in the beeping model. Let $N$ be an upper bound on the size of the\nnetwork and $D$ its diameter. Let $m$ be the size of the message in\nbroadcasting, and $M$ an upper bound on the size of all input messages in\ngossiping. For the task of broadcasting we give an algorithm working in time\n$O(D+m)$ for arbitrary networks, which is optimal. For the task of gossiping we\ngive an algorithm working in time $O(N(M+D\\log L))$ for arbitrary networks.\n  At the time of writing this paper we were unaware of the paper: A. Czumaj, P.\nDavis, Communicating with Beeps, arxiv:1505.06107 [cs.DC] which contains the\nsame results for broadcasting and a stronger upper bound for gossiping in a\nslightly different model.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 12:10:38 GMT"}, {"version": "v2", "created": "Wed, 21 Oct 2015 18:56:56 GMT"}], "update_date": "2015-10-22", "authors_parsed": [["Hounkanli", "Kokouvi", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1508.06583", "submitter": "Avery Miller", "authors": "Kokouvi Hounkanli, Avery Miller, Andrzej Pelc", "title": "Global Synchronization and Consensus Using Beeps in a Fault-Prone MAC", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Consensus is one of the fundamental tasks studied in distributed computing.\nProcessors have input values from some set $V$ and they have to decide the same\nvalue from this set. If all processors have the same input value, then they\nmust all decide this value. We study the task of consensus in a Multiple Access\nChannel (MAC) prone to faults, under a very weak communication model called the\n$\\mathit{beeping\\ model}$. Communication proceeds in synchronous rounds. Some\nprocessors wake up spontaneously, in possibly different rounds decided by an\nadversary. In each round, an awake processor can either listen, i.e., stay\nsilent, or beep, i.e., emit a signal. In each round, a fault can occur in the\nchannel independently with constant probability $0<p<1$. In a fault-free round,\nan awake processor hears a beep if it listens in this round and if one or more\nother processors beep in this round. A processor still dormant in a fault-free\nround in which some other processor beeps is woken up by this beep and hears\nit. In a faulty round nothing is heard, regardless of the behaviour of the\nprocessors.\n  An algorithm working with error probability at most $\\epsilon$, for a given\n$\\epsilon>0$, is called $\\epsilon$-$\\mathit{safe}$. Our main result is the\ndesign and analysis, for any constant $\\epsilon>0$, of a deterministic\n$\\epsilon$-safe consensus algorithm that works in time $O(\\log w)$ in a\nfault-prone MAC, where $w$ is the smallest input value of all participating\nprocessors. We show that this time cannot be improved, even when the MAC is\nfault-free. The main algorithmic tool that we develop to achieve our goal, and\nthat might be of independent interest, is a deterministic algorithm that, with\narbitrarily small constant error probability, establishes a global clock in a\nfault-prone MAC in constant time.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 17:42:44 GMT"}], "update_date": "2015-08-27", "authors_parsed": [["Hounkanli", "Kokouvi", ""], ["Miller", "Avery", ""], ["Pelc", "Andrzej", ""]]}, {"id": "1508.06705", "submitter": "Sekou Remy", "authors": "Jeff Kinnison and Sekou L. Remy", "title": "Using Genetic Algorithms to Benchmark the Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": "Sp2015M03", "categories": "cs.DC cs.NE cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a novel application of Genetic Algorithms(GAs) to\nquantify the performance of Platform as a Service (PaaS), a cloud service model\nthat plays a critical role in both industry and academia. While Cloud\nbenchmarks are not new, in this novel concept, the authors use a GA to take\nadvantage of the elasticity in Cloud services in a graceful manner that was not\npreviously possible. Using Google App Engine, Heroku, and Python Anywhere with\nthree distinct classes of client computers running our GA codebase, we\nquantified the completion time for application of the GA to search for the\nparameters of controllers for dynamical systems. Our results show statistically\nsignificant differences in PaaS performance by vendor, and also that the\nperformance of the PaaS performance is dependent upon the client that uses it.\nResults also show the effectiveness of our GA in determining the level of\nservice of PaaS providers, and for determining if the level of service of one\nPaaS vendor is repeatable with another. Such a concept could then increase the\nappeal of PaaS Cloud services by making them more financially appealing.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 03:09:08 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Kinnison", "Jeff", ""], ["Remy", "Sekou L.", ""]]}, {"id": "1508.06731", "submitter": "Othon Michail", "authors": "Dimitrios Amaxilatis, Marios Logaras, Othon Michail, Paul G. Spirakis", "title": "NETCS: A New Simulator of Population Protocols and Network Constructors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Constructors are an extension of the standard population protocol\nmodel in which finite-state agents interact in pairs under the control of an\nadversary scheduler. In this work we present NETCS, a simulator designed to\nevaluate the performance of various network constructors and population\nprotocols under different schedulers and network configurations. Our simulator\nprovides researchers with an intuitive user interface and a quick\nexperimentation environment to evaluate their work. It also harnesses the power\nof the cloud, as experiments are executed remotely and scheduled through the\nweb interface provided. To prove the validity and quality of our simulator we\nprovide an extensive evaluation of multiple protocols with more than 100000\nexperiments for different network sizes and configurations that validate the\ncorrectness of the theoretical analysis of existing protocols and estimate the\nreal values of the hidden asymptotic coefficients. We also show experimentally\n(with more than 40000 experiments) that a probabilistic algorithm is capable of\ncounting the actual size of the network in bounded time given a unique leader.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 06:46:02 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Amaxilatis", "Dimitrios", ""], ["Logaras", "Marios", ""], ["Michail", "Othon", ""], ["Spirakis", "Paul G.", ""]]}, {"id": "1508.06782", "submitter": "Emanuele Natale", "authors": "Luca Becchetti, Andrea Clementi, Emanuele Natale, Francesco Pasquale,\n  Luca Trevisan", "title": "Stabilizing Consensus with Many Opinions", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider the following distributed consensus problem: Each node in a\ncomplete communication network of size $n$ initially holds an \\emph{opinion},\nwhich is chosen arbitrarily from a finite set $\\Sigma$. The system must\nconverge toward a consensus state in which all, or almost all nodes, hold the\nsame opinion. Moreover, this opinion should be \\emph{valid}, i.e., it should be\none among those initially present in the system. This condition should be met\neven in the presence of an adaptive, malicious adversary who can modify the\nopinions of a bounded number of nodes in every round.\n  We consider the \\emph{3-majority dynamics}: At every round, every node pulls\nthe opinion from three random neighbors and sets his new opinion to the\nmajority one (ties are broken arbitrarily). Let $k$ be the number of valid\nopinions. We show that, if $k \\leqslant n^{\\alpha}$, where $\\alpha$ is a\nsuitable positive constant, the 3-majority dynamics converges in time\npolynomial in $k$ and $\\log n$ with high probability even in the presence of an\nadversary who can affect up to $o(\\sqrt{n})$ nodes at each round.\n  Previously, the convergence of the 3-majority protocol was known for\n$|\\Sigma| = 2$ only, with an argument that is robust to adversarial errors. On\nthe other hand, no anonymous, uniform-gossip protocol that is robust to\nadversarial errors was known for $|\\Sigma| > 2$.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 09:58:21 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Becchetti", "Luca", ""], ["Clementi", "Andrea", ""], ["Natale", "Emanuele", ""], ["Pasquale", "Francesco", ""], ["Trevisan", "Luca", ""]]}, {"id": "1508.06791", "submitter": "James Clarkson", "authors": "James Clarkson and Christos Kotselidis and Gavin Brown and Mikel\n  Luj\\'an", "title": "Boosting Java Performance using GPGPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous programming has started becoming the norm in order to achieve\nbetter performance by running portions of code on the most appropriate hardware\nresource. Currently, significant engineering efforts are undertaken in order to\nenable existing programming languages to perform heterogeneous execution mainly\non GPUs. In this paper we describe Jacc, an experimental framework which allows\ndevelopers to program GPGPUs directly from Java. By using the Jacc framework,\ndevelopers have the ability to add GPGPU support into their applications with\nminimal code refactoring.\n  To simplify the development of GPGPU applications we allow developers to\nmodel heterogeneous code using two key abstractions: \\textit{tasks}, which\nencapsulate all the information needed to execute code on a GPGPU; and\n\\textit{task graphs}, which capture the inter-task control-flow of the\napplication. Using this information the Jacc runtime is able to automatically\nhandle data movement and synchronization between the host and the GPGPU;\neliminating the need for explicitly managing disparate memory spaces.\n  In order to generate highly parallel GPGPU code, Jacc provides developers\nwith the ability to decorate key aspects of their code using annotations. The\ncompiler, in turn, exploits this information in order to automatically generate\ncode without requiring additional code refactoring.\n  Finally, we demonstrate the advantages of Jacc, both in terms of\nprogrammability and performance, by evaluating it against existing Java\nframeworks. Experimental results show an average performance speedup of 32x and\na 4.4x code decrease across eight evaluated benchmarks on a NVIDIA Tesla K20m\nGPU.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 10:15:31 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Clarkson", "James", ""], ["Kotselidis", "Christos", ""], ["Brown", "Gavin", ""], ["Luj\u00e1n", "Mikel", ""]]}, {"id": "1508.06821", "submitter": "Jens Korinth", "authors": "Jens Korinth, David de la Chevallerie, Andreas Koch", "title": "ThreadPoolComposer - An Open-Source FPGA Toolchain for Software\n  Developers", "comments": "Presented at Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015) (arXiv:1508.06320)", "journal-ref": null, "doi": null, "report-no": "FSP/2015/04", "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This extended abstract presents ThreadPoolComposer, a high-level\nsynthesis-based development framework and meta-toolchain that provides a\nuniform programming interface for FPGAs portable across multiple platforms.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 12:03:57 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Korinth", "Jens", ""], ["de la Chevallerie", "David", ""], ["Koch", "Andreas", ""]]}, {"id": "1508.06823", "submitter": "Vinay B. Y. Kumar", "authors": "Vinay B. Y. Kumar, Pinalkumar Engineer, Mandar Datar, Yatish Turakhia,\n  Saurabh Agarwal, Sanket Diwale, Sachin B. Patkar", "title": "Framework for Application Mapping over Packet-Switched Network of FPGAs:\n  Case Studies", "comments": "Presented at Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015) (arXiv:1508.06320)", "journal-ref": null, "doi": null, "report-no": "FSP/2015/05", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The algorithm-to-hardware High-level synthesis (HLS) tools today are\npurported to produce hardware comparable in quality to handcrafted designs,\nparticularly with user directive driven or domains specific HLS. However, HLS\ntools are not readily equipped for when an application/algorithm needs to\nscale. We present a (work-in-progress) semi-automated framework to map\napplications over a packet-switched network of modules (single FPGA) and then\nto seamlessly partition such a network over multiple FPGAs over quasi-serial\nlinks. We illustrate the framework through three application case studies: LDPC\nDecoding, Particle Filter based Object Tracking, and Matrix Vector\nMultiplication over GF(2). Starting with high-level representations of each\ncase application, we first express them in an intermediate message passing\nformulation, a model of communicating processing elements. Once the processing\nelements are identified, these are either handcrafted or realized using HLS.\nThe rest of the flow is automated where the processing elements are plugged on\nto a configurable network-on-chip (CONNECT) topology of choice, followed by\npartitioning the 'on-chip' links to work seamlessly across chips/FPGAs.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 12:14:41 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Kumar", "Vinay B. Y.", ""], ["Engineer", "Pinalkumar", ""], ["Datar", "Mandar", ""], ["Turakhia", "Yatish", ""], ["Agarwal", "Saurabh", ""], ["Diwale", "Sanket", ""], ["Patkar", "Sachin B.", ""]]}, {"id": "1508.06830", "submitter": "Antonio Filgueras", "authors": "Daniel Jim\\'enez-Gonz\\'alez, Carlos \\'Alvarez, Antonio Filgueras,\n  Xavier Martorell, Jan Langer, Juanjo Noguera, Kees Vissers", "title": "Coarse-Grain Performance Estimator for Heterogeneous Parallel Computing\n  Architectures like Zynq All-Programmable SoC", "comments": "Presented at Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015) (arXiv:1508.06320)", "journal-ref": null, "doi": null, "report-no": "FSP/2015/07", "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous computing is emerging as a mandatory requirement for\npower-efficient system design. With this aim, modern heterogeneous platforms\nlike Zynq All-Programmable SoC, that integrates ARM-based SMP and programmable\nlogic, have been designed. However, those platforms introduce large design\ncycles consisting on hardware/software partitioning, decisions on granularity\nand number of hardware accelerators, hardware/software integration, bitstream\ngeneration, etc.\n  This paper presents a performance parallel heterogeneous estimation for\nsystems where hardware/software co-design and run-time heterogeneous task\nscheduling are key. The results show that the programmer can quickly decide,\nbased only on her/his OmpSs (OpenMP + extensions) application, which is the\nco-design that achieves nearly optimal heterogeneous parallel performance,\nbased on the methodology presented and considering only synthesis estimation\nresults. The methodology presented reduces the programmer co-design decision\nfrom hours to minutes and shows high potential on hardware/software\nheterogeneous parallel performance estimation on the Zynq All-Programmable SoC.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 12:35:00 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Jim\u00e9nez-Gonz\u00e1lez", "Daniel", ""], ["\u00c1lvarez", "Carlos", ""], ["Filgueras", "Antonio", ""], ["Martorell", "Xavier", ""], ["Langer", "Jan", ""], ["Noguera", "Juanjo", ""], ["Vissers", "Kees", ""]]}, {"id": "1508.06843", "submitter": "Oliver Knodel", "authors": "Oliver Knodel, Rainer G. Spallek", "title": "RC3E: Provision and Management of Reconfigurable Hardware Accelerators\n  in a Cloud Environment", "comments": "Presented at Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015) (arXiv:1508.06320)", "journal-ref": null, "doi": null, "report-no": "FSP/2015/09", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous systems consisting of general-purpose processors and different\ntypes of hardware accelerators are becoming more and more common in HPC\nsystems. Especially FPGAs provide a promising opportunity to improve both\nperformance and energy efficiency of such systems. Adding FPGAs to clouds or\ndata centers allows easy access to such reconfigurable resources. In this paper\nwe present our cloud service models and cloud hypervisor called RC3E, which\nintegrates virtualized FPGA-based hardware accelerators into a cloud\nenvironment. With our hardware and software framework, multiple (virtual) user\ndesigns can be executed on a single physical FPGA device. We demonstrate the\nperformance of our approach by implementing up to four virtual user cores on a\nsingle device and present future perspectives for FPGAs in cloud-based data\nenvironments.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 13:05:24 GMT"}], "update_date": "2015-08-28", "authors_parsed": [["Knodel", "Oliver", ""], ["Spallek", "Rainer G.", ""]]}, {"id": "1508.07123", "submitter": "Kazushi Yamashina", "authors": "Kazushi Yamashina, Takeshi Ohkawa, Kanemitsu Ootsu, Takashi Yokota", "title": "Proposal of ROS-compliant FPGA Component for Low-Power Robotic Systems", "comments": "Presented at Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015) (arXiv:1508.06320)", "journal-ref": null, "doi": null, "report-no": "FSP/2015/12", "categories": "cs.AR cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, robots are required to be autonomous and their robotic\nsoftware are sophisticated. Robots have a problem of insufficient performance,\nsince it cannot equip with a high-performance microprocessor due to\nbattery-power operation. On the other hand, FPGA devices can accelerate\nspecific functions in a robot system without increasing power consumption by\nimplementing customized circuits. But it is difficult to introduce FPGA devices\ninto a robot due to large development cost of an FPGA circuit compared to\nsoftware. Therefore, in this study, we propose an FPGA component technology for\nan easy integration of an FPGA into robots, which is compliant with ROS (Robot\nOperating System). As a case study, we designed ROS-compliant FPGA component of\nimage labeling using Xilinx Zynq platform. The developed ROS-component FPGA\ncomponent performs 1.7 times faster compared to the ordinary ROS software\ncomponent.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2015 08:33:15 GMT"}], "update_date": "2015-08-31", "authors_parsed": [["Yamashina", "Kazushi", ""], ["Ohkawa", "Takeshi", ""], ["Ootsu", "Kanemitsu", ""], ["Yokota", "Takashi", ""]]}, {"id": "1508.07136", "submitter": "Robert Stewart", "authors": "Robert Stewart, Deepayan Bhowmik, Greg Michaelson, Andrew Wallace", "title": "RIPL: An Efficient Image Processing DSL for FPGAs", "comments": "Presented at Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015) (arXiv:1508.06320)", "journal-ref": "J. Funct. Prog. 17 (2007) 428-429", "doi": "10.1017/S0956796807006296", "report-no": "FSP/2015/16", "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Field programmable gate arrays (FPGAs) can accelerate image processing by\nexploiting fine-grained parallelism opportunities in image operations. FPGA\nlanguage designs are often subsets or extensions of existing languages, though\nthese typically lack suitable hardware computation models so compiling them to\nFPGAs leads to inefficient designs. Moreover, these languages lack image\nprocessing domain specificity. Our solution is RIPL, an image processing domain\nspecific language (DSL) for FPGAs. It has algorithmic skeletons to express\nimage processing, and these are exploited to generate deep pipelines of highly\nconcurrent and memory-efficient image processing components.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2015 09:08:49 GMT"}], "update_date": "2016-07-06", "authors_parsed": [["Stewart", "Robert", ""], ["Bhowmik", "Deepayan", ""], ["Michaelson", "Greg", ""], ["Wallace", "Andrew", ""]]}, {"id": "1508.07142", "submitter": "Ian Gray", "authors": "Ian Gray, Yu Chan, Jamie Garside, Neil Audsley, Andy Wellings", "title": "Transparent hardware synthesis of Java for predictable large-scale\n  distributed systems", "comments": "Presented at Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015) (arXiv:1508.06320)", "journal-ref": null, "doi": null, "report-no": "FSP/2015/19", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The JUNIPER project is developing a framework for the construction of\nlarge-scale distributed systems in which execution time bounds can be\nguaranteed. Part of this work involves the automatic implementation of input\nJava code on FPGAs, both for speed and predictability. An important focus of\nthis work is to make the use of FPGAs transparent though runtime co-design and\npartial reconfiguration. Initial results show that the use of Java does not\nhamper hardware generation, and provides tight execution time estimates. This\npaper describes an overview the approach taken, and presents some preliminary\nresults that demonstrate the promise in the technique.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2015 09:25:31 GMT"}], "update_date": "2015-08-31", "authors_parsed": [["Gray", "Ian", ""], ["Chan", "Yu", ""], ["Garside", "Jamie", ""], ["Audsley", "Neil", ""], ["Wellings", "Andy", ""]]}, {"id": "1508.07174", "submitter": "Alexandre Vaniachine", "authors": "Mikhail Borodin, Kaushik De, Jose Garcia Navarro, Dmitry Golubkov,\n  Alexei Klimentov, Tadashi Maeno, David South and Alexandre Vaniachine (on\n  behalf of the ATLAS Collaboration)", "title": "Unified System for Processing Real and Simulated Data in the ATLAS\n  Experiment", "comments": "XVII International Conference Data Analytics and Management in Data\n  Intensive Domains (DAMDID/RCDL), Obninsk, Russia, October 13 - 16, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC hep-ex physics.ins-det", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The physics goals of the next Large Hadron Collider run include high\nprecision tests of the Standard Model and searches for new physics. These goals\nrequire detailed comparison of data with computational models simulating the\nexpected data behavior. To highlight the role which modeling and simulation\nplays in future scientific discovery, we report on use cases and experience\nwith a unified system built to process both real and simulated data of growing\nvolume and variety.\n", "versions": [{"version": "v1", "created": "Fri, 28 Aug 2015 12:03:06 GMT"}], "update_date": "2019-08-14", "authors_parsed": [["Borodin", "Mikhail", "", "on\n  behalf of the ATLAS Collaboration"], ["De", "Kaushik", "", "on\n  behalf of the ATLAS Collaboration"], ["Navarro", "Jose Garcia", "", "on\n  behalf of the ATLAS Collaboration"], ["Golubkov", "Dmitry", "", "on\n  behalf of the ATLAS Collaboration"], ["Klimentov", "Alexei", "", "on\n  behalf of the ATLAS Collaboration"], ["Maeno", "Tadashi", "", "on\n  behalf of the ATLAS Collaboration"], ["South", "David", "", "on\n  behalf of the ATLAS Collaboration"], ["Vaniachine", "Alexandre", "", "on\n  behalf of the ATLAS Collaboration"]]}, {"id": "1508.07724", "submitter": "Anandi Giridharan", "authors": "Anandi Giridharan and Pallapa Venkataram", "title": "SDL based validation of a node monitoring protocol", "comments": "16 pages, 24 figures, International Conference of Networks,\n  Communications, Wireless and Mobile 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile ad hoc network is a wireless, self-configured, infrastructureless\nnetwork of mobile nodes. The nodes are highly mobile, which makes the\napplication running on them face network related problems like node failure,\nlink failure, network level disconnection, scarcity of resources, buffer\ndegradation, and intermittent disconnection etc. Node failure and Network fault\nare need to be monitored continuously by supervising the network status. Node\nmonitoring protocol is crucial, so it is required to test the protocol\nexhaustively to verify and validate the functionality and accuracy of the\ndesigned protocol. This paper presents a validation model for Node Monitoring\nProtocol using Specification and Description Llanguage (SDL) using both Static\nAgent (SA) and Mobile Agent (MA). We have verified properties of the Node\nMonitoring Protocol (NMP) based on the global states with no exits, deadlock\nstates or proper termination states using reachability graph. Message Sequence\nChart (MSC) gives an intuitive understanding of the described system behavior\nwith varying node density and complex behavior etc.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 08:57:47 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Giridharan", "Anandi", ""], ["Venkataram", "Pallapa", ""]]}, {"id": "1508.07740", "submitter": "Karel De Vogeleer", "authors": "Karel De Vogeleer, Gerard Memmi, Pierre Jouvelot", "title": "Parameter Sensitivity Analysis of the Energy/Frequency Convexity Rule\n  for Nanometer-scale Application Processors", "comments": "In submission to the Special Issue on Energy Efficient Multi-Core and\n  Many-Core Systems (The Elsevier Journal of Parallel and Distributed\n  Computing)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Both theoretical and experimental evidence are presented in this work in\norder to validate the existence of an Energy/Frequency Convexity Rule, which\nrelates energy consumption and microprocessor frequency for nanometer-scale\nmicroprocessors. Data gathered during several month-long experimental\nacquisition campaigns, supported by several independent publications, suggest\nthat energy consumed is indeed depending on the microprocessor's clock\nfrequency, and, more interestingly, the curve exhibits a clear minimum over the\nprocessor's frequency range. An analytical model for this behavior is presented\nand motivated, which fits well with the experimental data. A parameter\nsensitivity analysis shows how parameters affect the energy minimum in the\nclock frequency space. The conditions are discussed under which this convexity\nrule can be exploited, and when other methods are more effective, with the aim\nof improving the computer system's energy management efficiency. We show that\nthe power requirements of the computer system, besides the microprocessor, and\nthe overhead affect the location of the energy minimum the most. The\nsensitivity analysis of the Energy/Frequency Convexity Rule puts forward a\nnumber of simple guidelines especially for by low-power systems, such as\nbattery-powered and embedded systems, and less likely by high-performance\ncomputer systems.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 09:41:46 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["De Vogeleer", "Karel", ""], ["Memmi", "Gerard", ""], ["Jouvelot", "Pierre", ""]]}, {"id": "1508.07749", "submitter": "N. Axel Naumann", "authors": "Ilka Antcheva, Maarten Ballintijn, Bertrand Bellenot, Marek Biskup,\n  Rene Brun, Nenad Buncic, Philippe Canal, Diego Casadei, Olivier Couet, Valery\n  Fine, Leandro Franco, Gerardo Ganis, Andrei Gheata, David Gonzalez Maline,\n  Masaharu Goto, Jan Iwaszkiewicz, Anna Kreshuk, Diego Marcos Segura, Richard\n  Maunder, Lorenzo Moneta, Axel Naumann, Eddy Offermann, Valeriy Onuchin,\n  Suzanne Panacek, Fons Rademakers, Paul Russo, Matevz Tadel", "title": "ROOT - A C++ Framework for Petabyte Data Storage, Statistical Analysis\n  and Visualization", "comments": null, "journal-ref": "Computer Physics Communications Volume 180, Issue 12, December\n  2009, Pages 2499-2512", "doi": "10.1016/j.cpc.2009.08.005", "report-no": null, "categories": "physics.data-an cs.DC", "license": "http://creativecommons.org/licenses/by-sa/4.0/", "abstract": "  ROOT is an object-oriented C++ framework conceived in the high-energy physics\n(HEP) community, designed for storing and analyzing petabytes of data in an\nefficient way. Any instance of a C++ class can be stored into a ROOT file in a\nmachine-independent compressed binary format. In ROOT the TTree object\ncontainer is optimized for statistical data analysis over very large data sets\nby using vertical data storage techniques. These containers can span a large\nnumber of files on local disks, the web, or a number of different shared file\nsystems. In order to analyze this data, the user can chose out of a wide set of\nmathematical and statistical functions, including linear algebra classes,\nnumerical algorithms such as integration and minimization, and various methods\nfor performing regression analysis (fitting). In particular, ROOT offers\npackages for complex data modeling and fitting, as well as multivariate\nclassification based on machine learning techniques. A central piece in these\nanalysis tools are the histogram classes which provide binning of one- and\nmulti-dimensional data. Results can be saved in high-quality graphical formats\nlike Postscript and PDF or in bitmap formats like JPG or GIF. The result can\nalso be stored into ROOT macros that allow a full recreation and rework of the\ngraphics. Users typically create their analysis macros step by step, making use\nof the interactive C++ interpreter CINT, while running over small data samples.\nOnce the development is finished, they can run these macros at full compiled\nspeed over large data sets, using on-the-fly compilation, or by creating a\nstand-alone batch program. Finally, if processing farms are available, the user\ncan reduce the execution time of intrinsically parallel tasks - e.g. data\nmining in HEP - by using PROOF, which will take care of optimally distributing\nthe work over the available resources in a transparent way.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 10:12:27 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Antcheva", "Ilka", ""], ["Ballintijn", "Maarten", ""], ["Bellenot", "Bertrand", ""], ["Biskup", "Marek", ""], ["Brun", "Rene", ""], ["Buncic", "Nenad", ""], ["Canal", "Philippe", ""], ["Casadei", "Diego", ""], ["Couet", "Olivier", ""], ["Fine", "Valery", ""], ["Franco", "Leandro", ""], ["Ganis", "Gerardo", ""], ["Gheata", "Andrei", ""], ["Maline", "David Gonzalez", ""], ["Goto", "Masaharu", ""], ["Iwaszkiewicz", "Jan", ""], ["Kreshuk", "Anna", ""], ["Segura", "Diego Marcos", ""], ["Maunder", "Richard", ""], ["Moneta", "Lorenzo", ""], ["Naumann", "Axel", ""], ["Offermann", "Eddy", ""], ["Onuchin", "Valeriy", ""], ["Panacek", "Suzanne", ""], ["Rademakers", "Fons", ""], ["Russo", "Paul", ""], ["Tadel", "Matevz", ""]]}, {"id": "1508.07828", "submitter": "Qixia Yuan", "authors": "Andrzej Mizera and Jun Pang and Qixia Yuan", "title": "Parallel Approximate Steady-state Analysis of Large Probabilistic\n  Boolean Networks (Technical Report)", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC q-bio.QM", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Probabilistic Boolean networks (PBNs) is a widely used computational\nframework for modelling biological systems. The steady-state dynamics of PBNs\nis of special interest in the analysis of biological systems. However,\nobtaining the steady-state distributions for such systems poses a significant\nchallenge due to the state space explosion problem which often arises in the\ncase of large PBNs. The only viable way is to use statistical methods. We have\nconsidered the two-state Markov chain approach and the Skart method for the\nanalysis of large PBNs in our previous work. However, the sample size required\nin both methods is often huge in the case of large PBNs and generating them is\nexpensive in terms of computation time. Parallelising the sample generation is\nan ideal way to solve this issue. In this paper, we consider combining the\nGerman & Rubin method with either the two-state Markov chain approach or the\nSkart method for parallelisation. The first method can be used to run multiple\nindependent Markov chains in parallel and to control their convergence to the\nsteady-state while the other two methods can be used to determine the sample\nsize required for computing the steady-state probability of states of interest.\nExperimental results show that our proposed combinations can reduce time cost\nof computing stead-state probabilities of large PBNs significantly.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 13:55:33 GMT"}], "update_date": "2015-09-01", "authors_parsed": [["Mizera", "Andrzej", ""], ["Pang", "Jun", ""], ["Yuan", "Qixia", ""]]}, {"id": "1508.07845", "submitter": "Peng Peng", "authors": "Peng Peng, Lei Zou, Lei Chen, Dongyan Zhao", "title": "Query Workload-based RDF Graph Fragmentation and Allocation", "comments": "13 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the volume of the RDF data becomes increasingly large, it is essential for\nus to design a distributed database system to manage it. For distributed RDF\ndata design, it is quite common to partition the RDF data into some parts,\ncalled fragments, which are then distributed. Thus, the distribution design\nconsists of two steps: fragmentation and allocation. In this paper, we propose\na method to explore the intrinsic similarities among the structures of queries\nin a workload for fragmentation and allocation, which aims to reduce the number\nof crossing matches and the communication cost during SPARQL query processing.\nSpecifically, we mine and select some frequent access patterns to reflect the\ncharacteristics of the workload. Here, although we prove that selecting the\noptimal set of frequent access patterns is NP-hard, we propose a heuristic\nalgorithm which guarantees both the data integrity and the approximation ratio.\nBased on the selected frequent access patterns, we propose two fragmentation\nstrategies, vertical and horizontal fragmentation strategies, to divide RDF\ngraphs while meeting different kinds of query processing objectives. Vertical\nfragmentation is for better throughput and horizontal fragmentation is for\nbetter performance. After fragmentation, we discuss how to allocate these\nfragments to various sites. Finally, we discuss how to process a query based on\nthe results of fragmentation and allocation. Extensive experiments confirm the\nsuperior performance of our proposed solutions.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 14:23:38 GMT"}, {"version": "v2", "created": "Wed, 2 Sep 2015 02:29:51 GMT"}, {"version": "v3", "created": "Thu, 10 Dec 2015 16:10:04 GMT"}, {"version": "v4", "created": "Sat, 20 Feb 2016 08:16:59 GMT"}], "update_date": "2016-02-23", "authors_parsed": [["Peng", "Peng", ""], ["Zou", "Lei", ""], ["Chen", "Lei", ""], ["Zhao", "Dongyan", ""]]}, {"id": "1508.07982", "submitter": "Florian Schornbaum", "authors": "Florian Schornbaum and Ulrich R\\\"ude", "title": "Massively Parallel Algorithms for the Lattice Boltzmann Method on\n  Non-uniform Grids", "comments": "32 pages, 20 figures, 4 tables", "journal-ref": "SIAM J. Sci. Comput. 38-2 (2016), pp. C96-C126", "doi": "10.1137/15M1035240", "report-no": null, "categories": "cs.DC cs.CE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The lattice Boltzmann method exhibits excellent scalability on current\nsupercomputing systems and has thus increasingly become an alternative method\nfor large-scale non-stationary flow simulations, reaching up to a trillion grid\nnodes. Additionally, grid refinement can lead to substantial savings in memory\nand compute time. These saving, however, come at the cost of much more complex\ndata structures and algorithms. In particular, the interface between subdomains\nwith different grid sizes must receive special treatment. In this article, we\npresent parallel algorithms, distributed data structures, and communication\nroutines that are implemented in the software framework waLBerla in order to\nsupport large-scale, massively parallel lattice Boltzmann-based simulations on\nnon-uniform grids. Additionally, we evaluate the performance of our approach on\ntwo current petascale supercomputers. On an IBM Blue Gene/Q system, the largest\nweak scaling benchmarks with refined grids are executed with almost two million\nthreads, demonstrating not only near-perfect scalability but also an absolute\nperformance of close to a trillion lattice Boltzmann cell updates per second.\nOn an Intel-based system, the strong scaling of a simulation with refined grids\nand a total of more than 8.5 million cells is demonstrated to reach a\nperformance of less than one millisecond per time step. This enables\nsimulations with complex, non-uniform grids and four million time steps per\nhour compute time.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 19:57:37 GMT"}, {"version": "v2", "created": "Thu, 21 Jan 2016 19:51:58 GMT"}], "update_date": "2016-05-11", "authors_parsed": [["Schornbaum", "Florian", ""], ["R\u00fcde", "Ulrich", ""]]}]