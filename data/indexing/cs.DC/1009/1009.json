[{"id": "1009.0056", "submitter": "Gokarna Sharma", "authors": "Gokarna Sharma and Costas Busch", "title": "A Competitive Analysis for Balanced Transactional Memory Workloads", "comments": "18 pages, In submission for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider transactional memory contention management in the context of\nbalanced workloads, where if a transaction is writing, the number of write\noperations it performs is a constant fraction of its total reads and writes. We\nexplore the theoretical performance boundaries of contention management in\nbalanced workloads from the worst-case perspective by presenting and analyzing\ntwo new contention management algorithms. The first algorithm Clairvoyant is\nO(\\surd s)-competitive, where s is the number of shared resources. This\nalgorithm depends on explicitly knowing the conflict graph. The second\nalgorithm Non-Clairvoyant is O(\\surd s \\cdot log n)-competitive, with high\nprobability, which is only a O(log n) factor worse, but does not require\nknowledge of the conflict graph, where n is the number of transactions. Both of\nthese algorithms are greedy. We also prove that the performance of Clairvoyant\nis tight since there is no contention management algorithm that is better than\nO((\\surd s)^(1-\\epsilon))-competitive for any constant \\epsilon > 0, unless\nNP\\subseteq ZPP. To our knowledge, these results are significant improvements\nover the best previously known O(s) competitive ratio bound.\n", "versions": [{"version": "v1", "created": "Tue, 31 Aug 2010 23:54:57 GMT"}], "update_date": "2010-09-02", "authors_parsed": [["Sharma", "Gokarna", ""], ["Busch", "Costas", ""]]}, {"id": "1009.0390", "submitter": "Khalid Nawaz", "authors": "Khalid Nawaz, Alejandro P. Buchmann", "title": "Acdmcp: An adaptive and completely distributed multi-hop clustering\n  protocol for wireless sensor networks", "comments": null, "journal-ref": "International Journal of Wireless & Mobile Networks (IJWMN),\n  ISSN:0975-3834, 0975-4679, Academy & Industry Research Collaboration Center\n  (AIRCC), August 2010", "doi": "10.5121/ijwmn.2010.2302", "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Clustering is a very popular network structuring technique which mainly\naddresses the issue of scalability in large scale Wireless Sensor Networks.\nAdditionally, it has been shown to improve the energy efficiency and prolong\nthe life of the network. The suggested protocols mostly base their clustering\ncriteria on some grouping attribute(s) of the nodes. One important attribute\nthat is largely ignored by most of the existing multi-hop clustering protocols\nis the reliability of the communication links between the nodes. In this paper,\nwe suggest an adaptive and completely distributed multi-hop clustering protocol\nthat incorporates different notions of reliability of the communication links,\namong other things, into a composite metric and uses it in all phases of the\nclustering process. The joining criteria for the nodes, which lie at one hop\nfrom the elected cluster heads, to a particular cluster not only consider the\nreliability of their communication link with their cluster head but also other\nimportant attributes. The nodes that lie outside the communication range of\ncluster heads become cluster members transitively through existing cluster\nmembers utilizing the end-to-end notion of link reliability, between the nodes\nand the cluster heads, along with other important attributes. Similarly,\ninter-cluster communication paths are selected using a set of criteria that\nincludes the end-to-end communication link reliability with the sink node along\nwith other important node and network attributes. We believe that incorporating\nlink reliability in all phases of clustering process results in an efficient\nmulti-hop communication hierarchy that has the potential of bringing down the\ntotal communication costs in the network.\n", "versions": [{"version": "v1", "created": "Thu, 2 Sep 2010 10:59:37 GMT"}, {"version": "v2", "created": "Thu, 9 Sep 2010 07:58:24 GMT"}], "update_date": "2010-09-10", "authors_parsed": [["Nawaz", "Khalid", ""], ["Buchmann", "Alejandro P.", ""]]}, {"id": "1009.0862", "submitter": "Mugurel Ionut Andreica", "authors": "Mugurel Ionut Andreica, Andrei Dragus, Ana-Delia Sambotin, Nicolae\n  Tapus", "title": "Brief Announcement: Decentralized Construction of Multicast Trees\n  Embedded into P2P Overlay Networks based on Virtual Geometric Coordinates", "comments": "ISBN: 978-1-60558-888-9", "journal-ref": "Proceedings of the 29th Annual ACM SIGACT-SIGOPS Symposium on\n  Principles of Distributed Computing (PODC), pp. 283-284, Zurich, Switzerland,\n  25-28 July, 2010", "doi": "10.1145/1835698.1835766", "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we consider the problem of efficiently constructing in a fully\ndistributed manner multicast trees which are embedded into P2P overlays using\nvirtual geometric node coordinates. We consider two objectives: to minimize the\nnumber of messages required for constructing a multicast tree by using the\ngeometric properties of the P2P overlay, and to construct stable multicast\ntrees when the lifetime durations of the peers are known.\n", "versions": [{"version": "v1", "created": "Sat, 4 Sep 2010 19:28:13 GMT"}], "update_date": "2010-09-07", "authors_parsed": [["Andreica", "Mugurel Ionut", ""], ["Dragus", "Andrei", ""], ["Sambotin", "Ana-Delia", ""], ["Tapus", "Nicolae", ""]]}, {"id": "1009.1132", "submitter": "Yaniv Altshuler", "authors": "Yaniv Altshuler and Shlomi Dolev and Yuval Elovici", "title": "Efficient Collaborative Application Monitoring Scheme for Mobile\n  Networks", "comments": "19 pages (single colmun) + 9 pages (appendix and references)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MA cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  New operating systems for mobile devices allow their users to download\nmillions of applications created by various individual programmers, some of\nwhich may be malicious or flawed. In order to detect that an application is\nmalicious, monitoring its operation in a real environment for a significant\nperiod of time is often required. Mobile devices have limited computation and\npower resources and thus are limited in their monitoring capabilities. In this\npaper we propose an efficient collaborative monitoring scheme that harnesses\nthe collective resources of many mobile devices, \"vaccinating\" them against\npotentially unsafe applications. We suggest a new local information flooding\nalgorithm called \"TTL Probabilistic Propagation\" (TPP). The algorithm\nperiodically monitors one or more application and reports its conclusions to a\nsmall number of other mobile devices, who then propagate this information\nonwards. The algorithm is analyzed, and is shown to outperform existing state\nof the art information propagation algorithms, in terms of convergence time as\nwell as network overhead. The maximal \"load\" of the algorithm (the fastest\narrival rate of new suspicious applications, that can still guarantee complete\nmonitoring), is analytically calculated and shown to be significantly superior\ncompared to any non-collaborative approach. Finally, we show both analytically\nand experimentally using real world network data that implementing the proposed\nalgorithm significantly reduces the number of infected mobile devices. In\naddition, we analytically prove that the algorithm is tolerant to several types\nof Byzantine attacks where some adversarial agents may generate false\ninformation, or abuse the algorithm in other ways.\n", "versions": [{"version": "v1", "created": "Mon, 6 Sep 2010 19:26:58 GMT"}, {"version": "v2", "created": "Tue, 28 Sep 2010 17:17:54 GMT"}], "update_date": "2010-09-29", "authors_parsed": [["Altshuler", "Yaniv", ""], ["Dolev", "Shlomi", ""], ["Elovici", "Yuval", ""]]}, {"id": "1009.1341", "submitter": "Eric Seidel", "authors": "Gabrielle Allen, Tom Goodale, Frank L\\\"offler, David Rideout, Erik\n  Schnetter, and Eric L. Seidel", "title": "Component Specification in the Cactus Framework: The Cactus\n  Configuration Language", "comments": "10 pages", "journal-ref": null, "doi": "10.1109/GRID.2010.5698008", "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Component frameworks are complex systems that rely on many layers of\nabstraction to function properly. One essential requirement is a consistent\nmeans of describing each individual component and how it relates to both other\ncomponents and the whole framework. As component frameworks are designed to be\nflexible by nature, the description method should be simultaneously powerful,\nlead to efficient code, and be easy to use, so that new users can quickly adapt\ntheir own code to work with the framework. In this paper, we discuss the Cactus\nConfiguration Language (CCL) which is used to describe components (\"thorns'')\nin the Cactus Framework. The CCL provides a description language for the\nvariables, parameters, functions, scheduling and compilation of a component and\nincludes concepts such as interface and implementation which allow thorns\nproviding the same capabilities to be easily interchanged. We include several\napplication examples which illustrate how community toolkits use the CCL and\nCactus and identify needed additions to the language.\n", "versions": [{"version": "v1", "created": "Tue, 7 Sep 2010 17:04:06 GMT"}], "update_date": "2012-02-09", "authors_parsed": [["Allen", "Gabrielle", ""], ["Goodale", "Tom", ""], ["L\u00f6ffler", "Frank", ""], ["Rideout", "David", ""], ["Schnetter", "Erik", ""], ["Seidel", "Eric L.", ""]]}, {"id": "1009.1344", "submitter": "Laszlo Toka", "authors": "Laszlo Toka, Matteo Dell'Amico, Pietro Michiardi", "title": "On Scheduling and Redundancy for P2P Backup", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  An online backup system should be quick and reliable in both saving and\nrestoring users' data. To do so in a peer-to-peer implementation, data transfer\nscheduling and the amount of redundancy must be chosen wisely. We formalize the\nproblem of exchanging multiple pieces of data with intermittently available\npeers, and we show that random scheduling completes transfers nearly optimally\nin terms of duration as long as the system is sufficiently large. Moreover, we\npropose an adaptive redundancy scheme that improves performance and decreases\nresource usage while keeping the risks of data loss low. Extensive simulations\nshow that our techniques are effective in a realistic trace-driven scenario\nwith heterogeneous bandwidth.\n", "versions": [{"version": "v1", "created": "Tue, 7 Sep 2010 17:17:00 GMT"}], "update_date": "2010-09-17", "authors_parsed": [["Toka", "Laszlo", ""], ["Dell'Amico", "Matteo", ""], ["Michiardi", "Pietro", ""]]}, {"id": "1009.2314", "submitter": "Ajay Prasad", "authors": "Ajay Prasad, Sandeep Chaurasia, Arjun Singh, Deepak Gour", "title": "Mapping Cloud Computing onto Useful e-Governance", "comments": null, "journal-ref": "\"Mapping Cloud Computing onto Useful e-Governance\"; International\n  Journal of Computer Science and Information Security (IJCSIS), Vol. 8, No. 5,\n  2010", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Most of the services viewed in context to grid and cloud computing are mostly\nconfined to services that are available for intellectual purposes. The grid or\ncloud computing are large scale distributed systems. The essence of large scale\ndistribution can only be realized if the services are rendered to common man.\nThe only organization which has exposure to almost every single resident is the\nrespective governments in every country. As the size of population increases so\nthe need for a larger purview arises. The problem of having a large purview can\nbe solved by means of large scale grid for online services. The government\nservices can be rendered through fully customized Service-oriented Clouds. In\nthis paper we are presenting tight similarities between generic government\nfunctioning and the service oriented grid/cloud approach. Also, we will discuss\nthe major issues in establishing services oriented grids for governmental\norganization.\n", "versions": [{"version": "v1", "created": "Mon, 13 Sep 2010 07:36:47 GMT"}], "update_date": "2010-09-14", "authors_parsed": [["Prasad", "Ajay", ""], ["Chaurasia", "Sandeep", ""], ["Singh", "Arjun", ""], ["Gour", "Deepak", ""]]}, {"id": "1009.3088", "submitter": "Byung-Gon Chun", "authors": "Byung-Gon Chun, Sunghwan Ihm, Petros Maniatis, Mayur Naik", "title": "CloneCloud: Boosting Mobile Device Applications Through Cloud Clone\n  Execution", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.OS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mobile applications are becoming increasingly ubiquitous and provide ever\nricher functionality on mobile devices. At the same time, such devices often\nenjoy strong connectivity with more powerful machines ranging from laptops and\ndesktops to commercial clouds. This paper presents the design and\nimplementation of CloneCloud, a system that automatically transforms mobile\napplications to benefit from the cloud. The system is a flexible application\npartitioner and execution runtime that enables unmodified mobile applications\nrunning in an application-level virtual machine to seamlessly off-load part of\ntheir execution from mobile devices onto device clones operating in a\ncomputational cloud. CloneCloud uses a combination of static analysis and\ndynamic profiling to optimally and automatically partition an application so\nthat it migrates, executes in the cloud, and re-integrates computation in a\nfine-grained manner that makes efficient use of resources. Our evaluation shows\nthat CloneCloud can achieve up to 21.2x speedup of smartphone applications we\ntested and it allows different partitioning for different inputs and networks.\n", "versions": [{"version": "v1", "created": "Thu, 16 Sep 2010 04:43:46 GMT"}, {"version": "v2", "created": "Sun, 26 Sep 2010 01:40:36 GMT"}], "update_date": "2010-09-28", "authors_parsed": [["Chun", "Byung-Gon", ""], ["Ihm", "Sunghwan", ""], ["Maniatis", "Petros", ""], ["Naik", "Mayur", ""]]}, {"id": "1009.3134", "submitter": "Kostas Tsichlas", "authors": "G.S. Brodal, S. Sioutas, K. Tsichlas, and C. Zaroliagis", "title": "D$^2$-Tree: A New Overlay with Deterministic Bounds", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new overlay, called the {\\em Deterministic Decentralized tree}\n($D^2$-tree). The $D^2$-tree compares favourably to other overlays for the\nfollowing reasons: (a) it provides matching and better complexities, which are\ndeterministic for the supported operations; (b) the management of nodes (peers)\nand elements are completely decoupled from each other; and (c) an efficient\ndeterministic load-balancing mechanism is presented for the uniform\ndistribution of elements into nodes, while at the same time probabilistic\noptimal bounds are provided for the congestion of operations at the nodes. The\nload-balancing scheme of elements into nodes is deterministic and general\nenough to be applied to other hierarchical tree-based overlays. This\nload-balancing mechanism is based on an innovative lazy weight-balancing\nmechanism, which is interesting in its own right.\n", "versions": [{"version": "v1", "created": "Thu, 16 Sep 2010 10:11:04 GMT"}, {"version": "v2", "created": "Thu, 8 Mar 2012 20:05:39 GMT"}], "update_date": "2012-03-09", "authors_parsed": [["Brodal", "G. S.", ""], ["Sioutas", "S.", ""], ["Tsichlas", "K.", ""], ["Zaroliagis", "C.", ""]]}, {"id": "1009.3291", "submitter": "Zhiying Wang", "authors": "Zhiying Wang and Alexandros G. Dimakis and Jehoshua Bruck", "title": "Rebuilding for Array Codes in Distributed Storage Systems", "comments": "7 pages, 3 figures, accepted by workshop on the Application of\n  Communication Theory to Emerging Memory Technologies (ACTEMT) 2010", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In distributed storage systems that use coding, the issue of minimizing the\ncommunication required to rebuild a storage node after a failure arises. We\nconsider the problem of repairing an erased node in a distributed storage\nsystem that uses an EVENODD code. EVENODD codes are maximum distance separable\n(MDS) array codes that are used to protect against erasures, and only require\nXOR operations for encoding and decoding. We show that when there are two\nredundancy nodes, to rebuild one erased systematic node, only 3/4 of the\ninformation needs to be transmitted. Interestingly, in many cases, the required\ndisk I/O is also minimized.\n", "versions": [{"version": "v1", "created": "Thu, 16 Sep 2010 21:54:20 GMT"}], "update_date": "2010-09-20", "authors_parsed": [["Wang", "Zhiying", ""], ["Dimakis", "Alexandros G.", ""], ["Bruck", "Jehoshua", ""]]}, {"id": "1009.3665", "submitter": "Amitabh Chaudhary", "authors": "Tanu Malik, Xiaodan Wang, Philip Little, Amitabh Chaudhary, and Ani\n  Thakar", "title": "A Dynamic Data Middleware Cache for Rapidly-growing Scientific\n  Repositories", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern scientific repositories are growing rapidly in size. Scientists are\nincreasingly interested in viewing the latest data as part of query results.\nCurrent scientific middleware cache systems, however, assume repositories are\nstatic. Thus, they cannot answer scientific queries with the latest data. The\nqueries, instead, are routed to the repository until data at the cache is\nrefreshed. In data-intensive scientific disciplines, such as astronomy,\nindiscriminate query routing or data refreshing often results in runaway\nnetwork costs. This severely affects the performance and scalability of the\nrepositories and makes poor use of the cache system. We present Delta, a\ndynamic data middleware cache system for rapidly-growing scientific\nrepositories. Delta's key component is a decision framework that adaptively\ndecouples data objects---choosing to keep some data object at the cache, when\nthey are heavily queried, and keeping some data objects at the repository, when\nthey are heavily updated. Our algorithm profiles incoming workload to search\nfor optimal data decoupling that reduces network costs. It leverages formal\nconcepts from the network flow problem, and is robust to evolving scientific\nworkloads. We evaluate the efficacy of Delta, through a prototype\nimplementation, by running query traces collected from a real astronomy survey.\n", "versions": [{"version": "v1", "created": "Sun, 19 Sep 2010 22:26:23 GMT"}], "update_date": "2010-09-21", "authors_parsed": [["Malik", "Tanu", ""], ["Wang", "Xiaodan", ""], ["Little", "Philip", ""], ["Chaudhary", "Amitabh", ""], ["Thakar", "Ani", ""]]}, {"id": "1009.4048", "submitter": "Zeeshan Ahmed Mr.", "authors": "Zeeshan Ahmed", "title": "A Middleware road towards Web (Grid) Services", "comments": "In the proceedings of Blekinge Institute of Technology Student\n  Workshop on Architectures and Research in Middleware (BITSWARM), P 67, 12\n  January, Ronneby Sweden 2006", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Middleware technologies is a very big field, containing a strong already done\nresearch as well as the currently running research to confirm already done\nresearch's results and the to have some new solution by theoretical as well as\nthe experimental (practical) way. This document has been produced by Zeeshan\nAhmed (Student: Connectivity Software Technologies Blekinge Institute of\nTechnologies). This describes the research already done in the field of\nmiddleware technologies including Web Services, Grid Computing, Grid Services\nand Open Grid Service Infrastructure & Architecture. This document concludes\nwith the overview of Web (Grid) Service, Chain of Web (Grid) Services and the\nnecessary security issue.\n", "versions": [{"version": "v1", "created": "Tue, 21 Sep 2010 10:29:50 GMT"}], "update_date": "2010-09-22", "authors_parsed": [["Ahmed", "Zeeshan", ""]]}, {"id": "1009.4260", "submitter": "EPTCS", "authors": "Musab AlTurki (University of Illinois at Urbana-Champaign), Jos\\'e\n  Meseguer (University of Illinois at Urbana-Champaign)", "title": "Dist-Orc: A Rewriting-based Distributed Implementation of Orc with\n  Formal Analysis", "comments": "In Proceedings RTRTS 2010, arXiv:1009.3982", "journal-ref": "EPTCS 36, 2010, pp. 26-45", "doi": "10.4204/EPTCS.36.2", "report-no": null, "categories": "cs.LO cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Orc is a theory of orchestration of services that allows structured\nprogramming of distributed and timed computations. Several formal semantics\nhave been proposed for Orc, including a rewriting logic semantics developed by\nthe authors. Orc also has a fully fledged implementation in Java with\nfunctional programming features. However, as with descriptions of most\ndistributed languages, there exists a fairly substantial gap between Orc's\nformal semantics and its implementation, in that: (i) programs in Orc are not\neasily deployable in a distributed implementation just by using Orc's formal\nsemantics, and (ii) they are not readily formally analyzable at the level of a\ndistributed Orc implementation. In this work, we overcome problems (i) and (ii)\nfor Orc. Specifically, we describe an implementation technique based on\nrewriting logic and Maude that narrows this gap considerably. The enabling\nfeature of this technique is Maude's support for external objects through TCP\nsockets. We describe how sockets are used to implement Orc site calls and\nreturns, and to provide real-time timing information to Orc expressions and\nsites. We then show how Orc programs in the resulting distributed\nimplementation can be formally analyzed at a reasonable level of abstraction by\ndefining an abstract model of time and the socket communication infrastructure,\nand discuss the assumptions under which the analysis can be deemed correct.\nFinally, the distributed implementation and the formal analysis methodology are\nillustrated with a case study.\n", "versions": [{"version": "v1", "created": "Wed, 22 Sep 2010 04:02:11 GMT"}], "update_date": "2010-09-23", "authors_parsed": [["AlTurki", "Musab", "", "University of Illinois at Urbana-Champaign"], ["Meseguer", "Jos\u00e9", "", "University of Illinois at Urbana-Champaign"]]}, {"id": "1009.4330", "submitter": "Christian Trott", "authors": "Christian R. Trott, Lars Winterfeld, Paul S. Crozier", "title": "General-purpose molecular dynamics simulations on GPU-based clusters", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cond-mat.mtrl-sci cs.DC cs.PF physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a GPU implementation of LAMMPS, a widely-used parallel molecular\ndynamics (MD) software package, and show 5x to 13x single node speedups versus\nthe CPU-only version of LAMMPS. This new CUDA package for LAMMPS also enables\nmulti-GPU simulation on hybrid heterogeneous clusters, using MPI for inter-node\ncommunication, CUDA kernels on the GPU for all methods working with particle\ndata, and standard LAMMPS C++ code for CPU execution. Cell and neighbor list\napproaches are compared for best performance on GPUs, with thread-per-atom and\nblock-per-atom neighbor list variants showing best performance at low and high\nneighbor counts, respectively. Computational performance results of GPU-enabled\nLAMMPS are presented for a variety of materials classes (e.g. biomolecules,\npolymers, metals, semiconductors), along with a speed comparison versus other\navailable GPU-enabled MD software. Finally, we show strong and weak scaling\nperformance on a CPU/GPU cluster using up to 128 dual GPU nodes.\n", "versions": [{"version": "v1", "created": "Wed, 22 Sep 2010 11:34:20 GMT"}, {"version": "v2", "created": "Sun, 6 Mar 2011 16:47:29 GMT"}], "update_date": "2011-03-08", "authors_parsed": [["Trott", "Christian R.", ""], ["Winterfeld", "Lars", ""], ["Crozier", "Paul S.", ""]]}, {"id": "1009.4447", "submitter": "Karol Suchan", "authors": "Florent Becker, Mart\\'in Matamala, Nicolas Nisse, Ivan Rapaport, Karol\n  Suchan, Ioan Todinca", "title": "Adding a referee to an interconnection network: What can(not) be\n  computed in one round", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we ask which properties of a distributed network can be\ncomputed from a little amount of local information provided by its nodes. The\ndistributed model we consider is a restriction of the classical CONGEST\n(distributed) model and it is close to the simultaneous messages (communication\ncomplexity) model defined by Babai, Kimmel and Lokam. More precisely, each of\nthese n nodes -which only knows its own ID and the IDs of its neighbors- is\nallowed to send a message of O(log n) bits to some central entity, called the\nreferee. Is it possible for the referee to decide some basic structural\nproperties of the network topology G? We show that simple questions like, \"does\nG contain a square?\", \"does G contain a triangle?\" or \"Is the diameter of G at\nmost 3? cannot be solved in general. On the other hand, the referee can decode\nthe messages in order to have full knowledge of G when G belongs to many graph\nclasses such as planar graphs, bounded treewidth graphs and, more generally,\nbounded degeneracy graphs. We leave open questions related to the connectivity\nof arbitrary graphs.\n", "versions": [{"version": "v1", "created": "Wed, 22 Sep 2010 19:01:17 GMT"}, {"version": "v2", "created": "Tue, 5 Oct 2010 18:17:01 GMT"}], "update_date": "2010-10-06", "authors_parsed": [["Becker", "Florent", ""], ["Matamala", "Mart\u00edn", ""], ["Nisse", "Nicolas", ""], ["Rapaport", "Ivan", ""], ["Suchan", "Karol", ""], ["Todinca", "Ioan", ""]]}, {"id": "1009.4642", "submitter": "Constandinos Mavromoustakis X.", "authors": "Constandinos X. Mavromoustakis, Helen D. Karatza", "title": "A Gossip-based optimistic replication for efficient delay-sensitive\n  streaming using an interactive middleware support system", "comments": "IEEE Systems Journal 2010", "journal-ref": null, "doi": "10.1109/JSYST.2010.2047172", "report-no": null, "categories": "cs.DC cs.MM", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  While sharing resources the efficiency is substantially degraded as a result\nof the scarceness of availability of the requested resources in a multiclient\nsupport manner. These resources are often aggravated by many factors like the\ntemporal constraints for availability or node flooding by the requested\nreplicated file chunks. Thus replicated file chunks should be efficiently\ndisseminated in order to enable resource availability on-demand by the mobile\nusers. This work considers a cross layered middleware support system for\nefficient delay-sensitive streaming by using each device's connectivity and\nsocial interactions in a cross layered manner. The collaborative streaming is\nachieved through the epidemically replicated file chunk policy which uses a\ntransition-based approach of a chained model of an infectious disease with\nsusceptible, infected, recovered and death states. The Gossip-based stateful\nmodel enforces the mobile nodes whether to host a file chunk or not or, when no\nlonger a chunk is needed, to purge it. The proposed model is thoroughly\nevaluated through experimental simulation taking measures for the effective\nthroughput Eff as a function of the packet loss parameter in contrast with the\neffectiveness of the replication Gossip-based policy.\n", "versions": [{"version": "v1", "created": "Thu, 9 Sep 2010 09:14:37 GMT"}], "update_date": "2010-09-24", "authors_parsed": [["Mavromoustakis", "Constandinos X.", ""], ["Karatza", "Helen D.", ""]]}, {"id": "1009.4677", "submitter": "Ioana Dumitriu", "authors": "Ioana Dumitriu", "title": "Smallest eigenvalue distributions for two classes of $\\beta$-Jacobi\n  ensembles", "comments": "15 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "math.PR cs.DC cs.NA math-ph math.MP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We compute the exact and limiting smallest eigenvalue distributions for two\nclasses of $\\beta$-Jacobi ensembles not covered by previous studies. In the\ngeneral $\\beta$ case, these distributions are given by multivariate\nhypergeometric ${}_2F_{1}^{2/\\beta}$ functions, whose behavior can be analyzed\nasymptotically for special values of $\\beta$ which include $\\beta \\in\n2\\mathbb{N}_{+}$ as well as for $\\beta = 1$. Interest in these objects stems\nfrom their connections (in the $\\beta = 1,2$ cases) to principal submatrices of\nHaar-distributed (orthogonal, unitary) matrices appearing in randomized,\ncommunication-optimal, fast, and stable algorithms for eigenvalue computations\n\\cite{DDH07}, \\cite{BDD10}.\n", "versions": [{"version": "v1", "created": "Thu, 23 Sep 2010 18:31:26 GMT"}, {"version": "v2", "created": "Fri, 12 Aug 2011 21:53:36 GMT"}], "update_date": "2011-08-16", "authors_parsed": [["Dumitriu", "Ioana", ""]]}, {"id": "1009.4841", "submitter": "Omer Khalid Mr", "authors": "Omer Khalid, Ivo Maljevic, Richard Anthony, Miltos Petridis, Kevin\n  Parrot, Markus Schulz", "title": "Dynamic scheduling of virtual machines running hpc workloads in\n  scientific grids", "comments": "5 pages, 5 figures, NTMS 2009, Cairo, Egypt", "journal-ref": "In Proceedings of 3rd IEEE International Conference of New\n  Technologies, Mobility and Security, 2009", "doi": "10.1145/1330555.1330556", "report-no": null, "categories": "cs.DC cs.DS cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  The primary motivation for uptake of virtualization has been resource\nisolation, capacity management and resource customization allowing resource\nproviders to consolidate their resources in virtual machines. Various\napproaches have been taken to integrate virtualization in to scientific Grids\nespecially in the arena of High Performance Computing (HPC) to run grid jobs in\nvirtual machines, thus enabling better provisioning of the underlying resources\nand customization of the execution environment on runtime. Despite the gains,\nvirtualization layer also incur a performance penalty and its not very well\nunderstood that how such an overhead will impact the performance of systems\nwhere jobs are scheduled with tight deadlines. Since this overhead varies the\ntypes of workload whether they are memory intensive, CPU intensive or network\nI/O bound, and could lead to unpredictable deadline estimation for the running\njobs in the system. In our study, we have attempted to tackle this problem by\ndeveloping an intelligent scheduling technique for virtual machines which\nmonitors the workload types and deadlines, and calculate the system over head\nin real time to maximize number of jobs finishing within their agreed\ndeadlines.\n", "versions": [{"version": "v1", "created": "Fri, 24 Sep 2010 13:57:02 GMT"}], "update_date": "2010-09-27", "authors_parsed": [["Khalid", "Omer", ""], ["Maljevic", "Ivo", ""], ["Anthony", "Richard", ""], ["Petridis", "Miltos", ""], ["Parrot", "Kevin", ""], ["Schulz", "Markus", ""]]}, {"id": "1009.4847", "submitter": "Omer Khalid Mr", "authors": "Omer Khalid, Ivo Maljevic, Richard Anthony, Miltos Petridis, Kevin\n  Parrot, Markus Schulz", "title": "Deadline aware virtual machine scheduler for scientific grids and cloud\n  computing", "comments": "6 pages, 4 figures", "journal-ref": "In Proceeding of 24th IEEE International Conference of Advance\n  Information Networking and Applications, 2010", "doi": "10.1109/WAINA.2010.107", "report-no": null, "categories": "cs.DC cs.PF cs.SE", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Virtualization technology has enabled applications to be decoupled from the\nunderlying hardware providing the benefits of portability, better control over\nexecution environment and isolation. It has been widely adopted in scientific\ngrids and commercial clouds. Since virtualization, despite its benefits incurs\na performance penalty, which could be significant for systems dealing with\nuncertainty such as High Performance Computing (HPC) applications where jobs\nhave tight deadlines and have dependencies on other jobs before they could run.\nThe major obstacle lies in bridging the gap between performance requirements of\na job and performance offered by the virtualization technology if the jobs were\nto be executed in virtual machines. In this paper, we present a novel approach\nto optimize job deadlines when run in virtual machines by developing a\ndeadline-aware algorithm that responds to job execution delays in real time,\nand dynamically optimizes jobs to meet their deadline obligations. Our\napproaches borrowed concepts both from signal processing and statistical\ntechniques, and their comparative performance results are presented later in\nthe paper including the impact on utilization rate of the hardware resources.\n", "versions": [{"version": "v1", "created": "Fri, 24 Sep 2010 14:14:39 GMT"}], "update_date": "2010-09-27", "authors_parsed": [["Khalid", "Omer", ""], ["Maljevic", "Ivo", ""], ["Anthony", "Richard", ""], ["Petridis", "Miltos", ""], ["Parrot", "Kevin", ""], ["Schulz", "Markus", ""]]}, {"id": "1009.4870", "submitter": "Sandor P. Fekete", "authors": "Tobias Baumgartner and Sandor P. Fekete and Tom Kamphans and Alexander\n  Kroeller and Max Pagel", "title": "Hallway Monitoring: Distributed Data Processing with Wireless Sensor\n  Networks", "comments": "12 pages, 5 figures, to appear in REALWSN'10", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a sensor network testbed that monitors a hallway. It consists of\n120 load sensors and 29 passive infrared sensors (PIRs), connected to 30\nwireless sensor nodes. There are also 29 LEDs and speakers installed, operating\nas actuators, and enabling a direct interaction between the testbed and\npassers-by. Beyond that, the network is heterogeneous, consisting of three\ndifferent circuit boards---each with its specific responsibility. The design of\nthe load sensors is of extremely low cost compared to industrial solutions and\neasily transferred to other settings. The network is used for in-network data\nprocessing algorithms, offering possibilities to develop, for instance,\ndistributed target-tracking algorithms. Special features of our installation\nare highly correlated sensor data and the availability of miscellaneous sensor\ntypes.\n", "versions": [{"version": "v1", "created": "Fri, 24 Sep 2010 15:42:30 GMT"}], "update_date": "2010-09-27", "authors_parsed": [["Baumgartner", "Tobias", ""], ["Fekete", "Sandor P.", ""], ["Kamphans", "Tom", ""], ["Kroeller", "Alexander", ""], ["Pagel", "Max", ""]]}, {"id": "1009.4970", "submitter": "Quan-Lin Li", "authors": "Quan-Lin Li and John C.S. Lui", "title": "Doubly Exponential Solution for Randomized Load Balancing Models with\n  Markovian Arrival Processes and PH Service Times", "comments": "Randomized load balancing, supermarket model, matrix-analytic\n  approach, doubly exponential solution, density dependent jump Markov process,\n  Markovian Arrival Process (MAP), phase type (PH) distribution, fixed point,\n  exponential convergence, Lipschitz condition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DM cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  In this paper, we provide a novel matrix-analytic approach for studying\ndoubly exponential solutions of randomized load balancing models (also known as\nsupermarket models) with Markovian arrival processes (MAPs) and phase-type (PH)\nservice times. We describe the supermarket model as a system of differential\nvector equations by means of density dependent jump Markov processes, and\nobtain a closed-form solution with a doubly exponential structure to the fixed\npoint of the system of differential vector equations. Based on this, we show\nthat the fixed point can be decomposed into the product of two factors\ninflecting arrival information and service information, and further find that\nthe doubly exponential solution to the fixed point is not always unique for\nmore general supermarket models. Furthermore, we analyze the exponential\nconvergence of the current location of the supermarket model to its fixed\npoint, and apply the Kurtz Theorem to study density dependent jump Markov\nprocess given in the supermarket model with MAPs and PH service times, which\nleads to the Lipschitz condition under which the fraction measure of the\nsupermarket model weakly converges the system of differential vector equations.\nThis paper gains a new understanding of how workload probing can help in load\nbalancing jobs with non-Poisson arrivals and non-exponential service times.\n", "versions": [{"version": "v1", "created": "Sat, 25 Sep 2010 04:23:50 GMT"}, {"version": "v2", "created": "Sun, 12 Dec 2010 01:29:42 GMT"}], "update_date": "2010-12-14", "authors_parsed": [["Li", "Quan-Lin", ""], ["Lui", "John C. S.", ""]]}, {"id": "1009.5282", "submitter": "Roy Keyes", "authors": "Roy W. Keyes and Christian Romano and Dorian Arnold and Shuang Luan", "title": "Radiation therapy calculations using an on-demand virtual cluster via\n  cloud computing", "comments": "12 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.med-ph cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computer hardware costs are the limiting factor in producing highly accurate\nradiation dose calculations on convenient time scales. Because of this,\nlarge-scale, full Monte Carlo simulations and other resource intensive\nalgorithms are often considered infeasible for clinical settings. The emerging\ncloud computing paradigm promises to fundamentally alter the economics of such\ncalculations by providing relatively cheap, on-demand, pay-as-you-go computing\nresources over the Internet. We believe that cloud computing will usher in a\nnew era, in which very large scale calculations will be routinely performed by\nclinics and researchers using cloud-based resources. In this research, several\nproof-of-concept radiation therapy calculations were successfully performed on\na cloud-based virtual Monte Carlo cluster. Performance evaluations were made of\na distributed processing framework developed specifically for this project. The\nexpected 1/n performance was observed with some caveats. The economics of\ncloud-based virtual computing clusters versus traditional in-house hardware is\nalso discussed. For most situations, cloud computing can provide a substantial\ncost savings for distributed calculations.\n", "versions": [{"version": "v1", "created": "Mon, 27 Sep 2010 15:11:07 GMT"}], "update_date": "2010-09-28", "authors_parsed": [["Keyes", "Roy W.", ""], ["Romano", "Christian", ""], ["Arnold", "Dorian", ""], ["Luan", "Shuang", ""]]}, {"id": "1009.5341", "submitter": "Mateus de Oliveira Oliveira", "authors": "Mateus de Oliveira Oliveira", "title": "Canonizable Partial Order Generators and Regular Slice Languages", "comments": "38 pages. 9 Figures. This work extends the paper \"Canonizable Partial\n  Order Generators\" by the same author that appeared in the Proc. of the 6-th\n  International Conference on Language and Automata Theory and Applications\n  (LATA 2012)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a previous work we introduced slice graphs as a way to specify both\ninfinite languages of directed acyclic graphs (DAGs) and infinite languages of\npartial orders. Therein we focused on the study of Hasse diagram generators,\ni.e., slice graphs that generate only transitive reduced DAGs, and showed that\nthey could be used to solve several problems related to the partial order\nbehavior of p/t-nets. In the present work we show that both slice graphs and\nHasse diagram generators are worth studying on their own. First, we prove that\nany slice graph SG can be effectively transformed into a Hasse diagram\ngenerator HG representing the same set of partial orders. Thus from an\nalgorithmic standpoint we introduce a method of transitive reducing infinite\nfamilies of DAGs specified by slice graphs. Second, we identify the class of\nsaturated slice graphs. By using our transitive reduction algorithm, we prove\nthat the class of partial order languages representable by saturated slice\ngraphs is closed under union, intersection and even under a suitable notion of\ncomplementation (cut-width complementation). Furthermore partial order\nlanguages belonging to this class can be tested for inclusion and admit\ncanonical representatives in terms of Hasse diagram generators. As an\napplication of our results, we give stronger forms of some results in our\nprevious work, and establish some unknown connections between the partial order\nbehavior of $p/t$-nets and other well known formalisms for the specification of\ninfinite families of partial orders, such as Mazurkiewicz trace languages and\nmessage sequence chart (MSC) languages.\n", "versions": [{"version": "v1", "created": "Mon, 27 Sep 2010 17:49:21 GMT"}, {"version": "v2", "created": "Wed, 16 Feb 2011 11:55:03 GMT"}, {"version": "v3", "created": "Mon, 1 Aug 2011 10:10:59 GMT"}, {"version": "v4", "created": "Tue, 26 Jun 2012 11:17:41 GMT"}], "update_date": "2012-06-27", "authors_parsed": [["Oliveira", "Mateus de Oliveira", ""]]}, {"id": "1009.5853", "submitter": "Sandor P. Fekete", "authors": "Tobias Baumgartner, Sandor P. Fekete, Winfried Hellmann, Alexander\n  Kroeller", "title": "Simultaneous Event Execution in Heterogeneous Wireless Sensor Networks", "comments": "6 pages, 5 figures, 3 tables, to appear in Journal of Networks", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a synchronization algorithm to let nodes in a sensor network\nsimultaneously execute a task at a given point in time. In contrast to other\ntime synchronization algorithms we do not provide a global time basis that is\nshared on all nodes. Instead, any node in the network can spontaneously\ninitiate a process that allows the simultaneous execution of arbitrary tasks.\nWe show that our approach is beneficial in scenarios where a global time is not\nneeded, as it requires little communication compared with other time\nsynchronization algorithms. We also show that our algorithm works in\nheterogeneous systems where the hardware provides highly varying clock\naccuracy. Moreover, heterogeneity does not only affect the hardware, but also\nthe communication channels. We deal with different connection types---from\nhighly unreliable and fluctuating wireless channels to reliable and fast wired\nconnections.\n", "versions": [{"version": "v1", "created": "Wed, 29 Sep 2010 11:52:14 GMT"}], "update_date": "2010-09-30", "authors_parsed": [["Baumgartner", "Tobias", ""], ["Fekete", "Sandor P.", ""], ["Hellmann", "Winfried", ""], ["Kroeller", "Alexander", ""]]}, {"id": "1009.6057", "submitter": "Bikash Kumar Dey", "authors": "Virag Shah, Bikash Kumar Dey, D. Manjunath", "title": "Network Flows for Functions", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider in-network computation of an arbitrary function over an arbitrary\ncommunication network. A network with capacity constraints on the links is\ngiven. Some nodes in the network generate data, e.g., like sensor nodes in a\nsensor network. An arbitrary function of this distributed data is to be\nobtained at a terminal node. The structure of the function is described by a\ngiven computation schema, which in turn is represented by a directed tree. We\ndesign computing and communicating schemes to obtain the function at the\nterminal at the maximum rate. For this, we formulate linear programs to\ndetermine network flows that maximize the computation rate. We then develop\nfast combinatorial primal-dual algorithm to obtain $\\epsilon$-approximate\nsolutions to these linear programs. We then briefly describe extensions of our\ntechniques to the cases of multiple terminals wanting different functions,\nmultiple computation schemas for a function, computation with a given desired\nprecision, and to networks with energy constraints at nodes.\n", "versions": [{"version": "v1", "created": "Thu, 30 Sep 2010 08:01:57 GMT"}], "update_date": "2010-10-01", "authors_parsed": [["Shah", "Virag", ""], ["Dey", "Bikash Kumar", ""], ["Manjunath", "D.", ""]]}, {"id": "1009.6127", "submitter": "Hong Jiang", "authors": "Hong Jiang", "title": "Efficient Knowledge Base Management in DCSP", "comments": "11 pages", "journal-ref": "International Journal of Ad hoc, Sensor & Ubiquitous Computing\n  (IJASUC) Vol.1, No.3, September 2010, 21-31", "doi": "10.5121/ijasuc.2010.1302", "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DCSP (Distributed Constraint Satisfaction Problem) has been a very important\nresearch area in AI (Artificial Intelligence). There are many application\nproblems in distributed AI that can be formalized as DSCPs. With the increasing\ncomplexity and problem size of the application problems in AI, the required\nstorage place in searching and the average searching time are increasing too.\nThus, to use a limited storage place efficiently in solving DCSP becomes a very\nimportant problem, and it can help to reduce searching time as well. This paper\nprovides an efficient knowledge base management approach based on general usage\nof hyper-resolution-rule in consistence algorithm. The approach minimizes the\nincreasing of the knowledge base by eliminate sufficient constraint and false\nnogood. These eliminations do not change the completeness of the original\nknowledge base increased. The proofs are given as well. The example shows that\nthis approach decrease both the new nogoods generated and the knowledge base\ngreatly. Thus it decreases the required storage place and simplify the\nsearching process.\n", "versions": [{"version": "v1", "created": "Thu, 30 Sep 2010 13:45:55 GMT"}], "update_date": "2010-10-01", "authors_parsed": [["Jiang", "Hong", ""]]}]