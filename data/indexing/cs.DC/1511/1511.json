[{"id": "1511.00212", "submitter": "Camille Coti", "authors": "Camille Coti", "title": "Exploiting Redundant Computation in Communication-Avoiding Algorithms\n  for Algorithm-Based Fault Tolerance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Communication-avoiding algorithms allow redundant computations to minimize\nthe number of inter-process communications. In this paper, we propose to\nexploit this redundancy for fault-tolerance purpose. We illustrate this idea\nwith QR factorization of tall and skinny matrices, and we evaluate the number\nof failures our algorithm can tolerate under different semantics.\n", "versions": [{"version": "v1", "created": "Sun, 1 Nov 2015 07:16:00 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Coti", "Camille", ""]]}, {"id": "1511.00440", "submitter": "Hucheng Zhou", "authors": "Bo Zhao, Hucheng Zhou, Guoqiang Li, Yihua Huang", "title": "ZenLDA: An Efficient and Scalable Topic Model Training System on\n  Distributed Data-Parallel Platform", "comments": "11 pages, 10 figures. arXiv admin note: text overlap with\n  arXiv:1412.4986 by other authors", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents our recent efforts, zenLDA, an efficient and scalable\nCollapsed Gibbs Sampling system for Latent Dirichlet Allocation training, which\nis thought to be challenging that both data parallelism and model parallelism\nare required because of the Big sampling data with up to billions of documents\nand Big model size with up to trillions of parameters. zenLDA combines both\nalgorithm level improvements and system level optimizations. It first presents\na novel CGS algorithm that balances the time complexity, model accuracy and\nparallelization flexibility. The input corpus in zenLDA is represented as a\ndirected graph and model parameters are annotated as the corresponding vertex\nattributes. The distributed training is parallelized by partitioning the graph\nthat in each iteration it first applies CGS step for all partitions in\nparallel, followed by synchronizing the computed model each other. In this way,\nboth data parallelism and model parallelism are achieved by converting them to\ngraph parallelism. We revisited the tradeoff between system efficiency and\nmodel accuracy and presented approximations such as unsynchronized model,\nsparse model initialization and \"converged\" token exclusion. zenLDA is built on\nGraphX in Spark that provides distributed data abstraction (RDD) and expressive\nAPIs to simplify the programming efforts and simultaneously hides the system\ncomplexities. This enables us to implement other CGS algorithm with a few lines\nof code change. To better fit in distributed data-parallel framework and\nachieve comparable performance with contemporary systems, we also presented\nseveral system level optimizations to push the performance limit. zenLDA was\nevaluated it against web-scale corpus, and the result indicates that zenLDA can\nachieve about much better performance than other CGS algorithm we implemented,\nand simultaneously achieve better model accuracy.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 10:57:25 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Zhao", "Bo", ""], ["Zhou", "Hucheng", ""], ["Li", "Guoqiang", ""], ["Huang", "Yihua", ""]]}, {"id": "1511.00457", "submitter": "Dmitry N. Kozlov", "authors": "Dmitry N. Kozlov", "title": "Structure theory of flip graphs with applications to Weak Symmetry\n  Breaking", "comments": "Final version, as accepted for publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is devoted to advancing the theoretical understanding of the\niterated immediate snapshot (IIS) complexity of the Weak Symmetry Breaking task\n(WSB). Our rather unexpected main theorem states that there exist infinitely\nmany values of n, such that WSB for n~processes is solvable by a certain\nexplicitly constructed 3-round IIS protocol. In particular, the minimal number\nof rounds, which an IIS protocol needs in order to solve the WSB task, does not\ngo to infinity, when the number of processes goes to infinity. Our methods can\nalso be used to generate such values of n.\n  We phrase our proofs in combinatorial language, while avoiding using\ntopology. To this end, we study a~certain class of graphs, which we call flip\ngraphs. These graphs encode adjacency structure in certain subcomplexes of\niterated standard chromatic subdivisions of a simplex. While keeping the\ngeometric background in mind for an additional intuition, we develop the\nstructure theory of matchings in flip graphs in a purely combinatorial way. Our\nbound for the IIS complexity is then a corollary of this general theory.\n  As an afterthought of our result, we suggest to change the overall paradigm.\nSpecifically, we think, that the bounds on the IIS complexity of solving WSB\nfor n processes should be formulated in terms of the size of the solutions of\nthe associated Diophantine equation, rather than in terms of the value n\nitself.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 11:46:41 GMT"}, {"version": "v2", "created": "Fri, 12 Feb 2016 12:26:13 GMT"}, {"version": "v3", "created": "Thu, 10 Mar 2016 09:32:58 GMT"}, {"version": "v4", "created": "Fri, 29 Apr 2016 12:06:35 GMT"}, {"version": "v5", "created": "Thu, 23 Feb 2017 13:11:56 GMT"}], "update_date": "2017-02-24", "authors_parsed": [["Kozlov", "Dmitry N.", ""]]}, {"id": "1511.00486", "submitter": "Yoav Rodeh", "authors": "Pierre Fraigniaud, Amos Korman, Yoav Rodeh", "title": "Parallel Exhaustive Search without Coordination", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We analyze parallel algorithms in the context of exhaustive search over\ntotally ordered sets. Imagine an infinite list of \"boxes\", with a \"treasure\"\nhidden in one of them, where the boxes' order reflects the importance of\nfinding the treasure in a given box. At each time step, a search protocol\nexecuted by a searcher has the ability to peek into one box, and see whether\nthe treasure is present or not. By equally dividing the workload between them,\n$k$ searchers can find the treasure $k$ times faster than one searcher.\nHowever, this straightforward strategy is very sensitive to failures (e.g.,\ncrashes of processors), and overcoming this issue seems to require a large\namount of communication. We therefore address the question of designing\nparallel search algorithms maximizing their speed-up and maintaining high\nlevels of robustness, while minimizing the amount of resources for\ncoordination. Based on the observation that algorithms that avoid communication\nare inherently robust, we analyze the best running time performance of\nnon-coordinating algorithms. Specifically, we devise non-coordinating\nalgorithms that achieve a speed-up of $9/8$ for two searchers, a speed-up of\n$4/3$ for three searchers, and in general, a speed-up of $\\frac{k}{4}(1+1/k)^2$\nfor any $k\\geq 1$ searchers. Thus, asymptotically, the speed-up is only four\ntimes worse compared to the case of full-coordination, and our algorithms are\nsurprisingly simple and hence applicable. Moreover, these bounds are tight in a\nstrong sense as no non-coordinating search algorithm can achieve better\nspeed-ups. Overall, we highlight that, in faulty contexts in which coordination\nbetween the searchers is technically difficult to implement, intrusive with\nrespect to privacy, and/or costly in term of resources, it might well be worth\ngiving up on coordination, and simply run our non-coordinating exhaustive\nsearch algorithms.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 13:16:30 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Fraigniaud", "Pierre", ""], ["Korman", "Amos", ""], ["Rodeh", "Yoav", ""]]}, {"id": "1511.00575", "submitter": "Hao Wang", "authors": "Hao Wang, Jianwei Huang, Xiaojun Lin, Hamed Mohsenian-Rad", "title": "Proactive Demand Response for Data Centers: A Win-Win Solution", "comments": null, "journal-ref": "IEEE Transactions on Smart Grid, 7(3), Pages: 1584-1596, 2016", "doi": "10.1109/TSG.2015.2501808", "report-no": null, "categories": "cs.SY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to reduce the energy cost of data centers, recent studies suggest\ndistributing computation workload among multiple geographically dispersed data\ncenters, by exploiting the electricity price difference. However, the impact of\ndata center load redistribution on the power grid is not well understood yet.\nThis paper takes the first step towards tackling this important issue, by\nstudying how the power grid can take advantage of the data centers' load\ndistribution proactively for the purpose of power load balancing. We model the\ninteractions between power grid and data centers as a two-stage problem, where\nthe utility company chooses proper pricing mechanisms to balance the electric\npower load in the first stage, and the data centers seek to minimize their\ntotal energy cost by responding to the prices in the second stage. We show that\nthe two-stage problem is a bilevel quadratic program, which is NP-hard and\ncannot be solved using standard convex optimization techniques. We introduce\nbenchmark problems to derive upper and lower bounds for the solution of the\ntwo-stage problem. We further propose a branch and bound algorithm to attain\nthe globally optimal solution, and propose a heuristic algorithm with low\ncomputational complexity to obtain an alternative close-to-optimal solution. We\nalso study the impact of background load prediction error using the theoretical\nframework of robust optimization. The simulation results demonstrate that our\nproposed scheme can not only improve the power grid reliability but also reduce\nthe energy cost of data centers.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 16:28:17 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Wang", "Hao", ""], ["Huang", "Jianwei", ""], ["Lin", "Xiaojun", ""], ["Mohsenian-Rad", "Hamed", ""]]}, {"id": "1511.00613", "submitter": "Freddy C. Chua", "authors": "Freddy C. Chua and Bernardo A. Huberman", "title": "A Bayesian Approach to the Partitioning of Workflows", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC physics.soc-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When partitioning workflows in realistic scenarios, the knowledge of the\nprocessing units is often vague or unknown. A naive approach to addressing this\nissue is to perform many controlled experiments for different workloads, each\nconsisting of multiple number of trials in order to estimate the mean and\nvariance of the specific workload. Since this controlled experimental approach\ncan be quite costly in terms of time and resources, we propose a variant of the\nGibbs Sampling algorithm that uses a sequence of Bayesian inference updates to\nestimate the processing characteristics of the processing units. Using the\ninferred characteristics of the processing units, we are able to determine the\nbest way to split a workflow for processing it in parallel with the lowest\nexpected completion time and least variance.\n", "versions": [{"version": "v1", "created": "Mon, 2 Nov 2015 17:48:40 GMT"}], "update_date": "2015-11-03", "authors_parsed": [["Chua", "Freddy C.", ""], ["Huberman", "Bernardo A.", ""]]}, {"id": "1511.00900", "submitter": "Joel Rybicki", "authors": "Sebastian Brandt, Orr Fischer, Juho Hirvonen, Barbara Keller, Tuomo\n  Lempi\\\"ainen, Joel Rybicki, Jukka Suomela, Jara Uitto", "title": "A Lower Bound for the Distributed Lov\\'asz Local Lemma", "comments": "17 pages, 3 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We show that any randomised Monte Carlo distributed algorithm for the\nLov\\'asz local lemma requires $\\Omega(\\log \\log n)$ communication rounds,\nassuming that it finds a correct assignment with high probability. Our result\nholds even in the special case of $d = O(1)$, where $d$ is the maximum degree\nof the dependency graph. By prior work, there are distributed algorithms for\nthe Lov\\'asz local lemma with a running time of $O(\\log n)$ rounds in\nbounded-degree graphs, and the best lower bound before our work was\n$\\Omega(\\log^* n)$ rounds [Chung et al. 2014].\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 13:24:41 GMT"}], "update_date": "2015-11-04", "authors_parsed": [["Brandt", "Sebastian", ""], ["Fischer", "Orr", ""], ["Hirvonen", "Juho", ""], ["Keller", "Barbara", ""], ["Lempi\u00e4inen", "Tuomo", ""], ["Rybicki", "Joel", ""], ["Suomela", "Jukka", ""], ["Uitto", "Jara", ""]]}, {"id": "1511.01158", "submitter": "Minwei Feng", "authors": "Minwei Feng, Bing Xiang, Bowen Zhou", "title": "Distributed Deep Learning for Question Answering", "comments": "This paper will appear in the Proceeding of The 25th ACM\n  International Conference on Information and Knowledge Management (CIKM 2016),\n  Indianapolis, USA", "journal-ref": null, "doi": "10.1145/2983323.2983377", "report-no": null, "categories": "cs.LG cs.CL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper is an empirical study of the distributed deep learning for\nquestion answering subtasks: answer selection and question classification.\nComparison studies of SGD, MSGD, ADADELTA, ADAGRAD, ADAM/ADAMAX, RMSPROP,\nDOWNPOUR and EASGD/EAMSGD algorithms have been presented. Experimental results\nshow that the distributed framework based on the message passing interface can\naccelerate the convergence speed at a sublinear scale. This paper demonstrates\nthe importance of distributed training. For example, with 48 workers, a 24x\nspeedup is achievable for the answer selection task and running time is\ndecreased from 138.2 hours to 5.81 hours, which will increase the productivity\nsignificantly.\n", "versions": [{"version": "v1", "created": "Tue, 3 Nov 2015 23:18:35 GMT"}, {"version": "v2", "created": "Fri, 13 May 2016 15:41:54 GMT"}, {"version": "v3", "created": "Thu, 4 Aug 2016 16:41:37 GMT"}], "update_date": "2016-08-05", "authors_parsed": [["Feng", "Minwei", ""], ["Xiang", "Bing", ""], ["Zhou", "Bowen", ""]]}, {"id": "1511.01232", "submitter": "Roberto Morabito", "authors": "Roberto Morabito", "title": "Power Consumption of Virtualization Technologies: an Empirical\n  Investigation", "comments": "Accepted to the IEEE/ACM UCC 2015 (SD3C Workshop) - IEEE Copyright", "journal-ref": null, "doi": "10.1109/UCC.2015.93", "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Virtualization is growing rapidly as a result of the increasing number of\nalternative solutions in this area, and of the wide range of application field.\nUntil now, hypervisor-based virtualization has been the de facto solution to\nperform server virtualization. Recently, container-based virtualization - an\nalternative to hypervisors - has gained more attention because of lightweight\ncharacteristics, attracting cloud providers that have already made use of it to\ndeliver their services. However, a gap in the existing research on containers\nexists in the area of power consumption. This paper presents the results of a\nperformance comparison in terms of power consumption of four different\nvirtualization technologies: KVM and Xen, which are based on hypervisor\nvirtualization, Docker and LXC which are based on container virtualization. The\naim of this empirical investigation, carried out by means of a testbed, is to\nunderstand how these technologies react to particular workloads. Our initial\nresults show how, despite of the number of virtual entities running, both kinds\nof virtualization alternatives behave similarly in idle state and in CPU/Memory\nstress test. Contrarily, the results on network performance show differences\nbetween the two technologies.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 07:49:47 GMT"}], "update_date": "2017-10-30", "authors_parsed": [["Morabito", "Roberto", ""]]}, {"id": "1511.01287", "submitter": "Adrian Kosowski", "authors": "Pierre Fraigniaud (GANG), Marc Heinrich (GANG), Adrian Kosowski (GANG)", "title": "Local Conflict Coloring", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Locally finding a solution to symmetry-breaking tasks such as\nvertex-coloring, edge-coloring, maximal matching, maximal independent set,\netc., is a long-standing challenge in distributed network computing. More\nrecently, it has also become a challenge in the framework of centralized local\ncomputation. We introduce conflict coloring as a general symmetry-breaking task\nthat includes all the aforementioned tasks as specific instantiations ---\nconflict coloring includes all locally checkable labeling tasks from\n[Naor\\&Stockmeyer, STOC 1993]. Conflict coloring is characterized by two\nparameters $l$ and $d$, where the former measures the amount of freedom given\nto the nodes for selecting their colors, and the latter measures the number of\nconstraints which colors of adjacent nodes are subject to.We show that, in the\nstandard LOCAL model for distributed network computing, if $l/d \\textgreater{}\n\\Delta$, then conflict coloring can be solved in $\\tilde\nO(\\sqrt{\\Delta})+\\log^*n$ rounds in $n$-node graphs with maximum degree\n$\\Delta$, where $\\tilde O$ ignores the polylog factors in $\\Delta$. The\ndependency in~$n$ is optimal, as a consequence of the $\\Omega(\\log^*n)$ lower\nbound by [Linial, SIAM J. Comp. 1992] for $(\\Delta+1)$-coloring. An important\nspecial case of our result is a significant improvement over the best known\nalgorithm for distributed $(\\Delta+1)$-coloring due to [Barenboim, PODC 2015],\nwhich required $\\tilde O(\\Delta^{3/4})+\\log^*n$ rounds. Improvements for other\nvariants of coloring, including $(\\Delta+1)$-list-coloring,\n$(2\\Delta-1)$-edge-coloring, $T$-coloring, etc., also follow from our general\nresult on conflict coloring. Likewise, in the framework of centralized local\ncomputation algorithms (LCAs), our general result yields an LCA which requires\na smaller number of probes than the previously best known algorithm for\nvertex-coloring, and works for a wide range of coloring problems.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 10:56:55 GMT"}, {"version": "v2", "created": "Thu, 2 Feb 2017 12:38:21 GMT"}], "update_date": "2017-02-03", "authors_parsed": [["Fraigniaud", "Pierre", "", "GANG"], ["Heinrich", "Marc", "", "GANG"], ["Kosowski", "Adrian", "", "GANG"]]}, {"id": "1511.01443", "submitter": "Cheng Huang", "authors": "Cheng Huang and Xiaoming Huo", "title": "A Distributed One-Step Estimator", "comments": "31 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ME cs.DC stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Distributed statistical inference has recently attracted enormous attention.\nMany existing work focuses on the averaging estimator. We propose a one-step\napproach to enhance a simple-averaging based distributed estimator. We derive\nthe corresponding asymptotic properties of the newly proposed estimator. We\nfind that the proposed one-step estimator enjoys the same asymptotic properties\nas the centralized estimator. The proposed one-step approach merely requires\none additional round of communication in relative to the averaging estimator;\nso the extra communication burden is insignificant. In finite sample cases,\nnumerical examples show that the proposed estimator outperforms the simple\naveraging estimator with a large margin in terms of the mean squared errors. A\npotential application of the one-step approach is that one can use multiple\nmachines to speed up large scale statistical inference with little compromise\nin the quality of estimators. The proposed method becomes more valuable when\ndata can only be available at distributed machines with limited communication\nbandwidth.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 19:18:41 GMT"}, {"version": "v2", "created": "Tue, 10 Nov 2015 20:04:10 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Huang", "Cheng", ""], ["Huo", "Xiaoming", ""]]}, {"id": "1511.01446", "submitter": "Mbarka Soualhia", "authors": "Mbarka Soualhia, Foutse Khomh, Sofiene Tahar", "title": "ATLAS: An Adaptive Failure-aware Scheduler for Hadoop", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Hadoop has become the de facto standard for processing large data in today's\ncloud environment. The performance of Hadoop in the cloud has a direct impact\non many important applications ranging from web analytic, web indexing, image\nand document processing to high-performance scientific computing. However,\nbecause of the scale, complexity and dynamic nature of the cloud, failures are\ncommon and these failures often impact the performance of jobs running in\nHadoop. Although Hadoop possesses built-in failure detection and recovery\nmechanisms, several scheduled jobs still fail because of unforeseen events in\nthe cloud environment. A single task failure can cause the failure of the whole\njob and unpredictable job running times. In this report, we propose ATLAS\n(AdapTive faiLure-Aware Scheduler), a new scheduler for Hadoop that can adapt\nits scheduling decisions to events occurring in the cloud environment. Using\nstatistical models, ATLAS predicts task failures and adjusts its scheduling\ndecisions on the fly to reduce task failure occurrences. We implement ATLAS in\nthe Hadoop framework of Amazon Elastic MapReduce (EMR) and perform a case study\nto compare its performance with those of the FIFO, Fair and Capacity\nschedulers. Results show that ATLAS can reduce the percentage of failed jobs by\nup to 28% and the percentage of failed tasks by up to 39%, and the total\nexecution time of jobs by 10 minutes on average. ATLAS also reduces CPU and\nmemory usages.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 19:30:14 GMT"}, {"version": "v2", "created": "Thu, 5 Nov 2015 14:40:53 GMT"}], "update_date": "2016-11-04", "authors_parsed": [["Soualhia", "Mbarka", ""], ["Khomh", "Foutse", ""], ["Tahar", "Sofiene", ""]]}, {"id": "1511.01561", "submitter": "Andreas M\\\"uller", "authors": "Andreas M\\\"uller, Michal A. Kopera, Simone Marras, Lucas C. Wilcox,\n  Tobin Isaac, Francis X. Giraldo", "title": "Strong Scaling for Numerical Weather Prediction at Petascale with the\n  Atmospheric Model NUMA", "comments": "33 pages, 12 figures, submitted to the International Journal of\n  High-Performance Computing Applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE physics.ao-ph physics.flu-dyn physics.geo-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Numerical weather prediction (NWP) has proven to be computationally\nchallenging due to its inherent multiscale nature. Currently, the highest\nresolution NWP models use a horizontal resolution of about 10km. In order to\nincrease the resolution of NWP models highly scalable atmospheric models are\nneeded.\n  The Non-hydrostatic Unified Model of the Atmosphere (NUMA), developed by the\nauthors at the Naval Postgraduate School, was designed to achieve this purpose.\nNUMA is used by the Naval Research Laboratory, Monterey as the engine inside\nits next generation weather prediction system NEPTUNE. NUMA solves the fully\ncompressible Navier-Stokes equations by means of high-order Galerkin methods\n(both spectral element as well as discontinuous Galerkin methods can be used).\nMesh generation is done using the p4est library. NUMA is capable of running\nmiddle and upper atmosphere simulations since it does not make use of the\nshallow-atmosphere approximation.\n  This paper presents the performance analysis and optimization of the spectral\nelement version of NUMA. The performance at different optimization stages is\nanalyzed using a theoretical performance model as well as measurements via\nhardware counters. Machine independent optimization is compared to machine\nspecific optimization using BG/Q vector intrinsics. By using vector intrinsics\nthe main computations reach 1.2 PFlops on the entire machine Mira (12% of the\ntheoretical peak performance). The paper also presents scalability studies for\ntwo idealized test cases that are relevant for NWP applications. The\natmospheric model NUMA delivers an excellent strong scaling efficiency of 99%\non the entire supercomputer Mira using a mesh with 1.8 billion grid points.\nThis allows to run a global forecast of a baroclinic wave test case at 3km\nuniform horizontal resolution and double precision within the time frame\nrequired for operational weather prediction.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 00:31:29 GMT"}, {"version": "v2", "created": "Wed, 7 Sep 2016 10:50:52 GMT"}, {"version": "v3", "created": "Thu, 8 Sep 2016 11:55:11 GMT"}], "update_date": "2016-09-09", "authors_parsed": [["M\u00fcller", "Andreas", ""], ["Kopera", "Michal A.", ""], ["Marras", "Simone", ""], ["Wilcox", "Lucas C.", ""], ["Isaac", "Tobin", ""], ["Giraldo", "Francis X.", ""]]}, {"id": "1511.01643", "submitter": "Shantanu Sharma", "authors": "Nisha Panwar, Shantanu Sharma, Awadhesh Kumar Singh", "title": "A Survey on 5G: The Next Generation of Mobile Communication", "comments": "Accepted in Elsevier Physical Communication, 24 pages, 5 figures, 2\n  tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The rapidly increasing number of mobile devices, voluminous data, and higher\ndata rate are pushing to rethink the current generation of the cellular mobile\ncommunication. The next or fifth generation (5G) cellular networks are expected\nto meet high-end requirements. The 5G networks are broadly characterized by\nthree unique features: ubiquitous connectivity, extremely low latency, and very\nhigh-speed data transfer. The 5G networks would provide novel architectures and\ntechnologies beyond state-of-the-art architectures and technologies. In this\npaper, our intent is to find an answer to the question: \"what will be done by\n5G and how?\" We investigate and discuss serious limitations of the fourth\ngeneration (4G) cellular networks and corresponding new features of 5G\nnetworks. We identify challenges in 5G networks, new technologies for 5G\nnetworks, and present a comparative study of the proposed architectures that\ncan be categorized on the basis of energy-efficiency, network hierarchy, and\nnetwork types. Interestingly, the implementation issues, e.g., interference,\nQoS, handoff, security-privacy, channel access, and load balancing, hugely\neffect the realization of 5G networks. Furthermore, our illustrations highlight\nthe feasibility of these models through an evaluation of existing\nreal-experiments and testbeds.\n", "versions": [{"version": "v1", "created": "Wed, 4 Nov 2015 04:32:23 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Panwar", "Nisha", ""], ["Sharma", "Shantanu", ""], ["Singh", "Awadhesh Kumar", ""]]}, {"id": "1511.01779", "submitter": "Srivatsan Ravi Mr", "authors": "Srivatsan Ravi", "title": "On the Cost of Concurrency in Transactional Memory", "comments": "Ph.D. Thesis", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional techniques for synchronization are based on \\emph{locking} that\nprovides threads with exclusive access to shared data. \\emph{Coarse-grained}\nlocking typically forces threads to access large amounts of data sequentially\nand, thus, does not fully exploit hardware concurrency. Program-specific\n\\emph{fine-grained} locking or \\emph{non-blocking} (\\emph{i.e.}, not using\nlocks) synchronization, on the other hand, is a dark art to most programmers\nand trusted to the wisdom of a few computing experts. Thus, it is appealing to\nseek a middle ground between these two extremes: a synchronization mechanism\nthat relieves the programmer of the overhead of reasoning about data conflicts\nthat may arise from concurrent operations without severely limiting the\nprogram's performance. The \\emph{Transactional Memory (TM)} abstraction is\nproposed as such a mechanism: it intends to combine an easy-to-use programming\ninterface with an efficient utilization of the concurrent-computing abilities\nprovided by multicore architectures. TM allows the programmer to\n\\emph{speculatively} execute sequences of shared-memory operations as\n\\emph{atomic transactions} with \\emph{all-or-nothing} semantics: the\ntransaction can either \\emph{commit}, in which case it appears as executed\nsequentially, or \\emph{abort}, in which case its update operations do not take\neffect. Thus, the programmer can design software having only sequential\nsemantics in mind and let TM take care, at run-time, of resolving the conflicts\nin concurrent executions.\n  Intuitively, we want TMs to allow for as much \\emph{concurrency} as possible:\nin the absence of severe data conflicts, transactions should be able to\nprogress in parallel. But what are the inherent costs associated with providing\nhigh degrees of concurrency in TMs? This is the central question of the thesis.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 15:21:30 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Ravi", "Srivatsan", ""]]}, {"id": "1511.01821", "submitter": "Lili Su", "authors": "Lili Su, Nitin H. Vaidya", "title": "Fault-Tolerant Distributed Optimization (Part IV): Constrained\n  Optimization with Arbitrary Directed Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of constrained distributed optimization in multi-agent\nnetworks when some of the computing agents may be faulty. In this problem, the\nsystem goal is to have all the non-faulty agents collectively minimize a global\nobjective given by weighted average of local cost functions, each of which is\ninitially known to a non-faulty agent only. In particular, we are interested in\nthe scenario when the computing agents are connected by an arbitrary directed\ncommunication network, some of the agents may suffer from crash faults or\nByzantine faults, and the estimate of each agent is restricted to lie in a\ncommon constraint set. This problem finds its applications in social computing\nand distributed large-scale machine learning.\n  The fault-tolerant multi-agent optimization problem was first formulated by\nSu and Vaidya, and is solved when the local functions are defined over the\nwhole real line, and the networks are fully-connected. In this report, we\nconsider arbitrary directed communication networks and focus on the scenario\nwhere, local estimates at the non-faulty agents are constrained, and only local\ncommunication and minimal memory carried across iterations are allowed. In\nparticular, we generalize our previous results on fully-connected networks and\nunconstrained optimization to arbitrary directed networks and constrained\noptimization. As a byproduct, we provide a matrix representation for iterative\napproximate crash consensus. The matrix representation allows us to\ncharacterize the convergence rate for crash iterative consensus.\n", "versions": [{"version": "v1", "created": "Thu, 5 Nov 2015 17:28:35 GMT"}], "update_date": "2015-11-06", "authors_parsed": [["Su", "Lili", ""], ["Vaidya", "Nitin H.", ""]]}, {"id": "1511.02030", "submitter": "David Carrera", "authors": "Josep Ll. Berral, Nicolas Poggi, David Carrera, Aaron Call, Rob\n  Reinauer, Daron Green", "title": "ALOJA-ML: A Framework for Automating Characterization and Knowledge\n  Discovery in Hadoop Deployments", "comments": "Submitted to KDD'2015. Part of the Aloja Project. Partially funded by\n  European Research Council (ERC) under the European Union's Horizon 2020\n  research and innovation programme (grant agreement No 639595) - HiEST Project", "journal-ref": "Proceedings of the 21th ACM SIGKDD International Conference on\n  Knowledge Discovery and Data Mining. Pages 1701-1710. ACM New York, NY, USA.\n  2015. ISBN: 978-1-4503-3664-2", "doi": "10.1145/2783258.2788600", "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents ALOJA-Machine Learning (ALOJA-ML) an extension to the\nALOJA project that uses machine learning techniques to interpret Hadoop\nbenchmark performance data and performance tuning; here we detail the approach,\nefficacy of the model and initial results. Hadoop presents a complex execution\nenvironment, where costs and performance depends on a large number of software\n(SW) configurations and on multiple hardware (HW) deployment choices. These\nresults are accompanied by a test bed and tools to deploy and evaluate the\ncost-effectiveness of the different hardware configurations, parameter tunings,\nand Cloud services. Despite early success within ALOJA from expert-guided\nbenchmarking, it became clear that a genuinely comprehensive study requires\nautomation of modeling procedures to allow a systematic analysis of large and\nresource-constrained search spaces. ALOJA-ML provides such an automated system\nallowing knowledge discovery by modeling Hadoop executions from observed\nbenchmarks across a broad set of configuration parameters. The resulting\nperformance models can be used to forecast execution behavior of various\nworkloads; they allow 'a-priori' prediction of the execution times for new\nconfigurations and HW choices and they offer a route to model-based anomaly\ndetection. In addition, these models can guide the benchmarking exploration\nefficiently, by automatically prioritizing candidate future benchmark tests.\nInsights from ALOJA-ML's models can be used to reduce the operational time on\nclusters, speed-up the data acquisition and knowledge discovery process, and\nimportantly, reduce running costs. In addition to learning from the methodology\npresented in this work, the community can benefit in general from ALOJA\ndata-sets, framework, and derived insights to improve the design and deployment\nof Big Data applications.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 10:55:18 GMT"}], "update_date": "2015-11-09", "authors_parsed": [["Berral", "Josep Ll.", ""], ["Poggi", "Nicolas", ""], ["Carrera", "David", ""], ["Call", "Aaron", ""], ["Reinauer", "Rob", ""], ["Green", "Daron", ""]]}, {"id": "1511.02037", "submitter": "David Carrera", "authors": "Josep Ll. Berral, Nicolas Poggi, David Carrera, Aaron Call, Rob\n  Reinauer, Daron Green", "title": "ALOJA: A Framework for Benchmarking and Predictive Analytics in Big Data\n  Deployments", "comments": "Submitted to IEEE Transactions on Emerging Topics in Computing\n  (TETC). Part of the Aloja Project. Partially funded by European Research\n  Council (ERC) under the European Union's Horizon 2020 research and innovation\n  programme (grant agreement No 639595) - HiEST Project. arXiv admin note:\n  substantial text overlap with arXiv:1511.02030", "journal-ref": null, "doi": "10.1109/TETC.2015.2496504", "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article presents the ALOJA project and its analytics tools, which\nleverages machine learning to interpret Big Data benchmark performance data and\ntuning. ALOJA is part of a long-term collaboration between BSC and Microsoft to\nautomate the characterization of cost-effectiveness on Big Data deployments,\ncurrently focusing on Hadoop. Hadoop presents a complex run-time environment,\nwhere costs and performance depend on a large number of configuration choices.\nThe ALOJA project has created an open, vendor-neutral repository, featuring\nover 40,000 Hadoop job executions and their performance details. The repository\nis accompanied by a test-bed and tools to deploy and evaluate the\ncost-effectiveness of different hardware configurations, parameters and Cloud\nservices. Despite early success within ALOJA, a comprehensive study requires\nautomation of modeling procedures to allow an analysis of large and\nresource-constrained search spaces. The predictive analytics extension,\nALOJA-ML, provides an automated system allowing knowledge discovery by modeling\nenvironments from observed executions. The resulting models can forecast\nexecution behaviors, predicting execution times for new configurations and\nhardware choices. That also enables model-based anomaly detection or efficient\nbenchmark guidance by prioritizing executions. In addition, the community can\nbenefit from ALOJA data-sets and framework to improve the design and deployment\nof Big Data applications.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 11:27:29 GMT"}], "update_date": "2015-11-09", "authors_parsed": [["Berral", "Josep Ll.", ""], ["Poggi", "Nicolas", ""], ["Carrera", "David", ""], ["Call", "Aaron", ""], ["Reinauer", "Rob", ""], ["Green", "Daron", ""]]}, {"id": "1511.02043", "submitter": "David Carrera", "authors": "Marcelo Amaral, Jord\\`a Polo, David Carrera, Iqbal Mohomed, Merve\n  Unuvar, Malgorzata Steinder", "title": "Performance Evaluation of Microservices Architectures using Containers", "comments": "Submitted to the 14th IEEE International Symposium on Network\n  Computing and Applications (IEEE NCA15). Partially funded by European\n  Research Council (ERC) under the European Union's Horizon 2020 research and\n  innovation programme (grant agreement No 639595) - HiEST Project", "journal-ref": null, "doi": "10.1109/NCA.2015.49", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Microservices architecture has started a new trend for application\ndevelopment for a number of reasons: (1) to reduce complexity by using tiny\nservices; (2) to scale, remove and deploy parts of the system easily; (3) to\nimprove flexibility to use different frameworks and tools; (4) to increase the\noverall scalability; and (5) to improve the resilience of the system.\nContainers have empowered the usage of microservices architectures by being\nlightweight, providing fast start-up times, and having a low overhead.\nContainers can be used to develop applications based on monolithic\narchitectures where the whole system runs inside a single container or inside a\nmicroservices architecture where one or few processes run inside the\ncontainers. Two models can be used to implement a microservices architecture\nusing containers: master-slave, or nested-container. The goal of this work is\nto compare the performance of CPU and network running benchmarks in the two\naforementioned models of microservices architecture hence provide a benchmark\nanalysis guidance for system designers.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 12:04:39 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Amaral", "Marcelo", ""], ["Polo", "Jord\u00e0", ""], ["Carrera", "David", ""], ["Mohomed", "Iqbal", ""], ["Unuvar", "Merve", ""], ["Steinder", "Malgorzata", ""]]}, {"id": "1511.02166", "submitter": "Lukas Einkemmer", "authors": "Lukas Einkemmer", "title": "Evaluation of the Intel Xeon Phi 7120 and NVIDIA K80 as accelerators for\n  two-dimensional panel codes", "comments": null, "journal-ref": "PLoS ONE 12(6): e0178156, 2017", "doi": "10.1371/journal.pone.0178156", "report-no": null, "categories": "cs.DC cs.MS physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To optimize the geometry of airfoils for a specific application is an\nimportant engineering problem. In this context genetic algorithms have enjoyed\nsome success as they are able to explore the search space without getting stuck\nin local optima. However, these algorithms require the computation of\naerodynamic properties for a significant number of airfoil geometries.\nConsequently, for low-speed aerodynamics, panel methods are most often used as\nthe inner solver.\n  In this paper we evaluate the performance of such an optimization algorithm\non modern accelerators (more specifically, the Intel Xeon Phi 7120 and the\nNVIDIA K80). For that purpose, we have implemented an optimized version of the\nalgorithm on the CPU and Xeon Phi (based on OpenMP, vectorization, and the\nIntel MKL library) and on the GPU (based on CUDA and the MAGMA library). We\npresent timing results for all codes and discuss the similarities and\ndifferences between the three implementations. Overall, we observe a speedup of\napproximately $2.5$ for adding an Intel Xeon Phi 7120 to a dual socket\nworkstation and a speedup between $3.4$ and $3.8$ for adding a NVIDIA K80 to a\ndual socket workstation.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 17:17:36 GMT"}, {"version": "v2", "created": "Wed, 28 Mar 2018 15:07:53 GMT"}], "update_date": "2018-08-14", "authors_parsed": [["Einkemmer", "Lukas", ""]]}, {"id": "1511.02171", "submitter": "Francisco Igual", "authors": "Sandra Catal\\'an, Jos\\'e R. Herrero, Francisco D. Igual, Rafael\n  Rodr\\'iguez-S\\'anchez, Enrique S. Quintana-Ort\\'i", "title": "Multi-Threaded Dense Linear Algebra Libraries for Low-Power Asymmetric\n  Multicore Processors", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dense linear algebra libraries, such as BLAS and LAPACK, provide a relevant\ncollection of numerical tools for many scientific and engineering applications.\nWhile there exist high performance implementations of the BLAS (and LAPACK)\nfunctionality for many current multi-threaded architectures,the adaption of\nthese libraries for asymmetric multicore processors (AMPs)is still pending. In\nthis paper we address this challenge by developing an asymmetry-aware\nimplementation of the BLAS, based on the BLIS framework, and tailored for AMPs\nequipped with two types of cores: fast/power hungry versus slow/energy\nefficient. For this purpose, we integrate coarse-grain and fine-grain\nparallelization strategies into the library routines which, respectively,\ndynamically distribute the workload between the two core types and statically\nrepartition this work among the cores of the same type.\n  Our results on an ARM big.LITTLE processor embedded in the Exynos 5422 SoC,\nusing the asymmetry-aware version of the BLAS and a plain migration of the\nlegacy version of LAPACK, experimentally assess the benefits, limitations, and\npotential of this approach.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 17:36:20 GMT"}], "update_date": "2015-11-09", "authors_parsed": [["Catal\u00e1n", "Sandra", ""], ["Herrero", "Jos\u00e9 R.", ""], ["Igual", "Francisco D.", ""], ["Rodr\u00edguez-S\u00e1nchez", "Rafael", ""], ["Quintana-Ort\u00ed", "Enrique S.", ""]]}, {"id": "1511.02186", "submitter": "Gang Mei", "authors": "Gang Mei and Liangliang Xu and Nengxiong Xu", "title": "Accelerating Adaptive IDW Interpolation Algorithm on a Single GPU", "comments": "Preprint version for submitting to a journal. 15 pages, 7 figures, 1\n  table", "journal-ref": "Royal Society Open Science, 2017", "doi": "10.1098/rsos.170436", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper focuses on the design and implementing of GPU-accelerated Adaptive\nInverse Distance Weighting (AIDW) interpolation algorithm. The AIDW is an\nimproved version of the standard IDW, which can adaptively determine the power\nparameter according to the spatial points distribution pattern and achieve more\naccurate predictions than those by IDW. In this paper, we first present two\nversions of the GPU accelerated AIDW, the naive version without profiting from\nshared memory and the tiled version taking advantage of shared memory. We also\nimplement the naive version and the tiled version using the data layouts,\nStructure of Arrays (AoS) and Array of aligned Structures (AoaS), on single and\ndouble precision. We then evaluate the performance of the GPU-accelerated AIDW\nby comparing it with its original CPU version. Experimental results show that:\non single precision the naive version and the tiled version can achieve the\nspeedups of approximately 270 and 400, respectively. In addition, on single\nprecision the implementations using the layout SoA are always slightly faster\nthan those using layout AoaS. However, on double precision, the speedup is only\nabout 8; and we have also observed that: (1) there are no performance gains\nobtained from the tiled version against the naive version; and (2) the use of\nSoA and AoaS does not lead to significant differences in computational\nefficiency.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 18:37:01 GMT"}, {"version": "v2", "created": "Thu, 10 Dec 2015 14:04:39 GMT"}], "update_date": "2017-09-21", "authors_parsed": [["Mei", "Gang", ""], ["Xu", "Liangliang", ""], ["Xu", "Nengxiong", ""]]}, {"id": "1511.02240", "submitter": "Lasse Natvig", "authors": "Lasse Natvig, Torbj{\\o}rn Follan, Simen St{\\o}a, Sindre Magnussen and\n  Antonio Garcia Guirado", "title": "Climbing Mont Blanc - A Training Site for Energy Efficient Programming\n  on Heterogeneous Multicore Processors", "comments": "4 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Climbing Mont Blanc (CMB) is an open online judge used for training in energy\nefficient programming of state-of-the-art heterogeneous multicores. It uses an\nOdroid-XU3 board from Hardkernel with an Exynos Octa processor and integrated\npower sensors. This processor is three-way heterogeneous containing 14\ndifferent cores of three different types. The board currently accepts C and C++\nprograms, with support for OpenCL v1.1, OpenMP 4.0 and Pthreads. Programs\nsubmitted using the graphical user interface are evaluated with respect to\ntime, energy used, and energy-efficiency (EDP). A small and varied set of\nproblems are available, and the system is currently in use in a medium sized\ncourse on parallel computing at NTNU. Other online programming judges exist,\nbut we are not aware of any similar system that also reports energy-efficiency.\n", "versions": [{"version": "v1", "created": "Fri, 6 Nov 2015 21:15:53 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Natvig", "Lasse", ""], ["Follan", "Torbj\u00f8rn", ""], ["St\u00f8a", "Simen", ""], ["Magnussen", "Sindre", ""], ["Guirado", "Antonio Garcia", ""]]}, {"id": "1511.02354", "submitter": "Arne Ludwig", "authors": "Arne Ludwig, Carlo Fuerst, Alexander Henze and Stefan Schmid", "title": "Opposites Attract: Virtual Cluster Embedding for Profit", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  It is well-known that cloud application performance critically depends on the\nnetwork. Accordingly, new abstractions for cloud applications are proposed\nwhich extend the performance isolation guarantees to the network. The most\ncommon abstraction is the Virtual Cluster V C(n, b): the n virtual machines of\na customer are connected to a virtual switch at bandwidth b. However, today,\nnot much is known about how to efficiently embed and price virtual clusters.\nThis paper makes two contributions. (1) We present an algorithm called Tetris\nthat efficiently embeds virtual clusters arriving in an online fashion, by\njointly optimizing the node and link resources. We show that this algorithm\nallows to multiplex more virtual clusters over the same physical infrastructure\ncompared to existing algorithms, hence improving the provider profit. (2) We\npresent the first demand-specific pricing model called DSP for virtual\nclusters. Our pricing model is fair in the sense that a customer only needs to\npay for what he or she asked. Moreover, it features other desirable properties,\nsuch as price independence from mapping locations.\n", "versions": [{"version": "v1", "created": "Sat, 7 Nov 2015 13:43:29 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Ludwig", "Arne", ""], ["Fuerst", "Carlo", ""], ["Henze", "Alexander", ""], ["Schmid", "Stefan", ""]]}, {"id": "1511.02433", "submitter": "Andr\\'e Rodrigues Valente", "authors": "Andr\\'e Valente Rodrigues, Al\\'ipio Jorge, In\\^es Dutra", "title": "Accelerating Recommender Systems using GPUs", "comments": null, "journal-ref": "SAC '15 Proceedings of the 30th Annual ACM Symposium on Applied\n  Computing Pages 879-884 ACM New York, NY, USA", "doi": "10.1145/2695664.2695850", "report-no": null, "categories": "cs.IR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe GPU implementations of the matrix recommender algorithms CCD++\nand ALS. We compare the processing time and predictive ability of the GPU\nimplementations with existing multi-core versions of the same algorithms.\nResults on the GPU are better than the results of the multi-core versions\n(maximum speedup of 14.8).\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2015 03:25:28 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Rodrigues", "Andr\u00e9 Valente", ""], ["Jorge", "Al\u00edpio", ""], ["Dutra", "In\u00eas", ""]]}, {"id": "1511.02490", "submitter": "Chris Cummins", "authors": "Chris Cummins, Pavlos Petoumenos, Michel Steuwer, and Hugh Leather", "title": "Autotuning OpenCL Workgroup Size for Stencil Patterns", "comments": "8 pages, 6 figures, presented at the 6th International Workshop on\n  Adaptive Self-tuning Computing Systems (ADAPT '16)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Selecting an appropriate workgroup size is critical for the performance of\nOpenCL kernels, and requires knowledge of the underlying hardware, the data\nbeing operated on, and the implementation of the kernel. This makes portable\nperformance of OpenCL programs a challenging goal, since simple heuristics and\nstatically chosen values fail to exploit the available performance. To address\nthis, we propose the use of machine learning-enabled autotuning to\nautomatically predict workgroup sizes for stencil patterns on CPUs and\nmulti-GPUs.\n  We present three methodologies for predicting workgroup sizes. The first,\nusing classifiers to select the optimal workgroup size. The second and third\nproposed methodologies employ the novel use of regressors for performing\nclassification by predicting the runtime of kernels and the relative\nperformance of different workgroup sizes, respectively. We evaluate the\neffectiveness of each technique in an empirical study of 429 combinations of\narchitecture, kernel, and dataset, comparing an average of 629 different\nworkgroup sizes for each. We find that autotuning provides a median 3.79x\nspeedup over the best possible fixed workgroup size, achieving 94% of the\nmaximum performance.\n", "versions": [{"version": "v1", "created": "Sun, 8 Nov 2015 14:56:12 GMT"}, {"version": "v2", "created": "Sun, 22 Nov 2015 23:22:04 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2016 15:50:33 GMT"}], "update_date": "2016-01-07", "authors_parsed": [["Cummins", "Chris", ""], ["Petoumenos", "Pavlos", ""], ["Steuwer", "Michel", ""], ["Leather", "Hugh", ""]]}, {"id": "1511.02548", "submitter": "Mohammadhadi Amini", "authors": "M. Hadi Amini, R. Jaddivada, S. Mishra, O. Karabasoglu", "title": "Distributed Security Constrained Economic Dispatch", "comments": "6 pages, 8 figures, IEEE Innovative Smart Grid Technologies\n  Conference", "journal-ref": null, "doi": "10.1109/ISGT-Asia.2015.7387167", "report-no": null, "categories": "cs.SY cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we investigate two decomposition methods for their convergence\nrate which are used to solve security constrained economic dispatch (SCED): 1)\nLagrangian Relaxation (LR), and 2) Augmented Lagrangian Relaxation (ALR).\nFirst, the centralized SCED problem is posed for a 6-bus test network and then\nit is decomposed into subproblems using both of the methods. In order to model\nthe tie-line between decomposed areas of the test network, a novel method is\nproposed. The advantages and drawbacks of each method are discussed in terms of\naccuracy and information privacy. We show that there is a tradeoff between the\ninformation privacy and the convergence rate. It has been found that ALR\nconverges faster compared to LR, due to the large amount of shared data.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 01:28:55 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Amini", "M. Hadi", ""], ["Jaddivada", "R.", ""], ["Mishra", "S.", ""], ["Karabasoglu", "O.", ""]]}, {"id": "1511.02586", "submitter": "Cong Xie", "authors": "Cong Xie, Wu-Jun Li and Zhihua Zhang", "title": "S-PowerGraph: Streaming Graph Partitioning for Natural Graphs by\n  Vertex-Cut", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  One standard solution for analyzing large natural graphs is to adopt\ndistributed computation on clusters. In distributed computation, graph\npartitioning (GP) methods assign the vertices or edges of a graph to different\nmachines in a balanced way so that some distributed algorithms can be adapted\nfor. Most of traditional GP methods are offline, which means that the whole\ngraph has been observed before partitioning. However, the offline methods often\nincur high computation cost. Hence, streaming graph partitioning (SGP) methods,\nwhich can partition graphs in an online way, have recently attracted great\nattention in distributed computation. There exist two typical GP strategies:\nedge-cut and vertex-cut. Most SGP methods adopt edge-cut, but few vertex-cut\nmethods have been proposed for SGP. However, the vertex-cut strategy would be a\nbetter choice than the edge-cut strategy because the degree of a natural graph\nin general follows a highly skewed power-law distribution. Thus, we propose a\nnovel method, called S-PowerGraph, for SGP of natural graphs by vertex-cut. Our\nS-PowerGraph method is simple but effective. Experiments on several large\nnatural graphs and synthetic graphs show that our S-PowerGraph can outperform\nthe state-of-the-art baselines.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 07:28:33 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Xie", "Cong", ""], ["Li", "Wu-Jun", ""], ["Zhang", "Zhihua", ""]]}, {"id": "1511.02689", "submitter": "Sandra Gesing", "authors": "Sandra Gesing, Thomas Richard Connor and Ian Taylor", "title": "Genomics and Biological Big Data: Facing Current and Future Challenges\n  around Data and Software Sharing and Reproducibility", "comments": "Position paper at BDAC-15 (Big Data Analytics: Challenges and\n  Opportunities), workshop in cooperation with ACM/IEEE SC15, November 16,\n  2015, Austin, TX, USA", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.CY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Novel technologies in genomics allow creating data in exascale dimension with\nrelatively minor effort of human and laboratory and thus monetary resources\ncompared to capabilities only a decade ago. While the availability of this data\nsalvage to find answers for research questions, which would not have been\nfeasible before, maybe even not feasible to ask before, the amount of data\ncreates new challenges, which obviously need new software and data management\nsystems. Such new solutions have to consider integrative approaches, which are\nnot only considering the effectiveness and efficiency of data processing but\nimprove reusability, reproducibility and usability especially tailored to the\ntarget user communities of genomic big data. In our opinion, current solutions\ntackle part of the challenges and have each their strengths but lack to provide\na complete solution. We present in this paper the key challenges and the\ncharacteristics cutting-edge developments should possess for fulfilling the\nneeds of the user communities to allow for seamless sharing and data analysis\non a large scale.\n", "versions": [{"version": "v1", "created": "Mon, 9 Nov 2015 14:17:13 GMT"}], "update_date": "2015-11-10", "authors_parsed": [["Gesing", "Sandra", ""], ["Connor", "Thomas Richard", ""], ["Taylor", "Ian", ""]]}, {"id": "1511.02942", "submitter": "Jinshan Zeng", "authors": "Jinshan Zeng and Wotao Yin", "title": "ExtraPush for convex smooth decentralized optimization over directed\n  networks", "comments": "16 pages, 3 figures", "journal-ref": "Journal of Computational Mathematics, 2017", "doi": "10.4208/jcm.1606-m2015-0452", "report-no": null, "categories": "math.OC cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this note, we extend the algorithms Extra and subgradient-push to a new\nalgorithm ExtraPush for consensus optimization with convex differentiable\nobjective functions over a directed network. When the stationary distribution\nof the network can be computed in advance}, we propose a simplified algorithm\ncalled Normalized ExtraPush. Just like Extra, both ExtraPush and Normalized\nExtraPush can iterate with a fixed step size. But unlike Extra, they can take a\ncolumn-stochastic mixing matrix, which is not necessarily doubly stochastic.\nTherefore, they remove the undirected-network restriction of Extra.\nSubgradient-push, while also works for directed networks, is slower on the same\ntype of problem because it must use a sequence of diminishing step sizes.\n  We present preliminary analysis for ExtraPush under a bounded sequence\nassumption. For Normalized ExtraPush, we show that it naturally produces a\nbounded, linearly convergent sequence provided that the objective function is\nstrongly convex.\n  In our numerical experiments, ExtraPush and Normalized ExtraPush performed\nsimilarly well. They are significantly faster than subgradient-push, even when\nwe hand-optimize the step sizes for the latter.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 00:17:24 GMT"}, {"version": "v2", "created": "Sat, 28 Nov 2015 23:56:49 GMT"}, {"version": "v3", "created": "Tue, 13 Sep 2016 12:05:54 GMT"}, {"version": "v4", "created": "Wed, 30 Jan 2019 02:21:09 GMT"}], "update_date": "2019-01-31", "authors_parsed": [["Zeng", "Jinshan", ""], ["Yin", "Wotao", ""]]}, {"id": "1511.02960", "submitter": "Rui Han", "authors": "Rui Han, Junwei Wang, Siguang Huang, Chenrong Shao, Shulin Zhan,\n  Jianfeng Zhan, Jose Luis Vazquez-Poletti", "title": "PCS: Predictive Component-level Scheduling for Reducing Tail Latency in\n  Cloud Online Services", "comments": "10 pages, 9 figures, ICPP conference", "journal-ref": null, "doi": "10.1109/ICPP.2015.58", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern latency-critical online services often rely on composing results from\na large number of server components. Hence the tail latency (e.g. the 99th\npercentile of response time), rather than the average, of these components\ndetermines the overall service performance. When hosted on a cloud environment,\nthe components of a service typically co-locate with short batch jobs to\nincrease machine utilizations, and share and contend resources such as caches\nand I/O bandwidths with them. The highly dynamic nature of batch jobs in terms\nof their workload types and input sizes causes continuously changing\nperformance interference to individual components, hence leading to their\nlatency variability and high tail latency. However, existing techniques either\nignore such fine-grained component latency variability when managing service\nperformance, or rely on executing redundant requests to reduce the tail\nlatency, which adversely deteriorate the service performance when load gets\nheavier. In this paper, we propose PCS, a predictive and component-level\nscheduling framework to reduce tail latency for large-scale, parallel online\nservices. It uses an analytical performance model to simultaneously predict the\ncomponent latency and the overall service performance on different nodes. Based\non the predicted performance, the scheduler identifies straggling components\nand conducts near-optimal component-node allocations to adapt to the changing\nperformance interferences from batch jobs. We demonstrate that, using realistic\nworkloads, the proposed scheduler reduces the component tail latency by an\naverage of 67.05\\% and the average overall service latency by 64.16\\% compared\nwith the state-of-the-art techniques on reducing tail latency.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 01:44:44 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Han", "Rui", ""], ["Wang", "Junwei", ""], ["Huang", "Siguang", ""], ["Shao", "Chenrong", ""], ["Zhan", "Shulin", ""], ["Zhan", "Jianfeng", ""], ["Vazquez-Poletti", "Jose Luis", ""]]}, {"id": "1511.03202", "submitter": "Sarmistha Neogy Dr.", "authors": "Sarmistha Neogy", "title": "Checkpointing with Minimal Recover in Adhocnet based TMR", "comments": "International Journal of UbiComp (IJU), Vol.6, No.4, October 2015", "journal-ref": null, "doi": "10.5121/iju.2015.6403", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper describes two-fold approach towards utilizing Triple Modular\nRedundancy (TMR) in Wireless Adhoc Network (AdocNet). A distributed\ncheckpointing and recovery protocol is proposed. The protocol eliminates\nuseless checkpoints and helps in selecting only dependent processes in the\nconcerned checkpointing interval, to recover. A process starts recovery from\nits last checkpoint only if it finds that it is dependent (directly or\nindirectly) on the faulty process. The recovery protocol also prevents the\noccurrence of missing or orphan messages. In AdocNet, a set of three nodes\n(connected to each other) is considered to form a TMR set, being designated as\nmain, primary and secondary. A main node in one set may serve as primary or\nsecondary in another. Computation is not triplicated, but checkpoint by main is\nduplicated in its primary so that primary can continue if main fails.\nCheckpoint by primary is then duplicated in secondary if primary fails too.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 17:57:14 GMT"}], "update_date": "2015-11-11", "authors_parsed": [["Neogy", "Sarmistha", ""]]}, {"id": "1511.03404", "submitter": "Toma\\v{z} Dobravec", "authors": "Darko Bozidar and Tomaz Dobravec", "title": "Comparison of parallel sorting algorithms", "comments": "Technical report", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In our study we implemented and compared seven sequential and parallel\nsorting algorithms: bitonic sort, multistep bitonic sort, adaptive bitonic\nsort, merge sort, quicksort, radix sort and sample sort. Sequential algorithms\nwere implemented on a central processing unit using C++, whereas parallel\nalgorithms were implemented on a graphics processing unit using CUDA platform.\nWe chose these algorithms because to the best of our knowledge their sequential\nand parallel implementations were not yet compared all together in the same\nexecution environment. We improved the above mentioned implementations and\nadopted them to be able to sort input sequences of arbitrary length. We\ncompared algorithms on six different input distributions, which consisted of\n32-bit numbers, 32-bit key-value pairs, 64-bit numbers and 64-bit key-value\npairs. In this report we give a short description of seven sorting algorithms\nand all the results obtained by our tests.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 07:31:43 GMT"}, {"version": "v2", "created": "Thu, 12 Nov 2015 07:48:37 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Bozidar", "Darko", ""], ["Dobravec", "Tomaz", ""]]}, {"id": "1511.03524", "submitter": "Buddhadeb Sau", "authors": "B. Sau and S. Mukhopadhyaya and K. Mukhopadhyaya", "title": "MAINT: Localization of Mobile Sensors with Energy Control", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Localization is an important issue for Wireless Sensor Networks (WSN). A\nmobile sensor may change its position rapidly and thus require localization\ncalls frequently. A localization may require network wide information and\nincrease traffic over the network. It dissipates valuable energy for message\ncommunication. Thus localization is very costly. The control of the number of\nlocalization calls may save energy consumption, as it is rather expensive. To\nreduce the frequency of localization calls for a mobile sensor, we propose a\ntechnique that involves \\textit{Mobility Aware Interpolation} (MAINT) for\nposition estimation. It controls the number of localizations which gives much\nbetter result than the existing localization control schemes using mobility\naware extrapolation. The proposed method involves very low arithmetic\ncomputation overheads. We find analytical expressions for the expected error in\nposition estimation. A parameter, the time interval, has been introduced to\nexternally control the energy dissipation. Simulation studies are carried out\nto compare the performances of the proposed method with some existing\nlocalization control schemes as well as the theoretical results. The simulation\nresults shows that the expected error at any point of time may be computed from\nthis expression. We have seen that constant error limit can be maintained\nincreasing the time period of localization proportional to rate of change of\ndirection of its motion. Increasing time period, the energy may be saved with a\nstable error limit.\n", "versions": [{"version": "v1", "created": "Tue, 10 Nov 2015 07:22:10 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Sau", "B.", ""], ["Mukhopadhyaya", "S.", ""], ["Mukhopadhyaya", "K.", ""]]}, {"id": "1511.03599", "submitter": "Karel Ad\\'amek", "authors": "Karel Ad\\'amek, Jan Novotn\\'y and Wes Armour", "title": "A polyphase filter for many-core architectures", "comments": "19 pages, 20 figures, 5 tables", "journal-ref": null, "doi": "10.1016/j.ascom.2016.03.003", "report-no": null, "categories": "astro-ph.IM cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article we discuss our implementation of a polyphase filter for\nreal-time data processing in radio astronomy. We describe in detail our\nimplementation of the polyphase filter algorithm and its behaviour on three\ngenerations of NVIDIA GPU cards, on dual Intel Xeon CPUs and the Intel Xeon Phi\n(Knights Corner) platforms. All of our implementations aim to exploit the\npotential for data reuse that the algorithm offers. Our GPU implementations\nexplore two different methods for achieving this, the first makes use of\nL1/Texture cache, the second uses shared memory. We discuss the usability of\neach of our implementations along with their behaviours. We measure performance\nin execution time, which is a critical factor for real-time systems, we also\npresent results in terms of bandwidth (GB/s), compute (GFlop/s) and type\nconversions (GTc/s). We include a presentation of our results in terms of the\nsample rate which can be processed in real-time by a chosen platform, which\nmore intuitively describes the expected performance in a signal processing\nsetting. Our findings show that, for the GPUs considered, the performance of\nour polyphase filter when using lower precision input data is limited by type\nconversions rather than device bandwidth. We compare these results to an\nimplementation on the Xeon Phi. We show that our Xeon Phi implementation has a\nperformance that is 1.47x to 1.95x greater than our CPU implementation, however\nis not insufficient to compete with the performance of GPUs. We conclude with a\ncomparison of our best performing code to two other implementations of the\npolyphase filter, showing that our implementation is faster in nearly all\ncases. This work forms part of the Astro-Accelerate project, a many-core\naccelerated real-time data processing library for digital signal processing of\ntime-domain radio astronomy data.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 18:43:48 GMT"}, {"version": "v2", "created": "Tue, 19 Apr 2016 13:22:16 GMT"}, {"version": "v3", "created": "Thu, 21 Apr 2016 06:31:57 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Ad\u00e1mek", "Karel", ""], ["Novotn\u00fd", "Jan", ""], ["Armour", "Wes", ""]]}, {"id": "1511.03609", "submitter": "Andrei Costin", "authors": "Andrei Costin and Apostolis Zarras and Aur\\'elien Francillon", "title": "Automated Dynamic Firmware Analysis at Scale: A Case Study on Embedded\n  Web Interfaces", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Embedded devices are becoming more widespread, interconnected, and\nweb-enabled than ever. However, recent studies showed that these devices are\nfar from being secure. Moreover, many embedded systems rely on web interfaces\nfor user interaction or administration. Unfortunately, web security is known to\nbe difficult, and therefore the web interfaces of embedded systems represent a\nconsiderable attack surface.\n  In this paper, we present the first fully automated framework that applies\ndynamic firmware analysis techniques to achieve, in a scalable manner,\nautomated vulnerability discovery within embedded firmware images. We apply our\nframework to study the security of embedded web interfaces running in\nCommercial Off-The-Shelf (COTS) embedded devices, such as routers, DSL/cable\nmodems, VoIP phones, IP/CCTV cameras. We introduce a methodology and implement\na scalable framework for discovery of vulnerabilities in embedded web\ninterfaces regardless of the vendor, device, or architecture. To achieve this\ngoal, our framework performs full system emulation to achieve the execution of\nfirmware images in a software-only environment, i.e., without involving any\nphysical embedded devices. Then, we analyze the web interfaces within the\nfirmware using both static and dynamic tools. We also present some interesting\ncase-studies, and discuss the main challenges associated with the dynamic\nanalysis of firmware images and their web interfaces and network services. The\nobservations we make in this paper shed light on an important aspect of\nembedded devices which was not previously studied at a large scale.\n  We validate our framework by testing it on 1925 firmware images from 54\ndifferent vendors. We discover important vulnerabilities in 185 firmware\nimages, affecting nearly a quarter of vendors in our dataset. These\nexperimental results demonstrate the effectiveness of our approach.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 19:17:38 GMT"}], "update_date": "2015-11-12", "authors_parsed": [["Costin", "Andrei", ""], ["Zarras", "Apostolis", ""], ["Francillon", "Aur\u00e9lien", ""]]}, {"id": "1511.03639", "submitter": "Johannes Hofmann", "authors": "Johannes Hofmann, Dietmar Fey, Jan Eitzinger, Georg Hager, Gerhard\n  Wellein", "title": "Analysis of Intel's Haswell Microarchitecture Using The ECM Model and\n  Microbenchmarks", "comments": "arXiv admin note: substantial text overlap with arXiv:1509.03118", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.AR", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an in-depth analysis of Intel's Haswell microarchitecture\nfor streaming loop kernels. Among the new features examined is the dual-ring\nUncore design, Cluster-on-Die mode, Uncore Frequency Scaling, core improvements\nas new and improved execution units, as well as improvements throughout the\nmemory hierarchy. The Execution-Cache-Memory diagnostic performance model is\nused together with a generic set of microbenchmarks to quantify the efficiency\nof the microarchitecture. The set of microbenchmarks is chosen such that it can\nserve as a blueprint for other streaming loop kernels.\n", "versions": [{"version": "v1", "created": "Wed, 11 Nov 2015 20:20:03 GMT"}, {"version": "v2", "created": "Fri, 13 Nov 2015 12:43:22 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Hofmann", "Johannes", ""], ["Fey", "Dietmar", ""], ["Eitzinger", "Jan", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1511.03885", "submitter": "Karthee Sivalingam", "authors": "Karthee Sivalingam and Grenville Lister and Bryan Lawrence", "title": "Performance analysis and Optimisation of the Met Unified Model on a Cray\n  XC30", "comments": "16 pages, 9 figures, 7 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.comp-ph cs.DC physics.ao-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Unified Model (UM) code supports simulation of weather, climate and earth\nsystem processes. It is primarily developed by the UK Met Office, but in recent\nyears a wider community of users and developers have grown around the code.\nHere we present results from the optimisation work carried out by the UK\nNational Centre for Atmospheric Science (NCAS) for a high resolution\nconfiguration (N512 $\\approx$ 25km) on the UK ARCHER supercomputer, a Cray\nXC-30. On ARCHER, we use Cray Performance Analysis Tools (CrayPAT) to analyse\nthe performance of UM and then Cray Reveal to identify and parallelise serial\nloops using OpenMP directives. We compare performance of the optimised version\nat a range of scales, and with a range of optimisations, including altered MPI\nrank placement, and addition of OpenMP directives. It is seen that improvements\nin MPI configuration yield performance improvements of between 5 and 12\\%, and\nthe added OpenMP directives yield an additional 5-16\\% speedup. We also\nidentify further code optimisations which could yield yet greater improvement\nin performance. We note that speedup gained using addition of OpenMP directives\ndoes not result in improved performance on the IBM Power platform where much of\nthe code has been developed. This suggests that performance gains on future\nheterogeneous architectures will be hard to port. Nonetheless, it is clear that\nthe investment of months in analysis and optimisation has yielded performance\ngains that correspond to the saving of tens of millions of core-hours on\ncurrent climate projects.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 13:20:57 GMT"}], "update_date": "2015-11-13", "authors_parsed": [["Sivalingam", "Karthee", ""], ["Lister", "Grenville", ""], ["Lawrence", "Bryan", ""]]}, {"id": "1511.03927", "submitter": "Emanuele Natale", "authors": "Luca Becchetti, Andrea Clementi, Emanuele Natale, Francesco Pasquale,\n  Luca Trevisan", "title": "Find Your Place: Simple Distributed Algorithms for Community Detection", "comments": "33 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Given an underlying graph, we consider the following \\emph{dynamics}:\nInitially, each node locally chooses a value in $\\{-1,1\\}$, uniformly at random\nand independently of other nodes. Then, in each consecutive round, every node\nupdates its local value to the average of the values held by its neighbors, at\nthe same time applying an elementary, local clustering rule that only depends\non the current and the previous values held by the node.\n  We prove that the process resulting from this dynamics produces a clustering\nthat exactly or approximately (depending on the graph) reflects the underlying\ncut in logarithmic time, under various graph models that exhibit a sparse\nbalanced cut, including the stochastic block model. We also prove that a\nnatural extension of this dynamics performs community detection on a\nregularized version of the stochastic block model with multiple communities.\n  Rather surprisingly, our results provide rigorous evidence for the ability of\nan extremely simple and natural dynamics to address a computational problem\nthat is non-trivial even in a centralized setting.\n", "versions": [{"version": "v1", "created": "Thu, 12 Nov 2015 15:30:00 GMT"}, {"version": "v2", "created": "Tue, 16 Feb 2016 10:04:27 GMT"}, {"version": "v3", "created": "Fri, 8 Apr 2016 07:29:04 GMT"}, {"version": "v4", "created": "Sat, 23 Jul 2016 22:26:26 GMT"}], "update_date": "2016-07-26", "authors_parsed": [["Becchetti", "Luca", ""], ["Clementi", "Andrea", ""], ["Natale", "Emanuele", ""], ["Pasquale", "Francesco", ""], ["Trevisan", "Luca", ""]]}, {"id": "1511.04203", "submitter": "Markus Rampp", "authors": "Markus Rampp (MPCDF), Roland Preuss (IPP), Rainer Fischer (IPP) and\n  the ASDEX Upgrade Team (IPP)", "title": "GPEC, a real-time capable Tokamak equilibrium code", "comments": "minor typos corrected and reference updated, matches published\n  version", "journal-ref": "Fusion Science and Technology 70(1), 2016, 1-13", "doi": "10.13182/FST15-154", "report-no": null, "categories": "physics.plasm-ph cs.CE cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new parallel equilibrium reconstruction code for tokamak plasmas is\npresented. GPEC allows to compute equilibrium flux distributions sufficiently\naccurate to derive parameters for plasma control within 1 ms of runtime which\nenables real-time applications at the ASDEX Upgrade experiment (AUG) and other\nmachines with a control cycle of at least this size. The underlying algorithms\nare based on the well-established offline-analysis code CLISTE, following the\nclassical concept of iteratively solving the Grad-Shafranov equation and\nfeeding in diagnostic signals from the experiment. The new code adopts a hybrid\nparallelization scheme for computing the equilibrium flux distribution and\nextends the fast, shared-memory-parallel Poisson solver which we have described\npreviously by a distributed computation of the individual Poisson problems\ncorresponding to different basis functions. The code is based entirely on\nopen-source software components and runs on standard server hardware and\nsoftware environments. The real-time capability of GPEC is demonstrated by\nperforming an offline-computation of a sequence of 1000 flux distributions\nwhich are taken from one second of operation of a typical AUG discharge and\nderiving the relevant control parameters with a time resolution of a\nmillisecond. On current server hardware the new code allows employing a grid\nsize of 32x64 zones for the spatial discretization and up to 15 basis\nfunctions. It takes into account about 90 diagnostic signals while using up to\n4 equilibrium iterations and computing more than 20 plasma-control parameters,\nincluding the computationally expensive safety-factor q on at least 4 different\nlevels of the normalized flux.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 08:55:42 GMT"}, {"version": "v2", "created": "Wed, 25 May 2016 13:01:34 GMT"}], "update_date": "2016-07-08", "authors_parsed": [["Rampp", "Markus", "", "MPCDF"], ["Preuss", "Roland", "", "IPP"], ["Fischer", "Rainer", "", "IPP"], ["Team", "the ASDEX Upgrade", "", "IPP"]]}, {"id": "1511.04217", "submitter": "Sascha Hunold", "authors": "Sascha Hunold", "title": "A Survey on Reproducibility in Parallel Computing", "comments": "15 pages, 24 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We summarize the results of a survey on reproducibility in parallel\ncomputing, which was conducted during the Euro-Par conference in August 2015.\nThe survey form was handed out to all participants of the conference and the\nworkshops. The questionnaire, which specifically targeted the parallel\ncomputing community, contained questions in four different categories: general\nquestions on reproducibility, the current state of reproducibility, the\nreproducibility of the participants' own papers, and questions about the\nparticipants' familiarity with tools, software, or open-source software\nlicenses used for reproducible research.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 09:57:22 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Hunold", "Sascha", ""]]}, {"id": "1511.04348", "submitter": "Linnan Wang", "authors": "Linnan Wang, Wei Wu, Jianxiong Xiao, Yang Yi", "title": "Large Scale Artificial Neural Network Training Using Multi-GPUs", "comments": "SC 15 Poster", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes a method for accelerating large scale Artificial Neural\nNetworks (ANN) training using multi-GPUs by reducing the forward and backward\npasses to matrix multiplication. We propose an out-of-core multi-GPU matrix\nmultiplication and integrate the algorithm with the ANN training. The\nexperiments demonstrate that our matrix multiplication algorithm achieves\nlinear speedup on multiple inhomogeneous GPUs. The full paper of this project\ncan be found at [1].\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 16:36:05 GMT"}], "update_date": "2015-11-16", "authors_parsed": [["Wang", "Linnan", ""], ["Wu", "Wei", ""], ["Xiao", "Jianxiong", ""], ["Yi", "Yang", ""]]}, {"id": "1511.04428", "submitter": "Reza Arablouei", "authors": "Reza Arablouei, Kutluy{\\i}l Do\\u{g}an\\c{c}ay, Stefan Werner, and\n  Yih-Fang Huang", "title": "On the Asymptotic Bias of the Diffusion-Based Distributed Pareto\n  Optimization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.GT cs.SY math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the asymptotic bias analysis of the distributed Pareto\noptimization algorithm developed based on the diffusion strategies. We propose\nan alternative way to analyze the asymptotic bias of this algorithm at small\nstep-sizes and show that the asymptotic bias descends to zero with a linear\ndependence on the largest step-size parameter when this parameter is\nsufficiently small. In addition, through the proposed analytic approach, we\nprovide an expression for the small-step-size asymptotic bias when a condition\nassumed jointly on the combination matrices and the step-sizes does not\nstrictly hold. This is a likely scenario in practice, which has not been\nconsidered in the original paper that introduced the algorithm. Our methodology\nprovides new insights into the inner workings of the diffusion Pareto\noptimization algorithm while being considerably less involved than the\nsmall-step-size asymptotic bias analysis presented in the original work. This\nis because we take advantage of the special eigenstructure of the composite\ncombination matrix used in the algorithm without calling for any eigenspace\ndecomposition or matrix inversion.\n", "versions": [{"version": "v1", "created": "Fri, 13 Nov 2015 20:37:59 GMT"}, {"version": "v2", "created": "Fri, 15 Jan 2016 01:43:48 GMT"}, {"version": "v3", "created": "Sat, 4 Jun 2016 08:41:19 GMT"}], "update_date": "2016-06-07", "authors_parsed": [["Arablouei", "Reza", ""], ["Do\u011fan\u00e7ay", "Kutluy\u0131l", ""], ["Werner", "Stefan", ""], ["Huang", "Yih-Fang", ""]]}, {"id": "1511.04519", "submitter": "Hao Zhuang", "authors": "Hao Zhuang, Shih-Hung Weng, Jeng-Hau Lin, Chung-Kuan Cheng", "title": "MATEX: A Distributed Framework for Transient Simulation of Power\n  Distribution Networks", "comments": "ACM/IEEE DAC 2014. arXiv admin note: substantial text overlap with\n  arXiv:1505.06699", "journal-ref": null, "doi": "10.1145/2593069.2593160", "report-no": null, "categories": "cs.CE cs.DC cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We proposed MATEX, a distributed framework for transient simulation of power\ndistribution networks (PDNs). MATEX utilizes matrix exponential kernel with\nKrylov subspace approximations to solve differential equations of linear\ncircuit. First, the whole simulation task is divided into subtasks based on\ndecompositions of current sources, in order to reduce the computational\noverheads. Then these subtasks are distributed to different computing nodes and\nprocessed in parallel. Within each node, after the matrix factorization at the\nbeginning of simulation, the adaptive time stepping solver is performed without\nextra matrix re-factorizations. MATEX overcomes the stiff-ness hinder of\nprevious matrix exponential-based circuit simulator by rational Krylov subspace\nmethod, which leads to larger step sizes with smaller dimensions of Krylov\nsubspace bases and highly accelerates the whole computation. MATEX outperforms\nboth traditional fixed and adaptive time stepping methods, e.g., achieving\naround 13X over the trapezoidal framework with fixed time step for the IBM\npower grid benchmarks.\n", "versions": [{"version": "v1", "created": "Sat, 14 Nov 2015 06:29:51 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Zhuang", "Hao", ""], ["Weng", "Shih-Hung", ""], ["Lin", "Jeng-Hau", ""], ["Cheng", "Chung-Kuan", ""]]}, {"id": "1511.04651", "submitter": "Rui Han", "authors": "Rui Han", "title": "Investigations into Elasticity in Cloud Computing", "comments": "211 pages, 27 tables, 75 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The pay-as-you-go model supported by existing cloud infrastructure providers\nis appealing to most application service providers to deliver their\napplications in the cloud. Within this context, elasticity of applications has\nbecome one of the most important features in cloud computing. This elasticity\nenables real-time acquisition/release of compute resources to meet application\nperformance demands. In this thesis we investigate the problem of delivering\ncost-effective elasticity services for cloud applications.\n  Traditionally, the application level elasticity addresses the question of how\nto scale applications up and down to meet their performance requirements, but\ndoes not adequately address issues relating to minimising the costs of using\nthe service. With this current limitation in mind, we propose a scaling\napproach that makes use of cost-aware criteria to detect the bottlenecks within\nmulti-tier cloud applications, and scale these applications only at bottleneck\ntiers to reduce the costs incurred by consuming cloud infrastructure resources.\nOur approach is generic for a wide class of multi-tier applications, and we\ndemonstrate its effectiveness by studying the behaviour of an example\nelectronic commerce site application.\n  Furthermore, we consider the characteristics of the algorithm for\nimplementing the business logic of cloud applications, and investigate the\nelasticity at the algorithm level: when dealing with large-scale data under\nresource and time constraints, the algorithm's output should be elastic with\nrespect to the resource consumed. We propose a novel framework to guide the\ndevelopment of elastic algorithms that adapt to the available budget while\nguaranteeing the quality of output result, e.g. prediction accuracy for\nclassification tasks, improves monotonically with the used budget.\n", "versions": [{"version": "v1", "created": "Sun, 15 Nov 2015 03:38:55 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Han", "Rui", ""]]}, {"id": "1511.04861", "submitter": "Hyoung-Joo Kim", "authors": "Woo-Hyun Lee, Hee-Gook Jun, Hyoung-Joo Kim", "title": "Hadoop Mapreduce Performance Enhancement Using In-node Combiners", "comments": "International Journal of Computer Science & Information Technology,\n  2015", "journal-ref": null, "doi": "10.5121/ijcsit.2015.7501", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  While advanced analysis of large dataset is in high demand, data sizes have\nsurpassed capabilities of conventional software and hardware. Hadoop framework\ndistributes large datasets over multiple commodity servers and performs\nparallel computations. We discuss the I/O bottlenecks of Hadoop framework and\npropose methods for enhancing I/O performance. A proven approach is to cache\ndata to maximize memory-locality of all map tasks. We introduce an approach to\noptimize I/O, the in-node combining design which extends the traditional\ncombiner to a node level. The in-node combiner reduces the total number of\nintermediate results and curtail network traffic between mappers and reducers.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 08:27:58 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Lee", "Woo-Hyun", ""], ["Jun", "Hee-Gook", ""], ["Kim", "Hyoung-Joo", ""]]}, {"id": "1511.04985", "submitter": "Robert Soul\\'e", "authors": "Huynh Tu Dang, Marco Canini, Fernando Pedone, Robert Soul\\'e", "title": "Paxos Made Switch-y", "comments": null, "journal-ref": null, "doi": null, "report-no": "USI-INF-TR-2015-05", "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper describes an implementation of the well-known consensus protocol,\nPaxos, in the P4 programming language. P4 is a language for programming the\nbehavior of network forwarding devices (i.e., the network data plane). Moving\nconsensus logic into network devices could significantly improve the\nperformance of the core infrastructure and services in data centers. Moreover,\nimplementing Paxos in P4 provides a critical use case and set of requirements\nfor data plane language designers. In the long term, we imagine that consensus\ncould someday be offered as a network service, just as point-to-point\ncommunication is provided today.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 15:14:12 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Dang", "Huynh Tu", ""], ["Canini", "Marco", ""], ["Pedone", "Fernando", ""], ["Soul\u00e9", "Robert", ""]]}, {"id": "1511.05010", "submitter": "Carlos Baquero", "authors": "Marek Zawirski, Carlos Baquero, Annette Bieniusa, Nuno Pregui\\c{c}a,\n  Marc Shapiro", "title": "Eventually Consistent Register Revisited", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In order to converge in the presence of concurrent updates, modern eventually\nconsistent replication systems rely on causality information and operation\nsemantics. It is relatively easy to use semantics of high-level operations on\nreplicated data structures, such as sets, lists, etc. However, it is difficult\nto exploit semantics of operations on registers, which store opaque data. In\nexisting register designs, concurrent writes are resolved either by the\napplication, or by arbitrating them according to their timestamps. The former\nis complex and may require user intervention, whereas the latter causes\narbitrary updates to be lost. In this work, we identify a register construction\nthat generalizes existing ones by combining runtime causality ordering, to\nidentify concurrent writes, with static data semantics, to resolve them. We\npropose a simple conflict resolution template based on an\napplication-predefined order on the domain of values. It eliminates or reduces\nthe number of conflicts that need to be resolved by the user or by an explicit\napplication logic. We illustrate some variants of our approach with use cases,\nand how it generalizes existing designs.\n", "versions": [{"version": "v1", "created": "Mon, 16 Nov 2015 15:59:10 GMT"}], "update_date": "2015-11-17", "authors_parsed": [["Zawirski", "Marek", ""], ["Baquero", "Carlos", ""], ["Bieniusa", "Annette", ""], ["Pregui\u00e7a", "Nuno", ""], ["Shapiro", "Marc", ""]]}, {"id": "1511.05464", "submitter": "Joseph  Salmon", "authors": "Igor Colin and Aur\\'elien Bellet and Joseph Salmon and St\\'ephan\n  Cl\\'emen\\c{c}on", "title": "Extending Gossip Algorithms to Distributed Estimation of U-Statistics", "comments": "to be presented at NIPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.SY stat.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Efficient and robust algorithms for decentralized estimation in networks are\nessential to many distributed systems. Whereas distributed estimation of sample\nmean statistics has been the subject of a good deal of attention, computation\nof $U$-statistics, relying on more expensive averaging over pairs of\nobservations, is a less investigated area. Yet, such data functionals are\nessential to describe global properties of a statistical population, with\nimportant examples including Area Under the Curve, empirical variance, Gini\nmean difference and within-cluster point scatter. This paper proposes new\nsynchronous and asynchronous randomized gossip algorithms which simultaneously\npropagate data across the network and maintain local estimates of the\n$U$-statistic of interest. We establish convergence rate bounds of $O(1/t)$ and\n$O(\\log t / t)$ for the synchronous and asynchronous cases respectively, where\n$t$ is the number of iterations, with explicit data and network dependent\nterms. Beyond favorable comparisons in terms of rate analysis, numerical\nexperiments provide empirical evidence the proposed algorithms surpasses the\npreviously introduced approach.\n", "versions": [{"version": "v1", "created": "Tue, 17 Nov 2015 16:49:52 GMT"}], "update_date": "2019-01-25", "authors_parsed": [["Colin", "Igor", ""], ["Bellet", "Aur\u00e9lien", ""], ["Salmon", "Joseph", ""], ["Cl\u00e9men\u00e7on", "St\u00e9phan", ""]]}, {"id": "1511.05771", "submitter": "Roberto Rigamonti", "authors": "Baptiste Delporte and Roberto Rigamonti and Alberto Dassatti", "title": "Toward Transparent Heterogeneous Systems", "comments": "12 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Heterogeneous parallel systems are widely spread nowadays. Despite their\navailability, their usage and adoption are still limited, and even more rarely\nthey are used to full power. Indeed, compelling new technologies are constantly\ndeveloped and keep changing the technological landscape, but each of them\ntargets a limited sub-set of supported devices, and nearly all of them require\nnew programming paradigms and specific toolsets. Software, however, can hardly\nkeep the pace with the growing number of computational capabilities, and\ndevelopers are less and less motivated in learning skills that could quickly\nbecome obsolete. In this paper we present our effort in the direction of a\ntransparent system optimization based on automatic code profiling and\nJust-In-Time compilation, that resulted in a fully-working embedded prototype\ncapable of dynamically detect computing-intensive code blocks and automatically\ndispatch them to different computation units. Experimental results show that\nour system allows gains up to 32x in performance --- after an initial warm-up\nphase --- without requiring any human intervention.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 13:37:18 GMT"}, {"version": "v2", "created": "Fri, 20 Nov 2015 14:15:41 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Delporte", "Baptiste", ""], ["Rigamonti", "Roberto", ""], ["Dassatti", "Alberto", ""]]}, {"id": "1511.05778", "submitter": "Herv\\'e Paulino", "authors": "Herv\\'e Paulino, Nuno Delgado", "title": "Cache-Conscious Run-time Decomposition of Data Parallel Computations", "comments": "24 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-core architectures feature an intricate hierarchy of cache memories,\nwith multiple levels and sizes. To adequately decompose an application\naccording to the traits of a particular memory hierarchy is a cumbersome task\nthat may be rewarded with significant performance gains. The current\nstate-of-the-art in memory-hierarchy-aware parallel computing delegates this\nendeavour on the programmer, demanding from him deep knowledge of both parallel\nprogramming and computer architecture. In this paper we propose the shifting of\nthese memory-hierarchy-related concerns to the run-time system, which then\ntakes on the responsibility of distributing the computation's data across the\ntarget memory hierarchy. We evaluate our approach from a performance\nperspective, comparing it against the common cache-neglectful data\ndecomposition strategy.\n", "versions": [{"version": "v1", "created": "Wed, 18 Nov 2015 13:48:35 GMT"}, {"version": "v2", "created": "Thu, 19 Nov 2015 11:27:22 GMT"}], "update_date": "2015-11-20", "authors_parsed": [["Paulino", "Herv\u00e9", ""], ["Delgado", "Nuno", ""]]}, {"id": "1511.06033", "submitter": "Athanasios N. Nikolakopoulos", "authors": "Athanasios N. Nikolakopoulos, Vassilis Kalantzis, Efstratios\n  Gallopoulos and John D. Garofalakis", "title": "EigenRec: Generalizing PureSVD for Effective and Efficient Top-N\n  Recommendations", "comments": "23 pages. Journal version of the conference paper \"Factored Proximity\n  Models for Top-N Recommendation\"", "journal-ref": null, "doi": "10.1007/s10115-018-1197-7", "report-no": null, "categories": "cs.IR cs.DB cs.DC cs.NA cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce EigenRec; a versatile and efficient Latent-Factor framework for\nTop-N Recommendations that includes the well-known PureSVD algorithm as a\nspecial case. EigenRec builds a low dimensional model of an inter-item\nproximity matrix that combines a similarity component, with a scaling operator,\ndesigned to control the influence of the prior item popularity on the final\nmodel. Seeing PureSVD within our framework provides intuition about its inner\nworkings, exposes its inherent limitations, and also, paves the path towards\npainlessly improving its recommendation performance. A comprehensive set of\nexperiments on the MovieLens and the Yahoo datasets based on widely applied\nperformance metrics, indicate that EigenRec outperforms several\nstate-of-the-art algorithms, in terms of Standard and Long-Tail recommendation\naccuracy, exhibiting low susceptibility to sparsity, even in its most extreme\nmanifestations -- the Cold-Start problems. At the same time EigenRec has an\nattractive computational profile and it can apply readily in large-scale\nrecommendation settings.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 00:34:51 GMT"}, {"version": "v2", "created": "Wed, 31 May 2017 16:00:46 GMT"}, {"version": "v3", "created": "Tue, 5 Dec 2017 12:56:14 GMT"}], "update_date": "2018-05-04", "authors_parsed": [["Nikolakopoulos", "Athanasios N.", ""], ["Kalantzis", "Vassilis", ""], ["Gallopoulos", "Efstratios", ""], ["Garofalakis", "John D.", ""]]}, {"id": "1511.06035", "submitter": "David Dice", "authors": "Dave Dice", "title": "Malthusian Locks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications running in modern multithreaded environments are sometimes\n\\emph{over-threaded}. The excess threads do not improve performance, and in\nfact may act to degrade performance via \\emph{scalability collapse}. Often,\nsuch software also has highly contended locks. We opportunistically leverage\nthe existence of such locks by modifying the lock admission policy so as to\nintentionally limit the number of threads circulating over the lock in a given\nperiod. Specifically, if there are more threads circulating than are necessary\nto keep the lock saturated, our approach will selectively cull and passivate\nsome of those threads. We borrow the concept of \\emph{swapping} from the field\nof memory management and intentionally impose \\emph{concurrency restriction}\n(CR) if a lock is oversubscribed. In the worst case CR does no harm, but it\noften yields performance benefits. The resultant admission order is unfair over\nthe short term but we explicitly provide long-term fairness by periodically\nshifting threads between the set of passivated threads and those actively\ncirculating. Our approach is palliative, but often effective.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 00:55:31 GMT"}, {"version": "v2", "created": "Sun, 28 Feb 2016 20:15:21 GMT"}, {"version": "v3", "created": "Wed, 13 Jul 2016 19:17:47 GMT"}, {"version": "v4", "created": "Wed, 3 Aug 2016 17:07:46 GMT"}, {"version": "v5", "created": "Sat, 25 Mar 2017 02:04:27 GMT"}, {"version": "v6", "created": "Wed, 19 Apr 2017 22:31:37 GMT"}, {"version": "v7", "created": "Fri, 9 Jun 2017 19:52:56 GMT"}], "update_date": "2017-06-13", "authors_parsed": [["Dice", "Dave", ""]]}, {"id": "1511.06051", "submitter": "Robert Nishihara", "authors": "Philipp Moritz, Robert Nishihara, Ion Stoica, Michael I. Jordan", "title": "SparkNet: Training Deep Networks in Spark", "comments": "12 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NE math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Training deep networks is a time-consuming process, with networks for object\nrecognition often requiring multiple days to train. For this reason, leveraging\nthe resources of a cluster to speed up training is an important area of work.\nHowever, widely-popular batch-processing computational frameworks like\nMapReduce and Spark were not designed to support the asynchronous and\ncommunication-intensive workloads of existing distributed deep learning\nsystems. We introduce SparkNet, a framework for training deep networks in\nSpark. Our implementation includes a convenient interface for reading data from\nSpark RDDs, a Scala interface to the Caffe deep learning framework, and a\nlightweight multi-dimensional tensor library. Using a simple parallelization\nscheme for stochastic gradient descent, SparkNet scales well with the cluster\nsize and tolerates very high-latency communication. Furthermore, it is easy to\ndeploy and use with no parameter tuning, and it is compatible with existing\nCaffe models. We quantify the dependence of the speedup obtained by SparkNet on\nthe number of machines, the communication frequency, and the cluster's\ncommunication overhead, and we benchmark our system's performance on the\nImageNet dataset.\n", "versions": [{"version": "v1", "created": "Thu, 19 Nov 2015 03:29:56 GMT"}, {"version": "v2", "created": "Thu, 26 Nov 2015 10:35:40 GMT"}, {"version": "v3", "created": "Wed, 6 Jan 2016 07:48:06 GMT"}, {"version": "v4", "created": "Sun, 28 Feb 2016 23:43:36 GMT"}], "update_date": "2016-03-01", "authors_parsed": [["Moritz", "Philipp", ""], ["Nishihara", "Robert", ""], ["Stoica", "Ion", ""], ["Jordan", "Michael I.", ""]]}, {"id": "1511.06487", "submitter": "Charles Jordan", "authors": "David Avis and Charles Jordan", "title": "mplrs: A scalable parallel vertex/facet enumeration code", "comments": "Revision incorporating additional suggested changes", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.CG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We describe a new parallel implementation, mplrs, of the vertex enumeration\ncode lrs that uses the MPI parallel environment and can be run on a network of\ncomputers. The implementation makes use of a C wrapper that essentially uses\nthe existing lrs code with only minor modifications. mplrs was derived from the\nearlier parallel implementation plrs, written by G. Roumanis in C++. plrs uses\nthe Boost library and runs on a shared memory machine. In developing mplrs we\ndiscovered a method of balancing the parallel tree search, called budgeting,\nthat greatly improves parallelization beyond the bottleneck encountered\npreviously at around 32 cores.\n  This method can be readily adapted for use in other reverse search\nenumeration codes. We also report some preliminary computational results\ncomparing parallel and sequential codes for vertex/facet enumeration problems\nfor convex polyhedra. The problems chosen span the range from simple to highly\ndegenerate polytopes. For most problems tested, the results clearly show the\nadvantage of using the parallel implementation mplrs of the reverse search\nbased code lrs, even when as few as 8 cores are available. For some problems\nalmost linear speedup was observed up to 1200 cores, the largest number of\ncores tested.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 04:54:22 GMT"}, {"version": "v2", "created": "Wed, 2 Dec 2015 07:08:43 GMT"}, {"version": "v3", "created": "Tue, 29 Nov 2016 04:33:01 GMT"}, {"version": "v4", "created": "Thu, 12 Oct 2017 01:44:42 GMT"}], "update_date": "2017-10-13", "authors_parsed": [["Avis", "David", ""], ["Jordan", "Charles", ""]]}, {"id": "1511.06493", "submitter": "Francois Belletti", "authors": "Francois Belletti, Evan Sparks, Michael Franklin, Alexandre M. Bayen", "title": "Embarrassingly Parallel Time Series Analysis for Large Scale Weak Memory\n  Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Second order stationary models in time series analysis are based on the\nanalysis of essential statistics whose computations follow a common pattern. In\nparticular, with a map-reduce nomenclature, most of these operations can be\nmodeled as mapping a kernel that only depends on short windows of consecutive\ndata and reducing the results produced by each computation. This computational\npattern stems from the ergodicity of the model under consideration and is often\nreferred to as weak or short memory when it comes to data indexed with respect\nto time. In the following we will show how studying weak memory systems can be\ndone in a scalable manner thanks to a framework relying on specifically\ndesigned overlapping distributed data structures that enable fragmentation and\nreplication of the data across many machines as well as parallelism in\ncomputations. This scheme has been implemented for Apache Spark but is\ncertainly not system specific. Indeed we prove it is also adapted to leveraging\nhigh bandwidth fragmented memory blocks on GPUs.\n", "versions": [{"version": "v1", "created": "Fri, 20 Nov 2015 05:16:35 GMT"}], "update_date": "2015-11-23", "authors_parsed": [["Belletti", "Francois", ""], ["Sparks", "Evan", ""], ["Franklin", "Michael", ""], ["Bayen", "Alexandre M.", ""]]}, {"id": "1511.06825", "submitter": "Nguyen Quang-Hung", "authors": "Nguyen Quang-Hung, Nam Thoai", "title": "EMinRET: Heuristic for Energy-Aware VM Placement with Fixed Intervals\n  and Non-preemption", "comments": "8 pages, 4 figures, The International Conference on Advanced\n  Computing and Applications (ACOMP)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Infrastructure-as-a-Service (IaaS) clouds have become more popular enabling\nusers to run applications under virtual machines. This paper investigates the\nenergy-aware virtual machine (VM) allocation problems in IaaS clouds along\ncharacteristics: multiple resources, and fixed interval times and\nnon-preemption of virtual machines. Many previous works proposed to use a\nminimum number of physical machines, however, this is not necessarily a good\nsolution to minimize total energy consumption in the VM placement with multiple\nresources, fixed interval times and non-preemption. We observed that minimizing\ntotal energy consumption of physical machines is equivalent to minimize the sum\nof total completion time of all physical machines. Based on the observation, we\npropose EMinRET algorithm. The EMinRET algorithm swaps an allocating VM with a\nsuitable overlapped VM, which is of the same VM type and is allocated on the\nsame physical machine, to minimize total completion time of all physical\nmachines. The EMinRET uses resource utilization during executing time period of\na physical machine as the evaluation metric, and will then choose a host that\nminimizes the metric to allocate a new VM. In addition, this work studies some\nheuristics for sorting the list of virtual machines (e.g., sorting by the\nearliest starting time, or the longest duration time first, etc.) to allocate\nVM. Using the realistic log-trace in the Parallel Workloads Archive, our\nsimulation results show that the EMinRET algorithm could reduce from 25% to 45%\nenergy consumption compared with power-aware best-fit decreasing (PABFD)) and\nvector bin-packing norm-based greedy algorithms. Moreover, the EMinRET\nheuristic has also less total energy consumption than our previous heuristics\n(e.g. MinDFT and EPOBF) in the simulations (using same virtual machines sorting\nmethod).\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 03:40:56 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Quang-Hung", "Nguyen", ""], ["Thoai", "Nam", ""]]}, {"id": "1511.06968", "submitter": "Raghu Prabhakar", "authors": "Raghu Prabhakar, David Koeplinger, Kevin Brown, HyoukJoong Lee,\n  Christopher De Sa, Christos Kozyrakis, Kunle Olukotun", "title": "Generating Configurable Hardware from Parallel Patterns", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years the computing landscape has seen an in- creasing shift\ntowards specialized accelerators. Field pro- grammable gate arrays (FPGAs) are\nparticularly promising as they offer significant performance and energy\nimprovements compared to CPUs for a wide class of applications and are far more\nflexible than fixed-function ASICs. However, FPGAs are difficult to program.\nTraditional programming models for reconfigurable logic use low-level hardware\ndescription languages like Verilog and VHDL, which have none of the pro-\nductivity features of modern software development languages but produce very\nefficient designs, and low-level software lan- guages like C and OpenCL coupled\nwith high-level synthesis (HLS) tools that typically produce designs that are\nfar less efficient. Functional languages with parallel patterns are a better\nfit for hardware generation because they both provide high-level abstractions\nto programmers with little experience in hard- ware design and avoid many of\nthe problems faced when gen- erating hardware from imperative languages. In\nthis paper, we identify two optimizations that are important when using par-\nallel patterns to generate hardware: tiling and metapipelining. We present a\ngeneral representation of tiled parallel patterns, and provide rules for\nautomatically tiling patterns and gen- erating metapipelines. We demonstrate\nexperimentally that these optimizations result in speedups up to 40x on a set\nof benchmarks from the data analytics domain.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2015 05:57:27 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Prabhakar", "Raghu", ""], ["Koeplinger", "David", ""], ["Brown", "Kevin", ""], ["Lee", "HyoukJoong", ""], ["De Sa", "Christopher", ""], ["Kozyrakis", "Christos", ""], ["Olukotun", "Kunle", ""]]}, {"id": "1511.07017", "submitter": "Sudhakar Singh", "authors": "Sudhakar Singh, Rakhi Garg, P. K. Mishra", "title": "Performance Analysis of Apriori Algorithm with Different Data Structures\n  on Hadoop Cluster", "comments": "2009-2015 International Journal of Computer Applications,\n  FCS(Foundation of Computer Science)", "journal-ref": null, "doi": "10.5120/ijca2015906632", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Mining frequent itemsets from massive datasets is always being a most\nimportant problem of data mining. Apriori is the most popular and simplest\nalgorithm for frequent itemset mining. To enhance the efficiency and\nscalability of Apriori, a number of algorithms have been proposed addressing\nthe design of efficient data structures, minimizing database scan and parallel\nand distributed processing. MapReduce is the emerging parallel and distributed\ntechnology to process big datasets on Hadoop Cluster. To mine big datasets it\nis essential to re-design the data mining algorithm on this new paradigm. In\nthis paper, we implement three variations of Apriori algorithm using data\nstructures hash tree, trie and hash table trie i.e. trie with hash technique on\nMapReduce paradigm. We emphasize and investigate the significance of these\nthree data structures for Apriori algorithm on Hadoop cluster, which has not\nbeen given attention yet. Experiments are carried out on both real life and\nsynthetic datasets which shows that hash table trie data structures performs\nfar better than trie and hash tree in terms of execution time. Moreover the\nperformance in case of hash tree becomes worst.\n", "versions": [{"version": "v1", "created": "Sun, 22 Nov 2015 14:40:06 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Singh", "Sudhakar", ""], ["Garg", "Rakhi", ""], ["Mishra", "P. K.", ""]]}, {"id": "1511.07148", "submitter": "Naama Kraus", "authors": "Naama Kraus, David Carmel, Idit Keidar, Meni Orenbach", "title": "NearBucket-LSH: Efficient Similarity Search in P2P Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.IR cs.SI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present NearBucket-LSH, an effective algorithm for similarity search in\nlarge-scale distributed online social networks organized as peer-to-peer\noverlays. As communication is a dominant consideration in distributed systems,\nwe focus on minimizing the network cost while guaranteeing good search quality.\nOur algorithm is based on Locality Sensitive Hashing (LSH), which limits the\nsearch to collections of objects, called buckets, that have a high probability\nto be similar to the query. More specifically, NearBucket-LSH employs an LSH\nextension that searches in near buckets, and improves search quality but also\nsignificantly increases the network cost. We decrease the network cost by\nconsidering the internals of both LSH and the P2P overlay, and harnessing their\nproperties to our needs. We show that our NearBucket-LSH increases search\nquality for a given network cost compared to previous art. In many cases, the\nsearch quality increases by more than 50%.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 09:33:24 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Kraus", "Naama", ""], ["Carmel", "David", ""], ["Keidar", "Idit", ""], ["Orenbach", "Meni", ""]]}, {"id": "1511.07174", "submitter": "Bogdan Oancea", "authors": "Bogdan Oancea, Tudorel Andrei", "title": "Developing a High Performance Software Library with MPI and CUDA for\n  Matrix Computations", "comments": "in Computational Methods for Social Sciences, VOL. I, ISSUE 2/2013", "journal-ref": "Computational Methods for Social Sciences, VOL. I, ISSUE 2/2013", "doi": null, "report-no": null, "categories": "cs.DC cs.MS", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Nowadays, the paradigm of parallel computing is changing. CUDA is now a\npopular programming model for general purpose computations on GPUs and a great\nnumber of applications were ported to CUDA obtaining speedups of orders of\nmagnitude comparing to optimized CPU implementations. Hybrid approaches that\ncombine the message passing model with the shared memory model for parallel\ncomputing are a solution for very large applications. We considered a\nheterogeneous cluster that combines the CPU and GPU computations using MPI and\nCUDA for developing a high performance linear algebra library. Our library\ndeals with large linear systems solvers because they are a common problem in\nthe fields of science and engineering. Direct methods for computing the\nsolution of such systems can be very expensive due to high memory requirements\nand computational cost. An efficient alternative are iterative methods which\ncomputes only an approximation of the solution. In this paper we present an\nimplementation of a library that uses a hybrid model of computation using MPI\nand CUDA implementing both direct and iterative linear systems solvers. Our\nlibrary implements LU and Cholesky factorization based solvers and some of the\nnon-stationary iterative methods using the MPI/CUDA combination. We compared\nthe performance of our MPI/CUDA implementation with classic programs written to\nbe run on a single CPU.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 11:06:12 GMT"}], "update_date": "2018-02-09", "authors_parsed": [["Oancea", "Bogdan", ""], ["Andrei", "Tudorel", ""]]}, {"id": "1511.07185", "submitter": "Pedro Costa", "authors": "Pedro A.R.S. Costa, Xiao Bai, Fernando M.V. Ramos, Miguel Correia", "title": "Medusa: An Efficient Cloud Fault-Tolerant MapReduce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications such as web search and social networking have been moving from\ncentralized to decentralized cloud architectures to improve their scalability.\nMapReduce, a programming framework for processing large amounts of data using\nthousands of machines in a single cloud, also needs to be scaled out to\nmultiple clouds to adapt to this evolution. The challenge of building a\nmulti-cloud distributed architecture is substantial. Notwithstanding, the\nability to deal with the new types of faults introduced by such setting, such\nas the outage of a whole datacenter or an arbitrary fault caused by a malicious\ncloud insider, increases the endeavor considerably.\n  In this paper we propose Medusa, a platform that allows MapReduce\ncomputations to scale out to multiple clouds and tolerate several types of\nfaults. Our solution fulfills four objectives. First, it is transparent to the\nuser, who writes her typical MapReduce application without modification.\nSecond, it does not require any modification to the widely used Hadoop\nframework. Third, the proposed system goes well beyond the fault-tolerance\noffered by MapReduce to tolerate arbitrary faults, cloud outages, and even\nmalicious faults caused by corrupt cloud insiders. Fourth, it achieves this\nincreased level of fault tolerance at reasonable cost. We performed an\nextensive experimental evaluation in the ExoGENI testbed, demonstrating that\nour solution significantly reduces execution time when compared to traditional\nmethods that achieve the same level of resilience.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 12:02:43 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Costa", "Pedro A. R. S.", ""], ["Bai", "Xiao", ""], ["Ramos", "Fernando M. V.", ""], ["Correia", "Miguel", ""]]}, {"id": "1511.07207", "submitter": "Bogdan Oancea", "authors": "Bogdan Oancea, Tudorel Andrei, Raluca Mariana Dragoescu", "title": "Improving the performance of the linear systems solvers using CUDA", "comments": "in Proceedings of the Challenges of the Knowledge Society\n  International Conference, 2012", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  Parallel computing can offer an enormous advantage regarding the performance\nfor very large applications in almost any field: scientific computing, computer\nvision, databases, data mining, and economics. GPUs are high performance\nmany-core processors that can obtain very high FLOP rates. Since the first idea\nof using GPU for general purpose computing, things have evolved and now there\nare several approaches to GPU programming: CUDA from NVIDIA and Stream from\nAMD. CUDA is now a popular programming model for general purpose computations\non GPU for C/C++ programmers. A great number of applications were ported to\nCUDA programming model and they obtain speedups of orders of magnitude\ncomparing to optimized CPU implementations. In this paper we present an\nimplementation of a library for solving linear systems using the CCUDA\nframework. We present the results of performance tests and show that using GPU\none can obtain speedups of about of approximately 80 times comparing with a CPU\nimplementation.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 13:00:07 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Oancea", "Bogdan", ""], ["Andrei", "Tudorel", ""], ["Dragoescu", "Raluca Mariana", ""]]}, {"id": "1511.07261", "submitter": "Martin Bauer", "authors": "Martin Bauer, Florian Schornbaum, Christian Godenschwager, Matthias\n  Markl, Daniela Anderl, Harald K\\\"ostler, Ulrich R\\\"ude", "title": "A Python Extension for the Massively Parallel Multiphysics Simulation\n  Framework waLBerla", "comments": null, "journal-ref": null, "doi": "10.1080/17445760.2015.1118478", "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a Python extension to the massively parallel HPC simulation\ntoolkit waLBerla. waLBerla is a framework for stencil based algorithms\noperating on block-structured grids, with the main application field being\nfluid simulations in complex geometries using the lattice Boltzmann method.\nCareful performance engineering results in excellent node performance and good\nscalability to over 400,000 cores. To increase the usability and flexibility of\nthe framework, a Python interface was developed. Python extensions are used at\nall stages of the simulation pipeline: They simplify and automate scenario\nsetup, evaluation, and plotting. We show how our Python interface outperforms\nthe existing text-file-based configuration mechanism, providing features like\nautomatic nondimensionalization of physical quantities and handling of complex\nparameter dependencies. Furthermore, Python is used to process and evaluate\nresults while the simulation is running, leading to smaller output files and\nthe possibility to adjust parameters dependent on the current simulation state.\nC++ data structures are exported such that a seamless interfacing to other\nnumerical Python libraries is possible. The expressive power of Python and the\nperformance of C++ make development of efficient code with low time effort\npossible.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 15:06:47 GMT"}], "update_date": "2015-11-24", "authors_parsed": [["Bauer", "Martin", ""], ["Schornbaum", "Florian", ""], ["Godenschwager", "Christian", ""], ["Markl", "Matthias", ""], ["Anderl", "Daniela", ""], ["K\u00f6stler", "Harald", ""], ["R\u00fcde", "Ulrich", ""]]}, {"id": "1511.07312", "submitter": "John Taylor Childers", "authors": "J.T. Childers and T.D. Uram and T.J. LeCompte and M.E. Papka and D.P.\n  Benjamin", "title": "Adapting the serial Alpgen event generator to simulate LHC collisions on\n  millions of parallel threads", "comments": "13 pages, 7 figures, publication", "journal-ref": null, "doi": "10.1016/j.cpc.2016.09.013", "report-no": null, "categories": "hep-ph cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As the LHC moves to higher energies and luminosity, the demand for computing\nresources increases accordingly and will soon outpace the growth of the\nWorldwide LHC Computing Grid. To meet this greater demand, event generation\nMonte Carlo was targeted for adaptation to run on Mira, the supercomputer at\nthe Argonne Leadership Computing Facility. Alpgen is a Monte Carlo event\ngeneration application that is used by LHC experiments in the simulation of\ncollisions that take place in the Large Hadron Collider. This paper details the\nprocess by which Alpgen was adapted from a single-processor serial-application\nto a large-scale parallel-application and the performance that was achieved.\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 17:00:00 GMT"}], "update_date": "2017-01-11", "authors_parsed": [["Childers", "J. T.", ""], ["Uram", "T. D.", ""], ["LeCompte", "T. J.", ""], ["Papka", "M. E.", ""], ["Benjamin", "D. P.", ""]]}, {"id": "1511.07376", "submitter": "Matin Hashemi", "authors": "Seyyed Salar Latifi Oskouei, Hossein Golestani, Matin Hashemi, Soheil\n  Ghiasi", "title": "CNNdroid: GPU-Accelerated Execution of Trained Deep Convolutional Neural\n  Networks on Android", "comments": null, "journal-ref": "Proceedings of the 2016 ACM Multimedia Conference, Open Source\n  Software Track, pages 1201-1205, October 2016", "doi": "10.1145/2964284.2973801", "report-no": null, "categories": "cs.DC cs.CV", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many mobile applications running on smartphones and wearable devices would\npotentially benefit from the accuracy and scalability of deep CNN-based machine\nlearning algorithms. However, performance and energy consumption limitations\nmake the execution of such computationally intensive algorithms on mobile\ndevices prohibitive. We present a GPU-accelerated library, dubbed CNNdroid, for\nexecution of trained deep CNNs on Android-based mobile devices. Empirical\nevaluations show that CNNdroid achieves up to 60X speedup and 130X energy\nsaving on current mobile devices. The CNNdroid open source library is available\nfor download at https://github.com/ENCP/CNNdroid\n", "versions": [{"version": "v1", "created": "Mon, 23 Nov 2015 19:32:37 GMT"}, {"version": "v2", "created": "Sat, 15 Oct 2016 19:22:46 GMT"}], "update_date": "2016-10-18", "authors_parsed": [["Oskouei", "Seyyed Salar Latifi", ""], ["Golestani", "Hossein", ""], ["Hashemi", "Matin", ""], ["Ghiasi", "Soheil", ""]]}, {"id": "1511.07423", "submitter": "Nguyen Quang-Hung", "authors": "Nguyen Quang-Hung, Nam Thoai", "title": "Minimizing Total Busy Time for Energy-Aware Virtual Machine Allocation\n  Problems", "comments": "8 pages, Proceedings of the Sixth International Symposium on\n  Information and Communication Technology. arXiv admin note: substantial text\n  overlap with arXiv:1511.06825", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper investigates the energy-aware virtual machine (VM) allocation\nproblems in clouds along characteristics: multiple resources, fixed interval\ntime and non-preemption of virtual machines. Many previous works have been\nproposed to use a minimum number of physical machines, however, this is not\nnecessarily a good solution to minimize total energy consumption in the VM\nplacement with multiple resources, fixed interval time and non-preemption. We\nobserved that minimizing the sum of total busy time of all physical machines\nimplies minimizing total energy consumption of physical machines. In addition\nto, if mapping of a VM onto physical machines have the same total busy time\nthen the best mapping has physical machine's remaining available resource\nminimizing. Based on these observations, we proposed heuristic-based EM\nalgorithm to solve the energy-aware VM allocation with fixed starting time and\nduration time. In addition, this work studies some heuristics for sorting the\nlist of virtual machines (e.g., sorting by the earliest starting time, or\nlatest finishing time, or the longest duration time first, etc.) to allocate\nVM. We evaluate the EM using CloudSim toolkit and jobs log-traces in the\nFeitelson's Parallel Workloads Archive. Simulation's results show that all of\nEM-ST, EM-LFT and EM-LDTF algorithms could reduce total energy consumption\ncompared to state-of-the-art of power-aware VM allocation algorithms. (e.g.\nPower-Aware Best-Fit Decreasing (PABFD) [7])).\n", "versions": [{"version": "v1", "created": "Sat, 21 Nov 2015 04:53:42 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Quang-Hung", "Nguyen", ""], ["Thoai", "Nam", ""]]}, {"id": "1511.07658", "submitter": "Teng Li", "authors": "Teng Li, Vikram K. Narayana, Tarek El-Ghazawi", "title": "Efficient Resource Sharing Through GPU Virtualization on Accelerated\n  High Performance Computing Systems", "comments": "21 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The High Performance Computing (HPC) field is witnessing a widespread\nadoption of Graphics Processing Units (GPUs) as co-processors for conventional\nhomogeneous clusters. The adoption of prevalent Single- Program Multiple-Data\n(SPMD) programming paradigm for GPU-based parallel processing brings in the\nchallenge of resource underutilization, with the asymmetrical\nprocessor/co-processor distribution. In other words, under SPMD, balanced\nCPU/GPU distribution is required to ensure full resource utilization. In this\npaper, we propose a GPU resource virtualization approach to allow underutilized\nmicroprocessors to effi- ciently share the GPUs. We propose an efficient GPU\nsharing scenario achieved through GPU virtualization and analyze the\nperformance potentials through execution models. We further present the\nimplementation details of the virtualization infrastructure, followed by the\nexperimental analyses. The results demonstrate considerable performance gains\nwith GPU virtualization. Furthermore, the proposed solution enables full\nutilization of asymmetrical resources, through efficient GPU sharing among\nmicroprocessors, while incurring low overhead due to the added virtualization\nlayer.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 11:33:53 GMT"}], "update_date": "2015-11-25", "authors_parsed": [["Li", "Teng", ""], ["Narayana", "Vikram K.", ""], ["El-Ghazawi", "Tarek", ""]]}, {"id": "1511.07693", "submitter": "Marek Szuba", "authors": "Marek Szuba, Parinaz Ameri, Udo Grabowski, J\\\"org Meyer, Achim Streit", "title": "A Distributed System for Storing and Processing Data from\n  Earth-observing Satellites: System Design and Performance Evaluation of the\n  Visualisation Tool", "comments": "6 pages, 6 figures. To be published in the proceedings of the 16th\n  IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid\n  2016)", "journal-ref": null, "doi": "10.1109/CCGrid.2016.19", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a distributed system for storage, processing, three-dimensional\nvisualisation and basic analysis of data from Earth-observing satellites. The\ndatabase and the server have been designed for high performance and\nscalability, whereas the client is highly portable thanks to having been\ndesigned as a HTML5- and WebGL-based Web application. The system is based on\nthe so-called MEAN stack, a modern replacement for LAMP which has steadily been\ngaining traction among high-performance Web applications. We demonstrate the\nperformance of the system from the perspective of an user operating the client.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 13:12:33 GMT"}, {"version": "v2", "created": "Wed, 10 Feb 2016 12:32:40 GMT"}], "update_date": "2016-11-17", "authors_parsed": [["Szuba", "Marek", ""], ["Ameri", "Parinaz", ""], ["Grabowski", "Udo", ""], ["Meyer", "J\u00f6rg", ""], ["Streit", "Achim", ""]]}, {"id": "1511.07846", "submitter": "Leonidas Fegaras", "authors": "Leonidas Fegaras", "title": "Incremental Query Processing on Big Data Streams", "comments": "Extended version of a paper submitted to a journal", "journal-ref": null, "doi": "10.1109/TKDE.2016.2601103", "report-no": null, "categories": "cs.DB cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper addresses online query processing for large-scale, incremental\ndata analysis on a distributed stream processing engine (DSPE). Our goal is to\nconvert any SQL-like query to an incremental DSPE program automatically. In\ncontrast to other approaches, we derive incremental programs that return\naccurate results, not approximate answers. This is accomplished by retaining a\nminimal state during the query evaluation lifetime and by using incremental\nevaluation techniques to return an accurate snapshot answer at each time\ninterval that depends on the current state and the latest batches of data. Our\nmethods can handle many forms of queries on nested data collections, including\niterative and nested queries, group-by with aggregation, and equi-joins.\nFinally, we report on a prototype implementation of our framework, called MRQL\nStreaming, running on top of Spark and we experimentally validate the\neffectiveness of our methods.\n", "versions": [{"version": "v1", "created": "Tue, 24 Nov 2015 19:55:09 GMT"}, {"version": "v2", "created": "Sun, 17 Jan 2016 22:59:08 GMT"}, {"version": "v3", "created": "Sun, 6 Mar 2016 19:21:25 GMT"}], "update_date": "2016-08-23", "authors_parsed": [["Fegaras", "Leonidas", ""]]}, {"id": "1511.07983", "submitter": "Teng Li", "authors": "Teng Li, Vikram K. Narayana, Tarek El-Ghazawi", "title": "Reordering GPU Kernel Launches to Enable Efficient Concurrent Execution", "comments": "2 Pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Contemporary GPUs allow concurrent execution of small computational kernels\nin order to prevent idling of GPU resources. Despite the potential concurrency\nbetween independent kernels, the order in which kernels are issued to the GPU\nwill significantly influence the application performance. A technique for\nderiving suitable kernel launch orders is therefore presented, with the aim of\nreducing the total execution time. Experimental results indicate that the\nproposed method yields solutions that are well above the 90 percentile mark in\nthe design space of all possible permutations of the kernel launch sequences.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 08:01:18 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Li", "Teng", ""], ["Narayana", "Vikram K.", ""], ["El-Ghazawi", "Tarek", ""]]}, {"id": "1511.08078", "submitter": "Satish N. Srirama", "authors": "Satish Narayana Srirama and Pelle Jakovits and Vladislav\n  Ivani\\v{s}t\\v{s}ev", "title": "Desktop to Cloud Migration of Scientific Computing Experiments", "comments": "28 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific computing applications usually need huge amounts of computational\npower. The cloud provides interesting high-performance computing solutions,\nwith its promise of virtually infinite resources on demand. However, migrating\nscientific computing problems to clouds and the re-creation of software\nenvironment on the vendor-supplied OS and cloud instances is often a laborious\ntask. It is also assumed that the scientist who is performing the experiments\nhas significant knowledge of computer science, cloud computing and the\nmigration procedure, which is often not true. Considering these obstacles, we\nhave designed a tool suite that migrates the complete software environment\ndirectly to the cloud. The developed desktop-to-cloud-migration (D2CM) tool\nsupports transformation and migration of virtual machine images, reusable\ndeployment description and life-cycle management for applications to be hosted\non Amazon Cloud or compatible infrastructure such as Eucalyptus. The paper also\npresents an electrochemical case study and computational experiments targeted\nat designing modern supercapacitors. These experiments have extensively used\nthe tool in drawing domain specific results. Detailed analysis of the case\nshowed that D2CM tool not only simplifies the migration procedure for the\nscientists, but also helps them in optimizing the calculations and compute\nclusters, by providing them a new dimension -- cost-to-value of computational\nexperiments.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 14:54:46 GMT"}], "update_date": "2015-11-26", "authors_parsed": [["Srirama", "Satish Narayana", ""], ["Jakovits", "Pelle", ""], ["Ivani\u0161t\u0161ev", "Vladislav", ""]]}, {"id": "1511.08232", "submitter": "Cheng Wang", "authors": "Cheng Wang, Carole Delporte-Gallet, Hugues Fauconnier, Rachid\n  Guerraoui, Anne-Marie Kermarrec", "title": "Beyond One Third Byzantine Failures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  The Byzantine agreement problem requires a set of $n$ processes to agree on a\nvalue sent by a transmitter, despite a subset of $b$ processes behaving in an\narbitrary, i.e. Byzantine, manner and sending corrupted messages to all\nprocesses in the system. It is well known that the problem has a solution in a\n(an eventually) synchronous message passing distributed system iff the number\nof processes in the Byzantine subset is less than one third of the total number\nof processes, i.e. iff $n > 3b+1$. The rest of the processes are expected to be\ncorrect: they should never deviate from the algorithm assigned to them and send\ncorrupted messages. But what if they still do?\n  We show in this paper that it is possible to solve Byzantine agreement even\nif, beyond the $ b$ ($< n/3 $) Byzantine processes, some of the other processes\nalso send corrupted messages, as long as they do not send them to all. More\nspecifically, we generalize the classical Byzantine model and consider that\nByzantine failures might be partial. In each communication step, some of the\nprocesses might send corrupted messages to a subset of the processes. This\nsubset of processes - to which corrupted messages might be sent - could change\nover time. We compute the exact number of processes that can commit such\nfaults, besides those that commit classical Byzantine failures, while still\nsolving Byzantine agreement. We present a corresponding Byzantine agreement\nalgorithm and prove its optimality by giving resilience and complexity bounds.\n", "versions": [{"version": "v1", "created": "Wed, 25 Nov 2015 21:25:42 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Wang", "Cheng", ""], ["Delporte-Gallet", "Carole", ""], ["Fauconnier", "Hugues", ""], ["Guerraoui", "Rachid", ""], ["Kermarrec", "Anne-Marie", ""]]}, {"id": "1511.08447", "submitter": "Brijesh Dongol", "authors": "Brijesh Dongol, Robert M. Hierons", "title": "Decidability and Complexity for Quiescent Consistency and its Variations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LO cs.DC cs.DS cs.FL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quiescent consistency is a notion of correctness for a concurrent object that\ngives meaning to the object's behaviours in quiescent states, i.e., states in\nwhich none of the object's operations are being executed. Correctness of an\nimplementation object is defined in terms of a corresponding abstract\nspecification. This gives rise to two important verification questions:\nmembership (checking whether a behaviour of the implementation is allowed by\nthe specification) and correctness (checking whether all behaviours of the\nimplementation are allowed by the specification). In this paper, we show that\nthe membership problem for quiescent consistency is NP-complete and that the\ncorrectness problem is decidable, but coNP-hard and in EXPSPACE. For both\nproblems, we consider restricted versions of quiescent consistency by assuming\nan upper limit on the number of events between two quiescent points. Here, we\nshow that the membership problem is in PTIME, whereas correctness is in PSPACE.\n  Quiescent consistency does not guarantee sequential consistency, i.e., it\nallows operation calls by the same process to be reordered when mapping to an\nabstract specification. Therefore, we also consider quiescent sequential\nconsistency, which strengthens quiescent consistency with an additional\nsequential consistency condition. We show that the unrestricted versions of\nmembership and correctness are NP-complete and undecidable, respectively. When\nby placing a limit on the number of events between two quiescent points,\nmembership is in PTIME, while correctness is in PSPACE. Finally, we consider a\nversion of quiescent sequential consistency that places an upper limit on the\nnumber of processes for every run of the implementation, and show that the\nmembership problem for quiescent sequential consistency with this restriction\nis in PTIME.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 16:46:30 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Dongol", "Brijesh", ""], ["Hierons", "Robert M.", ""]]}, {"id": "1511.08486", "submitter": "Pengtao Xie", "authors": "Pengtao Xie, Jin Kyu Kim, Yi Zhou, Qirong Ho, Abhimanu Kumar, Yaoliang\n  Yu, Eric Xing", "title": "Distributed Machine Learning via Sufficient Factor Broadcasting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Matrix-parametrized models, including multiclass logistic regression and\nsparse coding, are used in machine learning (ML) applications ranging from\ncomputer vision to computational biology. When these models are applied to\nlarge-scale ML problems starting at millions of samples and tens of thousands\nof classes, their parameter matrix can grow at an unexpected rate, resulting in\nhigh parameter synchronization costs that greatly slow down distributed\nlearning. To address this issue, we propose a Sufficient Factor Broadcasting\n(SFB) computation model for efficient distributed learning of a large family of\nmatrix-parameterized models, which share the following property: the parameter\nupdate computed on each data sample is a rank-1 matrix, i.e., the outer product\nof two \"sufficient factors\" (SFs). By broadcasting the SFs among worker\nmachines and reconstructing the update matrices locally at each worker, SFB\nimproves communication efficiency --- communication costs are linear in the\nparameter matrix's dimensions, rather than quadratic --- without affecting\ncomputational correctness. We present a theoretical convergence analysis of\nSFB, and empirically corroborate its efficiency on four different\nmatrix-parametrized ML models.\n", "versions": [{"version": "v1", "created": "Thu, 26 Nov 2015 19:42:39 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Xie", "Pengtao", ""], ["Kim", "Jin Kyu", ""], ["Zhou", "Yi", ""], ["Ho", "Qirong", ""], ["Kumar", "Abhimanu", ""], ["Yu", "Yaoliang", ""], ["Xing", "Eric", ""]]}, {"id": "1511.08540", "submitter": "Tianchu Zhao", "authors": "Tianchu Zhao, Sheng Zhou, Xueying Guo, Yun Zhao, Zhisheng Niu", "title": "A Cooperative Scheduling Scheme of Local Cloud and Internet Cloud for\n  Delay-Aware Mobile Cloud Computing", "comments": "6 pages, 7 figures, accepted by GlobeCom'15 Workshop", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the proliferation of mobile applications, Mobile Cloud Computing (MCC)\nhas been proposed to help mobile devices save energy and improve computation\nperformance. To further improve the quality of service (QoS) of MCC, cloud\nservers can be deployed locally so that the latency is decreased. However, the\ncomputational resource of the local cloud is generally limited. In this paper,\nwe design a threshold-based policy to improve the QoS of MCC by cooperation of\nthe local cloud and Internet cloud resources, which takes the advantages of low\nlatency of the local cloud and abundant computational resources of the Internet\ncloud simultaneously. This policy also applies a priority queue in terms of\ndelay requirements of applications. The optimal thresholds depending on the\ntraffic load is obtained via a proposed algorithm. Numerical results show that\nthe QoS can be greatly enhanced with the assistance of Internet cloud when the\nlocal cloud is overloaded. Better QoS is achieved if the local cloud order\ntasks according to their delay requirements, where delay-sensitive applications\nare executed ahead of delay-tolerant applications. Moreover, the optimal\nthresholds of the policy have a sound impact on the QoS of the system.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 01:38:25 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Zhao", "Tianchu", ""], ["Zhou", "Sheng", ""], ["Guo", "Xueying", ""], ["Zhao", "Yun", ""], ["Niu", "Zhisheng", ""]]}, {"id": "1511.08707", "submitter": "Md Azharuddin", "authors": "Tripti Tanaya Tejaswi, Md Azharuddin, P. K. Jana", "title": "A GA based approach for task scheduling in multi-cloud environment", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/publicdomain/zero/1.0/", "abstract": "  In multi-cloud environment, task scheduling has attracted a lot of attention\ndue to NP-Complete nature of the problem. Moreover, it is very challenging due\nto heterogeneity of the cloud resources with varying capacities and\nfunctionalities. Therefore, minimizing the makespan for task scheduling is a\nchallenging issue. In this paper, we propose a genetic algorithm (GA) based\napproach for solving task scheduling problem. The algorithm is described with\ninnovative idea of fitness function derivation and mutation. The proposed\nalgorithm is exposed to rigorous testing using various benchmark datasets and\nits performance is evaluated in terms of total makespan.\n", "versions": [{"version": "v1", "created": "Fri, 27 Nov 2015 15:30:13 GMT"}], "update_date": "2015-11-30", "authors_parsed": [["Tejaswi", "Tripti Tanaya", ""], ["Azharuddin", "Md", ""], ["Jana", "P. K.", ""]]}, {"id": "1511.08857", "submitter": "Rajkumar Buyya", "authors": "Rajkumar Buyya and Diana Barreto", "title": "Multi-Cloud Resource Provisioning with Aneka: A Unified and Integrated\n  Utilisation of Microsoft Azure and Amazon EC2 Instances", "comments": "14 pages, 12 figures. Conference paper, Proceedings of the 2015\n  International Conference on Computing and Network Communications (CoCoNet\n  2015, IEEE Press, USA), Trivandrum, India, December 16-19, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Many vendors are offering computing services on subscription basis via\nInfrastructure-as-a-Service (IaaS) model. Users can acquire resources from\ndifferent providers and get the best of each of them to run their applications.\nHowever, deploying applications in multi-cloud environments is a complex task.\nTherefore, application platforms are needed to help developers to succeed.\nAneka is one such platform that supports developers to program and deploy\ndistributed applications in multi-cloud environments. It can be used to\nprovision resources from different cloud providers and can be configured to\nrequest resources dynamically according to the needs of specific applications.\nThis paper presents extensions incorporated in Aneka to support the deployment\nof applications in multi-cloud environments. The first extension shows the\nflexibility of Aneka architecture to add cloud providers. Specifically, we\ndescribe the addition of Microsoft Azure IaaS cloud provider. We also discuss\nthe inclusion of public IPs to communicate resources located in different\nnetworks and the functionality of using PowerShell to automatize installation\nof Aneka on remote resources. We demonstrate how an application composed of\nindependent tasks improves its total execution time when it is deployed in the\nmulti-cloud environment created by Aneka using resources provisioned from Azure\nand EC2.\n", "versions": [{"version": "v1", "created": "Sat, 28 Nov 2015 01:06:11 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Buyya", "Rajkumar", ""], ["Barreto", "Diana", ""]]}, {"id": "1511.08986", "submitter": "Rajkumar Buyya", "authors": "Sukhpal Singh, Inderveer Chana and Rajkumar Buyya", "title": "Agri-Info: Cloud Based Autonomic System for Delivering Agriculture as a\n  Service", "comments": "31 pages, 28 figures", "journal-ref": null, "doi": null, "report-no": "Technical Report CLOUDS-TR-2015-2, Cloud Computing and Distributed\n  Systems Laboratory, The University of Melbourne, Nov. 27, 2015", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has emerged as an important paradigm for managing and\ndelivering services efficiently over the Internet. Convergence of cloud\ncomputing with technologies such as wireless sensor networking and mobile\ncomputing offers new applications of cloud services but this requires\nmanagement of Quality of Service (QoS) parameters to efficiently monitor and\nmeasure the delivered services. This paper presents a QoS-aware Cloud Based\nAutonomic Information System for delivering agriculture related information as\na service through the use of latest Cloud technologies which manage various\ntypes of agriculture related data based on different domains. Proposed system\ngathers information from various users through preconfigured devices and\nmanages and provides required information to users automatically. Further,\nCuckoo Optimization Algorithm has been used for efficient resource allocation\nat infrastructure level for effective utilization of resources. We have\nevaluated the performance of the proposed approach in Cloud environment and\nexperimental results show that the proposed system performs better in terms of\nresource utilization, execution time, cost and computing capacity along with\nother QoS parameters.\n", "versions": [{"version": "v1", "created": "Sun, 29 Nov 2015 09:51:36 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Singh", "Sukhpal", ""], ["Chana", "Inderveer", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1511.09325", "submitter": "Pier Stanislao Paolucci", "authors": "Elena Pastorelli, Pier Stanislao Paolucci, Roberto Ammendola, Andrea\n  Biagioni, Ottorino Frezza, Francesca Lo Cicero, Alessandro Lonardo, Michele\n  Martinelli, Francesco Simula, Piero Vicini", "title": "Scaling to 1024 software processes and hardware cores of the distributed\n  simulation of a spiking neural network including up to 20G synapses", "comments": "6 pages, 4 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC q-bio.NC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This short report describes the scaling, up to 1024 software processes and\nhardware cores, of a distributed simulator of plastic spiking neural networks.\nA previous report demonstrated good scalability of the simulator up to 128\nprocesses. Herein we extend the speed-up measurements and strong and weak\nscaling analysis of the simulator to the range between 1 and 1024 software\nprocesses and hardware cores. We simulated two-dimensional grids of cortical\ncolumns including up to ~20G synapses connecting ~11M neurons. The neural\nnetwork was distributed over a set of MPI processes and the simulations were\nrun on a server platform composed of up to 64 dual-socket nodes, each socket\nequipped with Intel Haswell E5-2630 v3 processors (8 cores @ 2.4 GHz clock).\nAll nodes are interconned through an InfiniBand network. The DPSNN simulator\nhas been developed by INFN in the framework of EURETILE and CORTICONIC European\nFET Project and will be used by the WaveScalEW tem in the framework of the\nHuman Brain Project (HBP), SubProject 2 - Cognitive and Systems Neuroscience.\nThis report lays the groundwork for a more thorough comparison with the neural\nsimulation tool NEST.\n", "versions": [{"version": "v1", "created": "Mon, 30 Nov 2015 14:30:42 GMT"}], "update_date": "2015-12-01", "authors_parsed": [["Pastorelli", "Elena", ""], ["Paolucci", "Pier Stanislao", ""], ["Ammendola", "Roberto", ""], ["Biagioni", "Andrea", ""], ["Frezza", "Ottorino", ""], ["Cicero", "Francesca Lo", ""], ["Lonardo", "Alessandro", ""], ["Martinelli", "Michele", ""], ["Simula", "Francesco", ""], ["Vicini", "Piero", ""]]}]