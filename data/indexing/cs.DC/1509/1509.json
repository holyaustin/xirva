[{"id": "1509.00040", "submitter": "Kentaro Sano", "authors": "Kentaro Sano", "title": "DSL-based Design Space Exploration for Temporal and Spatial Parallelism\n  of Custom Stream Computing", "comments": "Presented at Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015) (arXiv:1508.06320)", "journal-ref": null, "doi": null, "report-no": "FSP/2015/06", "categories": "cs.AR cs.CE cs.DC cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stream computation is one of the approaches suitable for FPGA-based custom\ncomputing due to its high throughput capability brought by pipelining with\nregular memory access. To increase performance of iterative stream computation,\nwe can exploit both temporal and spatial parallelism by deepening and\nduplicating pipelines, respectively. However, the performance is constrained by\nseveral factors including available hardware resources on FPGA, an external\nmemory bandwidth, and utilization of pipeline stages, and therefore we need to\nfind the best mix of the different parallelism to achieve the highest\nperformance per power. In this paper, we present a domain-specific language\n(DSL) based design space exploration for temporally and/or spatially parallel\nstream computation with FPGA. We define a DSL where we can easily design a\nhierarchical structure of parallel stream computation with abstract description\nof computation. For iterative stream computation of fluid dynamics simulation,\nwe design hardware structures with a different mix of the temporal and spatial\nparallelism. By measuring the performance and the power consumption, we find\nthe best among them.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 12:23:57 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Sano", "Kentaro", ""]]}, {"id": "1509.00042", "submitter": "Hayden Kwok-Hay So", "authors": "Cheng Liu, Ho-Cheung Ng, Hayden Kwok-Hay So", "title": "Automatic Nested Loop Acceleration on FPGAs Using Soft CGRA Overlay", "comments": "Presented at Second International Workshop on FPGAs for Software\n  Programmers (FSP 2015) (arXiv:1508.06320)", "journal-ref": null, "doi": null, "report-no": "FSP/2015/03", "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Offloading compute intensive nested loops to execute on FPGA accelerators\nhave been demonstrated by numerous researchers as an effective performance\nenhancement technique across numerous application domains. To construct such\naccelerators with high design productivity, researchers have increasingly\nturned to the use of overlay architectures as an intermediate generation target\nbuilt on top of off-the-shelf FPGAs. However, achieving the desired\nperformance-overhead trade-off remains a major productivity challenge as\ncomplex application-specific customizations over a large design space covering\nmultiple architectural parameters are needed.\n  In this work, an automatic nested loop acceleration framework utilizing a\nregular soft coarse-grained reconfigurable array (SCGRA) overlay is presented.\nGiven high-level resource constraints, the framework automatically customizes\nthe overlay architectural design parameters, high-level compilation options as\nwell as communication between the accelerator and the host processor for\noptimized performance specifically to the given application. In our\nexperiments, at a cost of 10 to 20 minutes additional tools run time, the\nproposed customization process resulted in up to 5 times additional speedup\nover a baseline accelerator generated by the same framework without\ncustomization. Overall, when compared to the equivalent software running on the\nhost ARM processor alone on the Zedboard, the resulting accelerators achieved\nup to 10 times speedup.\n", "versions": [{"version": "v1", "created": "Thu, 27 Aug 2015 11:50:30 GMT"}], "update_date": "2015-09-02", "authors_parsed": [["Liu", "Cheng", ""], ["Ng", "Ho-Cheung", ""], ["So", "Hayden Kwok-Hay", ""]]}, {"id": "1509.00095", "submitter": "Li Chen", "authors": "Li Chen, Pooja Jain, Kingsum Chow, Emad Guirguis, Tony Wu", "title": "Brewing Analytics Quality for Cloud Performance", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has become increasingly popular. Many options of cloud\ndeployments are available. Testing cloud performance would enable us to choose\na cloud deployment based on the requirements. In this paper, we present an\ninnovative process, implemented in software, to allow us to assess the quality\nof the cloud performance data. The process combines performance data from\nmultiple machines, spanning across user experience data, workload performance\nmetrics, and readily available system performance data. Furthermore, we discuss\nthe major challenges of bringing raw data into tidy data formats in order to\nenable subsequent analysis, and describe how our process has several layers of\nassessment to validate the quality of the data processing procedure. We present\na case study to demonstrate the effectiveness of our proposed process, and\nconclude our paper with several future research directions worth investigating.\n", "versions": [{"version": "v1", "created": "Mon, 31 Aug 2015 23:55:54 GMT"}], "update_date": "2015-09-03", "authors_parsed": [["Chen", "Li", ""], ["Jain", "Pooja", ""], ["Chow", "Kingsum", ""], ["Guirguis", "Emad", ""], ["Wu", "Tony", ""]]}, {"id": "1509.00309", "submitter": "Edward Valeev", "authors": "Justus A. Calvin, Cannada A. Lewis, and Edward F. Valeev", "title": "Scalable Task-Based Algorithm for Multiplication of Block-Rank-Sparse\n  Matrices", "comments": "8 pages, 6 figures, accepted to IA3 2015. arXiv admin note: text\n  overlap with arXiv:1504.05046", "journal-ref": null, "doi": "10.1145/2833179.2833186", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A task-based formulation of Scalable Universal Matrix Multiplication\nAlgorithm (SUMMA), a popular algorithm for matrix multiplication (MM), is\napplied to the multiplication of hierarchy-free, rank-structured matrices that\nappear in the domain of quantum chemistry (QC). The novel features of our\nformulation are: (1) concurrent scheduling of multiple SUMMA iterations, and\n(2) fine-grained task-based composition. These features make it tolerant of the\nload imbalance due to the irregular matrix structure and eliminate all\nartifactual sources of global synchronization.Scalability of iterative\ncomputation of square-root inverse of block-rank-sparse QC matrices is\ndemonstrated; for full-rank (dense) matrices the performance of our SUMMA\nformulation usually exceeds that of the state-of-the-art dense MM\nimplementations (ScaLAPACK and Cyclops Tensor Framework).\n", "versions": [{"version": "v1", "created": "Tue, 1 Sep 2015 14:22:38 GMT"}, {"version": "v2", "created": "Fri, 9 Oct 2015 21:29:08 GMT"}], "update_date": "2015-10-13", "authors_parsed": [["Calvin", "Justus A.", ""], ["Lewis", "Cannada A.", ""], ["Valeev", "Edward F.", ""]]}, {"id": "1509.00773", "submitter": "Alina S\\^irbu", "authors": "Alkida Balliu, Dennis Olivetti, Ozalp Babaoglu, Moreno Marzolla, Alina\n  S\\^irbu", "title": "A Big Data Analyzer for Large Trace Logs", "comments": "26 pages, 10 figures", "journal-ref": "Computing, 98(12), Dec 2016, pp. 1225-1249", "doi": "10.1007/s00607-015-0480-7", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Current generation of Internet-based services are typically hosted on large\ndata centers that take the form of warehouse-size structures housing tens of\nthousands of servers. Continued availability of a modern data center is the\nresult of a complex orchestration among many internal and external actors\nincluding computing hardware, multiple layers of intricate software, networking\nand storage devices, electrical power and cooling plants. During the course of\ntheir operation, many of these components produce large amounts of data in the\nform of event and error logs that are essential not only for identifying and\nresolving problems but also for improving data center efficiency and\nmanagement. Most of these activities would benefit significantly from data\nanalytics techniques to exploit hidden statistical patterns and correlations\nthat may be present in the data. The sheer volume of data to be analyzed makes\nuncovering these correlations and patterns a challenging task. This paper\npresents BiDAl, a prototype Java tool for log-data analysis that incorporates\nseveral Big Data technologies in order to simplify the task of extracting\ninformation from data traces produced by large clusters and server farms. BiDAl\nprovides the user with several analysis languages (SQL, R and Hadoop MapReduce)\nand storage backends (HDFS and SQLite) that can be freely mixed and matched so\nthat a custom tool for a specific task can be easily constructed. BiDAl has a\nmodular architecture so that it can be extended with other backends and\nanalysis languages in the future. In this paper we present the design of BiDAl\nand describe our experience using it to analyze publicly-available traces from\nGoogle data clusters, with the goal of building a realistic model of a complex\ndata center.\n", "versions": [{"version": "v1", "created": "Wed, 2 Sep 2015 16:24:04 GMT"}], "update_date": "2018-10-10", "authors_parsed": [["Balliu", "Alkida", ""], ["Olivetti", "Dennis", ""], ["Babaoglu", "Ozalp", ""], ["Marzolla", "Moreno", ""], ["S\u00eerbu", "Alina", ""]]}, {"id": "1509.01040", "submitter": "Ibrahim Adeyanju", "authors": "Ibrahim Adeyanju", "title": "Building a Truly Distributed Constraint Solver with JADE", "comments": "7 pages", "journal-ref": "International Journal of Computer Applications (IJCA) 46 (8)\n  (2012) 5-7", "doi": null, "report-no": null, "categories": "cs.AI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real life problems such as scheduling meeting between people at different\nlocations can be modelled as distributed Constraint Satisfaction Problems\n(CSPs). Suitable and satisfactory solutions can then be found using constraint\nsatisfaction algorithms which can be exhaustive (backtracking) or otherwise\n(local search). However, most research in this area tested their algorithms by\nsimulation on a single PC with a single program entry point. The main\ncontribution of our work is the design and implementation of a truly\ndistributed constraint solver based on a local search algorithm using Java\nAgent DEvelopment framework (JADE) to enable communication between agents on\ndifferent machines. Particularly, we discuss design and implementation issues\nrelated to truly distributed constraint solver which might not be critical when\nsimulated on a single machine. Evaluation results indicate that our truly\ndistributed constraint solver works well within the observed limitations when\ntested with various distributed CSPs. Our application can also incorporate any\nconstraint solving algorithm with little modifications.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 11:41:45 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Adeyanju", "Ibrahim", ""]]}, {"id": "1509.01149", "submitter": "Grady Williams", "authors": "Grady Williams, Andrew Aldrich, Evangelos Theodorou", "title": "Model Predictive Path Integral Control using Covariance Variable\n  Importance Sampling", "comments": "8 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC cs.RO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we develop a Model Predictive Path Integral (MPPI) control\nalgorithm based on a generalized importance sampling scheme and perform\nparallel optimization via sampling using a Graphics Processing Unit (GPU). The\nproposed generalized importance sampling scheme allows for changes in the drift\nand diffusion terms of stochastic diffusion processes and plays a significant\nrole in the performance of the model predictive control algorithm. We compare\nthe proposed algorithm in simulation with a model predictive control version of\ndifferential dynamic programming.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 16:18:30 GMT"}, {"version": "v2", "created": "Fri, 4 Sep 2015 13:10:55 GMT"}, {"version": "v3", "created": "Wed, 28 Oct 2015 13:23:51 GMT"}], "update_date": "2015-10-29", "authors_parsed": [["Williams", "Grady", ""], ["Aldrich", "Andrew", ""], ["Theodorou", "Evangelos", ""]]}, {"id": "1509.01183", "submitter": "Miao Fan", "authors": "Miao Fan, Qiang Zhou, Thomas Fang Zheng and Ralph Grishman", "title": "Parallel Knowledge Embedding with MapReduce on a Multi-core Processor", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article firstly attempts to explore parallel algorithms of learning\ndistributed representations for both entities and relations in large-scale\nknowledge repositories with {\\it MapReduce} programming model on a multi-core\nprocessor. We accelerate the training progress of a canonical knowledge\nembedding method, i.e. {\\it translating embedding} ({\\bf TransE}) model, by\ndividing a whole knowledge repository into several balanced subsets, and\nfeeding each subset into an individual core where local embeddings can\nconcurrently run updating during the {\\it Map} phase. However, it usually\nsuffers from inconsistent low-dimensional vector representations of the same\nkey, which are collected from different {\\it Map} workers, and further leads to\nconflicts when conducting {\\it Reduce} to merge the various vectors associated\nwith the same key. Therefore, we try several strategies to acquire the merged\nembeddings which may not only retain the performance of {\\it entity inference},\n{\\it relation prediction}, and even {\\it triplet classification} evaluated by\nthe single-thread {\\bf TransE} on several well-known knowledge bases such as\nFreebase and NELL, but also scale up the learning speed along with the number\nof cores within a processor. So far, the empirical studies show that we could\nachieve comparable results as the single-thread {\\bf TransE} performs by the\n{\\it stochastic gradient descend} (SGD) algorithm, as well as increase the\ntraining speed multiple times via adapting the {\\it batch gradient descend}\n(BGD) algorithm for {\\it MapReduce} paradigm.\n", "versions": [{"version": "v1", "created": "Thu, 3 Sep 2015 17:53:24 GMT"}], "update_date": "2015-09-04", "authors_parsed": [["Fan", "Miao", ""], ["Zhou", "Qiang", ""], ["Zheng", "Thomas Fang", ""], ["Grishman", "Ralph", ""]]}, {"id": "1509.01330", "submitter": "Amina Mseddi", "authors": "Amina Mseddi, Mohammad Ali Salahuddin, Mohamed Faten Zhani, Halima\n  Elbiaze, Roch H. Glitho", "title": "On Optimizing Replica Migration in Distributed Cloud Storage Systems", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the wide adoption of large-scale Internet services and big data, the\ncloud has become the ideal environment to satisfy the ever-growing storage\ndemand, thanks to its seemingly limitless capacity, high availability and\nfaster access time. In this context, data replication has been touted as the\nultimate solution to improve data availability and reduce access time. However,\nreplica placement systems usually need to migrate and create a large number of\ndata replicas over time between and within data centers, incurring a large\noverhead in terms of network load and availability. In this paper, we propose\nCRANE, an effiCient Replica migrAtion scheme for distributed cloud Storage\nsystEms. CRANE complements any replica placement algorithm by efficiently\nmanaging replica creation in geo-distributed infrastructures by (1) minimizing\nthe time needed to copy the data to the new replica location, (2) avoiding\nnetwork congestion, and (3) ensuring a minimal availability of the data. Our\nresults show that, compared to swift (the OpenStack project for managing data\nstorage), CRANE is able to minimize up to 30% of the replica creation time and\n25% of inter-data center network traffic, while ensuring the minimum required\navailability of the data.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 02:21:30 GMT"}], "update_date": "2015-09-07", "authors_parsed": [["Mseddi", "Amina", ""], ["Salahuddin", "Mohammad Ali", ""], ["Zhani", "Mohamed Faten", ""], ["Elbiaze", "Halima", ""], ["Glitho", "Roch H.", ""]]}, {"id": "1509.01331", "submitter": "Rajkumar Buyya", "authors": "Raghavendra Kune, Pramodkumar Konugurthi, Arun Agarwal, Raghavendra\n  Rao Chillarige, and Rajkumar Buyya", "title": "The Anatomy of Big Data Computing", "comments": "33 pages, 11 figures, 5 tables. Appears in Software: Practice and\n  Experience (SPE), Wiley Press, 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Advances in information technology and its widespread growth in several areas\nof business, engineering, medical and scientific studies are resulting in\ninformation/data explosion. Knowledge discovery and decision making from such\nrapidly growing voluminous data is a challenging task in terms of data\norganization and processing, which is an emerging trend known as Big Data\nComputing; a new paradigm which combines large scale compute, new data\nintensive techniques and mathematical models to build data analytics. Big Data\ncomputing demands a huge storage and computing for data curation and processing\nthat could be delivered from on-premise or clouds infrastructures. This paper\ndiscusses the evolution of Big Data computing, differences between traditional\ndata warehousing and Big Data, taxonomy of Big Data computing and underpinning\ntechnologies, integrated platform of Big Data and Clouds known as Big Data\nClouds, layered architecture and components of Big Data Cloud and finally\ndiscusses open technical challenges and future directions.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 02:34:39 GMT"}], "update_date": "2015-09-07", "authors_parsed": [["Kune", "Raghavendra", ""], ["Konugurthi", "Pramodkumar", ""], ["Agarwal", "Arun", ""], ["Chillarige", "Raghavendra Rao", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1509.01352", "submitter": "Rangeet Mitra", "authors": "Rangeet Mitra and Vimal Bhatia", "title": "Diffusion-KLMS Algorithm and its Performance Analysis for Non-Linear\n  Distributed Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.LG cs.DC cs.IT cs.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a distributed network environment, the diffusion-least mean squares (LMS)\nalgorithm gives faster convergence than the original LMS algorithm. It has also\nbeen observed that, the diffusion-LMS generally outperforms other distributed\nLMS algorithms like spatial LMS and incremental LMS. However, both the original\nLMS and diffusion-LMS are not applicable in non-linear environments where data\nmay not be linearly separable. A variant of LMS called kernel-LMS (KLMS) has\nbeen proposed in the literature for such non-linearities. In this paper, we\npropose kernelised version of diffusion-LMS for non-linear distributed\nenvironments. Simulations show that the proposed approach has superior\nconvergence as compared to algorithms of the same genre. We also introduce a\ntechnique to predict the transient and steady-state behaviour of the proposed\nalgorithm. The techniques proposed in this work (or algorithms of same genre)\ncan be easily extended to distributed parameter estimation applications like\ncooperative spectrum sensing and massive multiple input multiple output (MIMO)\nreceiver design which are potential components for 5G communication systems.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 06:48:39 GMT"}], "update_date": "2015-09-07", "authors_parsed": [["Mitra", "Rangeet", ""], ["Bhatia", "Vimal", ""]]}, {"id": "1509.01481", "submitter": "Jurgis Pods", "authors": "Jurgis Pods", "title": "A Comparison of Computational Models for the Extracellular Potential of\n  Neurons", "comments": "12 pages (incl. references), 4 figures (color)", "journal-ref": "Journal of Integrative Neuroscience, vol. 16, no. 1, pp. 19-32,\n  2017", "doi": "10.3233/JIN-170009", "report-no": null, "categories": "q-bio.NC cs.CE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The extracellular space has an ambiguous role in neuroscience. It is present\nin every physiologically relevant system and often used as a measurement site\nin experimental recordings, but it has received subordinate attention compared\nto the intracellular domain. In computational modeling, it is often regarded as\na passive, homogeneous resistive medium with a constant conductivity, which\ngreatly simplifies the computation of extracellular potentials. However, recent\nstudies have shown that local ionic diffusion and capacitive effects of\nelectrically active membranes can have a substantial impact on the\nextracellular potential. These effects can not be described by traditional\nmodels, and they have been subject to theoretical and experimental analyses. We\nstrive to give an overview over recent progress in modeling the extracellular\nspace with special regard towards the concentration and potential dynamics on\ndifferent temporal and spatial scales. Three models with distinct assumptions\nand levels of detail are compared both theoretically and by means of numerical\nsimulations: the classical volume conductor (VC) model, which is most\nfrequently used in form of the line source approximation (LSA); the very\ndetailed, but computationally intensive Poisson-Nernst-Planck model of\nelectrodiffusion (PNP); and an intermediate one called the electroneutral model\n(EN). The results clearly show that there is no one model for all applications,\nas they show significantly different responses especially close to neuronal\nmembranes. Finally, we list some common use cases for model simulations and\ngive recommendations on which model to use in each situation.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 15:01:44 GMT"}], "update_date": "2017-05-02", "authors_parsed": [["Pods", "Jurgis", ""]]}, {"id": "1509.01506", "submitter": "Sabri Pllana", "authors": "Suejb Memeti and Sabri Pllana", "title": "Analyzing large-scale DNA Sequences on Multi-core Architectures", "comments": "The 18th IEEE International Conference on Computational Science and\n  Engineering (CSE 2015), Porto, Portugal, 20 - 23 October 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Rapid analysis of DNA sequences is important in preventing the evolution of\ndifferent viruses and bacteria during an early phase, early diagnosis of\ngenetic predispositions to certain diseases (cancer, cardiovascular diseases),\nand in DNA forensics. However, real-world DNA sequences may comprise several\nGigabytes and the process of DNA analysis demands adequate computational\nresources to be completed within a reasonable time. In this paper we present a\nscalable approach for parallel DNA analysis that is based on Finite Automata,\nand which is suitable for analyzing very large DNA segments. We evaluate our\napproach for real-world DNA segments of mouse (2.7GB), cat (2.4GB), dog\n(2.4GB), chicken (1GB), human (3.2GB) and turkey (0.2GB). Experimental results\non a dual-socket shared-memory system with 24 physical cores show speed-ups of\nup to 17.6x. Our approach is up to 3x faster than a pattern-based parallel\napproach that uses the RE2 library.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 15:46:50 GMT"}], "update_date": "2015-09-07", "authors_parsed": [["Memeti", "Suejb", ""], ["Pllana", "Sabri", ""]]}, {"id": "1509.01572", "submitter": "Andreas Kreienbuehl", "authors": "Andreas Kreienbuehl and Pietro Benedusi and Daniel Ruprecht and Rolf\n  Krause", "title": "Time parallel gravitational collapse simulation", "comments": "16 pages, 8 figures, 1 listing, and 1 table", "journal-ref": "Communications in Applied Mathematics and Computational Science\n  12-1 (2017), 109--128", "doi": "10.2140/camcos.2017.12.109", "report-no": null, "categories": "gr-qc cs.CE cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This article demonstrates the applicability of the parallel-in-time method\nParareal to the numerical solution of the Einstein gravity equations for the\nspherical collapse of a massless scalar field. To account for the shrinking of\nthe spatial domain in time, a tailored load balancing scheme is proposed and\ncompared to load balancing based on number of time steps alone. The performance\nof Parareal is studied for both the sub-critical and black hole case; our\nexperiments show that Parareal generates substantial speedup and, in the\nsuper-critical regime, can reproduce Choptuik's black hole mass scaling law.\n", "versions": [{"version": "v1", "created": "Fri, 4 Sep 2015 19:32:45 GMT"}, {"version": "v2", "created": "Sun, 24 Apr 2016 19:18:58 GMT"}, {"version": "v3", "created": "Wed, 28 Dec 2016 22:06:40 GMT"}], "update_date": "2017-05-23", "authors_parsed": [["Kreienbuehl", "Andreas", ""], ["Benedusi", "Pietro", ""], ["Ruprecht", "Daniel", ""], ["Krause", "Rolf", ""]]}, {"id": "1509.01596", "submitter": "Shahrouz Khalili", "authors": "Shahrouz Khalili and Osvaldo Simeone", "title": "Inter-Layer Per-Mobile Optimization of Cloud Mobile Computing: A\n  Message-Passing Approach", "comments": "submitted", "journal-ref": "Transactions on Emerging Telecommunications Technologies, 29\n  February 2016", "doi": "10.1002/ett.3028", "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud mobile computing enables the offloading of computation-intensive\napplications from a mobile device to a cloud processor via a wireless\ninterface. In light of the strong interplay between offloading decisions at the\napplication layer and physical-layer parameters, which determine the energy and\nlatency associated with the mobile-cloud communication, this paper investigates\nthe inter-layer optimization of fine-grained task offloading across both\nlayers. In prior art, this problem was formulated, under a serial\nimplementation of processing and communication, as a mixed integer program,\nentailing a complexity that is exponential in the number of tasks. In this\nwork, instead, algorithmic solutions are proposed that leverage the structure\nof the call graphs of typical applications by means of message passing on the\ncall graph, under both serial and parallel implementations of processing and\ncommunication. For call trees, the proposed solutions have a linear complexity\nin the number of tasks, and efficient extensions are presented for more general\ncall graphs that include \"map\" and \"reduce\"-type tasks. Moreover, the proposed\nschemes are optimal for the serial implementation, and provide principled\nheuristics for the parallel implementation. Extensive numerical results yield\ninsights into the impact of inter-layer optimization and on the comparison of\nthe two implementations.\n", "versions": [{"version": "v1", "created": "Wed, 26 Aug 2015 16:39:42 GMT"}], "update_date": "2016-08-29", "authors_parsed": [["Khalili", "Shahrouz", ""], ["Simeone", "Osvaldo", ""]]}, {"id": "1509.01746", "submitter": "Alejandro Erickson", "authors": "Alejandro Erickson and Abbas Eslami Kiasari and Javier Navaridas and\n  Iain A. Stewart", "title": "An Optimal Single-Path Routing Algorithm in the Datacenter Network\n  DPillar", "comments": "Accepted in IEEE Transactions on Parallel & Distributed Systems, July\n  2016", "journal-ref": null, "doi": "10.1109/TPDS.2016.2591011", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  DPillar has recently been proposed as a server-centric datacenter network and\nis combinatorially related to (but distinct from) the well-known wrapped\nbutterfly network. We explain the relationship between DPillar and the wrapped\nbutterfly network before proving that the underlying graph of DPillar is a\nCayley graph; hence, the datacenter network DPillar is node-symmetric. We use\nthis symmetry property to establish a single-path routing algorithm for DPillar\nthat computes a shortest path and has time complexity $O(k)$, where $k$\nparameterizes the dimension of DPillar (we refer to the number of ports in its\nswitches as $n$). Our analysis also enables us to calculate the diameter of\nDPillar exactly. Moreover, our algorithm is trivial to implement, being\nessentially a conditional clause of numeric tests, and improves significantly\nupon a routing algorithm earlier employed for DPillar. Furthermore, we provide\nempirical data in order to demonstrate this improvement. In particular, we\nempirically show that our routing algorithm improves the average length of\npaths found, the aggregate bottleneck throughput, and the communication\nlatency. A secondary, yet important, effect of our work is that it emphasises\nthat datacenter networks are amenable to a closer combinatorial scrutiny that\ncan significantly improve their computational efficiency and performance.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2015 22:35:46 GMT"}, {"version": "v2", "created": "Thu, 25 Feb 2016 14:37:52 GMT"}, {"version": "v3", "created": "Sat, 16 Jul 2016 13:58:39 GMT"}], "update_date": "2016-07-19", "authors_parsed": [["Erickson", "Alejandro", ""], ["Kiasari", "Abbas Eslami", ""], ["Navaridas", "Javier", ""], ["Stewart", "Iain A.", ""]]}, {"id": "1509.01747", "submitter": "Alejandro Erickson", "authors": "Alejandro Erickson and Abbas Eslami Kiasari and Javier Navaridas and\n  Iain A. Stewart", "title": "Routing Algorithms for Recursively-Defined Data Centre Networks", "comments": "Appeared at the 13th IEEE International Symposium on Parallel and\n  Distributed Processing with Applications (IEEE ISPA-15)", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The server-centric data centre network architecture can accommodate a wide\nvariety of network topologies. Newly proposed topologies in this arena often\nrequire several rounds of analysis and experimentation in order that they might\nachieve their full potential as data centre networks. We propose a family of\nnovel routing algorithms on two well-known data centre networks of this type,\n(Generalized) DCell and FiConn, using techniques that can be applied more\ngenerally to the class of networks we call completely connected\nrecursively-defined networks. In doing so, we develop a classification of all\npossible routes from server-node to server-node on these networks, called\ngeneral routes of order $t$, and find that for certain topologies of interest,\nour routing algorithms efficiently produce paths that are up to 16% shorter\nthan the best previously known algorithms, and are comparable to shortest\npaths. In addition to finding shorter paths, we show evidence that our\nalgorithms also have good load-balancing properties.\n", "versions": [{"version": "v1", "created": "Sat, 5 Sep 2015 22:40:58 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Erickson", "Alejandro", ""], ["Kiasari", "Abbas Eslami", ""], ["Navaridas", "Javier", ""], ["Stewart", "Iain A.", ""]]}, {"id": "1509.01858", "submitter": "Preetum Nakkiran", "authors": "Preetum Nakkiran, K.V. Rashmi, Kannan Ramchandran", "title": "Optimal Systematic Distributed Storage Codes with Fast Encoding", "comments": "16 pages, 4 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.NI math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Erasure codes are being increasingly used in distributed-storage systems in\nplace of data-replication, since they provide the same level of reliability\nwith much lower storage overhead. We consider the problem of constructing\nexplicit erasure codes for distributed storage with the following desirable\nproperties motivated by practice: (i) Maximum-Distance-Separable (MDS): to\nprovide maximal reliability at minimum storage overhead, (ii) Optimal\nrepair-bandwidth: to minimize the amount of data needed to be transferred to\nrepair a failed node from remaining ones, (iii) Flexibility in repair: to allow\nmaximal flexibility in selecting subset of nodes to use for repair, which\nincludes not requiring that all surviving nodes be used for repair, (iv)\nSystematic Form: to ensure that the original data exists in uncoded form, and\n(v) Fast encoding: to minimize the cost of generating encoded data (enabled by\na sparse generator matrix).\n  This paper presents the first explicit code construction which theoretically\nguarantees all the five desired properties simultaneously. Our construction\nbuilds on a powerful class of codes called Product-Matrix (PM) codes. PM codes\nsatisfy properties (i)-(iii), and either (iv) or (v), but not both\nsimultaneously. Indeed, native PM codes have inherent structure that leads to\nsparsity, but this structure is destroyed when the codes are made systematic.\nWe first present an analytical framework for understanding the interaction\nbetween the design of PM codes and the systematic property. Using this\nframework, we provide an explicit code construction that simultaneously\nachieves all the above desired properties. We also present general ways of\ntransforming existing storage and repair optimal codes to enable fast encoding\nthrough sparsity. In practice, such sparse codes result in encoding speedup by\na factor of about 4 for typical parameters.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2015 21:43:03 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Nakkiran", "Preetum", ""], ["Rashmi", "K. V.", ""], ["Ramchandran", "Kannan", ""]]}, {"id": "1509.01864", "submitter": "Lili Su", "authors": "Lili Su, Nitin Vaidya", "title": "Fault-Tolerant Multi-Agent Optimization: Part III", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.OC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study fault-tolerant distributed optimization of a sum of convex (cost)\nfunctions with real-valued scalar input/output in the presence of crash faults\nor Byzantine faults. In particular, the goal is to optimize a global cost\nfunction $\\frac{1}{n}\\sum_{i\\in \\mathcal{V}} h_i(x)$, where $\\mathcal{V}=\\{1,\n\\ldots, n\\}$ is the collection of agents, and $h_i(x)$ is agent $i$'s local\ncost function, which is initially known only to agent $i$. Since the above\nglobal cost function cannot be optimized exactly in presence of crash faults or\nByzantine faults, we define two weaker versions of the problem for crash faults\nand Byzantine faults, respectively.\n  When some agents may crash, the goal for the weaker problem is to generate an\noutput that is an optimum of a function formed as $$C(\\sum_{i\\in \\mathcal{N}}\nh_i(x)+\\sum_{i\\in \\mathcal{F}} \\alpha_i h_i(x)),$$ where $\\mathcal{N}$ is the\nset of non-faulty agents, $\\mathcal{F}$ is the set of faulty agents (crashed\nagents), $0\\le \\alpha_i\\le 1$ for each $i\\in \\mathcal{F}$ and $C$ is a\nnormalization constant such that $C(|\\mathcal{N}|+\\sum_{i\\in \\mathcal{F}}\n\\alpha_i)=1$. We present an iterative algorithm in which each agent only needs\nto perform local computation, and send one message per iteration.\n  When some agents may be Byzantine, the system cannot take full advantage of\nthe data kept by non-faulty agents. The goal for the associated weaker problem\nis to generate an output that is an optimum of a function formed as\n$$\\sum_{i\\in \\mathcal{N}}\\alpha_i h_i(x),$$ such that $\\alpha_i\\geq 0$ for each\n$i\\in \\mathcal{N}$ and $\\sum_{i\\in \\mathcal{N}}\\alpha_i=1$. We present an\niterative algorithm, where only local computation is needed and only one\nmessage per agent is sent in each iteration, that ensures that at least\n$|\\mathcal{N}|-f$ agents have weights ($\\alpha_i$'s) that are lower bounded by\n$\\frac{1}{2(|\\mathcal{N}|-f)}$.\n", "versions": [{"version": "v1", "created": "Sun, 6 Sep 2015 23:07:36 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Su", "Lili", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1509.02058", "submitter": "Francisco Igual", "authors": "Luis Costero and Francisco D. Igual and Katzalin Olcoz and Enrique S.\n  Quintana-Ort\\'i", "title": "Revisiting Conventional Task Schedulers to Exploit Asymmetry in ARM\n  big.LITTLE Architectures for Dense Linear Algebra", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Dealing with asymmetry in the architecture opens a plethora of questions from\nthe perspective of scheduling task-parallel applications, and there exist early\nattempts to address this problem via ad-hoc strategies embedded into a runtime\nframework. In this paper we take a different path, which consists in addressing\nthe complexity of the problem at the library level, via a few asymmetry-aware\nfundamental kernels, hiding the architecture heterogeneity from the task\nscheduler. For the specific domain of dense linear algebra, we show that this\nis not only possible but delivers much higher performance than a naive approach\nbased on an asymmetry-oblivious scheduler. Furthermore, this solution also\noutperforms an ad-hoc asymmetry-aware scheduler furnished with sophisticated\nscheduling techniques.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 14:26:58 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Costero", "Luis", ""], ["Igual", "Francisco D.", ""], ["Olcoz", "Katzalin", ""], ["Quintana-Ort\u00ed", "Enrique S.", ""]]}, {"id": "1509.02099", "submitter": "Francois Marmier", "authors": "Jacques Lamothe (Mines Albi-Carmaux), Fran\\c{c}ois Marmier (Mines\n  Albi-Carmaux), Matthieu Dupuy (Mines Albi-Carmaux), Paul Gaborit (Mines\n  Albi-Carmaux), Lionel Dupont (Mines Albi-Carmaux)", "title": "Scheduling rules to minimize total tardiness in a parallel machine\n  problem with setup and calendar constraints", "comments": null, "journal-ref": "Computers and Operations Research, 2012, 39 (6), pp.1236-1244.", "doi": "10.1016/j.cor.2010.07.007", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quality control lead times are one of most significant causes of loss of time\nin the pharmaceutical and cosmetics industries. This is partly due to the\norganization of laboratories that feature parallel multipurpose machines for\nchromatographic analyses. The testing process requires long setup times and\noperators are needed to launch the process. The various controls are\nnon-preemptive and are characterized by a release date, a due date and\navailable routings. These quality processes lead to significant delays, and we\ntherefore evaluate the total tardiness criterion. Previous heuristics were\ndefined for the total tardiness criterion, parallel machines, and setup such as\nATC (Apparent Tardiness Cost) and ATCS (ATC with setups). We propose new rules\nand a simulated annealing procedure in order to minimize total tardiness.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 15:56:57 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Lamothe", "Jacques", "", "Mines Albi-Carmaux"], ["Marmier", "Fran\u00e7ois", "", "Mines\n  Albi-Carmaux"], ["Dupuy", "Matthieu", "", "Mines Albi-Carmaux"], ["Gaborit", "Paul", "", "Mines\n  Albi-Carmaux"], ["Dupont", "Lionel", "", "Mines Albi-Carmaux"]]}, {"id": "1509.02135", "submitter": "Gary Lawson Jr", "authors": "Gary Lawson, Vaibhav Sundriyal, Masha Sosonkina, Yuzhong Shen", "title": "Experimentation Procedure for Offloaded Mini-Apps Executed on Cluster\n  Architectures with Xeon Phi Accelerators", "comments": "Complete, but references are a mess", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A heterogeneous cluster architecture is complex. It contains hundreds, or\nthousands of devices connected by a tiered communication system in order to\nsolve a problem. As a heterogeneous system, these devices will have varying\nperformance capabilities. To better understand the interactions which occur\nbetween the various devices during execution, an experimentation procedure has\nbeen devised to capture, store, and analyze important and meaningful data. The\nprocedure consists of various tools, techniques, and methods for capturing\nrelevant timing, power, and performance data for a typical execution. This\nprocedure currently applies to architectures with Intel Xeon processors and\nIntel Xeon Phi accelerators. It has been applied to the Co-Design Molecular\nDynamics mini-app, courtesy of the ExMatEx team. This work aims to provide\nend-users with a strategy for investigating codes executed on heterogeneous\ncluster architectures with Xeon Phi accelerators.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 17:44:02 GMT"}, {"version": "v2", "created": "Mon, 14 Sep 2015 21:44:29 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Lawson", "Gary", ""], ["Sundriyal", "Vaibhav", ""], ["Sosonkina", "Masha", ""], ["Shen", "Yuzhong", ""]]}, {"id": "1509.02140", "submitter": "Miguel Mosteiro", "authors": "Alessia Milani and Miguel A. Mosteiro", "title": "A Faster Counting Protocol for Anonymous Dynamic Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the problem of counting the number of nodes in a slotted-time\ncommunication network, under the challenging assumption that nodes do not have\nidentifiers and the network topology changes frequently. That is, for each time\nslot links among nodes can change arbitrarily provided that the network is\nalways connected. Tolerating dynamic topologies is crucial in face of mobility\nand unreliable communication whereas, even if identifiers are available, it\nmight be convenient to ignore them in massive networks with changing topology.\nCounting is a fundamental task in distributed computing since knowing the size\nof the system often facilitates the design of solutions for more complex\nproblems. Currently, the best upper bound proved on the running time to compute\nthe exact network size is double-exponential. However, only linear complexity\nlower bounds are known, leaving open the question of whether efficient Counting\nprotocols for Anonymous Dynamic Networks exist or not. In this paper we make a\nsignificant step towards answering this question by presenting a distributed\nCounting protocol for Anonymous Dynamic Networks which has exponential time\ncomplexity. Our algorithm ensures that eventually every node knows the exact\nsize of the system and stops executing the algorithm. Previous Counting\nprotocols have either double-exponential time complexity, or they are\nexponential but do not terminate, or terminate but do not provide running-time\nguarantees, or guarantee only an exponential upper bound on the network size.\nOther protocols are heuristic and do not guarantee the correct count.\n", "versions": [{"version": "v1", "created": "Mon, 7 Sep 2015 18:46:18 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["Milani", "Alessia", ""], ["Mosteiro", "Miguel A.", ""]]}, {"id": "1509.02256", "submitter": "Reza Bosagh Zadeh", "authors": "Reza Bosagh Zadeh, Xiangrui Meng, Aaron Staple, Burak Yavuz, Li Pu,\n  Shivaram Venkataraman, Evan Sparks, Alexander Ulanov, Matei Zaharia", "title": "Matrix Computations and Optimization in Apache Spark", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  We describe matrix computations available in the cluster programming\nframework, Apache Spark. Out of the box, Spark provides abstractions and\nimplementations for distributed matrices and optimization routines using these\nmatrices. When translating single-node algorithms to run on a distributed\ncluster, we observe that often a simple idea is enough: separating matrix\noperations from vector operations and shipping the matrix operations to be ran\non the cluster, while keeping vector operations local to the driver. In the\ncase of the Singular Value Decomposition, by taking this idea to an extreme, we\nare able to exploit the computational power of a cluster, while running code\nwritten decades ago for a single core. Another example is our Spark port of the\npopular TFOCS optimization package, originally built for MATLAB, which allows\nfor solving Linear programs as well as a variety of other convex programs. We\nconclude with a comprehensive set of benchmarks for hardware accelerated matrix\ncomputations from the JVM, which is interesting in its own right, as many\ncluster programming frameworks use the JVM. The contributions described in this\npaper are already merged into Apache Spark and available on Spark installations\nby default, and commercially supported by a slew of companies which provide\nfurther services.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 05:33:39 GMT"}, {"version": "v2", "created": "Wed, 30 Dec 2015 23:56:34 GMT"}, {"version": "v3", "created": "Wed, 13 Jul 2016 02:22:57 GMT"}], "update_date": "2016-07-14", "authors_parsed": [["Zadeh", "Reza Bosagh", ""], ["Meng", "Xiangrui", ""], ["Staple", "Aaron", ""], ["Yavuz", "Burak", ""], ["Pu", "Li", ""], ["Venkataraman", "Shivaram", ""], ["Sparks", "Evan", ""], ["Ulanov", "Alexander", ""], ["Zaharia", "Matei", ""]]}, {"id": "1509.02308", "submitter": "Xinxin Mei Ms", "authors": "Xinxin Mei and Xiaowen Chu", "title": "Dissecting GPU Memory Hierarchy through Microbenchmarking", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Memory access efficiency is a key factor in fully utilizing the computational\npower of graphics processing units (GPUs). However, many details of the GPU\nmemory hierarchy are not released by GPU vendors. In this paper, we propose a\nnovel fine-grained microbenchmarking approach and apply it to three generations\nof NVIDIA GPUs, namely Fermi, Kepler and Maxwell, to expose the previously\nunknown characteristics of their memory hierarchies. Specifically, we\ninvestigate the structures of different GPU cache systems, such as the data\ncache, the texture cache and the translation look-aside buffer (TLB). We also\ninvestigate the throughput and access latency of GPU global memory and shared\nmemory. Our microbenchmark results offer a better understanding of the\nmysterious GPU memory hierarchy, which will facilitate the software\noptimization and modelling of GPU architectures. To the best of our knowledge,\nthis is the first study to reveal the cache properties of Kepler and Maxwell\nGPUs, and the superiority of Maxwell in shared memory performance under bank\nconflict.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 10:13:02 GMT"}, {"version": "v2", "created": "Mon, 14 Mar 2016 13:20:42 GMT"}], "update_date": "2016-03-15", "authors_parsed": [["Mei", "Xinxin", ""], ["Chu", "Xiaowen", ""]]}, {"id": "1509.02400", "submitter": "Pooyan Abouzar", "authors": "Pooyan Abouzar, David G. Michelson, and Maziyar Hamdi", "title": "RSSI-Based Distributed Self-Localization for Wireless Sensor Networks\n  used in Precision Agriculture", "comments": "23 pages, 11 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Node localization algorithms that can be easily integrated into deployed\nwireless sensor networks (WSNs) and which run seamlessly with proprietary lower\nlayer communication protocols running on off-the-shelf modules can help\noperators of large farms and orchards avoid the difficulty, cost and/or time\ninvolved with manual or satellite-based node localization techniques. Even\nthough the state-of-the-art node localization algorithms can achieve low error\nrates using distributed techniques such as belief propagation (BP), they are\nnot well suited to WSNs deployed for precision agriculture applications with\nlarge number of nodes, few number of landmarks and lack real time update\ncapability. The algorithm proposed here is designed for applications such as\npest control and irrigation in large farms and orchards where greater power\nefficiency and scalability are required but location accuracy requirements are\nless demanding. Our algorithm uses received signal strength indicator (RSSI)\nvalues to estimate the distribution of distance between nodes then updates the\nlocation probability mass function (pmf) of nodes in a distributed manner. At\nevery time step, the most recently communicated path loss samples and location\nprior pmf received from neighbouring nodes is sufficient for nodes with unknown\nlocation to update their location pmf. This renders the algorithm recursive,\nhence results in lower computational complexity at each time step. We propose a\nparticular realization of the method in which only one node multicasts at each\ntime step and neighbouring nodes update their location pmf conditioned on all\ncommunicated samples over previous time steps. This is highly compatible with\nrealistic WSN deployments, e.g., ZigBee which are based upon the ad hoc\non-demand distance vector (AODV) where nodes flood route request (RREQ) and\nroute reply (RREP) packets in the network.\n", "versions": [{"version": "v1", "created": "Fri, 21 Aug 2015 21:31:05 GMT"}], "update_date": "2015-09-09", "authors_parsed": [["Abouzar", "Pooyan", ""], ["Michelson", "David G.", ""], ["Hamdi", "Maziyar", ""]]}, {"id": "1509.02464", "submitter": "Muntasir Raihan Rahman", "authors": "Muntasir Raihan Rahman, Lewis Tseng, Son Nguyen, Indranil Gupta, Nitin\n  Vaidya", "title": "Characterizing and Adapting the Consistency-Latency Tradeoff in\n  Distributed Key-value Stores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CAP theorem is a fundamental result that applies to distributed storage\nsystems. In this paper, we first present and prove two CAP-like impossibility\ntheorems. To state these theorems, we present probabilistic models to\ncharacterize the three important elements of the CAP theorem: consistency (C),\navailability or latency (A), and partition tolerance (P). The theorems show the\nun-achievable envelope, i.e., which combinations of the parameters of the three\nmodels make them impossible to achieve together. Next, we present the design of\na class of systems called PCAP that perform close to the envelope described by\nour theorems. In addition, these systems allow applications running on a single\ndata-center to specify either a latency SLA or a consistency SLA. The PCAP\nsystems automatically adapt, in real-time and under changing network\nconditions, to meet the SLA while optimizing the other C/A metric. We\nincorporate PCAP into two popular key-value stores -- Apache Cassandra and\nRiak. Our experiments with these two deployments, under realistic workloads,\nreveal that the PCAP system satisfactorily meets SLAs, and performs close to\nthe achievable envelope. We also extend PCAP from a single data-center to\nmultiple geo-distributed data-centers.\n", "versions": [{"version": "v1", "created": "Tue, 8 Sep 2015 17:46:29 GMT"}, {"version": "v2", "created": "Sat, 23 Jan 2016 18:29:02 GMT"}], "update_date": "2016-01-26", "authors_parsed": [["Rahman", "Muntasir Raihan", ""], ["Tseng", "Lewis", ""], ["Nguyen", "Son", ""], ["Gupta", "Indranil", ""], ["Vaidya", "Nitin", ""]]}, {"id": "1509.02597", "submitter": "Tsung-Hui Chang", "authors": "Tsung-Hui Chang, Mingyi Hong, Wei-Cheng Liao and Xiangfeng Wang", "title": "Asynchronous Distributed ADMM for Large-Scale Optimization- Part I:\n  Algorithm and Convergence Analysis", "comments": "37 pages", "journal-ref": null, "doi": "10.1109/TSP.2016.2537271", "report-no": null, "categories": "cs.DC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Aiming at solving large-scale learning problems, this paper studies\ndistributed optimization methods based on the alternating direction method of\nmultipliers (ADMM). By formulating the learning problem as a consensus problem,\nthe ADMM can be used to solve the consensus problem in a fully parallel fashion\nover a computer network with a star topology. However, traditional synchronized\ncomputation does not scale well with the problem size, as the speed of the\nalgorithm is limited by the slowest workers. This is particularly true in a\nheterogeneous network where the computing nodes experience different\ncomputation and communication delays. In this paper, we propose an asynchronous\ndistributed ADMM (AD-AMM) which can effectively improve the time efficiency of\ndistributed optimization. Our main interest lies in analyzing the convergence\nconditions of the AD-ADMM, under the popular partially asynchronous model,\nwhich is defined based on a maximum tolerable delay of the network.\nSpecifically, by considering general and possibly non-convex cost functions, we\nshow that the AD-ADMM is guaranteed to converge to the set of\nKarush-Kuhn-Tucker (KKT) points as long as the algorithm parameters are chosen\nappropriately according to the network delay. We further illustrate that the\nasynchrony of the ADMM has to be handled with care, as slightly modifying the\nimplementation of the AD-ADMM can jeopardize the algorithm convergence, even\nunder a standard convex setting.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 01:45:08 GMT"}, {"version": "v2", "created": "Fri, 19 Feb 2016 06:02:38 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Chang", "Tsung-Hui", ""], ["Hong", "Mingyi", ""], ["Liao", "Wei-Cheng", ""], ["Wang", "Xiangfeng", ""]]}, {"id": "1509.02604", "submitter": "Tsung-Hui Chang", "authors": "Tsung-Hui Chang, Wei-Cheng Liao, Mingyi Hong and Xiangfeng Wang", "title": "Asynchronous Distributed ADMM for Large-Scale Optimization- Part II:\n  Linear Convergence Analysis and Numerical Performance", "comments": "submitted for publication, 28 pages", "journal-ref": null, "doi": "10.1109/TSP.2016.2537261", "report-no": null, "categories": "cs.DC cs.LG cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The alternating direction method of multipliers (ADMM) has been recognized as\na versatile approach for solving modern large-scale machine learning and signal\nprocessing problems efficiently. When the data size and/or the problem\ndimension is large, a distributed version of ADMM can be used, which is capable\nof distributing the computation load and the data set to a network of computing\nnodes. Unfortunately, a direct synchronous implementation of such algorithm\ndoes not scale well with the problem size, as the algorithm speed is limited by\nthe slowest computing nodes. To address this issue, in a companion paper, we\nhave proposed an asynchronous distributed ADMM (AD-ADMM) and studied its\nworst-case convergence conditions. In this paper, we further the study by\ncharacterizing the conditions under which the AD-ADMM achieves linear\nconvergence. Our conditions as well as the resulting linear rates reveal the\nimpact that various algorithm parameters, network delay and network size have\non the algorithm performance. To demonstrate the superior time efficiency of\nthe proposed AD-ADMM, we test the AD-ADMM on a high-performance computer\ncluster by solving a large-scale logistic regression problem.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 02:07:27 GMT"}], "update_date": "2016-05-04", "authors_parsed": [["Chang", "Tsung-Hui", ""], ["Liao", "Wei-Cheng", ""], ["Hong", "Mingyi", ""], ["Wang", "Xiangfeng", ""]]}, {"id": "1509.02640", "submitter": "\\'Alvaro Garc\\'ia-Recuero", "authors": "\\'Alvaro Garc\\'ia-Recuero", "title": "On the energy efficiency of client-centric data consistency management\n  under random read/write access to Big Data with Apache HBase", "comments": "Energy and Performance Evaluation of Apache HBase", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The total estimated energy bill for data centers in 2010 was \\$11.5 billion,\nand experts estimate that the energy cost of a typical data center doubles\nevery five years. On the other hand, computational developments have started to\nlag behind storage advancements, therein becoming a future bottleneck for the\nongoing data growth which already approaches Exascale levels. We investigate\nthe relationship among data throughput and energy footprint on a large storage\ncluster, with the goal of formalizing it as a metric that reflects the trading\namong consistency and energy. Employing a client-centric consistency approach,\nand while honouring ACID properties of the chosen columnar store for the case\nstudy (Apache HBase), we present the factors involved in the energy consumption\nof the system as well as lessons learned to underpin further design of\nenergy-efficient cluster scale storage systems.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 05:44:42 GMT"}, {"version": "v2", "created": "Thu, 10 Sep 2015 10:13:39 GMT"}, {"version": "v3", "created": "Thu, 17 Sep 2015 15:24:50 GMT"}, {"version": "v4", "created": "Fri, 18 Sep 2015 09:13:23 GMT"}, {"version": "v5", "created": "Mon, 21 Sep 2015 23:56:07 GMT"}, {"version": "v6", "created": "Fri, 2 Oct 2015 07:50:05 GMT"}, {"version": "v7", "created": "Wed, 30 Nov 2016 15:06:06 GMT"}], "update_date": "2016-12-01", "authors_parsed": [["Garc\u00eda-Recuero", "\u00c1lvaro", ""]]}, {"id": "1509.02664", "submitter": "Amir Rastegarnia", "authors": "Azam Khalili, Amir Rastegarnia", "title": "Performance Analysis of Incremental LMS over Flat Fading Channels", "comments": "7 Figures, 10 pages. arXiv admin note: text overlap with\n  arXiv:1508.02108", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.IT cs.DC cs.SY math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We study the effect of fading in the communication channels between sensor\nnodes on the performance of the incremental least mean square (ILMS) algorithm,\nand derive steady state performance metrics, including the mean-square\ndeviation (MSD), excess mean-square error (EMSE) and meansquare error (MSE). We\nobtain conditions for mean convergence of the ILMS algorithm, and show that in\nthe presence of fading channels, the ILMS algorithm is asymptotically biased.\nFurthermore, the dynamic range for mean stability depends only on the mean\nchannel gain, and under simplifying technical assumptions, we show that the\nMSD, EMSE and MSE are non-decreasing functions of the channel gain variances,\nwith mean-square convergence to the steady states possible only if the channel\ngain variances are limited. We derive sufficient conditions to ensure\nmean-square convergence, and verify our results through simulations.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 07:42:26 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Khalili", "Azam", ""], ["Rastegarnia", "Amir", ""]]}, {"id": "1509.02730", "submitter": "Rangeet Mitra", "authors": "Rangeet Mitra and Vimal Bhatia", "title": "Finite Dictionary Variants of the Diffusion KLMS Algorithm", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC cs.IT cs.LG math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The diffusion based distributed learning approaches have been found to be a\nviable solution for learning over linearly separable datasets over a network.\nHowever, approaches till date are suitable for linearly separable datasets and\nneed to be extended to scenarios in which we need to learn a non-linearity. In\nsuch scenarios, the recently proposed diffusion kernel least mean squares\n(KLMS) has been found to be performing better than diffusion least mean squares\n(LMS). The drawback of diffusion KLMS is that it requires infinite storage for\nobservations (also called dictionary). This paper formulates the diffusion KLMS\nin a fixed budget setting such that the storage requirement is curtailed while\nmaintaining appreciable performance in terms of convergence. Simulations have\nbeen carried out to validate the two newly proposed algorithms named as\nquantised diffusion KLMS (QDKLMS) and fixed budget diffusion KLMS (FBDKLMS)\nagainst KLMS, which indicate that both the proposed algorithms deliver better\nperformance as compared to the KLMS while reducing the dictionary size storage\nrequirement.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 11:38:01 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Mitra", "Rangeet", ""], ["Bhatia", "Vimal", ""]]}, {"id": "1509.02830", "submitter": "Steve Kerrison", "authors": "Steve Kerrison and Kerstin Eder", "title": "Modeling and visualizing networked multi-core embedded software energy\n  consumption", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this report we present a network-level multi-core energy model and a\nsoftware development process workflow that allows software developers to\nestimate the energy consumption of multi-core embedded programs. This work\nfocuses on a high performance, cache-less and timing predictable embedded\nprocessor architecture, XS1. Prior modelling work is improved to increase\naccuracy, then extended to be parametric with respect to voltage and frequency\nscaling (VFS) and then integrated into a larger scale model of a network of\ninterconnected cores. The modelling is supported by enhancements to an open\nsource instruction set simulator to provide the first network timing aware\nsimulations of the target architecture. Simulation based modelling techniques\nare combined with methods of results presentation to demonstrate how such work\ncan be integrated into a software developer's workflow, enabling the developer\nto make informed, energy aware coding decisions. A set of single-,\nmulti-threaded and multi-core benchmarks are used to exercise and evaluate the\nmodels and provide use case examples for how results can be presented and\ninterpreted. The models all yield accuracy within an average +/-5 % error\nmargin.\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 16:06:35 GMT"}], "update_date": "2015-09-10", "authors_parsed": [["Kerrison", "Steve", ""], ["Eder", "Kerstin", ""]]}, {"id": "1509.03118", "submitter": "Johannes Hofmann", "authors": "Johannes Hofmann, Jan Eitzinger, Dietmar Fey", "title": "Execution-Cache-Memory Performance Model: Introduction and Validation", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This report serves two purposes: To introduce and validate the\nExecution-Cache-Memory (ECM) performance model and to provide a thorough\nanalysis of current Intel processor architectures with a special emphasis on\nIntel Xeon Haswell-EP. The ECM model is a simple analytical performance model\nwhich focuses on basic architectural resources. The architectural analysis and\nmodel predictions are showcased and validated using a set of elementary\nmicrobenchmarks.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 12:02:51 GMT"}, {"version": "v2", "created": "Thu, 2 Mar 2017 11:12:37 GMT"}, {"version": "v3", "created": "Fri, 3 Mar 2017 08:33:37 GMT"}], "update_date": "2017-03-06", "authors_parsed": [["Hofmann", "Johannes", ""], ["Eitzinger", "Jan", ""], ["Fey", "Dietmar", ""]]}, {"id": "1509.03161", "submitter": "Jiri Dokulil", "authors": "Jiri Dokulil, Siegfried Benkner", "title": "OCR extensions - local identifiers, labeled GUIDs, file IO, and data\n  block partitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present several proposals for extending the Open Community Runtime (OCR)\nspecification. The extension are identifiers with local validity, which use the\nconcept of futures to provide OCR implementations more optimization\nopportunities, labeled GUIDs with creator functions, which are based on the\nlocal identifiers and allow the developer to create arrays of OCR objects that\nare safe from race conditions in case of concurrent creation of objects, a\nsimple file IO interface, which builds on top of the existing data block\nconcepts, and finally data block partitioning, which allows better control and\nflexibility in situations where multiple tasks want to access disjoint parts of\na data block.\n", "versions": [{"version": "v1", "created": "Thu, 10 Sep 2015 14:00:55 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Dokulil", "Jiri", ""], ["Benkner", "Siegfried", ""]]}, {"id": "1509.03287", "submitter": "Panagiotis Agis Oikonomou-Filandras", "authors": "Panagiotis-Agis Oikonomou-Filandras, Kai-Kit Wong and Yangyang Zhang", "title": "Grid-Based Belief Propagation for Cooperative Localization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a novel parametric message representation for belief propagation\n(BP) that provides a novel grid-based way to address the cooperative\nlocalization problem in wireless networks. The proposed Grid-BP approach allows\nfaster calculations than non-parametric representations and works well with\nexisting grid-based coordinate systems, e.g., NATO's military grid reference\nsystem (MGRS). This overcomes the hidden challenge inherent in all distributed\nlocalization algorithms that require a universally known global reference\nsystem (GCS), even though every node localizes using arbitrary local coordinate\nsystems (LCSs) for a reference. Simulation results demonstrate that Grid-BP\nachieves similar accuracy at much reduced complexity when compared to common\ntechniques that assume ideal reference\n", "versions": [{"version": "v1", "created": "Wed, 9 Sep 2015 19:38:00 GMT"}], "update_date": "2015-09-11", "authors_parsed": [["Oikonomou-Filandras", "Panagiotis-Agis", ""], ["Wong", "Kai-Kit", ""], ["Zhang", "Yangyang", ""]]}, {"id": "1509.03486", "submitter": "Todor Ivanov", "authors": "Todor Ivanov and Sead Izberovic", "title": "Evaluating Hadoop Clusters with TPCx-HS", "comments": "32 pages", "journal-ref": null, "doi": null, "report-no": "Technical Report No. 2015-1", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The growing complexity and variety of Big Data platforms makes it both\ndifficult and time consuming for all system users to properly setup and operate\nthe systems. Another challenge is to compare the platforms in order to choose\nthe most appropriate one for a particular application. All these factors\nmotivate the need for a standardized Big Data benchmark that can help the users\nin the process of platform evaluation. Just recently TPCx-HS [1][2] has been\nreleased as the first standardized Big Data benchmark designed to stress test a\nHadoop cluster. The goal of this study is to evaluate and compare how the\nnetwork setup influences the performance of a Hadoop cluster. In particular,\nexperiments were performed using shared and dedicated 1Gbit networks utilized\nby the same Cloudera Hadoop Distribution (CDH) cluster setup. The TPCx-HS\nbenchmark, which is very network intensive, was used to stress test and compare\nboth cluster setups. All the presented results are obtained by using the\nofficially available version [1] of the benchmark, but they are not comparable\nwith the officially reported results and are meant as an experimental\nevaluation, not audited by any external organization. As expected the dedicated\n1Gbit network setup performed much faster than the shared 1Gbit setup. However,\nwhat was surprising is the negligible price difference between both cluster\nsetups, which pays off with a multifold performance return.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 13:00:44 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2015 18:02:17 GMT"}, {"version": "v3", "created": "Tue, 27 Oct 2015 17:16:33 GMT"}], "update_date": "2015-10-28", "authors_parsed": [["Ivanov", "Todor", ""], ["Izberovic", "Sead", ""]]}, {"id": "1509.03591", "submitter": "Peter Dugan Dr", "authors": "Peter Dugan and John Zollweg and Marian Popescu and Denise Risch and\n  Herve Glotin and Yann LeCun and and Christopher Clark", "title": "High Performance Computer Acoustic Data Accelerator: A New System for\n  Exploring Marine Mammal Acoustics for Big Data Applications", "comments": "Seven pages, submitted at International Conference on Machine\n  Learning 2014, Workshop uLearnBio, unsupervised learning for bioacoustic\n  applications", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  This paper presents a new software model designed for distributed sonic\nsignal detection runtime using machine learning algorithms called DeLMA. A new\nalgorithm--Acoustic Data-mining Accelerator (ADA)--is also presented. ADA is a\nrobust yet scalable solution for efficiently processing big sound archives\nusing distributing computing technologies. Together, DeLMA and the ADA\nalgorithm provide a powerful tool currently being used by the Bioacoustics\nResearch Program (BRP) at the Cornell Lab of Ornithology, Cornell University.\nThis paper provides a high level technical overview of the system, and\ndiscusses various aspects of the design. Basic runtime performance and project\nsummary are presented. The DeLMA-ADA baseline performance comparing desktop\nserial configuration to a 64 core distributed HPC system shows as much as a 44\ntimes faster increase in runtime execution. Performance tests using 48 cores on\nthe HPC shows a 9x to 12x efficiency over a 4 core desktop solution. Project\nsummary results for 19 east coast deployments show that the DeLMA-ADA solution\nhas processed over three million channel hours of sound to date.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 17:51:56 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Dugan", "Peter", ""], ["Zollweg", "John", ""], ["Popescu", "Marian", ""], ["Risch", "Denise", ""], ["Glotin", "Herve", ""], ["LeCun", "Yann", ""], ["Clark", "and Christopher", ""]]}, {"id": "1509.03603", "submitter": "Xiang Sun", "authors": "Xiang Sun, Nirwan Ansari, and Qiang Fan", "title": "Green Energy Aware Avatar Migration Strategy in Green Cloudlet Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose a Green Cloudlet Network (\\emph{GCN}) architecture to provide\nseamless Mobile Cloud Computing (\\emph{MCC}) services to User Equipments\n(\\emph{UE}s) with low latency in which each cloudlet is powered by both green\nand brown energy. Fully utilizing green energy can significantly reduce the\noperational cost of cloudlet providers. However, owing to the spatial dynamics\nof energy demand and green energy generation, the energy gap among different\ncloudlets in the network is unbalanced, i.e., some cloudlets' energy demands\ncan be fully provided by green energy but others need to utilize on-grid energy\n(i.e., brown energy) to satisfy their energy demands. We propose a Green-energy\nawarE Avatar migRation (\\emph{GEAR}) strategy to minimize the on-grid energy\nconsumption in GCN by redistributing the energy demands via Avatar migration\namong cloudlets according to cloudlets' green energy generation. Furthermore,\nGEAR ensures the Service Level Agreement (\\emph{SLA}) in terms of the maximum\nAvatar propagation delay by avoiding Avatars hosted in the remote cloudlets. We\nformulate the GEAR strategy as a mixed integer linear programming problem,\nwhich is NP-hard, and thus apply the Branch and Bound search to find its\nsub-optimal solution. Simulation results demonstrate that GEAR can save on-grid\nenergy consumption significantly as compared to the Follow me AvataR\n(\\emph{FAR}) migration strategy, which aims to minimize the propagation delay\nbetween an UE and its Avatar.\n", "versions": [{"version": "v1", "created": "Fri, 11 Sep 2015 18:37:15 GMT"}], "update_date": "2015-09-14", "authors_parsed": [["Sun", "Xiang", ""], ["Ansari", "Nirwan", ""], ["Fan", "Qiang", ""]]}, {"id": "1509.03699", "submitter": "Huangxin Wang", "authors": "Huangxin Wang and Jean X. Zhang and Bo Yang and Fei Li", "title": "Randomization Improving Online Time-Sensitive Revenue Maximization for\n  Green Data Centers", "comments": "arXiv admin note: substantial text overlap with arXiv:1404.4865", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Green data centers have become more and more popular recently due to their\nsustainability. The resource management module within a green data center,\nwhich is in charge of dispatching jobs and scheduling energy, becomes\nespecially critical as it directly affects a center's profit and\nsustainability. The thrust of managing a green data center's machine and energy\nresources lies at the uncertainty of incoming job requests and future\nshowing-up green energy supplies. Thus, the decision of scheduling resources\nhas to be made in an online manner. Some heuristic deterministic online\nalgorithms have been proposed in recent literature. In this paper, we consider\nonline algorithms for green data centers and introduce a randomized solution\nwith the objective of maximizing net profit. Competitive analysis is employed\nto measure online algorithms' theoretical performance. Our algorithm is\ntheoretical-sound and it outperforms the previously known deterministic\nalgorithms in many settings using real traces. To complement our study, optimal\noffline algorithms are also designed.\n", "versions": [{"version": "v1", "created": "Sat, 12 Sep 2015 03:32:07 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Wang", "Huangxin", ""], ["Zhang", "Jean X.", ""], ["Yang", "Bo", ""], ["Li", "Fei", ""]]}, {"id": "1509.03815", "submitter": "Stephane Devismes", "authors": "St\\'ephane Devismes, Colette Johnen", "title": "Silent Self-stabilizing BFS Tree Algorithms Revised", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we revisit two fundamental results of the self-stabilizing\nliterature about silent BFS spanning tree constructions: the Dolev et al\nalgorithm and the Huang and Chen's algorithm. More precisely, we propose in the\ncomposite atomicity model three straightforward adaptations inspired from those\nalgorithms. We then present a deep study of these three algorithms. Our results\nare related to both correctness (convergence and closure, assuming a\ndistributed unfair daemon) and complexity (analysis of the stabilization time\nin terms of rounds and steps).\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2015 06:26:21 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Devismes", "St\u00e9phane", ""], ["Johnen", "Colette", ""]]}, {"id": "1509.03838", "submitter": "Yiannis Andreopoulos", "authors": "Mohammad Ashraful Anam and Yiannis Andreopoulos", "title": "Failure Mitigation in Linear, Sesquilinear and Bijective Operations On\n  Integer Data Streams Via Numerical Entanglement", "comments": "Proc. 21st IEEE International On-Line Testing Symposium (IOLTS 2015),\n  July 2015, Halkidiki, Greece", "journal-ref": null, "doi": "10.1109/IOLTS.2015.7229844", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A new roll-forward technique is proposed that recovers from any single\nfail-stop failure in $M$ integer data streams ($M\\geq3$) when undergoing\nlinear, sesquilinear or bijective (LSB) operations, such as: scaling,\nadditions/subtractions, inner or outer vector products and permutations. In the\nproposed approach, the $M$ input integer data streams are linearly superimposed\nto form $M$ numerically entangled integer data streams that are stored in-place\nof the original inputs. A series of LSB operations can then be performed\ndirectly using these entangled data streams. The output results can be\nextracted from any $M-1$ entangled output streams by additions and arithmetic\nshifts, thereby guaranteeing robustness to a fail-stop failure in any single\nstream computation. Importantly, unlike other methods, the number of operations\nrequired for the entanglement, extraction and recovery of the results is\nlinearly related to the number of the inputs and does not depend on the\ncomplexity of the performed LSB operations. We have validated our proposal in\nan Intel processor (Haswell architecture with AVX2 support) via convolution\noperations. Our analysis and experiments reveal that the proposed approach\nincurs only $1.8\\%$ to $2.8\\%$ reduction in processing throughput in comparison\nto the failure-intolerant approach. This overhead is 9 to 14 times smaller than\nthat of the equivalent checksum-based method. Thus, our proposal can be used in\ndistributed systems and unreliable processor hardware, or safety-critical\napplications, where robustness against fail-stop failures becomes a necessity.\n", "versions": [{"version": "v1", "created": "Sun, 13 Sep 2015 11:48:47 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Anam", "Mohammad Ashraful", ""], ["Andreopoulos", "Yiannis", ""]]}, {"id": "1509.03934", "submitter": "Sam Maloney", "authors": "Sam Maloney", "title": "Dpush: A scalable decentralized spam resistant unsolicited messaging\n  protocol", "comments": "Newest paper/design; signature was moved inside encrypted data for\n  anonymity of sender to non recipients, grammar improvements", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Herein this paper is presented a novel invention - called Dpush - that\nenables truly scalable spam resistant uncensorable automatically encrypted and\ninherently authenticated messaging; thus restoring our ability to exert our\nright to private communication, and thus a step forward in restoring an\nuncorrupted democracy. Using a novel combination of a distributed hash table[1]\n(DHT) and a proof of work[2] (POW), combined in a way that can only be called a\nsynergy, the emergent property of a scalable and spam resistant unsolicited\nmessaging protocol elegantly emerges. Notable is that the receiver does not\nneed to be online at the time the message is sent. This invention is already\nimplemented and operating within the package that is called MORPHiS - which is\na Sybil[3] resistant enhanced Kademlia[1] DHT implementation combined with an\nalready functioning implementation of Dpush, as well as a polished HTTP Dmail\ninterface to send and receive such messages today. MORPHiS is available for\nfree (GPLv2) at the https://morph.is website.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 02:56:52 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 07:44:01 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Maloney", "Sam", ""]]}, {"id": "1509.04048", "submitter": "Sathya Peri", "authors": "Priyanka Kumar, Sathya Peri", "title": "Multiversion Conflict Notion for Transactional Memory Systems", "comments": "19 pages. arXiv admin note: substantial text overlap with\n  arXiv:1307.8256", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In recent years, Software Transactional Memory systems (STMs) have garnered\nsignificant interest as an elegant alternative for addressing concurrency\nissues in memory. STM systems take optimistic approach. Multiple transactions\nare allowed to execute concurrently. On completion, each transaction is\nvalidated and if any inconsistency is observed it is aborted. Otherwise it is\nallowed to commit.\n  In databases a class of histories called as conflict-serializability (CSR)\nbased on the notion of conflicts have been identified, whose membership can be\nefficiently verified. As a result, CSR is the commonly used correctness\ncriterion in databases. Similarly, using the notion of conflicts, a correctness\ncriterion, conflict-opacity (co-opacity) which is a sub-class of can be\ndesigned whose membership can be verified in polynomial time. Using the\nverification mechanism, an efficient STM implementation can be designed that is\npermissive w.r.t co-opacity.\n  By storing multiple versions for each transaction object, multi-version STMs\nprovide more concurrency than single-version STMs. But the main drawback of\nco-opacity is that it does not admit histories that are uses multiple versions.\nThis has motivated us to develop a new conflict notions for multi-version STMs.\nIn this paper, we present a new conflict notion multi-version conflict. Using\nthis conflict notion, we identify a new subclass of opacity (a popular\ncorrectness-criterion), mvc-opacity that admits multi-versioned histories and\nwhose membership can be verified in polynomial time. We show that co-opacity is\na proper subset of this class. The proposed conflict notion mv-conflict can be\napplied on non-sequential histories as well unlike traditional conflicts.\nFurther, we believe that this conflict notion can be easily extended to other\ncorrectness-criterion as well.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 12:07:49 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 08:10:26 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Kumar", "Priyanka", ""], ["Peri", "Sathya", ""]]}, {"id": "1509.04085", "submitter": "James Clarkson", "authors": "Christos Kotselidis and Andrey Rodchenko and Colin Barrett and Andy\n  Nisbet and John Mawer and Will Toms and James Clarkson and Cosmin Gorgovan\n  and Amanieu d'Antras and Yaman Cakmakci and Thanos Stratikopoulos and\n  Sebastian Werner and Jim Garside and Javier Navaridas and Antoniu Pop and\n  John Goodacre and Mikel Lujan", "title": "Project Beehive: A Hardware/Software Co-designed Stack for Runtime and\n  Architectural Research", "comments": "New version of this paper", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The end of Dennard scaling combined with stagnation in architectural and\ncompiler optimizations makes it challenging to achieve significant performance\ndeltas. Solutions based solely in hardware or software are no longer sufficient\nto maintain the pace of improvements seen during the past few decades. In\nhardware, the end of single-core scaling resulted in the proliferation of\nmulti-core system architectures, however this has forced complex parallel\nprogramming techniques into the mainstream. To further exploit physical\nresources, systems are becoming increasingly heterogeneous with specialized\ncomputing elements and accelerators. Programming across a range of disparate\narchitectures requires a new level of abstraction that programming languages\nwill have to adapt to. In software, emerging complex applications, from domains\nsuch as Big Data and computer vision, run on multi-layered software stacks\ntargeting hardware with a variety of constraints and resources. Hence,\noptimizing for the power-performance (and resiliency) space requires\nexperimentation platforms that offer quick and easy prototyping of\nhardware/software co-designed techniques. To that end, we present Project\nBeehive: A Hardware/Software co-designed stack for runtime and architectural\nresearch. Project Beehive utilizes various state-of-the-art software and\nhardware components along with novel and extensible co-design techniques. The\nobjective of Project Beehive is to provide a modern platform for\nexperimentation on emerging applications, programming languages, compilers,\nruntimes, and low-power heterogeneous many-core architectures in a full-system\nco-designed manner.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 13:30:53 GMT"}, {"version": "v2", "created": "Sat, 13 Aug 2016 08:54:38 GMT"}, {"version": "v3", "created": "Mon, 5 Jun 2017 08:22:19 GMT"}], "update_date": "2017-06-06", "authors_parsed": [["Kotselidis", "Christos", ""], ["Rodchenko", "Andrey", ""], ["Barrett", "Colin", ""], ["Nisbet", "Andy", ""], ["Mawer", "John", ""], ["Toms", "Will", ""], ["Clarkson", "James", ""], ["Gorgovan", "Cosmin", ""], ["d'Antras", "Amanieu", ""], ["Cakmakci", "Yaman", ""], ["Stratikopoulos", "Thanos", ""], ["Werner", "Sebastian", ""], ["Garside", "Jim", ""], ["Navaridas", "Javier", ""], ["Pop", "Antoniu", ""], ["Goodacre", "John", ""], ["Lujan", "Mikel", ""]]}, {"id": "1509.04210", "submitter": "Wei Zhang", "authors": "Suyog Gupta, Wei Zhang, Fei Wang", "title": "Model Accuracy and Runtime Tradeoff in Distributed Deep Learning:A\n  Systematic Study", "comments": "Accepted by The IEEE International Conference on Data Mining 2016\n  (ICDM 2016)", "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC cs.LG cs.NE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents Rudra, a parameter server based distributed computing\nframework tuned for training large-scale deep neural networks. Using variants\nof the asynchronous stochastic gradient descent algorithm we study the impact\nof synchronization protocol, stale gradient updates, minibatch size, learning\nrates, and number of learners on runtime performance and model accuracy. We\nintroduce a new learning rate modulation strategy to counter the effect of\nstale gradients and propose a new synchronization protocol that can effectively\nbound the staleness in gradients, improve runtime performance and achieve good\nmodel accuracy. Our empirical investigation reveals a principled approach for\ndistributed training of neural networks: the mini-batch size per learner should\nbe reduced as more learners are added to the system to preserve the model\naccuracy. We validate this approach using commonly-used image classification\nbenchmarks: CIFAR10 and ImageNet.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 17:14:52 GMT"}, {"version": "v2", "created": "Tue, 15 Sep 2015 01:31:18 GMT"}, {"version": "v3", "created": "Mon, 5 Dec 2016 21:26:38 GMT"}], "update_date": "2016-12-07", "authors_parsed": [["Gupta", "Suyog", ""], ["Zhang", "Wei", ""], ["Wang", "Fei", ""]]}, {"id": "1509.04252", "submitter": "Andreas Kreienbuehl", "authors": "Andreas Kreienbuehl and Arne Naegel and Daniel Ruprecht and Andreas\n  Vogel and Gabriel Wittum and Rolf Krause", "title": "Parareal convergence for 2D unsteady flow around a cylinder", "comments": "16 pages, 7 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CE cs.DC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this technical report we study the convergence of Parareal for 2D\nincompressible flow around a cylinder for different viscosities. Two methods\nare used as fine integrator: backward Euler and a fractional step method. It is\nfound that Parareal converges better for the implicit Euler, likely because it\nunder-resolves the fine-scale dynamics as a result of numerical diffusion.\n", "versions": [{"version": "v1", "created": "Mon, 14 Sep 2015 19:29:41 GMT"}], "update_date": "2015-09-15", "authors_parsed": [["Kreienbuehl", "Andreas", ""], ["Naegel", "Arne", ""], ["Ruprecht", "Daniel", ""], ["Vogel", "Andreas", ""], ["Wittum", "Gabriel", ""], ["Krause", "Rolf", ""]]}, {"id": "1509.04394", "submitter": "Asif Adnan", "authors": "Asif M Adnan, Sridhar Radhakrishnan, Suleyman Karabuk", "title": "Efficient Kernel Fusion Techniques for Massive Video Data Analysis on\n  GPGPUs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Kernels are executable code segments and kernel fusion is a technique for\ncombing the segments in a coherent manner to improve execution time. For the\nfirst time, we have developed a technique to fuse image processing kernels to\nbe executed on GPGPUs for improving execution time and total throughput (amount\nof data processed in unit time). We have applied our techniques for feature\ntracking on video images captured by a high speed digital video camera where\nthe number of frames captured varies between 600-1000 frames per second. Image\nprocessing kernels are composed of multiple simple kernels, which executes on\nthe input image in a given sequence. A set of kernels that can be fused\ntogether forms a partition (or fused kernel). Given a set of Kernels and the\ndata dependencies between them, it is difficult to determine the partitions of\nkernels such that the total performance is maximized (execution time and\nthroughput). We have developed and implemented an optimization model to find\nsuch a partition. We also developed an algorithm to fuse multiple kernels based\non their data dependencies. Additionally, to further improve performance on\nGPGPU systems, we have provided methods to distribute data and threads to\nprocessors. Our model was able to reduce data traffic, which resulted better\nperformance.The performance (both execution time and throughput) of the\nproposed method for kernel fusing and its subsequent execution is shown to be 2\nto 3 times higher than executing kernels in sequence. We have demonstrated our\ntechnique for facial feature tracking with applications to Neuroscience.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 04:30:12 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Adnan", "Asif M", ""], ["Radhakrishnan", "Sridhar", ""], ["Karabuk", "Suleyman", ""]]}, {"id": "1509.04417", "submitter": "Haribabu Kotakula", "authors": "K. Haribabu, Dayakar Reddy, Chittaranjan Hota, Antii Yl\\\"a-J\\\"a\\\"aski,\n  Sasu Tarkoma", "title": "Adaptive Lookup for Unstructured Peer-to-Peer Overlays", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scalability and efficient global search in unstructured peer-to-peer overlays\nhave been extensively studied in the literature. The global search comes at the\nexpense of local interactions between peers. Most of the unstructured\npeer-to-peer overlays do not provide any performance guarantee. In this work we\npropose a novel Quality of Service enabled lookup for unstructured peer-to-peer\noverlays that will allow the user's query to traverse only those overlay links\nwhich satisfy the given constraints. Additionally, it also improves the\nscalability by judiciously using the overlay resources. Our approach\nselectively forwards the queries using QoS metrics like latency, bandwidth, and\noverlay link status so as to ensure improved performance in a scenario where\nthe degree of peer joins and leaves are high. User is given only those results\nwhich can be downloaded with the given constraints. Also, the protocol aims at\nminimizing the message overhead over the overlay network.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 06:56:26 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Haribabu", "K.", ""], ["Reddy", "Dayakar", ""], ["Hota", "Chittaranjan", ""], ["Yl\u00e4-J\u00e4\u00e4ski", "Antii", ""], ["Tarkoma", "Sasu", ""]]}, {"id": "1509.04538", "submitter": "Shaoshuai Mou", "authors": "Brian D. O. Anderson, Shaoshuai Mou, A. Stephen Morse, Uwe Helmke", "title": "Decentralized gradient algorithm for solution of a linear equation", "comments": "10 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper develops a technique for solving a linear equation $Ax=b$ with a\nsquare and nonsingular matrix $A$, using a decentralized gradient algorithm. In\nthe language of control theory, there are $n$ agents, each storing at time $t$\nan $n$-vector, call it $x_i(t)$, and a graphical structure associating with\neach agent a vertex of a fixed, undirected and connected but otherwise\narbitrary graph $\\mathcal G$ with vertex set and edge set $\\mathcal V$ and\n$\\mathcal E$ respectively. We provide differential equation update laws for the\n$x_i$ with the property that each $x_i$ converges to the solution of the linear\nequation exponentially fast. The equation for $x_i$ includes additive terms\nweighting those $x_j$ for which vertices in $\\mathcal G$ corresponding to the\n$i$-th and $j$-th agents are adjacent. The results are extended to the case\nwhere $A$ is not square but has full row rank, and bounds are given on the\nconvergence rate.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 13:24:57 GMT"}], "update_date": "2015-09-16", "authors_parsed": [["Anderson", "Brian D. O.", ""], ["Mou", "Shaoshuai", ""], ["Morse", "A. Stephen", ""], ["Helmke", "Uwe", ""]]}, {"id": "1509.04627", "submitter": "Johannes Holke", "authors": "Carsten Burstedde, Johannes Holke", "title": "A tetrahedral space-filling curve for non-conforming adaptive meshes", "comments": "33 pages, 12 figures, 8 tables", "journal-ref": null, "doi": "10.1137/15M1040049", "report-no": null, "categories": "cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We introduce a space-filling curve for triangular and tetrahedral\nred-refinement that can be computed using bitwise interleaving operations\nsimilar to the well-known Z-order or Morton curve for cubical meshes. To store\nsufficient information for random access, we define a low-memory encoding using\n10 bytes per triangle and 14 bytes per tetrahedron. We present algorithms that\ncompute the parent, children, and face-neighbors of a mesh element in constant\ntime, as well as the next and previous element in the space-filling curve and\nwhether a given element is on the boundary of the root simplex or not. Our\npresentation concludes with a scalability demonstration that creates and adapts\nselected meshes on a large distributed-memory system.\n", "versions": [{"version": "v1", "created": "Tue, 15 Sep 2015 16:16:54 GMT"}, {"version": "v2", "created": "Fri, 21 Apr 2017 09:44:26 GMT"}], "update_date": "2017-04-24", "authors_parsed": [["Burstedde", "Carsten", ""], ["Holke", "Johannes", ""]]}, {"id": "1509.05197", "submitter": "Chenhao Qu", "authors": "Chenhao Qu, Rodrigo N. Calheiros, Rajkumar Buyya", "title": "A Reliable and Cost-Efficient Auto-Scaling System for Web Applications\n  Using Heterogeneous Spot Instances", "comments": null, "journal-ref": null, "doi": "10.1016/j.jnca.2016.03.001", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud providers sell their idle capacity on markets through an auction-like\nmechanism to increase their return on investment. The instances sold in this\nway are called spot instances. In spite that spot instances are usually 90%\ncheaper than on-demand instances, they can be terminated by provider when their\nbidding prices are lower than market prices. Thus, they are largely used to\nprovision fault-tolerant applications only. In this paper, we explore how to\nutilize spot instances to provision web applications, which are usually\nconsidered availability-critical. The idea is to take advantage of differences\nin price among various types of spot instances to reach both high availability\nand significant cost saving. We first propose a fault-tolerant model for web\napplications provisioned by spot instances. Based on that, we devise novel\nauto-scaling polices for hourly billed cloud markets. We implemented the\nproposed model and policies both on a simulation testbed for repeatable\nvalidation and Amazon EC2. The experiments on the simulation testbed and the\nreal platform against the benchmarks show that the proposed approach can\ngreatly reduce resource cost and still achieve satisfactory Quality of Service\n(QoS) in terms of response time and availability.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 10:24:32 GMT"}, {"version": "v2", "created": "Mon, 7 Mar 2016 00:46:27 GMT"}], "update_date": "2016-03-08", "authors_parsed": [["Qu", "Chenhao", ""], ["Calheiros", "Rodrigo N.", ""], ["Buyya", "Rajkumar", ""]]}, {"id": "1509.05393", "submitter": "Martin Kleppmann", "authors": "Martin Kleppmann", "title": "A Critique of the CAP Theorem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The CAP Theorem is a frequently cited impossibility result in distributed\nsystems, especially among NoSQL distributed databases. In this paper we survey\nsome of the confusion about the meaning of CAP, including inconsistencies and\nambiguities in its definitions, and we highlight some problems in its\nformalization. CAP is often interpreted as proof that eventually consistent\ndatabases have better availability properties than strongly consistent\ndatabases; although there is some truth in this, we show that more careful\nreasoning is required. These problems cast doubt on the utility of CAP as a\ntool for reasoning about trade-offs in practical systems. As alternative to\nCAP, we propose a \"delay-sensitivity\" framework, which analyzes the sensitivity\nof operation latency to network delay, and which may help practitioners reason\nabout the trade-offs between consistency guarantees and tolerance of network\nfaults.\n", "versions": [{"version": "v1", "created": "Thu, 17 Sep 2015 19:50:15 GMT"}, {"version": "v2", "created": "Fri, 18 Sep 2015 17:38:02 GMT"}], "update_date": "2015-09-21", "authors_parsed": [["Kleppmann", "Martin", ""]]}, {"id": "1509.05492", "submitter": "Melissa Romanus", "authors": "Melissa Romanus, Robert B. Ross, Manish Parashar", "title": "Challenges and Considerations for Utilizing Burst Buffers in\n  High-Performance Computing", "comments": "18 pages, 2 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As high-performance computing (HPC) moves into the exascale era, computer\nscientists and engineers must find innovative ways of transferring and\nprocessing unprecedented amounts of data. As the scale and complexity of the\napplications running on these machines increases, the cost of their\ninteractions and data exchanges (in terms of latency, energy, runtime, etc.)\ncan increase exponentially. In order to address I/O coordination and\ncommunication issues, computing vendors are developing an intermediate layer\nbetween compute nodes and the parallel file system composed of different types\nof memory (NVRAM, DRAM, SSD). These large scale memory appliances are being\ncalled 'burst buffers.' In this paper, we envision advanced memory at various\nlevels of HPC hardware and derive potential use cases for how to take advantage\nof it. We then present the challenges and issues that arise when utilizing\nburst buffers in next-generation supercomputers and map the challenges to the\nuse cases. Lastly, we discuss the emerging state-of-the-art burst buffer\nsolutions that are expected to become available by the end of the year in new\nHPC systems and which use cases these implementations may satisfy.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 03:01:41 GMT"}, {"version": "v2", "created": "Tue, 29 Sep 2015 16:03:56 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Romanus", "Melissa", ""], ["Ross", "Robert B.", ""], ["Parashar", "Manish", ""]]}, {"id": "1509.05664", "submitter": "Thorsten Wissmann", "authors": "Fathiyeh Faghih, Borzoo Bonakdarpour, Sebastien Tixeuil, and Sandeep\n  Kulkarni", "title": "Automated Synthesis of Distributed Self-Stabilizing Protocols", "comments": null, "journal-ref": "Logical Methods in Computer Science, Volume 14, Issue 1 (January\n  30, 2018) lmcs:4241", "doi": "10.23638/LMCS-14(1:12)2018", "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we introduce an SMT-based method that automatically\nsynthesizes a distributed self-stabilizing protocol from a given high-level\nspecification and network topology. Unlike existing approaches, where synthesis\nalgorithms require the explicit description of the set of legitimate states,\nour technique only needs the temporal behavior of the protocol. We extend our\napproach to synthesize ideal-stabilizing protocols, where every state is\nlegitimate. We also extend our technique to synthesize monotonic-stabilizing\nprotocols, where during recovery, each process can execute an most once one\naction. Our proposed methods are fully implemented and we report successful\nsynthesis of well-known protocols such as Dijkstra's token ring, a\nself-stabilizing version of Raymond's mutual exclusion algorithm,\nideal-stabilizing leader election and local mutual exclusion, as well as\nmonotonic-stabilizing maximal independent set and distributed Grundy coloring.\n", "versions": [{"version": "v1", "created": "Fri, 18 Sep 2015 15:26:44 GMT"}, {"version": "v2", "created": "Wed, 30 Nov 2016 18:05:01 GMT"}, {"version": "v3", "created": "Wed, 1 Nov 2017 11:42:11 GMT"}, {"version": "v4", "created": "Mon, 29 Jan 2018 15:30:26 GMT"}], "update_date": "2018-02-14", "authors_parsed": [["Faghih", "Fathiyeh", ""], ["Bonakdarpour", "Borzoo", ""], ["Tixeuil", "Sebastien", ""], ["Kulkarni", "Sandeep", ""]]}, {"id": "1509.05875", "submitter": "Minxian  Xu", "authors": "Wutong Yang, Minxian Xu, Guozhong Li, Wenhong Tian", "title": "CloudSimNFV: Modeling and Simulation of Energy-Efficient NFV in Cloud\n  Data Centers", "comments": "Cloud Computing, Network Function Virtualization, Simulation Toolkit,\n  Energy Consumption Model, Scheduling Algorithm", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Network Function Virtualization (NFV) takes advantage of hardware\nvirtualization to undertake software processing for various functions, and\ncomplements the drawbacks of traditional network technology. To speed up NFV\nrelated research, we need a user friendly and easy to use research tool, which\ncould support data center simulation, scheduling algorithms implementation and\nextension, and provide energy consumption simulation. As a cloud simulation\ntoolkit, CloudSim has strong extendibility that could be extended to simulate\nNFV environment. This paper introduces a NFV cloud framework based on CloudSim\nand an energy consumption model based on multi-dimensional extension,\nimplementing a toolkit named ClousimNFV to simulate the NFV scenario, proposing\nseveral scheduling algorithm based on for NFV applications. The toolkit\nvalidation and algorithm performance comparison are also given.\n", "versions": [{"version": "v1", "created": "Sat, 19 Sep 2015 11:39:58 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Yang", "Wutong", ""], ["Xu", "Minxian", ""], ["Li", "Guozhong", ""], ["Tian", "Wenhong", ""]]}, {"id": "1509.06065", "submitter": "Md Zakirul Alam Bhuiyan", "authors": "Md Zakirul Alam Bhuiyan, G. Wang, J. Wu, J. Cao", "title": "Dependable Structural Helath Monitoring Using Wireless Sensor Networks", "comments": "46 pages, 22 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  As an alternative to current wired-based networks, wireless sensor networks\n(WSNs) are becoming an increasingly compelling platform for engineering\nstructural health monitoring (SHM) due to relatively low-cost, easy\ninstallation, and so forth. However, there is still an unaddressed challenge:\nthe application-specific dependability in terms of sensor fault detection and\ntolerance. The dependability is also affected by a reduction on the quality of\nmonitoring when mitigating WSN constrains (e.g., limited energy, narrow\nbandwidth). We address these by designing a dependable distributed WSN\nframework for SHM (called DependSHM) and then examining its ability to cope\nwith sensor faults and constraints. We find evidence that faulty sensors can\ncorrupt results of a health event (e.g., damage) in a structural system without\nbeing detected. More specifically, we bring attention to an undiscovered yet\ninteresting fact, i.e., the real measured signals introduced by one or more\nfaulty sensors may cause an undamaged location to be identified as damaged\n(false positive) or a damaged location as undamaged (false negative) diagnosis.\nThis can be caused by faults in sensor bonding, precision degradation,\namplification gain, bias, drift, noise, and so forth. In DependSHM, we present\na distributed automated algorithm to detect such types of faults, and we offer\nan online signal reconstruction algorithm to recover from the wrong diagnosis.\nThrough comprehensive simulations and a WSN prototype system implementation, we\nevaluate the effectiveness of DependSHM.\n", "versions": [{"version": "v1", "created": "Sun, 20 Sep 2015 22:28:06 GMT"}], "update_date": "2015-09-22", "authors_parsed": [["Bhuiyan", "Md Zakirul Alam", ""], ["Wang", "G.", ""], ["Wu", "J.", ""], ["Cao", "J.", ""]]}, {"id": "1509.06282", "submitter": "Tarek Lahlou", "authors": "Tarek A. Lahlou and Thomas A. Baran", "title": "Web Services for Asynchronous, Distributed Optimization Using\n  Conservative Signal Processing", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents a systematic approach for implementing a class of\nnonlinear signal processing systems as a distributed web service, which in turn\nis used to solve optimization problems in a distributed, asynchronous fashion.\nAs opposed to requiring a specialized server, the presented approach requires\nonly the use of a commodity database back-end as a central resource, as might\ntypically be used to serve data for websites having large numbers of concurrent\nusers. In this sense the presented approach leverages not only the scalability\nand robustness of various database systems in sharing variables asynchronously\nbetween workers, but also critically it leverages the tools of signal\nprocessing in determining how the optimization algorithm might be organized and\ndistributed among various heterogeneous workers. A publicly-accessible\nimplementation is also presented, utilizing Firebase as a back-end server, and\nillustrating the use of the presented approach in solving various optimization\nproblems commonly arising in the context of signal processing.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 15:53:57 GMT"}, {"version": "v2", "created": "Thu, 24 Sep 2015 13:48:48 GMT"}], "update_date": "2015-09-25", "authors_parsed": [["Lahlou", "Tarek A.", ""], ["Baran", "Thomas A.", ""]]}, {"id": "1509.06420", "submitter": "Soumya Banerjee", "authors": "Soumya Banerjee and Joshua Hecker", "title": "A Multi-Agent System Approach to Load-Balancing and Resource Allocation\n  for Distributed Computing", "comments": "Complex Systems Digital Campus 2015 World eConference Conference on\n  Complex Systems", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this research we use a decentralized computing approach to allocate and\nschedule tasks on a massively distributed grid. Using emergent properties of\nmulti-agent systems, the algorithm dynamically creates and dissociates clusters\nto serve the changing resource demands of a global task queue. The algorithm is\ncompared to a standard First-in First-out (FIFO) scheduling algorithm.\nExperiments done on a simulator show that the distributed resource allocation\nprotocol (dRAP) algorithm outperforms the FIFO scheduling algorithm on time to\nempty queue, average waiting time and CPU utilization. Such a decentralized\ncomputing approach holds promise for massively distributed processing scenarios\nlike SETI@home and Google MapReduce.\n", "versions": [{"version": "v1", "created": "Mon, 21 Sep 2015 22:41:36 GMT"}], "update_date": "2015-09-23", "authors_parsed": [["Banerjee", "Soumya", ""], ["Hecker", "Joshua", ""]]}, {"id": "1509.06935", "submitter": "Daniel Ruprecht", "authors": "Daniel Ruprecht", "title": "Shared Memory Pipelined Parareal", "comments": null, "journal-ref": "In: Rivera F., Pena T., Cabaleiro J. (eds) Euro-Par 2017: Parallel\n  Processing. Lecture Notes in Computer Science, vol 10417. Springer", "doi": "10.1007/978-3-319-64203-1_48", "report-no": null, "categories": "cs.MS cs.DC cs.NA math.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For the parallel-in-time integration method Parareal, pipelining can be used\nto hide some of the cost of the serial correction step and improve its\nefficiency. The paper introduces a basic OpenMP implementation of pipelined\nParareal and compares it to a standard MPI-based variant. Both versions yield\nalmost identical runtimes, but, depending on the compiler, the OpenMP variant\nconsumes about 7% less energy and has a significantly smaller memory footprint.\nHowever, its higher implementation complexity might make it difficult to use in\nlegacy codes and in combination with spatial parallelisation.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 12:04:23 GMT"}, {"version": "v2", "created": "Wed, 20 Apr 2016 09:57:47 GMT"}, {"version": "v3", "created": "Mon, 11 Nov 2019 15:20:23 GMT"}], "update_date": "2019-11-12", "authors_parsed": [["Ruprecht", "Daniel", ""]]}, {"id": "1509.07053", "submitter": "Jakob Gruber", "authors": "Jakob Gruber", "title": "Practical Concurrent Priority Queues", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Priority queues are abstract data structures which store a set of key/value\npairs and allow efficient access to the item with the minimal (maximal) key.\nSuch queues are an important element in various areas of computer science such\nas algorithmics (i.e. Dijkstra's shortest path algorithm) and operating system\n(i.e. priority schedulers).\n  The recent trend towards multiprocessor computing requires new\nimplementations of basic data structures which are able to be used concurrently\nand scale well to a large number of threads. In particular, lock-free\nstructures promise superior scalability by avoiding the use of blocking\nsynchronization primitives.\n  Concurrent priority queues have been extensively researched over the past\ndecades. In this paper, we discuss three major ideas within the field:\nfine-grained locking employs multiple locks to avoid a single bottleneck within\nthe queue; SkipLists are search structures which use randomization and\ntherefore do not require elaborate reorganization schemes; and relaxed data\nstructures trade semantic guarantees for improved scalability.\n", "versions": [{"version": "v1", "created": "Wed, 23 Sep 2015 16:35:38 GMT"}], "update_date": "2015-09-24", "authors_parsed": [["Gruber", "Jakob", ""]]}, {"id": "1509.07395", "submitter": "Eitan Zahavi", "authors": "Eitan Zahavi, Alex Shpiner, Ori Rottenstreich, Avinoam Kolodny and\n  Isaac Keslassy", "title": "Links as a Service (LaaS): Feeling Alone in the Shared Cloud", "comments": "CCIT Report 888 September 2015, EE Pub No. 1845, Technion, Israel", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The most demanding tenants of shared clouds require complete isolation from\ntheir neighbors, in order to guarantee that their application performance is\nnot affected by other tenants. Unfortunately, while shared clouds can offer an\noption whereby tenants obtain dedicated servers, they do not offer any network\nprovisioning service, which would shield these tenants from network\ninterference. In this paper, we introduce Links as a Service, a new abstraction\nfor cloud service that provides physical isolation of network links. Each\ntenant gets an exclusive set of links forming a virtual fat tree, and is\nguaranteed to receive the exact same bandwidth and delay as if it were alone in\nthe shared cloud. Under simple assumptions, we derive theoretical conditions\nfor enabling LaaS without capacity over-provisioning in fat-trees. New tenants\nare only admitted in the network when they can be allocated hosts and links\nthat maintain these conditions. Using experiments on real clusters as well as\nsimulations with real-life tenant sizes, we show that LaaS completely avoids\nthe performance degradation caused by traffic from concurrent tenants on shared\nlinks. Compared to mere host isolation, LaaS can improve the application\nperformance by up to 200%, at the cost of a 10% reduction in the cloud\nutilization.\n", "versions": [{"version": "v1", "created": "Thu, 24 Sep 2015 14:49:45 GMT"}, {"version": "v2", "created": "Fri, 8 Jan 2016 12:39:35 GMT"}], "update_date": "2016-01-11", "authors_parsed": [["Zahavi", "Eitan", ""], ["Shpiner", "Alex", ""], ["Rottenstreich", "Ori", ""], ["Kolodny", "Avinoam", ""], ["Keslassy", "Isaac", ""]]}, {"id": "1509.07616", "submitter": "Jonghyun Lee", "authors": "Jounghyun Lee, Keun Young Lee, Karpjoo Jeong, Meilan Jiang, Bomchul\n  Kim, Suntae Hwang", "title": "A Cyberinfrastructure-based Approach to Real Time Water Temperature\n  Prediction", "comments": "10 pages, 14 figures, PRAGMA-ICDS-15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/4.0/", "abstract": "  The prediction of water temperature is crucial for aquatic ecosystem studies\nand management. In this paper, we raise challenging issues in supporting real\ntime water temperature prediction and present a system called WT-Agabus to\naddress those issues. The WT-Agabus system is designed to be a\ncyberinfrastructure and to support various prediction models in a uniform way.\nIn addition, we present a neural network-based water temperature prediction\nmodel to use only data available online from Korea Meteorological\nAdministration (KMA). In this paper, we also show the current prototype\nimplementation of the WT-Agabus system to support the prediction model\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 08:06:42 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Lee", "Jounghyun", ""], ["Lee", "Keun Young", ""], ["Jeong", "Karpjoo", ""], ["Jiang", "Meilan", ""], ["Kim", "Bomchul", ""], ["Hwang", "Suntae", ""]]}, {"id": "1509.07815", "submitter": "Robert Escriva", "authors": "Robert Escriva, Bernard Wong, Emin G\\\"un Sirer", "title": "Warp: Lightweight Multi-Key Transactions for Key-Value Stores", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Traditional NoSQL systems scale by sharding data across multiple servers and\nby performing each operation on a small number of servers. Because transactions\non multiple keys necessarily require coordination across multiple servers,\nNoSQL systems often explicitly avoid making transactional guarantees in order\nto avoid such coordination. Past work on transactional systems control this\ncoordination by either increasing the granularity at which transactions are\nordered, sacrificing serializability, or by making clock synchronicity\nassumptions.\n  This paper presents a novel protocol for providing serializable transactions\non top of a sharded data store. Called acyclic transactions, this protocol\nallows multiple transactions to prepare and commit simultaneously, improving\nconcurrency in the system, while ensuring that no cycles form between\nconcurrently-committing transactions. We have fully implemented acyclic\ntransactions in a document store called Warp. Experiments show that Warp\nachieves 4 times higher throughput than Sinfonia's mini-transactions on the\nstandard TPC-C benchmark with no aborts. Further, the system achieves 75% of\nthe throughput of the non-transactional key-value store it builds upon.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 18:05:44 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Escriva", "Robert", ""], ["Wong", "Bernard", ""], ["Sirer", "Emin G\u00fcn", ""]]}, {"id": "1509.07821", "submitter": "Robert Escriva", "authors": "Robert Escriva, Emin G\\\"un Sirer", "title": "The Design and Implementation of the Wave Transactional Filesystem", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper introduces the Wave Transactional Filesystem (WTF), a novel,\ntransactional, POSIX-compatible filesystem based on a new file slicing API that\nenables efficient file transformations. WTF provides transactional access to a\ndistributed filesystem, eliminating the possibility of inconsistencies across\nmultiple files. Further, the file slicing API enables applications to construct\nfiles from the contents of other files without having to rewrite or relocate\ndata. Combined, these enable a new class of high-performance applications.\nExperiments show that WTF can qualitatively outperform the industry-standard\nHDFS distributed filesystem, up to a factor of four in a sorting benchmark, by\nreducing I/O costs. Microbenchmarks indicate that the new features of WTF\nimpose only a modest overhead on top of the POSIX-compatible API.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 18:19:53 GMT"}], "update_date": "2015-09-28", "authors_parsed": [["Escriva", "Robert", ""], ["Sirer", "Emin G\u00fcn", ""]]}, {"id": "1509.07919", "submitter": "Ang Li", "authors": "Ang Li, Radu Serban, Dan Negrut", "title": "Analysis of A Splitting Approach for the Parallel Solution of Linear\n  Systems on GPU Cards", "comments": "38 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.MS cs.NA", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We discuss an approach for solving sparse or dense banded linear systems\n${\\bf A} {\\bf x} = {\\bf b}$ on a Graphics Processing Unit (GPU) card. The\nmatrix ${\\bf A} \\in {\\mathbb{R}}^{N \\times N}$ is possibly nonsymmetric and\nmoderately large; i.e., $10000 \\leq N \\leq 500000$. The ${\\it split\\ and\\\nparallelize}$ (${\\tt SaP}$) approach seeks to partition the matrix ${\\bf A}$\ninto diagonal sub-blocks ${\\bf A}_i$, $i=1,\\ldots,P$, which are independently\nfactored in parallel. The solution may choose to consider or to ignore the\nmatrices that couple the diagonal sub-blocks ${\\bf A}_i$. This approach, along\nwith the Krylov subspace-based iterative method that it preconditions, are\nimplemented in a solver called ${\\tt SaP::GPU}$, which is compared in terms of\nefficiency with three commonly used sparse direct solvers: ${\\tt PARDISO}$,\n${\\tt SuperLU}$, and ${\\tt MUMPS}$. ${\\tt SaP::GPU}$, which runs entirely on\nthe GPU except several stages involved in preliminary row-column permutations,\nis robust and compares well in terms of efficiency with the aforementioned\ndirect solvers. In a comparison against Intel's ${\\tt MKL}$, ${\\tt SaP::GPU}$\nalso fares well when used to solve dense banded systems that are close to being\ndiagonally dominant. ${\\tt SaP::GPU}$ is publicly available and distributed as\nopen source under a permissive BSD3 license.\n", "versions": [{"version": "v1", "created": "Fri, 25 Sep 2015 23:04:17 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Li", "Ang", ""], ["Serban", "Radu", ""], ["Negrut", "Dan", ""]]}, {"id": "1509.07935", "submitter": "Weidong Li", "authors": "Weidong Li, Xi Liu, Xiaolu Zhang, Xuejie Zhang", "title": "A note on the dynamic dominant resource fairness mechanism", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.GT cs.DC cs.DS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Multi-resource fair allocation has beena hot topic of resource allocation.\nMost recently, a dynamic dominant resource fairness (DRF) mechanism is proposed\nfor dynamic multi-resource fair allocation. In this paper, we prove that the\ncompetitive ratio of the dynamic DRF mechanism is the reciprocal of the number\nof resource types, for two different objectives. Moreover, we develop a\nlinear-time algorithm to find a dynamic DRF solution at each step.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2015 01:36:54 GMT"}, {"version": "v2", "created": "Wed, 16 Dec 2015 03:33:03 GMT"}], "update_date": "2015-12-17", "authors_parsed": [["Li", "Weidong", ""], ["Liu", "Xi", ""], ["Zhang", "Xiaolu", ""], ["Zhang", "Xuejie", ""]]}, {"id": "1509.07989", "submitter": "Ruchir Gupta", "authors": "Nitin Singha, Ruchir Gupta, Yatindra Nath Singh", "title": "Resource allocation in Peer-to-Peer Networks: A Control-Theoretical\n  Perspective", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  P2P system rely on voluntary allocation of resources by its members due to\nabsence of any central controlling authority. This resource allocation can be\nviewed as classical control problem where feedback is the amount of resource\nreceived, which controls the output i.e. the amount of resources shared back to\nthe network by the node. The motivation behind the use of control system in\nresource allocation is to exploit already existing tools in control theory to\nimprove the overall allocation process and thereby solving the problem of\nfreeriding and whitewashing in the network. At the outset, we have derived the\ntransfer function to model the P2P system. Subsequently, through the simulation\nresults we have shown that transfer function was able to provide optimal value\nof resource sharing for the peers during the normal as well as high degree of\noverloading in the network. Thereafter we verified the accuracy of the transfer\nfunction derived by comparing its output with the simulated P2P network. To\ndemonstrate how control system reduces free riding it has been shown through\nsimulations how the control systems penalizes the nodes indulging in different\nlevels of freeriding. Our proposed control system shows considerable gain over\nexisting state of art algorithm. This improvement is achieved through PI action\nof controller. Since low reputation peers usually subvert reputation system by\nwhitewashing. We propose and substantiate a technique modifying transfer\nfunction such that systems' sluggishness becomes adaptive in such a way that it\nencourage genuine new comers to enter network and discourages member peers to\nwhitewash.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2015 15:00:45 GMT"}, {"version": "v2", "created": "Thu, 24 Dec 2015 14:21:50 GMT"}], "update_date": "2015-12-25", "authors_parsed": [["Singha", "Nitin", ""], ["Gupta", "Ruchir", ""], ["Singh", "Yatindra Nath", ""]]}, {"id": "1509.08001", "submitter": "Shiqiang Wang Mr.", "authors": "Fanzhao Wang, Lei Guo, Shiqiang Wang, Qingyang Song and Abbas\n  Jamalipour", "title": "Approaching Single-Hop Performance in Multi-Hop Networks: End-To-End\n  Known-Interference Cancellation (E2E-KIC)", "comments": null, "journal-ref": null, "doi": "10.1109/TVT.2015.2482124", "report-no": null, "categories": "cs.NI cs.DC cs.IT math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  To improve the efficiency of wireless data communications, new physical-layer\ntransmission methods based on known-interference cancellation (KIC) have been\ndeveloped. These methods share the common idea that the interference can be\ncancelled when the content of it is known. Existing work on KIC mainly focuses\non single-hop or two-hop networks, with physical-layer network coding (PNC) and\nfull-duplex (FD) communications as typical examples. This paper extends the\nidea of KIC to general multi-hop networks, and proposes an end-to-end KIC\n(E2E-KIC) transmission method together with its MAC design. With E2E-KIC,\nmultiple nodes in a flow passing through a few nodes in an arbitrary topology\ncan simultaneously transmit and receive on the same channel. We first present a\ntheoretical analysis on the effectiveness of E2E-KIC in an idealized case.\nThen, to support E2E-KIC in multi-hop networks with arbitrary topology, we\npropose an E2E-KIC-supported MAC protocol (E2E-KIC MAC), which is based on an\nextension of the Request-to-Send/Clear-to-Send (RTS/CTS) mechanism in the IEEE\n802.11 MAC. We also analytically analyze the performance of the proposed\nE2E-KIC MAC in the presence of hidden terminals. Simulation results illustrate\nthat the proposed E2E-KIC MAC protocol can improve the network throughput and\nreduce the end-to-end delay.\n", "versions": [{"version": "v1", "created": "Sat, 26 Sep 2015 16:01:26 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Wang", "Fanzhao", ""], ["Guo", "Lei", ""], ["Wang", "Shiqiang", ""], ["Song", "Qingyang", ""], ["Jamalipour", "Abbas", ""]]}, {"id": "1509.08231", "submitter": "Hsi-En Yu", "authors": "Hsi-En Yu and Weicheng Huang", "title": "Building a Virtual HPC Cluster with Auto Scaling by the Docker", "comments": "PRAGMA-ICDS 15", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Solving the software dependency issue under the HPC environment has always\nbeen a difficult task for both computing system administrators and application\nscientists. This work would like to tackle the issue by introducing the modern\ncontainer technology, the Docker, to be specific. By integrating the\nauto-scaling feature of service discovery with the light-weight virtualization\ntool, the Docker, the construction of a virtual cluster on top of physical\ncluster hardware is attempted. Thus, through the isolation of computing\nenvironment, a remedy of software dependency of HPC environment is possible.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 08:21:30 GMT"}], "update_date": "2015-09-29", "authors_parsed": [["Yu", "Hsi-En", ""], ["Huang", "Weicheng", ""]]}, {"id": "1509.08267", "submitter": "Nandini Singhal", "authors": "Nandini Singhal, Sathya Peri, Subrahmanyam Kalyanasundaram", "title": "Multi-threaded Graph Coloring Algorithm for Shared Memory Architecture", "comments": null, "journal-ref": null, "doi": "10.1145/3007748.3018281", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we present multi-threaded algorithms for graph coloring\nsuitable to the shared memory programming model. We modify an existing\nalgorithm widely used in the literature and prove the correctness of the\nmodified algorithm. We also propose a new approach to solve the problem of\ncoloring using locks. Using datasets from real world graphs, we evaluate the\nperformance of the algorithms on the Intel platform. We compare the performance\nof the sequential approach v/s our proposed approach and analyze the speedup\nobtained against the existing algorithm from the literature. The results show\nthat the speedup obtained is consequential. We also provide a direction for\nfuture work towards improving the performance further in terms of different\nmetrics.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 11:03:43 GMT"}, {"version": "v2", "created": "Sun, 4 Oct 2015 17:27:14 GMT"}], "update_date": "2017-05-11", "authors_parsed": [["Singhal", "Nandini", ""], ["Peri", "Sathya", ""], ["Kalyanasundaram", "Subrahmanyam", ""]]}, {"id": "1509.08443", "submitter": "Ayush Dubey", "authors": "Ayush Dubey, Greg D. Hill, Robert Escriva, Emin G\\\"un Sirer", "title": "Weaver: A High-Performance, Transactional Graph Database Based on\n  Refinable Timestamps", "comments": null, "journal-ref": null, "doi": "10.14778/2983200.2983202", "report-no": null, "categories": "cs.DC cs.DB", "license": "http://creativecommons.org/licenses/by/4.0/", "abstract": "  Graph databases have become an increasingly common infrastructure component.\nYet existing systems either operate on offline snapshots, provide weak\nconsistency guarantees, or use expensive concurrency control techniques that\nlimit performance. In this paper, we introduce a new distributed graph\ndatabase, called Weaver, which enables efficient, transactional graph analyses\nas well as strictly serializable ACID transactions on dynamic graphs. The key\ninsight that allows Weaver to combine strict serializability with horizontal\nscalability and high performance is a novel request ordering mechanism called\nrefinable timestamps. This technique couples coarse-grained vector timestamps\nwith a fine-grained timeline oracle to pay the overhead of strong consistency\nonly when needed. Experiments show that Weaver enables a Bitcoin blockchain\nexplorer that is 8x faster than Blockchain.info, and achieves 12x higher\nthroughput than the Titan graph database on social network workloads and 4x\nlower latency than GraphLab on offline graph traversal workloads.\n", "versions": [{"version": "v1", "created": "Mon, 28 Sep 2015 19:30:30 GMT"}, {"version": "v2", "created": "Mon, 20 Jun 2016 03:41:20 GMT"}], "update_date": "2016-09-20", "authors_parsed": [["Dubey", "Ayush", ""], ["Hill", "Greg D.", ""], ["Escriva", "Robert", ""], ["Sirer", "Emin G\u00fcn", ""]]}, {"id": "1509.08560", "submitter": "EPTCS", "authors": "Luca Bortolussi (Saarland University, University of Trieste,\n  ISTI-CNR), Rocco De Nicola (IMT Lucca), Vashti Galpin (University of\n  Edinburgh), Stephen Gilmore (University of Edinburgh), Jane Hillston\n  (University of Edinburgh), Diego Latella (ISTI-CNR), Michele Loreti\n  (Universit\\`a di Firenze, IMT Lucca), Mieke Massink (ISTI-CNR)", "title": "CARMA: Collective Adaptive Resource-sharing Markovian Agents", "comments": "In Proceedings QAPL 2015, arXiv:1509.08169", "journal-ref": "EPTCS 194, 2015, pp. 16-31", "doi": "10.4204/EPTCS.194.2", "report-no": null, "categories": "cs.PL cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we present CARMA, a language recently defined to support\nspecification and analysis of collective adaptive systems. CARMA is a\nstochastic process algebra equipped with linguistic constructs specifically\ndeveloped for modelling and programming systems that can operate in open-ended\nand unpredictable environments. This class of systems is typically composed of\na huge number of interacting agents that dynamically adjust and combine their\nbehaviour to achieve specific goals. A CARMA model, termed a collective,\nconsists of a set of components, each of which exhibits a set of attributes. To\nmodel dynamic aggregations, which are sometimes referred to as ensembles, CARMA\nprovides communication primitives that are based on predicates over the\nexhibited attributes. These predicates are used to select the participants in a\ncommunication. Two communication mechanisms are provided in the CARMA language:\nmulticast-based and unicast-based. In this paper, we first introduce the basic\nprinciples of CARMA and then we show how our language can be used to support\nspecification with a simple but illustrative example of a socio-technical\ncollective adaptive system.\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 02:10:19 GMT"}], "update_date": "2015-09-30", "authors_parsed": [["Bortolussi", "Luca", "", "Saarland University, University of Trieste,\n  ISTI-CNR"], ["De Nicola", "Rocco", "", "IMT Lucca"], ["Galpin", "Vashti", "", "University of\n  Edinburgh"], ["Gilmore", "Stephen", "", "University of Edinburgh"], ["Hillston", "Jane", "", "University of Edinburgh"], ["Latella", "Diego", "", "ISTI-CNR"], ["Loreti", "Michele", "", "Universit\u00e0 di Firenze, IMT Lucca"], ["Massink", "Mieke", "", "ISTI-CNR"]]}, {"id": "1509.08955", "submitter": "Kensworth Subratie", "authors": "Kensworth Subratie, Saumitra Aditya, Renato Figueiredo, Cayelan C.\n  Carey and Paul Hanson", "title": "GRAPLEr: A Distributed Collaborative Environment for Lake Ecosystem\n  Modeling that Integrates Overlay Networks, High-throughput Computing, and Web\n  Services", "comments": "8 pages, 7 figures. PRAGMA29", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The GLEON Research And PRAGMA Lake Expedition -- GRAPLE -- is a collaborative\neffort between computer science and lake ecology researchers. It aims to\nimprove our understanding and predictive capacity of the threats to the water\nquality of our freshwater resources, including climate change. This paper\npresents GRAPLEr, a distributed computing system used to address the modeling\nneeds of GRAPLE researchers. GRAPLEr integrates and applies overlay virtual\nnetwork, high-throughput computing, and Web service technologies in a novel\nway. First, its user-level IP-over-P2P (IPOP) overlay network allows compute\nand storage resources distributed across independently-administered\ninstitutions (including private and public clouds) to be aggregated into a\ncommon virtual network, despite the presence of firewalls and network address\ntranslators. Second, resources aggregated by the IPOP virtual network run\nunmodified high-throughput computing middleware (HTCondor) to enable large\nnumbers of model simulations to be executed concurrently across the distributed\ncomputing resources. Third, a Web service interface allows end users to submit\njob requests to the system using client libraries that integrate with the R\nstatistical computing environment. The paper presents the GRAPLEr architecture,\ndescribes its implementation and reports on its performance for batches of\nGeneral Lake Model (GLM) simulations across three cloud infrastructures\n(University of Florida, CloudLab, and Microsoft Azure).\n", "versions": [{"version": "v1", "created": "Tue, 29 Sep 2015 21:17:56 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Subratie", "Kensworth", ""], ["Aditya", "Saumitra", ""], ["Figueiredo", "Renato", ""], ["Carey", "Cayelan C.", ""], ["Hanson", "Paul", ""]]}, {"id": "1509.09047", "submitter": "Stephan Friedrichs", "authors": "Stephan Friedrichs and Christoph Lenzen", "title": "Parallel Metric Tree Embedding based on an Algebraic View on\n  Moore-Bellman-Ford", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A \\emph{metric tree embedding} of expected \\emph{stretch~$\\alpha \\geq 1$}\nmaps a weighted $n$-node graph $G = (V, E, \\omega)$ to a weighted tree $T =\n(V_T, E_T, \\omega_T)$ with $V \\subseteq V_T$ such that, for all $v,w \\in V$,\n$\\operatorname{dist}(v, w, G) \\leq \\operatorname{dist}(v, w, T)$ and\n$operatorname{E}[\\operatorname{dist}(v, w, T)] \\leq \\alpha\n\\operatorname{dist}(v, w, G)$. Such embeddings are highly useful for designing\nfast approximation algorithms, as many hard problems are easy to solve on tree\ninstances. However, to date the best parallel $(\\operatorname{polylog}\nn)$-depth algorithm that achieves an asymptotically optimal expected stretch of\n$\\alpha \\in \\operatorname{O}(\\log n)$ requires $\\operatorname{\\Omega}(n^2)$\nwork and a metric as input.\n  In this paper, we show how to achieve the same guarantees using\n$\\operatorname{polylog} n$ depth and $\\operatorname{\\tilde{O}}(m^{1+\\epsilon})$\nwork, where $m = |E|$ and $\\epsilon > 0$ is an arbitrarily small constant.\nMoreover, one may further reduce the work to $\\operatorname{\\tilde{O}}(m +\nn^{1+\\epsilon})$ at the expense of increasing the expected stretch to\n$\\operatorname{O}(\\epsilon^{-1} \\log n)$.\n  Our main tool in deriving these parallel algorithms is an algebraic\ncharacterization of a generalization of the classic Moore-Bellman-Ford\nalgorithm. We consider this framework, which subsumes a variety of previous\n\"Moore-Bellman-Ford-like\" algorithms, to be of independent interest and discuss\nit in depth. In our tree embedding algorithm, we leverage it for providing\nefficient query access to an approximate metric that allows sampling the tree\nusing $\\operatorname{polylog} n$ depth and $\\operatorname{\\tilde{O}}(m)$ work.\n  We illustrate the generality and versatility of our techniques by various\nexamples and a number of additional results.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 07:51:48 GMT"}, {"version": "v2", "created": "Tue, 20 Oct 2015 15:26:19 GMT"}, {"version": "v3", "created": "Fri, 22 Apr 2016 12:28:16 GMT"}, {"version": "v4", "created": "Wed, 24 Aug 2016 08:34:52 GMT"}], "update_date": "2016-08-25", "authors_parsed": [["Friedrichs", "Stephan", ""], ["Lenzen", "Christoph", ""]]}, {"id": "1509.09199", "submitter": "Mark Zwolinski", "authors": "Anton Kulakov, Mark Zwolinski, Jeff Reeve", "title": "Fault Tolerance in Distributed Neural Computing", "comments": null, "journal-ref": null, "doi": "10.13140/RG.2.1.1387.0800", "report-no": null, "categories": "cs.NE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  With the increasing complexity of computing systems, complete hardware\nreliability can no longer be guaranteed. We need, however, to ensure overall\nsystem reliability. One of the most important features of artificial neural\nnetworks is their intrinsic fault-tolerance. The aim of this work is to\ninvestigate whether such networks have features that can be applied to wider\ncomputational systems. This paper presents an analysis, in both the learning\nand operational phases, of a distributed feed-forward neural network with\ndecentralised event-driven time management, which is insensitive to\nintermittent faults caused by unreliable communication or faulty hardware\ncomponents. The learning rules used in the model are local in space and time,\nwhich allows efficient scalable distributed implementation. We investigate the\noverhead caused by injected faults and analyse the sensitivity to limited\nfailures in the computational hardware in different areas of the network.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 14:46:44 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Kulakov", "Anton", ""], ["Zwolinski", "Mark", ""], ["Reeve", "Jeff", ""]]}, {"id": "1509.09207", "submitter": "Yukiko Yamauchi", "authors": "Yukiko Yamauchi, Taichi Uehara, Masafumi Yamashita", "title": "Pattern Formation Problem for Synchronous Mobile Robots in the Three\n  Dimensional Euclidean Space", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We consider a swarm of autonomous mobile robots each of which is an anonymous\npoint in the three-dimensional Euclidean space (3D-space) and synchronously\nexecutes a common distributed algorithm. We investigate the pattern formation\nproblem that requires the robots to form a given target pattern from an initial\nconfiguration and characterize the problem by showing a necessary and\nsufficient condition for the robots to form a given target pattern.\n  The pattern formation problem in the two dimensional Euclidean space\n(2D-space) has been investigated by Suzuki and Yamashita (SICOMP 1999, TCS\n2010), and Fujinaga et al. (SICOMP 2015). The symmetricity $\\rho(P)$ of a\nconfiguration (i.e., the positions of robots) $P$ is intuitively the order of\nthe cyclic group that acts on $P$. It has been shown that fully-synchronous\n(FSYNC) robots can form a target pattern $F$ from an initial configuration $P$\nif and only if $\\rho(P)$ divides $\\rho(F)$.\n  We extend the notion of symmetricity to 3D-space by using the rotation groups\neach of which is defined by a set of rotation axes and their arrangement. We\ndefine the symmetricity $\\varrho(P)$ of configuration $P$ in 3D-space as the\nset of rotation groups that acts on $P$ and whose rotation axes do not contain\nany robot. We show the following necessary and sufficient condition for the\npattern formation problem which is a natural extension of the existing results\nof the pattern formation problem in 2D-space: FSYNC robots in 3D-space can form\na target pattern $F$ from an initial configuration $P$ if and only if\n$\\varrho(P) \\subseteq \\varrho(F)$. For solvable instances, we present a pattern\nformation algorithm for oblivious FSYNC robots. The insight of this paper is\nthat symmetry of mobile robots in 3D-space is sometimes lower than the symmetry\nof their positions and the robots can show their symmetry by their movement.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 15:05:06 GMT"}, {"version": "v2", "created": "Wed, 24 Feb 2016 08:33:23 GMT"}], "update_date": "2016-02-25", "authors_parsed": [["Yamauchi", "Yukiko", ""], ["Uehara", "Taichi", ""], ["Yamashita", "Masafumi", ""]]}, {"id": "1509.09282", "submitter": "Shanying Zhu", "authors": "Shanying Zhu, Yeng Chai Soh, and Lihua Xie", "title": "Distributed Inference for Relay-Assisted Sensor Networks With\n  Intermittent Measurements Over Fading Channels", "comments": "32 pages, 14 figures", "journal-ref": null, "doi": "10.1109/TSP.2015.2489606", "report-no": null, "categories": "cs.IT cs.DC math.IT", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, we consider a general distributed estimation problem in\nrelay-assisted sensor networks by taking into account time-varying asymmetric\ncommunications, fading channels and intermittent measurements. Motivated by\ncentralized filtering algorithms, we propose a distributed innovation-based\nestimation algorithm by combining the measurement innovation (assimilation of\nnew measurement) and local data innovation (incorporation of neighboring data).\nOur algorithm is fully distributed which does not need a fusion center. We\nestablish theoretical results regarding asymptotic unbiasedness and consistency\nof the proposed algorithm. Specifically, in order to cope with time-varying\nasymmetric communications, we utilize an ordering technique and the generalized\nPerron complement to manipulate the first and second moment analyses in a\ntractable framework. Furthermore, we present a performance-oriented design of\nthe proposed algorithm for energy-constrained networks based on the theoretical\nresults. Simulation results corroborate the theoretical findings, thus\ndemonstrating the effectiveness of the proposed algorithm.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 18:14:08 GMT"}], "update_date": "2016-04-20", "authors_parsed": [["Zhu", "Shanying", ""], ["Soh", "Yeng Chai", ""], ["Xie", "Lihua", ""]]}, {"id": "1509.09313", "submitter": "Grey Ballard", "authors": "Ramakrishnan Kannan and Grey Ballard and Haesun Park", "title": "A High-Performance Parallel Algorithm for Nonnegative Matrix\n  Factorization", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Non-negative matrix factorization (NMF) is the problem of determining two\nnon-negative low rank factors $W$ and $H$, for the given input matrix $A$, such\nthat $A \\approx W H$. NMF is a useful tool for many applications in different\ndomains such as topic modeling in text mining, background separation in video\nanalysis, and community detection in social networks. Despite its popularity in\nthe data mining community, there is a lack of efficient parallel software to\nsolve the problem for big datasets. Existing distributed-memory algorithms are\nlimited in terms of performance and applicability, as they are implemented\nusing Hadoop and are designed only for sparse matrices.\n  We propose a distributed-memory parallel algorithm that computes the\nfactorization by iteratively solving alternating non-negative least squares\n(NLS) subproblems for $W$ and $H$. To our knowledge, our algorithm is the first\nhigh-performance parallel algorithm for NMF. It maintains the data and factor\nmatrices in memory (distributed across processors), uses MPI for interprocessor\ncommunication, and, in the dense case, provably minimizes communication costs\n(under mild assumptions). As opposed to previous implementations, our algorithm\nis also flexible: (1) it performs well for dense and sparse matrices, and (2)\nit allows the user to choose from among multiple algorithms for solving local\nNLS subproblems within the alternating iterations. We demonstrate the\nscalability of our algorithm and compare it with baseline implementations,\nshowing significant performance improvements.\n", "versions": [{"version": "v1", "created": "Wed, 30 Sep 2015 19:47:39 GMT"}], "update_date": "2015-10-01", "authors_parsed": [["Kannan", "Ramakrishnan", ""], ["Ballard", "Grey", ""], ["Park", "Haesun", ""]]}]