[{"id": "1410.0245", "submitter": "Jeremy Kun", "authors": "Benjamin Fish and Jeremy Kun and \\'Ad\\'am D\\'aniel Lelkes and Lev\n  Reyzin and Gy\\\"orgy Tur\\'an", "title": "On the Computational Complexity of MapReduce", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CC cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study MapReduce computations from a complexity-theoretic\nperspective. First, we formulate a uniform version of the MRC model of Karloff\net al. (2010). We then show that the class of regular languages, and moreover\nall of sublogarithmic space, lies in constant round MRC. This result also\napplies to the MPC model of Andoni et al. (2014). In addition, we prove that,\nconditioned on a variant of the Exponential Time Hypothesis, there are strict\nhierarchies within MRC so that increasing the number of rounds or the amount of\ntime per processor increases the power of MRC. To the best of our knowledge we\nare the first to approach the MapReduce model with complexity-theoretic\ntechniques, and our work lays the foundation for further analysis relating\nMapReduce to established complexity classes.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2014 14:44:01 GMT"}, {"version": "v2", "created": "Tue, 6 Oct 2015 18:43:00 GMT"}], "update_date": "2015-10-07", "authors_parsed": [["Fish", "Benjamin", ""], ["Kun", "Jeremy", ""], ["Lelkes", "\u00c1d\u00e1m D\u00e1niel", ""], ["Reyzin", "Lev", ""], ["Tur\u00e1n", "Gy\u00f6rgy", ""]]}, {"id": "1410.0329", "submitter": "Equipe Roma", "authors": "Lionel Eyraud-Dubois (LaBRI, INRIA Bordeaux - Sud-Ouest), Loris\n  Marchal (ENS Lyon / CNRS / Inria Grenoble Rh\\^one-Alpes, LIP), Oliver Sinnen\n  (ECE), Fr\\'ed\\'eric Vivien (ENS Lyon / CNRS / Inria Grenoble Rh\\^one-Alpes,\n  LIP)", "title": "Parallel scheduling of task trees with limited memory", "comments": "arXiv admin note: substantial text overlap with arXiv:1210.2580", "journal-ref": "N&deg; RR-8606 (2014)", "doi": null, "report-no": "RR-8606", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper investigates the execution of tree-shaped task graphs using\nmultiple processors. Each edge of such a tree represents some large data. A\ntask can only be executed if all input and output data fit into memory, and a\ndata can only be removed from memory after the completion of the task that uses\nit as an input data. Such trees arise, for instance, in the multifrontal method\nof sparse matrix factorization. The peak memory needed for the processing of\nthe entire tree depends on the execution order of the tasks. With one processor\nthe objective of the tree traversal is to minimize the required memory. This\nproblem was well studied and optimal polynomial algorithms were proposed. Here,\nwe extend the problem by considering multiple processors, which is of obvious\ninterest in the application area of matrix factorization. With multiple\nprocessors comes the additional objective to minimize the time needed to\ntraverse the tree, i.e., to minimize the makespan. Not surprisingly, this\nproblem proves to be much harder than the sequential one. We study the\ncomputational complexity of this problem and provide inapproximability results\neven for unit weight trees. We design a series of practical heuristics\nachieving different trade-offs between the minimization of peak memory usage\nand makespan. Some of these heuristics are able to process a tree while keeping\nthe memory usage under a given memory limit. The different heuristics are\nevaluated in an extensive experimental evaluation using realistic trees.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2014 19:02:20 GMT"}], "update_date": "2014-10-02", "authors_parsed": [["Eyraud-Dubois", "Lionel", "", "LaBRI, INRIA Bordeaux - Sud-Ouest"], ["Marchal", "Loris", "", "ENS Lyon / CNRS / Inria Grenoble Rh\u00f4ne-Alpes, LIP"], ["Sinnen", "Oliver", "", "ECE"], ["Vivien", "Fr\u00e9d\u00e9ric", "", "ENS Lyon / CNRS / Inria Grenoble Rh\u00f4ne-Alpes,\n  LIP"]]}, {"id": "1410.0373", "submitter": "Aleem Akhtar Asif", "authors": "Aamir Shafi, Aleem Akhtar, Ansar Javed, Bryan Carpenter", "title": "Teaching Parallel Programming Using Java", "comments": "8 Pages, 6 figures, MPJ Express, MPI Java, Teaching Parallel\n  Programming", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper presents an overview of the \"Applied Parallel Computing\" course\ntaught to final year Software Engineering undergraduate students in Spring 2014\nat NUST, Pakistan. The main objective of the course was to introduce practical\nparallel programming tools and techniques for shared and distributed memory\nconcurrent systems. A unique aspect of the course was that Java was used as the\nprinciple programming language. The course was divided into three sections. The\nfirst section covered parallel programming techniques for shared memory systems\nthat include multicore and Symmetric Multi-Processor (SMP) systems. In this\nsection, Java threads was taught as a viable programming API for such systems.\nThe second section was dedicated to parallel programming tools meant for\ndistributed memory systems including clusters and network of computers. We used\nMPJ Express-a Java MPI library-for conducting programming assignments and lab\nwork for this section. The third and the final section covered advanced topics\nincluding the MapReduce programming model using Hadoop and the General Purpose\nComputing on Graphics Processing Units (GPGPU).\n", "versions": [{"version": "v1", "created": "Wed, 27 Aug 2014 14:14:16 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Shafi", "Aamir", ""], ["Akhtar", "Aleem", ""], ["Javed", "Ansar", ""], ["Carpenter", "Bryan", ""]]}, {"id": "1410.0412", "submitter": "Markus Wittmann", "authors": "M. Wittmann, T. Zeiser, G. Hager, G. Wellein", "title": "Modeling and analyzing performance for highly optimized propagation\n  steps of the lattice Boltzmann method on sparse lattices", "comments": "Updated and extended version. Submitted to ISC 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Computational fluid dynamics (CFD) requires a vast amount of compute cycles\non contemporary large-scale parallel computers. Hence, performance optimization\nis a pivotal activity in this field of computational science. Not only does it\nreduce the time to solution, but it also allows to minimize the energy\nconsumption. In this work we study performance optimizations for an\nMPI-parallel lattice Boltzmann-based flow solver that uses a sparse lattice\nrepresentation with indirect addressing. First we describe how this indirect\naddressing can be minimized in order to increase the single-core and chip-level\nperformance. Second, the communication overhead is reduced via appropriate\npartitioning, but maintaining the single core performance improvements. Both\noptimizations allow to run the solver at an operating point with minimal energy\nconsumption.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2014 23:26:08 GMT"}, {"version": "v2", "created": "Wed, 23 Dec 2015 12:19:10 GMT"}], "update_date": "2015-12-24", "authors_parsed": [["Wittmann", "M.", ""], ["Zeiser", "T.", ""], ["Hager", "G.", ""], ["Wellein", "G.", ""]]}, {"id": "1410.0462", "submitter": "Jesper Larsson Tr\\\"aff", "authors": "Jesper Larsson Tr\\\"aff, Martin Wimmer", "title": "An improved, easily computable combinatorial lower bound for weighted\n  graph bipartitioning", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  There has recently been much progress on exact algorithms for the\n(un)weighted graph (bi)partitioning problem using branch-and-bound and related\nmethods. In this note we present and improve an easily computable, purely\ncombinatorial lower bound for the weighted bipartitioning problem. The bound is\ncomputable in $O(n\\log n+m)$ time steps for weighted graphs with $n$ vertices\nand $m$ edges. In the branch-and-bound setting, the bound for each new\nsubproblem can be updated in $O(n+(m/n)\\log n)$ time steps amortized over a\nseries of $n$ branching steps; a rarely triggered tightening of the bound\nrequires search on the graph of unassigned vertices and can take from $O(n+m)$\nto $O(nm+n^2\\log n)$ steps depending on implementation and possible bound\nquality. Representing a subproblem uses $O(n)$ space. Although the bound is\nweak, we believe that it can be advantageous in a parallel setting to be able\nto generate many subproblems fast, possibly out-weighting the advantages of\ntighter, but much more expensive (algebraic, spectral, flow) lower bounds.\n  We use a recent priority task-scheduling framework for giving a parallel\nimplementation, and show the relative improvements in bound quality and\nsolution speed by the different contributions of the lower bound. A detailed\ncomparison with standardized input graphs to other lower bounds and frameworks\nis pending. Detailed investigations of branching and subproblem selection rules\nare likewise not the focus here, but various options are discussed.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 07:32:12 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Tr\u00e4ff", "Jesper Larsson", ""], ["Wimmer", "Martin", ""]]}, {"id": "1410.0562", "submitter": "Jacopo Pantaleoni", "authors": "Jacopo Pantaleoni", "title": "A massively parallel algorithm for constructing the BWT of large string\n  sets", "comments": null, "journal-ref": null, "doi": null, "report-no": "NVR-2014-002", "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new scalable, lightweight algorithm to incrementally construct\nthe BWT and FM-index of large string sets such as those produced by Next\nGeneration Sequencing. The algorithm is designed for massive parallelism and\ncan effectively exploit the combination of low capacity high bandwidth memory\nand slower external system memory typical of GPU accelerated systems.\nParticularly, for a string set of n characters from an alphabet with \\sigma\nsymbols, it uses a constant amount of high-bandwidth memory and at most 3n\nlog(\\sigma) bits of system memory. Given that deep memory hierarchies are\nbecoming a pervasive trait of high performance computing architectures, we\nbelieve this to be a relevant feature. The implementation can handle reads of\narbitrary length and is up to 2 and respectively 6.5 times faster than\nstate-of-the-art for short and long genomic reads\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 14:25:51 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Pantaleoni", "Jacopo", ""]]}, {"id": "1410.0573", "submitter": "Thomas Nickson", "authors": "Thomas Nickson, Igor Potapov", "title": "Broadcasting Automata and Patterns on Z^2", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.FL cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Broadcasting Automata model draws inspiration from a variety of sources\nsuch as Ad-Hoc radio networks, cellular automata, neighbourhood se- quences and\nnature, employing many of the same pattern forming methods that can be seen in\nthe superposition of waves and resonance. Algorithms for broad- casting\nautomata model are in the same vain as those encountered in distributed\nalgorithms using a simple notion of waves, messages passed from automata to au-\ntomata throughout the topology, to construct computations. The waves generated\nby activating processes in a digital environment can be used for designing a\nvari- ety of wave algorithms. In this chapter we aim to study the geometrical\nshapes of informational waves on integer grid generated in broadcasting\nautomata model as well as their potential use for metric approximation in a\ndiscrete space. An explo- ration of the ability to vary the broadcasting radius\nof each node leads to results of categorisations of digital discs, their form,\ncomposition, encodings and gener- ation. Results pertaining to the nodal\npatterns generated by arbitrary transmission radii on the plane are explored\nwith a connection to broadcasting sequences and ap- proximation of discrete\nmetrics of which results are given for the approximation of astroids, a\npreviously unachievable concave metric, through a novel application of the\naggregation of waves via a number of explored functions.\n", "versions": [{"version": "v1", "created": "Thu, 2 Oct 2014 14:41:57 GMT"}], "update_date": "2014-10-03", "authors_parsed": [["Nickson", "Thomas", ""], ["Potapov", "Igor", ""]]}, {"id": "1410.0707", "submitter": "Pablo Romero Rodr\\'iguez", "authors": "Eduardo Canale, Pablo Romero, Gerardo Rubino", "title": "A Full Characterization of Irrelevant Components in Diameter Constrained\n  Reliability", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC math.CO", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In classical network reliability analysis, the system under study is a\nnetwork with perfect nodes but imperfect link, that fail stochastically and\nindependently. There, the goal is to find the probability that the resulting\nrandom graph is connected, called \\emph{reliability}. Although the exact\nreliability computation belongs to the class of $\\mathcal{NP}$-Hard problems,\nthe literature offers three exact methods for exact reliability computation, to\nknow, Sum of Disjoint Products (SDPs), Inclusion-Exclusion and Factorization.\n  Inspired in delay-sensitive applications in telecommunications, H\\'ector\nCancela and Louis Petingi defined in 2001 the diameter-constrained reliability,\nwhere terminals are required to be connected by $d$ hops or less, being $d$ a\npositive integer, called diameter.\n  Factorization theory in classical network reliability is a mature area.\nHowever, an extension to the diameter-constrained context requires at least the\nrecognition of irrelevant links, and an extension of deletion-contraction\nformula. In this paper, we fully characterize the determination of irrelevant\nlinks. Diameter-constrained reliability invariants are presented, which,\ntogether with the recognition of irrelevant links, represent the\nbuilding-blocks for a new factorization theory. The paper is closed with a\ndiscussion of trends for future work.\n", "versions": [{"version": "v1", "created": "Wed, 1 Oct 2014 10:45:09 GMT"}], "update_date": "2014-10-06", "authors_parsed": [["Canale", "Eduardo", ""], ["Romero", "Pablo", ""], ["Rubino", "Gerardo", ""]]}, {"id": "1410.0956", "submitter": "Federico Rossi", "authors": "Federico Rossi and Marco Pavone", "title": "Distributed consensus with mixed time/communication bandwidth\n  performance metrics", "comments": "Draft, submitted to Allerton 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SY cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we study the inherent trade-off between time and communication\ncomplexity for the distributed consensus problem. In our model, communication\ncomplexity is measured as the maximum data throughput (in bits per second) sent\nthrough the network at a given instant. Such a notion of communication\ncomplexity, referred to as bandwidth complexity, is related to the frequency\nbandwidth a designer should collectively allocate to the agents if they were to\ncommunicate via a wireless channel, which represents an important constraint\nfor dense robotic networks. We prove a lower bound on the bandwidth complexity\nof the consensus problem and provide a consensus algorithm that is\nbandwidth-optimal for a wide class of consensus functions. We then propose a\ndistributed algorithm that can trade communication complexity versus time\ncomplexity as a function of a tunable parameter, which can be adjusted by a\nsystem designer as a function of the properties of the wireless communication\nchannel. We rigorously characterize the tunable algorithm's worst-case\nbandwidth complexity and show that it compares favorably with the bandwidth\ncomplexity of well-known consensus algorithm.\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2014 18:52:00 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Rossi", "Federico", ""], ["Pavone", "Marco", ""]]}, {"id": "1410.1159", "submitter": "Aleksandar Milenkoski", "authors": "Aleksandar Milenkoski and Alexandru Iosup and Samuel Kounev and Kai\n  Sachs and Piotr Rygielski and Jason Ding and Walfredo Cirne and Florian\n  Rosenberg", "title": "Cloud Usage Patterns: A Formalism for Description of Cloud Usage\n  Scenarios", "comments": "SPEC (Standard Performance Evaluation Corporation) Research Group ---\n  Cloud Working Group", "journal-ref": null, "doi": null, "report-no": "SPEC-RG-2013-001", "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing is becoming an increasingly lucrative branch of the existing\ninformation and communication technologies (ICT). Enabling a debate about cloud\nusage scenarios can help with attracting new customers, sharing best-practices,\nand designing new cloud services. In contrast to previous approaches, which\nhave attempted mainly to formalize the common service delivery models (i.e.,\nInfrastructure-as-a-Service, Platform-as-a-Service, and Software-as-a-Service),\nin this work, we propose a formalism for describing common cloud usage\nscenarios referred to as cloud usage patterns. Our formalism takes a\nstructuralist approach allowing decomposition of a cloud usage scenario into\nelements corresponding to the common cloud service delivery models.\nFurthermore, our formalism considers several cloud usage patterns that have\nrecently emerged, such as hybrid services and value chains in which mediators\nare involved, also referred to as value chains with mediators. We propose a\nsimple yet expressive textual and visual language for our formalism, and we\nshow how it can be used in practice for describing a variety of real-world\ncloud usage scenarios. The scenarios for which we demonstrate our formalism\ninclude resource provisioning of global providers of infrastructure and/or\nplatform resources, online social networking services, user-data processing\nservices, online customer and ticketing services, online asset management and\nbanking applications, CRM (Customer Relationship Management) applications, and\nonline social gaming applications.\n", "versions": [{"version": "v1", "created": "Sun, 5 Oct 2014 13:28:42 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Milenkoski", "Aleksandar", ""], ["Iosup", "Alexandru", ""], ["Kounev", "Samuel", ""], ["Sachs", "Kai", ""], ["Rygielski", "Piotr", ""], ["Ding", "Jason", ""], ["Cirne", "Walfredo", ""], ["Rosenberg", "Florian", ""]]}, {"id": "1410.1209", "submitter": "Himanshu Chauhan", "authors": "Himanshu Chauhan and Vijay K. Garg", "title": "Necessary and Sufficient Conditions on Partial Orders for Modeling\n  Concurrent Computations", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Partial orders are used extensively for modeling and analyzing concurrent\ncomputations. In this paper, we define two properties of partially ordered\nsets: width-extensibility and interleaving-consistency, and show that a partial\norder can be a valid state based model: (1) of some synchronous concurrent\ncomputation iff it is width-extensible, and (2) of some asynchronous concurrent\ncomputation iff it is width-extensible and interleaving-consistent. We also\nshow a duality between the event based and state based models of concurrent\ncomputations, and give algorithms to convert models between the two domains.\nWhen applied to the problem of checkpointing, our theory leads to a better\nunderstanding of some existing results and algorithms in the field. It also\nleads to efficient detection algorithms for predicates whose evaluation\nrequires knowledge of states from all the processes in the system.\n", "versions": [{"version": "v1", "created": "Sun, 5 Oct 2014 20:26:27 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Chauhan", "Himanshu", ""], ["Garg", "Vijay K.", ""]]}, {"id": "1410.1237", "submitter": "Mahantesh Halappanavar", "authors": "Hao Lu and Mahantesh Halappanavar and Ananth Kalyanaraman", "title": "Parallel Heuristics for Scalable Community Detection", "comments": "Submitted to a journal", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SI cs.DC physics.soc-ph", "license": "http://creativecommons.org/licenses/publicdomain/", "abstract": "  Community detection has become a fundamental operation in numerous\ngraph-theoretic applications. It is used to reveal natural divisions that exist\nwithin real world networks without imposing prior size or cardinality\nconstraints on the set of communities. Despite its potential for application,\nthere is only limited support for community detection on large-scale parallel\ncomputers, largely owing to the irregular and inherently sequential nature of\nthe underlying heuristics. In this paper, we present parallelization heuristics\nfor fast community detection using the Louvain method as the serial template.\nThe Louvain method is an iterative heuristic for modularity optimization.\nOriginally developed by Blondel et al. in 2008, the method has become\nincreasingly popular owing to its ability to detect high modularity community\npartitions in a fast and memory-efficient manner. However, the method is also\ninherently sequential, thereby limiting its scalability. Here, we observe\ncertain key properties of this method that present challenges for its\nparallelization, and consequently propose heuristics that are designed to break\nthe sequential barrier. For evaluation purposes, we implemented our heuristics\nusing OpenMP multithreading, and tested them over real world graphs derived\nfrom multiple application domains (e.g., internet, citation, biological).\nCompared to the serial Louvain implementation, our parallel implementation is\nable to produce community outputs with a higher modularity for most of the\ninputs tested, in comparable number or fewer iterations, while providing\nabsolute speedups of up to 16x using 32 threads.\n", "versions": [{"version": "v1", "created": "Mon, 6 Oct 2014 01:54:15 GMT"}, {"version": "v2", "created": "Tue, 7 Oct 2014 01:01:12 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Lu", "Hao", ""], ["Halappanavar", "Mahantesh", ""], ["Kalyanaraman", "Ananth", ""]]}, {"id": "1410.1309", "submitter": "Moreno Marzolla", "authors": "Alkida Balliu, Dennis Olivetti, Ozalp Babaoglu, Moreno Marzolla, Alina\n  S\\^irbu", "title": "BiDAl: Big Data Analyzer for Cluster Traces", "comments": "published in E. Pl\\\"odereder, L. Grunske, E. Schneider, D. Ull\n  (editors), proc. INFORMATIK 2014 Workshop on System Software Support for Big\n  Data (BigSys 2014), September 25--26 2014, Stuttgart, Germany, Lecture Notes\n  in Informatics (LNI) Proceedings, Series of the Gesellschaft f\\\"ur Informatik\n  (GI), Volume P-232, pp. 1781--1795, ISBN 978-3-88579-626-8, ISSN 1617-5468", "journal-ref": "proc. INFORMATIK 2014 Workshop on System Software Support for Big\n  Data (BigSys 2014), Lecture Notes in Informatics (LNI), Volume P-232, pp.\n  1781-1795, ISBN 78-3-88579-626-8, ISSN 1617-5468", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern data centers that provide Internet-scale services are stadium-size\nstructures housing tens of thousands of heterogeneous devices (server clusters,\nnetworking equipment, power and cooling infrastructures) that must operate\ncontinuously and reliably. As part of their operation, these devices produce\nlarge amounts of data in the form of event and error logs that are essential\nnot only for identifying problems but also for improving data center efficiency\nand management. These activities employ data analytics and often exploit hidden\nstatistical patterns and correlations among different factors present in the\ndata. Uncovering these patterns and correlations is challenging due to the\nsheer volume of data to be analyzed. This paper presents BiDAl, a prototype\n\"log-data analysis framework\" that incorporates various Big Data technologies\nto simplify the analysis of data traces from large clusters. BiDAl is written\nin Java with a modular and extensible architecture so that different storage\nbackends (currently, HDFS and SQLite are supported), as well as different\nanalysis languages (current implementation supports SQL, R and Hadoop\nMapReduce) can be easily selected as appropriate. We present the design of\nBiDAl and describe our experience using it to analyze several public traces of\nGoogle data clusters for building a simulation model capable of reproducing\nobserved behavior.\n", "versions": [{"version": "v1", "created": "Mon, 6 Oct 2014 10:02:22 GMT"}], "update_date": "2014-10-07", "authors_parsed": [["Balliu", "Alkida", ""], ["Olivetti", "Dennis", ""], ["Babaoglu", "Ozalp", ""], ["Marzolla", "Moreno", ""], ["S\u00eerbu", "Alina", ""]]}, {"id": "1410.1729", "submitter": "Andrey Shchurov", "authors": "Andrey A. Shchurov", "title": "A Formal Model of Distributed Systems For Test Generation Missions", "comments": "6 pages, 9 figures", "journal-ref": "International Journal of Computer Trends and Technology (IJCTT)\n  V15(2):128-133, September 2014", "doi": "10.14445/22312803/IJCTT-V15P128", "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Nowadays, deployment of distributed systems sets high requirements for\nprocedures and tools for the complex testing of these systems - virtualization\nand cloud technologies make another level of system complexity. As a possible\nsolution, it is necessary to determine a formal list of control objectives -\nchecklists. The automated generation of checklists involves analyzing system\nmodels (with the analysis covering paths in a model). But complex distributed\nsystems are usually a set of coexisting topologies which interact and depend on\neach other and it is necessary to use several models in order to cover\ndifferent aspects. This work introduces a formal four layered model for test\ngeneration missions on the basis of the component-based approach and the\nconcept of layered networks. The interlayer mapping determines how the\ntopological properties on different layers affect each other and, as a\nconsequence, represents technologies (virtualization, clustering, etc.) used to\nbuild distributed systems\n", "versions": [{"version": "v1", "created": "Mon, 6 Oct 2014 10:57:38 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Shchurov", "Andrey A.", ""]]}, {"id": "1410.1747", "submitter": "Andrey Shchurov", "authors": "Andrey A. Shchurov and Radek Marik", "title": "A Formal Approach to Distributed System Tests Design", "comments": "10 pages, 6 figures", "journal-ref": "International Journal of Computer and Information Technology\n  (IJCIT) V03(04):696-705, July 2014", "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Deployment of distributed systems sets high requirements for procedures and\ntools for the complex testing of these systems. This work introduces a formal\nfour-layered model for test generation mission on the basis of the\ncomponent-based approach and the concept of layered networks. Based on this\nmodel, we describe the test generation strategy that covers every interaction\nfrom the end-user requirements on all coexisting architectural layers, and\nchecks the internal consistency of the system technical specifications with\nrespect to the end-user requirements. The next step introduces the Prolog-based\napproach to representing this model and the requirements-coverage strategy\n", "versions": [{"version": "v1", "created": "Mon, 6 Oct 2014 11:14:45 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Shchurov", "Andrey A.", ""], ["Marik", "Radek", ""]]}, {"id": "1410.1764", "submitter": "Erik Schnetter", "authors": "Erik Schnetter, Marek Blazewicz, Steven R. Brandt, David M. Koppelman,\n  Frank L\\\"offler", "title": "Chemora: A PDE Solving Framework for Modern HPC Architectures", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.MS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Modern HPC architectures consist of heterogeneous multi-core, many-node\nsystems with deep memory hierarchies. Modern applications employ ever more\nadvanced discretisation methods to study multi-physics problems. Developing\nsuch applications that explore cutting-edge physics on cutting-edge HPC systems\nhas become a complex task that requires significant HPC knowledge and\nexperience. Unfortunately, this combined knowledge is currently out of reach\nfor all but a few groups of application developers.\n  Chemora is a framework for solving systems of Partial Differential Equations\n(PDEs) that targets modern HPC architectures. Chemora is based on Cactus, which\nsees prominent usage in the computational relativistic astrophysics community.\nIn Chemora, PDEs are expressed either in a high-level \\LaTeX-like language or\nin Mathematica. Discretisation stencils are defined separately from equations,\nand can include Finite Differences, Discontinuous Galerkin Finite Elements\n(DGFE), Adaptive Mesh Refinement (AMR), and multi-block systems.\n  We use Chemora in the Einstein Toolkit to implement the Einstein Equations on\nCPUs and on accelerators, and study astrophysical systems such as black hole\nbinaries, neutron stars, and core-collapse supernovae.\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2014 20:53:26 GMT"}], "update_date": "2014-10-08", "authors_parsed": [["Schnetter", "Erik", ""], ["Blazewicz", "Marek", ""], ["Brandt", "Steven R.", ""], ["Koppelman", "David M.", ""], ["L\u00f6ffler", "Frank", ""]]}, {"id": "1410.1903", "submitter": "Luis Vaquero", "authors": "Luis M. Vaquero, Felix Cuadrado, Matei Ripeanu", "title": "Systems for Near Real-Time Analysis of Large-Scale Dynamic Graphs", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Graphs are widespread data structures used to model a wide variety of\nproblems. The sheer amount of data to be processed has prompted the creation of\na myriad of systems that help us cope with massive scale graphs. The pressure\nto deliver fast responses to queries on the graph is higher than ever before,\nas it is demanded by many applications (e.g. online recommendations, auctions,\nterrorism protection, etc.). In addition, graphs change continuously (so do the\nreal world entities that typically represent). Systems must be ready for both:\nnear real-time and dynamic massive graphs. We survey systems taking their\nscalability, real-time potential and capability to support dynamic changes to\nthe graph as driving guidelines. The main techniques and limitations are\ndistilled and categorised. The algorithms run on top of graph systems are not\nready for prime time dynamism either. Therefore,a short overview on dynamic\ngraph algorithms has also been included.\n", "versions": [{"version": "v1", "created": "Tue, 7 Oct 2014 20:37:49 GMT"}], "update_date": "2014-10-09", "authors_parsed": [["Vaquero", "Luis M.", ""], ["Cuadrado", "Felix", ""], ["Ripeanu", "Matei", ""]]}, {"id": "1410.2167", "submitter": "Luigi Nardi", "authors": "Luigi Nardi, Bruno Bodin, M. Zeeshan Zia, John Mawer, Andy Nisbet,\n  Paul H. J. Kelly, Andrew J. Davison, Mikel Luj\\'an, Michael F. P. O'Boyle,\n  Graham Riley, Nigel Topham, Steve Furber", "title": "Introducing SLAMBench, a performance and accuracy benchmarking\n  methodology for SLAM", "comments": "8 pages, ICRA 2015 conference paper", "journal-ref": "http://ieeexplore.ieee.org/xpl/articleDetails.jsp?arnumber=7140009\n  IEEE Xplore 2015", "doi": "10.1109/ICRA.2015.7140009", "report-no": null, "categories": "cs.RO cs.CV cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Real-time dense computer vision and SLAM offer great potential for a new\nlevel of scene modelling, tracking and real environmental interaction for many\ntypes of robot, but their high computational requirements mean that use on mass\nmarket embedded platforms is challenging. Meanwhile, trends in low-cost,\nlow-power processing are towards massive parallelism and heterogeneity, making\nit difficult for robotics and vision researchers to implement their algorithms\nin a performance-portable way. In this paper we introduce SLAMBench, a\npublicly-available software framework which represents a starting point for\nquantitative, comparable and validatable experimental research to investigate\ntrade-offs in performance, accuracy and energy consumption of a dense RGB-D\nSLAM system. SLAMBench provides a KinectFusion implementation in C++, OpenMP,\nOpenCL and CUDA, and harnesses the ICL-NUIM dataset of synthetic RGB-D\nsequences with trajectory and scene ground truth for reliable accuracy\ncomparison of different implementation and algorithms. We present an analysis\nand breakdown of the constituent algorithmic elements of KinectFusion, and\nexperimentally investigate their execution time on a variety of multicore and\nGPUaccelerated platforms. For a popular embedded platform, we also present an\nanalysis of energy efficiency for different configuration alternatives.\n", "versions": [{"version": "v1", "created": "Wed, 8 Oct 2014 15:34:43 GMT"}, {"version": "v2", "created": "Thu, 26 Feb 2015 16:28:27 GMT"}], "update_date": "2015-12-09", "authors_parsed": [["Nardi", "Luigi", ""], ["Bodin", "Bruno", ""], ["Zia", "M. Zeeshan", ""], ["Mawer", "John", ""], ["Nisbet", "Andy", ""], ["Kelly", "Paul H. J.", ""], ["Davison", "Andrew J.", ""], ["Luj\u00e1n", "Mikel", ""], ["O'Boyle", "Michael F. P.", ""], ["Riley", "Graham", ""], ["Topham", "Nigel", ""], ["Furber", "Steve", ""]]}, {"id": "1410.2208", "submitter": "Shafi'i Muhammad Abdulhamid Mr", "authors": "Shafii Muhammad Abdulhamid and Muhammad Shafie Abd Latiff", "title": "League Championship Algorithm Based Job Scheduling Scheme for\n  Infrastructure as a Service Cloud", "comments": "6 pages, 3 figures, IGCESH2014", "journal-ref": "5th International Graduate Conference on Engineering, Science and\n  Humanities (IGCESH2014), 2014", "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  League Championship Algorithm (LCA) is a sports-inspired population based\nalgorithmic framework for global optimization over a continuous search space\nfirst proposed by Ali Husseinzadeh Kashan in the year 2009. A common\ncharacteristic between all population based optimization algorithms similar to\nthe LCA is that, they attemt to move a population of achievable solutions to\npotential areas of the search space during optimization. In this paper, we\nproposed a job scheduling algorithm based on the L CA optimization technique\nfor the infrastructure as a service (IaaS) cloud. Three other established\nalgorithms i.e. First Come First Served (FCFS), Last Job First (LJF) and Best\nEffort First (BEF) were used to evaluate the performance of the proposed\nalgorithm. All four algorithms assumed to be non-preemptive. The parameters\nused for this experiment are the average response time and the average\ncompletion time. The results obtained shows that, LCA scheduling algorithm\nperform moderately better than the other algorithms as the number of virtual\nmachines increases.\n", "versions": [{"version": "v1", "created": "Mon, 22 Sep 2014 14:45:33 GMT"}], "update_date": "2014-10-09", "authors_parsed": [["Abdulhamid", "Shafii Muhammad", ""], ["Latiff", "Muhammad Shafie Abd", ""]]}, {"id": "1410.2501", "submitter": "Yannai A. Gonczarowski", "authors": "Armando Casta\\~neda, Yannai A. Gonczarowski, Yoram Moses", "title": "Unbeatable Consensus", "comments": "arXiv admin note: substantial text overlap with arXiv:1311.6902", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The unbeatability of a consensus protocol, introduced by Halpern, Moses and\nWaarts in 2001, is a stronger notion of optimality than the accepted notion of\nearly stopping protocols. Using a novel knowledge-based analysis, this paper\nderives the first practical unbeatable consensus protocols in the literature,\nfor the standard synchronous message-passing model with crash failures. These\nprotocols strictly dominate the best known protocols for uniform and for\nnon-uniform consensus, in some case beating them by a large margin. The\nanalysis provides a new understanding of the logical structure of consensus,\nand of the distinction between uniform and nonuniform consensus. Finally, the\nfirst (early stopping and) unbeatable protocol that treats decision values\n\"fairly\" is presented. All of these protocols have very concise descriptions,\nand are shown to be efficiently implementable.\n", "versions": [{"version": "v1", "created": "Thu, 9 Oct 2014 15:09:23 GMT"}], "update_date": "2014-10-10", "authors_parsed": [["Casta\u00f1eda", "Armando", ""], ["Gonczarowski", "Yannai A.", ""], ["Moses", "Yoram", ""]]}, {"id": "1410.2553", "submitter": "Bishoy Moussa", "authors": "Bishoy Moussa, Mahmoud Mostafa, and Mahmoud El-Khouly", "title": "XML Schema-based Minification for Communication of Security Information\n  and Event Management (SIEM) Systems in Cloud Environments", "comments": "XML, JSON, Minification, XML Schema, Cloud, Log, Communication,\n  Compression, XMill, GZip, Code Generation, Code Readability, 9 pages, 12\n  figures, 5 tables, Journal Article", "journal-ref": "International Journal of Advanced Computer Science and\n  Applications (IJACSA), 5(9), 2014", "doi": "10.14569/IJACSA.2014.050912", "report-no": null, "categories": "cs.DC cs.CR cs.NI", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  XML-based communication governs most of today's systems communication, due to\nits capability of representing complex structural and hierarchical data.\nHowever, XML document structure is considered a huge and bulky data that can be\nreduced to minimize bandwidth usage, transmission time, and maximize\nperformance. This contributes to a more efficient and utilized resource usage.\nIn cloud environments, this affects the amount of money the consumer pays.\nSeveral techniques are used to achieve this goal. This paper discusses these\ntechniques and proposes a new XML Schema-based Minification technique. The\nproposed technique works on XML Structure reduction using minification. The\nproposed technique provides a separation between the meaningful names and the\nunderlying minified names, which enhances software/code readability. This\ntechnique is applied to Intrusion Detection Message Exchange Format (IDMEF)\nmessages, as part of Security Information and Event Management (SIEM) system\ncommunication hosted on Microsoft Azure Cloud. Test results show message size\nreduction ranging from 8.15% to 50.34% in the raw message, without using\ntime-consuming compression techniques. Adding GZip compression to the proposed\ntechnique produces 66.1% shorter message size compared to original XML\nmessages.\n", "versions": [{"version": "v1", "created": "Fri, 3 Oct 2014 19:33:40 GMT"}], "update_date": "2014-10-10", "authors_parsed": [["Moussa", "Bishoy", ""], ["Mostafa", "Mahmoud", ""], ["El-Khouly", "Mahmoud", ""]]}, {"id": "1410.2698", "submitter": "Michael Gowanlock", "authors": "Michael Gowanlock and Henri Casanova", "title": "Technical Report: Towards Efficient Indexing of Spatiotemporal\n  Trajectories on the GPU for Distance Threshold Similarity Searches", "comments": "30 pages, 18 figures, 1 table", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Applications in many domains require processing moving object trajectories.\nIn this work, we focus on a trajectory similarity search that finds all\ntrajectories within a given distance of a query trajectory over a time\ninterval, which we call the distance threshold similarity search. We develop\nthree indexing strategies with spatial, temporal and spatiotemporal selectivity\nfor the GPU that differ significantly from indexes suitable for the CPU, and\nshow the conditions under which each index achieves good performance.\nFurthermore, we show that the GPU implementations outperform multithreaded CPU\nimplementations in a range of experimental scenarios, making the GPU an\nattractive technology for processing moving object trajectories. We test our\nimplementations on two synthetic and one real-world dataset of a galaxy merger.\n", "versions": [{"version": "v1", "created": "Fri, 10 Oct 2014 07:44:05 GMT"}], "update_date": "2014-10-13", "authors_parsed": [["Gowanlock", "Michael", ""], ["Casanova", "Henri", ""]]}, {"id": "1410.2803", "submitter": "Ali Shoker", "authors": "Paulo S\\'ergio Almeida, Ali Shoker, and Carlos Baquero", "title": "Efficient State-based CRDTs by Delta-Mutation", "comments": "19 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.DB cs.DS cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  CRDTs are distributed data types that make eventual consistency of a\ndistributed object possible and non ad-hoc. Specifically, state-based CRDTs\nensure convergence through disseminating the en- tire state, that may be large,\nand merging it to other replicas; whereas operation-based CRDTs disseminate\noperations (i.e., small states) assuming an exactly-once reliable dissemination\nlayer. We introduce Delta State Conflict-Free Replicated Datatypes\n({\\delta}-CRDT) that can achieve the best of both worlds: small messages with\nan incremental nature, as in operation-based CRDTs, disseminated over\nunreliable communication channels, as in traditional state-based CRDTs. This is\nachieved by defining {\\delta}-mutators to return a delta-state, typically with\na much smaller size than the full state, that is joined to both: local and\nremote states. We introduce the {\\delta}-CRDT framework, and we explain it\nthrough establishing a correspondence to current state-based CRDTs. In\naddition, we present an anti-entropy algorithm that ensures causal consistency,\nand we introduce two {\\delta}-CRDT specifications of well-known replicated\ndatatypes.\n", "versions": [{"version": "v1", "created": "Fri, 10 Oct 2014 15:16:23 GMT"}, {"version": "v2", "created": "Tue, 3 Mar 2015 12:32:20 GMT"}], "update_date": "2015-03-04", "authors_parsed": [["Almeida", "Paulo S\u00e9rgio", ""], ["Shoker", "Ali", ""], ["Baquero", "Carlos", ""]]}, {"id": "1410.2834", "submitter": "Ubiratam de Paula Junior", "authors": "Ubiratam de Paula Junior, L\\'ucia M. A. Drummond, Daniel de Oliveira,\n  Yuri Frota, Valmir C. Barbosa", "title": "Handling Flash-Crowd Events to Improve the Performance of Web\n  Applications", "comments": "Submitted to the 30th Symposium On Applied Computing (2015)", "journal-ref": "Proceedings of the 30th ACM/SIGAPP Symposium on Applied Computing,\n  769-774, 2015", "doi": "10.1145/2695664.2695839", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing can offer a set of computing resources according to users'\ndemand. It is suitable to be used to handle flash-crowd events in Web\napplications due to its elasticity and on-demand characteristics. Thus, when\nWeb applications need more computing or storage capacity, they just instantiate\nnew resources. However, providers have to estimate the amount of resources to\ninstantiate to handle with the flash-crowd event. This estimation is far from\ntrivial since each cloud environment provides several kinds of heterogeneous\nresources, each one with its own characteristics such as bandwidth, CPU, memory\nand financial cost. In this paper, the Flash Crowd Handling Problem (FCHP) is\nprecisely defined and formulated as an integer programming problem. A new\nalgorithm for handling with a flash crowd named FCHP-ILS is also proposed. With\nFCHP-ILS the Web applications can replicate contents in the already\ninstantiated resources and define the types and amount of resources to\ninstantiate in the cloud during a flash crowd. Our approach is evaluated\nconsidering real flash crowd traces obtained from the related literature. We\nalso present a case study, based on a synthetic dataset representing\nflash-crowd events in small scenarios aiming at the comparison of the proposed\napproach against Amazon's Auto-Scale mechanism.\n", "versions": [{"version": "v1", "created": "Fri, 10 Oct 2014 16:36:09 GMT"}], "update_date": "2015-05-04", "authors_parsed": [["Junior", "Ubiratam de Paula", ""], ["Drummond", "L\u00facia M. A.", ""], ["de Oliveira", "Daniel", ""], ["Frota", "Yuri", ""], ["Barbosa", "Valmir C.", ""]]}, {"id": "1410.3060", "submitter": "Tareq Malas", "authors": "Tareq Malas, Georg Hager, Hatem Ltaief, Holger Stengel, Gerhard\n  Wellein, and David Keyes", "title": "Multicore-optimized wavefront diamond blocking for optimizing stencil\n  updates", "comments": null, "journal-ref": null, "doi": "10.1137/140991133", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The importance of stencil-based algorithms in computational science has\nfocused attention on optimized parallel implementations for multilevel\ncache-based processors. Temporal blocking schemes leverage the large bandwidth\nand low latency of caches to accelerate stencil updates and approach\ntheoretical peak performance. A key ingredient is the reduction of data traffic\nacross slow data paths, especially the main memory interface. In this work we\ncombine the ideas of multi-core wavefront temporal blocking and diamond tiling\nto arrive at stencil update schemes that show large reductions in memory\npressure compared to existing approaches. The resulting schemes show\nperformance advantages in bandwidth-starved situations, which are exacerbated\nby the high bytes per lattice update case of variable coefficients. Our thread\ngroups concept provides a controllable trade-off between concurrency and memory\nusage, shifting the pressure between the memory interface and the CPU. We\npresent performance results on a contemporary Intel processor.\n", "versions": [{"version": "v1", "created": "Sun, 12 Oct 2014 07:55:49 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Malas", "Tareq", ""], ["Hager", "Georg", ""], ["Ltaief", "Hatem", ""], ["Stengel", "Holger", ""], ["Wellein", "Gerhard", ""], ["Keyes", "David", ""]]}, {"id": "1410.3104", "submitter": "Hongyang Sun", "authors": "Hongyang Sun, Patricia Stolf, Jean-Marc Pierson, Georges Da Costa", "title": "Energy-Efficient and Thermal-Aware Resource Management for Heterogeneous\n  Datacenters", "comments": null, "journal-ref": null, "doi": "10.1016/j.suscom.2014.08.005", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We propose in this paper to study the energy-, thermal- and performance-aware\nresource management in heterogeneous datacenters. Witnessing the continuous\ndevelopment of heterogeneity in datacenters, we are confronted with their\ndifferent behaviors in terms of performance, power consumption and thermal\ndissipation: Indeed, heterogeneity at server level lies both in the computing\ninfrastructure (computing power, electrical power consumption) and in the heat\nremoval systems (different enclosure, fans, thermal sinks). Also the physical\nlocations of the servers become important with heterogeneity since some servers\ncan (over)heat others. While many studies address independently these\nparameters (most of the time performance and power or energy), we show in this\npaper the necessity to tackle all these aspects for an optimal resource\nmanagement of the computing resources. This leads to improved energy usage in a\nheterogeneous datacenter including the cooling of the computer rooms. We build\nour approach on the concept of heat distribution matrix to handle the mutual\ninfluence of the servers, in heterogeneous environments, which is novel in this\ncontext. We propose a heuristic to solve the server placement problem and we\ndesign a generic greedy framework for the online scheduling problem. We derive\nseveral single-objective heuristics (for performance, energy, cooling) and a\nnovel fuzzy-based priority mechanism to handle their tradeoffs. Finally, we\nshow results using extensive simulations fed with actual measurements on\nheterogeneous servers.\n", "versions": [{"version": "v1", "created": "Sun, 12 Oct 2014 15:46:09 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Sun", "Hongyang", ""], ["Stolf", "Patricia", ""], ["Pierson", "Jean-Marc", ""], ["Da Costa", "Georges", ""]]}, {"id": "1410.3160", "submitter": "\\'Alvaro Garc\\'ia-Recuero", "authors": "\\'Alvaro Garc\\'ia-Recuero, S\\'ergio Esteves, Lu\\'is Veiga", "title": "Quality-of-Data for Consistency Levels in Geo-replicated Cloud Data\n  Stores", "comments": "IEEE CloudCom 2013, Bristol, UK", "journal-ref": null, "doi": "10.1109/CloudCom.2013.29", "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Cloud computing has recently emerged as a key technology to provide\nindividuals and companies with access to remote computing and storage\ninfrastructures. In order to achieve highly-available yet high-performing\nservices, cloud data stores rely on data replication. However, providing\nreplication brings with it the issue of consistency. Given that data are\nreplicated in multiple geographically distributed data centers, and to meet the\nincreasing requirements of distributed applications, many cloud data stores\nadopt eventual consistency and therefore allow to run data intensive operations\nunder low latency. This comes at the cost of data staleness. In this paper, we\nprioritize data replication based on a set of flexible data semantics that can\nbest suit all types of Big Data applications, avoiding overloading both network\nand systems during large periods of disconnection or partitions in the network.\nTherefore we integrated these data semantics into the core architecture of a\nwell-known NoSQL data store (e.g., HBase), which leverages a three-dimensional\nvector-field model (regarding timeliness, number of pending updates and\ndivergence bounds) to provision data selectively in an on-demand fashion to\napplications. This enhances the former consistency model by providing a number\nof required levels of consistency to different applications such as, social\nnetworks or e-commerce sites, where priority of updates also differ. In\naddition, our implementation of the model into HBase allows updates to be\ntagged and grouped atomically in logical batches, akin to transactions,\nensuring atomic changes and correctness of updates as they are propagated.\n", "versions": [{"version": "v1", "created": "Sun, 12 Oct 2014 22:36:13 GMT"}], "update_date": "2015-08-10", "authors_parsed": [["Garc\u00eda-Recuero", "\u00c1lvaro", ""], ["Esteves", "S\u00e9rgio", ""], ["Veiga", "Lu\u00eds", ""]]}, {"id": "1410.3440", "submitter": "Peter Elmer", "authors": "David Abdurachmanov, Peter Elmer, Giulio Eulisse, Robert Knight, Tapio\n  Niemi, Jukka K. Nurminen, Filip Nyback, Goncalo Pestana, Zhonghong Ou, Kashif\n  Khan", "title": "Techniques and tools for measuring energy efficiency of scientific\n  software applications", "comments": "Submitted to proceedings of 16th International workshop on Advanced\n  Computing and Analysis Techniques in physics research (ACAT 2014), Prague", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC hep-ex physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The scale of scientific High Performance Computing (HPC) and High Throughput\nComputing (HTC) has increased significantly in recent years, and is becoming\nsensitive to total energy use and cost. Energy-efficiency has thus become an\nimportant concern in scientific fields such as High Energy Physics (HEP). There\nhas been a growing interest in utilizing alternate architectures, such as low\npower ARM processors, to replace traditional Intel x86 architectures.\nNevertheless, even though such solutions have been successfully used in mobile\napplications with low I/O and memory demands, it is unclear if they are\nsuitable and more energy-efficient in the scientific computing environment.\nFurthermore, there is a lack of tools and experience to derive and compare\npower consumption between the architectures for various workloads, and\neventually to support software optimizations for energy efficiency. To that\nend, we have performed several physical and software-based measurements of\nworkloads from HEP applications running on ARM and Intel architectures, and\ncompare their power consumption and performance. We leverage several profiling\ntools (both in hardware and software) to extract different characteristics of\nthe power use. We report the results of these measurements and the experience\ngained in developing a set of measurement techniques and profiling tools to\naccurately assess the power consumption for scientific workloads.\n", "versions": [{"version": "v1", "created": "Fri, 10 Oct 2014 05:14:31 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Abdurachmanov", "David", ""], ["Elmer", "Peter", ""], ["Eulisse", "Giulio", ""], ["Knight", "Robert", ""], ["Niemi", "Tapio", ""], ["Nurminen", "Jukka K.", ""], ["Nyback", "Filip", ""], ["Pestana", "Goncalo", ""], ["Ou", "Zhonghong", ""], ["Khan", "Kashif", ""]]}, {"id": "1410.3441", "submitter": "Peter Elmer", "authors": "David Abdurachmanov, Brian Bockelman, Peter Elmer, Giulio Eulisse,\n  Robert Knight, Shahzad Muzaffar", "title": "Heterogeneous High Throughput Scientific Computing with APM X-Gene and\n  Intel Xeon Phi", "comments": "Submitted to proceedings of 16th International workshop on Advanced\n  Computing and Analysis Techniques in physics research (ACAT 2014), Prague", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC hep-ex physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Electrical power requirements will be a constraint on the future growth of\nDistributed High Throughput Computing (DHTC) as used by High Energy Physics.\nPerformance-per-watt is a critical metric for the evaluation of computer\narchitectures for cost- efficient computing. Additionally, future performance\ngrowth will come from heterogeneous, many-core, and high computing density\nplatforms with specialized processors. In this paper, we examine the Intel Xeon\nPhi Many Integrated Cores (MIC) co-processor and Applied Micro X-Gene ARMv8\n64-bit low-power server system-on-a-chip (SoC) solutions for scientific\ncomputing applications. We report our experience on software porting,\nperformance and energy efficiency and evaluate the potential for use of such\ntechnologies in the context of distributed computing systems such as the\nWorldwide LHC Computing Grid (WLCG).\n", "versions": [{"version": "v1", "created": "Fri, 10 Oct 2014 05:04:45 GMT"}], "update_date": "2014-10-14", "authors_parsed": [["Abdurachmanov", "David", ""], ["Bockelman", "Brian", ""], ["Elmer", "Peter", ""], ["Eulisse", "Giulio", ""], ["Knight", "Robert", ""], ["Muzaffar", "Shahzad", ""]]}, {"id": "1410.3677", "submitter": "Gevorg Poghosyan", "authors": "Gevorg Poghosyan, Sanchit Matta, Achim Streit, Micha{\\l} Bejger,\n  Andrzej Kr\\'olak", "title": "Architecture, implementation and parallelization of the software to\n  search for periodic gravitational wave signals", "comments": "11 pages, 9 figures. Submitted to Computer Physics Communications", "journal-ref": "Computer Physics Communications volume 188 pages 168 - 176 (2015)", "doi": "10.1016/j.cpc.2014.10.025", "report-no": null, "categories": "gr-qc astro-ph.HE cs.DC cs.PF cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The parallelization, design and scalability of the \\sky code to search for\nperiodic gravitational waves from rotating neutron stars is discussed. The code\nis based on an efficient implementation of the F-statistic using the Fast\nFourier Transform algorithm. To perform an analysis of data from the advanced\nLIGO and Virgo gravitational wave detectors' network, which will start\noperating in 2015, hundreds of millions of CPU hours will be required - the\ncode utilizing the potential of massively parallel supercomputers is therefore\nmandatory. We have parallelized the code using the Message Passing Interface\nstandard, implemented a mechanism for combining the searches at different\nsky-positions and frequency bands into one extremely scalable program. The\nparallel I/O interface is used to escape bottlenecks, when writing the\ngenerated data into file system. This allowed to develop a highly scalable\ncomputation code, which would enable the data analysis at large scales on\nacceptable time scales. Benchmarking of the code on a Cray XE6 system was\nperformed to show efficiency of our parallelization concept and to demonstrate\nscaling up to 50 thousand cores in parallel.\n", "versions": [{"version": "v1", "created": "Tue, 14 Oct 2014 13:15:38 GMT"}], "update_date": "2015-02-03", "authors_parsed": [["Poghosyan", "Gevorg", ""], ["Matta", "Sanchit", ""], ["Streit", "Achim", ""], ["Bejger", "Micha\u0142", ""], ["Kr\u00f3lak", "Andrzej", ""]]}, {"id": "1410.3712", "submitter": "Fabrizio Montesi", "authors": "Fabrizio Montesi", "title": "Process-aware web programming with Jolie", "comments": "IMADA-preprint-cs", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.PL", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We extend the Jolie programming language to capture the native modelling of\nprocess-aware web information systems, i.e., web information systems based upon\nthe execution of business processes. Our main contribution is to offer a\nunifying approach for the programming of distributed architectures on the web,\nwhich can capture web servers, stateful process execution, and the composition\nof services via mediation. We discuss applications of this approach through a\nseries of examples that cover, e.g., static content serving, multiparty\nsessions, and the evolution of web systems. Finally, we present a performance\nevaluation that includes a comparison of Jolie-based web systems to other\nframeworks and a measurement of its scalability.\n", "versions": [{"version": "v1", "created": "Tue, 14 Oct 2014 14:45:52 GMT"}, {"version": "v2", "created": "Wed, 15 Oct 2014 07:32:03 GMT"}, {"version": "v3", "created": "Thu, 21 Apr 2016 07:18:00 GMT"}], "update_date": "2016-04-22", "authors_parsed": [["Montesi", "Fabrizio", ""]]}, {"id": "1410.3856", "submitter": "Dmitriy Fingerman", "authors": "Aaradhna Goyal, Ali Alshamrani, Dhivyaa Nandakumar, Dileep Vanga,\n  Dmitriy Fingerman, Parul Gupta, Riya Ray, Srikanth Suryadevara", "title": "Towards Refactoring DMARF and GIPSY OSS", "comments": "Team 6, SOEN6471 Summer 2014; 67 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present here an exploratory and investigatory study of the requirements,\ndesign, and implementation of two opensource software systems: the Distributed\nModular Audio Recognition Framework (DMARF), and the General Intensional\nProgramming System (GIPSY). The inception, development, and evolution of the\ntwo systems have overlapped and in terms of the involved developers, as well as\nin their applications. DMARF is a platform independent collection of algorithms\nfor pattern recognition, identification and signal processing in audio and\nnatural language text samples, become a rich platform for the research\ncommunity in particular to use, test, and compare various algorithms in the\nbroad field of pattern recognition and machine learning. Intended as a platform\nfor intensional programming, GIPSY's inception was intended to push the field\nof intensional programming further, overcoming limitations in the available\ntools two decades ago. In this study, we present background research into the\ntwo systems and elaborate on their motivations and the requirements that drove\nand shaped their design and implementation. We subsequently elaborate in more\ndepth about various aspects their architectural design, including the\nelucidation of some use cases, domain models, and the overall class diagram of\nthe major components. Moreover, we investigated existing design patterns in\nboth systems and provided a detailed view of the involved components in such\npatterns. Furthermore, we delve deeper into the guts of both systems,\nidentifying code smells and suggesting possible refactorings. Patchsets of\nimplementations of selected refactorings have been collected into patchsets and\ncould be committed into future releases of the two systems, pending a review\nand approval of the developers and maintainers of DMARF and GIPSY.\n", "versions": [{"version": "v1", "created": "Tue, 14 Oct 2014 20:28:32 GMT"}, {"version": "v2", "created": "Tue, 25 Nov 2014 21:55:48 GMT"}], "update_date": "2014-11-27", "authors_parsed": [["Goyal", "Aaradhna", ""], ["Alshamrani", "Ali", ""], ["Nandakumar", "Dhivyaa", ""], ["Vanga", "Dileep", ""], ["Fingerman", "Dmitriy", ""], ["Gupta", "Parul", ""], ["Ray", "Riya", ""], ["Suryadevara", "Srikanth", ""]]}, {"id": "1410.4054", "submitter": "Karl Rupp", "authors": "Karl Rupp, Josef Weinbub, Ansgar J\\\"ungel, Tibor Grasser", "title": "Pipelined Iterative Solvers with Kernel Fusion for Graphics Processing\n  Units", "comments": "27 pages, 9 figures, 3 tables", "journal-ref": "ACM Transactions on Mathematical Software (TOMS), Volume 43, Issue\n  2, Article No. 11 (2016)", "doi": "10.1145/2907944", "report-no": null, "categories": "cs.MS cs.DC cs.PF", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We revisit the implementation of iterative solvers on discrete graphics\nprocessing units and demonstrate the benefit of implementations using extensive\nkernel fusion for pipelined formulations over conventional implementations of\nclassical formulations. The proposed implementations with both CUDA and OpenCL\nare freely available in ViennaCL and are shown to be competitive with or even\nsuperior to other solver packages for graphics processing units. Highest\nperformance gains are obtained for small to medium-sized systems, while our\nimplementations are on par with vendor-tuned implementations for very large\nsystems. Our results are especially beneficial for transient problems, where\nmany small to medium-sized systems instead of a single big system need to be\nsolved.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 13:23:31 GMT"}, {"version": "v2", "created": "Mon, 15 Dec 2014 15:56:36 GMT"}, {"version": "v3", "created": "Fri, 4 Nov 2016 11:18:16 GMT"}], "update_date": "2016-11-07", "authors_parsed": [["Rupp", "Karl", ""], ["Weinbub", "Josef", ""], ["J\u00fcngel", "Ansgar", ""], ["Grasser", "Tibor", ""]]}, {"id": "1410.4168", "submitter": "Adrien Devresse", "authors": "Adrien Devresse, Fabrizio Furano", "title": "Efficient HTTP based I/O on very large datasets for high performance\n  computing with the libdavix library", "comments": "Presented at: Very large Data Bases (VLDB) 2014, Hangzhou", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.PF cs.DC", "license": "http://creativecommons.org/licenses/by-nc-sa/3.0/", "abstract": "  Remote data access for data analysis in high performance computing is\ncommonly done with specialized data access protocols and storage systems. These\nprotocols are highly optimized for high throughput on very large datasets,\nmulti-streams, high availability, low latency and efficient parallel I/O. The\npurpose of this paper is to describe how we have adapted a generic protocol,\nthe Hyper Text Transport Protocol (HTTP) to make it a competitive alternative\nfor high performance I/O and data analysis applications in a global computing\ngrid: the Worldwide LHC Computing Grid. In this work, we first analyze the\ndesign differences between the HTTP protocol and the most common high\nperformance I/O protocols, pointing out the main performance weaknesses of\nHTTP. Then, we describe in detail how we solved these issues. Our solutions\nhave been implemented in a toolkit called davix, available through several\nrecent Linux distributions. Finally, we describe the results of our benchmarks\nwhere we compare the performance of davix against a HPC specific protocol for a\ndata analysis use case.\n", "versions": [{"version": "v1", "created": "Wed, 15 Oct 2014 18:57:12 GMT"}], "update_date": "2014-10-16", "authors_parsed": [["Devresse", "Adrien", ""], ["Furano", "Fabrizio", ""]]}, {"id": "1410.4373", "submitter": "Arnaud Casteigts", "authors": "Matthieu Barjon, Arnaud Casteigts, Serge Chaumette, Colette Johnen,\n  Yessin M. Neggaz", "title": "Maintaining a Distributed Spanning Forest in Highly Dynamic Networks", "comments": "Long version of an OPODIS'14 paper. This version offers 40% more\n  material, including the proofs and new content on the algorithm performance", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Highly dynamic networks are characterized by frequent changes in the\navailability of communication links. These networks are often partitioned into\nseveral components, which split and merge unpredictably. We present a\ndistributed algorithm that maintains a forest of (as few as possible) spanning\ntrees in such a network, with no restriction on the rate of change. Our\nalgorithm is inspired by high-level graph transformations, which we adapt here\nin a (synchronous) message passing model for dynamic networks. The resulting\nalgorithm has the following properties: First, every decision is purely\nlocal---in each round, a node only considers its role and that of its neighbors\nin the tree, with no further information propagation (in particular, no wave\nmechanisms). Second, whatever the rate and scale of the changes, the algorithm\nguarantees that, by the end of every round, the network is covered by a forest\nof spanning trees in which 1) no cycle occur, 2) every node belongs to exactly\none tree, and 3) every tree contains exactly one root (or token). We primarily\nfocus on the correctness of this algorithm, which is established rigorously.\nWhile performance is not the main focus, we suggest new complexity metrics for\nsuch problems, and report on preliminary experimentation results validating our\nalgorithm in a practical scenario.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2014 11:17:29 GMT"}, {"version": "v2", "created": "Tue, 24 Oct 2017 13:37:34 GMT"}], "update_date": "2017-10-25", "authors_parsed": [["Barjon", "Matthieu", ""], ["Casteigts", "Arnaud", ""], ["Chaumette", "Serge", ""], ["Johnen", "Colette", ""], ["Neggaz", "Yessin M.", ""]]}, {"id": "1410.4449", "submitter": "Alina S\\^irbu", "authors": "Alina S\\^irbu, Ozalp Babaoglu", "title": "A Holistic Approach to Log Data Analysis in High-Performance Computing\n  Systems: The Case of IBM Blue Gene/Q", "comments": "12 pages, 7 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The complexity and cost of managing high-performance computing\ninfrastructures are on the rise. Automating management and repair through\npredictive models to minimize human interventions is an attempt to increase\nsystem availability and contain these costs. Building predictive models that\nare accurate enough to be useful in automatic management cannot be based on\nrestricted log data from subsystems but requires a holistic approach to data\nanalysis from disparate sources. Here we provide a detailed multi-scale\ncharacterization study based on four datasets reporting power consumption,\ntemperature, workload, and hardware/software events for an IBM Blue Gene/Q\ninstallation. We show that the system runs a rich parallel workload, with low\ncorrelation among its components in terms of temperature and power, but higher\ncorrelation in terms of events. As expected, power and temperature correlate\nstrongly, while events display negative correlations with load and power. Power\nand workload show moderate correlations, and only at the scale of components.\nThe aim of the study is a systematic, integrated characterization of the\ncomputing infrastructure and discovery of correlation sources and levels to\nserve as basis for future predictive modeling efforts.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2014 14:40:00 GMT"}, {"version": "v2", "created": "Tue, 10 Feb 2015 10:41:57 GMT"}, {"version": "v3", "created": "Mon, 7 Sep 2015 11:08:50 GMT"}], "update_date": "2015-09-08", "authors_parsed": [["S\u00eerbu", "Alina", ""], ["Babaoglu", "Ozalp", ""]]}, {"id": "1410.4453", "submitter": "Kato Mivule", "authors": "Kato Mivule, Benjamin Harvey, Crystal Cobb, and Hoda El Sayed", "title": "A Review of CUDA, MapReduce, and Pthreads Parallel Computing Models", "comments": "10 Pages, 18 Figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The advent of high performance computing (HPC) and graphics processing units\n(GPU), present an enormous computation resource for Large data transactions\n(big data) that require parallel processing for robust and prompt data\nanalysis. While a number of HPC frameworks have been proposed, parallel\nprogramming models present a number of challenges, for instance, how to fully\nutilize features in the different programming models to implement and manage\nparallelism via multi-threading in both CPUs and GPUs. In this paper, we take\nan overview of three parallel programming models, CUDA, MapReduce, and\nPthreads. The goal is to explore literature on the subject and provide a high\nlevel view of the features presented in the programming models to assist high\nperformance users with a concise understanding of parallel programming concepts\nand thus faster implementation of big data projects using high performance\ncomputing.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2014 14:44:02 GMT"}], "update_date": "2014-10-17", "authors_parsed": [["Mivule", "Kato", ""], ["Harvey", "Benjamin", ""], ["Cobb", "Crystal", ""], ["Sayed", "Hoda El", ""]]}, {"id": "1410.4477", "submitter": "Amir Rastegarnia", "authors": "Azam Khalili, Wael M. Bazzi, Amir Rastegarnia", "title": "Analysis of incremental augmented affine projection algorithm for\n  distributed estimation of complex signals", "comments": "23 pages, 6 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.SY", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  This paper considers the problem of distributed estimation in an incremental\nnetwork when the measurements taken by the node follow a widely linear model.\nThe proposed algorithm which we refer to it as incremental augmented affine\nprojection algorithm (incAAPA) utilizes the full second order statistical\ninformation in the complex domain. Moreover, it exploits spatio-temporal\ndiversity to improve the estimation performance. We derive steady-state\nperformance metric of the incAAPA in terms of the mean-square deviation (MSD).\nWe further derive sufficient conditions to ensure mean-square convergence. Our\nanalysis illustrate that the proposed algorithm is able to process both second\norder circular (proper) and noncircular (improper) signals. The validity of the\ntheoretical results and the good performance of the proposed algorithm are\ndemonstrated by several computer simulations.\n", "versions": [{"version": "v1", "created": "Thu, 16 Oct 2014 16:03:22 GMT"}, {"version": "v2", "created": "Thu, 18 Dec 2014 12:57:13 GMT"}], "update_date": "2014-12-19", "authors_parsed": [["Khalili", "Azam", ""], ["Bazzi", "Wael M.", ""], ["Rastegarnia", "Amir", ""]]}, {"id": "1410.4713", "submitter": "Derek Groen", "authors": "Derek Groen, David Abou Chacra, Rupert W. Nash, Jiri Jaros, Miguel O.\n  Bernabeu and Peter V. Coveney", "title": "Weighted decomposition in high-performance lattice-Boltzmann\n  simulations: are some lattice sites more equal than others?", "comments": "11 pages, 8 figures, 1 table, accepted for the EASC2014 conference", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cond-mat.mes-hall", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Obtaining a good load balance is a significant challenge in scaling up\nlattice-Boltzmann simulations of realistic sparse problems to the exascale.\nHere we analyze the effect of weighted decomposition on the performance of the\nHemeLB lattice-Boltzmann simulation environment, when applied to sparse\ndomains. Prior to domain decomposition, we assign wall and in/outlet sites with\nincreased weights which reflect their increased computational cost. We combine\nour weighted decomposition with a second optimization, which is to sort the\nlattice sites according to a space filling curve. We tested these strategies on\na sparse bifurcation and very sparse aneurysm geometry, and find that using\nweights reduces calculation load imbalance by up to 85%, although the overall\ncommunication overhead is higher than some of our runs.\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2014 13:09:48 GMT"}], "update_date": "2014-10-20", "authors_parsed": [["Groen", "Derek", ""], ["Chacra", "David Abou", ""], ["Nash", "Rupert W.", ""], ["Jaros", "Jiri", ""], ["Bernabeu", "Miguel O.", ""], ["Coveney", "Peter V.", ""]]}, {"id": "1410.4772", "submitter": "Euripides Markou", "authors": "Shantanu Das, Flaminia L. Luccio, Euripides Markou", "title": "Mobile Agents Rendezvous in spite of a Malicious Agent", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We examine the problem of rendezvous, i.e., having multiple mobile agents\ngather in a single node of the network. Unlike previous studies, we need to\nachieve rendezvous in presence of a very powerful adversary, a malicious agent\nthat moves through the network and tries to block the honest agents and\nprevents them from gathering. The malicious agent is assumed to be arbitrarily\nfast, has full knowledge of the network and it cannot be exterminated by the\nhonest agents. On the other hand, the honest agents are assumed to be quite\nweak: They are asynchronous and anonymous, they have only finite memory, they\nhave no prior knowledge of the network and they can communicate with the other\nagents only when they meet at a node. Can the honest agents achieve rendezvous\nstarting from an arbitrary configuration in spite of the malicious agent? We\npresent some necessary conditions for solving rendezvous in spite of the\nmalicious agent in arbitrary networks. We then focus on the ring and mesh\ntopologies and provide algorithms to solve rendezvous. For ring networks, our\nalgorithms solve rendezvous in all feasible instances of the problem, while we\nshow that rendezvous is impossible for an even number of agents in unoriented\nrings. For the oriented mesh networks, we prove that the problem can be solved\nwhen the honest agents initially form a connected configuration without holes\nif and only if they can see which are the occupied nodes within a two-hops\ndistance. To the best of our knowledge, this is the first attempt to study such\na powerful and mobile fault model, in the context of mobile agents. Our model\nlies between the more powerful but static fault model of black holes (which can\neven destroy the agents), and the less powerful but mobile fault model of\nByzantine agents (which can only imitate the honest agents but can neither harm\nnor stop them).\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2014 15:50:46 GMT"}, {"version": "v2", "created": "Mon, 8 Feb 2016 19:18:59 GMT"}], "update_date": "2016-02-09", "authors_parsed": [["Das", "Shantanu", ""], ["Luccio", "Flaminia L.", ""], ["Markou", "Euripides", ""]]}, {"id": "1410.4876", "submitter": "Elis\\^angela Silva Dias", "authors": "Elis\\^angela Silva Dias, Diane Castonguay, Humberto Longo, Walid\n  Abdala Rfaei Jradi, Hugo A. D. do Nascimento", "title": "A GPU-based parallel algorithm for enumerating all chordless cycles in\n  graphs", "comments": "15 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In a finite undirected simple graph, a chordless cycle is an induced subgraph\nwhich is a cycle. We propose a GPU parallel algorithm for enumerating all\nchordless cycles of such a graph. The algorithm, implemented in OpenCL, is\nbased on a previous sequential algorithm developed by the current authors for\nthe same problem. It uses a more compact data structure for solution\nrepresentation which is suitable for the memory-size limitation of a GPU.\nMoreover, for graphs with a sufficiently large amount of chordless cycles, the\nalgorithm presents a significant improvement in execution time that outperforms\nthe sequential method.\n", "versions": [{"version": "v1", "created": "Fri, 17 Oct 2014 21:48:50 GMT"}, {"version": "v2", "created": "Thu, 25 Jun 2015 14:19:14 GMT"}], "update_date": "2015-06-26", "authors_parsed": [["Dias", "Elis\u00e2ngela Silva", ""], ["Castonguay", "Diane", ""], ["Longo", "Humberto", ""], ["Jradi", "Walid Abdala Rfaei", ""], ["Nascimento", "Hugo A. D. do", ""]]}, {"id": "1410.4967", "submitter": "Dimitrios Kallergis", "authors": "Dimitrios Kallergis, Konstantinos Chimos, Vizikidis Stefanos,\n  Theodoros Karvounidis, Christos Douligeris", "title": "Pirus: A Web-based File Hosting Service with Object Oriented Logic in\n  Cloud Computing", "comments": "6 pages, 3rd International Conference on Internet and Cloud Computing\n  Technology (ICICCT2013), November 6-7 2013, Singapore", "journal-ref": "International Journal of Information Technology & Computer Science\n  (IJITCS) 12 (3) (2013) 38-43", "doi": null, "report-no": null, "categories": "cs.SE cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper a new Web-based File Hosting Service with Object Oriented Logic\nin Cloud Computing called Pirus was developed. The service will be used by the\nacademic community of the University of Piraeus giving users the ability to\nremotely store and access their personal files with no security compromises. It\nalso offers the administrators the ability to manage users and roles. The\nobjective was to deliver a fully operational service, using state-of-the-art\nprogramming techniques to enable scalability and future development of the\nexisting functionality. The use of technologies such as .NET Framework, C#\nprogramming language, CSS and jQuery, MSSQL for database hosting and the\nsupport of Virtualization and Cloud Computing will contribute significantly in\ncompatibility, code reuse, reliability and reduce of maintenance costs and\nresources. The service was installed and tested in a controlled environment to\nascertain the required functionality and the offered reliability and safety\nwith complete success.\n  The technologies used and supported, allow future work in upgrading and\nextending the service. Changes and improvements, in hardware and software, in\norder to convert the service to a SaaS (Software as a Service) Cloud\napplication is a logical step in order to efficiently offer the service to a\nwider community. Improved and added functionality offered by further\ndevelopment will leverage the user experience.\n", "versions": [{"version": "v1", "created": "Sat, 18 Oct 2014 14:59:59 GMT"}], "update_date": "2017-06-16", "authors_parsed": [["Kallergis", "Dimitrios", ""], ["Chimos", "Konstantinos", ""], ["Stefanos", "Vizikidis", ""], ["Karvounidis", "Theodoros", ""], ["Douligeris", "Christos", ""]]}, {"id": "1410.4977", "submitter": "Amit Sheth", "authors": "Pratikkumar Desai, Amit Sheth and Pramod Anantharam", "title": "Semantic Gateway as a Service architecture for IoT Interoperability", "comments": "16 pages", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.NI cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Internet of Things (IoT) is set to occupy a substantial component of\nfuture Internet. The IoT connects sensors and devices that record physical\nobservations to applications and services of the Internet. As a successor to\ntechnologies such as RFID and Wireless Sensor Networks (WSN), the IoT has\nstumbled into vertical silos of proprietary systems, providing little or no\ninteroperability with similar systems. As the IoT represents future state of\nthe Internet, an intelligent and scalable architecture is required to provide\nconnectivity between these silos, enabling discovery of physical sensors and\ninterpretation of messages between things. This paper proposes a gateway and\nSemantic Web enabled IoT architecture to provide interoperability between\nsystems using established communication and data standards. The Semantic\nGateway as Service (SGS) allows translation between messaging protocols such as\nXMPP, CoAP and MQTT via a multi-protocol proxy architecture. Utilization of\nbroadly accepted specifications such as W3C's Semantic Sensor Network (SSN)\nontology for semantic annotations of sensor data provide semantic\ninteroperability between messages and support semantic reasoning to obtain\nhigher-level actionable knowledge from low-level sensor data.\n", "versions": [{"version": "v1", "created": "Sat, 18 Oct 2014 16:23:51 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Desai", "Pratikkumar", ""], ["Sheth", "Amit", ""], ["Anantharam", "Pramod", ""]]}, {"id": "1410.4984", "submitter": "Zhenwen Dai", "authors": "Zhenwen Dai, Andreas Damianou, James Hensman, Neil Lawrence", "title": "Gaussian Process Models with Parallelization and GPU acceleration", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this work, we present an extension of Gaussian process (GP) models with\nsophisticated parallelization and GPU acceleration. The parallelization scheme\narises naturally from the modular computational structure w.r.t. datapoints in\nthe sparse Gaussian process formulation. Additionally, the computational\nbottleneck is implemented with GPU acceleration for further speed up. Combining\nboth techniques allows applying Gaussian process models to millions of\ndatapoints. The efficiency of our algorithm is demonstrated with a synthetic\ndataset. Its source code has been integrated into our popular software library\nGPy.\n", "versions": [{"version": "v1", "created": "Sat, 18 Oct 2014 18:12:57 GMT"}], "update_date": "2014-10-21", "authors_parsed": [["Dai", "Zhenwen", ""], ["Damianou", "Andreas", ""], ["Hensman", "James", ""], ["Lawrence", "Neil", ""]]}, {"id": "1410.5010", "submitter": "Georg Hager", "authors": "Holger Stengel, Jan Treibig, Georg Hager, Gerhard Wellein", "title": "Quantifying performance bottlenecks of stencil computations using the\n  Execution-Cache-Memory model", "comments": "10 pages, 8 figures. Added Roofline comparison and other minor\n  improvements", "journal-ref": null, "doi": "10.1145/2751205.2751240", "report-no": null, "categories": "cs.PF cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Stencil algorithms on regular lattices appear in many fields of computational\nscience, and much effort has been put into optimized implementations. Such\nactivities are usually not guided by performance models that provide estimates\nof expected speedup. Understanding the performance properties and bottlenecks\nby performance modeling enables a clear view on promising optimization\nopportunities. In this work we refine the recently developed\nExecution-Cache-Memory (ECM) model and use it to quantify the performance\nbottlenecks of stencil algorithms on a contemporary Intel processor. This\nincludes applying the model to arrive at single-core performance and\nscalability predictions for typical corner case stencil loop kernels. Guided by\nthe ECM model we accurately quantify the significance of \"layer conditions,\"\nwhich are required to estimate the data traffic through the memory hierarchy,\nand study the impact of typical optimization approaches such as spatial\nblocking, strength reduction, and temporal blocking for their expected\nbenefits. We also compare the ECM model to the widely known Roofline model.\n", "versions": [{"version": "v1", "created": "Sat, 18 Oct 2014 21:49:45 GMT"}, {"version": "v2", "created": "Sat, 17 Jan 2015 14:07:26 GMT"}], "update_date": "2016-01-28", "authors_parsed": [["Stengel", "Holger", ""], ["Treibig", "Jan", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""]]}, {"id": "1410.5242", "submitter": "Moritz Kreutzer", "authors": "Moritz Kreutzer, Georg Hager, Gerhard Wellein, Andreas Pieper, Andreas\n  Alvermann, Holger Fehske", "title": "Performance Engineering of the Kernel Polynomial Method on Large-Scale\n  CPU-GPU Systems", "comments": "10 pages, 12 figures", "journal-ref": "Proceedings of the 2015 IEEE International Parallel and\n  Distributed Processing Symposium (IPDPS) 417-426", "doi": "10.1109/IPDPS.2015.76", "report-no": null, "categories": "cs.CE cond-mat.mes-hall cs.DC cs.PF physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The Kernel Polynomial Method (KPM) is a well-established scheme in quantum\nphysics and quantum chemistry to determine the eigenvalue density and spectral\nproperties of large sparse matrices. In this work we demonstrate the high\noptimization potential and feasibility of peta-scale heterogeneous CPU-GPU\nimplementations of the KPM. At the node level we show that it is possible to\ndecouple the sparse matrix problem posed by KPM from main memory bandwidth both\non CPU and GPU. To alleviate the effects of scattered data access we combine\nloosely coupled outer iterations with tightly coupled block sparse matrix\nmultiple vector operations, which enables pure data streaming. All\noptimizations are guided by a performance analysis and modelling process that\nindicates how the computational bottlenecks change with each optimization step.\nFinally we use the optimized node-level KPM with a hybrid-parallel framework to\nperform large scale heterogeneous electronic structure calculations for novel\ntopological materials on a petascale-class Cray XC30 system.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 12:16:22 GMT"}, {"version": "v2", "created": "Wed, 29 Jul 2015 10:52:10 GMT"}], "update_date": "2015-07-30", "authors_parsed": [["Kreutzer", "Moritz", ""], ["Hager", "Georg", ""], ["Wellein", "Gerhard", ""], ["Pieper", "Andreas", ""], ["Alvermann", "Andreas", ""], ["Fehske", "Holger", ""]]}, {"id": "1410.5355", "submitter": "Dominik Kaaser", "authors": "Robert Els\\\"asser and Dominik Kaaser", "title": "On the Influence of Graph Density on Randomized Gossiping", "comments": "Full version of paper submitted to IPDPS 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Information dissemination is a fundamental problem in parallel and\ndistributed computing. In its simplest variant, the broadcasting problem, a\nmessage has to be spread among all nodes of a graph. A prominent communication\nprotocol for this problem is based on the random phone call model (Karp et al.,\nFOCS 2000). In each step, every node opens a communication channel to a\nrandomly chosen neighbor for bi-directional communication.\n  Motivated by replicated databases and peer-to-peer networks, Berenbrink et\nal., ICALP 2010, considered the gossiping problem in the random phone call\nmodel. There, each node starts with its own message and all messages have to be\ndisseminated to all nodes in the network. They showed that any $O(\\log n)$-time\nalgorithm in complete graphs requires $\\Omega(\\log n)$ message transmissions\nper node to complete gossiping, w.h.p, while for broadcasting the average\nnumber of transmissions per node is $O(\\log\\log n)$.\n  It is known that the $O(n\\log\\log n)$ bound on the number of transmissions\nrequired for randomized broadcasting in complete graphs cannot be achieved in\nsparse graphs even if they have best expansion and connectivity properties. In\nthis paper, we analyze whether a similar influence of the graph density also\nholds w.r.t. the performance of gossiping. We study analytically and\nempirically the communication overhead generated by randomized gossiping in\nrandom graphs and consider simple modifications of the random phone call model\nin these graphs. Our results indicate that, unlike in broadcasting, there is no\nsignificant difference between the performance of randomized gossiping in\ncomplete graphs and sparse random graphs. Furthermore, our simulations indicate\nthat by tuning the parameters of our algorithms, we can significantly reduce\nthe communication overhead compared to the traditional push-pull approach in\nthe graphs we consider.\n", "versions": [{"version": "v1", "created": "Mon, 20 Oct 2014 17:10:32 GMT"}, {"version": "v2", "created": "Fri, 5 Dec 2014 19:23:45 GMT"}, {"version": "v3", "created": "Tue, 9 Dec 2014 09:10:55 GMT"}], "update_date": "2014-12-10", "authors_parsed": [["Els\u00e4sser", "Robert", ""], ["Kaaser", "Dominik", ""]]}, {"id": "1410.5784", "submitter": "Amartya Hatua", "authors": "Amartya Hatua", "title": "Optimal Feature Selection from VMware ESXi 5.1 Feature Set", "comments": "8 Pagee, http://airccse.org/journal/ijccms/current2014.html", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.LG", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  A study of VMware ESXi 5.1 server has been carried out to find the optimal\nset of parameters which suggest usage of different resources of the server.\nFeature selection algorithms have been used to extract the optimum set of\nparameters of the data obtained from VMware ESXi 5.1 server using esxtop\ncommand. Multiple virtual machines (VMs) are running in the mentioned server.\nK-means algorithm is used for clustering the VMs. The goodness of each cluster\nis determined by Davies Bouldin index and Dunn index respectively. The best\ncluster is further identified by the determined indices. The features of the\nbest cluster are considered into a set of optimal parameters.\n", "versions": [{"version": "v1", "created": "Sat, 18 Oct 2014 05:00:31 GMT"}], "update_date": "2014-10-22", "authors_parsed": [["Hatua", "Amartya", ""]]}, {"id": "1410.5904", "submitter": "Bhavya Kailkhura", "authors": "Bhavya Kailkhura, Swastik Brahma, Berkan Dulek, Yunghsiang S Han,\n  Pramod K. Varshney", "title": "Distributed Detection in Tree Networks: Byzantines and Mitigation\n  Techniques", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.CR cs.DC math.OC stat.AP", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper, the problem of distributed detection in tree networks in the\npresence of Byzantines is considered. Closed form expressions for optimal\nattacking strategies that minimize the miss detection error exponent at the\nfusion center (FC) are obtained. We also look at the problem from the network\ndesigner's (FC's) perspective. We study the problem of designing optimal\ndistributed detection parameters in a tree network in the presence of\nByzantines. Next, we model the strategic interaction between the FC and the\nattacker as a Leader-Follower (Stackelberg) game. This formulation provides a\nmethodology for predicting attacker and defender (FC) equilibrium strategies,\nwhich can be used to implement the optimal detector. Finally, a reputation\nbased scheme to identify Byzantines is proposed and its performance is\nanalytically evaluated. We also provide some numerical examples to gain\ninsights into the solution.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 03:00:10 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Kailkhura", "Bhavya", ""], ["Brahma", "Swastik", ""], ["Dulek", "Berkan", ""], ["Han", "Yunghsiang S", ""], ["Varshney", "Pramod K.", ""]]}, {"id": "1410.5976", "submitter": "Adam Barker", "authors": "Michael Luckeneder and Adam Barker", "title": "Uncovering the Perfect Place: Optimising Workflow Engine Deployment in\n  the Cloud", "comments": "Extended Abstract for the ACM International Symposium on\n  High-Performance Parallel and Distributed Computing (HPDC 2013) Poster Track", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When orchestrating highly distributed and data-intensive Web service\nworkflows the geographical placement of the orchestration engine can greatly\naffect the overall performance of a workflow. We present CloudForecast: a Web\nservice framework and analysis tool which, given a workflow specification,\ncomputes the optimal Amazon EC2 Cloud region to automatically deploy the\norchestration engine and execute the workflow. We use geographical distance of\nthe workflow, network latency and HTTP round-trip time between Amazon Cloud\nregions and the workflow nodes to find a ranking of Cloud regions. This overall\nranking predicts where the workflow orchestration engine should be deployed in\norder to reduce overall execution time. Our experimental results show that our\nproposed optimisation strategy, depending on the particular workflow, can speed\nup execution time on average by 82.25% compared to local execution.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 10:03:16 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Luckeneder", "Michael", ""], ["Barker", "Adam", ""]]}, {"id": "1410.6122", "submitter": "Matteo Dell'Amico Ph.D.", "authors": "Matteo Dell'Amico, Damiano Carra, Pietro Michiardi", "title": "PSBS: Practical Size-Based Scheduling", "comments": "arXiv admin note: substantial text overlap with arXiv:1403.5996", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Size-based schedulers have very desirable performance properties: optimal or\nnear-optimal response time can be coupled with strong fairness guarantees.\nDespite this, such systems are very rarely implemented in practical settings,\nbecause they require knowing a priori the amount of work needed to complete\njobs: this assumption is very difficult to satisfy in concrete systems. It is\ndefinitely more likely to inform the system with an estimate of the job sizes,\nbut existing studies point to somewhat pessimistic results if existing\nscheduler policies are used based on imprecise job size estimations. We take\nthe goal of designing scheduling policies that are explicitly designed to deal\nwith inexact job sizes: first, we show that existing size-based schedulers can\nhave bad performance with inexact job size information when job sizes are\nheavily skewed; we show that this issue, and the pessimistic results shown in\nthe literature, are due to problematic behavior when large jobs are\nunderestimated. Once the problem is identified, it is possible to amend\nexisting size-based schedulers to solve the issue. We generalize FSP -- a fair\nand efficient size-based scheduling policy -- in order to solve the problem\nhighlighted above; in addition, our solution deals with different job weights\n(that can be assigned to a job independently from its size). We provide an\nefficient implementation of the resulting protocol, which we call Practical\nSize-Based Scheduler (PSBS). Through simulations evaluated on synthetic and\nreal workloads, we show that PSBS has near-optimal performance in a large\nvariety of cases with inaccurate size information, that it performs fairly and\nit handles correctly job weights. We believe that this work shows that PSBS is\nindeed pratical, and we maintain that it could inspire the design of schedulers\nin a wide array of real-world use cases.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 17:57:22 GMT"}, {"version": "v2", "created": "Thu, 23 Oct 2014 14:25:56 GMT"}, {"version": "v3", "created": "Mon, 23 Mar 2015 17:47:46 GMT"}, {"version": "v4", "created": "Thu, 6 Aug 2015 16:09:04 GMT"}], "update_date": "2015-08-07", "authors_parsed": [["Dell'Amico", "Matteo", ""], ["Carra", "Damiano", ""], ["Michiardi", "Pietro", ""]]}, {"id": "1410.6146", "submitter": "Tien Van Do", "authors": "Tien Van Do (1) and Binh T. Vu (1) and Nam H. Do (1) and L\\'or\\'ant\n  Farkas (2) and Csaba Rotter (2) and Tam\\'as Tarj\\'anyi (2) ((1) Budapest\n  University of Technology and Economics, (2) Nokia)", "title": "Building Block Components to Control a Data Rate in the Apache Hadoop\n  Compute Platform", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Resource management is one of the most indispensable components of\ncluster-level infrastructure layers. Users of such systems should be able to\nspecify their job requirements as a configuration parameter (CPU, RAM, disk\nI/O, network I/O) and have the scheduler translate those into an appropriate\nreservation and allocation of resources. YARN is an emerging resource\nmanagement in the Hadoop ecosystem, which supports only RAM and CPU reservation\nat present.\n  In this paper, we propose a solution that takes into account the operation of\nthe Hadoop Distributed File System to control the data rate of applications in\nthe framework of a Hadoop compute platform. We utilize the property that a data\npipe between a container and a DataNode consists of a disk I/O subpipe and a\nTCP/IP subpipe. We have implemented building block software components to\ncontrol the data rate of data pipes between containers and DataNodes and\nprovide a proof-of-concept with measurement results.\n", "versions": [{"version": "v1", "created": "Wed, 22 Oct 2014 19:17:19 GMT"}], "update_date": "2014-10-23", "authors_parsed": [["Van Do", "Tien", ""], ["Vu", "Binh T.", ""], ["Do", "Nam H.", ""], ["Farkas", "L\u00f3r\u00e1nt", ""], ["Rotter", "Csaba", ""], ["Tarj\u00e1nyi", "Tam\u00e1s", ""]]}, {"id": "1410.6502", "submitter": "Satish Bhambri", "authors": "Satish Bhambri", "title": "Quantum Clouds: A future perspective", "comments": "14 pages, 1 figure", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Quantum computing and cloud computing are two giants for futuristic\ncomputing. Both technologies complement each other. Quantum clouds, therefore,\nis deploying the resources of quantum computation in a cloud environment to\nprovide solution to the challenges and problems faced by present model of\nclassical cloud computation. State of the art challenges faced by the cloud\nsuch as VM migration, data security, traffic management can be addressed by the\nquantum principles. But the merging of these two technologies have challenges\nof their own which need to be addressed before moving forward. What are those\nchallenges and how does a quantum computer solve the cloud problems? The\nrelation among quantum parallelism, superposition and flash crowd effect;\nLaundauer's principle and energy management; photon polarization principle and\ndata security; these fascinating queries are addressed in the paper.\n", "versions": [{"version": "v1", "created": "Sun, 5 Oct 2014 16:59:57 GMT"}], "update_date": "2014-10-27", "authors_parsed": [["Bhambri", "Satish", ""]]}, {"id": "1410.6604", "submitter": "Xiangyu Wang", "authors": "Xiangyu Wang, Peichao Peng, David Dunson", "title": "Median Selection Subset Aggregation for Parallel Inference", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "stat.ML cs.DC stat.CO stat.ME", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  For massive data sets, efficient computation commonly relies on distributed\nalgorithms that store and process subsets of the data on different machines,\nminimizing communication costs. Our focus is on regression and classification\nproblems involving many features. A variety of distributed algorithms have been\nproposed in this context, but challenges arise in defining an algorithm with\nlow communication, theoretical guarantees and excellent practical performance\nin general settings. We propose a MEdian Selection Subset AGgregation Estimator\n(message) algorithm, which attempts to solve these problems. The algorithm\napplies feature selection in parallel for each subset using Lasso or another\nmethod, calculates the `median' feature inclusion index, estimates coefficients\nfor the selected features in parallel for each subset, and then averages these\nestimates. The algorithm is simple, involves very minimal communication, scales\nefficiently in both sample and feature size, and has theoretical guarantees. In\nparticular, we show model selection consistency and coefficient estimation\nefficiency. Extensive experiments show excellent performance in variable\nselection, estimation, prediction, and computation time relative to usual\ncompetitors.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 07:52:55 GMT"}], "update_date": "2014-10-27", "authors_parsed": [["Wang", "Xiangyu", ""], ["Peng", "Peichao", ""], ["Dunson", "David", ""]]}, {"id": "1410.6669", "submitter": "Volker Turau", "authors": "Volker Turau", "title": "Analyzing the Fault-Containment Time of Self-Stabilizing Algorithms - A\n  Case Study for Graph Coloring", "comments": "23 pages, 5 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The paper presents techniques to derive upper bounds for the mean time to\nrecover from a single fault for self-stabilizing algorithms in the message\npassing model. For a new Delta+1-coloring algorithm we analytically derive a\nbound for the mean time to recover and show that the variance is bounded by a\nsmall constant independent of the network's size. For the class of\nbounded-independence graphs (e.g. unit disc graphs) all containment metrics are\nin O(1).\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 12:58:39 GMT"}], "update_date": "2014-10-27", "authors_parsed": [["Turau", "Volker", ""]]}, {"id": "1410.6685", "submitter": "Christopher M. Poskitt", "authors": "Alexey Kolesnichenko, Christopher M. Poskitt, Sebastian Nanz, Bertrand\n  Meyer", "title": "Contract-Based General-Purpose GPU Programming", "comments": null, "journal-ref": "Proc. International Conference on Generative Programming: Concepts\n  and Experiences (GPCE 2015), pages 75-84. ACM, 2015", "doi": "10.1145/2814204.2814216", "report-no": null, "categories": "cs.DC cs.SE", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Using GPUs as general-purpose processors has revolutionized parallel\ncomputing by offering, for a large and growing set of algorithms, massive\ndata-parallelization on desktop machines. An obstacle to widespread adoption,\nhowever, is the difficulty of programming them and the low-level control of the\nhardware required to achieve good performance. This paper suggests a\nprogramming library, SafeGPU, that aims at striking a balance between\nprogrammer productivity and performance, by making GPU data-parallel operations\naccessible from within a classical object-oriented programming language. The\nsolution is integrated with the design-by-contract approach, which increases\nconfidence in functional program correctness by embedding executable program\nspecifications into the program text. We show that our library leads to modular\nand maintainable code that is accessible to GPGPU non-experts, while providing\nperformance that is comparable with hand-written CUDA code. Furthermore,\nruntime contract checking turns out to be feasible, as the contracts can be\nexecuted on the GPU.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 14:03:04 GMT"}, {"version": "v2", "created": "Wed, 18 Mar 2015 12:36:46 GMT"}, {"version": "v3", "created": "Tue, 16 Jun 2015 17:42:43 GMT"}, {"version": "v4", "created": "Fri, 21 Aug 2015 16:15:39 GMT"}], "update_date": "2015-10-14", "authors_parsed": [["Kolesnichenko", "Alexey", ""], ["Poskitt", "Christopher M.", ""], ["Nanz", "Sebastian", ""], ["Meyer", "Bertrand", ""]]}, {"id": "1410.6754", "submitter": "Michael Axtmann", "authors": "Michael Axtmann, Timo Bingmann, Peter Sanders, and Christian Schulz", "title": "Practical Massively Parallel Sorting", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DS cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Previous parallel sorting algorithms do not scale to the largest available\nmachines, since they either have prohibitive communication volume or\nprohibitive critical path length. We describe algorithms that are a viable\ncompromise and overcome this gap both in theory and practice. The algorithms\nare multi-level generalizations of the known algorithms sample sort and\nmultiway mergesort. In particular our sample sort variant turns out to be very\nscalable. Some tools we develop may be of independent interest -- a simple,\npractical, and flexible sorting algorithm for small inputs working in\nlogarithmic time, a near linear time optimal algorithm for solving a\nconstrained bin packing problem, and an algorithm for data delivery, that\nguarantees a small number of message startups on each processor.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 17:56:48 GMT"}, {"version": "v2", "created": "Wed, 25 Feb 2015 10:53:28 GMT"}], "update_date": "2015-02-26", "authors_parsed": [["Axtmann", "Michael", ""], ["Bingmann", "Timo", ""], ["Sanders", "Peter", ""], ["Schulz", "Christian", ""]]}, {"id": "1410.6824", "submitter": "Ramy Medhat", "authors": "Ramy Medhat, Borzoo Bonakdarpour, Sebastian Fischmeister", "title": "Power Redistribution for Optimizing Performance in MPI Clusters", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Power efficiency has recently become a major concern in the high-performance\ncomputing domain. HPC centers are provisioned by a power bound which impacts\nexecution time. Naturally, a tradeoff arises between power efficiency and\ncomputational efficiency. This paper tackles the problem of performance\noptimization for MPI applications, where a power bound is assumed. The paper\nexposes a subset of HPC applications that leverage cluster parallelism using\nMPI, where nodes encounter multiple synchronization points and exhibit\ninter-node dependency. We abstract this structure into a dependency graph, and\nleverage the asymmetry in execution time of parallel jobs on different nodes by\nredistributing power gained from idling a blocked node to nodes that are\nlagging in their jobs. We introduce a solution based on integer linear\nprogramming (ILP) for optimal power distribution algorithm that minimizes total\nexecution time, while maintaining an upper power bound. We then present an\nonline heuristic that dynamically redistributes power at run time. The\nheuristic shows significant reductions in total execution time of a set of\nparallel benchmarks with speedup up to 2.25x.\n", "versions": [{"version": "v1", "created": "Fri, 24 Oct 2014 20:08:33 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Medhat", "Ramy", ""], ["Bonakdarpour", "Borzoo", ""], ["Fischmeister", "Sebastian", ""]]}, {"id": "1410.7057", "submitter": "Bijit Kumar Das", "authors": "Bijit Kumar Das, Mrityunjoy Chakraborty and Jer\\'onimo Arenas-Garc\\'ia", "title": "Sparse Distributed Learning via Heterogeneous Diffusion Adaptive\n  Networks", "comments": "4 pages, 1 figure, conference, submitted to IEEE ISCAS 2015, Lisbon,\n  Portugal", "journal-ref": null, "doi": "10.1109/ISCAS.2015.7168664", "report-no": null, "categories": "cs.LG cs.DC cs.SY stat.ML", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In-network distributed estimation of sparse parameter vectors via diffusion\nLMS strategies has been studied and investigated in recent years. In all the\nexisting works, some convex regularization approach has been used at each node\nof the network in order to achieve an overall network performance superior to\nthat of the simple diffusion LMS, albeit at the cost of increased computational\noverhead. In this paper, we provide analytical as well as experimental results\nwhich show that the convex regularization can be selectively applied only to\nsome chosen nodes keeping rest of the nodes sparsity agnostic, while still\nenjoying the same optimum behavior as can be realized by deploying the convex\nregularization at all the nodes. Due to the incorporation of unregularized\nlearning at a subset of nodes, less computational cost is needed in the\nproposed approach. We also provide a guideline for selection of the sparsity\naware nodes and a closed form expression for the optimum regularization\nparameter.\n", "versions": [{"version": "v1", "created": "Sun, 26 Oct 2014 16:38:38 GMT"}], "update_date": "2016-11-15", "authors_parsed": [["Das", "Bijit Kumar", ""], ["Chakraborty", "Mrityunjoy", ""], ["Arenas-Garc\u00eda", "Jer\u00f3nimo", ""]]}, {"id": "1410.7249", "submitter": "Loris Marchal", "authors": "Abdou Guermouche and Loris Marchal and Bertrand Simon and Fr\\'ed\\'eric\n  Vivien", "title": "Scheduling Trees of Malleable Tasks for Sparse Linear Algebra", "comments": "Paper accepted for publication at EuroPar 2015", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Scientific workloads are often described as directed acyclic task graphs. In\nthis paper, we focus on the multifrontal factorization of sparse matrices,\nwhose task graph is structured as a tree of parallel tasks. Among the existing\nmodels for parallel tasks, the concept of malleable tasks is especially\npowerful as it allows each task to be processed on a time-varying number of\nprocessors. Following the model advocated by Prasanna and Musicus for matrix\ncomputations, we consider malleable tasks whose speedup is $p^\\alpha$, where\n$p$ is the fractional share of processors on which a task executes, and\n$\\alpha$ ($0 < \\alpha \\leq 1$) is a parameter which does not depend on the\ntask. We first motivate the relevance of this model for our application with\nactual experiments on multicore platforms. Then, we study the optimal\nallocation proposed by Prasanna and Musicus for makespan minimization using\noptimal control theory. We largely simplify their proofs by resorting only to\npure scheduling arguments. Building on the insight gained thanks to these new\nproofs, we extend the study to distributed multicore platforms. There, a task\ncannot be distributed among several distributed nodes. In such a distributed\nsetting (homogeneous or heterogeneous), we prove the NP-completeness of the\ncorresponding scheduling problem, and propose some approximation algorithms. We\nfinally assess the relevance of our approach by simulations on realistic trees.\nWe show that the average performance gain of our allocations with respect to\nexisting solutions (that are thus unaware of the actual speedup functions) is\nup to 16% for $\\alpha=0.9$ (the value observed in the real experiments).\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 14:22:57 GMT"}, {"version": "v2", "created": "Thu, 4 Jun 2015 12:35:14 GMT"}], "update_date": "2015-06-05", "authors_parsed": [["Guermouche", "Abdou", ""], ["Marchal", "Loris", ""], ["Simon", "Bertrand", ""], ["Vivien", "Fr\u00e9d\u00e9ric", ""]]}, {"id": "1410.7256", "submitter": "Stathis Maneas", "authors": "Panos Diamantopoulos, Stathis Maneas, Christos Patsonakis, Nikos\n  Chondros, Mema Roussopoulos", "title": "Interactive Consistency in practical, mostly-asynchronous systems", "comments": "13 pages, 10 figures", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Interactive consistency is the problem in which n nodes, where up to t may be\nbyzantine, each with its own private value, run an algorithm that allows all\nnon-faulty nodes to infer the values of each other node. This problem is\nrelevant to critical applications that rely on the combination of the opinions\nof multiple peers to provide a service. Examples include monitoring a content\nsource to prevent equivocation or to track variability in the content provided,\nand resolving divergent state amongst the nodes of a distributed system.\nPrevious works assume a fully synchronous system, where one can make strong\nassumptions such as negligible message delivery delays and/or detection of\nabsent messages. However, practical, real-world systems are mostly\nasynchronous, i.e., they exhibit only some periods of synchrony during which\nmessage delivery is timely, thus requiring a different approach. In this paper,\nwe present a thorough study on practical interactive consistency. We leverage\nthe vast prior work on broadcast and byzantine consensus algorithms to design,\nimplement and evaluate a set of algorithms, with varying timing assumptions and\nmessage complexity, that can be used to achieve interactive consistency in\nreal-world distributed systems. We provide a complete, open-source\nimplementation of each proposed interactive consistency algorithm by building a\nmulti-layered stack of protocols that include several broadcast protocols, as\nwell as a binary and a multi-valued consensus protocol. Most of these protocols\nhave never been implemented and evaluated in a real system before. We analyze\nthe performance of our suite of algorithms experimentally by engaging in both\nsingle instance and multiple parallel instances of each alternative.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 14:32:21 GMT"}, {"version": "v2", "created": "Fri, 9 Jan 2015 12:39:05 GMT"}, {"version": "v3", "created": "Tue, 13 Jan 2015 11:39:06 GMT"}, {"version": "v4", "created": "Tue, 5 May 2015 21:35:57 GMT"}, {"version": "v5", "created": "Mon, 27 Jul 2015 16:50:17 GMT"}], "update_date": "2015-07-28", "authors_parsed": [["Diamantopoulos", "Panos", ""], ["Maneas", "Stathis", ""], ["Patsonakis", "Christos", ""], ["Chondros", "Nikos", ""], ["Roussopoulos", "Mema", ""]]}, {"id": "1410.7367", "submitter": "Elizabeth Basha", "authors": "Elizabeth Basha, Raja Jurdak, and Daniela Rus", "title": "In-Network Distributed Solar Current Prediction", "comments": "28 pages, accepted at TOSN and awaiting publication", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC cs.NI", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Long-term sensor network deployments demand careful power management. While\nmanaging power requires understanding the amount of energy harvestable from the\nlocal environment, current solar prediction methods rely only on recent local\nhistory, which makes them susceptible to high variability. In this paper, we\npresent a model and algorithms for distributed solar current prediction, based\non multiple linear regression to predict future solar current based on local,\nin-situ climatic and solar measurements. These algorithms leverage spatial\ninformation from neighbors and adapt to the changing local conditions not\ncaptured by global climatic information. We implement these algorithms on our\nFleck platform and run a 7-week-long experiment validating our work. In\nanalyzing our results from this experiment, we determined that computing our\nmodel requires an increased energy expenditure of 4.5mJ over simpler models (on\nthe order of 10^{-7}% of the harvested energy) to gain a prediction improvement\nof 39.7%.\n", "versions": [{"version": "v1", "created": "Mon, 27 Oct 2014 19:39:21 GMT"}], "update_date": "2014-10-28", "authors_parsed": [["Basha", "Elizabeth", ""], ["Jurdak", "Raja", ""], ["Rus", "Daniela", ""]]}, {"id": "1410.7466", "submitter": "EPTCS", "authors": "H{\\aa}kon Normann (IT University of Copenhagen), Cristian Prisacariu\n  (Institute for Informatics, University of Oslo), Thomas Hildebrandt (IT\n  University of Copenhagen)", "title": "Concurrency Models with Causality and Events as Psi-calculi", "comments": "In Proceedings ICE 2014, arXiv:1410.7013", "journal-ref": "EPTCS 166, 2014, pp. 4-20", "doi": "10.4204/EPTCS.166.3", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Psi-calculi are a parametric framework for nominal calculi, where standard\ncalculi are found as instances, like the pi-calculus, or the cryptographic\nspi-calculus and applied-pi. Psi-calculi have an interleaving operational\nsemantics, with a strong foundation on the theory of nominal sets and process\nalgebras. Much of the expressive power of psi-calculi comes from their logical\npart, i.e., assertions, conditions, and entailment, which are left quite open\nthus accommodating a wide range of logics. We are interested in how this\nexpressiveness can deal with event-based models of concurrency. We thus take\nthe popular prime event structures model and give an encoding into an instance\nof psi-calculi. We also take the recent and expressive model of Dynamic\nCondition Response Graphs (in which event structures are strictly included) and\ngive an encoding into another corresponding instance of psi-calculi. The\nencodings that we achieve look rather natural and intuitive. Additional results\nabout these encodings give us more confidence in their correctness.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 00:40:29 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Normann", "H\u00e5kon", "", "IT University of Copenhagen"], ["Prisacariu", "Cristian", "", "Institute for Informatics, University of Oslo"], ["Hildebrandt", "Thomas", "", "IT\n  University of Copenhagen"]]}, {"id": "1410.7470", "submitter": "EPTCS", "authors": "Nicolas Ninin (CEA, LIST and University Paris-Sud, France), Emmanuel\n  Haucourt (CEA, LIST)", "title": "The Boolean Algebra of Cubical Areas as a Tensor Product in the Category\n  of Semilattices with Zero", "comments": "In Proceedings ICE 2014, arXiv:1410.7013", "journal-ref": "EPTCS 166, 2014, pp. 60-66", "doi": "10.4204/EPTCS.166.7", "report-no": null, "categories": "cs.LO cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this paper we describe a model of concurrency together with an algebraic\nstructure reflecting the parallel composition. For the sake of simplicity we\nrestrict to linear concurrent programs i.e. the ones with no loops nor\nbranching. Such programs are given a semantics using cubical areas. Such a\nsemantics is said to be geometric. The collection of all these cubical areas\nenjoys a structure of tensor product in the category of semi-lattice with zero.\nThese results naturally extend to fully fledged concurrent programs up to some\ntechnical tricks.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 00:41:23 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Ninin", "Nicolas", "", "CEA, LIST and University Paris-Sud, France"], ["Haucourt", "Emmanuel", "", "CEA, LIST"]]}, {"id": "1410.7582", "submitter": "Kas{\\i}m Sinan Y{\\i}ld{\\i}r{\\i}m", "authors": "Kas{\\i}m Sinan Y{\\i}ld{\\i}r{\\i}m and \\\"Onder G\\\"urcan", "title": "Adaptive Synchronization of Robotic Sensor Networks", "comments": "First International Workshop on Robotic Sensor Networks part of\n  Cyber-Physical Systems Week, Berlin, Germany, 14 April 2014", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  The main focus of recent time synchronization research is developing\npower-efficient synchronization methods that meet pre-defined accuracy\nrequirements. However, an aspect that has been often overlooked is the high\ndynamics of the network topology due to the mobility of the nodes. Employing\nexisting flooding-based and peer-to-peer synchronization methods, are networked\nrobots still be able to adapt themselves and self-adjust their logical clocks\nunder mobile network dynamics? In this paper, we present the application and\nthe evaluation of the existing synchronization methods on robotic sensor\nnetworks. We show through simulations that Adaptive Value Tracking\nsynchronization is robust and efficient under mobility. Hence, deducing the\ntime synchronization problem in robotic sensor networks into a dynamic value\nsearching problem is preferable to existing synchronization methods in the\nliterature.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 11:02:23 GMT"}], "update_date": "2014-10-29", "authors_parsed": [["Y\u0131ld\u0131r\u0131m", "Kas\u0131m Sinan", ""], ["G\u00fcrcan", "\u00d6nder", ""]]}, {"id": "1410.7815", "submitter": "Quang-Hung Nguyen", "authors": "Nguyen Quang-Hung, Nam Thoai, Nguyen Thanh Son, Duy-Khanh Le", "title": "Energy-Aware Lease Scheduling in Virtualized Data Centers", "comments": "10 pages, 2 figures, Proceedings of the Fifth International\n  Conference on High Performance Scientific Computing, March 5-9, 2012, Hanoi,\n  Vietnam", "journal-ref": "Modeling, Simulation and Optimization of Complex Processes - HPSC\n  2012", "doi": null, "report-no": null, "categories": "cs.DC cs.NI cs.PF", "license": "http://creativecommons.org/licenses/by/3.0/", "abstract": "  Energy efficiency has become an important measurement of scheduling\nalgorithms in virtualized data centers. One of the challenges of\nenergy-efficient scheduling algorithms, however, is the trade-off between\nminimizing energy consumption and satisfying quality of service (e.g.\nperformance, resource availability on time for reservation requests). We\nconsider resource needs in the context of virtualized data centers of a private\ncloud system, which provides resource leases in terms of virtual machines (VMs)\nfor user applications. In this paper, we propose heuristics for scheduling VMs\nthat address the above challenge. On performance evaluation, simulated results\nhave shown a significant reduction on total energy consumption of our proposed\nalgorithms compared with an existing First-Come-First-Serve (FCFS) scheduling\nalgorithm with the same fulfillment of performance requirements. We also\ndiscuss the improvement of energy saving when additionally using migration\npolicies to the above mentioned algorithms.\n", "versions": [{"version": "v1", "created": "Tue, 28 Oct 2014 21:10:35 GMT"}], "update_date": "2014-10-30", "authors_parsed": [["Quang-Hung", "Nguyen", ""], ["Thoai", "Nam", ""], ["Son", "Nguyen Thanh", ""], ["Le", "Duy-Khanh", ""]]}, {"id": "1410.8176", "submitter": "Kasim Sinan Yildirim", "authors": "Kas{\\i}m Sinan Y{\\i}ld{\\i}r{\\i}m and Ruggero Carli and Luca Schenato", "title": "Proportional-Integral Clock Synchronization in Wireless Sensor Networks", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In this article, we present a new control theoretic distributed time\nsynchronization algorithm, named PISync, in order to synchronize sensor nodes\nin Wireless Sensor Networks (WSNs). PISync algorithm is based on a\nProportional-Integral (PI) controller. It applies a proportional feedback (P)\nand an integral feedback (I) on the local measured synchronization errors to\ncompensate the differences between the clock offsets and clock speeds. We\npresent practical flooding-based and fully distributed protocol implementations\nof the PISync algorithm, and we provide theoretical analysis to highlight the\nbenefits of this approach in terms of improved steady state error and\nscalability as compared to existing synchronization algorithms. We show through\nreal-world experiments and simulations that PISync protocols have several\nadvantages over existing protocols in the WSN literature, namely no need for\nmemory allocation, minimal CPU overhead and code size independent of network\nsize and topology, and graceful performance degradation in terms of network\nsize.\n", "versions": [{"version": "v1", "created": "Wed, 29 Oct 2014 21:51:09 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Y\u0131ld\u0131r\u0131m", "Kas\u0131m Sinan", ""], ["Carli", "Ruggero", ""], ["Schenato", "Luca", ""]]}, {"id": "1410.8357", "submitter": "Long Thai MSc", "authors": "Long Thai, Blesson Varghese, Adam Barker", "title": "Executing Bag of Distributed Tasks on the Cloud: Investigating the\n  Trade-offs Between Performance and Cost", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  Bag of Distributed Tasks (BoDT) can benefit from decentralised execution on\nthe Cloud. However, there is a trade-off between the performance that can be\nachieved by employing a large number of Cloud VMs for the tasks and the\nmonetary constraints that are often placed by a user. The research reported in\nthis paper is motivated towards investigating this trade-off so that an optimal\nplan for deploying BoDT applications on the cloud can be generated. A heuristic\nalgorithm, which considers the user's preference of performance and cost is\nproposed and implemented. The feasibility of the algorithm is demonstrated by\ngenerating execution plans for a sample application. The key result is that the\nalgorithm generates optimal execution plans for the application over 91\\% of\nthe time.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 13:01:30 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Thai", "Long", ""], ["Varghese", "Blesson", ""], ["Barker", "Adam", ""]]}, {"id": "1410.8359", "submitter": "Long Thai MSc", "authors": "Long Thai, Adam Barker, Blesson Varghese, Ozgur Akgun and Ian Miguel", "title": "Optimal Deployment of Geographically Distributed Workflow Engines on the\n  Cloud", "comments": null, "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.DC", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  When orchestrating Web service workflows, the geographical placement of the\norchestration engine(s) can greatly affect workflow performance. Data may have\nto be transferred across long geographical distances, which in turn increases\nexecution time and degrades the overall performance of a workflow. In this\npaper, we present a framework that, given a DAG-based workflow specification,\ncomputes the op- timal Amazon EC2 cloud regions to deploy the orchestration\nengines and execute a workflow. The framework incorporates a constraint model\nthat solves the workflow deployment problem, which is generated using an\nautomated constraint modelling system. The feasibility of the framework is\nevaluated by executing different sample workflows representative of sci-\nentific workloads. The experimental results indicate that the framework reduces\nthe workflow execution time and provides a speed up of 1.3x-2.5x over\ncentralised approaches.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 13:05:13 GMT"}], "update_date": "2014-10-31", "authors_parsed": [["Thai", "Long", ""], ["Barker", "Adam", ""], ["Varghese", "Blesson", ""], ["Akgun", "Ozgur", ""], ["Miguel", "Ian", ""]]}, {"id": "1410.8568", "submitter": "Damir Juric", "authors": "S. Shin, J. Chergui, D. Juric", "title": "A Solver for Massively Parallel Direct Numerical Simulation of\n  Three-Dimensional Multiphase Flows", "comments": "42 pages, 14 figures, 2 tables", "journal-ref": null, "doi": null, "report-no": null, "categories": "physics.flu-dyn cs.DC physics.comp-ph", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  We present a new solver for massively parallel simulations of fully\nthree-dimensional multiphase flows. The solver runs on a variety of computer\narchitectures from laptops to supercomputers and on 65536 threads or more\n(limited only by the availability to us of more threads). The code is wholly\nwritten by the authors in Fortran 2003 and uses a domain decomposition strategy\nfor parallelization with MPI. The fluid interface solver is based on a parallel\nimplementation of the LCRM hybrid Front Tracking/Level Set method designed to\nhandle highly deforming interfaces with complex topology changes. We discuss\nthe implementation of this interface method and its particular suitability to\ndistributed processing where all operations are carried out locally on\ndistributed subdomains. We have developed parallel GMRES and Multigrid\niterative solvers suited to the linear systems arising from the implicit\nsolution of the fluid velocities and pressure in the presence of strong density\nand viscosity discontinuities across fluid phases. Particular attention is\ndrawn to the details and performance of the parallel Multigrid solver. The code\nincludes modules for flow interaction with immersed solid objects, contact line\ndynamics, species and thermal transport with phase change. Here, however, we\nfocus on the simulation of the canonical problem of drop splash onto a liquid\nfilm and report on the parallel performance of the code on varying numbers of\nthreads. The 3D simulations were run on mesh resolutions up to $1024^3$ with\nresults at the higher resolutions showing the fine details and features of\ndroplet ejection, crown formation and rim instability observed under similar\nexperimental conditions. Keywords:\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 21:39:07 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Shin", "S.", ""], ["Chergui", "J.", ""], ["Juric", "D.", ""]]}, {"id": "1410.8772", "submitter": "Anish Varghese", "authors": "Anish Varghese, Bob Edwards, Gaurav Mitra and Alistair P. Rendell", "title": "Programming the Adapteva Epiphany 64-core Network-on-chip Coprocessor", "comments": "14 pages, submitted to IJHPCA Journal special edition", "journal-ref": null, "doi": null, "report-no": null, "categories": "cs.AR cs.DC cs.MS", "license": "http://arxiv.org/licenses/nonexclusive-distrib/1.0/", "abstract": "  In the construction of exascale computing systems energy efficiency and power\nconsumption are two of the major challenges. Low-power high performance\nembedded systems are of increasing interest as building blocks for large scale\nhigh- performance systems. However, extracting maximum performance out of such\nsystems presents many challenges. Various aspects from the hardware\narchitecture to the programming models used need to be explored. The Epiphany\narchitecture integrates low-power RISC cores on a 2D mesh network and promises\nup to 70 GFLOPS/Watt of processing efficiency. However, with just 32 KB of\nmemory per eCore for storing both data and code, and only low level inter-core\ncommunication support, programming the Epiphany system presents several\nchallenges. In this paper we evaluate the performance of the Epiphany system\nfor a variety of basic compute and communication operations. Guided by this\ndata we explore strategies for implementing scientific applications on memory\nconstrained low-powered devices such as the Epiphany. With future systems\nexpected to house thousands of cores in a single chip, the merits of such\narchitectures as a path to exascale is compared to other competing systems.\n", "versions": [{"version": "v1", "created": "Thu, 30 Oct 2014 08:29:11 GMT"}], "update_date": "2014-11-03", "authors_parsed": [["Varghese", "Anish", ""], ["Edwards", "Bob", ""], ["Mitra", "Gaurav", ""], ["Rendell", "Alistair P.", ""]]}]